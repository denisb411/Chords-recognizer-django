{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NN_model import DNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('samples_nylonGuitar_20480_fingerNpick_Mm7_R1B.csv')\n",
    "# df = pd.read_csv('samples_nylonGuitar_1024_Mm7_R03.csv')\n",
    "# df = pd.read_csv('../CachedData.csv')\n",
    "\n",
    "X_load = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "y_load = np.array(df.iloc[:,-1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 326)\n",
      "(12, 1281)\n",
      "5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEYCAYAAAAXsVIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac221f49b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAEYCAYAAAAwBWxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3X2YJMld2PnvLyIzq6qrX+ZNs6t9X3wShwSWEGsOgeDB\n4EOWfewJMDqfAAmMvYCQDx8+S8IPYCTM2cgIDhkErB7LMggQGPRixJvP1oEtQIIVIPBKYrFe9kWr\nfZnZnp7u6qp8ifjdH5FVXd1d3V2zmumenv195snJrKisiMjIt+jIzEhRVYwxxhhjjJnmjjoDxhhj\njDHm6mOVRGOMMcYYs4tVEo0xxhhjzC5WSTTGGGOMMbtYJdEYY4wxxuxilURjjDHGGLOLVRKNMZeN\niPyAiLztqPNhjDHmM2eVRGPMJRORl4rIPSKyISKfFpHfFJEXHHW+jDHGXD7ZUWfAGHO8iMh3A68B\nvh34baACXgjcCWxeQjyZqjZXJJOfIRERQFQ1HnVejDHmqFhLojFmbiKyArwO+E5VfYeqDlS1VtX3\nqOqr2tkKEflZEVkXkXtF5I6p339SRF4tIn8GDEQkE5HPEZHfEZEL7fx3Ts3/VhF5U9tSuSEivyci\n14vI/yMiqyLyURH5/Kn5XyMiH2vT/rCIfM3Ud15E3iAi50TkEyLyShFREcna739HRH5IRH6PVNn9\nLBH5FhH5SBvfx0Xk26bi+3IReUhEXiUij7Utqi8Wkb8lIveJyBMi8k+v1LowxpgrzSqJxphL8Xyg\nC7xzn3nuBN4OnAD+A/ATO77/34G/3X4vwK8B/xE4C/xD4OdF5LOn5n8J8L3AGaAE/gD44/bzrwA/\nOjXvx4AvBVaA1wJvE5Gnt9/9A+BFwHOB5wEvnpH3bwLuApaA+4HHgP8FWAa+BfgxEXne1PzXt+Vx\nI/D9wJuBbwS+oM3H94nI7XsVlDHGXM2skmiMuRSngXMHXCZ+n6r+hqoG4OeA5+z4/o2q+qCqDoEv\nAhaBf6mqlaq+F3gPqSI59k5V/aCqjkiV05Gq/mwb/y8Bk5ZEVf33qvqwqkZV/SXgL4EvbL9+CfDj\nqvqQqq4C/3JG3t+qqveqatO2kP66qn5Mk98lVWa/dGr+GvghVa1JFeMzbRrrqnov8OEZy2+MMceC\nVRKNMZfiPHBmfIl2D49MTW8C3R3zPzg1fQPw4I57/+4ntcyNPTo1PZzxeXH8QUReJiJ/2l66vgB8\nLqniNklrj3zMDBORF4nI+9tLxxeAvzUVH8D5trI6zsus/C5ijDHHkFUSjTGX4g9Il3xnXaqdl05N\nPwzcLCLTx6JbgE9daqQicivpcu8rgdOqegL4b6RL2gCfBm6a+snN++VNRDrArwI/AlzXxvcbU/EZ\nY8w1zSqJxpi5qeoa6d67n2wf0lgQkbxtcXv9k4jyA6TWxle18Xw58NWkS7eXqk+q5D0OICLfQmpJ\nHPtl4LtE5EYROQG8+oD4CqDTxteIyIuAr3oS+TLGmGPJKonGmEuiqm8Avpv0MMnjpEu0rwTe9STi\nqkiVwhcB54A3AS9T1Y8+ibg+DLyB1Nr5KPB5wO9NzfJm0j2Ffwb8CalVsAECM6jqOvB/kCqXq8BL\nSQ/iGGPMU4Ko6sFzGWPMNaZtGfxpVb31qPNijDFXI2tJNMY8JYhIr+3DMBORG4F/xv5d+RhjzFOa\nVRKNMU8VQuo7cZV0ufkjpPsrjTHmWGpfCnCPiJQi8tYD5v0/ReQREbkoIm9pH87bP3673GyMMcYY\nc/yIyNcCkfRq1J6qfvMe870Q+FngK0i9SrwTeL+qvma/+K0l0RhjjDHmGGpfj/ouUh+2+3k58G/a\nlwWskl6v+s0Hxb9fh7hXjTMrC3rb2RNTvZNJmhZpB0BcGitQNxAChAhB0ahprKT69rQ2CgTwgjgB\nJ5C5rbjZkS5t2uOxTEfE/r2o7Wq43Rkw48cyFS4z5rvUXtt0R7rjzzoVsFcD887y2CuBXXG148l0\nO0PU3XnQqbAd05OG7+nvtmVJtlbFeF16167TLE1nGXi/tb4uVYhQVe02FqAKaIhQKxohBiEERxMd\ndRQaFYIKQdPiBlWiQtPmX4COd3S9spQ1ZFnEF4osZNApoMjT8jbtdl036CiglVJVniY6GnVUEYIK\nzVQaQZVIJBCIRCINqhElkvqv1j22wFllMz3vPFcgpmIShyAIDhGHI8Ph8bg0iKTVhWzfrbelnoyX\nKyjUOl66hkhANaBou4zbNpZtkWzP/axlkTbfKRcirs274PAI42VIUw6ZLIMXwct481N8G41Ddx1S\nJjlUiEi7bGm6DlBFpSFQUxNpiBra9TC1D4lM53hqut0Xtg5a21JW1bQdTOIal1hbXrvKau9j1azD\n0u5taNY60N3f7/l5lnn34Sd7xWxn/HulN3t/2ds8B9jxNjj+b2o9izD+t23fQhB8+8m126fgRHCw\ntY068CheIHeKEyX3gSyLSEeQXp7Oga5tR9os0SqdPMXRHk99Gm/Ltuye3naOnJp531U3Pc9UPLQ7\nlkjK285j+GgEZQ2jGm0iGiA2gqpMdpc/Xzt3TlWftl/qV9oLX/iFev782lzzfvCD990LjKaC7lbV\nu59Ess8G3j31+UPAdSJyWlX3rGAei0ribWdP8Edv/Na0dbp248h8OtEXeZruFOnk3zTwyDlYG6BP\nbKAXS3TYENYDcQSxBI3pmCgCkoHvgBTg+h7Xz5DFAjm5AJ18aycZVzjGech8+s77ND3Oj5vasWaJ\ncft4Z0VneqOfpO22dsZx/FPz6fR8B6ULSIxTlbTYDro1rTqVT91a/p1p7FXJGv9+HGcTUqE3IYU1\nbeUqKlRNmidMfx/bin1M000aEyJaRTQCjaLNjsqsgGQCmeC6DjoZbqkDix3od+HMSVjqo2dOo8sr\nUBR7l9d+1tdxDz4Iqxfhwjr68CpxdUTzaE29AaOLORvrHc4NFnhos8eFOuN85Rg0wqBRLpTKoIlc\nqGoUpXCe25cKPmdZ+dLrz3Hm5IClm2o6n38aPvsW9MYbIEbk3Hl44gI8skrz0fOMPqU8/OAKj232\neLzs8PAw40ItPD6CjbpNo67Y1JIL7gIj2WAYVynjBk0cUochURvi1Bv2xpW4cd/WgkPbv6xU47YK\n5vaXpExvFm4yHsfnXQcvGbnvk7sF+u40C7rMclzmlF9gwXsWc0fXC4WHrhdyB162VnDQVIkaBWW1\nVNaqwKP1gA0ZsObOMYprjOJFmjCkiSUhViiRGBuYWgZgskxbYdO94PhJ3p0rcJKRZ31y18O7Dl23\nTCEL9PUEPe2xoD2WfMGC9ywXjn4mnOxAP4O+VxazSOEiCz6Su9hWJMeV+PQHRB0dm8ExCo71RtgM\nwkMD+NRmzePNgEf8QwzjKsNwgag1QRtirNty9m3Fe2vdOcnbsvf49mU3gse1F48CdSojLWliRYgl\nqjFtD2157Syrnet7uv9zwe0K232havc6mC77ND2Vxh7b1/ZMzDrmOXa1BuyIa/efRm10O2suk/hn\nLZ/fmm1GPnbvH2Gf73bG47ftP+BwLkNweFfgXI6XDO86ZDI9dOnqIjkFC7FPh5xFV9D1jl7mWM4d\n/RxOFrCUKSt55LpuxWJec+OJi6ycGdG91ZE95+lwcgn6Cyk7H/oYzScvppJY9Ei/QE73odceQ8fn\nqOlz5PR5eny+zPxWBW+/89X4fJNlIIJmWRtXBt0O6jPo9XYdw91HPwr3f4r40UcIj5fUF5TRakZd\neZompXfzf3jz/XsnfDjOn1/jA3/4M3PNm/m/PlLVOy5DsovAdM30YjteYp9WyGNRSTTGGGOMuSYo\n2xpuDskGsDz1eaUdr+/3I7sn0RhjjDHm0Gi66jnPcPncCzxn6vNzgEf3u9QMVkk0xhhjjDk843vq\n5xkO0Pb72iXd/+BFpCsis64S/yzwrSLyLBE5CXwf8NaD4rdKojHGGGPMoZl6BuCg4WDfCwyB1wDf\n2E5/r4jcIiIbInILgKr+FvB64P8D7gc+QXqhwL4O9Z5EEfkkcB3pDt4a+H3g21X1wcPMhzHGGGPM\nkblM9ySq6g8AP7DH14s75v1R4EcvJf6jaEn8alVdBJ4OPAr86yPIgzHGGGPM4Rs/uHJ5WhKvqCO7\n3KyqI+BXgGcdVR6MMcYYYw6VHsmDK0/KkXWBIyILwP8GvH+P7+8C7gK45ezyrFmMMcYYY44ZRebp\nB/QqcBSVxHeJSAP0gcdJ7xvcpe1R/G6AO55xg71g2hhjjDHXhqvgUvI8juJy84tV9QTQBV4J/K6I\nXH8E+TDGGGOMOVxK+0ayOYYjdpT3JAZVfQfpSecXHFU+jDHGGGMOz2XtAueKOsp7EgW4EzgJfOSo\n8mGMMcYYc2gUCEf/UMo8jqKS+GsiEkjFdD/wclW99wjyYYwxxhhzyPSqaCWcx6FWElX1tsNMzxhj\njDHmqjK+J/EYOLLLzcYYY4wxTz3WkmiMMcYYY3ZSkKugo+x5WCXRGGOMMebQaHrryjFwPCqJK0vE\nF37lfPMOh6lfn8wjZQ1NROsIMaABmpEj1EIMgqoA4JzifCTrBXwn4Dol2clNpGh7CJI0H5kDJ4hr\nPzuZhE3mAQgRoqJV2Eq/iWilxDKiDcSSNA6gTcrLdAfs4kBEcbkiGfgOuK4gHcH1M2QhR5Y60CuQ\nhQ4sL0K3gP4CeI9mGbg2/02D1DWMSqgbKEsYDGFUw7CCUY3WAaqANimvqG7Pj5e07IXfKofcT5VB\nWw7ebaUbUzyT/p6akMqlidvLKGoqn6Dt99Nj0KBoQ5qelBnEdj2G2hHj9nUqojjfkOUlWUfxPSU7\n8QB+OcOd6SMrC9DNIc8g89ApIMvazylM87xdrqnliRG5uA6f/DS6OkDXRjSPlNRrMFzLKUcZozJn\nUOUMmpxG029zgcIpZCl/Xe/pekcdFdVUHOuN8Oig3y7DBvl1F3GnV+HsGej30ZtugLNPg1uHZJ+9\nxuLaOs987ALPWF0nrj5O/emGat2xvtphMOywUeWcG3VZb/qcr1bYaITVShg2yijAoInUUWmi7ro9\nJpICVNO0KjQaUZQGRVUn84zH0xyCQxARMoRcPJkTFryn8MJiLvQzoZ8pK7niBXKneElDJkymvShO\nIBfFSUrrXJlzvsp4ZLTCer3CankdgyYw0JoyqymlopaKhoZAnZaFrQ06yta0a9eR4HB4cgpyLcg1\np0dB12X0s4yed3QzYSmHjhNWCqXnlUWvLOcNi1nFqU7JQlGzvDCi22vIuwHf0UlnY+PtttzMqErP\n2qDHelWwUedsBkejUEahihDbcszJWNBlcOAkp9GSqDVBa5RI1Hb5NE6GhmrGOkmZcC6bzBdJYyc5\nSsBJtpXXqfJSnT2d9jW3bTwuyxTmd+VDNewZ/7Z02ArbCt+anv4+CduWdnsmpz/4bR+n870fmYpz\n+292/j7OSHMvu+OcjHG7wgWHc/lkXabUpv5pILbl4Nr9rusdi7lnMReu78GpQrmxV3GmU3KyW3Lm\n9AbFYkP3Roe/ro/cdAr93Gemc4lz0ARkbR1fBwb3rON8xPdq/OND3IIfZz6NszZf4/PkAedImjg5\n52gZ0EbRSttzQdpfdp0Xs1RsruOQok3DCeJg9GDN5rmM80/02awWGTQ5G3VGrUId51ohh8cuNxtj\njDHGmG0UqyQaY4wxxpidro63qczDKonGGGOMMYdFAXtwxRhjjDHGbGcPrhhjjDHGmJ3snkRjjDHG\nGDOT3ZNojDHGGGO2szeuGGOMMcaYnZTUb/AxYJVEY4wxxphDo9t7Cb+KWSXRGGOMMeawKHZPojHG\nGGOMmcHuSTTGGGOMMdtYS6IxxhhjjNlN7cEVY4wxxhizg2IPrhhjjDHGmJ3ULjcbY4wxxpgZrJJ4\n+YRPnGf9m/8tPldcR/Ed8CsO189wpxdgZQGetgInVqDIoawgz+DMMrKygB/V+JtKdNTQHdZoFSBE\n4ihCVLRJK0ucAwdSOKSXgRNo4tbKbCI4QZ2kz06Q8XfjsKhobP9KqANapXS0VuIIwhBC5aiGnrry\n1I2nrDKa6KiDI6gjRCGoTJZfBDKJeFG8UwofyHyg29kkyzbI8kjeDbhccQWIB3GAS7/XBogQ69TC\nHWsh1EJoXBqCQxVidET1aNzaLMQpThTnIt4rPqtxTnE+4nNFMsX5rbTGtAENQgwprRiEGBwxCjEK\nqqCTZRREHN4rIorzinOKzyPiwHlwuSJZWjafAR0m5RxDRJu0XDFIWsbxMgVHPVJiULSJhPUaf3EN\nt7CBZJIK1wnSzaCTIYsd6Heh10FOrcBCD11eRjsd6Hah10PLEjlzClnfQAZDiicuUGyMWFgbQtmg\no5K4vkF9LrL+SMHmZsHasMtmkzEKnvUmY7NxXGw8ZXSMAnQ9XNdp6Gc1IprKa6PBrW0ia+soQL+P\n9nppfPYsuLbQY0RipGgaOqFhqaqhrpGqgo0BbI7SeFTDYARVQEPc2rbbbXiy3UZF6/S9VkosI1pB\nKNlVzqrt9NT2mrbZdj22g++l/db1BbfgkX6OLORIJ21rcXVIeHREWFfqDWG0kVPXjrrOJtthngWK\nTkOnHxhezBkMClaHPUaNZ9BklNFRxYKgHaKybR+KurWLCopLqx0vSi5K7iI9H+hmgaWiopM19Lob\n9Fcq8sVIfsrhljKkmyH9Aro59DtQZJDn0FmEzKfBubRdAdQNrK3D+hB97CJxdURzvqHchMGww6cH\nfR4dFTxaeh4YwPlR5JFykzU2OCefYjOep4obNE2FtpenRNJ6dzhE3NZnyaFN1m9bF65dboeIx0uG\naiQSUQ0ocRI3gLL9Xqlt37XTkd1hO/M2/iziEDxOMkT8JN+eHBE/ydtW+rGNN6Q8Eib5jVqn6fG4\nzbtq2PbbbdviVNyT9GQrzE19Hydpb+Vhunwm4xnp7E7LbR/vOEjuzMv0+nSS4yQnkw6ZdPDkdFkk\no0Nf+3S0oCsFfZ/RcY7F3NH1QjeDxQwWMljOlMUscqqo6WcjlvKa00ubLPQr+tc36Ry6UuBOLqXt\neGUBTizB6ZPojTdCtnUe0LNn4cuh++hbISqSSTpHZi7tXE1bHu05kqjpPDnPObJRtIpoqcRKCcN0\nroq1oynTOSM0bnLeGPPteQLa85RTLlxYYn3U4XzZZbPxjKJjGNL5NFxNdTJ7d7MxxhhjjNlFpyrW\nVzmrJBpjjDHGHCZrSTTGGGOMMbvo1XT9e2/u4FmMMcYYY8xlMe5Me57hACJySkTeKSIDEblfRF66\nx3wiIv9cRD4lImsi8jsi8uyD4j+SSmKbuVUR6RxF+sYYY4wxR2POCuJ8T0D/JFAB1wHfAPzUHpW/\nrwf+HvClwCngD4CfOyjyQ68kishtpEwqcOdhp2+MMcYYc2SU9MaVeYZ9iEgf+Drg+1R1Q1XfB7wb\n+KYZs98OvE9VP66pO4C3Ac86KKtH0ZL4MuD9wFuBlx9B+sYYY4wxR2f+lsQzInLP1HDXVCzPBBpV\nvW8q7EPArJbEtwN/RUSeKSI5qf71Wwdl8ygeXHkZ8KPAB4D3i8h1qvroEeTDGGOMMeZw6SW9ceWc\nqt6xx3eLwMUdYReBpRnzfhp4H/AXQAAeBL7ioMQPtSVRRF4A3Ar8sqp+EPgYsNdNlneNa87nRqPD\nzKYxxhhjzBWjbafiBw0H2ACWd4StAOsz5v1+4AuBm4Eu8FrgvSKysF8Ch325+eXAf1TVc+3nX2CP\nS86qereq3qGqd5zpdg8tg8YYY4wxV1R67djBw/7uAzIRecZU2HOAe2fM+1zg7ar6kKo2qvpW4CQH\n3Jd4aJebRaQHvATwIvJIG9wBTojIc1T1Q4eVF2OMMcaYI6FcljeuqOpARN4BvE5E/j7w+aQHgr94\nxux/BHy9iLwdeJz0JHQO/Pf90jjMexJfTLoO/nmkx7XHfpl0n+I/PsS8GGOMMcYcvku7J/EgrwDe\nAjwGnAe+Q1XvFZFbgA8Dz1LVB4AfBs4Cfwr0SZXDr1PVC/tFfpiVxJcD/7bN7ISI/ATwRhF5tao2\nh5gfY4wxxpjDd5kqiar6BKkRbmf4A6QHW8afR8B3tsPcDq2SqKp/c4/wXya1JhpjjDHGXPPmeCjl\nqmDvbjbGGGOMOSzj1/IdA1ZJNMYYY4w5LKqX5cGVw2CVRGOMMcaYw3Rw9zZXhWNRSQyNY/1ClzwP\n5EWgWAhIEZGuQuGh34Xrnka8/npYmtXR+GwHdhJZlsi5x5G1izAYwupFGIxgfYgOa3TUEAc1WkXi\nMKINaAWxhhgg1o7YQGg8qkIMQtM4YnSE4FCFEB2qAoB3itOIFwi6PXeOtEFFhTo6IqAjwbuI80o+\nCngf8Vn67LwiDkTS71QFjRCDoFEIjSPGlJ8QXQqLspWeKCKk+J2SFwGfRfJuxHUU3wHXF1zXI/0c\n6WaQ+zTOPLg2rqhQNWgVoGzQUYOWDXEjEEslDNvyastqnFeRdhkyxXnwPZACXM8hhUNyl9JykrYB\nESRz6fM4bTf1WWQrX64t26qBtU20bNDNGgYV8dwm4gDvkMJD4ZF+gXRy6Baw0k/LNBxt/SUYIxQZ\nct0K5BnS7+FCIFvfpLe6gQ4q4toauhkIg8joccfgYsHqxgKqaR1ef/Yii7dGspv70ESkvwC3nUVv\nvQm9+WbI5ttVpw87GiPUNTQNUo7Se0DrKuV3xqUOmZ5uGiTG9i/eJv02hK3fxqm/gqenx2XrXCpv\nkZT3Ike9h24H/PhzhmYZsr6Oe+RR3MceIju3QX5+SHG+SttGYLL+86fnuOuX4XNuZXE44mlVw23D\nsn3HaQNh9nKl/MjWeLwtjLeHPOVnMu51Ic/Rbgd6PbTThV4PsgzdUcYHahrk4hoMBsj5VfzFDfza\nBsUja5xc3eSmh9YoLzg2NwqeWO8zqDPWqoIqnuCx8gyPjBxrNVwolSoqYaqoMydkDop2nDvoeaHj\nlX4GXad0vXIib1jOA6c7I1Z6I06d3SQ2EEM6BsQg6fgUpe2abWtLGE9HTceNFLZ9EaPKZN6oKa66\nPa6lcZonTMeFtG8d25pWhGacBtBMxwuTecbjWaRdO+PVLWja5cffi+Joj2/t2MnW71LaMtmMUv62\nLyfAeDVMymdmbrafY3amnTnFi+IlkruIF01jpxQ+kPlAkafjel4E8k7A5w3ZwgVcFyQX3KJPx8KF\nPB2rcg9FOhZTZGno9NK2nudp+xZJY+fAe9Q5JAQQQYsibesxwvo6cu4ccmENPvYQLPfhe795x8qP\nyIVV5Nx5WN9I58hhCcMKXRtunSNHAW2UOFS0gVhuP0dOb4vjc+N0+Y7LDyBrz3E+i2RFRLJ0rpIM\nlpoSgDL6VLaNR3CEqe3vaqCAHo+GxONRSTTGGGOMuSbYPYnGGGOMMWYWbaySaIwxxhhjpllLojHG\nGGOMmcnuSTTGGGOMMduoWmfaxhhjjDFmBmtJNMYYY4wx2yhosJZEY4wxxhizk7UkGmOMMcaYnawz\nbWOMMcYYs51iLYnGGGOMMWY7ey2fMcYYY4zZTUHDUWdiPlZJNMYYY4w5RNaSaIwxxhhjtrN7Eo0x\nxhhjzCzWkmiMMcYYY3bR49GX9pOrJIpID/gS4C9V9f7LmyVjjDHGmGuTKmgjR52NucxVSRSRtwJ/\nqKpvEpEC+EPg2UAlIl+jqr95BfPIoMn4wMNnyZ3iRem4SD9r6GaBle6IXvdhlk59gvyE4nqyda3f\nzVgWJ5NwyQRcGsQBsvUZJ1AFmrWaOFRiCc1AaCpHXXqaxtEET9PkhOiogidEIagjRCEihCgoQlSI\nujUN7AhP4wiopg1n5yKI6OSzE0XasRMQUrk42RrTLs7Y9F8t47xsfW7TaoO8xFQUKLmLeKcUPpD5\nQKdoyLKIc0pWBJxXnC8RV4LT3WlGIQYhNhAaRwyOpskIoSAERxMcITqCSsqXpnKbrK92Gb2LeFEy\nH/BO8T7iXJtP12xbxzEKqhCjIwSXptu4t82n0q63DqrdXellLpL7QKczIC8CRS/QORlxXQEPUjhc\nP0NWushiB86egDOniLffBv3+9u2uHRyQA0vA9eMv19eR9XXIMuSJJ+ChR2BYpt+VJTzxRLs91tuv\nUYgDNx4E9RlkGXQ6aexcmu500B35mcdh/aGrTYMUORQZ5B4pHFIEXGy39y74JY+75STcfgPxC553\nSDnbIUaoa9jcROoaylHaeWK7TpyDzENeoL0e9HqQZeip03DqNHrzLduiE6DTDstMbQ8td9998Pt/\nzuhDF3jwoyuc2+zxyKjLRuMYBUcVISI4FC9QOGUxiyz4yKlOxXJRcaI/5OT1m3RucGTPehrc+j8Q\n/9oXXPmyModKd4wv+fdVlbZtaLfjDMoybdudAv38z4GlJfjXvwDNeHtvz1WDmrAeiJvQbApNKYTG\nUZUZITiqujs5xjftebKObuY5cqfxOc5LOv57l85JmQ90s4Y8D+R5Og/5LDIc5WxWBaPGs9l4RjHt\nK0GF5qpqudt9PrpazahGzfRC4P3t9J1sneN+oB2MMcYYY8xBNP29P89w1OatJJ4EHmun/ybwq6r6\nGPB24FlXImPGGGOMMdeia62S+AjwuSLiSa2K/6kNXwTqK5ExY4wxxphrjZJuLZtnOGrzPrjyFuCX\ngIeBAPznNvx/Aj56BfJljDHGGHPtUYjh6CuA85irJVFVXwf8PeBu4AWqWrVfNcAPX0qCIvJ3ReQD\nIjIQkcfa6VeIyPEoMWOMMcaYz8C11pKIqv7qjLB/dymJicg/Bl4FfCfw28AG8Fzg/wL+DVBeSnzG\nGGOMMceNxqOvAM5jrpZEEXmJiHzV1OfvF5GHROS3ReTpc8axArwOeIWq/oqqrmvyJ6r6DapqFURj\njDHGXNNU5x+O2rwPrvzAeEJEngf8U+CNpC7f3jBnHM8ndQn27nlmFpG7ROQeEbnnYrM5ZxLGGGOM\nMVez+S41Xw2Xm+etJN4K/EU7/TXAu1T19cB3A185ZxxngHOqOun5WER+X0QuiMhQRL5semZVvVtV\n71DVO5azhTmTMMYYY4y5iimEIHMNR23eSuKI1IE2pErhuAuctanwg5wHzojI5D5IVf1iVT3Rfjdv\nXowxxhjIj/HJAAAgAElEQVRjjqXj1AXOvBWz/wq8QUS+D7gD+I02/JnAg3PG8QekB1P+10vKoTHG\nGGPMNeRyVRJF5JSIvLPtMeZ+EXnpPvN+loi8R0TWReSciLz+oPjnrSS+EqiAvwN8u6o+3Ia/iPSU\n8oFU9QLwWuBNIvJ3RGRJRJyIPBe49BfLGmOMMcYcQ1FlrmEOP0mqn10HfAPwUyLy7J0ziUgB/L/A\ne0mvVb4JeNtBkc/VBY6qPgR89YzwfzTP76fmf72IfIrUDc7PAgPg48Crgd+/lLiMMcYYY44dlcvS\nBY6I9IGvAz5XVTeA94nIu4FvAl6zY/ZvBh5W1R+dCvuzg9KYu5/Ey0VVfx74+cNO1xhjjDHmqCkQ\nLk8/ic8EGlW9byrsQ8CXz5j3i4BPishvAn8N+G/AP1TVP98vgXn7SSxE5LUicp+IjEQkTA9zLYox\nxhhjjLmUexLPjLsDbIe7pqJZBC7uiPoisx8ovgn4u6TuC28Afh14d3sZek/z3pP4g8DLSX0iRuCf\nkK6DnwdeMWccxhhjjDFPacol3ZN4btwdYDvcPRXVBrC8I/oVYH1GskPgfar6m+2rlX8EOA18zn55\nnfdy80tID6z8loj8CPBuVf2YiHwE+J+Bn5kzniflXKn8u49HvAi5eHKX0cu6dL2wmEPXCycKZcEr\nhVMcIPLkuiof15qdQFQooxBUUKBpe0CP7N9MPO4lvVEICnUcj4UyKmWAMih1hCoooxCpNVLFQINS\nayAQiCiR2ObL4RA8ngyHF0cuDi+SysU5vIBDEEn5n0XavLt2HmmnRaQtNybjmeUjW2Xk3dbvvchk\nOsWbCkERoqaybFQJCiFCGaGJ2paNEtJiEtHJMngRMgdeoOOF3KV1XTgld7DgIXNK1ykdp3R9xIuS\nOyUTbfOztR1EHedqvH6Eul2/42XLRSlcpOsDK0XFQgGLRUlvpaY4LWS3LSH9AooM8gy6OXQKyDz0\nupB5ZDCAcgRVDWUJsV0459rCyiDL0H4f+n1YWkKX0h9+cuECrA3QcxsQV5HHLiAnFtPvywqaCCFA\n1TAp2Kho1MlWKeOV0G7E2sRU6E1Eq5DGQdEqQqNonX6vDWgDRIg1aGx7/W/av2rjjm3JgfMKTnEe\ncClM/Nb382gGMFzLWVvrMahyRuEUwyYjKnhROj7QyxrO3HORpZOP0/vtP0dHEa2VMIRYQagcoRbq\n0tM0jiZ46tpTR0dZZ9TRTYagMhmiCpH0V30kFed+2/x4nvF2vXM+L5q2QVFyl7ZHJ9p+F9v9K4VJ\nG+ad4l1M87uYyhQ4t77AxzdO8sDm0/jEBqyWgcerkk0tGcmQoQwI0hCoU3njyLVDToee9uhql570\nWM6vp+cdJzpCP9vkZPFfgHRMCrp1bErTaZ+s0+ZC3e6jVYwEhSpEIkpQJe54HYQT2Tr+tOPxcSkd\noyRNj8eyVW47TZftOJm4a3r2MV5mHLxUdRLnzl+Nw9N6TfPt9aaLnVHPc5ydZXzsha3ycEDu0nE1\nk3S8Gx/rcgddl85vCz7S8UrXRfpZQzcL9POabtaQ54FetyYrAkU/4HuQnXS4pRxZ7iBnlmClD2dP\noyvL6OISrKxAUaRhW8FEpCyhqpHhiObn/gv//j23TcprvGx1FGqFoDI5R8L+58npc2S69JrOCUGF\nanJe2Dp3Tq+/cXl1PRROWMiUroee18n5Oeh4fbZ5uQreXLKNcrm6t7kPyETkGar6l23Yc4B7Z8z7\nZ8CXXGoC87YkXgd8uJ3eAE60078FfNXMXxhjjDHGmF3inMN+VHUAvAN4nYj0ReQFwJ3Az82Y/W3A\nF4nI3xARD/wj4Bzwkf3SmLeS+ADpGjbAfwde2E4/n9SEaYwxxhhjDqAIIbq5hjm8AugBjwG/AHyH\nqt4rIreIyIaI3AKgqn8BfCPw08Aqqc/qO9tLz3ua93LzO0lvWnk/8OPAL4rIPwBuBP7VnHEYY4wx\nxjzlXa63qajqE8CLZ4Q/QHqwZTrsHaSWx7nN20/i90xN/4qIPAR8MXCfqr7nUhI0xhhjjHkqu+ru\nk9zDk+onUVXfT2pVNMYYY4wxc9LL9+DKFbdnJVFEvnbeSNomTGOMMcYYc4Bw3CuJwK/MGYcC/jLk\nxRhjjDHmmpa60DrmlURVnffJZ2OMMcYYM6eD+lu+Whz6u5uNMcYYY57K9uqw/Woz77ubf0hEvm1G\n+LeLyA9e/mwZY4wxxlx7LvG1fEdq3kvK3wR8cEb4B4GXXb7sGGOMMcZcw9rXGM4zHLV5LzefBc7P\nCD9PemWfMcYYY4w5wLgl8Ti4lNfyfdmM8C8DHrp82THGGGOMuZYJOudw1OZtSfwZ4MdEpADe24Z9\nJfAvgB++EhkzxhhjjLkWXVNvXFHVN4jIGeCNQNEGV8CPq+rrr1TmjDHGGGOuNVdDK+E85u4CR1W/\nR0T+OfCsNugjqrpxZbJljDHGGHPtUaCJ11glEUBVB8AfXaG8GGOMMcZc847J1ebj0Zm2ArXG9DSQ\nA6LDB8UJVFFwolQBcgFB8KJkCLlTvKRhPN3zES9K4QLdLFD4QC+v6RQN3V5N3o1k3Ui2BJIJsVKI\noA3EGmKAUDpiEELjqCtPjEJZZTTBU0dH2XjK4BkFTxUdm8FTBmmnhVqFYSOUkTR/dIQIowBBlaBQ\nBkUValV0R6+bXgQRKJwjd5A7oZdB4YR+pnQ8FA4WfKRwSi5K5sBLiidOPX5fRqGOQlClikKtUEcI\nmuYbN4kLihfo+FTOhVMWvFK4yGIW6fpA4SILWUPhA3lbztKmqeNH+qOjjo5R46miZ7PxlFEYhjSu\nomMUUj7KkPIRVNq8JCm/UEXwArkImYNOWx6ZKAs+kjul6yMdl6YL15C7SO4i3ilRoYmORh2qIMLk\n+8IH+r2STrdh4WRNtgJuySO9HIoszezavwRjW1hVDW6EXLgATQNr63DuAqwP0dUhcVATNxrKR5XN\n1YJPnV9hvcoJKtyyvM51N67TvVFo1iKxBMkgW9rE9c+jjRIHkTCEesOxvtphfdhhddhl0GRsBs96\nncpwFMfdJ6R1WUdoVGgilFEnYWVQ6qhUQQmaptN+ptREVJU4dShzCF4c+XhwQsencdendZC3gyA4\nAWFrvaXtTtP+HNvtS2EUlFFQyhCpY0rTi5CJsJB5FjJhMYcbeqc4XQRuvm8EpO2iGm9P0TEMwqBx\njKIwCrBeC2VQ1uut+NebmlIDG7JJKSNqSkZs0FDSaIkSCNrsOgY5HCIOad9Amj57pH32z6XSQXA4\n8XhyvGY4PJ6MTDM8GV49GZ6cLJUljtw5vAgd58ic0PGCl1QuF6vAWthg1V1gU9bZlFUaRjSxJGhJ\njA2RiGps97OQ9lfZelOq1A6Hww2ylEdxRK1RjQRtiLEmaoNqRInE2ABxEgahHUdo05lJdj4Huf2z\nTL7/TN/iGuaeUyf53ZHvcfiuPD8JO8pE2y1eDrqcOEnbbSubtJ2125tkk8/eFYh4MlfgXQcnOYX0\nyGWBLosU9OhpjyVOsOhyTnYyThTC0xfgdBG5rlPzV1Yucub0o6x83sfxNy0jN51Bb78Fej2034c8\nB+cgRmQwgPUBxAjnLlCdi3zF7Z+i06vJepF8GVwhaFS0as+RYXyuFEKdzpFN7WkaR4gunSejY9Rk\nVMExChllcO250bXnAteel2AY0vG+as9JIW5fk+m4Je0jHtI+Nby7o2q5yhrtVI/P083HopJojDHG\nGHOt2OfPrauKVRKNMcYYYw6RWkuiMcYYY4yZpkBzTG5KnLuSKCILwHNJb1/ZdiOHqr7jMufLGGOM\nMeYadHV0lD2PuSqJIvI3gF8ETs/4WrnEO5FF5JOk1/lN34H8TFV9+FLiMcYYY4w5TsYP2BwH8z7a\n9ePArwM3qarbMTzZR9W+WlUXpwarIBpjjDHmmnetvZbvNuBOq8gZY4wxxnxmjktL4ryVxN8DPhv4\n2BXMyzYichdwF0BXlg8rWWOMMcaYK0bb/n+Pgz0riSLyvKmPPw38iIjcAPw5UE/Pq6p//CTSfpeI\njHut/R1VffGOOO8G7gZYzp5+TOrcxhhjjDH7uxZaEu8h3V85Xd29e8Z8l/zgSuvFqvqfnsTvjDHG\nGGOOJeXa6Ez79kPLhTHGGGPMU8Sx70xbVe8/zIwYY4wxxlzrjlNL4lxd4IjID4nIt80I/3YR+cHL\nny1jjDHGmGtT0PmGozZvP4nfBHxwRvgHgZddaqKqepvdj2iMMcaYp5rUmbbMNRy1ebvAOQucnxF+\nnvTmFGOMMcYYM4eroJFwLvO2JD4AfNmM8C8DHrp82THGGGOMuYZp6gJnnuGozduS+DPAj4lIAby3\nDftK4F8AP3wlMmaMMcYYc605Tg+uzFVJVNU3iMgZ4I1A0QZXpHc6/6srlLeJrnPcvtgjF8gdZA76\nGXQ9nMiVxSxyuqhZymsWsobMR7yL5C6NnVcyH/Be8VnEOcX5SNaLuBx8D1xHcMsZrt9F+gWcXoRO\nu6hOwDnI/NZncaCxre5HqBooKyhrdG2IblSE8yVhXSlXHaNBznCYszbsstlkrNc5VXSUUaiio45C\no1tN0ON7EZyAICkLgBfFSRp7aaamFQfkLra/SWGZU7xERCCTiBdF2jhEtv+ZoipEbccIqtCoQ6dm\nEwGH4p1OyreTNWRZJPOBohPwWSQrIpIpzoNMbWUaQRsIlaMpHeUoo6oyNsqCsvGMQsZGnTGKjs3G\nUau0ZdOWz668gG/LoOOUjlcyiSz4SMdH+llNNwt0soZ+ryTPI0WvwXdSmcRaiEEItSPGdjqkZY7R\nsblZsLHeIcRxo3tDHSNlnQEN3imdrKFTNCwulnRPNnRuyZFehjhBx38O1gGadFhwOWR5pPCBzGUM\na8+5zR698xXZ4ghimkcKwEMcReJQKc87ykHGcJRzbn2BC1WHR0cFq7VjoxaeqGAUYLNR6hipo1IF\npdZIFQO1RoZUlFJSS8VIBlS6Sa2bBGqaWBK1IWqNapwqZ4eTHO86ZHTosEhXFylCj+V6ma4ULLqc\nrncUXuhljlyUbjZeN0Lu0jrKJa233G1tz0GFURDWG08VlTpC3SbvBToecieUUVlvHA8PO1TRMYrC\nRiOMAgwaoQzKeq1UMTIKyqBpKDWwoUMqKRnKgKFcpGaTMm4QtKSJFU0YEmKFaoNqJGoDhBlHIj8p\nDwCZuhCTwhwiri2vLA0ux0uGdx1y1yNzXTI69FhO/8clurGg6zxehI4XFjKh46ETBEHwteCakyyy\nyFBOEqQh+kgkojNONbHNu9vRfe04v0qklLTeS92giSVNHNLECtVAlFQOjjjZDtI4fdap8HE5TW8v\nk9OfNkzTPVpFdNuFt3lPnfNeBBvnZc/EE9nv3q/90prK7440dN84AR1vY25X9mTcPbG4yTwiebtt\nFTiXtq/M98hcwcAtUEiPXBbY4CTduMDGcJnVMmcz5DxReC7UjqArbFQ5n+XP099YJSsbxDlYXoTT\nJ6HXQ/MCYkQGA6hr8B6KjIU7TtB5bIB0CmSxQE4tQr/bZq89R06Px+dISMfAJsCwhFEF6yN0UBHO\njwjrkWYdNlcLhqOc9WGHsvGUwTMKfvL+Yi9K4QLLnYrFTsWpswO6T4f8fzwJN51Bb78FOp10Pt7H\nq2/ef7UcDjk2b1yZd09DVb8HOAN8UTs8TVVfo7rX3meMMcYYY3ZSnW84iIicEpF3ishARO4XkZfO\n8Zv/LCIqIgc2FM7bBc5bRGRJVQeq+kftsCEifRF5yzxxGGOMMcY81Y0vN88zzOEnSVd2rwO+Afgp\nEXn2XjOLyDcA+bx5nbcl8eVAb0Z4jyfRBY4xxhhjzFPV5XhwRUT6wNcB36eqG6r6PuDdpG4LZ82/\nAvwz4FXz5nPfpkYROUV6d7MAJ0Vk+iYTD/xt4NF5EzPGGGOMeSpTLltH2c8EGlW9byrsQ8CX7zH/\n/w38FPDIvAkcdD36HGl5FPjwjO+VVCudm4h8ktQsOn1n+FtV9ZWXEo8xxhhjzLEz5/2GrTMics/U\n57tV9e52ehG4uGP+i8DSzkhE5A7gS4DvAm6aN/GDKol/ndSK+F5Sk+YTU99VwP2q+vC8iU35anvj\nijHGGGOeii6hC5xzqnrHHt9tAMs7wlaA9ekASd0vvAn4LlVt5KAn76fsW0lU1d9tE7gdeMCeZDbG\nGGOMefLSa/kuS1T3AZmIPENV/7INew5w7475loE7gF9qK4jj/rEeEpGvV9X/ulcCe1YSReR5wJ9q\n6gDrNHB6r9qnqv7xHAtzSUTkLuAugEW/crmjN8YYY4w5EpejjqiqAxF5B/A6Efn7wOcDdwJfvGPW\nNeCGqc83A38IfAHw+H5p7NeSeA9wPfBYO63ArFqiwo5eWw/2rh0PwfwTVX3ztkjTNfe7Ac4WN1oL\npjHGGGOOvfTgymXrTPsVwFtIdbXzwHeo6r0icgvpWZJnqeoDTD2sIiJtL+g8qrqj1/sd9qsk3s5W\nDfP2J5n5vbzY7kk0xhhjzFPR5Xovs6o+Abx4RvgDpAdbZv3mk8xu9Ntlz0qiqt4/a9oYY4wxxjx5\nl6uSeKXt25m2iCyIyE+IyEMi8riI/EL7DmdjjDHGGHOJ9BKGo3bQG1deC3wL8OvALwJfReqI8TP1\nayKyMTW88zLEaYwxxhhzdZvzbStXQ2vjQf0kfi3wrar6dgAReRvweyLiVTXs/9PZVPW2J/M7Y4wx\nxpjjLj24chXUAOdwUEvizcCk/xxV/UOgYfuj1MYYY4wxZk7H5XLzQS2JnvRmlWnNHL8zxhhjjDEz\nXA2XkudxUGVPgLeJSDkV1gXeLCKb4wBVvfNKZG5sGBs+sr6Gx5OLJxfHgvcUzrFYpOmVwtPPunS9\nkgt4UXKnZFPTXpRc0jhzSiYxjV1spyPeKd5FvKwTVBjWOaPGU0XPRuOpomOjcVRRKKMwCkIToYye\noAsEhTouEzS9wDu272gcv4Jn3MIsstWM6x14GQ+CF+h4xQsUTsgddF27DEDhIrlTOi7i2+XJXcQJ\nyNTfHooQFZroJ9PT3+00/Vsn28OcaIpflYAQVKlCuwRlsSuuOKMPKCfaLrfinU7G3kUKH+hmDafc\nEOe1nXf7XhSio2kcTfDU0TGsM0bBM2gyyujYbBzDIATNeLwc57yXyli0Ld+0DWRunM/p/KXlnR67\nyW9Tnro+TJYvc0rhQspnBZ2qwV2M+MdrXKdJ951UijYQa9AGNAj1yBMax8nFTZ52YoPOQsPy8xeQ\n5/9V4l/9PBgMkOEmDDaRqoL7P4V+4jHCn6wzWHP8/+3de6wk6Vnf8e/zvlVdfTmXmZ1Zr73e+AY2\nl3VCEGtDFMcxIYohxI4V8wexgyIQcgA5UhRFsSVMAk4MCZERASxHJg5YsEQByRaxA84/sZEMJNZu\nkrW9kb1gdmd38c7unLmca3fX5X3yR/WZ6XOZOWe8Z7rPOfv7jErV9Xadrvd9+q2uZ+q6PixYGXW5\nUmZcGkeuVcZ65VweOVt1w3pdMfSaMSVbYZOKMVUY03hFzZjkVfu6GeMkmjTGPZGmHhQVCISQYUTy\n0CNYTmELdKxP3xfpph4FHZZjQTdGznQCvcwYZMbZjrOYOeeLmuW8ZikvuXthi4XFEQsvqcnOReJ9\nS3D3Ety1DMuLUFYwLttx07Tj5O3r5JCmHmJV1jRfucTWVxMXnryLi1s9Ht/scrk0ajeqEpqUGKWa\nTUZshHVKG1L6FpVvUXvbbiMSLYPYI4aC5BXuqR0msdienurZ18v3SrhD+wSsG8wCRiCzLoUt0PUF\nltNZlqzL+W7B2SJwroBvXGi4tzfiW++9xJlXV2SvWsI3S3xYkzZqaNr+dNPneU0We33xoZlMb6/M\nCQJYZpQXCzZWFnnu6jdyZVRwadxhtYps1IFrlbFVO2sVjGqnTIlhnRinhpHXNDSMraSioraaijGN\n1VQ+wkk4DQ017g1pMr0dr+k+tt8ZS2Z7b7kbpg54bcfWJrfmDfscDNuxDJrJsnYu373Z8R3vnn/a\n/t/1Xnu+96nbB0+/Zzvas7MdbV+JBAJmkUi7DhqBaDmZ52QUZGREzyi8ICejZxm5tdvEXhYootHP\njH4GSzksZonFzOmEti3DzQ7ZpRGEdfJ4EZb72MYmDPpYnkMnh80tiBEWF6CT0zz8FI/+jzMEY7KN\n3AK2KJvIZpUxvv5bbIyawFbTbidHyagSVAnK1KXxLlVaxGnLdm8jA+32MTPoxHYbuJi3vymLWeLe\nFHE3zjRbEBwGXTizhJ8/D4PBob6r4+CEHG0+MEn82D5lv3knKiIiIiJy2jm39ezmuTro2c0/PKuK\niIiIiJx6Ds0JyRJ1bqGIiIjIjJyaPYkiIiIicrROyzmJIiIiInKEtCdRRERERHZwHD8huxKVJIqI\niIjMUHMyckQliSIiIiKz4pyem2mLiIiIyFFxJYkiIiIisg8/Fk9mPpiSRBEREZEZ0eFmEREREdlX\no6ubRURERGS3E5IjKkkUERERmRU9lk9ERERE9qWbaYuIiIjITroFjoiIiIjs5ujClSOVW+TFnQWi\nQTQjmlFE6ASjl7XjIjiZtfNXDpUbZWoLgkE0Jxrk5uShHfqxoeOJTmjoxMRCMaYoaopuTbFYYxmQ\nIDXgtVGXgaYOjEcZdR0p60jZROomME6RJhmNG40HkoPTLn/7fwzB9rbNpu6VNP3+dnkwJ1g7Hcwx\ng8wSZhAttW0LiSykdpwlstiQZYm8aIi5k/UTsYC4GLB+xHoZYbGAbg69TjvOcyg6kMV2CKGtSEpt\nA+oamgZGJYwrKGtYH+LjGl8b4+OGNEqkTSdV0IzbmLkbPjn5wgKE6BCckEOIYFk7EMCmAuDJ8Zp2\naG58XjWKNHWgqgK9cU7ZRAZVTtkExk2k9kA9+R62z/kIkzjmwYnm5JN4hakYZyGRx0S/U9Hp1HT7\nFb27GrKzgfjSAXbXAO4+g7/yL8BggOcdyDIoihuxmra+TnjmGfiTC/jFa9QX1qmuOOVmYO1aj41x\nh7VxhzwkFoqS/pOr5K++2v7tYIAPBnC+/TGxLMOSkz+xQXY50SRjrc64UkWeHRlrlbNWJq6WFRup\nZN3WGYZNShsySqvUPqZKQ5yGOpW4J9wbfJ+zYoLlmIV2IBJDQWYFwXIyK8i9IPcOGZGMG+1uHJoE\nVXLKBKNkjJpAJwQ6oV1HUtPOb50Ay304fxZ/6Uvwe+/dG79b2dwk3vMIg8UnuGdjnbIJPDPqEC3S\nOJQpMUoNm4zYCpsMbY3St6h9TJk2SF6RUk3j9fU4uN+IRdv2SdvsRhmwY779pqfLEzWpqUmpIoSS\nxseMwwYj65FCQ+Nn6FYZ3WhUeaATEmeLEWfvr8ne9E2kN/7V61WIk8+N+y7t9vUef5z+409x/pEn\nqZ6+zJUnulzb6HF11OWZYcFqFVkZBzbqwFZtrFWBUR3ZrCOjVGMeiGRUVGAQPIJBQ0Xy7dhlJFLb\nzwzcm+vLN4uTtgUCbV8zAtFyApHgYfJenPS0MFXW/oX5Pusd4NZ+J+2S29dNqEmTf21pQ2M1ifb7\nb7zCaa6/7779urn+fbafufP7DpN+st0/jDhVFq/3o+k2hkn57nZuty3zDCOQeSR6RkY7T26RDCO3\n2G4Hg9GJRh6MzvXX0Ivt9rEXnSLAIEt0g9PPEsGccRNZ3eySktHfKukPrxEX14h3r2KLBQy6cHah\nbeD2NqGOxJcts9Qd0+nUdIqG7lJFLMATpKr9fW4qo67a3+hxmVFVkVGd0SSjToEqBRpvxzfbRrbb\nunb7lodENKebNWSxoZvV9HoVeach7yd8DM1XnsOevII9/Bjp8pDmakW5YpRbkaqMjMuMug40af/+\nMg/e9rJ5V+NQTkSSKCIiInJanJAdiUoSRURERGZJexJFREREZIf2iStKEkVERERkl+aE7Emc2Zmc\nZvaEmQ3NbN3MrpnZH5nZj9n2Gb8iIiIip1x7M20/1DBvs07Q3uLui8DLgX8DvAf46IzrICIiIjIn\njvvhhnmby+Fmd18F/quZXQT+p5l90N2/NI+6iIiIiMzScdhLeBhzPSfR3T9vZk8Dfw1QkigiIiKn\nmgMNzYHzHQfH4XzArwF37S40s3eZ2UNm9tA4bc2hWiIiIiJH7XDnIx5mb6OZ3WVmnzCzTTO7YGbv\nuMl8/9DMHjazNTN72sx+3swO3FF4HJLElwJXdhe6+0fc/QF3f6AI/TlUS0RERORoHfGFKx8CSuAe\n4J3Ah83s/n3m6wP/BDgPfCfwPcA/O+jD53q42cxeR5skfm6e9RARERGZld2PePx6mNkAeDvwWnff\nAD5nZr8L/BDw3ul53f3DU5N/bmYPAt990DLmkiSa2RLwRuDfA7/p7l+cRz1EREREZsuvP2P8eXoN\nULv7Y1NljwBvOsTfvhF49KCZZp0kftLMaiAB/w/4BeA/zLgOIiIiInPhQH34C1fOm9lDU9MfcfeP\nTF4vAGu75l8DFm/1gWb2I8ADwI8etPCZJYnu/opZLUtERETkeHL88IebV9z9gZu8twEs7SpbBtZv\n9mFm9jbg54C/6e4rBy1cj+UTERERmREH0tEcbn4MyMzs1e7+J5Oyb+Mmh5HN7HuBXwW+/7Cn+R2H\nq5tFREREXjDSIf/dirtvAh8H3m9mAzN7A/BW4Dd2z2tmfwN4EHi7u3/+sPVUkigiIiIyM34kSeLE\nTwA94Dngt4Afd/dHzexlZrZhZi+bzPdTtIeif29SvmFmv3/Qh5+Iw81LObz5XiOaE3CiJYrodEKi\nFxOd0LCYVxR5TTSnccPdSG7XPyOGRAA6WU2WJWJMFN2avNuQLzihD/FsjvUybDDAlnuQRahqqBOU\nNV41UDZ42UBdgjuegOTtcIDteb12aCCVjteQKvAamjKQamjq0A5NIKW2De6GmWPmxOjELJEXDbFI\nxAKyJSMsRMLZLjbow2IPlgcw6MPiAC8K6PWgk+MxI2UZhF3/R0ipHeoa8wR1A+MR1A02Hk+mx1BW\nMML3KEYAAA5ySURBVC6hm2NljS1XUDfEOuH1zk5twSALbSzz2I47GeRZ+zoECAYxtn8QQlsHJnH1\nNInvpKxu2ummgbJup4clXpb4ZgnjmjRKpPWGZgj1plGXgbqMVFWgbiJ1HXA3mhQY1RGf9JcmBeom\nkCXDk7X/hcoM6+VtLM8s4efvbuM4bTyGrS1sYx3b3IKrq3DxCunPVlj/Ys3VlT4XVu9lZZxzpcx4\nZhS4PHKeHdZUyenEBb79ybt5w+c2eN1n/xPZK5awl5yBV96Hnz/XxmTQIyxnFIOa/Fpi3BgblXFp\nlLg8qrnajLgcLjOMa2ymFapmSJPGlM0mTSpJqSR5TUpj2PHDEzALQCRYhllGCBnBssl0pAodguWM\nwhrRMtasT7SczApyL8jrgqLqEj3SIaNjOTmBbozkIaMTchbzBXoZnP0CLOfOi7s154tLnO89yYvO\nbpB1GrJOIuSOBQg5ECB0wHLDMmu/iwBpK3HlqxlPPXeGR64u8bVh4M/WnavjiovNGuthlS1WGdpV\nqmY4icGYlGqaVOJek3yMtyvkrrU0YJZjFjACZhlmYRKLcL0cwCzeWLe9PQl9+zyj9rNbzST2TRpT\n2YgqdGiyii27SpXuY3VzidWyS+MdLo3P4n9gvOrCV1h49Kl23dge2oW269SO4Rb/159el5K36+e4\npnpik/WnMi5cPMuzwx5PDTtcK41rFayMnM0qcaUasuVjtmyLjbDK2NcZ+wZVGlI3QxqvSV6RUt3e\n0c3Tnpi6p0n/amPbNiHsjCmBEHICgRAybNIX4+R7iOQEywkWMGI7/yT2NrWfYzv2aeq7aKjasVdt\nXUnteFLvRCKliuQ17un62P1Gm5hcYDD9nW63oxV39YudfWXn63be6ba2sWjbv91es0gkI1jermue\nk1HQ8Q6dVNAhIyej00SKEOnGQNYYRTSaBGWC5EYTHbNA8na7mBzGKVClwNq4oL9Rs7Q2oltUDO7a\npHNui/iigpC1vzn0univhw1HcHaB+77rzwmLOdbvYstnocjb3+CqgbrBx5PtZZ3wsoamvLGNhMNv\nJ6/3WfDJGG9f++TSV0+QRlA9UdOUiaaq+Nqzyzy31ePpYcFaFdisjfXaKJPTpL1r+7w4TkN1NJ/l\nfgV42z7lT9Je2LI9feDtbvZzIpJEERERkdPiNi5cmSsliSIiIiIz4vhRXbhyxylJFBEREZmhdPj7\nJM6VkkQRERGRmbmt+yTOlZJEERERkRlxnMaP5sKVO01JooiIiMgMuQ43i4iIiMhOfth7IM6dkkQR\nERGRGXF0CxwRERER2cOv34D/uFOSKCIiIjIzR/fElTtNSaKIiIjIjDh7H/N4XClJFBEREZkZXbgi\nIiIiIrs5OidRRERERHbTE1dEREREZBfHSXriioiIiIjspgtXRERERGQPJYlH6Eyv5O/e/wRmjgUI\n0YmFE3IIfQhFICznWD+HYPhGCU0ijRLUjieHBASwzLDMIAuEQQe6Gbbcg0EXzizC4gK+vEh60T1Q\nFAfWzW6jHbvnjbcThEPyyXAUn3Or6a/3c2YhTIYMuOU3WJbYlSswHGKbW1BVUE9OJs4i5DlkEe/1\n2r7QySEEWF3FVlbav9ncgueuwuoW6dImzXpNvZoYXQ5cu9Ln6bVzXCk7PDvKWa+NzRqujJ31ytmo\nayoShUc26ozVMqe64sTlYdsnQ8AXl+D83fjSErFpWDz3NV715avwBVheXaLyDlnIsSFsNF1GtoF7\nInlFnUqaVJJSSfIa3/fwRsIdzMAJGImUatwSDWUbpqm59/thMwuYhfY14fp0sLwdE4ihIIaCjvXI\nrc8C5xj4gAXvcyZbphONQRbIg5EFyAMEg+TgDlWCMjnjBoZN4ko1ZpUNroQvMUqrDJtrVGlIVW+S\nvN7V5gSecLx93TbkRpumeqlhuI0nryNYwCwjWNGOQ0YMHYLlZJNxsIw89MmsoGN9ci/o+yIdLyjo\n0LecbowMskg3Gt1oLORGNzqDDLrRyQ2K0GDmPHJ1mYevLPPcHwee2YKVUcOz5ZAtG7Jpm5PrIhsi\nORkZhRdEz8jJKCwjt0BugWhGDEY0CFO/Pglns27YSjVXWWPLLrHBZcq00Q71JnUa0TSjGzH0eipO\nX8/GLeztN7t+Ef2AX4vr81u7hrd9Lu7oe7s5Cfe0fz+Y9IGDlnuzeji0Kw6w3b4dbbJd9Zlad24e\ny8nnWKRtY9u/zDKy2G3XoTi4vi51wzId79GvFim8oCCnH3I6ITDIIkU0+lnb5/pZYJAFusFZzHK6\nMdGNiTOjgn5W8+Jyg+VqSDeOCffVMJg0YzyGiysw6JK96TWwtIgvLpBe9CIYDA4Rr9tzu/MzHsNo\nhI3HnH34C3zLY8+y9aUxa5cLVjd7XB52GTWRcWpj+4sXbncBR891dbOIiIiI7Ed7EkVERERkJ9eF\nKyIiIiKyh2tPooiIiIjsdJIey7f3TN8ZMLN3mNlDZrZhZs+Y2e+b2RvmURcRERGRWXLSoYZ5m3mS\naGb/FPhF4GeBe4CXAR8C3jrruoiIiIjMlk+uuj94mLeZHm42s2Xg/cAPu/vHp9761GQQEREROcUc\n93relTiUWZ+T+FeALvCJg2Y0s3cB7wK4r3/wvZhEREREjj3XOYk3cw5Y8UOk0O7+EXd/wN0fONft\nzqBqIiIiIndW+9CLk3FO4qz3JF4GzptZdphEUUREROR0OTm3wJn1nsQ/BsbA22a8XBEREZFjwHGv\nDjXM20yTRHdfBf4F8CEze5uZ9c0sN7PvM7Ofn2VdREREROYjHXKYr5nfTNvdP2hmF4H3AQ8C68DD\nwAdmXRcRERGR2XI4IYeb5/LEFXd/kDZBFBEREXlBcXzeVTgUPZZPREREZKa0J1FEREREdjg5Vzeb\n+/Hf5Wlm68BX5l2PF4DzwMq8K3HKKcZ3nmI8G4rznacYH72Xu/vd86yAmX2a9rs9jBV3/947WZ9b\nOSlJ4kPu/sC863HaKc53nmJ85ynGs6E433mKsczbrO+TKCIiIiIngJJEEREREdnjpCSJH5l3BV4g\nFOc7TzG+8xTj2VCc7zzFWObqRJyTKCIiIiKzdVL2JIqIiIjIDClJFBEREZE9lCSKiIiIyB7HOkk0\ns7vM7BNmtmlmF8zsHfOu02lkZp81s5GZbUwG3bj8eTKzd5vZQ2Y2NrNf3/Xe95jZl81sy8w+Y2Yv\nn1M1T7SbxdjMXmFmPtWfN8zsp+ZY1RPLzAoz++jk93fdzP6vmX3f1Pvqy8/TrWKsvizzdtwfy/ch\noATuAf4y8N/M7BF3f3S+1TqV3u3u/3HelThFvgb8a+DNQG+70MzOAx8HfhT4JPCvgP8CfNcc6njS\n7RvjKWfcvZ5tlU6dDHgK+OvAk8DfBn7bzP4isIH68lG4VYy3qS/LXBzbJNHMBsDbgde6+wbwOTP7\nXeCHgPfOtXIiB3D3jwOY2QPAfVNv/T3gUXf/ncn7Pw2smNk3u/uXZ17RE+wWMZYj4u6bwE9PFX3K\nzB4HvgM4h/ry83ZAjB+eS6VEJo7z4ebXALW7PzZV9ghw/5zqc9r9nJmtmNkfmtmb5l2ZU+x+2n4M\nXN9A/Cnq13fCBTN72sx+bbIHV54nM7uH9rf5UdSX74hdMd6mvixzcZyTxAVgbVfZGrA4h7qcdu8B\nXgW8lPbmrZ80s2+Yb5VOrQVgdVeZ+vXRWgFeB7ycdm/MIvDgXGt0CphZThvHj032FKovH7F9Yqy+\nLHN1nJPEDWBpV9kysD6Hupxq7v6/3H3d3cfu/jHgD2nPi5Gjp359h7n7hrs/5O61uz8LvBv4W2am\n5OXrZGYB+A3ac8TfPSlWXz5C+8VYfVnm7TgniY8BmZm9eqrs29i5C17uDAds3pU4pR6l7cfA9XNv\nvwH16ztp+7FSx/n37tgyMwM+SnsB4dvdvZq8pb58RG4R493Ul2Wmjm1Hm5zf8nHg/WY2MLM3AG+l\n/Z+WHBEzO2NmbzazrpllZvZO4I3Ap+ddt5NsEssuEIG4HV/gE8Brzeztk/f/JfCITvS/fTeLsZl9\np5l9k5kFMzsH/BLwWXfffWhUDufDwLcAb3H34VS5+vLR2TfG6ssyb8c2SZz4CdpbWzwH/Bbw47r9\nzZHLaW8jcon2/Jd/DLxt1wVDcvveBwxpr8T/B5PX73P3S7RX7X8AuAq8HvjBeVXyhNs3xrTn136a\n9rDnl4Ax8PfnVMcTbXLfw39Eewuyi1P36nun+vLRuFWMUV+WOTN3P3guEREREXlBOe57EkVERERk\nDpQkioiIiMgeShJFREREZA8liSIiIiKyh5JEEREREdlDSaKIiIiI7KEkUURODDNzM/uBeddDROSF\nQEmiiMzdJPm71fDrk1lfAnxyjlUVEXnB0M20RWTuzOzFU5N/B/hV2oRw21CPIhMRmS3tSRSRuXP3\ni9sDcG132XaCOH242cxeMZn+QTP7AzMbmtn/MbO/ZGavNbM/MrNNM/ucmb1yenlm9hYze9jMRmb2\nuJl9wMw6M2+4iMgxpiRRRE66nwH+LfDttAnmfwZ+GfhJ2ucJd4Ff2p7ZzN4MPAj8CnA/8CPADwA/\nO9Nai4gcc0oSReSk+wV3/z13/zLwQeBbgV9298+4+6O0yeB3T83/k8C/c/dfc/evuvtngPcAP2Zm\nNvPai4gcU9m8KyAi8jx9Yer1s5PxF3eVDcys7+5bwHcArzez90zNE4Ae8GLgmTtZWRGRk0JJooic\ndNXUa79FWZga/wzwO/t81qWjrZqIyMmlJFFEXmj+N/DN7v6n866IiMhxpiRRRF5o3g98yswuAL8N\n1MBrgde7+z+fa81ERI4RXbgiIi8o7v7fge+nvZjl85PhvcCT86yXiMhxo5tpi4iIiMge2pMoIiIi\nInsoSRQRERGRPZQkioiIiMgeShJFREREZA8liSIiIiKyh5JEEREREdlDSaKIiIiI7KEkUURERET2\n+P9tqKeMtZolagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac224b5320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "sample = librosa.core.stft(y=X_load[0], n_fft=1023, win_length=255, window='hamming', center=True, dtype=np.float, pad_mode='reflect')\n",
    "\n",
    "sample_chroma = librosa.feature.chroma_stft(y=X_load[200], sr=44100, n_fft=2048, hop_length=16)\n",
    "\n",
    "print(sample.shape)\n",
    "print(sample_chroma.shape)\n",
    "print(y_load[40])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "librosa.display.specshow(librosa.amplitude_to_db(sample,ref=np.max),y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(sample_chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa.display\n",
    "\n",
    "processedDataX_path = \"preprocessedSamples_X_Mm7_R1B.data\"\n",
    "processedDatay_path = \"preprocessedSamples_y_Mm7_R1B.data\"\n",
    "processedData_path = \"\"\n",
    "\n",
    "if os.path.isfile(processedData_path): #if already preprocessed\n",
    "    processedX = np.load(processedDataX_path)\n",
    "    processedy = np.load(processedDatay_path)\n",
    "else:\n",
    "    processedX = np.zeros((len(X_load),12,80,1), dtype=np.float)\n",
    "    processedy = np.zeros(len(y_load), dtype=np.float)\n",
    "    for i in range(len(X_load)):\n",
    "        sample = librosa.core.stft(y=X_load[i], n_fft=2048, win_length=128, window='hamming', center=True, dtype=np.float32, pad_mode='reflect')\n",
    "        sample = librosa.feature.chroma_stft(y=X_load[i], sr=44100, n_fft=20480, hop_length=258)\n",
    "        sample = np.atleast_3d(sample)\n",
    "        processedX[i] = sample\n",
    "        processedy[i] = y_load[i]\n",
    "    \n",
    "    processedX.dump(processedDataX_path)\n",
    "    processedy.dump(processedDatay_path)\n",
    "\n",
    "# processedX = np.zeros((len(X_load),10240), dtype=np.float)\n",
    "# processedy = np.zeros(len(y_load), dtype=np.float)\n",
    "\n",
    "# for i in range(len(X_load)):\n",
    "#     sample = np.array(X_load[i], dtype=np.float)\n",
    "#     sample = sample*np.hamming(20480)\n",
    "#     sample = np.abs(np.fft.rfft(sample))[1:]\n",
    "# #     sample = np.reshape(sample,(256,255, 1))\n",
    "# #     sample = np.append(sample, y[i])\n",
    "#     processedX[i] = sample\n",
    "#     processedy[i] = y_load[i]\n",
    "#     if i % 1000 == 0:\n",
    "#         print(i)\n",
    "#         print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0. ...,  47.  47.  47.]\n",
      "1725\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "print(processedy)\n",
    "sprocessedX, sprocessedy = shuffle(processedX, processedy)\n",
    "print(len(sprocessedX))\n",
    "\n",
    "\n",
    "# for i in range(len(sprocessedy)):\n",
    "# \tsprocessedy[i] = (sprocessedy[i]) - 1\n",
    "    \n",
    "trainRange = int(len(sprocessedX) * 0.7)\n",
    "validRange = int(len(sprocessedX) * 0.8)\n",
    "testRange = int(len(sprocessedX) * 0.2)\n",
    "\n",
    "\n",
    "X_train = np.array(sprocessedX[:trainRange], dtype=np.float)\n",
    "y_train = np.array(sprocessedy[:trainRange], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(sprocessedX[trainRange:validRange], dtype=np.float)\n",
    "y_valid = np.array(sprocessedy[trainRange:validRange], dtype=np.float)\n",
    "\n",
    "X_test = np.array(sprocessedX[testRange:], dtype=np.float)\n",
    "y_test = np.array(sprocessedy[testRange:], dtype=np.float)\n",
    "print(y_test[1])\n",
    "\n",
    "#print(X_train.shape,y_train.shape, X_valid.shape, y_valid.shape)\n",
    "\n",
    "len(sprocessedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sprocessedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "height = 12\n",
    "width = 80\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.4\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 800\n",
    "fc1_dropout_rate = 0.2\n",
    "\n",
    "n_outputs = 48\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 6 * 40])\n",
    "    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1_drop, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train accuracy: 80.0000%, valid. accuracy: 60.6936%, valid. best loss: 1.239738\n",
      "Epoch 1, train accuracy: 100.0000%, valid. accuracy: 68.7861%, valid. best loss: 0.742532\n",
      "Epoch 2, train accuracy: 100.0000%, valid. accuracy: 76.8786%, valid. best loss: 0.702498\n",
      "Epoch 3, train accuracy: 100.0000%, valid. accuracy: 80.9249%, valid. best loss: 0.624083\n",
      "Epoch 4, train accuracy: 100.0000%, valid. accuracy: 83.8150%, valid. best loss: 0.505121\n",
      "Epoch 5, train accuracy: 100.0000%, valid. accuracy: 79.1907%, valid. best loss: 0.419613\n",
      "Epoch 6, train accuracy: 80.0000%, valid. accuracy: 83.2370%, valid. best loss: 0.419613\n",
      "Epoch 7, train accuracy: 80.0000%, valid. accuracy: 86.1272%, valid. best loss: 0.412288\n",
      "Epoch 8, train accuracy: 100.0000%, valid. accuracy: 87.2832%, valid. best loss: 0.412288\n",
      "Epoch 9, train accuracy: 100.0000%, valid. accuracy: 87.8613%, valid. best loss: 0.412288\n",
      "Epoch 10, train accuracy: 100.0000%, valid. accuracy: 88.4393%, valid. best loss: 0.412288\n",
      "Epoch 11, train accuracy: 100.0000%, valid. accuracy: 85.5491%, valid. best loss: 0.412288\n",
      "Epoch 12, train accuracy: 100.0000%, valid. accuracy: 83.2370%, valid. best loss: 0.412288\n",
      "Epoch 13, train accuracy: 100.0000%, valid. accuracy: 83.8150%, valid. best loss: 0.412288\n",
      "Epoch 14, train accuracy: 100.0000%, valid. accuracy: 84.3931%, valid. best loss: 0.412288\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.942029\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 5\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 100\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        idx = 0\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            X_batch_reshaped = np.reshape(X_batch,(len(X_batch), -1))\n",
    "            sess.run(training_op, feed_dict={X: X_batch_reshaped, y: y_batch, training: True})\n",
    "            if idx % check_interval == 0:\n",
    "                X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "                loss_val = loss.eval(feed_dict={X: X_valid_reshaped,\n",
    "                                                y: y_valid})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "            idx += 1\n",
    "        X_batch_reshaped = np.reshape(X_batch,(len(X_batch), -1))\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch_reshaped, y: y_batch})\n",
    "        X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid_reshaped,\n",
    "                                           y: y_valid})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    X_test_reshaped = np.reshape(X_test,(len(X_test), -1))\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_reshaped,\n",
    "                                        y: y_test})\n",
    "    print(\"Final accuracy on test set:\", acc_test)\n",
    "    #save_path = saver.save(sess, \"./checkpoints/my_chordRec_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = np.reshape(X_train,(len(X_train), -1))\n",
    "X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "X_test_reshaped = np.reshape(X_test,(len(X_test), -1))\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=0, n_neurons=300, name=None,\n",
    "        activation=tf.nn.elu):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=he_init,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs\n",
    "    \n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "\n",
    "n_inputs = 10240\n",
    "n_outputs = 48\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "n_neurons_hidden1 = 700\n",
    "hidden1 = tf.layers.dense(X, n_neurons_hidden1, activation=leaky_relu(), name=\"fc1\")\n",
    "\n",
    "dropout_hidden1 = 0.4\n",
    "hidden1_drop = tf.layers.dropout(hidden1, dropout_hidden1)\n",
    "\n",
    "logits = tf.layers.dense(hidden1_drop, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 6.229672\tBest loss: 6.229672\tAccuracy: 62.79%\n",
      "1\tValidation loss: 0.800890\tBest loss: 0.800890\tAccuracy: 86.05%\n",
      "2\tValidation loss: 0.693056\tBest loss: 0.693056\tAccuracy: 86.05%\n",
      "3\tValidation loss: 0.369835\tBest loss: 0.369835\tAccuracy: 88.37%\n",
      "4\tValidation loss: 0.308786\tBest loss: 0.308786\tAccuracy: 92.44%\n",
      "5\tValidation loss: 0.943879\tBest loss: 0.308786\tAccuracy: 88.37%\n",
      "6\tValidation loss: 0.258311\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "7\tValidation loss: 0.267080\tBest loss: 0.258311\tAccuracy: 93.60%\n",
      "8\tValidation loss: 0.277454\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "9\tValidation loss: 0.281729\tBest loss: 0.258311\tAccuracy: 93.02%\n",
      "10\tValidation loss: 0.287909\tBest loss: 0.258311\tAccuracy: 93.02%\n",
      "11\tValidation loss: 0.288447\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "12\tValidation loss: 0.285949\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "13\tValidation loss: 0.268945\tBest loss: 0.258311\tAccuracy: 93.02%\n",
      "14\tValidation loss: 0.284507\tBest loss: 0.258311\tAccuracy: 93.60%\n",
      "15\tValidation loss: 0.291266\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "16\tValidation loss: 0.306245\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "17\tValidation loss: 0.312777\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "18\tValidation loss: 0.322899\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "19\tValidation loss: 0.322433\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "20\tValidation loss: 0.327921\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "21\tValidation loss: 0.330755\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "22\tValidation loss: 0.333036\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "23\tValidation loss: 0.342549\tBest loss: 0.258311\tAccuracy: 92.44%\n",
      "24\tValidation loss: 0.344919\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "25\tValidation loss: 0.353070\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "26\tValidation loss: 0.362670\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "27\tValidation loss: 0.357865\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "28\tValidation loss: 0.366808\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "29\tValidation loss: 0.367137\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "30\tValidation loss: 0.371197\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "31\tValidation loss: 0.368464\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "32\tValidation loss: 0.376785\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "33\tValidation loss: 0.375012\tBest loss: 0.258311\tAccuracy: 91.86%\n",
      "34\tValidation loss: 0.376284\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "35\tValidation loss: 0.377131\tBest loss: 0.258311\tAccuracy: 91.28%\n",
      "36\tValidation loss: 0.380773\tBest loss: 0.258311\tAccuracy: 90.70%\n",
      "Early stopping!\n",
      "Final test accuracy: 97.68%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 30\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train_reshaped))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train_reshaped) // batch_size):\n",
    "            X_batch, y_batch = X_train_reshaped[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid_reshaped, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            #save_path = saver.save(sess, \"checkpoints/chord_recognizer_model.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_reshaped, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:583: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 6798.663086\tBest loss: 6798.663086\tAccuracy: 6.47%\n",
      "1\tValidation loss: 165174.078125\tBest loss: 6798.663086\tAccuracy: 5.04%\n",
      "2\tValidation loss: 123280.765625\tBest loss: 6798.663086\tAccuracy: 3.60%\n",
      "3\tValidation loss: 34109.429688\tBest loss: 6798.663086\tAccuracy: 4.32%\n",
      "4\tValidation loss: 79324.882812\tBest loss: 6798.663086\tAccuracy: 2.16%\n",
      "5\tValidation loss: 33.290951\tBest loss: 33.290951\tAccuracy: 2.88%\n",
      "6\tValidation loss: 5.362980\tBest loss: 5.362980\tAccuracy: 0.00%\n",
      "7\tValidation loss: 7.258043\tBest loss: 5.362980\tAccuracy: 0.72%\n",
      "8\tValidation loss: 10.487857\tBest loss: 5.362980\tAccuracy: 2.88%\n",
      "9\tValidation loss: 4.773429\tBest loss: 4.773429\tAccuracy: 2.88%\n",
      "10\tValidation loss: 4.203965\tBest loss: 4.203965\tAccuracy: 0.72%\n",
      "11\tValidation loss: 4.054197\tBest loss: 4.054197\tAccuracy: 0.72%\n",
      "12\tValidation loss: 3.983546\tBest loss: 3.983546\tAccuracy: 0.72%\n",
      "13\tValidation loss: 3.945382\tBest loss: 3.945382\tAccuracy: 5.76%\n",
      "14\tValidation loss: 3.928518\tBest loss: 3.928518\tAccuracy: 5.76%\n",
      "15\tValidation loss: 3.927807\tBest loss: 3.927807\tAccuracy: 5.76%\n",
      "16\tValidation loss: 3.904853\tBest loss: 3.904853\tAccuracy: 5.76%\n",
      "17\tValidation loss: 3.898769\tBest loss: 3.898769\tAccuracy: 5.76%\n",
      "18\tValidation loss: 3.929713\tBest loss: 3.898769\tAccuracy: 5.76%\n",
      "19\tValidation loss: 3.886247\tBest loss: 3.886247\tAccuracy: 5.76%\n",
      "20\tValidation loss: 8.353172\tBest loss: 3.886247\tAccuracy: 0.72%\n",
      "21\tValidation loss: 3.876282\tBest loss: 3.876282\tAccuracy: 5.76%\n",
      "22\tValidation loss: 3.871507\tBest loss: 3.871507\tAccuracy: 5.76%\n",
      "23\tValidation loss: 3.854021\tBest loss: 3.854021\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.868782\tBest loss: 3.854021\tAccuracy: 1.44%\n",
      "25\tValidation loss: 3.867138\tBest loss: 3.854021\tAccuracy: 1.44%\n",
      "26\tValidation loss: 3.864670\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.863552\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.862178\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.860894\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "30\tValidation loss: 5.594682\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "31\tValidation loss: 6.946478\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "32\tValidation loss: 20.537422\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.856035\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.854522\tBest loss: 3.854021\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.852429\tBest loss: 3.852429\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.850831\tBest loss: 3.850831\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.849072\tBest loss: 3.849072\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.847436\tBest loss: 3.847436\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.845662\tBest loss: 3.845662\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.843909\tBest loss: 3.843909\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.842215\tBest loss: 3.842215\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.840591\tBest loss: 3.840591\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.838680\tBest loss: 3.838680\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.836839\tBest loss: 3.836839\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.834965\tBest loss: 3.834965\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.833356\tBest loss: 3.833356\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.831641\tBest loss: 3.831641\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.829763\tBest loss: 3.829763\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.827935\tBest loss: 3.827935\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.826230\tBest loss: 3.826230\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.824510\tBest loss: 3.824510\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.822575\tBest loss: 3.822575\tAccuracy: 3.60%\n",
      "53\tValidation loss: 3.821239\tBest loss: 3.821239\tAccuracy: 3.60%\n",
      "54\tValidation loss: 3.820234\tBest loss: 3.820234\tAccuracy: 3.60%\n",
      "55\tValidation loss: 3.818994\tBest loss: 3.818994\tAccuracy: 3.60%\n",
      "56\tValidation loss: 3.817769\tBest loss: 3.817769\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.816888\tBest loss: 3.816888\tAccuracy: 3.60%\n",
      "58\tValidation loss: 3.815762\tBest loss: 3.815762\tAccuracy: 3.60%\n",
      "59\tValidation loss: 3.814917\tBest loss: 3.814917\tAccuracy: 3.60%\n",
      "60\tValidation loss: 3.814099\tBest loss: 3.814099\tAccuracy: 3.60%\n",
      "61\tValidation loss: 3.813312\tBest loss: 3.813312\tAccuracy: 3.60%\n",
      "62\tValidation loss: 3.812646\tBest loss: 3.812646\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.811956\tBest loss: 3.811956\tAccuracy: 3.60%\n",
      "64\tValidation loss: 3.811474\tBest loss: 3.811474\tAccuracy: 3.60%\n",
      "65\tValidation loss: 3.811280\tBest loss: 3.811280\tAccuracy: 3.60%\n",
      "66\tValidation loss: 3.811690\tBest loss: 3.811280\tAccuracy: 3.60%\n",
      "67\tValidation loss: 3.811174\tBest loss: 3.811174\tAccuracy: 3.60%\n",
      "68\tValidation loss: 3.825436\tBest loss: 3.811174\tAccuracy: 3.60%\n",
      "69\tValidation loss: 1012.918213\tBest loss: 3.811174\tAccuracy: 0.72%\n",
      "70\tValidation loss: 38.258877\tBest loss: 3.811174\tAccuracy: 0.72%\n",
      "71\tValidation loss: 4.914204\tBest loss: 3.811174\tAccuracy: 6.47%\n",
      "72\tValidation loss: 7.474154\tBest loss: 3.811174\tAccuracy: 3.60%\n",
      "73\tValidation loss: 4.871696\tBest loss: 3.811174\tAccuracy: 5.04%\n",
      "74\tValidation loss: 3.803109\tBest loss: 3.803109\tAccuracy: 3.60%\n",
      "75\tValidation loss: 3.802732\tBest loss: 3.802732\tAccuracy: 3.60%\n",
      "76\tValidation loss: 3.802576\tBest loss: 3.802576\tAccuracy: 3.60%\n",
      "77\tValidation loss: 3.802441\tBest loss: 3.802441\tAccuracy: 3.60%\n",
      "78\tValidation loss: 3.800712\tBest loss: 3.800712\tAccuracy: 3.60%\n",
      "79\tValidation loss: 3.798999\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "80\tValidation loss: 3.799515\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "81\tValidation loss: 165.279007\tBest loss: 3.798999\tAccuracy: 0.72%\n",
      "82\tValidation loss: 4.119576\tBest loss: 3.798999\tAccuracy: 6.47%\n",
      "83\tValidation loss: 3.805299\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "84\tValidation loss: 3.807410\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "85\tValidation loss: 3.801645\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "86\tValidation loss: 3.864724\tBest loss: 3.798999\tAccuracy: 6.47%\n",
      "87\tValidation loss: 3.804662\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "88\tValidation loss: 3.805164\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "89\tValidation loss: 3.805691\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "90\tValidation loss: 3.806154\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "91\tValidation loss: 3.806576\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "92\tValidation loss: 3.806910\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "93\tValidation loss: 3.807159\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "94\tValidation loss: 3.807331\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "95\tValidation loss: 3.807448\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "96\tValidation loss: 3.808529\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "97\tValidation loss: 3.807317\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "98\tValidation loss: 3.807406\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "99\tValidation loss: 3.807483\tBest loss: 3.798999\tAccuracy: 3.60%\n",
      "100\tValidation loss: 3.806500\tBest loss: 3.798999\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=  15.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 5905.068359\tBest loss: 5905.068359\tAccuracy: 6.47%\n",
      "1\tValidation loss: 118230.125000\tBest loss: 5905.068359\tAccuracy: 5.04%\n",
      "2\tValidation loss: 79611.656250\tBest loss: 5905.068359\tAccuracy: 3.60%\n",
      "3\tValidation loss: 284529.437500\tBest loss: 5905.068359\tAccuracy: 0.72%\n",
      "4\tValidation loss: 269855.031250\tBest loss: 5905.068359\tAccuracy: 3.60%\n",
      "5\tValidation loss: 61093.324219\tBest loss: 5905.068359\tAccuracy: 2.16%\n",
      "6\tValidation loss: 14793.455078\tBest loss: 5905.068359\tAccuracy: 2.16%\n",
      "7\tValidation loss: 3501.679199\tBest loss: 3501.679199\tAccuracy: 2.16%\n",
      "8\tValidation loss: 8081.114258\tBest loss: 3501.679199\tAccuracy: 2.88%\n",
      "9\tValidation loss: 642.664429\tBest loss: 642.664429\tAccuracy: 0.72%\n",
      "10\tValidation loss: 3.908149\tBest loss: 3.908149\tAccuracy: 2.16%\n",
      "11\tValidation loss: 3.900404\tBest loss: 3.900404\tAccuracy: 2.88%\n",
      "12\tValidation loss: 3.899011\tBest loss: 3.899011\tAccuracy: 2.88%\n",
      "13\tValidation loss: 3.899048\tBest loss: 3.899011\tAccuracy: 2.16%\n",
      "14\tValidation loss: 3.954832\tBest loss: 3.899011\tAccuracy: 2.16%\n",
      "15\tValidation loss: 3.873307\tBest loss: 3.873307\tAccuracy: 2.16%\n",
      "16\tValidation loss: 3.872459\tBest loss: 3.872459\tAccuracy: 2.16%\n",
      "17\tValidation loss: 3.871672\tBest loss: 3.871672\tAccuracy: 2.16%\n",
      "18\tValidation loss: 3.870784\tBest loss: 3.870784\tAccuracy: 2.16%\n",
      "19\tValidation loss: 3.869834\tBest loss: 3.869834\tAccuracy: 2.16%\n",
      "20\tValidation loss: 3.868882\tBest loss: 3.868882\tAccuracy: 2.16%\n",
      "21\tValidation loss: 3.867889\tBest loss: 3.867889\tAccuracy: 2.16%\n",
      "22\tValidation loss: 3.866832\tBest loss: 3.866832\tAccuracy: 2.16%\n",
      "23\tValidation loss: 3.865765\tBest loss: 3.865765\tAccuracy: 2.16%\n",
      "24\tValidation loss: 3.864750\tBest loss: 3.864750\tAccuracy: 5.04%\n",
      "25\tValidation loss: 3.863674\tBest loss: 3.863674\tAccuracy: 5.04%\n",
      "26\tValidation loss: 3.862520\tBest loss: 3.862520\tAccuracy: 5.04%\n",
      "27\tValidation loss: 3.860937\tBest loss: 3.860937\tAccuracy: 1.44%\n",
      "28\tValidation loss: 3.859574\tBest loss: 3.859574\tAccuracy: 5.04%\n",
      "29\tValidation loss: 3.858338\tBest loss: 3.858338\tAccuracy: 5.04%\n",
      "30\tValidation loss: 3.856857\tBest loss: 3.856857\tAccuracy: 5.04%\n",
      "31\tValidation loss: 3.933700\tBest loss: 3.856857\tAccuracy: 5.04%\n",
      "32\tValidation loss: 3.854024\tBest loss: 3.854024\tAccuracy: 5.04%\n",
      "33\tValidation loss: 3.852483\tBest loss: 3.852483\tAccuracy: 5.04%\n",
      "34\tValidation loss: 3.850854\tBest loss: 3.850854\tAccuracy: 5.04%\n",
      "35\tValidation loss: 3.849111\tBest loss: 3.849111\tAccuracy: 10.07%\n",
      "36\tValidation loss: 3.847399\tBest loss: 3.847399\tAccuracy: 10.07%\n",
      "37\tValidation loss: 3.845297\tBest loss: 3.845297\tAccuracy: 10.07%\n",
      "38\tValidation loss: 3.842231\tBest loss: 3.842231\tAccuracy: 10.07%\n",
      "39\tValidation loss: 3.840504\tBest loss: 3.840504\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.838371\tBest loss: 3.838371\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.836946\tBest loss: 3.836946\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.834192\tBest loss: 3.834192\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.831186\tBest loss: 3.831186\tAccuracy: 3.60%\n",
      "44\tValidation loss: 7.414203\tBest loss: 3.831186\tAccuracy: 0.00%\n",
      "45\tValidation loss: 3.827425\tBest loss: 3.827425\tAccuracy: 10.07%\n",
      "46\tValidation loss: 3.823805\tBest loss: 3.823805\tAccuracy: 10.07%\n",
      "47\tValidation loss: 3.790801\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "48\tValidation loss: 3.815376\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "49\tValidation loss: 3.811409\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "50\tValidation loss: 3.806611\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "51\tValidation loss: 8.031549\tBest loss: 3.790801\tAccuracy: 9.35%\n",
      "52\tValidation loss: 3.801737\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "53\tValidation loss: 3.796430\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "54\tValidation loss: 3.792891\tBest loss: 3.790801\tAccuracy: 10.07%\n",
      "55\tValidation loss: 3.787949\tBest loss: 3.787949\tAccuracy: 10.07%\n",
      "56\tValidation loss: 3.781442\tBest loss: 3.781442\tAccuracy: 10.07%\n",
      "57\tValidation loss: 3.775211\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "58\tValidation loss: 3.797229\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "59\tValidation loss: 3.791416\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "60\tValidation loss: 3.786170\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "61\tValidation loss: 3.787138\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "62\tValidation loss: 3.775668\tBest loss: 3.775211\tAccuracy: 10.07%\n",
      "63\tValidation loss: 3.768162\tBest loss: 3.768162\tAccuracy: 10.07%\n",
      "64\tValidation loss: 3.759506\tBest loss: 3.759506\tAccuracy: 10.07%\n",
      "65\tValidation loss: 3.757522\tBest loss: 3.757522\tAccuracy: 10.07%\n",
      "66\tValidation loss: 145.821274\tBest loss: 3.757522\tAccuracy: 7.91%\n",
      "67\tValidation loss: 3.937175\tBest loss: 3.757522\tAccuracy: 4.32%\n",
      "68\tValidation loss: 3.823093\tBest loss: 3.757522\tAccuracy: 5.04%\n",
      "69\tValidation loss: 3.822273\tBest loss: 3.757522\tAccuracy: 5.04%\n",
      "70\tValidation loss: 3.821631\tBest loss: 3.757522\tAccuracy: 5.04%\n",
      "71\tValidation loss: 3.821110\tBest loss: 3.757522\tAccuracy: 5.04%\n",
      "72\tValidation loss: 3.820689\tBest loss: 3.757522\tAccuracy: 5.04%\n",
      "73\tValidation loss: 3.820338\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "74\tValidation loss: 3.820076\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "75\tValidation loss: 3.819806\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "76\tValidation loss: 3.819553\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "77\tValidation loss: 3.819287\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "78\tValidation loss: 3.819016\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "79\tValidation loss: 3.818830\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "80\tValidation loss: 3.818542\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "81\tValidation loss: 3.818528\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "82\tValidation loss: 3.816268\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "83\tValidation loss: 3.816920\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "84\tValidation loss: 3.816607\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "85\tValidation loss: 3.816322\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "86\tValidation loss: 3.815940\tBest loss: 3.757522\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=  13.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 6118.540039\tBest loss: 6118.540039\tAccuracy: 6.47%\n",
      "1\tValidation loss: 147969.390625\tBest loss: 6118.540039\tAccuracy: 5.04%\n",
      "2\tValidation loss: 65812.539062\tBest loss: 6118.540039\tAccuracy: 2.16%\n",
      "3\tValidation loss: 68599.335938\tBest loss: 6118.540039\tAccuracy: 0.72%\n",
      "4\tValidation loss: 520263.343750\tBest loss: 6118.540039\tAccuracy: 3.60%\n",
      "5\tValidation loss: 731.032959\tBest loss: 731.032959\tAccuracy: 2.88%\n",
      "6\tValidation loss: 226.539185\tBest loss: 226.539185\tAccuracy: 3.60%\n",
      "7\tValidation loss: 5.148311\tBest loss: 5.148311\tAccuracy: 5.04%\n",
      "8\tValidation loss: 8.228990\tBest loss: 5.148311\tAccuracy: 2.88%\n",
      "9\tValidation loss: 3.856407\tBest loss: 3.856407\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.875137\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "11\tValidation loss: 3.870994\tBest loss: 3.856407\tAccuracy: 1.44%\n",
      "12\tValidation loss: 3.868057\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "13\tValidation loss: 4.128505\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "14\tValidation loss: 3.861378\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "15\tValidation loss: 3.860342\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "16\tValidation loss: 3.859875\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "17\tValidation loss: 3.858284\tBest loss: 3.856407\tAccuracy: 2.88%\n",
      "18\tValidation loss: 8.426299\tBest loss: 3.856407\tAccuracy: 2.16%\n",
      "19\tValidation loss: 3.854329\tBest loss: 3.854329\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.853687\tBest loss: 3.853687\tAccuracy: 3.60%\n",
      "21\tValidation loss: 4.938440\tBest loss: 3.853687\tAccuracy: 4.32%\n",
      "22\tValidation loss: 6.778284\tBest loss: 3.853687\tAccuracy: 1.44%\n",
      "23\tValidation loss: 3.847907\tBest loss: 3.847907\tAccuracy: 3.60%\n",
      "24\tValidation loss: 5.902690\tBest loss: 3.847907\tAccuracy: 2.16%\n",
      "25\tValidation loss: 3.845297\tBest loss: 3.845297\tAccuracy: 2.16%\n",
      "26\tValidation loss: 22.745708\tBest loss: 3.845297\tAccuracy: 0.72%\n",
      "27\tValidation loss: 25.877155\tBest loss: 3.845297\tAccuracy: 0.00%\n",
      "28\tValidation loss: 33.681820\tBest loss: 3.845297\tAccuracy: 1.44%\n",
      "29\tValidation loss: 3.831571\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.832774\tBest loss: 3.831571\tAccuracy: 2.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\tValidation loss: 3.836548\tBest loss: 3.831571\tAccuracy: 7.19%\n",
      "32\tValidation loss: 3.858857\tBest loss: 3.831571\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.857726\tBest loss: 3.831571\tAccuracy: 6.47%\n",
      "34\tValidation loss: 3.856921\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.855771\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.889472\tBest loss: 3.831571\tAccuracy: 2.88%\n",
      "37\tValidation loss: 3.853422\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.871654\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.850991\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.849905\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.848397\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.847004\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.844375\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.844978\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.843753\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.841785\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.841263\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.838227\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.836162\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.838365\tBest loss: 3.831571\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=   6.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 282.970215\tBest loss: 282.970215\tAccuracy: 1.44%\n",
      "1\tValidation loss: 582.555237\tBest loss: 282.970215\tAccuracy: 6.47%\n",
      "2\tValidation loss: 801.427063\tBest loss: 282.970215\tAccuracy: 8.63%\n",
      "3\tValidation loss: 965.400940\tBest loss: 282.970215\tAccuracy: 13.67%\n",
      "4\tValidation loss: 1015.135132\tBest loss: 282.970215\tAccuracy: 11.51%\n",
      "5\tValidation loss: 838.361206\tBest loss: 282.970215\tAccuracy: 28.78%\n",
      "6\tValidation loss: 712.987244\tBest loss: 282.970215\tAccuracy: 34.53%\n",
      "7\tValidation loss: 608.746094\tBest loss: 282.970215\tAccuracy: 42.45%\n",
      "8\tValidation loss: 498.241577\tBest loss: 282.970215\tAccuracy: 44.60%\n",
      "9\tValidation loss: 414.824921\tBest loss: 282.970215\tAccuracy: 49.64%\n",
      "10\tValidation loss: 385.595856\tBest loss: 282.970215\tAccuracy: 50.36%\n",
      "11\tValidation loss: 357.491089\tBest loss: 282.970215\tAccuracy: 42.45%\n",
      "12\tValidation loss: 333.928192\tBest loss: 282.970215\tAccuracy: 44.60%\n",
      "13\tValidation loss: 287.970154\tBest loss: 282.970215\tAccuracy: 47.48%\n",
      "14\tValidation loss: 226.438141\tBest loss: 226.438141\tAccuracy: 54.68%\n",
      "15\tValidation loss: 184.830170\tBest loss: 184.830170\tAccuracy: 65.47%\n",
      "16\tValidation loss: 156.625519\tBest loss: 156.625519\tAccuracy: 65.47%\n",
      "17\tValidation loss: 136.101349\tBest loss: 136.101349\tAccuracy: 64.03%\n",
      "18\tValidation loss: 121.463760\tBest loss: 121.463760\tAccuracy: 65.47%\n",
      "19\tValidation loss: 113.694435\tBest loss: 113.694435\tAccuracy: 64.75%\n",
      "20\tValidation loss: 105.761246\tBest loss: 105.761246\tAccuracy: 63.31%\n",
      "21\tValidation loss: 91.069527\tBest loss: 91.069527\tAccuracy: 65.47%\n",
      "22\tValidation loss: 73.569565\tBest loss: 73.569565\tAccuracy: 69.06%\n",
      "23\tValidation loss: 59.791046\tBest loss: 59.791046\tAccuracy: 74.10%\n",
      "24\tValidation loss: 49.842644\tBest loss: 49.842644\tAccuracy: 76.26%\n",
      "25\tValidation loss: 42.266613\tBest loss: 42.266613\tAccuracy: 77.70%\n",
      "26\tValidation loss: 36.805458\tBest loss: 36.805458\tAccuracy: 78.42%\n",
      "27\tValidation loss: 32.746624\tBest loss: 32.746624\tAccuracy: 78.42%\n",
      "28\tValidation loss: 28.901917\tBest loss: 28.901917\tAccuracy: 77.70%\n",
      "29\tValidation loss: 27.470848\tBest loss: 27.470848\tAccuracy: 81.29%\n",
      "30\tValidation loss: 25.659910\tBest loss: 25.659910\tAccuracy: 84.17%\n",
      "31\tValidation loss: 24.547890\tBest loss: 24.547890\tAccuracy: 85.61%\n",
      "32\tValidation loss: 23.470186\tBest loss: 23.470186\tAccuracy: 86.33%\n",
      "33\tValidation loss: 22.175730\tBest loss: 22.175730\tAccuracy: 88.49%\n",
      "34\tValidation loss: 21.734196\tBest loss: 21.734196\tAccuracy: 88.49%\n",
      "35\tValidation loss: 21.522757\tBest loss: 21.522757\tAccuracy: 88.49%\n",
      "36\tValidation loss: 21.400761\tBest loss: 21.400761\tAccuracy: 88.49%\n",
      "37\tValidation loss: 21.328241\tBest loss: 21.328241\tAccuracy: 88.49%\n",
      "38\tValidation loss: 21.085766\tBest loss: 21.085766\tAccuracy: 87.77%\n",
      "39\tValidation loss: 20.806740\tBest loss: 20.806740\tAccuracy: 87.77%\n",
      "40\tValidation loss: 20.240467\tBest loss: 20.240467\tAccuracy: 87.77%\n",
      "41\tValidation loss: 19.544701\tBest loss: 19.544701\tAccuracy: 87.77%\n",
      "42\tValidation loss: 18.730577\tBest loss: 18.730577\tAccuracy: 87.77%\n",
      "43\tValidation loss: 17.906590\tBest loss: 17.906590\tAccuracy: 88.49%\n",
      "44\tValidation loss: 17.105913\tBest loss: 17.105913\tAccuracy: 89.21%\n",
      "45\tValidation loss: 16.359116\tBest loss: 16.359116\tAccuracy: 89.21%\n",
      "46\tValidation loss: 15.583869\tBest loss: 15.583869\tAccuracy: 89.21%\n",
      "47\tValidation loss: 14.872379\tBest loss: 14.872379\tAccuracy: 88.49%\n",
      "48\tValidation loss: 14.141841\tBest loss: 14.141841\tAccuracy: 87.77%\n",
      "49\tValidation loss: 13.666253\tBest loss: 13.666253\tAccuracy: 87.77%\n",
      "50\tValidation loss: 12.625648\tBest loss: 12.625648\tAccuracy: 87.77%\n",
      "51\tValidation loss: 11.846192\tBest loss: 11.846192\tAccuracy: 88.49%\n",
      "52\tValidation loss: 11.093891\tBest loss: 11.093891\tAccuracy: 88.49%\n",
      "53\tValidation loss: 10.413837\tBest loss: 10.413837\tAccuracy: 89.21%\n",
      "54\tValidation loss: 9.843010\tBest loss: 9.843010\tAccuracy: 89.21%\n",
      "55\tValidation loss: 9.301189\tBest loss: 9.301189\tAccuracy: 89.93%\n",
      "56\tValidation loss: 8.789881\tBest loss: 8.789881\tAccuracy: 89.93%\n",
      "57\tValidation loss: 8.381886\tBest loss: 8.381886\tAccuracy: 90.65%\n",
      "58\tValidation loss: 8.013885\tBest loss: 8.013885\tAccuracy: 90.65%\n",
      "59\tValidation loss: 7.673007\tBest loss: 7.673007\tAccuracy: 90.65%\n",
      "60\tValidation loss: 7.371294\tBest loss: 7.371294\tAccuracy: 90.65%\n",
      "61\tValidation loss: 7.153812\tBest loss: 7.153812\tAccuracy: 90.65%\n",
      "62\tValidation loss: 6.990871\tBest loss: 6.990871\tAccuracy: 91.37%\n",
      "63\tValidation loss: 6.914214\tBest loss: 6.914214\tAccuracy: 90.65%\n",
      "64\tValidation loss: 6.867948\tBest loss: 6.867948\tAccuracy: 90.65%\n",
      "65\tValidation loss: 6.807796\tBest loss: 6.807796\tAccuracy: 90.65%\n",
      "66\tValidation loss: 6.731580\tBest loss: 6.731580\tAccuracy: 91.37%\n",
      "67\tValidation loss: 6.714024\tBest loss: 6.714024\tAccuracy: 91.37%\n",
      "68\tValidation loss: 6.673781\tBest loss: 6.673781\tAccuracy: 91.37%\n",
      "69\tValidation loss: 6.611550\tBest loss: 6.611550\tAccuracy: 91.37%\n",
      "70\tValidation loss: 6.542257\tBest loss: 6.542257\tAccuracy: 91.37%\n",
      "71\tValidation loss: 6.463508\tBest loss: 6.463508\tAccuracy: 91.37%\n",
      "72\tValidation loss: 6.392050\tBest loss: 6.392050\tAccuracy: 91.37%\n",
      "73\tValidation loss: 6.327048\tBest loss: 6.327048\tAccuracy: 91.37%\n",
      "74\tValidation loss: 6.267794\tBest loss: 6.267794\tAccuracy: 91.37%\n",
      "75\tValidation loss: 6.212195\tBest loss: 6.212195\tAccuracy: 91.37%\n",
      "76\tValidation loss: 6.159967\tBest loss: 6.159967\tAccuracy: 91.37%\n",
      "77\tValidation loss: 6.110572\tBest loss: 6.110572\tAccuracy: 91.37%\n",
      "78\tValidation loss: 6.063839\tBest loss: 6.063839\tAccuracy: 91.37%\n",
      "79\tValidation loss: 6.020026\tBest loss: 6.020026\tAccuracy: 91.37%\n",
      "80\tValidation loss: 5.979086\tBest loss: 5.979086\tAccuracy: 91.37%\n",
      "81\tValidation loss: 5.941024\tBest loss: 5.941024\tAccuracy: 91.37%\n",
      "82\tValidation loss: 5.906183\tBest loss: 5.906183\tAccuracy: 91.37%\n",
      "83\tValidation loss: 5.874331\tBest loss: 5.874331\tAccuracy: 91.37%\n",
      "84\tValidation loss: 5.845226\tBest loss: 5.845226\tAccuracy: 91.37%\n",
      "85\tValidation loss: 5.818741\tBest loss: 5.818741\tAccuracy: 91.37%\n",
      "86\tValidation loss: 5.794726\tBest loss: 5.794726\tAccuracy: 91.37%\n",
      "87\tValidation loss: 5.773013\tBest loss: 5.773013\tAccuracy: 91.37%\n",
      "88\tValidation loss: 5.753267\tBest loss: 5.753267\tAccuracy: 91.37%\n",
      "89\tValidation loss: 5.735561\tBest loss: 5.735561\tAccuracy: 91.37%\n",
      "90\tValidation loss: 5.719836\tBest loss: 5.719836\tAccuracy: 91.37%\n",
      "91\tValidation loss: 5.705849\tBest loss: 5.705849\tAccuracy: 91.37%\n",
      "92\tValidation loss: 5.693583\tBest loss: 5.693583\tAccuracy: 91.37%\n",
      "93\tValidation loss: 5.682734\tBest loss: 5.682734\tAccuracy: 92.09%\n",
      "94\tValidation loss: 5.673344\tBest loss: 5.673344\tAccuracy: 92.09%\n",
      "95\tValidation loss: 5.664933\tBest loss: 5.664933\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\tValidation loss: 5.657479\tBest loss: 5.657479\tAccuracy: 92.09%\n",
      "97\tValidation loss: 5.650931\tBest loss: 5.650931\tAccuracy: 92.09%\n",
      "98\tValidation loss: 5.645205\tBest loss: 5.645205\tAccuracy: 92.09%\n",
      "99\tValidation loss: 5.640182\tBest loss: 5.640182\tAccuracy: 92.09%\n",
      "100\tValidation loss: 5.635870\tBest loss: 5.635870\tAccuracy: 92.09%\n",
      "101\tValidation loss: 5.632087\tBest loss: 5.632087\tAccuracy: 92.09%\n",
      "102\tValidation loss: 5.628845\tBest loss: 5.628845\tAccuracy: 92.09%\n",
      "103\tValidation loss: 5.625905\tBest loss: 5.625905\tAccuracy: 92.09%\n",
      "104\tValidation loss: 5.623304\tBest loss: 5.623304\tAccuracy: 92.09%\n",
      "105\tValidation loss: 5.620833\tBest loss: 5.620833\tAccuracy: 92.09%\n",
      "106\tValidation loss: 5.618576\tBest loss: 5.618576\tAccuracy: 92.09%\n",
      "107\tValidation loss: 5.616328\tBest loss: 5.616328\tAccuracy: 92.09%\n",
      "108\tValidation loss: 5.614203\tBest loss: 5.614203\tAccuracy: 92.09%\n",
      "109\tValidation loss: 5.612152\tBest loss: 5.612152\tAccuracy: 92.09%\n",
      "110\tValidation loss: 5.610146\tBest loss: 5.610146\tAccuracy: 92.09%\n",
      "111\tValidation loss: 5.608202\tBest loss: 5.608202\tAccuracy: 92.09%\n",
      "112\tValidation loss: 5.606295\tBest loss: 5.606295\tAccuracy: 92.09%\n",
      "113\tValidation loss: 5.604409\tBest loss: 5.604409\tAccuracy: 92.09%\n",
      "114\tValidation loss: 5.602572\tBest loss: 5.602572\tAccuracy: 92.09%\n",
      "115\tValidation loss: 5.600857\tBest loss: 5.600857\tAccuracy: 92.09%\n",
      "116\tValidation loss: 5.599135\tBest loss: 5.599135\tAccuracy: 92.09%\n",
      "117\tValidation loss: 5.597468\tBest loss: 5.597468\tAccuracy: 92.09%\n",
      "118\tValidation loss: 5.595832\tBest loss: 5.595832\tAccuracy: 92.09%\n",
      "119\tValidation loss: 5.594217\tBest loss: 5.594217\tAccuracy: 92.09%\n",
      "120\tValidation loss: 5.592663\tBest loss: 5.592663\tAccuracy: 92.09%\n",
      "121\tValidation loss: 5.591153\tBest loss: 5.591153\tAccuracy: 92.09%\n",
      "122\tValidation loss: 5.589683\tBest loss: 5.589683\tAccuracy: 92.09%\n",
      "123\tValidation loss: 5.588304\tBest loss: 5.588304\tAccuracy: 92.09%\n",
      "124\tValidation loss: 5.586965\tBest loss: 5.586965\tAccuracy: 92.09%\n",
      "125\tValidation loss: 5.585646\tBest loss: 5.585646\tAccuracy: 92.09%\n",
      "126\tValidation loss: 5.584363\tBest loss: 5.584363\tAccuracy: 92.09%\n",
      "127\tValidation loss: 5.583146\tBest loss: 5.583146\tAccuracy: 92.09%\n",
      "128\tValidation loss: 5.581980\tBest loss: 5.581980\tAccuracy: 92.09%\n",
      "129\tValidation loss: 5.580800\tBest loss: 5.580800\tAccuracy: 92.09%\n",
      "130\tValidation loss: 5.579710\tBest loss: 5.579710\tAccuracy: 92.09%\n",
      "131\tValidation loss: 5.578644\tBest loss: 5.578644\tAccuracy: 92.09%\n",
      "132\tValidation loss: 5.577619\tBest loss: 5.577619\tAccuracy: 92.09%\n",
      "133\tValidation loss: 5.576607\tBest loss: 5.576607\tAccuracy: 92.09%\n",
      "134\tValidation loss: 5.575657\tBest loss: 5.575657\tAccuracy: 92.09%\n",
      "135\tValidation loss: 5.574749\tBest loss: 5.574749\tAccuracy: 92.09%\n",
      "136\tValidation loss: 5.573846\tBest loss: 5.573846\tAccuracy: 92.09%\n",
      "137\tValidation loss: 5.572974\tBest loss: 5.572974\tAccuracy: 92.09%\n",
      "138\tValidation loss: 5.572153\tBest loss: 5.572153\tAccuracy: 92.09%\n",
      "139\tValidation loss: 5.571335\tBest loss: 5.571335\tAccuracy: 92.09%\n",
      "140\tValidation loss: 5.570570\tBest loss: 5.570570\tAccuracy: 92.09%\n",
      "141\tValidation loss: 5.569809\tBest loss: 5.569809\tAccuracy: 92.09%\n",
      "142\tValidation loss: 5.569095\tBest loss: 5.569095\tAccuracy: 92.09%\n",
      "143\tValidation loss: 5.568376\tBest loss: 5.568376\tAccuracy: 92.09%\n",
      "144\tValidation loss: 5.567666\tBest loss: 5.567666\tAccuracy: 92.09%\n",
      "145\tValidation loss: 5.567008\tBest loss: 5.567008\tAccuracy: 92.09%\n",
      "146\tValidation loss: 5.566329\tBest loss: 5.566329\tAccuracy: 92.09%\n",
      "147\tValidation loss: 5.565669\tBest loss: 5.565669\tAccuracy: 92.09%\n",
      "148\tValidation loss: 5.565049\tBest loss: 5.565049\tAccuracy: 92.09%\n",
      "149\tValidation loss: 5.564437\tBest loss: 5.564437\tAccuracy: 92.09%\n",
      "150\tValidation loss: 5.563852\tBest loss: 5.563852\tAccuracy: 92.09%\n",
      "151\tValidation loss: 5.563289\tBest loss: 5.563289\tAccuracy: 92.09%\n",
      "152\tValidation loss: 5.562746\tBest loss: 5.562746\tAccuracy: 92.09%\n",
      "153\tValidation loss: 5.562205\tBest loss: 5.562205\tAccuracy: 92.09%\n",
      "154\tValidation loss: 5.561666\tBest loss: 5.561666\tAccuracy: 92.09%\n",
      "155\tValidation loss: 5.561151\tBest loss: 5.561151\tAccuracy: 92.09%\n",
      "156\tValidation loss: 5.560658\tBest loss: 5.560658\tAccuracy: 92.09%\n",
      "157\tValidation loss: 5.560165\tBest loss: 5.560165\tAccuracy: 92.09%\n",
      "158\tValidation loss: 5.559686\tBest loss: 5.559686\tAccuracy: 92.09%\n",
      "159\tValidation loss: 5.559216\tBest loss: 5.559216\tAccuracy: 92.09%\n",
      "160\tValidation loss: 5.558758\tBest loss: 5.558758\tAccuracy: 92.09%\n",
      "161\tValidation loss: 5.558291\tBest loss: 5.558291\tAccuracy: 92.09%\n",
      "162\tValidation loss: 5.557847\tBest loss: 5.557847\tAccuracy: 92.09%\n",
      "163\tValidation loss: 5.557419\tBest loss: 5.557419\tAccuracy: 92.09%\n",
      "164\tValidation loss: 5.557000\tBest loss: 5.557000\tAccuracy: 92.09%\n",
      "165\tValidation loss: 5.556584\tBest loss: 5.556584\tAccuracy: 92.09%\n",
      "166\tValidation loss: 5.556170\tBest loss: 5.556170\tAccuracy: 92.09%\n",
      "167\tValidation loss: 5.555758\tBest loss: 5.555758\tAccuracy: 92.09%\n",
      "168\tValidation loss: 5.555362\tBest loss: 5.555362\tAccuracy: 92.09%\n",
      "169\tValidation loss: 5.554964\tBest loss: 5.554964\tAccuracy: 92.09%\n",
      "170\tValidation loss: 5.554566\tBest loss: 5.554566\tAccuracy: 92.09%\n",
      "171\tValidation loss: 5.554184\tBest loss: 5.554184\tAccuracy: 92.09%\n",
      "172\tValidation loss: 5.553805\tBest loss: 5.553805\tAccuracy: 92.09%\n",
      "173\tValidation loss: 5.553438\tBest loss: 5.553438\tAccuracy: 92.09%\n",
      "174\tValidation loss: 5.553078\tBest loss: 5.553078\tAccuracy: 92.09%\n",
      "175\tValidation loss: 5.552713\tBest loss: 5.552713\tAccuracy: 92.09%\n",
      "176\tValidation loss: 5.552364\tBest loss: 5.552364\tAccuracy: 92.09%\n",
      "177\tValidation loss: 5.552007\tBest loss: 5.552007\tAccuracy: 92.09%\n",
      "178\tValidation loss: 5.551671\tBest loss: 5.551671\tAccuracy: 92.09%\n",
      "179\tValidation loss: 5.551319\tBest loss: 5.551319\tAccuracy: 92.09%\n",
      "180\tValidation loss: 5.550967\tBest loss: 5.550967\tAccuracy: 92.09%\n",
      "181\tValidation loss: 5.550621\tBest loss: 5.550621\tAccuracy: 92.09%\n",
      "182\tValidation loss: 5.550283\tBest loss: 5.550283\tAccuracy: 92.09%\n",
      "183\tValidation loss: 5.549954\tBest loss: 5.549954\tAccuracy: 92.09%\n",
      "184\tValidation loss: 5.549621\tBest loss: 5.549621\tAccuracy: 92.09%\n",
      "185\tValidation loss: 5.549302\tBest loss: 5.549302\tAccuracy: 92.09%\n",
      "186\tValidation loss: 5.549002\tBest loss: 5.549002\tAccuracy: 92.09%\n",
      "187\tValidation loss: 5.548689\tBest loss: 5.548689\tAccuracy: 92.09%\n",
      "188\tValidation loss: 5.548380\tBest loss: 5.548380\tAccuracy: 92.09%\n",
      "189\tValidation loss: 5.548080\tBest loss: 5.548080\tAccuracy: 92.09%\n",
      "190\tValidation loss: 5.547772\tBest loss: 5.547772\tAccuracy: 92.09%\n",
      "191\tValidation loss: 5.547477\tBest loss: 5.547477\tAccuracy: 92.09%\n",
      "192\tValidation loss: 5.547179\tBest loss: 5.547179\tAccuracy: 92.09%\n",
      "193\tValidation loss: 5.546882\tBest loss: 5.546882\tAccuracy: 92.09%\n",
      "194\tValidation loss: 5.546587\tBest loss: 5.546587\tAccuracy: 92.09%\n",
      "195\tValidation loss: 5.546289\tBest loss: 5.546289\tAccuracy: 92.09%\n",
      "196\tValidation loss: 5.546003\tBest loss: 5.546003\tAccuracy: 92.09%\n",
      "197\tValidation loss: 5.545717\tBest loss: 5.545717\tAccuracy: 92.09%\n",
      "198\tValidation loss: 5.545449\tBest loss: 5.545449\tAccuracy: 92.09%\n",
      "199\tValidation loss: 5.545162\tBest loss: 5.545162\tAccuracy: 92.09%\n",
      "200\tValidation loss: 5.544890\tBest loss: 5.544890\tAccuracy: 92.09%\n",
      "201\tValidation loss: 5.544623\tBest loss: 5.544623\tAccuracy: 92.09%\n",
      "202\tValidation loss: 5.544352\tBest loss: 5.544352\tAccuracy: 92.09%\n",
      "203\tValidation loss: 5.544084\tBest loss: 5.544084\tAccuracy: 92.09%\n",
      "204\tValidation loss: 5.543816\tBest loss: 5.543816\tAccuracy: 92.09%\n",
      "205\tValidation loss: 5.543542\tBest loss: 5.543542\tAccuracy: 92.09%\n",
      "206\tValidation loss: 5.543264\tBest loss: 5.543264\tAccuracy: 92.09%\n",
      "207\tValidation loss: 5.543019\tBest loss: 5.543019\tAccuracy: 92.09%\n",
      "208\tValidation loss: 5.542767\tBest loss: 5.542767\tAccuracy: 92.09%\n",
      "209\tValidation loss: 5.542504\tBest loss: 5.542504\tAccuracy: 92.09%\n",
      "210\tValidation loss: 5.542248\tBest loss: 5.542248\tAccuracy: 92.09%\n",
      "211\tValidation loss: 5.541989\tBest loss: 5.541989\tAccuracy: 92.09%\n",
      "212\tValidation loss: 5.541737\tBest loss: 5.541737\tAccuracy: 92.09%\n",
      "213\tValidation loss: 5.541493\tBest loss: 5.541493\tAccuracy: 92.09%\n",
      "214\tValidation loss: 5.541251\tBest loss: 5.541251\tAccuracy: 92.09%\n",
      "215\tValidation loss: 5.540997\tBest loss: 5.540997\tAccuracy: 92.09%\n",
      "216\tValidation loss: 5.540757\tBest loss: 5.540757\tAccuracy: 92.09%\n",
      "217\tValidation loss: 5.540516\tBest loss: 5.540516\tAccuracy: 92.09%\n",
      "218\tValidation loss: 5.540261\tBest loss: 5.540261\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\tValidation loss: 5.540012\tBest loss: 5.540012\tAccuracy: 92.09%\n",
      "220\tValidation loss: 5.539795\tBest loss: 5.539795\tAccuracy: 92.09%\n",
      "221\tValidation loss: 5.539561\tBest loss: 5.539561\tAccuracy: 92.09%\n",
      "222\tValidation loss: 5.539329\tBest loss: 5.539329\tAccuracy: 92.09%\n",
      "223\tValidation loss: 5.539096\tBest loss: 5.539096\tAccuracy: 92.09%\n",
      "224\tValidation loss: 5.538857\tBest loss: 5.538857\tAccuracy: 92.09%\n",
      "225\tValidation loss: 5.538632\tBest loss: 5.538632\tAccuracy: 92.09%\n",
      "226\tValidation loss: 5.538402\tBest loss: 5.538402\tAccuracy: 92.09%\n",
      "227\tValidation loss: 5.538177\tBest loss: 5.538177\tAccuracy: 92.09%\n",
      "228\tValidation loss: 5.537953\tBest loss: 5.537953\tAccuracy: 92.09%\n",
      "229\tValidation loss: 5.537736\tBest loss: 5.537736\tAccuracy: 92.09%\n",
      "230\tValidation loss: 5.537505\tBest loss: 5.537505\tAccuracy: 92.09%\n",
      "231\tValidation loss: 5.537284\tBest loss: 5.537284\tAccuracy: 92.09%\n",
      "232\tValidation loss: 5.537055\tBest loss: 5.537055\tAccuracy: 92.09%\n",
      "233\tValidation loss: 5.536834\tBest loss: 5.536834\tAccuracy: 92.09%\n",
      "234\tValidation loss: 5.536633\tBest loss: 5.536633\tAccuracy: 92.09%\n",
      "235\tValidation loss: 5.536417\tBest loss: 5.536417\tAccuracy: 92.09%\n",
      "236\tValidation loss: 5.536200\tBest loss: 5.536200\tAccuracy: 92.09%\n",
      "237\tValidation loss: 5.535988\tBest loss: 5.535988\tAccuracy: 92.09%\n",
      "238\tValidation loss: 5.535758\tBest loss: 5.535758\tAccuracy: 92.09%\n",
      "239\tValidation loss: 5.535561\tBest loss: 5.535561\tAccuracy: 92.09%\n",
      "240\tValidation loss: 5.535352\tBest loss: 5.535352\tAccuracy: 92.09%\n",
      "241\tValidation loss: 5.535125\tBest loss: 5.535125\tAccuracy: 92.09%\n",
      "242\tValidation loss: 5.534926\tBest loss: 5.534926\tAccuracy: 92.09%\n",
      "243\tValidation loss: 5.534718\tBest loss: 5.534718\tAccuracy: 92.09%\n",
      "244\tValidation loss: 5.534516\tBest loss: 5.534516\tAccuracy: 92.09%\n",
      "245\tValidation loss: 5.534317\tBest loss: 5.534317\tAccuracy: 92.09%\n",
      "246\tValidation loss: 5.534115\tBest loss: 5.534115\tAccuracy: 92.09%\n",
      "247\tValidation loss: 5.533915\tBest loss: 5.533915\tAccuracy: 92.09%\n",
      "248\tValidation loss: 5.533721\tBest loss: 5.533721\tAccuracy: 92.09%\n",
      "249\tValidation loss: 5.533510\tBest loss: 5.533510\tAccuracy: 92.09%\n",
      "250\tValidation loss: 5.533314\tBest loss: 5.533314\tAccuracy: 92.09%\n",
      "251\tValidation loss: 5.533107\tBest loss: 5.533107\tAccuracy: 92.09%\n",
      "252\tValidation loss: 5.532902\tBest loss: 5.532902\tAccuracy: 92.09%\n",
      "253\tValidation loss: 5.532703\tBest loss: 5.532703\tAccuracy: 92.09%\n",
      "254\tValidation loss: 5.532512\tBest loss: 5.532512\tAccuracy: 92.09%\n",
      "255\tValidation loss: 5.532322\tBest loss: 5.532322\tAccuracy: 92.09%\n",
      "256\tValidation loss: 5.532139\tBest loss: 5.532139\tAccuracy: 92.09%\n",
      "257\tValidation loss: 5.531950\tBest loss: 5.531950\tAccuracy: 92.09%\n",
      "258\tValidation loss: 5.531768\tBest loss: 5.531768\tAccuracy: 92.09%\n",
      "259\tValidation loss: 5.531559\tBest loss: 5.531559\tAccuracy: 92.09%\n",
      "260\tValidation loss: 5.531363\tBest loss: 5.531363\tAccuracy: 92.09%\n",
      "261\tValidation loss: 5.531180\tBest loss: 5.531180\tAccuracy: 92.09%\n",
      "262\tValidation loss: 5.531008\tBest loss: 5.531008\tAccuracy: 92.09%\n",
      "263\tValidation loss: 5.530822\tBest loss: 5.530822\tAccuracy: 92.09%\n",
      "264\tValidation loss: 5.530629\tBest loss: 5.530629\tAccuracy: 92.09%\n",
      "265\tValidation loss: 5.530457\tBest loss: 5.530457\tAccuracy: 92.09%\n",
      "266\tValidation loss: 5.530276\tBest loss: 5.530276\tAccuracy: 92.09%\n",
      "267\tValidation loss: 5.530078\tBest loss: 5.530078\tAccuracy: 92.09%\n",
      "268\tValidation loss: 5.529895\tBest loss: 5.529895\tAccuracy: 92.09%\n",
      "269\tValidation loss: 5.529695\tBest loss: 5.529695\tAccuracy: 92.09%\n",
      "270\tValidation loss: 5.529516\tBest loss: 5.529516\tAccuracy: 92.09%\n",
      "271\tValidation loss: 5.529342\tBest loss: 5.529342\tAccuracy: 92.09%\n",
      "272\tValidation loss: 5.529164\tBest loss: 5.529164\tAccuracy: 92.09%\n",
      "273\tValidation loss: 5.528973\tBest loss: 5.528973\tAccuracy: 92.09%\n",
      "274\tValidation loss: 5.528790\tBest loss: 5.528790\tAccuracy: 92.09%\n",
      "275\tValidation loss: 5.528623\tBest loss: 5.528623\tAccuracy: 92.09%\n",
      "276\tValidation loss: 5.528449\tBest loss: 5.528449\tAccuracy: 92.09%\n",
      "277\tValidation loss: 5.528270\tBest loss: 5.528270\tAccuracy: 92.09%\n",
      "278\tValidation loss: 5.528110\tBest loss: 5.528110\tAccuracy: 92.09%\n",
      "279\tValidation loss: 5.527936\tBest loss: 5.527936\tAccuracy: 92.09%\n",
      "280\tValidation loss: 5.527756\tBest loss: 5.527756\tAccuracy: 92.09%\n",
      "281\tValidation loss: 5.527580\tBest loss: 5.527580\tAccuracy: 92.09%\n",
      "282\tValidation loss: 5.527407\tBest loss: 5.527407\tAccuracy: 92.09%\n",
      "283\tValidation loss: 5.527230\tBest loss: 5.527230\tAccuracy: 92.09%\n",
      "284\tValidation loss: 5.527065\tBest loss: 5.527065\tAccuracy: 92.09%\n",
      "285\tValidation loss: 5.526902\tBest loss: 5.526902\tAccuracy: 92.09%\n",
      "286\tValidation loss: 5.526731\tBest loss: 5.526731\tAccuracy: 92.09%\n",
      "287\tValidation loss: 5.526567\tBest loss: 5.526567\tAccuracy: 92.09%\n",
      "288\tValidation loss: 5.526412\tBest loss: 5.526412\tAccuracy: 92.09%\n",
      "289\tValidation loss: 5.526255\tBest loss: 5.526255\tAccuracy: 92.09%\n",
      "290\tValidation loss: 5.526088\tBest loss: 5.526088\tAccuracy: 92.09%\n",
      "291\tValidation loss: 5.525922\tBest loss: 5.525922\tAccuracy: 92.09%\n",
      "292\tValidation loss: 5.525746\tBest loss: 5.525746\tAccuracy: 92.09%\n",
      "293\tValidation loss: 5.525591\tBest loss: 5.525591\tAccuracy: 92.09%\n",
      "294\tValidation loss: 5.525432\tBest loss: 5.525432\tAccuracy: 92.09%\n",
      "295\tValidation loss: 5.525267\tBest loss: 5.525267\tAccuracy: 92.09%\n",
      "296\tValidation loss: 5.525098\tBest loss: 5.525098\tAccuracy: 92.09%\n",
      "297\tValidation loss: 5.524940\tBest loss: 5.524940\tAccuracy: 92.09%\n",
      "298\tValidation loss: 5.524784\tBest loss: 5.524784\tAccuracy: 92.09%\n",
      "299\tValidation loss: 5.524624\tBest loss: 5.524624\tAccuracy: 92.09%\n",
      "300\tValidation loss: 5.524470\tBest loss: 5.524470\tAccuracy: 92.09%\n",
      "301\tValidation loss: 5.524307\tBest loss: 5.524307\tAccuracy: 92.09%\n",
      "302\tValidation loss: 5.524155\tBest loss: 5.524155\tAccuracy: 92.09%\n",
      "303\tValidation loss: 5.523988\tBest loss: 5.523988\tAccuracy: 92.09%\n",
      "304\tValidation loss: 5.523829\tBest loss: 5.523829\tAccuracy: 92.09%\n",
      "305\tValidation loss: 5.523682\tBest loss: 5.523682\tAccuracy: 92.09%\n",
      "306\tValidation loss: 5.523536\tBest loss: 5.523536\tAccuracy: 92.09%\n",
      "307\tValidation loss: 5.523375\tBest loss: 5.523375\tAccuracy: 92.09%\n",
      "308\tValidation loss: 5.523231\tBest loss: 5.523231\tAccuracy: 92.09%\n",
      "309\tValidation loss: 5.523074\tBest loss: 5.523074\tAccuracy: 92.09%\n",
      "310\tValidation loss: 5.522927\tBest loss: 5.522927\tAccuracy: 92.09%\n",
      "311\tValidation loss: 5.522778\tBest loss: 5.522778\tAccuracy: 92.09%\n",
      "312\tValidation loss: 5.522620\tBest loss: 5.522620\tAccuracy: 92.09%\n",
      "313\tValidation loss: 5.522461\tBest loss: 5.522461\tAccuracy: 92.09%\n",
      "314\tValidation loss: 5.522315\tBest loss: 5.522315\tAccuracy: 92.09%\n",
      "315\tValidation loss: 5.522161\tBest loss: 5.522161\tAccuracy: 92.09%\n",
      "316\tValidation loss: 5.522024\tBest loss: 5.522024\tAccuracy: 92.09%\n",
      "317\tValidation loss: 5.521875\tBest loss: 5.521875\tAccuracy: 92.09%\n",
      "318\tValidation loss: 5.521731\tBest loss: 5.521731\tAccuracy: 92.09%\n",
      "319\tValidation loss: 5.521580\tBest loss: 5.521580\tAccuracy: 92.09%\n",
      "320\tValidation loss: 5.521435\tBest loss: 5.521435\tAccuracy: 92.09%\n",
      "321\tValidation loss: 5.521290\tBest loss: 5.521290\tAccuracy: 92.09%\n",
      "322\tValidation loss: 5.521133\tBest loss: 5.521133\tAccuracy: 92.09%\n",
      "323\tValidation loss: 5.520991\tBest loss: 5.520991\tAccuracy: 92.09%\n",
      "324\tValidation loss: 5.520852\tBest loss: 5.520852\tAccuracy: 92.09%\n",
      "325\tValidation loss: 5.520707\tBest loss: 5.520707\tAccuracy: 92.09%\n",
      "326\tValidation loss: 5.520560\tBest loss: 5.520560\tAccuracy: 92.09%\n",
      "327\tValidation loss: 5.520414\tBest loss: 5.520414\tAccuracy: 92.09%\n",
      "328\tValidation loss: 5.520272\tBest loss: 5.520272\tAccuracy: 92.09%\n",
      "329\tValidation loss: 5.520131\tBest loss: 5.520131\tAccuracy: 92.09%\n",
      "330\tValidation loss: 5.519992\tBest loss: 5.519992\tAccuracy: 92.09%\n",
      "331\tValidation loss: 5.519844\tBest loss: 5.519844\tAccuracy: 92.09%\n",
      "332\tValidation loss: 5.519717\tBest loss: 5.519717\tAccuracy: 92.09%\n",
      "333\tValidation loss: 5.519575\tBest loss: 5.519575\tAccuracy: 92.09%\n",
      "334\tValidation loss: 5.519450\tBest loss: 5.519450\tAccuracy: 92.09%\n",
      "335\tValidation loss: 5.519304\tBest loss: 5.519304\tAccuracy: 92.09%\n",
      "336\tValidation loss: 5.519172\tBest loss: 5.519172\tAccuracy: 92.09%\n",
      "337\tValidation loss: 5.519042\tBest loss: 5.519042\tAccuracy: 92.09%\n",
      "338\tValidation loss: 5.518909\tBest loss: 5.518909\tAccuracy: 92.09%\n",
      "339\tValidation loss: 5.518766\tBest loss: 5.518766\tAccuracy: 92.09%\n",
      "340\tValidation loss: 5.518616\tBest loss: 5.518616\tAccuracy: 92.09%\n",
      "341\tValidation loss: 5.518483\tBest loss: 5.518483\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\tValidation loss: 5.518352\tBest loss: 5.518352\tAccuracy: 92.09%\n",
      "343\tValidation loss: 5.518223\tBest loss: 5.518223\tAccuracy: 92.09%\n",
      "344\tValidation loss: 5.518081\tBest loss: 5.518081\tAccuracy: 92.09%\n",
      "345\tValidation loss: 5.517949\tBest loss: 5.517949\tAccuracy: 92.09%\n",
      "346\tValidation loss: 5.517818\tBest loss: 5.517818\tAccuracy: 92.09%\n",
      "347\tValidation loss: 5.517696\tBest loss: 5.517696\tAccuracy: 92.09%\n",
      "348\tValidation loss: 5.517558\tBest loss: 5.517558\tAccuracy: 92.09%\n",
      "349\tValidation loss: 5.517432\tBest loss: 5.517432\tAccuracy: 92.09%\n",
      "350\tValidation loss: 5.517296\tBest loss: 5.517296\tAccuracy: 92.09%\n",
      "351\tValidation loss: 5.517170\tBest loss: 5.517170\tAccuracy: 92.09%\n",
      "352\tValidation loss: 5.517041\tBest loss: 5.517041\tAccuracy: 92.09%\n",
      "353\tValidation loss: 5.516907\tBest loss: 5.516907\tAccuracy: 92.09%\n",
      "354\tValidation loss: 5.516777\tBest loss: 5.516777\tAccuracy: 92.09%\n",
      "355\tValidation loss: 5.516653\tBest loss: 5.516653\tAccuracy: 92.09%\n",
      "356\tValidation loss: 5.516521\tBest loss: 5.516521\tAccuracy: 92.09%\n",
      "357\tValidation loss: 5.516385\tBest loss: 5.516385\tAccuracy: 92.09%\n",
      "358\tValidation loss: 5.516265\tBest loss: 5.516265\tAccuracy: 92.09%\n",
      "359\tValidation loss: 5.516138\tBest loss: 5.516138\tAccuracy: 92.09%\n",
      "360\tValidation loss: 5.516026\tBest loss: 5.516026\tAccuracy: 92.09%\n",
      "361\tValidation loss: 5.515908\tBest loss: 5.515908\tAccuracy: 92.09%\n",
      "362\tValidation loss: 5.515781\tBest loss: 5.515781\tAccuracy: 92.09%\n",
      "363\tValidation loss: 5.515652\tBest loss: 5.515652\tAccuracy: 92.09%\n",
      "364\tValidation loss: 5.515526\tBest loss: 5.515526\tAccuracy: 92.09%\n",
      "365\tValidation loss: 5.515407\tBest loss: 5.515407\tAccuracy: 92.09%\n",
      "366\tValidation loss: 5.515278\tBest loss: 5.515278\tAccuracy: 92.09%\n",
      "367\tValidation loss: 5.515166\tBest loss: 5.515166\tAccuracy: 92.09%\n",
      "368\tValidation loss: 5.515038\tBest loss: 5.515038\tAccuracy: 92.09%\n",
      "369\tValidation loss: 5.514913\tBest loss: 5.514913\tAccuracy: 92.09%\n",
      "370\tValidation loss: 5.514789\tBest loss: 5.514789\tAccuracy: 92.09%\n",
      "371\tValidation loss: 5.514668\tBest loss: 5.514668\tAccuracy: 92.09%\n",
      "372\tValidation loss: 5.514538\tBest loss: 5.514538\tAccuracy: 92.09%\n",
      "373\tValidation loss: 5.514425\tBest loss: 5.514425\tAccuracy: 92.09%\n",
      "374\tValidation loss: 5.514301\tBest loss: 5.514301\tAccuracy: 92.09%\n",
      "375\tValidation loss: 5.514186\tBest loss: 5.514186\tAccuracy: 92.09%\n",
      "376\tValidation loss: 5.514056\tBest loss: 5.514056\tAccuracy: 92.09%\n",
      "377\tValidation loss: 5.513936\tBest loss: 5.513936\tAccuracy: 92.09%\n",
      "378\tValidation loss: 5.513819\tBest loss: 5.513819\tAccuracy: 92.09%\n",
      "379\tValidation loss: 5.513688\tBest loss: 5.513688\tAccuracy: 92.09%\n",
      "380\tValidation loss: 5.513573\tBest loss: 5.513573\tAccuracy: 92.09%\n",
      "381\tValidation loss: 5.513463\tBest loss: 5.513463\tAccuracy: 92.09%\n",
      "382\tValidation loss: 5.513336\tBest loss: 5.513336\tAccuracy: 92.09%\n",
      "383\tValidation loss: 5.513211\tBest loss: 5.513211\tAccuracy: 92.09%\n",
      "384\tValidation loss: 5.513094\tBest loss: 5.513094\tAccuracy: 92.09%\n",
      "385\tValidation loss: 5.512974\tBest loss: 5.512974\tAccuracy: 92.09%\n",
      "386\tValidation loss: 5.512861\tBest loss: 5.512861\tAccuracy: 92.09%\n",
      "387\tValidation loss: 5.512753\tBest loss: 5.512753\tAccuracy: 92.09%\n",
      "388\tValidation loss: 5.512634\tBest loss: 5.512634\tAccuracy: 92.09%\n",
      "389\tValidation loss: 5.512521\tBest loss: 5.512521\tAccuracy: 92.09%\n",
      "390\tValidation loss: 5.512394\tBest loss: 5.512394\tAccuracy: 92.09%\n",
      "391\tValidation loss: 5.512285\tBest loss: 5.512285\tAccuracy: 92.09%\n",
      "392\tValidation loss: 5.512169\tBest loss: 5.512169\tAccuracy: 92.09%\n",
      "393\tValidation loss: 5.512056\tBest loss: 5.512056\tAccuracy: 92.09%\n",
      "394\tValidation loss: 5.511939\tBest loss: 5.511939\tAccuracy: 92.09%\n",
      "395\tValidation loss: 5.511827\tBest loss: 5.511827\tAccuracy: 92.09%\n",
      "396\tValidation loss: 5.511708\tBest loss: 5.511708\tAccuracy: 92.09%\n",
      "397\tValidation loss: 5.511598\tBest loss: 5.511598\tAccuracy: 92.09%\n",
      "398\tValidation loss: 5.511479\tBest loss: 5.511479\tAccuracy: 92.09%\n",
      "399\tValidation loss: 5.511367\tBest loss: 5.511367\tAccuracy: 92.09%\n",
      "400\tValidation loss: 5.511251\tBest loss: 5.511251\tAccuracy: 92.09%\n",
      "401\tValidation loss: 5.511137\tBest loss: 5.511137\tAccuracy: 92.09%\n",
      "402\tValidation loss: 5.511025\tBest loss: 5.511025\tAccuracy: 92.09%\n",
      "403\tValidation loss: 5.510913\tBest loss: 5.510913\tAccuracy: 92.09%\n",
      "404\tValidation loss: 5.510806\tBest loss: 5.510806\tAccuracy: 92.09%\n",
      "405\tValidation loss: 5.510699\tBest loss: 5.510699\tAccuracy: 92.09%\n",
      "406\tValidation loss: 5.510584\tBest loss: 5.510584\tAccuracy: 92.09%\n",
      "407\tValidation loss: 5.510471\tBest loss: 5.510471\tAccuracy: 92.09%\n",
      "408\tValidation loss: 5.510359\tBest loss: 5.510359\tAccuracy: 92.09%\n",
      "409\tValidation loss: 5.510247\tBest loss: 5.510247\tAccuracy: 92.09%\n",
      "410\tValidation loss: 5.510141\tBest loss: 5.510141\tAccuracy: 92.09%\n",
      "411\tValidation loss: 5.510029\tBest loss: 5.510029\tAccuracy: 92.09%\n",
      "412\tValidation loss: 5.509919\tBest loss: 5.509919\tAccuracy: 92.09%\n",
      "413\tValidation loss: 5.509796\tBest loss: 5.509796\tAccuracy: 92.09%\n",
      "414\tValidation loss: 5.509689\tBest loss: 5.509689\tAccuracy: 92.09%\n",
      "415\tValidation loss: 5.509574\tBest loss: 5.509574\tAccuracy: 92.09%\n",
      "416\tValidation loss: 5.509479\tBest loss: 5.509479\tAccuracy: 92.09%\n",
      "417\tValidation loss: 5.509377\tBest loss: 5.509377\tAccuracy: 92.09%\n",
      "418\tValidation loss: 5.509278\tBest loss: 5.509278\tAccuracy: 92.09%\n",
      "419\tValidation loss: 5.509168\tBest loss: 5.509168\tAccuracy: 92.09%\n",
      "420\tValidation loss: 5.509058\tBest loss: 5.509058\tAccuracy: 92.09%\n",
      "421\tValidation loss: 5.508956\tBest loss: 5.508956\tAccuracy: 92.09%\n",
      "422\tValidation loss: 5.508848\tBest loss: 5.508848\tAccuracy: 92.09%\n",
      "423\tValidation loss: 5.508736\tBest loss: 5.508736\tAccuracy: 92.09%\n",
      "424\tValidation loss: 5.508630\tBest loss: 5.508630\tAccuracy: 92.09%\n",
      "425\tValidation loss: 5.508535\tBest loss: 5.508535\tAccuracy: 92.09%\n",
      "426\tValidation loss: 5.508426\tBest loss: 5.508426\tAccuracy: 92.09%\n",
      "427\tValidation loss: 5.508324\tBest loss: 5.508324\tAccuracy: 92.09%\n",
      "428\tValidation loss: 5.508217\tBest loss: 5.508217\tAccuracy: 92.09%\n",
      "429\tValidation loss: 5.508112\tBest loss: 5.508112\tAccuracy: 92.09%\n",
      "430\tValidation loss: 5.508014\tBest loss: 5.508014\tAccuracy: 92.09%\n",
      "431\tValidation loss: 5.507902\tBest loss: 5.507902\tAccuracy: 92.09%\n",
      "432\tValidation loss: 5.507801\tBest loss: 5.507801\tAccuracy: 92.09%\n",
      "433\tValidation loss: 5.507702\tBest loss: 5.507702\tAccuracy: 92.09%\n",
      "434\tValidation loss: 5.507593\tBest loss: 5.507593\tAccuracy: 92.09%\n",
      "435\tValidation loss: 5.507489\tBest loss: 5.507489\tAccuracy: 92.09%\n",
      "436\tValidation loss: 5.507385\tBest loss: 5.507385\tAccuracy: 92.09%\n",
      "437\tValidation loss: 5.507286\tBest loss: 5.507286\tAccuracy: 92.09%\n",
      "438\tValidation loss: 5.507188\tBest loss: 5.507188\tAccuracy: 92.09%\n",
      "439\tValidation loss: 5.507092\tBest loss: 5.507092\tAccuracy: 92.09%\n",
      "440\tValidation loss: 5.506988\tBest loss: 5.506988\tAccuracy: 92.09%\n",
      "441\tValidation loss: 5.506892\tBest loss: 5.506892\tAccuracy: 92.09%\n",
      "442\tValidation loss: 5.506785\tBest loss: 5.506785\tAccuracy: 92.09%\n",
      "443\tValidation loss: 5.506681\tBest loss: 5.506681\tAccuracy: 92.09%\n",
      "444\tValidation loss: 5.506585\tBest loss: 5.506585\tAccuracy: 92.09%\n",
      "445\tValidation loss: 5.506493\tBest loss: 5.506493\tAccuracy: 92.09%\n",
      "446\tValidation loss: 5.506395\tBest loss: 5.506395\tAccuracy: 92.09%\n",
      "447\tValidation loss: 5.506300\tBest loss: 5.506300\tAccuracy: 92.09%\n",
      "448\tValidation loss: 5.506196\tBest loss: 5.506196\tAccuracy: 92.09%\n",
      "449\tValidation loss: 5.506097\tBest loss: 5.506097\tAccuracy: 92.09%\n",
      "450\tValidation loss: 5.506001\tBest loss: 5.506001\tAccuracy: 92.09%\n",
      "451\tValidation loss: 5.505903\tBest loss: 5.505903\tAccuracy: 92.09%\n",
      "452\tValidation loss: 5.505807\tBest loss: 5.505807\tAccuracy: 92.09%\n",
      "453\tValidation loss: 5.505712\tBest loss: 5.505712\tAccuracy: 92.09%\n",
      "454\tValidation loss: 5.505625\tBest loss: 5.505625\tAccuracy: 92.09%\n",
      "455\tValidation loss: 5.505527\tBest loss: 5.505527\tAccuracy: 92.09%\n",
      "456\tValidation loss: 5.505426\tBest loss: 5.505426\tAccuracy: 92.09%\n",
      "457\tValidation loss: 5.505334\tBest loss: 5.505334\tAccuracy: 92.09%\n",
      "458\tValidation loss: 5.505245\tBest loss: 5.505245\tAccuracy: 92.09%\n",
      "459\tValidation loss: 5.505160\tBest loss: 5.505160\tAccuracy: 92.09%\n",
      "460\tValidation loss: 5.505070\tBest loss: 5.505070\tAccuracy: 92.09%\n",
      "461\tValidation loss: 5.504972\tBest loss: 5.504972\tAccuracy: 92.09%\n",
      "462\tValidation loss: 5.504875\tBest loss: 5.504875\tAccuracy: 92.09%\n",
      "463\tValidation loss: 5.504785\tBest loss: 5.504785\tAccuracy: 92.09%\n",
      "464\tValidation loss: 5.504698\tBest loss: 5.504698\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\tValidation loss: 5.504606\tBest loss: 5.504606\tAccuracy: 92.09%\n",
      "466\tValidation loss: 5.504505\tBest loss: 5.504505\tAccuracy: 92.09%\n",
      "467\tValidation loss: 5.504415\tBest loss: 5.504415\tAccuracy: 92.09%\n",
      "468\tValidation loss: 5.504317\tBest loss: 5.504317\tAccuracy: 92.09%\n",
      "469\tValidation loss: 5.504225\tBest loss: 5.504225\tAccuracy: 92.09%\n",
      "470\tValidation loss: 5.504126\tBest loss: 5.504126\tAccuracy: 92.09%\n",
      "471\tValidation loss: 5.504033\tBest loss: 5.504033\tAccuracy: 92.09%\n",
      "472\tValidation loss: 5.503937\tBest loss: 5.503937\tAccuracy: 92.09%\n",
      "473\tValidation loss: 5.503847\tBest loss: 5.503847\tAccuracy: 92.09%\n",
      "474\tValidation loss: 5.503760\tBest loss: 5.503760\tAccuracy: 92.09%\n",
      "475\tValidation loss: 5.503665\tBest loss: 5.503665\tAccuracy: 92.09%\n",
      "476\tValidation loss: 5.503563\tBest loss: 5.503563\tAccuracy: 92.09%\n",
      "477\tValidation loss: 5.503484\tBest loss: 5.503484\tAccuracy: 92.09%\n",
      "478\tValidation loss: 5.503397\tBest loss: 5.503397\tAccuracy: 92.09%\n",
      "479\tValidation loss: 5.503314\tBest loss: 5.503314\tAccuracy: 92.09%\n",
      "480\tValidation loss: 5.503226\tBest loss: 5.503226\tAccuracy: 92.09%\n",
      "481\tValidation loss: 5.503143\tBest loss: 5.503143\tAccuracy: 92.09%\n",
      "482\tValidation loss: 5.503050\tBest loss: 5.503050\tAccuracy: 92.09%\n",
      "483\tValidation loss: 5.502956\tBest loss: 5.502956\tAccuracy: 92.09%\n",
      "484\tValidation loss: 5.502866\tBest loss: 5.502866\tAccuracy: 92.09%\n",
      "485\tValidation loss: 5.502771\tBest loss: 5.502771\tAccuracy: 92.09%\n",
      "486\tValidation loss: 5.502682\tBest loss: 5.502682\tAccuracy: 92.09%\n",
      "487\tValidation loss: 5.502594\tBest loss: 5.502594\tAccuracy: 92.09%\n",
      "488\tValidation loss: 5.502494\tBest loss: 5.502494\tAccuracy: 92.09%\n",
      "489\tValidation loss: 5.502402\tBest loss: 5.502402\tAccuracy: 92.09%\n",
      "490\tValidation loss: 5.502308\tBest loss: 5.502308\tAccuracy: 92.09%\n",
      "491\tValidation loss: 5.502228\tBest loss: 5.502228\tAccuracy: 92.09%\n",
      "492\tValidation loss: 5.502142\tBest loss: 5.502142\tAccuracy: 92.09%\n",
      "493\tValidation loss: 5.502056\tBest loss: 5.502056\tAccuracy: 92.09%\n",
      "494\tValidation loss: 5.501972\tBest loss: 5.501972\tAccuracy: 92.09%\n",
      "495\tValidation loss: 5.501881\tBest loss: 5.501881\tAccuracy: 92.09%\n",
      "496\tValidation loss: 5.501800\tBest loss: 5.501800\tAccuracy: 92.09%\n",
      "497\tValidation loss: 5.501713\tBest loss: 5.501713\tAccuracy: 92.09%\n",
      "498\tValidation loss: 5.501629\tBest loss: 5.501629\tAccuracy: 92.09%\n",
      "499\tValidation loss: 5.501543\tBest loss: 5.501543\tAccuracy: 92.09%\n",
      "500\tValidation loss: 5.501458\tBest loss: 5.501458\tAccuracy: 92.09%\n",
      "501\tValidation loss: 5.501369\tBest loss: 5.501369\tAccuracy: 92.09%\n",
      "502\tValidation loss: 5.501280\tBest loss: 5.501280\tAccuracy: 92.09%\n",
      "503\tValidation loss: 5.501193\tBest loss: 5.501193\tAccuracy: 92.09%\n",
      "504\tValidation loss: 5.501102\tBest loss: 5.501102\tAccuracy: 92.09%\n",
      "505\tValidation loss: 5.501016\tBest loss: 5.501016\tAccuracy: 92.09%\n",
      "506\tValidation loss: 5.500931\tBest loss: 5.500931\tAccuracy: 92.09%\n",
      "507\tValidation loss: 5.500844\tBest loss: 5.500844\tAccuracy: 92.09%\n",
      "508\tValidation loss: 5.500766\tBest loss: 5.500766\tAccuracy: 92.09%\n",
      "509\tValidation loss: 5.500677\tBest loss: 5.500677\tAccuracy: 92.09%\n",
      "510\tValidation loss: 5.500580\tBest loss: 5.500580\tAccuracy: 92.09%\n",
      "511\tValidation loss: 5.500501\tBest loss: 5.500501\tAccuracy: 92.09%\n",
      "512\tValidation loss: 5.500423\tBest loss: 5.500423\tAccuracy: 92.09%\n",
      "513\tValidation loss: 5.500334\tBest loss: 5.500334\tAccuracy: 92.09%\n",
      "514\tValidation loss: 5.500251\tBest loss: 5.500251\tAccuracy: 92.09%\n",
      "515\tValidation loss: 5.500159\tBest loss: 5.500159\tAccuracy: 92.09%\n",
      "516\tValidation loss: 5.500077\tBest loss: 5.500077\tAccuracy: 92.09%\n",
      "517\tValidation loss: 5.500002\tBest loss: 5.500002\tAccuracy: 92.09%\n",
      "518\tValidation loss: 5.499928\tBest loss: 5.499928\tAccuracy: 92.09%\n",
      "519\tValidation loss: 5.499839\tBest loss: 5.499839\tAccuracy: 92.09%\n",
      "520\tValidation loss: 5.499764\tBest loss: 5.499764\tAccuracy: 92.09%\n",
      "521\tValidation loss: 5.499685\tBest loss: 5.499685\tAccuracy: 92.09%\n",
      "522\tValidation loss: 5.499613\tBest loss: 5.499613\tAccuracy: 92.09%\n",
      "523\tValidation loss: 5.499529\tBest loss: 5.499529\tAccuracy: 92.09%\n",
      "524\tValidation loss: 5.499450\tBest loss: 5.499450\tAccuracy: 92.09%\n",
      "525\tValidation loss: 5.499375\tBest loss: 5.499375\tAccuracy: 92.09%\n",
      "526\tValidation loss: 5.499302\tBest loss: 5.499302\tAccuracy: 92.09%\n",
      "527\tValidation loss: 5.499220\tBest loss: 5.499220\tAccuracy: 92.09%\n",
      "528\tValidation loss: 5.499140\tBest loss: 5.499140\tAccuracy: 92.09%\n",
      "529\tValidation loss: 5.499062\tBest loss: 5.499062\tAccuracy: 92.09%\n",
      "530\tValidation loss: 5.498985\tBest loss: 5.498985\tAccuracy: 92.09%\n",
      "531\tValidation loss: 5.498899\tBest loss: 5.498899\tAccuracy: 92.09%\n",
      "532\tValidation loss: 5.498811\tBest loss: 5.498811\tAccuracy: 92.09%\n",
      "533\tValidation loss: 5.498732\tBest loss: 5.498732\tAccuracy: 92.09%\n",
      "534\tValidation loss: 5.498655\tBest loss: 5.498655\tAccuracy: 92.09%\n",
      "535\tValidation loss: 5.498580\tBest loss: 5.498580\tAccuracy: 92.09%\n",
      "536\tValidation loss: 5.498507\tBest loss: 5.498507\tAccuracy: 92.09%\n",
      "537\tValidation loss: 5.498424\tBest loss: 5.498424\tAccuracy: 92.09%\n",
      "538\tValidation loss: 5.498345\tBest loss: 5.498345\tAccuracy: 92.09%\n",
      "539\tValidation loss: 5.498263\tBest loss: 5.498263\tAccuracy: 92.09%\n",
      "540\tValidation loss: 5.498181\tBest loss: 5.498181\tAccuracy: 92.09%\n",
      "541\tValidation loss: 5.498107\tBest loss: 5.498107\tAccuracy: 92.09%\n",
      "542\tValidation loss: 5.498023\tBest loss: 5.498023\tAccuracy: 92.09%\n",
      "543\tValidation loss: 5.497946\tBest loss: 5.497946\tAccuracy: 92.09%\n",
      "544\tValidation loss: 5.497868\tBest loss: 5.497868\tAccuracy: 92.09%\n",
      "545\tValidation loss: 5.497797\tBest loss: 5.497797\tAccuracy: 92.09%\n",
      "546\tValidation loss: 5.497720\tBest loss: 5.497720\tAccuracy: 92.09%\n",
      "547\tValidation loss: 5.497642\tBest loss: 5.497642\tAccuracy: 92.09%\n",
      "548\tValidation loss: 5.497561\tBest loss: 5.497561\tAccuracy: 92.09%\n",
      "549\tValidation loss: 5.497476\tBest loss: 5.497476\tAccuracy: 92.09%\n",
      "550\tValidation loss: 5.497400\tBest loss: 5.497400\tAccuracy: 92.09%\n",
      "551\tValidation loss: 5.497332\tBest loss: 5.497332\tAccuracy: 92.09%\n",
      "552\tValidation loss: 5.497263\tBest loss: 5.497263\tAccuracy: 92.09%\n",
      "553\tValidation loss: 5.497186\tBest loss: 5.497186\tAccuracy: 92.09%\n",
      "554\tValidation loss: 5.497103\tBest loss: 5.497103\tAccuracy: 92.09%\n",
      "555\tValidation loss: 5.497024\tBest loss: 5.497024\tAccuracy: 92.09%\n",
      "556\tValidation loss: 5.496942\tBest loss: 5.496942\tAccuracy: 92.09%\n",
      "557\tValidation loss: 5.496862\tBest loss: 5.496862\tAccuracy: 92.09%\n",
      "558\tValidation loss: 5.496791\tBest loss: 5.496791\tAccuracy: 92.09%\n",
      "559\tValidation loss: 5.496721\tBest loss: 5.496721\tAccuracy: 92.09%\n",
      "560\tValidation loss: 5.496642\tBest loss: 5.496642\tAccuracy: 92.09%\n",
      "561\tValidation loss: 5.496573\tBest loss: 5.496573\tAccuracy: 92.09%\n",
      "562\tValidation loss: 5.496499\tBest loss: 5.496499\tAccuracy: 92.09%\n",
      "563\tValidation loss: 5.496431\tBest loss: 5.496431\tAccuracy: 92.09%\n",
      "564\tValidation loss: 5.496356\tBest loss: 5.496356\tAccuracy: 92.09%\n",
      "565\tValidation loss: 5.496282\tBest loss: 5.496282\tAccuracy: 92.09%\n",
      "566\tValidation loss: 5.496209\tBest loss: 5.496209\tAccuracy: 92.09%\n",
      "567\tValidation loss: 5.496144\tBest loss: 5.496144\tAccuracy: 92.09%\n",
      "568\tValidation loss: 5.496062\tBest loss: 5.496062\tAccuracy: 92.09%\n",
      "569\tValidation loss: 5.495981\tBest loss: 5.495981\tAccuracy: 92.09%\n",
      "570\tValidation loss: 5.495904\tBest loss: 5.495904\tAccuracy: 92.09%\n",
      "571\tValidation loss: 5.495832\tBest loss: 5.495832\tAccuracy: 92.09%\n",
      "572\tValidation loss: 5.495761\tBest loss: 5.495761\tAccuracy: 92.09%\n",
      "573\tValidation loss: 5.495684\tBest loss: 5.495684\tAccuracy: 92.09%\n",
      "574\tValidation loss: 5.495605\tBest loss: 5.495605\tAccuracy: 92.09%\n",
      "575\tValidation loss: 5.495540\tBest loss: 5.495540\tAccuracy: 92.09%\n",
      "576\tValidation loss: 5.495462\tBest loss: 5.495462\tAccuracy: 92.09%\n",
      "577\tValidation loss: 5.495396\tBest loss: 5.495396\tAccuracy: 92.09%\n",
      "578\tValidation loss: 5.495320\tBest loss: 5.495320\tAccuracy: 92.09%\n",
      "579\tValidation loss: 5.495250\tBest loss: 5.495250\tAccuracy: 92.09%\n",
      "580\tValidation loss: 5.495181\tBest loss: 5.495181\tAccuracy: 92.09%\n",
      "581\tValidation loss: 5.495111\tBest loss: 5.495111\tAccuracy: 92.09%\n",
      "582\tValidation loss: 5.495033\tBest loss: 5.495033\tAccuracy: 92.09%\n",
      "583\tValidation loss: 5.494955\tBest loss: 5.494955\tAccuracy: 92.09%\n",
      "584\tValidation loss: 5.494885\tBest loss: 5.494885\tAccuracy: 92.09%\n",
      "585\tValidation loss: 5.494808\tBest loss: 5.494808\tAccuracy: 92.09%\n",
      "586\tValidation loss: 5.494734\tBest loss: 5.494734\tAccuracy: 92.09%\n",
      "587\tValidation loss: 5.494668\tBest loss: 5.494668\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\tValidation loss: 5.494598\tBest loss: 5.494598\tAccuracy: 92.09%\n",
      "589\tValidation loss: 5.494527\tBest loss: 5.494527\tAccuracy: 92.09%\n",
      "590\tValidation loss: 5.494454\tBest loss: 5.494454\tAccuracy: 92.09%\n",
      "591\tValidation loss: 5.494383\tBest loss: 5.494383\tAccuracy: 92.09%\n",
      "592\tValidation loss: 5.494317\tBest loss: 5.494317\tAccuracy: 92.09%\n",
      "593\tValidation loss: 5.494232\tBest loss: 5.494232\tAccuracy: 92.09%\n",
      "594\tValidation loss: 5.494165\tBest loss: 5.494165\tAccuracy: 92.09%\n",
      "595\tValidation loss: 5.494093\tBest loss: 5.494093\tAccuracy: 92.09%\n",
      "596\tValidation loss: 5.494025\tBest loss: 5.494025\tAccuracy: 92.09%\n",
      "597\tValidation loss: 5.493959\tBest loss: 5.493959\tAccuracy: 92.09%\n",
      "598\tValidation loss: 5.493893\tBest loss: 5.493893\tAccuracy: 92.09%\n",
      "599\tValidation loss: 5.493825\tBest loss: 5.493825\tAccuracy: 92.09%\n",
      "600\tValidation loss: 5.493760\tBest loss: 5.493760\tAccuracy: 92.09%\n",
      "601\tValidation loss: 5.493692\tBest loss: 5.493692\tAccuracy: 92.09%\n",
      "602\tValidation loss: 5.493611\tBest loss: 5.493611\tAccuracy: 92.09%\n",
      "603\tValidation loss: 5.493546\tBest loss: 5.493546\tAccuracy: 92.09%\n",
      "604\tValidation loss: 5.493479\tBest loss: 5.493479\tAccuracy: 92.09%\n",
      "605\tValidation loss: 5.493415\tBest loss: 5.493415\tAccuracy: 92.09%\n",
      "606\tValidation loss: 5.493347\tBest loss: 5.493347\tAccuracy: 92.09%\n",
      "607\tValidation loss: 5.493268\tBest loss: 5.493268\tAccuracy: 92.09%\n",
      "608\tValidation loss: 5.493202\tBest loss: 5.493202\tAccuracy: 92.09%\n",
      "609\tValidation loss: 5.493132\tBest loss: 5.493132\tAccuracy: 92.09%\n",
      "610\tValidation loss: 5.493078\tBest loss: 5.493078\tAccuracy: 92.09%\n",
      "611\tValidation loss: 5.493006\tBest loss: 5.493006\tAccuracy: 92.09%\n",
      "612\tValidation loss: 5.492938\tBest loss: 5.492938\tAccuracy: 92.09%\n",
      "613\tValidation loss: 5.492867\tBest loss: 5.492867\tAccuracy: 92.09%\n",
      "614\tValidation loss: 5.492801\tBest loss: 5.492801\tAccuracy: 92.09%\n",
      "615\tValidation loss: 5.492729\tBest loss: 5.492729\tAccuracy: 92.09%\n",
      "616\tValidation loss: 5.492666\tBest loss: 5.492666\tAccuracy: 92.09%\n",
      "617\tValidation loss: 5.492589\tBest loss: 5.492589\tAccuracy: 92.09%\n",
      "618\tValidation loss: 5.492526\tBest loss: 5.492526\tAccuracy: 92.09%\n",
      "619\tValidation loss: 5.492464\tBest loss: 5.492464\tAccuracy: 92.09%\n",
      "620\tValidation loss: 5.492398\tBest loss: 5.492398\tAccuracy: 92.09%\n",
      "621\tValidation loss: 5.492325\tBest loss: 5.492325\tAccuracy: 92.09%\n",
      "622\tValidation loss: 5.492254\tBest loss: 5.492254\tAccuracy: 92.09%\n",
      "623\tValidation loss: 5.492195\tBest loss: 5.492195\tAccuracy: 92.09%\n",
      "624\tValidation loss: 5.492132\tBest loss: 5.492132\tAccuracy: 92.09%\n",
      "625\tValidation loss: 5.492064\tBest loss: 5.492064\tAccuracy: 92.09%\n",
      "626\tValidation loss: 5.491993\tBest loss: 5.491993\tAccuracy: 92.09%\n",
      "627\tValidation loss: 5.491926\tBest loss: 5.491926\tAccuracy: 92.09%\n",
      "628\tValidation loss: 5.491857\tBest loss: 5.491857\tAccuracy: 92.09%\n",
      "629\tValidation loss: 5.491787\tBest loss: 5.491787\tAccuracy: 92.09%\n",
      "630\tValidation loss: 5.491724\tBest loss: 5.491724\tAccuracy: 92.09%\n",
      "631\tValidation loss: 5.491658\tBest loss: 5.491658\tAccuracy: 92.09%\n",
      "632\tValidation loss: 5.491593\tBest loss: 5.491593\tAccuracy: 92.09%\n",
      "633\tValidation loss: 5.491532\tBest loss: 5.491532\tAccuracy: 92.09%\n",
      "634\tValidation loss: 5.491463\tBest loss: 5.491463\tAccuracy: 92.09%\n",
      "635\tValidation loss: 5.491396\tBest loss: 5.491396\tAccuracy: 92.09%\n",
      "636\tValidation loss: 5.491333\tBest loss: 5.491333\tAccuracy: 92.09%\n",
      "637\tValidation loss: 5.491263\tBest loss: 5.491263\tAccuracy: 92.09%\n",
      "638\tValidation loss: 5.491193\tBest loss: 5.491193\tAccuracy: 92.09%\n",
      "639\tValidation loss: 5.491136\tBest loss: 5.491136\tAccuracy: 92.09%\n",
      "640\tValidation loss: 5.491073\tBest loss: 5.491073\tAccuracy: 92.09%\n",
      "641\tValidation loss: 5.491004\tBest loss: 5.491004\tAccuracy: 92.09%\n",
      "642\tValidation loss: 5.490942\tBest loss: 5.490942\tAccuracy: 92.09%\n",
      "643\tValidation loss: 5.490882\tBest loss: 5.490882\tAccuracy: 92.09%\n",
      "644\tValidation loss: 5.490819\tBest loss: 5.490819\tAccuracy: 92.09%\n",
      "645\tValidation loss: 5.490759\tBest loss: 5.490759\tAccuracy: 92.09%\n",
      "646\tValidation loss: 5.490693\tBest loss: 5.490693\tAccuracy: 92.09%\n",
      "647\tValidation loss: 5.490627\tBest loss: 5.490627\tAccuracy: 92.09%\n",
      "648\tValidation loss: 5.490570\tBest loss: 5.490570\tAccuracy: 92.09%\n",
      "649\tValidation loss: 5.490505\tBest loss: 5.490505\tAccuracy: 92.09%\n",
      "650\tValidation loss: 5.490438\tBest loss: 5.490438\tAccuracy: 92.09%\n",
      "651\tValidation loss: 5.490366\tBest loss: 5.490366\tAccuracy: 92.09%\n",
      "652\tValidation loss: 5.490301\tBest loss: 5.490301\tAccuracy: 92.09%\n",
      "653\tValidation loss: 5.490239\tBest loss: 5.490239\tAccuracy: 92.09%\n",
      "654\tValidation loss: 5.490178\tBest loss: 5.490178\tAccuracy: 92.09%\n",
      "655\tValidation loss: 5.490116\tBest loss: 5.490116\tAccuracy: 92.09%\n",
      "656\tValidation loss: 5.490054\tBest loss: 5.490054\tAccuracy: 92.09%\n",
      "657\tValidation loss: 5.489994\tBest loss: 5.489994\tAccuracy: 92.09%\n",
      "658\tValidation loss: 5.489922\tBest loss: 5.489922\tAccuracy: 92.09%\n",
      "659\tValidation loss: 5.489855\tBest loss: 5.489855\tAccuracy: 92.09%\n",
      "660\tValidation loss: 5.489797\tBest loss: 5.489797\tAccuracy: 92.09%\n",
      "661\tValidation loss: 5.489735\tBest loss: 5.489735\tAccuracy: 92.09%\n",
      "662\tValidation loss: 5.489669\tBest loss: 5.489669\tAccuracy: 92.09%\n",
      "663\tValidation loss: 5.489609\tBest loss: 5.489609\tAccuracy: 92.09%\n",
      "664\tValidation loss: 5.489546\tBest loss: 5.489546\tAccuracy: 92.09%\n",
      "665\tValidation loss: 5.489486\tBest loss: 5.489486\tAccuracy: 92.09%\n",
      "666\tValidation loss: 5.489429\tBest loss: 5.489429\tAccuracy: 92.09%\n",
      "667\tValidation loss: 5.489371\tBest loss: 5.489371\tAccuracy: 92.09%\n",
      "668\tValidation loss: 5.489306\tBest loss: 5.489306\tAccuracy: 92.09%\n",
      "669\tValidation loss: 5.489244\tBest loss: 5.489244\tAccuracy: 92.09%\n",
      "670\tValidation loss: 5.489178\tBest loss: 5.489178\tAccuracy: 92.09%\n",
      "671\tValidation loss: 5.489117\tBest loss: 5.489117\tAccuracy: 92.09%\n",
      "672\tValidation loss: 5.489053\tBest loss: 5.489053\tAccuracy: 92.09%\n",
      "673\tValidation loss: 5.488998\tBest loss: 5.488998\tAccuracy: 92.09%\n",
      "674\tValidation loss: 5.488936\tBest loss: 5.488936\tAccuracy: 92.09%\n",
      "675\tValidation loss: 5.488864\tBest loss: 5.488864\tAccuracy: 92.09%\n",
      "676\tValidation loss: 5.488805\tBest loss: 5.488805\tAccuracy: 92.09%\n",
      "677\tValidation loss: 5.488741\tBest loss: 5.488741\tAccuracy: 92.09%\n",
      "678\tValidation loss: 5.488680\tBest loss: 5.488680\tAccuracy: 92.09%\n",
      "679\tValidation loss: 5.488626\tBest loss: 5.488626\tAccuracy: 92.09%\n",
      "680\tValidation loss: 5.488563\tBest loss: 5.488563\tAccuracy: 92.09%\n",
      "681\tValidation loss: 5.488506\tBest loss: 5.488506\tAccuracy: 92.09%\n",
      "682\tValidation loss: 5.488451\tBest loss: 5.488451\tAccuracy: 92.09%\n",
      "683\tValidation loss: 5.488394\tBest loss: 5.488394\tAccuracy: 92.09%\n",
      "684\tValidation loss: 5.488340\tBest loss: 5.488340\tAccuracy: 92.09%\n",
      "685\tValidation loss: 5.488279\tBest loss: 5.488279\tAccuracy: 92.09%\n",
      "686\tValidation loss: 5.488221\tBest loss: 5.488221\tAccuracy: 92.09%\n",
      "687\tValidation loss: 5.488156\tBest loss: 5.488156\tAccuracy: 92.09%\n",
      "688\tValidation loss: 5.488100\tBest loss: 5.488100\tAccuracy: 92.09%\n",
      "689\tValidation loss: 5.488044\tBest loss: 5.488044\tAccuracy: 92.09%\n",
      "690\tValidation loss: 5.487988\tBest loss: 5.487988\tAccuracy: 92.09%\n",
      "691\tValidation loss: 5.487921\tBest loss: 5.487921\tAccuracy: 92.09%\n",
      "692\tValidation loss: 5.487860\tBest loss: 5.487860\tAccuracy: 92.09%\n",
      "693\tValidation loss: 5.487804\tBest loss: 5.487804\tAccuracy: 92.09%\n",
      "694\tValidation loss: 5.487746\tBest loss: 5.487746\tAccuracy: 92.09%\n",
      "695\tValidation loss: 5.487694\tBest loss: 5.487694\tAccuracy: 92.09%\n",
      "696\tValidation loss: 5.487639\tBest loss: 5.487639\tAccuracy: 92.09%\n",
      "697\tValidation loss: 5.487582\tBest loss: 5.487582\tAccuracy: 92.09%\n",
      "698\tValidation loss: 5.487524\tBest loss: 5.487524\tAccuracy: 92.09%\n",
      "699\tValidation loss: 5.487465\tBest loss: 5.487465\tAccuracy: 92.09%\n",
      "700\tValidation loss: 5.487408\tBest loss: 5.487408\tAccuracy: 92.09%\n",
      "701\tValidation loss: 5.487349\tBest loss: 5.487349\tAccuracy: 92.09%\n",
      "702\tValidation loss: 5.487292\tBest loss: 5.487292\tAccuracy: 92.09%\n",
      "703\tValidation loss: 5.487240\tBest loss: 5.487240\tAccuracy: 92.09%\n",
      "704\tValidation loss: 5.487185\tBest loss: 5.487185\tAccuracy: 92.09%\n",
      "705\tValidation loss: 5.487129\tBest loss: 5.487129\tAccuracy: 92.09%\n",
      "706\tValidation loss: 5.487079\tBest loss: 5.487079\tAccuracy: 92.09%\n",
      "707\tValidation loss: 5.487022\tBest loss: 5.487022\tAccuracy: 92.09%\n",
      "708\tValidation loss: 5.486955\tBest loss: 5.486955\tAccuracy: 92.09%\n",
      "709\tValidation loss: 5.486900\tBest loss: 5.486900\tAccuracy: 92.09%\n",
      "710\tValidation loss: 5.486846\tBest loss: 5.486846\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\tValidation loss: 5.486793\tBest loss: 5.486793\tAccuracy: 92.09%\n",
      "712\tValidation loss: 5.486736\tBest loss: 5.486736\tAccuracy: 92.09%\n",
      "713\tValidation loss: 5.486674\tBest loss: 5.486674\tAccuracy: 92.09%\n",
      "714\tValidation loss: 5.486619\tBest loss: 5.486619\tAccuracy: 92.09%\n",
      "715\tValidation loss: 5.486565\tBest loss: 5.486565\tAccuracy: 92.09%\n",
      "716\tValidation loss: 5.486508\tBest loss: 5.486508\tAccuracy: 92.09%\n",
      "717\tValidation loss: 5.486452\tBest loss: 5.486452\tAccuracy: 92.09%\n",
      "718\tValidation loss: 5.486392\tBest loss: 5.486392\tAccuracy: 92.09%\n",
      "719\tValidation loss: 5.486338\tBest loss: 5.486338\tAccuracy: 92.09%\n",
      "720\tValidation loss: 5.486287\tBest loss: 5.486287\tAccuracy: 92.09%\n",
      "721\tValidation loss: 5.486236\tBest loss: 5.486236\tAccuracy: 92.09%\n",
      "722\tValidation loss: 5.486181\tBest loss: 5.486181\tAccuracy: 92.09%\n",
      "723\tValidation loss: 5.486123\tBest loss: 5.486123\tAccuracy: 92.09%\n",
      "724\tValidation loss: 5.486072\tBest loss: 5.486072\tAccuracy: 92.09%\n",
      "725\tValidation loss: 5.486020\tBest loss: 5.486020\tAccuracy: 92.09%\n",
      "726\tValidation loss: 5.485961\tBest loss: 5.485961\tAccuracy: 92.09%\n",
      "727\tValidation loss: 5.485903\tBest loss: 5.485903\tAccuracy: 92.09%\n",
      "728\tValidation loss: 5.485851\tBest loss: 5.485851\tAccuracy: 92.09%\n",
      "729\tValidation loss: 5.485799\tBest loss: 5.485799\tAccuracy: 92.09%\n",
      "730\tValidation loss: 5.485743\tBest loss: 5.485743\tAccuracy: 92.09%\n",
      "731\tValidation loss: 5.485682\tBest loss: 5.485682\tAccuracy: 92.09%\n",
      "732\tValidation loss: 5.485623\tBest loss: 5.485623\tAccuracy: 92.09%\n",
      "733\tValidation loss: 5.485567\tBest loss: 5.485567\tAccuracy: 92.09%\n",
      "734\tValidation loss: 5.485516\tBest loss: 5.485516\tAccuracy: 92.09%\n",
      "735\tValidation loss: 5.485464\tBest loss: 5.485464\tAccuracy: 92.09%\n",
      "736\tValidation loss: 5.485409\tBest loss: 5.485409\tAccuracy: 92.09%\n",
      "737\tValidation loss: 5.485354\tBest loss: 5.485354\tAccuracy: 92.09%\n",
      "738\tValidation loss: 5.485298\tBest loss: 5.485298\tAccuracy: 92.09%\n",
      "739\tValidation loss: 5.485240\tBest loss: 5.485240\tAccuracy: 92.09%\n",
      "740\tValidation loss: 5.485181\tBest loss: 5.485181\tAccuracy: 92.09%\n",
      "741\tValidation loss: 5.485122\tBest loss: 5.485122\tAccuracy: 92.09%\n",
      "742\tValidation loss: 5.485076\tBest loss: 5.485076\tAccuracy: 92.09%\n",
      "743\tValidation loss: 5.485024\tBest loss: 5.485024\tAccuracy: 92.09%\n",
      "744\tValidation loss: 5.484970\tBest loss: 5.484970\tAccuracy: 92.09%\n",
      "745\tValidation loss: 5.484915\tBest loss: 5.484915\tAccuracy: 92.09%\n",
      "746\tValidation loss: 5.484865\tBest loss: 5.484865\tAccuracy: 92.09%\n",
      "747\tValidation loss: 5.484818\tBest loss: 5.484818\tAccuracy: 92.09%\n",
      "748\tValidation loss: 5.484765\tBest loss: 5.484765\tAccuracy: 92.09%\n",
      "749\tValidation loss: 5.484711\tBest loss: 5.484711\tAccuracy: 92.09%\n",
      "750\tValidation loss: 5.484658\tBest loss: 5.484658\tAccuracy: 92.09%\n",
      "751\tValidation loss: 5.484607\tBest loss: 5.484607\tAccuracy: 92.09%\n",
      "752\tValidation loss: 5.484558\tBest loss: 5.484558\tAccuracy: 92.09%\n",
      "753\tValidation loss: 5.484503\tBest loss: 5.484503\tAccuracy: 92.09%\n",
      "754\tValidation loss: 5.484446\tBest loss: 5.484446\tAccuracy: 92.09%\n",
      "755\tValidation loss: 5.484392\tBest loss: 5.484392\tAccuracy: 92.09%\n",
      "756\tValidation loss: 5.484339\tBest loss: 5.484339\tAccuracy: 92.09%\n",
      "757\tValidation loss: 5.484285\tBest loss: 5.484285\tAccuracy: 92.09%\n",
      "758\tValidation loss: 5.484225\tBest loss: 5.484225\tAccuracy: 92.09%\n",
      "759\tValidation loss: 5.484169\tBest loss: 5.484169\tAccuracy: 92.09%\n",
      "760\tValidation loss: 5.484119\tBest loss: 5.484119\tAccuracy: 92.09%\n",
      "761\tValidation loss: 5.484075\tBest loss: 5.484075\tAccuracy: 92.09%\n",
      "762\tValidation loss: 5.484021\tBest loss: 5.484021\tAccuracy: 92.09%\n",
      "763\tValidation loss: 5.483972\tBest loss: 5.483972\tAccuracy: 92.09%\n",
      "764\tValidation loss: 5.483925\tBest loss: 5.483925\tAccuracy: 92.09%\n",
      "765\tValidation loss: 5.483873\tBest loss: 5.483873\tAccuracy: 92.09%\n",
      "766\tValidation loss: 5.483824\tBest loss: 5.483824\tAccuracy: 92.09%\n",
      "767\tValidation loss: 5.483777\tBest loss: 5.483777\tAccuracy: 92.09%\n",
      "768\tValidation loss: 5.483725\tBest loss: 5.483725\tAccuracy: 92.09%\n",
      "769\tValidation loss: 5.483677\tBest loss: 5.483677\tAccuracy: 92.09%\n",
      "770\tValidation loss: 5.483632\tBest loss: 5.483632\tAccuracy: 92.09%\n",
      "771\tValidation loss: 5.483575\tBest loss: 5.483575\tAccuracy: 92.09%\n",
      "772\tValidation loss: 5.483521\tBest loss: 5.483521\tAccuracy: 92.09%\n",
      "773\tValidation loss: 5.483467\tBest loss: 5.483467\tAccuracy: 92.09%\n",
      "774\tValidation loss: 5.483416\tBest loss: 5.483416\tAccuracy: 92.09%\n",
      "775\tValidation loss: 5.483379\tBest loss: 5.483379\tAccuracy: 92.09%\n",
      "776\tValidation loss: 5.483327\tBest loss: 5.483327\tAccuracy: 92.09%\n",
      "777\tValidation loss: 5.483279\tBest loss: 5.483279\tAccuracy: 92.09%\n",
      "778\tValidation loss: 5.483223\tBest loss: 5.483223\tAccuracy: 92.09%\n",
      "779\tValidation loss: 5.483177\tBest loss: 5.483177\tAccuracy: 92.09%\n",
      "780\tValidation loss: 5.483130\tBest loss: 5.483130\tAccuracy: 92.09%\n",
      "781\tValidation loss: 5.483069\tBest loss: 5.483069\tAccuracy: 92.09%\n",
      "782\tValidation loss: 5.483019\tBest loss: 5.483019\tAccuracy: 92.09%\n",
      "783\tValidation loss: 5.482969\tBest loss: 5.482969\tAccuracy: 92.09%\n",
      "784\tValidation loss: 5.482913\tBest loss: 5.482913\tAccuracy: 92.09%\n",
      "785\tValidation loss: 5.482862\tBest loss: 5.482862\tAccuracy: 92.09%\n",
      "786\tValidation loss: 5.482808\tBest loss: 5.482808\tAccuracy: 92.09%\n",
      "787\tValidation loss: 5.482765\tBest loss: 5.482765\tAccuracy: 92.09%\n",
      "788\tValidation loss: 5.482711\tBest loss: 5.482711\tAccuracy: 92.09%\n",
      "789\tValidation loss: 5.482668\tBest loss: 5.482668\tAccuracy: 92.09%\n",
      "790\tValidation loss: 5.482619\tBest loss: 5.482619\tAccuracy: 92.09%\n",
      "791\tValidation loss: 5.482568\tBest loss: 5.482568\tAccuracy: 92.09%\n",
      "792\tValidation loss: 5.482522\tBest loss: 5.482522\tAccuracy: 92.09%\n",
      "793\tValidation loss: 5.482478\tBest loss: 5.482478\tAccuracy: 92.09%\n",
      "794\tValidation loss: 5.482434\tBest loss: 5.482434\tAccuracy: 92.09%\n",
      "795\tValidation loss: 5.482385\tBest loss: 5.482385\tAccuracy: 92.09%\n",
      "796\tValidation loss: 5.482331\tBest loss: 5.482331\tAccuracy: 92.09%\n",
      "797\tValidation loss: 5.482282\tBest loss: 5.482282\tAccuracy: 92.09%\n",
      "798\tValidation loss: 5.482233\tBest loss: 5.482233\tAccuracy: 92.09%\n",
      "799\tValidation loss: 5.482176\tBest loss: 5.482176\tAccuracy: 92.09%\n",
      "800\tValidation loss: 5.482129\tBest loss: 5.482129\tAccuracy: 92.09%\n",
      "801\tValidation loss: 5.482077\tBest loss: 5.482077\tAccuracy: 92.09%\n",
      "802\tValidation loss: 5.482030\tBest loss: 5.482030\tAccuracy: 92.09%\n",
      "803\tValidation loss: 5.481982\tBest loss: 5.481982\tAccuracy: 92.09%\n",
      "804\tValidation loss: 5.481925\tBest loss: 5.481925\tAccuracy: 92.09%\n",
      "805\tValidation loss: 5.481876\tBest loss: 5.481876\tAccuracy: 92.09%\n",
      "806\tValidation loss: 5.481831\tBest loss: 5.481831\tAccuracy: 92.09%\n",
      "807\tValidation loss: 5.481783\tBest loss: 5.481783\tAccuracy: 92.09%\n",
      "808\tValidation loss: 5.481735\tBest loss: 5.481735\tAccuracy: 92.09%\n",
      "809\tValidation loss: 5.481684\tBest loss: 5.481684\tAccuracy: 92.09%\n",
      "810\tValidation loss: 5.481640\tBest loss: 5.481640\tAccuracy: 92.09%\n",
      "811\tValidation loss: 5.481589\tBest loss: 5.481589\tAccuracy: 92.09%\n",
      "812\tValidation loss: 5.481538\tBest loss: 5.481538\tAccuracy: 92.09%\n",
      "813\tValidation loss: 5.481496\tBest loss: 5.481496\tAccuracy: 92.09%\n",
      "814\tValidation loss: 5.481451\tBest loss: 5.481451\tAccuracy: 92.09%\n",
      "815\tValidation loss: 5.481399\tBest loss: 5.481399\tAccuracy: 92.09%\n",
      "816\tValidation loss: 5.481348\tBest loss: 5.481348\tAccuracy: 92.09%\n",
      "817\tValidation loss: 5.481306\tBest loss: 5.481306\tAccuracy: 92.09%\n",
      "818\tValidation loss: 5.481254\tBest loss: 5.481254\tAccuracy: 92.09%\n",
      "819\tValidation loss: 5.481205\tBest loss: 5.481205\tAccuracy: 92.09%\n",
      "820\tValidation loss: 5.481150\tBest loss: 5.481150\tAccuracy: 92.09%\n",
      "821\tValidation loss: 5.481097\tBest loss: 5.481097\tAccuracy: 92.09%\n",
      "822\tValidation loss: 5.481051\tBest loss: 5.481051\tAccuracy: 92.09%\n",
      "823\tValidation loss: 5.481006\tBest loss: 5.481006\tAccuracy: 92.09%\n",
      "824\tValidation loss: 5.480961\tBest loss: 5.480961\tAccuracy: 92.09%\n",
      "825\tValidation loss: 5.480913\tBest loss: 5.480913\tAccuracy: 92.09%\n",
      "826\tValidation loss: 5.480865\tBest loss: 5.480865\tAccuracy: 92.09%\n",
      "827\tValidation loss: 5.480819\tBest loss: 5.480819\tAccuracy: 92.09%\n",
      "828\tValidation loss: 5.480776\tBest loss: 5.480776\tAccuracy: 92.09%\n",
      "829\tValidation loss: 5.480719\tBest loss: 5.480719\tAccuracy: 92.09%\n",
      "830\tValidation loss: 5.480664\tBest loss: 5.480664\tAccuracy: 92.09%\n",
      "831\tValidation loss: 5.480609\tBest loss: 5.480609\tAccuracy: 92.09%\n",
      "832\tValidation loss: 5.480574\tBest loss: 5.480574\tAccuracy: 92.09%\n",
      "833\tValidation loss: 5.480531\tBest loss: 5.480531\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834\tValidation loss: 5.480478\tBest loss: 5.480478\tAccuracy: 92.09%\n",
      "835\tValidation loss: 5.480435\tBest loss: 5.480435\tAccuracy: 92.09%\n",
      "836\tValidation loss: 5.480389\tBest loss: 5.480389\tAccuracy: 92.09%\n",
      "837\tValidation loss: 5.480348\tBest loss: 5.480348\tAccuracy: 92.09%\n",
      "838\tValidation loss: 5.480299\tBest loss: 5.480299\tAccuracy: 92.09%\n",
      "839\tValidation loss: 5.480256\tBest loss: 5.480256\tAccuracy: 92.09%\n",
      "840\tValidation loss: 5.480209\tBest loss: 5.480209\tAccuracy: 92.09%\n",
      "841\tValidation loss: 5.480168\tBest loss: 5.480168\tAccuracy: 92.09%\n",
      "842\tValidation loss: 5.480122\tBest loss: 5.480122\tAccuracy: 92.09%\n",
      "843\tValidation loss: 5.480082\tBest loss: 5.480082\tAccuracy: 92.09%\n",
      "844\tValidation loss: 5.480033\tBest loss: 5.480033\tAccuracy: 92.09%\n",
      "845\tValidation loss: 5.479987\tBest loss: 5.479987\tAccuracy: 92.09%\n",
      "846\tValidation loss: 5.479934\tBest loss: 5.479934\tAccuracy: 92.09%\n",
      "847\tValidation loss: 5.479890\tBest loss: 5.479890\tAccuracy: 92.09%\n",
      "848\tValidation loss: 5.479843\tBest loss: 5.479843\tAccuracy: 92.09%\n",
      "849\tValidation loss: 5.479803\tBest loss: 5.479803\tAccuracy: 92.09%\n",
      "850\tValidation loss: 5.479760\tBest loss: 5.479760\tAccuracy: 92.09%\n",
      "851\tValidation loss: 5.479712\tBest loss: 5.479712\tAccuracy: 92.09%\n",
      "852\tValidation loss: 5.479669\tBest loss: 5.479669\tAccuracy: 92.09%\n",
      "853\tValidation loss: 5.479628\tBest loss: 5.479628\tAccuracy: 92.09%\n",
      "854\tValidation loss: 5.479579\tBest loss: 5.479579\tAccuracy: 92.09%\n",
      "855\tValidation loss: 5.479533\tBest loss: 5.479533\tAccuracy: 92.09%\n",
      "856\tValidation loss: 5.479490\tBest loss: 5.479490\tAccuracy: 92.09%\n",
      "857\tValidation loss: 5.479445\tBest loss: 5.479445\tAccuracy: 92.09%\n",
      "858\tValidation loss: 5.479400\tBest loss: 5.479400\tAccuracy: 92.09%\n",
      "859\tValidation loss: 5.479358\tBest loss: 5.479358\tAccuracy: 92.09%\n",
      "860\tValidation loss: 5.479319\tBest loss: 5.479319\tAccuracy: 92.09%\n",
      "861\tValidation loss: 5.479271\tBest loss: 5.479271\tAccuracy: 92.09%\n",
      "862\tValidation loss: 5.479220\tBest loss: 5.479220\tAccuracy: 92.09%\n",
      "863\tValidation loss: 5.479180\tBest loss: 5.479180\tAccuracy: 92.09%\n",
      "864\tValidation loss: 5.479137\tBest loss: 5.479137\tAccuracy: 92.09%\n",
      "865\tValidation loss: 5.479093\tBest loss: 5.479093\tAccuracy: 92.09%\n",
      "866\tValidation loss: 5.479052\tBest loss: 5.479052\tAccuracy: 92.09%\n",
      "867\tValidation loss: 5.479009\tBest loss: 5.479009\tAccuracy: 92.09%\n",
      "868\tValidation loss: 5.478961\tBest loss: 5.478961\tAccuracy: 92.09%\n",
      "869\tValidation loss: 5.478915\tBest loss: 5.478915\tAccuracy: 92.09%\n",
      "870\tValidation loss: 5.478871\tBest loss: 5.478871\tAccuracy: 92.09%\n",
      "871\tValidation loss: 5.478828\tBest loss: 5.478828\tAccuracy: 92.09%\n",
      "872\tValidation loss: 5.478787\tBest loss: 5.478787\tAccuracy: 92.09%\n",
      "873\tValidation loss: 5.478742\tBest loss: 5.478742\tAccuracy: 92.09%\n",
      "874\tValidation loss: 5.478702\tBest loss: 5.478702\tAccuracy: 92.09%\n",
      "875\tValidation loss: 5.478656\tBest loss: 5.478656\tAccuracy: 92.09%\n",
      "876\tValidation loss: 5.478609\tBest loss: 5.478609\tAccuracy: 92.09%\n",
      "877\tValidation loss: 5.478562\tBest loss: 5.478562\tAccuracy: 92.09%\n",
      "878\tValidation loss: 5.478526\tBest loss: 5.478526\tAccuracy: 92.09%\n",
      "879\tValidation loss: 5.478477\tBest loss: 5.478477\tAccuracy: 92.09%\n",
      "880\tValidation loss: 5.478437\tBest loss: 5.478437\tAccuracy: 92.09%\n",
      "881\tValidation loss: 5.478390\tBest loss: 5.478390\tAccuracy: 92.09%\n",
      "882\tValidation loss: 5.478344\tBest loss: 5.478344\tAccuracy: 92.09%\n",
      "883\tValidation loss: 5.478296\tBest loss: 5.478296\tAccuracy: 92.09%\n",
      "884\tValidation loss: 5.478250\tBest loss: 5.478250\tAccuracy: 92.09%\n",
      "885\tValidation loss: 5.478209\tBest loss: 5.478209\tAccuracy: 92.09%\n",
      "886\tValidation loss: 5.478163\tBest loss: 5.478163\tAccuracy: 92.09%\n",
      "887\tValidation loss: 5.478116\tBest loss: 5.478116\tAccuracy: 92.09%\n",
      "888\tValidation loss: 5.478070\tBest loss: 5.478070\tAccuracy: 92.09%\n",
      "889\tValidation loss: 5.478024\tBest loss: 5.478024\tAccuracy: 92.09%\n",
      "890\tValidation loss: 5.477986\tBest loss: 5.477986\tAccuracy: 92.09%\n",
      "891\tValidation loss: 5.477951\tBest loss: 5.477951\tAccuracy: 92.09%\n",
      "892\tValidation loss: 5.477907\tBest loss: 5.477907\tAccuracy: 92.09%\n",
      "893\tValidation loss: 5.477868\tBest loss: 5.477868\tAccuracy: 92.09%\n",
      "894\tValidation loss: 5.477829\tBest loss: 5.477829\tAccuracy: 92.09%\n",
      "895\tValidation loss: 5.477784\tBest loss: 5.477784\tAccuracy: 92.09%\n",
      "896\tValidation loss: 5.477734\tBest loss: 5.477734\tAccuracy: 92.09%\n",
      "897\tValidation loss: 5.477691\tBest loss: 5.477691\tAccuracy: 92.09%\n",
      "898\tValidation loss: 5.477647\tBest loss: 5.477647\tAccuracy: 92.09%\n",
      "899\tValidation loss: 5.477605\tBest loss: 5.477605\tAccuracy: 92.09%\n",
      "900\tValidation loss: 5.477566\tBest loss: 5.477566\tAccuracy: 92.09%\n",
      "901\tValidation loss: 5.477530\tBest loss: 5.477530\tAccuracy: 92.09%\n",
      "902\tValidation loss: 5.477486\tBest loss: 5.477486\tAccuracy: 92.09%\n",
      "903\tValidation loss: 5.477449\tBest loss: 5.477449\tAccuracy: 92.09%\n",
      "904\tValidation loss: 5.477408\tBest loss: 5.477408\tAccuracy: 92.09%\n",
      "905\tValidation loss: 5.477361\tBest loss: 5.477361\tAccuracy: 92.09%\n",
      "906\tValidation loss: 5.477318\tBest loss: 5.477318\tAccuracy: 92.09%\n",
      "907\tValidation loss: 5.477271\tBest loss: 5.477271\tAccuracy: 92.09%\n",
      "908\tValidation loss: 5.477230\tBest loss: 5.477230\tAccuracy: 92.09%\n",
      "909\tValidation loss: 5.477189\tBest loss: 5.477189\tAccuracy: 92.09%\n",
      "910\tValidation loss: 5.477148\tBest loss: 5.477148\tAccuracy: 92.09%\n",
      "911\tValidation loss: 5.477106\tBest loss: 5.477106\tAccuracy: 92.09%\n",
      "912\tValidation loss: 5.477064\tBest loss: 5.477064\tAccuracy: 92.09%\n",
      "913\tValidation loss: 5.477020\tBest loss: 5.477020\tAccuracy: 92.09%\n",
      "914\tValidation loss: 5.476980\tBest loss: 5.476980\tAccuracy: 92.09%\n",
      "915\tValidation loss: 5.476943\tBest loss: 5.476943\tAccuracy: 92.09%\n",
      "916\tValidation loss: 5.476896\tBest loss: 5.476896\tAccuracy: 92.09%\n",
      "917\tValidation loss: 5.476849\tBest loss: 5.476849\tAccuracy: 92.09%\n",
      "918\tValidation loss: 5.476805\tBest loss: 5.476805\tAccuracy: 92.09%\n",
      "919\tValidation loss: 5.476765\tBest loss: 5.476765\tAccuracy: 92.09%\n",
      "920\tValidation loss: 5.476726\tBest loss: 5.476726\tAccuracy: 92.09%\n",
      "921\tValidation loss: 5.476686\tBest loss: 5.476686\tAccuracy: 92.09%\n",
      "922\tValidation loss: 5.476651\tBest loss: 5.476651\tAccuracy: 92.09%\n",
      "923\tValidation loss: 5.476613\tBest loss: 5.476613\tAccuracy: 92.09%\n",
      "924\tValidation loss: 5.476569\tBest loss: 5.476569\tAccuracy: 92.09%\n",
      "925\tValidation loss: 5.476524\tBest loss: 5.476524\tAccuracy: 92.09%\n",
      "926\tValidation loss: 5.476480\tBest loss: 5.476480\tAccuracy: 92.09%\n",
      "927\tValidation loss: 5.476446\tBest loss: 5.476446\tAccuracy: 92.09%\n",
      "928\tValidation loss: 5.476398\tBest loss: 5.476398\tAccuracy: 92.09%\n",
      "929\tValidation loss: 5.476361\tBest loss: 5.476361\tAccuracy: 92.09%\n",
      "930\tValidation loss: 5.476323\tBest loss: 5.476323\tAccuracy: 92.09%\n",
      "931\tValidation loss: 5.476282\tBest loss: 5.476282\tAccuracy: 92.09%\n",
      "932\tValidation loss: 5.476247\tBest loss: 5.476247\tAccuracy: 92.09%\n",
      "933\tValidation loss: 5.476205\tBest loss: 5.476205\tAccuracy: 92.09%\n",
      "934\tValidation loss: 5.476170\tBest loss: 5.476170\tAccuracy: 92.09%\n",
      "935\tValidation loss: 5.476124\tBest loss: 5.476124\tAccuracy: 92.09%\n",
      "936\tValidation loss: 5.476081\tBest loss: 5.476081\tAccuracy: 92.09%\n",
      "937\tValidation loss: 5.476040\tBest loss: 5.476040\tAccuracy: 92.09%\n",
      "938\tValidation loss: 5.475998\tBest loss: 5.475998\tAccuracy: 92.09%\n",
      "939\tValidation loss: 5.475964\tBest loss: 5.475964\tAccuracy: 92.09%\n",
      "940\tValidation loss: 5.475926\tBest loss: 5.475926\tAccuracy: 92.09%\n",
      "941\tValidation loss: 5.475876\tBest loss: 5.475876\tAccuracy: 92.09%\n",
      "942\tValidation loss: 5.475840\tBest loss: 5.475840\tAccuracy: 92.09%\n",
      "943\tValidation loss: 5.475798\tBest loss: 5.475798\tAccuracy: 92.09%\n",
      "944\tValidation loss: 5.475754\tBest loss: 5.475754\tAccuracy: 92.09%\n",
      "945\tValidation loss: 5.475709\tBest loss: 5.475709\tAccuracy: 92.09%\n",
      "946\tValidation loss: 5.475662\tBest loss: 5.475662\tAccuracy: 92.09%\n",
      "947\tValidation loss: 5.475628\tBest loss: 5.475628\tAccuracy: 92.09%\n",
      "948\tValidation loss: 5.475592\tBest loss: 5.475592\tAccuracy: 92.09%\n",
      "949\tValidation loss: 5.475554\tBest loss: 5.475554\tAccuracy: 92.09%\n",
      "950\tValidation loss: 5.475518\tBest loss: 5.475518\tAccuracy: 92.09%\n",
      "951\tValidation loss: 5.475475\tBest loss: 5.475475\tAccuracy: 92.09%\n",
      "952\tValidation loss: 5.475442\tBest loss: 5.475442\tAccuracy: 92.09%\n",
      "953\tValidation loss: 5.475399\tBest loss: 5.475399\tAccuracy: 92.09%\n",
      "954\tValidation loss: 5.475358\tBest loss: 5.475358\tAccuracy: 92.09%\n",
      "955\tValidation loss: 5.475325\tBest loss: 5.475325\tAccuracy: 92.09%\n",
      "956\tValidation loss: 5.475285\tBest loss: 5.475285\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\tValidation loss: 5.475242\tBest loss: 5.475242\tAccuracy: 92.09%\n",
      "958\tValidation loss: 5.475198\tBest loss: 5.475198\tAccuracy: 92.09%\n",
      "959\tValidation loss: 5.475165\tBest loss: 5.475165\tAccuracy: 92.09%\n",
      "960\tValidation loss: 5.475130\tBest loss: 5.475130\tAccuracy: 92.09%\n",
      "961\tValidation loss: 5.475087\tBest loss: 5.475087\tAccuracy: 92.09%\n",
      "962\tValidation loss: 5.475044\tBest loss: 5.475044\tAccuracy: 92.09%\n",
      "963\tValidation loss: 5.475006\tBest loss: 5.475006\tAccuracy: 92.09%\n",
      "964\tValidation loss: 5.474967\tBest loss: 5.474967\tAccuracy: 92.09%\n",
      "965\tValidation loss: 5.474933\tBest loss: 5.474933\tAccuracy: 92.09%\n",
      "966\tValidation loss: 5.474898\tBest loss: 5.474898\tAccuracy: 92.09%\n",
      "967\tValidation loss: 5.474859\tBest loss: 5.474859\tAccuracy: 92.09%\n",
      "968\tValidation loss: 5.474815\tBest loss: 5.474815\tAccuracy: 92.09%\n",
      "969\tValidation loss: 5.474774\tBest loss: 5.474774\tAccuracy: 92.09%\n",
      "970\tValidation loss: 5.474740\tBest loss: 5.474740\tAccuracy: 92.09%\n",
      "971\tValidation loss: 5.474701\tBest loss: 5.474701\tAccuracy: 92.09%\n",
      "972\tValidation loss: 5.474665\tBest loss: 5.474665\tAccuracy: 92.09%\n",
      "973\tValidation loss: 5.474626\tBest loss: 5.474626\tAccuracy: 92.09%\n",
      "974\tValidation loss: 5.474586\tBest loss: 5.474586\tAccuracy: 92.09%\n",
      "975\tValidation loss: 5.474553\tBest loss: 5.474553\tAccuracy: 92.09%\n",
      "976\tValidation loss: 5.474512\tBest loss: 5.474512\tAccuracy: 92.09%\n",
      "977\tValidation loss: 5.474471\tBest loss: 5.474471\tAccuracy: 92.09%\n",
      "978\tValidation loss: 5.474433\tBest loss: 5.474433\tAccuracy: 92.09%\n",
      "979\tValidation loss: 5.474395\tBest loss: 5.474395\tAccuracy: 92.09%\n",
      "980\tValidation loss: 5.474364\tBest loss: 5.474364\tAccuracy: 92.09%\n",
      "981\tValidation loss: 5.474323\tBest loss: 5.474323\tAccuracy: 92.09%\n",
      "982\tValidation loss: 5.474285\tBest loss: 5.474285\tAccuracy: 92.09%\n",
      "983\tValidation loss: 5.474247\tBest loss: 5.474247\tAccuracy: 92.09%\n",
      "984\tValidation loss: 5.474209\tBest loss: 5.474209\tAccuracy: 92.09%\n",
      "985\tValidation loss: 5.474175\tBest loss: 5.474175\tAccuracy: 92.09%\n",
      "986\tValidation loss: 5.474141\tBest loss: 5.474141\tAccuracy: 92.09%\n",
      "987\tValidation loss: 5.474103\tBest loss: 5.474103\tAccuracy: 92.09%\n",
      "988\tValidation loss: 5.474065\tBest loss: 5.474065\tAccuracy: 92.09%\n",
      "989\tValidation loss: 5.474026\tBest loss: 5.474026\tAccuracy: 92.09%\n",
      "990\tValidation loss: 5.473988\tBest loss: 5.473988\tAccuracy: 92.09%\n",
      "991\tValidation loss: 5.473950\tBest loss: 5.473950\tAccuracy: 92.09%\n",
      "992\tValidation loss: 5.473914\tBest loss: 5.473914\tAccuracy: 92.09%\n",
      "993\tValidation loss: 5.473882\tBest loss: 5.473882\tAccuracy: 92.09%\n",
      "994\tValidation loss: 5.473846\tBest loss: 5.473846\tAccuracy: 92.09%\n",
      "995\tValidation loss: 5.473809\tBest loss: 5.473809\tAccuracy: 92.09%\n",
      "996\tValidation loss: 5.473775\tBest loss: 5.473775\tAccuracy: 92.09%\n",
      "997\tValidation loss: 5.473728\tBest loss: 5.473728\tAccuracy: 92.09%\n",
      "998\tValidation loss: 5.473685\tBest loss: 5.473685\tAccuracy: 92.09%\n",
      "999\tValidation loss: 5.473650\tBest loss: 5.473650\tAccuracy: 92.09%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total= 1.3min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 288.278412\tBest loss: 288.278412\tAccuracy: 1.44%\n",
      "1\tValidation loss: 593.091919\tBest loss: 288.278412\tAccuracy: 5.04%\n",
      "2\tValidation loss: 848.852173\tBest loss: 288.278412\tAccuracy: 9.35%\n",
      "3\tValidation loss: 1027.162598\tBest loss: 288.278412\tAccuracy: 7.91%\n",
      "4\tValidation loss: 1057.119019\tBest loss: 288.278412\tAccuracy: 14.39%\n",
      "5\tValidation loss: 973.825256\tBest loss: 288.278412\tAccuracy: 25.90%\n",
      "6\tValidation loss: 871.336365\tBest loss: 288.278412\tAccuracy: 33.09%\n",
      "7\tValidation loss: 742.456909\tBest loss: 288.278412\tAccuracy: 45.32%\n",
      "8\tValidation loss: 659.531616\tBest loss: 288.278412\tAccuracy: 48.92%\n",
      "9\tValidation loss: 595.240051\tBest loss: 288.278412\tAccuracy: 46.76%\n",
      "10\tValidation loss: 560.810974\tBest loss: 288.278412\tAccuracy: 47.48%\n",
      "11\tValidation loss: 509.615601\tBest loss: 288.278412\tAccuracy: 42.45%\n",
      "12\tValidation loss: 421.869965\tBest loss: 288.278412\tAccuracy: 42.45%\n",
      "13\tValidation loss: 331.076233\tBest loss: 288.278412\tAccuracy: 52.52%\n",
      "14\tValidation loss: 273.639679\tBest loss: 273.639679\tAccuracy: 54.68%\n",
      "15\tValidation loss: 220.643097\tBest loss: 220.643097\tAccuracy: 61.15%\n",
      "16\tValidation loss: 161.452164\tBest loss: 161.452164\tAccuracy: 63.31%\n",
      "17\tValidation loss: 123.368568\tBest loss: 123.368568\tAccuracy: 66.91%\n",
      "18\tValidation loss: 105.465981\tBest loss: 105.465981\tAccuracy: 69.78%\n",
      "19\tValidation loss: 101.601379\tBest loss: 101.601379\tAccuracy: 68.35%\n",
      "20\tValidation loss: 98.495102\tBest loss: 98.495102\tAccuracy: 71.94%\n",
      "21\tValidation loss: 97.082703\tBest loss: 97.082703\tAccuracy: 69.06%\n",
      "22\tValidation loss: 93.672653\tBest loss: 93.672653\tAccuracy: 70.50%\n",
      "23\tValidation loss: 87.145950\tBest loss: 87.145950\tAccuracy: 70.50%\n",
      "24\tValidation loss: 77.346527\tBest loss: 77.346527\tAccuracy: 72.66%\n",
      "25\tValidation loss: 64.862846\tBest loss: 64.862846\tAccuracy: 75.54%\n",
      "26\tValidation loss: 52.037811\tBest loss: 52.037811\tAccuracy: 76.26%\n",
      "27\tValidation loss: 42.710960\tBest loss: 42.710960\tAccuracy: 82.73%\n",
      "28\tValidation loss: 36.637478\tBest loss: 36.637478\tAccuracy: 83.45%\n",
      "29\tValidation loss: 31.339237\tBest loss: 31.339237\tAccuracy: 84.17%\n",
      "30\tValidation loss: 27.847879\tBest loss: 27.847879\tAccuracy: 85.61%\n",
      "31\tValidation loss: 24.883984\tBest loss: 24.883984\tAccuracy: 86.33%\n",
      "32\tValidation loss: 23.211754\tBest loss: 23.211754\tAccuracy: 88.49%\n",
      "33\tValidation loss: 22.181414\tBest loss: 22.181414\tAccuracy: 87.77%\n",
      "34\tValidation loss: 21.046597\tBest loss: 21.046597\tAccuracy: 87.77%\n",
      "35\tValidation loss: 19.608681\tBest loss: 19.608681\tAccuracy: 87.77%\n",
      "36\tValidation loss: 18.538704\tBest loss: 18.538704\tAccuracy: 85.61%\n",
      "37\tValidation loss: 17.591499\tBest loss: 17.591499\tAccuracy: 86.33%\n",
      "38\tValidation loss: 16.960453\tBest loss: 16.960453\tAccuracy: 86.33%\n",
      "39\tValidation loss: 16.942507\tBest loss: 16.942507\tAccuracy: 86.33%\n",
      "40\tValidation loss: 17.363789\tBest loss: 16.942507\tAccuracy: 85.61%\n",
      "41\tValidation loss: 17.922588\tBest loss: 16.942507\tAccuracy: 87.05%\n",
      "42\tValidation loss: 18.465925\tBest loss: 16.942507\tAccuracy: 87.05%\n",
      "43\tValidation loss: 18.639423\tBest loss: 16.942507\tAccuracy: 87.05%\n",
      "44\tValidation loss: 18.298649\tBest loss: 16.942507\tAccuracy: 87.05%\n",
      "45\tValidation loss: 17.299368\tBest loss: 16.942507\tAccuracy: 87.05%\n",
      "46\tValidation loss: 16.078934\tBest loss: 16.078934\tAccuracy: 87.05%\n",
      "47\tValidation loss: 14.927382\tBest loss: 14.927382\tAccuracy: 87.77%\n",
      "48\tValidation loss: 13.899141\tBest loss: 13.899141\tAccuracy: 87.05%\n",
      "49\tValidation loss: 12.946232\tBest loss: 12.946232\tAccuracy: 87.77%\n",
      "50\tValidation loss: 12.288344\tBest loss: 12.288344\tAccuracy: 89.21%\n",
      "51\tValidation loss: 11.753651\tBest loss: 11.753651\tAccuracy: 89.21%\n",
      "52\tValidation loss: 11.664536\tBest loss: 11.664536\tAccuracy: 89.93%\n",
      "53\tValidation loss: 11.548638\tBest loss: 11.548638\tAccuracy: 89.21%\n",
      "54\tValidation loss: 11.354977\tBest loss: 11.354977\tAccuracy: 89.21%\n",
      "55\tValidation loss: 11.049477\tBest loss: 11.049477\tAccuracy: 88.49%\n",
      "56\tValidation loss: 10.780684\tBest loss: 10.780684\tAccuracy: 89.21%\n",
      "57\tValidation loss: 10.554779\tBest loss: 10.554779\tAccuracy: 88.49%\n",
      "58\tValidation loss: 10.342155\tBest loss: 10.342155\tAccuracy: 87.77%\n",
      "59\tValidation loss: 10.125660\tBest loss: 10.125660\tAccuracy: 87.77%\n",
      "60\tValidation loss: 9.954869\tBest loss: 9.954869\tAccuracy: 88.49%\n",
      "61\tValidation loss: 9.804387\tBest loss: 9.804387\tAccuracy: 88.49%\n",
      "62\tValidation loss: 9.652266\tBest loss: 9.652266\tAccuracy: 88.49%\n",
      "63\tValidation loss: 9.498151\tBest loss: 9.498151\tAccuracy: 88.49%\n",
      "64\tValidation loss: 9.334392\tBest loss: 9.334392\tAccuracy: 88.49%\n",
      "65\tValidation loss: 9.182908\tBest loss: 9.182908\tAccuracy: 89.21%\n",
      "66\tValidation loss: 9.075123\tBest loss: 9.075123\tAccuracy: 89.21%\n",
      "67\tValidation loss: 8.986152\tBest loss: 8.986152\tAccuracy: 89.21%\n",
      "68\tValidation loss: 8.931939\tBest loss: 8.931939\tAccuracy: 89.93%\n",
      "69\tValidation loss: 8.909398\tBest loss: 8.909398\tAccuracy: 89.93%\n",
      "70\tValidation loss: 8.886112\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "71\tValidation loss: 8.887117\tBest loss: 8.886112\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\tValidation loss: 8.925291\tBest loss: 8.886112\tAccuracy: 90.65%\n",
      "73\tValidation loss: 8.968299\tBest loss: 8.886112\tAccuracy: 90.65%\n",
      "74\tValidation loss: 9.009891\tBest loss: 8.886112\tAccuracy: 90.65%\n",
      "75\tValidation loss: 9.078149\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "76\tValidation loss: 9.150789\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "77\tValidation loss: 9.213456\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "78\tValidation loss: 9.257488\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "79\tValidation loss: 9.285364\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "80\tValidation loss: 9.304285\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "81\tValidation loss: 9.316881\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "82\tValidation loss: 9.323933\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "83\tValidation loss: 9.326941\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "84\tValidation loss: 9.326727\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "85\tValidation loss: 9.323165\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "86\tValidation loss: 9.316335\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "87\tValidation loss: 9.306027\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "88\tValidation loss: 9.292355\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "89\tValidation loss: 9.275608\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "90\tValidation loss: 9.255991\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "91\tValidation loss: 9.234514\tBest loss: 8.886112\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   7.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 284.157288\tBest loss: 284.157288\tAccuracy: 2.16%\n",
      "1\tValidation loss: 576.926758\tBest loss: 284.157288\tAccuracy: 5.04%\n",
      "2\tValidation loss: 803.898682\tBest loss: 284.157288\tAccuracy: 7.19%\n",
      "3\tValidation loss: 929.424744\tBest loss: 284.157288\tAccuracy: 11.51%\n",
      "4\tValidation loss: 985.351013\tBest loss: 284.157288\tAccuracy: 16.55%\n",
      "5\tValidation loss: 804.822876\tBest loss: 284.157288\tAccuracy: 33.81%\n",
      "6\tValidation loss: 732.494507\tBest loss: 284.157288\tAccuracy: 35.97%\n",
      "7\tValidation loss: 658.270508\tBest loss: 284.157288\tAccuracy: 43.88%\n",
      "8\tValidation loss: 591.638916\tBest loss: 284.157288\tAccuracy: 43.88%\n",
      "9\tValidation loss: 477.341309\tBest loss: 284.157288\tAccuracy: 46.04%\n",
      "10\tValidation loss: 387.042236\tBest loss: 284.157288\tAccuracy: 51.08%\n",
      "11\tValidation loss: 307.253662\tBest loss: 284.157288\tAccuracy: 46.04%\n",
      "12\tValidation loss: 226.162369\tBest loss: 226.162369\tAccuracy: 53.24%\n",
      "13\tValidation loss: 142.238815\tBest loss: 142.238815\tAccuracy: 63.31%\n",
      "14\tValidation loss: 109.030357\tBest loss: 109.030357\tAccuracy: 73.38%\n",
      "15\tValidation loss: 108.212784\tBest loss: 108.212784\tAccuracy: 68.35%\n",
      "16\tValidation loss: 105.785767\tBest loss: 105.785767\tAccuracy: 65.47%\n",
      "17\tValidation loss: 95.878387\tBest loss: 95.878387\tAccuracy: 65.47%\n",
      "18\tValidation loss: 81.849205\tBest loss: 81.849205\tAccuracy: 69.06%\n",
      "19\tValidation loss: 75.723412\tBest loss: 75.723412\tAccuracy: 69.78%\n",
      "20\tValidation loss: 75.405167\tBest loss: 75.405167\tAccuracy: 69.06%\n",
      "21\tValidation loss: 73.183304\tBest loss: 73.183304\tAccuracy: 69.06%\n",
      "22\tValidation loss: 67.088318\tBest loss: 67.088318\tAccuracy: 74.82%\n",
      "23\tValidation loss: 61.383575\tBest loss: 61.383575\tAccuracy: 77.70%\n",
      "24\tValidation loss: 56.870075\tBest loss: 56.870075\tAccuracy: 80.58%\n",
      "25\tValidation loss: 53.078625\tBest loss: 53.078625\tAccuracy: 81.29%\n",
      "26\tValidation loss: 48.378593\tBest loss: 48.378593\tAccuracy: 80.58%\n",
      "27\tValidation loss: 43.057877\tBest loss: 43.057877\tAccuracy: 78.42%\n",
      "28\tValidation loss: 37.888107\tBest loss: 37.888107\tAccuracy: 79.86%\n",
      "29\tValidation loss: 33.617508\tBest loss: 33.617508\tAccuracy: 80.58%\n",
      "30\tValidation loss: 31.987391\tBest loss: 31.987391\tAccuracy: 81.29%\n",
      "31\tValidation loss: 30.810146\tBest loss: 30.810146\tAccuracy: 82.01%\n",
      "32\tValidation loss: 30.121571\tBest loss: 30.121571\tAccuracy: 84.89%\n",
      "33\tValidation loss: 28.718010\tBest loss: 28.718010\tAccuracy: 83.45%\n",
      "34\tValidation loss: 27.252333\tBest loss: 27.252333\tAccuracy: 84.17%\n",
      "35\tValidation loss: 25.816629\tBest loss: 25.816629\tAccuracy: 84.17%\n",
      "36\tValidation loss: 24.096247\tBest loss: 24.096247\tAccuracy: 83.45%\n",
      "37\tValidation loss: 22.175133\tBest loss: 22.175133\tAccuracy: 82.73%\n",
      "38\tValidation loss: 20.378273\tBest loss: 20.378273\tAccuracy: 83.45%\n",
      "39\tValidation loss: 19.382025\tBest loss: 19.382025\tAccuracy: 84.17%\n",
      "40\tValidation loss: 18.770691\tBest loss: 18.770691\tAccuracy: 84.89%\n",
      "41\tValidation loss: 18.229650\tBest loss: 18.229650\tAccuracy: 84.89%\n",
      "42\tValidation loss: 17.597940\tBest loss: 17.597940\tAccuracy: 86.33%\n",
      "43\tValidation loss: 17.270338\tBest loss: 17.270338\tAccuracy: 84.89%\n",
      "44\tValidation loss: 16.883518\tBest loss: 16.883518\tAccuracy: 84.89%\n",
      "45\tValidation loss: 16.501402\tBest loss: 16.501402\tAccuracy: 86.33%\n",
      "46\tValidation loss: 16.107634\tBest loss: 16.107634\tAccuracy: 86.33%\n",
      "47\tValidation loss: 15.707012\tBest loss: 15.707012\tAccuracy: 85.61%\n",
      "48\tValidation loss: 15.277725\tBest loss: 15.277725\tAccuracy: 85.61%\n",
      "49\tValidation loss: 14.979657\tBest loss: 14.979657\tAccuracy: 86.33%\n",
      "50\tValidation loss: 14.620317\tBest loss: 14.620317\tAccuracy: 86.33%\n",
      "51\tValidation loss: 14.153160\tBest loss: 14.153160\tAccuracy: 87.05%\n",
      "52\tValidation loss: 13.589479\tBest loss: 13.589479\tAccuracy: 87.05%\n",
      "53\tValidation loss: 12.954781\tBest loss: 12.954781\tAccuracy: 87.05%\n",
      "54\tValidation loss: 12.268535\tBest loss: 12.268535\tAccuracy: 87.05%\n",
      "55\tValidation loss: 11.555498\tBest loss: 11.555498\tAccuracy: 87.05%\n",
      "56\tValidation loss: 10.869694\tBest loss: 10.869694\tAccuracy: 87.77%\n",
      "57\tValidation loss: 10.222250\tBest loss: 10.222250\tAccuracy: 88.49%\n",
      "58\tValidation loss: 9.717797\tBest loss: 9.717797\tAccuracy: 89.93%\n",
      "59\tValidation loss: 9.337154\tBest loss: 9.337154\tAccuracy: 89.93%\n",
      "60\tValidation loss: 9.095756\tBest loss: 9.095756\tAccuracy: 90.65%\n",
      "61\tValidation loss: 8.938956\tBest loss: 8.938956\tAccuracy: 89.93%\n",
      "62\tValidation loss: 8.813844\tBest loss: 8.813844\tAccuracy: 89.93%\n",
      "63\tValidation loss: 8.709357\tBest loss: 8.709357\tAccuracy: 89.93%\n",
      "64\tValidation loss: 8.625335\tBest loss: 8.625335\tAccuracy: 89.93%\n",
      "65\tValidation loss: 8.562359\tBest loss: 8.562359\tAccuracy: 89.93%\n",
      "66\tValidation loss: 8.519598\tBest loss: 8.519598\tAccuracy: 89.21%\n",
      "67\tValidation loss: 8.492534\tBest loss: 8.492534\tAccuracy: 89.21%\n",
      "68\tValidation loss: 8.476327\tBest loss: 8.476327\tAccuracy: 89.21%\n",
      "69\tValidation loss: 8.469265\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "70\tValidation loss: 8.470738\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "71\tValidation loss: 8.481025\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "72\tValidation loss: 8.499399\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "73\tValidation loss: 8.525723\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "74\tValidation loss: 8.559356\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "75\tValidation loss: 8.599337\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "76\tValidation loss: 8.644003\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "77\tValidation loss: 8.690041\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "78\tValidation loss: 8.734346\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "79\tValidation loss: 8.775848\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "80\tValidation loss: 8.814298\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "81\tValidation loss: 8.848436\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "82\tValidation loss: 8.875084\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "83\tValidation loss: 8.891108\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "84\tValidation loss: 8.894567\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "85\tValidation loss: 8.886685\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "86\tValidation loss: 8.870058\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "87\tValidation loss: 8.847201\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "88\tValidation loss: 8.821535\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "89\tValidation loss: 8.798992\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "90\tValidation loss: 8.786190\tBest loss: 8.469265\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   7.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 5.654469\tBest loss: 5.654469\tAccuracy: 31.65%\n",
      "1\tValidation loss: 3.358501\tBest loss: 3.358501\tAccuracy: 47.48%\n",
      "2\tValidation loss: 1.717536\tBest loss: 1.717536\tAccuracy: 70.50%\n",
      "3\tValidation loss: 1.244670\tBest loss: 1.244670\tAccuracy: 71.94%\n",
      "4\tValidation loss: 1.326219\tBest loss: 1.244670\tAccuracy: 71.94%\n",
      "5\tValidation loss: 0.810172\tBest loss: 0.810172\tAccuracy: 82.01%\n",
      "6\tValidation loss: 0.764876\tBest loss: 0.764876\tAccuracy: 81.29%\n",
      "7\tValidation loss: 0.670511\tBest loss: 0.670511\tAccuracy: 84.17%\n",
      "8\tValidation loss: 0.979561\tBest loss: 0.670511\tAccuracy: 79.14%\n",
      "9\tValidation loss: 0.650064\tBest loss: 0.650064\tAccuracy: 85.61%\n",
      "10\tValidation loss: 0.738097\tBest loss: 0.650064\tAccuracy: 87.05%\n",
      "11\tValidation loss: 0.576545\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "12\tValidation loss: 0.617016\tBest loss: 0.576545\tAccuracy: 85.61%\n",
      "13\tValidation loss: 0.654548\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "14\tValidation loss: 0.642676\tBest loss: 0.576545\tAccuracy: 86.33%\n",
      "15\tValidation loss: 0.660919\tBest loss: 0.576545\tAccuracy: 85.61%\n",
      "16\tValidation loss: 0.682038\tBest loss: 0.576545\tAccuracy: 86.33%\n",
      "17\tValidation loss: 0.669337\tBest loss: 0.576545\tAccuracy: 86.33%\n",
      "18\tValidation loss: 0.584757\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "19\tValidation loss: 0.632842\tBest loss: 0.576545\tAccuracy: 87.77%\n",
      "20\tValidation loss: 0.614756\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "21\tValidation loss: 0.625077\tBest loss: 0.576545\tAccuracy: 87.77%\n",
      "22\tValidation loss: 0.632570\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "23\tValidation loss: 0.618096\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "24\tValidation loss: 0.613857\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "25\tValidation loss: 0.640430\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "26\tValidation loss: 0.629190\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "27\tValidation loss: 0.628809\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "28\tValidation loss: 0.642672\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "29\tValidation loss: 0.638222\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "30\tValidation loss: 0.633795\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "31\tValidation loss: 0.633313\tBest loss: 0.576545\tAccuracy: 87.05%\n",
      "32\tValidation loss: 0.635305\tBest loss: 0.576545\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=   9.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 3.262462\tBest loss: 3.262462\tAccuracy: 50.36%\n",
      "1\tValidation loss: 2.154784\tBest loss: 2.154784\tAccuracy: 63.31%\n",
      "2\tValidation loss: 0.793037\tBest loss: 0.793037\tAccuracy: 79.14%\n",
      "3\tValidation loss: 0.919602\tBest loss: 0.793037\tAccuracy: 79.86%\n",
      "4\tValidation loss: 0.727254\tBest loss: 0.727254\tAccuracy: 80.58%\n",
      "5\tValidation loss: 0.624393\tBest loss: 0.624393\tAccuracy: 82.73%\n",
      "6\tValidation loss: 0.544205\tBest loss: 0.544205\tAccuracy: 83.45%\n",
      "7\tValidation loss: 0.437091\tBest loss: 0.437091\tAccuracy: 85.61%\n",
      "8\tValidation loss: 0.650690\tBest loss: 0.437091\tAccuracy: 81.29%\n",
      "9\tValidation loss: 0.579411\tBest loss: 0.437091\tAccuracy: 87.05%\n",
      "10\tValidation loss: 0.530619\tBest loss: 0.437091\tAccuracy: 82.73%\n",
      "11\tValidation loss: 0.521589\tBest loss: 0.437091\tAccuracy: 85.61%\n",
      "12\tValidation loss: 0.554461\tBest loss: 0.437091\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.465316\tBest loss: 0.437091\tAccuracy: 86.33%\n",
      "14\tValidation loss: 0.476846\tBest loss: 0.437091\tAccuracy: 87.77%\n",
      "15\tValidation loss: 0.429749\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "16\tValidation loss: 0.455645\tBest loss: 0.429749\tAccuracy: 85.61%\n",
      "17\tValidation loss: 0.467287\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "18\tValidation loss: 0.466312\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "19\tValidation loss: 0.434643\tBest loss: 0.429749\tAccuracy: 85.61%\n",
      "20\tValidation loss: 0.493284\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "21\tValidation loss: 0.473937\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "22\tValidation loss: 0.474551\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "23\tValidation loss: 0.477160\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "24\tValidation loss: 0.458558\tBest loss: 0.429749\tAccuracy: 87.05%\n",
      "25\tValidation loss: 0.461643\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "26\tValidation loss: 0.484149\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "27\tValidation loss: 0.476365\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "28\tValidation loss: 0.494228\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.481218\tBest loss: 0.429749\tAccuracy: 85.61%\n",
      "30\tValidation loss: 0.482689\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "31\tValidation loss: 0.485059\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "32\tValidation loss: 0.485441\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "33\tValidation loss: 0.492602\tBest loss: 0.429749\tAccuracy: 84.89%\n",
      "34\tValidation loss: 0.492058\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "35\tValidation loss: 0.503292\tBest loss: 0.429749\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.500089\tBest loss: 0.429749\tAccuracy: 86.33%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  10.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 6.385900\tBest loss: 6.385900\tAccuracy: 39.57%\n",
      "1\tValidation loss: 1.762163\tBest loss: 1.762163\tAccuracy: 71.22%\n",
      "2\tValidation loss: 0.940326\tBest loss: 0.940326\tAccuracy: 78.42%\n",
      "3\tValidation loss: 0.854494\tBest loss: 0.854494\tAccuracy: 82.01%\n",
      "4\tValidation loss: 0.733836\tBest loss: 0.733836\tAccuracy: 82.73%\n",
      "5\tValidation loss: 0.605872\tBest loss: 0.605872\tAccuracy: 86.33%\n",
      "6\tValidation loss: 0.492041\tBest loss: 0.492041\tAccuracy: 87.77%\n",
      "7\tValidation loss: 0.514891\tBest loss: 0.492041\tAccuracy: 88.49%\n",
      "8\tValidation loss: 0.750225\tBest loss: 0.492041\tAccuracy: 85.61%\n",
      "9\tValidation loss: 0.596320\tBest loss: 0.492041\tAccuracy: 85.61%\n",
      "10\tValidation loss: 0.439634\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "11\tValidation loss: 0.443686\tBest loss: 0.439634\tAccuracy: 86.33%\n",
      "12\tValidation loss: 0.467055\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "13\tValidation loss: 0.471017\tBest loss: 0.439634\tAccuracy: 90.65%\n",
      "14\tValidation loss: 0.491362\tBest loss: 0.439634\tAccuracy: 90.65%\n",
      "15\tValidation loss: 0.509135\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "16\tValidation loss: 0.514396\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "17\tValidation loss: 0.493328\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "18\tValidation loss: 0.570666\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "19\tValidation loss: 0.525798\tBest loss: 0.439634\tAccuracy: 89.93%\n",
      "20\tValidation loss: 0.545437\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "21\tValidation loss: 0.550382\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "22\tValidation loss: 0.573311\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.560562\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "24\tValidation loss: 0.544406\tBest loss: 0.439634\tAccuracy: 89.93%\n",
      "25\tValidation loss: 0.564079\tBest loss: 0.439634\tAccuracy: 89.93%\n",
      "26\tValidation loss: 0.560393\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "27\tValidation loss: 0.568571\tBest loss: 0.439634\tAccuracy: 89.93%\n",
      "28\tValidation loss: 0.544693\tBest loss: 0.439634\tAccuracy: 89.93%\n",
      "29\tValidation loss: 0.564411\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.565265\tBest loss: 0.439634\tAccuracy: 88.49%\n",
      "31\tValidation loss: 0.569690\tBest loss: 0.439634\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=   9.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.675543\tBest loss: 3.675543\tAccuracy: 30.22%\n",
      "1\tValidation loss: 2.328459\tBest loss: 2.328459\tAccuracy: 42.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\tValidation loss: 1.871550\tBest loss: 1.871550\tAccuracy: 48.92%\n",
      "3\tValidation loss: 1.734332\tBest loss: 1.734332\tAccuracy: 58.27%\n",
      "4\tValidation loss: 1.443110\tBest loss: 1.443110\tAccuracy: 61.87%\n",
      "5\tValidation loss: 1.103601\tBest loss: 1.103601\tAccuracy: 71.94%\n",
      "6\tValidation loss: 1.115056\tBest loss: 1.103601\tAccuracy: 69.78%\n",
      "7\tValidation loss: 0.908126\tBest loss: 0.908126\tAccuracy: 75.54%\n",
      "8\tValidation loss: 0.816731\tBest loss: 0.816731\tAccuracy: 79.14%\n",
      "9\tValidation loss: 0.863642\tBest loss: 0.816731\tAccuracy: 76.26%\n",
      "10\tValidation loss: 0.864751\tBest loss: 0.816731\tAccuracy: 74.10%\n",
      "11\tValidation loss: 0.684483\tBest loss: 0.684483\tAccuracy: 82.73%\n",
      "12\tValidation loss: 0.599920\tBest loss: 0.599920\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.590567\tBest loss: 0.590567\tAccuracy: 83.45%\n",
      "14\tValidation loss: 0.603348\tBest loss: 0.590567\tAccuracy: 83.45%\n",
      "15\tValidation loss: 0.613168\tBest loss: 0.590567\tAccuracy: 84.89%\n",
      "16\tValidation loss: 0.568851\tBest loss: 0.568851\tAccuracy: 85.61%\n",
      "17\tValidation loss: 0.581657\tBest loss: 0.568851\tAccuracy: 84.17%\n",
      "18\tValidation loss: 0.535590\tBest loss: 0.535590\tAccuracy: 85.61%\n",
      "19\tValidation loss: 0.549015\tBest loss: 0.535590\tAccuracy: 85.61%\n",
      "20\tValidation loss: 0.524884\tBest loss: 0.524884\tAccuracy: 86.33%\n",
      "21\tValidation loss: 0.508049\tBest loss: 0.508049\tAccuracy: 84.89%\n",
      "22\tValidation loss: 0.480236\tBest loss: 0.480236\tAccuracy: 86.33%\n",
      "23\tValidation loss: 0.475684\tBest loss: 0.475684\tAccuracy: 86.33%\n",
      "24\tValidation loss: 0.532839\tBest loss: 0.475684\tAccuracy: 84.89%\n",
      "25\tValidation loss: 0.477008\tBest loss: 0.475684\tAccuracy: 85.61%\n",
      "26\tValidation loss: 0.542091\tBest loss: 0.475684\tAccuracy: 83.45%\n",
      "27\tValidation loss: 0.491334\tBest loss: 0.475684\tAccuracy: 86.33%\n",
      "28\tValidation loss: 0.477987\tBest loss: 0.475684\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.429048\tBest loss: 0.429048\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.479752\tBest loss: 0.429048\tAccuracy: 87.05%\n",
      "31\tValidation loss: 0.475144\tBest loss: 0.429048\tAccuracy: 85.61%\n",
      "32\tValidation loss: 0.464745\tBest loss: 0.429048\tAccuracy: 88.49%\n",
      "33\tValidation loss: 0.500263\tBest loss: 0.429048\tAccuracy: 87.05%\n",
      "34\tValidation loss: 0.396372\tBest loss: 0.396372\tAccuracy: 88.49%\n",
      "35\tValidation loss: 0.455838\tBest loss: 0.396372\tAccuracy: 87.05%\n",
      "36\tValidation loss: 0.440588\tBest loss: 0.396372\tAccuracy: 88.49%\n",
      "37\tValidation loss: 0.459244\tBest loss: 0.396372\tAccuracy: 87.05%\n",
      "38\tValidation loss: 0.467623\tBest loss: 0.396372\tAccuracy: 88.49%\n",
      "39\tValidation loss: 0.465617\tBest loss: 0.396372\tAccuracy: 85.61%\n",
      "40\tValidation loss: 0.539756\tBest loss: 0.396372\tAccuracy: 84.89%\n",
      "41\tValidation loss: 0.450716\tBest loss: 0.396372\tAccuracy: 87.77%\n",
      "42\tValidation loss: 0.419414\tBest loss: 0.396372\tAccuracy: 87.77%\n",
      "43\tValidation loss: 0.430310\tBest loss: 0.396372\tAccuracy: 87.77%\n",
      "44\tValidation loss: 0.387122\tBest loss: 0.387122\tAccuracy: 89.93%\n",
      "45\tValidation loss: 0.410252\tBest loss: 0.387122\tAccuracy: 88.49%\n",
      "46\tValidation loss: 0.397282\tBest loss: 0.387122\tAccuracy: 89.21%\n",
      "47\tValidation loss: 0.379178\tBest loss: 0.379178\tAccuracy: 89.21%\n",
      "48\tValidation loss: 0.400936\tBest loss: 0.379178\tAccuracy: 89.21%\n",
      "49\tValidation loss: 0.392951\tBest loss: 0.379178\tAccuracy: 89.93%\n",
      "50\tValidation loss: 0.375391\tBest loss: 0.375391\tAccuracy: 90.65%\n",
      "51\tValidation loss: 0.419060\tBest loss: 0.375391\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.394294\tBest loss: 0.375391\tAccuracy: 88.49%\n",
      "53\tValidation loss: 0.379773\tBest loss: 0.375391\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.385167\tBest loss: 0.375391\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.394006\tBest loss: 0.375391\tAccuracy: 87.05%\n",
      "56\tValidation loss: 0.372020\tBest loss: 0.372020\tAccuracy: 87.77%\n",
      "57\tValidation loss: 0.341861\tBest loss: 0.341861\tAccuracy: 91.37%\n",
      "58\tValidation loss: 0.384764\tBest loss: 0.341861\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.380479\tBest loss: 0.341861\tAccuracy: 89.21%\n",
      "60\tValidation loss: 0.348054\tBest loss: 0.341861\tAccuracy: 90.65%\n",
      "61\tValidation loss: 0.343614\tBest loss: 0.341861\tAccuracy: 90.65%\n",
      "62\tValidation loss: 0.350592\tBest loss: 0.341861\tAccuracy: 89.21%\n",
      "63\tValidation loss: 0.363800\tBest loss: 0.341861\tAccuracy: 89.21%\n",
      "64\tValidation loss: 0.356485\tBest loss: 0.341861\tAccuracy: 89.93%\n",
      "65\tValidation loss: 0.336359\tBest loss: 0.336359\tAccuracy: 92.09%\n",
      "66\tValidation loss: 0.367782\tBest loss: 0.336359\tAccuracy: 90.65%\n",
      "67\tValidation loss: 0.386165\tBest loss: 0.336359\tAccuracy: 90.65%\n",
      "68\tValidation loss: 0.501364\tBest loss: 0.336359\tAccuracy: 90.65%\n",
      "69\tValidation loss: 0.375784\tBest loss: 0.336359\tAccuracy: 89.21%\n",
      "70\tValidation loss: 0.325899\tBest loss: 0.325899\tAccuracy: 89.21%\n",
      "71\tValidation loss: 0.352704\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "72\tValidation loss: 0.347974\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "73\tValidation loss: 0.373687\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "74\tValidation loss: 0.388850\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "75\tValidation loss: 0.352387\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "76\tValidation loss: 0.368935\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "77\tValidation loss: 0.373157\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "78\tValidation loss: 0.375129\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.381020\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "80\tValidation loss: 0.360880\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "81\tValidation loss: 0.344767\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "82\tValidation loss: 0.343715\tBest loss: 0.325899\tAccuracy: 92.09%\n",
      "83\tValidation loss: 0.400080\tBest loss: 0.325899\tAccuracy: 88.49%\n",
      "84\tValidation loss: 0.381045\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "85\tValidation loss: 0.375588\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.353434\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.374325\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "88\tValidation loss: 0.377902\tBest loss: 0.325899\tAccuracy: 90.65%\n",
      "89\tValidation loss: 0.372680\tBest loss: 0.325899\tAccuracy: 91.37%\n",
      "90\tValidation loss: 0.381109\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "91\tValidation loss: 0.390471\tBest loss: 0.325899\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  10.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.160105\tBest loss: 3.160105\tAccuracy: 22.30%\n",
      "1\tValidation loss: 2.516324\tBest loss: 2.516324\tAccuracy: 34.53%\n",
      "2\tValidation loss: 2.214575\tBest loss: 2.214575\tAccuracy: 45.32%\n",
      "3\tValidation loss: 2.193433\tBest loss: 2.193433\tAccuracy: 53.96%\n",
      "4\tValidation loss: 1.453000\tBest loss: 1.453000\tAccuracy: 61.87%\n",
      "5\tValidation loss: 1.547631\tBest loss: 1.453000\tAccuracy: 63.31%\n",
      "6\tValidation loss: 1.073032\tBest loss: 1.073032\tAccuracy: 68.35%\n",
      "7\tValidation loss: 1.018218\tBest loss: 1.018218\tAccuracy: 70.50%\n",
      "8\tValidation loss: 0.849789\tBest loss: 0.849789\tAccuracy: 75.54%\n",
      "9\tValidation loss: 0.679933\tBest loss: 0.679933\tAccuracy: 82.73%\n",
      "10\tValidation loss: 0.765787\tBest loss: 0.679933\tAccuracy: 79.86%\n",
      "11\tValidation loss: 0.692503\tBest loss: 0.679933\tAccuracy: 80.58%\n",
      "12\tValidation loss: 0.679172\tBest loss: 0.679172\tAccuracy: 79.86%\n",
      "13\tValidation loss: 0.752356\tBest loss: 0.679172\tAccuracy: 78.42%\n",
      "14\tValidation loss: 0.453232\tBest loss: 0.453232\tAccuracy: 86.33%\n",
      "15\tValidation loss: 0.542435\tBest loss: 0.453232\tAccuracy: 82.01%\n",
      "16\tValidation loss: 0.461270\tBest loss: 0.453232\tAccuracy: 89.21%\n",
      "17\tValidation loss: 0.542328\tBest loss: 0.453232\tAccuracy: 83.45%\n",
      "18\tValidation loss: 0.467341\tBest loss: 0.453232\tAccuracy: 87.05%\n",
      "19\tValidation loss: 0.386761\tBest loss: 0.386761\tAccuracy: 87.05%\n",
      "20\tValidation loss: 0.359447\tBest loss: 0.359447\tAccuracy: 90.65%\n",
      "21\tValidation loss: 0.388934\tBest loss: 0.359447\tAccuracy: 86.33%\n",
      "22\tValidation loss: 0.364742\tBest loss: 0.359447\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.346101\tBest loss: 0.346101\tAccuracy: 91.37%\n",
      "24\tValidation loss: 0.330297\tBest loss: 0.330297\tAccuracy: 91.37%\n",
      "25\tValidation loss: 0.331018\tBest loss: 0.330297\tAccuracy: 89.21%\n",
      "26\tValidation loss: 0.266184\tBest loss: 0.266184\tAccuracy: 92.09%\n",
      "27\tValidation loss: 0.283026\tBest loss: 0.266184\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 0.281581\tBest loss: 0.266184\tAccuracy: 92.81%\n",
      "29\tValidation loss: 0.268702\tBest loss: 0.266184\tAccuracy: 92.09%\n",
      "30\tValidation loss: 0.278853\tBest loss: 0.266184\tAccuracy: 89.93%\n",
      "31\tValidation loss: 0.294524\tBest loss: 0.266184\tAccuracy: 89.21%\n",
      "32\tValidation loss: 0.270506\tBest loss: 0.266184\tAccuracy: 91.37%\n",
      "33\tValidation loss: 0.322545\tBest loss: 0.266184\tAccuracy: 88.49%\n",
      "34\tValidation loss: 0.285600\tBest loss: 0.266184\tAccuracy: 91.37%\n",
      "35\tValidation loss: 0.234058\tBest loss: 0.234058\tAccuracy: 93.53%\n",
      "36\tValidation loss: 0.270624\tBest loss: 0.234058\tAccuracy: 91.37%\n",
      "37\tValidation loss: 0.241040\tBest loss: 0.234058\tAccuracy: 92.09%\n",
      "38\tValidation loss: 0.255335\tBest loss: 0.234058\tAccuracy: 90.65%\n",
      "39\tValidation loss: 0.277009\tBest loss: 0.234058\tAccuracy: 91.37%\n",
      "40\tValidation loss: 0.233170\tBest loss: 0.233170\tAccuracy: 92.09%\n",
      "41\tValidation loss: 0.245423\tBest loss: 0.233170\tAccuracy: 92.09%\n",
      "42\tValidation loss: 0.225611\tBest loss: 0.225611\tAccuracy: 92.81%\n",
      "43\tValidation loss: 0.216724\tBest loss: 0.216724\tAccuracy: 93.53%\n",
      "44\tValidation loss: 0.212613\tBest loss: 0.212613\tAccuracy: 94.96%\n",
      "45\tValidation loss: 0.258522\tBest loss: 0.212613\tAccuracy: 91.37%\n",
      "46\tValidation loss: 0.225691\tBest loss: 0.212613\tAccuracy: 94.24%\n",
      "47\tValidation loss: 0.226719\tBest loss: 0.212613\tAccuracy: 92.81%\n",
      "48\tValidation loss: 0.231508\tBest loss: 0.212613\tAccuracy: 93.53%\n",
      "49\tValidation loss: 0.237115\tBest loss: 0.212613\tAccuracy: 92.09%\n",
      "50\tValidation loss: 0.277254\tBest loss: 0.212613\tAccuracy: 89.21%\n",
      "51\tValidation loss: 0.288978\tBest loss: 0.212613\tAccuracy: 89.93%\n",
      "52\tValidation loss: 0.295924\tBest loss: 0.212613\tAccuracy: 90.65%\n",
      "53\tValidation loss: 0.218449\tBest loss: 0.212613\tAccuracy: 93.53%\n",
      "54\tValidation loss: 0.311045\tBest loss: 0.212613\tAccuracy: 91.37%\n",
      "55\tValidation loss: 0.250605\tBest loss: 0.212613\tAccuracy: 92.09%\n",
      "56\tValidation loss: 0.259161\tBest loss: 0.212613\tAccuracy: 92.09%\n",
      "57\tValidation loss: 0.229597\tBest loss: 0.212613\tAccuracy: 92.81%\n",
      "58\tValidation loss: 0.236567\tBest loss: 0.212613\tAccuracy: 92.09%\n",
      "59\tValidation loss: 0.307757\tBest loss: 0.212613\tAccuracy: 91.37%\n",
      "60\tValidation loss: 0.211510\tBest loss: 0.211510\tAccuracy: 94.24%\n",
      "61\tValidation loss: 0.216163\tBest loss: 0.211510\tAccuracy: 94.24%\n",
      "62\tValidation loss: 0.213814\tBest loss: 0.211510\tAccuracy: 93.53%\n",
      "63\tValidation loss: 0.218047\tBest loss: 0.211510\tAccuracy: 92.81%\n",
      "64\tValidation loss: 0.216934\tBest loss: 0.211510\tAccuracy: 92.81%\n",
      "65\tValidation loss: 0.220178\tBest loss: 0.211510\tAccuracy: 92.09%\n",
      "66\tValidation loss: 0.212573\tBest loss: 0.211510\tAccuracy: 94.24%\n",
      "67\tValidation loss: 0.213411\tBest loss: 0.211510\tAccuracy: 94.24%\n",
      "68\tValidation loss: 0.221824\tBest loss: 0.211510\tAccuracy: 94.96%\n",
      "69\tValidation loss: 0.205763\tBest loss: 0.205763\tAccuracy: 93.53%\n",
      "70\tValidation loss: 0.202866\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "71\tValidation loss: 0.207401\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "72\tValidation loss: 0.208098\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "73\tValidation loss: 0.204348\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "74\tValidation loss: 0.221063\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "75\tValidation loss: 0.217564\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "76\tValidation loss: 0.207118\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "77\tValidation loss: 0.252998\tBest loss: 0.202866\tAccuracy: 91.37%\n",
      "78\tValidation loss: 0.231404\tBest loss: 0.202866\tAccuracy: 92.81%\n",
      "79\tValidation loss: 0.226918\tBest loss: 0.202866\tAccuracy: 94.96%\n",
      "80\tValidation loss: 0.218635\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "81\tValidation loss: 0.230192\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "82\tValidation loss: 0.208321\tBest loss: 0.202866\tAccuracy: 94.24%\n",
      "83\tValidation loss: 0.271287\tBest loss: 0.202866\tAccuracy: 92.09%\n",
      "84\tValidation loss: 0.207602\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "85\tValidation loss: 0.250238\tBest loss: 0.202866\tAccuracy: 92.81%\n",
      "86\tValidation loss: 0.253047\tBest loss: 0.202866\tAccuracy: 92.09%\n",
      "87\tValidation loss: 0.216455\tBest loss: 0.202866\tAccuracy: 93.53%\n",
      "88\tValidation loss: 0.201897\tBest loss: 0.201897\tAccuracy: 94.24%\n",
      "89\tValidation loss: 0.222769\tBest loss: 0.201897\tAccuracy: 93.53%\n",
      "90\tValidation loss: 0.220414\tBest loss: 0.201897\tAccuracy: 92.81%\n",
      "91\tValidation loss: 0.207880\tBest loss: 0.201897\tAccuracy: 94.96%\n",
      "92\tValidation loss: 0.199322\tBest loss: 0.199322\tAccuracy: 94.96%\n",
      "93\tValidation loss: 0.224360\tBest loss: 0.199322\tAccuracy: 94.24%\n",
      "94\tValidation loss: 0.227115\tBest loss: 0.199322\tAccuracy: 93.53%\n",
      "95\tValidation loss: 0.193168\tBest loss: 0.193168\tAccuracy: 94.24%\n",
      "96\tValidation loss: 0.206314\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "97\tValidation loss: 0.231086\tBest loss: 0.193168\tAccuracy: 92.81%\n",
      "98\tValidation loss: 0.207301\tBest loss: 0.193168\tAccuracy: 94.24%\n",
      "99\tValidation loss: 0.210769\tBest loss: 0.193168\tAccuracy: 94.96%\n",
      "100\tValidation loss: 0.206354\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "101\tValidation loss: 0.212693\tBest loss: 0.193168\tAccuracy: 92.81%\n",
      "102\tValidation loss: 0.222058\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "103\tValidation loss: 0.209043\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "104\tValidation loss: 0.236028\tBest loss: 0.193168\tAccuracy: 92.81%\n",
      "105\tValidation loss: 0.242444\tBest loss: 0.193168\tAccuracy: 92.81%\n",
      "106\tValidation loss: 0.239245\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "107\tValidation loss: 0.233432\tBest loss: 0.193168\tAccuracy: 91.37%\n",
      "108\tValidation loss: 0.212347\tBest loss: 0.193168\tAccuracy: 94.24%\n",
      "109\tValidation loss: 0.216165\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "110\tValidation loss: 0.232662\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "111\tValidation loss: 0.255645\tBest loss: 0.193168\tAccuracy: 92.09%\n",
      "112\tValidation loss: 0.207502\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "113\tValidation loss: 0.222542\tBest loss: 0.193168\tAccuracy: 93.53%\n",
      "114\tValidation loss: 0.218461\tBest loss: 0.193168\tAccuracy: 94.24%\n",
      "115\tValidation loss: 0.228780\tBest loss: 0.193168\tAccuracy: 92.81%\n",
      "116\tValidation loss: 0.234519\tBest loss: 0.193168\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  13.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.434050\tBest loss: 3.434050\tAccuracy: 37.41%\n",
      "1\tValidation loss: 2.427866\tBest loss: 2.427866\tAccuracy: 39.57%\n",
      "2\tValidation loss: 2.076081\tBest loss: 2.076081\tAccuracy: 47.48%\n",
      "3\tValidation loss: 1.817093\tBest loss: 1.817093\tAccuracy: 55.40%\n",
      "4\tValidation loss: 1.629209\tBest loss: 1.629209\tAccuracy: 64.03%\n",
      "5\tValidation loss: 1.445447\tBest loss: 1.445447\tAccuracy: 69.06%\n",
      "6\tValidation loss: 1.149150\tBest loss: 1.149150\tAccuracy: 73.38%\n",
      "7\tValidation loss: 0.985732\tBest loss: 0.985732\tAccuracy: 77.70%\n",
      "8\tValidation loss: 0.775189\tBest loss: 0.775189\tAccuracy: 78.42%\n",
      "9\tValidation loss: 0.839213\tBest loss: 0.775189\tAccuracy: 76.26%\n",
      "10\tValidation loss: 0.795927\tBest loss: 0.775189\tAccuracy: 77.70%\n",
      "11\tValidation loss: 0.748273\tBest loss: 0.748273\tAccuracy: 82.01%\n",
      "12\tValidation loss: 0.649755\tBest loss: 0.649755\tAccuracy: 79.86%\n",
      "13\tValidation loss: 0.627124\tBest loss: 0.627124\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.593720\tBest loss: 0.593720\tAccuracy: 81.29%\n",
      "15\tValidation loss: 0.610094\tBest loss: 0.593720\tAccuracy: 81.29%\n",
      "16\tValidation loss: 0.647044\tBest loss: 0.593720\tAccuracy: 80.58%\n",
      "17\tValidation loss: 0.548362\tBest loss: 0.548362\tAccuracy: 84.17%\n",
      "18\tValidation loss: 0.493940\tBest loss: 0.493940\tAccuracy: 84.17%\n",
      "19\tValidation loss: 0.465409\tBest loss: 0.465409\tAccuracy: 85.61%\n",
      "20\tValidation loss: 0.478977\tBest loss: 0.465409\tAccuracy: 84.89%\n",
      "21\tValidation loss: 0.425683\tBest loss: 0.425683\tAccuracy: 87.77%\n",
      "22\tValidation loss: 0.392441\tBest loss: 0.392441\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.396367\tBest loss: 0.392441\tAccuracy: 89.21%\n",
      "24\tValidation loss: 0.362577\tBest loss: 0.362577\tAccuracy: 89.93%\n",
      "25\tValidation loss: 0.340984\tBest loss: 0.340984\tAccuracy: 90.65%\n",
      "26\tValidation loss: 0.452737\tBest loss: 0.340984\tAccuracy: 89.93%\n",
      "27\tValidation loss: 0.387001\tBest loss: 0.340984\tAccuracy: 88.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 0.350248\tBest loss: 0.340984\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.332291\tBest loss: 0.332291\tAccuracy: 91.37%\n",
      "30\tValidation loss: 0.335293\tBest loss: 0.332291\tAccuracy: 92.09%\n",
      "31\tValidation loss: 0.329148\tBest loss: 0.329148\tAccuracy: 90.65%\n",
      "32\tValidation loss: 0.304653\tBest loss: 0.304653\tAccuracy: 93.53%\n",
      "33\tValidation loss: 0.319954\tBest loss: 0.304653\tAccuracy: 90.65%\n",
      "34\tValidation loss: 0.303883\tBest loss: 0.303883\tAccuracy: 91.37%\n",
      "35\tValidation loss: 0.268717\tBest loss: 0.268717\tAccuracy: 92.81%\n",
      "36\tValidation loss: 0.336196\tBest loss: 0.268717\tAccuracy: 89.93%\n",
      "37\tValidation loss: 0.297914\tBest loss: 0.268717\tAccuracy: 92.81%\n",
      "38\tValidation loss: 0.298141\tBest loss: 0.268717\tAccuracy: 93.53%\n",
      "39\tValidation loss: 0.289833\tBest loss: 0.268717\tAccuracy: 92.81%\n",
      "40\tValidation loss: 0.274029\tBest loss: 0.268717\tAccuracy: 92.81%\n",
      "41\tValidation loss: 0.271585\tBest loss: 0.268717\tAccuracy: 93.53%\n",
      "42\tValidation loss: 0.246038\tBest loss: 0.246038\tAccuracy: 94.24%\n",
      "43\tValidation loss: 0.279437\tBest loss: 0.246038\tAccuracy: 91.37%\n",
      "44\tValidation loss: 0.282606\tBest loss: 0.246038\tAccuracy: 91.37%\n",
      "45\tValidation loss: 0.290071\tBest loss: 0.246038\tAccuracy: 91.37%\n",
      "46\tValidation loss: 0.278559\tBest loss: 0.246038\tAccuracy: 92.09%\n",
      "47\tValidation loss: 0.258834\tBest loss: 0.246038\tAccuracy: 92.09%\n",
      "48\tValidation loss: 0.257004\tBest loss: 0.246038\tAccuracy: 94.24%\n",
      "49\tValidation loss: 0.249638\tBest loss: 0.246038\tAccuracy: 94.24%\n",
      "50\tValidation loss: 0.254120\tBest loss: 0.246038\tAccuracy: 92.09%\n",
      "51\tValidation loss: 0.281242\tBest loss: 0.246038\tAccuracy: 93.53%\n",
      "52\tValidation loss: 0.249616\tBest loss: 0.246038\tAccuracy: 94.96%\n",
      "53\tValidation loss: 0.258493\tBest loss: 0.246038\tAccuracy: 94.24%\n",
      "54\tValidation loss: 0.254265\tBest loss: 0.246038\tAccuracy: 94.96%\n",
      "55\tValidation loss: 0.314515\tBest loss: 0.246038\tAccuracy: 92.81%\n",
      "56\tValidation loss: 0.273974\tBest loss: 0.246038\tAccuracy: 93.53%\n",
      "57\tValidation loss: 0.270301\tBest loss: 0.246038\tAccuracy: 92.81%\n",
      "58\tValidation loss: 0.281438\tBest loss: 0.246038\tAccuracy: 92.81%\n",
      "59\tValidation loss: 0.307336\tBest loss: 0.246038\tAccuracy: 91.37%\n",
      "60\tValidation loss: 0.271358\tBest loss: 0.246038\tAccuracy: 93.53%\n",
      "61\tValidation loss: 0.261579\tBest loss: 0.246038\tAccuracy: 94.24%\n",
      "62\tValidation loss: 0.298272\tBest loss: 0.246038\tAccuracy: 92.09%\n",
      "63\tValidation loss: 0.273145\tBest loss: 0.246038\tAccuracy: 92.81%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   8.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 3.261381\tBest loss: 3.261381\tAccuracy: 20.86%\n",
      "1\tValidation loss: 2.909235\tBest loss: 2.909235\tAccuracy: 20.14%\n",
      "2\tValidation loss: 2.739699\tBest loss: 2.739699\tAccuracy: 32.37%\n",
      "3\tValidation loss: 2.633792\tBest loss: 2.633792\tAccuracy: 32.37%\n",
      "4\tValidation loss: 2.550368\tBest loss: 2.550368\tAccuracy: 38.85%\n",
      "5\tValidation loss: 2.318892\tBest loss: 2.318892\tAccuracy: 48.92%\n",
      "6\tValidation loss: 2.195000\tBest loss: 2.195000\tAccuracy: 51.80%\n",
      "7\tValidation loss: 2.140156\tBest loss: 2.140156\tAccuracy: 51.08%\n",
      "8\tValidation loss: 2.097752\tBest loss: 2.097752\tAccuracy: 51.80%\n",
      "9\tValidation loss: 1.917841\tBest loss: 1.917841\tAccuracy: 56.83%\n",
      "10\tValidation loss: 1.820768\tBest loss: 1.820768\tAccuracy: 60.43%\n",
      "11\tValidation loss: 1.763702\tBest loss: 1.763702\tAccuracy: 61.15%\n",
      "12\tValidation loss: 1.652684\tBest loss: 1.652684\tAccuracy: 64.75%\n",
      "13\tValidation loss: 1.546793\tBest loss: 1.546793\tAccuracy: 65.47%\n",
      "14\tValidation loss: 1.527610\tBest loss: 1.527610\tAccuracy: 67.63%\n",
      "15\tValidation loss: 1.428757\tBest loss: 1.428757\tAccuracy: 67.63%\n",
      "16\tValidation loss: 1.410949\tBest loss: 1.410949\tAccuracy: 66.91%\n",
      "17\tValidation loss: 1.334971\tBest loss: 1.334971\tAccuracy: 75.54%\n",
      "18\tValidation loss: 1.252890\tBest loss: 1.252890\tAccuracy: 69.78%\n",
      "19\tValidation loss: 1.186094\tBest loss: 1.186094\tAccuracy: 71.22%\n",
      "20\tValidation loss: 1.220708\tBest loss: 1.186094\tAccuracy: 67.63%\n",
      "21\tValidation loss: 1.096146\tBest loss: 1.096146\tAccuracy: 79.14%\n",
      "22\tValidation loss: 1.048832\tBest loss: 1.048832\tAccuracy: 79.14%\n",
      "23\tValidation loss: 1.062822\tBest loss: 1.048832\tAccuracy: 79.14%\n",
      "24\tValidation loss: 1.019384\tBest loss: 1.019384\tAccuracy: 76.26%\n",
      "25\tValidation loss: 0.990307\tBest loss: 0.990307\tAccuracy: 76.98%\n",
      "26\tValidation loss: 0.985647\tBest loss: 0.985647\tAccuracy: 78.42%\n",
      "27\tValidation loss: 0.974957\tBest loss: 0.974957\tAccuracy: 78.42%\n",
      "28\tValidation loss: 0.935775\tBest loss: 0.935775\tAccuracy: 78.42%\n",
      "29\tValidation loss: 0.894616\tBest loss: 0.894616\tAccuracy: 82.01%\n",
      "30\tValidation loss: 0.871801\tBest loss: 0.871801\tAccuracy: 79.86%\n",
      "31\tValidation loss: 0.848769\tBest loss: 0.848769\tAccuracy: 78.42%\n",
      "32\tValidation loss: 0.845407\tBest loss: 0.845407\tAccuracy: 79.86%\n",
      "33\tValidation loss: 0.822697\tBest loss: 0.822697\tAccuracy: 79.86%\n",
      "34\tValidation loss: 0.804055\tBest loss: 0.804055\tAccuracy: 82.01%\n",
      "35\tValidation loss: 0.767262\tBest loss: 0.767262\tAccuracy: 84.17%\n",
      "36\tValidation loss: 0.752002\tBest loss: 0.752002\tAccuracy: 84.17%\n",
      "37\tValidation loss: 0.683030\tBest loss: 0.683030\tAccuracy: 83.45%\n",
      "38\tValidation loss: 0.700247\tBest loss: 0.683030\tAccuracy: 84.17%\n",
      "39\tValidation loss: 0.709140\tBest loss: 0.683030\tAccuracy: 87.05%\n",
      "40\tValidation loss: 0.686393\tBest loss: 0.683030\tAccuracy: 84.17%\n",
      "41\tValidation loss: 0.692826\tBest loss: 0.683030\tAccuracy: 84.17%\n",
      "42\tValidation loss: 0.697998\tBest loss: 0.683030\tAccuracy: 84.89%\n",
      "43\tValidation loss: 0.652195\tBest loss: 0.652195\tAccuracy: 84.17%\n",
      "44\tValidation loss: 0.646803\tBest loss: 0.646803\tAccuracy: 84.89%\n",
      "45\tValidation loss: 0.617599\tBest loss: 0.617599\tAccuracy: 88.49%\n",
      "46\tValidation loss: 0.658794\tBest loss: 0.617599\tAccuracy: 84.89%\n",
      "47\tValidation loss: 0.621785\tBest loss: 0.617599\tAccuracy: 85.61%\n",
      "48\tValidation loss: 0.582546\tBest loss: 0.582546\tAccuracy: 88.49%\n",
      "49\tValidation loss: 0.600903\tBest loss: 0.582546\tAccuracy: 84.17%\n",
      "50\tValidation loss: 0.594278\tBest loss: 0.582546\tAccuracy: 86.33%\n",
      "51\tValidation loss: 0.610435\tBest loss: 0.582546\tAccuracy: 85.61%\n",
      "52\tValidation loss: 0.575529\tBest loss: 0.575529\tAccuracy: 86.33%\n",
      "53\tValidation loss: 0.572508\tBest loss: 0.572508\tAccuracy: 86.33%\n",
      "54\tValidation loss: 0.551077\tBest loss: 0.551077\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.523705\tBest loss: 0.523705\tAccuracy: 89.93%\n",
      "56\tValidation loss: 0.518184\tBest loss: 0.518184\tAccuracy: 89.21%\n",
      "57\tValidation loss: 0.507899\tBest loss: 0.507899\tAccuracy: 89.93%\n",
      "58\tValidation loss: 0.534554\tBest loss: 0.507899\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.520980\tBest loss: 0.507899\tAccuracy: 88.49%\n",
      "60\tValidation loss: 0.542269\tBest loss: 0.507899\tAccuracy: 85.61%\n",
      "61\tValidation loss: 0.522292\tBest loss: 0.507899\tAccuracy: 87.05%\n",
      "62\tValidation loss: 0.517774\tBest loss: 0.507899\tAccuracy: 88.49%\n",
      "63\tValidation loss: 0.540019\tBest loss: 0.507899\tAccuracy: 87.05%\n",
      "64\tValidation loss: 0.521689\tBest loss: 0.507899\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.491715\tBest loss: 0.491715\tAccuracy: 87.77%\n",
      "66\tValidation loss: 0.479365\tBest loss: 0.479365\tAccuracy: 87.77%\n",
      "67\tValidation loss: 0.481115\tBest loss: 0.479365\tAccuracy: 86.33%\n",
      "68\tValidation loss: 0.482928\tBest loss: 0.479365\tAccuracy: 86.33%\n",
      "69\tValidation loss: 0.470584\tBest loss: 0.470584\tAccuracy: 88.49%\n",
      "70\tValidation loss: 0.457567\tBest loss: 0.457567\tAccuracy: 89.93%\n",
      "71\tValidation loss: 0.456441\tBest loss: 0.456441\tAccuracy: 89.21%\n",
      "72\tValidation loss: 0.434634\tBest loss: 0.434634\tAccuracy: 91.37%\n",
      "73\tValidation loss: 0.421773\tBest loss: 0.421773\tAccuracy: 91.37%\n",
      "74\tValidation loss: 0.445221\tBest loss: 0.421773\tAccuracy: 89.21%\n",
      "75\tValidation loss: 0.436176\tBest loss: 0.421773\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.462614\tBest loss: 0.421773\tAccuracy: 89.93%\n",
      "77\tValidation loss: 0.435369\tBest loss: 0.421773\tAccuracy: 90.65%\n",
      "78\tValidation loss: 0.429064\tBest loss: 0.421773\tAccuracy: 90.65%\n",
      "79\tValidation loss: 0.442064\tBest loss: 0.421773\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.422608\tBest loss: 0.421773\tAccuracy: 90.65%\n",
      "81\tValidation loss: 0.421242\tBest loss: 0.421242\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\tValidation loss: 0.422186\tBest loss: 0.421242\tAccuracy: 89.21%\n",
      "83\tValidation loss: 0.428090\tBest loss: 0.421242\tAccuracy: 89.21%\n",
      "84\tValidation loss: 0.425754\tBest loss: 0.421242\tAccuracy: 88.49%\n",
      "85\tValidation loss: 0.405798\tBest loss: 0.405798\tAccuracy: 88.49%\n",
      "86\tValidation loss: 0.412638\tBest loss: 0.405798\tAccuracy: 87.05%\n",
      "87\tValidation loss: 0.415571\tBest loss: 0.405798\tAccuracy: 89.93%\n",
      "88\tValidation loss: 0.399069\tBest loss: 0.399069\tAccuracy: 92.09%\n",
      "89\tValidation loss: 0.405078\tBest loss: 0.399069\tAccuracy: 92.09%\n",
      "90\tValidation loss: 0.413694\tBest loss: 0.399069\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.386067\tBest loss: 0.386067\tAccuracy: 91.37%\n",
      "92\tValidation loss: 0.393290\tBest loss: 0.386067\tAccuracy: 91.37%\n",
      "93\tValidation loss: 0.390812\tBest loss: 0.386067\tAccuracy: 90.65%\n",
      "94\tValidation loss: 0.382039\tBest loss: 0.382039\tAccuracy: 89.93%\n",
      "95\tValidation loss: 0.362654\tBest loss: 0.362654\tAccuracy: 92.09%\n",
      "96\tValidation loss: 0.367664\tBest loss: 0.362654\tAccuracy: 92.81%\n",
      "97\tValidation loss: 0.370398\tBest loss: 0.362654\tAccuracy: 91.37%\n",
      "98\tValidation loss: 0.364027\tBest loss: 0.362654\tAccuracy: 92.09%\n",
      "99\tValidation loss: 0.357317\tBest loss: 0.357317\tAccuracy: 92.81%\n",
      "100\tValidation loss: 0.370899\tBest loss: 0.357317\tAccuracy: 91.37%\n",
      "101\tValidation loss: 0.363939\tBest loss: 0.357317\tAccuracy: 90.65%\n",
      "102\tValidation loss: 0.356764\tBest loss: 0.356764\tAccuracy: 90.65%\n",
      "103\tValidation loss: 0.357515\tBest loss: 0.356764\tAccuracy: 92.09%\n",
      "104\tValidation loss: 0.344403\tBest loss: 0.344403\tAccuracy: 89.21%\n",
      "105\tValidation loss: 0.343197\tBest loss: 0.343197\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.340597\tBest loss: 0.340597\tAccuracy: 92.09%\n",
      "107\tValidation loss: 0.362297\tBest loss: 0.340597\tAccuracy: 91.37%\n",
      "108\tValidation loss: 0.360465\tBest loss: 0.340597\tAccuracy: 89.93%\n",
      "109\tValidation loss: 0.353077\tBest loss: 0.340597\tAccuracy: 89.93%\n",
      "110\tValidation loss: 0.352375\tBest loss: 0.340597\tAccuracy: 90.65%\n",
      "111\tValidation loss: 0.354679\tBest loss: 0.340597\tAccuracy: 91.37%\n",
      "112\tValidation loss: 0.342080\tBest loss: 0.340597\tAccuracy: 90.65%\n",
      "113\tValidation loss: 0.359390\tBest loss: 0.340597\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.344202\tBest loss: 0.340597\tAccuracy: 92.09%\n",
      "115\tValidation loss: 0.327664\tBest loss: 0.327664\tAccuracy: 92.09%\n",
      "116\tValidation loss: 0.328950\tBest loss: 0.327664\tAccuracy: 90.65%\n",
      "117\tValidation loss: 0.321388\tBest loss: 0.321388\tAccuracy: 92.09%\n",
      "118\tValidation loss: 0.347968\tBest loss: 0.321388\tAccuracy: 89.21%\n",
      "119\tValidation loss: 0.343112\tBest loss: 0.321388\tAccuracy: 90.65%\n",
      "120\tValidation loss: 0.333355\tBest loss: 0.321388\tAccuracy: 91.37%\n",
      "121\tValidation loss: 0.333856\tBest loss: 0.321388\tAccuracy: 92.09%\n",
      "122\tValidation loss: 0.337597\tBest loss: 0.321388\tAccuracy: 91.37%\n",
      "123\tValidation loss: 0.342410\tBest loss: 0.321388\tAccuracy: 91.37%\n",
      "124\tValidation loss: 0.329059\tBest loss: 0.321388\tAccuracy: 91.37%\n",
      "125\tValidation loss: 0.313131\tBest loss: 0.313131\tAccuracy: 91.37%\n",
      "126\tValidation loss: 0.319062\tBest loss: 0.313131\tAccuracy: 93.53%\n",
      "127\tValidation loss: 0.342110\tBest loss: 0.313131\tAccuracy: 90.65%\n",
      "128\tValidation loss: 0.331086\tBest loss: 0.313131\tAccuracy: 92.81%\n",
      "129\tValidation loss: 0.327407\tBest loss: 0.313131\tAccuracy: 92.09%\n",
      "130\tValidation loss: 0.314461\tBest loss: 0.313131\tAccuracy: 91.37%\n",
      "131\tValidation loss: 0.302725\tBest loss: 0.302725\tAccuracy: 92.09%\n",
      "132\tValidation loss: 0.321586\tBest loss: 0.302725\tAccuracy: 92.09%\n",
      "133\tValidation loss: 0.310352\tBest loss: 0.302725\tAccuracy: 91.37%\n",
      "134\tValidation loss: 0.296479\tBest loss: 0.296479\tAccuracy: 92.09%\n",
      "135\tValidation loss: 0.316621\tBest loss: 0.296479\tAccuracy: 89.21%\n",
      "136\tValidation loss: 0.309460\tBest loss: 0.296479\tAccuracy: 89.93%\n",
      "137\tValidation loss: 0.313375\tBest loss: 0.296479\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.317807\tBest loss: 0.296479\tAccuracy: 91.37%\n",
      "139\tValidation loss: 0.312887\tBest loss: 0.296479\tAccuracy: 91.37%\n",
      "140\tValidation loss: 0.299061\tBest loss: 0.296479\tAccuracy: 92.09%\n",
      "141\tValidation loss: 0.304908\tBest loss: 0.296479\tAccuracy: 92.09%\n",
      "142\tValidation loss: 0.298048\tBest loss: 0.296479\tAccuracy: 91.37%\n",
      "143\tValidation loss: 0.290230\tBest loss: 0.290230\tAccuracy: 92.09%\n",
      "144\tValidation loss: 0.297025\tBest loss: 0.290230\tAccuracy: 92.09%\n",
      "145\tValidation loss: 0.299225\tBest loss: 0.290230\tAccuracy: 91.37%\n",
      "146\tValidation loss: 0.296393\tBest loss: 0.290230\tAccuracy: 92.09%\n",
      "147\tValidation loss: 0.300562\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "148\tValidation loss: 0.290505\tBest loss: 0.290230\tAccuracy: 92.09%\n",
      "149\tValidation loss: 0.320583\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "150\tValidation loss: 0.319565\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "151\tValidation loss: 0.305065\tBest loss: 0.290230\tAccuracy: 89.93%\n",
      "152\tValidation loss: 0.303276\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "153\tValidation loss: 0.296106\tBest loss: 0.290230\tAccuracy: 91.37%\n",
      "154\tValidation loss: 0.302976\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "155\tValidation loss: 0.312280\tBest loss: 0.290230\tAccuracy: 91.37%\n",
      "156\tValidation loss: 0.311981\tBest loss: 0.290230\tAccuracy: 90.65%\n",
      "157\tValidation loss: 0.300041\tBest loss: 0.290230\tAccuracy: 91.37%\n",
      "158\tValidation loss: 0.294061\tBest loss: 0.290230\tAccuracy: 91.37%\n",
      "159\tValidation loss: 0.277966\tBest loss: 0.277966\tAccuracy: 92.81%\n",
      "160\tValidation loss: 0.271178\tBest loss: 0.271178\tAccuracy: 92.81%\n",
      "161\tValidation loss: 0.277171\tBest loss: 0.271178\tAccuracy: 92.81%\n",
      "162\tValidation loss: 0.274390\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "163\tValidation loss: 0.283630\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "164\tValidation loss: 0.275664\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "165\tValidation loss: 0.284000\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "166\tValidation loss: 0.284446\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "167\tValidation loss: 0.271618\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "168\tValidation loss: 0.278054\tBest loss: 0.271178\tAccuracy: 92.09%\n",
      "169\tValidation loss: 0.269820\tBest loss: 0.269820\tAccuracy: 92.09%\n",
      "170\tValidation loss: 0.273962\tBest loss: 0.269820\tAccuracy: 92.09%\n",
      "171\tValidation loss: 0.268938\tBest loss: 0.268938\tAccuracy: 92.09%\n",
      "172\tValidation loss: 0.270677\tBest loss: 0.268938\tAccuracy: 92.81%\n",
      "173\tValidation loss: 0.282523\tBest loss: 0.268938\tAccuracy: 92.09%\n",
      "174\tValidation loss: 0.272891\tBest loss: 0.268938\tAccuracy: 92.81%\n",
      "175\tValidation loss: 0.267624\tBest loss: 0.267624\tAccuracy: 92.09%\n",
      "176\tValidation loss: 0.272009\tBest loss: 0.267624\tAccuracy: 92.81%\n",
      "177\tValidation loss: 0.263676\tBest loss: 0.263676\tAccuracy: 92.81%\n",
      "178\tValidation loss: 0.268010\tBest loss: 0.263676\tAccuracy: 92.81%\n",
      "179\tValidation loss: 0.271556\tBest loss: 0.263676\tAccuracy: 92.09%\n",
      "180\tValidation loss: 0.259319\tBest loss: 0.259319\tAccuracy: 92.81%\n",
      "181\tValidation loss: 0.248815\tBest loss: 0.248815\tAccuracy: 92.09%\n",
      "182\tValidation loss: 0.259813\tBest loss: 0.248815\tAccuracy: 92.09%\n",
      "183\tValidation loss: 0.254294\tBest loss: 0.248815\tAccuracy: 92.09%\n",
      "184\tValidation loss: 0.261070\tBest loss: 0.248815\tAccuracy: 92.09%\n",
      "185\tValidation loss: 0.261492\tBest loss: 0.248815\tAccuracy: 92.81%\n",
      "186\tValidation loss: 0.252442\tBest loss: 0.248815\tAccuracy: 92.81%\n",
      "187\tValidation loss: 0.250306\tBest loss: 0.248815\tAccuracy: 92.81%\n",
      "188\tValidation loss: 0.262581\tBest loss: 0.248815\tAccuracy: 92.81%\n",
      "189\tValidation loss: 0.248745\tBest loss: 0.248745\tAccuracy: 93.53%\n",
      "190\tValidation loss: 0.257251\tBest loss: 0.248745\tAccuracy: 92.81%\n",
      "191\tValidation loss: 0.253153\tBest loss: 0.248745\tAccuracy: 92.81%\n",
      "192\tValidation loss: 0.257826\tBest loss: 0.248745\tAccuracy: 92.81%\n",
      "193\tValidation loss: 0.251895\tBest loss: 0.248745\tAccuracy: 92.81%\n",
      "194\tValidation loss: 0.258624\tBest loss: 0.248745\tAccuracy: 92.81%\n",
      "195\tValidation loss: 0.253529\tBest loss: 0.248745\tAccuracy: 92.09%\n",
      "196\tValidation loss: 0.244770\tBest loss: 0.244770\tAccuracy: 93.53%\n",
      "197\tValidation loss: 0.246747\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "198\tValidation loss: 0.248806\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "199\tValidation loss: 0.250681\tBest loss: 0.244770\tAccuracy: 91.37%\n",
      "200\tValidation loss: 0.260017\tBest loss: 0.244770\tAccuracy: 91.37%\n",
      "201\tValidation loss: 0.259088\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "202\tValidation loss: 0.246391\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "203\tValidation loss: 0.247433\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "204\tValidation loss: 0.257429\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "205\tValidation loss: 0.254460\tBest loss: 0.244770\tAccuracy: 92.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\tValidation loss: 0.249182\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "207\tValidation loss: 0.252422\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "208\tValidation loss: 0.259071\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "209\tValidation loss: 0.265684\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "210\tValidation loss: 0.252776\tBest loss: 0.244770\tAccuracy: 93.53%\n",
      "211\tValidation loss: 0.253849\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "212\tValidation loss: 0.258116\tBest loss: 0.244770\tAccuracy: 92.81%\n",
      "213\tValidation loss: 0.259322\tBest loss: 0.244770\tAccuracy: 92.09%\n",
      "214\tValidation loss: 0.240400\tBest loss: 0.240400\tAccuracy: 92.81%\n",
      "215\tValidation loss: 0.239842\tBest loss: 0.239842\tAccuracy: 92.81%\n",
      "216\tValidation loss: 0.229323\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "217\tValidation loss: 0.236809\tBest loss: 0.229323\tAccuracy: 92.81%\n",
      "218\tValidation loss: 0.235195\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "219\tValidation loss: 0.235522\tBest loss: 0.229323\tAccuracy: 92.81%\n",
      "220\tValidation loss: 0.237775\tBest loss: 0.229323\tAccuracy: 92.81%\n",
      "221\tValidation loss: 0.235314\tBest loss: 0.229323\tAccuracy: 92.81%\n",
      "222\tValidation loss: 0.249761\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "223\tValidation loss: 0.247196\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "224\tValidation loss: 0.245540\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "225\tValidation loss: 0.237654\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "226\tValidation loss: 0.235665\tBest loss: 0.229323\tAccuracy: 93.53%\n",
      "227\tValidation loss: 0.221612\tBest loss: 0.221612\tAccuracy: 93.53%\n",
      "228\tValidation loss: 0.218158\tBest loss: 0.218158\tAccuracy: 93.53%\n",
      "229\tValidation loss: 0.230413\tBest loss: 0.218158\tAccuracy: 92.81%\n",
      "230\tValidation loss: 0.237950\tBest loss: 0.218158\tAccuracy: 92.09%\n",
      "231\tValidation loss: 0.252685\tBest loss: 0.218158\tAccuracy: 91.37%\n",
      "232\tValidation loss: 0.249342\tBest loss: 0.218158\tAccuracy: 91.37%\n",
      "233\tValidation loss: 0.248750\tBest loss: 0.218158\tAccuracy: 92.81%\n",
      "234\tValidation loss: 0.246332\tBest loss: 0.218158\tAccuracy: 93.53%\n",
      "235\tValidation loss: 0.253660\tBest loss: 0.218158\tAccuracy: 92.09%\n",
      "236\tValidation loss: 0.245183\tBest loss: 0.218158\tAccuracy: 93.53%\n",
      "237\tValidation loss: 0.237821\tBest loss: 0.218158\tAccuracy: 93.53%\n",
      "238\tValidation loss: 0.233637\tBest loss: 0.218158\tAccuracy: 92.81%\n",
      "239\tValidation loss: 0.224765\tBest loss: 0.218158\tAccuracy: 92.09%\n",
      "240\tValidation loss: 0.227647\tBest loss: 0.218158\tAccuracy: 91.37%\n",
      "241\tValidation loss: 0.209890\tBest loss: 0.209890\tAccuracy: 92.09%\n",
      "242\tValidation loss: 0.213451\tBest loss: 0.209890\tAccuracy: 92.81%\n",
      "243\tValidation loss: 0.201758\tBest loss: 0.201758\tAccuracy: 93.53%\n",
      "244\tValidation loss: 0.209670\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "245\tValidation loss: 0.216828\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "246\tValidation loss: 0.224290\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "247\tValidation loss: 0.231561\tBest loss: 0.201758\tAccuracy: 92.09%\n",
      "248\tValidation loss: 0.228096\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "249\tValidation loss: 0.227108\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "250\tValidation loss: 0.228118\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "251\tValidation loss: 0.233094\tBest loss: 0.201758\tAccuracy: 92.09%\n",
      "252\tValidation loss: 0.215281\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "253\tValidation loss: 0.222883\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "254\tValidation loss: 0.221385\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "255\tValidation loss: 0.227953\tBest loss: 0.201758\tAccuracy: 92.09%\n",
      "256\tValidation loss: 0.232581\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "257\tValidation loss: 0.226001\tBest loss: 0.201758\tAccuracy: 92.09%\n",
      "258\tValidation loss: 0.225382\tBest loss: 0.201758\tAccuracy: 91.37%\n",
      "259\tValidation loss: 0.218612\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "260\tValidation loss: 0.216481\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "261\tValidation loss: 0.220125\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "262\tValidation loss: 0.223094\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "263\tValidation loss: 0.228205\tBest loss: 0.201758\tAccuracy: 92.81%\n",
      "264\tValidation loss: 0.216856\tBest loss: 0.201758\tAccuracy: 93.53%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  37.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 3.275172\tBest loss: 3.275172\tAccuracy: 20.14%\n",
      "1\tValidation loss: 3.057995\tBest loss: 3.057995\tAccuracy: 20.86%\n",
      "2\tValidation loss: 2.695798\tBest loss: 2.695798\tAccuracy: 34.53%\n",
      "3\tValidation loss: 2.585542\tBest loss: 2.585542\tAccuracy: 42.45%\n",
      "4\tValidation loss: 2.281778\tBest loss: 2.281778\tAccuracy: 53.24%\n",
      "5\tValidation loss: 2.192633\tBest loss: 2.192633\tAccuracy: 49.64%\n",
      "6\tValidation loss: 2.065485\tBest loss: 2.065485\tAccuracy: 55.40%\n",
      "7\tValidation loss: 1.945833\tBest loss: 1.945833\tAccuracy: 58.27%\n",
      "8\tValidation loss: 1.873330\tBest loss: 1.873330\tAccuracy: 60.43%\n",
      "9\tValidation loss: 1.741037\tBest loss: 1.741037\tAccuracy: 63.31%\n",
      "10\tValidation loss: 1.621620\tBest loss: 1.621620\tAccuracy: 66.91%\n",
      "11\tValidation loss: 1.593844\tBest loss: 1.593844\tAccuracy: 65.47%\n",
      "12\tValidation loss: 1.503762\tBest loss: 1.503762\tAccuracy: 63.31%\n",
      "13\tValidation loss: 1.516783\tBest loss: 1.503762\tAccuracy: 61.87%\n",
      "14\tValidation loss: 1.433941\tBest loss: 1.433941\tAccuracy: 68.35%\n",
      "15\tValidation loss: 1.348970\tBest loss: 1.348970\tAccuracy: 72.66%\n",
      "16\tValidation loss: 1.202601\tBest loss: 1.202601\tAccuracy: 76.98%\n",
      "17\tValidation loss: 1.115573\tBest loss: 1.115573\tAccuracy: 79.14%\n",
      "18\tValidation loss: 1.111420\tBest loss: 1.111420\tAccuracy: 76.98%\n",
      "19\tValidation loss: 1.062904\tBest loss: 1.062904\tAccuracy: 76.26%\n",
      "20\tValidation loss: 0.994048\tBest loss: 0.994048\tAccuracy: 80.58%\n",
      "21\tValidation loss: 1.002441\tBest loss: 0.994048\tAccuracy: 81.29%\n",
      "22\tValidation loss: 0.952128\tBest loss: 0.952128\tAccuracy: 79.14%\n",
      "23\tValidation loss: 0.909606\tBest loss: 0.909606\tAccuracy: 78.42%\n",
      "24\tValidation loss: 0.926411\tBest loss: 0.909606\tAccuracy: 81.29%\n",
      "25\tValidation loss: 0.883440\tBest loss: 0.883440\tAccuracy: 82.01%\n",
      "26\tValidation loss: 0.854144\tBest loss: 0.854144\tAccuracy: 80.58%\n",
      "27\tValidation loss: 0.814425\tBest loss: 0.814425\tAccuracy: 83.45%\n",
      "28\tValidation loss: 0.843035\tBest loss: 0.814425\tAccuracy: 82.01%\n",
      "29\tValidation loss: 0.820025\tBest loss: 0.814425\tAccuracy: 84.17%\n",
      "30\tValidation loss: 0.822057\tBest loss: 0.814425\tAccuracy: 79.86%\n",
      "31\tValidation loss: 0.762560\tBest loss: 0.762560\tAccuracy: 79.86%\n",
      "32\tValidation loss: 0.761178\tBest loss: 0.761178\tAccuracy: 82.01%\n",
      "33\tValidation loss: 0.762791\tBest loss: 0.761178\tAccuracy: 83.45%\n",
      "34\tValidation loss: 0.756648\tBest loss: 0.756648\tAccuracy: 81.29%\n",
      "35\tValidation loss: 0.726411\tBest loss: 0.726411\tAccuracy: 82.73%\n",
      "36\tValidation loss: 0.716703\tBest loss: 0.716703\tAccuracy: 84.17%\n",
      "37\tValidation loss: 0.710058\tBest loss: 0.710058\tAccuracy: 83.45%\n",
      "38\tValidation loss: 0.648692\tBest loss: 0.648692\tAccuracy: 84.89%\n",
      "39\tValidation loss: 0.668792\tBest loss: 0.648692\tAccuracy: 85.61%\n",
      "40\tValidation loss: 0.659584\tBest loss: 0.648692\tAccuracy: 84.17%\n",
      "41\tValidation loss: 0.639089\tBest loss: 0.639089\tAccuracy: 85.61%\n",
      "42\tValidation loss: 0.634973\tBest loss: 0.634973\tAccuracy: 84.89%\n",
      "43\tValidation loss: 0.637395\tBest loss: 0.634973\tAccuracy: 86.33%\n",
      "44\tValidation loss: 0.606207\tBest loss: 0.606207\tAccuracy: 86.33%\n",
      "45\tValidation loss: 0.606045\tBest loss: 0.606045\tAccuracy: 84.17%\n",
      "46\tValidation loss: 0.603768\tBest loss: 0.603768\tAccuracy: 86.33%\n",
      "47\tValidation loss: 0.583833\tBest loss: 0.583833\tAccuracy: 86.33%\n",
      "48\tValidation loss: 0.579779\tBest loss: 0.579779\tAccuracy: 86.33%\n",
      "49\tValidation loss: 0.530956\tBest loss: 0.530956\tAccuracy: 84.89%\n",
      "50\tValidation loss: 0.558368\tBest loss: 0.530956\tAccuracy: 84.89%\n",
      "51\tValidation loss: 0.549678\tBest loss: 0.530956\tAccuracy: 87.05%\n",
      "52\tValidation loss: 0.517024\tBest loss: 0.517024\tAccuracy: 86.33%\n",
      "53\tValidation loss: 0.516262\tBest loss: 0.516262\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.526619\tBest loss: 0.516262\tAccuracy: 87.77%\n",
      "55\tValidation loss: 0.493948\tBest loss: 0.493948\tAccuracy: 88.49%\n",
      "56\tValidation loss: 0.491519\tBest loss: 0.491519\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.495586\tBest loss: 0.491519\tAccuracy: 88.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\tValidation loss: 0.488119\tBest loss: 0.488119\tAccuracy: 89.21%\n",
      "59\tValidation loss: 0.478289\tBest loss: 0.478289\tAccuracy: 89.93%\n",
      "60\tValidation loss: 0.486005\tBest loss: 0.478289\tAccuracy: 88.49%\n",
      "61\tValidation loss: 0.495698\tBest loss: 0.478289\tAccuracy: 87.77%\n",
      "62\tValidation loss: 0.512329\tBest loss: 0.478289\tAccuracy: 87.05%\n",
      "63\tValidation loss: 0.502407\tBest loss: 0.478289\tAccuracy: 88.49%\n",
      "64\tValidation loss: 0.458214\tBest loss: 0.458214\tAccuracy: 89.21%\n",
      "65\tValidation loss: 0.464354\tBest loss: 0.458214\tAccuracy: 89.93%\n",
      "66\tValidation loss: 0.468635\tBest loss: 0.458214\tAccuracy: 89.21%\n",
      "67\tValidation loss: 0.469959\tBest loss: 0.458214\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.423060\tBest loss: 0.423060\tAccuracy: 89.93%\n",
      "69\tValidation loss: 0.414246\tBest loss: 0.414246\tAccuracy: 89.93%\n",
      "70\tValidation loss: 0.428718\tBest loss: 0.414246\tAccuracy: 90.65%\n",
      "71\tValidation loss: 0.411375\tBest loss: 0.411375\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.440427\tBest loss: 0.411375\tAccuracy: 89.21%\n",
      "73\tValidation loss: 0.412459\tBest loss: 0.411375\tAccuracy: 90.65%\n",
      "74\tValidation loss: 0.389385\tBest loss: 0.389385\tAccuracy: 90.65%\n",
      "75\tValidation loss: 0.404619\tBest loss: 0.389385\tAccuracy: 88.49%\n",
      "76\tValidation loss: 0.402156\tBest loss: 0.389385\tAccuracy: 91.37%\n",
      "77\tValidation loss: 0.404986\tBest loss: 0.389385\tAccuracy: 89.93%\n",
      "78\tValidation loss: 0.406229\tBest loss: 0.389385\tAccuracy: 89.21%\n",
      "79\tValidation loss: 0.391795\tBest loss: 0.389385\tAccuracy: 91.37%\n",
      "80\tValidation loss: 0.378094\tBest loss: 0.378094\tAccuracy: 90.65%\n",
      "81\tValidation loss: 0.372930\tBest loss: 0.372930\tAccuracy: 91.37%\n",
      "82\tValidation loss: 0.389234\tBest loss: 0.372930\tAccuracy: 91.37%\n",
      "83\tValidation loss: 0.390197\tBest loss: 0.372930\tAccuracy: 92.09%\n",
      "84\tValidation loss: 0.394518\tBest loss: 0.372930\tAccuracy: 89.93%\n",
      "85\tValidation loss: 0.384798\tBest loss: 0.372930\tAccuracy: 89.93%\n",
      "86\tValidation loss: 0.363418\tBest loss: 0.363418\tAccuracy: 92.09%\n",
      "87\tValidation loss: 0.364536\tBest loss: 0.363418\tAccuracy: 89.93%\n",
      "88\tValidation loss: 0.367165\tBest loss: 0.363418\tAccuracy: 92.09%\n",
      "89\tValidation loss: 0.365586\tBest loss: 0.363418\tAccuracy: 90.65%\n",
      "90\tValidation loss: 0.363982\tBest loss: 0.363418\tAccuracy: 92.09%\n",
      "91\tValidation loss: 0.343062\tBest loss: 0.343062\tAccuracy: 92.81%\n",
      "92\tValidation loss: 0.349474\tBest loss: 0.343062\tAccuracy: 92.81%\n",
      "93\tValidation loss: 0.349062\tBest loss: 0.343062\tAccuracy: 92.09%\n",
      "94\tValidation loss: 0.372154\tBest loss: 0.343062\tAccuracy: 89.93%\n",
      "95\tValidation loss: 0.373741\tBest loss: 0.343062\tAccuracy: 89.21%\n",
      "96\tValidation loss: 0.349443\tBest loss: 0.343062\tAccuracy: 91.37%\n",
      "97\tValidation loss: 0.345873\tBest loss: 0.343062\tAccuracy: 92.09%\n",
      "98\tValidation loss: 0.336375\tBest loss: 0.336375\tAccuracy: 91.37%\n",
      "99\tValidation loss: 0.334990\tBest loss: 0.334990\tAccuracy: 91.37%\n",
      "100\tValidation loss: 0.334689\tBest loss: 0.334689\tAccuracy: 92.09%\n",
      "101\tValidation loss: 0.341678\tBest loss: 0.334689\tAccuracy: 91.37%\n",
      "102\tValidation loss: 0.337499\tBest loss: 0.334689\tAccuracy: 91.37%\n",
      "103\tValidation loss: 0.346801\tBest loss: 0.334689\tAccuracy: 92.81%\n",
      "104\tValidation loss: 0.339543\tBest loss: 0.334689\tAccuracy: 91.37%\n",
      "105\tValidation loss: 0.318226\tBest loss: 0.318226\tAccuracy: 92.81%\n",
      "106\tValidation loss: 0.317528\tBest loss: 0.317528\tAccuracy: 91.37%\n",
      "107\tValidation loss: 0.327448\tBest loss: 0.317528\tAccuracy: 91.37%\n",
      "108\tValidation loss: 0.322658\tBest loss: 0.317528\tAccuracy: 91.37%\n",
      "109\tValidation loss: 0.312329\tBest loss: 0.312329\tAccuracy: 92.09%\n",
      "110\tValidation loss: 0.317135\tBest loss: 0.312329\tAccuracy: 93.53%\n",
      "111\tValidation loss: 0.298672\tBest loss: 0.298672\tAccuracy: 92.09%\n",
      "112\tValidation loss: 0.300706\tBest loss: 0.298672\tAccuracy: 92.09%\n",
      "113\tValidation loss: 0.305779\tBest loss: 0.298672\tAccuracy: 92.81%\n",
      "114\tValidation loss: 0.307150\tBest loss: 0.298672\tAccuracy: 90.65%\n",
      "115\tValidation loss: 0.311476\tBest loss: 0.298672\tAccuracy: 89.93%\n",
      "116\tValidation loss: 0.310508\tBest loss: 0.298672\tAccuracy: 89.93%\n",
      "117\tValidation loss: 0.311953\tBest loss: 0.298672\tAccuracy: 90.65%\n",
      "118\tValidation loss: 0.292625\tBest loss: 0.292625\tAccuracy: 92.09%\n",
      "119\tValidation loss: 0.298429\tBest loss: 0.292625\tAccuracy: 91.37%\n",
      "120\tValidation loss: 0.302255\tBest loss: 0.292625\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.288456\tBest loss: 0.288456\tAccuracy: 91.37%\n",
      "122\tValidation loss: 0.280550\tBest loss: 0.280550\tAccuracy: 89.93%\n",
      "123\tValidation loss: 0.280375\tBest loss: 0.280375\tAccuracy: 91.37%\n",
      "124\tValidation loss: 0.301042\tBest loss: 0.280375\tAccuracy: 91.37%\n",
      "125\tValidation loss: 0.284411\tBest loss: 0.280375\tAccuracy: 92.81%\n",
      "126\tValidation loss: 0.276334\tBest loss: 0.276334\tAccuracy: 91.37%\n",
      "127\tValidation loss: 0.256713\tBest loss: 0.256713\tAccuracy: 92.09%\n",
      "128\tValidation loss: 0.285672\tBest loss: 0.256713\tAccuracy: 92.09%\n",
      "129\tValidation loss: 0.289100\tBest loss: 0.256713\tAccuracy: 91.37%\n",
      "130\tValidation loss: 0.272640\tBest loss: 0.256713\tAccuracy: 92.81%\n",
      "131\tValidation loss: 0.286272\tBest loss: 0.256713\tAccuracy: 91.37%\n",
      "132\tValidation loss: 0.269689\tBest loss: 0.256713\tAccuracy: 92.81%\n",
      "133\tValidation loss: 0.260314\tBest loss: 0.256713\tAccuracy: 93.53%\n",
      "134\tValidation loss: 0.254155\tBest loss: 0.254155\tAccuracy: 92.81%\n",
      "135\tValidation loss: 0.239047\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "136\tValidation loss: 0.250582\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "137\tValidation loss: 0.258668\tBest loss: 0.239047\tAccuracy: 92.09%\n",
      "138\tValidation loss: 0.267281\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "139\tValidation loss: 0.262495\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "140\tValidation loss: 0.250325\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "141\tValidation loss: 0.249487\tBest loss: 0.239047\tAccuracy: 92.81%\n",
      "142\tValidation loss: 0.241180\tBest loss: 0.239047\tAccuracy: 94.24%\n",
      "143\tValidation loss: 0.245594\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "144\tValidation loss: 0.258346\tBest loss: 0.239047\tAccuracy: 92.81%\n",
      "145\tValidation loss: 0.259859\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "146\tValidation loss: 0.254864\tBest loss: 0.239047\tAccuracy: 94.96%\n",
      "147\tValidation loss: 0.248692\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "148\tValidation loss: 0.250919\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "149\tValidation loss: 0.260188\tBest loss: 0.239047\tAccuracy: 92.81%\n",
      "150\tValidation loss: 0.263910\tBest loss: 0.239047\tAccuracy: 92.81%\n",
      "151\tValidation loss: 0.251614\tBest loss: 0.239047\tAccuracy: 94.24%\n",
      "152\tValidation loss: 0.244343\tBest loss: 0.239047\tAccuracy: 93.53%\n",
      "153\tValidation loss: 0.260298\tBest loss: 0.239047\tAccuracy: 92.09%\n",
      "154\tValidation loss: 0.246837\tBest loss: 0.239047\tAccuracy: 92.09%\n",
      "155\tValidation loss: 0.233234\tBest loss: 0.233234\tAccuracy: 93.53%\n",
      "156\tValidation loss: 0.232123\tBest loss: 0.232123\tAccuracy: 94.24%\n",
      "157\tValidation loss: 0.230089\tBest loss: 0.230089\tAccuracy: 94.96%\n",
      "158\tValidation loss: 0.221670\tBest loss: 0.221670\tAccuracy: 94.24%\n",
      "159\tValidation loss: 0.215109\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "160\tValidation loss: 0.229745\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "161\tValidation loss: 0.222374\tBest loss: 0.215109\tAccuracy: 96.40%\n",
      "162\tValidation loss: 0.222173\tBest loss: 0.215109\tAccuracy: 96.40%\n",
      "163\tValidation loss: 0.221509\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "164\tValidation loss: 0.227520\tBest loss: 0.215109\tAccuracy: 94.24%\n",
      "165\tValidation loss: 0.229044\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "166\tValidation loss: 0.218247\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "167\tValidation loss: 0.225857\tBest loss: 0.215109\tAccuracy: 94.24%\n",
      "168\tValidation loss: 0.228156\tBest loss: 0.215109\tAccuracy: 94.24%\n",
      "169\tValidation loss: 0.222199\tBest loss: 0.215109\tAccuracy: 93.53%\n",
      "170\tValidation loss: 0.222385\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "171\tValidation loss: 0.226936\tBest loss: 0.215109\tAccuracy: 93.53%\n",
      "172\tValidation loss: 0.218823\tBest loss: 0.215109\tAccuracy: 93.53%\n",
      "173\tValidation loss: 0.216011\tBest loss: 0.215109\tAccuracy: 94.96%\n",
      "174\tValidation loss: 0.189679\tBest loss: 0.189679\tAccuracy: 95.68%\n",
      "175\tValidation loss: 0.187590\tBest loss: 0.187590\tAccuracy: 95.68%\n",
      "176\tValidation loss: 0.185034\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "177\tValidation loss: 0.209810\tBest loss: 0.185034\tAccuracy: 94.24%\n",
      "178\tValidation loss: 0.200845\tBest loss: 0.185034\tAccuracy: 95.68%\n",
      "179\tValidation loss: 0.203746\tBest loss: 0.185034\tAccuracy: 94.24%\n",
      "180\tValidation loss: 0.203917\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "181\tValidation loss: 0.203383\tBest loss: 0.185034\tAccuracy: 92.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\tValidation loss: 0.207476\tBest loss: 0.185034\tAccuracy: 92.81%\n",
      "183\tValidation loss: 0.206211\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "184\tValidation loss: 0.200733\tBest loss: 0.185034\tAccuracy: 95.68%\n",
      "185\tValidation loss: 0.198073\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "186\tValidation loss: 0.198527\tBest loss: 0.185034\tAccuracy: 95.68%\n",
      "187\tValidation loss: 0.197762\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "188\tValidation loss: 0.198323\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "189\tValidation loss: 0.209390\tBest loss: 0.185034\tAccuracy: 93.53%\n",
      "190\tValidation loss: 0.200914\tBest loss: 0.185034\tAccuracy: 94.24%\n",
      "191\tValidation loss: 0.196594\tBest loss: 0.185034\tAccuracy: 93.53%\n",
      "192\tValidation loss: 0.195421\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "193\tValidation loss: 0.191535\tBest loss: 0.185034\tAccuracy: 96.40%\n",
      "194\tValidation loss: 0.195256\tBest loss: 0.185034\tAccuracy: 95.68%\n",
      "195\tValidation loss: 0.195190\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "196\tValidation loss: 0.201148\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "197\tValidation loss: 0.199333\tBest loss: 0.185034\tAccuracy: 94.96%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  29.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 3.346708\tBest loss: 3.346708\tAccuracy: 16.55%\n",
      "1\tValidation loss: 3.015083\tBest loss: 3.015083\tAccuracy: 22.30%\n",
      "2\tValidation loss: 2.758667\tBest loss: 2.758667\tAccuracy: 38.13%\n",
      "3\tValidation loss: 2.675627\tBest loss: 2.675627\tAccuracy: 38.13%\n",
      "4\tValidation loss: 2.495848\tBest loss: 2.495848\tAccuracy: 43.17%\n",
      "5\tValidation loss: 2.380451\tBest loss: 2.380451\tAccuracy: 46.04%\n",
      "6\tValidation loss: 2.177449\tBest loss: 2.177449\tAccuracy: 52.52%\n",
      "7\tValidation loss: 1.981875\tBest loss: 1.981875\tAccuracy: 61.15%\n",
      "8\tValidation loss: 1.972519\tBest loss: 1.972519\tAccuracy: 56.12%\n",
      "9\tValidation loss: 1.736415\tBest loss: 1.736415\tAccuracy: 64.75%\n",
      "10\tValidation loss: 1.643427\tBest loss: 1.643427\tAccuracy: 62.59%\n",
      "11\tValidation loss: 1.675274\tBest loss: 1.643427\tAccuracy: 65.47%\n",
      "12\tValidation loss: 1.615545\tBest loss: 1.615545\tAccuracy: 67.63%\n",
      "13\tValidation loss: 1.496984\tBest loss: 1.496984\tAccuracy: 66.91%\n",
      "14\tValidation loss: 1.392043\tBest loss: 1.392043\tAccuracy: 71.22%\n",
      "15\tValidation loss: 1.385537\tBest loss: 1.385537\tAccuracy: 72.66%\n",
      "16\tValidation loss: 1.277099\tBest loss: 1.277099\tAccuracy: 75.54%\n",
      "17\tValidation loss: 1.204510\tBest loss: 1.204510\tAccuracy: 76.26%\n",
      "18\tValidation loss: 1.103531\tBest loss: 1.103531\tAccuracy: 79.14%\n",
      "19\tValidation loss: 1.093817\tBest loss: 1.093817\tAccuracy: 74.10%\n",
      "20\tValidation loss: 1.057337\tBest loss: 1.057337\tAccuracy: 78.42%\n",
      "21\tValidation loss: 1.018445\tBest loss: 1.018445\tAccuracy: 79.14%\n",
      "22\tValidation loss: 1.011335\tBest loss: 1.011335\tAccuracy: 76.26%\n",
      "23\tValidation loss: 0.957732\tBest loss: 0.957732\tAccuracy: 77.70%\n",
      "24\tValidation loss: 0.881598\tBest loss: 0.881598\tAccuracy: 82.01%\n",
      "25\tValidation loss: 0.908288\tBest loss: 0.881598\tAccuracy: 82.73%\n",
      "26\tValidation loss: 0.884072\tBest loss: 0.881598\tAccuracy: 83.45%\n",
      "27\tValidation loss: 0.855663\tBest loss: 0.855663\tAccuracy: 82.01%\n",
      "28\tValidation loss: 0.824478\tBest loss: 0.824478\tAccuracy: 81.29%\n",
      "29\tValidation loss: 0.797027\tBest loss: 0.797027\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.776908\tBest loss: 0.776908\tAccuracy: 83.45%\n",
      "31\tValidation loss: 0.771802\tBest loss: 0.771802\tAccuracy: 80.58%\n",
      "32\tValidation loss: 0.767170\tBest loss: 0.767170\tAccuracy: 84.17%\n",
      "33\tValidation loss: 0.721393\tBest loss: 0.721393\tAccuracy: 83.45%\n",
      "34\tValidation loss: 0.698624\tBest loss: 0.698624\tAccuracy: 86.33%\n",
      "35\tValidation loss: 0.690108\tBest loss: 0.690108\tAccuracy: 83.45%\n",
      "36\tValidation loss: 0.681614\tBest loss: 0.681614\tAccuracy: 87.05%\n",
      "37\tValidation loss: 0.664362\tBest loss: 0.664362\tAccuracy: 85.61%\n",
      "38\tValidation loss: 0.654419\tBest loss: 0.654419\tAccuracy: 86.33%\n",
      "39\tValidation loss: 0.653048\tBest loss: 0.653048\tAccuracy: 82.73%\n",
      "40\tValidation loss: 0.656018\tBest loss: 0.653048\tAccuracy: 83.45%\n",
      "41\tValidation loss: 0.653101\tBest loss: 0.653048\tAccuracy: 83.45%\n",
      "42\tValidation loss: 0.644763\tBest loss: 0.644763\tAccuracy: 87.05%\n",
      "43\tValidation loss: 0.601459\tBest loss: 0.601459\tAccuracy: 86.33%\n",
      "44\tValidation loss: 0.589664\tBest loss: 0.589664\tAccuracy: 87.05%\n",
      "45\tValidation loss: 0.613479\tBest loss: 0.589664\tAccuracy: 89.21%\n",
      "46\tValidation loss: 0.573153\tBest loss: 0.573153\tAccuracy: 87.77%\n",
      "47\tValidation loss: 0.561980\tBest loss: 0.561980\tAccuracy: 88.49%\n",
      "48\tValidation loss: 0.567978\tBest loss: 0.561980\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.557427\tBest loss: 0.557427\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.541141\tBest loss: 0.541141\tAccuracy: 86.33%\n",
      "51\tValidation loss: 0.539310\tBest loss: 0.539310\tAccuracy: 87.05%\n",
      "52\tValidation loss: 0.571130\tBest loss: 0.539310\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.563527\tBest loss: 0.539310\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.552485\tBest loss: 0.539310\tAccuracy: 84.17%\n",
      "55\tValidation loss: 0.545032\tBest loss: 0.539310\tAccuracy: 86.33%\n",
      "56\tValidation loss: 0.526958\tBest loss: 0.526958\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.484282\tBest loss: 0.484282\tAccuracy: 89.93%\n",
      "58\tValidation loss: 0.492056\tBest loss: 0.484282\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.469042\tBest loss: 0.469042\tAccuracy: 88.49%\n",
      "60\tValidation loss: 0.465481\tBest loss: 0.465481\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.486008\tBest loss: 0.465481\tAccuracy: 90.65%\n",
      "62\tValidation loss: 0.453893\tBest loss: 0.453893\tAccuracy: 89.93%\n",
      "63\tValidation loss: 0.473965\tBest loss: 0.453893\tAccuracy: 88.49%\n",
      "64\tValidation loss: 0.471700\tBest loss: 0.453893\tAccuracy: 89.93%\n",
      "65\tValidation loss: 0.439882\tBest loss: 0.439882\tAccuracy: 90.65%\n",
      "66\tValidation loss: 0.442433\tBest loss: 0.439882\tAccuracy: 89.93%\n",
      "67\tValidation loss: 0.446052\tBest loss: 0.439882\tAccuracy: 89.21%\n",
      "68\tValidation loss: 0.415283\tBest loss: 0.415283\tAccuracy: 89.21%\n",
      "69\tValidation loss: 0.431491\tBest loss: 0.415283\tAccuracy: 90.65%\n",
      "70\tValidation loss: 0.430119\tBest loss: 0.415283\tAccuracy: 89.21%\n",
      "71\tValidation loss: 0.435942\tBest loss: 0.415283\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.424285\tBest loss: 0.415283\tAccuracy: 89.21%\n",
      "73\tValidation loss: 0.418874\tBest loss: 0.415283\tAccuracy: 89.21%\n",
      "74\tValidation loss: 0.425799\tBest loss: 0.415283\tAccuracy: 90.65%\n",
      "75\tValidation loss: 0.413688\tBest loss: 0.413688\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.397716\tBest loss: 0.397716\tAccuracy: 90.65%\n",
      "77\tValidation loss: 0.393839\tBest loss: 0.393839\tAccuracy: 91.37%\n",
      "78\tValidation loss: 0.361276\tBest loss: 0.361276\tAccuracy: 92.09%\n",
      "79\tValidation loss: 0.369635\tBest loss: 0.361276\tAccuracy: 92.09%\n",
      "80\tValidation loss: 0.362825\tBest loss: 0.361276\tAccuracy: 89.21%\n",
      "81\tValidation loss: 0.382487\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "82\tValidation loss: 0.390932\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "83\tValidation loss: 0.392874\tBest loss: 0.361276\tAccuracy: 89.93%\n",
      "84\tValidation loss: 0.373083\tBest loss: 0.361276\tAccuracy: 89.21%\n",
      "85\tValidation loss: 0.376013\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.381944\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.388405\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "88\tValidation loss: 0.381112\tBest loss: 0.361276\tAccuracy: 90.65%\n",
      "89\tValidation loss: 0.358827\tBest loss: 0.358827\tAccuracy: 89.21%\n",
      "90\tValidation loss: 0.356207\tBest loss: 0.356207\tAccuracy: 90.65%\n",
      "91\tValidation loss: 0.360230\tBest loss: 0.356207\tAccuracy: 90.65%\n",
      "92\tValidation loss: 0.353617\tBest loss: 0.353617\tAccuracy: 89.21%\n",
      "93\tValidation loss: 0.385570\tBest loss: 0.353617\tAccuracy: 88.49%\n",
      "94\tValidation loss: 0.352579\tBest loss: 0.352579\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.354448\tBest loss: 0.352579\tAccuracy: 90.65%\n",
      "96\tValidation loss: 0.337561\tBest loss: 0.337561\tAccuracy: 91.37%\n",
      "97\tValidation loss: 0.340866\tBest loss: 0.337561\tAccuracy: 88.49%\n",
      "98\tValidation loss: 0.326626\tBest loss: 0.326626\tAccuracy: 92.09%\n",
      "99\tValidation loss: 0.340058\tBest loss: 0.326626\tAccuracy: 92.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\tValidation loss: 0.344053\tBest loss: 0.326626\tAccuracy: 92.81%\n",
      "101\tValidation loss: 0.337524\tBest loss: 0.326626\tAccuracy: 90.65%\n",
      "102\tValidation loss: 0.339418\tBest loss: 0.326626\tAccuracy: 92.81%\n",
      "103\tValidation loss: 0.321610\tBest loss: 0.321610\tAccuracy: 91.37%\n",
      "104\tValidation loss: 0.334107\tBest loss: 0.321610\tAccuracy: 90.65%\n",
      "105\tValidation loss: 0.342226\tBest loss: 0.321610\tAccuracy: 92.09%\n",
      "106\tValidation loss: 0.327588\tBest loss: 0.321610\tAccuracy: 91.37%\n",
      "107\tValidation loss: 0.331428\tBest loss: 0.321610\tAccuracy: 89.93%\n",
      "108\tValidation loss: 0.319308\tBest loss: 0.319308\tAccuracy: 90.65%\n",
      "109\tValidation loss: 0.326721\tBest loss: 0.319308\tAccuracy: 90.65%\n",
      "110\tValidation loss: 0.310630\tBest loss: 0.310630\tAccuracy: 91.37%\n",
      "111\tValidation loss: 0.301316\tBest loss: 0.301316\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.297094\tBest loss: 0.297094\tAccuracy: 92.09%\n",
      "113\tValidation loss: 0.310965\tBest loss: 0.297094\tAccuracy: 92.81%\n",
      "114\tValidation loss: 0.317391\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "115\tValidation loss: 0.318010\tBest loss: 0.297094\tAccuracy: 93.53%\n",
      "116\tValidation loss: 0.305774\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "117\tValidation loss: 0.302560\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "118\tValidation loss: 0.305665\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "119\tValidation loss: 0.308936\tBest loss: 0.297094\tAccuracy: 90.65%\n",
      "120\tValidation loss: 0.300975\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "121\tValidation loss: 0.300630\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "122\tValidation loss: 0.337170\tBest loss: 0.297094\tAccuracy: 90.65%\n",
      "123\tValidation loss: 0.311021\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "124\tValidation loss: 0.315085\tBest loss: 0.297094\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.319015\tBest loss: 0.297094\tAccuracy: 89.93%\n",
      "126\tValidation loss: 0.320005\tBest loss: 0.297094\tAccuracy: 90.65%\n",
      "127\tValidation loss: 0.302682\tBest loss: 0.297094\tAccuracy: 91.37%\n",
      "128\tValidation loss: 0.297092\tBest loss: 0.297092\tAccuracy: 91.37%\n",
      "129\tValidation loss: 0.289029\tBest loss: 0.289029\tAccuracy: 90.65%\n",
      "130\tValidation loss: 0.285525\tBest loss: 0.285525\tAccuracy: 90.65%\n",
      "131\tValidation loss: 0.293973\tBest loss: 0.285525\tAccuracy: 89.93%\n",
      "132\tValidation loss: 0.275565\tBest loss: 0.275565\tAccuracy: 91.37%\n",
      "133\tValidation loss: 0.293594\tBest loss: 0.275565\tAccuracy: 91.37%\n",
      "134\tValidation loss: 0.287403\tBest loss: 0.275565\tAccuracy: 91.37%\n",
      "135\tValidation loss: 0.288068\tBest loss: 0.275565\tAccuracy: 90.65%\n",
      "136\tValidation loss: 0.303019\tBest loss: 0.275565\tAccuracy: 91.37%\n",
      "137\tValidation loss: 0.274015\tBest loss: 0.274015\tAccuracy: 91.37%\n",
      "138\tValidation loss: 0.269207\tBest loss: 0.269207\tAccuracy: 91.37%\n",
      "139\tValidation loss: 0.266350\tBest loss: 0.266350\tAccuracy: 91.37%\n",
      "140\tValidation loss: 0.286114\tBest loss: 0.266350\tAccuracy: 92.09%\n",
      "141\tValidation loss: 0.275553\tBest loss: 0.266350\tAccuracy: 91.37%\n",
      "142\tValidation loss: 0.267477\tBest loss: 0.266350\tAccuracy: 92.81%\n",
      "143\tValidation loss: 0.265174\tBest loss: 0.265174\tAccuracy: 93.53%\n",
      "144\tValidation loss: 0.274369\tBest loss: 0.265174\tAccuracy: 92.81%\n",
      "145\tValidation loss: 0.264949\tBest loss: 0.264949\tAccuracy: 91.37%\n",
      "146\tValidation loss: 0.261753\tBest loss: 0.261753\tAccuracy: 93.53%\n",
      "147\tValidation loss: 0.250127\tBest loss: 0.250127\tAccuracy: 92.81%\n",
      "148\tValidation loss: 0.272185\tBest loss: 0.250127\tAccuracy: 90.65%\n",
      "149\tValidation loss: 0.262910\tBest loss: 0.250127\tAccuracy: 91.37%\n",
      "150\tValidation loss: 0.281638\tBest loss: 0.250127\tAccuracy: 89.93%\n",
      "151\tValidation loss: 0.273814\tBest loss: 0.250127\tAccuracy: 89.93%\n",
      "152\tValidation loss: 0.273506\tBest loss: 0.250127\tAccuracy: 92.09%\n",
      "153\tValidation loss: 0.267196\tBest loss: 0.250127\tAccuracy: 92.09%\n",
      "154\tValidation loss: 0.263549\tBest loss: 0.250127\tAccuracy: 92.09%\n",
      "155\tValidation loss: 0.248323\tBest loss: 0.248323\tAccuracy: 91.37%\n",
      "156\tValidation loss: 0.262354\tBest loss: 0.248323\tAccuracy: 92.09%\n",
      "157\tValidation loss: 0.266820\tBest loss: 0.248323\tAccuracy: 90.65%\n",
      "158\tValidation loss: 0.261541\tBest loss: 0.248323\tAccuracy: 92.09%\n",
      "159\tValidation loss: 0.258044\tBest loss: 0.248323\tAccuracy: 92.09%\n",
      "160\tValidation loss: 0.253934\tBest loss: 0.248323\tAccuracy: 91.37%\n",
      "161\tValidation loss: 0.250575\tBest loss: 0.248323\tAccuracy: 91.37%\n",
      "162\tValidation loss: 0.248325\tBest loss: 0.248323\tAccuracy: 93.53%\n",
      "163\tValidation loss: 0.245375\tBest loss: 0.245375\tAccuracy: 92.81%\n",
      "164\tValidation loss: 0.274403\tBest loss: 0.245375\tAccuracy: 91.37%\n",
      "165\tValidation loss: 0.262334\tBest loss: 0.245375\tAccuracy: 92.09%\n",
      "166\tValidation loss: 0.263017\tBest loss: 0.245375\tAccuracy: 91.37%\n",
      "167\tValidation loss: 0.264196\tBest loss: 0.245375\tAccuracy: 90.65%\n",
      "168\tValidation loss: 0.268753\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "169\tValidation loss: 0.253666\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "170\tValidation loss: 0.266336\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "171\tValidation loss: 0.256077\tBest loss: 0.245375\tAccuracy: 92.09%\n",
      "172\tValidation loss: 0.270165\tBest loss: 0.245375\tAccuracy: 90.65%\n",
      "173\tValidation loss: 0.276681\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "174\tValidation loss: 0.264160\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "175\tValidation loss: 0.262489\tBest loss: 0.245375\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.243074\tBest loss: 0.243074\tAccuracy: 91.37%\n",
      "177\tValidation loss: 0.239539\tBest loss: 0.239539\tAccuracy: 91.37%\n",
      "178\tValidation loss: 0.249673\tBest loss: 0.239539\tAccuracy: 91.37%\n",
      "179\tValidation loss: 0.258375\tBest loss: 0.239539\tAccuracy: 90.65%\n",
      "180\tValidation loss: 0.296185\tBest loss: 0.239539\tAccuracy: 89.21%\n",
      "181\tValidation loss: 0.279547\tBest loss: 0.239539\tAccuracy: 90.65%\n",
      "182\tValidation loss: 0.258231\tBest loss: 0.239539\tAccuracy: 89.93%\n",
      "183\tValidation loss: 0.251591\tBest loss: 0.239539\tAccuracy: 92.81%\n",
      "184\tValidation loss: 0.235674\tBest loss: 0.235674\tAccuracy: 92.81%\n",
      "185\tValidation loss: 0.241808\tBest loss: 0.235674\tAccuracy: 93.53%\n",
      "186\tValidation loss: 0.253877\tBest loss: 0.235674\tAccuracy: 92.81%\n",
      "187\tValidation loss: 0.233537\tBest loss: 0.233537\tAccuracy: 91.37%\n",
      "188\tValidation loss: 0.230279\tBest loss: 0.230279\tAccuracy: 93.53%\n",
      "189\tValidation loss: 0.232740\tBest loss: 0.230279\tAccuracy: 92.81%\n",
      "190\tValidation loss: 0.234002\tBest loss: 0.230279\tAccuracy: 93.53%\n",
      "191\tValidation loss: 0.236952\tBest loss: 0.230279\tAccuracy: 92.09%\n",
      "192\tValidation loss: 0.244253\tBest loss: 0.230279\tAccuracy: 92.09%\n",
      "193\tValidation loss: 0.258286\tBest loss: 0.230279\tAccuracy: 91.37%\n",
      "194\tValidation loss: 0.248393\tBest loss: 0.230279\tAccuracy: 89.93%\n",
      "195\tValidation loss: 0.263644\tBest loss: 0.230279\tAccuracy: 90.65%\n",
      "196\tValidation loss: 0.261387\tBest loss: 0.230279\tAccuracy: 90.65%\n",
      "197\tValidation loss: 0.255611\tBest loss: 0.230279\tAccuracy: 92.09%\n",
      "198\tValidation loss: 0.242245\tBest loss: 0.230279\tAccuracy: 92.81%\n",
      "199\tValidation loss: 0.238010\tBest loss: 0.230279\tAccuracy: 93.53%\n",
      "200\tValidation loss: 0.222916\tBest loss: 0.222916\tAccuracy: 92.81%\n",
      "201\tValidation loss: 0.216149\tBest loss: 0.216149\tAccuracy: 92.81%\n",
      "202\tValidation loss: 0.219732\tBest loss: 0.216149\tAccuracy: 93.53%\n",
      "203\tValidation loss: 0.236369\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "204\tValidation loss: 0.256237\tBest loss: 0.216149\tAccuracy: 90.65%\n",
      "205\tValidation loss: 0.249449\tBest loss: 0.216149\tAccuracy: 91.37%\n",
      "206\tValidation loss: 0.255495\tBest loss: 0.216149\tAccuracy: 91.37%\n",
      "207\tValidation loss: 0.235794\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "208\tValidation loss: 0.222270\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "209\tValidation loss: 0.224308\tBest loss: 0.216149\tAccuracy: 93.53%\n",
      "210\tValidation loss: 0.229062\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "211\tValidation loss: 0.233930\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "212\tValidation loss: 0.222071\tBest loss: 0.216149\tAccuracy: 92.81%\n",
      "213\tValidation loss: 0.229045\tBest loss: 0.216149\tAccuracy: 92.81%\n",
      "214\tValidation loss: 0.226119\tBest loss: 0.216149\tAccuracy: 92.81%\n",
      "215\tValidation loss: 0.241289\tBest loss: 0.216149\tAccuracy: 94.24%\n",
      "216\tValidation loss: 0.242481\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "217\tValidation loss: 0.244297\tBest loss: 0.216149\tAccuracy: 91.37%\n",
      "218\tValidation loss: 0.241267\tBest loss: 0.216149\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.245769\tBest loss: 0.216149\tAccuracy: 90.65%\n",
      "220\tValidation loss: 0.234078\tBest loss: 0.216149\tAccuracy: 92.81%\n",
      "221\tValidation loss: 0.240705\tBest loss: 0.216149\tAccuracy: 92.09%\n",
      "222\tValidation loss: 0.256021\tBest loss: 0.216149\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  33.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4260.773926\tBest loss: 4260.773926\tAccuracy: 5.76%\n",
      "1\tValidation loss: 3.871872\tBest loss: 3.871872\tAccuracy: 2.16%\n",
      "2\tValidation loss: 3.858869\tBest loss: 3.858869\tAccuracy: 6.47%\n",
      "3\tValidation loss: 3.839460\tBest loss: 3.839460\tAccuracy: 6.47%\n",
      "4\tValidation loss: 3.821056\tBest loss: 3.821056\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.815031\tBest loss: 3.815031\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.814354\tBest loss: 3.814354\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.807791\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.809890\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.813317\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.816056\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.817462\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.818935\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.813221\tBest loss: 3.807791\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.811526\tBest loss: 3.807791\tAccuracy: 6.47%\n",
      "15\tValidation loss: 3.814036\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.812583\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.817616\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.816210\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.814231\tBest loss: 3.807791\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.817920\tBest loss: 3.807791\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.813641\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.812860\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.818095\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.817240\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.818586\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.815075\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.814438\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.812751\tBest loss: 3.807791\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   7.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 33089.648438\tBest loss: 33089.648438\tAccuracy: 2.16%\n",
      "1\tValidation loss: 3.872039\tBest loss: 3.872039\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.860034\tBest loss: 3.860034\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.841364\tBest loss: 3.841364\tAccuracy: 3.60%\n",
      "4\tValidation loss: 3.825820\tBest loss: 3.825820\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.815878\tBest loss: 3.815878\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.809962\tBest loss: 3.809962\tAccuracy: 6.47%\n",
      "7\tValidation loss: 3.810196\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.812277\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.811445\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.812699\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.810728\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.810435\tBest loss: 3.809962\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.808605\tBest loss: 3.808605\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.810610\tBest loss: 3.808605\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.810102\tBest loss: 3.808605\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.813217\tBest loss: 3.808605\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.810730\tBest loss: 3.808605\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.803182\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.807958\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.813325\tBest loss: 3.803182\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.812291\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.817734\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.815307\tBest loss: 3.803182\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.816332\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.812186\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.812384\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.809203\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.810707\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.808764\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.809764\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.808095\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.809381\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.809901\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.813676\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.808238\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.811902\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.807626\tBest loss: 3.803182\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.806314\tBest loss: 3.803182\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.810685\tBest loss: 3.803182\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   9.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 2414.520020\tBest loss: 2414.520020\tAccuracy: 5.04%\n",
      "1\tValidation loss: 3.878499\tBest loss: 3.878499\tAccuracy: 0.72%\n",
      "2\tValidation loss: 3.858448\tBest loss: 3.858448\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.839950\tBest loss: 3.839950\tAccuracy: 3.60%\n",
      "4\tValidation loss: 3.820360\tBest loss: 3.820360\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.812930\tBest loss: 3.812930\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.817072\tBest loss: 3.812930\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.818840\tBest loss: 3.812930\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.813698\tBest loss: 3.812930\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.811250\tBest loss: 3.811250\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.810971\tBest loss: 3.810971\tAccuracy: 6.47%\n",
      "11\tValidation loss: 3.814517\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.818364\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.854503\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.816077\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.816113\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "16\tValidation loss: 7.169260\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.812230\tBest loss: 3.810971\tAccuracy: 6.47%\n",
      "18\tValidation loss: 3.812158\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.817859\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.811715\tBest loss: 3.810971\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.809626\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.810745\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.811519\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.813859\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.811885\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.815140\tBest loss: 3.809626\tAccuracy: 6.47%\n",
      "27\tValidation loss: 3.813105\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.812520\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.929395\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.858285\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.815731\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.811260\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.813356\tBest loss: 3.809626\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.806510\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.811829\tBest loss: 3.806510\tAccuracy: 6.47%\n",
      "36\tValidation loss: 3.815220\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.813177\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.817068\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.816924\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.813219\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.810440\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.815674\tBest loss: 3.806510\tAccuracy: 6.47%\n",
      "43\tValidation loss: 3.814633\tBest loss: 3.806510\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\tValidation loss: 3.812086\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.810662\tBest loss: 3.806510\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.806138\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "47\tValidation loss: 8.117283\tBest loss: 3.806138\tAccuracy: 1.44%\n",
      "48\tValidation loss: 3.807827\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.806296\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.818692\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.811409\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.810230\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "53\tValidation loss: 3.811477\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "54\tValidation loss: 3.809575\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "55\tValidation loss: 3.807867\tBest loss: 3.806138\tAccuracy: 6.47%\n",
      "56\tValidation loss: 3.814563\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.818340\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "58\tValidation loss: 3.810195\tBest loss: 3.806138\tAccuracy: 6.47%\n",
      "59\tValidation loss: 3.814018\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "60\tValidation loss: 3.814392\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "61\tValidation loss: 3.816594\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "62\tValidation loss: 3.816311\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.810912\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "64\tValidation loss: 3.809741\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "65\tValidation loss: 3.811072\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "66\tValidation loss: 3.810749\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "67\tValidation loss: 3.809751\tBest loss: 3.806138\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  15.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 17183.457031\tBest loss: 17183.457031\tAccuracy: 1.44%\n",
      "1\tValidation loss: 1372.837280\tBest loss: 1372.837280\tAccuracy: 1.44%\n",
      "2\tValidation loss: 2504.947510\tBest loss: 1372.837280\tAccuracy: 2.16%\n",
      "3\tValidation loss: 6166.188965\tBest loss: 1372.837280\tAccuracy: 2.88%\n",
      "4\tValidation loss: 4616.713379\tBest loss: 1372.837280\tAccuracy: 1.44%\n",
      "5\tValidation loss: 5134.251953\tBest loss: 1372.837280\tAccuracy: 3.60%\n",
      "6\tValidation loss: 2805.272949\tBest loss: 1372.837280\tAccuracy: 2.88%\n",
      "7\tValidation loss: 5442.639648\tBest loss: 1372.837280\tAccuracy: 6.47%\n",
      "8\tValidation loss: 7717.409180\tBest loss: 1372.837280\tAccuracy: 1.44%\n",
      "9\tValidation loss: 2895.771729\tBest loss: 1372.837280\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3142.592773\tBest loss: 1372.837280\tAccuracy: 2.16%\n",
      "11\tValidation loss: 2624.495605\tBest loss: 1372.837280\tAccuracy: 0.72%\n",
      "12\tValidation loss: 2046.534546\tBest loss: 1372.837280\tAccuracy: 0.72%\n",
      "13\tValidation loss: 1180.930664\tBest loss: 1180.930664\tAccuracy: 0.00%\n",
      "14\tValidation loss: 4178.757812\tBest loss: 1180.930664\tAccuracy: 1.44%\n",
      "15\tValidation loss: 2187.812988\tBest loss: 1180.930664\tAccuracy: 2.16%\n",
      "16\tValidation loss: 3000.036133\tBest loss: 1180.930664\tAccuracy: 0.72%\n",
      "17\tValidation loss: 1832.939209\tBest loss: 1180.930664\tAccuracy: 2.16%\n",
      "18\tValidation loss: 1671.246826\tBest loss: 1180.930664\tAccuracy: 2.16%\n",
      "19\tValidation loss: 1323.960205\tBest loss: 1180.930664\tAccuracy: 0.72%\n",
      "20\tValidation loss: 909.654541\tBest loss: 909.654541\tAccuracy: 6.47%\n",
      "21\tValidation loss: 1360.311646\tBest loss: 909.654541\tAccuracy: 2.16%\n",
      "22\tValidation loss: 845.678833\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "23\tValidation loss: 1153.288086\tBest loss: 845.678833\tAccuracy: 4.32%\n",
      "24\tValidation loss: 1089.143311\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "25\tValidation loss: 1023.464844\tBest loss: 845.678833\tAccuracy: 4.32%\n",
      "26\tValidation loss: 1743.780762\tBest loss: 845.678833\tAccuracy: 2.16%\n",
      "27\tValidation loss: 1490.966553\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "28\tValidation loss: 1526.421753\tBest loss: 845.678833\tAccuracy: 0.00%\n",
      "29\tValidation loss: 1071.225220\tBest loss: 845.678833\tAccuracy: 0.72%\n",
      "30\tValidation loss: 3879.192627\tBest loss: 845.678833\tAccuracy: 0.72%\n",
      "31\tValidation loss: 3343.184082\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "32\tValidation loss: 3224.254883\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "33\tValidation loss: 3478.899170\tBest loss: 845.678833\tAccuracy: 0.72%\n",
      "34\tValidation loss: 3869.721924\tBest loss: 845.678833\tAccuracy: 2.88%\n",
      "35\tValidation loss: 3347.525391\tBest loss: 845.678833\tAccuracy: 0.72%\n",
      "36\tValidation loss: 3153.729980\tBest loss: 845.678833\tAccuracy: 2.88%\n",
      "37\tValidation loss: 2771.766602\tBest loss: 845.678833\tAccuracy: 4.32%\n",
      "38\tValidation loss: 2246.100098\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "39\tValidation loss: 2917.139160\tBest loss: 845.678833\tAccuracy: 0.00%\n",
      "40\tValidation loss: 3350.167480\tBest loss: 845.678833\tAccuracy: 1.44%\n",
      "41\tValidation loss: 3020.945801\tBest loss: 845.678833\tAccuracy: 2.16%\n",
      "42\tValidation loss: 2750.780518\tBest loss: 845.678833\tAccuracy: 2.16%\n",
      "43\tValidation loss: 1811.509155\tBest loss: 845.678833\tAccuracy: 2.16%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 18107.107422\tBest loss: 18107.107422\tAccuracy: 1.44%\n",
      "1\tValidation loss: 2484.725098\tBest loss: 2484.725098\tAccuracy: 1.44%\n",
      "2\tValidation loss: 2163.422119\tBest loss: 2163.422119\tAccuracy: 2.88%\n",
      "3\tValidation loss: 4718.937500\tBest loss: 2163.422119\tAccuracy: 2.16%\n",
      "4\tValidation loss: 4259.767578\tBest loss: 2163.422119\tAccuracy: 0.72%\n",
      "5\tValidation loss: 1779.754395\tBest loss: 1779.754395\tAccuracy: 1.44%\n",
      "6\tValidation loss: 1899.469727\tBest loss: 1779.754395\tAccuracy: 4.32%\n",
      "7\tValidation loss: 688.327393\tBest loss: 688.327393\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3244.373291\tBest loss: 688.327393\tAccuracy: 5.04%\n",
      "9\tValidation loss: 775.086975\tBest loss: 688.327393\tAccuracy: 1.44%\n",
      "10\tValidation loss: 982.080811\tBest loss: 688.327393\tAccuracy: 5.76%\n",
      "11\tValidation loss: 1990.928955\tBest loss: 688.327393\tAccuracy: 2.88%\n",
      "12\tValidation loss: 1605.342773\tBest loss: 688.327393\tAccuracy: 5.04%\n",
      "13\tValidation loss: 1873.573486\tBest loss: 688.327393\tAccuracy: 6.47%\n",
      "14\tValidation loss: 2177.331543\tBest loss: 688.327393\tAccuracy: 2.16%\n",
      "15\tValidation loss: 1915.021606\tBest loss: 688.327393\tAccuracy: 0.00%\n",
      "16\tValidation loss: 2174.501465\tBest loss: 688.327393\tAccuracy: 1.44%\n",
      "17\tValidation loss: 2102.879883\tBest loss: 688.327393\tAccuracy: 0.72%\n",
      "18\tValidation loss: 2033.825928\tBest loss: 688.327393\tAccuracy: 0.00%\n",
      "19\tValidation loss: 1761.890503\tBest loss: 688.327393\tAccuracy: 2.88%\n",
      "20\tValidation loss: 1228.839478\tBest loss: 688.327393\tAccuracy: 5.76%\n",
      "21\tValidation loss: 1416.262451\tBest loss: 688.327393\tAccuracy: 1.44%\n",
      "22\tValidation loss: 861.818115\tBest loss: 688.327393\tAccuracy: 4.32%\n",
      "23\tValidation loss: 583.208679\tBest loss: 583.208679\tAccuracy: 5.04%\n",
      "24\tValidation loss: 512.667175\tBest loss: 512.667175\tAccuracy: 1.44%\n",
      "25\tValidation loss: 321.650879\tBest loss: 321.650879\tAccuracy: 3.60%\n",
      "26\tValidation loss: 391.526794\tBest loss: 321.650879\tAccuracy: 2.16%\n",
      "27\tValidation loss: 576.923401\tBest loss: 321.650879\tAccuracy: 2.88%\n",
      "28\tValidation loss: 572.096313\tBest loss: 321.650879\tAccuracy: 0.72%\n",
      "29\tValidation loss: 1099.359985\tBest loss: 321.650879\tAccuracy: 0.72%\n",
      "30\tValidation loss: 719.555542\tBest loss: 321.650879\tAccuracy: 2.16%\n",
      "31\tValidation loss: 840.147705\tBest loss: 321.650879\tAccuracy: 6.47%\n",
      "32\tValidation loss: 596.621277\tBest loss: 321.650879\tAccuracy: 2.88%\n",
      "33\tValidation loss: 672.931396\tBest loss: 321.650879\tAccuracy: 5.76%\n",
      "34\tValidation loss: 942.007141\tBest loss: 321.650879\tAccuracy: 3.60%\n",
      "35\tValidation loss: 629.239563\tBest loss: 321.650879\tAccuracy: 8.63%\n",
      "36\tValidation loss: 592.446167\tBest loss: 321.650879\tAccuracy: 5.04%\n",
      "37\tValidation loss: 811.736877\tBest loss: 321.650879\tAccuracy: 7.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 681.110901\tBest loss: 321.650879\tAccuracy: 2.88%\n",
      "39\tValidation loss: 646.613464\tBest loss: 321.650879\tAccuracy: 1.44%\n",
      "40\tValidation loss: 700.080505\tBest loss: 321.650879\tAccuracy: 4.32%\n",
      "41\tValidation loss: 884.202393\tBest loss: 321.650879\tAccuracy: 7.19%\n",
      "42\tValidation loss: 1164.005127\tBest loss: 321.650879\tAccuracy: 2.16%\n",
      "43\tValidation loss: 947.038574\tBest loss: 321.650879\tAccuracy: 6.47%\n",
      "44\tValidation loss: 720.257507\tBest loss: 321.650879\tAccuracy: 7.91%\n",
      "45\tValidation loss: 800.683655\tBest loss: 321.650879\tAccuracy: 2.16%\n",
      "46\tValidation loss: 2109.968018\tBest loss: 321.650879\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 16419.123047\tBest loss: 16419.123047\tAccuracy: 1.44%\n",
      "1\tValidation loss: 1674.238037\tBest loss: 1674.238037\tAccuracy: 1.44%\n",
      "2\tValidation loss: 2168.029297\tBest loss: 1674.238037\tAccuracy: 1.44%\n",
      "3\tValidation loss: 3102.014404\tBest loss: 1674.238037\tAccuracy: 3.60%\n",
      "4\tValidation loss: 6370.691406\tBest loss: 1674.238037\tAccuracy: 3.60%\n",
      "5\tValidation loss: 2036.881104\tBest loss: 1674.238037\tAccuracy: 6.47%\n",
      "6\tValidation loss: 2333.496582\tBest loss: 1674.238037\tAccuracy: 1.44%\n",
      "7\tValidation loss: 1124.430908\tBest loss: 1124.430908\tAccuracy: 4.32%\n",
      "8\tValidation loss: 1042.620483\tBest loss: 1042.620483\tAccuracy: 2.16%\n",
      "9\tValidation loss: 580.737976\tBest loss: 580.737976\tAccuracy: 2.88%\n",
      "10\tValidation loss: 2227.879639\tBest loss: 580.737976\tAccuracy: 1.44%\n",
      "11\tValidation loss: 1744.624146\tBest loss: 580.737976\tAccuracy: 1.44%\n",
      "12\tValidation loss: 1831.133057\tBest loss: 580.737976\tAccuracy: 0.72%\n",
      "13\tValidation loss: 1490.117065\tBest loss: 580.737976\tAccuracy: 0.00%\n",
      "14\tValidation loss: 1061.425537\tBest loss: 580.737976\tAccuracy: 2.16%\n",
      "15\tValidation loss: 1282.927490\tBest loss: 580.737976\tAccuracy: 0.00%\n",
      "16\tValidation loss: 1395.656494\tBest loss: 580.737976\tAccuracy: 2.16%\n",
      "17\tValidation loss: 1069.116333\tBest loss: 580.737976\tAccuracy: 4.32%\n",
      "18\tValidation loss: 645.239075\tBest loss: 580.737976\tAccuracy: 5.04%\n",
      "19\tValidation loss: 1443.339233\tBest loss: 580.737976\tAccuracy: 2.88%\n",
      "20\tValidation loss: 932.469543\tBest loss: 580.737976\tAccuracy: 0.72%\n",
      "21\tValidation loss: 793.558533\tBest loss: 580.737976\tAccuracy: 3.60%\n",
      "22\tValidation loss: 962.808838\tBest loss: 580.737976\tAccuracy: 5.76%\n",
      "23\tValidation loss: 709.607239\tBest loss: 580.737976\tAccuracy: 1.44%\n",
      "24\tValidation loss: 1000.904358\tBest loss: 580.737976\tAccuracy: 3.60%\n",
      "25\tValidation loss: 1069.382812\tBest loss: 580.737976\tAccuracy: 2.16%\n",
      "26\tValidation loss: 851.152832\tBest loss: 580.737976\tAccuracy: 1.44%\n",
      "27\tValidation loss: 640.763062\tBest loss: 580.737976\tAccuracy: 4.32%\n",
      "28\tValidation loss: 578.940063\tBest loss: 578.940063\tAccuracy: 0.00%\n",
      "29\tValidation loss: 547.851929\tBest loss: 547.851929\tAccuracy: 2.88%\n",
      "30\tValidation loss: 573.648376\tBest loss: 547.851929\tAccuracy: 0.00%\n",
      "31\tValidation loss: 811.223267\tBest loss: 547.851929\tAccuracy: 2.16%\n",
      "32\tValidation loss: 761.817871\tBest loss: 547.851929\tAccuracy: 1.44%\n",
      "33\tValidation loss: 792.157288\tBest loss: 547.851929\tAccuracy: 5.76%\n",
      "34\tValidation loss: 911.733459\tBest loss: 547.851929\tAccuracy: 2.88%\n",
      "35\tValidation loss: 800.233521\tBest loss: 547.851929\tAccuracy: 2.88%\n",
      "36\tValidation loss: 728.893799\tBest loss: 547.851929\tAccuracy: 2.88%\n",
      "37\tValidation loss: 886.588867\tBest loss: 547.851929\tAccuracy: 0.72%\n",
      "38\tValidation loss: 717.155640\tBest loss: 547.851929\tAccuracy: 2.88%\n",
      "39\tValidation loss: 805.307251\tBest loss: 547.851929\tAccuracy: 0.72%\n",
      "40\tValidation loss: 615.695557\tBest loss: 547.851929\tAccuracy: 1.44%\n",
      "41\tValidation loss: 858.923828\tBest loss: 547.851929\tAccuracy: 0.72%\n",
      "42\tValidation loss: 742.844727\tBest loss: 547.851929\tAccuracy: 1.44%\n",
      "43\tValidation loss: 567.039368\tBest loss: 547.851929\tAccuracy: 2.16%\n",
      "44\tValidation loss: 679.408264\tBest loss: 547.851929\tAccuracy: 1.44%\n",
      "45\tValidation loss: 571.105286\tBest loss: 547.851929\tAccuracy: 3.60%\n",
      "46\tValidation loss: 1398.753662\tBest loss: 547.851929\tAccuracy: 3.60%\n",
      "47\tValidation loss: 820.343567\tBest loss: 547.851929\tAccuracy: 1.44%\n",
      "48\tValidation loss: 637.819519\tBest loss: 547.851929\tAccuracy: 6.47%\n",
      "49\tValidation loss: 640.821716\tBest loss: 547.851929\tAccuracy: 3.60%\n",
      "50\tValidation loss: 768.135071\tBest loss: 547.851929\tAccuracy: 7.19%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   5.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 2040.482910\tBest loss: 2040.482910\tAccuracy: 1.44%\n",
      "1\tValidation loss: 60552.843750\tBest loss: 2040.482910\tAccuracy: 6.47%\n",
      "2\tValidation loss: 33785.398438\tBest loss: 2040.482910\tAccuracy: 6.47%\n",
      "3\tValidation loss: 81237.390625\tBest loss: 2040.482910\tAccuracy: 5.04%\n",
      "4\tValidation loss: 46045.628906\tBest loss: 2040.482910\tAccuracy: 0.72%\n",
      "5\tValidation loss: 21869.089844\tBest loss: 2040.482910\tAccuracy: 5.04%\n",
      "6\tValidation loss: 20978.828125\tBest loss: 2040.482910\tAccuracy: 3.60%\n",
      "7\tValidation loss: 8677.233398\tBest loss: 2040.482910\tAccuracy: 2.88%\n",
      "8\tValidation loss: 4677.397949\tBest loss: 2040.482910\tAccuracy: 0.72%\n",
      "9\tValidation loss: 2822.938232\tBest loss: 2040.482910\tAccuracy: 2.88%\n",
      "10\tValidation loss: 4206.174805\tBest loss: 2040.482910\tAccuracy: 5.04%\n",
      "11\tValidation loss: 2543.872803\tBest loss: 2040.482910\tAccuracy: 2.16%\n",
      "12\tValidation loss: 2514.009277\tBest loss: 2040.482910\tAccuracy: 6.47%\n",
      "13\tValidation loss: 2115.208252\tBest loss: 2040.482910\tAccuracy: 2.88%\n",
      "14\tValidation loss: 1318.913940\tBest loss: 1318.913940\tAccuracy: 6.47%\n",
      "15\tValidation loss: 1790.629517\tBest loss: 1318.913940\tAccuracy: 5.04%\n",
      "16\tValidation loss: 1323.833008\tBest loss: 1318.913940\tAccuracy: 7.19%\n",
      "17\tValidation loss: 1256.172241\tBest loss: 1256.172241\tAccuracy: 0.72%\n",
      "18\tValidation loss: 1476.045776\tBest loss: 1256.172241\tAccuracy: 7.91%\n",
      "19\tValidation loss: 885.679138\tBest loss: 885.679138\tAccuracy: 2.16%\n",
      "20\tValidation loss: 1102.790283\tBest loss: 885.679138\tAccuracy: 6.47%\n",
      "21\tValidation loss: 900.402039\tBest loss: 885.679138\tAccuracy: 4.32%\n",
      "22\tValidation loss: 734.739258\tBest loss: 734.739258\tAccuracy: 10.79%\n",
      "23\tValidation loss: 1079.395630\tBest loss: 734.739258\tAccuracy: 5.76%\n",
      "24\tValidation loss: 702.384277\tBest loss: 702.384277\tAccuracy: 5.76%\n",
      "25\tValidation loss: 586.417969\tBest loss: 586.417969\tAccuracy: 6.47%\n",
      "26\tValidation loss: 483.415527\tBest loss: 483.415527\tAccuracy: 8.63%\n",
      "27\tValidation loss: 517.852600\tBest loss: 483.415527\tAccuracy: 13.67%\n",
      "28\tValidation loss: 1236.344971\tBest loss: 483.415527\tAccuracy: 0.72%\n",
      "29\tValidation loss: 966.443359\tBest loss: 483.415527\tAccuracy: 6.47%\n",
      "30\tValidation loss: 620.936707\tBest loss: 483.415527\tAccuracy: 2.16%\n",
      "31\tValidation loss: 520.327393\tBest loss: 483.415527\tAccuracy: 3.60%\n",
      "32\tValidation loss: 468.457764\tBest loss: 468.457764\tAccuracy: 9.35%\n",
      "33\tValidation loss: 570.662415\tBest loss: 468.457764\tAccuracy: 6.47%\n",
      "34\tValidation loss: 413.307220\tBest loss: 413.307220\tAccuracy: 4.32%\n",
      "35\tValidation loss: 418.246552\tBest loss: 413.307220\tAccuracy: 9.35%\n",
      "36\tValidation loss: 396.010712\tBest loss: 396.010712\tAccuracy: 5.04%\n",
      "37\tValidation loss: 365.957001\tBest loss: 365.957001\tAccuracy: 8.63%\n",
      "38\tValidation loss: 2806.783203\tBest loss: 365.957001\tAccuracy: 5.76%\n",
      "39\tValidation loss: 2369.286377\tBest loss: 365.957001\tAccuracy: 0.72%\n",
      "40\tValidation loss: 3669.967529\tBest loss: 365.957001\tAccuracy: 5.04%\n",
      "41\tValidation loss: 3561.700928\tBest loss: 365.957001\tAccuracy: 3.60%\n",
      "42\tValidation loss: 9086.325195\tBest loss: 365.957001\tAccuracy: 1.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\tValidation loss: 91115.078125\tBest loss: 365.957001\tAccuracy: 0.72%\n",
      "44\tValidation loss: 8014.605469\tBest loss: 365.957001\tAccuracy: 0.00%\n",
      "45\tValidation loss: 10586.471680\tBest loss: 365.957001\tAccuracy: 1.44%\n",
      "46\tValidation loss: 6353.544922\tBest loss: 365.957001\tAccuracy: 1.44%\n",
      "47\tValidation loss: 6930.857910\tBest loss: 365.957001\tAccuracy: 3.60%\n",
      "48\tValidation loss: 4294.694824\tBest loss: 365.957001\tAccuracy: 3.60%\n",
      "49\tValidation loss: 5869.056641\tBest loss: 365.957001\tAccuracy: 0.72%\n",
      "50\tValidation loss: 4935.137695\tBest loss: 365.957001\tAccuracy: 6.47%\n",
      "51\tValidation loss: 5994.855469\tBest loss: 365.957001\tAccuracy: 5.76%\n",
      "52\tValidation loss: 4083.319336\tBest loss: 365.957001\tAccuracy: 6.47%\n",
      "53\tValidation loss: 5007.958984\tBest loss: 365.957001\tAccuracy: 2.88%\n",
      "54\tValidation loss: 11868.273438\tBest loss: 365.957001\tAccuracy: 1.44%\n",
      "55\tValidation loss: 4871.685059\tBest loss: 365.957001\tAccuracy: 6.47%\n",
      "56\tValidation loss: 4131.070801\tBest loss: 365.957001\tAccuracy: 0.72%\n",
      "57\tValidation loss: 3397.527588\tBest loss: 365.957001\tAccuracy: 0.72%\n",
      "58\tValidation loss: 16105.792969\tBest loss: 365.957001\tAccuracy: 2.88%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   6.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 1637.789917\tBest loss: 1637.789917\tAccuracy: 1.44%\n",
      "1\tValidation loss: 58984.281250\tBest loss: 1637.789917\tAccuracy: 6.47%\n",
      "2\tValidation loss: 34956.992188\tBest loss: 1637.789917\tAccuracy: 6.47%\n",
      "3\tValidation loss: 92539.289062\tBest loss: 1637.789917\tAccuracy: 5.04%\n",
      "4\tValidation loss: 20621.697266\tBest loss: 1637.789917\tAccuracy: 5.04%\n",
      "5\tValidation loss: 6309.717773\tBest loss: 1637.789917\tAccuracy: 2.88%\n",
      "6\tValidation loss: 4086.901367\tBest loss: 1637.789917\tAccuracy: 3.60%\n",
      "7\tValidation loss: 21674.927734\tBest loss: 1637.789917\tAccuracy: 2.88%\n",
      "8\tValidation loss: 3327.326660\tBest loss: 1637.789917\tAccuracy: 1.44%\n",
      "9\tValidation loss: 2498.832764\tBest loss: 1637.789917\tAccuracy: 1.44%\n",
      "10\tValidation loss: 1975.953979\tBest loss: 1637.789917\tAccuracy: 2.16%\n",
      "11\tValidation loss: 972.343994\tBest loss: 972.343994\tAccuracy: 5.76%\n",
      "12\tValidation loss: 514.326843\tBest loss: 514.326843\tAccuracy: 2.16%\n",
      "13\tValidation loss: 556.205933\tBest loss: 514.326843\tAccuracy: 3.60%\n",
      "14\tValidation loss: 1087.330811\tBest loss: 514.326843\tAccuracy: 5.04%\n",
      "15\tValidation loss: 594.179138\tBest loss: 514.326843\tAccuracy: 4.32%\n",
      "16\tValidation loss: 502.036591\tBest loss: 502.036591\tAccuracy: 1.44%\n",
      "17\tValidation loss: 620.935608\tBest loss: 502.036591\tAccuracy: 5.04%\n",
      "18\tValidation loss: 447.603455\tBest loss: 447.603455\tAccuracy: 5.04%\n",
      "19\tValidation loss: 617.192444\tBest loss: 447.603455\tAccuracy: 7.19%\n",
      "20\tValidation loss: 486.721680\tBest loss: 447.603455\tAccuracy: 7.19%\n",
      "21\tValidation loss: 1007.445312\tBest loss: 447.603455\tAccuracy: 1.44%\n",
      "22\tValidation loss: 646.239258\tBest loss: 447.603455\tAccuracy: 0.00%\n",
      "23\tValidation loss: 562.216980\tBest loss: 447.603455\tAccuracy: 5.76%\n",
      "24\tValidation loss: 854.721008\tBest loss: 447.603455\tAccuracy: 2.16%\n",
      "25\tValidation loss: 496.221558\tBest loss: 447.603455\tAccuracy: 7.91%\n",
      "26\tValidation loss: 428.907501\tBest loss: 428.907501\tAccuracy: 6.47%\n",
      "27\tValidation loss: 1065.657349\tBest loss: 428.907501\tAccuracy: 3.60%\n",
      "28\tValidation loss: 451.672729\tBest loss: 428.907501\tAccuracy: 9.35%\n",
      "29\tValidation loss: 1034.345337\tBest loss: 428.907501\tAccuracy: 4.32%\n",
      "30\tValidation loss: 1867.905151\tBest loss: 428.907501\tAccuracy: 1.44%\n",
      "31\tValidation loss: 26735.234375\tBest loss: 428.907501\tAccuracy: 2.88%\n",
      "32\tValidation loss: 2930.858887\tBest loss: 428.907501\tAccuracy: 5.04%\n",
      "33\tValidation loss: 8092.317871\tBest loss: 428.907501\tAccuracy: 1.44%\n",
      "34\tValidation loss: 5454.219238\tBest loss: 428.907501\tAccuracy: 1.44%\n",
      "35\tValidation loss: 2329.487549\tBest loss: 428.907501\tAccuracy: 0.72%\n",
      "36\tValidation loss: 2006.171753\tBest loss: 428.907501\tAccuracy: 10.79%\n",
      "37\tValidation loss: 5795.665039\tBest loss: 428.907501\tAccuracy: 3.60%\n",
      "38\tValidation loss: 2701.250488\tBest loss: 428.907501\tAccuracy: 6.47%\n",
      "39\tValidation loss: 2797.683594\tBest loss: 428.907501\tAccuracy: 2.16%\n",
      "40\tValidation loss: 2173.247070\tBest loss: 428.907501\tAccuracy: 4.32%\n",
      "41\tValidation loss: 2139.925781\tBest loss: 428.907501\tAccuracy: 8.63%\n",
      "42\tValidation loss: 1483.086182\tBest loss: 428.907501\tAccuracy: 9.35%\n",
      "43\tValidation loss: 4554.617188\tBest loss: 428.907501\tAccuracy: 2.88%\n",
      "44\tValidation loss: 2984.271484\tBest loss: 428.907501\tAccuracy: 4.32%\n",
      "45\tValidation loss: 1441.625488\tBest loss: 428.907501\tAccuracy: 9.35%\n",
      "46\tValidation loss: 1608.281982\tBest loss: 428.907501\tAccuracy: 5.76%\n",
      "47\tValidation loss: 17805.496094\tBest loss: 428.907501\tAccuracy: 5.76%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 1766.039795\tBest loss: 1766.039795\tAccuracy: 5.04%\n",
      "1\tValidation loss: 28344.449219\tBest loss: 1766.039795\tAccuracy: 6.47%\n",
      "2\tValidation loss: 28587.492188\tBest loss: 1766.039795\tAccuracy: 6.47%\n",
      "3\tValidation loss: 112825.445312\tBest loss: 1766.039795\tAccuracy: 2.16%\n",
      "4\tValidation loss: 69279.984375\tBest loss: 1766.039795\tAccuracy: 5.76%\n",
      "5\tValidation loss: 10034.406250\tBest loss: 1766.039795\tAccuracy: 5.04%\n",
      "6\tValidation loss: 8309.741211\tBest loss: 1766.039795\tAccuracy: 0.72%\n",
      "7\tValidation loss: 1200.189697\tBest loss: 1200.189697\tAccuracy: 2.16%\n",
      "8\tValidation loss: 2006.080078\tBest loss: 1200.189697\tAccuracy: 1.44%\n",
      "9\tValidation loss: 2191.613525\tBest loss: 1200.189697\tAccuracy: 0.72%\n",
      "10\tValidation loss: 1482.724243\tBest loss: 1200.189697\tAccuracy: 1.44%\n",
      "11\tValidation loss: 1009.413940\tBest loss: 1009.413940\tAccuracy: 4.32%\n",
      "12\tValidation loss: 1396.963501\tBest loss: 1009.413940\tAccuracy: 1.44%\n",
      "13\tValidation loss: 2913.102051\tBest loss: 1009.413940\tAccuracy: 2.16%\n",
      "14\tValidation loss: 1378.438721\tBest loss: 1009.413940\tAccuracy: 4.32%\n",
      "15\tValidation loss: 1235.491089\tBest loss: 1009.413940\tAccuracy: 6.47%\n",
      "16\tValidation loss: 1509.674194\tBest loss: 1009.413940\tAccuracy: 1.44%\n",
      "17\tValidation loss: 771.265320\tBest loss: 771.265320\tAccuracy: 0.72%\n",
      "18\tValidation loss: 546.480408\tBest loss: 546.480408\tAccuracy: 1.44%\n",
      "19\tValidation loss: 663.526001\tBest loss: 546.480408\tAccuracy: 1.44%\n",
      "20\tValidation loss: 427.389984\tBest loss: 427.389984\tAccuracy: 6.47%\n",
      "21\tValidation loss: 535.565796\tBest loss: 427.389984\tAccuracy: 2.88%\n",
      "22\tValidation loss: 309.928070\tBest loss: 309.928070\tAccuracy: 0.72%\n",
      "23\tValidation loss: 505.976044\tBest loss: 309.928070\tAccuracy: 0.72%\n",
      "24\tValidation loss: 455.520203\tBest loss: 309.928070\tAccuracy: 2.88%\n",
      "25\tValidation loss: 643.324341\tBest loss: 309.928070\tAccuracy: 2.16%\n",
      "26\tValidation loss: 1944.613281\tBest loss: 309.928070\tAccuracy: 2.16%\n",
      "27\tValidation loss: 501.334747\tBest loss: 309.928070\tAccuracy: 8.63%\n",
      "28\tValidation loss: 1297.677246\tBest loss: 309.928070\tAccuracy: 0.00%\n",
      "29\tValidation loss: 3210.493408\tBest loss: 309.928070\tAccuracy: 2.16%\n",
      "30\tValidation loss: 5385.664062\tBest loss: 309.928070\tAccuracy: 0.72%\n",
      "31\tValidation loss: 770.804321\tBest loss: 309.928070\tAccuracy: 6.47%\n",
      "32\tValidation loss: 1101.495239\tBest loss: 309.928070\tAccuracy: 7.19%\n",
      "33\tValidation loss: 1697.920410\tBest loss: 309.928070\tAccuracy: 1.44%\n",
      "34\tValidation loss: 1191.210815\tBest loss: 309.928070\tAccuracy: 5.76%\n",
      "35\tValidation loss: 759.149048\tBest loss: 309.928070\tAccuracy: 6.47%\n",
      "36\tValidation loss: 7062.851562\tBest loss: 309.928070\tAccuracy: 2.16%\n",
      "37\tValidation loss: 2595.155029\tBest loss: 309.928070\tAccuracy: 6.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 4896.802734\tBest loss: 309.928070\tAccuracy: 6.47%\n",
      "39\tValidation loss: 4072.391357\tBest loss: 309.928070\tAccuracy: 1.44%\n",
      "40\tValidation loss: 2667.138428\tBest loss: 309.928070\tAccuracy: 7.19%\n",
      "41\tValidation loss: 3433.732178\tBest loss: 309.928070\tAccuracy: 0.72%\n",
      "42\tValidation loss: 1521.869751\tBest loss: 309.928070\tAccuracy: 6.47%\n",
      "43\tValidation loss: 1638.528320\tBest loss: 309.928070\tAccuracy: 2.88%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   5.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 66.391403\tBest loss: 66.391403\tAccuracy: 4.32%\n",
      "1\tValidation loss: 26.313488\tBest loss: 26.313488\tAccuracy: 5.76%\n",
      "2\tValidation loss: 3.824061\tBest loss: 3.824061\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.853095\tBest loss: 3.824061\tAccuracy: 3.60%\n",
      "4\tValidation loss: 3.830846\tBest loss: 3.824061\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.841349\tBest loss: 3.824061\tAccuracy: 3.60%\n",
      "6\tValidation loss: 22.688040\tBest loss: 3.824061\tAccuracy: 1.44%\n",
      "7\tValidation loss: 3.811646\tBest loss: 3.811646\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.820310\tBest loss: 3.811646\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.830802\tBest loss: 3.811646\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.822549\tBest loss: 3.811646\tAccuracy: 3.60%\n",
      "11\tValidation loss: 555.408142\tBest loss: 3.811646\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.814470\tBest loss: 3.811646\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.820802\tBest loss: 3.811646\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.800305\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "15\tValidation loss: 616.240906\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.830663\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.840556\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.831041\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "19\tValidation loss: 3.821078\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.804591\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.804023\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "22\tValidation loss: 3.811341\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.851921\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.848070\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "25\tValidation loss: 3.842508\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.826376\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.822898\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.814289\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.827239\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.826030\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.825519\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "32\tValidation loss: 3.821189\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.817855\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.828031\tBest loss: 3.800305\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.817310\tBest loss: 3.800305\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   6.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 18.243408\tBest loss: 18.243408\tAccuracy: 0.72%\n",
      "1\tValidation loss: 18.921530\tBest loss: 18.243408\tAccuracy: 4.32%\n",
      "2\tValidation loss: 3.876474\tBest loss: 3.876474\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.798336\tBest loss: 3.798336\tAccuracy: 4.32%\n",
      "4\tValidation loss: 8.965645\tBest loss: 3.798336\tAccuracy: 7.91%\n",
      "5\tValidation loss: 3.830614\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.830792\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.825849\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "8\tValidation loss: 3.838242\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.837340\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "10\tValidation loss: 3.854033\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.851633\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "12\tValidation loss: 3.846496\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "13\tValidation loss: 3.842196\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.832704\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "15\tValidation loss: 723.363770\tBest loss: 3.798336\tAccuracy: 2.16%\n",
      "16\tValidation loss: 3.859930\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.846747\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.821179\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.832713\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.837199\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.844142\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.845151\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.862967\tBest loss: 3.798336\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.856121\tBest loss: 3.798336\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   4.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 6.235868\tBest loss: 6.235868\tAccuracy: 2.88%\n",
      "1\tValidation loss: 3.993997\tBest loss: 3.993997\tAccuracy: 6.47%\n",
      "2\tValidation loss: 4.040612\tBest loss: 3.993997\tAccuracy: 6.47%\n",
      "3\tValidation loss: 5.344434\tBest loss: 3.993997\tAccuracy: 3.60%\n",
      "4\tValidation loss: 3.872396\tBest loss: 3.872396\tAccuracy: 3.60%\n",
      "5\tValidation loss: 8.542308\tBest loss: 3.872396\tAccuracy: 2.88%\n",
      "6\tValidation loss: 3.866210\tBest loss: 3.866210\tAccuracy: 6.47%\n",
      "7\tValidation loss: 291.257629\tBest loss: 3.866210\tAccuracy: 5.76%\n",
      "8\tValidation loss: 3.837963\tBest loss: 3.837963\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.841330\tBest loss: 3.837963\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.836687\tBest loss: 3.836687\tAccuracy: 6.47%\n",
      "11\tValidation loss: 3.842051\tBest loss: 3.836687\tAccuracy: 6.47%\n",
      "12\tValidation loss: 3.838752\tBest loss: 3.836687\tAccuracy: 6.47%\n",
      "13\tValidation loss: 3.825013\tBest loss: 3.825013\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.819900\tBest loss: 3.819900\tAccuracy: 6.47%\n",
      "15\tValidation loss: 1349.484009\tBest loss: 3.819900\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.816073\tBest loss: 3.816073\tAccuracy: 6.47%\n",
      "17\tValidation loss: 788.660095\tBest loss: 3.816073\tAccuracy: 1.44%\n",
      "18\tValidation loss: 3.816348\tBest loss: 3.816073\tAccuracy: 6.47%\n",
      "19\tValidation loss: 3.825254\tBest loss: 3.816073\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.805722\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.809016\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "22\tValidation loss: 3.809515\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "23\tValidation loss: 3.814797\tBest loss: 3.805722\tAccuracy: 1.44%\n",
      "24\tValidation loss: 3.819220\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "25\tValidation loss: 3.807068\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "26\tValidation loss: 796.486816\tBest loss: 3.805722\tAccuracy: 2.16%\n",
      "27\tValidation loss: 3.806679\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "28\tValidation loss: 3.811919\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.808495\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.806742\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "31\tValidation loss: 572.903442\tBest loss: 3.805722\tAccuracy: 0.72%\n",
      "32\tValidation loss: 3.822167\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.820142\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.807513\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "35\tValidation loss: 3.814457\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "36\tValidation loss: 3.813694\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.813529\tBest loss: 3.805722\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 3.822193\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.820587\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.812569\tBest loss: 3.805722\tAccuracy: 6.47%\n",
      "41\tValidation loss: 3.808083\tBest loss: 3.805722\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   8.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 1448.369751\tBest loss: 1448.369751\tAccuracy: 3.60%\n",
      "1\tValidation loss: 4.044550\tBest loss: 4.044550\tAccuracy: 0.00%\n",
      "2\tValidation loss: 3.872005\tBest loss: 3.872005\tAccuracy: 2.16%\n",
      "3\tValidation loss: 5.508413\tBest loss: 3.872005\tAccuracy: 5.76%\n",
      "4\tValidation loss: 3.861933\tBest loss: 3.861933\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.844621\tBest loss: 3.844621\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.831549\tBest loss: 3.831549\tAccuracy: 6.47%\n",
      "7\tValidation loss: 3.819106\tBest loss: 3.819106\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.807517\tBest loss: 3.807517\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.812622\tBest loss: 3.807517\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.812877\tBest loss: 3.807517\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.818783\tBest loss: 3.807517\tAccuracy: 3.60%\n",
      "12\tValidation loss: 5.005172\tBest loss: 3.807517\tAccuracy: 1.44%\n",
      "13\tValidation loss: 3.810162\tBest loss: 3.807517\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.805642\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.812839\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.812250\tBest loss: 3.805642\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.848157\tBest loss: 3.805642\tAccuracy: 6.47%\n",
      "18\tValidation loss: 3.818277\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.814160\tBest loss: 3.805642\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.807170\tBest loss: 3.805642\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.808119\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.821052\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.817166\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.816022\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.821874\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.841198\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.821115\tBest loss: 3.805642\tAccuracy: 6.47%\n",
      "28\tValidation loss: 3.814382\tBest loss: 3.805642\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.799182\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "30\tValidation loss: 3.807313\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "31\tValidation loss: 3.816476\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "32\tValidation loss: 3.837663\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.813913\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "34\tValidation loss: 4.036755\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.845211\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "36\tValidation loss: 3.874474\tBest loss: 3.799182\tAccuracy: 5.04%\n",
      "37\tValidation loss: 3.799826\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.805973\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.802320\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "40\tValidation loss: 3.802536\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "41\tValidation loss: 3.814209\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "42\tValidation loss: 3.822185\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.817102\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.811277\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.810176\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "46\tValidation loss: 3.815289\tBest loss: 3.799182\tAccuracy: 6.47%\n",
      "47\tValidation loss: 3.809855\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.829011\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.808633\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.813210\tBest loss: 3.799182\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   6.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 312819.218750\tBest loss: 312819.218750\tAccuracy: 0.72%\n",
      "1\tValidation loss: 3.895471\tBest loss: 3.895471\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.875813\tBest loss: 3.875813\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.864208\tBest loss: 3.864208\tAccuracy: 1.44%\n",
      "4\tValidation loss: 3.854204\tBest loss: 3.854204\tAccuracy: 6.47%\n",
      "5\tValidation loss: 3.845140\tBest loss: 3.845140\tAccuracy: 6.47%\n",
      "6\tValidation loss: 3.833122\tBest loss: 3.833122\tAccuracy: 6.47%\n",
      "7\tValidation loss: 3.827855\tBest loss: 3.827855\tAccuracy: 6.47%\n",
      "8\tValidation loss: 3.817259\tBest loss: 3.817259\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.816737\tBest loss: 3.816737\tAccuracy: 6.47%\n",
      "10\tValidation loss: 3.821748\tBest loss: 3.816737\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.812431\tBest loss: 3.812431\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.828008\tBest loss: 3.812431\tAccuracy: 1.44%\n",
      "13\tValidation loss: 3.815741\tBest loss: 3.812431\tAccuracy: 1.44%\n",
      "14\tValidation loss: 3.802492\tBest loss: 3.802492\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.799519\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.808023\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "17\tValidation loss: 4.106327\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "18\tValidation loss: 4.142258\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "19\tValidation loss: 3.834322\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.817397\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.810595\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.816298\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "23\tValidation loss: 3.811306\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.818553\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.805036\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.810572\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.847975\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.802461\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "29\tValidation loss: 3.808830\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.812594\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.803318\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.810757\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.809344\tBest loss: 3.799519\tAccuracy: 6.47%\n",
      "34\tValidation loss: 3.815114\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.804343\tBest loss: 3.799519\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.810402\tBest loss: 3.799519\tAccuracy: 5.76%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 173.214218\tBest loss: 173.214218\tAccuracy: 2.88%\n",
      "1\tValidation loss: 11.582639\tBest loss: 11.582639\tAccuracy: 0.72%\n",
      "2\tValidation loss: 8.611062\tBest loss: 8.611062\tAccuracy: 2.16%\n",
      "3\tValidation loss: 8.512115\tBest loss: 8.512115\tAccuracy: 2.88%\n",
      "4\tValidation loss: 3.866870\tBest loss: 3.866870\tAccuracy: 2.88%\n",
      "5\tValidation loss: 3.881497\tBest loss: 3.866870\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.847564\tBest loss: 3.847564\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.822472\tBest loss: 3.822472\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.817496\tBest loss: 3.817496\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.804851\tBest loss: 3.804851\tAccuracy: 6.47%\n",
      "10\tValidation loss: 4.863107\tBest loss: 3.804851\tAccuracy: 6.47%\n",
      "11\tValidation loss: 3.829978\tBest loss: 3.804851\tAccuracy: 2.16%\n",
      "12\tValidation loss: 3.878481\tBest loss: 3.804851\tAccuracy: 6.47%\n",
      "13\tValidation loss: 3.814663\tBest loss: 3.804851\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\tValidation loss: 3.812418\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.816298\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.815249\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.810501\tBest loss: 3.804851\tAccuracy: 6.47%\n",
      "18\tValidation loss: 3.813683\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "19\tValidation loss: 4.146570\tBest loss: 3.804851\tAccuracy: 2.16%\n",
      "20\tValidation loss: 3.856963\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.833178\tBest loss: 3.804851\tAccuracy: 6.47%\n",
      "22\tValidation loss: 3.816703\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.851464\tBest loss: 3.804851\tAccuracy: 1.44%\n",
      "24\tValidation loss: 4.793091\tBest loss: 3.804851\tAccuracy: 2.16%\n",
      "25\tValidation loss: 3.829546\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.823681\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.830374\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.811436\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.809865\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.824153\tBest loss: 3.804851\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.2, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   4.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 244.848572\tBest loss: 244.848572\tAccuracy: 0.72%\n",
      "1\tValidation loss: 249.191223\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "2\tValidation loss: 275.931976\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "3\tValidation loss: 342.934143\tBest loss: 244.848572\tAccuracy: 2.16%\n",
      "4\tValidation loss: 295.326935\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "5\tValidation loss: 290.571472\tBest loss: 244.848572\tAccuracy: 0.72%\n",
      "6\tValidation loss: 365.157745\tBest loss: 244.848572\tAccuracy: 1.44%\n",
      "7\tValidation loss: 307.092041\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "8\tValidation loss: 287.646454\tBest loss: 244.848572\tAccuracy: 0.72%\n",
      "9\tValidation loss: 309.000244\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "10\tValidation loss: 425.747375\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "11\tValidation loss: 266.124512\tBest loss: 244.848572\tAccuracy: 6.47%\n",
      "12\tValidation loss: 340.801086\tBest loss: 244.848572\tAccuracy: 5.76%\n",
      "13\tValidation loss: 321.410919\tBest loss: 244.848572\tAccuracy: 3.60%\n",
      "14\tValidation loss: 357.651215\tBest loss: 244.848572\tAccuracy: 0.72%\n",
      "15\tValidation loss: 237.745590\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "16\tValidation loss: 281.663483\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "17\tValidation loss: 463.786041\tBest loss: 237.745590\tAccuracy: 0.00%\n",
      "18\tValidation loss: 418.376556\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "19\tValidation loss: 385.682251\tBest loss: 237.745590\tAccuracy: 0.00%\n",
      "20\tValidation loss: 415.166687\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "21\tValidation loss: 295.429016\tBest loss: 237.745590\tAccuracy: 2.16%\n",
      "22\tValidation loss: 300.691833\tBest loss: 237.745590\tAccuracy: 6.47%\n",
      "23\tValidation loss: 374.745453\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "24\tValidation loss: 270.231964\tBest loss: 237.745590\tAccuracy: 0.00%\n",
      "25\tValidation loss: 386.659332\tBest loss: 237.745590\tAccuracy: 0.72%\n",
      "26\tValidation loss: 228.604858\tBest loss: 228.604858\tAccuracy: 0.00%\n",
      "27\tValidation loss: 258.801117\tBest loss: 228.604858\tAccuracy: 2.16%\n",
      "28\tValidation loss: 275.344086\tBest loss: 228.604858\tAccuracy: 0.72%\n",
      "29\tValidation loss: 389.014801\tBest loss: 228.604858\tAccuracy: 2.16%\n",
      "30\tValidation loss: 356.689758\tBest loss: 228.604858\tAccuracy: 1.44%\n",
      "31\tValidation loss: 215.152344\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "32\tValidation loss: 304.153839\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "33\tValidation loss: 320.951599\tBest loss: 215.152344\tAccuracy: 2.16%\n",
      "34\tValidation loss: 381.183258\tBest loss: 215.152344\tAccuracy: 1.44%\n",
      "35\tValidation loss: 351.152191\tBest loss: 215.152344\tAccuracy: 2.16%\n",
      "36\tValidation loss: 479.378052\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "37\tValidation loss: 327.309723\tBest loss: 215.152344\tAccuracy: 5.76%\n",
      "38\tValidation loss: 401.488953\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "39\tValidation loss: 321.329865\tBest loss: 215.152344\tAccuracy: 3.60%\n",
      "40\tValidation loss: 375.215881\tBest loss: 215.152344\tAccuracy: 1.44%\n",
      "41\tValidation loss: 268.445709\tBest loss: 215.152344\tAccuracy: 2.88%\n",
      "42\tValidation loss: 361.841583\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "43\tValidation loss: 475.968506\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "44\tValidation loss: 297.271301\tBest loss: 215.152344\tAccuracy: 5.76%\n",
      "45\tValidation loss: 405.007965\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "46\tValidation loss: 247.400635\tBest loss: 215.152344\tAccuracy: 5.76%\n",
      "47\tValidation loss: 473.826721\tBest loss: 215.152344\tAccuracy: 5.76%\n",
      "48\tValidation loss: 313.618073\tBest loss: 215.152344\tAccuracy: 0.72%\n",
      "49\tValidation loss: 274.261841\tBest loss: 215.152344\tAccuracy: 2.16%\n",
      "50\tValidation loss: 291.761108\tBest loss: 215.152344\tAccuracy: 1.44%\n",
      "51\tValidation loss: 199.182114\tBest loss: 199.182114\tAccuracy: 1.44%\n",
      "52\tValidation loss: 398.765594\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "53\tValidation loss: 319.944794\tBest loss: 199.182114\tAccuracy: 0.72%\n",
      "54\tValidation loss: 352.478210\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "55\tValidation loss: 318.934021\tBest loss: 199.182114\tAccuracy: 0.72%\n",
      "56\tValidation loss: 270.527832\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "57\tValidation loss: 371.401703\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "58\tValidation loss: 330.709381\tBest loss: 199.182114\tAccuracy: 0.72%\n",
      "59\tValidation loss: 417.817566\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "60\tValidation loss: 279.947052\tBest loss: 199.182114\tAccuracy: 0.72%\n",
      "61\tValidation loss: 361.516479\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "62\tValidation loss: 215.290863\tBest loss: 199.182114\tAccuracy: 0.00%\n",
      "63\tValidation loss: 260.992126\tBest loss: 199.182114\tAccuracy: 0.72%\n",
      "64\tValidation loss: 229.178970\tBest loss: 199.182114\tAccuracy: 2.88%\n",
      "65\tValidation loss: 258.336548\tBest loss: 199.182114\tAccuracy: 1.44%\n",
      "66\tValidation loss: 237.449051\tBest loss: 199.182114\tAccuracy: 5.76%\n",
      "67\tValidation loss: 261.550842\tBest loss: 199.182114\tAccuracy: 2.16%\n",
      "68\tValidation loss: 539.196289\tBest loss: 199.182114\tAccuracy: 1.44%\n",
      "69\tValidation loss: 408.349030\tBest loss: 199.182114\tAccuracy: 1.44%\n",
      "70\tValidation loss: 298.083038\tBest loss: 199.182114\tAccuracy: 6.47%\n",
      "71\tValidation loss: 358.598267\tBest loss: 199.182114\tAccuracy: 3.60%\n",
      "72\tValidation loss: 456.187164\tBest loss: 199.182114\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  37.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 221.963669\tBest loss: 221.963669\tAccuracy: 1.44%\n",
      "1\tValidation loss: 288.199280\tBest loss: 221.963669\tAccuracy: 0.72%\n",
      "2\tValidation loss: 373.012421\tBest loss: 221.963669\tAccuracy: 1.44%\n",
      "3\tValidation loss: 365.312378\tBest loss: 221.963669\tAccuracy: 3.60%\n",
      "4\tValidation loss: 355.840576\tBest loss: 221.963669\tAccuracy: 2.16%\n",
      "5\tValidation loss: 181.113205\tBest loss: 181.113205\tAccuracy: 4.32%\n",
      "6\tValidation loss: 243.951416\tBest loss: 181.113205\tAccuracy: 6.47%\n",
      "7\tValidation loss: 282.044678\tBest loss: 181.113205\tAccuracy: 5.76%\n",
      "8\tValidation loss: 368.716888\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "9\tValidation loss: 335.197449\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "10\tValidation loss: 208.527054\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "11\tValidation loss: 438.086670\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "12\tValidation loss: 445.876495\tBest loss: 181.113205\tAccuracy: 2.88%\n",
      "13\tValidation loss: 382.847595\tBest loss: 181.113205\tAccuracy: 2.16%\n",
      "14\tValidation loss: 277.870789\tBest loss: 181.113205\tAccuracy: 0.00%\n",
      "15\tValidation loss: 321.110016\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "16\tValidation loss: 341.337097\tBest loss: 181.113205\tAccuracy: 0.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\tValidation loss: 293.911407\tBest loss: 181.113205\tAccuracy: 6.47%\n",
      "18\tValidation loss: 305.440125\tBest loss: 181.113205\tAccuracy: 0.00%\n",
      "19\tValidation loss: 345.259552\tBest loss: 181.113205\tAccuracy: 1.44%\n",
      "20\tValidation loss: 381.227844\tBest loss: 181.113205\tAccuracy: 3.60%\n",
      "21\tValidation loss: 326.279419\tBest loss: 181.113205\tAccuracy: 5.04%\n",
      "22\tValidation loss: 287.467407\tBest loss: 181.113205\tAccuracy: 2.16%\n",
      "23\tValidation loss: 352.190247\tBest loss: 181.113205\tAccuracy: 0.00%\n",
      "24\tValidation loss: 415.697571\tBest loss: 181.113205\tAccuracy: 0.72%\n",
      "25\tValidation loss: 360.142700\tBest loss: 181.113205\tAccuracy: 0.72%\n",
      "26\tValidation loss: 276.987366\tBest loss: 181.113205\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  14.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 172.840912\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "1\tValidation loss: 396.516174\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "2\tValidation loss: 259.690918\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "3\tValidation loss: 422.046112\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "4\tValidation loss: 374.713989\tBest loss: 172.840912\tAccuracy: 3.60%\n",
      "5\tValidation loss: 357.986725\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "6\tValidation loss: 283.166931\tBest loss: 172.840912\tAccuracy: 3.60%\n",
      "7\tValidation loss: 423.955200\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "8\tValidation loss: 457.610229\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "9\tValidation loss: 231.424530\tBest loss: 172.840912\tAccuracy: 0.00%\n",
      "10\tValidation loss: 364.555786\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "11\tValidation loss: 357.434296\tBest loss: 172.840912\tAccuracy: 3.60%\n",
      "12\tValidation loss: 403.085480\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "13\tValidation loss: 286.703064\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "14\tValidation loss: 231.950211\tBest loss: 172.840912\tAccuracy: 2.16%\n",
      "15\tValidation loss: 419.790894\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "16\tValidation loss: 398.267517\tBest loss: 172.840912\tAccuracy: 1.44%\n",
      "17\tValidation loss: 226.211411\tBest loss: 172.840912\tAccuracy: 2.16%\n",
      "18\tValidation loss: 308.793121\tBest loss: 172.840912\tAccuracy: 3.60%\n",
      "19\tValidation loss: 321.405579\tBest loss: 172.840912\tAccuracy: 0.72%\n",
      "20\tValidation loss: 234.437317\tBest loss: 172.840912\tAccuracy: 2.88%\n",
      "21\tValidation loss: 392.543060\tBest loss: 172.840912\tAccuracy: 5.76%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.3, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  12.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 149.243881\tBest loss: 149.243881\tAccuracy: 41.01%\n",
      "1\tValidation loss: 13.022841\tBest loss: 13.022841\tAccuracy: 76.98%\n",
      "2\tValidation loss: 3.064739\tBest loss: 3.064739\tAccuracy: 85.61%\n",
      "3\tValidation loss: 2.273248\tBest loss: 2.273248\tAccuracy: 87.77%\n",
      "4\tValidation loss: 1.692203\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "5\tValidation loss: 1.711377\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "6\tValidation loss: 1.706171\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "7\tValidation loss: 1.747848\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "8\tValidation loss: 1.835517\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "9\tValidation loss: 1.920583\tBest loss: 1.692203\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.312274\tBest loss: 1.312274\tAccuracy: 92.81%\n",
      "11\tValidation loss: 1.345087\tBest loss: 1.312274\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.337866\tBest loss: 1.312274\tAccuracy: 91.37%\n",
      "13\tValidation loss: 1.294053\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "14\tValidation loss: 1.311133\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "15\tValidation loss: 1.415579\tBest loss: 1.294053\tAccuracy: 92.09%\n",
      "16\tValidation loss: 1.386243\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "17\tValidation loss: 1.367903\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "18\tValidation loss: 1.358055\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "19\tValidation loss: 1.336080\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "20\tValidation loss: 1.333977\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "21\tValidation loss: 1.313326\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "22\tValidation loss: 1.305875\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "23\tValidation loss: 1.292080\tBest loss: 1.292080\tAccuracy: 92.81%\n",
      "24\tValidation loss: 1.282079\tBest loss: 1.282079\tAccuracy: 92.81%\n",
      "25\tValidation loss: 1.264940\tBest loss: 1.264940\tAccuracy: 92.81%\n",
      "26\tValidation loss: 1.251236\tBest loss: 1.251236\tAccuracy: 92.81%\n",
      "27\tValidation loss: 1.237349\tBest loss: 1.237349\tAccuracy: 92.81%\n",
      "28\tValidation loss: 1.230950\tBest loss: 1.230950\tAccuracy: 92.81%\n",
      "29\tValidation loss: 1.225333\tBest loss: 1.225333\tAccuracy: 92.81%\n",
      "30\tValidation loss: 1.221472\tBest loss: 1.221472\tAccuracy: 92.81%\n",
      "31\tValidation loss: 1.219496\tBest loss: 1.219496\tAccuracy: 92.81%\n",
      "32\tValidation loss: 1.217501\tBest loss: 1.217501\tAccuracy: 92.81%\n",
      "33\tValidation loss: 1.215930\tBest loss: 1.215930\tAccuracy: 92.81%\n",
      "34\tValidation loss: 1.213558\tBest loss: 1.213558\tAccuracy: 92.81%\n",
      "35\tValidation loss: 1.212316\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "36\tValidation loss: 1.213393\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "37\tValidation loss: 1.214216\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "38\tValidation loss: 1.212729\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "39\tValidation loss: 1.212647\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "40\tValidation loss: 1.213709\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "41\tValidation loss: 1.213682\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "42\tValidation loss: 1.213243\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "43\tValidation loss: 1.213021\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "44\tValidation loss: 1.213771\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "45\tValidation loss: 1.214675\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "46\tValidation loss: 1.215699\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "47\tValidation loss: 1.216275\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "48\tValidation loss: 1.216820\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "49\tValidation loss: 1.217206\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "50\tValidation loss: 1.217296\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "51\tValidation loss: 1.217452\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "52\tValidation loss: 1.217616\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "53\tValidation loss: 1.218499\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "54\tValidation loss: 1.219201\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "55\tValidation loss: 1.219641\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "56\tValidation loss: 1.220639\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   6.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 106.085571\tBest loss: 106.085571\tAccuracy: 43.17%\n",
      "1\tValidation loss: 7.470767\tBest loss: 7.470767\tAccuracy: 80.58%\n",
      "2\tValidation loss: 3.732459\tBest loss: 3.732459\tAccuracy: 84.17%\n",
      "3\tValidation loss: 2.476254\tBest loss: 2.476254\tAccuracy: 88.49%\n",
      "4\tValidation loss: 2.166965\tBest loss: 2.166965\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.884392\tBest loss: 1.884392\tAccuracy: 85.61%\n",
      "6\tValidation loss: 1.722733\tBest loss: 1.722733\tAccuracy: 88.49%\n",
      "7\tValidation loss: 1.640909\tBest loss: 1.640909\tAccuracy: 89.93%\n",
      "8\tValidation loss: 1.498040\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "9\tValidation loss: 1.592884\tBest loss: 1.498040\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.516133\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "11\tValidation loss: 1.520671\tBest loss: 1.498040\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 1.459917\tBest loss: 1.459917\tAccuracy: 89.21%\n",
      "13\tValidation loss: 1.449063\tBest loss: 1.449063\tAccuracy: 90.65%\n",
      "14\tValidation loss: 1.457271\tBest loss: 1.449063\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.442070\tBest loss: 1.442070\tAccuracy: 90.65%\n",
      "16\tValidation loss: 1.397251\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "17\tValidation loss: 1.409543\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "18\tValidation loss: 1.403412\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "19\tValidation loss: 1.399037\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "20\tValidation loss: 1.399575\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "21\tValidation loss: 1.398277\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "22\tValidation loss: 1.395848\tBest loss: 1.395848\tAccuracy: 90.65%\n",
      "23\tValidation loss: 1.395264\tBest loss: 1.395264\tAccuracy: 90.65%\n",
      "24\tValidation loss: 1.392942\tBest loss: 1.392942\tAccuracy: 90.65%\n",
      "25\tValidation loss: 1.389107\tBest loss: 1.389107\tAccuracy: 90.65%\n",
      "26\tValidation loss: 1.388084\tBest loss: 1.388084\tAccuracy: 90.65%\n",
      "27\tValidation loss: 1.388053\tBest loss: 1.388053\tAccuracy: 90.65%\n",
      "28\tValidation loss: 1.386218\tBest loss: 1.386218\tAccuracy: 90.65%\n",
      "29\tValidation loss: 1.385202\tBest loss: 1.385202\tAccuracy: 90.65%\n",
      "30\tValidation loss: 1.385309\tBest loss: 1.385202\tAccuracy: 90.65%\n",
      "31\tValidation loss: 1.384943\tBest loss: 1.384943\tAccuracy: 90.65%\n",
      "32\tValidation loss: 1.384230\tBest loss: 1.384230\tAccuracy: 90.65%\n",
      "33\tValidation loss: 1.383366\tBest loss: 1.383366\tAccuracy: 90.65%\n",
      "34\tValidation loss: 1.382838\tBest loss: 1.382838\tAccuracy: 90.65%\n",
      "35\tValidation loss: 1.382352\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "36\tValidation loss: 1.383041\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "37\tValidation loss: 1.382644\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "38\tValidation loss: 1.381945\tBest loss: 1.381945\tAccuracy: 90.65%\n",
      "39\tValidation loss: 1.381864\tBest loss: 1.381864\tAccuracy: 90.65%\n",
      "40\tValidation loss: 1.381380\tBest loss: 1.381380\tAccuracy: 89.93%\n",
      "41\tValidation loss: 1.380342\tBest loss: 1.380342\tAccuracy: 89.93%\n",
      "42\tValidation loss: 1.380001\tBest loss: 1.380001\tAccuracy: 89.93%\n",
      "43\tValidation loss: 1.379563\tBest loss: 1.379563\tAccuracy: 89.93%\n",
      "44\tValidation loss: 1.379130\tBest loss: 1.379130\tAccuracy: 89.93%\n",
      "45\tValidation loss: 1.378901\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "46\tValidation loss: 1.379094\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "47\tValidation loss: 1.378875\tBest loss: 1.378875\tAccuracy: 89.93%\n",
      "48\tValidation loss: 1.378457\tBest loss: 1.378457\tAccuracy: 89.93%\n",
      "49\tValidation loss: 1.378312\tBest loss: 1.378312\tAccuracy: 89.93%\n",
      "50\tValidation loss: 1.378067\tBest loss: 1.378067\tAccuracy: 89.93%\n",
      "51\tValidation loss: 1.377724\tBest loss: 1.377724\tAccuracy: 89.93%\n",
      "52\tValidation loss: 1.377167\tBest loss: 1.377167\tAccuracy: 89.93%\n",
      "53\tValidation loss: 1.376782\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "54\tValidation loss: 1.376867\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "55\tValidation loss: 1.376913\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "56\tValidation loss: 1.376736\tBest loss: 1.376736\tAccuracy: 89.93%\n",
      "57\tValidation loss: 1.376402\tBest loss: 1.376402\tAccuracy: 89.93%\n",
      "58\tValidation loss: 1.376336\tBest loss: 1.376336\tAccuracy: 89.93%\n",
      "59\tValidation loss: 1.375827\tBest loss: 1.375827\tAccuracy: 89.93%\n",
      "60\tValidation loss: 1.375190\tBest loss: 1.375190\tAccuracy: 89.93%\n",
      "61\tValidation loss: 1.375145\tBest loss: 1.375145\tAccuracy: 89.93%\n",
      "62\tValidation loss: 1.374501\tBest loss: 1.374501\tAccuracy: 90.65%\n",
      "63\tValidation loss: 1.374355\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "64\tValidation loss: 1.374605\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "65\tValidation loss: 1.374385\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "66\tValidation loss: 1.374017\tBest loss: 1.374017\tAccuracy: 90.65%\n",
      "67\tValidation loss: 1.373549\tBest loss: 1.373549\tAccuracy: 90.65%\n",
      "68\tValidation loss: 1.373207\tBest loss: 1.373207\tAccuracy: 90.65%\n",
      "69\tValidation loss: 1.373017\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "70\tValidation loss: 1.373183\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "71\tValidation loss: 1.373071\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "72\tValidation loss: 1.373059\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "73\tValidation loss: 1.372931\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "74\tValidation loss: 1.372952\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "75\tValidation loss: 1.372553\tBest loss: 1.372553\tAccuracy: 90.65%\n",
      "76\tValidation loss: 1.372201\tBest loss: 1.372201\tAccuracy: 90.65%\n",
      "77\tValidation loss: 1.372061\tBest loss: 1.372061\tAccuracy: 90.65%\n",
      "78\tValidation loss: 1.371762\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "79\tValidation loss: 1.371888\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "80\tValidation loss: 1.371850\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "81\tValidation loss: 1.371671\tBest loss: 1.371671\tAccuracy: 90.65%\n",
      "82\tValidation loss: 1.371479\tBest loss: 1.371479\tAccuracy: 90.65%\n",
      "83\tValidation loss: 1.371271\tBest loss: 1.371271\tAccuracy: 90.65%\n",
      "84\tValidation loss: 1.371223\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "85\tValidation loss: 1.371225\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "86\tValidation loss: 1.371065\tBest loss: 1.371065\tAccuracy: 90.65%\n",
      "87\tValidation loss: 1.370694\tBest loss: 1.370694\tAccuracy: 90.65%\n",
      "88\tValidation loss: 1.370362\tBest loss: 1.370362\tAccuracy: 90.65%\n",
      "89\tValidation loss: 1.370111\tBest loss: 1.370111\tAccuracy: 90.65%\n",
      "90\tValidation loss: 1.369944\tBest loss: 1.369944\tAccuracy: 90.65%\n",
      "91\tValidation loss: 1.369722\tBest loss: 1.369722\tAccuracy: 90.65%\n",
      "92\tValidation loss: 1.369701\tBest loss: 1.369701\tAccuracy: 90.65%\n",
      "93\tValidation loss: 1.369633\tBest loss: 1.369633\tAccuracy: 90.65%\n",
      "94\tValidation loss: 1.369630\tBest loss: 1.369630\tAccuracy: 90.65%\n",
      "95\tValidation loss: 1.369463\tBest loss: 1.369463\tAccuracy: 90.65%\n",
      "96\tValidation loss: 1.369438\tBest loss: 1.369438\tAccuracy: 90.65%\n",
      "97\tValidation loss: 1.369115\tBest loss: 1.369115\tAccuracy: 90.65%\n",
      "98\tValidation loss: 1.368974\tBest loss: 1.368974\tAccuracy: 90.65%\n",
      "99\tValidation loss: 1.368726\tBest loss: 1.368726\tAccuracy: 90.65%\n",
      "100\tValidation loss: 1.368736\tBest loss: 1.368726\tAccuracy: 90.65%\n",
      "101\tValidation loss: 1.368508\tBest loss: 1.368508\tAccuracy: 90.65%\n",
      "102\tValidation loss: 1.368246\tBest loss: 1.368246\tAccuracy: 90.65%\n",
      "103\tValidation loss: 1.368216\tBest loss: 1.368216\tAccuracy: 90.65%\n",
      "104\tValidation loss: 1.368142\tBest loss: 1.368142\tAccuracy: 90.65%\n",
      "105\tValidation loss: 1.367981\tBest loss: 1.367981\tAccuracy: 90.65%\n",
      "106\tValidation loss: 1.367801\tBest loss: 1.367801\tAccuracy: 90.65%\n",
      "107\tValidation loss: 1.367592\tBest loss: 1.367592\tAccuracy: 90.65%\n",
      "108\tValidation loss: 1.367494\tBest loss: 1.367494\tAccuracy: 90.65%\n",
      "109\tValidation loss: 1.367285\tBest loss: 1.367285\tAccuracy: 90.65%\n",
      "110\tValidation loss: 1.367244\tBest loss: 1.367244\tAccuracy: 90.65%\n",
      "111\tValidation loss: 1.367137\tBest loss: 1.367137\tAccuracy: 90.65%\n",
      "112\tValidation loss: 1.366981\tBest loss: 1.366981\tAccuracy: 90.65%\n",
      "113\tValidation loss: 1.366910\tBest loss: 1.366910\tAccuracy: 90.65%\n",
      "114\tValidation loss: 1.366804\tBest loss: 1.366804\tAccuracy: 90.65%\n",
      "115\tValidation loss: 1.366653\tBest loss: 1.366653\tAccuracy: 90.65%\n",
      "116\tValidation loss: 1.366652\tBest loss: 1.366652\tAccuracy: 90.65%\n",
      "117\tValidation loss: 1.366573\tBest loss: 1.366573\tAccuracy: 90.65%\n",
      "118\tValidation loss: 1.366432\tBest loss: 1.366432\tAccuracy: 90.65%\n",
      "119\tValidation loss: 1.366418\tBest loss: 1.366418\tAccuracy: 90.65%\n",
      "120\tValidation loss: 1.366286\tBest loss: 1.366286\tAccuracy: 90.65%\n",
      "121\tValidation loss: 1.366272\tBest loss: 1.366272\tAccuracy: 90.65%\n",
      "122\tValidation loss: 1.366105\tBest loss: 1.366105\tAccuracy: 90.65%\n",
      "123\tValidation loss: 1.365904\tBest loss: 1.365904\tAccuracy: 90.65%\n",
      "124\tValidation loss: 1.365771\tBest loss: 1.365771\tAccuracy: 90.65%\n",
      "125\tValidation loss: 1.365732\tBest loss: 1.365732\tAccuracy: 90.65%\n",
      "126\tValidation loss: 1.365605\tBest loss: 1.365605\tAccuracy: 90.65%\n",
      "127\tValidation loss: 1.365537\tBest loss: 1.365537\tAccuracy: 90.65%\n",
      "128\tValidation loss: 1.365500\tBest loss: 1.365500\tAccuracy: 90.65%\n",
      "129\tValidation loss: 1.365339\tBest loss: 1.365339\tAccuracy: 90.65%\n",
      "130\tValidation loss: 1.365180\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "131\tValidation loss: 1.365199\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "132\tValidation loss: 1.365084\tBest loss: 1.365084\tAccuracy: 90.65%\n",
      "133\tValidation loss: 1.364945\tBest loss: 1.364945\tAccuracy: 90.65%\n",
      "134\tValidation loss: 1.364810\tBest loss: 1.364810\tAccuracy: 90.65%\n",
      "135\tValidation loss: 1.364704\tBest loss: 1.364704\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\tValidation loss: 1.364617\tBest loss: 1.364617\tAccuracy: 90.65%\n",
      "137\tValidation loss: 1.364582\tBest loss: 1.364582\tAccuracy: 90.65%\n",
      "138\tValidation loss: 1.364432\tBest loss: 1.364432\tAccuracy: 90.65%\n",
      "139\tValidation loss: 1.364315\tBest loss: 1.364315\tAccuracy: 90.65%\n",
      "140\tValidation loss: 1.364292\tBest loss: 1.364292\tAccuracy: 90.65%\n",
      "141\tValidation loss: 1.364212\tBest loss: 1.364212\tAccuracy: 90.65%\n",
      "142\tValidation loss: 1.364155\tBest loss: 1.364155\tAccuracy: 90.65%\n",
      "143\tValidation loss: 1.364090\tBest loss: 1.364090\tAccuracy: 90.65%\n",
      "144\tValidation loss: 1.364098\tBest loss: 1.364090\tAccuracy: 90.65%\n",
      "145\tValidation loss: 1.364024\tBest loss: 1.364024\tAccuracy: 90.65%\n",
      "146\tValidation loss: 1.364007\tBest loss: 1.364007\tAccuracy: 90.65%\n",
      "147\tValidation loss: 1.363933\tBest loss: 1.363933\tAccuracy: 90.65%\n",
      "148\tValidation loss: 1.363901\tBest loss: 1.363901\tAccuracy: 90.65%\n",
      "149\tValidation loss: 1.363889\tBest loss: 1.363889\tAccuracy: 90.65%\n",
      "150\tValidation loss: 1.363727\tBest loss: 1.363727\tAccuracy: 90.65%\n",
      "151\tValidation loss: 1.363622\tBest loss: 1.363622\tAccuracy: 90.65%\n",
      "152\tValidation loss: 1.363590\tBest loss: 1.363590\tAccuracy: 90.65%\n",
      "153\tValidation loss: 1.363539\tBest loss: 1.363539\tAccuracy: 90.65%\n",
      "154\tValidation loss: 1.363504\tBest loss: 1.363504\tAccuracy: 90.65%\n",
      "155\tValidation loss: 1.363386\tBest loss: 1.363386\tAccuracy: 90.65%\n",
      "156\tValidation loss: 1.363268\tBest loss: 1.363268\tAccuracy: 90.65%\n",
      "157\tValidation loss: 1.363187\tBest loss: 1.363187\tAccuracy: 90.65%\n",
      "158\tValidation loss: 1.363079\tBest loss: 1.363079\tAccuracy: 90.65%\n",
      "159\tValidation loss: 1.362932\tBest loss: 1.362932\tAccuracy: 90.65%\n",
      "160\tValidation loss: 1.362914\tBest loss: 1.362914\tAccuracy: 90.65%\n",
      "161\tValidation loss: 1.362863\tBest loss: 1.362863\tAccuracy: 90.65%\n",
      "162\tValidation loss: 1.362810\tBest loss: 1.362810\tAccuracy: 90.65%\n",
      "163\tValidation loss: 1.362725\tBest loss: 1.362725\tAccuracy: 90.65%\n",
      "164\tValidation loss: 1.362710\tBest loss: 1.362710\tAccuracy: 90.65%\n",
      "165\tValidation loss: 1.362671\tBest loss: 1.362671\tAccuracy: 90.65%\n",
      "166\tValidation loss: 1.362583\tBest loss: 1.362583\tAccuracy: 90.65%\n",
      "167\tValidation loss: 1.362535\tBest loss: 1.362535\tAccuracy: 90.65%\n",
      "168\tValidation loss: 1.362468\tBest loss: 1.362468\tAccuracy: 90.65%\n",
      "169\tValidation loss: 1.362393\tBest loss: 1.362393\tAccuracy: 90.65%\n",
      "170\tValidation loss: 1.362326\tBest loss: 1.362326\tAccuracy: 90.65%\n",
      "171\tValidation loss: 1.362287\tBest loss: 1.362287\tAccuracy: 90.65%\n",
      "172\tValidation loss: 1.362193\tBest loss: 1.362193\tAccuracy: 90.65%\n",
      "173\tValidation loss: 1.362143\tBest loss: 1.362143\tAccuracy: 90.65%\n",
      "174\tValidation loss: 1.362107\tBest loss: 1.362107\tAccuracy: 90.65%\n",
      "175\tValidation loss: 1.362070\tBest loss: 1.362070\tAccuracy: 90.65%\n",
      "176\tValidation loss: 1.361972\tBest loss: 1.361972\tAccuracy: 90.65%\n",
      "177\tValidation loss: 1.361931\tBest loss: 1.361931\tAccuracy: 90.65%\n",
      "178\tValidation loss: 1.361834\tBest loss: 1.361834\tAccuracy: 90.65%\n",
      "179\tValidation loss: 1.361734\tBest loss: 1.361734\tAccuracy: 90.65%\n",
      "180\tValidation loss: 1.361679\tBest loss: 1.361679\tAccuracy: 90.65%\n",
      "181\tValidation loss: 1.361609\tBest loss: 1.361609\tAccuracy: 90.65%\n",
      "182\tValidation loss: 1.361546\tBest loss: 1.361546\tAccuracy: 90.65%\n",
      "183\tValidation loss: 1.361496\tBest loss: 1.361496\tAccuracy: 90.65%\n",
      "184\tValidation loss: 1.361399\tBest loss: 1.361399\tAccuracy: 90.65%\n",
      "185\tValidation loss: 1.361292\tBest loss: 1.361292\tAccuracy: 90.65%\n",
      "186\tValidation loss: 1.361284\tBest loss: 1.361284\tAccuracy: 90.65%\n",
      "187\tValidation loss: 1.361248\tBest loss: 1.361248\tAccuracy: 90.65%\n",
      "188\tValidation loss: 1.361247\tBest loss: 1.361247\tAccuracy: 90.65%\n",
      "189\tValidation loss: 1.361195\tBest loss: 1.361195\tAccuracy: 90.65%\n",
      "190\tValidation loss: 1.361111\tBest loss: 1.361111\tAccuracy: 90.65%\n",
      "191\tValidation loss: 1.361039\tBest loss: 1.361039\tAccuracy: 90.65%\n",
      "192\tValidation loss: 1.360950\tBest loss: 1.360950\tAccuracy: 90.65%\n",
      "193\tValidation loss: 1.360903\tBest loss: 1.360903\tAccuracy: 90.65%\n",
      "194\tValidation loss: 1.360811\tBest loss: 1.360811\tAccuracy: 90.65%\n",
      "195\tValidation loss: 1.360744\tBest loss: 1.360744\tAccuracy: 90.65%\n",
      "196\tValidation loss: 1.360727\tBest loss: 1.360727\tAccuracy: 90.65%\n",
      "197\tValidation loss: 1.360654\tBest loss: 1.360654\tAccuracy: 90.65%\n",
      "198\tValidation loss: 1.360600\tBest loss: 1.360600\tAccuracy: 90.65%\n",
      "199\tValidation loss: 1.360593\tBest loss: 1.360593\tAccuracy: 90.65%\n",
      "200\tValidation loss: 1.360552\tBest loss: 1.360552\tAccuracy: 90.65%\n",
      "201\tValidation loss: 1.360520\tBest loss: 1.360520\tAccuracy: 90.65%\n",
      "202\tValidation loss: 1.360448\tBest loss: 1.360448\tAccuracy: 90.65%\n",
      "203\tValidation loss: 1.360379\tBest loss: 1.360379\tAccuracy: 90.65%\n",
      "204\tValidation loss: 1.360336\tBest loss: 1.360336\tAccuracy: 90.65%\n",
      "205\tValidation loss: 1.360225\tBest loss: 1.360225\tAccuracy: 90.65%\n",
      "206\tValidation loss: 1.360179\tBest loss: 1.360179\tAccuracy: 90.65%\n",
      "207\tValidation loss: 1.360137\tBest loss: 1.360137\tAccuracy: 90.65%\n",
      "208\tValidation loss: 1.360098\tBest loss: 1.360098\tAccuracy: 90.65%\n",
      "209\tValidation loss: 1.360004\tBest loss: 1.360004\tAccuracy: 90.65%\n",
      "210\tValidation loss: 1.359919\tBest loss: 1.359919\tAccuracy: 90.65%\n",
      "211\tValidation loss: 1.359850\tBest loss: 1.359850\tAccuracy: 90.65%\n",
      "212\tValidation loss: 1.359799\tBest loss: 1.359799\tAccuracy: 90.65%\n",
      "213\tValidation loss: 1.359726\tBest loss: 1.359726\tAccuracy: 90.65%\n",
      "214\tValidation loss: 1.359684\tBest loss: 1.359684\tAccuracy: 90.65%\n",
      "215\tValidation loss: 1.359655\tBest loss: 1.359655\tAccuracy: 90.65%\n",
      "216\tValidation loss: 1.359659\tBest loss: 1.359655\tAccuracy: 90.65%\n",
      "217\tValidation loss: 1.359636\tBest loss: 1.359636\tAccuracy: 90.65%\n",
      "218\tValidation loss: 1.359626\tBest loss: 1.359626\tAccuracy: 90.65%\n",
      "219\tValidation loss: 1.359591\tBest loss: 1.359591\tAccuracy: 90.65%\n",
      "220\tValidation loss: 1.359488\tBest loss: 1.359488\tAccuracy: 90.65%\n",
      "221\tValidation loss: 1.359433\tBest loss: 1.359433\tAccuracy: 90.65%\n",
      "222\tValidation loss: 1.359385\tBest loss: 1.359385\tAccuracy: 90.65%\n",
      "223\tValidation loss: 1.359340\tBest loss: 1.359340\tAccuracy: 90.65%\n",
      "224\tValidation loss: 1.359300\tBest loss: 1.359300\tAccuracy: 90.65%\n",
      "225\tValidation loss: 1.359262\tBest loss: 1.359262\tAccuracy: 90.65%\n",
      "226\tValidation loss: 1.359231\tBest loss: 1.359231\tAccuracy: 90.65%\n",
      "227\tValidation loss: 1.359203\tBest loss: 1.359203\tAccuracy: 90.65%\n",
      "228\tValidation loss: 1.359148\tBest loss: 1.359148\tAccuracy: 90.65%\n",
      "229\tValidation loss: 1.359111\tBest loss: 1.359111\tAccuracy: 90.65%\n",
      "230\tValidation loss: 1.359068\tBest loss: 1.359068\tAccuracy: 90.65%\n",
      "231\tValidation loss: 1.359008\tBest loss: 1.359008\tAccuracy: 90.65%\n",
      "232\tValidation loss: 1.358955\tBest loss: 1.358955\tAccuracy: 90.65%\n",
      "233\tValidation loss: 1.358945\tBest loss: 1.358945\tAccuracy: 90.65%\n",
      "234\tValidation loss: 1.358918\tBest loss: 1.358918\tAccuracy: 90.65%\n",
      "235\tValidation loss: 1.358917\tBest loss: 1.358917\tAccuracy: 90.65%\n",
      "236\tValidation loss: 1.358853\tBest loss: 1.358853\tAccuracy: 90.65%\n",
      "237\tValidation loss: 1.358815\tBest loss: 1.358815\tAccuracy: 90.65%\n",
      "238\tValidation loss: 1.358807\tBest loss: 1.358807\tAccuracy: 90.65%\n",
      "239\tValidation loss: 1.358748\tBest loss: 1.358748\tAccuracy: 90.65%\n",
      "240\tValidation loss: 1.358672\tBest loss: 1.358672\tAccuracy: 90.65%\n",
      "241\tValidation loss: 1.358637\tBest loss: 1.358637\tAccuracy: 90.65%\n",
      "242\tValidation loss: 1.358584\tBest loss: 1.358584\tAccuracy: 90.65%\n",
      "243\tValidation loss: 1.358526\tBest loss: 1.358526\tAccuracy: 90.65%\n",
      "244\tValidation loss: 1.358477\tBest loss: 1.358477\tAccuracy: 90.65%\n",
      "245\tValidation loss: 1.358429\tBest loss: 1.358429\tAccuracy: 90.65%\n",
      "246\tValidation loss: 1.358401\tBest loss: 1.358401\tAccuracy: 90.65%\n",
      "247\tValidation loss: 1.358355\tBest loss: 1.358355\tAccuracy: 90.65%\n",
      "248\tValidation loss: 1.358315\tBest loss: 1.358315\tAccuracy: 90.65%\n",
      "249\tValidation loss: 1.358309\tBest loss: 1.358309\tAccuracy: 90.65%\n",
      "250\tValidation loss: 1.358236\tBest loss: 1.358236\tAccuracy: 90.65%\n",
      "251\tValidation loss: 1.358177\tBest loss: 1.358177\tAccuracy: 90.65%\n",
      "252\tValidation loss: 1.358171\tBest loss: 1.358171\tAccuracy: 90.65%\n",
      "253\tValidation loss: 1.358156\tBest loss: 1.358156\tAccuracy: 90.65%\n",
      "254\tValidation loss: 1.358108\tBest loss: 1.358108\tAccuracy: 90.65%\n",
      "255\tValidation loss: 1.358063\tBest loss: 1.358063\tAccuracy: 90.65%\n",
      "256\tValidation loss: 1.357976\tBest loss: 1.357976\tAccuracy: 90.65%\n",
      "257\tValidation loss: 1.357931\tBest loss: 1.357931\tAccuracy: 90.65%\n",
      "258\tValidation loss: 1.357858\tBest loss: 1.357858\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\tValidation loss: 1.357818\tBest loss: 1.357818\tAccuracy: 90.65%\n",
      "260\tValidation loss: 1.357803\tBest loss: 1.357803\tAccuracy: 90.65%\n",
      "261\tValidation loss: 1.357744\tBest loss: 1.357744\tAccuracy: 90.65%\n",
      "262\tValidation loss: 1.357704\tBest loss: 1.357704\tAccuracy: 90.65%\n",
      "263\tValidation loss: 1.357672\tBest loss: 1.357672\tAccuracy: 90.65%\n",
      "264\tValidation loss: 1.357630\tBest loss: 1.357630\tAccuracy: 90.65%\n",
      "265\tValidation loss: 1.357592\tBest loss: 1.357592\tAccuracy: 90.65%\n",
      "266\tValidation loss: 1.357564\tBest loss: 1.357564\tAccuracy: 90.65%\n",
      "267\tValidation loss: 1.357525\tBest loss: 1.357525\tAccuracy: 90.65%\n",
      "268\tValidation loss: 1.357511\tBest loss: 1.357511\tAccuracy: 90.65%\n",
      "269\tValidation loss: 1.357447\tBest loss: 1.357447\tAccuracy: 90.65%\n",
      "270\tValidation loss: 1.357448\tBest loss: 1.357447\tAccuracy: 90.65%\n",
      "271\tValidation loss: 1.357414\tBest loss: 1.357414\tAccuracy: 90.65%\n",
      "272\tValidation loss: 1.357348\tBest loss: 1.357348\tAccuracy: 90.65%\n",
      "273\tValidation loss: 1.357306\tBest loss: 1.357306\tAccuracy: 90.65%\n",
      "274\tValidation loss: 1.357242\tBest loss: 1.357242\tAccuracy: 90.65%\n",
      "275\tValidation loss: 1.357188\tBest loss: 1.357188\tAccuracy: 90.65%\n",
      "276\tValidation loss: 1.357168\tBest loss: 1.357168\tAccuracy: 90.65%\n",
      "277\tValidation loss: 1.357127\tBest loss: 1.357127\tAccuracy: 90.65%\n",
      "278\tValidation loss: 1.357076\tBest loss: 1.357076\tAccuracy: 90.65%\n",
      "279\tValidation loss: 1.357073\tBest loss: 1.357073\tAccuracy: 90.65%\n",
      "280\tValidation loss: 1.357021\tBest loss: 1.357021\tAccuracy: 90.65%\n",
      "281\tValidation loss: 1.356973\tBest loss: 1.356973\tAccuracy: 90.65%\n",
      "282\tValidation loss: 1.356917\tBest loss: 1.356917\tAccuracy: 90.65%\n",
      "283\tValidation loss: 1.356887\tBest loss: 1.356887\tAccuracy: 90.65%\n",
      "284\tValidation loss: 1.356826\tBest loss: 1.356826\tAccuracy: 90.65%\n",
      "285\tValidation loss: 1.356769\tBest loss: 1.356769\tAccuracy: 90.65%\n",
      "286\tValidation loss: 1.356751\tBest loss: 1.356751\tAccuracy: 90.65%\n",
      "287\tValidation loss: 1.356731\tBest loss: 1.356731\tAccuracy: 90.65%\n",
      "288\tValidation loss: 1.356692\tBest loss: 1.356692\tAccuracy: 90.65%\n",
      "289\tValidation loss: 1.356651\tBest loss: 1.356651\tAccuracy: 90.65%\n",
      "290\tValidation loss: 1.356633\tBest loss: 1.356633\tAccuracy: 90.65%\n",
      "291\tValidation loss: 1.356578\tBest loss: 1.356578\tAccuracy: 90.65%\n",
      "292\tValidation loss: 1.356493\tBest loss: 1.356493\tAccuracy: 90.65%\n",
      "293\tValidation loss: 1.356451\tBest loss: 1.356451\tAccuracy: 90.65%\n",
      "294\tValidation loss: 1.356450\tBest loss: 1.356450\tAccuracy: 90.65%\n",
      "295\tValidation loss: 1.356415\tBest loss: 1.356415\tAccuracy: 90.65%\n",
      "296\tValidation loss: 1.356353\tBest loss: 1.356353\tAccuracy: 90.65%\n",
      "297\tValidation loss: 1.356302\tBest loss: 1.356302\tAccuracy: 90.65%\n",
      "298\tValidation loss: 1.356250\tBest loss: 1.356250\tAccuracy: 90.65%\n",
      "299\tValidation loss: 1.356214\tBest loss: 1.356214\tAccuracy: 90.65%\n",
      "300\tValidation loss: 1.356166\tBest loss: 1.356166\tAccuracy: 90.65%\n",
      "301\tValidation loss: 1.356126\tBest loss: 1.356126\tAccuracy: 90.65%\n",
      "302\tValidation loss: 1.356100\tBest loss: 1.356100\tAccuracy: 90.65%\n",
      "303\tValidation loss: 1.356050\tBest loss: 1.356050\tAccuracy: 90.65%\n",
      "304\tValidation loss: 1.356008\tBest loss: 1.356008\tAccuracy: 90.65%\n",
      "305\tValidation loss: 1.355963\tBest loss: 1.355963\tAccuracy: 90.65%\n",
      "306\tValidation loss: 1.355914\tBest loss: 1.355914\tAccuracy: 90.65%\n",
      "307\tValidation loss: 1.355872\tBest loss: 1.355872\tAccuracy: 90.65%\n",
      "308\tValidation loss: 1.355817\tBest loss: 1.355817\tAccuracy: 90.65%\n",
      "309\tValidation loss: 1.355788\tBest loss: 1.355788\tAccuracy: 90.65%\n",
      "310\tValidation loss: 1.355756\tBest loss: 1.355756\tAccuracy: 90.65%\n",
      "311\tValidation loss: 1.355726\tBest loss: 1.355726\tAccuracy: 90.65%\n",
      "312\tValidation loss: 1.355669\tBest loss: 1.355669\tAccuracy: 90.65%\n",
      "313\tValidation loss: 1.355616\tBest loss: 1.355616\tAccuracy: 90.65%\n",
      "314\tValidation loss: 1.355590\tBest loss: 1.355590\tAccuracy: 90.65%\n",
      "315\tValidation loss: 1.355553\tBest loss: 1.355553\tAccuracy: 90.65%\n",
      "316\tValidation loss: 1.355505\tBest loss: 1.355505\tAccuracy: 90.65%\n",
      "317\tValidation loss: 1.355485\tBest loss: 1.355485\tAccuracy: 90.65%\n",
      "318\tValidation loss: 1.355468\tBest loss: 1.355468\tAccuracy: 90.65%\n",
      "319\tValidation loss: 1.355430\tBest loss: 1.355430\tAccuracy: 90.65%\n",
      "320\tValidation loss: 1.355397\tBest loss: 1.355397\tAccuracy: 90.65%\n",
      "321\tValidation loss: 1.355391\tBest loss: 1.355391\tAccuracy: 90.65%\n",
      "322\tValidation loss: 1.355370\tBest loss: 1.355370\tAccuracy: 90.65%\n",
      "323\tValidation loss: 1.355340\tBest loss: 1.355340\tAccuracy: 90.65%\n",
      "324\tValidation loss: 1.355298\tBest loss: 1.355298\tAccuracy: 90.65%\n",
      "325\tValidation loss: 1.355266\tBest loss: 1.355266\tAccuracy: 90.65%\n",
      "326\tValidation loss: 1.355245\tBest loss: 1.355245\tAccuracy: 90.65%\n",
      "327\tValidation loss: 1.355196\tBest loss: 1.355196\tAccuracy: 90.65%\n",
      "328\tValidation loss: 1.355158\tBest loss: 1.355158\tAccuracy: 90.65%\n",
      "329\tValidation loss: 1.355134\tBest loss: 1.355134\tAccuracy: 90.65%\n",
      "330\tValidation loss: 1.355118\tBest loss: 1.355118\tAccuracy: 90.65%\n",
      "331\tValidation loss: 1.355090\tBest loss: 1.355090\tAccuracy: 90.65%\n",
      "332\tValidation loss: 1.355044\tBest loss: 1.355044\tAccuracy: 90.65%\n",
      "333\tValidation loss: 1.355020\tBest loss: 1.355020\tAccuracy: 90.65%\n",
      "334\tValidation loss: 1.355002\tBest loss: 1.355002\tAccuracy: 90.65%\n",
      "335\tValidation loss: 1.354968\tBest loss: 1.354968\tAccuracy: 90.65%\n",
      "336\tValidation loss: 1.354929\tBest loss: 1.354929\tAccuracy: 90.65%\n",
      "337\tValidation loss: 1.354897\tBest loss: 1.354897\tAccuracy: 90.65%\n",
      "338\tValidation loss: 1.354860\tBest loss: 1.354860\tAccuracy: 90.65%\n",
      "339\tValidation loss: 1.354820\tBest loss: 1.354820\tAccuracy: 90.65%\n",
      "340\tValidation loss: 1.354779\tBest loss: 1.354779\tAccuracy: 90.65%\n",
      "341\tValidation loss: 1.354759\tBest loss: 1.354759\tAccuracy: 90.65%\n",
      "342\tValidation loss: 1.354709\tBest loss: 1.354709\tAccuracy: 90.65%\n",
      "343\tValidation loss: 1.354679\tBest loss: 1.354679\tAccuracy: 90.65%\n",
      "344\tValidation loss: 1.354669\tBest loss: 1.354669\tAccuracy: 90.65%\n",
      "345\tValidation loss: 1.354644\tBest loss: 1.354644\tAccuracy: 90.65%\n",
      "346\tValidation loss: 1.354612\tBest loss: 1.354612\tAccuracy: 90.65%\n",
      "347\tValidation loss: 1.354573\tBest loss: 1.354573\tAccuracy: 90.65%\n",
      "348\tValidation loss: 1.354527\tBest loss: 1.354527\tAccuracy: 90.65%\n",
      "349\tValidation loss: 1.354511\tBest loss: 1.354511\tAccuracy: 90.65%\n",
      "350\tValidation loss: 1.354487\tBest loss: 1.354487\tAccuracy: 90.65%\n",
      "351\tValidation loss: 1.354435\tBest loss: 1.354435\tAccuracy: 90.65%\n",
      "352\tValidation loss: 1.354395\tBest loss: 1.354395\tAccuracy: 90.65%\n",
      "353\tValidation loss: 1.354366\tBest loss: 1.354366\tAccuracy: 90.65%\n",
      "354\tValidation loss: 1.354362\tBest loss: 1.354362\tAccuracy: 90.65%\n",
      "355\tValidation loss: 1.354313\tBest loss: 1.354313\tAccuracy: 90.65%\n",
      "356\tValidation loss: 1.354275\tBest loss: 1.354275\tAccuracy: 90.65%\n",
      "357\tValidation loss: 1.354271\tBest loss: 1.354271\tAccuracy: 90.65%\n",
      "358\tValidation loss: 1.354235\tBest loss: 1.354235\tAccuracy: 90.65%\n",
      "359\tValidation loss: 1.354187\tBest loss: 1.354187\tAccuracy: 90.65%\n",
      "360\tValidation loss: 1.354172\tBest loss: 1.354172\tAccuracy: 90.65%\n",
      "361\tValidation loss: 1.354151\tBest loss: 1.354151\tAccuracy: 90.65%\n",
      "362\tValidation loss: 1.354128\tBest loss: 1.354128\tAccuracy: 90.65%\n",
      "363\tValidation loss: 1.354084\tBest loss: 1.354084\tAccuracy: 90.65%\n",
      "364\tValidation loss: 1.354037\tBest loss: 1.354037\tAccuracy: 90.65%\n",
      "365\tValidation loss: 1.354014\tBest loss: 1.354014\tAccuracy: 90.65%\n",
      "366\tValidation loss: 1.353944\tBest loss: 1.353944\tAccuracy: 90.65%\n",
      "367\tValidation loss: 1.353944\tBest loss: 1.353944\tAccuracy: 90.65%\n",
      "368\tValidation loss: 1.353909\tBest loss: 1.353909\tAccuracy: 90.65%\n",
      "369\tValidation loss: 1.353863\tBest loss: 1.353863\tAccuracy: 90.65%\n",
      "370\tValidation loss: 1.353847\tBest loss: 1.353847\tAccuracy: 90.65%\n",
      "371\tValidation loss: 1.353815\tBest loss: 1.353815\tAccuracy: 90.65%\n",
      "372\tValidation loss: 1.353785\tBest loss: 1.353785\tAccuracy: 90.65%\n",
      "373\tValidation loss: 1.353734\tBest loss: 1.353734\tAccuracy: 90.65%\n",
      "374\tValidation loss: 1.353717\tBest loss: 1.353717\tAccuracy: 90.65%\n",
      "375\tValidation loss: 1.353708\tBest loss: 1.353708\tAccuracy: 90.65%\n",
      "376\tValidation loss: 1.353699\tBest loss: 1.353699\tAccuracy: 90.65%\n",
      "377\tValidation loss: 1.353674\tBest loss: 1.353674\tAccuracy: 90.65%\n",
      "378\tValidation loss: 1.353634\tBest loss: 1.353634\tAccuracy: 90.65%\n",
      "379\tValidation loss: 1.353604\tBest loss: 1.353604\tAccuracy: 90.65%\n",
      "380\tValidation loss: 1.353585\tBest loss: 1.353585\tAccuracy: 90.65%\n",
      "381\tValidation loss: 1.353555\tBest loss: 1.353555\tAccuracy: 90.65%\n",
      "382\tValidation loss: 1.353521\tBest loss: 1.353521\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\tValidation loss: 1.353494\tBest loss: 1.353494\tAccuracy: 90.65%\n",
      "384\tValidation loss: 1.353480\tBest loss: 1.353480\tAccuracy: 90.65%\n",
      "385\tValidation loss: 1.353462\tBest loss: 1.353462\tAccuracy: 90.65%\n",
      "386\tValidation loss: 1.353435\tBest loss: 1.353435\tAccuracy: 90.65%\n",
      "387\tValidation loss: 1.353400\tBest loss: 1.353400\tAccuracy: 90.65%\n",
      "388\tValidation loss: 1.353373\tBest loss: 1.353373\tAccuracy: 90.65%\n",
      "389\tValidation loss: 1.353334\tBest loss: 1.353334\tAccuracy: 90.65%\n",
      "390\tValidation loss: 1.353294\tBest loss: 1.353294\tAccuracy: 90.65%\n",
      "391\tValidation loss: 1.353256\tBest loss: 1.353256\tAccuracy: 90.65%\n",
      "392\tValidation loss: 1.353237\tBest loss: 1.353237\tAccuracy: 90.65%\n",
      "393\tValidation loss: 1.353212\tBest loss: 1.353212\tAccuracy: 90.65%\n",
      "394\tValidation loss: 1.353169\tBest loss: 1.353169\tAccuracy: 90.65%\n",
      "395\tValidation loss: 1.353163\tBest loss: 1.353163\tAccuracy: 90.65%\n",
      "396\tValidation loss: 1.353143\tBest loss: 1.353143\tAccuracy: 90.65%\n",
      "397\tValidation loss: 1.353112\tBest loss: 1.353112\tAccuracy: 90.65%\n",
      "398\tValidation loss: 1.353081\tBest loss: 1.353081\tAccuracy: 90.65%\n",
      "399\tValidation loss: 1.353027\tBest loss: 1.353027\tAccuracy: 90.65%\n",
      "400\tValidation loss: 1.352988\tBest loss: 1.352988\tAccuracy: 90.65%\n",
      "401\tValidation loss: 1.352969\tBest loss: 1.352969\tAccuracy: 90.65%\n",
      "402\tValidation loss: 1.352943\tBest loss: 1.352943\tAccuracy: 90.65%\n",
      "403\tValidation loss: 1.352894\tBest loss: 1.352894\tAccuracy: 90.65%\n",
      "404\tValidation loss: 1.352871\tBest loss: 1.352871\tAccuracy: 90.65%\n",
      "405\tValidation loss: 1.352851\tBest loss: 1.352851\tAccuracy: 90.65%\n",
      "406\tValidation loss: 1.352810\tBest loss: 1.352810\tAccuracy: 90.65%\n",
      "407\tValidation loss: 1.352800\tBest loss: 1.352800\tAccuracy: 90.65%\n",
      "408\tValidation loss: 1.352789\tBest loss: 1.352789\tAccuracy: 90.65%\n",
      "409\tValidation loss: 1.352767\tBest loss: 1.352767\tAccuracy: 90.65%\n",
      "410\tValidation loss: 1.352739\tBest loss: 1.352739\tAccuracy: 90.65%\n",
      "411\tValidation loss: 1.352715\tBest loss: 1.352715\tAccuracy: 90.65%\n",
      "412\tValidation loss: 1.352697\tBest loss: 1.352697\tAccuracy: 90.65%\n",
      "413\tValidation loss: 1.352645\tBest loss: 1.352645\tAccuracy: 90.65%\n",
      "414\tValidation loss: 1.352612\tBest loss: 1.352612\tAccuracy: 90.65%\n",
      "415\tValidation loss: 1.352593\tBest loss: 1.352593\tAccuracy: 90.65%\n",
      "416\tValidation loss: 1.352552\tBest loss: 1.352552\tAccuracy: 90.65%\n",
      "417\tValidation loss: 1.352525\tBest loss: 1.352525\tAccuracy: 90.65%\n",
      "418\tValidation loss: 1.352498\tBest loss: 1.352498\tAccuracy: 90.65%\n",
      "419\tValidation loss: 1.352471\tBest loss: 1.352471\tAccuracy: 90.65%\n",
      "420\tValidation loss: 1.352439\tBest loss: 1.352439\tAccuracy: 90.65%\n",
      "421\tValidation loss: 1.352405\tBest loss: 1.352405\tAccuracy: 90.65%\n",
      "422\tValidation loss: 1.352367\tBest loss: 1.352367\tAccuracy: 90.65%\n",
      "423\tValidation loss: 1.352348\tBest loss: 1.352348\tAccuracy: 90.65%\n",
      "424\tValidation loss: 1.352332\tBest loss: 1.352332\tAccuracy: 90.65%\n",
      "425\tValidation loss: 1.352316\tBest loss: 1.352316\tAccuracy: 90.65%\n",
      "426\tValidation loss: 1.352276\tBest loss: 1.352276\tAccuracy: 90.65%\n",
      "427\tValidation loss: 1.352249\tBest loss: 1.352249\tAccuracy: 90.65%\n",
      "428\tValidation loss: 1.352201\tBest loss: 1.352201\tAccuracy: 90.65%\n",
      "429\tValidation loss: 1.352178\tBest loss: 1.352178\tAccuracy: 90.65%\n",
      "430\tValidation loss: 1.352173\tBest loss: 1.352173\tAccuracy: 90.65%\n",
      "431\tValidation loss: 1.352159\tBest loss: 1.352159\tAccuracy: 90.65%\n",
      "432\tValidation loss: 1.352123\tBest loss: 1.352123\tAccuracy: 90.65%\n",
      "433\tValidation loss: 1.352100\tBest loss: 1.352100\tAccuracy: 90.65%\n",
      "434\tValidation loss: 1.352070\tBest loss: 1.352070\tAccuracy: 90.65%\n",
      "435\tValidation loss: 1.352042\tBest loss: 1.352042\tAccuracy: 90.65%\n",
      "436\tValidation loss: 1.352006\tBest loss: 1.352006\tAccuracy: 90.65%\n",
      "437\tValidation loss: 1.352019\tBest loss: 1.352006\tAccuracy: 90.65%\n",
      "438\tValidation loss: 1.351989\tBest loss: 1.351989\tAccuracy: 90.65%\n",
      "439\tValidation loss: 1.351960\tBest loss: 1.351960\tAccuracy: 90.65%\n",
      "440\tValidation loss: 1.351941\tBest loss: 1.351941\tAccuracy: 90.65%\n",
      "441\tValidation loss: 1.351900\tBest loss: 1.351900\tAccuracy: 90.65%\n",
      "442\tValidation loss: 1.351871\tBest loss: 1.351871\tAccuracy: 90.65%\n",
      "443\tValidation loss: 1.351830\tBest loss: 1.351830\tAccuracy: 90.65%\n",
      "444\tValidation loss: 1.351819\tBest loss: 1.351819\tAccuracy: 90.65%\n",
      "445\tValidation loss: 1.351802\tBest loss: 1.351802\tAccuracy: 90.65%\n",
      "446\tValidation loss: 1.351791\tBest loss: 1.351791\tAccuracy: 90.65%\n",
      "447\tValidation loss: 1.351754\tBest loss: 1.351754\tAccuracy: 90.65%\n",
      "448\tValidation loss: 1.351730\tBest loss: 1.351730\tAccuracy: 90.65%\n",
      "449\tValidation loss: 1.351709\tBest loss: 1.351709\tAccuracy: 90.65%\n",
      "450\tValidation loss: 1.351680\tBest loss: 1.351680\tAccuracy: 90.65%\n",
      "451\tValidation loss: 1.351653\tBest loss: 1.351653\tAccuracy: 90.65%\n",
      "452\tValidation loss: 1.351626\tBest loss: 1.351626\tAccuracy: 90.65%\n",
      "453\tValidation loss: 1.351606\tBest loss: 1.351606\tAccuracy: 90.65%\n",
      "454\tValidation loss: 1.351580\tBest loss: 1.351580\tAccuracy: 90.65%\n",
      "455\tValidation loss: 1.351564\tBest loss: 1.351564\tAccuracy: 90.65%\n",
      "456\tValidation loss: 1.351530\tBest loss: 1.351530\tAccuracy: 90.65%\n",
      "457\tValidation loss: 1.351492\tBest loss: 1.351492\tAccuracy: 90.65%\n",
      "458\tValidation loss: 1.351452\tBest loss: 1.351452\tAccuracy: 90.65%\n",
      "459\tValidation loss: 1.351429\tBest loss: 1.351429\tAccuracy: 90.65%\n",
      "460\tValidation loss: 1.351408\tBest loss: 1.351408\tAccuracy: 90.65%\n",
      "461\tValidation loss: 1.351380\tBest loss: 1.351380\tAccuracy: 90.65%\n",
      "462\tValidation loss: 1.351331\tBest loss: 1.351331\tAccuracy: 90.65%\n",
      "463\tValidation loss: 1.351335\tBest loss: 1.351331\tAccuracy: 90.65%\n",
      "464\tValidation loss: 1.351301\tBest loss: 1.351301\tAccuracy: 90.65%\n",
      "465\tValidation loss: 1.351277\tBest loss: 1.351277\tAccuracy: 90.65%\n",
      "466\tValidation loss: 1.351257\tBest loss: 1.351257\tAccuracy: 90.65%\n",
      "467\tValidation loss: 1.351242\tBest loss: 1.351242\tAccuracy: 90.65%\n",
      "468\tValidation loss: 1.351233\tBest loss: 1.351233\tAccuracy: 90.65%\n",
      "469\tValidation loss: 1.351216\tBest loss: 1.351216\tAccuracy: 90.65%\n",
      "470\tValidation loss: 1.351196\tBest loss: 1.351196\tAccuracy: 90.65%\n",
      "471\tValidation loss: 1.351168\tBest loss: 1.351168\tAccuracy: 90.65%\n",
      "472\tValidation loss: 1.351148\tBest loss: 1.351148\tAccuracy: 90.65%\n",
      "473\tValidation loss: 1.351125\tBest loss: 1.351125\tAccuracy: 90.65%\n",
      "474\tValidation loss: 1.351111\tBest loss: 1.351111\tAccuracy: 90.65%\n",
      "475\tValidation loss: 1.351078\tBest loss: 1.351078\tAccuracy: 90.65%\n",
      "476\tValidation loss: 1.351060\tBest loss: 1.351060\tAccuracy: 90.65%\n",
      "477\tValidation loss: 1.351040\tBest loss: 1.351040\tAccuracy: 90.65%\n",
      "478\tValidation loss: 1.351012\tBest loss: 1.351012\tAccuracy: 90.65%\n",
      "479\tValidation loss: 1.350992\tBest loss: 1.350992\tAccuracy: 90.65%\n",
      "480\tValidation loss: 1.350981\tBest loss: 1.350981\tAccuracy: 90.65%\n",
      "481\tValidation loss: 1.350967\tBest loss: 1.350967\tAccuracy: 90.65%\n",
      "482\tValidation loss: 1.350944\tBest loss: 1.350944\tAccuracy: 90.65%\n",
      "483\tValidation loss: 1.350913\tBest loss: 1.350913\tAccuracy: 90.65%\n",
      "484\tValidation loss: 1.350889\tBest loss: 1.350889\tAccuracy: 90.65%\n",
      "485\tValidation loss: 1.350880\tBest loss: 1.350880\tAccuracy: 90.65%\n",
      "486\tValidation loss: 1.350846\tBest loss: 1.350846\tAccuracy: 90.65%\n",
      "487\tValidation loss: 1.350817\tBest loss: 1.350817\tAccuracy: 90.65%\n",
      "488\tValidation loss: 1.350785\tBest loss: 1.350785\tAccuracy: 90.65%\n",
      "489\tValidation loss: 1.350767\tBest loss: 1.350767\tAccuracy: 90.65%\n",
      "490\tValidation loss: 1.350724\tBest loss: 1.350724\tAccuracy: 90.65%\n",
      "491\tValidation loss: 1.350707\tBest loss: 1.350707\tAccuracy: 90.65%\n",
      "492\tValidation loss: 1.350664\tBest loss: 1.350664\tAccuracy: 90.65%\n",
      "493\tValidation loss: 1.350655\tBest loss: 1.350655\tAccuracy: 90.65%\n",
      "494\tValidation loss: 1.350627\tBest loss: 1.350627\tAccuracy: 90.65%\n",
      "495\tValidation loss: 1.350592\tBest loss: 1.350592\tAccuracy: 90.65%\n",
      "496\tValidation loss: 1.350575\tBest loss: 1.350575\tAccuracy: 90.65%\n",
      "497\tValidation loss: 1.350551\tBest loss: 1.350551\tAccuracy: 90.65%\n",
      "498\tValidation loss: 1.350527\tBest loss: 1.350527\tAccuracy: 90.65%\n",
      "499\tValidation loss: 1.350499\tBest loss: 1.350499\tAccuracy: 90.65%\n",
      "500\tValidation loss: 1.350463\tBest loss: 1.350463\tAccuracy: 90.65%\n",
      "501\tValidation loss: 1.350443\tBest loss: 1.350443\tAccuracy: 90.65%\n",
      "502\tValidation loss: 1.350422\tBest loss: 1.350422\tAccuracy: 90.65%\n",
      "503\tValidation loss: 1.350406\tBest loss: 1.350406\tAccuracy: 90.65%\n",
      "504\tValidation loss: 1.350378\tBest loss: 1.350378\tAccuracy: 90.65%\n",
      "505\tValidation loss: 1.350351\tBest loss: 1.350351\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\tValidation loss: 1.350332\tBest loss: 1.350332\tAccuracy: 90.65%\n",
      "507\tValidation loss: 1.350299\tBest loss: 1.350299\tAccuracy: 90.65%\n",
      "508\tValidation loss: 1.350271\tBest loss: 1.350271\tAccuracy: 90.65%\n",
      "509\tValidation loss: 1.350260\tBest loss: 1.350260\tAccuracy: 90.65%\n",
      "510\tValidation loss: 1.350244\tBest loss: 1.350244\tAccuracy: 90.65%\n",
      "511\tValidation loss: 1.350213\tBest loss: 1.350213\tAccuracy: 90.65%\n",
      "512\tValidation loss: 1.350183\tBest loss: 1.350183\tAccuracy: 90.65%\n",
      "513\tValidation loss: 1.350172\tBest loss: 1.350172\tAccuracy: 90.65%\n",
      "514\tValidation loss: 1.350157\tBest loss: 1.350157\tAccuracy: 90.65%\n",
      "515\tValidation loss: 1.350139\tBest loss: 1.350139\tAccuracy: 90.65%\n",
      "516\tValidation loss: 1.350105\tBest loss: 1.350105\tAccuracy: 90.65%\n",
      "517\tValidation loss: 1.350087\tBest loss: 1.350087\tAccuracy: 90.65%\n",
      "518\tValidation loss: 1.350051\tBest loss: 1.350051\tAccuracy: 90.65%\n",
      "519\tValidation loss: 1.350010\tBest loss: 1.350010\tAccuracy: 90.65%\n",
      "520\tValidation loss: 1.349993\tBest loss: 1.349993\tAccuracy: 90.65%\n",
      "521\tValidation loss: 1.349981\tBest loss: 1.349981\tAccuracy: 90.65%\n",
      "522\tValidation loss: 1.349957\tBest loss: 1.349957\tAccuracy: 90.65%\n",
      "523\tValidation loss: 1.349934\tBest loss: 1.349934\tAccuracy: 90.65%\n",
      "524\tValidation loss: 1.349895\tBest loss: 1.349895\tAccuracy: 90.65%\n",
      "525\tValidation loss: 1.349885\tBest loss: 1.349885\tAccuracy: 90.65%\n",
      "526\tValidation loss: 1.349852\tBest loss: 1.349852\tAccuracy: 90.65%\n",
      "527\tValidation loss: 1.349836\tBest loss: 1.349836\tAccuracy: 90.65%\n",
      "528\tValidation loss: 1.349817\tBest loss: 1.349817\tAccuracy: 90.65%\n",
      "529\tValidation loss: 1.349790\tBest loss: 1.349790\tAccuracy: 90.65%\n",
      "530\tValidation loss: 1.349777\tBest loss: 1.349777\tAccuracy: 90.65%\n",
      "531\tValidation loss: 1.349759\tBest loss: 1.349759\tAccuracy: 90.65%\n",
      "532\tValidation loss: 1.349737\tBest loss: 1.349737\tAccuracy: 90.65%\n",
      "533\tValidation loss: 1.349736\tBest loss: 1.349736\tAccuracy: 90.65%\n",
      "534\tValidation loss: 1.349720\tBest loss: 1.349720\tAccuracy: 90.65%\n",
      "535\tValidation loss: 1.349683\tBest loss: 1.349683\tAccuracy: 90.65%\n",
      "536\tValidation loss: 1.349664\tBest loss: 1.349664\tAccuracy: 90.65%\n",
      "537\tValidation loss: 1.349634\tBest loss: 1.349634\tAccuracy: 90.65%\n",
      "538\tValidation loss: 1.349625\tBest loss: 1.349625\tAccuracy: 90.65%\n",
      "539\tValidation loss: 1.349599\tBest loss: 1.349599\tAccuracy: 90.65%\n",
      "540\tValidation loss: 1.349578\tBest loss: 1.349578\tAccuracy: 90.65%\n",
      "541\tValidation loss: 1.349555\tBest loss: 1.349555\tAccuracy: 90.65%\n",
      "542\tValidation loss: 1.349527\tBest loss: 1.349527\tAccuracy: 90.65%\n",
      "543\tValidation loss: 1.349504\tBest loss: 1.349504\tAccuracy: 90.65%\n",
      "544\tValidation loss: 1.349490\tBest loss: 1.349490\tAccuracy: 90.65%\n",
      "545\tValidation loss: 1.349464\tBest loss: 1.349464\tAccuracy: 90.65%\n",
      "546\tValidation loss: 1.349448\tBest loss: 1.349448\tAccuracy: 90.65%\n",
      "547\tValidation loss: 1.349418\tBest loss: 1.349418\tAccuracy: 90.65%\n",
      "548\tValidation loss: 1.349418\tBest loss: 1.349418\tAccuracy: 90.65%\n",
      "549\tValidation loss: 1.349391\tBest loss: 1.349391\tAccuracy: 90.65%\n",
      "550\tValidation loss: 1.349371\tBest loss: 1.349371\tAccuracy: 90.65%\n",
      "551\tValidation loss: 1.349335\tBest loss: 1.349335\tAccuracy: 90.65%\n",
      "552\tValidation loss: 1.349313\tBest loss: 1.349313\tAccuracy: 90.65%\n",
      "553\tValidation loss: 1.349291\tBest loss: 1.349291\tAccuracy: 90.65%\n",
      "554\tValidation loss: 1.349268\tBest loss: 1.349268\tAccuracy: 90.65%\n",
      "555\tValidation loss: 1.349266\tBest loss: 1.349266\tAccuracy: 90.65%\n",
      "556\tValidation loss: 1.349230\tBest loss: 1.349230\tAccuracy: 90.65%\n",
      "557\tValidation loss: 1.349222\tBest loss: 1.349222\tAccuracy: 90.65%\n",
      "558\tValidation loss: 1.349188\tBest loss: 1.349188\tAccuracy: 90.65%\n",
      "559\tValidation loss: 1.349178\tBest loss: 1.349178\tAccuracy: 90.65%\n",
      "560\tValidation loss: 1.349156\tBest loss: 1.349156\tAccuracy: 90.65%\n",
      "561\tValidation loss: 1.349136\tBest loss: 1.349136\tAccuracy: 90.65%\n",
      "562\tValidation loss: 1.349128\tBest loss: 1.349128\tAccuracy: 90.65%\n",
      "563\tValidation loss: 1.349099\tBest loss: 1.349099\tAccuracy: 90.65%\n",
      "564\tValidation loss: 1.349081\tBest loss: 1.349081\tAccuracy: 90.65%\n",
      "565\tValidation loss: 1.349065\tBest loss: 1.349065\tAccuracy: 91.37%\n",
      "566\tValidation loss: 1.349051\tBest loss: 1.349051\tAccuracy: 91.37%\n",
      "567\tValidation loss: 1.349023\tBest loss: 1.349023\tAccuracy: 91.37%\n",
      "568\tValidation loss: 1.349004\tBest loss: 1.349004\tAccuracy: 91.37%\n",
      "569\tValidation loss: 1.348984\tBest loss: 1.348984\tAccuracy: 91.37%\n",
      "570\tValidation loss: 1.348963\tBest loss: 1.348963\tAccuracy: 91.37%\n",
      "571\tValidation loss: 1.348924\tBest loss: 1.348924\tAccuracy: 91.37%\n",
      "572\tValidation loss: 1.348914\tBest loss: 1.348914\tAccuracy: 91.37%\n",
      "573\tValidation loss: 1.348897\tBest loss: 1.348897\tAccuracy: 91.37%\n",
      "574\tValidation loss: 1.348880\tBest loss: 1.348880\tAccuracy: 91.37%\n",
      "575\tValidation loss: 1.348857\tBest loss: 1.348857\tAccuracy: 91.37%\n",
      "576\tValidation loss: 1.348849\tBest loss: 1.348849\tAccuracy: 91.37%\n",
      "577\tValidation loss: 1.348829\tBest loss: 1.348829\tAccuracy: 91.37%\n",
      "578\tValidation loss: 1.348819\tBest loss: 1.348819\tAccuracy: 91.37%\n",
      "579\tValidation loss: 1.348791\tBest loss: 1.348791\tAccuracy: 91.37%\n",
      "580\tValidation loss: 1.348768\tBest loss: 1.348768\tAccuracy: 91.37%\n",
      "581\tValidation loss: 1.348759\tBest loss: 1.348759\tAccuracy: 91.37%\n",
      "582\tValidation loss: 1.348753\tBest loss: 1.348753\tAccuracy: 91.37%\n",
      "583\tValidation loss: 1.348736\tBest loss: 1.348736\tAccuracy: 91.37%\n",
      "584\tValidation loss: 1.348711\tBest loss: 1.348711\tAccuracy: 91.37%\n",
      "585\tValidation loss: 1.348699\tBest loss: 1.348699\tAccuracy: 91.37%\n",
      "586\tValidation loss: 1.348700\tBest loss: 1.348699\tAccuracy: 91.37%\n",
      "587\tValidation loss: 1.348676\tBest loss: 1.348676\tAccuracy: 91.37%\n",
      "588\tValidation loss: 1.348655\tBest loss: 1.348655\tAccuracy: 91.37%\n",
      "589\tValidation loss: 1.348637\tBest loss: 1.348637\tAccuracy: 91.37%\n",
      "590\tValidation loss: 1.348624\tBest loss: 1.348624\tAccuracy: 91.37%\n",
      "591\tValidation loss: 1.348602\tBest loss: 1.348602\tAccuracy: 91.37%\n",
      "592\tValidation loss: 1.348574\tBest loss: 1.348574\tAccuracy: 91.37%\n",
      "593\tValidation loss: 1.348547\tBest loss: 1.348547\tAccuracy: 91.37%\n",
      "594\tValidation loss: 1.348542\tBest loss: 1.348542\tAccuracy: 91.37%\n",
      "595\tValidation loss: 1.348530\tBest loss: 1.348530\tAccuracy: 91.37%\n",
      "596\tValidation loss: 1.348513\tBest loss: 1.348513\tAccuracy: 91.37%\n",
      "597\tValidation loss: 1.348505\tBest loss: 1.348505\tAccuracy: 91.37%\n",
      "598\tValidation loss: 1.348487\tBest loss: 1.348487\tAccuracy: 91.37%\n",
      "599\tValidation loss: 1.348471\tBest loss: 1.348471\tAccuracy: 91.37%\n",
      "600\tValidation loss: 1.348453\tBest loss: 1.348453\tAccuracy: 91.37%\n",
      "601\tValidation loss: 1.348430\tBest loss: 1.348430\tAccuracy: 91.37%\n",
      "602\tValidation loss: 1.348400\tBest loss: 1.348400\tAccuracy: 91.37%\n",
      "603\tValidation loss: 1.348385\tBest loss: 1.348385\tAccuracy: 91.37%\n",
      "604\tValidation loss: 1.348366\tBest loss: 1.348366\tAccuracy: 91.37%\n",
      "605\tValidation loss: 1.348343\tBest loss: 1.348343\tAccuracy: 91.37%\n",
      "606\tValidation loss: 1.348331\tBest loss: 1.348331\tAccuracy: 91.37%\n",
      "607\tValidation loss: 1.348317\tBest loss: 1.348317\tAccuracy: 91.37%\n",
      "608\tValidation loss: 1.348313\tBest loss: 1.348313\tAccuracy: 91.37%\n",
      "609\tValidation loss: 1.348292\tBest loss: 1.348292\tAccuracy: 91.37%\n",
      "610\tValidation loss: 1.348258\tBest loss: 1.348258\tAccuracy: 91.37%\n",
      "611\tValidation loss: 1.348246\tBest loss: 1.348246\tAccuracy: 91.37%\n",
      "612\tValidation loss: 1.348222\tBest loss: 1.348222\tAccuracy: 91.37%\n",
      "613\tValidation loss: 1.348207\tBest loss: 1.348207\tAccuracy: 91.37%\n",
      "614\tValidation loss: 1.348189\tBest loss: 1.348189\tAccuracy: 91.37%\n",
      "615\tValidation loss: 1.348180\tBest loss: 1.348180\tAccuracy: 91.37%\n",
      "616\tValidation loss: 1.348151\tBest loss: 1.348151\tAccuracy: 91.37%\n",
      "617\tValidation loss: 1.348141\tBest loss: 1.348141\tAccuracy: 91.37%\n",
      "618\tValidation loss: 1.348124\tBest loss: 1.348124\tAccuracy: 91.37%\n",
      "619\tValidation loss: 1.348100\tBest loss: 1.348100\tAccuracy: 91.37%\n",
      "620\tValidation loss: 1.348078\tBest loss: 1.348078\tAccuracy: 91.37%\n",
      "621\tValidation loss: 1.348067\tBest loss: 1.348067\tAccuracy: 91.37%\n",
      "622\tValidation loss: 1.348037\tBest loss: 1.348037\tAccuracy: 91.37%\n",
      "623\tValidation loss: 1.348019\tBest loss: 1.348019\tAccuracy: 91.37%\n",
      "624\tValidation loss: 1.348001\tBest loss: 1.348001\tAccuracy: 91.37%\n",
      "625\tValidation loss: 1.347975\tBest loss: 1.347975\tAccuracy: 91.37%\n",
      "626\tValidation loss: 1.347960\tBest loss: 1.347960\tAccuracy: 91.37%\n",
      "627\tValidation loss: 1.347941\tBest loss: 1.347941\tAccuracy: 91.37%\n",
      "628\tValidation loss: 1.347917\tBest loss: 1.347917\tAccuracy: 91.37%\n",
      "629\tValidation loss: 1.347911\tBest loss: 1.347911\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\tValidation loss: 1.347896\tBest loss: 1.347896\tAccuracy: 91.37%\n",
      "631\tValidation loss: 1.347869\tBest loss: 1.347869\tAccuracy: 91.37%\n",
      "632\tValidation loss: 1.347857\tBest loss: 1.347857\tAccuracy: 91.37%\n",
      "633\tValidation loss: 1.347846\tBest loss: 1.347846\tAccuracy: 91.37%\n",
      "634\tValidation loss: 1.347821\tBest loss: 1.347821\tAccuracy: 91.37%\n",
      "635\tValidation loss: 1.347802\tBest loss: 1.347802\tAccuracy: 91.37%\n",
      "636\tValidation loss: 1.347793\tBest loss: 1.347793\tAccuracy: 91.37%\n",
      "637\tValidation loss: 1.347782\tBest loss: 1.347782\tAccuracy: 91.37%\n",
      "638\tValidation loss: 1.347765\tBest loss: 1.347765\tAccuracy: 91.37%\n",
      "639\tValidation loss: 1.347739\tBest loss: 1.347739\tAccuracy: 91.37%\n",
      "640\tValidation loss: 1.347721\tBest loss: 1.347721\tAccuracy: 91.37%\n",
      "641\tValidation loss: 1.347702\tBest loss: 1.347702\tAccuracy: 91.37%\n",
      "642\tValidation loss: 1.347692\tBest loss: 1.347692\tAccuracy: 91.37%\n",
      "643\tValidation loss: 1.347678\tBest loss: 1.347678\tAccuracy: 91.37%\n",
      "644\tValidation loss: 1.347673\tBest loss: 1.347673\tAccuracy: 91.37%\n",
      "645\tValidation loss: 1.347658\tBest loss: 1.347658\tAccuracy: 91.37%\n",
      "646\tValidation loss: 1.347644\tBest loss: 1.347644\tAccuracy: 91.37%\n",
      "647\tValidation loss: 1.347619\tBest loss: 1.347619\tAccuracy: 91.37%\n",
      "648\tValidation loss: 1.347603\tBest loss: 1.347603\tAccuracy: 91.37%\n",
      "649\tValidation loss: 1.347595\tBest loss: 1.347595\tAccuracy: 91.37%\n",
      "650\tValidation loss: 1.347578\tBest loss: 1.347578\tAccuracy: 91.37%\n",
      "651\tValidation loss: 1.347560\tBest loss: 1.347560\tAccuracy: 91.37%\n",
      "652\tValidation loss: 1.347544\tBest loss: 1.347544\tAccuracy: 91.37%\n",
      "653\tValidation loss: 1.347515\tBest loss: 1.347515\tAccuracy: 91.37%\n",
      "654\tValidation loss: 1.347493\tBest loss: 1.347493\tAccuracy: 91.37%\n",
      "655\tValidation loss: 1.347487\tBest loss: 1.347487\tAccuracy: 91.37%\n",
      "656\tValidation loss: 1.347473\tBest loss: 1.347473\tAccuracy: 91.37%\n",
      "657\tValidation loss: 1.347453\tBest loss: 1.347453\tAccuracy: 91.37%\n",
      "658\tValidation loss: 1.347434\tBest loss: 1.347434\tAccuracy: 91.37%\n",
      "659\tValidation loss: 1.347416\tBest loss: 1.347416\tAccuracy: 91.37%\n",
      "660\tValidation loss: 1.347399\tBest loss: 1.347399\tAccuracy: 91.37%\n",
      "661\tValidation loss: 1.347381\tBest loss: 1.347381\tAccuracy: 91.37%\n",
      "662\tValidation loss: 1.347369\tBest loss: 1.347369\tAccuracy: 91.37%\n",
      "663\tValidation loss: 1.347362\tBest loss: 1.347362\tAccuracy: 91.37%\n",
      "664\tValidation loss: 1.347356\tBest loss: 1.347356\tAccuracy: 91.37%\n",
      "665\tValidation loss: 1.347345\tBest loss: 1.347345\tAccuracy: 91.37%\n",
      "666\tValidation loss: 1.347320\tBest loss: 1.347320\tAccuracy: 91.37%\n",
      "667\tValidation loss: 1.347313\tBest loss: 1.347313\tAccuracy: 91.37%\n",
      "668\tValidation loss: 1.347295\tBest loss: 1.347295\tAccuracy: 91.37%\n",
      "669\tValidation loss: 1.347271\tBest loss: 1.347271\tAccuracy: 91.37%\n",
      "670\tValidation loss: 1.347251\tBest loss: 1.347251\tAccuracy: 91.37%\n",
      "671\tValidation loss: 1.347229\tBest loss: 1.347229\tAccuracy: 91.37%\n",
      "672\tValidation loss: 1.347215\tBest loss: 1.347215\tAccuracy: 91.37%\n",
      "673\tValidation loss: 1.347197\tBest loss: 1.347197\tAccuracy: 91.37%\n",
      "674\tValidation loss: 1.347183\tBest loss: 1.347183\tAccuracy: 91.37%\n",
      "675\tValidation loss: 1.347161\tBest loss: 1.347161\tAccuracy: 91.37%\n",
      "676\tValidation loss: 1.347150\tBest loss: 1.347150\tAccuracy: 91.37%\n",
      "677\tValidation loss: 1.347129\tBest loss: 1.347129\tAccuracy: 91.37%\n",
      "678\tValidation loss: 1.347113\tBest loss: 1.347113\tAccuracy: 91.37%\n",
      "679\tValidation loss: 1.347098\tBest loss: 1.347098\tAccuracy: 91.37%\n",
      "680\tValidation loss: 1.347092\tBest loss: 1.347092\tAccuracy: 91.37%\n",
      "681\tValidation loss: 1.347068\tBest loss: 1.347068\tAccuracy: 91.37%\n",
      "682\tValidation loss: 1.347052\tBest loss: 1.347052\tAccuracy: 91.37%\n",
      "683\tValidation loss: 1.347044\tBest loss: 1.347044\tAccuracy: 91.37%\n",
      "684\tValidation loss: 1.347035\tBest loss: 1.347035\tAccuracy: 91.37%\n",
      "685\tValidation loss: 1.347021\tBest loss: 1.347021\tAccuracy: 91.37%\n",
      "686\tValidation loss: 1.346999\tBest loss: 1.346999\tAccuracy: 91.37%\n",
      "687\tValidation loss: 1.346978\tBest loss: 1.346978\tAccuracy: 91.37%\n",
      "688\tValidation loss: 1.346958\tBest loss: 1.346958\tAccuracy: 91.37%\n",
      "689\tValidation loss: 1.346946\tBest loss: 1.346946\tAccuracy: 91.37%\n",
      "690\tValidation loss: 1.346927\tBest loss: 1.346927\tAccuracy: 91.37%\n",
      "691\tValidation loss: 1.346907\tBest loss: 1.346907\tAccuracy: 91.37%\n",
      "692\tValidation loss: 1.346897\tBest loss: 1.346897\tAccuracy: 91.37%\n",
      "693\tValidation loss: 1.346880\tBest loss: 1.346880\tAccuracy: 91.37%\n",
      "694\tValidation loss: 1.346866\tBest loss: 1.346866\tAccuracy: 91.37%\n",
      "695\tValidation loss: 1.346857\tBest loss: 1.346857\tAccuracy: 91.37%\n",
      "696\tValidation loss: 1.346854\tBest loss: 1.346854\tAccuracy: 91.37%\n",
      "697\tValidation loss: 1.346826\tBest loss: 1.346826\tAccuracy: 91.37%\n",
      "698\tValidation loss: 1.346819\tBest loss: 1.346819\tAccuracy: 91.37%\n",
      "699\tValidation loss: 1.346803\tBest loss: 1.346803\tAccuracy: 91.37%\n",
      "700\tValidation loss: 1.346791\tBest loss: 1.346791\tAccuracy: 91.37%\n",
      "701\tValidation loss: 1.346786\tBest loss: 1.346786\tAccuracy: 91.37%\n",
      "702\tValidation loss: 1.346769\tBest loss: 1.346769\tAccuracy: 91.37%\n",
      "703\tValidation loss: 1.346754\tBest loss: 1.346754\tAccuracy: 91.37%\n",
      "704\tValidation loss: 1.346749\tBest loss: 1.346749\tAccuracy: 91.37%\n",
      "705\tValidation loss: 1.346722\tBest loss: 1.346722\tAccuracy: 91.37%\n",
      "706\tValidation loss: 1.346697\tBest loss: 1.346697\tAccuracy: 91.37%\n",
      "707\tValidation loss: 1.346689\tBest loss: 1.346689\tAccuracy: 91.37%\n",
      "708\tValidation loss: 1.346676\tBest loss: 1.346676\tAccuracy: 91.37%\n",
      "709\tValidation loss: 1.346666\tBest loss: 1.346666\tAccuracy: 91.37%\n",
      "710\tValidation loss: 1.346653\tBest loss: 1.346653\tAccuracy: 91.37%\n",
      "711\tValidation loss: 1.346640\tBest loss: 1.346640\tAccuracy: 91.37%\n",
      "712\tValidation loss: 1.346624\tBest loss: 1.346624\tAccuracy: 91.37%\n",
      "713\tValidation loss: 1.346613\tBest loss: 1.346613\tAccuracy: 91.37%\n",
      "714\tValidation loss: 1.346594\tBest loss: 1.346594\tAccuracy: 91.37%\n",
      "715\tValidation loss: 1.346596\tBest loss: 1.346594\tAccuracy: 91.37%\n",
      "716\tValidation loss: 1.346585\tBest loss: 1.346585\tAccuracy: 91.37%\n",
      "717\tValidation loss: 1.346565\tBest loss: 1.346565\tAccuracy: 91.37%\n",
      "718\tValidation loss: 1.346542\tBest loss: 1.346542\tAccuracy: 91.37%\n",
      "719\tValidation loss: 1.346520\tBest loss: 1.346520\tAccuracy: 91.37%\n",
      "720\tValidation loss: 1.346506\tBest loss: 1.346506\tAccuracy: 91.37%\n",
      "721\tValidation loss: 1.346493\tBest loss: 1.346493\tAccuracy: 91.37%\n",
      "722\tValidation loss: 1.346483\tBest loss: 1.346483\tAccuracy: 91.37%\n",
      "723\tValidation loss: 1.346472\tBest loss: 1.346472\tAccuracy: 91.37%\n",
      "724\tValidation loss: 1.346459\tBest loss: 1.346459\tAccuracy: 91.37%\n",
      "725\tValidation loss: 1.346436\tBest loss: 1.346436\tAccuracy: 91.37%\n",
      "726\tValidation loss: 1.346420\tBest loss: 1.346420\tAccuracy: 91.37%\n",
      "727\tValidation loss: 1.346408\tBest loss: 1.346408\tAccuracy: 91.37%\n",
      "728\tValidation loss: 1.346400\tBest loss: 1.346400\tAccuracy: 91.37%\n",
      "729\tValidation loss: 1.346390\tBest loss: 1.346390\tAccuracy: 91.37%\n",
      "730\tValidation loss: 1.346372\tBest loss: 1.346372\tAccuracy: 91.37%\n",
      "731\tValidation loss: 1.346355\tBest loss: 1.346355\tAccuracy: 91.37%\n",
      "732\tValidation loss: 1.346345\tBest loss: 1.346345\tAccuracy: 91.37%\n",
      "733\tValidation loss: 1.346330\tBest loss: 1.346330\tAccuracy: 91.37%\n",
      "734\tValidation loss: 1.346321\tBest loss: 1.346321\tAccuracy: 91.37%\n",
      "735\tValidation loss: 1.346303\tBest loss: 1.346303\tAccuracy: 91.37%\n",
      "736\tValidation loss: 1.346288\tBest loss: 1.346288\tAccuracy: 91.37%\n",
      "737\tValidation loss: 1.346270\tBest loss: 1.346270\tAccuracy: 91.37%\n",
      "738\tValidation loss: 1.346245\tBest loss: 1.346245\tAccuracy: 91.37%\n",
      "739\tValidation loss: 1.346221\tBest loss: 1.346221\tAccuracy: 91.37%\n",
      "740\tValidation loss: 1.346197\tBest loss: 1.346197\tAccuracy: 91.37%\n",
      "741\tValidation loss: 1.346192\tBest loss: 1.346192\tAccuracy: 91.37%\n",
      "742\tValidation loss: 1.346179\tBest loss: 1.346179\tAccuracy: 91.37%\n",
      "743\tValidation loss: 1.346158\tBest loss: 1.346158\tAccuracy: 91.37%\n",
      "744\tValidation loss: 1.346146\tBest loss: 1.346146\tAccuracy: 91.37%\n",
      "745\tValidation loss: 1.346132\tBest loss: 1.346132\tAccuracy: 91.37%\n",
      "746\tValidation loss: 1.346127\tBest loss: 1.346127\tAccuracy: 91.37%\n",
      "747\tValidation loss: 1.346106\tBest loss: 1.346106\tAccuracy: 91.37%\n",
      "748\tValidation loss: 1.346095\tBest loss: 1.346095\tAccuracy: 91.37%\n",
      "749\tValidation loss: 1.346076\tBest loss: 1.346076\tAccuracy: 91.37%\n",
      "750\tValidation loss: 1.346069\tBest loss: 1.346069\tAccuracy: 91.37%\n",
      "751\tValidation loss: 1.346047\tBest loss: 1.346047\tAccuracy: 91.37%\n",
      "752\tValidation loss: 1.346034\tBest loss: 1.346034\tAccuracy: 91.37%\n",
      "753\tValidation loss: 1.346027\tBest loss: 1.346027\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\tValidation loss: 1.346018\tBest loss: 1.346018\tAccuracy: 91.37%\n",
      "755\tValidation loss: 1.346002\tBest loss: 1.346002\tAccuracy: 91.37%\n",
      "756\tValidation loss: 1.345985\tBest loss: 1.345985\tAccuracy: 91.37%\n",
      "757\tValidation loss: 1.345967\tBest loss: 1.345967\tAccuracy: 91.37%\n",
      "758\tValidation loss: 1.345961\tBest loss: 1.345961\tAccuracy: 91.37%\n",
      "759\tValidation loss: 1.345946\tBest loss: 1.345946\tAccuracy: 91.37%\n",
      "760\tValidation loss: 1.345948\tBest loss: 1.345946\tAccuracy: 91.37%\n",
      "761\tValidation loss: 1.345932\tBest loss: 1.345932\tAccuracy: 91.37%\n",
      "762\tValidation loss: 1.345911\tBest loss: 1.345911\tAccuracy: 91.37%\n",
      "763\tValidation loss: 1.345907\tBest loss: 1.345907\tAccuracy: 91.37%\n",
      "764\tValidation loss: 1.345888\tBest loss: 1.345888\tAccuracy: 91.37%\n",
      "765\tValidation loss: 1.345880\tBest loss: 1.345880\tAccuracy: 91.37%\n",
      "766\tValidation loss: 1.345858\tBest loss: 1.345858\tAccuracy: 91.37%\n",
      "767\tValidation loss: 1.345836\tBest loss: 1.345836\tAccuracy: 91.37%\n",
      "768\tValidation loss: 1.345818\tBest loss: 1.345818\tAccuracy: 91.37%\n",
      "769\tValidation loss: 1.345799\tBest loss: 1.345799\tAccuracy: 91.37%\n",
      "770\tValidation loss: 1.345786\tBest loss: 1.345786\tAccuracy: 91.37%\n",
      "771\tValidation loss: 1.345759\tBest loss: 1.345759\tAccuracy: 91.37%\n",
      "772\tValidation loss: 1.345747\tBest loss: 1.345747\tAccuracy: 91.37%\n",
      "773\tValidation loss: 1.345745\tBest loss: 1.345745\tAccuracy: 91.37%\n",
      "774\tValidation loss: 1.345736\tBest loss: 1.345736\tAccuracy: 91.37%\n",
      "775\tValidation loss: 1.345724\tBest loss: 1.345724\tAccuracy: 91.37%\n",
      "776\tValidation loss: 1.345721\tBest loss: 1.345721\tAccuracy: 91.37%\n",
      "777\tValidation loss: 1.345711\tBest loss: 1.345711\tAccuracy: 91.37%\n",
      "778\tValidation loss: 1.345696\tBest loss: 1.345696\tAccuracy: 91.37%\n",
      "779\tValidation loss: 1.345681\tBest loss: 1.345681\tAccuracy: 91.37%\n",
      "780\tValidation loss: 1.345678\tBest loss: 1.345678\tAccuracy: 91.37%\n",
      "781\tValidation loss: 1.345658\tBest loss: 1.345658\tAccuracy: 91.37%\n",
      "782\tValidation loss: 1.345640\tBest loss: 1.345640\tAccuracy: 91.37%\n",
      "783\tValidation loss: 1.345625\tBest loss: 1.345625\tAccuracy: 91.37%\n",
      "784\tValidation loss: 1.345621\tBest loss: 1.345621\tAccuracy: 91.37%\n",
      "785\tValidation loss: 1.345613\tBest loss: 1.345613\tAccuracy: 91.37%\n",
      "786\tValidation loss: 1.345611\tBest loss: 1.345611\tAccuracy: 91.37%\n",
      "787\tValidation loss: 1.345588\tBest loss: 1.345588\tAccuracy: 91.37%\n",
      "788\tValidation loss: 1.345577\tBest loss: 1.345577\tAccuracy: 91.37%\n",
      "789\tValidation loss: 1.345566\tBest loss: 1.345566\tAccuracy: 91.37%\n",
      "790\tValidation loss: 1.345555\tBest loss: 1.345555\tAccuracy: 91.37%\n",
      "791\tValidation loss: 1.345535\tBest loss: 1.345535\tAccuracy: 91.37%\n",
      "792\tValidation loss: 1.345504\tBest loss: 1.345504\tAccuracy: 91.37%\n",
      "793\tValidation loss: 1.345492\tBest loss: 1.345492\tAccuracy: 91.37%\n",
      "794\tValidation loss: 1.345484\tBest loss: 1.345484\tAccuracy: 91.37%\n",
      "795\tValidation loss: 1.345466\tBest loss: 1.345466\tAccuracy: 91.37%\n",
      "796\tValidation loss: 1.345449\tBest loss: 1.345449\tAccuracy: 91.37%\n",
      "797\tValidation loss: 1.345440\tBest loss: 1.345440\tAccuracy: 91.37%\n",
      "798\tValidation loss: 1.345424\tBest loss: 1.345424\tAccuracy: 91.37%\n",
      "799\tValidation loss: 1.345417\tBest loss: 1.345417\tAccuracy: 91.37%\n",
      "800\tValidation loss: 1.345416\tBest loss: 1.345416\tAccuracy: 91.37%\n",
      "801\tValidation loss: 1.345408\tBest loss: 1.345408\tAccuracy: 91.37%\n",
      "802\tValidation loss: 1.345410\tBest loss: 1.345408\tAccuracy: 91.37%\n",
      "803\tValidation loss: 1.345397\tBest loss: 1.345397\tAccuracy: 91.37%\n",
      "804\tValidation loss: 1.345376\tBest loss: 1.345376\tAccuracy: 91.37%\n",
      "805\tValidation loss: 1.345374\tBest loss: 1.345374\tAccuracy: 91.37%\n",
      "806\tValidation loss: 1.345352\tBest loss: 1.345352\tAccuracy: 91.37%\n",
      "807\tValidation loss: 1.345341\tBest loss: 1.345341\tAccuracy: 91.37%\n",
      "808\tValidation loss: 1.345324\tBest loss: 1.345324\tAccuracy: 91.37%\n",
      "809\tValidation loss: 1.345324\tBest loss: 1.345324\tAccuracy: 91.37%\n",
      "810\tValidation loss: 1.345304\tBest loss: 1.345304\tAccuracy: 91.37%\n",
      "811\tValidation loss: 1.345281\tBest loss: 1.345281\tAccuracy: 91.37%\n",
      "812\tValidation loss: 1.345283\tBest loss: 1.345281\tAccuracy: 91.37%\n",
      "813\tValidation loss: 1.345272\tBest loss: 1.345272\tAccuracy: 91.37%\n",
      "814\tValidation loss: 1.345265\tBest loss: 1.345265\tAccuracy: 91.37%\n",
      "815\tValidation loss: 1.345256\tBest loss: 1.345256\tAccuracy: 91.37%\n",
      "816\tValidation loss: 1.345235\tBest loss: 1.345235\tAccuracy: 91.37%\n",
      "817\tValidation loss: 1.345218\tBest loss: 1.345218\tAccuracy: 91.37%\n",
      "818\tValidation loss: 1.345219\tBest loss: 1.345218\tAccuracy: 91.37%\n",
      "819\tValidation loss: 1.345205\tBest loss: 1.345205\tAccuracy: 91.37%\n",
      "820\tValidation loss: 1.345189\tBest loss: 1.345189\tAccuracy: 91.37%\n",
      "821\tValidation loss: 1.345174\tBest loss: 1.345174\tAccuracy: 91.37%\n",
      "822\tValidation loss: 1.345171\tBest loss: 1.345171\tAccuracy: 91.37%\n",
      "823\tValidation loss: 1.345155\tBest loss: 1.345155\tAccuracy: 91.37%\n",
      "824\tValidation loss: 1.345157\tBest loss: 1.345155\tAccuracy: 91.37%\n",
      "825\tValidation loss: 1.345146\tBest loss: 1.345146\tAccuracy: 91.37%\n",
      "826\tValidation loss: 1.345136\tBest loss: 1.345136\tAccuracy: 91.37%\n",
      "827\tValidation loss: 1.345116\tBest loss: 1.345116\tAccuracy: 91.37%\n",
      "828\tValidation loss: 1.345095\tBest loss: 1.345095\tAccuracy: 91.37%\n",
      "829\tValidation loss: 1.345085\tBest loss: 1.345085\tAccuracy: 91.37%\n",
      "830\tValidation loss: 1.345072\tBest loss: 1.345072\tAccuracy: 91.37%\n",
      "831\tValidation loss: 1.345047\tBest loss: 1.345047\tAccuracy: 91.37%\n",
      "832\tValidation loss: 1.345042\tBest loss: 1.345042\tAccuracy: 91.37%\n",
      "833\tValidation loss: 1.345024\tBest loss: 1.345024\tAccuracy: 91.37%\n",
      "834\tValidation loss: 1.345018\tBest loss: 1.345018\tAccuracy: 91.37%\n",
      "835\tValidation loss: 1.345005\tBest loss: 1.345005\tAccuracy: 91.37%\n",
      "836\tValidation loss: 1.344991\tBest loss: 1.344991\tAccuracy: 91.37%\n",
      "837\tValidation loss: 1.344972\tBest loss: 1.344972\tAccuracy: 91.37%\n",
      "838\tValidation loss: 1.344960\tBest loss: 1.344960\tAccuracy: 91.37%\n",
      "839\tValidation loss: 1.344946\tBest loss: 1.344946\tAccuracy: 91.37%\n",
      "840\tValidation loss: 1.344945\tBest loss: 1.344945\tAccuracy: 91.37%\n",
      "841\tValidation loss: 1.344926\tBest loss: 1.344926\tAccuracy: 91.37%\n",
      "842\tValidation loss: 1.344913\tBest loss: 1.344913\tAccuracy: 91.37%\n",
      "843\tValidation loss: 1.344908\tBest loss: 1.344908\tAccuracy: 91.37%\n",
      "844\tValidation loss: 1.344903\tBest loss: 1.344903\tAccuracy: 91.37%\n",
      "845\tValidation loss: 1.344891\tBest loss: 1.344891\tAccuracy: 91.37%\n",
      "846\tValidation loss: 1.344886\tBest loss: 1.344886\tAccuracy: 91.37%\n",
      "847\tValidation loss: 1.344874\tBest loss: 1.344874\tAccuracy: 91.37%\n",
      "848\tValidation loss: 1.344864\tBest loss: 1.344864\tAccuracy: 91.37%\n",
      "849\tValidation loss: 1.344864\tBest loss: 1.344864\tAccuracy: 91.37%\n",
      "850\tValidation loss: 1.344839\tBest loss: 1.344839\tAccuracy: 91.37%\n",
      "851\tValidation loss: 1.344830\tBest loss: 1.344830\tAccuracy: 91.37%\n",
      "852\tValidation loss: 1.344821\tBest loss: 1.344821\tAccuracy: 91.37%\n",
      "853\tValidation loss: 1.344816\tBest loss: 1.344816\tAccuracy: 91.37%\n",
      "854\tValidation loss: 1.344811\tBest loss: 1.344811\tAccuracy: 91.37%\n",
      "855\tValidation loss: 1.344807\tBest loss: 1.344807\tAccuracy: 91.37%\n",
      "856\tValidation loss: 1.344789\tBest loss: 1.344789\tAccuracy: 91.37%\n",
      "857\tValidation loss: 1.344773\tBest loss: 1.344773\tAccuracy: 91.37%\n",
      "858\tValidation loss: 1.344761\tBest loss: 1.344761\tAccuracy: 91.37%\n",
      "859\tValidation loss: 1.344759\tBest loss: 1.344759\tAccuracy: 91.37%\n",
      "860\tValidation loss: 1.344746\tBest loss: 1.344746\tAccuracy: 91.37%\n",
      "861\tValidation loss: 1.344729\tBest loss: 1.344729\tAccuracy: 91.37%\n",
      "862\tValidation loss: 1.344723\tBest loss: 1.344723\tAccuracy: 91.37%\n",
      "863\tValidation loss: 1.344721\tBest loss: 1.344721\tAccuracy: 91.37%\n",
      "864\tValidation loss: 1.344693\tBest loss: 1.344693\tAccuracy: 91.37%\n",
      "865\tValidation loss: 1.344675\tBest loss: 1.344675\tAccuracy: 91.37%\n",
      "866\tValidation loss: 1.344663\tBest loss: 1.344663\tAccuracy: 91.37%\n",
      "867\tValidation loss: 1.344662\tBest loss: 1.344662\tAccuracy: 91.37%\n",
      "868\tValidation loss: 1.344651\tBest loss: 1.344651\tAccuracy: 91.37%\n",
      "869\tValidation loss: 1.344638\tBest loss: 1.344638\tAccuracy: 91.37%\n",
      "870\tValidation loss: 1.344625\tBest loss: 1.344625\tAccuracy: 91.37%\n",
      "871\tValidation loss: 1.344613\tBest loss: 1.344613\tAccuracy: 91.37%\n",
      "872\tValidation loss: 1.344596\tBest loss: 1.344596\tAccuracy: 91.37%\n",
      "873\tValidation loss: 1.344590\tBest loss: 1.344590\tAccuracy: 91.37%\n",
      "874\tValidation loss: 1.344573\tBest loss: 1.344573\tAccuracy: 91.37%\n",
      "875\tValidation loss: 1.344565\tBest loss: 1.344565\tAccuracy: 91.37%\n",
      "876\tValidation loss: 1.344554\tBest loss: 1.344554\tAccuracy: 91.37%\n",
      "877\tValidation loss: 1.344532\tBest loss: 1.344532\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878\tValidation loss: 1.344517\tBest loss: 1.344517\tAccuracy: 91.37%\n",
      "879\tValidation loss: 1.344507\tBest loss: 1.344507\tAccuracy: 91.37%\n",
      "880\tValidation loss: 1.344493\tBest loss: 1.344493\tAccuracy: 91.37%\n",
      "881\tValidation loss: 1.344480\tBest loss: 1.344480\tAccuracy: 91.37%\n",
      "882\tValidation loss: 1.344474\tBest loss: 1.344474\tAccuracy: 91.37%\n",
      "883\tValidation loss: 1.344473\tBest loss: 1.344473\tAccuracy: 91.37%\n",
      "884\tValidation loss: 1.344462\tBest loss: 1.344462\tAccuracy: 91.37%\n",
      "885\tValidation loss: 1.344437\tBest loss: 1.344437\tAccuracy: 91.37%\n",
      "886\tValidation loss: 1.344416\tBest loss: 1.344416\tAccuracy: 91.37%\n",
      "887\tValidation loss: 1.344409\tBest loss: 1.344409\tAccuracy: 91.37%\n",
      "888\tValidation loss: 1.344397\tBest loss: 1.344397\tAccuracy: 91.37%\n",
      "889\tValidation loss: 1.344391\tBest loss: 1.344391\tAccuracy: 91.37%\n",
      "890\tValidation loss: 1.344380\tBest loss: 1.344380\tAccuracy: 91.37%\n",
      "891\tValidation loss: 1.344376\tBest loss: 1.344376\tAccuracy: 91.37%\n",
      "892\tValidation loss: 1.344350\tBest loss: 1.344350\tAccuracy: 91.37%\n",
      "893\tValidation loss: 1.344347\tBest loss: 1.344347\tAccuracy: 91.37%\n",
      "894\tValidation loss: 1.344337\tBest loss: 1.344337\tAccuracy: 91.37%\n",
      "895\tValidation loss: 1.344317\tBest loss: 1.344317\tAccuracy: 91.37%\n",
      "896\tValidation loss: 1.344298\tBest loss: 1.344298\tAccuracy: 91.37%\n",
      "897\tValidation loss: 1.344288\tBest loss: 1.344288\tAccuracy: 91.37%\n",
      "898\tValidation loss: 1.344282\tBest loss: 1.344282\tAccuracy: 91.37%\n",
      "899\tValidation loss: 1.344277\tBest loss: 1.344277\tAccuracy: 91.37%\n",
      "900\tValidation loss: 1.344270\tBest loss: 1.344270\tAccuracy: 91.37%\n",
      "901\tValidation loss: 1.344270\tBest loss: 1.344270\tAccuracy: 91.37%\n",
      "902\tValidation loss: 1.344260\tBest loss: 1.344260\tAccuracy: 91.37%\n",
      "903\tValidation loss: 1.344232\tBest loss: 1.344232\tAccuracy: 91.37%\n",
      "904\tValidation loss: 1.344229\tBest loss: 1.344229\tAccuracy: 91.37%\n",
      "905\tValidation loss: 1.344218\tBest loss: 1.344218\tAccuracy: 91.37%\n",
      "906\tValidation loss: 1.344203\tBest loss: 1.344203\tAccuracy: 91.37%\n",
      "907\tValidation loss: 1.344193\tBest loss: 1.344193\tAccuracy: 91.37%\n",
      "908\tValidation loss: 1.344184\tBest loss: 1.344184\tAccuracy: 91.37%\n",
      "909\tValidation loss: 1.344177\tBest loss: 1.344177\tAccuracy: 91.37%\n",
      "910\tValidation loss: 1.344154\tBest loss: 1.344154\tAccuracy: 91.37%\n",
      "911\tValidation loss: 1.344149\tBest loss: 1.344149\tAccuracy: 91.37%\n",
      "912\tValidation loss: 1.344133\tBest loss: 1.344133\tAccuracy: 91.37%\n",
      "913\tValidation loss: 1.344126\tBest loss: 1.344126\tAccuracy: 91.37%\n",
      "914\tValidation loss: 1.344115\tBest loss: 1.344115\tAccuracy: 91.37%\n",
      "915\tValidation loss: 1.344106\tBest loss: 1.344106\tAccuracy: 91.37%\n",
      "916\tValidation loss: 1.344091\tBest loss: 1.344091\tAccuracy: 91.37%\n",
      "917\tValidation loss: 1.344090\tBest loss: 1.344090\tAccuracy: 91.37%\n",
      "918\tValidation loss: 1.344087\tBest loss: 1.344087\tAccuracy: 91.37%\n",
      "919\tValidation loss: 1.344077\tBest loss: 1.344077\tAccuracy: 91.37%\n",
      "920\tValidation loss: 1.344064\tBest loss: 1.344064\tAccuracy: 91.37%\n",
      "921\tValidation loss: 1.344056\tBest loss: 1.344056\tAccuracy: 91.37%\n",
      "922\tValidation loss: 1.344038\tBest loss: 1.344038\tAccuracy: 91.37%\n",
      "923\tValidation loss: 1.344020\tBest loss: 1.344020\tAccuracy: 91.37%\n",
      "924\tValidation loss: 1.344012\tBest loss: 1.344012\tAccuracy: 91.37%\n",
      "925\tValidation loss: 1.344007\tBest loss: 1.344007\tAccuracy: 91.37%\n",
      "926\tValidation loss: 1.344002\tBest loss: 1.344002\tAccuracy: 91.37%\n",
      "927\tValidation loss: 1.343985\tBest loss: 1.343985\tAccuracy: 91.37%\n",
      "928\tValidation loss: 1.343975\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "929\tValidation loss: 1.343979\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "930\tValidation loss: 1.343980\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "931\tValidation loss: 1.343966\tBest loss: 1.343966\tAccuracy: 91.37%\n",
      "932\tValidation loss: 1.343948\tBest loss: 1.343948\tAccuracy: 91.37%\n",
      "933\tValidation loss: 1.343941\tBest loss: 1.343941\tAccuracy: 91.37%\n",
      "934\tValidation loss: 1.343943\tBest loss: 1.343941\tAccuracy: 91.37%\n",
      "935\tValidation loss: 1.343925\tBest loss: 1.343925\tAccuracy: 91.37%\n",
      "936\tValidation loss: 1.343921\tBest loss: 1.343921\tAccuracy: 91.37%\n",
      "937\tValidation loss: 1.343917\tBest loss: 1.343917\tAccuracy: 91.37%\n",
      "938\tValidation loss: 1.343908\tBest loss: 1.343908\tAccuracy: 91.37%\n",
      "939\tValidation loss: 1.343894\tBest loss: 1.343894\tAccuracy: 91.37%\n",
      "940\tValidation loss: 1.343889\tBest loss: 1.343889\tAccuracy: 91.37%\n",
      "941\tValidation loss: 1.343884\tBest loss: 1.343884\tAccuracy: 91.37%\n",
      "942\tValidation loss: 1.343867\tBest loss: 1.343867\tAccuracy: 91.37%\n",
      "943\tValidation loss: 1.343859\tBest loss: 1.343859\tAccuracy: 91.37%\n",
      "944\tValidation loss: 1.343844\tBest loss: 1.343844\tAccuracy: 91.37%\n",
      "945\tValidation loss: 1.343827\tBest loss: 1.343827\tAccuracy: 91.37%\n",
      "946\tValidation loss: 1.343829\tBest loss: 1.343827\tAccuracy: 91.37%\n",
      "947\tValidation loss: 1.343825\tBest loss: 1.343825\tAccuracy: 91.37%\n",
      "948\tValidation loss: 1.343808\tBest loss: 1.343808\tAccuracy: 91.37%\n",
      "949\tValidation loss: 1.343783\tBest loss: 1.343783\tAccuracy: 91.37%\n",
      "950\tValidation loss: 1.343769\tBest loss: 1.343769\tAccuracy: 91.37%\n",
      "951\tValidation loss: 1.343763\tBest loss: 1.343763\tAccuracy: 91.37%\n",
      "952\tValidation loss: 1.343744\tBest loss: 1.343744\tAccuracy: 91.37%\n",
      "953\tValidation loss: 1.343724\tBest loss: 1.343724\tAccuracy: 91.37%\n",
      "954\tValidation loss: 1.343712\tBest loss: 1.343712\tAccuracy: 91.37%\n",
      "955\tValidation loss: 1.343695\tBest loss: 1.343695\tAccuracy: 91.37%\n",
      "956\tValidation loss: 1.343686\tBest loss: 1.343686\tAccuracy: 91.37%\n",
      "957\tValidation loss: 1.343675\tBest loss: 1.343675\tAccuracy: 91.37%\n",
      "958\tValidation loss: 1.343670\tBest loss: 1.343670\tAccuracy: 91.37%\n",
      "959\tValidation loss: 1.343655\tBest loss: 1.343655\tAccuracy: 91.37%\n",
      "960\tValidation loss: 1.343645\tBest loss: 1.343645\tAccuracy: 91.37%\n",
      "961\tValidation loss: 1.343642\tBest loss: 1.343642\tAccuracy: 91.37%\n",
      "962\tValidation loss: 1.343638\tBest loss: 1.343638\tAccuracy: 91.37%\n",
      "963\tValidation loss: 1.343629\tBest loss: 1.343629\tAccuracy: 91.37%\n",
      "964\tValidation loss: 1.343615\tBest loss: 1.343615\tAccuracy: 91.37%\n",
      "965\tValidation loss: 1.343608\tBest loss: 1.343608\tAccuracy: 91.37%\n",
      "966\tValidation loss: 1.343593\tBest loss: 1.343593\tAccuracy: 91.37%\n",
      "967\tValidation loss: 1.343583\tBest loss: 1.343583\tAccuracy: 91.37%\n",
      "968\tValidation loss: 1.343577\tBest loss: 1.343577\tAccuracy: 91.37%\n",
      "969\tValidation loss: 1.343563\tBest loss: 1.343563\tAccuracy: 91.37%\n",
      "970\tValidation loss: 1.343546\tBest loss: 1.343546\tAccuracy: 91.37%\n",
      "971\tValidation loss: 1.343526\tBest loss: 1.343526\tAccuracy: 91.37%\n",
      "972\tValidation loss: 1.343518\tBest loss: 1.343518\tAccuracy: 91.37%\n",
      "973\tValidation loss: 1.343514\tBest loss: 1.343514\tAccuracy: 91.37%\n",
      "974\tValidation loss: 1.343500\tBest loss: 1.343500\tAccuracy: 91.37%\n",
      "975\tValidation loss: 1.343493\tBest loss: 1.343493\tAccuracy: 91.37%\n",
      "976\tValidation loss: 1.343480\tBest loss: 1.343480\tAccuracy: 91.37%\n",
      "977\tValidation loss: 1.343467\tBest loss: 1.343467\tAccuracy: 91.37%\n",
      "978\tValidation loss: 1.343456\tBest loss: 1.343456\tAccuracy: 91.37%\n",
      "979\tValidation loss: 1.343454\tBest loss: 1.343454\tAccuracy: 91.37%\n",
      "980\tValidation loss: 1.343452\tBest loss: 1.343452\tAccuracy: 91.37%\n",
      "981\tValidation loss: 1.343437\tBest loss: 1.343437\tAccuracy: 91.37%\n",
      "982\tValidation loss: 1.343432\tBest loss: 1.343432\tAccuracy: 91.37%\n",
      "983\tValidation loss: 1.343420\tBest loss: 1.343420\tAccuracy: 91.37%\n",
      "984\tValidation loss: 1.343413\tBest loss: 1.343413\tAccuracy: 91.37%\n",
      "985\tValidation loss: 1.343400\tBest loss: 1.343400\tAccuracy: 91.37%\n",
      "986\tValidation loss: 1.343396\tBest loss: 1.343396\tAccuracy: 91.37%\n",
      "987\tValidation loss: 1.343385\tBest loss: 1.343385\tAccuracy: 91.37%\n",
      "988\tValidation loss: 1.343379\tBest loss: 1.343379\tAccuracy: 91.37%\n",
      "989\tValidation loss: 1.343367\tBest loss: 1.343367\tAccuracy: 91.37%\n",
      "990\tValidation loss: 1.343351\tBest loss: 1.343351\tAccuracy: 91.37%\n",
      "991\tValidation loss: 1.343350\tBest loss: 1.343350\tAccuracy: 91.37%\n",
      "992\tValidation loss: 1.343348\tBest loss: 1.343348\tAccuracy: 91.37%\n",
      "993\tValidation loss: 1.343343\tBest loss: 1.343343\tAccuracy: 91.37%\n",
      "994\tValidation loss: 1.343329\tBest loss: 1.343329\tAccuracy: 91.37%\n",
      "995\tValidation loss: 1.343320\tBest loss: 1.343320\tAccuracy: 91.37%\n",
      "996\tValidation loss: 1.343313\tBest loss: 1.343313\tAccuracy: 91.37%\n",
      "997\tValidation loss: 1.343300\tBest loss: 1.343300\tAccuracy: 91.37%\n",
      "998\tValidation loss: 1.343305\tBest loss: 1.343300\tAccuracy: 91.37%\n",
      "999\tValidation loss: 1.343290\tBest loss: 1.343290\tAccuracy: 91.37%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total= 1.9min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 86.605972\tBest loss: 86.605972\tAccuracy: 43.88%\n",
      "1\tValidation loss: 4.071143\tBest loss: 4.071143\tAccuracy: 82.73%\n",
      "2\tValidation loss: 4.820080\tBest loss: 4.071143\tAccuracy: 81.29%\n",
      "3\tValidation loss: 1.532486\tBest loss: 1.532486\tAccuracy: 89.21%\n",
      "4\tValidation loss: 1.616773\tBest loss: 1.532486\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.491755\tBest loss: 1.491755\tAccuracy: 89.93%\n",
      "6\tValidation loss: 1.318320\tBest loss: 1.318320\tAccuracy: 89.93%\n",
      "7\tValidation loss: 1.380828\tBest loss: 1.318320\tAccuracy: 90.65%\n",
      "8\tValidation loss: 1.369809\tBest loss: 1.318320\tAccuracy: 91.37%\n",
      "9\tValidation loss: 1.212981\tBest loss: 1.212981\tAccuracy: 91.37%\n",
      "10\tValidation loss: 1.206968\tBest loss: 1.206968\tAccuracy: 89.93%\n",
      "11\tValidation loss: 1.167929\tBest loss: 1.167929\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.164988\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "13\tValidation loss: 1.168885\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "14\tValidation loss: 1.185779\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.218265\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "16\tValidation loss: 1.224380\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "17\tValidation loss: 1.223912\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "18\tValidation loss: 1.226741\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "19\tValidation loss: 1.211427\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "20\tValidation loss: 1.209961\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "21\tValidation loss: 1.205905\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "22\tValidation loss: 1.200269\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "23\tValidation loss: 1.196383\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "24\tValidation loss: 1.191659\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "25\tValidation loss: 1.190099\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "26\tValidation loss: 1.188881\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "27\tValidation loss: 1.185355\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "28\tValidation loss: 1.183045\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "29\tValidation loss: 1.179846\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "30\tValidation loss: 1.177564\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "31\tValidation loss: 1.175673\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "32\tValidation loss: 1.173678\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "33\tValidation loss: 1.170931\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.3, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   4.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.994166\tBest loss: 3.994166\tAccuracy: 3.60%\n",
      "1\tValidation loss: 3.818085\tBest loss: 3.818085\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.860402\tBest loss: 3.818085\tAccuracy: 6.47%\n",
      "3\tValidation loss: 3.826934\tBest loss: 3.818085\tAccuracy: 6.47%\n",
      "4\tValidation loss: 3.812777\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.825700\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "6\tValidation loss: 3.835967\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "7\tValidation loss: 4676.877930\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "8\tValidation loss: 3.814500\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.829723\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.830043\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.831943\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "12\tValidation loss: 3.831775\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.821590\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.814372\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "15\tValidation loss: 3.823787\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.818436\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.833723\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.821157\tBest loss: 3.812777\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.823001\tBest loss: 3.812777\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.812505\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.813695\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.813571\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.837004\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.827038\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "25\tValidation loss: 3.839740\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.825749\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "27\tValidation loss: 3.820734\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.815211\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.836431\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.834504\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.836134\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "32\tValidation loss: 3.821348\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.818179\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.827930\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.814583\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "36\tValidation loss: 3.814571\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "37\tValidation loss: 3.821537\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.820573\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.822592\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "40\tValidation loss: 3.816162\tBest loss: 3.812505\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.815980\tBest loss: 3.812505\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=  24.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.853891\tBest loss: 3.853891\tAccuracy: 3.60%\n",
      "1\tValidation loss: 3.834088\tBest loss: 3.834088\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.829721\tBest loss: 3.829721\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.839921\tBest loss: 3.829721\tAccuracy: 6.47%\n",
      "4\tValidation loss: 3.829281\tBest loss: 3.829281\tAccuracy: 6.47%\n",
      "5\tValidation loss: 3.833132\tBest loss: 3.829281\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.815785\tBest loss: 3.815785\tAccuracy: 6.47%\n",
      "7\tValidation loss: 3.818699\tBest loss: 3.815785\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.817578\tBest loss: 3.815785\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.820118\tBest loss: 3.815785\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.823188\tBest loss: 3.815785\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.816097\tBest loss: 3.815785\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.817975\tBest loss: 3.815785\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.808156\tBest loss: 3.808156\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.811126\tBest loss: 3.808156\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.802822\tBest loss: 3.802822\tAccuracy: 6.47%\n",
      "16\tValidation loss: 3.827215\tBest loss: 3.802822\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.819435\tBest loss: 3.802822\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.793709\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.816628\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.829820\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.819813\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.841805\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "23\tValidation loss: 3.819861\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.832269\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.816211\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.823270\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.804132\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "28\tValidation loss: 3.814384\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.815703\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.819558\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "31\tValidation loss: 3.810843\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.814575\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.809785\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "34\tValidation loss: 3.825628\tBest loss: 3.793709\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\tValidation loss: 3.802409\tBest loss: 3.793709\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.820516\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "37\tValidation loss: 3.803730\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "38\tValidation loss: 3.801605\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.816671\tBest loss: 3.793709\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=  24.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.804376\tBest loss: 3.804376\tAccuracy: 6.47%\n",
      "1\tValidation loss: 3.809803\tBest loss: 3.804376\tAccuracy: 6.47%\n",
      "2\tValidation loss: 3.799619\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "3\tValidation loss: 3.820187\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "4\tValidation loss: 3.822607\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.825471\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.838146\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.819809\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "8\tValidation loss: 3.815232\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.818463\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.814271\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "11\tValidation loss: 3.822901\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.831524\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.823187\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.824331\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.818938\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "16\tValidation loss: 3.828208\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.817155\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "18\tValidation loss: 3.822590\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.838048\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.821698\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.818270\tBest loss: 3.799619\tAccuracy: 6.47%\n",
      "22\tValidation loss: 3.817580\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.827881\tBest loss: 3.799619\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.05, dropout_rate=0.3, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=  14.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.750136\tBest loss: 3.750136\tAccuracy: 30.22%\n",
      "1\tValidation loss: 5.166069\tBest loss: 3.750136\tAccuracy: 19.42%\n",
      "2\tValidation loss: 4.942630\tBest loss: 3.750136\tAccuracy: 15.83%\n",
      "3\tValidation loss: 26.010689\tBest loss: 3.750136\tAccuracy: 5.04%\n",
      "4\tValidation loss: 44.404423\tBest loss: 3.750136\tAccuracy: 6.47%\n",
      "5\tValidation loss: 10.190509\tBest loss: 3.750136\tAccuracy: 9.35%\n",
      "6\tValidation loss: 4.120443\tBest loss: 3.750136\tAccuracy: 11.51%\n",
      "7\tValidation loss: 3.824320\tBest loss: 3.750136\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.821103\tBest loss: 3.750136\tAccuracy: 6.47%\n",
      "9\tValidation loss: 3.791060\tBest loss: 3.750136\tAccuracy: 5.04%\n",
      "10\tValidation loss: 3.675415\tBest loss: 3.675415\tAccuracy: 6.47%\n",
      "11\tValidation loss: 4.674513\tBest loss: 3.675415\tAccuracy: 5.04%\n",
      "12\tValidation loss: 3.808919\tBest loss: 3.675415\tAccuracy: 4.32%\n",
      "13\tValidation loss: 3.762620\tBest loss: 3.675415\tAccuracy: 4.32%\n",
      "14\tValidation loss: 3.435833\tBest loss: 3.435833\tAccuracy: 9.35%\n",
      "15\tValidation loss: 3.528824\tBest loss: 3.435833\tAccuracy: 11.51%\n",
      "16\tValidation loss: 3.694589\tBest loss: 3.435833\tAccuracy: 7.19%\n",
      "17\tValidation loss: 3.691342\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.680608\tBest loss: 3.435833\tAccuracy: 5.76%\n",
      "19\tValidation loss: 3.642519\tBest loss: 3.435833\tAccuracy: 4.32%\n",
      "20\tValidation loss: 3.737686\tBest loss: 3.435833\tAccuracy: 5.76%\n",
      "21\tValidation loss: 3.688340\tBest loss: 3.435833\tAccuracy: 5.76%\n",
      "22\tValidation loss: 3.738995\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.652719\tBest loss: 3.435833\tAccuracy: 9.35%\n",
      "24\tValidation loss: 3.737861\tBest loss: 3.435833\tAccuracy: 2.88%\n",
      "25\tValidation loss: 3.678661\tBest loss: 3.435833\tAccuracy: 5.76%\n",
      "26\tValidation loss: 3.762593\tBest loss: 3.435833\tAccuracy: 2.88%\n",
      "27\tValidation loss: 3.795717\tBest loss: 3.435833\tAccuracy: 1.44%\n",
      "28\tValidation loss: 3.704777\tBest loss: 3.435833\tAccuracy: 6.47%\n",
      "29\tValidation loss: 3.747448\tBest loss: 3.435833\tAccuracy: 5.04%\n",
      "30\tValidation loss: 3.784468\tBest loss: 3.435833\tAccuracy: 2.16%\n",
      "31\tValidation loss: 3.742084\tBest loss: 3.435833\tAccuracy: 5.76%\n",
      "32\tValidation loss: 3.808546\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.806521\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.805516\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.799194\tBest loss: 3.435833\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   7.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 4.507265\tBest loss: 4.507265\tAccuracy: 17.27%\n",
      "1\tValidation loss: 4.749967\tBest loss: 4.507265\tAccuracy: 14.39%\n",
      "2\tValidation loss: 4.574401\tBest loss: 4.507265\tAccuracy: 18.71%\n",
      "3\tValidation loss: 8.879236\tBest loss: 4.507265\tAccuracy: 6.47%\n",
      "4\tValidation loss: 5.269712\tBest loss: 4.507265\tAccuracy: 8.63%\n",
      "5\tValidation loss: 3.958997\tBest loss: 3.958997\tAccuracy: 3.60%\n",
      "6\tValidation loss: 5.214985\tBest loss: 3.958997\tAccuracy: 4.32%\n",
      "7\tValidation loss: 3.969481\tBest loss: 3.958997\tAccuracy: 3.60%\n",
      "8\tValidation loss: 4.914867\tBest loss: 3.958997\tAccuracy: 5.04%\n",
      "9\tValidation loss: 35.670357\tBest loss: 3.958997\tAccuracy: 1.44%\n",
      "10\tValidation loss: 3.830506\tBest loss: 3.830506\tAccuracy: 2.16%\n",
      "11\tValidation loss: 3.821038\tBest loss: 3.821038\tAccuracy: 4.32%\n",
      "12\tValidation loss: 3.829298\tBest loss: 3.821038\tAccuracy: 4.32%\n",
      "13\tValidation loss: 3.807430\tBest loss: 3.807430\tAccuracy: 7.19%\n",
      "14\tValidation loss: 3.828303\tBest loss: 3.807430\tAccuracy: 6.47%\n",
      "15\tValidation loss: 3.821228\tBest loss: 3.807430\tAccuracy: 6.47%\n",
      "16\tValidation loss: 3.777862\tBest loss: 3.777862\tAccuracy: 7.91%\n",
      "17\tValidation loss: 3.748412\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "18\tValidation loss: 3.787700\tBest loss: 3.748412\tAccuracy: 7.19%\n",
      "19\tValidation loss: 3.787694\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "20\tValidation loss: 3.788625\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "21\tValidation loss: 43.747963\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "22\tValidation loss: 3.791352\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "23\tValidation loss: 35.720955\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "24\tValidation loss: 31.887304\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "25\tValidation loss: 3.788955\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "26\tValidation loss: 3.785062\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "27\tValidation loss: 3.783319\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "28\tValidation loss: 3.781426\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "29\tValidation loss: 3.776440\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "30\tValidation loss: 3.762165\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "31\tValidation loss: 3.781998\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "32\tValidation loss: 3.752931\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "33\tValidation loss: 3.751980\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "34\tValidation loss: 3.750486\tBest loss: 3.748412\tAccuracy: 5.04%\n",
      "35\tValidation loss: 3.788265\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "36\tValidation loss: 3.788652\tBest loss: 3.748412\tAccuracy: 4.32%\n",
      "37\tValidation loss: 3.745531\tBest loss: 3.745531\tAccuracy: 5.04%\n",
      "38\tValidation loss: 54.695374\tBest loss: 3.745531\tAccuracy: 5.04%\n",
      "39\tValidation loss: 41.002373\tBest loss: 3.745531\tAccuracy: 2.88%\n",
      "40\tValidation loss: 6.440461\tBest loss: 3.745531\tAccuracy: 4.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\tValidation loss: 3.753243\tBest loss: 3.745531\tAccuracy: 5.04%\n",
      "42\tValidation loss: 3.740388\tBest loss: 3.740388\tAccuracy: 7.91%\n",
      "43\tValidation loss: 3.777868\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "44\tValidation loss: 3.814044\tBest loss: 3.740388\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.776873\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "46\tValidation loss: 3.776887\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "47\tValidation loss: 3.776421\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "48\tValidation loss: 3.776295\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "49\tValidation loss: 3.776112\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "50\tValidation loss: 3.776551\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "51\tValidation loss: 3.765077\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "52\tValidation loss: 3.764649\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "53\tValidation loss: 3.764538\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "54\tValidation loss: 3.762312\tBest loss: 3.740388\tAccuracy: 7.19%\n",
      "55\tValidation loss: 3.762521\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "56\tValidation loss: 3.763446\tBest loss: 3.740388\tAccuracy: 7.19%\n",
      "57\tValidation loss: 3.761754\tBest loss: 3.740388\tAccuracy: 7.19%\n",
      "58\tValidation loss: 3.762188\tBest loss: 3.740388\tAccuracy: 7.19%\n",
      "59\tValidation loss: 3.763492\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "60\tValidation loss: 3.765028\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "61\tValidation loss: 3.764558\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "62\tValidation loss: 3.764999\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "63\tValidation loss: 3.759897\tBest loss: 3.740388\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  12.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 4.005316\tBest loss: 4.005316\tAccuracy: 24.46%\n",
      "1\tValidation loss: 10.030501\tBest loss: 4.005316\tAccuracy: 14.39%\n",
      "2\tValidation loss: 24.070642\tBest loss: 4.005316\tAccuracy: 2.88%\n",
      "3\tValidation loss: 6.535654\tBest loss: 4.005316\tAccuracy: 17.99%\n",
      "4\tValidation loss: 8.364150\tBest loss: 4.005316\tAccuracy: 10.79%\n",
      "5\tValidation loss: 10.974322\tBest loss: 4.005316\tAccuracy: 10.79%\n",
      "6\tValidation loss: 3.781625\tBest loss: 3.781625\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.752508\tBest loss: 3.752508\tAccuracy: 6.47%\n",
      "8\tValidation loss: 3.452478\tBest loss: 3.452478\tAccuracy: 15.83%\n",
      "9\tValidation loss: 3.716230\tBest loss: 3.452478\tAccuracy: 5.04%\n",
      "10\tValidation loss: 3.799067\tBest loss: 3.452478\tAccuracy: 2.16%\n",
      "11\tValidation loss: 3.870416\tBest loss: 3.452478\tAccuracy: 7.91%\n",
      "12\tValidation loss: 3.831947\tBest loss: 3.452478\tAccuracy: 6.47%\n",
      "13\tValidation loss: 3.803979\tBest loss: 3.452478\tAccuracy: 6.47%\n",
      "14\tValidation loss: 4.534881\tBest loss: 3.452478\tAccuracy: 5.76%\n",
      "15\tValidation loss: 3.599484\tBest loss: 3.452478\tAccuracy: 11.51%\n",
      "16\tValidation loss: 3.791360\tBest loss: 3.452478\tAccuracy: 7.19%\n",
      "17\tValidation loss: 3.720443\tBest loss: 3.452478\tAccuracy: 9.35%\n",
      "18\tValidation loss: 3.815988\tBest loss: 3.452478\tAccuracy: 6.47%\n",
      "19\tValidation loss: 3.814971\tBest loss: 3.452478\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.813716\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.812805\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.813435\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.768751\tBest loss: 3.452478\tAccuracy: 4.32%\n",
      "24\tValidation loss: 3.786242\tBest loss: 3.452478\tAccuracy: 4.32%\n",
      "25\tValidation loss: 3.786329\tBest loss: 3.452478\tAccuracy: 4.32%\n",
      "26\tValidation loss: 3.813019\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.812445\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.811035\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.810884\tBest loss: 3.452478\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.4, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   6.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 10.551769\tBest loss: 10.551769\tAccuracy: 8.63%\n",
      "1\tValidation loss: 2.434773\tBest loss: 2.434773\tAccuracy: 37.41%\n",
      "2\tValidation loss: 1.636212\tBest loss: 1.636212\tAccuracy: 55.40%\n",
      "3\tValidation loss: 1.264466\tBest loss: 1.264466\tAccuracy: 64.75%\n",
      "4\tValidation loss: 1.473241\tBest loss: 1.264466\tAccuracy: 61.87%\n",
      "5\tValidation loss: 1.043726\tBest loss: 1.043726\tAccuracy: 70.50%\n",
      "6\tValidation loss: 1.015549\tBest loss: 1.015549\tAccuracy: 74.82%\n",
      "7\tValidation loss: 0.855822\tBest loss: 0.855822\tAccuracy: 81.29%\n",
      "8\tValidation loss: 0.803164\tBest loss: 0.803164\tAccuracy: 78.42%\n",
      "9\tValidation loss: 0.755823\tBest loss: 0.755823\tAccuracy: 81.29%\n",
      "10\tValidation loss: 0.770150\tBest loss: 0.755823\tAccuracy: 79.86%\n",
      "11\tValidation loss: 0.723187\tBest loss: 0.723187\tAccuracy: 81.29%\n",
      "12\tValidation loss: 0.668792\tBest loss: 0.668792\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.644422\tBest loss: 0.644422\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.654905\tBest loss: 0.644422\tAccuracy: 82.73%\n",
      "15\tValidation loss: 0.692442\tBest loss: 0.644422\tAccuracy: 85.61%\n",
      "16\tValidation loss: 0.558130\tBest loss: 0.558130\tAccuracy: 87.05%\n",
      "17\tValidation loss: 0.531175\tBest loss: 0.531175\tAccuracy: 88.49%\n",
      "18\tValidation loss: 0.515332\tBest loss: 0.515332\tAccuracy: 87.05%\n",
      "19\tValidation loss: 0.526775\tBest loss: 0.515332\tAccuracy: 87.77%\n",
      "20\tValidation loss: 0.508451\tBest loss: 0.508451\tAccuracy: 89.21%\n",
      "21\tValidation loss: 0.504448\tBest loss: 0.504448\tAccuracy: 88.49%\n",
      "22\tValidation loss: 0.480626\tBest loss: 0.480626\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.464728\tBest loss: 0.464728\tAccuracy: 90.65%\n",
      "24\tValidation loss: 0.435023\tBest loss: 0.435023\tAccuracy: 89.93%\n",
      "25\tValidation loss: 0.435212\tBest loss: 0.435023\tAccuracy: 87.77%\n",
      "26\tValidation loss: 0.443295\tBest loss: 0.435023\tAccuracy: 87.77%\n",
      "27\tValidation loss: 0.434519\tBest loss: 0.434519\tAccuracy: 88.49%\n",
      "28\tValidation loss: 0.421318\tBest loss: 0.421318\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.436656\tBest loss: 0.421318\tAccuracy: 87.77%\n",
      "30\tValidation loss: 0.394910\tBest loss: 0.394910\tAccuracy: 89.93%\n",
      "31\tValidation loss: 0.394844\tBest loss: 0.394844\tAccuracy: 88.49%\n",
      "32\tValidation loss: 0.404349\tBest loss: 0.394844\tAccuracy: 87.77%\n",
      "33\tValidation loss: 0.383145\tBest loss: 0.383145\tAccuracy: 87.05%\n",
      "34\tValidation loss: 0.380410\tBest loss: 0.380410\tAccuracy: 89.93%\n",
      "35\tValidation loss: 0.402840\tBest loss: 0.380410\tAccuracy: 87.05%\n",
      "36\tValidation loss: 0.360322\tBest loss: 0.360322\tAccuracy: 89.93%\n",
      "37\tValidation loss: 0.363731\tBest loss: 0.360322\tAccuracy: 92.09%\n",
      "38\tValidation loss: 0.366101\tBest loss: 0.360322\tAccuracy: 87.77%\n",
      "39\tValidation loss: 0.380146\tBest loss: 0.360322\tAccuracy: 87.05%\n",
      "40\tValidation loss: 0.364620\tBest loss: 0.360322\tAccuracy: 90.65%\n",
      "41\tValidation loss: 0.325502\tBest loss: 0.325502\tAccuracy: 92.09%\n",
      "42\tValidation loss: 0.322502\tBest loss: 0.322502\tAccuracy: 92.09%\n",
      "43\tValidation loss: 0.334140\tBest loss: 0.322502\tAccuracy: 90.65%\n",
      "44\tValidation loss: 0.365157\tBest loss: 0.322502\tAccuracy: 88.49%\n",
      "45\tValidation loss: 0.359222\tBest loss: 0.322502\tAccuracy: 89.93%\n",
      "46\tValidation loss: 0.361279\tBest loss: 0.322502\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.331050\tBest loss: 0.322502\tAccuracy: 89.93%\n",
      "48\tValidation loss: 0.331028\tBest loss: 0.322502\tAccuracy: 91.37%\n",
      "49\tValidation loss: 0.314249\tBest loss: 0.314249\tAccuracy: 92.09%\n",
      "50\tValidation loss: 0.319343\tBest loss: 0.314249\tAccuracy: 89.93%\n",
      "51\tValidation loss: 0.307027\tBest loss: 0.307027\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.309922\tBest loss: 0.307027\tAccuracy: 90.65%\n",
      "53\tValidation loss: 0.311783\tBest loss: 0.307027\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.325188\tBest loss: 0.307027\tAccuracy: 87.05%\n",
      "55\tValidation loss: 0.303166\tBest loss: 0.303166\tAccuracy: 89.21%\n",
      "56\tValidation loss: 0.317061\tBest loss: 0.303166\tAccuracy: 87.77%\n",
      "57\tValidation loss: 0.300146\tBest loss: 0.300146\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\tValidation loss: 0.278376\tBest loss: 0.278376\tAccuracy: 91.37%\n",
      "59\tValidation loss: 0.278227\tBest loss: 0.278227\tAccuracy: 92.09%\n",
      "60\tValidation loss: 0.291869\tBest loss: 0.278227\tAccuracy: 92.09%\n",
      "61\tValidation loss: 0.292974\tBest loss: 0.278227\tAccuracy: 91.37%\n",
      "62\tValidation loss: 0.303885\tBest loss: 0.278227\tAccuracy: 89.21%\n",
      "63\tValidation loss: 0.281981\tBest loss: 0.278227\tAccuracy: 90.65%\n",
      "64\tValidation loss: 0.258705\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "65\tValidation loss: 0.286579\tBest loss: 0.258705\tAccuracy: 89.93%\n",
      "66\tValidation loss: 0.273967\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "67\tValidation loss: 0.274639\tBest loss: 0.258705\tAccuracy: 92.09%\n",
      "68\tValidation loss: 0.267874\tBest loss: 0.258705\tAccuracy: 92.81%\n",
      "69\tValidation loss: 0.273912\tBest loss: 0.258705\tAccuracy: 92.09%\n",
      "70\tValidation loss: 0.278148\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "71\tValidation loss: 0.271254\tBest loss: 0.258705\tAccuracy: 92.81%\n",
      "72\tValidation loss: 0.281805\tBest loss: 0.258705\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.281013\tBest loss: 0.258705\tAccuracy: 89.93%\n",
      "74\tValidation loss: 0.269453\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "75\tValidation loss: 0.269307\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "76\tValidation loss: 0.281976\tBest loss: 0.258705\tAccuracy: 89.93%\n",
      "77\tValidation loss: 0.286412\tBest loss: 0.258705\tAccuracy: 89.21%\n",
      "78\tValidation loss: 0.264134\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "79\tValidation loss: 0.283230\tBest loss: 0.258705\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.286337\tBest loss: 0.258705\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.269021\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "82\tValidation loss: 0.275591\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "83\tValidation loss: 0.283244\tBest loss: 0.258705\tAccuracy: 89.93%\n",
      "84\tValidation loss: 0.263195\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "85\tValidation loss: 0.275438\tBest loss: 0.258705\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  14.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 41.685169\tBest loss: 41.685169\tAccuracy: 7.91%\n",
      "1\tValidation loss: 5.243692\tBest loss: 5.243692\tAccuracy: 20.14%\n",
      "2\tValidation loss: 1.966438\tBest loss: 1.966438\tAccuracy: 47.48%\n",
      "3\tValidation loss: 1.392023\tBest loss: 1.392023\tAccuracy: 62.59%\n",
      "4\tValidation loss: 1.582431\tBest loss: 1.392023\tAccuracy: 58.99%\n",
      "5\tValidation loss: 1.173651\tBest loss: 1.173651\tAccuracy: 67.63%\n",
      "6\tValidation loss: 1.026917\tBest loss: 1.026917\tAccuracy: 71.94%\n",
      "7\tValidation loss: 1.134660\tBest loss: 1.026917\tAccuracy: 69.78%\n",
      "8\tValidation loss: 0.960892\tBest loss: 0.960892\tAccuracy: 75.54%\n",
      "9\tValidation loss: 0.947002\tBest loss: 0.947002\tAccuracy: 71.94%\n",
      "10\tValidation loss: 0.891552\tBest loss: 0.891552\tAccuracy: 74.10%\n",
      "11\tValidation loss: 0.838655\tBest loss: 0.838655\tAccuracy: 76.98%\n",
      "12\tValidation loss: 0.793438\tBest loss: 0.793438\tAccuracy: 79.86%\n",
      "13\tValidation loss: 0.817554\tBest loss: 0.793438\tAccuracy: 77.70%\n",
      "14\tValidation loss: 0.739232\tBest loss: 0.739232\tAccuracy: 82.01%\n",
      "15\tValidation loss: 0.739679\tBest loss: 0.739232\tAccuracy: 78.42%\n",
      "16\tValidation loss: 0.685818\tBest loss: 0.685818\tAccuracy: 83.45%\n",
      "17\tValidation loss: 0.691464\tBest loss: 0.685818\tAccuracy: 79.86%\n",
      "18\tValidation loss: 0.645428\tBest loss: 0.645428\tAccuracy: 82.01%\n",
      "19\tValidation loss: 0.662387\tBest loss: 0.645428\tAccuracy: 80.58%\n",
      "20\tValidation loss: 0.627441\tBest loss: 0.627441\tAccuracy: 82.01%\n",
      "21\tValidation loss: 0.658082\tBest loss: 0.627441\tAccuracy: 81.29%\n",
      "22\tValidation loss: 0.615818\tBest loss: 0.615818\tAccuracy: 83.45%\n",
      "23\tValidation loss: 0.567068\tBest loss: 0.567068\tAccuracy: 83.45%\n",
      "24\tValidation loss: 0.566741\tBest loss: 0.566741\tAccuracy: 84.17%\n",
      "25\tValidation loss: 0.544694\tBest loss: 0.544694\tAccuracy: 84.89%\n",
      "26\tValidation loss: 0.551056\tBest loss: 0.544694\tAccuracy: 85.61%\n",
      "27\tValidation loss: 0.518630\tBest loss: 0.518630\tAccuracy: 87.77%\n",
      "28\tValidation loss: 0.536122\tBest loss: 0.518630\tAccuracy: 87.05%\n",
      "29\tValidation loss: 0.492018\tBest loss: 0.492018\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.462859\tBest loss: 0.462859\tAccuracy: 89.93%\n",
      "31\tValidation loss: 0.492869\tBest loss: 0.462859\tAccuracy: 86.33%\n",
      "32\tValidation loss: 0.464193\tBest loss: 0.462859\tAccuracy: 89.93%\n",
      "33\tValidation loss: 0.480084\tBest loss: 0.462859\tAccuracy: 86.33%\n",
      "34\tValidation loss: 0.474869\tBest loss: 0.462859\tAccuracy: 86.33%\n",
      "35\tValidation loss: 0.438189\tBest loss: 0.438189\tAccuracy: 89.93%\n",
      "36\tValidation loss: 0.463116\tBest loss: 0.438189\tAccuracy: 86.33%\n",
      "37\tValidation loss: 0.444649\tBest loss: 0.438189\tAccuracy: 90.65%\n",
      "38\tValidation loss: 0.443004\tBest loss: 0.438189\tAccuracy: 88.49%\n",
      "39\tValidation loss: 0.450362\tBest loss: 0.438189\tAccuracy: 89.21%\n",
      "40\tValidation loss: 0.413684\tBest loss: 0.413684\tAccuracy: 89.93%\n",
      "41\tValidation loss: 0.400914\tBest loss: 0.400914\tAccuracy: 88.49%\n",
      "42\tValidation loss: 0.385370\tBest loss: 0.385370\tAccuracy: 90.65%\n",
      "43\tValidation loss: 0.381751\tBest loss: 0.381751\tAccuracy: 92.81%\n",
      "44\tValidation loss: 0.368767\tBest loss: 0.368767\tAccuracy: 90.65%\n",
      "45\tValidation loss: 0.371633\tBest loss: 0.368767\tAccuracy: 92.09%\n",
      "46\tValidation loss: 0.362286\tBest loss: 0.362286\tAccuracy: 91.37%\n",
      "47\tValidation loss: 0.404413\tBest loss: 0.362286\tAccuracy: 89.93%\n",
      "48\tValidation loss: 0.353841\tBest loss: 0.353841\tAccuracy: 89.93%\n",
      "49\tValidation loss: 0.380218\tBest loss: 0.353841\tAccuracy: 89.21%\n",
      "50\tValidation loss: 0.360198\tBest loss: 0.353841\tAccuracy: 90.65%\n",
      "51\tValidation loss: 0.364985\tBest loss: 0.353841\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.353999\tBest loss: 0.353841\tAccuracy: 90.65%\n",
      "53\tValidation loss: 0.380590\tBest loss: 0.353841\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.357549\tBest loss: 0.353841\tAccuracy: 91.37%\n",
      "55\tValidation loss: 0.316750\tBest loss: 0.316750\tAccuracy: 91.37%\n",
      "56\tValidation loss: 0.319023\tBest loss: 0.316750\tAccuracy: 92.09%\n",
      "57\tValidation loss: 0.323455\tBest loss: 0.316750\tAccuracy: 91.37%\n",
      "58\tValidation loss: 0.305763\tBest loss: 0.305763\tAccuracy: 91.37%\n",
      "59\tValidation loss: 0.321218\tBest loss: 0.305763\tAccuracy: 90.65%\n",
      "60\tValidation loss: 0.313301\tBest loss: 0.305763\tAccuracy: 92.09%\n",
      "61\tValidation loss: 0.309482\tBest loss: 0.305763\tAccuracy: 89.93%\n",
      "62\tValidation loss: 0.325816\tBest loss: 0.305763\tAccuracy: 90.65%\n",
      "63\tValidation loss: 0.308933\tBest loss: 0.305763\tAccuracy: 91.37%\n",
      "64\tValidation loss: 0.304820\tBest loss: 0.304820\tAccuracy: 93.53%\n",
      "65\tValidation loss: 0.314546\tBest loss: 0.304820\tAccuracy: 93.53%\n",
      "66\tValidation loss: 0.294470\tBest loss: 0.294470\tAccuracy: 92.09%\n",
      "67\tValidation loss: 0.304468\tBest loss: 0.294470\tAccuracy: 91.37%\n",
      "68\tValidation loss: 0.292099\tBest loss: 0.292099\tAccuracy: 92.81%\n",
      "69\tValidation loss: 0.287411\tBest loss: 0.287411\tAccuracy: 92.09%\n",
      "70\tValidation loss: 0.280537\tBest loss: 0.280537\tAccuracy: 92.09%\n",
      "71\tValidation loss: 0.276890\tBest loss: 0.276890\tAccuracy: 93.53%\n",
      "72\tValidation loss: 0.264799\tBest loss: 0.264799\tAccuracy: 92.81%\n",
      "73\tValidation loss: 0.293753\tBest loss: 0.264799\tAccuracy: 91.37%\n",
      "74\tValidation loss: 0.278604\tBest loss: 0.264799\tAccuracy: 92.09%\n",
      "75\tValidation loss: 0.265081\tBest loss: 0.264799\tAccuracy: 92.81%\n",
      "76\tValidation loss: 0.258201\tBest loss: 0.258201\tAccuracy: 92.09%\n",
      "77\tValidation loss: 0.253958\tBest loss: 0.253958\tAccuracy: 92.81%\n",
      "78\tValidation loss: 0.275737\tBest loss: 0.253958\tAccuracy: 92.09%\n",
      "79\tValidation loss: 0.267049\tBest loss: 0.253958\tAccuracy: 91.37%\n",
      "80\tValidation loss: 0.244606\tBest loss: 0.244606\tAccuracy: 92.81%\n",
      "81\tValidation loss: 0.253443\tBest loss: 0.244606\tAccuracy: 92.81%\n",
      "82\tValidation loss: 0.262360\tBest loss: 0.244606\tAccuracy: 93.53%\n",
      "83\tValidation loss: 0.258449\tBest loss: 0.244606\tAccuracy: 92.09%\n",
      "84\tValidation loss: 0.260047\tBest loss: 0.244606\tAccuracy: 92.81%\n",
      "85\tValidation loss: 0.267653\tBest loss: 0.244606\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.244536\tBest loss: 0.244536\tAccuracy: 91.37%\n",
      "87\tValidation loss: 0.239482\tBest loss: 0.239482\tAccuracy: 94.24%\n",
      "88\tValidation loss: 0.236201\tBest loss: 0.236201\tAccuracy: 93.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\tValidation loss: 0.244152\tBest loss: 0.236201\tAccuracy: 92.81%\n",
      "90\tValidation loss: 0.251212\tBest loss: 0.236201\tAccuracy: 92.09%\n",
      "91\tValidation loss: 0.235639\tBest loss: 0.235639\tAccuracy: 94.24%\n",
      "92\tValidation loss: 0.235638\tBest loss: 0.235638\tAccuracy: 92.81%\n",
      "93\tValidation loss: 0.224915\tBest loss: 0.224915\tAccuracy: 93.53%\n",
      "94\tValidation loss: 0.240040\tBest loss: 0.224915\tAccuracy: 92.09%\n",
      "95\tValidation loss: 0.237764\tBest loss: 0.224915\tAccuracy: 90.65%\n",
      "96\tValidation loss: 0.218260\tBest loss: 0.218260\tAccuracy: 94.96%\n",
      "97\tValidation loss: 0.209884\tBest loss: 0.209884\tAccuracy: 94.96%\n",
      "98\tValidation loss: 0.205490\tBest loss: 0.205490\tAccuracy: 92.09%\n",
      "99\tValidation loss: 0.228716\tBest loss: 0.205490\tAccuracy: 92.81%\n",
      "100\tValidation loss: 0.213217\tBest loss: 0.205490\tAccuracy: 92.81%\n",
      "101\tValidation loss: 0.211540\tBest loss: 0.205490\tAccuracy: 92.09%\n",
      "102\tValidation loss: 0.220029\tBest loss: 0.205490\tAccuracy: 92.09%\n",
      "103\tValidation loss: 0.221162\tBest loss: 0.205490\tAccuracy: 93.53%\n",
      "104\tValidation loss: 0.250335\tBest loss: 0.205490\tAccuracy: 92.81%\n",
      "105\tValidation loss: 0.211534\tBest loss: 0.205490\tAccuracy: 93.53%\n",
      "106\tValidation loss: 0.209956\tBest loss: 0.205490\tAccuracy: 92.81%\n",
      "107\tValidation loss: 0.192342\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "108\tValidation loss: 0.204847\tBest loss: 0.192342\tAccuracy: 92.09%\n",
      "109\tValidation loss: 0.205448\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "110\tValidation loss: 0.216464\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "111\tValidation loss: 0.210320\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "112\tValidation loss: 0.199478\tBest loss: 0.192342\tAccuracy: 94.24%\n",
      "113\tValidation loss: 0.206639\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "114\tValidation loss: 0.202806\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "115\tValidation loss: 0.195929\tBest loss: 0.192342\tAccuracy: 94.24%\n",
      "116\tValidation loss: 0.206097\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "117\tValidation loss: 0.201146\tBest loss: 0.192342\tAccuracy: 94.24%\n",
      "118\tValidation loss: 0.196722\tBest loss: 0.192342\tAccuracy: 94.24%\n",
      "119\tValidation loss: 0.195629\tBest loss: 0.192342\tAccuracy: 94.24%\n",
      "120\tValidation loss: 0.207391\tBest loss: 0.192342\tAccuracy: 93.53%\n",
      "121\tValidation loss: 0.194783\tBest loss: 0.192342\tAccuracy: 94.96%\n",
      "122\tValidation loss: 0.189846\tBest loss: 0.189846\tAccuracy: 93.53%\n",
      "123\tValidation loss: 0.198321\tBest loss: 0.189846\tAccuracy: 92.09%\n",
      "124\tValidation loss: 0.191087\tBest loss: 0.189846\tAccuracy: 94.24%\n",
      "125\tValidation loss: 0.188639\tBest loss: 0.188639\tAccuracy: 93.53%\n",
      "126\tValidation loss: 0.196460\tBest loss: 0.188639\tAccuracy: 94.96%\n",
      "127\tValidation loss: 0.187050\tBest loss: 0.187050\tAccuracy: 94.24%\n",
      "128\tValidation loss: 0.188475\tBest loss: 0.187050\tAccuracy: 94.24%\n",
      "129\tValidation loss: 0.186277\tBest loss: 0.186277\tAccuracy: 92.81%\n",
      "130\tValidation loss: 0.177462\tBest loss: 0.177462\tAccuracy: 94.24%\n",
      "131\tValidation loss: 0.182757\tBest loss: 0.177462\tAccuracy: 95.68%\n",
      "132\tValidation loss: 0.173619\tBest loss: 0.173619\tAccuracy: 95.68%\n",
      "133\tValidation loss: 0.162167\tBest loss: 0.162167\tAccuracy: 95.68%\n",
      "134\tValidation loss: 0.165469\tBest loss: 0.162167\tAccuracy: 94.96%\n",
      "135\tValidation loss: 0.166434\tBest loss: 0.162167\tAccuracy: 94.96%\n",
      "136\tValidation loss: 0.162770\tBest loss: 0.162167\tAccuracy: 93.53%\n",
      "137\tValidation loss: 0.165849\tBest loss: 0.162167\tAccuracy: 94.24%\n",
      "138\tValidation loss: 0.169345\tBest loss: 0.162167\tAccuracy: 94.96%\n",
      "139\tValidation loss: 0.169945\tBest loss: 0.162167\tAccuracy: 94.24%\n",
      "140\tValidation loss: 0.165427\tBest loss: 0.162167\tAccuracy: 94.96%\n",
      "141\tValidation loss: 0.155931\tBest loss: 0.155931\tAccuracy: 94.24%\n",
      "142\tValidation loss: 0.161271\tBest loss: 0.155931\tAccuracy: 95.68%\n",
      "143\tValidation loss: 0.163399\tBest loss: 0.155931\tAccuracy: 96.40%\n",
      "144\tValidation loss: 0.177114\tBest loss: 0.155931\tAccuracy: 95.68%\n",
      "145\tValidation loss: 0.198806\tBest loss: 0.155931\tAccuracy: 94.24%\n",
      "146\tValidation loss: 0.192202\tBest loss: 0.155931\tAccuracy: 93.53%\n",
      "147\tValidation loss: 0.164032\tBest loss: 0.155931\tAccuracy: 94.96%\n",
      "148\tValidation loss: 0.155166\tBest loss: 0.155166\tAccuracy: 94.96%\n",
      "149\tValidation loss: 0.154770\tBest loss: 0.154770\tAccuracy: 94.96%\n",
      "150\tValidation loss: 0.158132\tBest loss: 0.154770\tAccuracy: 95.68%\n",
      "151\tValidation loss: 0.168918\tBest loss: 0.154770\tAccuracy: 94.96%\n",
      "152\tValidation loss: 0.158480\tBest loss: 0.154770\tAccuracy: 94.96%\n",
      "153\tValidation loss: 0.165141\tBest loss: 0.154770\tAccuracy: 94.24%\n",
      "154\tValidation loss: 0.165553\tBest loss: 0.154770\tAccuracy: 94.24%\n",
      "155\tValidation loss: 0.160150\tBest loss: 0.154770\tAccuracy: 93.53%\n",
      "156\tValidation loss: 0.150684\tBest loss: 0.150684\tAccuracy: 93.53%\n",
      "157\tValidation loss: 0.150710\tBest loss: 0.150684\tAccuracy: 95.68%\n",
      "158\tValidation loss: 0.163565\tBest loss: 0.150684\tAccuracy: 94.24%\n",
      "159\tValidation loss: 0.154643\tBest loss: 0.150684\tAccuracy: 94.24%\n",
      "160\tValidation loss: 0.146646\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "161\tValidation loss: 0.170117\tBest loss: 0.146646\tAccuracy: 95.68%\n",
      "162\tValidation loss: 0.155552\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "163\tValidation loss: 0.160577\tBest loss: 0.146646\tAccuracy: 94.24%\n",
      "164\tValidation loss: 0.173658\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "165\tValidation loss: 0.167838\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "166\tValidation loss: 0.166482\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "167\tValidation loss: 0.175399\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "168\tValidation loss: 0.161879\tBest loss: 0.146646\tAccuracy: 94.24%\n",
      "169\tValidation loss: 0.159411\tBest loss: 0.146646\tAccuracy: 95.68%\n",
      "170\tValidation loss: 0.154155\tBest loss: 0.146646\tAccuracy: 94.24%\n",
      "171\tValidation loss: 0.155635\tBest loss: 0.146646\tAccuracy: 94.24%\n",
      "172\tValidation loss: 0.154469\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "173\tValidation loss: 0.159547\tBest loss: 0.146646\tAccuracy: 94.24%\n",
      "174\tValidation loss: 0.154407\tBest loss: 0.146646\tAccuracy: 94.96%\n",
      "175\tValidation loss: 0.142625\tBest loss: 0.142625\tAccuracy: 96.40%\n",
      "176\tValidation loss: 0.135637\tBest loss: 0.135637\tAccuracy: 96.40%\n",
      "177\tValidation loss: 0.142715\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "178\tValidation loss: 0.145155\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "179\tValidation loss: 0.148364\tBest loss: 0.135637\tAccuracy: 94.24%\n",
      "180\tValidation loss: 0.151018\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "181\tValidation loss: 0.155874\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "182\tValidation loss: 0.146993\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "183\tValidation loss: 0.143963\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "184\tValidation loss: 0.159708\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "185\tValidation loss: 0.163287\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "186\tValidation loss: 0.166092\tBest loss: 0.135637\tAccuracy: 93.53%\n",
      "187\tValidation loss: 0.173797\tBest loss: 0.135637\tAccuracy: 94.24%\n",
      "188\tValidation loss: 0.162862\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "189\tValidation loss: 0.159848\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "190\tValidation loss: 0.157053\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "191\tValidation loss: 0.151063\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "192\tValidation loss: 0.141306\tBest loss: 0.135637\tAccuracy: 96.40%\n",
      "193\tValidation loss: 0.143069\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "194\tValidation loss: 0.143121\tBest loss: 0.135637\tAccuracy: 95.68%\n",
      "195\tValidation loss: 0.143234\tBest loss: 0.135637\tAccuracy: 94.96%\n",
      "196\tValidation loss: 0.151823\tBest loss: 0.135637\tAccuracy: 94.24%\n",
      "197\tValidation loss: 0.155322\tBest loss: 0.135637\tAccuracy: 93.53%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  32.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 139.149521\tBest loss: 139.149521\tAccuracy: 3.60%\n",
      "1\tValidation loss: 4.401121\tBest loss: 4.401121\tAccuracy: 28.06%\n",
      "2\tValidation loss: 2.532996\tBest loss: 2.532996\tAccuracy: 46.04%\n",
      "3\tValidation loss: 1.651434\tBest loss: 1.651434\tAccuracy: 59.71%\n",
      "4\tValidation loss: 1.395869\tBest loss: 1.395869\tAccuracy: 59.71%\n",
      "5\tValidation loss: 1.103685\tBest loss: 1.103685\tAccuracy: 72.66%\n",
      "6\tValidation loss: 1.149374\tBest loss: 1.103685\tAccuracy: 67.63%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\tValidation loss: 0.889741\tBest loss: 0.889741\tAccuracy: 78.42%\n",
      "8\tValidation loss: 0.912454\tBest loss: 0.889741\tAccuracy: 79.14%\n",
      "9\tValidation loss: 0.758666\tBest loss: 0.758666\tAccuracy: 81.29%\n",
      "10\tValidation loss: 0.882119\tBest loss: 0.758666\tAccuracy: 76.98%\n",
      "11\tValidation loss: 0.743559\tBest loss: 0.743559\tAccuracy: 80.58%\n",
      "12\tValidation loss: 0.730151\tBest loss: 0.730151\tAccuracy: 82.01%\n",
      "13\tValidation loss: 0.658392\tBest loss: 0.658392\tAccuracy: 84.17%\n",
      "14\tValidation loss: 0.665115\tBest loss: 0.658392\tAccuracy: 82.73%\n",
      "15\tValidation loss: 0.606627\tBest loss: 0.606627\tAccuracy: 83.45%\n",
      "16\tValidation loss: 0.626515\tBest loss: 0.606627\tAccuracy: 84.17%\n",
      "17\tValidation loss: 0.570091\tBest loss: 0.570091\tAccuracy: 84.17%\n",
      "18\tValidation loss: 0.536613\tBest loss: 0.536613\tAccuracy: 88.49%\n",
      "19\tValidation loss: 0.543038\tBest loss: 0.536613\tAccuracy: 87.05%\n",
      "20\tValidation loss: 0.531069\tBest loss: 0.531069\tAccuracy: 85.61%\n",
      "21\tValidation loss: 0.506560\tBest loss: 0.506560\tAccuracy: 85.61%\n",
      "22\tValidation loss: 0.503520\tBest loss: 0.503520\tAccuracy: 87.77%\n",
      "23\tValidation loss: 0.489915\tBest loss: 0.489915\tAccuracy: 87.77%\n",
      "24\tValidation loss: 0.477825\tBest loss: 0.477825\tAccuracy: 89.21%\n",
      "25\tValidation loss: 0.504111\tBest loss: 0.477825\tAccuracy: 86.33%\n",
      "26\tValidation loss: 0.502166\tBest loss: 0.477825\tAccuracy: 85.61%\n",
      "27\tValidation loss: 0.469184\tBest loss: 0.469184\tAccuracy: 87.77%\n",
      "28\tValidation loss: 0.436773\tBest loss: 0.436773\tAccuracy: 87.77%\n",
      "29\tValidation loss: 0.431028\tBest loss: 0.431028\tAccuracy: 88.49%\n",
      "30\tValidation loss: 0.414464\tBest loss: 0.414464\tAccuracy: 89.21%\n",
      "31\tValidation loss: 0.463000\tBest loss: 0.414464\tAccuracy: 87.77%\n",
      "32\tValidation loss: 0.397547\tBest loss: 0.397547\tAccuracy: 90.65%\n",
      "33\tValidation loss: 0.397702\tBest loss: 0.397547\tAccuracy: 89.93%\n",
      "34\tValidation loss: 0.377014\tBest loss: 0.377014\tAccuracy: 90.65%\n",
      "35\tValidation loss: 0.369722\tBest loss: 0.369722\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.383523\tBest loss: 0.369722\tAccuracy: 89.93%\n",
      "37\tValidation loss: 0.370127\tBest loss: 0.369722\tAccuracy: 90.65%\n",
      "38\tValidation loss: 0.380645\tBest loss: 0.369722\tAccuracy: 91.37%\n",
      "39\tValidation loss: 0.366572\tBest loss: 0.366572\tAccuracy: 91.37%\n",
      "40\tValidation loss: 0.375253\tBest loss: 0.366572\tAccuracy: 89.21%\n",
      "41\tValidation loss: 0.390905\tBest loss: 0.366572\tAccuracy: 88.49%\n",
      "42\tValidation loss: 0.391430\tBest loss: 0.366572\tAccuracy: 88.49%\n",
      "43\tValidation loss: 0.370049\tBest loss: 0.366572\tAccuracy: 89.93%\n",
      "44\tValidation loss: 0.356998\tBest loss: 0.356998\tAccuracy: 89.21%\n",
      "45\tValidation loss: 0.360121\tBest loss: 0.356998\tAccuracy: 89.93%\n",
      "46\tValidation loss: 0.372315\tBest loss: 0.356998\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.375819\tBest loss: 0.356998\tAccuracy: 88.49%\n",
      "48\tValidation loss: 0.361242\tBest loss: 0.356998\tAccuracy: 89.21%\n",
      "49\tValidation loss: 0.348167\tBest loss: 0.348167\tAccuracy: 89.21%\n",
      "50\tValidation loss: 0.332848\tBest loss: 0.332848\tAccuracy: 90.65%\n",
      "51\tValidation loss: 0.334713\tBest loss: 0.332848\tAccuracy: 89.93%\n",
      "52\tValidation loss: 0.377513\tBest loss: 0.332848\tAccuracy: 89.21%\n",
      "53\tValidation loss: 0.342890\tBest loss: 0.332848\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.326369\tBest loss: 0.326369\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.342328\tBest loss: 0.326369\tAccuracy: 90.65%\n",
      "56\tValidation loss: 0.312285\tBest loss: 0.312285\tAccuracy: 91.37%\n",
      "57\tValidation loss: 0.309816\tBest loss: 0.309816\tAccuracy: 90.65%\n",
      "58\tValidation loss: 0.301910\tBest loss: 0.301910\tAccuracy: 89.93%\n",
      "59\tValidation loss: 0.311507\tBest loss: 0.301910\tAccuracy: 91.37%\n",
      "60\tValidation loss: 0.299229\tBest loss: 0.299229\tAccuracy: 90.65%\n",
      "61\tValidation loss: 0.302597\tBest loss: 0.299229\tAccuracy: 90.65%\n",
      "62\tValidation loss: 0.292285\tBest loss: 0.292285\tAccuracy: 90.65%\n",
      "63\tValidation loss: 0.289736\tBest loss: 0.289736\tAccuracy: 89.93%\n",
      "64\tValidation loss: 0.294611\tBest loss: 0.289736\tAccuracy: 90.65%\n",
      "65\tValidation loss: 0.314881\tBest loss: 0.289736\tAccuracy: 89.21%\n",
      "66\tValidation loss: 0.289267\tBest loss: 0.289267\tAccuracy: 88.49%\n",
      "67\tValidation loss: 0.281324\tBest loss: 0.281324\tAccuracy: 90.65%\n",
      "68\tValidation loss: 0.279861\tBest loss: 0.279861\tAccuracy: 89.93%\n",
      "69\tValidation loss: 0.258200\tBest loss: 0.258200\tAccuracy: 92.09%\n",
      "70\tValidation loss: 0.286158\tBest loss: 0.258200\tAccuracy: 89.21%\n",
      "71\tValidation loss: 0.288413\tBest loss: 0.258200\tAccuracy: 89.21%\n",
      "72\tValidation loss: 0.265248\tBest loss: 0.258200\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.261498\tBest loss: 0.258200\tAccuracy: 90.65%\n",
      "74\tValidation loss: 0.264146\tBest loss: 0.258200\tAccuracy: 89.93%\n",
      "75\tValidation loss: 0.285342\tBest loss: 0.258200\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.274250\tBest loss: 0.258200\tAccuracy: 89.93%\n",
      "77\tValidation loss: 0.269601\tBest loss: 0.258200\tAccuracy: 90.65%\n",
      "78\tValidation loss: 0.255123\tBest loss: 0.255123\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.260682\tBest loss: 0.255123\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.252634\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.268504\tBest loss: 0.252634\tAccuracy: 91.37%\n",
      "82\tValidation loss: 0.273990\tBest loss: 0.252634\tAccuracy: 89.21%\n",
      "83\tValidation loss: 0.258621\tBest loss: 0.252634\tAccuracy: 89.21%\n",
      "84\tValidation loss: 0.263135\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "85\tValidation loss: 0.259702\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.265506\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "87\tValidation loss: 0.264740\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "88\tValidation loss: 0.264765\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "89\tValidation loss: 0.260947\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "90\tValidation loss: 0.261079\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "91\tValidation loss: 0.264814\tBest loss: 0.252634\tAccuracy: 91.37%\n",
      "92\tValidation loss: 0.269896\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "93\tValidation loss: 0.256427\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "94\tValidation loss: 0.273958\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.286208\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "96\tValidation loss: 0.273660\tBest loss: 0.252634\tAccuracy: 89.93%\n",
      "97\tValidation loss: 0.260795\tBest loss: 0.252634\tAccuracy: 90.65%\n",
      "98\tValidation loss: 0.270091\tBest loss: 0.252634\tAccuracy: 92.09%\n",
      "99\tValidation loss: 0.245999\tBest loss: 0.245999\tAccuracy: 92.09%\n",
      "100\tValidation loss: 0.242522\tBest loss: 0.242522\tAccuracy: 92.09%\n",
      "101\tValidation loss: 0.239678\tBest loss: 0.239678\tAccuracy: 91.37%\n",
      "102\tValidation loss: 0.236872\tBest loss: 0.236872\tAccuracy: 92.09%\n",
      "103\tValidation loss: 0.242981\tBest loss: 0.236872\tAccuracy: 91.37%\n",
      "104\tValidation loss: 0.232663\tBest loss: 0.232663\tAccuracy: 92.09%\n",
      "105\tValidation loss: 0.250621\tBest loss: 0.232663\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.252506\tBest loss: 0.232663\tAccuracy: 91.37%\n",
      "107\tValidation loss: 0.239413\tBest loss: 0.232663\tAccuracy: 92.09%\n",
      "108\tValidation loss: 0.243200\tBest loss: 0.232663\tAccuracy: 91.37%\n",
      "109\tValidation loss: 0.243958\tBest loss: 0.232663\tAccuracy: 92.09%\n",
      "110\tValidation loss: 0.237509\tBest loss: 0.232663\tAccuracy: 92.81%\n",
      "111\tValidation loss: 0.249896\tBest loss: 0.232663\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.248116\tBest loss: 0.232663\tAccuracy: 91.37%\n",
      "113\tValidation loss: 0.242323\tBest loss: 0.232663\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.244307\tBest loss: 0.232663\tAccuracy: 91.37%\n",
      "115\tValidation loss: 0.245195\tBest loss: 0.232663\tAccuracy: 92.09%\n",
      "116\tValidation loss: 0.231288\tBest loss: 0.231288\tAccuracy: 91.37%\n",
      "117\tValidation loss: 0.235208\tBest loss: 0.231288\tAccuracy: 91.37%\n",
      "118\tValidation loss: 0.244316\tBest loss: 0.231288\tAccuracy: 91.37%\n",
      "119\tValidation loss: 0.242501\tBest loss: 0.231288\tAccuracy: 91.37%\n",
      "120\tValidation loss: 0.236966\tBest loss: 0.231288\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.227455\tBest loss: 0.227455\tAccuracy: 92.81%\n",
      "122\tValidation loss: 0.230077\tBest loss: 0.227455\tAccuracy: 92.81%\n",
      "123\tValidation loss: 0.257245\tBest loss: 0.227455\tAccuracy: 92.09%\n",
      "124\tValidation loss: 0.264993\tBest loss: 0.227455\tAccuracy: 92.81%\n",
      "125\tValidation loss: 0.248087\tBest loss: 0.227455\tAccuracy: 93.53%\n",
      "126\tValidation loss: 0.250477\tBest loss: 0.227455\tAccuracy: 92.81%\n",
      "127\tValidation loss: 0.247119\tBest loss: 0.227455\tAccuracy: 92.81%\n",
      "128\tValidation loss: 0.274065\tBest loss: 0.227455\tAccuracy: 91.37%\n",
      "129\tValidation loss: 0.249375\tBest loss: 0.227455\tAccuracy: 92.09%\n",
      "130\tValidation loss: 0.241277\tBest loss: 0.227455\tAccuracy: 92.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\tValidation loss: 0.221556\tBest loss: 0.221556\tAccuracy: 92.81%\n",
      "132\tValidation loss: 0.233940\tBest loss: 0.221556\tAccuracy: 92.09%\n",
      "133\tValidation loss: 0.242366\tBest loss: 0.221556\tAccuracy: 92.81%\n",
      "134\tValidation loss: 0.228876\tBest loss: 0.221556\tAccuracy: 92.81%\n",
      "135\tValidation loss: 0.230508\tBest loss: 0.221556\tAccuracy: 93.53%\n",
      "136\tValidation loss: 0.219743\tBest loss: 0.219743\tAccuracy: 92.81%\n",
      "137\tValidation loss: 0.224133\tBest loss: 0.219743\tAccuracy: 92.81%\n",
      "138\tValidation loss: 0.241143\tBest loss: 0.219743\tAccuracy: 92.09%\n",
      "139\tValidation loss: 0.219368\tBest loss: 0.219368\tAccuracy: 93.53%\n",
      "140\tValidation loss: 0.225263\tBest loss: 0.219368\tAccuracy: 92.09%\n",
      "141\tValidation loss: 0.211679\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "142\tValidation loss: 0.234488\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "143\tValidation loss: 0.256526\tBest loss: 0.211679\tAccuracy: 89.93%\n",
      "144\tValidation loss: 0.242129\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "145\tValidation loss: 0.232905\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "146\tValidation loss: 0.228913\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "147\tValidation loss: 0.244999\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "148\tValidation loss: 0.223321\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "149\tValidation loss: 0.220304\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "150\tValidation loss: 0.227393\tBest loss: 0.211679\tAccuracy: 92.81%\n",
      "151\tValidation loss: 0.227897\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "152\tValidation loss: 0.221295\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "153\tValidation loss: 0.236649\tBest loss: 0.211679\tAccuracy: 91.37%\n",
      "154\tValidation loss: 0.236533\tBest loss: 0.211679\tAccuracy: 92.09%\n",
      "155\tValidation loss: 0.232097\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "156\tValidation loss: 0.225766\tBest loss: 0.211679\tAccuracy: 93.53%\n",
      "157\tValidation loss: 0.208105\tBest loss: 0.208105\tAccuracy: 94.24%\n",
      "158\tValidation loss: 0.197927\tBest loss: 0.197927\tAccuracy: 93.53%\n",
      "159\tValidation loss: 0.203830\tBest loss: 0.197927\tAccuracy: 92.09%\n",
      "160\tValidation loss: 0.207201\tBest loss: 0.197927\tAccuracy: 93.53%\n",
      "161\tValidation loss: 0.188509\tBest loss: 0.188509\tAccuracy: 93.53%\n",
      "162\tValidation loss: 0.193319\tBest loss: 0.188509\tAccuracy: 93.53%\n",
      "163\tValidation loss: 0.210956\tBest loss: 0.188509\tAccuracy: 93.53%\n",
      "164\tValidation loss: 0.223363\tBest loss: 0.188509\tAccuracy: 93.53%\n",
      "165\tValidation loss: 0.211312\tBest loss: 0.188509\tAccuracy: 92.81%\n",
      "166\tValidation loss: 0.202732\tBest loss: 0.188509\tAccuracy: 93.53%\n",
      "167\tValidation loss: 0.195406\tBest loss: 0.188509\tAccuracy: 94.24%\n",
      "168\tValidation loss: 0.185847\tBest loss: 0.185847\tAccuracy: 93.53%\n",
      "169\tValidation loss: 0.189547\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "170\tValidation loss: 0.198334\tBest loss: 0.185847\tAccuracy: 92.09%\n",
      "171\tValidation loss: 0.198300\tBest loss: 0.185847\tAccuracy: 94.24%\n",
      "172\tValidation loss: 0.188970\tBest loss: 0.185847\tAccuracy: 93.53%\n",
      "173\tValidation loss: 0.189232\tBest loss: 0.185847\tAccuracy: 93.53%\n",
      "174\tValidation loss: 0.196537\tBest loss: 0.185847\tAccuracy: 92.09%\n",
      "175\tValidation loss: 0.206296\tBest loss: 0.185847\tAccuracy: 91.37%\n",
      "176\tValidation loss: 0.210868\tBest loss: 0.185847\tAccuracy: 91.37%\n",
      "177\tValidation loss: 0.214691\tBest loss: 0.185847\tAccuracy: 91.37%\n",
      "178\tValidation loss: 0.214328\tBest loss: 0.185847\tAccuracy: 92.09%\n",
      "179\tValidation loss: 0.219778\tBest loss: 0.185847\tAccuracy: 92.09%\n",
      "180\tValidation loss: 0.221531\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "181\tValidation loss: 0.227630\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "182\tValidation loss: 0.217401\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "183\tValidation loss: 0.204520\tBest loss: 0.185847\tAccuracy: 93.53%\n",
      "184\tValidation loss: 0.211382\tBest loss: 0.185847\tAccuracy: 93.53%\n",
      "185\tValidation loss: 0.202737\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "186\tValidation loss: 0.200064\tBest loss: 0.185847\tAccuracy: 92.81%\n",
      "187\tValidation loss: 0.180494\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "188\tValidation loss: 0.185049\tBest loss: 0.180494\tAccuracy: 92.81%\n",
      "189\tValidation loss: 0.191304\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "190\tValidation loss: 0.209498\tBest loss: 0.180494\tAccuracy: 91.37%\n",
      "191\tValidation loss: 0.202999\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "192\tValidation loss: 0.207545\tBest loss: 0.180494\tAccuracy: 91.37%\n",
      "193\tValidation loss: 0.204611\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "194\tValidation loss: 0.214081\tBest loss: 0.180494\tAccuracy: 91.37%\n",
      "195\tValidation loss: 0.199749\tBest loss: 0.180494\tAccuracy: 91.37%\n",
      "196\tValidation loss: 0.193273\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "197\tValidation loss: 0.203997\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "198\tValidation loss: 0.219904\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "199\tValidation loss: 0.212581\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "200\tValidation loss: 0.218035\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "201\tValidation loss: 0.225021\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "202\tValidation loss: 0.215711\tBest loss: 0.180494\tAccuracy: 93.53%\n",
      "203\tValidation loss: 0.220399\tBest loss: 0.180494\tAccuracy: 92.81%\n",
      "204\tValidation loss: 0.223259\tBest loss: 0.180494\tAccuracy: 92.81%\n",
      "205\tValidation loss: 0.214302\tBest loss: 0.180494\tAccuracy: 92.81%\n",
      "206\tValidation loss: 0.225793\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "207\tValidation loss: 0.210342\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "208\tValidation loss: 0.202395\tBest loss: 0.180494\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  34.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 38.750076\tBest loss: 38.750076\tAccuracy: 6.47%\n",
      "1\tValidation loss: 70.122902\tBest loss: 38.750076\tAccuracy: 6.47%\n",
      "2\tValidation loss: 19.075710\tBest loss: 19.075710\tAccuracy: 7.91%\n",
      "3\tValidation loss: 6.250095\tBest loss: 6.250095\tAccuracy: 11.51%\n",
      "4\tValidation loss: 3.773827\tBest loss: 3.773827\tAccuracy: 15.83%\n",
      "5\tValidation loss: 3.476066\tBest loss: 3.476066\tAccuracy: 23.02%\n",
      "6\tValidation loss: 3.442422\tBest loss: 3.442422\tAccuracy: 25.18%\n",
      "7\tValidation loss: 3.418784\tBest loss: 3.418784\tAccuracy: 23.02%\n",
      "8\tValidation loss: 3.352417\tBest loss: 3.352417\tAccuracy: 27.34%\n",
      "9\tValidation loss: 3.307367\tBest loss: 3.307367\tAccuracy: 27.34%\n",
      "10\tValidation loss: 3.259898\tBest loss: 3.259898\tAccuracy: 27.34%\n",
      "11\tValidation loss: 3.184710\tBest loss: 3.184710\tAccuracy: 28.78%\n",
      "12\tValidation loss: 3.185156\tBest loss: 3.184710\tAccuracy: 25.18%\n",
      "13\tValidation loss: 3.136975\tBest loss: 3.136975\tAccuracy: 26.62%\n",
      "14\tValidation loss: 3.047182\tBest loss: 3.047182\tAccuracy: 29.50%\n",
      "15\tValidation loss: 3.024715\tBest loss: 3.024715\tAccuracy: 25.90%\n",
      "16\tValidation loss: 2.969376\tBest loss: 2.969376\tAccuracy: 28.06%\n",
      "17\tValidation loss: 2.915254\tBest loss: 2.915254\tAccuracy: 29.50%\n",
      "18\tValidation loss: 2.842924\tBest loss: 2.842924\tAccuracy: 31.65%\n",
      "19\tValidation loss: 2.776860\tBest loss: 2.776860\tAccuracy: 29.50%\n",
      "20\tValidation loss: 2.747198\tBest loss: 2.747198\tAccuracy: 29.50%\n",
      "21\tValidation loss: 2.639022\tBest loss: 2.639022\tAccuracy: 35.25%\n",
      "22\tValidation loss: 2.595881\tBest loss: 2.595881\tAccuracy: 37.41%\n",
      "23\tValidation loss: 2.550530\tBest loss: 2.550530\tAccuracy: 42.45%\n",
      "24\tValidation loss: 2.496853\tBest loss: 2.496853\tAccuracy: 41.73%\n",
      "25\tValidation loss: 2.466489\tBest loss: 2.466489\tAccuracy: 46.76%\n",
      "26\tValidation loss: 2.403799\tBest loss: 2.403799\tAccuracy: 48.20%\n",
      "27\tValidation loss: 2.375482\tBest loss: 2.375482\tAccuracy: 48.92%\n",
      "28\tValidation loss: 2.282650\tBest loss: 2.282650\tAccuracy: 51.08%\n",
      "29\tValidation loss: 2.259911\tBest loss: 2.259911\tAccuracy: 50.36%\n",
      "30\tValidation loss: 2.190551\tBest loss: 2.190551\tAccuracy: 53.24%\n",
      "31\tValidation loss: 2.212194\tBest loss: 2.190551\tAccuracy: 51.08%\n",
      "32\tValidation loss: 2.169420\tBest loss: 2.169420\tAccuracy: 52.52%\n",
      "33\tValidation loss: 2.151632\tBest loss: 2.151632\tAccuracy: 51.08%\n",
      "34\tValidation loss: 2.088548\tBest loss: 2.088548\tAccuracy: 52.52%\n",
      "35\tValidation loss: 2.035708\tBest loss: 2.035708\tAccuracy: 53.24%\n",
      "36\tValidation loss: 1.970699\tBest loss: 1.970699\tAccuracy: 55.40%\n",
      "37\tValidation loss: 1.969454\tBest loss: 1.969454\tAccuracy: 56.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 1.937370\tBest loss: 1.937370\tAccuracy: 53.24%\n",
      "39\tValidation loss: 1.868672\tBest loss: 1.868672\tAccuracy: 55.40%\n",
      "40\tValidation loss: 1.879448\tBest loss: 1.868672\tAccuracy: 56.12%\n",
      "41\tValidation loss: 1.803720\tBest loss: 1.803720\tAccuracy: 56.83%\n",
      "42\tValidation loss: 1.854445\tBest loss: 1.803720\tAccuracy: 58.27%\n",
      "43\tValidation loss: 1.833001\tBest loss: 1.803720\tAccuracy: 56.12%\n",
      "44\tValidation loss: 1.796080\tBest loss: 1.796080\tAccuracy: 57.55%\n",
      "45\tValidation loss: 1.764896\tBest loss: 1.764896\tAccuracy: 59.71%\n",
      "46\tValidation loss: 1.699279\tBest loss: 1.699279\tAccuracy: 58.99%\n",
      "47\tValidation loss: 1.720058\tBest loss: 1.699279\tAccuracy: 58.27%\n",
      "48\tValidation loss: 1.704606\tBest loss: 1.699279\tAccuracy: 60.43%\n",
      "49\tValidation loss: 1.647974\tBest loss: 1.647974\tAccuracy: 60.43%\n",
      "50\tValidation loss: 1.567388\tBest loss: 1.567388\tAccuracy: 62.59%\n",
      "51\tValidation loss: 1.572374\tBest loss: 1.567388\tAccuracy: 61.15%\n",
      "52\tValidation loss: 1.569543\tBest loss: 1.567388\tAccuracy: 60.43%\n",
      "53\tValidation loss: 1.584177\tBest loss: 1.567388\tAccuracy: 61.15%\n",
      "54\tValidation loss: 1.569067\tBest loss: 1.567388\tAccuracy: 64.03%\n",
      "55\tValidation loss: 1.500933\tBest loss: 1.500933\tAccuracy: 64.75%\n",
      "56\tValidation loss: 1.513745\tBest loss: 1.500933\tAccuracy: 64.75%\n",
      "57\tValidation loss: 1.461981\tBest loss: 1.461981\tAccuracy: 66.19%\n",
      "58\tValidation loss: 1.443502\tBest loss: 1.443502\tAccuracy: 64.75%\n",
      "59\tValidation loss: 1.411056\tBest loss: 1.411056\tAccuracy: 64.75%\n",
      "60\tValidation loss: 1.394229\tBest loss: 1.394229\tAccuracy: 65.47%\n",
      "61\tValidation loss: 1.342869\tBest loss: 1.342869\tAccuracy: 66.19%\n",
      "62\tValidation loss: 1.299891\tBest loss: 1.299891\tAccuracy: 69.78%\n",
      "63\tValidation loss: 1.294094\tBest loss: 1.294094\tAccuracy: 69.78%\n",
      "64\tValidation loss: 1.271454\tBest loss: 1.271454\tAccuracy: 69.78%\n",
      "65\tValidation loss: 1.291671\tBest loss: 1.271454\tAccuracy: 66.19%\n",
      "66\tValidation loss: 1.253561\tBest loss: 1.253561\tAccuracy: 71.22%\n",
      "67\tValidation loss: 1.245282\tBest loss: 1.245282\tAccuracy: 71.94%\n",
      "68\tValidation loss: 1.225471\tBest loss: 1.225471\tAccuracy: 70.50%\n",
      "69\tValidation loss: 1.185851\tBest loss: 1.185851\tAccuracy: 74.10%\n",
      "70\tValidation loss: 1.206626\tBest loss: 1.185851\tAccuracy: 67.63%\n",
      "71\tValidation loss: 1.193107\tBest loss: 1.185851\tAccuracy: 69.78%\n",
      "72\tValidation loss: 1.142874\tBest loss: 1.142874\tAccuracy: 74.10%\n",
      "73\tValidation loss: 1.111183\tBest loss: 1.111183\tAccuracy: 72.66%\n",
      "74\tValidation loss: 1.090952\tBest loss: 1.090952\tAccuracy: 73.38%\n",
      "75\tValidation loss: 1.117815\tBest loss: 1.090952\tAccuracy: 72.66%\n",
      "76\tValidation loss: 1.111525\tBest loss: 1.090952\tAccuracy: 70.50%\n",
      "77\tValidation loss: 1.043955\tBest loss: 1.043955\tAccuracy: 74.82%\n",
      "78\tValidation loss: 1.028646\tBest loss: 1.028646\tAccuracy: 76.98%\n",
      "79\tValidation loss: 1.027975\tBest loss: 1.027975\tAccuracy: 78.42%\n",
      "80\tValidation loss: 1.037450\tBest loss: 1.027975\tAccuracy: 76.26%\n",
      "81\tValidation loss: 1.031189\tBest loss: 1.027975\tAccuracy: 76.26%\n",
      "82\tValidation loss: 0.986361\tBest loss: 0.986361\tAccuracy: 75.54%\n",
      "83\tValidation loss: 0.992993\tBest loss: 0.986361\tAccuracy: 73.38%\n",
      "84\tValidation loss: 0.986025\tBest loss: 0.986025\tAccuracy: 76.26%\n",
      "85\tValidation loss: 0.944072\tBest loss: 0.944072\tAccuracy: 79.14%\n",
      "86\tValidation loss: 0.976607\tBest loss: 0.944072\tAccuracy: 76.26%\n",
      "87\tValidation loss: 0.970226\tBest loss: 0.944072\tAccuracy: 76.98%\n",
      "88\tValidation loss: 0.915920\tBest loss: 0.915920\tAccuracy: 78.42%\n",
      "89\tValidation loss: 0.924890\tBest loss: 0.915920\tAccuracy: 76.26%\n",
      "90\tValidation loss: 0.890540\tBest loss: 0.890540\tAccuracy: 76.98%\n",
      "91\tValidation loss: 0.875707\tBest loss: 0.875707\tAccuracy: 78.42%\n",
      "92\tValidation loss: 0.865638\tBest loss: 0.865638\tAccuracy: 79.86%\n",
      "93\tValidation loss: 0.885488\tBest loss: 0.865638\tAccuracy: 76.26%\n",
      "94\tValidation loss: 0.864064\tBest loss: 0.864064\tAccuracy: 80.58%\n",
      "95\tValidation loss: 0.887585\tBest loss: 0.864064\tAccuracy: 78.42%\n",
      "96\tValidation loss: 0.881116\tBest loss: 0.864064\tAccuracy: 78.42%\n",
      "97\tValidation loss: 0.873052\tBest loss: 0.864064\tAccuracy: 78.42%\n",
      "98\tValidation loss: 0.833599\tBest loss: 0.833599\tAccuracy: 79.86%\n",
      "99\tValidation loss: 0.852582\tBest loss: 0.833599\tAccuracy: 79.14%\n",
      "100\tValidation loss: 0.845444\tBest loss: 0.833599\tAccuracy: 79.86%\n",
      "101\tValidation loss: 0.838441\tBest loss: 0.833599\tAccuracy: 79.86%\n",
      "102\tValidation loss: 0.837175\tBest loss: 0.833599\tAccuracy: 80.58%\n",
      "103\tValidation loss: 0.809679\tBest loss: 0.809679\tAccuracy: 79.86%\n",
      "104\tValidation loss: 0.813044\tBest loss: 0.809679\tAccuracy: 80.58%\n",
      "105\tValidation loss: 0.781864\tBest loss: 0.781864\tAccuracy: 79.86%\n",
      "106\tValidation loss: 0.800600\tBest loss: 0.781864\tAccuracy: 79.86%\n",
      "107\tValidation loss: 0.784316\tBest loss: 0.781864\tAccuracy: 79.86%\n",
      "108\tValidation loss: 0.769734\tBest loss: 0.769734\tAccuracy: 82.73%\n",
      "109\tValidation loss: 0.745062\tBest loss: 0.745062\tAccuracy: 85.61%\n",
      "110\tValidation loss: 0.753917\tBest loss: 0.745062\tAccuracy: 82.73%\n",
      "111\tValidation loss: 0.744680\tBest loss: 0.744680\tAccuracy: 83.45%\n",
      "112\tValidation loss: 0.733763\tBest loss: 0.733763\tAccuracy: 82.73%\n",
      "113\tValidation loss: 0.756916\tBest loss: 0.733763\tAccuracy: 82.73%\n",
      "114\tValidation loss: 0.738904\tBest loss: 0.733763\tAccuracy: 83.45%\n",
      "115\tValidation loss: 0.734664\tBest loss: 0.733763\tAccuracy: 84.17%\n",
      "116\tValidation loss: 0.715076\tBest loss: 0.715076\tAccuracy: 84.89%\n",
      "117\tValidation loss: 0.702241\tBest loss: 0.702241\tAccuracy: 84.89%\n",
      "118\tValidation loss: 0.713183\tBest loss: 0.702241\tAccuracy: 82.73%\n",
      "119\tValidation loss: 0.714525\tBest loss: 0.702241\tAccuracy: 84.89%\n",
      "120\tValidation loss: 0.703053\tBest loss: 0.702241\tAccuracy: 84.17%\n",
      "121\tValidation loss: 0.713337\tBest loss: 0.702241\tAccuracy: 84.17%\n",
      "122\tValidation loss: 0.695180\tBest loss: 0.695180\tAccuracy: 85.61%\n",
      "123\tValidation loss: 0.699511\tBest loss: 0.695180\tAccuracy: 85.61%\n",
      "124\tValidation loss: 0.689458\tBest loss: 0.689458\tAccuracy: 84.89%\n",
      "125\tValidation loss: 0.697608\tBest loss: 0.689458\tAccuracy: 85.61%\n",
      "126\tValidation loss: 0.676915\tBest loss: 0.676915\tAccuracy: 84.17%\n",
      "127\tValidation loss: 0.656392\tBest loss: 0.656392\tAccuracy: 85.61%\n",
      "128\tValidation loss: 0.663101\tBest loss: 0.656392\tAccuracy: 84.89%\n",
      "129\tValidation loss: 0.666466\tBest loss: 0.656392\tAccuracy: 85.61%\n",
      "130\tValidation loss: 0.681304\tBest loss: 0.656392\tAccuracy: 85.61%\n",
      "131\tValidation loss: 0.678635\tBest loss: 0.656392\tAccuracy: 84.17%\n",
      "132\tValidation loss: 0.699200\tBest loss: 0.656392\tAccuracy: 83.45%\n",
      "133\tValidation loss: 0.676282\tBest loss: 0.656392\tAccuracy: 84.17%\n",
      "134\tValidation loss: 0.675605\tBest loss: 0.656392\tAccuracy: 82.73%\n",
      "135\tValidation loss: 0.661646\tBest loss: 0.656392\tAccuracy: 82.73%\n",
      "136\tValidation loss: 0.657517\tBest loss: 0.656392\tAccuracy: 83.45%\n",
      "137\tValidation loss: 0.648987\tBest loss: 0.648987\tAccuracy: 84.17%\n",
      "138\tValidation loss: 0.651641\tBest loss: 0.648987\tAccuracy: 82.01%\n",
      "139\tValidation loss: 0.636420\tBest loss: 0.636420\tAccuracy: 83.45%\n",
      "140\tValidation loss: 0.642378\tBest loss: 0.636420\tAccuracy: 84.17%\n",
      "141\tValidation loss: 0.636208\tBest loss: 0.636208\tAccuracy: 84.89%\n",
      "142\tValidation loss: 0.629985\tBest loss: 0.629985\tAccuracy: 84.89%\n",
      "143\tValidation loss: 0.638995\tBest loss: 0.629985\tAccuracy: 84.89%\n",
      "144\tValidation loss: 0.631108\tBest loss: 0.629985\tAccuracy: 84.17%\n",
      "145\tValidation loss: 0.649183\tBest loss: 0.629985\tAccuracy: 84.17%\n",
      "146\tValidation loss: 0.649132\tBest loss: 0.629985\tAccuracy: 84.89%\n",
      "147\tValidation loss: 0.634716\tBest loss: 0.629985\tAccuracy: 84.89%\n",
      "148\tValidation loss: 0.616813\tBest loss: 0.616813\tAccuracy: 84.89%\n",
      "149\tValidation loss: 0.611839\tBest loss: 0.611839\tAccuracy: 84.89%\n",
      "150\tValidation loss: 0.607216\tBest loss: 0.607216\tAccuracy: 85.61%\n",
      "151\tValidation loss: 0.597870\tBest loss: 0.597870\tAccuracy: 84.89%\n",
      "152\tValidation loss: 0.606551\tBest loss: 0.597870\tAccuracy: 85.61%\n",
      "153\tValidation loss: 0.592158\tBest loss: 0.592158\tAccuracy: 87.77%\n",
      "154\tValidation loss: 0.582896\tBest loss: 0.582896\tAccuracy: 86.33%\n",
      "155\tValidation loss: 0.587467\tBest loss: 0.582896\tAccuracy: 85.61%\n",
      "156\tValidation loss: 0.584151\tBest loss: 0.582896\tAccuracy: 85.61%\n",
      "157\tValidation loss: 0.592315\tBest loss: 0.582896\tAccuracy: 86.33%\n",
      "158\tValidation loss: 0.611118\tBest loss: 0.582896\tAccuracy: 84.89%\n",
      "159\tValidation loss: 0.594339\tBest loss: 0.582896\tAccuracy: 87.05%\n",
      "160\tValidation loss: 0.604661\tBest loss: 0.582896\tAccuracy: 86.33%\n",
      "161\tValidation loss: 0.589978\tBest loss: 0.582896\tAccuracy: 87.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\tValidation loss: 0.578920\tBest loss: 0.578920\tAccuracy: 88.49%\n",
      "163\tValidation loss: 0.580236\tBest loss: 0.578920\tAccuracy: 87.77%\n",
      "164\tValidation loss: 0.574390\tBest loss: 0.574390\tAccuracy: 87.77%\n",
      "165\tValidation loss: 0.558882\tBest loss: 0.558882\tAccuracy: 87.77%\n",
      "166\tValidation loss: 0.566822\tBest loss: 0.558882\tAccuracy: 87.77%\n",
      "167\tValidation loss: 0.563703\tBest loss: 0.558882\tAccuracy: 87.05%\n",
      "168\tValidation loss: 0.568965\tBest loss: 0.558882\tAccuracy: 87.05%\n",
      "169\tValidation loss: 0.553484\tBest loss: 0.553484\tAccuracy: 87.77%\n",
      "170\tValidation loss: 0.558977\tBest loss: 0.553484\tAccuracy: 87.05%\n",
      "171\tValidation loss: 0.557315\tBest loss: 0.553484\tAccuracy: 86.33%\n",
      "172\tValidation loss: 0.562268\tBest loss: 0.553484\tAccuracy: 85.61%\n",
      "173\tValidation loss: 0.555599\tBest loss: 0.553484\tAccuracy: 85.61%\n",
      "174\tValidation loss: 0.557883\tBest loss: 0.553484\tAccuracy: 86.33%\n",
      "175\tValidation loss: 0.560292\tBest loss: 0.553484\tAccuracy: 84.89%\n",
      "176\tValidation loss: 0.546871\tBest loss: 0.546871\tAccuracy: 85.61%\n",
      "177\tValidation loss: 0.540110\tBest loss: 0.540110\tAccuracy: 85.61%\n",
      "178\tValidation loss: 0.564751\tBest loss: 0.540110\tAccuracy: 84.89%\n",
      "179\tValidation loss: 0.555964\tBest loss: 0.540110\tAccuracy: 84.89%\n",
      "180\tValidation loss: 0.554771\tBest loss: 0.540110\tAccuracy: 85.61%\n",
      "181\tValidation loss: 0.545861\tBest loss: 0.540110\tAccuracy: 85.61%\n",
      "182\tValidation loss: 0.540473\tBest loss: 0.540110\tAccuracy: 86.33%\n",
      "183\tValidation loss: 0.530641\tBest loss: 0.530641\tAccuracy: 87.05%\n",
      "184\tValidation loss: 0.528229\tBest loss: 0.528229\tAccuracy: 86.33%\n",
      "185\tValidation loss: 0.533952\tBest loss: 0.528229\tAccuracy: 88.49%\n",
      "186\tValidation loss: 0.533553\tBest loss: 0.528229\tAccuracy: 87.05%\n",
      "187\tValidation loss: 0.533679\tBest loss: 0.528229\tAccuracy: 87.77%\n",
      "188\tValidation loss: 0.527615\tBest loss: 0.527615\tAccuracy: 87.77%\n",
      "189\tValidation loss: 0.522952\tBest loss: 0.522952\tAccuracy: 87.77%\n",
      "190\tValidation loss: 0.522431\tBest loss: 0.522431\tAccuracy: 87.77%\n",
      "191\tValidation loss: 0.518764\tBest loss: 0.518764\tAccuracy: 88.49%\n",
      "192\tValidation loss: 0.528983\tBest loss: 0.518764\tAccuracy: 88.49%\n",
      "193\tValidation loss: 0.527080\tBest loss: 0.518764\tAccuracy: 88.49%\n",
      "194\tValidation loss: 0.511725\tBest loss: 0.511725\tAccuracy: 87.77%\n",
      "195\tValidation loss: 0.508372\tBest loss: 0.508372\tAccuracy: 87.05%\n",
      "196\tValidation loss: 0.513253\tBest loss: 0.508372\tAccuracy: 87.05%\n",
      "197\tValidation loss: 0.506020\tBest loss: 0.506020\tAccuracy: 87.05%\n",
      "198\tValidation loss: 0.499026\tBest loss: 0.499026\tAccuracy: 87.77%\n",
      "199\tValidation loss: 0.501267\tBest loss: 0.499026\tAccuracy: 89.21%\n",
      "200\tValidation loss: 0.500134\tBest loss: 0.499026\tAccuracy: 88.49%\n",
      "201\tValidation loss: 0.494081\tBest loss: 0.494081\tAccuracy: 88.49%\n",
      "202\tValidation loss: 0.487463\tBest loss: 0.487463\tAccuracy: 87.05%\n",
      "203\tValidation loss: 0.491988\tBest loss: 0.487463\tAccuracy: 87.05%\n",
      "204\tValidation loss: 0.490395\tBest loss: 0.487463\tAccuracy: 87.05%\n",
      "205\tValidation loss: 0.485373\tBest loss: 0.485373\tAccuracy: 87.05%\n",
      "206\tValidation loss: 0.496594\tBest loss: 0.485373\tAccuracy: 88.49%\n",
      "207\tValidation loss: 0.497682\tBest loss: 0.485373\tAccuracy: 87.77%\n",
      "208\tValidation loss: 0.507349\tBest loss: 0.485373\tAccuracy: 87.05%\n",
      "209\tValidation loss: 0.504145\tBest loss: 0.485373\tAccuracy: 87.77%\n",
      "210\tValidation loss: 0.501970\tBest loss: 0.485373\tAccuracy: 87.05%\n",
      "211\tValidation loss: 0.500892\tBest loss: 0.485373\tAccuracy: 87.05%\n",
      "212\tValidation loss: 0.491176\tBest loss: 0.485373\tAccuracy: 86.33%\n",
      "213\tValidation loss: 0.494945\tBest loss: 0.485373\tAccuracy: 86.33%\n",
      "214\tValidation loss: 0.493588\tBest loss: 0.485373\tAccuracy: 86.33%\n",
      "215\tValidation loss: 0.495533\tBest loss: 0.485373\tAccuracy: 86.33%\n",
      "216\tValidation loss: 0.483391\tBest loss: 0.483391\tAccuracy: 87.05%\n",
      "217\tValidation loss: 0.479894\tBest loss: 0.479894\tAccuracy: 87.05%\n",
      "218\tValidation loss: 0.472591\tBest loss: 0.472591\tAccuracy: 87.77%\n",
      "219\tValidation loss: 0.469154\tBest loss: 0.469154\tAccuracy: 87.05%\n",
      "220\tValidation loss: 0.476487\tBest loss: 0.469154\tAccuracy: 87.77%\n",
      "221\tValidation loss: 0.477903\tBest loss: 0.469154\tAccuracy: 87.77%\n",
      "222\tValidation loss: 0.467122\tBest loss: 0.467122\tAccuracy: 87.77%\n",
      "223\tValidation loss: 0.469133\tBest loss: 0.467122\tAccuracy: 88.49%\n",
      "224\tValidation loss: 0.469846\tBest loss: 0.467122\tAccuracy: 87.77%\n",
      "225\tValidation loss: 0.466788\tBest loss: 0.466788\tAccuracy: 88.49%\n",
      "226\tValidation loss: 0.466591\tBest loss: 0.466591\tAccuracy: 87.77%\n",
      "227\tValidation loss: 0.467806\tBest loss: 0.466591\tAccuracy: 87.05%\n",
      "228\tValidation loss: 0.461588\tBest loss: 0.461588\tAccuracy: 86.33%\n",
      "229\tValidation loss: 0.468706\tBest loss: 0.461588\tAccuracy: 87.05%\n",
      "230\tValidation loss: 0.470745\tBest loss: 0.461588\tAccuracy: 87.05%\n",
      "231\tValidation loss: 0.470393\tBest loss: 0.461588\tAccuracy: 87.77%\n",
      "232\tValidation loss: 0.466627\tBest loss: 0.461588\tAccuracy: 86.33%\n",
      "233\tValidation loss: 0.459299\tBest loss: 0.459299\tAccuracy: 87.05%\n",
      "234\tValidation loss: 0.449045\tBest loss: 0.449045\tAccuracy: 88.49%\n",
      "235\tValidation loss: 0.448341\tBest loss: 0.448341\tAccuracy: 87.77%\n",
      "236\tValidation loss: 0.462274\tBest loss: 0.448341\tAccuracy: 88.49%\n",
      "237\tValidation loss: 0.458371\tBest loss: 0.448341\tAccuracy: 88.49%\n",
      "238\tValidation loss: 0.440929\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "239\tValidation loss: 0.451418\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "240\tValidation loss: 0.448161\tBest loss: 0.440929\tAccuracy: 87.77%\n",
      "241\tValidation loss: 0.454344\tBest loss: 0.440929\tAccuracy: 87.05%\n",
      "242\tValidation loss: 0.460121\tBest loss: 0.440929\tAccuracy: 87.77%\n",
      "243\tValidation loss: 0.452355\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "244\tValidation loss: 0.447384\tBest loss: 0.440929\tAccuracy: 89.21%\n",
      "245\tValidation loss: 0.451892\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "246\tValidation loss: 0.452048\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "247\tValidation loss: 0.451046\tBest loss: 0.440929\tAccuracy: 89.21%\n",
      "248\tValidation loss: 0.447842\tBest loss: 0.440929\tAccuracy: 89.21%\n",
      "249\tValidation loss: 0.441709\tBest loss: 0.440929\tAccuracy: 88.49%\n",
      "250\tValidation loss: 0.438309\tBest loss: 0.438309\tAccuracy: 88.49%\n",
      "251\tValidation loss: 0.438039\tBest loss: 0.438039\tAccuracy: 88.49%\n",
      "252\tValidation loss: 0.437622\tBest loss: 0.437622\tAccuracy: 88.49%\n",
      "253\tValidation loss: 0.433835\tBest loss: 0.433835\tAccuracy: 87.77%\n",
      "254\tValidation loss: 0.436377\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "255\tValidation loss: 0.436652\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "256\tValidation loss: 0.441659\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "257\tValidation loss: 0.443191\tBest loss: 0.433835\tAccuracy: 87.77%\n",
      "258\tValidation loss: 0.446087\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "259\tValidation loss: 0.447971\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "260\tValidation loss: 0.439940\tBest loss: 0.433835\tAccuracy: 88.49%\n",
      "261\tValidation loss: 0.434391\tBest loss: 0.433835\tAccuracy: 87.77%\n",
      "262\tValidation loss: 0.429826\tBest loss: 0.429826\tAccuracy: 87.77%\n",
      "263\tValidation loss: 0.425731\tBest loss: 0.425731\tAccuracy: 87.77%\n",
      "264\tValidation loss: 0.427217\tBest loss: 0.425731\tAccuracy: 87.77%\n",
      "265\tValidation loss: 0.424991\tBest loss: 0.424991\tAccuracy: 88.49%\n",
      "266\tValidation loss: 0.424095\tBest loss: 0.424095\tAccuracy: 87.77%\n",
      "267\tValidation loss: 0.439548\tBest loss: 0.424095\tAccuracy: 87.77%\n",
      "268\tValidation loss: 0.433844\tBest loss: 0.424095\tAccuracy: 88.49%\n",
      "269\tValidation loss: 0.417613\tBest loss: 0.417613\tAccuracy: 87.77%\n",
      "270\tValidation loss: 0.414417\tBest loss: 0.414417\tAccuracy: 89.21%\n",
      "271\tValidation loss: 0.411165\tBest loss: 0.411165\tAccuracy: 88.49%\n",
      "272\tValidation loss: 0.410468\tBest loss: 0.410468\tAccuracy: 87.77%\n",
      "273\tValidation loss: 0.416862\tBest loss: 0.410468\tAccuracy: 87.77%\n",
      "274\tValidation loss: 0.411203\tBest loss: 0.410468\tAccuracy: 87.77%\n",
      "275\tValidation loss: 0.413984\tBest loss: 0.410468\tAccuracy: 88.49%\n",
      "276\tValidation loss: 0.416759\tBest loss: 0.410468\tAccuracy: 89.21%\n",
      "277\tValidation loss: 0.412498\tBest loss: 0.410468\tAccuracy: 89.21%\n",
      "278\tValidation loss: 0.414881\tBest loss: 0.410468\tAccuracy: 89.21%\n",
      "279\tValidation loss: 0.420153\tBest loss: 0.410468\tAccuracy: 89.21%\n",
      "280\tValidation loss: 0.413027\tBest loss: 0.410468\tAccuracy: 88.49%\n",
      "281\tValidation loss: 0.409738\tBest loss: 0.409738\tAccuracy: 88.49%\n",
      "282\tValidation loss: 0.408504\tBest loss: 0.408504\tAccuracy: 89.21%\n",
      "283\tValidation loss: 0.418965\tBest loss: 0.408504\tAccuracy: 89.21%\n",
      "284\tValidation loss: 0.405417\tBest loss: 0.405417\tAccuracy: 88.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\tValidation loss: 0.404267\tBest loss: 0.404267\tAccuracy: 88.49%\n",
      "286\tValidation loss: 0.391057\tBest loss: 0.391057\tAccuracy: 88.49%\n",
      "287\tValidation loss: 0.393759\tBest loss: 0.391057\tAccuracy: 88.49%\n",
      "288\tValidation loss: 0.397283\tBest loss: 0.391057\tAccuracy: 88.49%\n",
      "289\tValidation loss: 0.403523\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "290\tValidation loss: 0.401479\tBest loss: 0.391057\tAccuracy: 89.21%\n",
      "291\tValidation loss: 0.405312\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "292\tValidation loss: 0.398022\tBest loss: 0.391057\tAccuracy: 88.49%\n",
      "293\tValidation loss: 0.406382\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "294\tValidation loss: 0.406079\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "295\tValidation loss: 0.404226\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "296\tValidation loss: 0.405031\tBest loss: 0.391057\tAccuracy: 88.49%\n",
      "297\tValidation loss: 0.400240\tBest loss: 0.391057\tAccuracy: 87.77%\n",
      "298\tValidation loss: 0.394017\tBest loss: 0.391057\tAccuracy: 89.21%\n",
      "299\tValidation loss: 0.389309\tBest loss: 0.389309\tAccuracy: 89.21%\n",
      "300\tValidation loss: 0.391805\tBest loss: 0.389309\tAccuracy: 88.49%\n",
      "301\tValidation loss: 0.392658\tBest loss: 0.389309\tAccuracy: 88.49%\n",
      "302\tValidation loss: 0.397179\tBest loss: 0.389309\tAccuracy: 88.49%\n",
      "303\tValidation loss: 0.395834\tBest loss: 0.389309\tAccuracy: 89.21%\n",
      "304\tValidation loss: 0.395069\tBest loss: 0.389309\tAccuracy: 89.21%\n",
      "305\tValidation loss: 0.379965\tBest loss: 0.379965\tAccuracy: 88.49%\n",
      "306\tValidation loss: 0.385151\tBest loss: 0.379965\tAccuracy: 88.49%\n",
      "307\tValidation loss: 0.382136\tBest loss: 0.379965\tAccuracy: 89.21%\n",
      "308\tValidation loss: 0.385110\tBest loss: 0.379965\tAccuracy: 88.49%\n",
      "309\tValidation loss: 0.381029\tBest loss: 0.379965\tAccuracy: 89.93%\n",
      "310\tValidation loss: 0.380624\tBest loss: 0.379965\tAccuracy: 90.65%\n",
      "311\tValidation loss: 0.378044\tBest loss: 0.378044\tAccuracy: 88.49%\n",
      "312\tValidation loss: 0.383525\tBest loss: 0.378044\tAccuracy: 88.49%\n",
      "313\tValidation loss: 0.392682\tBest loss: 0.378044\tAccuracy: 88.49%\n",
      "314\tValidation loss: 0.392755\tBest loss: 0.378044\tAccuracy: 89.21%\n",
      "315\tValidation loss: 0.387237\tBest loss: 0.378044\tAccuracy: 89.21%\n",
      "316\tValidation loss: 0.384810\tBest loss: 0.378044\tAccuracy: 89.93%\n",
      "317\tValidation loss: 0.382019\tBest loss: 0.378044\tAccuracy: 89.21%\n",
      "318\tValidation loss: 0.388391\tBest loss: 0.378044\tAccuracy: 89.93%\n",
      "319\tValidation loss: 0.386162\tBest loss: 0.378044\tAccuracy: 90.65%\n",
      "320\tValidation loss: 0.386636\tBest loss: 0.378044\tAccuracy: 90.65%\n",
      "321\tValidation loss: 0.394382\tBest loss: 0.378044\tAccuracy: 89.21%\n",
      "322\tValidation loss: 0.384988\tBest loss: 0.378044\tAccuracy: 89.21%\n",
      "323\tValidation loss: 0.379696\tBest loss: 0.378044\tAccuracy: 89.93%\n",
      "324\tValidation loss: 0.379356\tBest loss: 0.378044\tAccuracy: 91.37%\n",
      "325\tValidation loss: 0.378669\tBest loss: 0.378044\tAccuracy: 89.93%\n",
      "326\tValidation loss: 0.380345\tBest loss: 0.378044\tAccuracy: 88.49%\n",
      "327\tValidation loss: 0.372682\tBest loss: 0.372682\tAccuracy: 88.49%\n",
      "328\tValidation loss: 0.375610\tBest loss: 0.372682\tAccuracy: 88.49%\n",
      "329\tValidation loss: 0.375894\tBest loss: 0.372682\tAccuracy: 89.21%\n",
      "330\tValidation loss: 0.380828\tBest loss: 0.372682\tAccuracy: 88.49%\n",
      "331\tValidation loss: 0.378562\tBest loss: 0.372682\tAccuracy: 89.21%\n",
      "332\tValidation loss: 0.373893\tBest loss: 0.372682\tAccuracy: 89.21%\n",
      "333\tValidation loss: 0.371953\tBest loss: 0.371953\tAccuracy: 89.21%\n",
      "334\tValidation loss: 0.370522\tBest loss: 0.370522\tAccuracy: 89.21%\n",
      "335\tValidation loss: 0.370454\tBest loss: 0.370454\tAccuracy: 88.49%\n",
      "336\tValidation loss: 0.372711\tBest loss: 0.370454\tAccuracy: 89.21%\n",
      "337\tValidation loss: 0.370084\tBest loss: 0.370084\tAccuracy: 89.21%\n",
      "338\tValidation loss: 0.362855\tBest loss: 0.362855\tAccuracy: 89.21%\n",
      "339\tValidation loss: 0.371927\tBest loss: 0.362855\tAccuracy: 89.21%\n",
      "340\tValidation loss: 0.365914\tBest loss: 0.362855\tAccuracy: 88.49%\n",
      "341\tValidation loss: 0.365646\tBest loss: 0.362855\tAccuracy: 88.49%\n",
      "342\tValidation loss: 0.368610\tBest loss: 0.362855\tAccuracy: 88.49%\n",
      "343\tValidation loss: 0.368751\tBest loss: 0.362855\tAccuracy: 88.49%\n",
      "344\tValidation loss: 0.373175\tBest loss: 0.362855\tAccuracy: 89.21%\n",
      "345\tValidation loss: 0.368184\tBest loss: 0.362855\tAccuracy: 89.21%\n",
      "346\tValidation loss: 0.367481\tBest loss: 0.362855\tAccuracy: 89.93%\n",
      "347\tValidation loss: 0.364900\tBest loss: 0.362855\tAccuracy: 89.21%\n",
      "348\tValidation loss: 0.361725\tBest loss: 0.361725\tAccuracy: 88.49%\n",
      "349\tValidation loss: 0.358315\tBest loss: 0.358315\tAccuracy: 88.49%\n",
      "350\tValidation loss: 0.353534\tBest loss: 0.353534\tAccuracy: 88.49%\n",
      "351\tValidation loss: 0.348341\tBest loss: 0.348341\tAccuracy: 88.49%\n",
      "352\tValidation loss: 0.349073\tBest loss: 0.348341\tAccuracy: 89.21%\n",
      "353\tValidation loss: 0.355613\tBest loss: 0.348341\tAccuracy: 89.93%\n",
      "354\tValidation loss: 0.351902\tBest loss: 0.348341\tAccuracy: 89.21%\n",
      "355\tValidation loss: 0.362346\tBest loss: 0.348341\tAccuracy: 88.49%\n",
      "356\tValidation loss: 0.357325\tBest loss: 0.348341\tAccuracy: 88.49%\n",
      "357\tValidation loss: 0.353841\tBest loss: 0.348341\tAccuracy: 88.49%\n",
      "358\tValidation loss: 0.343122\tBest loss: 0.343122\tAccuracy: 89.21%\n",
      "359\tValidation loss: 0.341528\tBest loss: 0.341528\tAccuracy: 88.49%\n",
      "360\tValidation loss: 0.347434\tBest loss: 0.341528\tAccuracy: 88.49%\n",
      "361\tValidation loss: 0.354620\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "362\tValidation loss: 0.351329\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "363\tValidation loss: 0.350563\tBest loss: 0.341528\tAccuracy: 89.93%\n",
      "364\tValidation loss: 0.357827\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "365\tValidation loss: 0.354099\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "366\tValidation loss: 0.357494\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "367\tValidation loss: 0.352717\tBest loss: 0.341528\tAccuracy: 89.21%\n",
      "368\tValidation loss: 0.356459\tBest loss: 0.341528\tAccuracy: 90.65%\n",
      "369\tValidation loss: 0.346726\tBest loss: 0.341528\tAccuracy: 89.93%\n",
      "370\tValidation loss: 0.343798\tBest loss: 0.341528\tAccuracy: 89.93%\n",
      "371\tValidation loss: 0.339254\tBest loss: 0.339254\tAccuracy: 90.65%\n",
      "372\tValidation loss: 0.333286\tBest loss: 0.333286\tAccuracy: 89.93%\n",
      "373\tValidation loss: 0.339017\tBest loss: 0.333286\tAccuracy: 89.21%\n",
      "374\tValidation loss: 0.342951\tBest loss: 0.333286\tAccuracy: 89.21%\n",
      "375\tValidation loss: 0.341832\tBest loss: 0.333286\tAccuracy: 89.21%\n",
      "376\tValidation loss: 0.341949\tBest loss: 0.333286\tAccuracy: 89.21%\n",
      "377\tValidation loss: 0.337337\tBest loss: 0.333286\tAccuracy: 90.65%\n",
      "378\tValidation loss: 0.334508\tBest loss: 0.333286\tAccuracy: 89.93%\n",
      "379\tValidation loss: 0.329214\tBest loss: 0.329214\tAccuracy: 89.93%\n",
      "380\tValidation loss: 0.326859\tBest loss: 0.326859\tAccuracy: 89.93%\n",
      "381\tValidation loss: 0.328750\tBest loss: 0.326859\tAccuracy: 89.21%\n",
      "382\tValidation loss: 0.329649\tBest loss: 0.326859\tAccuracy: 89.21%\n",
      "383\tValidation loss: 0.328420\tBest loss: 0.326859\tAccuracy: 89.21%\n",
      "384\tValidation loss: 0.329025\tBest loss: 0.326859\tAccuracy: 89.93%\n",
      "385\tValidation loss: 0.329034\tBest loss: 0.326859\tAccuracy: 89.21%\n",
      "386\tValidation loss: 0.325517\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "387\tValidation loss: 0.325623\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "388\tValidation loss: 0.325701\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "389\tValidation loss: 0.329539\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "390\tValidation loss: 0.326112\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "391\tValidation loss: 0.327388\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "392\tValidation loss: 0.328640\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "393\tValidation loss: 0.328969\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "394\tValidation loss: 0.332756\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "395\tValidation loss: 0.332996\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "396\tValidation loss: 0.336747\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "397\tValidation loss: 0.331875\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "398\tValidation loss: 0.337368\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "399\tValidation loss: 0.337985\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "400\tValidation loss: 0.336720\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "401\tValidation loss: 0.345547\tBest loss: 0.325517\tAccuracy: 90.65%\n",
      "402\tValidation loss: 0.338332\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "403\tValidation loss: 0.330529\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "404\tValidation loss: 0.328669\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "405\tValidation loss: 0.330594\tBest loss: 0.325517\tAccuracy: 89.21%\n",
      "406\tValidation loss: 0.327311\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "407\tValidation loss: 0.329387\tBest loss: 0.325517\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  45.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 39.097527\tBest loss: 39.097527\tAccuracy: 6.47%\n",
      "1\tValidation loss: 74.634743\tBest loss: 39.097527\tAccuracy: 5.76%\n",
      "2\tValidation loss: 34.122536\tBest loss: 34.122536\tAccuracy: 6.47%\n",
      "3\tValidation loss: 7.972496\tBest loss: 7.972496\tAccuracy: 10.79%\n",
      "4\tValidation loss: 4.450730\tBest loss: 4.450730\tAccuracy: 12.95%\n",
      "5\tValidation loss: 3.856185\tBest loss: 3.856185\tAccuracy: 17.27%\n",
      "6\tValidation loss: 3.755742\tBest loss: 3.755742\tAccuracy: 16.55%\n",
      "7\tValidation loss: 3.658859\tBest loss: 3.658859\tAccuracy: 18.71%\n",
      "8\tValidation loss: 3.595162\tBest loss: 3.595162\tAccuracy: 17.27%\n",
      "9\tValidation loss: 3.565504\tBest loss: 3.565504\tAccuracy: 17.27%\n",
      "10\tValidation loss: 3.488037\tBest loss: 3.488037\tAccuracy: 17.99%\n",
      "11\tValidation loss: 3.456656\tBest loss: 3.456656\tAccuracy: 16.55%\n",
      "12\tValidation loss: 3.397351\tBest loss: 3.397351\tAccuracy: 17.27%\n",
      "13\tValidation loss: 3.313260\tBest loss: 3.313260\tAccuracy: 20.86%\n",
      "14\tValidation loss: 3.291460\tBest loss: 3.291460\tAccuracy: 20.86%\n",
      "15\tValidation loss: 3.234102\tBest loss: 3.234102\tAccuracy: 20.86%\n",
      "16\tValidation loss: 3.157450\tBest loss: 3.157450\tAccuracy: 25.18%\n",
      "17\tValidation loss: 3.165227\tBest loss: 3.157450\tAccuracy: 20.86%\n",
      "18\tValidation loss: 3.047119\tBest loss: 3.047119\tAccuracy: 26.62%\n",
      "19\tValidation loss: 3.027949\tBest loss: 3.027949\tAccuracy: 27.34%\n",
      "20\tValidation loss: 2.967574\tBest loss: 2.967574\tAccuracy: 28.06%\n",
      "21\tValidation loss: 2.874049\tBest loss: 2.874049\tAccuracy: 29.50%\n",
      "22\tValidation loss: 2.808562\tBest loss: 2.808562\tAccuracy: 31.65%\n",
      "23\tValidation loss: 2.756036\tBest loss: 2.756036\tAccuracy: 40.29%\n",
      "24\tValidation loss: 2.730151\tBest loss: 2.730151\tAccuracy: 41.01%\n",
      "25\tValidation loss: 2.675634\tBest loss: 2.675634\tAccuracy: 41.73%\n",
      "26\tValidation loss: 2.618113\tBest loss: 2.618113\tAccuracy: 43.88%\n",
      "27\tValidation loss: 2.598477\tBest loss: 2.598477\tAccuracy: 39.57%\n",
      "28\tValidation loss: 2.552156\tBest loss: 2.552156\tAccuracy: 43.88%\n",
      "29\tValidation loss: 2.527622\tBest loss: 2.527622\tAccuracy: 41.01%\n",
      "30\tValidation loss: 2.475848\tBest loss: 2.475848\tAccuracy: 43.88%\n",
      "31\tValidation loss: 2.417530\tBest loss: 2.417530\tAccuracy: 43.88%\n",
      "32\tValidation loss: 2.343320\tBest loss: 2.343320\tAccuracy: 46.04%\n",
      "33\tValidation loss: 2.333507\tBest loss: 2.333507\tAccuracy: 46.76%\n",
      "34\tValidation loss: 2.297812\tBest loss: 2.297812\tAccuracy: 46.76%\n",
      "35\tValidation loss: 2.232942\tBest loss: 2.232942\tAccuracy: 48.92%\n",
      "36\tValidation loss: 2.204841\tBest loss: 2.204841\tAccuracy: 50.36%\n",
      "37\tValidation loss: 2.165895\tBest loss: 2.165895\tAccuracy: 48.20%\n",
      "38\tValidation loss: 2.147470\tBest loss: 2.147470\tAccuracy: 51.80%\n",
      "39\tValidation loss: 2.084512\tBest loss: 2.084512\tAccuracy: 51.80%\n",
      "40\tValidation loss: 2.069289\tBest loss: 2.069289\tAccuracy: 50.36%\n",
      "41\tValidation loss: 2.049259\tBest loss: 2.049259\tAccuracy: 53.96%\n",
      "42\tValidation loss: 1.964125\tBest loss: 1.964125\tAccuracy: 56.12%\n",
      "43\tValidation loss: 1.995052\tBest loss: 1.964125\tAccuracy: 54.68%\n",
      "44\tValidation loss: 1.959657\tBest loss: 1.959657\tAccuracy: 53.96%\n",
      "45\tValidation loss: 1.911008\tBest loss: 1.911008\tAccuracy: 56.12%\n",
      "46\tValidation loss: 1.825988\tBest loss: 1.825988\tAccuracy: 58.99%\n",
      "47\tValidation loss: 1.819140\tBest loss: 1.819140\tAccuracy: 56.83%\n",
      "48\tValidation loss: 1.818778\tBest loss: 1.818778\tAccuracy: 58.99%\n",
      "49\tValidation loss: 1.789657\tBest loss: 1.789657\tAccuracy: 58.27%\n",
      "50\tValidation loss: 1.739836\tBest loss: 1.739836\tAccuracy: 61.87%\n",
      "51\tValidation loss: 1.731087\tBest loss: 1.731087\tAccuracy: 61.87%\n",
      "52\tValidation loss: 1.667914\tBest loss: 1.667914\tAccuracy: 61.87%\n",
      "53\tValidation loss: 1.670308\tBest loss: 1.667914\tAccuracy: 63.31%\n",
      "54\tValidation loss: 1.621240\tBest loss: 1.621240\tAccuracy: 64.03%\n",
      "55\tValidation loss: 1.600060\tBest loss: 1.600060\tAccuracy: 64.75%\n",
      "56\tValidation loss: 1.592517\tBest loss: 1.592517\tAccuracy: 63.31%\n",
      "57\tValidation loss: 1.569066\tBest loss: 1.569066\tAccuracy: 65.47%\n",
      "58\tValidation loss: 1.549540\tBest loss: 1.549540\tAccuracy: 63.31%\n",
      "59\tValidation loss: 1.516138\tBest loss: 1.516138\tAccuracy: 64.03%\n",
      "60\tValidation loss: 1.512696\tBest loss: 1.512696\tAccuracy: 66.91%\n",
      "61\tValidation loss: 1.484048\tBest loss: 1.484048\tAccuracy: 65.47%\n",
      "62\tValidation loss: 1.453177\tBest loss: 1.453177\tAccuracy: 66.91%\n",
      "63\tValidation loss: 1.458075\tBest loss: 1.453177\tAccuracy: 64.75%\n",
      "64\tValidation loss: 1.414938\tBest loss: 1.414938\tAccuracy: 68.35%\n",
      "65\tValidation loss: 1.394949\tBest loss: 1.394949\tAccuracy: 66.91%\n",
      "66\tValidation loss: 1.396399\tBest loss: 1.394949\tAccuracy: 66.19%\n",
      "67\tValidation loss: 1.398958\tBest loss: 1.394949\tAccuracy: 66.91%\n",
      "68\tValidation loss: 1.353869\tBest loss: 1.353869\tAccuracy: 69.06%\n",
      "69\tValidation loss: 1.339141\tBest loss: 1.339141\tAccuracy: 69.06%\n",
      "70\tValidation loss: 1.344650\tBest loss: 1.339141\tAccuracy: 69.06%\n",
      "71\tValidation loss: 1.346384\tBest loss: 1.339141\tAccuracy: 67.63%\n",
      "72\tValidation loss: 1.300583\tBest loss: 1.300583\tAccuracy: 69.06%\n",
      "73\tValidation loss: 1.249313\tBest loss: 1.249313\tAccuracy: 71.22%\n",
      "74\tValidation loss: 1.265836\tBest loss: 1.249313\tAccuracy: 70.50%\n",
      "75\tValidation loss: 1.255524\tBest loss: 1.249313\tAccuracy: 70.50%\n",
      "76\tValidation loss: 1.256151\tBest loss: 1.249313\tAccuracy: 69.78%\n",
      "77\tValidation loss: 1.218809\tBest loss: 1.218809\tAccuracy: 71.22%\n",
      "78\tValidation loss: 1.204628\tBest loss: 1.204628\tAccuracy: 71.22%\n",
      "79\tValidation loss: 1.213012\tBest loss: 1.204628\tAccuracy: 71.22%\n",
      "80\tValidation loss: 1.193966\tBest loss: 1.193966\tAccuracy: 71.94%\n",
      "81\tValidation loss: 1.140888\tBest loss: 1.140888\tAccuracy: 72.66%\n",
      "82\tValidation loss: 1.183397\tBest loss: 1.140888\tAccuracy: 71.94%\n",
      "83\tValidation loss: 1.149869\tBest loss: 1.140888\tAccuracy: 71.22%\n",
      "84\tValidation loss: 1.136196\tBest loss: 1.136196\tAccuracy: 72.66%\n",
      "85\tValidation loss: 1.115309\tBest loss: 1.115309\tAccuracy: 71.94%\n",
      "86\tValidation loss: 1.116151\tBest loss: 1.115309\tAccuracy: 71.22%\n",
      "87\tValidation loss: 1.106518\tBest loss: 1.106518\tAccuracy: 71.94%\n",
      "88\tValidation loss: 1.079345\tBest loss: 1.079345\tAccuracy: 74.10%\n",
      "89\tValidation loss: 1.078650\tBest loss: 1.078650\tAccuracy: 72.66%\n",
      "90\tValidation loss: 1.072822\tBest loss: 1.072822\tAccuracy: 72.66%\n",
      "91\tValidation loss: 1.052016\tBest loss: 1.052016\tAccuracy: 75.54%\n",
      "92\tValidation loss: 1.025041\tBest loss: 1.025041\tAccuracy: 75.54%\n",
      "93\tValidation loss: 1.028825\tBest loss: 1.025041\tAccuracy: 77.70%\n",
      "94\tValidation loss: 1.004793\tBest loss: 1.004793\tAccuracy: 76.26%\n",
      "95\tValidation loss: 1.031768\tBest loss: 1.004793\tAccuracy: 76.26%\n",
      "96\tValidation loss: 1.009637\tBest loss: 1.004793\tAccuracy: 77.70%\n",
      "97\tValidation loss: 1.004673\tBest loss: 1.004673\tAccuracy: 77.70%\n",
      "98\tValidation loss: 1.023558\tBest loss: 1.004673\tAccuracy: 76.26%\n",
      "99\tValidation loss: 1.010154\tBest loss: 1.004673\tAccuracy: 76.26%\n",
      "100\tValidation loss: 0.987624\tBest loss: 0.987624\tAccuracy: 76.98%\n",
      "101\tValidation loss: 0.961852\tBest loss: 0.961852\tAccuracy: 76.98%\n",
      "102\tValidation loss: 0.966312\tBest loss: 0.961852\tAccuracy: 76.26%\n",
      "103\tValidation loss: 0.927479\tBest loss: 0.927479\tAccuracy: 77.70%\n",
      "104\tValidation loss: 0.918374\tBest loss: 0.918374\tAccuracy: 80.58%\n",
      "105\tValidation loss: 0.919215\tBest loss: 0.918374\tAccuracy: 79.14%\n",
      "106\tValidation loss: 0.925588\tBest loss: 0.918374\tAccuracy: 79.14%\n",
      "107\tValidation loss: 0.910881\tBest loss: 0.910881\tAccuracy: 79.14%\n",
      "108\tValidation loss: 0.887478\tBest loss: 0.887478\tAccuracy: 81.29%\n",
      "109\tValidation loss: 0.889183\tBest loss: 0.887478\tAccuracy: 79.86%\n",
      "110\tValidation loss: 0.878335\tBest loss: 0.878335\tAccuracy: 82.01%\n",
      "111\tValidation loss: 0.862001\tBest loss: 0.862001\tAccuracy: 80.58%\n",
      "112\tValidation loss: 0.868429\tBest loss: 0.862001\tAccuracy: 80.58%\n",
      "113\tValidation loss: 0.864229\tBest loss: 0.862001\tAccuracy: 81.29%\n",
      "114\tValidation loss: 0.879822\tBest loss: 0.862001\tAccuracy: 79.14%\n",
      "115\tValidation loss: 0.887962\tBest loss: 0.862001\tAccuracy: 76.98%\n",
      "116\tValidation loss: 0.872479\tBest loss: 0.862001\tAccuracy: 80.58%\n",
      "117\tValidation loss: 0.860367\tBest loss: 0.860367\tAccuracy: 80.58%\n",
      "118\tValidation loss: 0.858850\tBest loss: 0.858850\tAccuracy: 82.73%\n",
      "119\tValidation loss: 0.848638\tBest loss: 0.848638\tAccuracy: 81.29%\n",
      "120\tValidation loss: 0.860566\tBest loss: 0.848638\tAccuracy: 79.86%\n",
      "121\tValidation loss: 0.867809\tBest loss: 0.848638\tAccuracy: 81.29%\n",
      "122\tValidation loss: 0.825328\tBest loss: 0.825328\tAccuracy: 81.29%\n",
      "123\tValidation loss: 0.840948\tBest loss: 0.825328\tAccuracy: 79.86%\n",
      "124\tValidation loss: 0.843488\tBest loss: 0.825328\tAccuracy: 79.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.819790\tBest loss: 0.819790\tAccuracy: 80.58%\n",
      "126\tValidation loss: 0.809768\tBest loss: 0.809768\tAccuracy: 81.29%\n",
      "127\tValidation loss: 0.782467\tBest loss: 0.782467\tAccuracy: 82.73%\n",
      "128\tValidation loss: 0.794141\tBest loss: 0.782467\tAccuracy: 82.73%\n",
      "129\tValidation loss: 0.803410\tBest loss: 0.782467\tAccuracy: 81.29%\n",
      "130\tValidation loss: 0.800731\tBest loss: 0.782467\tAccuracy: 81.29%\n",
      "131\tValidation loss: 0.779955\tBest loss: 0.779955\tAccuracy: 81.29%\n",
      "132\tValidation loss: 0.759467\tBest loss: 0.759467\tAccuracy: 83.45%\n",
      "133\tValidation loss: 0.736216\tBest loss: 0.736216\tAccuracy: 84.89%\n",
      "134\tValidation loss: 0.738183\tBest loss: 0.736216\tAccuracy: 85.61%\n",
      "135\tValidation loss: 0.734591\tBest loss: 0.734591\tAccuracy: 85.61%\n",
      "136\tValidation loss: 0.761450\tBest loss: 0.734591\tAccuracy: 82.73%\n",
      "137\tValidation loss: 0.759622\tBest loss: 0.734591\tAccuracy: 84.17%\n",
      "138\tValidation loss: 0.755065\tBest loss: 0.734591\tAccuracy: 83.45%\n",
      "139\tValidation loss: 0.762952\tBest loss: 0.734591\tAccuracy: 82.73%\n",
      "140\tValidation loss: 0.752570\tBest loss: 0.734591\tAccuracy: 84.17%\n",
      "141\tValidation loss: 0.758922\tBest loss: 0.734591\tAccuracy: 82.73%\n",
      "142\tValidation loss: 0.747415\tBest loss: 0.734591\tAccuracy: 82.73%\n",
      "143\tValidation loss: 0.732545\tBest loss: 0.732545\tAccuracy: 82.73%\n",
      "144\tValidation loss: 0.732503\tBest loss: 0.732503\tAccuracy: 82.73%\n",
      "145\tValidation loss: 0.747725\tBest loss: 0.732503\tAccuracy: 80.58%\n",
      "146\tValidation loss: 0.764127\tBest loss: 0.732503\tAccuracy: 81.29%\n",
      "147\tValidation loss: 0.740191\tBest loss: 0.732503\tAccuracy: 82.01%\n",
      "148\tValidation loss: 0.741410\tBest loss: 0.732503\tAccuracy: 82.01%\n",
      "149\tValidation loss: 0.725366\tBest loss: 0.725366\tAccuracy: 84.17%\n",
      "150\tValidation loss: 0.713642\tBest loss: 0.713642\tAccuracy: 82.73%\n",
      "151\tValidation loss: 0.716550\tBest loss: 0.713642\tAccuracy: 83.45%\n",
      "152\tValidation loss: 0.710031\tBest loss: 0.710031\tAccuracy: 84.89%\n",
      "153\tValidation loss: 0.723490\tBest loss: 0.710031\tAccuracy: 83.45%\n",
      "154\tValidation loss: 0.728162\tBest loss: 0.710031\tAccuracy: 84.17%\n",
      "155\tValidation loss: 0.710710\tBest loss: 0.710031\tAccuracy: 84.89%\n",
      "156\tValidation loss: 0.708774\tBest loss: 0.708774\tAccuracy: 85.61%\n",
      "157\tValidation loss: 0.702706\tBest loss: 0.702706\tAccuracy: 83.45%\n",
      "158\tValidation loss: 0.696774\tBest loss: 0.696774\tAccuracy: 84.89%\n",
      "159\tValidation loss: 0.694734\tBest loss: 0.694734\tAccuracy: 86.33%\n",
      "160\tValidation loss: 0.694403\tBest loss: 0.694403\tAccuracy: 84.17%\n",
      "161\tValidation loss: 0.705443\tBest loss: 0.694403\tAccuracy: 84.17%\n",
      "162\tValidation loss: 0.678893\tBest loss: 0.678893\tAccuracy: 84.89%\n",
      "163\tValidation loss: 0.690176\tBest loss: 0.678893\tAccuracy: 82.73%\n",
      "164\tValidation loss: 0.691849\tBest loss: 0.678893\tAccuracy: 84.89%\n",
      "165\tValidation loss: 0.676329\tBest loss: 0.676329\tAccuracy: 85.61%\n",
      "166\tValidation loss: 0.668874\tBest loss: 0.668874\tAccuracy: 84.89%\n",
      "167\tValidation loss: 0.664550\tBest loss: 0.664550\tAccuracy: 84.89%\n",
      "168\tValidation loss: 0.654879\tBest loss: 0.654879\tAccuracy: 87.05%\n",
      "169\tValidation loss: 0.663092\tBest loss: 0.654879\tAccuracy: 86.33%\n",
      "170\tValidation loss: 0.678601\tBest loss: 0.654879\tAccuracy: 83.45%\n",
      "171\tValidation loss: 0.677598\tBest loss: 0.654879\tAccuracy: 84.89%\n",
      "172\tValidation loss: 0.655234\tBest loss: 0.654879\tAccuracy: 84.89%\n",
      "173\tValidation loss: 0.649442\tBest loss: 0.649442\tAccuracy: 84.89%\n",
      "174\tValidation loss: 0.651915\tBest loss: 0.649442\tAccuracy: 84.17%\n",
      "175\tValidation loss: 0.654068\tBest loss: 0.649442\tAccuracy: 84.89%\n",
      "176\tValidation loss: 0.669818\tBest loss: 0.649442\tAccuracy: 84.17%\n",
      "177\tValidation loss: 0.648008\tBest loss: 0.648008\tAccuracy: 86.33%\n",
      "178\tValidation loss: 0.652426\tBest loss: 0.648008\tAccuracy: 84.89%\n",
      "179\tValidation loss: 0.651255\tBest loss: 0.648008\tAccuracy: 85.61%\n",
      "180\tValidation loss: 0.653590\tBest loss: 0.648008\tAccuracy: 84.89%\n",
      "181\tValidation loss: 0.647079\tBest loss: 0.647079\tAccuracy: 84.89%\n",
      "182\tValidation loss: 0.630239\tBest loss: 0.630239\tAccuracy: 84.17%\n",
      "183\tValidation loss: 0.633389\tBest loss: 0.630239\tAccuracy: 86.33%\n",
      "184\tValidation loss: 0.622747\tBest loss: 0.622747\tAccuracy: 86.33%\n",
      "185\tValidation loss: 0.629583\tBest loss: 0.622747\tAccuracy: 86.33%\n",
      "186\tValidation loss: 0.625622\tBest loss: 0.622747\tAccuracy: 86.33%\n",
      "187\tValidation loss: 0.608307\tBest loss: 0.608307\tAccuracy: 85.61%\n",
      "188\tValidation loss: 0.618765\tBest loss: 0.608307\tAccuracy: 85.61%\n",
      "189\tValidation loss: 0.629502\tBest loss: 0.608307\tAccuracy: 87.05%\n",
      "190\tValidation loss: 0.612528\tBest loss: 0.608307\tAccuracy: 87.05%\n",
      "191\tValidation loss: 0.615073\tBest loss: 0.608307\tAccuracy: 85.61%\n",
      "192\tValidation loss: 0.606002\tBest loss: 0.606002\tAccuracy: 84.89%\n",
      "193\tValidation loss: 0.614876\tBest loss: 0.606002\tAccuracy: 85.61%\n",
      "194\tValidation loss: 0.602008\tBest loss: 0.602008\tAccuracy: 86.33%\n",
      "195\tValidation loss: 0.596107\tBest loss: 0.596107\tAccuracy: 87.05%\n",
      "196\tValidation loss: 0.602092\tBest loss: 0.596107\tAccuracy: 85.61%\n",
      "197\tValidation loss: 0.600697\tBest loss: 0.596107\tAccuracy: 87.77%\n",
      "198\tValidation loss: 0.607473\tBest loss: 0.596107\tAccuracy: 86.33%\n",
      "199\tValidation loss: 0.595445\tBest loss: 0.595445\tAccuracy: 87.05%\n",
      "200\tValidation loss: 0.592467\tBest loss: 0.592467\tAccuracy: 85.61%\n",
      "201\tValidation loss: 0.593120\tBest loss: 0.592467\tAccuracy: 87.05%\n",
      "202\tValidation loss: 0.586170\tBest loss: 0.586170\tAccuracy: 87.77%\n",
      "203\tValidation loss: 0.576960\tBest loss: 0.576960\tAccuracy: 87.05%\n",
      "204\tValidation loss: 0.583113\tBest loss: 0.576960\tAccuracy: 84.89%\n",
      "205\tValidation loss: 0.584763\tBest loss: 0.576960\tAccuracy: 84.17%\n",
      "206\tValidation loss: 0.591506\tBest loss: 0.576960\tAccuracy: 86.33%\n",
      "207\tValidation loss: 0.596269\tBest loss: 0.576960\tAccuracy: 85.61%\n",
      "208\tValidation loss: 0.585129\tBest loss: 0.576960\tAccuracy: 85.61%\n",
      "209\tValidation loss: 0.590141\tBest loss: 0.576960\tAccuracy: 85.61%\n",
      "210\tValidation loss: 0.589037\tBest loss: 0.576960\tAccuracy: 85.61%\n",
      "211\tValidation loss: 0.571948\tBest loss: 0.571948\tAccuracy: 87.77%\n",
      "212\tValidation loss: 0.572410\tBest loss: 0.571948\tAccuracy: 85.61%\n",
      "213\tValidation loss: 0.562497\tBest loss: 0.562497\tAccuracy: 86.33%\n",
      "214\tValidation loss: 0.562059\tBest loss: 0.562059\tAccuracy: 84.89%\n",
      "215\tValidation loss: 0.554897\tBest loss: 0.554897\tAccuracy: 86.33%\n",
      "216\tValidation loss: 0.546052\tBest loss: 0.546052\tAccuracy: 88.49%\n",
      "217\tValidation loss: 0.537701\tBest loss: 0.537701\tAccuracy: 87.77%\n",
      "218\tValidation loss: 0.543800\tBest loss: 0.537701\tAccuracy: 86.33%\n",
      "219\tValidation loss: 0.544697\tBest loss: 0.537701\tAccuracy: 85.61%\n",
      "220\tValidation loss: 0.544050\tBest loss: 0.537701\tAccuracy: 85.61%\n",
      "221\tValidation loss: 0.535755\tBest loss: 0.535755\tAccuracy: 87.05%\n",
      "222\tValidation loss: 0.537789\tBest loss: 0.535755\tAccuracy: 87.05%\n",
      "223\tValidation loss: 0.535166\tBest loss: 0.535166\tAccuracy: 87.05%\n",
      "224\tValidation loss: 0.536982\tBest loss: 0.535166\tAccuracy: 87.77%\n",
      "225\tValidation loss: 0.535371\tBest loss: 0.535166\tAccuracy: 87.77%\n",
      "226\tValidation loss: 0.528371\tBest loss: 0.528371\tAccuracy: 87.77%\n",
      "227\tValidation loss: 0.519367\tBest loss: 0.519367\tAccuracy: 87.77%\n",
      "228\tValidation loss: 0.526353\tBest loss: 0.519367\tAccuracy: 86.33%\n",
      "229\tValidation loss: 0.518678\tBest loss: 0.518678\tAccuracy: 87.77%\n",
      "230\tValidation loss: 0.519906\tBest loss: 0.518678\tAccuracy: 88.49%\n",
      "231\tValidation loss: 0.528870\tBest loss: 0.518678\tAccuracy: 85.61%\n",
      "232\tValidation loss: 0.519393\tBest loss: 0.518678\tAccuracy: 87.05%\n",
      "233\tValidation loss: 0.515997\tBest loss: 0.515997\tAccuracy: 88.49%\n",
      "234\tValidation loss: 0.524419\tBest loss: 0.515997\tAccuracy: 88.49%\n",
      "235\tValidation loss: 0.513565\tBest loss: 0.513565\tAccuracy: 88.49%\n",
      "236\tValidation loss: 0.511728\tBest loss: 0.511728\tAccuracy: 87.05%\n",
      "237\tValidation loss: 0.519942\tBest loss: 0.511728\tAccuracy: 88.49%\n",
      "238\tValidation loss: 0.510544\tBest loss: 0.510544\tAccuracy: 89.93%\n",
      "239\tValidation loss: 0.513564\tBest loss: 0.510544\tAccuracy: 87.77%\n",
      "240\tValidation loss: 0.519884\tBest loss: 0.510544\tAccuracy: 87.77%\n",
      "241\tValidation loss: 0.521067\tBest loss: 0.510544\tAccuracy: 86.33%\n",
      "242\tValidation loss: 0.516298\tBest loss: 0.510544\tAccuracy: 86.33%\n",
      "243\tValidation loss: 0.510941\tBest loss: 0.510544\tAccuracy: 88.49%\n",
      "244\tValidation loss: 0.508916\tBest loss: 0.508916\tAccuracy: 88.49%\n",
      "245\tValidation loss: 0.500754\tBest loss: 0.500754\tAccuracy: 87.77%\n",
      "246\tValidation loss: 0.489656\tBest loss: 0.489656\tAccuracy: 89.21%\n",
      "247\tValidation loss: 0.504169\tBest loss: 0.489656\tAccuracy: 89.21%\n",
      "248\tValidation loss: 0.497411\tBest loss: 0.489656\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\tValidation loss: 0.482914\tBest loss: 0.482914\tAccuracy: 91.37%\n",
      "250\tValidation loss: 0.476151\tBest loss: 0.476151\tAccuracy: 90.65%\n",
      "251\tValidation loss: 0.463001\tBest loss: 0.463001\tAccuracy: 91.37%\n",
      "252\tValidation loss: 0.470013\tBest loss: 0.463001\tAccuracy: 92.09%\n",
      "253\tValidation loss: 0.465441\tBest loss: 0.463001\tAccuracy: 89.93%\n",
      "254\tValidation loss: 0.461183\tBest loss: 0.461183\tAccuracy: 89.93%\n",
      "255\tValidation loss: 0.461420\tBest loss: 0.461183\tAccuracy: 89.93%\n",
      "256\tValidation loss: 0.472492\tBest loss: 0.461183\tAccuracy: 89.93%\n",
      "257\tValidation loss: 0.467246\tBest loss: 0.461183\tAccuracy: 90.65%\n",
      "258\tValidation loss: 0.469499\tBest loss: 0.461183\tAccuracy: 89.93%\n",
      "259\tValidation loss: 0.457173\tBest loss: 0.457173\tAccuracy: 89.93%\n",
      "260\tValidation loss: 0.458938\tBest loss: 0.457173\tAccuracy: 89.21%\n",
      "261\tValidation loss: 0.450115\tBest loss: 0.450115\tAccuracy: 91.37%\n",
      "262\tValidation loss: 0.460493\tBest loss: 0.450115\tAccuracy: 92.09%\n",
      "263\tValidation loss: 0.461007\tBest loss: 0.450115\tAccuracy: 89.21%\n",
      "264\tValidation loss: 0.460590\tBest loss: 0.450115\tAccuracy: 89.21%\n",
      "265\tValidation loss: 0.470092\tBest loss: 0.450115\tAccuracy: 88.49%\n",
      "266\tValidation loss: 0.464610\tBest loss: 0.450115\tAccuracy: 89.21%\n",
      "267\tValidation loss: 0.461577\tBest loss: 0.450115\tAccuracy: 90.65%\n",
      "268\tValidation loss: 0.460104\tBest loss: 0.450115\tAccuracy: 88.49%\n",
      "269\tValidation loss: 0.454740\tBest loss: 0.450115\tAccuracy: 89.21%\n",
      "270\tValidation loss: 0.453878\tBest loss: 0.450115\tAccuracy: 89.21%\n",
      "271\tValidation loss: 0.451824\tBest loss: 0.450115\tAccuracy: 90.65%\n",
      "272\tValidation loss: 0.445870\tBest loss: 0.445870\tAccuracy: 92.09%\n",
      "273\tValidation loss: 0.449655\tBest loss: 0.445870\tAccuracy: 89.93%\n",
      "274\tValidation loss: 0.445938\tBest loss: 0.445870\tAccuracy: 91.37%\n",
      "275\tValidation loss: 0.440938\tBest loss: 0.440938\tAccuracy: 91.37%\n",
      "276\tValidation loss: 0.450280\tBest loss: 0.440938\tAccuracy: 89.21%\n",
      "277\tValidation loss: 0.447612\tBest loss: 0.440938\tAccuracy: 88.49%\n",
      "278\tValidation loss: 0.445945\tBest loss: 0.440938\tAccuracy: 89.21%\n",
      "279\tValidation loss: 0.449146\tBest loss: 0.440938\tAccuracy: 89.21%\n",
      "280\tValidation loss: 0.454066\tBest loss: 0.440938\tAccuracy: 89.21%\n",
      "281\tValidation loss: 0.451372\tBest loss: 0.440938\tAccuracy: 89.21%\n",
      "282\tValidation loss: 0.444234\tBest loss: 0.440938\tAccuracy: 89.93%\n",
      "283\tValidation loss: 0.437863\tBest loss: 0.437863\tAccuracy: 90.65%\n",
      "284\tValidation loss: 0.432061\tBest loss: 0.432061\tAccuracy: 90.65%\n",
      "285\tValidation loss: 0.446697\tBest loss: 0.432061\tAccuracy: 90.65%\n",
      "286\tValidation loss: 0.443362\tBest loss: 0.432061\tAccuracy: 91.37%\n",
      "287\tValidation loss: 0.441973\tBest loss: 0.432061\tAccuracy: 91.37%\n",
      "288\tValidation loss: 0.432974\tBest loss: 0.432061\tAccuracy: 91.37%\n",
      "289\tValidation loss: 0.421639\tBest loss: 0.421639\tAccuracy: 91.37%\n",
      "290\tValidation loss: 0.424447\tBest loss: 0.421639\tAccuracy: 89.93%\n",
      "291\tValidation loss: 0.430072\tBest loss: 0.421639\tAccuracy: 88.49%\n",
      "292\tValidation loss: 0.423506\tBest loss: 0.421639\tAccuracy: 89.21%\n",
      "293\tValidation loss: 0.422063\tBest loss: 0.421639\tAccuracy: 92.09%\n",
      "294\tValidation loss: 0.424854\tBest loss: 0.421639\tAccuracy: 92.09%\n",
      "295\tValidation loss: 0.419538\tBest loss: 0.419538\tAccuracy: 90.65%\n",
      "296\tValidation loss: 0.425972\tBest loss: 0.419538\tAccuracy: 89.93%\n",
      "297\tValidation loss: 0.417492\tBest loss: 0.417492\tAccuracy: 90.65%\n",
      "298\tValidation loss: 0.412010\tBest loss: 0.412010\tAccuracy: 91.37%\n",
      "299\tValidation loss: 0.409864\tBest loss: 0.409864\tAccuracy: 91.37%\n",
      "300\tValidation loss: 0.410720\tBest loss: 0.409864\tAccuracy: 92.09%\n",
      "301\tValidation loss: 0.403579\tBest loss: 0.403579\tAccuracy: 90.65%\n",
      "302\tValidation loss: 0.406408\tBest loss: 0.403579\tAccuracy: 89.93%\n",
      "303\tValidation loss: 0.408883\tBest loss: 0.403579\tAccuracy: 90.65%\n",
      "304\tValidation loss: 0.412676\tBest loss: 0.403579\tAccuracy: 90.65%\n",
      "305\tValidation loss: 0.409406\tBest loss: 0.403579\tAccuracy: 89.93%\n",
      "306\tValidation loss: 0.399351\tBest loss: 0.399351\tAccuracy: 90.65%\n",
      "307\tValidation loss: 0.412889\tBest loss: 0.399351\tAccuracy: 89.93%\n",
      "308\tValidation loss: 0.406024\tBest loss: 0.399351\tAccuracy: 91.37%\n",
      "309\tValidation loss: 0.399910\tBest loss: 0.399351\tAccuracy: 89.93%\n",
      "310\tValidation loss: 0.391052\tBest loss: 0.391052\tAccuracy: 89.93%\n",
      "311\tValidation loss: 0.404932\tBest loss: 0.391052\tAccuracy: 89.21%\n",
      "312\tValidation loss: 0.402662\tBest loss: 0.391052\tAccuracy: 90.65%\n",
      "313\tValidation loss: 0.405288\tBest loss: 0.391052\tAccuracy: 89.93%\n",
      "314\tValidation loss: 0.400810\tBest loss: 0.391052\tAccuracy: 90.65%\n",
      "315\tValidation loss: 0.401806\tBest loss: 0.391052\tAccuracy: 89.93%\n",
      "316\tValidation loss: 0.395898\tBest loss: 0.391052\tAccuracy: 90.65%\n",
      "317\tValidation loss: 0.400992\tBest loss: 0.391052\tAccuracy: 89.93%\n",
      "318\tValidation loss: 0.395522\tBest loss: 0.391052\tAccuracy: 90.65%\n",
      "319\tValidation loss: 0.395326\tBest loss: 0.391052\tAccuracy: 90.65%\n",
      "320\tValidation loss: 0.392388\tBest loss: 0.391052\tAccuracy: 91.37%\n",
      "321\tValidation loss: 0.391460\tBest loss: 0.391052\tAccuracy: 91.37%\n",
      "322\tValidation loss: 0.388145\tBest loss: 0.388145\tAccuracy: 91.37%\n",
      "323\tValidation loss: 0.386482\tBest loss: 0.386482\tAccuracy: 89.93%\n",
      "324\tValidation loss: 0.391662\tBest loss: 0.386482\tAccuracy: 91.37%\n",
      "325\tValidation loss: 0.389525\tBest loss: 0.386482\tAccuracy: 90.65%\n",
      "326\tValidation loss: 0.399245\tBest loss: 0.386482\tAccuracy: 90.65%\n",
      "327\tValidation loss: 0.397641\tBest loss: 0.386482\tAccuracy: 92.09%\n",
      "328\tValidation loss: 0.395959\tBest loss: 0.386482\tAccuracy: 90.65%\n",
      "329\tValidation loss: 0.393477\tBest loss: 0.386482\tAccuracy: 91.37%\n",
      "330\tValidation loss: 0.392374\tBest loss: 0.386482\tAccuracy: 91.37%\n",
      "331\tValidation loss: 0.400161\tBest loss: 0.386482\tAccuracy: 90.65%\n",
      "332\tValidation loss: 0.397918\tBest loss: 0.386482\tAccuracy: 91.37%\n",
      "333\tValidation loss: 0.402264\tBest loss: 0.386482\tAccuracy: 91.37%\n",
      "334\tValidation loss: 0.387254\tBest loss: 0.386482\tAccuracy: 92.09%\n",
      "335\tValidation loss: 0.382393\tBest loss: 0.382393\tAccuracy: 92.09%\n",
      "336\tValidation loss: 0.385081\tBest loss: 0.382393\tAccuracy: 91.37%\n",
      "337\tValidation loss: 0.386305\tBest loss: 0.382393\tAccuracy: 92.09%\n",
      "338\tValidation loss: 0.385453\tBest loss: 0.382393\tAccuracy: 91.37%\n",
      "339\tValidation loss: 0.381771\tBest loss: 0.381771\tAccuracy: 92.09%\n",
      "340\tValidation loss: 0.385478\tBest loss: 0.381771\tAccuracy: 92.09%\n",
      "341\tValidation loss: 0.382406\tBest loss: 0.381771\tAccuracy: 91.37%\n",
      "342\tValidation loss: 0.379548\tBest loss: 0.379548\tAccuracy: 91.37%\n",
      "343\tValidation loss: 0.385084\tBest loss: 0.379548\tAccuracy: 90.65%\n",
      "344\tValidation loss: 0.378351\tBest loss: 0.378351\tAccuracy: 92.09%\n",
      "345\tValidation loss: 0.375923\tBest loss: 0.375923\tAccuracy: 92.81%\n",
      "346\tValidation loss: 0.376087\tBest loss: 0.375923\tAccuracy: 92.09%\n",
      "347\tValidation loss: 0.369610\tBest loss: 0.369610\tAccuracy: 91.37%\n",
      "348\tValidation loss: 0.370051\tBest loss: 0.369610\tAccuracy: 92.09%\n",
      "349\tValidation loss: 0.370266\tBest loss: 0.369610\tAccuracy: 91.37%\n",
      "350\tValidation loss: 0.377168\tBest loss: 0.369610\tAccuracy: 92.09%\n",
      "351\tValidation loss: 0.372759\tBest loss: 0.369610\tAccuracy: 92.81%\n",
      "352\tValidation loss: 0.372690\tBest loss: 0.369610\tAccuracy: 90.65%\n",
      "353\tValidation loss: 0.366892\tBest loss: 0.366892\tAccuracy: 92.09%\n",
      "354\tValidation loss: 0.360977\tBest loss: 0.360977\tAccuracy: 92.81%\n",
      "355\tValidation loss: 0.362792\tBest loss: 0.360977\tAccuracy: 92.09%\n",
      "356\tValidation loss: 0.360853\tBest loss: 0.360853\tAccuracy: 92.09%\n",
      "357\tValidation loss: 0.358529\tBest loss: 0.358529\tAccuracy: 92.09%\n",
      "358\tValidation loss: 0.353606\tBest loss: 0.353606\tAccuracy: 91.37%\n",
      "359\tValidation loss: 0.361266\tBest loss: 0.353606\tAccuracy: 92.09%\n",
      "360\tValidation loss: 0.356793\tBest loss: 0.353606\tAccuracy: 92.81%\n",
      "361\tValidation loss: 0.358884\tBest loss: 0.353606\tAccuracy: 92.81%\n",
      "362\tValidation loss: 0.352434\tBest loss: 0.352434\tAccuracy: 93.53%\n",
      "363\tValidation loss: 0.348106\tBest loss: 0.348106\tAccuracy: 94.24%\n",
      "364\tValidation loss: 0.344129\tBest loss: 0.344129\tAccuracy: 93.53%\n",
      "365\tValidation loss: 0.345946\tBest loss: 0.344129\tAccuracy: 93.53%\n",
      "366\tValidation loss: 0.347201\tBest loss: 0.344129\tAccuracy: 94.24%\n",
      "367\tValidation loss: 0.343419\tBest loss: 0.343419\tAccuracy: 94.24%\n",
      "368\tValidation loss: 0.340439\tBest loss: 0.340439\tAccuracy: 92.81%\n",
      "369\tValidation loss: 0.337393\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "370\tValidation loss: 0.342440\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "371\tValidation loss: 0.340927\tBest loss: 0.337393\tAccuracy: 93.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\tValidation loss: 0.338599\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "373\tValidation loss: 0.345991\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "374\tValidation loss: 0.344131\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "375\tValidation loss: 0.339771\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "376\tValidation loss: 0.345632\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "377\tValidation loss: 0.344154\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "378\tValidation loss: 0.340162\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "379\tValidation loss: 0.340906\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "380\tValidation loss: 0.338351\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "381\tValidation loss: 0.338008\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "382\tValidation loss: 0.344193\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "383\tValidation loss: 0.338333\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "384\tValidation loss: 0.342849\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "385\tValidation loss: 0.343289\tBest loss: 0.337393\tAccuracy: 92.81%\n",
      "386\tValidation loss: 0.349101\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "387\tValidation loss: 0.344590\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "388\tValidation loss: 0.345764\tBest loss: 0.337393\tAccuracy: 91.37%\n",
      "389\tValidation loss: 0.338056\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "390\tValidation loss: 0.343087\tBest loss: 0.337393\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  45.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 36.466911\tBest loss: 36.466911\tAccuracy: 6.47%\n",
      "1\tValidation loss: 71.100533\tBest loss: 36.466911\tAccuracy: 5.76%\n",
      "2\tValidation loss: 20.739893\tBest loss: 20.739893\tAccuracy: 9.35%\n",
      "3\tValidation loss: 6.634761\tBest loss: 6.634761\tAccuracy: 12.95%\n",
      "4\tValidation loss: 4.312547\tBest loss: 4.312547\tAccuracy: 15.83%\n",
      "5\tValidation loss: 3.608873\tBest loss: 3.608873\tAccuracy: 26.62%\n",
      "6\tValidation loss: 3.518299\tBest loss: 3.518299\tAccuracy: 24.46%\n",
      "7\tValidation loss: 3.491664\tBest loss: 3.491664\tAccuracy: 23.74%\n",
      "8\tValidation loss: 3.425460\tBest loss: 3.425460\tAccuracy: 24.46%\n",
      "9\tValidation loss: 3.374866\tBest loss: 3.374866\tAccuracy: 26.62%\n",
      "10\tValidation loss: 3.339995\tBest loss: 3.339995\tAccuracy: 25.90%\n",
      "11\tValidation loss: 3.274054\tBest loss: 3.274054\tAccuracy: 23.74%\n",
      "12\tValidation loss: 3.217420\tBest loss: 3.217420\tAccuracy: 25.90%\n",
      "13\tValidation loss: 3.112176\tBest loss: 3.112176\tAccuracy: 30.94%\n",
      "14\tValidation loss: 3.056119\tBest loss: 3.056119\tAccuracy: 31.65%\n",
      "15\tValidation loss: 2.985763\tBest loss: 2.985763\tAccuracy: 32.37%\n",
      "16\tValidation loss: 2.902080\tBest loss: 2.902080\tAccuracy: 34.53%\n",
      "17\tValidation loss: 2.852663\tBest loss: 2.852663\tAccuracy: 37.41%\n",
      "18\tValidation loss: 2.807653\tBest loss: 2.807653\tAccuracy: 35.97%\n",
      "19\tValidation loss: 2.747738\tBest loss: 2.747738\tAccuracy: 37.41%\n",
      "20\tValidation loss: 2.720037\tBest loss: 2.720037\tAccuracy: 36.69%\n",
      "21\tValidation loss: 2.683063\tBest loss: 2.683063\tAccuracy: 41.73%\n",
      "22\tValidation loss: 2.628304\tBest loss: 2.628304\tAccuracy: 46.04%\n",
      "23\tValidation loss: 2.578995\tBest loss: 2.578995\tAccuracy: 43.17%\n",
      "24\tValidation loss: 2.570635\tBest loss: 2.570635\tAccuracy: 43.17%\n",
      "25\tValidation loss: 2.494375\tBest loss: 2.494375\tAccuracy: 45.32%\n",
      "26\tValidation loss: 2.475857\tBest loss: 2.475857\tAccuracy: 46.04%\n",
      "27\tValidation loss: 2.359985\tBest loss: 2.359985\tAccuracy: 47.48%\n",
      "28\tValidation loss: 2.310243\tBest loss: 2.310243\tAccuracy: 46.04%\n",
      "29\tValidation loss: 2.289001\tBest loss: 2.289001\tAccuracy: 46.76%\n",
      "30\tValidation loss: 2.278087\tBest loss: 2.278087\tAccuracy: 48.92%\n",
      "31\tValidation loss: 2.210669\tBest loss: 2.210669\tAccuracy: 51.08%\n",
      "32\tValidation loss: 2.178407\tBest loss: 2.178407\tAccuracy: 52.52%\n",
      "33\tValidation loss: 2.099483\tBest loss: 2.099483\tAccuracy: 52.52%\n",
      "34\tValidation loss: 2.070941\tBest loss: 2.070941\tAccuracy: 52.52%\n",
      "35\tValidation loss: 2.007421\tBest loss: 2.007421\tAccuracy: 54.68%\n",
      "36\tValidation loss: 2.006961\tBest loss: 2.006961\tAccuracy: 53.96%\n",
      "37\tValidation loss: 1.956119\tBest loss: 1.956119\tAccuracy: 56.83%\n",
      "38\tValidation loss: 1.888573\tBest loss: 1.888573\tAccuracy: 57.55%\n",
      "39\tValidation loss: 1.834048\tBest loss: 1.834048\tAccuracy: 56.83%\n",
      "40\tValidation loss: 1.863037\tBest loss: 1.834048\tAccuracy: 53.96%\n",
      "41\tValidation loss: 1.826911\tBest loss: 1.826911\tAccuracy: 56.12%\n",
      "42\tValidation loss: 1.756652\tBest loss: 1.756652\tAccuracy: 58.27%\n",
      "43\tValidation loss: 1.733552\tBest loss: 1.733552\tAccuracy: 59.71%\n",
      "44\tValidation loss: 1.660848\tBest loss: 1.660848\tAccuracy: 59.71%\n",
      "45\tValidation loss: 1.619848\tBest loss: 1.619848\tAccuracy: 61.15%\n",
      "46\tValidation loss: 1.608686\tBest loss: 1.608686\tAccuracy: 61.15%\n",
      "47\tValidation loss: 1.613256\tBest loss: 1.608686\tAccuracy: 61.87%\n",
      "48\tValidation loss: 1.566018\tBest loss: 1.566018\tAccuracy: 65.47%\n",
      "49\tValidation loss: 1.569320\tBest loss: 1.566018\tAccuracy: 62.59%\n",
      "50\tValidation loss: 1.510137\tBest loss: 1.510137\tAccuracy: 66.19%\n",
      "51\tValidation loss: 1.531224\tBest loss: 1.510137\tAccuracy: 65.47%\n",
      "52\tValidation loss: 1.453197\tBest loss: 1.453197\tAccuracy: 68.35%\n",
      "53\tValidation loss: 1.420834\tBest loss: 1.420834\tAccuracy: 66.91%\n",
      "54\tValidation loss: 1.373255\tBest loss: 1.373255\tAccuracy: 69.06%\n",
      "55\tValidation loss: 1.370672\tBest loss: 1.370672\tAccuracy: 69.06%\n",
      "56\tValidation loss: 1.362190\tBest loss: 1.362190\tAccuracy: 69.06%\n",
      "57\tValidation loss: 1.344249\tBest loss: 1.344249\tAccuracy: 67.63%\n",
      "58\tValidation loss: 1.284849\tBest loss: 1.284849\tAccuracy: 74.10%\n",
      "59\tValidation loss: 1.262296\tBest loss: 1.262296\tAccuracy: 71.94%\n",
      "60\tValidation loss: 1.264501\tBest loss: 1.262296\tAccuracy: 71.94%\n",
      "61\tValidation loss: 1.254987\tBest loss: 1.254987\tAccuracy: 71.94%\n",
      "62\tValidation loss: 1.254603\tBest loss: 1.254603\tAccuracy: 70.50%\n",
      "63\tValidation loss: 1.224291\tBest loss: 1.224291\tAccuracy: 74.10%\n",
      "64\tValidation loss: 1.211300\tBest loss: 1.211300\tAccuracy: 71.94%\n",
      "65\tValidation loss: 1.153592\tBest loss: 1.153592\tAccuracy: 74.82%\n",
      "66\tValidation loss: 1.165010\tBest loss: 1.153592\tAccuracy: 71.94%\n",
      "67\tValidation loss: 1.141515\tBest loss: 1.141515\tAccuracy: 74.10%\n",
      "68\tValidation loss: 1.093103\tBest loss: 1.093103\tAccuracy: 74.82%\n",
      "69\tValidation loss: 1.102472\tBest loss: 1.093103\tAccuracy: 74.82%\n",
      "70\tValidation loss: 1.112086\tBest loss: 1.093103\tAccuracy: 74.10%\n",
      "71\tValidation loss: 1.090577\tBest loss: 1.090577\tAccuracy: 73.38%\n",
      "72\tValidation loss: 1.058841\tBest loss: 1.058841\tAccuracy: 75.54%\n",
      "73\tValidation loss: 1.067319\tBest loss: 1.058841\tAccuracy: 76.26%\n",
      "74\tValidation loss: 1.045843\tBest loss: 1.045843\tAccuracy: 77.70%\n",
      "75\tValidation loss: 1.031561\tBest loss: 1.031561\tAccuracy: 76.98%\n",
      "76\tValidation loss: 0.981170\tBest loss: 0.981170\tAccuracy: 78.42%\n",
      "77\tValidation loss: 0.971182\tBest loss: 0.971182\tAccuracy: 79.86%\n",
      "78\tValidation loss: 0.964656\tBest loss: 0.964656\tAccuracy: 78.42%\n",
      "79\tValidation loss: 0.961203\tBest loss: 0.961203\tAccuracy: 79.14%\n",
      "80\tValidation loss: 0.949868\tBest loss: 0.949868\tAccuracy: 79.14%\n",
      "81\tValidation loss: 0.937516\tBest loss: 0.937516\tAccuracy: 77.70%\n",
      "82\tValidation loss: 0.899515\tBest loss: 0.899515\tAccuracy: 79.14%\n",
      "83\tValidation loss: 0.895856\tBest loss: 0.895856\tAccuracy: 79.14%\n",
      "84\tValidation loss: 0.870189\tBest loss: 0.870189\tAccuracy: 79.14%\n",
      "85\tValidation loss: 0.884383\tBest loss: 0.870189\tAccuracy: 79.86%\n",
      "86\tValidation loss: 0.884341\tBest loss: 0.870189\tAccuracy: 79.14%\n",
      "87\tValidation loss: 0.924448\tBest loss: 0.870189\tAccuracy: 76.98%\n",
      "88\tValidation loss: 0.909409\tBest loss: 0.870189\tAccuracy: 76.98%\n",
      "89\tValidation loss: 0.903776\tBest loss: 0.870189\tAccuracy: 77.70%\n",
      "90\tValidation loss: 0.912512\tBest loss: 0.870189\tAccuracy: 78.42%\n",
      "91\tValidation loss: 0.893355\tBest loss: 0.870189\tAccuracy: 79.86%\n",
      "92\tValidation loss: 0.898642\tBest loss: 0.870189\tAccuracy: 79.14%\n",
      "93\tValidation loss: 0.869045\tBest loss: 0.869045\tAccuracy: 79.86%\n",
      "94\tValidation loss: 0.853575\tBest loss: 0.853575\tAccuracy: 81.29%\n",
      "95\tValidation loss: 0.842121\tBest loss: 0.842121\tAccuracy: 80.58%\n",
      "96\tValidation loss: 0.830099\tBest loss: 0.830099\tAccuracy: 80.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\tValidation loss: 0.818693\tBest loss: 0.818693\tAccuracy: 81.29%\n",
      "98\tValidation loss: 0.811056\tBest loss: 0.811056\tAccuracy: 81.29%\n",
      "99\tValidation loss: 0.838692\tBest loss: 0.811056\tAccuracy: 79.86%\n",
      "100\tValidation loss: 0.815361\tBest loss: 0.811056\tAccuracy: 79.14%\n",
      "101\tValidation loss: 0.814597\tBest loss: 0.811056\tAccuracy: 80.58%\n",
      "102\tValidation loss: 0.821763\tBest loss: 0.811056\tAccuracy: 79.14%\n",
      "103\tValidation loss: 0.808492\tBest loss: 0.808492\tAccuracy: 80.58%\n",
      "104\tValidation loss: 0.792507\tBest loss: 0.792507\tAccuracy: 81.29%\n",
      "105\tValidation loss: 0.799396\tBest loss: 0.792507\tAccuracy: 80.58%\n",
      "106\tValidation loss: 0.782814\tBest loss: 0.782814\tAccuracy: 80.58%\n",
      "107\tValidation loss: 0.800510\tBest loss: 0.782814\tAccuracy: 82.01%\n",
      "108\tValidation loss: 0.775589\tBest loss: 0.775589\tAccuracy: 81.29%\n",
      "109\tValidation loss: 0.762887\tBest loss: 0.762887\tAccuracy: 82.01%\n",
      "110\tValidation loss: 0.763107\tBest loss: 0.762887\tAccuracy: 81.29%\n",
      "111\tValidation loss: 0.757570\tBest loss: 0.757570\tAccuracy: 82.01%\n",
      "112\tValidation loss: 0.771860\tBest loss: 0.757570\tAccuracy: 82.01%\n",
      "113\tValidation loss: 0.764088\tBest loss: 0.757570\tAccuracy: 80.58%\n",
      "114\tValidation loss: 0.746172\tBest loss: 0.746172\tAccuracy: 82.01%\n",
      "115\tValidation loss: 0.731725\tBest loss: 0.731725\tAccuracy: 82.01%\n",
      "116\tValidation loss: 0.726091\tBest loss: 0.726091\tAccuracy: 82.01%\n",
      "117\tValidation loss: 0.717558\tBest loss: 0.717558\tAccuracy: 80.58%\n",
      "118\tValidation loss: 0.718084\tBest loss: 0.717558\tAccuracy: 82.01%\n",
      "119\tValidation loss: 0.709147\tBest loss: 0.709147\tAccuracy: 82.01%\n",
      "120\tValidation loss: 0.721448\tBest loss: 0.709147\tAccuracy: 81.29%\n",
      "121\tValidation loss: 0.726159\tBest loss: 0.709147\tAccuracy: 80.58%\n",
      "122\tValidation loss: 0.722924\tBest loss: 0.709147\tAccuracy: 80.58%\n",
      "123\tValidation loss: 0.705007\tBest loss: 0.705007\tAccuracy: 80.58%\n",
      "124\tValidation loss: 0.709998\tBest loss: 0.705007\tAccuracy: 82.01%\n",
      "125\tValidation loss: 0.711665\tBest loss: 0.705007\tAccuracy: 80.58%\n",
      "126\tValidation loss: 0.704310\tBest loss: 0.704310\tAccuracy: 81.29%\n",
      "127\tValidation loss: 0.694616\tBest loss: 0.694616\tAccuracy: 80.58%\n",
      "128\tValidation loss: 0.686440\tBest loss: 0.686440\tAccuracy: 82.01%\n",
      "129\tValidation loss: 0.675738\tBest loss: 0.675738\tAccuracy: 82.73%\n",
      "130\tValidation loss: 0.682447\tBest loss: 0.675738\tAccuracy: 82.01%\n",
      "131\tValidation loss: 0.689257\tBest loss: 0.675738\tAccuracy: 82.73%\n",
      "132\tValidation loss: 0.697699\tBest loss: 0.675738\tAccuracy: 81.29%\n",
      "133\tValidation loss: 0.718800\tBest loss: 0.675738\tAccuracy: 80.58%\n",
      "134\tValidation loss: 0.688523\tBest loss: 0.675738\tAccuracy: 82.01%\n",
      "135\tValidation loss: 0.672646\tBest loss: 0.672646\tAccuracy: 83.45%\n",
      "136\tValidation loss: 0.670760\tBest loss: 0.670760\tAccuracy: 82.73%\n",
      "137\tValidation loss: 0.655426\tBest loss: 0.655426\tAccuracy: 83.45%\n",
      "138\tValidation loss: 0.647119\tBest loss: 0.647119\tAccuracy: 82.01%\n",
      "139\tValidation loss: 0.663917\tBest loss: 0.647119\tAccuracy: 82.01%\n",
      "140\tValidation loss: 0.653797\tBest loss: 0.647119\tAccuracy: 82.01%\n",
      "141\tValidation loss: 0.667583\tBest loss: 0.647119\tAccuracy: 82.73%\n",
      "142\tValidation loss: 0.656481\tBest loss: 0.647119\tAccuracy: 82.01%\n",
      "143\tValidation loss: 0.651002\tBest loss: 0.647119\tAccuracy: 83.45%\n",
      "144\tValidation loss: 0.646619\tBest loss: 0.646619\tAccuracy: 82.01%\n",
      "145\tValidation loss: 0.643508\tBest loss: 0.643508\tAccuracy: 84.17%\n",
      "146\tValidation loss: 0.650059\tBest loss: 0.643508\tAccuracy: 82.73%\n",
      "147\tValidation loss: 0.672210\tBest loss: 0.643508\tAccuracy: 82.01%\n",
      "148\tValidation loss: 0.662020\tBest loss: 0.643508\tAccuracy: 82.01%\n",
      "149\tValidation loss: 0.645738\tBest loss: 0.643508\tAccuracy: 82.73%\n",
      "150\tValidation loss: 0.656218\tBest loss: 0.643508\tAccuracy: 82.01%\n",
      "151\tValidation loss: 0.650441\tBest loss: 0.643508\tAccuracy: 82.73%\n",
      "152\tValidation loss: 0.639319\tBest loss: 0.639319\tAccuracy: 84.17%\n",
      "153\tValidation loss: 0.632440\tBest loss: 0.632440\tAccuracy: 82.73%\n",
      "154\tValidation loss: 0.613762\tBest loss: 0.613762\tAccuracy: 85.61%\n",
      "155\tValidation loss: 0.616166\tBest loss: 0.613762\tAccuracy: 84.89%\n",
      "156\tValidation loss: 0.594245\tBest loss: 0.594245\tAccuracy: 83.45%\n",
      "157\tValidation loss: 0.598610\tBest loss: 0.594245\tAccuracy: 84.17%\n",
      "158\tValidation loss: 0.587203\tBest loss: 0.587203\tAccuracy: 84.17%\n",
      "159\tValidation loss: 0.591818\tBest loss: 0.587203\tAccuracy: 85.61%\n",
      "160\tValidation loss: 0.586397\tBest loss: 0.586397\tAccuracy: 84.89%\n",
      "161\tValidation loss: 0.597193\tBest loss: 0.586397\tAccuracy: 84.17%\n",
      "162\tValidation loss: 0.600941\tBest loss: 0.586397\tAccuracy: 84.17%\n",
      "163\tValidation loss: 0.597078\tBest loss: 0.586397\tAccuracy: 84.89%\n",
      "164\tValidation loss: 0.594538\tBest loss: 0.586397\tAccuracy: 84.89%\n",
      "165\tValidation loss: 0.584979\tBest loss: 0.584979\tAccuracy: 84.89%\n",
      "166\tValidation loss: 0.572576\tBest loss: 0.572576\tAccuracy: 86.33%\n",
      "167\tValidation loss: 0.562696\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "168\tValidation loss: 0.580931\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "169\tValidation loss: 0.574067\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "170\tValidation loss: 0.581865\tBest loss: 0.562696\tAccuracy: 83.45%\n",
      "171\tValidation loss: 0.582249\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "172\tValidation loss: 0.583842\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "173\tValidation loss: 0.590794\tBest loss: 0.562696\tAccuracy: 84.17%\n",
      "174\tValidation loss: 0.573805\tBest loss: 0.562696\tAccuracy: 84.89%\n",
      "175\tValidation loss: 0.561958\tBest loss: 0.561958\tAccuracy: 84.17%\n",
      "176\tValidation loss: 0.553453\tBest loss: 0.553453\tAccuracy: 85.61%\n",
      "177\tValidation loss: 0.567879\tBest loss: 0.553453\tAccuracy: 82.01%\n",
      "178\tValidation loss: 0.575254\tBest loss: 0.553453\tAccuracy: 84.17%\n",
      "179\tValidation loss: 0.581281\tBest loss: 0.553453\tAccuracy: 84.89%\n",
      "180\tValidation loss: 0.583603\tBest loss: 0.553453\tAccuracy: 85.61%\n",
      "181\tValidation loss: 0.577185\tBest loss: 0.553453\tAccuracy: 84.17%\n",
      "182\tValidation loss: 0.567892\tBest loss: 0.553453\tAccuracy: 84.89%\n",
      "183\tValidation loss: 0.561650\tBest loss: 0.553453\tAccuracy: 84.89%\n",
      "184\tValidation loss: 0.556906\tBest loss: 0.553453\tAccuracy: 84.17%\n",
      "185\tValidation loss: 0.563016\tBest loss: 0.553453\tAccuracy: 84.17%\n",
      "186\tValidation loss: 0.554330\tBest loss: 0.553453\tAccuracy: 84.17%\n",
      "187\tValidation loss: 0.535005\tBest loss: 0.535005\tAccuracy: 84.89%\n",
      "188\tValidation loss: 0.546555\tBest loss: 0.535005\tAccuracy: 85.61%\n",
      "189\tValidation loss: 0.541124\tBest loss: 0.535005\tAccuracy: 86.33%\n",
      "190\tValidation loss: 0.550645\tBest loss: 0.535005\tAccuracy: 85.61%\n",
      "191\tValidation loss: 0.549702\tBest loss: 0.535005\tAccuracy: 84.89%\n",
      "192\tValidation loss: 0.556599\tBest loss: 0.535005\tAccuracy: 85.61%\n",
      "193\tValidation loss: 0.547225\tBest loss: 0.535005\tAccuracy: 86.33%\n",
      "194\tValidation loss: 0.546972\tBest loss: 0.535005\tAccuracy: 84.89%\n",
      "195\tValidation loss: 0.558925\tBest loss: 0.535005\tAccuracy: 85.61%\n",
      "196\tValidation loss: 0.543133\tBest loss: 0.535005\tAccuracy: 86.33%\n",
      "197\tValidation loss: 0.536396\tBest loss: 0.535005\tAccuracy: 84.89%\n",
      "198\tValidation loss: 0.534474\tBest loss: 0.534474\tAccuracy: 84.17%\n",
      "199\tValidation loss: 0.536609\tBest loss: 0.534474\tAccuracy: 84.89%\n",
      "200\tValidation loss: 0.523399\tBest loss: 0.523399\tAccuracy: 86.33%\n",
      "201\tValidation loss: 0.517678\tBest loss: 0.517678\tAccuracy: 85.61%\n",
      "202\tValidation loss: 0.523282\tBest loss: 0.517678\tAccuracy: 85.61%\n",
      "203\tValidation loss: 0.531197\tBest loss: 0.517678\tAccuracy: 84.89%\n",
      "204\tValidation loss: 0.524188\tBest loss: 0.517678\tAccuracy: 84.17%\n",
      "205\tValidation loss: 0.532362\tBest loss: 0.517678\tAccuracy: 84.89%\n",
      "206\tValidation loss: 0.518732\tBest loss: 0.517678\tAccuracy: 84.17%\n",
      "207\tValidation loss: 0.516922\tBest loss: 0.516922\tAccuracy: 86.33%\n",
      "208\tValidation loss: 0.536697\tBest loss: 0.516922\tAccuracy: 86.33%\n",
      "209\tValidation loss: 0.530419\tBest loss: 0.516922\tAccuracy: 84.17%\n",
      "210\tValidation loss: 0.523957\tBest loss: 0.516922\tAccuracy: 84.89%\n",
      "211\tValidation loss: 0.514145\tBest loss: 0.514145\tAccuracy: 85.61%\n",
      "212\tValidation loss: 0.509123\tBest loss: 0.509123\tAccuracy: 85.61%\n",
      "213\tValidation loss: 0.499843\tBest loss: 0.499843\tAccuracy: 84.89%\n",
      "214\tValidation loss: 0.498158\tBest loss: 0.498158\tAccuracy: 85.61%\n",
      "215\tValidation loss: 0.506530\tBest loss: 0.498158\tAccuracy: 85.61%\n",
      "216\tValidation loss: 0.500355\tBest loss: 0.498158\tAccuracy: 86.33%\n",
      "217\tValidation loss: 0.505619\tBest loss: 0.498158\tAccuracy: 87.05%\n",
      "218\tValidation loss: 0.507626\tBest loss: 0.498158\tAccuracy: 85.61%\n",
      "219\tValidation loss: 0.491078\tBest loss: 0.491078\tAccuracy: 87.77%\n",
      "220\tValidation loss: 0.485676\tBest loss: 0.485676\tAccuracy: 87.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\tValidation loss: 0.493305\tBest loss: 0.485676\tAccuracy: 85.61%\n",
      "222\tValidation loss: 0.486401\tBest loss: 0.485676\tAccuracy: 87.05%\n",
      "223\tValidation loss: 0.481540\tBest loss: 0.481540\tAccuracy: 87.05%\n",
      "224\tValidation loss: 0.491055\tBest loss: 0.481540\tAccuracy: 87.05%\n",
      "225\tValidation loss: 0.480443\tBest loss: 0.480443\tAccuracy: 86.33%\n",
      "226\tValidation loss: 0.482712\tBest loss: 0.480443\tAccuracy: 86.33%\n",
      "227\tValidation loss: 0.479792\tBest loss: 0.479792\tAccuracy: 86.33%\n",
      "228\tValidation loss: 0.484806\tBest loss: 0.479792\tAccuracy: 87.05%\n",
      "229\tValidation loss: 0.477881\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "230\tValidation loss: 0.478067\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "231\tValidation loss: 0.478034\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "232\tValidation loss: 0.483469\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "233\tValidation loss: 0.495773\tBest loss: 0.477881\tAccuracy: 84.89%\n",
      "234\tValidation loss: 0.494635\tBest loss: 0.477881\tAccuracy: 84.89%\n",
      "235\tValidation loss: 0.494994\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "236\tValidation loss: 0.489432\tBest loss: 0.477881\tAccuracy: 85.61%\n",
      "237\tValidation loss: 0.488562\tBest loss: 0.477881\tAccuracy: 84.89%\n",
      "238\tValidation loss: 0.484461\tBest loss: 0.477881\tAccuracy: 85.61%\n",
      "239\tValidation loss: 0.491112\tBest loss: 0.477881\tAccuracy: 86.33%\n",
      "240\tValidation loss: 0.485030\tBest loss: 0.477881\tAccuracy: 87.05%\n",
      "241\tValidation loss: 0.473768\tBest loss: 0.473768\tAccuracy: 86.33%\n",
      "242\tValidation loss: 0.476594\tBest loss: 0.473768\tAccuracy: 85.61%\n",
      "243\tValidation loss: 0.465093\tBest loss: 0.465093\tAccuracy: 86.33%\n",
      "244\tValidation loss: 0.472841\tBest loss: 0.465093\tAccuracy: 87.77%\n",
      "245\tValidation loss: 0.471158\tBest loss: 0.465093\tAccuracy: 87.77%\n",
      "246\tValidation loss: 0.467996\tBest loss: 0.465093\tAccuracy: 86.33%\n",
      "247\tValidation loss: 0.462355\tBest loss: 0.462355\tAccuracy: 85.61%\n",
      "248\tValidation loss: 0.462283\tBest loss: 0.462283\tAccuracy: 85.61%\n",
      "249\tValidation loss: 0.455164\tBest loss: 0.455164\tAccuracy: 86.33%\n",
      "250\tValidation loss: 0.458388\tBest loss: 0.455164\tAccuracy: 87.05%\n",
      "251\tValidation loss: 0.467153\tBest loss: 0.455164\tAccuracy: 85.61%\n",
      "252\tValidation loss: 0.465754\tBest loss: 0.455164\tAccuracy: 86.33%\n",
      "253\tValidation loss: 0.457773\tBest loss: 0.455164\tAccuracy: 86.33%\n",
      "254\tValidation loss: 0.450552\tBest loss: 0.450552\tAccuracy: 87.05%\n",
      "255\tValidation loss: 0.451492\tBest loss: 0.450552\tAccuracy: 88.49%\n",
      "256\tValidation loss: 0.447235\tBest loss: 0.447235\tAccuracy: 87.05%\n",
      "257\tValidation loss: 0.444233\tBest loss: 0.444233\tAccuracy: 85.61%\n",
      "258\tValidation loss: 0.448459\tBest loss: 0.444233\tAccuracy: 87.05%\n",
      "259\tValidation loss: 0.442059\tBest loss: 0.442059\tAccuracy: 86.33%\n",
      "260\tValidation loss: 0.436434\tBest loss: 0.436434\tAccuracy: 88.49%\n",
      "261\tValidation loss: 0.437781\tBest loss: 0.436434\tAccuracy: 86.33%\n",
      "262\tValidation loss: 0.435286\tBest loss: 0.435286\tAccuracy: 87.77%\n",
      "263\tValidation loss: 0.432825\tBest loss: 0.432825\tAccuracy: 88.49%\n",
      "264\tValidation loss: 0.424324\tBest loss: 0.424324\tAccuracy: 89.21%\n",
      "265\tValidation loss: 0.430488\tBest loss: 0.424324\tAccuracy: 89.21%\n",
      "266\tValidation loss: 0.438232\tBest loss: 0.424324\tAccuracy: 87.77%\n",
      "267\tValidation loss: 0.435664\tBest loss: 0.424324\tAccuracy: 87.77%\n",
      "268\tValidation loss: 0.428941\tBest loss: 0.424324\tAccuracy: 87.77%\n",
      "269\tValidation loss: 0.431441\tBest loss: 0.424324\tAccuracy: 88.49%\n",
      "270\tValidation loss: 0.436607\tBest loss: 0.424324\tAccuracy: 87.05%\n",
      "271\tValidation loss: 0.436021\tBest loss: 0.424324\tAccuracy: 86.33%\n",
      "272\tValidation loss: 0.429773\tBest loss: 0.424324\tAccuracy: 87.77%\n",
      "273\tValidation loss: 0.437182\tBest loss: 0.424324\tAccuracy: 87.77%\n",
      "274\tValidation loss: 0.438075\tBest loss: 0.424324\tAccuracy: 87.05%\n",
      "275\tValidation loss: 0.425572\tBest loss: 0.424324\tAccuracy: 87.05%\n",
      "276\tValidation loss: 0.421855\tBest loss: 0.421855\tAccuracy: 87.05%\n",
      "277\tValidation loss: 0.420611\tBest loss: 0.420611\tAccuracy: 88.49%\n",
      "278\tValidation loss: 0.414712\tBest loss: 0.414712\tAccuracy: 89.21%\n",
      "279\tValidation loss: 0.412891\tBest loss: 0.412891\tAccuracy: 89.93%\n",
      "280\tValidation loss: 0.418696\tBest loss: 0.412891\tAccuracy: 88.49%\n",
      "281\tValidation loss: 0.427797\tBest loss: 0.412891\tAccuracy: 87.77%\n",
      "282\tValidation loss: 0.418121\tBest loss: 0.412891\tAccuracy: 87.05%\n",
      "283\tValidation loss: 0.420080\tBest loss: 0.412891\tAccuracy: 87.05%\n",
      "284\tValidation loss: 0.410393\tBest loss: 0.410393\tAccuracy: 88.49%\n",
      "285\tValidation loss: 0.415034\tBest loss: 0.410393\tAccuracy: 89.21%\n",
      "286\tValidation loss: 0.412727\tBest loss: 0.410393\tAccuracy: 88.49%\n",
      "287\tValidation loss: 0.397720\tBest loss: 0.397720\tAccuracy: 89.21%\n",
      "288\tValidation loss: 0.407993\tBest loss: 0.397720\tAccuracy: 87.77%\n",
      "289\tValidation loss: 0.403416\tBest loss: 0.397720\tAccuracy: 88.49%\n",
      "290\tValidation loss: 0.394786\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "291\tValidation loss: 0.395592\tBest loss: 0.394786\tAccuracy: 89.21%\n",
      "292\tValidation loss: 0.402627\tBest loss: 0.394786\tAccuracy: 87.77%\n",
      "293\tValidation loss: 0.404468\tBest loss: 0.394786\tAccuracy: 87.77%\n",
      "294\tValidation loss: 0.409346\tBest loss: 0.394786\tAccuracy: 89.93%\n",
      "295\tValidation loss: 0.413079\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "296\tValidation loss: 0.401808\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "297\tValidation loss: 0.408069\tBest loss: 0.394786\tAccuracy: 86.33%\n",
      "298\tValidation loss: 0.414798\tBest loss: 0.394786\tAccuracy: 87.77%\n",
      "299\tValidation loss: 0.414091\tBest loss: 0.394786\tAccuracy: 87.77%\n",
      "300\tValidation loss: 0.412776\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "301\tValidation loss: 0.420077\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "302\tValidation loss: 0.400735\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "303\tValidation loss: 0.408821\tBest loss: 0.394786\tAccuracy: 89.21%\n",
      "304\tValidation loss: 0.408255\tBest loss: 0.394786\tAccuracy: 89.93%\n",
      "305\tValidation loss: 0.405412\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "306\tValidation loss: 0.406914\tBest loss: 0.394786\tAccuracy: 88.49%\n",
      "307\tValidation loss: 0.411623\tBest loss: 0.394786\tAccuracy: 87.77%\n",
      "308\tValidation loss: 0.404362\tBest loss: 0.394786\tAccuracy: 87.05%\n",
      "309\tValidation loss: 0.395204\tBest loss: 0.394786\tAccuracy: 89.21%\n",
      "310\tValidation loss: 0.397237\tBest loss: 0.394786\tAccuracy: 89.93%\n",
      "311\tValidation loss: 0.392803\tBest loss: 0.392803\tAccuracy: 90.65%\n",
      "312\tValidation loss: 0.390222\tBest loss: 0.390222\tAccuracy: 90.65%\n",
      "313\tValidation loss: 0.389550\tBest loss: 0.389550\tAccuracy: 89.93%\n",
      "314\tValidation loss: 0.391132\tBest loss: 0.389550\tAccuracy: 89.93%\n",
      "315\tValidation loss: 0.391308\tBest loss: 0.389550\tAccuracy: 89.93%\n",
      "316\tValidation loss: 0.382181\tBest loss: 0.382181\tAccuracy: 89.93%\n",
      "317\tValidation loss: 0.390561\tBest loss: 0.382181\tAccuracy: 89.93%\n",
      "318\tValidation loss: 0.397860\tBest loss: 0.382181\tAccuracy: 90.65%\n",
      "319\tValidation loss: 0.394736\tBest loss: 0.382181\tAccuracy: 90.65%\n",
      "320\tValidation loss: 0.392723\tBest loss: 0.382181\tAccuracy: 90.65%\n",
      "321\tValidation loss: 0.395190\tBest loss: 0.382181\tAccuracy: 89.21%\n",
      "322\tValidation loss: 0.402789\tBest loss: 0.382181\tAccuracy: 88.49%\n",
      "323\tValidation loss: 0.391156\tBest loss: 0.382181\tAccuracy: 89.93%\n",
      "324\tValidation loss: 0.387271\tBest loss: 0.382181\tAccuracy: 89.21%\n",
      "325\tValidation loss: 0.383482\tBest loss: 0.382181\tAccuracy: 89.93%\n",
      "326\tValidation loss: 0.382919\tBest loss: 0.382181\tAccuracy: 90.65%\n",
      "327\tValidation loss: 0.380404\tBest loss: 0.380404\tAccuracy: 89.93%\n",
      "328\tValidation loss: 0.386547\tBest loss: 0.380404\tAccuracy: 90.65%\n",
      "329\tValidation loss: 0.381855\tBest loss: 0.380404\tAccuracy: 90.65%\n",
      "330\tValidation loss: 0.380984\tBest loss: 0.380404\tAccuracy: 89.21%\n",
      "331\tValidation loss: 0.373970\tBest loss: 0.373970\tAccuracy: 89.93%\n",
      "332\tValidation loss: 0.376107\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "333\tValidation loss: 0.382995\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "334\tValidation loss: 0.381167\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "335\tValidation loss: 0.381605\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "336\tValidation loss: 0.390706\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "337\tValidation loss: 0.390703\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "338\tValidation loss: 0.388146\tBest loss: 0.373970\tAccuracy: 89.93%\n",
      "339\tValidation loss: 0.385830\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "340\tValidation loss: 0.393262\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "341\tValidation loss: 0.389067\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "342\tValidation loss: 0.385650\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "343\tValidation loss: 0.387724\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "344\tValidation loss: 0.386594\tBest loss: 0.373970\tAccuracy: 89.93%\n",
      "345\tValidation loss: 0.381562\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "346\tValidation loss: 0.381561\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "347\tValidation loss: 0.384190\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "348\tValidation loss: 0.383292\tBest loss: 0.373970\tAccuracy: 88.49%\n",
      "349\tValidation loss: 0.381356\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "350\tValidation loss: 0.376817\tBest loss: 0.373970\tAccuracy: 90.65%\n",
      "351\tValidation loss: 0.383044\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "352\tValidation loss: 0.385089\tBest loss: 0.373970\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  41.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 54.436783\tBest loss: 54.436783\tAccuracy: 21.58%\n",
      "1\tValidation loss: 90.219719\tBest loss: 54.436783\tAccuracy: 10.79%\n",
      "2\tValidation loss: 81.948097\tBest loss: 54.436783\tAccuracy: 18.71%\n",
      "3\tValidation loss: 71.844193\tBest loss: 54.436783\tAccuracy: 16.55%\n",
      "4\tValidation loss: 41.075958\tBest loss: 41.075958\tAccuracy: 23.74%\n",
      "5\tValidation loss: 27.433163\tBest loss: 27.433163\tAccuracy: 30.22%\n",
      "6\tValidation loss: 8.863759\tBest loss: 8.863759\tAccuracy: 42.45%\n",
      "7\tValidation loss: 3.276110\tBest loss: 3.276110\tAccuracy: 57.55%\n",
      "8\tValidation loss: 1.816476\tBest loss: 1.816476\tAccuracy: 69.78%\n",
      "9\tValidation loss: 1.072105\tBest loss: 1.072105\tAccuracy: 78.42%\n",
      "10\tValidation loss: 0.943807\tBest loss: 0.943807\tAccuracy: 79.86%\n",
      "11\tValidation loss: 0.784506\tBest loss: 0.784506\tAccuracy: 82.01%\n",
      "12\tValidation loss: 0.792437\tBest loss: 0.784506\tAccuracy: 79.14%\n",
      "13\tValidation loss: 0.704532\tBest loss: 0.704532\tAccuracy: 84.89%\n",
      "14\tValidation loss: 0.670577\tBest loss: 0.670577\tAccuracy: 87.05%\n",
      "15\tValidation loss: 0.658756\tBest loss: 0.658756\tAccuracy: 85.61%\n",
      "16\tValidation loss: 0.625199\tBest loss: 0.625199\tAccuracy: 87.05%\n",
      "17\tValidation loss: 0.616054\tBest loss: 0.616054\tAccuracy: 86.33%\n",
      "18\tValidation loss: 0.607585\tBest loss: 0.607585\tAccuracy: 87.05%\n",
      "19\tValidation loss: 0.582940\tBest loss: 0.582940\tAccuracy: 86.33%\n",
      "20\tValidation loss: 0.562026\tBest loss: 0.562026\tAccuracy: 87.77%\n",
      "21\tValidation loss: 0.554894\tBest loss: 0.554894\tAccuracy: 87.05%\n",
      "22\tValidation loss: 0.551552\tBest loss: 0.551552\tAccuracy: 84.89%\n",
      "23\tValidation loss: 0.545419\tBest loss: 0.545419\tAccuracy: 86.33%\n",
      "24\tValidation loss: 0.539017\tBest loss: 0.539017\tAccuracy: 84.89%\n",
      "25\tValidation loss: 0.532388\tBest loss: 0.532388\tAccuracy: 87.05%\n",
      "26\tValidation loss: 0.504632\tBest loss: 0.504632\tAccuracy: 87.77%\n",
      "27\tValidation loss: 0.487125\tBest loss: 0.487125\tAccuracy: 87.77%\n",
      "28\tValidation loss: 0.495113\tBest loss: 0.487125\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.487037\tBest loss: 0.487037\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.464715\tBest loss: 0.464715\tAccuracy: 87.05%\n",
      "31\tValidation loss: 0.473909\tBest loss: 0.464715\tAccuracy: 87.77%\n",
      "32\tValidation loss: 0.472188\tBest loss: 0.464715\tAccuracy: 86.33%\n",
      "33\tValidation loss: 0.443902\tBest loss: 0.443902\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.475710\tBest loss: 0.443902\tAccuracy: 87.05%\n",
      "35\tValidation loss: 0.452412\tBest loss: 0.443902\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.445238\tBest loss: 0.443902\tAccuracy: 89.21%\n",
      "37\tValidation loss: 0.439217\tBest loss: 0.439217\tAccuracy: 89.93%\n",
      "38\tValidation loss: 0.426867\tBest loss: 0.426867\tAccuracy: 89.93%\n",
      "39\tValidation loss: 0.418679\tBest loss: 0.418679\tAccuracy: 89.93%\n",
      "40\tValidation loss: 0.410890\tBest loss: 0.410890\tAccuracy: 90.65%\n",
      "41\tValidation loss: 0.409978\tBest loss: 0.409978\tAccuracy: 87.77%\n",
      "42\tValidation loss: 0.405748\tBest loss: 0.405748\tAccuracy: 89.21%\n",
      "43\tValidation loss: 0.401912\tBest loss: 0.401912\tAccuracy: 89.21%\n",
      "44\tValidation loss: 0.407931\tBest loss: 0.401912\tAccuracy: 89.21%\n",
      "45\tValidation loss: 0.404862\tBest loss: 0.401912\tAccuracy: 89.21%\n",
      "46\tValidation loss: 0.408787\tBest loss: 0.401912\tAccuracy: 87.05%\n",
      "47\tValidation loss: 0.403185\tBest loss: 0.401912\tAccuracy: 89.21%\n",
      "48\tValidation loss: 0.400838\tBest loss: 0.400838\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.398568\tBest loss: 0.398568\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.387184\tBest loss: 0.387184\tAccuracy: 88.49%\n",
      "51\tValidation loss: 0.371914\tBest loss: 0.371914\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.377853\tBest loss: 0.371914\tAccuracy: 89.21%\n",
      "53\tValidation loss: 0.372006\tBest loss: 0.371914\tAccuracy: 88.49%\n",
      "54\tValidation loss: 0.376120\tBest loss: 0.371914\tAccuracy: 87.77%\n",
      "55\tValidation loss: 0.366120\tBest loss: 0.366120\tAccuracy: 89.21%\n",
      "56\tValidation loss: 0.367741\tBest loss: 0.366120\tAccuracy: 89.21%\n",
      "57\tValidation loss: 0.367026\tBest loss: 0.366120\tAccuracy: 89.21%\n",
      "58\tValidation loss: 0.357908\tBest loss: 0.357908\tAccuracy: 89.21%\n",
      "59\tValidation loss: 0.357188\tBest loss: 0.357188\tAccuracy: 89.21%\n",
      "60\tValidation loss: 0.342807\tBest loss: 0.342807\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.341537\tBest loss: 0.341537\tAccuracy: 89.21%\n",
      "62\tValidation loss: 0.346945\tBest loss: 0.341537\tAccuracy: 89.93%\n",
      "63\tValidation loss: 0.342112\tBest loss: 0.341537\tAccuracy: 89.21%\n",
      "64\tValidation loss: 0.347041\tBest loss: 0.341537\tAccuracy: 89.21%\n",
      "65\tValidation loss: 0.337711\tBest loss: 0.337711\tAccuracy: 89.21%\n",
      "66\tValidation loss: 0.338526\tBest loss: 0.337711\tAccuracy: 90.65%\n",
      "67\tValidation loss: 0.334306\tBest loss: 0.334306\tAccuracy: 90.65%\n",
      "68\tValidation loss: 0.329001\tBest loss: 0.329001\tAccuracy: 90.65%\n",
      "69\tValidation loss: 0.334749\tBest loss: 0.329001\tAccuracy: 90.65%\n",
      "70\tValidation loss: 0.331866\tBest loss: 0.329001\tAccuracy: 89.93%\n",
      "71\tValidation loss: 0.325047\tBest loss: 0.325047\tAccuracy: 90.65%\n",
      "72\tValidation loss: 0.316610\tBest loss: 0.316610\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.323730\tBest loss: 0.316610\tAccuracy: 89.93%\n",
      "74\tValidation loss: 0.315581\tBest loss: 0.315581\tAccuracy: 90.65%\n",
      "75\tValidation loss: 0.310359\tBest loss: 0.310359\tAccuracy: 91.37%\n",
      "76\tValidation loss: 0.310939\tBest loss: 0.310359\tAccuracy: 90.65%\n",
      "77\tValidation loss: 0.325940\tBest loss: 0.310359\tAccuracy: 90.65%\n",
      "78\tValidation loss: 0.324382\tBest loss: 0.310359\tAccuracy: 90.65%\n",
      "79\tValidation loss: 0.322499\tBest loss: 0.310359\tAccuracy: 89.93%\n",
      "80\tValidation loss: 0.320015\tBest loss: 0.310359\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.317091\tBest loss: 0.310359\tAccuracy: 90.65%\n",
      "82\tValidation loss: 0.315481\tBest loss: 0.310359\tAccuracy: 89.93%\n",
      "83\tValidation loss: 0.306360\tBest loss: 0.306360\tAccuracy: 90.65%\n",
      "84\tValidation loss: 0.307725\tBest loss: 0.306360\tAccuracy: 90.65%\n",
      "85\tValidation loss: 0.308479\tBest loss: 0.306360\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.302225\tBest loss: 0.302225\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.319149\tBest loss: 0.302225\tAccuracy: 90.65%\n",
      "88\tValidation loss: 0.308158\tBest loss: 0.302225\tAccuracy: 89.93%\n",
      "89\tValidation loss: 0.296038\tBest loss: 0.296038\tAccuracy: 90.65%\n",
      "90\tValidation loss: 0.301813\tBest loss: 0.296038\tAccuracy: 90.65%\n",
      "91\tValidation loss: 0.302376\tBest loss: 0.296038\tAccuracy: 90.65%\n",
      "92\tValidation loss: 0.294219\tBest loss: 0.294219\tAccuracy: 92.09%\n",
      "93\tValidation loss: 0.300311\tBest loss: 0.294219\tAccuracy: 91.37%\n",
      "94\tValidation loss: 0.299851\tBest loss: 0.294219\tAccuracy: 91.37%\n",
      "95\tValidation loss: 0.297790\tBest loss: 0.294219\tAccuracy: 90.65%\n",
      "96\tValidation loss: 0.287283\tBest loss: 0.287283\tAccuracy: 91.37%\n",
      "97\tValidation loss: 0.292222\tBest loss: 0.287283\tAccuracy: 91.37%\n",
      "98\tValidation loss: 0.291011\tBest loss: 0.287283\tAccuracy: 91.37%\n",
      "99\tValidation loss: 0.289746\tBest loss: 0.287283\tAccuracy: 91.37%\n",
      "100\tValidation loss: 0.281514\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "101\tValidation loss: 0.288306\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "102\tValidation loss: 0.300383\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "103\tValidation loss: 0.302450\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "104\tValidation loss: 0.298758\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "105\tValidation loss: 0.292748\tBest loss: 0.281514\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\tValidation loss: 0.296288\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "107\tValidation loss: 0.290453\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "108\tValidation loss: 0.286128\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "109\tValidation loss: 0.296320\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "110\tValidation loss: 0.284392\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "111\tValidation loss: 0.290404\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.290759\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "113\tValidation loss: 0.288047\tBest loss: 0.281514\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.293773\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "115\tValidation loss: 0.285785\tBest loss: 0.281514\tAccuracy: 90.65%\n",
      "116\tValidation loss: 0.275170\tBest loss: 0.275170\tAccuracy: 92.09%\n",
      "117\tValidation loss: 0.282080\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "118\tValidation loss: 0.282246\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "119\tValidation loss: 0.283221\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "120\tValidation loss: 0.285988\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "121\tValidation loss: 0.280327\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "122\tValidation loss: 0.290227\tBest loss: 0.275170\tAccuracy: 89.93%\n",
      "123\tValidation loss: 0.292069\tBest loss: 0.275170\tAccuracy: 90.65%\n",
      "124\tValidation loss: 0.276203\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "125\tValidation loss: 0.282447\tBest loss: 0.275170\tAccuracy: 90.65%\n",
      "126\tValidation loss: 0.279408\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "127\tValidation loss: 0.279081\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "128\tValidation loss: 0.278008\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "129\tValidation loss: 0.288899\tBest loss: 0.275170\tAccuracy: 90.65%\n",
      "130\tValidation loss: 0.281038\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "131\tValidation loss: 0.277783\tBest loss: 0.275170\tAccuracy: 92.09%\n",
      "132\tValidation loss: 0.282078\tBest loss: 0.275170\tAccuracy: 92.09%\n",
      "133\tValidation loss: 0.280971\tBest loss: 0.275170\tAccuracy: 92.09%\n",
      "134\tValidation loss: 0.287799\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "135\tValidation loss: 0.283782\tBest loss: 0.275170\tAccuracy: 90.65%\n",
      "136\tValidation loss: 0.282041\tBest loss: 0.275170\tAccuracy: 90.65%\n",
      "137\tValidation loss: 0.280431\tBest loss: 0.275170\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  16.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 53.285156\tBest loss: 53.285156\tAccuracy: 17.27%\n",
      "1\tValidation loss: 83.499100\tBest loss: 53.285156\tAccuracy: 25.90%\n",
      "2\tValidation loss: 84.606865\tBest loss: 53.285156\tAccuracy: 23.74%\n",
      "3\tValidation loss: 57.590065\tBest loss: 53.285156\tAccuracy: 20.14%\n",
      "4\tValidation loss: 27.011055\tBest loss: 27.011055\tAccuracy: 27.34%\n",
      "5\tValidation loss: 11.273521\tBest loss: 11.273521\tAccuracy: 41.01%\n",
      "6\tValidation loss: 6.208996\tBest loss: 6.208996\tAccuracy: 51.80%\n",
      "7\tValidation loss: 2.005697\tBest loss: 2.005697\tAccuracy: 65.47%\n",
      "8\tValidation loss: 1.238894\tBest loss: 1.238894\tAccuracy: 69.78%\n",
      "9\tValidation loss: 0.963391\tBest loss: 0.963391\tAccuracy: 76.98%\n",
      "10\tValidation loss: 0.886600\tBest loss: 0.886600\tAccuracy: 80.58%\n",
      "11\tValidation loss: 0.760864\tBest loss: 0.760864\tAccuracy: 81.29%\n",
      "12\tValidation loss: 0.763152\tBest loss: 0.760864\tAccuracy: 80.58%\n",
      "13\tValidation loss: 0.703146\tBest loss: 0.703146\tAccuracy: 82.01%\n",
      "14\tValidation loss: 0.690008\tBest loss: 0.690008\tAccuracy: 82.01%\n",
      "15\tValidation loss: 0.694034\tBest loss: 0.690008\tAccuracy: 82.73%\n",
      "16\tValidation loss: 0.673870\tBest loss: 0.673870\tAccuracy: 80.58%\n",
      "17\tValidation loss: 0.637378\tBest loss: 0.637378\tAccuracy: 83.45%\n",
      "18\tValidation loss: 0.640467\tBest loss: 0.637378\tAccuracy: 82.73%\n",
      "19\tValidation loss: 0.628912\tBest loss: 0.628912\tAccuracy: 84.17%\n",
      "20\tValidation loss: 0.625798\tBest loss: 0.625798\tAccuracy: 82.73%\n",
      "21\tValidation loss: 0.607718\tBest loss: 0.607718\tAccuracy: 81.29%\n",
      "22\tValidation loss: 0.587027\tBest loss: 0.587027\tAccuracy: 83.45%\n",
      "23\tValidation loss: 0.574863\tBest loss: 0.574863\tAccuracy: 84.17%\n",
      "24\tValidation loss: 0.563943\tBest loss: 0.563943\tAccuracy: 84.89%\n",
      "25\tValidation loss: 0.559987\tBest loss: 0.559987\tAccuracy: 84.17%\n",
      "26\tValidation loss: 0.535116\tBest loss: 0.535116\tAccuracy: 84.17%\n",
      "27\tValidation loss: 0.536273\tBest loss: 0.535116\tAccuracy: 84.17%\n",
      "28\tValidation loss: 0.522660\tBest loss: 0.522660\tAccuracy: 84.89%\n",
      "29\tValidation loss: 0.511545\tBest loss: 0.511545\tAccuracy: 84.17%\n",
      "30\tValidation loss: 0.551546\tBest loss: 0.511545\tAccuracy: 82.01%\n",
      "31\tValidation loss: 0.508263\tBest loss: 0.508263\tAccuracy: 83.45%\n",
      "32\tValidation loss: 0.494005\tBest loss: 0.494005\tAccuracy: 84.89%\n",
      "33\tValidation loss: 0.482641\tBest loss: 0.482641\tAccuracy: 84.89%\n",
      "34\tValidation loss: 0.481968\tBest loss: 0.481968\tAccuracy: 84.17%\n",
      "35\tValidation loss: 0.487054\tBest loss: 0.481968\tAccuracy: 84.17%\n",
      "36\tValidation loss: 0.476417\tBest loss: 0.476417\tAccuracy: 84.17%\n",
      "37\tValidation loss: 0.465998\tBest loss: 0.465998\tAccuracy: 84.17%\n",
      "38\tValidation loss: 0.469153\tBest loss: 0.465998\tAccuracy: 84.89%\n",
      "39\tValidation loss: 0.471462\tBest loss: 0.465998\tAccuracy: 82.73%\n",
      "40\tValidation loss: 0.470195\tBest loss: 0.465998\tAccuracy: 82.73%\n",
      "41\tValidation loss: 0.452634\tBest loss: 0.452634\tAccuracy: 83.45%\n",
      "42\tValidation loss: 0.453446\tBest loss: 0.452634\tAccuracy: 84.89%\n",
      "43\tValidation loss: 0.443562\tBest loss: 0.443562\tAccuracy: 84.89%\n",
      "44\tValidation loss: 0.435336\tBest loss: 0.435336\tAccuracy: 85.61%\n",
      "45\tValidation loss: 0.433361\tBest loss: 0.433361\tAccuracy: 84.89%\n",
      "46\tValidation loss: 0.422058\tBest loss: 0.422058\tAccuracy: 84.89%\n",
      "47\tValidation loss: 0.423358\tBest loss: 0.422058\tAccuracy: 84.89%\n",
      "48\tValidation loss: 0.419145\tBest loss: 0.419145\tAccuracy: 84.89%\n",
      "49\tValidation loss: 0.417376\tBest loss: 0.417376\tAccuracy: 83.45%\n",
      "50\tValidation loss: 0.414228\tBest loss: 0.414228\tAccuracy: 84.89%\n",
      "51\tValidation loss: 0.407737\tBest loss: 0.407737\tAccuracy: 86.33%\n",
      "52\tValidation loss: 0.399213\tBest loss: 0.399213\tAccuracy: 87.77%\n",
      "53\tValidation loss: 0.393534\tBest loss: 0.393534\tAccuracy: 87.77%\n",
      "54\tValidation loss: 0.394844\tBest loss: 0.393534\tAccuracy: 87.05%\n",
      "55\tValidation loss: 0.379983\tBest loss: 0.379983\tAccuracy: 87.77%\n",
      "56\tValidation loss: 0.381005\tBest loss: 0.379983\tAccuracy: 87.77%\n",
      "57\tValidation loss: 0.373070\tBest loss: 0.373070\tAccuracy: 87.05%\n",
      "58\tValidation loss: 0.371535\tBest loss: 0.371535\tAccuracy: 87.05%\n",
      "59\tValidation loss: 0.369424\tBest loss: 0.369424\tAccuracy: 85.61%\n",
      "60\tValidation loss: 0.377078\tBest loss: 0.369424\tAccuracy: 87.05%\n",
      "61\tValidation loss: 0.356471\tBest loss: 0.356471\tAccuracy: 88.49%\n",
      "62\tValidation loss: 0.358182\tBest loss: 0.356471\tAccuracy: 87.05%\n",
      "63\tValidation loss: 0.364921\tBest loss: 0.356471\tAccuracy: 87.05%\n",
      "64\tValidation loss: 0.370060\tBest loss: 0.356471\tAccuracy: 86.33%\n",
      "65\tValidation loss: 0.361465\tBest loss: 0.356471\tAccuracy: 87.05%\n",
      "66\tValidation loss: 0.368917\tBest loss: 0.356471\tAccuracy: 87.05%\n",
      "67\tValidation loss: 0.357943\tBest loss: 0.356471\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.355422\tBest loss: 0.355422\tAccuracy: 87.77%\n",
      "69\tValidation loss: 0.374382\tBest loss: 0.355422\tAccuracy: 85.61%\n",
      "70\tValidation loss: 0.365074\tBest loss: 0.355422\tAccuracy: 85.61%\n",
      "71\tValidation loss: 0.353376\tBest loss: 0.353376\tAccuracy: 85.61%\n",
      "72\tValidation loss: 0.349611\tBest loss: 0.349611\tAccuracy: 86.33%\n",
      "73\tValidation loss: 0.343988\tBest loss: 0.343988\tAccuracy: 87.77%\n",
      "74\tValidation loss: 0.336732\tBest loss: 0.336732\tAccuracy: 88.49%\n",
      "75\tValidation loss: 0.334125\tBest loss: 0.334125\tAccuracy: 87.77%\n",
      "76\tValidation loss: 0.335282\tBest loss: 0.334125\tAccuracy: 89.21%\n",
      "77\tValidation loss: 0.329374\tBest loss: 0.329374\tAccuracy: 89.21%\n",
      "78\tValidation loss: 0.323420\tBest loss: 0.323420\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.331649\tBest loss: 0.323420\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.331803\tBest loss: 0.323420\tAccuracy: 88.49%\n",
      "81\tValidation loss: 0.325711\tBest loss: 0.323420\tAccuracy: 87.77%\n",
      "82\tValidation loss: 0.326482\tBest loss: 0.323420\tAccuracy: 89.21%\n",
      "83\tValidation loss: 0.315457\tBest loss: 0.315457\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\tValidation loss: 0.313985\tBest loss: 0.313985\tAccuracy: 88.49%\n",
      "85\tValidation loss: 0.311248\tBest loss: 0.311248\tAccuracy: 89.21%\n",
      "86\tValidation loss: 0.304795\tBest loss: 0.304795\tAccuracy: 88.49%\n",
      "87\tValidation loss: 0.305536\tBest loss: 0.304795\tAccuracy: 89.21%\n",
      "88\tValidation loss: 0.301288\tBest loss: 0.301288\tAccuracy: 89.21%\n",
      "89\tValidation loss: 0.302895\tBest loss: 0.301288\tAccuracy: 89.93%\n",
      "90\tValidation loss: 0.298069\tBest loss: 0.298069\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.304214\tBest loss: 0.298069\tAccuracy: 89.21%\n",
      "92\tValidation loss: 0.303022\tBest loss: 0.298069\tAccuracy: 89.93%\n",
      "93\tValidation loss: 0.297498\tBest loss: 0.297498\tAccuracy: 89.93%\n",
      "94\tValidation loss: 0.296163\tBest loss: 0.296163\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.299554\tBest loss: 0.296163\tAccuracy: 89.93%\n",
      "96\tValidation loss: 0.292688\tBest loss: 0.292688\tAccuracy: 89.21%\n",
      "97\tValidation loss: 0.292210\tBest loss: 0.292210\tAccuracy: 89.93%\n",
      "98\tValidation loss: 0.294117\tBest loss: 0.292210\tAccuracy: 89.93%\n",
      "99\tValidation loss: 0.296279\tBest loss: 0.292210\tAccuracy: 89.93%\n",
      "100\tValidation loss: 0.287829\tBest loss: 0.287829\tAccuracy: 89.93%\n",
      "101\tValidation loss: 0.283708\tBest loss: 0.283708\tAccuracy: 90.65%\n",
      "102\tValidation loss: 0.284120\tBest loss: 0.283708\tAccuracy: 90.65%\n",
      "103\tValidation loss: 0.283291\tBest loss: 0.283291\tAccuracy: 89.93%\n",
      "104\tValidation loss: 0.286545\tBest loss: 0.283291\tAccuracy: 90.65%\n",
      "105\tValidation loss: 0.278407\tBest loss: 0.278407\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.280875\tBest loss: 0.278407\tAccuracy: 89.21%\n",
      "107\tValidation loss: 0.281358\tBest loss: 0.278407\tAccuracy: 90.65%\n",
      "108\tValidation loss: 0.278258\tBest loss: 0.278258\tAccuracy: 92.09%\n",
      "109\tValidation loss: 0.282191\tBest loss: 0.278258\tAccuracy: 89.93%\n",
      "110\tValidation loss: 0.281854\tBest loss: 0.278258\tAccuracy: 89.93%\n",
      "111\tValidation loss: 0.283194\tBest loss: 0.278258\tAccuracy: 89.93%\n",
      "112\tValidation loss: 0.275933\tBest loss: 0.275933\tAccuracy: 91.37%\n",
      "113\tValidation loss: 0.277367\tBest loss: 0.275933\tAccuracy: 92.09%\n",
      "114\tValidation loss: 0.276743\tBest loss: 0.275933\tAccuracy: 92.09%\n",
      "115\tValidation loss: 0.270376\tBest loss: 0.270376\tAccuracy: 91.37%\n",
      "116\tValidation loss: 0.271426\tBest loss: 0.270376\tAccuracy: 91.37%\n",
      "117\tValidation loss: 0.279062\tBest loss: 0.270376\tAccuracy: 89.21%\n",
      "118\tValidation loss: 0.274201\tBest loss: 0.270376\tAccuracy: 89.21%\n",
      "119\tValidation loss: 0.273943\tBest loss: 0.270376\tAccuracy: 89.93%\n",
      "120\tValidation loss: 0.269119\tBest loss: 0.269119\tAccuracy: 89.21%\n",
      "121\tValidation loss: 0.271475\tBest loss: 0.269119\tAccuracy: 89.93%\n",
      "122\tValidation loss: 0.278275\tBest loss: 0.269119\tAccuracy: 88.49%\n",
      "123\tValidation loss: 0.278878\tBest loss: 0.269119\tAccuracy: 90.65%\n",
      "124\tValidation loss: 0.277647\tBest loss: 0.269119\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.268404\tBest loss: 0.268404\tAccuracy: 91.37%\n",
      "126\tValidation loss: 0.263898\tBest loss: 0.263898\tAccuracy: 90.65%\n",
      "127\tValidation loss: 0.262895\tBest loss: 0.262895\tAccuracy: 89.93%\n",
      "128\tValidation loss: 0.262401\tBest loss: 0.262401\tAccuracy: 91.37%\n",
      "129\tValidation loss: 0.262796\tBest loss: 0.262401\tAccuracy: 91.37%\n",
      "130\tValidation loss: 0.270411\tBest loss: 0.262401\tAccuracy: 89.93%\n",
      "131\tValidation loss: 0.271560\tBest loss: 0.262401\tAccuracy: 90.65%\n",
      "132\tValidation loss: 0.260553\tBest loss: 0.260553\tAccuracy: 91.37%\n",
      "133\tValidation loss: 0.253478\tBest loss: 0.253478\tAccuracy: 91.37%\n",
      "134\tValidation loss: 0.254188\tBest loss: 0.253478\tAccuracy: 92.09%\n",
      "135\tValidation loss: 0.254456\tBest loss: 0.253478\tAccuracy: 91.37%\n",
      "136\tValidation loss: 0.266983\tBest loss: 0.253478\tAccuracy: 89.93%\n",
      "137\tValidation loss: 0.257587\tBest loss: 0.253478\tAccuracy: 91.37%\n",
      "138\tValidation loss: 0.251756\tBest loss: 0.251756\tAccuracy: 89.93%\n",
      "139\tValidation loss: 0.250813\tBest loss: 0.250813\tAccuracy: 91.37%\n",
      "140\tValidation loss: 0.254165\tBest loss: 0.250813\tAccuracy: 91.37%\n",
      "141\tValidation loss: 0.259052\tBest loss: 0.250813\tAccuracy: 91.37%\n",
      "142\tValidation loss: 0.252663\tBest loss: 0.250813\tAccuracy: 92.81%\n",
      "143\tValidation loss: 0.247558\tBest loss: 0.247558\tAccuracy: 94.24%\n",
      "144\tValidation loss: 0.251667\tBest loss: 0.247558\tAccuracy: 92.81%\n",
      "145\tValidation loss: 0.255290\tBest loss: 0.247558\tAccuracy: 92.81%\n",
      "146\tValidation loss: 0.248476\tBest loss: 0.247558\tAccuracy: 92.09%\n",
      "147\tValidation loss: 0.247223\tBest loss: 0.247223\tAccuracy: 92.09%\n",
      "148\tValidation loss: 0.260559\tBest loss: 0.247223\tAccuracy: 90.65%\n",
      "149\tValidation loss: 0.252909\tBest loss: 0.247223\tAccuracy: 91.37%\n",
      "150\tValidation loss: 0.262642\tBest loss: 0.247223\tAccuracy: 92.09%\n",
      "151\tValidation loss: 0.252399\tBest loss: 0.247223\tAccuracy: 93.53%\n",
      "152\tValidation loss: 0.255799\tBest loss: 0.247223\tAccuracy: 91.37%\n",
      "153\tValidation loss: 0.253062\tBest loss: 0.247223\tAccuracy: 91.37%\n",
      "154\tValidation loss: 0.253867\tBest loss: 0.247223\tAccuracy: 90.65%\n",
      "155\tValidation loss: 0.248033\tBest loss: 0.247223\tAccuracy: 90.65%\n",
      "156\tValidation loss: 0.245095\tBest loss: 0.245095\tAccuracy: 90.65%\n",
      "157\tValidation loss: 0.244373\tBest loss: 0.244373\tAccuracy: 92.81%\n",
      "158\tValidation loss: 0.240873\tBest loss: 0.240873\tAccuracy: 93.53%\n",
      "159\tValidation loss: 0.240632\tBest loss: 0.240632\tAccuracy: 92.81%\n",
      "160\tValidation loss: 0.243030\tBest loss: 0.240632\tAccuracy: 92.09%\n",
      "161\tValidation loss: 0.246360\tBest loss: 0.240632\tAccuracy: 93.53%\n",
      "162\tValidation loss: 0.244533\tBest loss: 0.240632\tAccuracy: 93.53%\n",
      "163\tValidation loss: 0.242388\tBest loss: 0.240632\tAccuracy: 91.37%\n",
      "164\tValidation loss: 0.247932\tBest loss: 0.240632\tAccuracy: 92.09%\n",
      "165\tValidation loss: 0.244713\tBest loss: 0.240632\tAccuracy: 92.09%\n",
      "166\tValidation loss: 0.242427\tBest loss: 0.240632\tAccuracy: 92.09%\n",
      "167\tValidation loss: 0.238341\tBest loss: 0.238341\tAccuracy: 93.53%\n",
      "168\tValidation loss: 0.236814\tBest loss: 0.236814\tAccuracy: 93.53%\n",
      "169\tValidation loss: 0.234266\tBest loss: 0.234266\tAccuracy: 93.53%\n",
      "170\tValidation loss: 0.236469\tBest loss: 0.234266\tAccuracy: 92.81%\n",
      "171\tValidation loss: 0.238401\tBest loss: 0.234266\tAccuracy: 92.09%\n",
      "172\tValidation loss: 0.244022\tBest loss: 0.234266\tAccuracy: 92.09%\n",
      "173\tValidation loss: 0.241384\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "174\tValidation loss: 0.247811\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "175\tValidation loss: 0.246313\tBest loss: 0.234266\tAccuracy: 90.65%\n",
      "176\tValidation loss: 0.246151\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "177\tValidation loss: 0.242724\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "178\tValidation loss: 0.238770\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "179\tValidation loss: 0.234738\tBest loss: 0.234266\tAccuracy: 91.37%\n",
      "180\tValidation loss: 0.231538\tBest loss: 0.231538\tAccuracy: 91.37%\n",
      "181\tValidation loss: 0.235572\tBest loss: 0.231538\tAccuracy: 91.37%\n",
      "182\tValidation loss: 0.229262\tBest loss: 0.229262\tAccuracy: 91.37%\n",
      "183\tValidation loss: 0.227767\tBest loss: 0.227767\tAccuracy: 92.81%\n",
      "184\tValidation loss: 0.238103\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "185\tValidation loss: 0.238440\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "186\tValidation loss: 0.232197\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "187\tValidation loss: 0.230268\tBest loss: 0.227767\tAccuracy: 92.81%\n",
      "188\tValidation loss: 0.236575\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "189\tValidation loss: 0.236341\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "190\tValidation loss: 0.239496\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "191\tValidation loss: 0.239976\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "192\tValidation loss: 0.243023\tBest loss: 0.227767\tAccuracy: 89.93%\n",
      "193\tValidation loss: 0.241248\tBest loss: 0.227767\tAccuracy: 90.65%\n",
      "194\tValidation loss: 0.235355\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "195\tValidation loss: 0.234880\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "196\tValidation loss: 0.231578\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "197\tValidation loss: 0.229392\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "198\tValidation loss: 0.233205\tBest loss: 0.227767\tAccuracy: 92.81%\n",
      "199\tValidation loss: 0.233404\tBest loss: 0.227767\tAccuracy: 92.09%\n",
      "200\tValidation loss: 0.237094\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "201\tValidation loss: 0.233215\tBest loss: 0.227767\tAccuracy: 90.65%\n",
      "202\tValidation loss: 0.233110\tBest loss: 0.227767\tAccuracy: 90.65%\n",
      "203\tValidation loss: 0.233043\tBest loss: 0.227767\tAccuracy: 90.65%\n",
      "204\tValidation loss: 0.230349\tBest loss: 0.227767\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  24.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 51.936264\tBest loss: 51.936264\tAccuracy: 18.71%\n",
      "1\tValidation loss: 82.229286\tBest loss: 51.936264\tAccuracy: 20.14%\n",
      "2\tValidation loss: 85.364822\tBest loss: 51.936264\tAccuracy: 24.46%\n",
      "3\tValidation loss: 72.417191\tBest loss: 51.936264\tAccuracy: 16.55%\n",
      "4\tValidation loss: 33.438477\tBest loss: 33.438477\tAccuracy: 19.42%\n",
      "5\tValidation loss: 14.145321\tBest loss: 14.145321\tAccuracy: 43.17%\n",
      "6\tValidation loss: 5.421160\tBest loss: 5.421160\tAccuracy: 50.36%\n",
      "7\tValidation loss: 2.330715\tBest loss: 2.330715\tAccuracy: 61.15%\n",
      "8\tValidation loss: 1.378894\tBest loss: 1.378894\tAccuracy: 76.26%\n",
      "9\tValidation loss: 0.961275\tBest loss: 0.961275\tAccuracy: 78.42%\n",
      "10\tValidation loss: 0.866168\tBest loss: 0.866168\tAccuracy: 82.01%\n",
      "11\tValidation loss: 0.796477\tBest loss: 0.796477\tAccuracy: 82.01%\n",
      "12\tValidation loss: 0.801004\tBest loss: 0.796477\tAccuracy: 83.45%\n",
      "13\tValidation loss: 0.741341\tBest loss: 0.741341\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.701452\tBest loss: 0.701452\tAccuracy: 83.45%\n",
      "15\tValidation loss: 0.698128\tBest loss: 0.698128\tAccuracy: 83.45%\n",
      "16\tValidation loss: 0.678341\tBest loss: 0.678341\tAccuracy: 82.73%\n",
      "17\tValidation loss: 0.657542\tBest loss: 0.657542\tAccuracy: 86.33%\n",
      "18\tValidation loss: 0.608598\tBest loss: 0.608598\tAccuracy: 86.33%\n",
      "19\tValidation loss: 0.596634\tBest loss: 0.596634\tAccuracy: 86.33%\n",
      "20\tValidation loss: 0.604537\tBest loss: 0.596634\tAccuracy: 86.33%\n",
      "21\tValidation loss: 0.593433\tBest loss: 0.593433\tAccuracy: 87.05%\n",
      "22\tValidation loss: 0.584996\tBest loss: 0.584996\tAccuracy: 87.05%\n",
      "23\tValidation loss: 0.565981\tBest loss: 0.565981\tAccuracy: 87.05%\n",
      "24\tValidation loss: 0.541892\tBest loss: 0.541892\tAccuracy: 87.05%\n",
      "25\tValidation loss: 0.527456\tBest loss: 0.527456\tAccuracy: 87.05%\n",
      "26\tValidation loss: 0.517721\tBest loss: 0.517721\tAccuracy: 87.05%\n",
      "27\tValidation loss: 0.519469\tBest loss: 0.517721\tAccuracy: 87.77%\n",
      "28\tValidation loss: 0.527074\tBest loss: 0.517721\tAccuracy: 85.61%\n",
      "29\tValidation loss: 0.495885\tBest loss: 0.495885\tAccuracy: 87.05%\n",
      "30\tValidation loss: 0.484953\tBest loss: 0.484953\tAccuracy: 86.33%\n",
      "31\tValidation loss: 0.478669\tBest loss: 0.478669\tAccuracy: 85.61%\n",
      "32\tValidation loss: 0.466477\tBest loss: 0.466477\tAccuracy: 86.33%\n",
      "33\tValidation loss: 0.463420\tBest loss: 0.463420\tAccuracy: 87.05%\n",
      "34\tValidation loss: 0.459261\tBest loss: 0.459261\tAccuracy: 87.05%\n",
      "35\tValidation loss: 0.455462\tBest loss: 0.455462\tAccuracy: 87.05%\n",
      "36\tValidation loss: 0.448732\tBest loss: 0.448732\tAccuracy: 87.05%\n",
      "37\tValidation loss: 0.435341\tBest loss: 0.435341\tAccuracy: 87.77%\n",
      "38\tValidation loss: 0.423554\tBest loss: 0.423554\tAccuracy: 87.05%\n",
      "39\tValidation loss: 0.435872\tBest loss: 0.423554\tAccuracy: 87.77%\n",
      "40\tValidation loss: 0.426615\tBest loss: 0.423554\tAccuracy: 87.77%\n",
      "41\tValidation loss: 0.419644\tBest loss: 0.419644\tAccuracy: 87.05%\n",
      "42\tValidation loss: 0.410115\tBest loss: 0.410115\tAccuracy: 87.05%\n",
      "43\tValidation loss: 0.413270\tBest loss: 0.410115\tAccuracy: 87.77%\n",
      "44\tValidation loss: 0.409745\tBest loss: 0.409745\tAccuracy: 87.05%\n",
      "45\tValidation loss: 0.397415\tBest loss: 0.397415\tAccuracy: 87.77%\n",
      "46\tValidation loss: 0.394922\tBest loss: 0.394922\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.384491\tBest loss: 0.384491\tAccuracy: 88.49%\n",
      "48\tValidation loss: 0.391241\tBest loss: 0.384491\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.391117\tBest loss: 0.384491\tAccuracy: 87.77%\n",
      "50\tValidation loss: 0.388005\tBest loss: 0.384491\tAccuracy: 87.77%\n",
      "51\tValidation loss: 0.394314\tBest loss: 0.384491\tAccuracy: 87.77%\n",
      "52\tValidation loss: 0.395271\tBest loss: 0.384491\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.393499\tBest loss: 0.384491\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.390405\tBest loss: 0.384491\tAccuracy: 89.21%\n",
      "55\tValidation loss: 0.396496\tBest loss: 0.384491\tAccuracy: 87.77%\n",
      "56\tValidation loss: 0.379770\tBest loss: 0.379770\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.381151\tBest loss: 0.379770\tAccuracy: 89.21%\n",
      "58\tValidation loss: 0.375854\tBest loss: 0.375854\tAccuracy: 89.21%\n",
      "59\tValidation loss: 0.366114\tBest loss: 0.366114\tAccuracy: 89.21%\n",
      "60\tValidation loss: 0.366086\tBest loss: 0.366086\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.375050\tBest loss: 0.366086\tAccuracy: 89.21%\n",
      "62\tValidation loss: 0.365017\tBest loss: 0.365017\tAccuracy: 88.49%\n",
      "63\tValidation loss: 0.359085\tBest loss: 0.359085\tAccuracy: 88.49%\n",
      "64\tValidation loss: 0.352164\tBest loss: 0.352164\tAccuracy: 88.49%\n",
      "65\tValidation loss: 0.355502\tBest loss: 0.352164\tAccuracy: 89.93%\n",
      "66\tValidation loss: 0.355715\tBest loss: 0.352164\tAccuracy: 89.21%\n",
      "67\tValidation loss: 0.352506\tBest loss: 0.352164\tAccuracy: 89.21%\n",
      "68\tValidation loss: 0.348441\tBest loss: 0.348441\tAccuracy: 89.21%\n",
      "69\tValidation loss: 0.345761\tBest loss: 0.345761\tAccuracy: 89.21%\n",
      "70\tValidation loss: 0.341564\tBest loss: 0.341564\tAccuracy: 89.93%\n",
      "71\tValidation loss: 0.343173\tBest loss: 0.341564\tAccuracy: 89.21%\n",
      "72\tValidation loss: 0.356874\tBest loss: 0.341564\tAccuracy: 89.21%\n",
      "73\tValidation loss: 0.358418\tBest loss: 0.341564\tAccuracy: 89.21%\n",
      "74\tValidation loss: 0.351888\tBest loss: 0.341564\tAccuracy: 89.21%\n",
      "75\tValidation loss: 0.352594\tBest loss: 0.341564\tAccuracy: 88.49%\n",
      "76\tValidation loss: 0.340964\tBest loss: 0.340964\tAccuracy: 88.49%\n",
      "77\tValidation loss: 0.338991\tBest loss: 0.338991\tAccuracy: 88.49%\n",
      "78\tValidation loss: 0.336942\tBest loss: 0.336942\tAccuracy: 89.21%\n",
      "79\tValidation loss: 0.331899\tBest loss: 0.331899\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.328708\tBest loss: 0.328708\tAccuracy: 89.21%\n",
      "81\tValidation loss: 0.331185\tBest loss: 0.328708\tAccuracy: 89.21%\n",
      "82\tValidation loss: 0.325296\tBest loss: 0.325296\tAccuracy: 89.21%\n",
      "83\tValidation loss: 0.330606\tBest loss: 0.325296\tAccuracy: 89.21%\n",
      "84\tValidation loss: 0.327792\tBest loss: 0.325296\tAccuracy: 89.21%\n",
      "85\tValidation loss: 0.331557\tBest loss: 0.325296\tAccuracy: 89.21%\n",
      "86\tValidation loss: 0.324780\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "87\tValidation loss: 0.341679\tBest loss: 0.324780\tAccuracy: 88.49%\n",
      "88\tValidation loss: 0.339883\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "89\tValidation loss: 0.338684\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "90\tValidation loss: 0.335390\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.333643\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "92\tValidation loss: 0.330538\tBest loss: 0.324780\tAccuracy: 89.21%\n",
      "93\tValidation loss: 0.319104\tBest loss: 0.319104\tAccuracy: 89.21%\n",
      "94\tValidation loss: 0.323061\tBest loss: 0.319104\tAccuracy: 89.93%\n",
      "95\tValidation loss: 0.321205\tBest loss: 0.319104\tAccuracy: 89.93%\n",
      "96\tValidation loss: 0.318930\tBest loss: 0.318930\tAccuracy: 89.93%\n",
      "97\tValidation loss: 0.319395\tBest loss: 0.318930\tAccuracy: 89.93%\n",
      "98\tValidation loss: 0.312704\tBest loss: 0.312704\tAccuracy: 89.21%\n",
      "99\tValidation loss: 0.309938\tBest loss: 0.309938\tAccuracy: 89.21%\n",
      "100\tValidation loss: 0.305599\tBest loss: 0.305599\tAccuracy: 89.21%\n",
      "101\tValidation loss: 0.305954\tBest loss: 0.305599\tAccuracy: 89.93%\n",
      "102\tValidation loss: 0.307618\tBest loss: 0.305599\tAccuracy: 91.37%\n",
      "103\tValidation loss: 0.303737\tBest loss: 0.303737\tAccuracy: 90.65%\n",
      "104\tValidation loss: 0.302559\tBest loss: 0.302559\tAccuracy: 91.37%\n",
      "105\tValidation loss: 0.313417\tBest loss: 0.302559\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.312584\tBest loss: 0.302559\tAccuracy: 89.93%\n",
      "107\tValidation loss: 0.311818\tBest loss: 0.302559\tAccuracy: 89.93%\n",
      "108\tValidation loss: 0.307584\tBest loss: 0.302559\tAccuracy: 90.65%\n",
      "109\tValidation loss: 0.316748\tBest loss: 0.302559\tAccuracy: 89.93%\n",
      "110\tValidation loss: 0.308702\tBest loss: 0.302559\tAccuracy: 90.65%\n",
      "111\tValidation loss: 0.304159\tBest loss: 0.302559\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.302032\tBest loss: 0.302032\tAccuracy: 91.37%\n",
      "113\tValidation loss: 0.296689\tBest loss: 0.296689\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.298367\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "115\tValidation loss: 0.302375\tBest loss: 0.296689\tAccuracy: 89.93%\n",
      "116\tValidation loss: 0.306067\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "117\tValidation loss: 0.304821\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "118\tValidation loss: 0.305652\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "119\tValidation loss: 0.303061\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "120\tValidation loss: 0.304008\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.299782\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "122\tValidation loss: 0.302038\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "123\tValidation loss: 0.301034\tBest loss: 0.296689\tAccuracy: 89.93%\n",
      "124\tValidation loss: 0.300082\tBest loss: 0.296689\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.302614\tBest loss: 0.296689\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 0.310109\tBest loss: 0.296689\tAccuracy: 89.93%\n",
      "127\tValidation loss: 0.294437\tBest loss: 0.294437\tAccuracy: 89.93%\n",
      "128\tValidation loss: 0.297011\tBest loss: 0.294437\tAccuracy: 89.93%\n",
      "129\tValidation loss: 0.289031\tBest loss: 0.289031\tAccuracy: 90.65%\n",
      "130\tValidation loss: 0.293863\tBest loss: 0.289031\tAccuracy: 90.65%\n",
      "131\tValidation loss: 0.296478\tBest loss: 0.289031\tAccuracy: 89.93%\n",
      "132\tValidation loss: 0.296273\tBest loss: 0.289031\tAccuracy: 90.65%\n",
      "133\tValidation loss: 0.283476\tBest loss: 0.283476\tAccuracy: 92.09%\n",
      "134\tValidation loss: 0.284008\tBest loss: 0.283476\tAccuracy: 91.37%\n",
      "135\tValidation loss: 0.287599\tBest loss: 0.283476\tAccuracy: 89.93%\n",
      "136\tValidation loss: 0.284034\tBest loss: 0.283476\tAccuracy: 91.37%\n",
      "137\tValidation loss: 0.284305\tBest loss: 0.283476\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.285447\tBest loss: 0.283476\tAccuracy: 90.65%\n",
      "139\tValidation loss: 0.282799\tBest loss: 0.282799\tAccuracy: 90.65%\n",
      "140\tValidation loss: 0.292193\tBest loss: 0.282799\tAccuracy: 90.65%\n",
      "141\tValidation loss: 0.289104\tBest loss: 0.282799\tAccuracy: 90.65%\n",
      "142\tValidation loss: 0.284942\tBest loss: 0.282799\tAccuracy: 90.65%\n",
      "143\tValidation loss: 0.284004\tBest loss: 0.282799\tAccuracy: 90.65%\n",
      "144\tValidation loss: 0.288011\tBest loss: 0.282799\tAccuracy: 91.37%\n",
      "145\tValidation loss: 0.278841\tBest loss: 0.278841\tAccuracy: 91.37%\n",
      "146\tValidation loss: 0.276773\tBest loss: 0.276773\tAccuracy: 91.37%\n",
      "147\tValidation loss: 0.277593\tBest loss: 0.276773\tAccuracy: 91.37%\n",
      "148\tValidation loss: 0.286266\tBest loss: 0.276773\tAccuracy: 90.65%\n",
      "149\tValidation loss: 0.281126\tBest loss: 0.276773\tAccuracy: 90.65%\n",
      "150\tValidation loss: 0.282598\tBest loss: 0.276773\tAccuracy: 90.65%\n",
      "151\tValidation loss: 0.283214\tBest loss: 0.276773\tAccuracy: 90.65%\n",
      "152\tValidation loss: 0.280682\tBest loss: 0.276773\tAccuracy: 91.37%\n",
      "153\tValidation loss: 0.276235\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "154\tValidation loss: 0.279082\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "155\tValidation loss: 0.276857\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "156\tValidation loss: 0.279713\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "157\tValidation loss: 0.280166\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "158\tValidation loss: 0.284655\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "159\tValidation loss: 0.284033\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "160\tValidation loss: 0.283419\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "161\tValidation loss: 0.282387\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "162\tValidation loss: 0.284851\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "163\tValidation loss: 0.282586\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "164\tValidation loss: 0.285768\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "165\tValidation loss: 0.286775\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "166\tValidation loss: 0.285172\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "167\tValidation loss: 0.285891\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "168\tValidation loss: 0.292182\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "169\tValidation loss: 0.287311\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "170\tValidation loss: 0.282208\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "171\tValidation loss: 0.279043\tBest loss: 0.276235\tAccuracy: 91.37%\n",
      "172\tValidation loss: 0.285846\tBest loss: 0.276235\tAccuracy: 90.65%\n",
      "173\tValidation loss: 0.287846\tBest loss: 0.276235\tAccuracy: 90.65%\n",
      "174\tValidation loss: 0.284009\tBest loss: 0.276235\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  21.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 54.573334\tBest loss: 54.573334\tAccuracy: 20.14%\n",
      "1\tValidation loss: 84.825356\tBest loss: 54.573334\tAccuracy: 18.71%\n",
      "2\tValidation loss: 86.336502\tBest loss: 54.573334\tAccuracy: 20.86%\n",
      "3\tValidation loss: 77.770798\tBest loss: 54.573334\tAccuracy: 14.39%\n",
      "4\tValidation loss: 40.845119\tBest loss: 40.845119\tAccuracy: 24.46%\n",
      "5\tValidation loss: 23.472893\tBest loss: 23.472893\tAccuracy: 28.06%\n",
      "6\tValidation loss: 7.606061\tBest loss: 7.606061\tAccuracy: 41.73%\n",
      "7\tValidation loss: 2.438491\tBest loss: 2.438491\tAccuracy: 64.03%\n",
      "8\tValidation loss: 1.531828\tBest loss: 1.531828\tAccuracy: 70.50%\n",
      "9\tValidation loss: 0.936981\tBest loss: 0.936981\tAccuracy: 77.70%\n",
      "10\tValidation loss: 0.819033\tBest loss: 0.819033\tAccuracy: 82.01%\n",
      "11\tValidation loss: 0.771948\tBest loss: 0.771948\tAccuracy: 80.58%\n",
      "12\tValidation loss: 0.727757\tBest loss: 0.727757\tAccuracy: 82.01%\n",
      "13\tValidation loss: 0.677777\tBest loss: 0.677777\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.665560\tBest loss: 0.665560\tAccuracy: 83.45%\n",
      "15\tValidation loss: 0.656470\tBest loss: 0.656470\tAccuracy: 84.17%\n",
      "16\tValidation loss: 0.621769\tBest loss: 0.621769\tAccuracy: 84.89%\n",
      "17\tValidation loss: 0.597086\tBest loss: 0.597086\tAccuracy: 86.33%\n",
      "18\tValidation loss: 0.594262\tBest loss: 0.594262\tAccuracy: 84.17%\n",
      "19\tValidation loss: 0.578927\tBest loss: 0.578927\tAccuracy: 84.17%\n",
      "20\tValidation loss: 0.564980\tBest loss: 0.564980\tAccuracy: 84.89%\n",
      "21\tValidation loss: 0.552088\tBest loss: 0.552088\tAccuracy: 85.61%\n",
      "22\tValidation loss: 0.556024\tBest loss: 0.552088\tAccuracy: 84.17%\n",
      "23\tValidation loss: 0.542129\tBest loss: 0.542129\tAccuracy: 84.89%\n",
      "24\tValidation loss: 0.552199\tBest loss: 0.542129\tAccuracy: 84.17%\n",
      "25\tValidation loss: 0.522302\tBest loss: 0.522302\tAccuracy: 85.61%\n",
      "26\tValidation loss: 0.512731\tBest loss: 0.512731\tAccuracy: 85.61%\n",
      "27\tValidation loss: 0.501214\tBest loss: 0.501214\tAccuracy: 85.61%\n",
      "28\tValidation loss: 0.507765\tBest loss: 0.501214\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.500893\tBest loss: 0.500893\tAccuracy: 85.61%\n",
      "30\tValidation loss: 0.496128\tBest loss: 0.496128\tAccuracy: 85.61%\n",
      "31\tValidation loss: 0.482139\tBest loss: 0.482139\tAccuracy: 86.33%\n",
      "32\tValidation loss: 0.489279\tBest loss: 0.482139\tAccuracy: 85.61%\n",
      "33\tValidation loss: 0.477192\tBest loss: 0.477192\tAccuracy: 85.61%\n",
      "34\tValidation loss: 0.495346\tBest loss: 0.477192\tAccuracy: 84.17%\n",
      "35\tValidation loss: 0.477173\tBest loss: 0.477173\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.468275\tBest loss: 0.468275\tAccuracy: 86.33%\n",
      "37\tValidation loss: 0.456221\tBest loss: 0.456221\tAccuracy: 87.05%\n",
      "38\tValidation loss: 0.447479\tBest loss: 0.447479\tAccuracy: 87.05%\n",
      "39\tValidation loss: 0.442817\tBest loss: 0.442817\tAccuracy: 87.77%\n",
      "40\tValidation loss: 0.431505\tBest loss: 0.431505\tAccuracy: 87.05%\n",
      "41\tValidation loss: 0.434397\tBest loss: 0.431505\tAccuracy: 87.05%\n",
      "42\tValidation loss: 0.432874\tBest loss: 0.431505\tAccuracy: 87.05%\n",
      "43\tValidation loss: 0.440015\tBest loss: 0.431505\tAccuracy: 87.05%\n",
      "44\tValidation loss: 0.437747\tBest loss: 0.431505\tAccuracy: 87.05%\n",
      "45\tValidation loss: 0.428956\tBest loss: 0.428956\tAccuracy: 87.05%\n",
      "46\tValidation loss: 0.427246\tBest loss: 0.427246\tAccuracy: 87.05%\n",
      "47\tValidation loss: 0.421590\tBest loss: 0.421590\tAccuracy: 87.05%\n",
      "48\tValidation loss: 0.425045\tBest loss: 0.421590\tAccuracy: 87.05%\n",
      "49\tValidation loss: 0.421314\tBest loss: 0.421314\tAccuracy: 87.05%\n",
      "50\tValidation loss: 0.419454\tBest loss: 0.419454\tAccuracy: 87.05%\n",
      "51\tValidation loss: 0.402198\tBest loss: 0.402198\tAccuracy: 87.05%\n",
      "52\tValidation loss: 0.419411\tBest loss: 0.402198\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.415538\tBest loss: 0.402198\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.408495\tBest loss: 0.402198\tAccuracy: 87.77%\n",
      "55\tValidation loss: 0.402467\tBest loss: 0.402198\tAccuracy: 87.77%\n",
      "56\tValidation loss: 0.401654\tBest loss: 0.401654\tAccuracy: 87.77%\n",
      "57\tValidation loss: 0.393780\tBest loss: 0.393780\tAccuracy: 87.77%\n",
      "58\tValidation loss: 0.405302\tBest loss: 0.393780\tAccuracy: 87.05%\n",
      "59\tValidation loss: 0.403418\tBest loss: 0.393780\tAccuracy: 87.05%\n",
      "60\tValidation loss: 0.386710\tBest loss: 0.386710\tAccuracy: 87.77%\n",
      "61\tValidation loss: 0.386861\tBest loss: 0.386710\tAccuracy: 87.05%\n",
      "62\tValidation loss: 0.388371\tBest loss: 0.386710\tAccuracy: 87.77%\n",
      "63\tValidation loss: 0.385936\tBest loss: 0.385936\tAccuracy: 87.77%\n",
      "64\tValidation loss: 0.395196\tBest loss: 0.385936\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.387912\tBest loss: 0.385936\tAccuracy: 87.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\tValidation loss: 0.390745\tBest loss: 0.385936\tAccuracy: 87.77%\n",
      "67\tValidation loss: 0.389097\tBest loss: 0.385936\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.379790\tBest loss: 0.379790\tAccuracy: 87.77%\n",
      "69\tValidation loss: 0.381842\tBest loss: 0.379790\tAccuracy: 87.77%\n",
      "70\tValidation loss: 0.379537\tBest loss: 0.379537\tAccuracy: 87.77%\n",
      "71\tValidation loss: 0.378437\tBest loss: 0.378437\tAccuracy: 87.77%\n",
      "72\tValidation loss: 0.391005\tBest loss: 0.378437\tAccuracy: 87.77%\n",
      "73\tValidation loss: 0.384792\tBest loss: 0.378437\tAccuracy: 88.49%\n",
      "74\tValidation loss: 0.367065\tBest loss: 0.367065\tAccuracy: 88.49%\n",
      "75\tValidation loss: 0.357092\tBest loss: 0.357092\tAccuracy: 89.21%\n",
      "76\tValidation loss: 0.363698\tBest loss: 0.357092\tAccuracy: 88.49%\n",
      "77\tValidation loss: 0.374236\tBest loss: 0.357092\tAccuracy: 88.49%\n",
      "78\tValidation loss: 0.364929\tBest loss: 0.357092\tAccuracy: 88.49%\n",
      "79\tValidation loss: 0.355819\tBest loss: 0.355819\tAccuracy: 88.49%\n",
      "80\tValidation loss: 0.363375\tBest loss: 0.355819\tAccuracy: 88.49%\n",
      "81\tValidation loss: 0.360554\tBest loss: 0.355819\tAccuracy: 88.49%\n",
      "82\tValidation loss: 0.360441\tBest loss: 0.355819\tAccuracy: 88.49%\n",
      "83\tValidation loss: 0.352674\tBest loss: 0.352674\tAccuracy: 88.49%\n",
      "84\tValidation loss: 0.354447\tBest loss: 0.352674\tAccuracy: 87.77%\n",
      "85\tValidation loss: 0.349695\tBest loss: 0.349695\tAccuracy: 88.49%\n",
      "86\tValidation loss: 0.348062\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "87\tValidation loss: 0.358987\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "88\tValidation loss: 0.360332\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "89\tValidation loss: 0.352023\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "90\tValidation loss: 0.351048\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "91\tValidation loss: 0.352587\tBest loss: 0.348062\tAccuracy: 88.49%\n",
      "92\tValidation loss: 0.340736\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "93\tValidation loss: 0.350155\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "94\tValidation loss: 0.352038\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "95\tValidation loss: 0.356485\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.348339\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "97\tValidation loss: 0.353749\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "98\tValidation loss: 0.342239\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "99\tValidation loss: 0.342712\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "100\tValidation loss: 0.346393\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "101\tValidation loss: 0.341679\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "102\tValidation loss: 0.347064\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "103\tValidation loss: 0.349330\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "104\tValidation loss: 0.347204\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "105\tValidation loss: 0.353152\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "106\tValidation loss: 0.349298\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "107\tValidation loss: 0.341761\tBest loss: 0.340736\tAccuracy: 88.49%\n",
      "108\tValidation loss: 0.339239\tBest loss: 0.339239\tAccuracy: 88.49%\n",
      "109\tValidation loss: 0.346615\tBest loss: 0.339239\tAccuracy: 88.49%\n",
      "110\tValidation loss: 0.328314\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "111\tValidation loss: 0.328849\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "112\tValidation loss: 0.334927\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "113\tValidation loss: 0.336382\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "114\tValidation loss: 0.335412\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "115\tValidation loss: 0.333889\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "116\tValidation loss: 0.336080\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "117\tValidation loss: 0.338352\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "118\tValidation loss: 0.354359\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "119\tValidation loss: 0.344973\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "120\tValidation loss: 0.340206\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "121\tValidation loss: 0.347263\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "122\tValidation loss: 0.346638\tBest loss: 0.328314\tAccuracy: 88.49%\n",
      "123\tValidation loss: 0.326553\tBest loss: 0.326553\tAccuracy: 88.49%\n",
      "124\tValidation loss: 0.320374\tBest loss: 0.320374\tAccuracy: 89.21%\n",
      "125\tValidation loss: 0.326250\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "126\tValidation loss: 0.325332\tBest loss: 0.320374\tAccuracy: 89.21%\n",
      "127\tValidation loss: 0.321911\tBest loss: 0.320374\tAccuracy: 89.21%\n",
      "128\tValidation loss: 0.331794\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "129\tValidation loss: 0.324239\tBest loss: 0.320374\tAccuracy: 89.21%\n",
      "130\tValidation loss: 0.332647\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "131\tValidation loss: 0.325232\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "132\tValidation loss: 0.325891\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "133\tValidation loss: 0.326873\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "134\tValidation loss: 0.327009\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "135\tValidation loss: 0.330732\tBest loss: 0.320374\tAccuracy: 88.49%\n",
      "136\tValidation loss: 0.326121\tBest loss: 0.320374\tAccuracy: 89.21%\n",
      "137\tValidation loss: 0.320238\tBest loss: 0.320238\tAccuracy: 89.21%\n",
      "138\tValidation loss: 0.314208\tBest loss: 0.314208\tAccuracy: 89.21%\n",
      "139\tValidation loss: 0.322318\tBest loss: 0.314208\tAccuracy: 89.21%\n",
      "140\tValidation loss: 0.324181\tBest loss: 0.314208\tAccuracy: 89.21%\n",
      "141\tValidation loss: 0.327327\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "142\tValidation loss: 0.327694\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "143\tValidation loss: 0.321479\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "144\tValidation loss: 0.326921\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "145\tValidation loss: 0.319354\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "146\tValidation loss: 0.330088\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "147\tValidation loss: 0.320870\tBest loss: 0.314208\tAccuracy: 88.49%\n",
      "148\tValidation loss: 0.313099\tBest loss: 0.313099\tAccuracy: 89.21%\n",
      "149\tValidation loss: 0.316516\tBest loss: 0.313099\tAccuracy: 89.21%\n",
      "150\tValidation loss: 0.317969\tBest loss: 0.313099\tAccuracy: 89.21%\n",
      "151\tValidation loss: 0.312830\tBest loss: 0.312830\tAccuracy: 89.93%\n",
      "152\tValidation loss: 0.314335\tBest loss: 0.312830\tAccuracy: 89.93%\n",
      "153\tValidation loss: 0.316644\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "154\tValidation loss: 0.318954\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "155\tValidation loss: 0.319331\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "156\tValidation loss: 0.328153\tBest loss: 0.312830\tAccuracy: 88.49%\n",
      "157\tValidation loss: 0.326226\tBest loss: 0.312830\tAccuracy: 88.49%\n",
      "158\tValidation loss: 0.318326\tBest loss: 0.312830\tAccuracy: 88.49%\n",
      "159\tValidation loss: 0.321347\tBest loss: 0.312830\tAccuracy: 88.49%\n",
      "160\tValidation loss: 0.322421\tBest loss: 0.312830\tAccuracy: 88.49%\n",
      "161\tValidation loss: 0.321372\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "162\tValidation loss: 0.319441\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "163\tValidation loss: 0.322425\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "164\tValidation loss: 0.320684\tBest loss: 0.312830\tAccuracy: 89.21%\n",
      "165\tValidation loss: 0.315060\tBest loss: 0.312830\tAccuracy: 89.93%\n",
      "166\tValidation loss: 0.317332\tBest loss: 0.312830\tAccuracy: 89.93%\n",
      "167\tValidation loss: 0.313709\tBest loss: 0.312830\tAccuracy: 89.93%\n",
      "168\tValidation loss: 0.312116\tBest loss: 0.312116\tAccuracy: 89.93%\n",
      "169\tValidation loss: 0.314045\tBest loss: 0.312116\tAccuracy: 89.21%\n",
      "170\tValidation loss: 0.313149\tBest loss: 0.312116\tAccuracy: 89.21%\n",
      "171\tValidation loss: 0.309403\tBest loss: 0.309403\tAccuracy: 89.21%\n",
      "172\tValidation loss: 0.304618\tBest loss: 0.304618\tAccuracy: 89.93%\n",
      "173\tValidation loss: 0.300881\tBest loss: 0.300881\tAccuracy: 89.21%\n",
      "174\tValidation loss: 0.296512\tBest loss: 0.296512\tAccuracy: 90.65%\n",
      "175\tValidation loss: 0.304411\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.302067\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "177\tValidation loss: 0.303966\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "178\tValidation loss: 0.300828\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "179\tValidation loss: 0.303273\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "180\tValidation loss: 0.305085\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "181\tValidation loss: 0.304966\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "182\tValidation loss: 0.311740\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "183\tValidation loss: 0.317371\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "184\tValidation loss: 0.312030\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "185\tValidation loss: 0.310630\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "186\tValidation loss: 0.299568\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "187\tValidation loss: 0.298795\tBest loss: 0.296512\tAccuracy: 90.65%\n",
      "188\tValidation loss: 0.306831\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "189\tValidation loss: 0.311054\tBest loss: 0.296512\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\tValidation loss: 0.309747\tBest loss: 0.296512\tAccuracy: 90.65%\n",
      "191\tValidation loss: 0.310902\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "192\tValidation loss: 0.331631\tBest loss: 0.296512\tAccuracy: 89.21%\n",
      "193\tValidation loss: 0.316912\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "194\tValidation loss: 0.318698\tBest loss: 0.296512\tAccuracy: 89.93%\n",
      "195\tValidation loss: 0.311263\tBest loss: 0.296512\tAccuracy: 90.65%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  22.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 52.121109\tBest loss: 52.121109\tAccuracy: 17.99%\n",
      "1\tValidation loss: 85.536758\tBest loss: 52.121109\tAccuracy: 25.90%\n",
      "2\tValidation loss: 82.605095\tBest loss: 52.121109\tAccuracy: 22.30%\n",
      "3\tValidation loss: 58.491501\tBest loss: 52.121109\tAccuracy: 19.42%\n",
      "4\tValidation loss: 27.490952\tBest loss: 27.490952\tAccuracy: 21.58%\n",
      "5\tValidation loss: 15.505988\tBest loss: 15.505988\tAccuracy: 35.25%\n",
      "6\tValidation loss: 7.082354\tBest loss: 7.082354\tAccuracy: 53.24%\n",
      "7\tValidation loss: 2.528422\tBest loss: 2.528422\tAccuracy: 61.87%\n",
      "8\tValidation loss: 1.541750\tBest loss: 1.541750\tAccuracy: 67.63%\n",
      "9\tValidation loss: 1.002531\tBest loss: 1.002531\tAccuracy: 75.54%\n",
      "10\tValidation loss: 0.906154\tBest loss: 0.906154\tAccuracy: 73.38%\n",
      "11\tValidation loss: 0.833033\tBest loss: 0.833033\tAccuracy: 76.26%\n",
      "12\tValidation loss: 0.764534\tBest loss: 0.764534\tAccuracy: 76.98%\n",
      "13\tValidation loss: 0.732623\tBest loss: 0.732623\tAccuracy: 79.86%\n",
      "14\tValidation loss: 0.716314\tBest loss: 0.716314\tAccuracy: 79.14%\n",
      "15\tValidation loss: 0.686027\tBest loss: 0.686027\tAccuracy: 79.86%\n",
      "16\tValidation loss: 0.675726\tBest loss: 0.675726\tAccuracy: 82.01%\n",
      "17\tValidation loss: 0.636765\tBest loss: 0.636765\tAccuracy: 82.01%\n",
      "18\tValidation loss: 0.619103\tBest loss: 0.619103\tAccuracy: 81.29%\n",
      "19\tValidation loss: 0.620672\tBest loss: 0.619103\tAccuracy: 79.86%\n",
      "20\tValidation loss: 0.608035\tBest loss: 0.608035\tAccuracy: 79.86%\n",
      "21\tValidation loss: 0.601202\tBest loss: 0.601202\tAccuracy: 80.58%\n",
      "22\tValidation loss: 0.590855\tBest loss: 0.590855\tAccuracy: 82.73%\n",
      "23\tValidation loss: 0.576208\tBest loss: 0.576208\tAccuracy: 82.01%\n",
      "24\tValidation loss: 0.570014\tBest loss: 0.570014\tAccuracy: 82.01%\n",
      "25\tValidation loss: 0.550048\tBest loss: 0.550048\tAccuracy: 80.58%\n",
      "26\tValidation loss: 0.531388\tBest loss: 0.531388\tAccuracy: 82.73%\n",
      "27\tValidation loss: 0.515168\tBest loss: 0.515168\tAccuracy: 84.89%\n",
      "28\tValidation loss: 0.506879\tBest loss: 0.506879\tAccuracy: 85.61%\n",
      "29\tValidation loss: 0.500797\tBest loss: 0.500797\tAccuracy: 85.61%\n",
      "30\tValidation loss: 0.505580\tBest loss: 0.500797\tAccuracy: 85.61%\n",
      "31\tValidation loss: 0.497254\tBest loss: 0.497254\tAccuracy: 86.33%\n",
      "32\tValidation loss: 0.505813\tBest loss: 0.497254\tAccuracy: 86.33%\n",
      "33\tValidation loss: 0.489969\tBest loss: 0.489969\tAccuracy: 85.61%\n",
      "34\tValidation loss: 0.480553\tBest loss: 0.480553\tAccuracy: 85.61%\n",
      "35\tValidation loss: 0.475032\tBest loss: 0.475032\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.462161\tBest loss: 0.462161\tAccuracy: 84.89%\n",
      "37\tValidation loss: 0.454820\tBest loss: 0.454820\tAccuracy: 85.61%\n",
      "38\tValidation loss: 0.448422\tBest loss: 0.448422\tAccuracy: 85.61%\n",
      "39\tValidation loss: 0.441435\tBest loss: 0.441435\tAccuracy: 85.61%\n",
      "40\tValidation loss: 0.438281\tBest loss: 0.438281\tAccuracy: 85.61%\n",
      "41\tValidation loss: 0.427913\tBest loss: 0.427913\tAccuracy: 86.33%\n",
      "42\tValidation loss: 0.419533\tBest loss: 0.419533\tAccuracy: 86.33%\n",
      "43\tValidation loss: 0.415674\tBest loss: 0.415674\tAccuracy: 85.61%\n",
      "44\tValidation loss: 0.413608\tBest loss: 0.413608\tAccuracy: 85.61%\n",
      "45\tValidation loss: 0.413901\tBest loss: 0.413608\tAccuracy: 84.89%\n",
      "46\tValidation loss: 0.404159\tBest loss: 0.404159\tAccuracy: 84.89%\n",
      "47\tValidation loss: 0.402649\tBest loss: 0.402649\tAccuracy: 84.89%\n",
      "48\tValidation loss: 0.393946\tBest loss: 0.393946\tAccuracy: 85.61%\n",
      "49\tValidation loss: 0.388277\tBest loss: 0.388277\tAccuracy: 87.05%\n",
      "50\tValidation loss: 0.387577\tBest loss: 0.387577\tAccuracy: 87.77%\n",
      "51\tValidation loss: 0.381128\tBest loss: 0.381128\tAccuracy: 87.77%\n",
      "52\tValidation loss: 0.382983\tBest loss: 0.381128\tAccuracy: 89.21%\n",
      "53\tValidation loss: 0.382280\tBest loss: 0.381128\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.371473\tBest loss: 0.371473\tAccuracy: 88.49%\n",
      "55\tValidation loss: 0.372026\tBest loss: 0.371473\tAccuracy: 89.21%\n",
      "56\tValidation loss: 0.371170\tBest loss: 0.371170\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.367389\tBest loss: 0.367389\tAccuracy: 87.77%\n",
      "58\tValidation loss: 0.361541\tBest loss: 0.361541\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.368835\tBest loss: 0.361541\tAccuracy: 86.33%\n",
      "60\tValidation loss: 0.369194\tBest loss: 0.361541\tAccuracy: 87.05%\n",
      "61\tValidation loss: 0.362257\tBest loss: 0.361541\tAccuracy: 87.05%\n",
      "62\tValidation loss: 0.357864\tBest loss: 0.357864\tAccuracy: 87.77%\n",
      "63\tValidation loss: 0.359478\tBest loss: 0.357864\tAccuracy: 87.77%\n",
      "64\tValidation loss: 0.350233\tBest loss: 0.350233\tAccuracy: 88.49%\n",
      "65\tValidation loss: 0.367815\tBest loss: 0.350233\tAccuracy: 86.33%\n",
      "66\tValidation loss: 0.362454\tBest loss: 0.350233\tAccuracy: 89.93%\n",
      "67\tValidation loss: 0.351274\tBest loss: 0.350233\tAccuracy: 89.21%\n",
      "68\tValidation loss: 0.352083\tBest loss: 0.350233\tAccuracy: 89.21%\n",
      "69\tValidation loss: 0.354643\tBest loss: 0.350233\tAccuracy: 89.93%\n",
      "70\tValidation loss: 0.351218\tBest loss: 0.350233\tAccuracy: 89.21%\n",
      "71\tValidation loss: 0.353462\tBest loss: 0.350233\tAccuracy: 89.93%\n",
      "72\tValidation loss: 0.356265\tBest loss: 0.350233\tAccuracy: 88.49%\n",
      "73\tValidation loss: 0.349491\tBest loss: 0.349491\tAccuracy: 89.93%\n",
      "74\tValidation loss: 0.347779\tBest loss: 0.347779\tAccuracy: 89.21%\n",
      "75\tValidation loss: 0.341068\tBest loss: 0.341068\tAccuracy: 89.21%\n",
      "76\tValidation loss: 0.341012\tBest loss: 0.341012\tAccuracy: 88.49%\n",
      "77\tValidation loss: 0.336833\tBest loss: 0.336833\tAccuracy: 88.49%\n",
      "78\tValidation loss: 0.337122\tBest loss: 0.336833\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.335149\tBest loss: 0.335149\tAccuracy: 89.21%\n",
      "80\tValidation loss: 0.332402\tBest loss: 0.332402\tAccuracy: 87.77%\n",
      "81\tValidation loss: 0.327646\tBest loss: 0.327646\tAccuracy: 89.21%\n",
      "82\tValidation loss: 0.331023\tBest loss: 0.327646\tAccuracy: 89.93%\n",
      "83\tValidation loss: 0.331364\tBest loss: 0.327646\tAccuracy: 89.93%\n",
      "84\tValidation loss: 0.331088\tBest loss: 0.327646\tAccuracy: 89.21%\n",
      "85\tValidation loss: 0.330626\tBest loss: 0.327646\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.325911\tBest loss: 0.325911\tAccuracy: 89.93%\n",
      "87\tValidation loss: 0.326232\tBest loss: 0.325911\tAccuracy: 89.21%\n",
      "88\tValidation loss: 0.329154\tBest loss: 0.325911\tAccuracy: 88.49%\n",
      "89\tValidation loss: 0.319502\tBest loss: 0.319502\tAccuracy: 89.21%\n",
      "90\tValidation loss: 0.316258\tBest loss: 0.316258\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.317064\tBest loss: 0.316258\tAccuracy: 90.65%\n",
      "92\tValidation loss: 0.304533\tBest loss: 0.304533\tAccuracy: 89.93%\n",
      "93\tValidation loss: 0.311100\tBest loss: 0.304533\tAccuracy: 89.21%\n",
      "94\tValidation loss: 0.308928\tBest loss: 0.304533\tAccuracy: 89.21%\n",
      "95\tValidation loss: 0.309306\tBest loss: 0.304533\tAccuracy: 89.21%\n",
      "96\tValidation loss: 0.307750\tBest loss: 0.304533\tAccuracy: 89.21%\n",
      "97\tValidation loss: 0.301213\tBest loss: 0.301213\tAccuracy: 89.93%\n",
      "98\tValidation loss: 0.315946\tBest loss: 0.301213\tAccuracy: 89.21%\n",
      "99\tValidation loss: 0.314485\tBest loss: 0.301213\tAccuracy: 89.21%\n",
      "100\tValidation loss: 0.310639\tBest loss: 0.301213\tAccuracy: 89.93%\n",
      "101\tValidation loss: 0.314056\tBest loss: 0.301213\tAccuracy: 89.21%\n",
      "102\tValidation loss: 0.313396\tBest loss: 0.301213\tAccuracy: 89.21%\n",
      "103\tValidation loss: 0.304604\tBest loss: 0.301213\tAccuracy: 88.49%\n",
      "104\tValidation loss: 0.293033\tBest loss: 0.293033\tAccuracy: 89.93%\n",
      "105\tValidation loss: 0.290370\tBest loss: 0.290370\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.290053\tBest loss: 0.290053\tAccuracy: 89.93%\n",
      "107\tValidation loss: 0.293500\tBest loss: 0.290053\tAccuracy: 89.93%\n",
      "108\tValidation loss: 0.289918\tBest loss: 0.289918\tAccuracy: 89.93%\n",
      "109\tValidation loss: 0.292468\tBest loss: 0.289918\tAccuracy: 90.65%\n",
      "110\tValidation loss: 0.294824\tBest loss: 0.289918\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\tValidation loss: 0.296616\tBest loss: 0.289918\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.298226\tBest loss: 0.289918\tAccuracy: 90.65%\n",
      "113\tValidation loss: 0.297091\tBest loss: 0.289918\tAccuracy: 90.65%\n",
      "114\tValidation loss: 0.287528\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "115\tValidation loss: 0.291582\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "116\tValidation loss: 0.289135\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "117\tValidation loss: 0.288796\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "118\tValidation loss: 0.288497\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "119\tValidation loss: 0.289177\tBest loss: 0.287528\tAccuracy: 89.93%\n",
      "120\tValidation loss: 0.287338\tBest loss: 0.287338\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.289910\tBest loss: 0.287338\tAccuracy: 90.65%\n",
      "122\tValidation loss: 0.301796\tBest loss: 0.287338\tAccuracy: 89.93%\n",
      "123\tValidation loss: 0.303556\tBest loss: 0.287338\tAccuracy: 89.93%\n",
      "124\tValidation loss: 0.300420\tBest loss: 0.287338\tAccuracy: 89.21%\n",
      "125\tValidation loss: 0.298287\tBest loss: 0.287338\tAccuracy: 89.21%\n",
      "126\tValidation loss: 0.291774\tBest loss: 0.287338\tAccuracy: 89.21%\n",
      "127\tValidation loss: 0.288908\tBest loss: 0.287338\tAccuracy: 89.21%\n",
      "128\tValidation loss: 0.295684\tBest loss: 0.287338\tAccuracy: 89.93%\n",
      "129\tValidation loss: 0.288979\tBest loss: 0.287338\tAccuracy: 89.93%\n",
      "130\tValidation loss: 0.277518\tBest loss: 0.277518\tAccuracy: 89.21%\n",
      "131\tValidation loss: 0.275262\tBest loss: 0.275262\tAccuracy: 89.93%\n",
      "132\tValidation loss: 0.276545\tBest loss: 0.275262\tAccuracy: 89.93%\n",
      "133\tValidation loss: 0.276095\tBest loss: 0.275262\tAccuracy: 90.65%\n",
      "134\tValidation loss: 0.276945\tBest loss: 0.275262\tAccuracy: 90.65%\n",
      "135\tValidation loss: 0.282677\tBest loss: 0.275262\tAccuracy: 89.93%\n",
      "136\tValidation loss: 0.287493\tBest loss: 0.275262\tAccuracy: 90.65%\n",
      "137\tValidation loss: 0.275063\tBest loss: 0.275063\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.274209\tBest loss: 0.274209\tAccuracy: 90.65%\n",
      "139\tValidation loss: 0.269650\tBest loss: 0.269650\tAccuracy: 90.65%\n",
      "140\tValidation loss: 0.275550\tBest loss: 0.269650\tAccuracy: 90.65%\n",
      "141\tValidation loss: 0.274730\tBest loss: 0.269650\tAccuracy: 90.65%\n",
      "142\tValidation loss: 0.277830\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "143\tValidation loss: 0.279228\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "144\tValidation loss: 0.275682\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "145\tValidation loss: 0.276072\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "146\tValidation loss: 0.281845\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "147\tValidation loss: 0.280517\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "148\tValidation loss: 0.279195\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "149\tValidation loss: 0.274384\tBest loss: 0.269650\tAccuracy: 89.21%\n",
      "150\tValidation loss: 0.281188\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "151\tValidation loss: 0.274979\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "152\tValidation loss: 0.273820\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "153\tValidation loss: 0.280967\tBest loss: 0.269650\tAccuracy: 88.49%\n",
      "154\tValidation loss: 0.281777\tBest loss: 0.269650\tAccuracy: 89.21%\n",
      "155\tValidation loss: 0.280227\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "156\tValidation loss: 0.276190\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "157\tValidation loss: 0.274324\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "158\tValidation loss: 0.273068\tBest loss: 0.269650\tAccuracy: 89.93%\n",
      "159\tValidation loss: 0.267110\tBest loss: 0.267110\tAccuracy: 89.21%\n",
      "160\tValidation loss: 0.269632\tBest loss: 0.267110\tAccuracy: 89.93%\n",
      "161\tValidation loss: 0.264004\tBest loss: 0.264004\tAccuracy: 89.93%\n",
      "162\tValidation loss: 0.258498\tBest loss: 0.258498\tAccuracy: 89.93%\n",
      "163\tValidation loss: 0.258986\tBest loss: 0.258498\tAccuracy: 89.21%\n",
      "164\tValidation loss: 0.262377\tBest loss: 0.258498\tAccuracy: 89.21%\n",
      "165\tValidation loss: 0.264123\tBest loss: 0.258498\tAccuracy: 89.21%\n",
      "166\tValidation loss: 0.257936\tBest loss: 0.257936\tAccuracy: 89.21%\n",
      "167\tValidation loss: 0.259341\tBest loss: 0.257936\tAccuracy: 89.21%\n",
      "168\tValidation loss: 0.257934\tBest loss: 0.257934\tAccuracy: 90.65%\n",
      "169\tValidation loss: 0.260384\tBest loss: 0.257934\tAccuracy: 89.93%\n",
      "170\tValidation loss: 0.261266\tBest loss: 0.257934\tAccuracy: 89.93%\n",
      "171\tValidation loss: 0.259337\tBest loss: 0.257934\tAccuracy: 89.93%\n",
      "172\tValidation loss: 0.259033\tBest loss: 0.257934\tAccuracy: 89.93%\n",
      "173\tValidation loss: 0.257317\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "174\tValidation loss: 0.267031\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "175\tValidation loss: 0.264792\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.257739\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "177\tValidation loss: 0.261501\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "178\tValidation loss: 0.261434\tBest loss: 0.257317\tAccuracy: 89.93%\n",
      "179\tValidation loss: 0.263970\tBest loss: 0.257317\tAccuracy: 89.21%\n",
      "180\tValidation loss: 0.253488\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "181\tValidation loss: 0.256680\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "182\tValidation loss: 0.261535\tBest loss: 0.253488\tAccuracy: 89.93%\n",
      "183\tValidation loss: 0.260231\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "184\tValidation loss: 0.268193\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "185\tValidation loss: 0.259715\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "186\tValidation loss: 0.258818\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "187\tValidation loss: 0.260532\tBest loss: 0.253488\tAccuracy: 89.93%\n",
      "188\tValidation loss: 0.263950\tBest loss: 0.253488\tAccuracy: 90.65%\n",
      "189\tValidation loss: 0.261341\tBest loss: 0.253488\tAccuracy: 89.93%\n",
      "190\tValidation loss: 0.259658\tBest loss: 0.253488\tAccuracy: 89.21%\n",
      "191\tValidation loss: 0.256446\tBest loss: 0.253488\tAccuracy: 89.21%\n",
      "192\tValidation loss: 0.259833\tBest loss: 0.253488\tAccuracy: 89.21%\n",
      "193\tValidation loss: 0.255463\tBest loss: 0.253488\tAccuracy: 89.93%\n",
      "194\tValidation loss: 0.254024\tBest loss: 0.253488\tAccuracy: 89.93%\n",
      "195\tValidation loss: 0.248459\tBest loss: 0.248459\tAccuracy: 90.65%\n",
      "196\tValidation loss: 0.247839\tBest loss: 0.247839\tAccuracy: 90.65%\n",
      "197\tValidation loss: 0.245068\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "198\tValidation loss: 0.249184\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "199\tValidation loss: 0.251429\tBest loss: 0.245068\tAccuracy: 91.37%\n",
      "200\tValidation loss: 0.250367\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "201\tValidation loss: 0.250836\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "202\tValidation loss: 0.259800\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "203\tValidation loss: 0.252476\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "204\tValidation loss: 0.251696\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "205\tValidation loss: 0.248906\tBest loss: 0.245068\tAccuracy: 91.37%\n",
      "206\tValidation loss: 0.253085\tBest loss: 0.245068\tAccuracy: 91.37%\n",
      "207\tValidation loss: 0.263724\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "208\tValidation loss: 0.260357\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "209\tValidation loss: 0.261329\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "210\tValidation loss: 0.252929\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "211\tValidation loss: 0.254363\tBest loss: 0.245068\tAccuracy: 89.93%\n",
      "212\tValidation loss: 0.253855\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "213\tValidation loss: 0.249683\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "214\tValidation loss: 0.250154\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "215\tValidation loss: 0.250871\tBest loss: 0.245068\tAccuracy: 90.65%\n",
      "216\tValidation loss: 0.248655\tBest loss: 0.245068\tAccuracy: 91.37%\n",
      "217\tValidation loss: 0.248386\tBest loss: 0.245068\tAccuracy: 91.37%\n",
      "218\tValidation loss: 0.246185\tBest loss: 0.245068\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  25.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 50.005684\tBest loss: 50.005684\tAccuracy: 19.42%\n",
      "1\tValidation loss: 89.494492\tBest loss: 50.005684\tAccuracy: 21.58%\n",
      "2\tValidation loss: 85.657661\tBest loss: 50.005684\tAccuracy: 29.50%\n",
      "3\tValidation loss: 57.222881\tBest loss: 50.005684\tAccuracy: 16.55%\n",
      "4\tValidation loss: 24.133434\tBest loss: 24.133434\tAccuracy: 26.62%\n",
      "5\tValidation loss: 11.850414\tBest loss: 11.850414\tAccuracy: 41.01%\n",
      "6\tValidation loss: 4.988533\tBest loss: 4.988533\tAccuracy: 47.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\tValidation loss: 1.934641\tBest loss: 1.934641\tAccuracy: 68.35%\n",
      "8\tValidation loss: 1.209337\tBest loss: 1.209337\tAccuracy: 74.82%\n",
      "9\tValidation loss: 0.953341\tBest loss: 0.953341\tAccuracy: 76.26%\n",
      "10\tValidation loss: 0.834205\tBest loss: 0.834205\tAccuracy: 79.14%\n",
      "11\tValidation loss: 0.757625\tBest loss: 0.757625\tAccuracy: 83.45%\n",
      "12\tValidation loss: 0.754784\tBest loss: 0.754784\tAccuracy: 82.73%\n",
      "13\tValidation loss: 0.714299\tBest loss: 0.714299\tAccuracy: 82.01%\n",
      "14\tValidation loss: 0.683868\tBest loss: 0.683868\tAccuracy: 82.73%\n",
      "15\tValidation loss: 0.645115\tBest loss: 0.645115\tAccuracy: 83.45%\n",
      "16\tValidation loss: 0.638161\tBest loss: 0.638161\tAccuracy: 84.17%\n",
      "17\tValidation loss: 0.608741\tBest loss: 0.608741\tAccuracy: 84.17%\n",
      "18\tValidation loss: 0.603653\tBest loss: 0.603653\tAccuracy: 84.17%\n",
      "19\tValidation loss: 0.585586\tBest loss: 0.585586\tAccuracy: 84.17%\n",
      "20\tValidation loss: 0.567185\tBest loss: 0.567185\tAccuracy: 84.89%\n",
      "21\tValidation loss: 0.552966\tBest loss: 0.552966\tAccuracy: 84.89%\n",
      "22\tValidation loss: 0.548253\tBest loss: 0.548253\tAccuracy: 84.17%\n",
      "23\tValidation loss: 0.531448\tBest loss: 0.531448\tAccuracy: 84.89%\n",
      "24\tValidation loss: 0.522291\tBest loss: 0.522291\tAccuracy: 85.61%\n",
      "25\tValidation loss: 0.505263\tBest loss: 0.505263\tAccuracy: 85.61%\n",
      "26\tValidation loss: 0.500055\tBest loss: 0.500055\tAccuracy: 84.89%\n",
      "27\tValidation loss: 0.485698\tBest loss: 0.485698\tAccuracy: 85.61%\n",
      "28\tValidation loss: 0.478439\tBest loss: 0.478439\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.469691\tBest loss: 0.469691\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.471388\tBest loss: 0.469691\tAccuracy: 84.89%\n",
      "31\tValidation loss: 0.481422\tBest loss: 0.469691\tAccuracy: 86.33%\n",
      "32\tValidation loss: 0.463679\tBest loss: 0.463679\tAccuracy: 87.05%\n",
      "33\tValidation loss: 0.452935\tBest loss: 0.452935\tAccuracy: 86.33%\n",
      "34\tValidation loss: 0.446036\tBest loss: 0.446036\tAccuracy: 87.77%\n",
      "35\tValidation loss: 0.456643\tBest loss: 0.446036\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.440221\tBest loss: 0.440221\tAccuracy: 86.33%\n",
      "37\tValidation loss: 0.433839\tBest loss: 0.433839\tAccuracy: 87.77%\n",
      "38\tValidation loss: 0.421430\tBest loss: 0.421430\tAccuracy: 87.05%\n",
      "39\tValidation loss: 0.424107\tBest loss: 0.421430\tAccuracy: 87.05%\n",
      "40\tValidation loss: 0.420981\tBest loss: 0.420981\tAccuracy: 87.05%\n",
      "41\tValidation loss: 0.418041\tBest loss: 0.418041\tAccuracy: 87.05%\n",
      "42\tValidation loss: 0.413397\tBest loss: 0.413397\tAccuracy: 87.05%\n",
      "43\tValidation loss: 0.413798\tBest loss: 0.413397\tAccuracy: 87.05%\n",
      "44\tValidation loss: 0.408933\tBest loss: 0.408933\tAccuracy: 87.05%\n",
      "45\tValidation loss: 0.401868\tBest loss: 0.401868\tAccuracy: 87.05%\n",
      "46\tValidation loss: 0.406550\tBest loss: 0.401868\tAccuracy: 87.05%\n",
      "47\tValidation loss: 0.402002\tBest loss: 0.401868\tAccuracy: 87.05%\n",
      "48\tValidation loss: 0.401499\tBest loss: 0.401499\tAccuracy: 87.05%\n",
      "49\tValidation loss: 0.401884\tBest loss: 0.401499\tAccuracy: 87.05%\n",
      "50\tValidation loss: 0.399469\tBest loss: 0.399469\tAccuracy: 87.05%\n",
      "51\tValidation loss: 0.403132\tBest loss: 0.399469\tAccuracy: 87.05%\n",
      "52\tValidation loss: 0.402300\tBest loss: 0.399469\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.394136\tBest loss: 0.394136\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.389993\tBest loss: 0.389993\tAccuracy: 87.05%\n",
      "55\tValidation loss: 0.400851\tBest loss: 0.389993\tAccuracy: 86.33%\n",
      "56\tValidation loss: 0.394372\tBest loss: 0.389993\tAccuracy: 86.33%\n",
      "57\tValidation loss: 0.386308\tBest loss: 0.386308\tAccuracy: 86.33%\n",
      "58\tValidation loss: 0.379713\tBest loss: 0.379713\tAccuracy: 87.77%\n",
      "59\tValidation loss: 0.369129\tBest loss: 0.369129\tAccuracy: 87.05%\n",
      "60\tValidation loss: 0.376378\tBest loss: 0.369129\tAccuracy: 87.77%\n",
      "61\tValidation loss: 0.376919\tBest loss: 0.369129\tAccuracy: 87.05%\n",
      "62\tValidation loss: 0.374572\tBest loss: 0.369129\tAccuracy: 87.77%\n",
      "63\tValidation loss: 0.367222\tBest loss: 0.367222\tAccuracy: 87.77%\n",
      "64\tValidation loss: 0.365899\tBest loss: 0.365899\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.364679\tBest loss: 0.364679\tAccuracy: 87.77%\n",
      "66\tValidation loss: 0.362638\tBest loss: 0.362638\tAccuracy: 87.77%\n",
      "67\tValidation loss: 0.359561\tBest loss: 0.359561\tAccuracy: 88.49%\n",
      "68\tValidation loss: 0.355980\tBest loss: 0.355980\tAccuracy: 88.49%\n",
      "69\tValidation loss: 0.355896\tBest loss: 0.355896\tAccuracy: 88.49%\n",
      "70\tValidation loss: 0.352524\tBest loss: 0.352524\tAccuracy: 88.49%\n",
      "71\tValidation loss: 0.359231\tBest loss: 0.352524\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.361168\tBest loss: 0.352524\tAccuracy: 88.49%\n",
      "73\tValidation loss: 0.364434\tBest loss: 0.352524\tAccuracy: 87.77%\n",
      "74\tValidation loss: 0.345016\tBest loss: 0.345016\tAccuracy: 87.77%\n",
      "75\tValidation loss: 0.343496\tBest loss: 0.343496\tAccuracy: 87.77%\n",
      "76\tValidation loss: 0.339683\tBest loss: 0.339683\tAccuracy: 88.49%\n",
      "77\tValidation loss: 0.339830\tBest loss: 0.339683\tAccuracy: 88.49%\n",
      "78\tValidation loss: 0.338768\tBest loss: 0.338768\tAccuracy: 88.49%\n",
      "79\tValidation loss: 0.341445\tBest loss: 0.338768\tAccuracy: 87.77%\n",
      "80\tValidation loss: 0.341444\tBest loss: 0.338768\tAccuracy: 88.49%\n",
      "81\tValidation loss: 0.337943\tBest loss: 0.337943\tAccuracy: 89.21%\n",
      "82\tValidation loss: 0.338849\tBest loss: 0.337943\tAccuracy: 89.21%\n",
      "83\tValidation loss: 0.340964\tBest loss: 0.337943\tAccuracy: 89.21%\n",
      "84\tValidation loss: 0.337334\tBest loss: 0.337334\tAccuracy: 88.49%\n",
      "85\tValidation loss: 0.332824\tBest loss: 0.332824\tAccuracy: 88.49%\n",
      "86\tValidation loss: 0.333687\tBest loss: 0.332824\tAccuracy: 88.49%\n",
      "87\tValidation loss: 0.332302\tBest loss: 0.332302\tAccuracy: 89.21%\n",
      "88\tValidation loss: 0.330139\tBest loss: 0.330139\tAccuracy: 89.21%\n",
      "89\tValidation loss: 0.332690\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "90\tValidation loss: 0.332308\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "91\tValidation loss: 0.332780\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "92\tValidation loss: 0.335329\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "93\tValidation loss: 0.331778\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "94\tValidation loss: 0.331348\tBest loss: 0.330139\tAccuracy: 88.49%\n",
      "95\tValidation loss: 0.329574\tBest loss: 0.329574\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.326356\tBest loss: 0.326356\tAccuracy: 89.21%\n",
      "97\tValidation loss: 0.328379\tBest loss: 0.326356\tAccuracy: 88.49%\n",
      "98\tValidation loss: 0.319588\tBest loss: 0.319588\tAccuracy: 89.21%\n",
      "99\tValidation loss: 0.321090\tBest loss: 0.319588\tAccuracy: 88.49%\n",
      "100\tValidation loss: 0.324237\tBest loss: 0.319588\tAccuracy: 89.21%\n",
      "101\tValidation loss: 0.325382\tBest loss: 0.319588\tAccuracy: 88.49%\n",
      "102\tValidation loss: 0.319509\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "103\tValidation loss: 0.330871\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "104\tValidation loss: 0.330060\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "105\tValidation loss: 0.332916\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "106\tValidation loss: 0.331622\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "107\tValidation loss: 0.329717\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "108\tValidation loss: 0.324392\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "109\tValidation loss: 0.331997\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "110\tValidation loss: 0.322207\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "111\tValidation loss: 0.321984\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "112\tValidation loss: 0.323091\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "113\tValidation loss: 0.323486\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "114\tValidation loss: 0.324190\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "115\tValidation loss: 0.327548\tBest loss: 0.319509\tAccuracy: 88.49%\n",
      "116\tValidation loss: 0.324852\tBest loss: 0.319509\tAccuracy: 89.21%\n",
      "117\tValidation loss: 0.315325\tBest loss: 0.315325\tAccuracy: 89.93%\n",
      "118\tValidation loss: 0.316600\tBest loss: 0.315325\tAccuracy: 89.93%\n",
      "119\tValidation loss: 0.312718\tBest loss: 0.312718\tAccuracy: 89.93%\n",
      "120\tValidation loss: 0.314767\tBest loss: 0.312718\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.307148\tBest loss: 0.307148\tAccuracy: 90.65%\n",
      "122\tValidation loss: 0.305740\tBest loss: 0.305740\tAccuracy: 90.65%\n",
      "123\tValidation loss: 0.312480\tBest loss: 0.305740\tAccuracy: 90.65%\n",
      "124\tValidation loss: 0.312324\tBest loss: 0.305740\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.312150\tBest loss: 0.305740\tAccuracy: 89.93%\n",
      "126\tValidation loss: 0.307594\tBest loss: 0.305740\tAccuracy: 89.93%\n",
      "127\tValidation loss: 0.306363\tBest loss: 0.305740\tAccuracy: 90.65%\n",
      "128\tValidation loss: 0.308152\tBest loss: 0.305740\tAccuracy: 90.65%\n",
      "129\tValidation loss: 0.305852\tBest loss: 0.305740\tAccuracy: 89.93%\n",
      "130\tValidation loss: 0.302433\tBest loss: 0.302433\tAccuracy: 90.65%\n",
      "131\tValidation loss: 0.303819\tBest loss: 0.302433\tAccuracy: 90.65%\n",
      "132\tValidation loss: 0.304214\tBest loss: 0.302433\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\tValidation loss: 0.303116\tBest loss: 0.302433\tAccuracy: 90.65%\n",
      "134\tValidation loss: 0.300123\tBest loss: 0.300123\tAccuracy: 90.65%\n",
      "135\tValidation loss: 0.300268\tBest loss: 0.300123\tAccuracy: 90.65%\n",
      "136\tValidation loss: 0.297552\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "137\tValidation loss: 0.298945\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.300668\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "139\tValidation loss: 0.300655\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "140\tValidation loss: 0.300055\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "141\tValidation loss: 0.302148\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "142\tValidation loss: 0.298630\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "143\tValidation loss: 0.300178\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "144\tValidation loss: 0.299171\tBest loss: 0.297552\tAccuracy: 90.65%\n",
      "145\tValidation loss: 0.288286\tBest loss: 0.288286\tAccuracy: 90.65%\n",
      "146\tValidation loss: 0.287871\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "147\tValidation loss: 0.297306\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "148\tValidation loss: 0.303527\tBest loss: 0.287871\tAccuracy: 89.93%\n",
      "149\tValidation loss: 0.297172\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "150\tValidation loss: 0.290873\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "151\tValidation loss: 0.289328\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "152\tValidation loss: 0.290447\tBest loss: 0.287871\tAccuracy: 90.65%\n",
      "153\tValidation loss: 0.286498\tBest loss: 0.286498\tAccuracy: 90.65%\n",
      "154\tValidation loss: 0.290726\tBest loss: 0.286498\tAccuracy: 90.65%\n",
      "155\tValidation loss: 0.286452\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "156\tValidation loss: 0.288832\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "157\tValidation loss: 0.299154\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "158\tValidation loss: 0.296952\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "159\tValidation loss: 0.300974\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "160\tValidation loss: 0.301772\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "161\tValidation loss: 0.302407\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "162\tValidation loss: 0.298416\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "163\tValidation loss: 0.300294\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "164\tValidation loss: 0.300217\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "165\tValidation loss: 0.299933\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "166\tValidation loss: 0.303574\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "167\tValidation loss: 0.302216\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "168\tValidation loss: 0.305544\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "169\tValidation loss: 0.300302\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "170\tValidation loss: 0.302819\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "171\tValidation loss: 0.298885\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "172\tValidation loss: 0.300489\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "173\tValidation loss: 0.306395\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "174\tValidation loss: 0.302850\tBest loss: 0.286452\tAccuracy: 89.93%\n",
      "175\tValidation loss: 0.308807\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "176\tValidation loss: 0.305816\tBest loss: 0.286452\tAccuracy: 90.65%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  21.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 248441.906250\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "1\tValidation loss: 3651316.250000\tBest loss: 248441.906250\tAccuracy: 3.60%\n",
      "2\tValidation loss: 9449493.000000\tBest loss: 248441.906250\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3051184.250000\tBest loss: 248441.906250\tAccuracy: 3.60%\n",
      "4\tValidation loss: 2941799.000000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "5\tValidation loss: 447819.937500\tBest loss: 248441.906250\tAccuracy: 5.04%\n",
      "6\tValidation loss: 1061287.000000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "7\tValidation loss: 1000276.187500\tBest loss: 248441.906250\tAccuracy: 0.00%\n",
      "8\tValidation loss: 1385363.250000\tBest loss: 248441.906250\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3577077.250000\tBest loss: 248441.906250\tAccuracy: 5.76%\n",
      "10\tValidation loss: 3092487.250000\tBest loss: 248441.906250\tAccuracy: 3.60%\n",
      "11\tValidation loss: 1547850.875000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "12\tValidation loss: 6138848.000000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "13\tValidation loss: 3459783.250000\tBest loss: 248441.906250\tAccuracy: 6.47%\n",
      "14\tValidation loss: 2800036.000000\tBest loss: 248441.906250\tAccuracy: 4.32%\n",
      "15\tValidation loss: 5191376.000000\tBest loss: 248441.906250\tAccuracy: 1.44%\n",
      "16\tValidation loss: 4183810.250000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "17\tValidation loss: 3649088.500000\tBest loss: 248441.906250\tAccuracy: 7.91%\n",
      "18\tValidation loss: 2577424.000000\tBest loss: 248441.906250\tAccuracy: 2.88%\n",
      "19\tValidation loss: 1847713.000000\tBest loss: 248441.906250\tAccuracy: 1.44%\n",
      "20\tValidation loss: 6142134.000000\tBest loss: 248441.906250\tAccuracy: 0.72%\n",
      "21\tValidation loss: 6460008.000000\tBest loss: 248441.906250\tAccuracy: 2.16%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 239364.421875\tBest loss: 239364.421875\tAccuracy: 2.16%\n",
      "1\tValidation loss: 3591395.250000\tBest loss: 239364.421875\tAccuracy: 3.60%\n",
      "2\tValidation loss: 12417123.000000\tBest loss: 239364.421875\tAccuracy: 3.60%\n",
      "3\tValidation loss: 1611365.375000\tBest loss: 239364.421875\tAccuracy: 0.00%\n",
      "4\tValidation loss: 3400338.750000\tBest loss: 239364.421875\tAccuracy: 0.72%\n",
      "5\tValidation loss: 1546220.000000\tBest loss: 239364.421875\tAccuracy: 0.72%\n",
      "6\tValidation loss: 1001483.375000\tBest loss: 239364.421875\tAccuracy: 4.32%\n",
      "7\tValidation loss: 785004.187500\tBest loss: 239364.421875\tAccuracy: 2.16%\n",
      "8\tValidation loss: 1092196.625000\tBest loss: 239364.421875\tAccuracy: 3.60%\n",
      "9\tValidation loss: 13352084.000000\tBest loss: 239364.421875\tAccuracy: 5.04%\n",
      "10\tValidation loss: 2510062.500000\tBest loss: 239364.421875\tAccuracy: 5.04%\n",
      "11\tValidation loss: 4304369.500000\tBest loss: 239364.421875\tAccuracy: 0.72%\n",
      "12\tValidation loss: 6124618.000000\tBest loss: 239364.421875\tAccuracy: 0.72%\n",
      "13\tValidation loss: 4152217.500000\tBest loss: 239364.421875\tAccuracy: 5.04%\n",
      "14\tValidation loss: 6851246.000000\tBest loss: 239364.421875\tAccuracy: 2.16%\n",
      "15\tValidation loss: 12813544.000000\tBest loss: 239364.421875\tAccuracy: 2.88%\n",
      "16\tValidation loss: 12092178.000000\tBest loss: 239364.421875\tAccuracy: 1.44%\n",
      "17\tValidation loss: 9918769.000000\tBest loss: 239364.421875\tAccuracy: 2.16%\n",
      "18\tValidation loss: 36731824.000000\tBest loss: 239364.421875\tAccuracy: 2.16%\n",
      "19\tValidation loss: 45293396.000000\tBest loss: 239364.421875\tAccuracy: 0.72%\n",
      "20\tValidation loss: 4962279.000000\tBest loss: 239364.421875\tAccuracy: 2.88%\n",
      "21\tValidation loss: 6233756.500000\tBest loss: 239364.421875\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 229951.140625\tBest loss: 229951.140625\tAccuracy: 2.16%\n",
      "1\tValidation loss: 3302150.000000\tBest loss: 229951.140625\tAccuracy: 5.76%\n",
      "2\tValidation loss: 12961515.000000\tBest loss: 229951.140625\tAccuracy: 5.76%\n",
      "3\tValidation loss: 1879175.500000\tBest loss: 229951.140625\tAccuracy: 0.00%\n",
      "4\tValidation loss: 1918239.500000\tBest loss: 229951.140625\tAccuracy: 7.91%\n",
      "5\tValidation loss: 621005.687500\tBest loss: 229951.140625\tAccuracy: 0.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 2228982.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "7\tValidation loss: 3291901.500000\tBest loss: 229951.140625\tAccuracy: 2.16%\n",
      "8\tValidation loss: 3235464.500000\tBest loss: 229951.140625\tAccuracy: 4.32%\n",
      "9\tValidation loss: 1227408.250000\tBest loss: 229951.140625\tAccuracy: 3.60%\n",
      "10\tValidation loss: 17086282.000000\tBest loss: 229951.140625\tAccuracy: 5.76%\n",
      "11\tValidation loss: 9129847.000000\tBest loss: 229951.140625\tAccuracy: 5.04%\n",
      "12\tValidation loss: 5307191.000000\tBest loss: 229951.140625\tAccuracy: 1.44%\n",
      "13\tValidation loss: 111169232.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "14\tValidation loss: 8325546.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "15\tValidation loss: 12871057.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "16\tValidation loss: 12904499.000000\tBest loss: 229951.140625\tAccuracy: 1.44%\n",
      "17\tValidation loss: 16280129.000000\tBest loss: 229951.140625\tAccuracy: 2.16%\n",
      "18\tValidation loss: 6861279.500000\tBest loss: 229951.140625\tAccuracy: 6.47%\n",
      "19\tValidation loss: 5128904.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "20\tValidation loss: 16260795.000000\tBest loss: 229951.140625\tAccuracy: 0.00%\n",
      "21\tValidation loss: 23810788.000000\tBest loss: 229951.140625\tAccuracy: 0.72%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 18.948738\tBest loss: 18.948738\tAccuracy: 61.15%\n",
      "1\tValidation loss: 10.321592\tBest loss: 10.321592\tAccuracy: 76.98%\n",
      "2\tValidation loss: 3.770998\tBest loss: 3.770998\tAccuracy: 87.05%\n",
      "3\tValidation loss: 11.295426\tBest loss: 3.770998\tAccuracy: 77.70%\n",
      "4\tValidation loss: 3.812961\tBest loss: 3.770998\tAccuracy: 88.49%\n",
      "5\tValidation loss: 3.717416\tBest loss: 3.717416\tAccuracy: 86.33%\n",
      "6\tValidation loss: 9.376371\tBest loss: 3.717416\tAccuracy: 85.61%\n",
      "7\tValidation loss: 2.787595\tBest loss: 2.787595\tAccuracy: 89.21%\n",
      "8\tValidation loss: 6.953020\tBest loss: 2.787595\tAccuracy: 82.73%\n",
      "9\tValidation loss: 8.017022\tBest loss: 2.787595\tAccuracy: 83.45%\n",
      "10\tValidation loss: 7.768340\tBest loss: 2.787595\tAccuracy: 82.01%\n",
      "11\tValidation loss: 4.636343\tBest loss: 2.787595\tAccuracy: 84.17%\n",
      "12\tValidation loss: 5.669104\tBest loss: 2.787595\tAccuracy: 89.21%\n",
      "13\tValidation loss: 3.030086\tBest loss: 2.787595\tAccuracy: 86.33%\n",
      "14\tValidation loss: 2.500068\tBest loss: 2.500068\tAccuracy: 88.49%\n",
      "15\tValidation loss: 2.139264\tBest loss: 2.139264\tAccuracy: 90.65%\n",
      "16\tValidation loss: 2.088370\tBest loss: 2.088370\tAccuracy: 91.37%\n",
      "17\tValidation loss: 2.080561\tBest loss: 2.080561\tAccuracy: 90.65%\n",
      "18\tValidation loss: 4.727272\tBest loss: 2.080561\tAccuracy: 87.77%\n",
      "19\tValidation loss: 2.066689\tBest loss: 2.066689\tAccuracy: 90.65%\n",
      "20\tValidation loss: 2.068271\tBest loss: 2.066689\tAccuracy: 90.65%\n",
      "21\tValidation loss: 2.082674\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "22\tValidation loss: 2.097466\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "23\tValidation loss: 2.096781\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "24\tValidation loss: 2.096332\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "25\tValidation loss: 2.095852\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "26\tValidation loss: 2.095549\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "27\tValidation loss: 2.095013\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "28\tValidation loss: 2.094700\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "29\tValidation loss: 2.094285\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "30\tValidation loss: 2.093940\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "31\tValidation loss: 2.093610\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "32\tValidation loss: 2.093231\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "33\tValidation loss: 2.093024\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "34\tValidation loss: 2.092657\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "35\tValidation loss: 2.092392\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "36\tValidation loss: 2.092000\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "37\tValidation loss: 2.091656\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "38\tValidation loss: 2.091388\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "39\tValidation loss: 2.091057\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "40\tValidation loss: 2.090898\tBest loss: 2.066689\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   7.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 16.494648\tBest loss: 16.494648\tAccuracy: 61.87%\n",
      "1\tValidation loss: 6.492070\tBest loss: 6.492070\tAccuracy: 80.58%\n",
      "2\tValidation loss: 4.780264\tBest loss: 4.780264\tAccuracy: 81.29%\n",
      "3\tValidation loss: 13.023949\tBest loss: 4.780264\tAccuracy: 76.26%\n",
      "4\tValidation loss: 12.381816\tBest loss: 4.780264\tAccuracy: 79.14%\n",
      "5\tValidation loss: 9.837890\tBest loss: 4.780264\tAccuracy: 75.54%\n",
      "6\tValidation loss: 6.193449\tBest loss: 4.780264\tAccuracy: 82.01%\n",
      "7\tValidation loss: 6.617145\tBest loss: 4.780264\tAccuracy: 86.33%\n",
      "8\tValidation loss: 2.737778\tBest loss: 2.737778\tAccuracy: 88.49%\n",
      "9\tValidation loss: 3.269994\tBest loss: 2.737778\tAccuracy: 89.21%\n",
      "10\tValidation loss: 3.978527\tBest loss: 2.737778\tAccuracy: 86.33%\n",
      "11\tValidation loss: 3.302893\tBest loss: 2.737778\tAccuracy: 87.77%\n",
      "12\tValidation loss: 2.584303\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "13\tValidation loss: 2.658018\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "14\tValidation loss: 2.646901\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "15\tValidation loss: 2.637608\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "16\tValidation loss: 2.630996\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "17\tValidation loss: 2.626045\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "18\tValidation loss: 2.621739\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "19\tValidation loss: 2.618183\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "20\tValidation loss: 2.614772\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "21\tValidation loss: 2.612431\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "22\tValidation loss: 2.609774\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "23\tValidation loss: 2.607476\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "24\tValidation loss: 2.605683\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "25\tValidation loss: 2.603001\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "26\tValidation loss: 2.599754\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "27\tValidation loss: 2.598974\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "28\tValidation loss: 2.598864\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "29\tValidation loss: 2.597383\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "30\tValidation loss: 2.595401\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "31\tValidation loss: 2.595086\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "32\tValidation loss: 2.592755\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "33\tValidation loss: 2.590677\tBest loss: 2.584303\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   6.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 15.844247\tBest loss: 15.844247\tAccuracy: 60.43%\n",
      "1\tValidation loss: 11.504639\tBest loss: 11.504639\tAccuracy: 70.50%\n",
      "2\tValidation loss: 6.395064\tBest loss: 6.395064\tAccuracy: 77.70%\n",
      "3\tValidation loss: 4.346110\tBest loss: 4.346110\tAccuracy: 82.73%\n",
      "4\tValidation loss: 6.573398\tBest loss: 4.346110\tAccuracy: 81.29%\n",
      "5\tValidation loss: 3.192980\tBest loss: 3.192980\tAccuracy: 86.33%\n",
      "6\tValidation loss: 4.304125\tBest loss: 3.192980\tAccuracy: 85.61%\n",
      "7\tValidation loss: 11.067080\tBest loss: 3.192980\tAccuracy: 78.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\tValidation loss: 3.708724\tBest loss: 3.192980\tAccuracy: 86.33%\n",
      "9\tValidation loss: 2.345372\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "10\tValidation loss: 15.008185\tBest loss: 2.345372\tAccuracy: 76.26%\n",
      "11\tValidation loss: 3.205638\tBest loss: 2.345372\tAccuracy: 87.05%\n",
      "12\tValidation loss: 17.000864\tBest loss: 2.345372\tAccuracy: 84.17%\n",
      "13\tValidation loss: 6.862008\tBest loss: 2.345372\tAccuracy: 84.89%\n",
      "14\tValidation loss: 6.753398\tBest loss: 2.345372\tAccuracy: 82.01%\n",
      "15\tValidation loss: 5.498814\tBest loss: 2.345372\tAccuracy: 86.33%\n",
      "16\tValidation loss: 3.090231\tBest loss: 2.345372\tAccuracy: 88.49%\n",
      "17\tValidation loss: 2.883656\tBest loss: 2.345372\tAccuracy: 89.21%\n",
      "18\tValidation loss: 2.821943\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "19\tValidation loss: 2.814933\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "20\tValidation loss: 2.809264\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "21\tValidation loss: 2.804144\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "22\tValidation loss: 2.799974\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "23\tValidation loss: 2.796471\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "24\tValidation loss: 2.792949\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "25\tValidation loss: 2.789884\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "26\tValidation loss: 2.786625\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "27\tValidation loss: 2.783798\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "28\tValidation loss: 2.780671\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "29\tValidation loss: 2.777909\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "30\tValidation loss: 2.775187\tBest loss: 2.345372\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.3, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   5.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 149.243881\tBest loss: 149.243881\tAccuracy: 41.01%\n",
      "1\tValidation loss: 13.022842\tBest loss: 13.022842\tAccuracy: 76.98%\n",
      "2\tValidation loss: 3.064739\tBest loss: 3.064739\tAccuracy: 85.61%\n",
      "3\tValidation loss: 2.273248\tBest loss: 2.273248\tAccuracy: 87.77%\n",
      "4\tValidation loss: 1.692203\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "5\tValidation loss: 1.711377\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "6\tValidation loss: 1.706171\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "7\tValidation loss: 1.747848\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "8\tValidation loss: 1.835517\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "9\tValidation loss: 1.920583\tBest loss: 1.692203\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.312274\tBest loss: 1.312274\tAccuracy: 92.81%\n",
      "11\tValidation loss: 1.345087\tBest loss: 1.312274\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.337866\tBest loss: 1.312274\tAccuracy: 91.37%\n",
      "13\tValidation loss: 1.294053\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "14\tValidation loss: 1.311134\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "15\tValidation loss: 1.415579\tBest loss: 1.294053\tAccuracy: 92.09%\n",
      "16\tValidation loss: 1.386243\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "17\tValidation loss: 1.367903\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "18\tValidation loss: 1.358056\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "19\tValidation loss: 1.336080\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "20\tValidation loss: 1.333977\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "21\tValidation loss: 1.313326\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "22\tValidation loss: 1.305875\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "23\tValidation loss: 1.292080\tBest loss: 1.292080\tAccuracy: 92.81%\n",
      "24\tValidation loss: 1.282080\tBest loss: 1.282080\tAccuracy: 92.81%\n",
      "25\tValidation loss: 1.264940\tBest loss: 1.264940\tAccuracy: 92.81%\n",
      "26\tValidation loss: 1.251236\tBest loss: 1.251236\tAccuracy: 92.81%\n",
      "27\tValidation loss: 1.237349\tBest loss: 1.237349\tAccuracy: 92.81%\n",
      "28\tValidation loss: 1.230950\tBest loss: 1.230950\tAccuracy: 92.81%\n",
      "29\tValidation loss: 1.225333\tBest loss: 1.225333\tAccuracy: 92.81%\n",
      "30\tValidation loss: 1.221472\tBest loss: 1.221472\tAccuracy: 92.81%\n",
      "31\tValidation loss: 1.219496\tBest loss: 1.219496\tAccuracy: 92.81%\n",
      "32\tValidation loss: 1.217501\tBest loss: 1.217501\tAccuracy: 92.81%\n",
      "33\tValidation loss: 1.215929\tBest loss: 1.215929\tAccuracy: 92.81%\n",
      "34\tValidation loss: 1.213557\tBest loss: 1.213557\tAccuracy: 92.81%\n",
      "35\tValidation loss: 1.212316\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "36\tValidation loss: 1.213393\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "37\tValidation loss: 1.214216\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "38\tValidation loss: 1.212729\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "39\tValidation loss: 1.212647\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "40\tValidation loss: 1.213709\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "41\tValidation loss: 1.213682\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "42\tValidation loss: 1.213243\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "43\tValidation loss: 1.213021\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "44\tValidation loss: 1.213771\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "45\tValidation loss: 1.214675\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "46\tValidation loss: 1.215699\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "47\tValidation loss: 1.216275\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "48\tValidation loss: 1.216820\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "49\tValidation loss: 1.217206\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "50\tValidation loss: 1.217297\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "51\tValidation loss: 1.217452\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "52\tValidation loss: 1.217616\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "53\tValidation loss: 1.218500\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "54\tValidation loss: 1.219201\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "55\tValidation loss: 1.219640\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "56\tValidation loss: 1.220639\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total=   6.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 106.085571\tBest loss: 106.085571\tAccuracy: 43.17%\n",
      "1\tValidation loss: 7.470766\tBest loss: 7.470766\tAccuracy: 80.58%\n",
      "2\tValidation loss: 3.732459\tBest loss: 3.732459\tAccuracy: 84.17%\n",
      "3\tValidation loss: 2.476254\tBest loss: 2.476254\tAccuracy: 88.49%\n",
      "4\tValidation loss: 2.166965\tBest loss: 2.166965\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.884392\tBest loss: 1.884392\tAccuracy: 85.61%\n",
      "6\tValidation loss: 1.722733\tBest loss: 1.722733\tAccuracy: 88.49%\n",
      "7\tValidation loss: 1.640909\tBest loss: 1.640909\tAccuracy: 89.93%\n",
      "8\tValidation loss: 1.498040\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "9\tValidation loss: 1.592885\tBest loss: 1.498040\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.516133\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "11\tValidation loss: 1.520671\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "12\tValidation loss: 1.459917\tBest loss: 1.459917\tAccuracy: 89.21%\n",
      "13\tValidation loss: 1.449062\tBest loss: 1.449062\tAccuracy: 90.65%\n",
      "14\tValidation loss: 1.457271\tBest loss: 1.449062\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.442070\tBest loss: 1.442070\tAccuracy: 90.65%\n",
      "16\tValidation loss: 1.397251\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "17\tValidation loss: 1.409543\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "18\tValidation loss: 1.403412\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "19\tValidation loss: 1.399037\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "20\tValidation loss: 1.399575\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "21\tValidation loss: 1.398277\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "22\tValidation loss: 1.395848\tBest loss: 1.395848\tAccuracy: 90.65%\n",
      "23\tValidation loss: 1.395264\tBest loss: 1.395264\tAccuracy: 90.65%\n",
      "24\tValidation loss: 1.392942\tBest loss: 1.392942\tAccuracy: 90.65%\n",
      "25\tValidation loss: 1.389107\tBest loss: 1.389107\tAccuracy: 90.65%\n",
      "26\tValidation loss: 1.388084\tBest loss: 1.388084\tAccuracy: 90.65%\n",
      "27\tValidation loss: 1.388053\tBest loss: 1.388053\tAccuracy: 90.65%\n",
      "28\tValidation loss: 1.386218\tBest loss: 1.386218\tAccuracy: 90.65%\n",
      "29\tValidation loss: 1.385202\tBest loss: 1.385202\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\tValidation loss: 1.385309\tBest loss: 1.385202\tAccuracy: 90.65%\n",
      "31\tValidation loss: 1.384943\tBest loss: 1.384943\tAccuracy: 90.65%\n",
      "32\tValidation loss: 1.384230\tBest loss: 1.384230\tAccuracy: 90.65%\n",
      "33\tValidation loss: 1.383366\tBest loss: 1.383366\tAccuracy: 90.65%\n",
      "34\tValidation loss: 1.382838\tBest loss: 1.382838\tAccuracy: 90.65%\n",
      "35\tValidation loss: 1.382352\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "36\tValidation loss: 1.383041\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "37\tValidation loss: 1.382644\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "38\tValidation loss: 1.381944\tBest loss: 1.381944\tAccuracy: 90.65%\n",
      "39\tValidation loss: 1.381864\tBest loss: 1.381864\tAccuracy: 90.65%\n",
      "40\tValidation loss: 1.381380\tBest loss: 1.381380\tAccuracy: 89.93%\n",
      "41\tValidation loss: 1.380342\tBest loss: 1.380342\tAccuracy: 89.93%\n",
      "42\tValidation loss: 1.380001\tBest loss: 1.380001\tAccuracy: 89.93%\n",
      "43\tValidation loss: 1.379563\tBest loss: 1.379563\tAccuracy: 89.93%\n",
      "44\tValidation loss: 1.379130\tBest loss: 1.379130\tAccuracy: 89.93%\n",
      "45\tValidation loss: 1.378901\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "46\tValidation loss: 1.379094\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "47\tValidation loss: 1.378875\tBest loss: 1.378875\tAccuracy: 89.93%\n",
      "48\tValidation loss: 1.378456\tBest loss: 1.378456\tAccuracy: 89.93%\n",
      "49\tValidation loss: 1.378312\tBest loss: 1.378312\tAccuracy: 89.93%\n",
      "50\tValidation loss: 1.378066\tBest loss: 1.378066\tAccuracy: 89.93%\n",
      "51\tValidation loss: 1.377724\tBest loss: 1.377724\tAccuracy: 89.93%\n",
      "52\tValidation loss: 1.377167\tBest loss: 1.377167\tAccuracy: 89.93%\n",
      "53\tValidation loss: 1.376782\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "54\tValidation loss: 1.376867\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "55\tValidation loss: 1.376913\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "56\tValidation loss: 1.376736\tBest loss: 1.376736\tAccuracy: 89.93%\n",
      "57\tValidation loss: 1.376402\tBest loss: 1.376402\tAccuracy: 89.93%\n",
      "58\tValidation loss: 1.376335\tBest loss: 1.376335\tAccuracy: 89.93%\n",
      "59\tValidation loss: 1.375827\tBest loss: 1.375827\tAccuracy: 89.93%\n",
      "60\tValidation loss: 1.375189\tBest loss: 1.375189\tAccuracy: 89.93%\n",
      "61\tValidation loss: 1.375146\tBest loss: 1.375146\tAccuracy: 89.93%\n",
      "62\tValidation loss: 1.374501\tBest loss: 1.374501\tAccuracy: 90.65%\n",
      "63\tValidation loss: 1.374355\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "64\tValidation loss: 1.374605\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "65\tValidation loss: 1.374385\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "66\tValidation loss: 1.374017\tBest loss: 1.374017\tAccuracy: 90.65%\n",
      "67\tValidation loss: 1.373550\tBest loss: 1.373550\tAccuracy: 90.65%\n",
      "68\tValidation loss: 1.373206\tBest loss: 1.373206\tAccuracy: 90.65%\n",
      "69\tValidation loss: 1.373018\tBest loss: 1.373018\tAccuracy: 90.65%\n",
      "70\tValidation loss: 1.373183\tBest loss: 1.373018\tAccuracy: 90.65%\n",
      "71\tValidation loss: 1.373071\tBest loss: 1.373018\tAccuracy: 90.65%\n",
      "72\tValidation loss: 1.373059\tBest loss: 1.373018\tAccuracy: 90.65%\n",
      "73\tValidation loss: 1.372931\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "74\tValidation loss: 1.372952\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "75\tValidation loss: 1.372553\tBest loss: 1.372553\tAccuracy: 90.65%\n",
      "76\tValidation loss: 1.372201\tBest loss: 1.372201\tAccuracy: 90.65%\n",
      "77\tValidation loss: 1.372062\tBest loss: 1.372062\tAccuracy: 90.65%\n",
      "78\tValidation loss: 1.371762\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "79\tValidation loss: 1.371889\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "80\tValidation loss: 1.371850\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "81\tValidation loss: 1.371671\tBest loss: 1.371671\tAccuracy: 90.65%\n",
      "82\tValidation loss: 1.371478\tBest loss: 1.371478\tAccuracy: 90.65%\n",
      "83\tValidation loss: 1.371271\tBest loss: 1.371271\tAccuracy: 90.65%\n",
      "84\tValidation loss: 1.371223\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "85\tValidation loss: 1.371225\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "86\tValidation loss: 1.371065\tBest loss: 1.371065\tAccuracy: 90.65%\n",
      "87\tValidation loss: 1.370694\tBest loss: 1.370694\tAccuracy: 90.65%\n",
      "88\tValidation loss: 1.370361\tBest loss: 1.370361\tAccuracy: 90.65%\n",
      "89\tValidation loss: 1.370110\tBest loss: 1.370110\tAccuracy: 90.65%\n",
      "90\tValidation loss: 1.369943\tBest loss: 1.369943\tAccuracy: 90.65%\n",
      "91\tValidation loss: 1.369720\tBest loss: 1.369720\tAccuracy: 90.65%\n",
      "92\tValidation loss: 1.369700\tBest loss: 1.369700\tAccuracy: 90.65%\n",
      "93\tValidation loss: 1.369634\tBest loss: 1.369634\tAccuracy: 90.65%\n",
      "94\tValidation loss: 1.369630\tBest loss: 1.369630\tAccuracy: 90.65%\n",
      "95\tValidation loss: 1.369463\tBest loss: 1.369463\tAccuracy: 90.65%\n",
      "96\tValidation loss: 1.369437\tBest loss: 1.369437\tAccuracy: 90.65%\n",
      "97\tValidation loss: 1.369115\tBest loss: 1.369115\tAccuracy: 90.65%\n",
      "98\tValidation loss: 1.368975\tBest loss: 1.368975\tAccuracy: 90.65%\n",
      "99\tValidation loss: 1.368727\tBest loss: 1.368727\tAccuracy: 90.65%\n",
      "100\tValidation loss: 1.368736\tBest loss: 1.368727\tAccuracy: 90.65%\n",
      "101\tValidation loss: 1.368508\tBest loss: 1.368508\tAccuracy: 90.65%\n",
      "102\tValidation loss: 1.368247\tBest loss: 1.368247\tAccuracy: 90.65%\n",
      "103\tValidation loss: 1.368217\tBest loss: 1.368217\tAccuracy: 90.65%\n",
      "104\tValidation loss: 1.368143\tBest loss: 1.368143\tAccuracy: 90.65%\n",
      "105\tValidation loss: 1.367982\tBest loss: 1.367982\tAccuracy: 90.65%\n",
      "106\tValidation loss: 1.367802\tBest loss: 1.367802\tAccuracy: 90.65%\n",
      "107\tValidation loss: 1.367592\tBest loss: 1.367592\tAccuracy: 90.65%\n",
      "108\tValidation loss: 1.367495\tBest loss: 1.367495\tAccuracy: 90.65%\n",
      "109\tValidation loss: 1.367285\tBest loss: 1.367285\tAccuracy: 90.65%\n",
      "110\tValidation loss: 1.367244\tBest loss: 1.367244\tAccuracy: 90.65%\n",
      "111\tValidation loss: 1.367138\tBest loss: 1.367138\tAccuracy: 90.65%\n",
      "112\tValidation loss: 1.366982\tBest loss: 1.366982\tAccuracy: 90.65%\n",
      "113\tValidation loss: 1.366910\tBest loss: 1.366910\tAccuracy: 90.65%\n",
      "114\tValidation loss: 1.366804\tBest loss: 1.366804\tAccuracy: 90.65%\n",
      "115\tValidation loss: 1.366654\tBest loss: 1.366654\tAccuracy: 90.65%\n",
      "116\tValidation loss: 1.366652\tBest loss: 1.366652\tAccuracy: 90.65%\n",
      "117\tValidation loss: 1.366574\tBest loss: 1.366574\tAccuracy: 90.65%\n",
      "118\tValidation loss: 1.366433\tBest loss: 1.366433\tAccuracy: 90.65%\n",
      "119\tValidation loss: 1.366417\tBest loss: 1.366417\tAccuracy: 90.65%\n",
      "120\tValidation loss: 1.366286\tBest loss: 1.366286\tAccuracy: 90.65%\n",
      "121\tValidation loss: 1.366273\tBest loss: 1.366273\tAccuracy: 90.65%\n",
      "122\tValidation loss: 1.366104\tBest loss: 1.366104\tAccuracy: 90.65%\n",
      "123\tValidation loss: 1.365904\tBest loss: 1.365904\tAccuracy: 90.65%\n",
      "124\tValidation loss: 1.365770\tBest loss: 1.365770\tAccuracy: 90.65%\n",
      "125\tValidation loss: 1.365732\tBest loss: 1.365732\tAccuracy: 90.65%\n",
      "126\tValidation loss: 1.365605\tBest loss: 1.365605\tAccuracy: 90.65%\n",
      "127\tValidation loss: 1.365536\tBest loss: 1.365536\tAccuracy: 90.65%\n",
      "128\tValidation loss: 1.365501\tBest loss: 1.365501\tAccuracy: 90.65%\n",
      "129\tValidation loss: 1.365338\tBest loss: 1.365338\tAccuracy: 90.65%\n",
      "130\tValidation loss: 1.365180\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "131\tValidation loss: 1.365199\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "132\tValidation loss: 1.365084\tBest loss: 1.365084\tAccuracy: 90.65%\n",
      "133\tValidation loss: 1.364945\tBest loss: 1.364945\tAccuracy: 90.65%\n",
      "134\tValidation loss: 1.364809\tBest loss: 1.364809\tAccuracy: 90.65%\n",
      "135\tValidation loss: 1.364703\tBest loss: 1.364703\tAccuracy: 90.65%\n",
      "136\tValidation loss: 1.364616\tBest loss: 1.364616\tAccuracy: 90.65%\n",
      "137\tValidation loss: 1.364583\tBest loss: 1.364583\tAccuracy: 90.65%\n",
      "138\tValidation loss: 1.364435\tBest loss: 1.364435\tAccuracy: 90.65%\n",
      "139\tValidation loss: 1.364313\tBest loss: 1.364313\tAccuracy: 90.65%\n",
      "140\tValidation loss: 1.364291\tBest loss: 1.364291\tAccuracy: 90.65%\n",
      "141\tValidation loss: 1.364212\tBest loss: 1.364212\tAccuracy: 90.65%\n",
      "142\tValidation loss: 1.364156\tBest loss: 1.364156\tAccuracy: 90.65%\n",
      "143\tValidation loss: 1.364089\tBest loss: 1.364089\tAccuracy: 90.65%\n",
      "144\tValidation loss: 1.364098\tBest loss: 1.364089\tAccuracy: 90.65%\n",
      "145\tValidation loss: 1.364024\tBest loss: 1.364024\tAccuracy: 90.65%\n",
      "146\tValidation loss: 1.364007\tBest loss: 1.364007\tAccuracy: 90.65%\n",
      "147\tValidation loss: 1.363935\tBest loss: 1.363935\tAccuracy: 90.65%\n",
      "148\tValidation loss: 1.363901\tBest loss: 1.363901\tAccuracy: 90.65%\n",
      "149\tValidation loss: 1.363888\tBest loss: 1.363888\tAccuracy: 90.65%\n",
      "150\tValidation loss: 1.363728\tBest loss: 1.363728\tAccuracy: 90.65%\n",
      "151\tValidation loss: 1.363622\tBest loss: 1.363622\tAccuracy: 90.65%\n",
      "152\tValidation loss: 1.363590\tBest loss: 1.363590\tAccuracy: 90.65%\n",
      "153\tValidation loss: 1.363539\tBest loss: 1.363539\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\tValidation loss: 1.363503\tBest loss: 1.363503\tAccuracy: 90.65%\n",
      "155\tValidation loss: 1.363386\tBest loss: 1.363386\tAccuracy: 90.65%\n",
      "156\tValidation loss: 1.363268\tBest loss: 1.363268\tAccuracy: 90.65%\n",
      "157\tValidation loss: 1.363187\tBest loss: 1.363187\tAccuracy: 90.65%\n",
      "158\tValidation loss: 1.363079\tBest loss: 1.363079\tAccuracy: 90.65%\n",
      "159\tValidation loss: 1.362931\tBest loss: 1.362931\tAccuracy: 90.65%\n",
      "160\tValidation loss: 1.362914\tBest loss: 1.362914\tAccuracy: 90.65%\n",
      "161\tValidation loss: 1.362863\tBest loss: 1.362863\tAccuracy: 90.65%\n",
      "162\tValidation loss: 1.362811\tBest loss: 1.362811\tAccuracy: 90.65%\n",
      "163\tValidation loss: 1.362726\tBest loss: 1.362726\tAccuracy: 90.65%\n",
      "164\tValidation loss: 1.362710\tBest loss: 1.362710\tAccuracy: 90.65%\n",
      "165\tValidation loss: 1.362672\tBest loss: 1.362672\tAccuracy: 90.65%\n",
      "166\tValidation loss: 1.362583\tBest loss: 1.362583\tAccuracy: 90.65%\n",
      "167\tValidation loss: 1.362536\tBest loss: 1.362536\tAccuracy: 90.65%\n",
      "168\tValidation loss: 1.362468\tBest loss: 1.362468\tAccuracy: 90.65%\n",
      "169\tValidation loss: 1.362392\tBest loss: 1.362392\tAccuracy: 90.65%\n",
      "170\tValidation loss: 1.362327\tBest loss: 1.362327\tAccuracy: 90.65%\n",
      "171\tValidation loss: 1.362286\tBest loss: 1.362286\tAccuracy: 90.65%\n",
      "172\tValidation loss: 1.362193\tBest loss: 1.362193\tAccuracy: 90.65%\n",
      "173\tValidation loss: 1.362141\tBest loss: 1.362141\tAccuracy: 90.65%\n",
      "174\tValidation loss: 1.362106\tBest loss: 1.362106\tAccuracy: 90.65%\n",
      "175\tValidation loss: 1.362068\tBest loss: 1.362068\tAccuracy: 90.65%\n",
      "176\tValidation loss: 1.361970\tBest loss: 1.361970\tAccuracy: 90.65%\n",
      "177\tValidation loss: 1.361930\tBest loss: 1.361930\tAccuracy: 90.65%\n",
      "178\tValidation loss: 1.361834\tBest loss: 1.361834\tAccuracy: 90.65%\n",
      "179\tValidation loss: 1.361734\tBest loss: 1.361734\tAccuracy: 90.65%\n",
      "180\tValidation loss: 1.361680\tBest loss: 1.361680\tAccuracy: 90.65%\n",
      "181\tValidation loss: 1.361610\tBest loss: 1.361610\tAccuracy: 90.65%\n",
      "182\tValidation loss: 1.361546\tBest loss: 1.361546\tAccuracy: 90.65%\n",
      "183\tValidation loss: 1.361497\tBest loss: 1.361497\tAccuracy: 90.65%\n",
      "184\tValidation loss: 1.361397\tBest loss: 1.361397\tAccuracy: 90.65%\n",
      "185\tValidation loss: 1.361291\tBest loss: 1.361291\tAccuracy: 90.65%\n",
      "186\tValidation loss: 1.361284\tBest loss: 1.361284\tAccuracy: 90.65%\n",
      "187\tValidation loss: 1.361249\tBest loss: 1.361249\tAccuracy: 90.65%\n",
      "188\tValidation loss: 1.361248\tBest loss: 1.361248\tAccuracy: 90.65%\n",
      "189\tValidation loss: 1.361195\tBest loss: 1.361195\tAccuracy: 90.65%\n",
      "190\tValidation loss: 1.361112\tBest loss: 1.361112\tAccuracy: 90.65%\n",
      "191\tValidation loss: 1.361038\tBest loss: 1.361038\tAccuracy: 90.65%\n",
      "192\tValidation loss: 1.360952\tBest loss: 1.360952\tAccuracy: 90.65%\n",
      "193\tValidation loss: 1.360903\tBest loss: 1.360903\tAccuracy: 90.65%\n",
      "194\tValidation loss: 1.360809\tBest loss: 1.360809\tAccuracy: 90.65%\n",
      "195\tValidation loss: 1.360745\tBest loss: 1.360745\tAccuracy: 90.65%\n",
      "196\tValidation loss: 1.360728\tBest loss: 1.360728\tAccuracy: 90.65%\n",
      "197\tValidation loss: 1.360653\tBest loss: 1.360653\tAccuracy: 90.65%\n",
      "198\tValidation loss: 1.360602\tBest loss: 1.360602\tAccuracy: 90.65%\n",
      "199\tValidation loss: 1.360594\tBest loss: 1.360594\tAccuracy: 90.65%\n",
      "200\tValidation loss: 1.360551\tBest loss: 1.360551\tAccuracy: 90.65%\n",
      "201\tValidation loss: 1.360520\tBest loss: 1.360520\tAccuracy: 90.65%\n",
      "202\tValidation loss: 1.360448\tBest loss: 1.360448\tAccuracy: 90.65%\n",
      "203\tValidation loss: 1.360380\tBest loss: 1.360380\tAccuracy: 90.65%\n",
      "204\tValidation loss: 1.360336\tBest loss: 1.360336\tAccuracy: 90.65%\n",
      "205\tValidation loss: 1.360225\tBest loss: 1.360225\tAccuracy: 90.65%\n",
      "206\tValidation loss: 1.360178\tBest loss: 1.360178\tAccuracy: 90.65%\n",
      "207\tValidation loss: 1.360137\tBest loss: 1.360137\tAccuracy: 90.65%\n",
      "208\tValidation loss: 1.360098\tBest loss: 1.360098\tAccuracy: 90.65%\n",
      "209\tValidation loss: 1.360004\tBest loss: 1.360004\tAccuracy: 90.65%\n",
      "210\tValidation loss: 1.359919\tBest loss: 1.359919\tAccuracy: 90.65%\n",
      "211\tValidation loss: 1.359851\tBest loss: 1.359851\tAccuracy: 90.65%\n",
      "212\tValidation loss: 1.359800\tBest loss: 1.359800\tAccuracy: 90.65%\n",
      "213\tValidation loss: 1.359725\tBest loss: 1.359725\tAccuracy: 90.65%\n",
      "214\tValidation loss: 1.359683\tBest loss: 1.359683\tAccuracy: 90.65%\n",
      "215\tValidation loss: 1.359655\tBest loss: 1.359655\tAccuracy: 90.65%\n",
      "216\tValidation loss: 1.359660\tBest loss: 1.359655\tAccuracy: 90.65%\n",
      "217\tValidation loss: 1.359635\tBest loss: 1.359635\tAccuracy: 90.65%\n",
      "218\tValidation loss: 1.359623\tBest loss: 1.359623\tAccuracy: 90.65%\n",
      "219\tValidation loss: 1.359591\tBest loss: 1.359591\tAccuracy: 90.65%\n",
      "220\tValidation loss: 1.359488\tBest loss: 1.359488\tAccuracy: 90.65%\n",
      "221\tValidation loss: 1.359432\tBest loss: 1.359432\tAccuracy: 90.65%\n",
      "222\tValidation loss: 1.359386\tBest loss: 1.359386\tAccuracy: 90.65%\n",
      "223\tValidation loss: 1.359340\tBest loss: 1.359340\tAccuracy: 90.65%\n",
      "224\tValidation loss: 1.359300\tBest loss: 1.359300\tAccuracy: 90.65%\n",
      "225\tValidation loss: 1.359260\tBest loss: 1.359260\tAccuracy: 90.65%\n",
      "226\tValidation loss: 1.359232\tBest loss: 1.359232\tAccuracy: 90.65%\n",
      "227\tValidation loss: 1.359200\tBest loss: 1.359200\tAccuracy: 90.65%\n",
      "228\tValidation loss: 1.359150\tBest loss: 1.359150\tAccuracy: 90.65%\n",
      "229\tValidation loss: 1.359113\tBest loss: 1.359113\tAccuracy: 90.65%\n",
      "230\tValidation loss: 1.359070\tBest loss: 1.359070\tAccuracy: 90.65%\n",
      "231\tValidation loss: 1.359007\tBest loss: 1.359007\tAccuracy: 90.65%\n",
      "232\tValidation loss: 1.358955\tBest loss: 1.358955\tAccuracy: 90.65%\n",
      "233\tValidation loss: 1.358946\tBest loss: 1.358946\tAccuracy: 90.65%\n",
      "234\tValidation loss: 1.358916\tBest loss: 1.358916\tAccuracy: 90.65%\n",
      "235\tValidation loss: 1.358918\tBest loss: 1.358916\tAccuracy: 90.65%\n",
      "236\tValidation loss: 1.358853\tBest loss: 1.358853\tAccuracy: 90.65%\n",
      "237\tValidation loss: 1.358815\tBest loss: 1.358815\tAccuracy: 90.65%\n",
      "238\tValidation loss: 1.358809\tBest loss: 1.358809\tAccuracy: 90.65%\n",
      "239\tValidation loss: 1.358747\tBest loss: 1.358747\tAccuracy: 90.65%\n",
      "240\tValidation loss: 1.358672\tBest loss: 1.358672\tAccuracy: 90.65%\n",
      "241\tValidation loss: 1.358639\tBest loss: 1.358639\tAccuracy: 90.65%\n",
      "242\tValidation loss: 1.358584\tBest loss: 1.358584\tAccuracy: 90.65%\n",
      "243\tValidation loss: 1.358527\tBest loss: 1.358527\tAccuracy: 90.65%\n",
      "244\tValidation loss: 1.358479\tBest loss: 1.358479\tAccuracy: 90.65%\n",
      "245\tValidation loss: 1.358430\tBest loss: 1.358430\tAccuracy: 90.65%\n",
      "246\tValidation loss: 1.358400\tBest loss: 1.358400\tAccuracy: 90.65%\n",
      "247\tValidation loss: 1.358355\tBest loss: 1.358355\tAccuracy: 90.65%\n",
      "248\tValidation loss: 1.358314\tBest loss: 1.358314\tAccuracy: 90.65%\n",
      "249\tValidation loss: 1.358310\tBest loss: 1.358310\tAccuracy: 90.65%\n",
      "250\tValidation loss: 1.358235\tBest loss: 1.358235\tAccuracy: 90.65%\n",
      "251\tValidation loss: 1.358179\tBest loss: 1.358179\tAccuracy: 90.65%\n",
      "252\tValidation loss: 1.358171\tBest loss: 1.358171\tAccuracy: 90.65%\n",
      "253\tValidation loss: 1.358155\tBest loss: 1.358155\tAccuracy: 90.65%\n",
      "254\tValidation loss: 1.358109\tBest loss: 1.358109\tAccuracy: 90.65%\n",
      "255\tValidation loss: 1.358063\tBest loss: 1.358063\tAccuracy: 90.65%\n",
      "256\tValidation loss: 1.357976\tBest loss: 1.357976\tAccuracy: 90.65%\n",
      "257\tValidation loss: 1.357931\tBest loss: 1.357931\tAccuracy: 90.65%\n",
      "258\tValidation loss: 1.357858\tBest loss: 1.357858\tAccuracy: 90.65%\n",
      "259\tValidation loss: 1.357819\tBest loss: 1.357819\tAccuracy: 90.65%\n",
      "260\tValidation loss: 1.357803\tBest loss: 1.357803\tAccuracy: 90.65%\n",
      "261\tValidation loss: 1.357745\tBest loss: 1.357745\tAccuracy: 90.65%\n",
      "262\tValidation loss: 1.357703\tBest loss: 1.357703\tAccuracy: 90.65%\n",
      "263\tValidation loss: 1.357672\tBest loss: 1.357672\tAccuracy: 90.65%\n",
      "264\tValidation loss: 1.357631\tBest loss: 1.357631\tAccuracy: 90.65%\n",
      "265\tValidation loss: 1.357593\tBest loss: 1.357593\tAccuracy: 90.65%\n",
      "266\tValidation loss: 1.357564\tBest loss: 1.357564\tAccuracy: 90.65%\n",
      "267\tValidation loss: 1.357527\tBest loss: 1.357527\tAccuracy: 90.65%\n",
      "268\tValidation loss: 1.357511\tBest loss: 1.357511\tAccuracy: 90.65%\n",
      "269\tValidation loss: 1.357448\tBest loss: 1.357448\tAccuracy: 90.65%\n",
      "270\tValidation loss: 1.357449\tBest loss: 1.357448\tAccuracy: 90.65%\n",
      "271\tValidation loss: 1.357415\tBest loss: 1.357415\tAccuracy: 90.65%\n",
      "272\tValidation loss: 1.357349\tBest loss: 1.357349\tAccuracy: 90.65%\n",
      "273\tValidation loss: 1.357305\tBest loss: 1.357305\tAccuracy: 90.65%\n",
      "274\tValidation loss: 1.357242\tBest loss: 1.357242\tAccuracy: 90.65%\n",
      "275\tValidation loss: 1.357188\tBest loss: 1.357188\tAccuracy: 90.65%\n",
      "276\tValidation loss: 1.357169\tBest loss: 1.357169\tAccuracy: 90.65%\n",
      "277\tValidation loss: 1.357125\tBest loss: 1.357125\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\tValidation loss: 1.357075\tBest loss: 1.357075\tAccuracy: 90.65%\n",
      "279\tValidation loss: 1.357073\tBest loss: 1.357073\tAccuracy: 90.65%\n",
      "280\tValidation loss: 1.357019\tBest loss: 1.357019\tAccuracy: 90.65%\n",
      "281\tValidation loss: 1.356971\tBest loss: 1.356971\tAccuracy: 90.65%\n",
      "282\tValidation loss: 1.356918\tBest loss: 1.356918\tAccuracy: 90.65%\n",
      "283\tValidation loss: 1.356889\tBest loss: 1.356889\tAccuracy: 90.65%\n",
      "284\tValidation loss: 1.356828\tBest loss: 1.356828\tAccuracy: 90.65%\n",
      "285\tValidation loss: 1.356768\tBest loss: 1.356768\tAccuracy: 90.65%\n",
      "286\tValidation loss: 1.356750\tBest loss: 1.356750\tAccuracy: 90.65%\n",
      "287\tValidation loss: 1.356731\tBest loss: 1.356731\tAccuracy: 90.65%\n",
      "288\tValidation loss: 1.356692\tBest loss: 1.356692\tAccuracy: 90.65%\n",
      "289\tValidation loss: 1.356651\tBest loss: 1.356651\tAccuracy: 90.65%\n",
      "290\tValidation loss: 1.356634\tBest loss: 1.356634\tAccuracy: 90.65%\n",
      "291\tValidation loss: 1.356577\tBest loss: 1.356577\tAccuracy: 90.65%\n",
      "292\tValidation loss: 1.356494\tBest loss: 1.356494\tAccuracy: 90.65%\n",
      "293\tValidation loss: 1.356450\tBest loss: 1.356450\tAccuracy: 90.65%\n",
      "294\tValidation loss: 1.356451\tBest loss: 1.356450\tAccuracy: 90.65%\n",
      "295\tValidation loss: 1.356416\tBest loss: 1.356416\tAccuracy: 90.65%\n",
      "296\tValidation loss: 1.356352\tBest loss: 1.356352\tAccuracy: 90.65%\n",
      "297\tValidation loss: 1.356302\tBest loss: 1.356302\tAccuracy: 90.65%\n",
      "298\tValidation loss: 1.356250\tBest loss: 1.356250\tAccuracy: 90.65%\n",
      "299\tValidation loss: 1.356214\tBest loss: 1.356214\tAccuracy: 90.65%\n",
      "300\tValidation loss: 1.356166\tBest loss: 1.356166\tAccuracy: 90.65%\n",
      "301\tValidation loss: 1.356124\tBest loss: 1.356124\tAccuracy: 90.65%\n",
      "302\tValidation loss: 1.356100\tBest loss: 1.356100\tAccuracy: 90.65%\n",
      "303\tValidation loss: 1.356049\tBest loss: 1.356049\tAccuracy: 90.65%\n",
      "304\tValidation loss: 1.356008\tBest loss: 1.356008\tAccuracy: 90.65%\n",
      "305\tValidation loss: 1.355963\tBest loss: 1.355963\tAccuracy: 90.65%\n",
      "306\tValidation loss: 1.355914\tBest loss: 1.355914\tAccuracy: 90.65%\n",
      "307\tValidation loss: 1.355873\tBest loss: 1.355873\tAccuracy: 90.65%\n",
      "308\tValidation loss: 1.355815\tBest loss: 1.355815\tAccuracy: 90.65%\n",
      "309\tValidation loss: 1.355787\tBest loss: 1.355787\tAccuracy: 90.65%\n",
      "310\tValidation loss: 1.355756\tBest loss: 1.355756\tAccuracy: 90.65%\n",
      "311\tValidation loss: 1.355725\tBest loss: 1.355725\tAccuracy: 90.65%\n",
      "312\tValidation loss: 1.355669\tBest loss: 1.355669\tAccuracy: 90.65%\n",
      "313\tValidation loss: 1.355616\tBest loss: 1.355616\tAccuracy: 90.65%\n",
      "314\tValidation loss: 1.355590\tBest loss: 1.355590\tAccuracy: 90.65%\n",
      "315\tValidation loss: 1.355550\tBest loss: 1.355550\tAccuracy: 90.65%\n",
      "316\tValidation loss: 1.355505\tBest loss: 1.355505\tAccuracy: 90.65%\n",
      "317\tValidation loss: 1.355484\tBest loss: 1.355484\tAccuracy: 90.65%\n",
      "318\tValidation loss: 1.355469\tBest loss: 1.355469\tAccuracy: 90.65%\n",
      "319\tValidation loss: 1.355430\tBest loss: 1.355430\tAccuracy: 90.65%\n",
      "320\tValidation loss: 1.355397\tBest loss: 1.355397\tAccuracy: 90.65%\n",
      "321\tValidation loss: 1.355393\tBest loss: 1.355393\tAccuracy: 90.65%\n",
      "322\tValidation loss: 1.355369\tBest loss: 1.355369\tAccuracy: 90.65%\n",
      "323\tValidation loss: 1.355339\tBest loss: 1.355339\tAccuracy: 90.65%\n",
      "324\tValidation loss: 1.355298\tBest loss: 1.355298\tAccuracy: 90.65%\n",
      "325\tValidation loss: 1.355267\tBest loss: 1.355267\tAccuracy: 90.65%\n",
      "326\tValidation loss: 1.355243\tBest loss: 1.355243\tAccuracy: 90.65%\n",
      "327\tValidation loss: 1.355195\tBest loss: 1.355195\tAccuracy: 90.65%\n",
      "328\tValidation loss: 1.355158\tBest loss: 1.355158\tAccuracy: 90.65%\n",
      "329\tValidation loss: 1.355134\tBest loss: 1.355134\tAccuracy: 90.65%\n",
      "330\tValidation loss: 1.355120\tBest loss: 1.355120\tAccuracy: 90.65%\n",
      "331\tValidation loss: 1.355089\tBest loss: 1.355089\tAccuracy: 90.65%\n",
      "332\tValidation loss: 1.355045\tBest loss: 1.355045\tAccuracy: 90.65%\n",
      "333\tValidation loss: 1.355021\tBest loss: 1.355021\tAccuracy: 90.65%\n",
      "334\tValidation loss: 1.355004\tBest loss: 1.355004\tAccuracy: 90.65%\n",
      "335\tValidation loss: 1.354969\tBest loss: 1.354969\tAccuracy: 90.65%\n",
      "336\tValidation loss: 1.354930\tBest loss: 1.354930\tAccuracy: 90.65%\n",
      "337\tValidation loss: 1.354898\tBest loss: 1.354898\tAccuracy: 90.65%\n",
      "338\tValidation loss: 1.354861\tBest loss: 1.354861\tAccuracy: 90.65%\n",
      "339\tValidation loss: 1.354822\tBest loss: 1.354822\tAccuracy: 90.65%\n",
      "340\tValidation loss: 1.354781\tBest loss: 1.354781\tAccuracy: 90.65%\n",
      "341\tValidation loss: 1.354757\tBest loss: 1.354757\tAccuracy: 90.65%\n",
      "342\tValidation loss: 1.354709\tBest loss: 1.354709\tAccuracy: 90.65%\n",
      "343\tValidation loss: 1.354680\tBest loss: 1.354680\tAccuracy: 90.65%\n",
      "344\tValidation loss: 1.354670\tBest loss: 1.354670\tAccuracy: 90.65%\n",
      "345\tValidation loss: 1.354645\tBest loss: 1.354645\tAccuracy: 90.65%\n",
      "346\tValidation loss: 1.354612\tBest loss: 1.354612\tAccuracy: 90.65%\n",
      "347\tValidation loss: 1.354573\tBest loss: 1.354573\tAccuracy: 90.65%\n",
      "348\tValidation loss: 1.354526\tBest loss: 1.354526\tAccuracy: 90.65%\n",
      "349\tValidation loss: 1.354512\tBest loss: 1.354512\tAccuracy: 90.65%\n",
      "350\tValidation loss: 1.354487\tBest loss: 1.354487\tAccuracy: 90.65%\n",
      "351\tValidation loss: 1.354435\tBest loss: 1.354435\tAccuracy: 90.65%\n",
      "352\tValidation loss: 1.354397\tBest loss: 1.354397\tAccuracy: 90.65%\n",
      "353\tValidation loss: 1.354364\tBest loss: 1.354364\tAccuracy: 90.65%\n",
      "354\tValidation loss: 1.354362\tBest loss: 1.354362\tAccuracy: 90.65%\n",
      "355\tValidation loss: 1.354316\tBest loss: 1.354316\tAccuracy: 90.65%\n",
      "356\tValidation loss: 1.354275\tBest loss: 1.354275\tAccuracy: 90.65%\n",
      "357\tValidation loss: 1.354271\tBest loss: 1.354271\tAccuracy: 90.65%\n",
      "358\tValidation loss: 1.354236\tBest loss: 1.354236\tAccuracy: 90.65%\n",
      "359\tValidation loss: 1.354187\tBest loss: 1.354187\tAccuracy: 90.65%\n",
      "360\tValidation loss: 1.354172\tBest loss: 1.354172\tAccuracy: 90.65%\n",
      "361\tValidation loss: 1.354152\tBest loss: 1.354152\tAccuracy: 90.65%\n",
      "362\tValidation loss: 1.354127\tBest loss: 1.354127\tAccuracy: 90.65%\n",
      "363\tValidation loss: 1.354087\tBest loss: 1.354087\tAccuracy: 90.65%\n",
      "364\tValidation loss: 1.354036\tBest loss: 1.354036\tAccuracy: 90.65%\n",
      "365\tValidation loss: 1.354016\tBest loss: 1.354016\tAccuracy: 90.65%\n",
      "366\tValidation loss: 1.353946\tBest loss: 1.353946\tAccuracy: 90.65%\n",
      "367\tValidation loss: 1.353945\tBest loss: 1.353945\tAccuracy: 90.65%\n",
      "368\tValidation loss: 1.353909\tBest loss: 1.353909\tAccuracy: 90.65%\n",
      "369\tValidation loss: 1.353862\tBest loss: 1.353862\tAccuracy: 90.65%\n",
      "370\tValidation loss: 1.353846\tBest loss: 1.353846\tAccuracy: 90.65%\n",
      "371\tValidation loss: 1.353816\tBest loss: 1.353816\tAccuracy: 90.65%\n",
      "372\tValidation loss: 1.353787\tBest loss: 1.353787\tAccuracy: 90.65%\n",
      "373\tValidation loss: 1.353734\tBest loss: 1.353734\tAccuracy: 90.65%\n",
      "374\tValidation loss: 1.353717\tBest loss: 1.353717\tAccuracy: 90.65%\n",
      "375\tValidation loss: 1.353707\tBest loss: 1.353707\tAccuracy: 90.65%\n",
      "376\tValidation loss: 1.353700\tBest loss: 1.353700\tAccuracy: 90.65%\n",
      "377\tValidation loss: 1.353673\tBest loss: 1.353673\tAccuracy: 90.65%\n",
      "378\tValidation loss: 1.353634\tBest loss: 1.353634\tAccuracy: 90.65%\n",
      "379\tValidation loss: 1.353605\tBest loss: 1.353605\tAccuracy: 90.65%\n",
      "380\tValidation loss: 1.353586\tBest loss: 1.353586\tAccuracy: 90.65%\n",
      "381\tValidation loss: 1.353554\tBest loss: 1.353554\tAccuracy: 90.65%\n",
      "382\tValidation loss: 1.353519\tBest loss: 1.353519\tAccuracy: 90.65%\n",
      "383\tValidation loss: 1.353495\tBest loss: 1.353495\tAccuracy: 90.65%\n",
      "384\tValidation loss: 1.353483\tBest loss: 1.353483\tAccuracy: 90.65%\n",
      "385\tValidation loss: 1.353460\tBest loss: 1.353460\tAccuracy: 90.65%\n",
      "386\tValidation loss: 1.353435\tBest loss: 1.353435\tAccuracy: 90.65%\n",
      "387\tValidation loss: 1.353402\tBest loss: 1.353402\tAccuracy: 90.65%\n",
      "388\tValidation loss: 1.353372\tBest loss: 1.353372\tAccuracy: 90.65%\n",
      "389\tValidation loss: 1.353333\tBest loss: 1.353333\tAccuracy: 90.65%\n",
      "390\tValidation loss: 1.353293\tBest loss: 1.353293\tAccuracy: 90.65%\n",
      "391\tValidation loss: 1.353257\tBest loss: 1.353257\tAccuracy: 90.65%\n",
      "392\tValidation loss: 1.353236\tBest loss: 1.353236\tAccuracy: 90.65%\n",
      "393\tValidation loss: 1.353213\tBest loss: 1.353213\tAccuracy: 90.65%\n",
      "394\tValidation loss: 1.353169\tBest loss: 1.353169\tAccuracy: 90.65%\n",
      "395\tValidation loss: 1.353164\tBest loss: 1.353164\tAccuracy: 90.65%\n",
      "396\tValidation loss: 1.353144\tBest loss: 1.353144\tAccuracy: 90.65%\n",
      "397\tValidation loss: 1.353113\tBest loss: 1.353113\tAccuracy: 90.65%\n",
      "398\tValidation loss: 1.353081\tBest loss: 1.353081\tAccuracy: 90.65%\n",
      "399\tValidation loss: 1.353028\tBest loss: 1.353028\tAccuracy: 90.65%\n",
      "400\tValidation loss: 1.352990\tBest loss: 1.352990\tAccuracy: 90.65%\n",
      "401\tValidation loss: 1.352968\tBest loss: 1.352968\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\tValidation loss: 1.352944\tBest loss: 1.352944\tAccuracy: 90.65%\n",
      "403\tValidation loss: 1.352894\tBest loss: 1.352894\tAccuracy: 90.65%\n",
      "404\tValidation loss: 1.352873\tBest loss: 1.352873\tAccuracy: 90.65%\n",
      "405\tValidation loss: 1.352850\tBest loss: 1.352850\tAccuracy: 90.65%\n",
      "406\tValidation loss: 1.352811\tBest loss: 1.352811\tAccuracy: 90.65%\n",
      "407\tValidation loss: 1.352799\tBest loss: 1.352799\tAccuracy: 90.65%\n",
      "408\tValidation loss: 1.352787\tBest loss: 1.352787\tAccuracy: 90.65%\n",
      "409\tValidation loss: 1.352768\tBest loss: 1.352768\tAccuracy: 90.65%\n",
      "410\tValidation loss: 1.352738\tBest loss: 1.352738\tAccuracy: 90.65%\n",
      "411\tValidation loss: 1.352715\tBest loss: 1.352715\tAccuracy: 90.65%\n",
      "412\tValidation loss: 1.352699\tBest loss: 1.352699\tAccuracy: 90.65%\n",
      "413\tValidation loss: 1.352649\tBest loss: 1.352649\tAccuracy: 90.65%\n",
      "414\tValidation loss: 1.352612\tBest loss: 1.352612\tAccuracy: 90.65%\n",
      "415\tValidation loss: 1.352592\tBest loss: 1.352592\tAccuracy: 90.65%\n",
      "416\tValidation loss: 1.352552\tBest loss: 1.352552\tAccuracy: 90.65%\n",
      "417\tValidation loss: 1.352526\tBest loss: 1.352526\tAccuracy: 90.65%\n",
      "418\tValidation loss: 1.352502\tBest loss: 1.352502\tAccuracy: 90.65%\n",
      "419\tValidation loss: 1.352470\tBest loss: 1.352470\tAccuracy: 90.65%\n",
      "420\tValidation loss: 1.352439\tBest loss: 1.352439\tAccuracy: 90.65%\n",
      "421\tValidation loss: 1.352405\tBest loss: 1.352405\tAccuracy: 90.65%\n",
      "422\tValidation loss: 1.352367\tBest loss: 1.352367\tAccuracy: 90.65%\n",
      "423\tValidation loss: 1.352345\tBest loss: 1.352345\tAccuracy: 90.65%\n",
      "424\tValidation loss: 1.352332\tBest loss: 1.352332\tAccuracy: 90.65%\n",
      "425\tValidation loss: 1.352316\tBest loss: 1.352316\tAccuracy: 90.65%\n",
      "426\tValidation loss: 1.352276\tBest loss: 1.352276\tAccuracy: 90.65%\n",
      "427\tValidation loss: 1.352251\tBest loss: 1.352251\tAccuracy: 90.65%\n",
      "428\tValidation loss: 1.352198\tBest loss: 1.352198\tAccuracy: 90.65%\n",
      "429\tValidation loss: 1.352175\tBest loss: 1.352175\tAccuracy: 90.65%\n",
      "430\tValidation loss: 1.352174\tBest loss: 1.352174\tAccuracy: 90.65%\n",
      "431\tValidation loss: 1.352159\tBest loss: 1.352159\tAccuracy: 90.65%\n",
      "432\tValidation loss: 1.352124\tBest loss: 1.352124\tAccuracy: 90.65%\n",
      "433\tValidation loss: 1.352097\tBest loss: 1.352097\tAccuracy: 90.65%\n",
      "434\tValidation loss: 1.352071\tBest loss: 1.352071\tAccuracy: 90.65%\n",
      "435\tValidation loss: 1.352042\tBest loss: 1.352042\tAccuracy: 90.65%\n",
      "436\tValidation loss: 1.352009\tBest loss: 1.352009\tAccuracy: 90.65%\n",
      "437\tValidation loss: 1.352017\tBest loss: 1.352009\tAccuracy: 90.65%\n",
      "438\tValidation loss: 1.351988\tBest loss: 1.351988\tAccuracy: 90.65%\n",
      "439\tValidation loss: 1.351961\tBest loss: 1.351961\tAccuracy: 90.65%\n",
      "440\tValidation loss: 1.351942\tBest loss: 1.351942\tAccuracy: 90.65%\n",
      "441\tValidation loss: 1.351901\tBest loss: 1.351901\tAccuracy: 90.65%\n",
      "442\tValidation loss: 1.351870\tBest loss: 1.351870\tAccuracy: 90.65%\n",
      "443\tValidation loss: 1.351830\tBest loss: 1.351830\tAccuracy: 90.65%\n",
      "444\tValidation loss: 1.351819\tBest loss: 1.351819\tAccuracy: 90.65%\n",
      "445\tValidation loss: 1.351801\tBest loss: 1.351801\tAccuracy: 90.65%\n",
      "446\tValidation loss: 1.351791\tBest loss: 1.351791\tAccuracy: 90.65%\n",
      "447\tValidation loss: 1.351755\tBest loss: 1.351755\tAccuracy: 90.65%\n",
      "448\tValidation loss: 1.351729\tBest loss: 1.351729\tAccuracy: 90.65%\n",
      "449\tValidation loss: 1.351710\tBest loss: 1.351710\tAccuracy: 90.65%\n",
      "450\tValidation loss: 1.351680\tBest loss: 1.351680\tAccuracy: 90.65%\n",
      "451\tValidation loss: 1.351654\tBest loss: 1.351654\tAccuracy: 90.65%\n",
      "452\tValidation loss: 1.351627\tBest loss: 1.351627\tAccuracy: 90.65%\n",
      "453\tValidation loss: 1.351606\tBest loss: 1.351606\tAccuracy: 90.65%\n",
      "454\tValidation loss: 1.351578\tBest loss: 1.351578\tAccuracy: 90.65%\n",
      "455\tValidation loss: 1.351565\tBest loss: 1.351565\tAccuracy: 90.65%\n",
      "456\tValidation loss: 1.351531\tBest loss: 1.351531\tAccuracy: 90.65%\n",
      "457\tValidation loss: 1.351492\tBest loss: 1.351492\tAccuracy: 90.65%\n",
      "458\tValidation loss: 1.351452\tBest loss: 1.351452\tAccuracy: 90.65%\n",
      "459\tValidation loss: 1.351431\tBest loss: 1.351431\tAccuracy: 90.65%\n",
      "460\tValidation loss: 1.351409\tBest loss: 1.351409\tAccuracy: 90.65%\n",
      "461\tValidation loss: 1.351378\tBest loss: 1.351378\tAccuracy: 90.65%\n",
      "462\tValidation loss: 1.351333\tBest loss: 1.351333\tAccuracy: 90.65%\n",
      "463\tValidation loss: 1.351335\tBest loss: 1.351333\tAccuracy: 90.65%\n",
      "464\tValidation loss: 1.351302\tBest loss: 1.351302\tAccuracy: 90.65%\n",
      "465\tValidation loss: 1.351277\tBest loss: 1.351277\tAccuracy: 90.65%\n",
      "466\tValidation loss: 1.351258\tBest loss: 1.351258\tAccuracy: 90.65%\n",
      "467\tValidation loss: 1.351244\tBest loss: 1.351244\tAccuracy: 90.65%\n",
      "468\tValidation loss: 1.351233\tBest loss: 1.351233\tAccuracy: 90.65%\n",
      "469\tValidation loss: 1.351217\tBest loss: 1.351217\tAccuracy: 90.65%\n",
      "470\tValidation loss: 1.351196\tBest loss: 1.351196\tAccuracy: 90.65%\n",
      "471\tValidation loss: 1.351167\tBest loss: 1.351167\tAccuracy: 90.65%\n",
      "472\tValidation loss: 1.351149\tBest loss: 1.351149\tAccuracy: 90.65%\n",
      "473\tValidation loss: 1.351125\tBest loss: 1.351125\tAccuracy: 90.65%\n",
      "474\tValidation loss: 1.351109\tBest loss: 1.351109\tAccuracy: 90.65%\n",
      "475\tValidation loss: 1.351081\tBest loss: 1.351081\tAccuracy: 90.65%\n",
      "476\tValidation loss: 1.351061\tBest loss: 1.351061\tAccuracy: 90.65%\n",
      "477\tValidation loss: 1.351040\tBest loss: 1.351040\tAccuracy: 90.65%\n",
      "478\tValidation loss: 1.351011\tBest loss: 1.351011\tAccuracy: 90.65%\n",
      "479\tValidation loss: 1.350990\tBest loss: 1.350990\tAccuracy: 90.65%\n",
      "480\tValidation loss: 1.350982\tBest loss: 1.350982\tAccuracy: 90.65%\n",
      "481\tValidation loss: 1.350967\tBest loss: 1.350967\tAccuracy: 90.65%\n",
      "482\tValidation loss: 1.350944\tBest loss: 1.350944\tAccuracy: 90.65%\n",
      "483\tValidation loss: 1.350912\tBest loss: 1.350912\tAccuracy: 90.65%\n",
      "484\tValidation loss: 1.350886\tBest loss: 1.350886\tAccuracy: 90.65%\n",
      "485\tValidation loss: 1.350881\tBest loss: 1.350881\tAccuracy: 90.65%\n",
      "486\tValidation loss: 1.350846\tBest loss: 1.350846\tAccuracy: 90.65%\n",
      "487\tValidation loss: 1.350815\tBest loss: 1.350815\tAccuracy: 90.65%\n",
      "488\tValidation loss: 1.350784\tBest loss: 1.350784\tAccuracy: 90.65%\n",
      "489\tValidation loss: 1.350765\tBest loss: 1.350765\tAccuracy: 90.65%\n",
      "490\tValidation loss: 1.350725\tBest loss: 1.350725\tAccuracy: 90.65%\n",
      "491\tValidation loss: 1.350706\tBest loss: 1.350706\tAccuracy: 90.65%\n",
      "492\tValidation loss: 1.350664\tBest loss: 1.350664\tAccuracy: 90.65%\n",
      "493\tValidation loss: 1.350654\tBest loss: 1.350654\tAccuracy: 90.65%\n",
      "494\tValidation loss: 1.350630\tBest loss: 1.350630\tAccuracy: 90.65%\n",
      "495\tValidation loss: 1.350587\tBest loss: 1.350587\tAccuracy: 90.65%\n",
      "496\tValidation loss: 1.350575\tBest loss: 1.350575\tAccuracy: 90.65%\n",
      "497\tValidation loss: 1.350550\tBest loss: 1.350550\tAccuracy: 90.65%\n",
      "498\tValidation loss: 1.350527\tBest loss: 1.350527\tAccuracy: 90.65%\n",
      "499\tValidation loss: 1.350499\tBest loss: 1.350499\tAccuracy: 90.65%\n",
      "500\tValidation loss: 1.350463\tBest loss: 1.350463\tAccuracy: 90.65%\n",
      "501\tValidation loss: 1.350444\tBest loss: 1.350444\tAccuracy: 90.65%\n",
      "502\tValidation loss: 1.350421\tBest loss: 1.350421\tAccuracy: 90.65%\n",
      "503\tValidation loss: 1.350406\tBest loss: 1.350406\tAccuracy: 90.65%\n",
      "504\tValidation loss: 1.350378\tBest loss: 1.350378\tAccuracy: 90.65%\n",
      "505\tValidation loss: 1.350354\tBest loss: 1.350354\tAccuracy: 90.65%\n",
      "506\tValidation loss: 1.350331\tBest loss: 1.350331\tAccuracy: 90.65%\n",
      "507\tValidation loss: 1.350297\tBest loss: 1.350297\tAccuracy: 90.65%\n",
      "508\tValidation loss: 1.350271\tBest loss: 1.350271\tAccuracy: 90.65%\n",
      "509\tValidation loss: 1.350259\tBest loss: 1.350259\tAccuracy: 90.65%\n",
      "510\tValidation loss: 1.350245\tBest loss: 1.350245\tAccuracy: 90.65%\n",
      "511\tValidation loss: 1.350213\tBest loss: 1.350213\tAccuracy: 90.65%\n",
      "512\tValidation loss: 1.350184\tBest loss: 1.350184\tAccuracy: 90.65%\n",
      "513\tValidation loss: 1.350172\tBest loss: 1.350172\tAccuracy: 90.65%\n",
      "514\tValidation loss: 1.350157\tBest loss: 1.350157\tAccuracy: 90.65%\n",
      "515\tValidation loss: 1.350136\tBest loss: 1.350136\tAccuracy: 90.65%\n",
      "516\tValidation loss: 1.350104\tBest loss: 1.350104\tAccuracy: 90.65%\n",
      "517\tValidation loss: 1.350088\tBest loss: 1.350088\tAccuracy: 90.65%\n",
      "518\tValidation loss: 1.350049\tBest loss: 1.350049\tAccuracy: 90.65%\n",
      "519\tValidation loss: 1.350011\tBest loss: 1.350011\tAccuracy: 90.65%\n",
      "520\tValidation loss: 1.349992\tBest loss: 1.349992\tAccuracy: 90.65%\n",
      "521\tValidation loss: 1.349979\tBest loss: 1.349979\tAccuracy: 90.65%\n",
      "522\tValidation loss: 1.349957\tBest loss: 1.349957\tAccuracy: 90.65%\n",
      "523\tValidation loss: 1.349934\tBest loss: 1.349934\tAccuracy: 90.65%\n",
      "524\tValidation loss: 1.349896\tBest loss: 1.349896\tAccuracy: 90.65%\n",
      "525\tValidation loss: 1.349883\tBest loss: 1.349883\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\tValidation loss: 1.349848\tBest loss: 1.349848\tAccuracy: 90.65%\n",
      "527\tValidation loss: 1.349837\tBest loss: 1.349837\tAccuracy: 90.65%\n",
      "528\tValidation loss: 1.349818\tBest loss: 1.349818\tAccuracy: 90.65%\n",
      "529\tValidation loss: 1.349789\tBest loss: 1.349789\tAccuracy: 90.65%\n",
      "530\tValidation loss: 1.349775\tBest loss: 1.349775\tAccuracy: 90.65%\n",
      "531\tValidation loss: 1.349759\tBest loss: 1.349759\tAccuracy: 90.65%\n",
      "532\tValidation loss: 1.349737\tBest loss: 1.349737\tAccuracy: 90.65%\n",
      "533\tValidation loss: 1.349733\tBest loss: 1.349733\tAccuracy: 90.65%\n",
      "534\tValidation loss: 1.349718\tBest loss: 1.349718\tAccuracy: 90.65%\n",
      "535\tValidation loss: 1.349683\tBest loss: 1.349683\tAccuracy: 90.65%\n",
      "536\tValidation loss: 1.349665\tBest loss: 1.349665\tAccuracy: 90.65%\n",
      "537\tValidation loss: 1.349635\tBest loss: 1.349635\tAccuracy: 90.65%\n",
      "538\tValidation loss: 1.349628\tBest loss: 1.349628\tAccuracy: 90.65%\n",
      "539\tValidation loss: 1.349601\tBest loss: 1.349601\tAccuracy: 90.65%\n",
      "540\tValidation loss: 1.349577\tBest loss: 1.349577\tAccuracy: 90.65%\n",
      "541\tValidation loss: 1.349554\tBest loss: 1.349554\tAccuracy: 90.65%\n",
      "542\tValidation loss: 1.349527\tBest loss: 1.349527\tAccuracy: 90.65%\n",
      "543\tValidation loss: 1.349505\tBest loss: 1.349505\tAccuracy: 90.65%\n",
      "544\tValidation loss: 1.349489\tBest loss: 1.349489\tAccuracy: 90.65%\n",
      "545\tValidation loss: 1.349465\tBest loss: 1.349465\tAccuracy: 90.65%\n",
      "546\tValidation loss: 1.349448\tBest loss: 1.349448\tAccuracy: 90.65%\n",
      "547\tValidation loss: 1.349418\tBest loss: 1.349418\tAccuracy: 90.65%\n",
      "548\tValidation loss: 1.349416\tBest loss: 1.349416\tAccuracy: 90.65%\n",
      "549\tValidation loss: 1.349389\tBest loss: 1.349389\tAccuracy: 90.65%\n",
      "550\tValidation loss: 1.349369\tBest loss: 1.349369\tAccuracy: 90.65%\n",
      "551\tValidation loss: 1.349334\tBest loss: 1.349334\tAccuracy: 90.65%\n",
      "552\tValidation loss: 1.349313\tBest loss: 1.349313\tAccuracy: 90.65%\n",
      "553\tValidation loss: 1.349292\tBest loss: 1.349292\tAccuracy: 90.65%\n",
      "554\tValidation loss: 1.349267\tBest loss: 1.349267\tAccuracy: 90.65%\n",
      "555\tValidation loss: 1.349268\tBest loss: 1.349267\tAccuracy: 90.65%\n",
      "556\tValidation loss: 1.349229\tBest loss: 1.349229\tAccuracy: 90.65%\n",
      "557\tValidation loss: 1.349221\tBest loss: 1.349221\tAccuracy: 90.65%\n",
      "558\tValidation loss: 1.349189\tBest loss: 1.349189\tAccuracy: 90.65%\n",
      "559\tValidation loss: 1.349179\tBest loss: 1.349179\tAccuracy: 90.65%\n",
      "560\tValidation loss: 1.349157\tBest loss: 1.349157\tAccuracy: 90.65%\n",
      "561\tValidation loss: 1.349137\tBest loss: 1.349137\tAccuracy: 90.65%\n",
      "562\tValidation loss: 1.349129\tBest loss: 1.349129\tAccuracy: 90.65%\n",
      "563\tValidation loss: 1.349099\tBest loss: 1.349099\tAccuracy: 90.65%\n",
      "564\tValidation loss: 1.349082\tBest loss: 1.349082\tAccuracy: 90.65%\n",
      "565\tValidation loss: 1.349065\tBest loss: 1.349065\tAccuracy: 91.37%\n",
      "566\tValidation loss: 1.349051\tBest loss: 1.349051\tAccuracy: 91.37%\n",
      "567\tValidation loss: 1.349024\tBest loss: 1.349024\tAccuracy: 91.37%\n",
      "568\tValidation loss: 1.349002\tBest loss: 1.349002\tAccuracy: 91.37%\n",
      "569\tValidation loss: 1.348983\tBest loss: 1.348983\tAccuracy: 91.37%\n",
      "570\tValidation loss: 1.348964\tBest loss: 1.348964\tAccuracy: 91.37%\n",
      "571\tValidation loss: 1.348924\tBest loss: 1.348924\tAccuracy: 91.37%\n",
      "572\tValidation loss: 1.348913\tBest loss: 1.348913\tAccuracy: 91.37%\n",
      "573\tValidation loss: 1.348896\tBest loss: 1.348896\tAccuracy: 91.37%\n",
      "574\tValidation loss: 1.348881\tBest loss: 1.348881\tAccuracy: 91.37%\n",
      "575\tValidation loss: 1.348856\tBest loss: 1.348856\tAccuracy: 91.37%\n",
      "576\tValidation loss: 1.348849\tBest loss: 1.348849\tAccuracy: 91.37%\n",
      "577\tValidation loss: 1.348830\tBest loss: 1.348830\tAccuracy: 91.37%\n",
      "578\tValidation loss: 1.348818\tBest loss: 1.348818\tAccuracy: 91.37%\n",
      "579\tValidation loss: 1.348792\tBest loss: 1.348792\tAccuracy: 91.37%\n",
      "580\tValidation loss: 1.348772\tBest loss: 1.348772\tAccuracy: 91.37%\n",
      "581\tValidation loss: 1.348758\tBest loss: 1.348758\tAccuracy: 91.37%\n",
      "582\tValidation loss: 1.348752\tBest loss: 1.348752\tAccuracy: 91.37%\n",
      "583\tValidation loss: 1.348738\tBest loss: 1.348738\tAccuracy: 91.37%\n",
      "584\tValidation loss: 1.348714\tBest loss: 1.348714\tAccuracy: 91.37%\n",
      "585\tValidation loss: 1.348700\tBest loss: 1.348700\tAccuracy: 91.37%\n",
      "586\tValidation loss: 1.348699\tBest loss: 1.348699\tAccuracy: 91.37%\n",
      "587\tValidation loss: 1.348677\tBest loss: 1.348677\tAccuracy: 91.37%\n",
      "588\tValidation loss: 1.348656\tBest loss: 1.348656\tAccuracy: 91.37%\n",
      "589\tValidation loss: 1.348634\tBest loss: 1.348634\tAccuracy: 91.37%\n",
      "590\tValidation loss: 1.348626\tBest loss: 1.348626\tAccuracy: 91.37%\n",
      "591\tValidation loss: 1.348602\tBest loss: 1.348602\tAccuracy: 91.37%\n",
      "592\tValidation loss: 1.348574\tBest loss: 1.348574\tAccuracy: 91.37%\n",
      "593\tValidation loss: 1.348547\tBest loss: 1.348547\tAccuracy: 91.37%\n",
      "594\tValidation loss: 1.348541\tBest loss: 1.348541\tAccuracy: 91.37%\n",
      "595\tValidation loss: 1.348529\tBest loss: 1.348529\tAccuracy: 91.37%\n",
      "596\tValidation loss: 1.348513\tBest loss: 1.348513\tAccuracy: 91.37%\n",
      "597\tValidation loss: 1.348505\tBest loss: 1.348505\tAccuracy: 91.37%\n",
      "598\tValidation loss: 1.348486\tBest loss: 1.348486\tAccuracy: 91.37%\n",
      "599\tValidation loss: 1.348473\tBest loss: 1.348473\tAccuracy: 91.37%\n",
      "600\tValidation loss: 1.348452\tBest loss: 1.348452\tAccuracy: 91.37%\n",
      "601\tValidation loss: 1.348429\tBest loss: 1.348429\tAccuracy: 91.37%\n",
      "602\tValidation loss: 1.348402\tBest loss: 1.348402\tAccuracy: 91.37%\n",
      "603\tValidation loss: 1.348387\tBest loss: 1.348387\tAccuracy: 91.37%\n",
      "604\tValidation loss: 1.348368\tBest loss: 1.348368\tAccuracy: 91.37%\n",
      "605\tValidation loss: 1.348344\tBest loss: 1.348344\tAccuracy: 91.37%\n",
      "606\tValidation loss: 1.348331\tBest loss: 1.348331\tAccuracy: 91.37%\n",
      "607\tValidation loss: 1.348315\tBest loss: 1.348315\tAccuracy: 91.37%\n",
      "608\tValidation loss: 1.348313\tBest loss: 1.348313\tAccuracy: 91.37%\n",
      "609\tValidation loss: 1.348292\tBest loss: 1.348292\tAccuracy: 91.37%\n",
      "610\tValidation loss: 1.348262\tBest loss: 1.348262\tAccuracy: 91.37%\n",
      "611\tValidation loss: 1.348248\tBest loss: 1.348248\tAccuracy: 91.37%\n",
      "612\tValidation loss: 1.348221\tBest loss: 1.348221\tAccuracy: 91.37%\n",
      "613\tValidation loss: 1.348206\tBest loss: 1.348206\tAccuracy: 91.37%\n",
      "614\tValidation loss: 1.348188\tBest loss: 1.348188\tAccuracy: 91.37%\n",
      "615\tValidation loss: 1.348181\tBest loss: 1.348181\tAccuracy: 91.37%\n",
      "616\tValidation loss: 1.348152\tBest loss: 1.348152\tAccuracy: 91.37%\n",
      "617\tValidation loss: 1.348140\tBest loss: 1.348140\tAccuracy: 91.37%\n",
      "618\tValidation loss: 1.348126\tBest loss: 1.348126\tAccuracy: 91.37%\n",
      "619\tValidation loss: 1.348101\tBest loss: 1.348101\tAccuracy: 91.37%\n",
      "620\tValidation loss: 1.348078\tBest loss: 1.348078\tAccuracy: 91.37%\n",
      "621\tValidation loss: 1.348066\tBest loss: 1.348066\tAccuracy: 91.37%\n",
      "622\tValidation loss: 1.348037\tBest loss: 1.348037\tAccuracy: 91.37%\n",
      "623\tValidation loss: 1.348019\tBest loss: 1.348019\tAccuracy: 91.37%\n",
      "624\tValidation loss: 1.348001\tBest loss: 1.348001\tAccuracy: 91.37%\n",
      "625\tValidation loss: 1.347975\tBest loss: 1.347975\tAccuracy: 91.37%\n",
      "626\tValidation loss: 1.347959\tBest loss: 1.347959\tAccuracy: 91.37%\n",
      "627\tValidation loss: 1.347941\tBest loss: 1.347941\tAccuracy: 91.37%\n",
      "628\tValidation loss: 1.347916\tBest loss: 1.347916\tAccuracy: 91.37%\n",
      "629\tValidation loss: 1.347910\tBest loss: 1.347910\tAccuracy: 91.37%\n",
      "630\tValidation loss: 1.347895\tBest loss: 1.347895\tAccuracy: 91.37%\n",
      "631\tValidation loss: 1.347870\tBest loss: 1.347870\tAccuracy: 91.37%\n",
      "632\tValidation loss: 1.347857\tBest loss: 1.347857\tAccuracy: 91.37%\n",
      "633\tValidation loss: 1.347848\tBest loss: 1.347848\tAccuracy: 91.37%\n",
      "634\tValidation loss: 1.347821\tBest loss: 1.347821\tAccuracy: 91.37%\n",
      "635\tValidation loss: 1.347801\tBest loss: 1.347801\tAccuracy: 91.37%\n",
      "636\tValidation loss: 1.347793\tBest loss: 1.347793\tAccuracy: 91.37%\n",
      "637\tValidation loss: 1.347782\tBest loss: 1.347782\tAccuracy: 91.37%\n",
      "638\tValidation loss: 1.347765\tBest loss: 1.347765\tAccuracy: 91.37%\n",
      "639\tValidation loss: 1.347739\tBest loss: 1.347739\tAccuracy: 91.37%\n",
      "640\tValidation loss: 1.347720\tBest loss: 1.347720\tAccuracy: 91.37%\n",
      "641\tValidation loss: 1.347704\tBest loss: 1.347704\tAccuracy: 91.37%\n",
      "642\tValidation loss: 1.347691\tBest loss: 1.347691\tAccuracy: 91.37%\n",
      "643\tValidation loss: 1.347678\tBest loss: 1.347678\tAccuracy: 91.37%\n",
      "644\tValidation loss: 1.347670\tBest loss: 1.347670\tAccuracy: 91.37%\n",
      "645\tValidation loss: 1.347659\tBest loss: 1.347659\tAccuracy: 91.37%\n",
      "646\tValidation loss: 1.347644\tBest loss: 1.347644\tAccuracy: 91.37%\n",
      "647\tValidation loss: 1.347618\tBest loss: 1.347618\tAccuracy: 91.37%\n",
      "648\tValidation loss: 1.347601\tBest loss: 1.347601\tAccuracy: 91.37%\n",
      "649\tValidation loss: 1.347595\tBest loss: 1.347595\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\tValidation loss: 1.347579\tBest loss: 1.347579\tAccuracy: 91.37%\n",
      "651\tValidation loss: 1.347559\tBest loss: 1.347559\tAccuracy: 91.37%\n",
      "652\tValidation loss: 1.347543\tBest loss: 1.347543\tAccuracy: 91.37%\n",
      "653\tValidation loss: 1.347515\tBest loss: 1.347515\tAccuracy: 91.37%\n",
      "654\tValidation loss: 1.347493\tBest loss: 1.347493\tAccuracy: 91.37%\n",
      "655\tValidation loss: 1.347487\tBest loss: 1.347487\tAccuracy: 91.37%\n",
      "656\tValidation loss: 1.347472\tBest loss: 1.347472\tAccuracy: 91.37%\n",
      "657\tValidation loss: 1.347454\tBest loss: 1.347454\tAccuracy: 91.37%\n",
      "658\tValidation loss: 1.347434\tBest loss: 1.347434\tAccuracy: 91.37%\n",
      "659\tValidation loss: 1.347413\tBest loss: 1.347413\tAccuracy: 91.37%\n",
      "660\tValidation loss: 1.347397\tBest loss: 1.347397\tAccuracy: 91.37%\n",
      "661\tValidation loss: 1.347384\tBest loss: 1.347384\tAccuracy: 91.37%\n",
      "662\tValidation loss: 1.347367\tBest loss: 1.347367\tAccuracy: 91.37%\n",
      "663\tValidation loss: 1.347362\tBest loss: 1.347362\tAccuracy: 91.37%\n",
      "664\tValidation loss: 1.347355\tBest loss: 1.347355\tAccuracy: 91.37%\n",
      "665\tValidation loss: 1.347347\tBest loss: 1.347347\tAccuracy: 91.37%\n",
      "666\tValidation loss: 1.347323\tBest loss: 1.347323\tAccuracy: 91.37%\n",
      "667\tValidation loss: 1.347313\tBest loss: 1.347313\tAccuracy: 91.37%\n",
      "668\tValidation loss: 1.347296\tBest loss: 1.347296\tAccuracy: 91.37%\n",
      "669\tValidation loss: 1.347274\tBest loss: 1.347274\tAccuracy: 91.37%\n",
      "670\tValidation loss: 1.347250\tBest loss: 1.347250\tAccuracy: 91.37%\n",
      "671\tValidation loss: 1.347228\tBest loss: 1.347228\tAccuracy: 91.37%\n",
      "672\tValidation loss: 1.347216\tBest loss: 1.347216\tAccuracy: 91.37%\n",
      "673\tValidation loss: 1.347200\tBest loss: 1.347200\tAccuracy: 91.37%\n",
      "674\tValidation loss: 1.347183\tBest loss: 1.347183\tAccuracy: 91.37%\n",
      "675\tValidation loss: 1.347161\tBest loss: 1.347161\tAccuracy: 91.37%\n",
      "676\tValidation loss: 1.347151\tBest loss: 1.347151\tAccuracy: 91.37%\n",
      "677\tValidation loss: 1.347131\tBest loss: 1.347131\tAccuracy: 91.37%\n",
      "678\tValidation loss: 1.347112\tBest loss: 1.347112\tAccuracy: 91.37%\n",
      "679\tValidation loss: 1.347099\tBest loss: 1.347099\tAccuracy: 91.37%\n",
      "680\tValidation loss: 1.347091\tBest loss: 1.347091\tAccuracy: 91.37%\n",
      "681\tValidation loss: 1.347070\tBest loss: 1.347070\tAccuracy: 91.37%\n",
      "682\tValidation loss: 1.347052\tBest loss: 1.347052\tAccuracy: 91.37%\n",
      "683\tValidation loss: 1.347045\tBest loss: 1.347045\tAccuracy: 91.37%\n",
      "684\tValidation loss: 1.347036\tBest loss: 1.347036\tAccuracy: 91.37%\n",
      "685\tValidation loss: 1.347022\tBest loss: 1.347022\tAccuracy: 91.37%\n",
      "686\tValidation loss: 1.346997\tBest loss: 1.346997\tAccuracy: 91.37%\n",
      "687\tValidation loss: 1.346977\tBest loss: 1.346977\tAccuracy: 91.37%\n",
      "688\tValidation loss: 1.346958\tBest loss: 1.346958\tAccuracy: 91.37%\n",
      "689\tValidation loss: 1.346947\tBest loss: 1.346947\tAccuracy: 91.37%\n",
      "690\tValidation loss: 1.346929\tBest loss: 1.346929\tAccuracy: 91.37%\n",
      "691\tValidation loss: 1.346905\tBest loss: 1.346905\tAccuracy: 91.37%\n",
      "692\tValidation loss: 1.346897\tBest loss: 1.346897\tAccuracy: 91.37%\n",
      "693\tValidation loss: 1.346881\tBest loss: 1.346881\tAccuracy: 91.37%\n",
      "694\tValidation loss: 1.346867\tBest loss: 1.346867\tAccuracy: 91.37%\n",
      "695\tValidation loss: 1.346858\tBest loss: 1.346858\tAccuracy: 91.37%\n",
      "696\tValidation loss: 1.346854\tBest loss: 1.346854\tAccuracy: 91.37%\n",
      "697\tValidation loss: 1.346829\tBest loss: 1.346829\tAccuracy: 91.37%\n",
      "698\tValidation loss: 1.346820\tBest loss: 1.346820\tAccuracy: 91.37%\n",
      "699\tValidation loss: 1.346803\tBest loss: 1.346803\tAccuracy: 91.37%\n",
      "700\tValidation loss: 1.346791\tBest loss: 1.346791\tAccuracy: 91.37%\n",
      "701\tValidation loss: 1.346787\tBest loss: 1.346787\tAccuracy: 91.37%\n",
      "702\tValidation loss: 1.346771\tBest loss: 1.346771\tAccuracy: 91.37%\n",
      "703\tValidation loss: 1.346754\tBest loss: 1.346754\tAccuracy: 91.37%\n",
      "704\tValidation loss: 1.346749\tBest loss: 1.346749\tAccuracy: 91.37%\n",
      "705\tValidation loss: 1.346721\tBest loss: 1.346721\tAccuracy: 91.37%\n",
      "706\tValidation loss: 1.346699\tBest loss: 1.346699\tAccuracy: 91.37%\n",
      "707\tValidation loss: 1.346690\tBest loss: 1.346690\tAccuracy: 91.37%\n",
      "708\tValidation loss: 1.346676\tBest loss: 1.346676\tAccuracy: 91.37%\n",
      "709\tValidation loss: 1.346668\tBest loss: 1.346668\tAccuracy: 91.37%\n",
      "710\tValidation loss: 1.346655\tBest loss: 1.346655\tAccuracy: 91.37%\n",
      "711\tValidation loss: 1.346639\tBest loss: 1.346639\tAccuracy: 91.37%\n",
      "712\tValidation loss: 1.346624\tBest loss: 1.346624\tAccuracy: 91.37%\n",
      "713\tValidation loss: 1.346616\tBest loss: 1.346616\tAccuracy: 91.37%\n",
      "714\tValidation loss: 1.346594\tBest loss: 1.346594\tAccuracy: 91.37%\n",
      "715\tValidation loss: 1.346597\tBest loss: 1.346594\tAccuracy: 91.37%\n",
      "716\tValidation loss: 1.346583\tBest loss: 1.346583\tAccuracy: 91.37%\n",
      "717\tValidation loss: 1.346566\tBest loss: 1.346566\tAccuracy: 91.37%\n",
      "718\tValidation loss: 1.346544\tBest loss: 1.346544\tAccuracy: 91.37%\n",
      "719\tValidation loss: 1.346523\tBest loss: 1.346523\tAccuracy: 91.37%\n",
      "720\tValidation loss: 1.346507\tBest loss: 1.346507\tAccuracy: 91.37%\n",
      "721\tValidation loss: 1.346495\tBest loss: 1.346495\tAccuracy: 91.37%\n",
      "722\tValidation loss: 1.346484\tBest loss: 1.346484\tAccuracy: 91.37%\n",
      "723\tValidation loss: 1.346470\tBest loss: 1.346470\tAccuracy: 91.37%\n",
      "724\tValidation loss: 1.346457\tBest loss: 1.346457\tAccuracy: 91.37%\n",
      "725\tValidation loss: 1.346436\tBest loss: 1.346436\tAccuracy: 91.37%\n",
      "726\tValidation loss: 1.346418\tBest loss: 1.346418\tAccuracy: 91.37%\n",
      "727\tValidation loss: 1.346409\tBest loss: 1.346409\tAccuracy: 91.37%\n",
      "728\tValidation loss: 1.346398\tBest loss: 1.346398\tAccuracy: 91.37%\n",
      "729\tValidation loss: 1.346388\tBest loss: 1.346388\tAccuracy: 91.37%\n",
      "730\tValidation loss: 1.346372\tBest loss: 1.346372\tAccuracy: 91.37%\n",
      "731\tValidation loss: 1.346354\tBest loss: 1.346354\tAccuracy: 91.37%\n",
      "732\tValidation loss: 1.346344\tBest loss: 1.346344\tAccuracy: 91.37%\n",
      "733\tValidation loss: 1.346328\tBest loss: 1.346328\tAccuracy: 91.37%\n",
      "734\tValidation loss: 1.346320\tBest loss: 1.346320\tAccuracy: 91.37%\n",
      "735\tValidation loss: 1.346302\tBest loss: 1.346302\tAccuracy: 91.37%\n",
      "736\tValidation loss: 1.346288\tBest loss: 1.346288\tAccuracy: 91.37%\n",
      "737\tValidation loss: 1.346270\tBest loss: 1.346270\tAccuracy: 91.37%\n",
      "738\tValidation loss: 1.346246\tBest loss: 1.346246\tAccuracy: 91.37%\n",
      "739\tValidation loss: 1.346220\tBest loss: 1.346220\tAccuracy: 91.37%\n",
      "740\tValidation loss: 1.346199\tBest loss: 1.346199\tAccuracy: 91.37%\n",
      "741\tValidation loss: 1.346191\tBest loss: 1.346191\tAccuracy: 91.37%\n",
      "742\tValidation loss: 1.346179\tBest loss: 1.346179\tAccuracy: 91.37%\n",
      "743\tValidation loss: 1.346160\tBest loss: 1.346160\tAccuracy: 91.37%\n",
      "744\tValidation loss: 1.346145\tBest loss: 1.346145\tAccuracy: 91.37%\n",
      "745\tValidation loss: 1.346132\tBest loss: 1.346132\tAccuracy: 91.37%\n",
      "746\tValidation loss: 1.346128\tBest loss: 1.346128\tAccuracy: 91.37%\n",
      "747\tValidation loss: 1.346106\tBest loss: 1.346106\tAccuracy: 91.37%\n",
      "748\tValidation loss: 1.346094\tBest loss: 1.346094\tAccuracy: 91.37%\n",
      "749\tValidation loss: 1.346078\tBest loss: 1.346078\tAccuracy: 91.37%\n",
      "750\tValidation loss: 1.346069\tBest loss: 1.346069\tAccuracy: 91.37%\n",
      "751\tValidation loss: 1.346047\tBest loss: 1.346047\tAccuracy: 91.37%\n",
      "752\tValidation loss: 1.346033\tBest loss: 1.346033\tAccuracy: 91.37%\n",
      "753\tValidation loss: 1.346025\tBest loss: 1.346025\tAccuracy: 91.37%\n",
      "754\tValidation loss: 1.346020\tBest loss: 1.346020\tAccuracy: 91.37%\n",
      "755\tValidation loss: 1.346001\tBest loss: 1.346001\tAccuracy: 91.37%\n",
      "756\tValidation loss: 1.345986\tBest loss: 1.345986\tAccuracy: 91.37%\n",
      "757\tValidation loss: 1.345966\tBest loss: 1.345966\tAccuracy: 91.37%\n",
      "758\tValidation loss: 1.345963\tBest loss: 1.345963\tAccuracy: 91.37%\n",
      "759\tValidation loss: 1.345949\tBest loss: 1.345949\tAccuracy: 91.37%\n",
      "760\tValidation loss: 1.345947\tBest loss: 1.345947\tAccuracy: 91.37%\n",
      "761\tValidation loss: 1.345933\tBest loss: 1.345933\tAccuracy: 91.37%\n",
      "762\tValidation loss: 1.345910\tBest loss: 1.345910\tAccuracy: 91.37%\n",
      "763\tValidation loss: 1.345908\tBest loss: 1.345908\tAccuracy: 91.37%\n",
      "764\tValidation loss: 1.345889\tBest loss: 1.345889\tAccuracy: 91.37%\n",
      "765\tValidation loss: 1.345880\tBest loss: 1.345880\tAccuracy: 91.37%\n",
      "766\tValidation loss: 1.345857\tBest loss: 1.345857\tAccuracy: 91.37%\n",
      "767\tValidation loss: 1.345837\tBest loss: 1.345837\tAccuracy: 91.37%\n",
      "768\tValidation loss: 1.345818\tBest loss: 1.345818\tAccuracy: 91.37%\n",
      "769\tValidation loss: 1.345801\tBest loss: 1.345801\tAccuracy: 91.37%\n",
      "770\tValidation loss: 1.345786\tBest loss: 1.345786\tAccuracy: 91.37%\n",
      "771\tValidation loss: 1.345759\tBest loss: 1.345759\tAccuracy: 91.37%\n",
      "772\tValidation loss: 1.345746\tBest loss: 1.345746\tAccuracy: 91.37%\n",
      "773\tValidation loss: 1.345747\tBest loss: 1.345746\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\tValidation loss: 1.345735\tBest loss: 1.345735\tAccuracy: 91.37%\n",
      "775\tValidation loss: 1.345722\tBest loss: 1.345722\tAccuracy: 91.37%\n",
      "776\tValidation loss: 1.345724\tBest loss: 1.345722\tAccuracy: 91.37%\n",
      "777\tValidation loss: 1.345709\tBest loss: 1.345709\tAccuracy: 91.37%\n",
      "778\tValidation loss: 1.345697\tBest loss: 1.345697\tAccuracy: 91.37%\n",
      "779\tValidation loss: 1.345682\tBest loss: 1.345682\tAccuracy: 91.37%\n",
      "780\tValidation loss: 1.345677\tBest loss: 1.345677\tAccuracy: 91.37%\n",
      "781\tValidation loss: 1.345654\tBest loss: 1.345654\tAccuracy: 91.37%\n",
      "782\tValidation loss: 1.345641\tBest loss: 1.345641\tAccuracy: 91.37%\n",
      "783\tValidation loss: 1.345624\tBest loss: 1.345624\tAccuracy: 91.37%\n",
      "784\tValidation loss: 1.345622\tBest loss: 1.345622\tAccuracy: 91.37%\n",
      "785\tValidation loss: 1.345612\tBest loss: 1.345612\tAccuracy: 91.37%\n",
      "786\tValidation loss: 1.345612\tBest loss: 1.345612\tAccuracy: 91.37%\n",
      "787\tValidation loss: 1.345587\tBest loss: 1.345587\tAccuracy: 91.37%\n",
      "788\tValidation loss: 1.345578\tBest loss: 1.345578\tAccuracy: 91.37%\n",
      "789\tValidation loss: 1.345564\tBest loss: 1.345564\tAccuracy: 91.37%\n",
      "790\tValidation loss: 1.345554\tBest loss: 1.345554\tAccuracy: 91.37%\n",
      "791\tValidation loss: 1.345535\tBest loss: 1.345535\tAccuracy: 91.37%\n",
      "792\tValidation loss: 1.345503\tBest loss: 1.345503\tAccuracy: 91.37%\n",
      "793\tValidation loss: 1.345494\tBest loss: 1.345494\tAccuracy: 91.37%\n",
      "794\tValidation loss: 1.345484\tBest loss: 1.345484\tAccuracy: 91.37%\n",
      "795\tValidation loss: 1.345469\tBest loss: 1.345469\tAccuracy: 91.37%\n",
      "796\tValidation loss: 1.345450\tBest loss: 1.345450\tAccuracy: 91.37%\n",
      "797\tValidation loss: 1.345441\tBest loss: 1.345441\tAccuracy: 91.37%\n",
      "798\tValidation loss: 1.345424\tBest loss: 1.345424\tAccuracy: 91.37%\n",
      "799\tValidation loss: 1.345417\tBest loss: 1.345417\tAccuracy: 91.37%\n",
      "800\tValidation loss: 1.345418\tBest loss: 1.345417\tAccuracy: 91.37%\n",
      "801\tValidation loss: 1.345408\tBest loss: 1.345408\tAccuracy: 91.37%\n",
      "802\tValidation loss: 1.345409\tBest loss: 1.345408\tAccuracy: 91.37%\n",
      "803\tValidation loss: 1.345396\tBest loss: 1.345396\tAccuracy: 91.37%\n",
      "804\tValidation loss: 1.345376\tBest loss: 1.345376\tAccuracy: 91.37%\n",
      "805\tValidation loss: 1.345374\tBest loss: 1.345374\tAccuracy: 91.37%\n",
      "806\tValidation loss: 1.345353\tBest loss: 1.345353\tAccuracy: 91.37%\n",
      "807\tValidation loss: 1.345341\tBest loss: 1.345341\tAccuracy: 91.37%\n",
      "808\tValidation loss: 1.345326\tBest loss: 1.345326\tAccuracy: 91.37%\n",
      "809\tValidation loss: 1.345325\tBest loss: 1.345325\tAccuracy: 91.37%\n",
      "810\tValidation loss: 1.345306\tBest loss: 1.345306\tAccuracy: 91.37%\n",
      "811\tValidation loss: 1.345284\tBest loss: 1.345284\tAccuracy: 91.37%\n",
      "812\tValidation loss: 1.345282\tBest loss: 1.345282\tAccuracy: 91.37%\n",
      "813\tValidation loss: 1.345275\tBest loss: 1.345275\tAccuracy: 91.37%\n",
      "814\tValidation loss: 1.345265\tBest loss: 1.345265\tAccuracy: 91.37%\n",
      "815\tValidation loss: 1.345256\tBest loss: 1.345256\tAccuracy: 91.37%\n",
      "816\tValidation loss: 1.345234\tBest loss: 1.345234\tAccuracy: 91.37%\n",
      "817\tValidation loss: 1.345218\tBest loss: 1.345218\tAccuracy: 91.37%\n",
      "818\tValidation loss: 1.345218\tBest loss: 1.345218\tAccuracy: 91.37%\n",
      "819\tValidation loss: 1.345204\tBest loss: 1.345204\tAccuracy: 91.37%\n",
      "820\tValidation loss: 1.345190\tBest loss: 1.345190\tAccuracy: 91.37%\n",
      "821\tValidation loss: 1.345175\tBest loss: 1.345175\tAccuracy: 91.37%\n",
      "822\tValidation loss: 1.345169\tBest loss: 1.345169\tAccuracy: 91.37%\n",
      "823\tValidation loss: 1.345155\tBest loss: 1.345155\tAccuracy: 91.37%\n",
      "824\tValidation loss: 1.345157\tBest loss: 1.345155\tAccuracy: 91.37%\n",
      "825\tValidation loss: 1.345147\tBest loss: 1.345147\tAccuracy: 91.37%\n",
      "826\tValidation loss: 1.345137\tBest loss: 1.345137\tAccuracy: 91.37%\n",
      "827\tValidation loss: 1.345116\tBest loss: 1.345116\tAccuracy: 91.37%\n",
      "828\tValidation loss: 1.345095\tBest loss: 1.345095\tAccuracy: 91.37%\n",
      "829\tValidation loss: 1.345085\tBest loss: 1.345085\tAccuracy: 91.37%\n",
      "830\tValidation loss: 1.345072\tBest loss: 1.345072\tAccuracy: 91.37%\n",
      "831\tValidation loss: 1.345047\tBest loss: 1.345047\tAccuracy: 91.37%\n",
      "832\tValidation loss: 1.345043\tBest loss: 1.345043\tAccuracy: 91.37%\n",
      "833\tValidation loss: 1.345025\tBest loss: 1.345025\tAccuracy: 91.37%\n",
      "834\tValidation loss: 1.345019\tBest loss: 1.345019\tAccuracy: 91.37%\n",
      "835\tValidation loss: 1.345003\tBest loss: 1.345003\tAccuracy: 91.37%\n",
      "836\tValidation loss: 1.344991\tBest loss: 1.344991\tAccuracy: 91.37%\n",
      "837\tValidation loss: 1.344975\tBest loss: 1.344975\tAccuracy: 91.37%\n",
      "838\tValidation loss: 1.344960\tBest loss: 1.344960\tAccuracy: 91.37%\n",
      "839\tValidation loss: 1.344947\tBest loss: 1.344947\tAccuracy: 91.37%\n",
      "840\tValidation loss: 1.344946\tBest loss: 1.344946\tAccuracy: 91.37%\n",
      "841\tValidation loss: 1.344928\tBest loss: 1.344928\tAccuracy: 91.37%\n",
      "842\tValidation loss: 1.344915\tBest loss: 1.344915\tAccuracy: 91.37%\n",
      "843\tValidation loss: 1.344909\tBest loss: 1.344909\tAccuracy: 91.37%\n",
      "844\tValidation loss: 1.344904\tBest loss: 1.344904\tAccuracy: 91.37%\n",
      "845\tValidation loss: 1.344891\tBest loss: 1.344891\tAccuracy: 91.37%\n",
      "846\tValidation loss: 1.344886\tBest loss: 1.344886\tAccuracy: 91.37%\n",
      "847\tValidation loss: 1.344875\tBest loss: 1.344875\tAccuracy: 91.37%\n",
      "848\tValidation loss: 1.344866\tBest loss: 1.344866\tAccuracy: 91.37%\n",
      "849\tValidation loss: 1.344864\tBest loss: 1.344864\tAccuracy: 91.37%\n",
      "850\tValidation loss: 1.344841\tBest loss: 1.344841\tAccuracy: 91.37%\n",
      "851\tValidation loss: 1.344831\tBest loss: 1.344831\tAccuracy: 91.37%\n",
      "852\tValidation loss: 1.344819\tBest loss: 1.344819\tAccuracy: 91.37%\n",
      "853\tValidation loss: 1.344816\tBest loss: 1.344816\tAccuracy: 91.37%\n",
      "854\tValidation loss: 1.344808\tBest loss: 1.344808\tAccuracy: 91.37%\n",
      "855\tValidation loss: 1.344807\tBest loss: 1.344807\tAccuracy: 91.37%\n",
      "856\tValidation loss: 1.344787\tBest loss: 1.344787\tAccuracy: 91.37%\n",
      "857\tValidation loss: 1.344774\tBest loss: 1.344774\tAccuracy: 91.37%\n",
      "858\tValidation loss: 1.344760\tBest loss: 1.344760\tAccuracy: 91.37%\n",
      "859\tValidation loss: 1.344758\tBest loss: 1.344758\tAccuracy: 91.37%\n",
      "860\tValidation loss: 1.344747\tBest loss: 1.344747\tAccuracy: 91.37%\n",
      "861\tValidation loss: 1.344730\tBest loss: 1.344730\tAccuracy: 91.37%\n",
      "862\tValidation loss: 1.344723\tBest loss: 1.344723\tAccuracy: 91.37%\n",
      "863\tValidation loss: 1.344721\tBest loss: 1.344721\tAccuracy: 91.37%\n",
      "864\tValidation loss: 1.344693\tBest loss: 1.344693\tAccuracy: 91.37%\n",
      "865\tValidation loss: 1.344677\tBest loss: 1.344677\tAccuracy: 91.37%\n",
      "866\tValidation loss: 1.344663\tBest loss: 1.344663\tAccuracy: 91.37%\n",
      "867\tValidation loss: 1.344663\tBest loss: 1.344663\tAccuracy: 91.37%\n",
      "868\tValidation loss: 1.344652\tBest loss: 1.344652\tAccuracy: 91.37%\n",
      "869\tValidation loss: 1.344638\tBest loss: 1.344638\tAccuracy: 91.37%\n",
      "870\tValidation loss: 1.344623\tBest loss: 1.344623\tAccuracy: 91.37%\n",
      "871\tValidation loss: 1.344613\tBest loss: 1.344613\tAccuracy: 91.37%\n",
      "872\tValidation loss: 1.344597\tBest loss: 1.344597\tAccuracy: 91.37%\n",
      "873\tValidation loss: 1.344589\tBest loss: 1.344589\tAccuracy: 91.37%\n",
      "874\tValidation loss: 1.344571\tBest loss: 1.344571\tAccuracy: 91.37%\n",
      "875\tValidation loss: 1.344567\tBest loss: 1.344567\tAccuracy: 91.37%\n",
      "876\tValidation loss: 1.344554\tBest loss: 1.344554\tAccuracy: 91.37%\n",
      "877\tValidation loss: 1.344534\tBest loss: 1.344534\tAccuracy: 91.37%\n",
      "878\tValidation loss: 1.344517\tBest loss: 1.344517\tAccuracy: 91.37%\n",
      "879\tValidation loss: 1.344508\tBest loss: 1.344508\tAccuracy: 91.37%\n",
      "880\tValidation loss: 1.344494\tBest loss: 1.344494\tAccuracy: 91.37%\n",
      "881\tValidation loss: 1.344482\tBest loss: 1.344482\tAccuracy: 91.37%\n",
      "882\tValidation loss: 1.344475\tBest loss: 1.344475\tAccuracy: 91.37%\n",
      "883\tValidation loss: 1.344473\tBest loss: 1.344473\tAccuracy: 91.37%\n",
      "884\tValidation loss: 1.344462\tBest loss: 1.344462\tAccuracy: 91.37%\n",
      "885\tValidation loss: 1.344437\tBest loss: 1.344437\tAccuracy: 91.37%\n",
      "886\tValidation loss: 1.344417\tBest loss: 1.344417\tAccuracy: 91.37%\n",
      "887\tValidation loss: 1.344408\tBest loss: 1.344408\tAccuracy: 91.37%\n",
      "888\tValidation loss: 1.344399\tBest loss: 1.344399\tAccuracy: 91.37%\n",
      "889\tValidation loss: 1.344392\tBest loss: 1.344392\tAccuracy: 91.37%\n",
      "890\tValidation loss: 1.344382\tBest loss: 1.344382\tAccuracy: 91.37%\n",
      "891\tValidation loss: 1.344375\tBest loss: 1.344375\tAccuracy: 91.37%\n",
      "892\tValidation loss: 1.344352\tBest loss: 1.344352\tAccuracy: 91.37%\n",
      "893\tValidation loss: 1.344346\tBest loss: 1.344346\tAccuracy: 91.37%\n",
      "894\tValidation loss: 1.344339\tBest loss: 1.344339\tAccuracy: 91.37%\n",
      "895\tValidation loss: 1.344321\tBest loss: 1.344321\tAccuracy: 91.37%\n",
      "896\tValidation loss: 1.344297\tBest loss: 1.344297\tAccuracy: 91.37%\n",
      "897\tValidation loss: 1.344291\tBest loss: 1.344291\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898\tValidation loss: 1.344283\tBest loss: 1.344283\tAccuracy: 91.37%\n",
      "899\tValidation loss: 1.344279\tBest loss: 1.344279\tAccuracy: 91.37%\n",
      "900\tValidation loss: 1.344269\tBest loss: 1.344269\tAccuracy: 91.37%\n",
      "901\tValidation loss: 1.344270\tBest loss: 1.344269\tAccuracy: 91.37%\n",
      "902\tValidation loss: 1.344259\tBest loss: 1.344259\tAccuracy: 91.37%\n",
      "903\tValidation loss: 1.344235\tBest loss: 1.344235\tAccuracy: 91.37%\n",
      "904\tValidation loss: 1.344230\tBest loss: 1.344230\tAccuracy: 91.37%\n",
      "905\tValidation loss: 1.344217\tBest loss: 1.344217\tAccuracy: 91.37%\n",
      "906\tValidation loss: 1.344203\tBest loss: 1.344203\tAccuracy: 91.37%\n",
      "907\tValidation loss: 1.344191\tBest loss: 1.344191\tAccuracy: 91.37%\n",
      "908\tValidation loss: 1.344187\tBest loss: 1.344187\tAccuracy: 91.37%\n",
      "909\tValidation loss: 1.344178\tBest loss: 1.344178\tAccuracy: 91.37%\n",
      "910\tValidation loss: 1.344155\tBest loss: 1.344155\tAccuracy: 91.37%\n",
      "911\tValidation loss: 1.344149\tBest loss: 1.344149\tAccuracy: 91.37%\n",
      "912\tValidation loss: 1.344131\tBest loss: 1.344131\tAccuracy: 91.37%\n",
      "913\tValidation loss: 1.344127\tBest loss: 1.344127\tAccuracy: 91.37%\n",
      "914\tValidation loss: 1.344115\tBest loss: 1.344115\tAccuracy: 91.37%\n",
      "915\tValidation loss: 1.344105\tBest loss: 1.344105\tAccuracy: 91.37%\n",
      "916\tValidation loss: 1.344092\tBest loss: 1.344092\tAccuracy: 91.37%\n",
      "917\tValidation loss: 1.344087\tBest loss: 1.344087\tAccuracy: 91.37%\n",
      "918\tValidation loss: 1.344086\tBest loss: 1.344086\tAccuracy: 91.37%\n",
      "919\tValidation loss: 1.344080\tBest loss: 1.344080\tAccuracy: 91.37%\n",
      "920\tValidation loss: 1.344066\tBest loss: 1.344066\tAccuracy: 91.37%\n",
      "921\tValidation loss: 1.344055\tBest loss: 1.344055\tAccuracy: 91.37%\n",
      "922\tValidation loss: 1.344035\tBest loss: 1.344035\tAccuracy: 91.37%\n",
      "923\tValidation loss: 1.344020\tBest loss: 1.344020\tAccuracy: 91.37%\n",
      "924\tValidation loss: 1.344012\tBest loss: 1.344012\tAccuracy: 91.37%\n",
      "925\tValidation loss: 1.344007\tBest loss: 1.344007\tAccuracy: 91.37%\n",
      "926\tValidation loss: 1.343998\tBest loss: 1.343998\tAccuracy: 91.37%\n",
      "927\tValidation loss: 1.343983\tBest loss: 1.343983\tAccuracy: 91.37%\n",
      "928\tValidation loss: 1.343975\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "929\tValidation loss: 1.343977\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "930\tValidation loss: 1.343980\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "931\tValidation loss: 1.343965\tBest loss: 1.343965\tAccuracy: 91.37%\n",
      "932\tValidation loss: 1.343946\tBest loss: 1.343946\tAccuracy: 91.37%\n",
      "933\tValidation loss: 1.343940\tBest loss: 1.343940\tAccuracy: 91.37%\n",
      "934\tValidation loss: 1.343942\tBest loss: 1.343940\tAccuracy: 91.37%\n",
      "935\tValidation loss: 1.343926\tBest loss: 1.343926\tAccuracy: 91.37%\n",
      "936\tValidation loss: 1.343919\tBest loss: 1.343919\tAccuracy: 91.37%\n",
      "937\tValidation loss: 1.343917\tBest loss: 1.343917\tAccuracy: 91.37%\n",
      "938\tValidation loss: 1.343906\tBest loss: 1.343906\tAccuracy: 91.37%\n",
      "939\tValidation loss: 1.343896\tBest loss: 1.343896\tAccuracy: 91.37%\n",
      "940\tValidation loss: 1.343890\tBest loss: 1.343890\tAccuracy: 91.37%\n",
      "941\tValidation loss: 1.343881\tBest loss: 1.343881\tAccuracy: 91.37%\n",
      "942\tValidation loss: 1.343868\tBest loss: 1.343868\tAccuracy: 91.37%\n",
      "943\tValidation loss: 1.343858\tBest loss: 1.343858\tAccuracy: 91.37%\n",
      "944\tValidation loss: 1.343843\tBest loss: 1.343843\tAccuracy: 91.37%\n",
      "945\tValidation loss: 1.343826\tBest loss: 1.343826\tAccuracy: 91.37%\n",
      "946\tValidation loss: 1.343827\tBest loss: 1.343826\tAccuracy: 91.37%\n",
      "947\tValidation loss: 1.343825\tBest loss: 1.343825\tAccuracy: 91.37%\n",
      "948\tValidation loss: 1.343808\tBest loss: 1.343808\tAccuracy: 91.37%\n",
      "949\tValidation loss: 1.343784\tBest loss: 1.343784\tAccuracy: 91.37%\n",
      "950\tValidation loss: 1.343770\tBest loss: 1.343770\tAccuracy: 91.37%\n",
      "951\tValidation loss: 1.343762\tBest loss: 1.343762\tAccuracy: 91.37%\n",
      "952\tValidation loss: 1.343744\tBest loss: 1.343744\tAccuracy: 91.37%\n",
      "953\tValidation loss: 1.343724\tBest loss: 1.343724\tAccuracy: 91.37%\n",
      "954\tValidation loss: 1.343712\tBest loss: 1.343712\tAccuracy: 91.37%\n",
      "955\tValidation loss: 1.343694\tBest loss: 1.343694\tAccuracy: 91.37%\n",
      "956\tValidation loss: 1.343686\tBest loss: 1.343686\tAccuracy: 91.37%\n",
      "957\tValidation loss: 1.343678\tBest loss: 1.343678\tAccuracy: 91.37%\n",
      "958\tValidation loss: 1.343668\tBest loss: 1.343668\tAccuracy: 91.37%\n",
      "959\tValidation loss: 1.343655\tBest loss: 1.343655\tAccuracy: 91.37%\n",
      "960\tValidation loss: 1.343647\tBest loss: 1.343647\tAccuracy: 91.37%\n",
      "961\tValidation loss: 1.343644\tBest loss: 1.343644\tAccuracy: 91.37%\n",
      "962\tValidation loss: 1.343634\tBest loss: 1.343634\tAccuracy: 91.37%\n",
      "963\tValidation loss: 1.343628\tBest loss: 1.343628\tAccuracy: 91.37%\n",
      "964\tValidation loss: 1.343614\tBest loss: 1.343614\tAccuracy: 91.37%\n",
      "965\tValidation loss: 1.343607\tBest loss: 1.343607\tAccuracy: 91.37%\n",
      "966\tValidation loss: 1.343593\tBest loss: 1.343593\tAccuracy: 91.37%\n",
      "967\tValidation loss: 1.343582\tBest loss: 1.343582\tAccuracy: 91.37%\n",
      "968\tValidation loss: 1.343580\tBest loss: 1.343580\tAccuracy: 91.37%\n",
      "969\tValidation loss: 1.343564\tBest loss: 1.343564\tAccuracy: 91.37%\n",
      "970\tValidation loss: 1.343547\tBest loss: 1.343547\tAccuracy: 91.37%\n",
      "971\tValidation loss: 1.343529\tBest loss: 1.343529\tAccuracy: 91.37%\n",
      "972\tValidation loss: 1.343516\tBest loss: 1.343516\tAccuracy: 91.37%\n",
      "973\tValidation loss: 1.343512\tBest loss: 1.343512\tAccuracy: 91.37%\n",
      "974\tValidation loss: 1.343501\tBest loss: 1.343501\tAccuracy: 91.37%\n",
      "975\tValidation loss: 1.343494\tBest loss: 1.343494\tAccuracy: 91.37%\n",
      "976\tValidation loss: 1.343480\tBest loss: 1.343480\tAccuracy: 91.37%\n",
      "977\tValidation loss: 1.343467\tBest loss: 1.343467\tAccuracy: 91.37%\n",
      "978\tValidation loss: 1.343455\tBest loss: 1.343455\tAccuracy: 91.37%\n",
      "979\tValidation loss: 1.343455\tBest loss: 1.343455\tAccuracy: 91.37%\n",
      "980\tValidation loss: 1.343452\tBest loss: 1.343452\tAccuracy: 91.37%\n",
      "981\tValidation loss: 1.343435\tBest loss: 1.343435\tAccuracy: 91.37%\n",
      "982\tValidation loss: 1.343431\tBest loss: 1.343431\tAccuracy: 91.37%\n",
      "983\tValidation loss: 1.343420\tBest loss: 1.343420\tAccuracy: 91.37%\n",
      "984\tValidation loss: 1.343413\tBest loss: 1.343413\tAccuracy: 91.37%\n",
      "985\tValidation loss: 1.343401\tBest loss: 1.343401\tAccuracy: 91.37%\n",
      "986\tValidation loss: 1.343396\tBest loss: 1.343396\tAccuracy: 91.37%\n",
      "987\tValidation loss: 1.343386\tBest loss: 1.343386\tAccuracy: 91.37%\n",
      "988\tValidation loss: 1.343379\tBest loss: 1.343379\tAccuracy: 91.37%\n",
      "989\tValidation loss: 1.343368\tBest loss: 1.343368\tAccuracy: 91.37%\n",
      "990\tValidation loss: 1.343353\tBest loss: 1.343353\tAccuracy: 91.37%\n",
      "991\tValidation loss: 1.343350\tBest loss: 1.343350\tAccuracy: 91.37%\n",
      "992\tValidation loss: 1.343346\tBest loss: 1.343346\tAccuracy: 91.37%\n",
      "993\tValidation loss: 1.343344\tBest loss: 1.343344\tAccuracy: 91.37%\n",
      "994\tValidation loss: 1.343328\tBest loss: 1.343328\tAccuracy: 91.37%\n",
      "995\tValidation loss: 1.343317\tBest loss: 1.343317\tAccuracy: 91.37%\n",
      "996\tValidation loss: 1.343313\tBest loss: 1.343313\tAccuracy: 91.37%\n",
      "997\tValidation loss: 1.343299\tBest loss: 1.343299\tAccuracy: 91.37%\n",
      "998\tValidation loss: 1.343306\tBest loss: 1.343299\tAccuracy: 91.37%\n",
      "999\tValidation loss: 1.343291\tBest loss: 1.343291\tAccuracy: 91.37%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total= 1.9min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 86.605972\tBest loss: 86.605972\tAccuracy: 43.88%\n",
      "1\tValidation loss: 4.071143\tBest loss: 4.071143\tAccuracy: 82.73%\n",
      "2\tValidation loss: 4.820080\tBest loss: 4.071143\tAccuracy: 81.29%\n",
      "3\tValidation loss: 1.532486\tBest loss: 1.532486\tAccuracy: 89.21%\n",
      "4\tValidation loss: 1.616773\tBest loss: 1.532486\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.491755\tBest loss: 1.491755\tAccuracy: 89.93%\n",
      "6\tValidation loss: 1.318320\tBest loss: 1.318320\tAccuracy: 89.93%\n",
      "7\tValidation loss: 1.380828\tBest loss: 1.318320\tAccuracy: 90.65%\n",
      "8\tValidation loss: 1.369809\tBest loss: 1.318320\tAccuracy: 91.37%\n",
      "9\tValidation loss: 1.212981\tBest loss: 1.212981\tAccuracy: 91.37%\n",
      "10\tValidation loss: 1.206968\tBest loss: 1.206968\tAccuracy: 89.93%\n",
      "11\tValidation loss: 1.167929\tBest loss: 1.167929\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.164988\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "13\tValidation loss: 1.168887\tBest loss: 1.164988\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\tValidation loss: 1.185780\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.218265\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "16\tValidation loss: 1.224380\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "17\tValidation loss: 1.223913\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "18\tValidation loss: 1.226741\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "19\tValidation loss: 1.211428\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "20\tValidation loss: 1.209963\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "21\tValidation loss: 1.205905\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "22\tValidation loss: 1.200270\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "23\tValidation loss: 1.196384\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "24\tValidation loss: 1.191661\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "25\tValidation loss: 1.190100\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "26\tValidation loss: 1.188881\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "27\tValidation loss: 1.185356\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "28\tValidation loss: 1.183044\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "29\tValidation loss: 1.179847\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "30\tValidation loss: 1.177564\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "31\tValidation loss: 1.175674\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "32\tValidation loss: 1.173679\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "33\tValidation loss: 1.170932\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total=   4.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 37.045567\tBest loss: 37.045567\tAccuracy: 6.47%\n",
      "1\tValidation loss: 68.441414\tBest loss: 37.045567\tAccuracy: 2.88%\n",
      "2\tValidation loss: 25.453587\tBest loss: 25.453587\tAccuracy: 12.23%\n",
      "3\tValidation loss: 8.837578\tBest loss: 8.837578\tAccuracy: 13.67%\n",
      "4\tValidation loss: 7.437123\tBest loss: 7.437123\tAccuracy: 26.62%\n",
      "5\tValidation loss: 4.466009\tBest loss: 4.466009\tAccuracy: 27.34%\n",
      "6\tValidation loss: 3.758559\tBest loss: 3.758559\tAccuracy: 35.97%\n",
      "7\tValidation loss: 2.003646\tBest loss: 2.003646\tAccuracy: 44.60%\n",
      "8\tValidation loss: 2.517001\tBest loss: 2.003646\tAccuracy: 44.60%\n",
      "9\tValidation loss: 1.638429\tBest loss: 1.638429\tAccuracy: 56.83%\n",
      "10\tValidation loss: 2.124261\tBest loss: 1.638429\tAccuracy: 48.20%\n",
      "11\tValidation loss: 1.319254\tBest loss: 1.319254\tAccuracy: 61.15%\n",
      "12\tValidation loss: 1.784643\tBest loss: 1.319254\tAccuracy: 53.24%\n",
      "13\tValidation loss: 1.210814\tBest loss: 1.210814\tAccuracy: 64.75%\n",
      "14\tValidation loss: 1.403034\tBest loss: 1.210814\tAccuracy: 58.27%\n",
      "15\tValidation loss: 1.378905\tBest loss: 1.210814\tAccuracy: 59.71%\n",
      "16\tValidation loss: 1.187359\tBest loss: 1.187359\tAccuracy: 69.06%\n",
      "17\tValidation loss: 1.439288\tBest loss: 1.187359\tAccuracy: 58.99%\n",
      "18\tValidation loss: 1.047078\tBest loss: 1.047078\tAccuracy: 68.35%\n",
      "19\tValidation loss: 1.050750\tBest loss: 1.047078\tAccuracy: 69.78%\n",
      "20\tValidation loss: 1.102121\tBest loss: 1.047078\tAccuracy: 66.91%\n",
      "21\tValidation loss: 1.018230\tBest loss: 1.018230\tAccuracy: 69.78%\n",
      "22\tValidation loss: 1.027551\tBest loss: 1.018230\tAccuracy: 70.50%\n",
      "23\tValidation loss: 0.925919\tBest loss: 0.925919\tAccuracy: 75.54%\n",
      "24\tValidation loss: 0.978601\tBest loss: 0.925919\tAccuracy: 72.66%\n",
      "25\tValidation loss: 0.868458\tBest loss: 0.868458\tAccuracy: 76.26%\n",
      "26\tValidation loss: 0.876285\tBest loss: 0.868458\tAccuracy: 76.26%\n",
      "27\tValidation loss: 0.982862\tBest loss: 0.868458\tAccuracy: 72.66%\n",
      "28\tValidation loss: 0.903300\tBest loss: 0.868458\tAccuracy: 71.22%\n",
      "29\tValidation loss: 0.918991\tBest loss: 0.868458\tAccuracy: 72.66%\n",
      "30\tValidation loss: 0.857272\tBest loss: 0.857272\tAccuracy: 75.54%\n",
      "31\tValidation loss: 0.903948\tBest loss: 0.857272\tAccuracy: 74.10%\n",
      "32\tValidation loss: 0.800340\tBest loss: 0.800340\tAccuracy: 76.98%\n",
      "33\tValidation loss: 0.852336\tBest loss: 0.800340\tAccuracy: 74.10%\n",
      "34\tValidation loss: 0.812304\tBest loss: 0.800340\tAccuracy: 77.70%\n",
      "35\tValidation loss: 0.781005\tBest loss: 0.781005\tAccuracy: 76.98%\n",
      "36\tValidation loss: 0.806227\tBest loss: 0.781005\tAccuracy: 76.98%\n",
      "37\tValidation loss: 0.786460\tBest loss: 0.781005\tAccuracy: 74.82%\n",
      "38\tValidation loss: 0.751139\tBest loss: 0.751139\tAccuracy: 79.86%\n",
      "39\tValidation loss: 0.731509\tBest loss: 0.731509\tAccuracy: 82.73%\n",
      "40\tValidation loss: 0.725019\tBest loss: 0.725019\tAccuracy: 81.29%\n",
      "41\tValidation loss: 0.733174\tBest loss: 0.725019\tAccuracy: 79.86%\n",
      "42\tValidation loss: 0.753184\tBest loss: 0.725019\tAccuracy: 79.14%\n",
      "43\tValidation loss: 0.731401\tBest loss: 0.725019\tAccuracy: 78.42%\n",
      "44\tValidation loss: 0.737010\tBest loss: 0.725019\tAccuracy: 80.58%\n",
      "45\tValidation loss: 0.705639\tBest loss: 0.705639\tAccuracy: 79.86%\n",
      "46\tValidation loss: 0.700279\tBest loss: 0.700279\tAccuracy: 82.73%\n",
      "47\tValidation loss: 0.692621\tBest loss: 0.692621\tAccuracy: 80.58%\n",
      "48\tValidation loss: 0.688306\tBest loss: 0.688306\tAccuracy: 82.01%\n",
      "49\tValidation loss: 0.677188\tBest loss: 0.677188\tAccuracy: 81.29%\n",
      "50\tValidation loss: 0.687529\tBest loss: 0.677188\tAccuracy: 80.58%\n",
      "51\tValidation loss: 0.682673\tBest loss: 0.677188\tAccuracy: 79.86%\n",
      "52\tValidation loss: 0.688405\tBest loss: 0.677188\tAccuracy: 79.86%\n",
      "53\tValidation loss: 0.679118\tBest loss: 0.677188\tAccuracy: 79.14%\n",
      "54\tValidation loss: 0.702729\tBest loss: 0.677188\tAccuracy: 79.86%\n",
      "55\tValidation loss: 0.661160\tBest loss: 0.661160\tAccuracy: 82.01%\n",
      "56\tValidation loss: 0.673393\tBest loss: 0.661160\tAccuracy: 81.29%\n",
      "57\tValidation loss: 0.689959\tBest loss: 0.661160\tAccuracy: 79.86%\n",
      "58\tValidation loss: 0.639531\tBest loss: 0.639531\tAccuracy: 82.01%\n",
      "59\tValidation loss: 0.636898\tBest loss: 0.636898\tAccuracy: 82.73%\n",
      "60\tValidation loss: 0.613396\tBest loss: 0.613396\tAccuracy: 82.73%\n",
      "61\tValidation loss: 0.588120\tBest loss: 0.588120\tAccuracy: 87.77%\n",
      "62\tValidation loss: 0.598713\tBest loss: 0.588120\tAccuracy: 87.05%\n",
      "63\tValidation loss: 0.596632\tBest loss: 0.588120\tAccuracy: 84.89%\n",
      "64\tValidation loss: 0.596668\tBest loss: 0.588120\tAccuracy: 84.89%\n",
      "65\tValidation loss: 0.595924\tBest loss: 0.588120\tAccuracy: 83.45%\n",
      "66\tValidation loss: 0.621088\tBest loss: 0.588120\tAccuracy: 84.17%\n",
      "67\tValidation loss: 0.613848\tBest loss: 0.588120\tAccuracy: 83.45%\n",
      "68\tValidation loss: 0.600780\tBest loss: 0.588120\tAccuracy: 83.45%\n",
      "69\tValidation loss: 0.603970\tBest loss: 0.588120\tAccuracy: 84.17%\n",
      "70\tValidation loss: 0.593281\tBest loss: 0.588120\tAccuracy: 82.73%\n",
      "71\tValidation loss: 0.606047\tBest loss: 0.588120\tAccuracy: 83.45%\n",
      "72\tValidation loss: 0.591842\tBest loss: 0.588120\tAccuracy: 84.17%\n",
      "73\tValidation loss: 0.587967\tBest loss: 0.587967\tAccuracy: 83.45%\n",
      "74\tValidation loss: 0.578935\tBest loss: 0.578935\tAccuracy: 83.45%\n",
      "75\tValidation loss: 0.567714\tBest loss: 0.567714\tAccuracy: 83.45%\n",
      "76\tValidation loss: 0.575063\tBest loss: 0.567714\tAccuracy: 83.45%\n",
      "77\tValidation loss: 0.548488\tBest loss: 0.548488\tAccuracy: 84.89%\n",
      "78\tValidation loss: 0.556545\tBest loss: 0.548488\tAccuracy: 84.89%\n",
      "79\tValidation loss: 0.548237\tBest loss: 0.548237\tAccuracy: 84.89%\n",
      "80\tValidation loss: 0.565331\tBest loss: 0.548237\tAccuracy: 84.17%\n",
      "81\tValidation loss: 0.567969\tBest loss: 0.548237\tAccuracy: 84.17%\n",
      "82\tValidation loss: 0.552418\tBest loss: 0.548237\tAccuracy: 84.89%\n",
      "83\tValidation loss: 0.543481\tBest loss: 0.543481\tAccuracy: 86.33%\n",
      "84\tValidation loss: 0.540691\tBest loss: 0.540691\tAccuracy: 87.05%\n",
      "85\tValidation loss: 0.524535\tBest loss: 0.524535\tAccuracy: 87.77%\n",
      "86\tValidation loss: 0.524666\tBest loss: 0.524535\tAccuracy: 86.33%\n",
      "87\tValidation loss: 0.519484\tBest loss: 0.519484\tAccuracy: 88.49%\n",
      "88\tValidation loss: 0.522455\tBest loss: 0.519484\tAccuracy: 87.77%\n",
      "89\tValidation loss: 0.529741\tBest loss: 0.519484\tAccuracy: 86.33%\n",
      "90\tValidation loss: 0.519901\tBest loss: 0.519484\tAccuracy: 86.33%\n",
      "91\tValidation loss: 0.535263\tBest loss: 0.519484\tAccuracy: 86.33%\n",
      "92\tValidation loss: 0.534049\tBest loss: 0.519484\tAccuracy: 85.61%\n",
      "93\tValidation loss: 0.524939\tBest loss: 0.519484\tAccuracy: 85.61%\n",
      "94\tValidation loss: 0.528963\tBest loss: 0.519484\tAccuracy: 85.61%\n",
      "95\tValidation loss: 0.531695\tBest loss: 0.519484\tAccuracy: 83.45%\n",
      "96\tValidation loss: 0.523690\tBest loss: 0.519484\tAccuracy: 85.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\tValidation loss: 0.514620\tBest loss: 0.514620\tAccuracy: 86.33%\n",
      "98\tValidation loss: 0.517993\tBest loss: 0.514620\tAccuracy: 87.05%\n",
      "99\tValidation loss: 0.524507\tBest loss: 0.514620\tAccuracy: 86.33%\n",
      "100\tValidation loss: 0.527652\tBest loss: 0.514620\tAccuracy: 85.61%\n",
      "101\tValidation loss: 0.518514\tBest loss: 0.514620\tAccuracy: 86.33%\n",
      "102\tValidation loss: 0.517130\tBest loss: 0.514620\tAccuracy: 87.05%\n",
      "103\tValidation loss: 0.525347\tBest loss: 0.514620\tAccuracy: 86.33%\n",
      "104\tValidation loss: 0.524643\tBest loss: 0.514620\tAccuracy: 86.33%\n",
      "105\tValidation loss: 0.521725\tBest loss: 0.514620\tAccuracy: 85.61%\n",
      "106\tValidation loss: 0.505524\tBest loss: 0.505524\tAccuracy: 86.33%\n",
      "107\tValidation loss: 0.499838\tBest loss: 0.499838\tAccuracy: 87.05%\n",
      "108\tValidation loss: 0.500298\tBest loss: 0.499838\tAccuracy: 87.05%\n",
      "109\tValidation loss: 0.494296\tBest loss: 0.494296\tAccuracy: 88.49%\n",
      "110\tValidation loss: 0.506312\tBest loss: 0.494296\tAccuracy: 87.77%\n",
      "111\tValidation loss: 0.494945\tBest loss: 0.494296\tAccuracy: 87.77%\n",
      "112\tValidation loss: 0.487988\tBest loss: 0.487988\tAccuracy: 87.77%\n",
      "113\tValidation loss: 0.489410\tBest loss: 0.487988\tAccuracy: 87.77%\n",
      "114\tValidation loss: 0.475567\tBest loss: 0.475567\tAccuracy: 89.21%\n",
      "115\tValidation loss: 0.473879\tBest loss: 0.473879\tAccuracy: 87.77%\n",
      "116\tValidation loss: 0.485385\tBest loss: 0.473879\tAccuracy: 88.49%\n",
      "117\tValidation loss: 0.475407\tBest loss: 0.473879\tAccuracy: 87.05%\n",
      "118\tValidation loss: 0.474773\tBest loss: 0.473879\tAccuracy: 88.49%\n",
      "119\tValidation loss: 0.480906\tBest loss: 0.473879\tAccuracy: 87.77%\n",
      "120\tValidation loss: 0.483036\tBest loss: 0.473879\tAccuracy: 87.05%\n",
      "121\tValidation loss: 0.492955\tBest loss: 0.473879\tAccuracy: 87.05%\n",
      "122\tValidation loss: 0.480884\tBest loss: 0.473879\tAccuracy: 88.49%\n",
      "123\tValidation loss: 0.483481\tBest loss: 0.473879\tAccuracy: 86.33%\n",
      "124\tValidation loss: 0.482982\tBest loss: 0.473879\tAccuracy: 88.49%\n",
      "125\tValidation loss: 0.475575\tBest loss: 0.473879\tAccuracy: 87.77%\n",
      "126\tValidation loss: 0.472794\tBest loss: 0.472794\tAccuracy: 89.21%\n",
      "127\tValidation loss: 0.475205\tBest loss: 0.472794\tAccuracy: 88.49%\n",
      "128\tValidation loss: 0.469498\tBest loss: 0.469498\tAccuracy: 88.49%\n",
      "129\tValidation loss: 0.476293\tBest loss: 0.469498\tAccuracy: 87.77%\n",
      "130\tValidation loss: 0.461441\tBest loss: 0.461441\tAccuracy: 88.49%\n",
      "131\tValidation loss: 0.468302\tBest loss: 0.461441\tAccuracy: 89.21%\n",
      "132\tValidation loss: 0.469437\tBest loss: 0.461441\tAccuracy: 89.93%\n",
      "133\tValidation loss: 0.463340\tBest loss: 0.461441\tAccuracy: 89.93%\n",
      "134\tValidation loss: 0.453347\tBest loss: 0.453347\tAccuracy: 90.65%\n",
      "135\tValidation loss: 0.456764\tBest loss: 0.453347\tAccuracy: 89.21%\n",
      "136\tValidation loss: 0.451013\tBest loss: 0.451013\tAccuracy: 89.21%\n",
      "137\tValidation loss: 0.450828\tBest loss: 0.450828\tAccuracy: 89.21%\n",
      "138\tValidation loss: 0.457961\tBest loss: 0.450828\tAccuracy: 89.21%\n",
      "139\tValidation loss: 0.462079\tBest loss: 0.450828\tAccuracy: 89.21%\n",
      "140\tValidation loss: 0.450137\tBest loss: 0.450137\tAccuracy: 89.93%\n",
      "141\tValidation loss: 0.436602\tBest loss: 0.436602\tAccuracy: 89.21%\n",
      "142\tValidation loss: 0.430481\tBest loss: 0.430481\tAccuracy: 90.65%\n",
      "143\tValidation loss: 0.430725\tBest loss: 0.430481\tAccuracy: 90.65%\n",
      "144\tValidation loss: 0.444052\tBest loss: 0.430481\tAccuracy: 90.65%\n",
      "145\tValidation loss: 0.441671\tBest loss: 0.430481\tAccuracy: 90.65%\n",
      "146\tValidation loss: 0.440056\tBest loss: 0.430481\tAccuracy: 89.93%\n",
      "147\tValidation loss: 0.438862\tBest loss: 0.430481\tAccuracy: 89.93%\n",
      "148\tValidation loss: 0.434896\tBest loss: 0.430481\tAccuracy: 89.21%\n",
      "149\tValidation loss: 0.426928\tBest loss: 0.426928\tAccuracy: 87.77%\n",
      "150\tValidation loss: 0.428999\tBest loss: 0.426928\tAccuracy: 88.49%\n",
      "151\tValidation loss: 0.428224\tBest loss: 0.426928\tAccuracy: 87.05%\n",
      "152\tValidation loss: 0.427705\tBest loss: 0.426928\tAccuracy: 88.49%\n",
      "153\tValidation loss: 0.418459\tBest loss: 0.418459\tAccuracy: 88.49%\n",
      "154\tValidation loss: 0.418228\tBest loss: 0.418228\tAccuracy: 89.21%\n",
      "155\tValidation loss: 0.417967\tBest loss: 0.417967\tAccuracy: 89.93%\n",
      "156\tValidation loss: 0.420032\tBest loss: 0.417967\tAccuracy: 89.21%\n",
      "157\tValidation loss: 0.428378\tBest loss: 0.417967\tAccuracy: 89.21%\n",
      "158\tValidation loss: 0.413199\tBest loss: 0.413199\tAccuracy: 89.21%\n",
      "159\tValidation loss: 0.417262\tBest loss: 0.413199\tAccuracy: 88.49%\n",
      "160\tValidation loss: 0.418533\tBest loss: 0.413199\tAccuracy: 89.21%\n",
      "161\tValidation loss: 0.417122\tBest loss: 0.413199\tAccuracy: 89.21%\n",
      "162\tValidation loss: 0.418491\tBest loss: 0.413199\tAccuracy: 89.93%\n",
      "163\tValidation loss: 0.412353\tBest loss: 0.412353\tAccuracy: 89.93%\n",
      "164\tValidation loss: 0.408280\tBest loss: 0.408280\tAccuracy: 89.21%\n",
      "165\tValidation loss: 0.408115\tBest loss: 0.408115\tAccuracy: 89.21%\n",
      "166\tValidation loss: 0.408456\tBest loss: 0.408115\tAccuracy: 89.21%\n",
      "167\tValidation loss: 0.405703\tBest loss: 0.405703\tAccuracy: 89.21%\n",
      "168\tValidation loss: 0.409263\tBest loss: 0.405703\tAccuracy: 89.21%\n",
      "169\tValidation loss: 0.395324\tBest loss: 0.395324\tAccuracy: 89.93%\n",
      "170\tValidation loss: 0.399774\tBest loss: 0.395324\tAccuracy: 89.21%\n",
      "171\tValidation loss: 0.403268\tBest loss: 0.395324\tAccuracy: 88.49%\n",
      "172\tValidation loss: 0.401886\tBest loss: 0.395324\tAccuracy: 88.49%\n",
      "173\tValidation loss: 0.400399\tBest loss: 0.395324\tAccuracy: 89.21%\n",
      "174\tValidation loss: 0.395033\tBest loss: 0.395033\tAccuracy: 89.93%\n",
      "175\tValidation loss: 0.393921\tBest loss: 0.393921\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.395801\tBest loss: 0.393921\tAccuracy: 90.65%\n",
      "177\tValidation loss: 0.398483\tBest loss: 0.393921\tAccuracy: 89.93%\n",
      "178\tValidation loss: 0.390251\tBest loss: 0.390251\tAccuracy: 89.93%\n",
      "179\tValidation loss: 0.386427\tBest loss: 0.386427\tAccuracy: 89.21%\n",
      "180\tValidation loss: 0.383731\tBest loss: 0.383731\tAccuracy: 89.21%\n",
      "181\tValidation loss: 0.384284\tBest loss: 0.383731\tAccuracy: 89.93%\n",
      "182\tValidation loss: 0.384013\tBest loss: 0.383731\tAccuracy: 89.93%\n",
      "183\tValidation loss: 0.374475\tBest loss: 0.374475\tAccuracy: 89.93%\n",
      "184\tValidation loss: 0.379333\tBest loss: 0.374475\tAccuracy: 89.93%\n",
      "185\tValidation loss: 0.376651\tBest loss: 0.374475\tAccuracy: 89.93%\n",
      "186\tValidation loss: 0.375222\tBest loss: 0.374475\tAccuracy: 89.93%\n",
      "187\tValidation loss: 0.383301\tBest loss: 0.374475\tAccuracy: 90.65%\n",
      "188\tValidation loss: 0.380513\tBest loss: 0.374475\tAccuracy: 90.65%\n",
      "189\tValidation loss: 0.382301\tBest loss: 0.374475\tAccuracy: 91.37%\n",
      "190\tValidation loss: 0.374293\tBest loss: 0.374293\tAccuracy: 90.65%\n",
      "191\tValidation loss: 0.381367\tBest loss: 0.374293\tAccuracy: 90.65%\n",
      "192\tValidation loss: 0.378331\tBest loss: 0.374293\tAccuracy: 90.65%\n",
      "193\tValidation loss: 0.377830\tBest loss: 0.374293\tAccuracy: 90.65%\n",
      "194\tValidation loss: 0.379624\tBest loss: 0.374293\tAccuracy: 89.93%\n",
      "195\tValidation loss: 0.380112\tBest loss: 0.374293\tAccuracy: 89.93%\n",
      "196\tValidation loss: 0.375538\tBest loss: 0.374293\tAccuracy: 89.93%\n",
      "197\tValidation loss: 0.373074\tBest loss: 0.373074\tAccuracy: 89.21%\n",
      "198\tValidation loss: 0.369737\tBest loss: 0.369737\tAccuracy: 89.21%\n",
      "199\tValidation loss: 0.370862\tBest loss: 0.369737\tAccuracy: 89.21%\n",
      "200\tValidation loss: 0.374359\tBest loss: 0.369737\tAccuracy: 89.21%\n",
      "201\tValidation loss: 0.373823\tBest loss: 0.369737\tAccuracy: 89.93%\n",
      "202\tValidation loss: 0.365223\tBest loss: 0.365223\tAccuracy: 88.49%\n",
      "203\tValidation loss: 0.362762\tBest loss: 0.362762\tAccuracy: 89.21%\n",
      "204\tValidation loss: 0.359425\tBest loss: 0.359425\tAccuracy: 89.93%\n",
      "205\tValidation loss: 0.354880\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "206\tValidation loss: 0.358590\tBest loss: 0.354880\tAccuracy: 90.65%\n",
      "207\tValidation loss: 0.364449\tBest loss: 0.354880\tAccuracy: 90.65%\n",
      "208\tValidation loss: 0.368498\tBest loss: 0.354880\tAccuracy: 90.65%\n",
      "209\tValidation loss: 0.361718\tBest loss: 0.354880\tAccuracy: 90.65%\n",
      "210\tValidation loss: 0.361751\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "211\tValidation loss: 0.360359\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "212\tValidation loss: 0.360284\tBest loss: 0.354880\tAccuracy: 90.65%\n",
      "213\tValidation loss: 0.363629\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "214\tValidation loss: 0.365337\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "215\tValidation loss: 0.363888\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "216\tValidation loss: 0.355674\tBest loss: 0.354880\tAccuracy: 89.93%\n",
      "217\tValidation loss: 0.352447\tBest loss: 0.352447\tAccuracy: 89.93%\n",
      "218\tValidation loss: 0.343086\tBest loss: 0.343086\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.337012\tBest loss: 0.337012\tAccuracy: 90.65%\n",
      "220\tValidation loss: 0.334452\tBest loss: 0.334452\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\tValidation loss: 0.333474\tBest loss: 0.333474\tAccuracy: 90.65%\n",
      "222\tValidation loss: 0.332558\tBest loss: 0.332558\tAccuracy: 90.65%\n",
      "223\tValidation loss: 0.329467\tBest loss: 0.329467\tAccuracy: 90.65%\n",
      "224\tValidation loss: 0.326957\tBest loss: 0.326957\tAccuracy: 89.93%\n",
      "225\tValidation loss: 0.325966\tBest loss: 0.325966\tAccuracy: 90.65%\n",
      "226\tValidation loss: 0.329665\tBest loss: 0.325966\tAccuracy: 89.93%\n",
      "227\tValidation loss: 0.322324\tBest loss: 0.322324\tAccuracy: 89.93%\n",
      "228\tValidation loss: 0.325522\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "229\tValidation loss: 0.328660\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "230\tValidation loss: 0.332308\tBest loss: 0.322324\tAccuracy: 92.09%\n",
      "231\tValidation loss: 0.330380\tBest loss: 0.322324\tAccuracy: 91.37%\n",
      "232\tValidation loss: 0.325480\tBest loss: 0.322324\tAccuracy: 91.37%\n",
      "233\tValidation loss: 0.327975\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "234\tValidation loss: 0.331044\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "235\tValidation loss: 0.334170\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "236\tValidation loss: 0.327748\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "237\tValidation loss: 0.327358\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "238\tValidation loss: 0.327808\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "239\tValidation loss: 0.327289\tBest loss: 0.322324\tAccuracy: 90.65%\n",
      "240\tValidation loss: 0.321880\tBest loss: 0.321880\tAccuracy: 91.37%\n",
      "241\tValidation loss: 0.318842\tBest loss: 0.318842\tAccuracy: 91.37%\n",
      "242\tValidation loss: 0.319934\tBest loss: 0.318842\tAccuracy: 91.37%\n",
      "243\tValidation loss: 0.322809\tBest loss: 0.318842\tAccuracy: 91.37%\n",
      "244\tValidation loss: 0.319334\tBest loss: 0.318842\tAccuracy: 91.37%\n",
      "245\tValidation loss: 0.319429\tBest loss: 0.318842\tAccuracy: 91.37%\n",
      "246\tValidation loss: 0.315942\tBest loss: 0.315942\tAccuracy: 91.37%\n",
      "247\tValidation loss: 0.318404\tBest loss: 0.315942\tAccuracy: 90.65%\n",
      "248\tValidation loss: 0.320128\tBest loss: 0.315942\tAccuracy: 90.65%\n",
      "249\tValidation loss: 0.316079\tBest loss: 0.315942\tAccuracy: 90.65%\n",
      "250\tValidation loss: 0.315889\tBest loss: 0.315889\tAccuracy: 90.65%\n",
      "251\tValidation loss: 0.314221\tBest loss: 0.314221\tAccuracy: 90.65%\n",
      "252\tValidation loss: 0.316965\tBest loss: 0.314221\tAccuracy: 90.65%\n",
      "253\tValidation loss: 0.313019\tBest loss: 0.313019\tAccuracy: 89.93%\n",
      "254\tValidation loss: 0.315461\tBest loss: 0.313019\tAccuracy: 89.93%\n",
      "255\tValidation loss: 0.308561\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "256\tValidation loss: 0.310673\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "257\tValidation loss: 0.309740\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "258\tValidation loss: 0.310377\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "259\tValidation loss: 0.312114\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "260\tValidation loss: 0.310072\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "261\tValidation loss: 0.318290\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "262\tValidation loss: 0.317001\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "263\tValidation loss: 0.311366\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "264\tValidation loss: 0.310672\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "265\tValidation loss: 0.315067\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "266\tValidation loss: 0.318421\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "267\tValidation loss: 0.317193\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "268\tValidation loss: 0.315071\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "269\tValidation loss: 0.316723\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "270\tValidation loss: 0.315725\tBest loss: 0.308561\tAccuracy: 91.37%\n",
      "271\tValidation loss: 0.319954\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "272\tValidation loss: 0.313884\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "273\tValidation loss: 0.311702\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "274\tValidation loss: 0.309897\tBest loss: 0.308561\tAccuracy: 90.65%\n",
      "275\tValidation loss: 0.317165\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "276\tValidation loss: 0.313137\tBest loss: 0.308561\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  30.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 39.957703\tBest loss: 39.957703\tAccuracy: 7.91%\n",
      "1\tValidation loss: 73.401260\tBest loss: 39.957703\tAccuracy: 5.76%\n",
      "2\tValidation loss: 29.123260\tBest loss: 29.123260\tAccuracy: 7.91%\n",
      "3\tValidation loss: 13.454262\tBest loss: 13.454262\tAccuracy: 17.99%\n",
      "4\tValidation loss: 6.186340\tBest loss: 6.186340\tAccuracy: 23.74%\n",
      "5\tValidation loss: 4.301236\tBest loss: 4.301236\tAccuracy: 33.81%\n",
      "6\tValidation loss: 3.137463\tBest loss: 3.137463\tAccuracy: 46.76%\n",
      "7\tValidation loss: 3.766341\tBest loss: 3.137463\tAccuracy: 36.69%\n",
      "8\tValidation loss: 1.919530\tBest loss: 1.919530\tAccuracy: 46.04%\n",
      "9\tValidation loss: 3.115047\tBest loss: 1.919530\tAccuracy: 40.29%\n",
      "10\tValidation loss: 1.473948\tBest loss: 1.473948\tAccuracy: 61.15%\n",
      "11\tValidation loss: 2.144673\tBest loss: 1.473948\tAccuracy: 50.36%\n",
      "12\tValidation loss: 1.357825\tBest loss: 1.357825\tAccuracy: 63.31%\n",
      "13\tValidation loss: 1.734134\tBest loss: 1.357825\tAccuracy: 55.40%\n",
      "14\tValidation loss: 1.277691\tBest loss: 1.277691\tAccuracy: 63.31%\n",
      "15\tValidation loss: 1.432959\tBest loss: 1.277691\tAccuracy: 63.31%\n",
      "16\tValidation loss: 1.208434\tBest loss: 1.208434\tAccuracy: 65.47%\n",
      "17\tValidation loss: 1.093804\tBest loss: 1.093804\tAccuracy: 69.06%\n",
      "18\tValidation loss: 1.160608\tBest loss: 1.093804\tAccuracy: 66.19%\n",
      "19\tValidation loss: 1.102432\tBest loss: 1.093804\tAccuracy: 69.78%\n",
      "20\tValidation loss: 1.149879\tBest loss: 1.093804\tAccuracy: 67.63%\n",
      "21\tValidation loss: 1.067920\tBest loss: 1.067920\tAccuracy: 68.35%\n",
      "22\tValidation loss: 1.192585\tBest loss: 1.067920\tAccuracy: 65.47%\n",
      "23\tValidation loss: 1.092461\tBest loss: 1.067920\tAccuracy: 70.50%\n",
      "24\tValidation loss: 1.058566\tBest loss: 1.058566\tAccuracy: 71.94%\n",
      "25\tValidation loss: 1.243392\tBest loss: 1.058566\tAccuracy: 65.47%\n",
      "26\tValidation loss: 0.991383\tBest loss: 0.991383\tAccuracy: 71.94%\n",
      "27\tValidation loss: 1.055976\tBest loss: 0.991383\tAccuracy: 69.78%\n",
      "28\tValidation loss: 0.887303\tBest loss: 0.887303\tAccuracy: 74.10%\n",
      "29\tValidation loss: 0.936595\tBest loss: 0.887303\tAccuracy: 73.38%\n",
      "30\tValidation loss: 0.885560\tBest loss: 0.885560\tAccuracy: 73.38%\n",
      "31\tValidation loss: 0.908550\tBest loss: 0.885560\tAccuracy: 71.94%\n",
      "32\tValidation loss: 0.926660\tBest loss: 0.885560\tAccuracy: 71.94%\n",
      "33\tValidation loss: 0.905791\tBest loss: 0.885560\tAccuracy: 72.66%\n",
      "34\tValidation loss: 0.917554\tBest loss: 0.885560\tAccuracy: 70.50%\n",
      "35\tValidation loss: 0.891776\tBest loss: 0.885560\tAccuracy: 71.22%\n",
      "36\tValidation loss: 0.912857\tBest loss: 0.885560\tAccuracy: 69.78%\n",
      "37\tValidation loss: 0.927349\tBest loss: 0.885560\tAccuracy: 71.22%\n",
      "38\tValidation loss: 0.812889\tBest loss: 0.812889\tAccuracy: 74.10%\n",
      "39\tValidation loss: 0.787385\tBest loss: 0.787385\tAccuracy: 76.98%\n",
      "40\tValidation loss: 0.797617\tBest loss: 0.787385\tAccuracy: 74.10%\n",
      "41\tValidation loss: 0.794446\tBest loss: 0.787385\tAccuracy: 74.82%\n",
      "42\tValidation loss: 0.788799\tBest loss: 0.787385\tAccuracy: 76.98%\n",
      "43\tValidation loss: 0.790586\tBest loss: 0.787385\tAccuracy: 77.70%\n",
      "44\tValidation loss: 0.735593\tBest loss: 0.735593\tAccuracy: 78.42%\n",
      "45\tValidation loss: 0.756103\tBest loss: 0.735593\tAccuracy: 75.54%\n",
      "46\tValidation loss: 0.743928\tBest loss: 0.735593\tAccuracy: 79.86%\n",
      "47\tValidation loss: 0.684183\tBest loss: 0.684183\tAccuracy: 84.17%\n",
      "48\tValidation loss: 0.695238\tBest loss: 0.684183\tAccuracy: 81.29%\n",
      "49\tValidation loss: 0.678084\tBest loss: 0.678084\tAccuracy: 82.01%\n",
      "50\tValidation loss: 0.705419\tBest loss: 0.678084\tAccuracy: 81.29%\n",
      "51\tValidation loss: 0.712866\tBest loss: 0.678084\tAccuracy: 80.58%\n",
      "52\tValidation loss: 0.731897\tBest loss: 0.678084\tAccuracy: 77.70%\n",
      "53\tValidation loss: 0.730545\tBest loss: 0.678084\tAccuracy: 81.29%\n",
      "54\tValidation loss: 0.740466\tBest loss: 0.678084\tAccuracy: 79.14%\n",
      "55\tValidation loss: 0.688777\tBest loss: 0.678084\tAccuracy: 80.58%\n",
      "56\tValidation loss: 0.712958\tBest loss: 0.678084\tAccuracy: 81.29%\n",
      "57\tValidation loss: 0.699170\tBest loss: 0.678084\tAccuracy: 80.58%\n",
      "58\tValidation loss: 0.700155\tBest loss: 0.678084\tAccuracy: 79.14%\n",
      "59\tValidation loss: 0.682274\tBest loss: 0.678084\tAccuracy: 77.70%\n",
      "60\tValidation loss: 0.691481\tBest loss: 0.678084\tAccuracy: 78.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\tValidation loss: 0.693581\tBest loss: 0.678084\tAccuracy: 79.86%\n",
      "62\tValidation loss: 0.698438\tBest loss: 0.678084\tAccuracy: 77.70%\n",
      "63\tValidation loss: 0.686069\tBest loss: 0.678084\tAccuracy: 79.14%\n",
      "64\tValidation loss: 0.662142\tBest loss: 0.662142\tAccuracy: 79.86%\n",
      "65\tValidation loss: 0.650261\tBest loss: 0.650261\tAccuracy: 81.29%\n",
      "66\tValidation loss: 0.633058\tBest loss: 0.633058\tAccuracy: 81.29%\n",
      "67\tValidation loss: 0.667088\tBest loss: 0.633058\tAccuracy: 79.14%\n",
      "68\tValidation loss: 0.671549\tBest loss: 0.633058\tAccuracy: 82.73%\n",
      "69\tValidation loss: 0.633874\tBest loss: 0.633058\tAccuracy: 83.45%\n",
      "70\tValidation loss: 0.624616\tBest loss: 0.624616\tAccuracy: 82.73%\n",
      "71\tValidation loss: 0.627949\tBest loss: 0.624616\tAccuracy: 84.89%\n",
      "72\tValidation loss: 0.611662\tBest loss: 0.611662\tAccuracy: 84.17%\n",
      "73\tValidation loss: 0.604328\tBest loss: 0.604328\tAccuracy: 84.89%\n",
      "74\tValidation loss: 0.599689\tBest loss: 0.599689\tAccuracy: 82.73%\n",
      "75\tValidation loss: 0.620122\tBest loss: 0.599689\tAccuracy: 82.01%\n",
      "76\tValidation loss: 0.593238\tBest loss: 0.593238\tAccuracy: 80.58%\n",
      "77\tValidation loss: 0.618493\tBest loss: 0.593238\tAccuracy: 79.86%\n",
      "78\tValidation loss: 0.591131\tBest loss: 0.591131\tAccuracy: 82.73%\n",
      "79\tValidation loss: 0.590244\tBest loss: 0.590244\tAccuracy: 82.73%\n",
      "80\tValidation loss: 0.592800\tBest loss: 0.590244\tAccuracy: 82.73%\n",
      "81\tValidation loss: 0.592322\tBest loss: 0.590244\tAccuracy: 82.01%\n",
      "82\tValidation loss: 0.574501\tBest loss: 0.574501\tAccuracy: 82.01%\n",
      "83\tValidation loss: 0.545267\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "84\tValidation loss: 0.597156\tBest loss: 0.545267\tAccuracy: 81.29%\n",
      "85\tValidation loss: 0.583296\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "86\tValidation loss: 0.555943\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "87\tValidation loss: 0.568597\tBest loss: 0.545267\tAccuracy: 82.73%\n",
      "88\tValidation loss: 0.553720\tBest loss: 0.545267\tAccuracy: 82.01%\n",
      "89\tValidation loss: 0.570518\tBest loss: 0.545267\tAccuracy: 81.29%\n",
      "90\tValidation loss: 0.557904\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "91\tValidation loss: 0.555326\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "92\tValidation loss: 0.550792\tBest loss: 0.545267\tAccuracy: 84.17%\n",
      "93\tValidation loss: 0.555172\tBest loss: 0.545267\tAccuracy: 83.45%\n",
      "94\tValidation loss: 0.545110\tBest loss: 0.545110\tAccuracy: 84.17%\n",
      "95\tValidation loss: 0.556016\tBest loss: 0.545110\tAccuracy: 84.89%\n",
      "96\tValidation loss: 0.521576\tBest loss: 0.521576\tAccuracy: 84.17%\n",
      "97\tValidation loss: 0.532684\tBest loss: 0.521576\tAccuracy: 84.89%\n",
      "98\tValidation loss: 0.561041\tBest loss: 0.521576\tAccuracy: 84.17%\n",
      "99\tValidation loss: 0.552951\tBest loss: 0.521576\tAccuracy: 84.17%\n",
      "100\tValidation loss: 0.547646\tBest loss: 0.521576\tAccuracy: 84.17%\n",
      "101\tValidation loss: 0.538203\tBest loss: 0.521576\tAccuracy: 84.17%\n",
      "102\tValidation loss: 0.515506\tBest loss: 0.515506\tAccuracy: 85.61%\n",
      "103\tValidation loss: 0.512353\tBest loss: 0.512353\tAccuracy: 84.89%\n",
      "104\tValidation loss: 0.518021\tBest loss: 0.512353\tAccuracy: 85.61%\n",
      "105\tValidation loss: 0.518470\tBest loss: 0.512353\tAccuracy: 84.17%\n",
      "106\tValidation loss: 0.498598\tBest loss: 0.498598\tAccuracy: 86.33%\n",
      "107\tValidation loss: 0.489317\tBest loss: 0.489317\tAccuracy: 86.33%\n",
      "108\tValidation loss: 0.485327\tBest loss: 0.485327\tAccuracy: 85.61%\n",
      "109\tValidation loss: 0.483167\tBest loss: 0.483167\tAccuracy: 86.33%\n",
      "110\tValidation loss: 0.472714\tBest loss: 0.472714\tAccuracy: 85.61%\n",
      "111\tValidation loss: 0.482844\tBest loss: 0.472714\tAccuracy: 86.33%\n",
      "112\tValidation loss: 0.488496\tBest loss: 0.472714\tAccuracy: 83.45%\n",
      "113\tValidation loss: 0.512565\tBest loss: 0.472714\tAccuracy: 83.45%\n",
      "114\tValidation loss: 0.491689\tBest loss: 0.472714\tAccuracy: 84.89%\n",
      "115\tValidation loss: 0.476361\tBest loss: 0.472714\tAccuracy: 85.61%\n",
      "116\tValidation loss: 0.467911\tBest loss: 0.467911\tAccuracy: 87.05%\n",
      "117\tValidation loss: 0.473150\tBest loss: 0.467911\tAccuracy: 87.77%\n",
      "118\tValidation loss: 0.476389\tBest loss: 0.467911\tAccuracy: 86.33%\n",
      "119\tValidation loss: 0.487260\tBest loss: 0.467911\tAccuracy: 85.61%\n",
      "120\tValidation loss: 0.467387\tBest loss: 0.467387\tAccuracy: 84.89%\n",
      "121\tValidation loss: 0.466146\tBest loss: 0.466146\tAccuracy: 86.33%\n",
      "122\tValidation loss: 0.490387\tBest loss: 0.466146\tAccuracy: 84.89%\n",
      "123\tValidation loss: 0.485905\tBest loss: 0.466146\tAccuracy: 84.17%\n",
      "124\tValidation loss: 0.473629\tBest loss: 0.466146\tAccuracy: 86.33%\n",
      "125\tValidation loss: 0.465815\tBest loss: 0.465815\tAccuracy: 87.05%\n",
      "126\tValidation loss: 0.462373\tBest loss: 0.462373\tAccuracy: 86.33%\n",
      "127\tValidation loss: 0.453933\tBest loss: 0.453933\tAccuracy: 84.89%\n",
      "128\tValidation loss: 0.474476\tBest loss: 0.453933\tAccuracy: 85.61%\n",
      "129\tValidation loss: 0.477094\tBest loss: 0.453933\tAccuracy: 86.33%\n",
      "130\tValidation loss: 0.457713\tBest loss: 0.453933\tAccuracy: 87.77%\n",
      "131\tValidation loss: 0.451001\tBest loss: 0.451001\tAccuracy: 87.77%\n",
      "132\tValidation loss: 0.453184\tBest loss: 0.451001\tAccuracy: 87.77%\n",
      "133\tValidation loss: 0.438482\tBest loss: 0.438482\tAccuracy: 87.77%\n",
      "134\tValidation loss: 0.430102\tBest loss: 0.430102\tAccuracy: 88.49%\n",
      "135\tValidation loss: 0.437407\tBest loss: 0.430102\tAccuracy: 86.33%\n",
      "136\tValidation loss: 0.431657\tBest loss: 0.430102\tAccuracy: 87.77%\n",
      "137\tValidation loss: 0.431258\tBest loss: 0.430102\tAccuracy: 87.05%\n",
      "138\tValidation loss: 0.416717\tBest loss: 0.416717\tAccuracy: 89.21%\n",
      "139\tValidation loss: 0.421341\tBest loss: 0.416717\tAccuracy: 88.49%\n",
      "140\tValidation loss: 0.437444\tBest loss: 0.416717\tAccuracy: 88.49%\n",
      "141\tValidation loss: 0.438357\tBest loss: 0.416717\tAccuracy: 88.49%\n",
      "142\tValidation loss: 0.433811\tBest loss: 0.416717\tAccuracy: 87.77%\n",
      "143\tValidation loss: 0.435413\tBest loss: 0.416717\tAccuracy: 87.05%\n",
      "144\tValidation loss: 0.441498\tBest loss: 0.416717\tAccuracy: 87.05%\n",
      "145\tValidation loss: 0.421634\tBest loss: 0.416717\tAccuracy: 88.49%\n",
      "146\tValidation loss: 0.414145\tBest loss: 0.414145\tAccuracy: 89.21%\n",
      "147\tValidation loss: 0.412293\tBest loss: 0.412293\tAccuracy: 89.93%\n",
      "148\tValidation loss: 0.408006\tBest loss: 0.408006\tAccuracy: 89.93%\n",
      "149\tValidation loss: 0.399145\tBest loss: 0.399145\tAccuracy: 89.93%\n",
      "150\tValidation loss: 0.399049\tBest loss: 0.399049\tAccuracy: 89.21%\n",
      "151\tValidation loss: 0.423773\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "152\tValidation loss: 0.424583\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "153\tValidation loss: 0.417905\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "154\tValidation loss: 0.423037\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "155\tValidation loss: 0.406285\tBest loss: 0.399049\tAccuracy: 89.21%\n",
      "156\tValidation loss: 0.403774\tBest loss: 0.399049\tAccuracy: 89.93%\n",
      "157\tValidation loss: 0.403595\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "158\tValidation loss: 0.404520\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "159\tValidation loss: 0.403530\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "160\tValidation loss: 0.405616\tBest loss: 0.399049\tAccuracy: 87.77%\n",
      "161\tValidation loss: 0.409054\tBest loss: 0.399049\tAccuracy: 88.49%\n",
      "162\tValidation loss: 0.392626\tBest loss: 0.392626\tAccuracy: 89.21%\n",
      "163\tValidation loss: 0.384319\tBest loss: 0.384319\tAccuracy: 89.21%\n",
      "164\tValidation loss: 0.393369\tBest loss: 0.384319\tAccuracy: 89.21%\n",
      "165\tValidation loss: 0.381188\tBest loss: 0.381188\tAccuracy: 89.21%\n",
      "166\tValidation loss: 0.385685\tBest loss: 0.381188\tAccuracy: 89.93%\n",
      "167\tValidation loss: 0.382920\tBest loss: 0.381188\tAccuracy: 89.93%\n",
      "168\tValidation loss: 0.383332\tBest loss: 0.381188\tAccuracy: 89.93%\n",
      "169\tValidation loss: 0.383867\tBest loss: 0.381188\tAccuracy: 89.93%\n",
      "170\tValidation loss: 0.381050\tBest loss: 0.381050\tAccuracy: 89.93%\n",
      "171\tValidation loss: 0.370871\tBest loss: 0.370871\tAccuracy: 89.93%\n",
      "172\tValidation loss: 0.366329\tBest loss: 0.366329\tAccuracy: 89.93%\n",
      "173\tValidation loss: 0.365885\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "174\tValidation loss: 0.378733\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "175\tValidation loss: 0.376753\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.380814\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "177\tValidation loss: 0.378242\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "178\tValidation loss: 0.382031\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "179\tValidation loss: 0.384018\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "180\tValidation loss: 0.389944\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "181\tValidation loss: 0.381965\tBest loss: 0.365885\tAccuracy: 90.65%\n",
      "182\tValidation loss: 0.377138\tBest loss: 0.365885\tAccuracy: 90.65%\n",
      "183\tValidation loss: 0.376383\tBest loss: 0.365885\tAccuracy: 90.65%\n",
      "184\tValidation loss: 0.383416\tBest loss: 0.365885\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\tValidation loss: 0.381896\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "186\tValidation loss: 0.377712\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "187\tValidation loss: 0.373776\tBest loss: 0.365885\tAccuracy: 89.93%\n",
      "188\tValidation loss: 0.380198\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "189\tValidation loss: 0.376753\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "190\tValidation loss: 0.367013\tBest loss: 0.365885\tAccuracy: 89.21%\n",
      "191\tValidation loss: 0.360633\tBest loss: 0.360633\tAccuracy: 89.21%\n",
      "192\tValidation loss: 0.367382\tBest loss: 0.360633\tAccuracy: 88.49%\n",
      "193\tValidation loss: 0.367276\tBest loss: 0.360633\tAccuracy: 90.65%\n",
      "194\tValidation loss: 0.361529\tBest loss: 0.360633\tAccuracy: 91.37%\n",
      "195\tValidation loss: 0.361387\tBest loss: 0.360633\tAccuracy: 91.37%\n",
      "196\tValidation loss: 0.358197\tBest loss: 0.358197\tAccuracy: 90.65%\n",
      "197\tValidation loss: 0.358606\tBest loss: 0.358197\tAccuracy: 90.65%\n",
      "198\tValidation loss: 0.350574\tBest loss: 0.350574\tAccuracy: 90.65%\n",
      "199\tValidation loss: 0.340559\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "200\tValidation loss: 0.346640\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "201\tValidation loss: 0.351115\tBest loss: 0.340559\tAccuracy: 90.65%\n",
      "202\tValidation loss: 0.343352\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "203\tValidation loss: 0.348988\tBest loss: 0.340559\tAccuracy: 90.65%\n",
      "204\tValidation loss: 0.357538\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "205\tValidation loss: 0.349374\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "206\tValidation loss: 0.351124\tBest loss: 0.340559\tAccuracy: 90.65%\n",
      "207\tValidation loss: 0.347044\tBest loss: 0.340559\tAccuracy: 89.93%\n",
      "208\tValidation loss: 0.351840\tBest loss: 0.340559\tAccuracy: 89.21%\n",
      "209\tValidation loss: 0.356643\tBest loss: 0.340559\tAccuracy: 90.65%\n",
      "210\tValidation loss: 0.345734\tBest loss: 0.340559\tAccuracy: 91.37%\n",
      "211\tValidation loss: 0.356255\tBest loss: 0.340559\tAccuracy: 91.37%\n",
      "212\tValidation loss: 0.343870\tBest loss: 0.340559\tAccuracy: 92.09%\n",
      "213\tValidation loss: 0.345749\tBest loss: 0.340559\tAccuracy: 92.09%\n",
      "214\tValidation loss: 0.341042\tBest loss: 0.340559\tAccuracy: 90.65%\n",
      "215\tValidation loss: 0.336094\tBest loss: 0.336094\tAccuracy: 91.37%\n",
      "216\tValidation loss: 0.336366\tBest loss: 0.336094\tAccuracy: 91.37%\n",
      "217\tValidation loss: 0.342210\tBest loss: 0.336094\tAccuracy: 89.93%\n",
      "218\tValidation loss: 0.341650\tBest loss: 0.336094\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.340277\tBest loss: 0.336094\tAccuracy: 90.65%\n",
      "220\tValidation loss: 0.336493\tBest loss: 0.336094\tAccuracy: 89.93%\n",
      "221\tValidation loss: 0.330639\tBest loss: 0.330639\tAccuracy: 91.37%\n",
      "222\tValidation loss: 0.325246\tBest loss: 0.325246\tAccuracy: 91.37%\n",
      "223\tValidation loss: 0.324022\tBest loss: 0.324022\tAccuracy: 91.37%\n",
      "224\tValidation loss: 0.316971\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "225\tValidation loss: 0.325121\tBest loss: 0.316971\tAccuracy: 89.93%\n",
      "226\tValidation loss: 0.321587\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "227\tValidation loss: 0.321087\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "228\tValidation loss: 0.323789\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "229\tValidation loss: 0.324305\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "230\tValidation loss: 0.324651\tBest loss: 0.316971\tAccuracy: 90.65%\n",
      "231\tValidation loss: 0.333237\tBest loss: 0.316971\tAccuracy: 90.65%\n",
      "232\tValidation loss: 0.327687\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "233\tValidation loss: 0.324161\tBest loss: 0.316971\tAccuracy: 91.37%\n",
      "234\tValidation loss: 0.316968\tBest loss: 0.316968\tAccuracy: 91.37%\n",
      "235\tValidation loss: 0.326301\tBest loss: 0.316968\tAccuracy: 90.65%\n",
      "236\tValidation loss: 0.321789\tBest loss: 0.316968\tAccuracy: 90.65%\n",
      "237\tValidation loss: 0.322990\tBest loss: 0.316968\tAccuracy: 91.37%\n",
      "238\tValidation loss: 0.322223\tBest loss: 0.316968\tAccuracy: 91.37%\n",
      "239\tValidation loss: 0.322464\tBest loss: 0.316968\tAccuracy: 91.37%\n",
      "240\tValidation loss: 0.320985\tBest loss: 0.316968\tAccuracy: 90.65%\n",
      "241\tValidation loss: 0.311146\tBest loss: 0.311146\tAccuracy: 90.65%\n",
      "242\tValidation loss: 0.309324\tBest loss: 0.309324\tAccuracy: 91.37%\n",
      "243\tValidation loss: 0.312292\tBest loss: 0.309324\tAccuracy: 91.37%\n",
      "244\tValidation loss: 0.312799\tBest loss: 0.309324\tAccuracy: 91.37%\n",
      "245\tValidation loss: 0.305758\tBest loss: 0.305758\tAccuracy: 91.37%\n",
      "246\tValidation loss: 0.315155\tBest loss: 0.305758\tAccuracy: 90.65%\n",
      "247\tValidation loss: 0.310834\tBest loss: 0.305758\tAccuracy: 91.37%\n",
      "248\tValidation loss: 0.323078\tBest loss: 0.305758\tAccuracy: 89.93%\n",
      "249\tValidation loss: 0.315211\tBest loss: 0.305758\tAccuracy: 91.37%\n",
      "250\tValidation loss: 0.310104\tBest loss: 0.305758\tAccuracy: 91.37%\n",
      "251\tValidation loss: 0.309531\tBest loss: 0.305758\tAccuracy: 91.37%\n",
      "252\tValidation loss: 0.305150\tBest loss: 0.305150\tAccuracy: 91.37%\n",
      "253\tValidation loss: 0.300072\tBest loss: 0.300072\tAccuracy: 92.81%\n",
      "254\tValidation loss: 0.293589\tBest loss: 0.293589\tAccuracy: 91.37%\n",
      "255\tValidation loss: 0.290799\tBest loss: 0.290799\tAccuracy: 92.09%\n",
      "256\tValidation loss: 0.288592\tBest loss: 0.288592\tAccuracy: 92.09%\n",
      "257\tValidation loss: 0.290814\tBest loss: 0.288592\tAccuracy: 92.09%\n",
      "258\tValidation loss: 0.300889\tBest loss: 0.288592\tAccuracy: 90.65%\n",
      "259\tValidation loss: 0.291452\tBest loss: 0.288592\tAccuracy: 92.09%\n",
      "260\tValidation loss: 0.296979\tBest loss: 0.288592\tAccuracy: 91.37%\n",
      "261\tValidation loss: 0.299544\tBest loss: 0.288592\tAccuracy: 90.65%\n",
      "262\tValidation loss: 0.297939\tBest loss: 0.288592\tAccuracy: 91.37%\n",
      "263\tValidation loss: 0.299858\tBest loss: 0.288592\tAccuracy: 91.37%\n",
      "264\tValidation loss: 0.296799\tBest loss: 0.288592\tAccuracy: 91.37%\n",
      "265\tValidation loss: 0.299705\tBest loss: 0.288592\tAccuracy: 91.37%\n",
      "266\tValidation loss: 0.296486\tBest loss: 0.288592\tAccuracy: 92.09%\n",
      "267\tValidation loss: 0.287352\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "268\tValidation loss: 0.294206\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "269\tValidation loss: 0.296556\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "270\tValidation loss: 0.290313\tBest loss: 0.287352\tAccuracy: 92.81%\n",
      "271\tValidation loss: 0.301424\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "272\tValidation loss: 0.305293\tBest loss: 0.287352\tAccuracy: 92.81%\n",
      "273\tValidation loss: 0.296812\tBest loss: 0.287352\tAccuracy: 92.81%\n",
      "274\tValidation loss: 0.295260\tBest loss: 0.287352\tAccuracy: 91.37%\n",
      "275\tValidation loss: 0.299002\tBest loss: 0.287352\tAccuracy: 91.37%\n",
      "276\tValidation loss: 0.301493\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "277\tValidation loss: 0.296239\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "278\tValidation loss: 0.296745\tBest loss: 0.287352\tAccuracy: 92.09%\n",
      "279\tValidation loss: 0.289359\tBest loss: 0.287352\tAccuracy: 94.24%\n",
      "280\tValidation loss: 0.283396\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "281\tValidation loss: 0.287901\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "282\tValidation loss: 0.287838\tBest loss: 0.283396\tAccuracy: 94.24%\n",
      "283\tValidation loss: 0.288307\tBest loss: 0.283396\tAccuracy: 94.24%\n",
      "284\tValidation loss: 0.302144\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "285\tValidation loss: 0.295854\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "286\tValidation loss: 0.289982\tBest loss: 0.283396\tAccuracy: 92.81%\n",
      "287\tValidation loss: 0.283842\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "288\tValidation loss: 0.286985\tBest loss: 0.283396\tAccuracy: 91.37%\n",
      "289\tValidation loss: 0.287806\tBest loss: 0.283396\tAccuracy: 91.37%\n",
      "290\tValidation loss: 0.289716\tBest loss: 0.283396\tAccuracy: 92.81%\n",
      "291\tValidation loss: 0.283586\tBest loss: 0.283396\tAccuracy: 93.53%\n",
      "292\tValidation loss: 0.291089\tBest loss: 0.283396\tAccuracy: 92.81%\n",
      "293\tValidation loss: 0.292425\tBest loss: 0.283396\tAccuracy: 93.53%\n",
      "294\tValidation loss: 0.288879\tBest loss: 0.283396\tAccuracy: 93.53%\n",
      "295\tValidation loss: 0.289454\tBest loss: 0.283396\tAccuracy: 92.09%\n",
      "296\tValidation loss: 0.294188\tBest loss: 0.283396\tAccuracy: 91.37%\n",
      "297\tValidation loss: 0.291815\tBest loss: 0.283396\tAccuracy: 91.37%\n",
      "298\tValidation loss: 0.284874\tBest loss: 0.283396\tAccuracy: 92.81%\n",
      "299\tValidation loss: 0.294293\tBest loss: 0.283396\tAccuracy: 91.37%\n",
      "300\tValidation loss: 0.284563\tBest loss: 0.283396\tAccuracy: 94.24%\n",
      "301\tValidation loss: 0.283660\tBest loss: 0.283396\tAccuracy: 92.81%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  33.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 33.582676\tBest loss: 33.582676\tAccuracy: 6.47%\n",
      "1\tValidation loss: 64.612175\tBest loss: 33.582676\tAccuracy: 3.60%\n",
      "2\tValidation loss: 26.575790\tBest loss: 26.575790\tAccuracy: 7.19%\n",
      "3\tValidation loss: 16.845655\tBest loss: 16.845655\tAccuracy: 16.55%\n",
      "4\tValidation loss: 12.766041\tBest loss: 12.766041\tAccuracy: 17.99%\n",
      "5\tValidation loss: 5.978451\tBest loss: 5.978451\tAccuracy: 25.90%\n",
      "6\tValidation loss: 7.053162\tBest loss: 5.978451\tAccuracy: 22.30%\n",
      "7\tValidation loss: 3.889654\tBest loss: 3.889654\tAccuracy: 35.25%\n",
      "8\tValidation loss: 3.602134\tBest loss: 3.602134\tAccuracy: 31.65%\n",
      "9\tValidation loss: 2.164643\tBest loss: 2.164643\tAccuracy: 51.08%\n",
      "10\tValidation loss: 2.770364\tBest loss: 2.164643\tAccuracy: 42.45%\n",
      "11\tValidation loss: 1.677397\tBest loss: 1.677397\tAccuracy: 51.80%\n",
      "12\tValidation loss: 2.170036\tBest loss: 1.677397\tAccuracy: 52.52%\n",
      "13\tValidation loss: 1.291712\tBest loss: 1.291712\tAccuracy: 60.43%\n",
      "14\tValidation loss: 1.718064\tBest loss: 1.291712\tAccuracy: 53.96%\n",
      "15\tValidation loss: 1.327313\tBest loss: 1.291712\tAccuracy: 58.99%\n",
      "16\tValidation loss: 1.379373\tBest loss: 1.291712\tAccuracy: 60.43%\n",
      "17\tValidation loss: 1.163308\tBest loss: 1.163308\tAccuracy: 66.91%\n",
      "18\tValidation loss: 1.236138\tBest loss: 1.163308\tAccuracy: 64.75%\n",
      "19\tValidation loss: 1.177308\tBest loss: 1.163308\tAccuracy: 66.19%\n",
      "20\tValidation loss: 1.332312\tBest loss: 1.163308\tAccuracy: 61.15%\n",
      "21\tValidation loss: 1.105838\tBest loss: 1.105838\tAccuracy: 67.63%\n",
      "22\tValidation loss: 1.259388\tBest loss: 1.105838\tAccuracy: 63.31%\n",
      "23\tValidation loss: 1.095387\tBest loss: 1.095387\tAccuracy: 67.63%\n",
      "24\tValidation loss: 1.247585\tBest loss: 1.095387\tAccuracy: 62.59%\n",
      "25\tValidation loss: 0.994122\tBest loss: 0.994122\tAccuracy: 66.91%\n",
      "26\tValidation loss: 1.067427\tBest loss: 0.994122\tAccuracy: 66.91%\n",
      "27\tValidation loss: 1.091346\tBest loss: 0.994122\tAccuracy: 67.63%\n",
      "28\tValidation loss: 1.043071\tBest loss: 0.994122\tAccuracy: 71.22%\n",
      "29\tValidation loss: 0.959298\tBest loss: 0.959298\tAccuracy: 70.50%\n",
      "30\tValidation loss: 1.096525\tBest loss: 0.959298\tAccuracy: 73.38%\n",
      "31\tValidation loss: 0.962715\tBest loss: 0.959298\tAccuracy: 74.10%\n",
      "32\tValidation loss: 0.983110\tBest loss: 0.959298\tAccuracy: 71.94%\n",
      "33\tValidation loss: 0.929956\tBest loss: 0.929956\tAccuracy: 71.94%\n",
      "34\tValidation loss: 0.935717\tBest loss: 0.929956\tAccuracy: 71.94%\n",
      "35\tValidation loss: 0.878802\tBest loss: 0.878802\tAccuracy: 74.10%\n",
      "36\tValidation loss: 0.886559\tBest loss: 0.878802\tAccuracy: 74.82%\n",
      "37\tValidation loss: 0.903030\tBest loss: 0.878802\tAccuracy: 71.22%\n",
      "38\tValidation loss: 0.912005\tBest loss: 0.878802\tAccuracy: 71.94%\n",
      "39\tValidation loss: 0.841007\tBest loss: 0.841007\tAccuracy: 74.10%\n",
      "40\tValidation loss: 0.852797\tBest loss: 0.841007\tAccuracy: 74.82%\n",
      "41\tValidation loss: 0.857529\tBest loss: 0.841007\tAccuracy: 74.10%\n",
      "42\tValidation loss: 0.810552\tBest loss: 0.810552\tAccuracy: 75.54%\n",
      "43\tValidation loss: 0.833902\tBest loss: 0.810552\tAccuracy: 76.98%\n",
      "44\tValidation loss: 0.782643\tBest loss: 0.782643\tAccuracy: 77.70%\n",
      "45\tValidation loss: 0.750112\tBest loss: 0.750112\tAccuracy: 81.29%\n",
      "46\tValidation loss: 0.809116\tBest loss: 0.750112\tAccuracy: 76.98%\n",
      "47\tValidation loss: 0.752345\tBest loss: 0.750112\tAccuracy: 79.86%\n",
      "48\tValidation loss: 0.734253\tBest loss: 0.734253\tAccuracy: 80.58%\n",
      "49\tValidation loss: 0.777075\tBest loss: 0.734253\tAccuracy: 79.86%\n",
      "50\tValidation loss: 0.745141\tBest loss: 0.734253\tAccuracy: 80.58%\n",
      "51\tValidation loss: 0.735457\tBest loss: 0.734253\tAccuracy: 79.86%\n",
      "52\tValidation loss: 0.696482\tBest loss: 0.696482\tAccuracy: 81.29%\n",
      "53\tValidation loss: 0.707447\tBest loss: 0.696482\tAccuracy: 80.58%\n",
      "54\tValidation loss: 0.715067\tBest loss: 0.696482\tAccuracy: 80.58%\n",
      "55\tValidation loss: 0.717001\tBest loss: 0.696482\tAccuracy: 81.29%\n",
      "56\tValidation loss: 0.682690\tBest loss: 0.682690\tAccuracy: 82.01%\n",
      "57\tValidation loss: 0.709413\tBest loss: 0.682690\tAccuracy: 80.58%\n",
      "58\tValidation loss: 0.701696\tBest loss: 0.682690\tAccuracy: 79.14%\n",
      "59\tValidation loss: 0.695639\tBest loss: 0.682690\tAccuracy: 79.86%\n",
      "60\tValidation loss: 0.677700\tBest loss: 0.677700\tAccuracy: 82.01%\n",
      "61\tValidation loss: 0.685228\tBest loss: 0.677700\tAccuracy: 82.73%\n",
      "62\tValidation loss: 0.696073\tBest loss: 0.677700\tAccuracy: 81.29%\n",
      "63\tValidation loss: 0.665530\tBest loss: 0.665530\tAccuracy: 84.17%\n",
      "64\tValidation loss: 0.647588\tBest loss: 0.647588\tAccuracy: 83.45%\n",
      "65\tValidation loss: 0.679640\tBest loss: 0.647588\tAccuracy: 82.01%\n",
      "66\tValidation loss: 0.650649\tBest loss: 0.647588\tAccuracy: 84.17%\n",
      "67\tValidation loss: 0.646367\tBest loss: 0.646367\tAccuracy: 85.61%\n",
      "68\tValidation loss: 0.651114\tBest loss: 0.646367\tAccuracy: 84.17%\n",
      "69\tValidation loss: 0.619188\tBest loss: 0.619188\tAccuracy: 82.73%\n",
      "70\tValidation loss: 0.605357\tBest loss: 0.605357\tAccuracy: 83.45%\n",
      "71\tValidation loss: 0.595475\tBest loss: 0.595475\tAccuracy: 85.61%\n",
      "72\tValidation loss: 0.587253\tBest loss: 0.587253\tAccuracy: 84.89%\n",
      "73\tValidation loss: 0.606339\tBest loss: 0.587253\tAccuracy: 84.17%\n",
      "74\tValidation loss: 0.601746\tBest loss: 0.587253\tAccuracy: 83.45%\n",
      "75\tValidation loss: 0.584292\tBest loss: 0.584292\tAccuracy: 84.17%\n",
      "76\tValidation loss: 0.590779\tBest loss: 0.584292\tAccuracy: 84.17%\n",
      "77\tValidation loss: 0.579171\tBest loss: 0.579171\tAccuracy: 84.89%\n",
      "78\tValidation loss: 0.561318\tBest loss: 0.561318\tAccuracy: 86.33%\n",
      "79\tValidation loss: 0.580866\tBest loss: 0.561318\tAccuracy: 84.17%\n",
      "80\tValidation loss: 0.583115\tBest loss: 0.561318\tAccuracy: 84.17%\n",
      "81\tValidation loss: 0.582441\tBest loss: 0.561318\tAccuracy: 85.61%\n",
      "82\tValidation loss: 0.552977\tBest loss: 0.552977\tAccuracy: 86.33%\n",
      "83\tValidation loss: 0.556144\tBest loss: 0.552977\tAccuracy: 86.33%\n",
      "84\tValidation loss: 0.582797\tBest loss: 0.552977\tAccuracy: 82.73%\n",
      "85\tValidation loss: 0.555743\tBest loss: 0.552977\tAccuracy: 83.45%\n",
      "86\tValidation loss: 0.550470\tBest loss: 0.550470\tAccuracy: 86.33%\n",
      "87\tValidation loss: 0.556000\tBest loss: 0.550470\tAccuracy: 84.89%\n",
      "88\tValidation loss: 0.556090\tBest loss: 0.550470\tAccuracy: 84.89%\n",
      "89\tValidation loss: 0.545605\tBest loss: 0.545605\tAccuracy: 85.61%\n",
      "90\tValidation loss: 0.541907\tBest loss: 0.541907\tAccuracy: 84.89%\n",
      "91\tValidation loss: 0.545920\tBest loss: 0.541907\tAccuracy: 84.89%\n",
      "92\tValidation loss: 0.554497\tBest loss: 0.541907\tAccuracy: 83.45%\n",
      "93\tValidation loss: 0.540140\tBest loss: 0.540140\tAccuracy: 84.89%\n",
      "94\tValidation loss: 0.549987\tBest loss: 0.540140\tAccuracy: 84.17%\n",
      "95\tValidation loss: 0.575065\tBest loss: 0.540140\tAccuracy: 83.45%\n",
      "96\tValidation loss: 0.550459\tBest loss: 0.540140\tAccuracy: 84.89%\n",
      "97\tValidation loss: 0.527842\tBest loss: 0.527842\tAccuracy: 84.89%\n",
      "98\tValidation loss: 0.527555\tBest loss: 0.527555\tAccuracy: 84.89%\n",
      "99\tValidation loss: 0.534034\tBest loss: 0.527555\tAccuracy: 84.17%\n",
      "100\tValidation loss: 0.533750\tBest loss: 0.527555\tAccuracy: 84.17%\n",
      "101\tValidation loss: 0.521937\tBest loss: 0.521937\tAccuracy: 84.89%\n",
      "102\tValidation loss: 0.529368\tBest loss: 0.521937\tAccuracy: 84.17%\n",
      "103\tValidation loss: 0.534605\tBest loss: 0.521937\tAccuracy: 86.33%\n",
      "104\tValidation loss: 0.523350\tBest loss: 0.521937\tAccuracy: 85.61%\n",
      "105\tValidation loss: 0.542260\tBest loss: 0.521937\tAccuracy: 84.17%\n",
      "106\tValidation loss: 0.546453\tBest loss: 0.521937\tAccuracy: 84.17%\n",
      "107\tValidation loss: 0.541760\tBest loss: 0.521937\tAccuracy: 85.61%\n",
      "108\tValidation loss: 0.527852\tBest loss: 0.521937\tAccuracy: 85.61%\n",
      "109\tValidation loss: 0.516222\tBest loss: 0.516222\tAccuracy: 84.17%\n",
      "110\tValidation loss: 0.527351\tBest loss: 0.516222\tAccuracy: 83.45%\n",
      "111\tValidation loss: 0.537457\tBest loss: 0.516222\tAccuracy: 84.17%\n",
      "112\tValidation loss: 0.512030\tBest loss: 0.512030\tAccuracy: 84.89%\n",
      "113\tValidation loss: 0.495731\tBest loss: 0.495731\tAccuracy: 86.33%\n",
      "114\tValidation loss: 0.497830\tBest loss: 0.495731\tAccuracy: 86.33%\n",
      "115\tValidation loss: 0.499250\tBest loss: 0.495731\tAccuracy: 86.33%\n",
      "116\tValidation loss: 0.492586\tBest loss: 0.492586\tAccuracy: 85.61%\n",
      "117\tValidation loss: 0.497816\tBest loss: 0.492586\tAccuracy: 86.33%\n",
      "118\tValidation loss: 0.488944\tBest loss: 0.488944\tAccuracy: 85.61%\n",
      "119\tValidation loss: 0.479838\tBest loss: 0.479838\tAccuracy: 87.05%\n",
      "120\tValidation loss: 0.472106\tBest loss: 0.472106\tAccuracy: 87.05%\n",
      "121\tValidation loss: 0.471381\tBest loss: 0.471381\tAccuracy: 87.77%\n",
      "122\tValidation loss: 0.483506\tBest loss: 0.471381\tAccuracy: 87.05%\n",
      "123\tValidation loss: 0.478658\tBest loss: 0.471381\tAccuracy: 85.61%\n",
      "124\tValidation loss: 0.484802\tBest loss: 0.471381\tAccuracy: 86.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.486254\tBest loss: 0.471381\tAccuracy: 86.33%\n",
      "126\tValidation loss: 0.481820\tBest loss: 0.471381\tAccuracy: 86.33%\n",
      "127\tValidation loss: 0.484045\tBest loss: 0.471381\tAccuracy: 87.05%\n",
      "128\tValidation loss: 0.477720\tBest loss: 0.471381\tAccuracy: 87.77%\n",
      "129\tValidation loss: 0.472043\tBest loss: 0.471381\tAccuracy: 87.77%\n",
      "130\tValidation loss: 0.483503\tBest loss: 0.471381\tAccuracy: 87.05%\n",
      "131\tValidation loss: 0.484515\tBest loss: 0.471381\tAccuracy: 87.77%\n",
      "132\tValidation loss: 0.476772\tBest loss: 0.471381\tAccuracy: 87.05%\n",
      "133\tValidation loss: 0.472200\tBest loss: 0.471381\tAccuracy: 86.33%\n",
      "134\tValidation loss: 0.476638\tBest loss: 0.471381\tAccuracy: 86.33%\n",
      "135\tValidation loss: 0.460499\tBest loss: 0.460499\tAccuracy: 87.05%\n",
      "136\tValidation loss: 0.452801\tBest loss: 0.452801\tAccuracy: 87.05%\n",
      "137\tValidation loss: 0.456062\tBest loss: 0.452801\tAccuracy: 88.49%\n",
      "138\tValidation loss: 0.450464\tBest loss: 0.450464\tAccuracy: 89.21%\n",
      "139\tValidation loss: 0.443390\tBest loss: 0.443390\tAccuracy: 89.21%\n",
      "140\tValidation loss: 0.443947\tBest loss: 0.443390\tAccuracy: 87.77%\n",
      "141\tValidation loss: 0.440008\tBest loss: 0.440008\tAccuracy: 89.21%\n",
      "142\tValidation loss: 0.448240\tBest loss: 0.440008\tAccuracy: 89.21%\n",
      "143\tValidation loss: 0.449398\tBest loss: 0.440008\tAccuracy: 88.49%\n",
      "144\tValidation loss: 0.453296\tBest loss: 0.440008\tAccuracy: 87.77%\n",
      "145\tValidation loss: 0.439681\tBest loss: 0.439681\tAccuracy: 88.49%\n",
      "146\tValidation loss: 0.444945\tBest loss: 0.439681\tAccuracy: 88.49%\n",
      "147\tValidation loss: 0.450354\tBest loss: 0.439681\tAccuracy: 87.77%\n",
      "148\tValidation loss: 0.438843\tBest loss: 0.438843\tAccuracy: 89.93%\n",
      "149\tValidation loss: 0.436915\tBest loss: 0.436915\tAccuracy: 89.93%\n",
      "150\tValidation loss: 0.430893\tBest loss: 0.430893\tAccuracy: 88.49%\n",
      "151\tValidation loss: 0.427439\tBest loss: 0.427439\tAccuracy: 89.21%\n",
      "152\tValidation loss: 0.427248\tBest loss: 0.427248\tAccuracy: 88.49%\n",
      "153\tValidation loss: 0.419656\tBest loss: 0.419656\tAccuracy: 88.49%\n",
      "154\tValidation loss: 0.425749\tBest loss: 0.419656\tAccuracy: 88.49%\n",
      "155\tValidation loss: 0.421058\tBest loss: 0.419656\tAccuracy: 89.21%\n",
      "156\tValidation loss: 0.419085\tBest loss: 0.419085\tAccuracy: 89.21%\n",
      "157\tValidation loss: 0.426402\tBest loss: 0.419085\tAccuracy: 87.05%\n",
      "158\tValidation loss: 0.423167\tBest loss: 0.419085\tAccuracy: 88.49%\n",
      "159\tValidation loss: 0.421101\tBest loss: 0.419085\tAccuracy: 89.93%\n",
      "160\tValidation loss: 0.421845\tBest loss: 0.419085\tAccuracy: 89.93%\n",
      "161\tValidation loss: 0.424821\tBest loss: 0.419085\tAccuracy: 89.93%\n",
      "162\tValidation loss: 0.422808\tBest loss: 0.419085\tAccuracy: 89.21%\n",
      "163\tValidation loss: 0.416767\tBest loss: 0.416767\tAccuracy: 89.21%\n",
      "164\tValidation loss: 0.411186\tBest loss: 0.411186\tAccuracy: 87.77%\n",
      "165\tValidation loss: 0.415852\tBest loss: 0.411186\tAccuracy: 88.49%\n",
      "166\tValidation loss: 0.415504\tBest loss: 0.411186\tAccuracy: 88.49%\n",
      "167\tValidation loss: 0.409193\tBest loss: 0.409193\tAccuracy: 89.21%\n",
      "168\tValidation loss: 0.409389\tBest loss: 0.409193\tAccuracy: 88.49%\n",
      "169\tValidation loss: 0.404087\tBest loss: 0.404087\tAccuracy: 88.49%\n",
      "170\tValidation loss: 0.401567\tBest loss: 0.401567\tAccuracy: 88.49%\n",
      "171\tValidation loss: 0.396034\tBest loss: 0.396034\tAccuracy: 88.49%\n",
      "172\tValidation loss: 0.396660\tBest loss: 0.396034\tAccuracy: 88.49%\n",
      "173\tValidation loss: 0.397733\tBest loss: 0.396034\tAccuracy: 89.21%\n",
      "174\tValidation loss: 0.402286\tBest loss: 0.396034\tAccuracy: 89.21%\n",
      "175\tValidation loss: 0.397250\tBest loss: 0.396034\tAccuracy: 88.49%\n",
      "176\tValidation loss: 0.401134\tBest loss: 0.396034\tAccuracy: 87.77%\n",
      "177\tValidation loss: 0.395471\tBest loss: 0.395471\tAccuracy: 88.49%\n",
      "178\tValidation loss: 0.397598\tBest loss: 0.395471\tAccuracy: 88.49%\n",
      "179\tValidation loss: 0.403996\tBest loss: 0.395471\tAccuracy: 88.49%\n",
      "180\tValidation loss: 0.399946\tBest loss: 0.395471\tAccuracy: 88.49%\n",
      "181\tValidation loss: 0.396376\tBest loss: 0.395471\tAccuracy: 88.49%\n",
      "182\tValidation loss: 0.394276\tBest loss: 0.394276\tAccuracy: 89.21%\n",
      "183\tValidation loss: 0.398820\tBest loss: 0.394276\tAccuracy: 89.21%\n",
      "184\tValidation loss: 0.409398\tBest loss: 0.394276\tAccuracy: 88.49%\n",
      "185\tValidation loss: 0.412252\tBest loss: 0.394276\tAccuracy: 87.77%\n",
      "186\tValidation loss: 0.408790\tBest loss: 0.394276\tAccuracy: 87.77%\n",
      "187\tValidation loss: 0.401628\tBest loss: 0.394276\tAccuracy: 88.49%\n",
      "188\tValidation loss: 0.398758\tBest loss: 0.394276\tAccuracy: 88.49%\n",
      "189\tValidation loss: 0.393521\tBest loss: 0.393521\tAccuracy: 87.77%\n",
      "190\tValidation loss: 0.394374\tBest loss: 0.393521\tAccuracy: 88.49%\n",
      "191\tValidation loss: 0.392126\tBest loss: 0.392126\tAccuracy: 88.49%\n",
      "192\tValidation loss: 0.387474\tBest loss: 0.387474\tAccuracy: 88.49%\n",
      "193\tValidation loss: 0.388519\tBest loss: 0.387474\tAccuracy: 89.21%\n",
      "194\tValidation loss: 0.396280\tBest loss: 0.387474\tAccuracy: 88.49%\n",
      "195\tValidation loss: 0.394629\tBest loss: 0.387474\tAccuracy: 89.21%\n",
      "196\tValidation loss: 0.393489\tBest loss: 0.387474\tAccuracy: 89.21%\n",
      "197\tValidation loss: 0.388724\tBest loss: 0.387474\tAccuracy: 89.93%\n",
      "198\tValidation loss: 0.386593\tBest loss: 0.386593\tAccuracy: 89.93%\n",
      "199\tValidation loss: 0.395685\tBest loss: 0.386593\tAccuracy: 88.49%\n",
      "200\tValidation loss: 0.381328\tBest loss: 0.381328\tAccuracy: 89.21%\n",
      "201\tValidation loss: 0.379693\tBest loss: 0.379693\tAccuracy: 89.21%\n",
      "202\tValidation loss: 0.383033\tBest loss: 0.379693\tAccuracy: 88.49%\n",
      "203\tValidation loss: 0.380610\tBest loss: 0.379693\tAccuracy: 87.77%\n",
      "204\tValidation loss: 0.379997\tBest loss: 0.379693\tAccuracy: 88.49%\n",
      "205\tValidation loss: 0.376236\tBest loss: 0.376236\tAccuracy: 88.49%\n",
      "206\tValidation loss: 0.377146\tBest loss: 0.376236\tAccuracy: 88.49%\n",
      "207\tValidation loss: 0.378259\tBest loss: 0.376236\tAccuracy: 88.49%\n",
      "208\tValidation loss: 0.374428\tBest loss: 0.374428\tAccuracy: 89.21%\n",
      "209\tValidation loss: 0.374948\tBest loss: 0.374428\tAccuracy: 89.21%\n",
      "210\tValidation loss: 0.375341\tBest loss: 0.374428\tAccuracy: 89.21%\n",
      "211\tValidation loss: 0.376045\tBest loss: 0.374428\tAccuracy: 88.49%\n",
      "212\tValidation loss: 0.378720\tBest loss: 0.374428\tAccuracy: 89.21%\n",
      "213\tValidation loss: 0.373377\tBest loss: 0.373377\tAccuracy: 89.21%\n",
      "214\tValidation loss: 0.372778\tBest loss: 0.372778\tAccuracy: 88.49%\n",
      "215\tValidation loss: 0.366520\tBest loss: 0.366520\tAccuracy: 90.65%\n",
      "216\tValidation loss: 0.368641\tBest loss: 0.366520\tAccuracy: 89.93%\n",
      "217\tValidation loss: 0.365552\tBest loss: 0.365552\tAccuracy: 90.65%\n",
      "218\tValidation loss: 0.364107\tBest loss: 0.364107\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.354943\tBest loss: 0.354943\tAccuracy: 90.65%\n",
      "220\tValidation loss: 0.359998\tBest loss: 0.354943\tAccuracy: 89.93%\n",
      "221\tValidation loss: 0.364213\tBest loss: 0.354943\tAccuracy: 89.21%\n",
      "222\tValidation loss: 0.363933\tBest loss: 0.354943\tAccuracy: 89.93%\n",
      "223\tValidation loss: 0.356086\tBest loss: 0.354943\tAccuracy: 89.93%\n",
      "224\tValidation loss: 0.361532\tBest loss: 0.354943\tAccuracy: 89.21%\n",
      "225\tValidation loss: 0.356542\tBest loss: 0.354943\tAccuracy: 88.49%\n",
      "226\tValidation loss: 0.353075\tBest loss: 0.353075\tAccuracy: 90.65%\n",
      "227\tValidation loss: 0.356278\tBest loss: 0.353075\tAccuracy: 90.65%\n",
      "228\tValidation loss: 0.354595\tBest loss: 0.353075\tAccuracy: 90.65%\n",
      "229\tValidation loss: 0.352740\tBest loss: 0.352740\tAccuracy: 90.65%\n",
      "230\tValidation loss: 0.357124\tBest loss: 0.352740\tAccuracy: 89.21%\n",
      "231\tValidation loss: 0.356845\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "232\tValidation loss: 0.357989\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "233\tValidation loss: 0.365089\tBest loss: 0.352740\tAccuracy: 89.21%\n",
      "234\tValidation loss: 0.367038\tBest loss: 0.352740\tAccuracy: 90.65%\n",
      "235\tValidation loss: 0.363831\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "236\tValidation loss: 0.364709\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "237\tValidation loss: 0.362467\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "238\tValidation loss: 0.362889\tBest loss: 0.352740\tAccuracy: 89.21%\n",
      "239\tValidation loss: 0.365705\tBest loss: 0.352740\tAccuracy: 89.21%\n",
      "240\tValidation loss: 0.366795\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "241\tValidation loss: 0.357679\tBest loss: 0.352740\tAccuracy: 89.93%\n",
      "242\tValidation loss: 0.350468\tBest loss: 0.350468\tAccuracy: 89.93%\n",
      "243\tValidation loss: 0.349619\tBest loss: 0.349619\tAccuracy: 90.65%\n",
      "244\tValidation loss: 0.346783\tBest loss: 0.346783\tAccuracy: 90.65%\n",
      "245\tValidation loss: 0.355040\tBest loss: 0.346783\tAccuracy: 89.21%\n",
      "246\tValidation loss: 0.348664\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "247\tValidation loss: 0.350627\tBest loss: 0.346783\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 0.352189\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "249\tValidation loss: 0.351147\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "250\tValidation loss: 0.355071\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "251\tValidation loss: 0.354985\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "252\tValidation loss: 0.352280\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "253\tValidation loss: 0.352801\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "254\tValidation loss: 0.354237\tBest loss: 0.346783\tAccuracy: 89.21%\n",
      "255\tValidation loss: 0.348590\tBest loss: 0.346783\tAccuracy: 89.93%\n",
      "256\tValidation loss: 0.346091\tBest loss: 0.346091\tAccuracy: 89.93%\n",
      "257\tValidation loss: 0.345467\tBest loss: 0.345467\tAccuracy: 89.93%\n",
      "258\tValidation loss: 0.349223\tBest loss: 0.345467\tAccuracy: 89.21%\n",
      "259\tValidation loss: 0.343046\tBest loss: 0.343046\tAccuracy: 90.65%\n",
      "260\tValidation loss: 0.347197\tBest loss: 0.343046\tAccuracy: 91.37%\n",
      "261\tValidation loss: 0.345437\tBest loss: 0.343046\tAccuracy: 89.93%\n",
      "262\tValidation loss: 0.350682\tBest loss: 0.343046\tAccuracy: 89.93%\n",
      "263\tValidation loss: 0.348334\tBest loss: 0.343046\tAccuracy: 89.93%\n",
      "264\tValidation loss: 0.342147\tBest loss: 0.342147\tAccuracy: 89.93%\n",
      "265\tValidation loss: 0.344018\tBest loss: 0.342147\tAccuracy: 89.93%\n",
      "266\tValidation loss: 0.339586\tBest loss: 0.339586\tAccuracy: 90.65%\n",
      "267\tValidation loss: 0.342608\tBest loss: 0.339586\tAccuracy: 89.21%\n",
      "268\tValidation loss: 0.341182\tBest loss: 0.339586\tAccuracy: 89.93%\n",
      "269\tValidation loss: 0.340253\tBest loss: 0.339586\tAccuracy: 89.21%\n",
      "270\tValidation loss: 0.343679\tBest loss: 0.339586\tAccuracy: 89.21%\n",
      "271\tValidation loss: 0.338439\tBest loss: 0.338439\tAccuracy: 89.93%\n",
      "272\tValidation loss: 0.337927\tBest loss: 0.337927\tAccuracy: 89.93%\n",
      "273\tValidation loss: 0.332896\tBest loss: 0.332896\tAccuracy: 89.21%\n",
      "274\tValidation loss: 0.325958\tBest loss: 0.325958\tAccuracy: 90.65%\n",
      "275\tValidation loss: 0.322799\tBest loss: 0.322799\tAccuracy: 91.37%\n",
      "276\tValidation loss: 0.321621\tBest loss: 0.321621\tAccuracy: 90.65%\n",
      "277\tValidation loss: 0.320222\tBest loss: 0.320222\tAccuracy: 90.65%\n",
      "278\tValidation loss: 0.319773\tBest loss: 0.319773\tAccuracy: 90.65%\n",
      "279\tValidation loss: 0.316707\tBest loss: 0.316707\tAccuracy: 89.93%\n",
      "280\tValidation loss: 0.320680\tBest loss: 0.316707\tAccuracy: 90.65%\n",
      "281\tValidation loss: 0.315850\tBest loss: 0.315850\tAccuracy: 89.93%\n",
      "282\tValidation loss: 0.319095\tBest loss: 0.315850\tAccuracy: 90.65%\n",
      "283\tValidation loss: 0.316214\tBest loss: 0.315850\tAccuracy: 91.37%\n",
      "284\tValidation loss: 0.322446\tBest loss: 0.315850\tAccuracy: 90.65%\n",
      "285\tValidation loss: 0.322777\tBest loss: 0.315850\tAccuracy: 89.93%\n",
      "286\tValidation loss: 0.317867\tBest loss: 0.315850\tAccuracy: 89.93%\n",
      "287\tValidation loss: 0.315373\tBest loss: 0.315373\tAccuracy: 89.93%\n",
      "288\tValidation loss: 0.316114\tBest loss: 0.315373\tAccuracy: 89.93%\n",
      "289\tValidation loss: 0.316726\tBest loss: 0.315373\tAccuracy: 89.93%\n",
      "290\tValidation loss: 0.320306\tBest loss: 0.315373\tAccuracy: 91.37%\n",
      "291\tValidation loss: 0.321256\tBest loss: 0.315373\tAccuracy: 89.93%\n",
      "292\tValidation loss: 0.320645\tBest loss: 0.315373\tAccuracy: 90.65%\n",
      "293\tValidation loss: 0.316675\tBest loss: 0.315373\tAccuracy: 92.09%\n",
      "294\tValidation loss: 0.316618\tBest loss: 0.315373\tAccuracy: 91.37%\n",
      "295\tValidation loss: 0.312074\tBest loss: 0.312074\tAccuracy: 91.37%\n",
      "296\tValidation loss: 0.315596\tBest loss: 0.312074\tAccuracy: 92.09%\n",
      "297\tValidation loss: 0.324913\tBest loss: 0.312074\tAccuracy: 89.93%\n",
      "298\tValidation loss: 0.320116\tBest loss: 0.312074\tAccuracy: 90.65%\n",
      "299\tValidation loss: 0.323691\tBest loss: 0.312074\tAccuracy: 89.21%\n",
      "300\tValidation loss: 0.326541\tBest loss: 0.312074\tAccuracy: 89.21%\n",
      "301\tValidation loss: 0.321221\tBest loss: 0.312074\tAccuracy: 89.93%\n",
      "302\tValidation loss: 0.322133\tBest loss: 0.312074\tAccuracy: 90.65%\n",
      "303\tValidation loss: 0.318583\tBest loss: 0.312074\tAccuracy: 90.65%\n",
      "304\tValidation loss: 0.317859\tBest loss: 0.312074\tAccuracy: 90.65%\n",
      "305\tValidation loss: 0.313746\tBest loss: 0.312074\tAccuracy: 89.93%\n",
      "306\tValidation loss: 0.310301\tBest loss: 0.310301\tAccuracy: 89.93%\n",
      "307\tValidation loss: 0.312638\tBest loss: 0.310301\tAccuracy: 89.93%\n",
      "308\tValidation loss: 0.319142\tBest loss: 0.310301\tAccuracy: 89.21%\n",
      "309\tValidation loss: 0.315247\tBest loss: 0.310301\tAccuracy: 89.21%\n",
      "310\tValidation loss: 0.310844\tBest loss: 0.310301\tAccuracy: 90.65%\n",
      "311\tValidation loss: 0.309791\tBest loss: 0.309791\tAccuracy: 89.93%\n",
      "312\tValidation loss: 0.300358\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "313\tValidation loss: 0.303552\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "314\tValidation loss: 0.304613\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "315\tValidation loss: 0.305389\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "316\tValidation loss: 0.304630\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "317\tValidation loss: 0.301811\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "318\tValidation loss: 0.308039\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "319\tValidation loss: 0.306341\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "320\tValidation loss: 0.308399\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "321\tValidation loss: 0.310230\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "322\tValidation loss: 0.306217\tBest loss: 0.300358\tAccuracy: 89.21%\n",
      "323\tValidation loss: 0.300654\tBest loss: 0.300358\tAccuracy: 90.65%\n",
      "324\tValidation loss: 0.300751\tBest loss: 0.300358\tAccuracy: 91.37%\n",
      "325\tValidation loss: 0.305595\tBest loss: 0.300358\tAccuracy: 89.93%\n",
      "326\tValidation loss: 0.308872\tBest loss: 0.300358\tAccuracy: 89.21%\n",
      "327\tValidation loss: 0.299733\tBest loss: 0.299733\tAccuracy: 91.37%\n",
      "328\tValidation loss: 0.302551\tBest loss: 0.299733\tAccuracy: 89.21%\n",
      "329\tValidation loss: 0.305430\tBest loss: 0.299733\tAccuracy: 89.93%\n",
      "330\tValidation loss: 0.310489\tBest loss: 0.299733\tAccuracy: 88.49%\n",
      "331\tValidation loss: 0.301706\tBest loss: 0.299733\tAccuracy: 89.93%\n",
      "332\tValidation loss: 0.302062\tBest loss: 0.299733\tAccuracy: 90.65%\n",
      "333\tValidation loss: 0.302253\tBest loss: 0.299733\tAccuracy: 89.93%\n",
      "334\tValidation loss: 0.303075\tBest loss: 0.299733\tAccuracy: 89.93%\n",
      "335\tValidation loss: 0.302199\tBest loss: 0.299733\tAccuracy: 89.93%\n",
      "336\tValidation loss: 0.303563\tBest loss: 0.299733\tAccuracy: 90.65%\n",
      "337\tValidation loss: 0.300813\tBest loss: 0.299733\tAccuracy: 91.37%\n",
      "338\tValidation loss: 0.298105\tBest loss: 0.298105\tAccuracy: 91.37%\n",
      "339\tValidation loss: 0.297686\tBest loss: 0.297686\tAccuracy: 91.37%\n",
      "340\tValidation loss: 0.298416\tBest loss: 0.297686\tAccuracy: 89.93%\n",
      "341\tValidation loss: 0.297608\tBest loss: 0.297608\tAccuracy: 91.37%\n",
      "342\tValidation loss: 0.295842\tBest loss: 0.295842\tAccuracy: 92.09%\n",
      "343\tValidation loss: 0.295537\tBest loss: 0.295537\tAccuracy: 90.65%\n",
      "344\tValidation loss: 0.292636\tBest loss: 0.292636\tAccuracy: 91.37%\n",
      "345\tValidation loss: 0.291463\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "346\tValidation loss: 0.295978\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "347\tValidation loss: 0.296009\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "348\tValidation loss: 0.295701\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "349\tValidation loss: 0.297059\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "350\tValidation loss: 0.299476\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "351\tValidation loss: 0.294854\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "352\tValidation loss: 0.294276\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "353\tValidation loss: 0.298470\tBest loss: 0.291463\tAccuracy: 89.93%\n",
      "354\tValidation loss: 0.298618\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "355\tValidation loss: 0.298820\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "356\tValidation loss: 0.297993\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "357\tValidation loss: 0.301571\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "358\tValidation loss: 0.298766\tBest loss: 0.291463\tAccuracy: 90.65%\n",
      "359\tValidation loss: 0.293318\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "360\tValidation loss: 0.295845\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "361\tValidation loss: 0.292798\tBest loss: 0.291463\tAccuracy: 91.37%\n",
      "362\tValidation loss: 0.291271\tBest loss: 0.291271\tAccuracy: 91.37%\n",
      "363\tValidation loss: 0.289889\tBest loss: 0.289889\tAccuracy: 92.09%\n",
      "364\tValidation loss: 0.291965\tBest loss: 0.289889\tAccuracy: 92.09%\n",
      "365\tValidation loss: 0.289485\tBest loss: 0.289485\tAccuracy: 91.37%\n",
      "366\tValidation loss: 0.291164\tBest loss: 0.289485\tAccuracy: 91.37%\n",
      "367\tValidation loss: 0.292032\tBest loss: 0.289485\tAccuracy: 92.09%\n",
      "368\tValidation loss: 0.288633\tBest loss: 0.288633\tAccuracy: 92.09%\n",
      "369\tValidation loss: 0.289057\tBest loss: 0.288633\tAccuracy: 92.09%\n",
      "370\tValidation loss: 0.291402\tBest loss: 0.288633\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\tValidation loss: 0.290796\tBest loss: 0.288633\tAccuracy: 91.37%\n",
      "372\tValidation loss: 0.294931\tBest loss: 0.288633\tAccuracy: 92.09%\n",
      "373\tValidation loss: 0.294601\tBest loss: 0.288633\tAccuracy: 91.37%\n",
      "374\tValidation loss: 0.289930\tBest loss: 0.288633\tAccuracy: 92.09%\n",
      "375\tValidation loss: 0.292241\tBest loss: 0.288633\tAccuracy: 91.37%\n",
      "376\tValidation loss: 0.289671\tBest loss: 0.288633\tAccuracy: 91.37%\n",
      "377\tValidation loss: 0.285409\tBest loss: 0.285409\tAccuracy: 91.37%\n",
      "378\tValidation loss: 0.285353\tBest loss: 0.285353\tAccuracy: 91.37%\n",
      "379\tValidation loss: 0.289491\tBest loss: 0.285353\tAccuracy: 91.37%\n",
      "380\tValidation loss: 0.288041\tBest loss: 0.285353\tAccuracy: 92.09%\n",
      "381\tValidation loss: 0.289028\tBest loss: 0.285353\tAccuracy: 92.09%\n",
      "382\tValidation loss: 0.288073\tBest loss: 0.285353\tAccuracy: 91.37%\n",
      "383\tValidation loss: 0.291876\tBest loss: 0.285353\tAccuracy: 90.65%\n",
      "384\tValidation loss: 0.285897\tBest loss: 0.285353\tAccuracy: 92.09%\n",
      "385\tValidation loss: 0.280584\tBest loss: 0.280584\tAccuracy: 92.81%\n",
      "386\tValidation loss: 0.283892\tBest loss: 0.280584\tAccuracy: 92.09%\n",
      "387\tValidation loss: 0.284212\tBest loss: 0.280584\tAccuracy: 92.09%\n",
      "388\tValidation loss: 0.278364\tBest loss: 0.278364\tAccuracy: 92.81%\n",
      "389\tValidation loss: 0.278203\tBest loss: 0.278203\tAccuracy: 92.81%\n",
      "390\tValidation loss: 0.279393\tBest loss: 0.278203\tAccuracy: 92.81%\n",
      "391\tValidation loss: 0.276704\tBest loss: 0.276704\tAccuracy: 92.81%\n",
      "392\tValidation loss: 0.279255\tBest loss: 0.276704\tAccuracy: 92.81%\n",
      "393\tValidation loss: 0.280510\tBest loss: 0.276704\tAccuracy: 92.09%\n",
      "394\tValidation loss: 0.277764\tBest loss: 0.276704\tAccuracy: 92.81%\n",
      "395\tValidation loss: 0.278784\tBest loss: 0.276704\tAccuracy: 91.37%\n",
      "396\tValidation loss: 0.277001\tBest loss: 0.276704\tAccuracy: 93.53%\n",
      "397\tValidation loss: 0.278323\tBest loss: 0.276704\tAccuracy: 91.37%\n",
      "398\tValidation loss: 0.279049\tBest loss: 0.276704\tAccuracy: 92.09%\n",
      "399\tValidation loss: 0.278360\tBest loss: 0.276704\tAccuracy: 91.37%\n",
      "400\tValidation loss: 0.278006\tBest loss: 0.276704\tAccuracy: 92.09%\n",
      "401\tValidation loss: 0.277700\tBest loss: 0.276704\tAccuracy: 92.81%\n",
      "402\tValidation loss: 0.273928\tBest loss: 0.273928\tAccuracy: 94.24%\n",
      "403\tValidation loss: 0.275876\tBest loss: 0.273928\tAccuracy: 94.24%\n",
      "404\tValidation loss: 0.278122\tBest loss: 0.273928\tAccuracy: 94.24%\n",
      "405\tValidation loss: 0.270306\tBest loss: 0.270306\tAccuracy: 93.53%\n",
      "406\tValidation loss: 0.273135\tBest loss: 0.270306\tAccuracy: 93.53%\n",
      "407\tValidation loss: 0.271017\tBest loss: 0.270306\tAccuracy: 94.24%\n",
      "408\tValidation loss: 0.270044\tBest loss: 0.270044\tAccuracy: 93.53%\n",
      "409\tValidation loss: 0.269914\tBest loss: 0.269914\tAccuracy: 94.24%\n",
      "410\tValidation loss: 0.270138\tBest loss: 0.269914\tAccuracy: 93.53%\n",
      "411\tValidation loss: 0.268390\tBest loss: 0.268390\tAccuracy: 92.81%\n",
      "412\tValidation loss: 0.268024\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "413\tValidation loss: 0.272155\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "414\tValidation loss: 0.269431\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "415\tValidation loss: 0.273042\tBest loss: 0.268024\tAccuracy: 92.09%\n",
      "416\tValidation loss: 0.273325\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "417\tValidation loss: 0.272372\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "418\tValidation loss: 0.273207\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "419\tValidation loss: 0.274736\tBest loss: 0.268024\tAccuracy: 92.81%\n",
      "420\tValidation loss: 0.274834\tBest loss: 0.268024\tAccuracy: 91.37%\n",
      "421\tValidation loss: 0.276120\tBest loss: 0.268024\tAccuracy: 92.81%\n",
      "422\tValidation loss: 0.273339\tBest loss: 0.268024\tAccuracy: 93.53%\n",
      "423\tValidation loss: 0.274697\tBest loss: 0.268024\tAccuracy: 92.09%\n",
      "424\tValidation loss: 0.274252\tBest loss: 0.268024\tAccuracy: 92.09%\n",
      "425\tValidation loss: 0.266080\tBest loss: 0.266080\tAccuracy: 92.81%\n",
      "426\tValidation loss: 0.267634\tBest loss: 0.266080\tAccuracy: 93.53%\n",
      "427\tValidation loss: 0.265631\tBest loss: 0.265631\tAccuracy: 93.53%\n",
      "428\tValidation loss: 0.267729\tBest loss: 0.265631\tAccuracy: 94.24%\n",
      "429\tValidation loss: 0.270986\tBest loss: 0.265631\tAccuracy: 93.53%\n",
      "430\tValidation loss: 0.271241\tBest loss: 0.265631\tAccuracy: 92.81%\n",
      "431\tValidation loss: 0.271290\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "432\tValidation loss: 0.273534\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "433\tValidation loss: 0.272248\tBest loss: 0.265631\tAccuracy: 91.37%\n",
      "434\tValidation loss: 0.271199\tBest loss: 0.265631\tAccuracy: 91.37%\n",
      "435\tValidation loss: 0.271794\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "436\tValidation loss: 0.270500\tBest loss: 0.265631\tAccuracy: 92.81%\n",
      "437\tValidation loss: 0.273163\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "438\tValidation loss: 0.271385\tBest loss: 0.265631\tAccuracy: 92.81%\n",
      "439\tValidation loss: 0.267390\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "440\tValidation loss: 0.270826\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "441\tValidation loss: 0.269528\tBest loss: 0.265631\tAccuracy: 92.09%\n",
      "442\tValidation loss: 0.268823\tBest loss: 0.265631\tAccuracy: 92.81%\n",
      "443\tValidation loss: 0.268803\tBest loss: 0.265631\tAccuracy: 91.37%\n",
      "444\tValidation loss: 0.264818\tBest loss: 0.264818\tAccuracy: 92.09%\n",
      "445\tValidation loss: 0.269047\tBest loss: 0.264818\tAccuracy: 92.09%\n",
      "446\tValidation loss: 0.269695\tBest loss: 0.264818\tAccuracy: 91.37%\n",
      "447\tValidation loss: 0.269468\tBest loss: 0.264818\tAccuracy: 91.37%\n",
      "448\tValidation loss: 0.269140\tBest loss: 0.264818\tAccuracy: 91.37%\n",
      "449\tValidation loss: 0.269052\tBest loss: 0.264818\tAccuracy: 92.81%\n",
      "450\tValidation loss: 0.264397\tBest loss: 0.264397\tAccuracy: 92.81%\n",
      "451\tValidation loss: 0.258275\tBest loss: 0.258275\tAccuracy: 93.53%\n",
      "452\tValidation loss: 0.258487\tBest loss: 0.258275\tAccuracy: 93.53%\n",
      "453\tValidation loss: 0.259619\tBest loss: 0.258275\tAccuracy: 92.81%\n",
      "454\tValidation loss: 0.262913\tBest loss: 0.258275\tAccuracy: 92.81%\n",
      "455\tValidation loss: 0.266026\tBest loss: 0.258275\tAccuracy: 93.53%\n",
      "456\tValidation loss: 0.265701\tBest loss: 0.258275\tAccuracy: 92.09%\n",
      "457\tValidation loss: 0.265242\tBest loss: 0.258275\tAccuracy: 92.09%\n",
      "458\tValidation loss: 0.262768\tBest loss: 0.258275\tAccuracy: 93.53%\n",
      "459\tValidation loss: 0.261683\tBest loss: 0.258275\tAccuracy: 92.81%\n",
      "460\tValidation loss: 0.259222\tBest loss: 0.258275\tAccuracy: 93.53%\n",
      "461\tValidation loss: 0.257872\tBest loss: 0.257872\tAccuracy: 94.24%\n",
      "462\tValidation loss: 0.254600\tBest loss: 0.254600\tAccuracy: 94.24%\n",
      "463\tValidation loss: 0.258484\tBest loss: 0.254600\tAccuracy: 94.24%\n",
      "464\tValidation loss: 0.259272\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "465\tValidation loss: 0.261567\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "466\tValidation loss: 0.260202\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "467\tValidation loss: 0.258916\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "468\tValidation loss: 0.258390\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "469\tValidation loss: 0.257568\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "470\tValidation loss: 0.258721\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "471\tValidation loss: 0.260156\tBest loss: 0.254600\tAccuracy: 92.09%\n",
      "472\tValidation loss: 0.256451\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "473\tValidation loss: 0.258475\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "474\tValidation loss: 0.261087\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "475\tValidation loss: 0.259969\tBest loss: 0.254600\tAccuracy: 92.09%\n",
      "476\tValidation loss: 0.261028\tBest loss: 0.254600\tAccuracy: 92.09%\n",
      "477\tValidation loss: 0.262892\tBest loss: 0.254600\tAccuracy: 93.53%\n",
      "478\tValidation loss: 0.264399\tBest loss: 0.254600\tAccuracy: 91.37%\n",
      "479\tValidation loss: 0.266531\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "480\tValidation loss: 0.264792\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "481\tValidation loss: 0.265319\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "482\tValidation loss: 0.262461\tBest loss: 0.254600\tAccuracy: 92.09%\n",
      "483\tValidation loss: 0.264849\tBest loss: 0.254600\tAccuracy: 92.81%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  53.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 6.030608\tBest loss: 6.030608\tAccuracy: 25.90%\n",
      "1\tValidation loss: 21.790359\tBest loss: 6.030608\tAccuracy: 32.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\tValidation loss: 11.673184\tBest loss: 6.030608\tAccuracy: 55.40%\n",
      "3\tValidation loss: 15.219469\tBest loss: 6.030608\tAccuracy: 67.63%\n",
      "4\tValidation loss: 9.399362\tBest loss: 6.030608\tAccuracy: 70.50%\n",
      "5\tValidation loss: 15.219438\tBest loss: 6.030608\tAccuracy: 68.35%\n",
      "6\tValidation loss: 6.497176\tBest loss: 6.030608\tAccuracy: 79.86%\n",
      "7\tValidation loss: 10.359752\tBest loss: 6.030608\tAccuracy: 79.86%\n",
      "8\tValidation loss: 6.500898\tBest loss: 6.030608\tAccuracy: 82.73%\n",
      "9\tValidation loss: 8.165427\tBest loss: 6.030608\tAccuracy: 81.29%\n",
      "10\tValidation loss: 8.975989\tBest loss: 6.030608\tAccuracy: 79.86%\n",
      "11\tValidation loss: 8.715972\tBest loss: 6.030608\tAccuracy: 81.29%\n",
      "12\tValidation loss: 15.852048\tBest loss: 6.030608\tAccuracy: 80.58%\n",
      "13\tValidation loss: 5.431739\tBest loss: 5.431739\tAccuracy: 82.01%\n",
      "14\tValidation loss: 5.779327\tBest loss: 5.431739\tAccuracy: 82.01%\n",
      "15\tValidation loss: 10.286968\tBest loss: 5.431739\tAccuracy: 82.73%\n",
      "16\tValidation loss: 13.469550\tBest loss: 5.431739\tAccuracy: 79.14%\n",
      "17\tValidation loss: 13.248369\tBest loss: 5.431739\tAccuracy: 79.86%\n",
      "18\tValidation loss: 5.711171\tBest loss: 5.431739\tAccuracy: 88.49%\n",
      "19\tValidation loss: 6.033221\tBest loss: 5.431739\tAccuracy: 89.93%\n",
      "20\tValidation loss: 12.877505\tBest loss: 5.431739\tAccuracy: 83.45%\n",
      "21\tValidation loss: 12.494970\tBest loss: 5.431739\tAccuracy: 81.29%\n",
      "22\tValidation loss: 9.587540\tBest loss: 5.431739\tAccuracy: 83.45%\n",
      "23\tValidation loss: 6.214433\tBest loss: 5.431739\tAccuracy: 86.33%\n",
      "24\tValidation loss: 10.054705\tBest loss: 5.431739\tAccuracy: 82.01%\n",
      "25\tValidation loss: 11.448778\tBest loss: 5.431739\tAccuracy: 79.86%\n",
      "26\tValidation loss: 7.876119\tBest loss: 5.431739\tAccuracy: 89.21%\n",
      "27\tValidation loss: 12.431455\tBest loss: 5.431739\tAccuracy: 85.61%\n",
      "28\tValidation loss: 14.372458\tBest loss: 5.431739\tAccuracy: 84.17%\n",
      "29\tValidation loss: 13.712862\tBest loss: 5.431739\tAccuracy: 82.01%\n",
      "30\tValidation loss: 14.076951\tBest loss: 5.431739\tAccuracy: 85.61%\n",
      "31\tValidation loss: 5.777931\tBest loss: 5.431739\tAccuracy: 87.77%\n",
      "32\tValidation loss: 10.205835\tBest loss: 5.431739\tAccuracy: 86.33%\n",
      "33\tValidation loss: 7.012161\tBest loss: 5.431739\tAccuracy: 89.21%\n",
      "34\tValidation loss: 8.677154\tBest loss: 5.431739\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=   7.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 16.524113\tBest loss: 16.524113\tAccuracy: 20.86%\n",
      "1\tValidation loss: 18.279457\tBest loss: 16.524113\tAccuracy: 41.73%\n",
      "2\tValidation loss: 11.711048\tBest loss: 11.711048\tAccuracy: 63.31%\n",
      "3\tValidation loss: 9.196198\tBest loss: 9.196198\tAccuracy: 68.35%\n",
      "4\tValidation loss: 9.479092\tBest loss: 9.196198\tAccuracy: 71.22%\n",
      "5\tValidation loss: 6.387208\tBest loss: 6.387208\tAccuracy: 73.38%\n",
      "6\tValidation loss: 9.542064\tBest loss: 6.387208\tAccuracy: 76.98%\n",
      "7\tValidation loss: 8.398026\tBest loss: 6.387208\tAccuracy: 77.70%\n",
      "8\tValidation loss: 5.188910\tBest loss: 5.188910\tAccuracy: 87.05%\n",
      "9\tValidation loss: 5.890215\tBest loss: 5.188910\tAccuracy: 81.29%\n",
      "10\tValidation loss: 6.293723\tBest loss: 5.188910\tAccuracy: 83.45%\n",
      "11\tValidation loss: 5.687260\tBest loss: 5.188910\tAccuracy: 82.01%\n",
      "12\tValidation loss: 10.368624\tBest loss: 5.188910\tAccuracy: 82.01%\n",
      "13\tValidation loss: 7.567860\tBest loss: 5.188910\tAccuracy: 82.73%\n",
      "14\tValidation loss: 9.842859\tBest loss: 5.188910\tAccuracy: 82.73%\n",
      "15\tValidation loss: 11.693741\tBest loss: 5.188910\tAccuracy: 82.01%\n",
      "16\tValidation loss: 3.385095\tBest loss: 3.385095\tAccuracy: 87.77%\n",
      "17\tValidation loss: 13.512238\tBest loss: 3.385095\tAccuracy: 83.45%\n",
      "18\tValidation loss: 17.384539\tBest loss: 3.385095\tAccuracy: 79.86%\n",
      "19\tValidation loss: 15.587664\tBest loss: 3.385095\tAccuracy: 80.58%\n",
      "20\tValidation loss: 6.580306\tBest loss: 3.385095\tAccuracy: 84.17%\n",
      "21\tValidation loss: 14.265253\tBest loss: 3.385095\tAccuracy: 78.42%\n",
      "22\tValidation loss: 8.945313\tBest loss: 3.385095\tAccuracy: 87.05%\n",
      "23\tValidation loss: 6.306144\tBest loss: 3.385095\tAccuracy: 84.89%\n",
      "24\tValidation loss: 5.936964\tBest loss: 3.385095\tAccuracy: 86.33%\n",
      "25\tValidation loss: 21.076748\tBest loss: 3.385095\tAccuracy: 75.54%\n",
      "26\tValidation loss: 7.137661\tBest loss: 3.385095\tAccuracy: 87.05%\n",
      "27\tValidation loss: 9.405996\tBest loss: 3.385095\tAccuracy: 84.89%\n",
      "28\tValidation loss: 9.443278\tBest loss: 3.385095\tAccuracy: 87.77%\n",
      "29\tValidation loss: 10.188725\tBest loss: 3.385095\tAccuracy: 85.61%\n",
      "30\tValidation loss: 7.350066\tBest loss: 3.385095\tAccuracy: 88.49%\n",
      "31\tValidation loss: 3.082160\tBest loss: 3.082160\tAccuracy: 92.81%\n",
      "32\tValidation loss: 4.351601\tBest loss: 3.082160\tAccuracy: 92.81%\n",
      "33\tValidation loss: 6.844560\tBest loss: 3.082160\tAccuracy: 88.49%\n",
      "34\tValidation loss: 14.485582\tBest loss: 3.082160\tAccuracy: 83.45%\n",
      "35\tValidation loss: 8.387809\tBest loss: 3.082160\tAccuracy: 87.77%\n",
      "36\tValidation loss: 13.192445\tBest loss: 3.082160\tAccuracy: 84.17%\n",
      "37\tValidation loss: 7.418048\tBest loss: 3.082160\tAccuracy: 90.65%\n",
      "38\tValidation loss: 4.878036\tBest loss: 3.082160\tAccuracy: 91.37%\n",
      "39\tValidation loss: 12.878600\tBest loss: 3.082160\tAccuracy: 84.17%\n",
      "40\tValidation loss: 22.916719\tBest loss: 3.082160\tAccuracy: 86.33%\n",
      "41\tValidation loss: 7.231350\tBest loss: 3.082160\tAccuracy: 89.93%\n",
      "42\tValidation loss: 6.668201\tBest loss: 3.082160\tAccuracy: 92.09%\n",
      "43\tValidation loss: 11.706655\tBest loss: 3.082160\tAccuracy: 87.05%\n",
      "44\tValidation loss: 3.782576\tBest loss: 3.082160\tAccuracy: 90.65%\n",
      "45\tValidation loss: 6.692107\tBest loss: 3.082160\tAccuracy: 90.65%\n",
      "46\tValidation loss: 8.570817\tBest loss: 3.082160\tAccuracy: 90.65%\n",
      "47\tValidation loss: 12.407990\tBest loss: 3.082160\tAccuracy: 87.05%\n",
      "48\tValidation loss: 7.264773\tBest loss: 3.082160\tAccuracy: 86.33%\n",
      "49\tValidation loss: 9.980677\tBest loss: 3.082160\tAccuracy: 87.05%\n",
      "50\tValidation loss: 15.885382\tBest loss: 3.082160\tAccuracy: 86.33%\n",
      "51\tValidation loss: 8.107875\tBest loss: 3.082160\tAccuracy: 87.77%\n",
      "52\tValidation loss: 8.105183\tBest loss: 3.082160\tAccuracy: 87.05%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  12.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 6.901161\tBest loss: 6.901161\tAccuracy: 36.69%\n",
      "1\tValidation loss: 14.254731\tBest loss: 6.901161\tAccuracy: 49.64%\n",
      "2\tValidation loss: 12.565206\tBest loss: 6.901161\tAccuracy: 59.71%\n",
      "3\tValidation loss: 8.720770\tBest loss: 6.901161\tAccuracy: 71.94%\n",
      "4\tValidation loss: 15.072201\tBest loss: 6.901161\tAccuracy: 68.35%\n",
      "5\tValidation loss: 11.927107\tBest loss: 6.901161\tAccuracy: 71.94%\n",
      "6\tValidation loss: 7.286364\tBest loss: 6.901161\tAccuracy: 79.14%\n",
      "7\tValidation loss: 7.671318\tBest loss: 6.901161\tAccuracy: 80.58%\n",
      "8\tValidation loss: 13.022978\tBest loss: 6.901161\tAccuracy: 74.82%\n",
      "9\tValidation loss: 8.371691\tBest loss: 6.901161\tAccuracy: 85.61%\n",
      "10\tValidation loss: 4.768515\tBest loss: 4.768515\tAccuracy: 84.17%\n",
      "11\tValidation loss: 8.129921\tBest loss: 4.768515\tAccuracy: 84.17%\n",
      "12\tValidation loss: 8.543435\tBest loss: 4.768515\tAccuracy: 82.01%\n",
      "13\tValidation loss: 4.616838\tBest loss: 4.616838\tAccuracy: 87.77%\n",
      "14\tValidation loss: 3.618592\tBest loss: 3.618592\tAccuracy: 90.65%\n",
      "15\tValidation loss: 9.623567\tBest loss: 3.618592\tAccuracy: 83.45%\n",
      "16\tValidation loss: 6.953052\tBest loss: 3.618592\tAccuracy: 84.89%\n",
      "17\tValidation loss: 8.777802\tBest loss: 3.618592\tAccuracy: 84.17%\n",
      "18\tValidation loss: 16.984907\tBest loss: 3.618592\tAccuracy: 76.26%\n",
      "19\tValidation loss: 7.546766\tBest loss: 3.618592\tAccuracy: 87.77%\n",
      "20\tValidation loss: 7.436337\tBest loss: 3.618592\tAccuracy: 87.77%\n",
      "21\tValidation loss: 7.625556\tBest loss: 3.618592\tAccuracy: 88.49%\n",
      "22\tValidation loss: 9.072329\tBest loss: 3.618592\tAccuracy: 86.33%\n",
      "23\tValidation loss: 12.831216\tBest loss: 3.618592\tAccuracy: 79.14%\n",
      "24\tValidation loss: 15.405385\tBest loss: 3.618592\tAccuracy: 84.17%\n",
      "25\tValidation loss: 19.427197\tBest loss: 3.618592\tAccuracy: 82.01%\n",
      "26\tValidation loss: 18.334396\tBest loss: 3.618592\tAccuracy: 82.01%\n",
      "27\tValidation loss: 13.989886\tBest loss: 3.618592\tAccuracy: 84.17%\n",
      "28\tValidation loss: 11.166677\tBest loss: 3.618592\tAccuracy: 84.89%\n",
      "29\tValidation loss: 17.493181\tBest loss: 3.618592\tAccuracy: 83.45%\n",
      "30\tValidation loss: 12.714124\tBest loss: 3.618592\tAccuracy: 85.61%\n",
      "31\tValidation loss: 7.459078\tBest loss: 3.618592\tAccuracy: 89.93%\n",
      "32\tValidation loss: 5.555041\tBest loss: 3.618592\tAccuracy: 89.93%\n",
      "33\tValidation loss: 6.362608\tBest loss: 3.618592\tAccuracy: 89.21%\n",
      "34\tValidation loss: 6.981414\tBest loss: 3.618592\tAccuracy: 90.65%\n",
      "35\tValidation loss: 7.662377\tBest loss: 3.618592\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=   8.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 8923374592.000000\tBest loss: 8923374592.000000\tAccuracy: 6.47%\n",
      "1\tValidation loss: 24488810.000000\tBest loss: 24488810.000000\tAccuracy: 2.88%\n",
      "2\tValidation loss: 7123672.000000\tBest loss: 7123672.000000\tAccuracy: 2.88%\n",
      "3\tValidation loss: 3028660.750000\tBest loss: 3028660.750000\tAccuracy: 3.60%\n",
      "4\tValidation loss: 2563990.250000\tBest loss: 2563990.250000\tAccuracy: 0.72%\n",
      "5\tValidation loss: 1455127.125000\tBest loss: 1455127.125000\tAccuracy: 1.44%\n",
      "6\tValidation loss: 1100705.125000\tBest loss: 1100705.125000\tAccuracy: 0.72%\n",
      "7\tValidation loss: 1084849.250000\tBest loss: 1084849.250000\tAccuracy: 0.72%\n",
      "8\tValidation loss: 960275.437500\tBest loss: 960275.437500\tAccuracy: 0.72%\n",
      "9\tValidation loss: 873961.125000\tBest loss: 873961.125000\tAccuracy: 0.72%\n",
      "10\tValidation loss: 627793.875000\tBest loss: 627793.875000\tAccuracy: 0.72%\n",
      "11\tValidation loss: 505419.000000\tBest loss: 505419.000000\tAccuracy: 0.72%\n",
      "12\tValidation loss: 547897.187500\tBest loss: 505419.000000\tAccuracy: 2.88%\n",
      "13\tValidation loss: 522375.625000\tBest loss: 505419.000000\tAccuracy: 0.72%\n",
      "14\tValidation loss: 456777.156250\tBest loss: 456777.156250\tAccuracy: 1.44%\n",
      "15\tValidation loss: 377311.156250\tBest loss: 377311.156250\tAccuracy: 4.32%\n",
      "16\tValidation loss: 367228.531250\tBest loss: 367228.531250\tAccuracy: 2.88%\n",
      "17\tValidation loss: 334248.218750\tBest loss: 334248.218750\tAccuracy: 0.00%\n",
      "18\tValidation loss: 343076.687500\tBest loss: 334248.218750\tAccuracy: 0.00%\n",
      "19\tValidation loss: 297986.187500\tBest loss: 297986.187500\tAccuracy: 1.44%\n",
      "20\tValidation loss: 301417.468750\tBest loss: 297986.187500\tAccuracy: 2.88%\n",
      "21\tValidation loss: 345293.500000\tBest loss: 297986.187500\tAccuracy: 6.47%\n",
      "22\tValidation loss: 307241.312500\tBest loss: 297986.187500\tAccuracy: 1.44%\n",
      "23\tValidation loss: 436800.812500\tBest loss: 297986.187500\tAccuracy: 6.47%\n",
      "24\tValidation loss: 294018.093750\tBest loss: 294018.093750\tAccuracy: 5.76%\n",
      "25\tValidation loss: 293423.906250\tBest loss: 293423.906250\tAccuracy: 3.60%\n",
      "26\tValidation loss: 284001.812500\tBest loss: 284001.812500\tAccuracy: 2.16%\n",
      "27\tValidation loss: 289076.843750\tBest loss: 284001.812500\tAccuracy: 1.44%\n",
      "28\tValidation loss: 232118.203125\tBest loss: 232118.203125\tAccuracy: 1.44%\n",
      "29\tValidation loss: 238869.562500\tBest loss: 232118.203125\tAccuracy: 2.88%\n",
      "30\tValidation loss: 303584.593750\tBest loss: 232118.203125\tAccuracy: 2.16%\n",
      "31\tValidation loss: 286546.125000\tBest loss: 232118.203125\tAccuracy: 3.60%\n",
      "32\tValidation loss: 264974.750000\tBest loss: 232118.203125\tAccuracy: 2.16%\n",
      "33\tValidation loss: 241901.031250\tBest loss: 232118.203125\tAccuracy: 2.88%\n",
      "34\tValidation loss: 238639.468750\tBest loss: 232118.203125\tAccuracy: 0.72%\n",
      "35\tValidation loss: 209681.109375\tBest loss: 209681.109375\tAccuracy: 2.16%\n",
      "36\tValidation loss: 236581.531250\tBest loss: 209681.109375\tAccuracy: 1.44%\n",
      "37\tValidation loss: 233957.609375\tBest loss: 209681.109375\tAccuracy: 0.72%\n",
      "38\tValidation loss: 211151.812500\tBest loss: 209681.109375\tAccuracy: 2.16%\n",
      "39\tValidation loss: 220447.812500\tBest loss: 209681.109375\tAccuracy: 5.76%\n",
      "40\tValidation loss: 197791.656250\tBest loss: 197791.656250\tAccuracy: 1.44%\n",
      "41\tValidation loss: 184600.046875\tBest loss: 184600.046875\tAccuracy: 1.44%\n",
      "42\tValidation loss: 193350.203125\tBest loss: 184600.046875\tAccuracy: 0.00%\n",
      "43\tValidation loss: 174088.125000\tBest loss: 174088.125000\tAccuracy: 0.72%\n",
      "44\tValidation loss: 201601.984375\tBest loss: 174088.125000\tAccuracy: 0.72%\n",
      "45\tValidation loss: 175212.203125\tBest loss: 174088.125000\tAccuracy: 0.00%\n",
      "46\tValidation loss: 156787.046875\tBest loss: 156787.046875\tAccuracy: 0.72%\n",
      "47\tValidation loss: 171778.046875\tBest loss: 156787.046875\tAccuracy: 0.72%\n",
      "48\tValidation loss: 180423.156250\tBest loss: 156787.046875\tAccuracy: 0.00%\n",
      "49\tValidation loss: 152849.015625\tBest loss: 152849.015625\tAccuracy: 0.72%\n",
      "50\tValidation loss: 157987.921875\tBest loss: 152849.015625\tAccuracy: 0.72%\n",
      "51\tValidation loss: 137871.531250\tBest loss: 137871.531250\tAccuracy: 2.16%\n",
      "52\tValidation loss: 134447.546875\tBest loss: 134447.546875\tAccuracy: 1.44%\n",
      "53\tValidation loss: 135848.046875\tBest loss: 134447.546875\tAccuracy: 2.88%\n",
      "54\tValidation loss: 170200.765625\tBest loss: 134447.546875\tAccuracy: 0.72%\n",
      "55\tValidation loss: 150796.406250\tBest loss: 134447.546875\tAccuracy: 0.72%\n",
      "56\tValidation loss: 182831.000000\tBest loss: 134447.546875\tAccuracy: 2.16%\n",
      "57\tValidation loss: 162130.812500\tBest loss: 134447.546875\tAccuracy: 1.44%\n",
      "58\tValidation loss: 164718.796875\tBest loss: 134447.546875\tAccuracy: 0.72%\n",
      "59\tValidation loss: 148946.656250\tBest loss: 134447.546875\tAccuracy: 1.44%\n",
      "60\tValidation loss: 137074.109375\tBest loss: 134447.546875\tAccuracy: 2.16%\n",
      "61\tValidation loss: 111774.312500\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "62\tValidation loss: 126619.218750\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "63\tValidation loss: 123608.023438\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "64\tValidation loss: 147194.109375\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "65\tValidation loss: 136062.468750\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "66\tValidation loss: 128559.039062\tBest loss: 111774.312500\tAccuracy: 1.44%\n",
      "67\tValidation loss: 130989.070312\tBest loss: 111774.312500\tAccuracy: 0.72%\n",
      "68\tValidation loss: 105162.609375\tBest loss: 105162.609375\tAccuracy: 1.44%\n",
      "69\tValidation loss: 111121.945312\tBest loss: 105162.609375\tAccuracy: 1.44%\n",
      "70\tValidation loss: 99950.781250\tBest loss: 99950.781250\tAccuracy: 5.04%\n",
      "71\tValidation loss: 110895.500000\tBest loss: 99950.781250\tAccuracy: 1.44%\n",
      "72\tValidation loss: 115037.578125\tBest loss: 99950.781250\tAccuracy: 2.16%\n",
      "73\tValidation loss: 102490.343750\tBest loss: 99950.781250\tAccuracy: 2.16%\n",
      "74\tValidation loss: 103357.031250\tBest loss: 99950.781250\tAccuracy: 0.00%\n",
      "75\tValidation loss: 100961.328125\tBest loss: 99950.781250\tAccuracy: 2.88%\n",
      "76\tValidation loss: 103994.750000\tBest loss: 99950.781250\tAccuracy: 1.44%\n",
      "77\tValidation loss: 96066.546875\tBest loss: 96066.546875\tAccuracy: 0.00%\n",
      "78\tValidation loss: 87507.453125\tBest loss: 87507.453125\tAccuracy: 1.44%\n",
      "79\tValidation loss: 104776.007812\tBest loss: 87507.453125\tAccuracy: 3.60%\n",
      "80\tValidation loss: 92987.656250\tBest loss: 87507.453125\tAccuracy: 2.16%\n",
      "81\tValidation loss: 92996.078125\tBest loss: 87507.453125\tAccuracy: 2.16%\n",
      "82\tValidation loss: 92689.375000\tBest loss: 87507.453125\tAccuracy: 2.16%\n",
      "83\tValidation loss: 83611.257812\tBest loss: 83611.257812\tAccuracy: 1.44%\n",
      "84\tValidation loss: 115807.195312\tBest loss: 83611.257812\tAccuracy: 1.44%\n",
      "85\tValidation loss: 113442.601562\tBest loss: 83611.257812\tAccuracy: 2.16%\n",
      "86\tValidation loss: 90599.406250\tBest loss: 83611.257812\tAccuracy: 2.16%\n",
      "87\tValidation loss: 87998.726562\tBest loss: 83611.257812\tAccuracy: 1.44%\n",
      "88\tValidation loss: 92984.460938\tBest loss: 83611.257812\tAccuracy: 2.88%\n",
      "89\tValidation loss: 81419.359375\tBest loss: 81419.359375\tAccuracy: 1.44%\n",
      "90\tValidation loss: 87249.562500\tBest loss: 81419.359375\tAccuracy: 2.16%\n",
      "91\tValidation loss: 83990.421875\tBest loss: 81419.359375\tAccuracy: 1.44%\n",
      "92\tValidation loss: 88246.781250\tBest loss: 81419.359375\tAccuracy: 2.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\tValidation loss: 85331.218750\tBest loss: 81419.359375\tAccuracy: 1.44%\n",
      "94\tValidation loss: 97266.546875\tBest loss: 81419.359375\tAccuracy: 0.72%\n",
      "95\tValidation loss: 92914.414062\tBest loss: 81419.359375\tAccuracy: 0.00%\n",
      "96\tValidation loss: 84220.843750\tBest loss: 81419.359375\tAccuracy: 1.44%\n",
      "97\tValidation loss: 85340.234375\tBest loss: 81419.359375\tAccuracy: 1.44%\n",
      "98\tValidation loss: 79228.234375\tBest loss: 79228.234375\tAccuracy: 0.72%\n",
      "99\tValidation loss: 80235.781250\tBest loss: 79228.234375\tAccuracy: 0.00%\n",
      "100\tValidation loss: 66684.679688\tBest loss: 66684.679688\tAccuracy: 0.00%\n",
      "101\tValidation loss: 101554.648438\tBest loss: 66684.679688\tAccuracy: 0.72%\n",
      "102\tValidation loss: 88297.781250\tBest loss: 66684.679688\tAccuracy: 0.00%\n",
      "103\tValidation loss: 78104.476562\tBest loss: 66684.679688\tAccuracy: 0.72%\n",
      "104\tValidation loss: 81164.921875\tBest loss: 66684.679688\tAccuracy: 1.44%\n",
      "105\tValidation loss: 71833.000000\tBest loss: 66684.679688\tAccuracy: 2.16%\n",
      "106\tValidation loss: 76773.734375\tBest loss: 66684.679688\tAccuracy: 1.44%\n",
      "107\tValidation loss: 71441.437500\tBest loss: 66684.679688\tAccuracy: 1.44%\n",
      "108\tValidation loss: 71120.890625\tBest loss: 66684.679688\tAccuracy: 0.72%\n",
      "109\tValidation loss: 77314.429688\tBest loss: 66684.679688\tAccuracy: 0.00%\n",
      "110\tValidation loss: 73613.843750\tBest loss: 66684.679688\tAccuracy: 1.44%\n",
      "111\tValidation loss: 75917.585938\tBest loss: 66684.679688\tAccuracy: 1.44%\n",
      "112\tValidation loss: 66548.945312\tBest loss: 66548.945312\tAccuracy: 0.72%\n",
      "113\tValidation loss: 61156.347656\tBest loss: 61156.347656\tAccuracy: 0.72%\n",
      "114\tValidation loss: 110700.820312\tBest loss: 61156.347656\tAccuracy: 1.44%\n",
      "115\tValidation loss: 87816.656250\tBest loss: 61156.347656\tAccuracy: 1.44%\n",
      "116\tValidation loss: 81848.390625\tBest loss: 61156.347656\tAccuracy: 0.72%\n",
      "117\tValidation loss: 85465.031250\tBest loss: 61156.347656\tAccuracy: 1.44%\n",
      "118\tValidation loss: 68077.367188\tBest loss: 61156.347656\tAccuracy: 0.72%\n",
      "119\tValidation loss: 74844.546875\tBest loss: 61156.347656\tAccuracy: 1.44%\n",
      "120\tValidation loss: 70937.804688\tBest loss: 61156.347656\tAccuracy: 0.72%\n",
      "121\tValidation loss: 67358.257812\tBest loss: 61156.347656\tAccuracy: 1.44%\n",
      "122\tValidation loss: 59348.523438\tBest loss: 59348.523438\tAccuracy: 1.44%\n",
      "123\tValidation loss: 60001.320312\tBest loss: 59348.523438\tAccuracy: 1.44%\n",
      "124\tValidation loss: 59260.800781\tBest loss: 59260.800781\tAccuracy: 2.88%\n",
      "125\tValidation loss: 67017.953125\tBest loss: 59260.800781\tAccuracy: 1.44%\n",
      "126\tValidation loss: 50355.769531\tBest loss: 50355.769531\tAccuracy: 2.88%\n",
      "127\tValidation loss: 53025.789062\tBest loss: 50355.769531\tAccuracy: 2.88%\n",
      "128\tValidation loss: 55352.148438\tBest loss: 50355.769531\tAccuracy: 4.32%\n",
      "129\tValidation loss: 52073.371094\tBest loss: 50355.769531\tAccuracy: 2.88%\n",
      "130\tValidation loss: 54177.937500\tBest loss: 50355.769531\tAccuracy: 1.44%\n",
      "131\tValidation loss: 48590.718750\tBest loss: 48590.718750\tAccuracy: 0.72%\n",
      "132\tValidation loss: 52574.894531\tBest loss: 48590.718750\tAccuracy: 2.88%\n",
      "133\tValidation loss: 54588.015625\tBest loss: 48590.718750\tAccuracy: 1.44%\n",
      "134\tValidation loss: 54470.917969\tBest loss: 48590.718750\tAccuracy: 1.44%\n",
      "135\tValidation loss: 49780.882812\tBest loss: 48590.718750\tAccuracy: 2.88%\n",
      "136\tValidation loss: 47968.957031\tBest loss: 47968.957031\tAccuracy: 2.16%\n",
      "137\tValidation loss: 40977.925781\tBest loss: 40977.925781\tAccuracy: 1.44%\n",
      "138\tValidation loss: 48269.980469\tBest loss: 40977.925781\tAccuracy: 1.44%\n",
      "139\tValidation loss: 41293.042969\tBest loss: 40977.925781\tAccuracy: 0.72%\n",
      "140\tValidation loss: 53123.976562\tBest loss: 40977.925781\tAccuracy: 1.44%\n",
      "141\tValidation loss: 46971.558594\tBest loss: 40977.925781\tAccuracy: 0.72%\n",
      "142\tValidation loss: 52171.003906\tBest loss: 40977.925781\tAccuracy: 0.72%\n",
      "143\tValidation loss: 45761.855469\tBest loss: 40977.925781\tAccuracy: 2.88%\n",
      "144\tValidation loss: 53283.054688\tBest loss: 40977.925781\tAccuracy: 1.44%\n",
      "145\tValidation loss: 44470.613281\tBest loss: 40977.925781\tAccuracy: 0.72%\n",
      "146\tValidation loss: 45543.324219\tBest loss: 40977.925781\tAccuracy: 2.88%\n",
      "147\tValidation loss: 44607.953125\tBest loss: 40977.925781\tAccuracy: 2.16%\n",
      "148\tValidation loss: 47279.117188\tBest loss: 40977.925781\tAccuracy: 1.44%\n",
      "149\tValidation loss: 39389.769531\tBest loss: 39389.769531\tAccuracy: 0.00%\n",
      "150\tValidation loss: 52474.105469\tBest loss: 39389.769531\tAccuracy: 1.44%\n",
      "151\tValidation loss: 56847.207031\tBest loss: 39389.769531\tAccuracy: 1.44%\n",
      "152\tValidation loss: 49265.578125\tBest loss: 39389.769531\tAccuracy: 0.72%\n",
      "153\tValidation loss: 44283.765625\tBest loss: 39389.769531\tAccuracy: 0.72%\n",
      "154\tValidation loss: 46213.453125\tBest loss: 39389.769531\tAccuracy: 2.88%\n",
      "155\tValidation loss: 44903.230469\tBest loss: 39389.769531\tAccuracy: 0.72%\n",
      "156\tValidation loss: 46945.281250\tBest loss: 39389.769531\tAccuracy: 0.72%\n",
      "157\tValidation loss: 43273.203125\tBest loss: 39389.769531\tAccuracy: 2.88%\n",
      "158\tValidation loss: 43773.394531\tBest loss: 39389.769531\tAccuracy: 0.00%\n",
      "159\tValidation loss: 42180.984375\tBest loss: 39389.769531\tAccuracy: 3.60%\n",
      "160\tValidation loss: 42294.160156\tBest loss: 39389.769531\tAccuracy: 2.88%\n",
      "161\tValidation loss: 39615.433594\tBest loss: 39389.769531\tAccuracy: 2.88%\n",
      "162\tValidation loss: 41757.054688\tBest loss: 39389.769531\tAccuracy: 2.16%\n",
      "163\tValidation loss: 41749.414062\tBest loss: 39389.769531\tAccuracy: 1.44%\n",
      "164\tValidation loss: 44386.949219\tBest loss: 39389.769531\tAccuracy: 2.88%\n",
      "165\tValidation loss: 37861.937500\tBest loss: 37861.937500\tAccuracy: 1.44%\n",
      "166\tValidation loss: 45093.925781\tBest loss: 37861.937500\tAccuracy: 2.88%\n",
      "167\tValidation loss: 40229.191406\tBest loss: 37861.937500\tAccuracy: 1.44%\n",
      "168\tValidation loss: 39416.789062\tBest loss: 37861.937500\tAccuracy: 1.44%\n",
      "169\tValidation loss: 40488.460938\tBest loss: 37861.937500\tAccuracy: 1.44%\n",
      "170\tValidation loss: 38006.179688\tBest loss: 37861.937500\tAccuracy: 2.88%\n",
      "171\tValidation loss: 37590.855469\tBest loss: 37590.855469\tAccuracy: 2.88%\n",
      "172\tValidation loss: 37633.363281\tBest loss: 37590.855469\tAccuracy: 0.72%\n",
      "173\tValidation loss: 38065.406250\tBest loss: 37590.855469\tAccuracy: 0.72%\n",
      "174\tValidation loss: 37135.769531\tBest loss: 37135.769531\tAccuracy: 2.16%\n",
      "175\tValidation loss: 58961.710938\tBest loss: 37135.769531\tAccuracy: 5.76%\n",
      "176\tValidation loss: 51964.113281\tBest loss: 37135.769531\tAccuracy: 3.60%\n",
      "177\tValidation loss: 60505.242188\tBest loss: 37135.769531\tAccuracy: 2.16%\n",
      "178\tValidation loss: 67902.375000\tBest loss: 37135.769531\tAccuracy: 0.72%\n",
      "179\tValidation loss: 82728.242188\tBest loss: 37135.769531\tAccuracy: 2.88%\n",
      "180\tValidation loss: 64846.957031\tBest loss: 37135.769531\tAccuracy: 2.88%\n",
      "181\tValidation loss: 51929.738281\tBest loss: 37135.769531\tAccuracy: 0.72%\n",
      "182\tValidation loss: 61218.097656\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "183\tValidation loss: 54905.414062\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "184\tValidation loss: 57104.000000\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "185\tValidation loss: 54789.230469\tBest loss: 37135.769531\tAccuracy: 0.72%\n",
      "186\tValidation loss: 52912.820312\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "187\tValidation loss: 52484.222656\tBest loss: 37135.769531\tAccuracy: 2.16%\n",
      "188\tValidation loss: 48509.187500\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "189\tValidation loss: 45371.746094\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "190\tValidation loss: 48164.468750\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "191\tValidation loss: 46276.851562\tBest loss: 37135.769531\tAccuracy: 0.72%\n",
      "192\tValidation loss: 38069.714844\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "193\tValidation loss: 56159.101562\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "194\tValidation loss: 48706.808594\tBest loss: 37135.769531\tAccuracy: 1.44%\n",
      "195\tValidation loss: 41732.703125\tBest loss: 37135.769531\tAccuracy: 2.16%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  33.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 405601472.000000\tBest loss: 405601472.000000\tAccuracy: 4.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tValidation loss: 22954896.000000\tBest loss: 22954896.000000\tAccuracy: 0.72%\n",
      "2\tValidation loss: 6055976.500000\tBest loss: 6055976.500000\tAccuracy: 0.72%\n",
      "3\tValidation loss: 2125588.500000\tBest loss: 2125588.500000\tAccuracy: 2.16%\n",
      "4\tValidation loss: 1370843.750000\tBest loss: 1370843.750000\tAccuracy: 3.60%\n",
      "5\tValidation loss: 667183.875000\tBest loss: 667183.875000\tAccuracy: 2.16%\n",
      "6\tValidation loss: 527291.750000\tBest loss: 527291.750000\tAccuracy: 0.72%\n",
      "7\tValidation loss: 453729.375000\tBest loss: 453729.375000\tAccuracy: 6.47%\n",
      "8\tValidation loss: 316372.906250\tBest loss: 316372.906250\tAccuracy: 0.00%\n",
      "9\tValidation loss: 400800.156250\tBest loss: 316372.906250\tAccuracy: 2.16%\n",
      "10\tValidation loss: 290963.437500\tBest loss: 290963.437500\tAccuracy: 2.88%\n",
      "11\tValidation loss: 267261.562500\tBest loss: 267261.562500\tAccuracy: 0.00%\n",
      "12\tValidation loss: 257484.671875\tBest loss: 257484.671875\tAccuracy: 2.16%\n",
      "13\tValidation loss: 275851.906250\tBest loss: 257484.671875\tAccuracy: 6.47%\n",
      "14\tValidation loss: 248988.000000\tBest loss: 248988.000000\tAccuracy: 3.60%\n",
      "15\tValidation loss: 171423.921875\tBest loss: 171423.921875\tAccuracy: 5.76%\n",
      "16\tValidation loss: 141059.250000\tBest loss: 141059.250000\tAccuracy: 6.47%\n",
      "17\tValidation loss: 280392.687500\tBest loss: 141059.250000\tAccuracy: 2.16%\n",
      "18\tValidation loss: 180171.437500\tBest loss: 141059.250000\tAccuracy: 5.76%\n",
      "19\tValidation loss: 322938.187500\tBest loss: 141059.250000\tAccuracy: 1.44%\n",
      "20\tValidation loss: 172170.500000\tBest loss: 141059.250000\tAccuracy: 2.16%\n",
      "21\tValidation loss: 177406.453125\tBest loss: 141059.250000\tAccuracy: 6.47%\n",
      "22\tValidation loss: 167783.796875\tBest loss: 141059.250000\tAccuracy: 5.76%\n",
      "23\tValidation loss: 133966.187500\tBest loss: 133966.187500\tAccuracy: 6.47%\n",
      "24\tValidation loss: 170766.906250\tBest loss: 133966.187500\tAccuracy: 5.76%\n",
      "25\tValidation loss: 206785.046875\tBest loss: 133966.187500\tAccuracy: 1.44%\n",
      "26\tValidation loss: 155902.437500\tBest loss: 133966.187500\tAccuracy: 6.47%\n",
      "27\tValidation loss: 124085.703125\tBest loss: 124085.703125\tAccuracy: 5.76%\n",
      "28\tValidation loss: 100612.523438\tBest loss: 100612.523438\tAccuracy: 6.47%\n",
      "29\tValidation loss: 138853.093750\tBest loss: 100612.523438\tAccuracy: 3.60%\n",
      "30\tValidation loss: 103284.695312\tBest loss: 100612.523438\tAccuracy: 5.76%\n",
      "31\tValidation loss: 148090.125000\tBest loss: 100612.523438\tAccuracy: 2.16%\n",
      "32\tValidation loss: 129832.312500\tBest loss: 100612.523438\tAccuracy: 3.60%\n",
      "33\tValidation loss: 82549.414062\tBest loss: 82549.414062\tAccuracy: 1.44%\n",
      "34\tValidation loss: 91011.148438\tBest loss: 82549.414062\tAccuracy: 2.88%\n",
      "35\tValidation loss: 88861.742188\tBest loss: 82549.414062\tAccuracy: 2.16%\n",
      "36\tValidation loss: 94930.500000\tBest loss: 82549.414062\tAccuracy: 0.72%\n",
      "37\tValidation loss: 67570.929688\tBest loss: 67570.929688\tAccuracy: 6.47%\n",
      "38\tValidation loss: 101512.195312\tBest loss: 67570.929688\tAccuracy: 5.04%\n",
      "39\tValidation loss: 93282.703125\tBest loss: 67570.929688\tAccuracy: 6.47%\n",
      "40\tValidation loss: 73661.898438\tBest loss: 67570.929688\tAccuracy: 0.72%\n",
      "41\tValidation loss: 96947.343750\tBest loss: 67570.929688\tAccuracy: 1.44%\n",
      "42\tValidation loss: 80791.320312\tBest loss: 67570.929688\tAccuracy: 1.44%\n",
      "43\tValidation loss: 65900.507812\tBest loss: 65900.507812\tAccuracy: 2.16%\n",
      "44\tValidation loss: 77385.523438\tBest loss: 65900.507812\tAccuracy: 5.76%\n",
      "45\tValidation loss: 75853.710938\tBest loss: 65900.507812\tAccuracy: 5.76%\n",
      "46\tValidation loss: 60458.339844\tBest loss: 60458.339844\tAccuracy: 1.44%\n",
      "47\tValidation loss: 67950.390625\tBest loss: 60458.339844\tAccuracy: 0.72%\n",
      "48\tValidation loss: 88375.882812\tBest loss: 60458.339844\tAccuracy: 5.76%\n",
      "49\tValidation loss: 72231.429688\tBest loss: 60458.339844\tAccuracy: 1.44%\n",
      "50\tValidation loss: 59706.660156\tBest loss: 59706.660156\tAccuracy: 2.88%\n",
      "51\tValidation loss: 81271.515625\tBest loss: 59706.660156\tAccuracy: 3.60%\n",
      "52\tValidation loss: 51947.429688\tBest loss: 51947.429688\tAccuracy: 5.76%\n",
      "53\tValidation loss: 63896.898438\tBest loss: 51947.429688\tAccuracy: 5.76%\n",
      "54\tValidation loss: 51140.058594\tBest loss: 51140.058594\tAccuracy: 2.16%\n",
      "55\tValidation loss: 44830.164062\tBest loss: 44830.164062\tAccuracy: 0.72%\n",
      "56\tValidation loss: 38938.468750\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "57\tValidation loss: 45975.945312\tBest loss: 38938.468750\tAccuracy: 2.16%\n",
      "58\tValidation loss: 41688.808594\tBest loss: 38938.468750\tAccuracy: 2.16%\n",
      "59\tValidation loss: 40993.179688\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "60\tValidation loss: 41832.824219\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "61\tValidation loss: 52973.320312\tBest loss: 38938.468750\tAccuracy: 2.16%\n",
      "62\tValidation loss: 41081.617188\tBest loss: 38938.468750\tAccuracy: 4.32%\n",
      "63\tValidation loss: 51791.640625\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "64\tValidation loss: 39163.515625\tBest loss: 38938.468750\tAccuracy: 2.88%\n",
      "65\tValidation loss: 43585.710938\tBest loss: 38938.468750\tAccuracy: 2.88%\n",
      "66\tValidation loss: 46420.050781\tBest loss: 38938.468750\tAccuracy: 3.60%\n",
      "67\tValidation loss: 42775.273438\tBest loss: 38938.468750\tAccuracy: 5.04%\n",
      "68\tValidation loss: 50156.488281\tBest loss: 38938.468750\tAccuracy: 2.88%\n",
      "69\tValidation loss: 46238.679688\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "70\tValidation loss: 51510.296875\tBest loss: 38938.468750\tAccuracy: 0.72%\n",
      "71\tValidation loss: 35421.628906\tBest loss: 35421.628906\tAccuracy: 5.76%\n",
      "72\tValidation loss: 48691.464844\tBest loss: 35421.628906\tAccuracy: 0.72%\n",
      "73\tValidation loss: 33322.734375\tBest loss: 33322.734375\tAccuracy: 5.76%\n",
      "74\tValidation loss: 37647.648438\tBest loss: 33322.734375\tAccuracy: 3.60%\n",
      "75\tValidation loss: 33987.171875\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "76\tValidation loss: 51649.726562\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "77\tValidation loss: 42414.636719\tBest loss: 33322.734375\tAccuracy: 1.44%\n",
      "78\tValidation loss: 47590.488281\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "79\tValidation loss: 36402.304688\tBest loss: 33322.734375\tAccuracy: 2.88%\n",
      "80\tValidation loss: 45476.628906\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "81\tValidation loss: 46500.621094\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "82\tValidation loss: 51520.785156\tBest loss: 33322.734375\tAccuracy: 2.88%\n",
      "83\tValidation loss: 33526.753906\tBest loss: 33322.734375\tAccuracy: 5.76%\n",
      "84\tValidation loss: 45391.781250\tBest loss: 33322.734375\tAccuracy: 0.72%\n",
      "85\tValidation loss: 33245.957031\tBest loss: 33245.957031\tAccuracy: 5.76%\n",
      "86\tValidation loss: 45362.808594\tBest loss: 33245.957031\tAccuracy: 1.44%\n",
      "87\tValidation loss: 30018.599609\tBest loss: 30018.599609\tAccuracy: 0.72%\n",
      "88\tValidation loss: 35909.429688\tBest loss: 30018.599609\tAccuracy: 5.76%\n",
      "89\tValidation loss: 36433.441406\tBest loss: 30018.599609\tAccuracy: 3.60%\n",
      "90\tValidation loss: 27458.753906\tBest loss: 27458.753906\tAccuracy: 3.60%\n",
      "91\tValidation loss: 29775.984375\tBest loss: 27458.753906\tAccuracy: 2.88%\n",
      "92\tValidation loss: 31125.675781\tBest loss: 27458.753906\tAccuracy: 5.76%\n",
      "93\tValidation loss: 28339.640625\tBest loss: 27458.753906\tAccuracy: 4.32%\n",
      "94\tValidation loss: 27198.613281\tBest loss: 27198.613281\tAccuracy: 1.44%\n",
      "95\tValidation loss: 23814.013672\tBest loss: 23814.013672\tAccuracy: 0.00%\n",
      "96\tValidation loss: 31106.826172\tBest loss: 23814.013672\tAccuracy: 0.00%\n",
      "97\tValidation loss: 32113.962891\tBest loss: 23814.013672\tAccuracy: 5.76%\n",
      "98\tValidation loss: 25896.474609\tBest loss: 23814.013672\tAccuracy: 5.04%\n",
      "99\tValidation loss: 26371.011719\tBest loss: 23814.013672\tAccuracy: 2.16%\n",
      "100\tValidation loss: 44550.636719\tBest loss: 23814.013672\tAccuracy: 0.72%\n",
      "101\tValidation loss: 26490.949219\tBest loss: 23814.013672\tAccuracy: 0.72%\n",
      "102\tValidation loss: 38859.160156\tBest loss: 23814.013672\tAccuracy: 2.88%\n",
      "103\tValidation loss: 30155.947266\tBest loss: 23814.013672\tAccuracy: 3.60%\n",
      "104\tValidation loss: 27306.572266\tBest loss: 23814.013672\tAccuracy: 5.04%\n",
      "105\tValidation loss: 22908.564453\tBest loss: 22908.564453\tAccuracy: 1.44%\n",
      "106\tValidation loss: 22274.617188\tBest loss: 22274.617188\tAccuracy: 2.16%\n",
      "107\tValidation loss: 20916.486328\tBest loss: 20916.486328\tAccuracy: 5.76%\n",
      "108\tValidation loss: 25447.421875\tBest loss: 20916.486328\tAccuracy: 0.72%\n",
      "109\tValidation loss: 25602.791016\tBest loss: 20916.486328\tAccuracy: 5.76%\n",
      "110\tValidation loss: 27953.695312\tBest loss: 20916.486328\tAccuracy: 1.44%\n",
      "111\tValidation loss: 25050.312500\tBest loss: 20916.486328\tAccuracy: 5.76%\n",
      "112\tValidation loss: 26833.298828\tBest loss: 20916.486328\tAccuracy: 2.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\tValidation loss: 28088.601562\tBest loss: 20916.486328\tAccuracy: 3.60%\n",
      "114\tValidation loss: 25798.113281\tBest loss: 20916.486328\tAccuracy: 2.88%\n",
      "115\tValidation loss: 21632.052734\tBest loss: 20916.486328\tAccuracy: 0.72%\n",
      "116\tValidation loss: 18899.642578\tBest loss: 18899.642578\tAccuracy: 5.76%\n",
      "117\tValidation loss: 19377.441406\tBest loss: 18899.642578\tAccuracy: 5.76%\n",
      "118\tValidation loss: 28600.054688\tBest loss: 18899.642578\tAccuracy: 0.72%\n",
      "119\tValidation loss: 18698.113281\tBest loss: 18698.113281\tAccuracy: 3.60%\n",
      "120\tValidation loss: 21514.158203\tBest loss: 18698.113281\tAccuracy: 3.60%\n",
      "121\tValidation loss: 23696.726562\tBest loss: 18698.113281\tAccuracy: 2.16%\n",
      "122\tValidation loss: 21032.037109\tBest loss: 18698.113281\tAccuracy: 0.72%\n",
      "123\tValidation loss: 22030.042969\tBest loss: 18698.113281\tAccuracy: 2.88%\n",
      "124\tValidation loss: 22606.304688\tBest loss: 18698.113281\tAccuracy: 5.76%\n",
      "125\tValidation loss: 26015.119141\tBest loss: 18698.113281\tAccuracy: 3.60%\n",
      "126\tValidation loss: 17005.632812\tBest loss: 17005.632812\tAccuracy: 2.88%\n",
      "127\tValidation loss: 17878.443359\tBest loss: 17005.632812\tAccuracy: 5.76%\n",
      "128\tValidation loss: 16373.083008\tBest loss: 16373.083008\tAccuracy: 5.04%\n",
      "129\tValidation loss: 17817.583984\tBest loss: 16373.083008\tAccuracy: 3.60%\n",
      "130\tValidation loss: 19623.433594\tBest loss: 16373.083008\tAccuracy: 5.76%\n",
      "131\tValidation loss: 21057.941406\tBest loss: 16373.083008\tAccuracy: 2.16%\n",
      "132\tValidation loss: 18239.535156\tBest loss: 16373.083008\tAccuracy: 5.76%\n",
      "133\tValidation loss: 19070.964844\tBest loss: 16373.083008\tAccuracy: 1.44%\n",
      "134\tValidation loss: 15873.692383\tBest loss: 15873.692383\tAccuracy: 5.76%\n",
      "135\tValidation loss: 17199.023438\tBest loss: 15873.692383\tAccuracy: 5.76%\n",
      "136\tValidation loss: 17756.099609\tBest loss: 15873.692383\tAccuracy: 0.72%\n",
      "137\tValidation loss: 23148.375000\tBest loss: 15873.692383\tAccuracy: 2.16%\n",
      "138\tValidation loss: 17407.425781\tBest loss: 15873.692383\tAccuracy: 5.76%\n",
      "139\tValidation loss: 23354.138672\tBest loss: 15873.692383\tAccuracy: 5.04%\n",
      "140\tValidation loss: 15888.155273\tBest loss: 15873.692383\tAccuracy: 5.76%\n",
      "141\tValidation loss: 17605.574219\tBest loss: 15873.692383\tAccuracy: 5.76%\n",
      "142\tValidation loss: 18845.687500\tBest loss: 15873.692383\tAccuracy: 0.72%\n",
      "143\tValidation loss: 18585.658203\tBest loss: 15873.692383\tAccuracy: 0.72%\n",
      "144\tValidation loss: 19721.705078\tBest loss: 15873.692383\tAccuracy: 2.16%\n",
      "145\tValidation loss: 20010.630859\tBest loss: 15873.692383\tAccuracy: 0.72%\n",
      "146\tValidation loss: 22535.923828\tBest loss: 15873.692383\tAccuracy: 3.60%\n",
      "147\tValidation loss: 14445.409180\tBest loss: 14445.409180\tAccuracy: 0.72%\n",
      "148\tValidation loss: 16215.069336\tBest loss: 14445.409180\tAccuracy: 2.88%\n",
      "149\tValidation loss: 17376.173828\tBest loss: 14445.409180\tAccuracy: 2.16%\n",
      "150\tValidation loss: 18863.550781\tBest loss: 14445.409180\tAccuracy: 0.72%\n",
      "151\tValidation loss: 14754.783203\tBest loss: 14445.409180\tAccuracy: 5.76%\n",
      "152\tValidation loss: 16453.173828\tBest loss: 14445.409180\tAccuracy: 0.00%\n",
      "153\tValidation loss: 18490.929688\tBest loss: 14445.409180\tAccuracy: 3.60%\n",
      "154\tValidation loss: 19871.654297\tBest loss: 14445.409180\tAccuracy: 3.60%\n",
      "155\tValidation loss: 15499.841797\tBest loss: 14445.409180\tAccuracy: 0.72%\n",
      "156\tValidation loss: 24361.132812\tBest loss: 14445.409180\tAccuracy: 3.60%\n",
      "157\tValidation loss: 13848.276367\tBest loss: 13848.276367\tAccuracy: 2.88%\n",
      "158\tValidation loss: 15458.023438\tBest loss: 13848.276367\tAccuracy: 1.44%\n",
      "159\tValidation loss: 12382.095703\tBest loss: 12382.095703\tAccuracy: 2.88%\n",
      "160\tValidation loss: 14151.939453\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "161\tValidation loss: 13067.223633\tBest loss: 12382.095703\tAccuracy: 5.76%\n",
      "162\tValidation loss: 19716.257812\tBest loss: 12382.095703\tAccuracy: 5.04%\n",
      "163\tValidation loss: 13786.511719\tBest loss: 12382.095703\tAccuracy: 2.16%\n",
      "164\tValidation loss: 16356.440430\tBest loss: 12382.095703\tAccuracy: 5.04%\n",
      "165\tValidation loss: 15287.083984\tBest loss: 12382.095703\tAccuracy: 5.04%\n",
      "166\tValidation loss: 13723.355469\tBest loss: 12382.095703\tAccuracy: 5.76%\n",
      "167\tValidation loss: 22766.494141\tBest loss: 12382.095703\tAccuracy: 2.16%\n",
      "168\tValidation loss: 16734.652344\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "169\tValidation loss: 17191.130859\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "170\tValidation loss: 14016.561523\tBest loss: 12382.095703\tAccuracy: 2.16%\n",
      "171\tValidation loss: 15447.294922\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "172\tValidation loss: 15628.099609\tBest loss: 12382.095703\tAccuracy: 5.76%\n",
      "173\tValidation loss: 16650.130859\tBest loss: 12382.095703\tAccuracy: 3.60%\n",
      "174\tValidation loss: 14582.064453\tBest loss: 12382.095703\tAccuracy: 2.16%\n",
      "175\tValidation loss: 14869.980469\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "176\tValidation loss: 14930.075195\tBest loss: 12382.095703\tAccuracy: 1.44%\n",
      "177\tValidation loss: 17090.785156\tBest loss: 12382.095703\tAccuracy: 1.44%\n",
      "178\tValidation loss: 15570.351562\tBest loss: 12382.095703\tAccuracy: 0.72%\n",
      "179\tValidation loss: 12131.049805\tBest loss: 12131.049805\tAccuracy: 5.04%\n",
      "180\tValidation loss: 11562.044922\tBest loss: 11562.044922\tAccuracy: 6.47%\n",
      "181\tValidation loss: 15440.510742\tBest loss: 11562.044922\tAccuracy: 5.76%\n",
      "182\tValidation loss: 12586.083984\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "183\tValidation loss: 20828.740234\tBest loss: 11562.044922\tAccuracy: 5.04%\n",
      "184\tValidation loss: 22920.695312\tBest loss: 11562.044922\tAccuracy: 5.76%\n",
      "185\tValidation loss: 22112.386719\tBest loss: 11562.044922\tAccuracy: 2.88%\n",
      "186\tValidation loss: 19145.193359\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "187\tValidation loss: 17244.566406\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "188\tValidation loss: 16513.464844\tBest loss: 11562.044922\tAccuracy: 6.47%\n",
      "189\tValidation loss: 16119.683594\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "190\tValidation loss: 19727.736328\tBest loss: 11562.044922\tAccuracy: 3.60%\n",
      "191\tValidation loss: 14937.054688\tBest loss: 11562.044922\tAccuracy: 2.88%\n",
      "192\tValidation loss: 14533.389648\tBest loss: 11562.044922\tAccuracy: 1.44%\n",
      "193\tValidation loss: 18415.335938\tBest loss: 11562.044922\tAccuracy: 1.44%\n",
      "194\tValidation loss: 14215.099609\tBest loss: 11562.044922\tAccuracy: 0.00%\n",
      "195\tValidation loss: 19262.611328\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "196\tValidation loss: 15424.311523\tBest loss: 11562.044922\tAccuracy: 5.76%\n",
      "197\tValidation loss: 14199.809570\tBest loss: 11562.044922\tAccuracy: 3.60%\n",
      "198\tValidation loss: 14010.923828\tBest loss: 11562.044922\tAccuracy: 5.76%\n",
      "199\tValidation loss: 14138.463867\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "200\tValidation loss: 14195.847656\tBest loss: 11562.044922\tAccuracy: 3.60%\n",
      "201\tValidation loss: 16321.577148\tBest loss: 11562.044922\tAccuracy: 0.72%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  34.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 17111896064.000000\tBest loss: 17111896064.000000\tAccuracy: 0.72%\n",
      "1\tValidation loss: 6333808640.000000\tBest loss: 6333808640.000000\tAccuracy: 1.44%\n",
      "2\tValidation loss: 2363435264.000000\tBest loss: 2363435264.000000\tAccuracy: 1.44%\n",
      "3\tValidation loss: 743628288.000000\tBest loss: 743628288.000000\tAccuracy: 2.16%\n",
      "4\tValidation loss: 438008256.000000\tBest loss: 438008256.000000\tAccuracy: 6.47%\n",
      "5\tValidation loss: 183724624.000000\tBest loss: 183724624.000000\tAccuracy: 2.16%\n",
      "6\tValidation loss: 107534288.000000\tBest loss: 107534288.000000\tAccuracy: 1.44%\n",
      "7\tValidation loss: 56659504.000000\tBest loss: 56659504.000000\tAccuracy: 1.44%\n",
      "8\tValidation loss: 79465688.000000\tBest loss: 56659504.000000\tAccuracy: 2.88%\n",
      "9\tValidation loss: 66170464.000000\tBest loss: 56659504.000000\tAccuracy: 3.60%\n",
      "10\tValidation loss: 46095764.000000\tBest loss: 46095764.000000\tAccuracy: 0.00%\n",
      "11\tValidation loss: 40736232.000000\tBest loss: 40736232.000000\tAccuracy: 3.60%\n",
      "12\tValidation loss: 89929240.000000\tBest loss: 40736232.000000\tAccuracy: 0.00%\n",
      "13\tValidation loss: 100069048.000000\tBest loss: 40736232.000000\tAccuracy: 1.44%\n",
      "14\tValidation loss: 97499984.000000\tBest loss: 40736232.000000\tAccuracy: 5.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tValidation loss: 56440880.000000\tBest loss: 40736232.000000\tAccuracy: 2.16%\n",
      "16\tValidation loss: 55319572.000000\tBest loss: 40736232.000000\tAccuracy: 0.72%\n",
      "17\tValidation loss: 42485688.000000\tBest loss: 40736232.000000\tAccuracy: 3.60%\n",
      "18\tValidation loss: 36313368.000000\tBest loss: 36313368.000000\tAccuracy: 2.88%\n",
      "19\tValidation loss: 35801972.000000\tBest loss: 35801972.000000\tAccuracy: 1.44%\n",
      "20\tValidation loss: 36979328.000000\tBest loss: 35801972.000000\tAccuracy: 3.60%\n",
      "21\tValidation loss: 32545546.000000\tBest loss: 32545546.000000\tAccuracy: 1.44%\n",
      "22\tValidation loss: 19488112.000000\tBest loss: 19488112.000000\tAccuracy: 3.60%\n",
      "23\tValidation loss: 27117132.000000\tBest loss: 19488112.000000\tAccuracy: 1.44%\n",
      "24\tValidation loss: 19605972.000000\tBest loss: 19488112.000000\tAccuracy: 0.00%\n",
      "25\tValidation loss: 22101272.000000\tBest loss: 19488112.000000\tAccuracy: 2.16%\n",
      "26\tValidation loss: 23714344.000000\tBest loss: 19488112.000000\tAccuracy: 0.00%\n",
      "27\tValidation loss: 17034480.000000\tBest loss: 17034480.000000\tAccuracy: 0.00%\n",
      "28\tValidation loss: 13842398.000000\tBest loss: 13842398.000000\tAccuracy: 4.32%\n",
      "29\tValidation loss: 18448880.000000\tBest loss: 13842398.000000\tAccuracy: 1.44%\n",
      "30\tValidation loss: 9998528.000000\tBest loss: 9998528.000000\tAccuracy: 4.32%\n",
      "31\tValidation loss: 62177000.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "32\tValidation loss: 74939096.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "33\tValidation loss: 70193648.000000\tBest loss: 9998528.000000\tAccuracy: 5.76%\n",
      "34\tValidation loss: 34564712.000000\tBest loss: 9998528.000000\tAccuracy: 4.32%\n",
      "35\tValidation loss: 23273700.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "36\tValidation loss: 20066044.000000\tBest loss: 9998528.000000\tAccuracy: 2.88%\n",
      "37\tValidation loss: 21353760.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "38\tValidation loss: 25487680.000000\tBest loss: 9998528.000000\tAccuracy: 1.44%\n",
      "39\tValidation loss: 22470040.000000\tBest loss: 9998528.000000\tAccuracy: 0.72%\n",
      "40\tValidation loss: 12161465.000000\tBest loss: 9998528.000000\tAccuracy: 4.32%\n",
      "41\tValidation loss: 14115196.000000\tBest loss: 9998528.000000\tAccuracy: 2.88%\n",
      "42\tValidation loss: 18369572.000000\tBest loss: 9998528.000000\tAccuracy: 0.72%\n",
      "43\tValidation loss: 26712736.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "44\tValidation loss: 11476436.000000\tBest loss: 9998528.000000\tAccuracy: 6.47%\n",
      "45\tValidation loss: 14702615.000000\tBest loss: 9998528.000000\tAccuracy: 2.16%\n",
      "46\tValidation loss: 11835539.000000\tBest loss: 9998528.000000\tAccuracy: 0.72%\n",
      "47\tValidation loss: 12220740.000000\tBest loss: 9998528.000000\tAccuracy: 2.88%\n",
      "48\tValidation loss: 17299104.000000\tBest loss: 9998528.000000\tAccuracy: 1.44%\n",
      "49\tValidation loss: 16216610.000000\tBest loss: 9998528.000000\tAccuracy: 2.88%\n",
      "50\tValidation loss: 13015811.000000\tBest loss: 9998528.000000\tAccuracy: 1.44%\n",
      "51\tValidation loss: 12506654.000000\tBest loss: 9998528.000000\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.1, dropout_rate=0.3, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  10.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 64241.882812\tBest loss: 64241.882812\tAccuracy: 2.16%\n",
      "1\tValidation loss: 51845.078125\tBest loss: 51845.078125\tAccuracy: 10.79%\n",
      "2\tValidation loss: 28112.138672\tBest loss: 28112.138672\tAccuracy: 17.27%\n",
      "3\tValidation loss: 25529.724609\tBest loss: 25529.724609\tAccuracy: 23.74%\n",
      "4\tValidation loss: 10516.420898\tBest loss: 10516.420898\tAccuracy: 39.57%\n",
      "5\tValidation loss: 8139.481934\tBest loss: 8139.481934\tAccuracy: 46.76%\n",
      "6\tValidation loss: 7536.719727\tBest loss: 7536.719727\tAccuracy: 51.80%\n",
      "7\tValidation loss: 7943.814453\tBest loss: 7536.719727\tAccuracy: 53.96%\n",
      "8\tValidation loss: 10768.360352\tBest loss: 7536.719727\tAccuracy: 56.83%\n",
      "9\tValidation loss: 12793.201172\tBest loss: 7536.719727\tAccuracy: 60.43%\n",
      "10\tValidation loss: 13915.216797\tBest loss: 7536.719727\tAccuracy: 53.24%\n",
      "11\tValidation loss: 12654.459961\tBest loss: 7536.719727\tAccuracy: 55.40%\n",
      "12\tValidation loss: 15993.693359\tBest loss: 7536.719727\tAccuracy: 59.71%\n",
      "13\tValidation loss: 15869.751953\tBest loss: 7536.719727\tAccuracy: 61.87%\n",
      "14\tValidation loss: 18465.025391\tBest loss: 7536.719727\tAccuracy: 61.87%\n",
      "15\tValidation loss: 19308.044922\tBest loss: 7536.719727\tAccuracy: 69.06%\n",
      "16\tValidation loss: 25707.029297\tBest loss: 7536.719727\tAccuracy: 61.15%\n",
      "17\tValidation loss: 28515.951172\tBest loss: 7536.719727\tAccuracy: 61.15%\n",
      "18\tValidation loss: 40675.359375\tBest loss: 7536.719727\tAccuracy: 64.75%\n",
      "19\tValidation loss: 56766.386719\tBest loss: 7536.719727\tAccuracy: 69.06%\n",
      "20\tValidation loss: 81821.460938\tBest loss: 7536.719727\tAccuracy: 68.35%\n",
      "21\tValidation loss: 75948.640625\tBest loss: 7536.719727\tAccuracy: 69.06%\n",
      "22\tValidation loss: 103811.562500\tBest loss: 7536.719727\tAccuracy: 58.99%\n",
      "23\tValidation loss: 86048.929688\tBest loss: 7536.719727\tAccuracy: 68.35%\n",
      "24\tValidation loss: 78763.632812\tBest loss: 7536.719727\tAccuracy: 66.19%\n",
      "25\tValidation loss: 84353.656250\tBest loss: 7536.719727\tAccuracy: 73.38%\n",
      "26\tValidation loss: 233341.546875\tBest loss: 7536.719727\tAccuracy: 63.31%\n",
      "27\tValidation loss: 196053.953125\tBest loss: 7536.719727\tAccuracy: 67.63%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 86793.882812\tBest loss: 86793.882812\tAccuracy: 0.00%\n",
      "1\tValidation loss: 85436.281250\tBest loss: 85436.281250\tAccuracy: 7.91%\n",
      "2\tValidation loss: 40025.378906\tBest loss: 40025.378906\tAccuracy: 5.76%\n",
      "3\tValidation loss: 17304.236328\tBest loss: 17304.236328\tAccuracy: 26.62%\n",
      "4\tValidation loss: 11227.879883\tBest loss: 11227.879883\tAccuracy: 37.41%\n",
      "5\tValidation loss: 4391.973145\tBest loss: 4391.973145\tAccuracy: 55.40%\n",
      "6\tValidation loss: 8657.230469\tBest loss: 4391.973145\tAccuracy: 43.17%\n",
      "7\tValidation loss: 6128.960938\tBest loss: 4391.973145\tAccuracy: 50.36%\n",
      "8\tValidation loss: 6277.469238\tBest loss: 4391.973145\tAccuracy: 61.15%\n",
      "9\tValidation loss: 5855.512207\tBest loss: 4391.973145\tAccuracy: 64.03%\n",
      "10\tValidation loss: 7633.476074\tBest loss: 4391.973145\tAccuracy: 57.55%\n",
      "11\tValidation loss: 15076.216797\tBest loss: 4391.973145\tAccuracy: 56.83%\n",
      "12\tValidation loss: 10329.605469\tBest loss: 4391.973145\tAccuracy: 58.99%\n",
      "13\tValidation loss: 11650.375000\tBest loss: 4391.973145\tAccuracy: 62.59%\n",
      "14\tValidation loss: 14898.952148\tBest loss: 4391.973145\tAccuracy: 63.31%\n",
      "15\tValidation loss: 38043.812500\tBest loss: 4391.973145\tAccuracy: 51.80%\n",
      "16\tValidation loss: 17829.396484\tBest loss: 4391.973145\tAccuracy: 71.94%\n",
      "17\tValidation loss: 30830.773438\tBest loss: 4391.973145\tAccuracy: 61.15%\n",
      "18\tValidation loss: 77284.335938\tBest loss: 4391.973145\tAccuracy: 51.80%\n",
      "19\tValidation loss: 66381.132812\tBest loss: 4391.973145\tAccuracy: 69.78%\n",
      "20\tValidation loss: 79786.273438\tBest loss: 4391.973145\tAccuracy: 67.63%\n",
      "21\tValidation loss: 219687.484375\tBest loss: 4391.973145\tAccuracy: 46.76%\n",
      "22\tValidation loss: 122745.945312\tBest loss: 4391.973145\tAccuracy: 64.03%\n",
      "23\tValidation loss: 93908.359375\tBest loss: 4391.973145\tAccuracy: 66.19%\n",
      "24\tValidation loss: 105706.312500\tBest loss: 4391.973145\tAccuracy: 71.94%\n",
      "25\tValidation loss: 89550.953125\tBest loss: 4391.973145\tAccuracy: 73.38%\n",
      "26\tValidation loss: 229057.531250\tBest loss: 4391.973145\tAccuracy: 62.59%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   4.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 74678.453125\tBest loss: 74678.453125\tAccuracy: 6.47%\n",
      "1\tValidation loss: 29682.472656\tBest loss: 29682.472656\tAccuracy: 12.23%\n",
      "2\tValidation loss: 11466.108398\tBest loss: 11466.108398\tAccuracy: 33.81%\n",
      "3\tValidation loss: 8815.075195\tBest loss: 8815.075195\tAccuracy: 38.85%\n",
      "4\tValidation loss: 8335.465820\tBest loss: 8335.465820\tAccuracy: 50.36%\n",
      "5\tValidation loss: 16322.347656\tBest loss: 8335.465820\tAccuracy: 43.88%\n",
      "6\tValidation loss: 8657.787109\tBest loss: 8335.465820\tAccuracy: 58.99%\n",
      "7\tValidation loss: 14790.937500\tBest loss: 8335.465820\tAccuracy: 46.76%\n",
      "8\tValidation loss: 15712.235352\tBest loss: 8335.465820\tAccuracy: 56.12%\n",
      "9\tValidation loss: 19019.613281\tBest loss: 8335.465820\tAccuracy: 56.83%\n",
      "10\tValidation loss: 17014.087891\tBest loss: 8335.465820\tAccuracy: 61.15%\n",
      "11\tValidation loss: 40694.726562\tBest loss: 8335.465820\tAccuracy: 62.59%\n",
      "12\tValidation loss: 19185.441406\tBest loss: 8335.465820\tAccuracy: 70.50%\n",
      "13\tValidation loss: 55375.554688\tBest loss: 8335.465820\tAccuracy: 57.55%\n",
      "14\tValidation loss: 24823.910156\tBest loss: 8335.465820\tAccuracy: 72.66%\n",
      "15\tValidation loss: 73562.812500\tBest loss: 8335.465820\tAccuracy: 58.99%\n",
      "16\tValidation loss: 118418.875000\tBest loss: 8335.465820\tAccuracy: 61.15%\n",
      "17\tValidation loss: 80091.445312\tBest loss: 8335.465820\tAccuracy: 68.35%\n",
      "18\tValidation loss: 215942.578125\tBest loss: 8335.465820\tAccuracy: 61.15%\n",
      "19\tValidation loss: 89753.148438\tBest loss: 8335.465820\tAccuracy: 67.63%\n",
      "20\tValidation loss: 49818.863281\tBest loss: 8335.465820\tAccuracy: 77.70%\n",
      "21\tValidation loss: 74888.093750\tBest loss: 8335.465820\tAccuracy: 74.82%\n",
      "22\tValidation loss: 46636.609375\tBest loss: 8335.465820\tAccuracy: 80.58%\n",
      "23\tValidation loss: 78009.093750\tBest loss: 8335.465820\tAccuracy: 79.86%\n",
      "24\tValidation loss: 166593.343750\tBest loss: 8335.465820\tAccuracy: 68.35%\n",
      "25\tValidation loss: 161545.546875\tBest loss: 8335.465820\tAccuracy: 79.86%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.4, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 603.420532\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "1\tValidation loss: 1217.689941\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "2\tValidation loss: 2662945.250000\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "3\tValidation loss: 2051541.875000\tBest loss: 603.420532\tAccuracy: 3.60%\n",
      "4\tValidation loss: 11544859.000000\tBest loss: 603.420532\tAccuracy: 3.60%\n",
      "5\tValidation loss: 1990634.250000\tBest loss: 603.420532\tAccuracy: 5.76%\n",
      "6\tValidation loss: 420165.000000\tBest loss: 603.420532\tAccuracy: 6.47%\n",
      "7\tValidation loss: 113394.046875\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "8\tValidation loss: 136923.546875\tBest loss: 603.420532\tAccuracy: 2.16%\n",
      "9\tValidation loss: 236655.000000\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "10\tValidation loss: 79001.906250\tBest loss: 603.420532\tAccuracy: 5.76%\n",
      "11\tValidation loss: 28827.753906\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "12\tValidation loss: 16794.886719\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "13\tValidation loss: 15043.820312\tBest loss: 603.420532\tAccuracy: 0.72%\n",
      "14\tValidation loss: 10931.888672\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "15\tValidation loss: 10878.472656\tBest loss: 603.420532\tAccuracy: 2.16%\n",
      "16\tValidation loss: 9322.203125\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "17\tValidation loss: 7581.692871\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "18\tValidation loss: 7213.898926\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "19\tValidation loss: 6101.861328\tBest loss: 603.420532\tAccuracy: 2.16%\n",
      "20\tValidation loss: 5881.009766\tBest loss: 603.420532\tAccuracy: 1.44%\n",
      "21\tValidation loss: 5371.048828\tBest loss: 603.420532\tAccuracy: 2.16%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 562.878601\tBest loss: 562.878601\tAccuracy: 4.32%\n",
      "1\tValidation loss: 873.812500\tBest loss: 562.878601\tAccuracy: 3.60%\n",
      "2\tValidation loss: 1103634.250000\tBest loss: 562.878601\tAccuracy: 0.72%\n",
      "3\tValidation loss: 822916.562500\tBest loss: 562.878601\tAccuracy: 5.76%\n",
      "4\tValidation loss: 8816595.000000\tBest loss: 562.878601\tAccuracy: 5.76%\n",
      "5\tValidation loss: 3739813.250000\tBest loss: 562.878601\tAccuracy: 5.76%\n",
      "6\tValidation loss: 4182443.750000\tBest loss: 562.878601\tAccuracy: 5.76%\n",
      "7\tValidation loss: 3042599.000000\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "8\tValidation loss: 1017083.375000\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "9\tValidation loss: 301511.531250\tBest loss: 562.878601\tAccuracy: 6.47%\n",
      "10\tValidation loss: 179717.218750\tBest loss: 562.878601\tAccuracy: 0.00%\n",
      "11\tValidation loss: 96307.382812\tBest loss: 562.878601\tAccuracy: 1.44%\n",
      "12\tValidation loss: 41329.476562\tBest loss: 562.878601\tAccuracy: 0.72%\n",
      "13\tValidation loss: 21609.310547\tBest loss: 562.878601\tAccuracy: 1.44%\n",
      "14\tValidation loss: 13900.486328\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "15\tValidation loss: 11075.425781\tBest loss: 562.878601\tAccuracy: 1.44%\n",
      "16\tValidation loss: 8063.216797\tBest loss: 562.878601\tAccuracy: 1.44%\n",
      "17\tValidation loss: 8013.166016\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "18\tValidation loss: 7715.119629\tBest loss: 562.878601\tAccuracy: 1.44%\n",
      "19\tValidation loss: 6812.276855\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "20\tValidation loss: 4603.532715\tBest loss: 562.878601\tAccuracy: 2.16%\n",
      "21\tValidation loss: 3867.810547\tBest loss: 562.878601\tAccuracy: 0.72%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 500.141602\tBest loss: 500.141602\tAccuracy: 0.72%\n",
      "1\tValidation loss: 462.994202\tBest loss: 462.994202\tAccuracy: 0.72%\n",
      "2\tValidation loss: 398828.000000\tBest loss: 462.994202\tAccuracy: 3.60%\n",
      "3\tValidation loss: 207457.750000\tBest loss: 462.994202\tAccuracy: 2.16%\n",
      "4\tValidation loss: 1688952.875000\tBest loss: 462.994202\tAccuracy: 3.60%\n",
      "5\tValidation loss: 11069387.000000\tBest loss: 462.994202\tAccuracy: 3.60%\n",
      "6\tValidation loss: 2212678.500000\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "7\tValidation loss: 11066722.000000\tBest loss: 462.994202\tAccuracy: 2.16%\n",
      "8\tValidation loss: 711183.687500\tBest loss: 462.994202\tAccuracy: 0.72%\n",
      "9\tValidation loss: 698418.250000\tBest loss: 462.994202\tAccuracy: 4.32%\n",
      "10\tValidation loss: 129755.203125\tBest loss: 462.994202\tAccuracy: 1.44%\n",
      "11\tValidation loss: 115962.156250\tBest loss: 462.994202\tAccuracy: 2.16%\n",
      "12\tValidation loss: 76693.093750\tBest loss: 462.994202\tAccuracy: 0.72%\n",
      "13\tValidation loss: 27259.146484\tBest loss: 462.994202\tAccuracy: 5.04%\n",
      "14\tValidation loss: 24830.599609\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "15\tValidation loss: 16807.884766\tBest loss: 462.994202\tAccuracy: 5.04%\n",
      "16\tValidation loss: 15118.498047\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "17\tValidation loss: 11306.290039\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "18\tValidation loss: 9423.792969\tBest loss: 462.994202\tAccuracy: 2.16%\n",
      "19\tValidation loss: 8834.035156\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "20\tValidation loss: 7495.137695\tBest loss: 462.994202\tAccuracy: 4.32%\n",
      "21\tValidation loss: 6407.946777\tBest loss: 462.994202\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tValidation loss: 6291.804688\tBest loss: 462.994202\tAccuracy: 5.76%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 82.402573\tBest loss: 82.402573\tAccuracy: 2.16%\n",
      "1\tValidation loss: 4.459408\tBest loss: 4.459408\tAccuracy: 2.16%\n",
      "2\tValidation loss: 3.986385\tBest loss: 3.986385\tAccuracy: 5.04%\n",
      "3\tValidation loss: 3.961152\tBest loss: 3.961152\tAccuracy: 5.76%\n",
      "4\tValidation loss: 3.978808\tBest loss: 3.961152\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.935896\tBest loss: 3.935896\tAccuracy: 6.47%\n",
      "6\tValidation loss: 3.914304\tBest loss: 3.914304\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.871971\tBest loss: 3.871971\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.856334\tBest loss: 3.856334\tAccuracy: 5.04%\n",
      "9\tValidation loss: 3.871285\tBest loss: 3.856334\tAccuracy: 4.32%\n",
      "10\tValidation loss: 4.217537\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "11\tValidation loss: 4.053246\tBest loss: 3.856334\tAccuracy: 6.47%\n",
      "12\tValidation loss: 4.050246\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "13\tValidation loss: 4.053273\tBest loss: 3.856334\tAccuracy: 6.47%\n",
      "14\tValidation loss: 4.045618\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "15\tValidation loss: 4.046911\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "16\tValidation loss: 4.047659\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "17\tValidation loss: 4.061921\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "18\tValidation loss: 4.313148\tBest loss: 3.856334\tAccuracy: 6.47%\n",
      "19\tValidation loss: 4.303596\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "20\tValidation loss: 4.301816\tBest loss: 3.856334\tAccuracy: 6.47%\n",
      "21\tValidation loss: 4.301518\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "22\tValidation loss: 4.302383\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "23\tValidation loss: 4.305574\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "24\tValidation loss: 4.305696\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "25\tValidation loss: 4.306297\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "26\tValidation loss: 4.303636\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "27\tValidation loss: 4.303843\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "28\tValidation loss: 4.303391\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "29\tValidation loss: 4.304916\tBest loss: 3.856334\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   4.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 8.059899\tBest loss: 8.059899\tAccuracy: 2.16%\n",
      "1\tValidation loss: 4.628477\tBest loss: 4.628477\tAccuracy: 2.16%\n",
      "2\tValidation loss: 4.576141\tBest loss: 4.576141\tAccuracy: 2.16%\n",
      "3\tValidation loss: 4.569009\tBest loss: 4.569009\tAccuracy: 2.16%\n",
      "4\tValidation loss: 4.574915\tBest loss: 4.569009\tAccuracy: 4.32%\n",
      "5\tValidation loss: 4.555984\tBest loss: 4.555984\tAccuracy: 4.32%\n",
      "6\tValidation loss: 4.549142\tBest loss: 4.549142\tAccuracy: 4.32%\n",
      "7\tValidation loss: 4.528419\tBest loss: 4.528419\tAccuracy: 7.19%\n",
      "8\tValidation loss: 4.536638\tBest loss: 4.528419\tAccuracy: 4.32%\n",
      "9\tValidation loss: 4.521101\tBest loss: 4.521101\tAccuracy: 7.19%\n",
      "10\tValidation loss: 4.535817\tBest loss: 4.521101\tAccuracy: 7.19%\n",
      "11\tValidation loss: 4.552675\tBest loss: 4.521101\tAccuracy: 4.32%\n",
      "12\tValidation loss: 4.528123\tBest loss: 4.521101\tAccuracy: 4.32%\n",
      "13\tValidation loss: 4.537797\tBest loss: 4.521101\tAccuracy: 4.32%\n",
      "14\tValidation loss: 4.528127\tBest loss: 4.521101\tAccuracy: 4.32%\n",
      "15\tValidation loss: 4.360464\tBest loss: 4.360464\tAccuracy: 6.47%\n",
      "16\tValidation loss: 4.360250\tBest loss: 4.360250\tAccuracy: 6.47%\n",
      "17\tValidation loss: 4.363995\tBest loss: 4.360250\tAccuracy: 3.60%\n",
      "18\tValidation loss: 4.351308\tBest loss: 4.351308\tAccuracy: 6.47%\n",
      "19\tValidation loss: 4.354926\tBest loss: 4.351308\tAccuracy: 6.47%\n",
      "20\tValidation loss: 4.357183\tBest loss: 4.351308\tAccuracy: 6.47%\n",
      "21\tValidation loss: 4.352686\tBest loss: 4.351308\tAccuracy: 3.60%\n",
      "22\tValidation loss: 4.354554\tBest loss: 4.351308\tAccuracy: 3.60%\n",
      "23\tValidation loss: 4.357111\tBest loss: 4.351308\tAccuracy: 6.47%\n",
      "24\tValidation loss: 4.506455\tBest loss: 4.351308\tAccuracy: 3.60%\n",
      "25\tValidation loss: 4.308530\tBest loss: 4.308530\tAccuracy: 3.60%\n",
      "26\tValidation loss: 4.308436\tBest loss: 4.308436\tAccuracy: 3.60%\n",
      "27\tValidation loss: 4.305707\tBest loss: 4.305707\tAccuracy: 3.60%\n",
      "28\tValidation loss: 4.304577\tBest loss: 4.304577\tAccuracy: 3.60%\n",
      "29\tValidation loss: 4.304819\tBest loss: 4.304577\tAccuracy: 3.60%\n",
      "30\tValidation loss: 4.306300\tBest loss: 4.304577\tAccuracy: 3.60%\n",
      "31\tValidation loss: 4.304283\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "32\tValidation loss: 4.305608\tBest loss: 4.304283\tAccuracy: 6.47%\n",
      "33\tValidation loss: 4.305823\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "34\tValidation loss: 4.308849\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "35\tValidation loss: 4.306108\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "36\tValidation loss: 4.307886\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "37\tValidation loss: 4.305524\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "38\tValidation loss: 4.304306\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "39\tValidation loss: 4.307361\tBest loss: 4.304283\tAccuracy: 6.47%\n",
      "40\tValidation loss: 4.307054\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "41\tValidation loss: 4.306141\tBest loss: 4.304283\tAccuracy: 6.47%\n",
      "42\tValidation loss: 4.306148\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "43\tValidation loss: 4.305803\tBest loss: 4.304283\tAccuracy: 3.60%\n",
      "44\tValidation loss: 4.303596\tBest loss: 4.303596\tAccuracy: 3.60%\n",
      "45\tValidation loss: 4.306991\tBest loss: 4.303596\tAccuracy: 3.60%\n",
      "46\tValidation loss: 4.301750\tBest loss: 4.301750\tAccuracy: 3.60%\n",
      "47\tValidation loss: 4.302808\tBest loss: 4.301750\tAccuracy: 3.60%\n",
      "48\tValidation loss: 4.301177\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "49\tValidation loss: 4.304361\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "50\tValidation loss: 4.306943\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "51\tValidation loss: 4.308664\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "52\tValidation loss: 4.308624\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "53\tValidation loss: 4.305554\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "54\tValidation loss: 4.306646\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "55\tValidation loss: 4.306284\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "56\tValidation loss: 4.306350\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "57\tValidation loss: 4.307796\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "58\tValidation loss: 4.305950\tBest loss: 4.301177\tAccuracy: 6.47%\n",
      "59\tValidation loss: 4.307571\tBest loss: 4.301177\tAccuracy: 6.47%\n",
      "60\tValidation loss: 4.304180\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "61\tValidation loss: 4.302721\tBest loss: 4.301177\tAccuracy: 6.47%\n",
      "62\tValidation loss: 4.305806\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "63\tValidation loss: 4.302463\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "64\tValidation loss: 4.304347\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "65\tValidation loss: 4.305138\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "66\tValidation loss: 4.304886\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "67\tValidation loss: 4.304420\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "68\tValidation loss: 4.306271\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "69\tValidation loss: 4.305760\tBest loss: 4.301177\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   8.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 50.885151\tBest loss: 50.885151\tAccuracy: 0.00%\n",
      "1\tValidation loss: 6.009387\tBest loss: 6.009387\tAccuracy: 5.76%\n",
      "2\tValidation loss: 5.976129\tBest loss: 5.976129\tAccuracy: 2.88%\n",
      "3\tValidation loss: 5.965228\tBest loss: 5.965228\tAccuracy: 2.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\tValidation loss: 5.957552\tBest loss: 5.957552\tAccuracy: 2.88%\n",
      "5\tValidation loss: 5.949115\tBest loss: 5.949115\tAccuracy: 2.88%\n",
      "6\tValidation loss: 5.939030\tBest loss: 5.939030\tAccuracy: 2.88%\n",
      "7\tValidation loss: 5.934467\tBest loss: 5.934467\tAccuracy: 2.88%\n",
      "8\tValidation loss: 5.907985\tBest loss: 5.907985\tAccuracy: 2.88%\n",
      "9\tValidation loss: 5.892630\tBest loss: 5.892630\tAccuracy: 2.88%\n",
      "10\tValidation loss: 5.878761\tBest loss: 5.878761\tAccuracy: 6.47%\n",
      "11\tValidation loss: 5.898826\tBest loss: 5.878761\tAccuracy: 2.88%\n",
      "12\tValidation loss: 5.875940\tBest loss: 5.875940\tAccuracy: 2.88%\n",
      "13\tValidation loss: 5.848323\tBest loss: 5.848323\tAccuracy: 2.88%\n",
      "14\tValidation loss: 5.840858\tBest loss: 5.840858\tAccuracy: 2.88%\n",
      "15\tValidation loss: 5.838360\tBest loss: 5.838360\tAccuracy: 2.88%\n",
      "16\tValidation loss: 5.841758\tBest loss: 5.838360\tAccuracy: 2.88%\n",
      "17\tValidation loss: 5.838298\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "18\tValidation loss: 5.840403\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "19\tValidation loss: 5.841508\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "20\tValidation loss: 5.846298\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "21\tValidation loss: 5.842007\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "22\tValidation loss: 5.844934\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "23\tValidation loss: 5.848553\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "24\tValidation loss: 5.844851\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "25\tValidation loss: 5.845141\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "26\tValidation loss: 5.847462\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "27\tValidation loss: 5.845347\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "28\tValidation loss: 5.846732\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "29\tValidation loss: 5.845840\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "30\tValidation loss: 5.847034\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "31\tValidation loss: 5.848149\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "32\tValidation loss: 5.849481\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "33\tValidation loss: 5.849973\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "34\tValidation loss: 5.857589\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "35\tValidation loss: 5.862085\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "36\tValidation loss: 5.861490\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "37\tValidation loss: 5.859733\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "38\tValidation loss: 5.861897\tBest loss: 5.838298\tAccuracy: 2.88%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=5, learning_rate=0.05, dropout_rate=0, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 2618218.500000\tBest loss: 2618218.500000\tAccuracy: 5.76%\n",
      "1\tValidation loss: 55415.859375\tBest loss: 55415.859375\tAccuracy: 1.44%\n",
      "2\tValidation loss: 5539.918945\tBest loss: 5539.918945\tAccuracy: 2.88%\n",
      "3\tValidation loss: 162.963028\tBest loss: 162.963028\tAccuracy: 1.44%\n",
      "4\tValidation loss: 133.683533\tBest loss: 133.683533\tAccuracy: 0.72%\n",
      "5\tValidation loss: 123.462463\tBest loss: 123.462463\tAccuracy: 5.76%\n",
      "6\tValidation loss: 114.951614\tBest loss: 114.951614\tAccuracy: 4.32%\n",
      "7\tValidation loss: 104.240021\tBest loss: 104.240021\tAccuracy: 4.32%\n",
      "8\tValidation loss: 91.726334\tBest loss: 91.726334\tAccuracy: 4.32%\n",
      "9\tValidation loss: 79.043037\tBest loss: 79.043037\tAccuracy: 4.32%\n",
      "10\tValidation loss: 69.733170\tBest loss: 69.733170\tAccuracy: 0.72%\n",
      "11\tValidation loss: 62.043800\tBest loss: 62.043800\tAccuracy: 2.16%\n",
      "12\tValidation loss: 54.434494\tBest loss: 54.434494\tAccuracy: 0.72%\n",
      "13\tValidation loss: 47.398029\tBest loss: 47.398029\tAccuracy: 4.32%\n",
      "14\tValidation loss: 41.307091\tBest loss: 41.307091\tAccuracy: 4.32%\n",
      "15\tValidation loss: 35.648907\tBest loss: 35.648907\tAccuracy: 4.32%\n",
      "16\tValidation loss: 30.098528\tBest loss: 30.098528\tAccuracy: 2.16%\n",
      "17\tValidation loss: 25.838089\tBest loss: 25.838089\tAccuracy: 2.16%\n",
      "18\tValidation loss: 22.028013\tBest loss: 22.028013\tAccuracy: 4.32%\n",
      "19\tValidation loss: 18.938828\tBest loss: 18.938828\tAccuracy: 4.32%\n",
      "20\tValidation loss: 16.569853\tBest loss: 16.569853\tAccuracy: 0.72%\n",
      "21\tValidation loss: 15.301548\tBest loss: 15.301548\tAccuracy: 2.16%\n",
      "22\tValidation loss: 13.679859\tBest loss: 13.679859\tAccuracy: 4.32%\n",
      "23\tValidation loss: 12.731608\tBest loss: 12.731608\tAccuracy: 0.72%\n",
      "24\tValidation loss: 11.710594\tBest loss: 11.710594\tAccuracy: 2.16%\n",
      "25\tValidation loss: 10.652041\tBest loss: 10.652041\tAccuracy: 5.04%\n",
      "26\tValidation loss: 10.129395\tBest loss: 10.129395\tAccuracy: 4.32%\n",
      "27\tValidation loss: 9.566960\tBest loss: 9.566960\tAccuracy: 4.32%\n",
      "28\tValidation loss: 8.978035\tBest loss: 8.978035\tAccuracy: 4.32%\n",
      "29\tValidation loss: 8.469240\tBest loss: 8.469240\tAccuracy: 4.32%\n",
      "30\tValidation loss: 8.331826\tBest loss: 8.331826\tAccuracy: 6.47%\n",
      "31\tValidation loss: 8.293095\tBest loss: 8.293095\tAccuracy: 1.44%\n",
      "32\tValidation loss: 8.161300\tBest loss: 8.161300\tAccuracy: 0.72%\n",
      "33\tValidation loss: 7.921530\tBest loss: 7.921530\tAccuracy: 6.47%\n",
      "34\tValidation loss: 8.013602\tBest loss: 7.921530\tAccuracy: 0.00%\n",
      "35\tValidation loss: 7.776062\tBest loss: 7.776062\tAccuracy: 1.44%\n",
      "36\tValidation loss: 7.796044\tBest loss: 7.776062\tAccuracy: 6.47%\n",
      "37\tValidation loss: 7.622677\tBest loss: 7.622677\tAccuracy: 3.60%\n",
      "38\tValidation loss: 7.531362\tBest loss: 7.531362\tAccuracy: 6.47%\n",
      "39\tValidation loss: 7.554691\tBest loss: 7.531362\tAccuracy: 5.04%\n",
      "40\tValidation loss: 7.698009\tBest loss: 7.531362\tAccuracy: 0.72%\n",
      "41\tValidation loss: 7.173051\tBest loss: 7.173051\tAccuracy: 6.47%\n",
      "42\tValidation loss: 7.159921\tBest loss: 7.159921\tAccuracy: 2.88%\n",
      "43\tValidation loss: 6.930996\tBest loss: 6.930996\tAccuracy: 4.32%\n",
      "44\tValidation loss: 6.976301\tBest loss: 6.930996\tAccuracy: 0.72%\n",
      "45\tValidation loss: 6.978484\tBest loss: 6.930996\tAccuracy: 6.47%\n",
      "46\tValidation loss: 6.799801\tBest loss: 6.799801\tAccuracy: 2.16%\n",
      "47\tValidation loss: 6.872533\tBest loss: 6.799801\tAccuracy: 4.32%\n",
      "48\tValidation loss: 6.681646\tBest loss: 6.681646\tAccuracy: 4.32%\n",
      "49\tValidation loss: 6.730942\tBest loss: 6.681646\tAccuracy: 6.47%\n",
      "50\tValidation loss: 6.453270\tBest loss: 6.453270\tAccuracy: 6.47%\n",
      "51\tValidation loss: 6.580786\tBest loss: 6.453270\tAccuracy: 0.72%\n",
      "52\tValidation loss: 6.361922\tBest loss: 6.361922\tAccuracy: 6.47%\n",
      "53\tValidation loss: 6.367435\tBest loss: 6.361922\tAccuracy: 2.16%\n",
      "54\tValidation loss: 6.247548\tBest loss: 6.247548\tAccuracy: 6.47%\n",
      "55\tValidation loss: 6.226847\tBest loss: 6.226847\tAccuracy: 2.88%\n",
      "56\tValidation loss: 6.131516\tBest loss: 6.131516\tAccuracy: 1.44%\n",
      "57\tValidation loss: 6.081791\tBest loss: 6.081791\tAccuracy: 6.47%\n",
      "58\tValidation loss: 6.083054\tBest loss: 6.081791\tAccuracy: 0.72%\n",
      "59\tValidation loss: 5.916021\tBest loss: 5.916021\tAccuracy: 4.32%\n",
      "60\tValidation loss: 5.966903\tBest loss: 5.916021\tAccuracy: 6.47%\n",
      "61\tValidation loss: 6.036391\tBest loss: 5.916021\tAccuracy: 5.04%\n",
      "62\tValidation loss: 6.035958\tBest loss: 5.916021\tAccuracy: 2.16%\n",
      "63\tValidation loss: 18.606169\tBest loss: 5.916021\tAccuracy: 5.76%\n",
      "64\tValidation loss: 12.337954\tBest loss: 5.916021\tAccuracy: 2.16%\n",
      "65\tValidation loss: 11.001723\tBest loss: 5.916021\tAccuracy: 1.44%\n",
      "66\tValidation loss: 10.653378\tBest loss: 5.916021\tAccuracy: 6.47%\n",
      "67\tValidation loss: 9.570092\tBest loss: 5.916021\tAccuracy: 1.44%\n",
      "68\tValidation loss: 8.711419\tBest loss: 5.916021\tAccuracy: 0.72%\n",
      "69\tValidation loss: 7.918751\tBest loss: 5.916021\tAccuracy: 6.47%\n",
      "70\tValidation loss: 7.530273\tBest loss: 5.916021\tAccuracy: 5.76%\n",
      "71\tValidation loss: 6.919925\tBest loss: 5.916021\tAccuracy: 6.47%\n",
      "72\tValidation loss: 6.749439\tBest loss: 5.916021\tAccuracy: 6.47%\n",
      "73\tValidation loss: 6.388181\tBest loss: 5.916021\tAccuracy: 2.16%\n",
      "74\tValidation loss: 6.090509\tBest loss: 5.916021\tAccuracy: 0.72%\n",
      "75\tValidation loss: 5.534592\tBest loss: 5.534592\tAccuracy: 4.32%\n",
      "76\tValidation loss: 5.303668\tBest loss: 5.303668\tAccuracy: 4.32%\n",
      "77\tValidation loss: 4.944445\tBest loss: 4.944445\tAccuracy: 6.47%\n",
      "78\tValidation loss: 4.701263\tBest loss: 4.701263\tAccuracy: 2.88%\n",
      "79\tValidation loss: 4.764574\tBest loss: 4.701263\tAccuracy: 1.44%\n",
      "80\tValidation loss: 4.595486\tBest loss: 4.595486\tAccuracy: 6.47%\n",
      "81\tValidation loss: 4.493007\tBest loss: 4.493007\tAccuracy: 2.88%\n",
      "82\tValidation loss: 4.406553\tBest loss: 4.406553\tAccuracy: 2.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\tValidation loss: 4.220613\tBest loss: 4.220613\tAccuracy: 2.16%\n",
      "84\tValidation loss: 4.074062\tBest loss: 4.074062\tAccuracy: 5.76%\n",
      "85\tValidation loss: 4.271890\tBest loss: 4.074062\tAccuracy: 2.88%\n",
      "86\tValidation loss: 4.005409\tBest loss: 4.005409\tAccuracy: 2.16%\n",
      "87\tValidation loss: 3.947615\tBest loss: 3.947615\tAccuracy: 2.88%\n",
      "88\tValidation loss: 4.035957\tBest loss: 3.947615\tAccuracy: 3.60%\n",
      "89\tValidation loss: 4.098505\tBest loss: 3.947615\tAccuracy: 3.60%\n",
      "90\tValidation loss: 3.973028\tBest loss: 3.947615\tAccuracy: 6.47%\n",
      "91\tValidation loss: 3.913897\tBest loss: 3.913897\tAccuracy: 5.04%\n",
      "92\tValidation loss: 4.235509\tBest loss: 3.913897\tAccuracy: 0.72%\n",
      "93\tValidation loss: 4.241673\tBest loss: 3.913897\tAccuracy: 6.47%\n",
      "94\tValidation loss: 4.177124\tBest loss: 3.913897\tAccuracy: 1.44%\n",
      "95\tValidation loss: 4.330416\tBest loss: 3.913897\tAccuracy: 0.72%\n",
      "96\tValidation loss: 3.982828\tBest loss: 3.913897\tAccuracy: 1.44%\n",
      "97\tValidation loss: 3.967166\tBest loss: 3.913897\tAccuracy: 6.47%\n",
      "98\tValidation loss: 3.893291\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "99\tValidation loss: 4.175701\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "100\tValidation loss: 4.073514\tBest loss: 3.893291\tAccuracy: 6.47%\n",
      "101\tValidation loss: 3.924634\tBest loss: 3.893291\tAccuracy: 1.44%\n",
      "102\tValidation loss: 4.004674\tBest loss: 3.893291\tAccuracy: 2.16%\n",
      "103\tValidation loss: 4.206964\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "104\tValidation loss: 4.069052\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "105\tValidation loss: 4.023721\tBest loss: 3.893291\tAccuracy: 0.72%\n",
      "106\tValidation loss: 4.090322\tBest loss: 3.893291\tAccuracy: 6.47%\n",
      "107\tValidation loss: 4.053441\tBest loss: 3.893291\tAccuracy: 5.04%\n",
      "108\tValidation loss: 4.103545\tBest loss: 3.893291\tAccuracy: 2.16%\n",
      "109\tValidation loss: 3.966658\tBest loss: 3.893291\tAccuracy: 4.32%\n",
      "110\tValidation loss: 3.937466\tBest loss: 3.893291\tAccuracy: 6.47%\n",
      "111\tValidation loss: 3.919722\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "112\tValidation loss: 4.044353\tBest loss: 3.893291\tAccuracy: 6.47%\n",
      "113\tValidation loss: 4.397672\tBest loss: 3.893291\tAccuracy: 0.72%\n",
      "114\tValidation loss: 3.990854\tBest loss: 3.893291\tAccuracy: 2.16%\n",
      "115\tValidation loss: 4.008563\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "116\tValidation loss: 3.915932\tBest loss: 3.893291\tAccuracy: 3.60%\n",
      "117\tValidation loss: 4.001350\tBest loss: 3.893291\tAccuracy: 0.72%\n",
      "118\tValidation loss: 4.157137\tBest loss: 3.893291\tAccuracy: 2.88%\n",
      "119\tValidation loss: 4.063698\tBest loss: 3.893291\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  26.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 1732346.500000\tBest loss: 1732346.500000\tAccuracy: 1.44%\n",
      "1\tValidation loss: 33882.828125\tBest loss: 33882.828125\tAccuracy: 0.00%\n",
      "2\tValidation loss: 1892.026367\tBest loss: 1892.026367\tAccuracy: 1.44%\n",
      "3\tValidation loss: 5733.938965\tBest loss: 1892.026367\tAccuracy: 0.72%\n",
      "4\tValidation loss: 5014.808594\tBest loss: 1892.026367\tAccuracy: 1.44%\n",
      "5\tValidation loss: 4648.378418\tBest loss: 1892.026367\tAccuracy: 3.60%\n",
      "6\tValidation loss: 4141.204102\tBest loss: 1892.026367\tAccuracy: 0.00%\n",
      "7\tValidation loss: 3685.696533\tBest loss: 1892.026367\tAccuracy: 1.44%\n",
      "8\tValidation loss: 3255.559082\tBest loss: 1892.026367\tAccuracy: 0.72%\n",
      "9\tValidation loss: 3115.887695\tBest loss: 1892.026367\tAccuracy: 2.16%\n",
      "10\tValidation loss: 2885.698242\tBest loss: 1892.026367\tAccuracy: 2.16%\n",
      "11\tValidation loss: 2581.093018\tBest loss: 1892.026367\tAccuracy: 2.88%\n",
      "12\tValidation loss: 2301.758057\tBest loss: 1892.026367\tAccuracy: 3.60%\n",
      "13\tValidation loss: 2077.042480\tBest loss: 1892.026367\tAccuracy: 1.44%\n",
      "14\tValidation loss: 1925.774780\tBest loss: 1892.026367\tAccuracy: 2.16%\n",
      "15\tValidation loss: 1711.875977\tBest loss: 1711.875977\tAccuracy: 1.44%\n",
      "16\tValidation loss: 1476.164062\tBest loss: 1476.164062\tAccuracy: 3.60%\n",
      "17\tValidation loss: 969.992920\tBest loss: 969.992920\tAccuracy: 0.72%\n",
      "18\tValidation loss: 714.455017\tBest loss: 714.455017\tAccuracy: 3.60%\n",
      "19\tValidation loss: 572.180359\tBest loss: 572.180359\tAccuracy: 5.04%\n",
      "20\tValidation loss: 681.855713\tBest loss: 572.180359\tAccuracy: 0.72%\n",
      "21\tValidation loss: 656.711914\tBest loss: 572.180359\tAccuracy: 0.00%\n",
      "22\tValidation loss: 635.831238\tBest loss: 572.180359\tAccuracy: 0.72%\n",
      "23\tValidation loss: 582.638916\tBest loss: 572.180359\tAccuracy: 2.16%\n",
      "24\tValidation loss: 683.958130\tBest loss: 572.180359\tAccuracy: 1.44%\n",
      "25\tValidation loss: 683.697327\tBest loss: 572.180359\tAccuracy: 1.44%\n",
      "26\tValidation loss: 690.884644\tBest loss: 572.180359\tAccuracy: 0.00%\n",
      "27\tValidation loss: 724.467529\tBest loss: 572.180359\tAccuracy: 1.44%\n",
      "28\tValidation loss: 705.389587\tBest loss: 572.180359\tAccuracy: 0.72%\n",
      "29\tValidation loss: 509.653931\tBest loss: 509.653931\tAccuracy: 1.44%\n",
      "30\tValidation loss: 560.857666\tBest loss: 509.653931\tAccuracy: 3.60%\n",
      "31\tValidation loss: 549.925293\tBest loss: 509.653931\tAccuracy: 2.16%\n",
      "32\tValidation loss: 486.665283\tBest loss: 486.665283\tAccuracy: 1.44%\n",
      "33\tValidation loss: 404.739838\tBest loss: 404.739838\tAccuracy: 3.60%\n",
      "34\tValidation loss: 389.818420\tBest loss: 389.818420\tAccuracy: 1.44%\n",
      "35\tValidation loss: 508.724335\tBest loss: 389.818420\tAccuracy: 0.00%\n",
      "36\tValidation loss: 596.783386\tBest loss: 389.818420\tAccuracy: 2.16%\n",
      "37\tValidation loss: 555.945435\tBest loss: 389.818420\tAccuracy: 1.44%\n",
      "38\tValidation loss: 535.550232\tBest loss: 389.818420\tAccuracy: 1.44%\n",
      "39\tValidation loss: 515.525269\tBest loss: 389.818420\tAccuracy: 0.72%\n",
      "40\tValidation loss: 489.664551\tBest loss: 389.818420\tAccuracy: 3.60%\n",
      "41\tValidation loss: 384.574585\tBest loss: 384.574585\tAccuracy: 0.00%\n",
      "42\tValidation loss: 400.113434\tBest loss: 384.574585\tAccuracy: 0.72%\n",
      "43\tValidation loss: 339.194458\tBest loss: 339.194458\tAccuracy: 1.44%\n",
      "44\tValidation loss: 332.063721\tBest loss: 332.063721\tAccuracy: 0.00%\n",
      "45\tValidation loss: 346.904541\tBest loss: 332.063721\tAccuracy: 5.04%\n",
      "46\tValidation loss: 385.212128\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "47\tValidation loss: 384.514923\tBest loss: 332.063721\tAccuracy: 5.76%\n",
      "48\tValidation loss: 471.801941\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "49\tValidation loss: 667.928223\tBest loss: 332.063721\tAccuracy: 3.60%\n",
      "50\tValidation loss: 656.966248\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "51\tValidation loss: 646.063660\tBest loss: 332.063721\tAccuracy: 1.44%\n",
      "52\tValidation loss: 662.087036\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "53\tValidation loss: 543.672791\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "54\tValidation loss: 531.202759\tBest loss: 332.063721\tAccuracy: 0.00%\n",
      "55\tValidation loss: 445.905182\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "56\tValidation loss: 464.645813\tBest loss: 332.063721\tAccuracy: 1.44%\n",
      "57\tValidation loss: 641.529602\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "58\tValidation loss: 671.965515\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "59\tValidation loss: 682.294189\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "60\tValidation loss: 724.055908\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "61\tValidation loss: 647.372253\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "62\tValidation loss: 526.576355\tBest loss: 332.063721\tAccuracy: 0.72%\n",
      "63\tValidation loss: 542.290100\tBest loss: 332.063721\tAccuracy: 2.16%\n",
      "64\tValidation loss: 477.754913\tBest loss: 332.063721\tAccuracy: 5.04%\n",
      "65\tValidation loss: 561.685120\tBest loss: 332.063721\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  14.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 761057.562500\tBest loss: 761057.562500\tAccuracy: 4.32%\n",
      "1\tValidation loss: 80005.984375\tBest loss: 80005.984375\tAccuracy: 2.88%\n",
      "2\tValidation loss: 908.041992\tBest loss: 908.041992\tAccuracy: 3.60%\n",
      "3\tValidation loss: 179.777100\tBest loss: 179.777100\tAccuracy: 2.16%\n",
      "4\tValidation loss: 180.055679\tBest loss: 179.777100\tAccuracy: 2.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\tValidation loss: 169.685257\tBest loss: 169.685257\tAccuracy: 1.44%\n",
      "6\tValidation loss: 151.783905\tBest loss: 151.783905\tAccuracy: 2.16%\n",
      "7\tValidation loss: 131.300217\tBest loss: 131.300217\tAccuracy: 2.16%\n",
      "8\tValidation loss: 112.533310\tBest loss: 112.533310\tAccuracy: 1.44%\n",
      "9\tValidation loss: 98.153229\tBest loss: 98.153229\tAccuracy: 2.88%\n",
      "10\tValidation loss: 84.919144\tBest loss: 84.919144\tAccuracy: 2.16%\n",
      "11\tValidation loss: 73.261276\tBest loss: 73.261276\tAccuracy: 2.16%\n",
      "12\tValidation loss: 61.784058\tBest loss: 61.784058\tAccuracy: 3.60%\n",
      "13\tValidation loss: 50.836227\tBest loss: 50.836227\tAccuracy: 2.16%\n",
      "14\tValidation loss: 42.596413\tBest loss: 42.596413\tAccuracy: 0.00%\n",
      "15\tValidation loss: 35.734169\tBest loss: 35.734169\tAccuracy: 2.16%\n",
      "16\tValidation loss: 29.922535\tBest loss: 29.922535\tAccuracy: 2.16%\n",
      "17\tValidation loss: 25.179399\tBest loss: 25.179399\tAccuracy: 0.00%\n",
      "18\tValidation loss: 20.678986\tBest loss: 20.678986\tAccuracy: 2.16%\n",
      "19\tValidation loss: 16.826471\tBest loss: 16.826471\tAccuracy: 3.60%\n",
      "20\tValidation loss: 13.685307\tBest loss: 13.685307\tAccuracy: 3.60%\n",
      "21\tValidation loss: 11.967793\tBest loss: 11.967793\tAccuracy: 2.16%\n",
      "22\tValidation loss: 10.681032\tBest loss: 10.681032\tAccuracy: 1.44%\n",
      "23\tValidation loss: 9.290010\tBest loss: 9.290010\tAccuracy: 3.60%\n",
      "24\tValidation loss: 8.232771\tBest loss: 8.232771\tAccuracy: 3.60%\n",
      "25\tValidation loss: 7.384768\tBest loss: 7.384768\tAccuracy: 2.16%\n",
      "26\tValidation loss: 6.411876\tBest loss: 6.411876\tAccuracy: 5.76%\n",
      "27\tValidation loss: 5.710096\tBest loss: 5.710096\tAccuracy: 2.16%\n",
      "28\tValidation loss: 5.104942\tBest loss: 5.104942\tAccuracy: 4.32%\n",
      "29\tValidation loss: 4.710785\tBest loss: 4.710785\tAccuracy: 3.60%\n",
      "30\tValidation loss: 4.453511\tBest loss: 4.453511\tAccuracy: 0.72%\n",
      "31\tValidation loss: 4.197015\tBest loss: 4.197015\tAccuracy: 3.60%\n",
      "32\tValidation loss: 4.039522\tBest loss: 4.039522\tAccuracy: 3.60%\n",
      "33\tValidation loss: 4.197079\tBest loss: 4.039522\tAccuracy: 6.47%\n",
      "34\tValidation loss: 3.964514\tBest loss: 3.964514\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.967517\tBest loss: 3.964514\tAccuracy: 5.04%\n",
      "36\tValidation loss: 3.863382\tBest loss: 3.863382\tAccuracy: 1.44%\n",
      "37\tValidation loss: 3.964163\tBest loss: 3.863382\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.863224\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.931908\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.935658\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.865695\tBest loss: 3.863224\tAccuracy: 2.16%\n",
      "42\tValidation loss: 4.017133\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.986686\tBest loss: 3.863224\tAccuracy: 2.88%\n",
      "44\tValidation loss: 4.014478\tBest loss: 3.863224\tAccuracy: 2.88%\n",
      "45\tValidation loss: 3.990492\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "46\tValidation loss: 3.935939\tBest loss: 3.863224\tAccuracy: 0.72%\n",
      "47\tValidation loss: 3.991157\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "48\tValidation loss: 3.927693\tBest loss: 3.863224\tAccuracy: 0.72%\n",
      "49\tValidation loss: 4.111245\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.934721\tBest loss: 3.863224\tAccuracy: 2.88%\n",
      "51\tValidation loss: 3.979430\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.915999\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "53\tValidation loss: 3.951762\tBest loss: 3.863224\tAccuracy: 1.44%\n",
      "54\tValidation loss: 4.016998\tBest loss: 3.863224\tAccuracy: 0.72%\n",
      "55\tValidation loss: 3.961615\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "56\tValidation loss: 3.916049\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "57\tValidation loss: 4.120438\tBest loss: 3.863224\tAccuracy: 2.88%\n",
      "58\tValidation loss: 3.922803\tBest loss: 3.863224\tAccuracy: 6.47%\n",
      "59\tValidation loss: 4.491147\tBest loss: 3.863224\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=6, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  14.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 2.843190\tBest loss: 2.843190\tAccuracy: 48.20%\n",
      "1\tValidation loss: 2.390770\tBest loss: 2.390770\tAccuracy: 49.64%\n",
      "2\tValidation loss: 4.742936\tBest loss: 2.390770\tAccuracy: 36.69%\n",
      "3\tValidation loss: 4.394928\tBest loss: 2.390770\tAccuracy: 46.04%\n",
      "4\tValidation loss: 13.452433\tBest loss: 2.390770\tAccuracy: 41.01%\n",
      "5\tValidation loss: 1.855199\tBest loss: 1.855199\tAccuracy: 64.03%\n",
      "6\tValidation loss: 5.741939\tBest loss: 1.855199\tAccuracy: 49.64%\n",
      "7\tValidation loss: 0.962705\tBest loss: 0.962705\tAccuracy: 78.42%\n",
      "8\tValidation loss: 10.230620\tBest loss: 0.962705\tAccuracy: 62.59%\n",
      "9\tValidation loss: 1.445522\tBest loss: 0.962705\tAccuracy: 74.82%\n",
      "10\tValidation loss: 8.775061\tBest loss: 0.962705\tAccuracy: 50.36%\n",
      "11\tValidation loss: 2.196068\tBest loss: 0.962705\tAccuracy: 72.66%\n",
      "12\tValidation loss: 4.786249\tBest loss: 0.962705\tAccuracy: 73.38%\n",
      "13\tValidation loss: 1.064571\tBest loss: 0.962705\tAccuracy: 80.58%\n",
      "14\tValidation loss: 3.751219\tBest loss: 0.962705\tAccuracy: 71.22%\n",
      "15\tValidation loss: 2.672868\tBest loss: 0.962705\tAccuracy: 80.58%\n",
      "16\tValidation loss: 9.425019\tBest loss: 0.962705\tAccuracy: 64.75%\n",
      "17\tValidation loss: 1.431581\tBest loss: 0.962705\tAccuracy: 84.89%\n",
      "18\tValidation loss: 5.433762\tBest loss: 0.962705\tAccuracy: 77.70%\n",
      "19\tValidation loss: 2.214548\tBest loss: 0.962705\tAccuracy: 84.17%\n",
      "20\tValidation loss: 1.929890\tBest loss: 0.962705\tAccuracy: 86.33%\n",
      "21\tValidation loss: 2.060414\tBest loss: 0.962705\tAccuracy: 82.73%\n",
      "22\tValidation loss: 1.821760\tBest loss: 0.962705\tAccuracy: 87.77%\n",
      "23\tValidation loss: 2.319620\tBest loss: 0.962705\tAccuracy: 84.17%\n",
      "24\tValidation loss: 0.593658\tBest loss: 0.593658\tAccuracy: 91.37%\n",
      "25\tValidation loss: 1.452677\tBest loss: 0.593658\tAccuracy: 87.77%\n",
      "26\tValidation loss: 1.145754\tBest loss: 0.593658\tAccuracy: 89.21%\n",
      "27\tValidation loss: 2.376166\tBest loss: 0.593658\tAccuracy: 86.33%\n",
      "28\tValidation loss: 0.752960\tBest loss: 0.593658\tAccuracy: 89.21%\n",
      "29\tValidation loss: 5.142971\tBest loss: 0.593658\tAccuracy: 80.58%\n",
      "30\tValidation loss: 1.095900\tBest loss: 0.593658\tAccuracy: 88.49%\n",
      "31\tValidation loss: 3.573198\tBest loss: 0.593658\tAccuracy: 84.17%\n",
      "32\tValidation loss: 1.036780\tBest loss: 0.593658\tAccuracy: 90.65%\n",
      "33\tValidation loss: 0.769668\tBest loss: 0.593658\tAccuracy: 89.93%\n",
      "34\tValidation loss: 1.581205\tBest loss: 0.593658\tAccuracy: 86.33%\n",
      "35\tValidation loss: 1.373891\tBest loss: 0.593658\tAccuracy: 88.49%\n",
      "36\tValidation loss: 6.051073\tBest loss: 0.593658\tAccuracy: 82.01%\n",
      "37\tValidation loss: 3.139036\tBest loss: 0.593658\tAccuracy: 84.89%\n",
      "38\tValidation loss: 1.934965\tBest loss: 0.593658\tAccuracy: 88.49%\n",
      "39\tValidation loss: 4.578280\tBest loss: 0.593658\tAccuracy: 87.77%\n",
      "40\tValidation loss: 0.926185\tBest loss: 0.593658\tAccuracy: 91.37%\n",
      "41\tValidation loss: 1.310250\tBest loss: 0.593658\tAccuracy: 89.93%\n",
      "42\tValidation loss: 4.307605\tBest loss: 0.593658\tAccuracy: 82.01%\n",
      "43\tValidation loss: 1.991061\tBest loss: 0.593658\tAccuracy: 91.37%\n",
      "44\tValidation loss: 0.970940\tBest loss: 0.593658\tAccuracy: 92.09%\n",
      "45\tValidation loss: 2.471666\tBest loss: 0.593658\tAccuracy: 85.61%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   7.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.087363\tBest loss: 3.087363\tAccuracy: 33.09%\n",
      "1\tValidation loss: 2.358213\tBest loss: 2.358213\tAccuracy: 35.97%\n",
      "2\tValidation loss: 4.235436\tBest loss: 2.358213\tAccuracy: 43.88%\n",
      "3\tValidation loss: 6.222913\tBest loss: 2.358213\tAccuracy: 41.01%\n",
      "4\tValidation loss: 1.968399\tBest loss: 1.968399\tAccuracy: 62.59%\n",
      "5\tValidation loss: 1.326349\tBest loss: 1.326349\tAccuracy: 68.35%\n",
      "6\tValidation loss: 6.970564\tBest loss: 1.326349\tAccuracy: 51.80%\n",
      "7\tValidation loss: 2.157207\tBest loss: 1.326349\tAccuracy: 65.47%\n",
      "8\tValidation loss: 2.480780\tBest loss: 1.326349\tAccuracy: 75.54%\n",
      "9\tValidation loss: 1.546575\tBest loss: 1.326349\tAccuracy: 76.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 0.995208\tBest loss: 0.995208\tAccuracy: 80.58%\n",
      "11\tValidation loss: 2.345901\tBest loss: 0.995208\tAccuracy: 83.45%\n",
      "12\tValidation loss: 5.712546\tBest loss: 0.995208\tAccuracy: 66.91%\n",
      "13\tValidation loss: 1.464812\tBest loss: 0.995208\tAccuracy: 82.73%\n",
      "14\tValidation loss: 1.118920\tBest loss: 0.995208\tAccuracy: 87.77%\n",
      "15\tValidation loss: 6.951855\tBest loss: 0.995208\tAccuracy: 69.78%\n",
      "16\tValidation loss: 1.169066\tBest loss: 0.995208\tAccuracy: 87.05%\n",
      "17\tValidation loss: 3.539518\tBest loss: 0.995208\tAccuracy: 83.45%\n",
      "18\tValidation loss: 0.984135\tBest loss: 0.984135\tAccuracy: 85.61%\n",
      "19\tValidation loss: 0.883584\tBest loss: 0.883584\tAccuracy: 89.93%\n",
      "20\tValidation loss: 0.736602\tBest loss: 0.736602\tAccuracy: 90.65%\n",
      "21\tValidation loss: 0.465134\tBest loss: 0.465134\tAccuracy: 91.37%\n",
      "22\tValidation loss: 1.829865\tBest loss: 0.465134\tAccuracy: 83.45%\n",
      "23\tValidation loss: 3.531392\tBest loss: 0.465134\tAccuracy: 82.01%\n",
      "24\tValidation loss: 4.231411\tBest loss: 0.465134\tAccuracy: 82.01%\n",
      "25\tValidation loss: 0.877622\tBest loss: 0.465134\tAccuracy: 89.21%\n",
      "26\tValidation loss: 1.077066\tBest loss: 0.465134\tAccuracy: 90.65%\n",
      "27\tValidation loss: 1.886408\tBest loss: 0.465134\tAccuracy: 88.49%\n",
      "28\tValidation loss: 0.761580\tBest loss: 0.465134\tAccuracy: 89.93%\n",
      "29\tValidation loss: 1.112047\tBest loss: 0.465134\tAccuracy: 90.65%\n",
      "30\tValidation loss: 6.247220\tBest loss: 0.465134\tAccuracy: 79.14%\n",
      "31\tValidation loss: 0.438148\tBest loss: 0.438148\tAccuracy: 93.53%\n",
      "32\tValidation loss: 0.995935\tBest loss: 0.438148\tAccuracy: 90.65%\n",
      "33\tValidation loss: 2.652880\tBest loss: 0.438148\tAccuracy: 87.77%\n",
      "34\tValidation loss: 3.382292\tBest loss: 0.438148\tAccuracy: 84.17%\n",
      "35\tValidation loss: 1.290332\tBest loss: 0.438148\tAccuracy: 91.37%\n",
      "36\tValidation loss: 1.228415\tBest loss: 0.438148\tAccuracy: 88.49%\n",
      "37\tValidation loss: 1.938297\tBest loss: 0.438148\tAccuracy: 86.33%\n",
      "38\tValidation loss: 1.974110\tBest loss: 0.438148\tAccuracy: 85.61%\n",
      "39\tValidation loss: 1.710377\tBest loss: 0.438148\tAccuracy: 89.93%\n",
      "40\tValidation loss: 1.252232\tBest loss: 0.438148\tAccuracy: 89.21%\n",
      "41\tValidation loss: 1.081894\tBest loss: 0.438148\tAccuracy: 92.09%\n",
      "42\tValidation loss: 0.935743\tBest loss: 0.438148\tAccuracy: 91.37%\n",
      "43\tValidation loss: 2.870522\tBest loss: 0.438148\tAccuracy: 82.01%\n",
      "44\tValidation loss: 5.677866\tBest loss: 0.438148\tAccuracy: 75.54%\n",
      "45\tValidation loss: 1.133818\tBest loss: 0.438148\tAccuracy: 91.37%\n",
      "46\tValidation loss: 1.747729\tBest loss: 0.438148\tAccuracy: 91.37%\n",
      "47\tValidation loss: 0.975829\tBest loss: 0.438148\tAccuracy: 92.09%\n",
      "48\tValidation loss: 0.781646\tBest loss: 0.438148\tAccuracy: 93.53%\n",
      "49\tValidation loss: 2.375061\tBest loss: 0.438148\tAccuracy: 89.93%\n",
      "50\tValidation loss: 3.753765\tBest loss: 0.438148\tAccuracy: 84.89%\n",
      "51\tValidation loss: 1.688004\tBest loss: 0.438148\tAccuracy: 90.65%\n",
      "52\tValidation loss: 3.298457\tBest loss: 0.438148\tAccuracy: 85.61%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   8.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 2.857420\tBest loss: 2.857420\tAccuracy: 35.25%\n",
      "1\tValidation loss: 3.618169\tBest loss: 2.857420\tAccuracy: 32.37%\n",
      "2\tValidation loss: 9.105911\tBest loss: 2.857420\tAccuracy: 25.90%\n",
      "3\tValidation loss: 4.802311\tBest loss: 2.857420\tAccuracy: 54.68%\n",
      "4\tValidation loss: 2.597390\tBest loss: 2.597390\tAccuracy: 66.91%\n",
      "5\tValidation loss: 6.780318\tBest loss: 2.597390\tAccuracy: 48.20%\n",
      "6\tValidation loss: 2.022485\tBest loss: 2.022485\tAccuracy: 70.50%\n",
      "7\tValidation loss: 3.279542\tBest loss: 2.022485\tAccuracy: 67.63%\n",
      "8\tValidation loss: 3.992323\tBest loss: 2.022485\tAccuracy: 71.22%\n",
      "9\tValidation loss: 2.793187\tBest loss: 2.022485\tAccuracy: 74.10%\n",
      "10\tValidation loss: 2.252245\tBest loss: 2.022485\tAccuracy: 82.01%\n",
      "11\tValidation loss: 4.553103\tBest loss: 2.022485\tAccuracy: 77.70%\n",
      "12\tValidation loss: 6.080208\tBest loss: 2.022485\tAccuracy: 69.06%\n",
      "13\tValidation loss: 2.088560\tBest loss: 2.022485\tAccuracy: 78.42%\n",
      "14\tValidation loss: 4.182131\tBest loss: 2.022485\tAccuracy: 74.10%\n",
      "15\tValidation loss: 1.985642\tBest loss: 1.985642\tAccuracy: 83.45%\n",
      "16\tValidation loss: 1.002079\tBest loss: 1.002079\tAccuracy: 87.05%\n",
      "17\tValidation loss: 1.545293\tBest loss: 1.002079\tAccuracy: 85.61%\n",
      "18\tValidation loss: 1.575839\tBest loss: 1.002079\tAccuracy: 82.73%\n",
      "19\tValidation loss: 1.115876\tBest loss: 1.002079\tAccuracy: 86.33%\n",
      "20\tValidation loss: 1.533998\tBest loss: 1.002079\tAccuracy: 88.49%\n",
      "21\tValidation loss: 6.241096\tBest loss: 1.002079\tAccuracy: 71.94%\n",
      "22\tValidation loss: 2.688328\tBest loss: 1.002079\tAccuracy: 84.17%\n",
      "23\tValidation loss: 0.681792\tBest loss: 0.681792\tAccuracy: 91.37%\n",
      "24\tValidation loss: 2.011144\tBest loss: 0.681792\tAccuracy: 84.17%\n",
      "25\tValidation loss: 1.355819\tBest loss: 0.681792\tAccuracy: 84.89%\n",
      "26\tValidation loss: 0.701825\tBest loss: 0.681792\tAccuracy: 89.21%\n",
      "27\tValidation loss: 1.666736\tBest loss: 0.681792\tAccuracy: 84.89%\n",
      "28\tValidation loss: 1.697211\tBest loss: 0.681792\tAccuracy: 89.93%\n",
      "29\tValidation loss: 2.291791\tBest loss: 0.681792\tAccuracy: 85.61%\n",
      "30\tValidation loss: 4.110428\tBest loss: 0.681792\tAccuracy: 81.29%\n",
      "31\tValidation loss: 2.109870\tBest loss: 0.681792\tAccuracy: 85.61%\n",
      "32\tValidation loss: 2.433720\tBest loss: 0.681792\tAccuracy: 87.05%\n",
      "33\tValidation loss: 1.279010\tBest loss: 0.681792\tAccuracy: 87.05%\n",
      "34\tValidation loss: 0.798445\tBest loss: 0.681792\tAccuracy: 91.37%\n",
      "35\tValidation loss: 1.350616\tBest loss: 0.681792\tAccuracy: 89.21%\n",
      "36\tValidation loss: 1.881454\tBest loss: 0.681792\tAccuracy: 87.05%\n",
      "37\tValidation loss: 1.657519\tBest loss: 0.681792\tAccuracy: 90.65%\n",
      "38\tValidation loss: 1.656636\tBest loss: 0.681792\tAccuracy: 86.33%\n",
      "39\tValidation loss: 0.643341\tBest loss: 0.643341\tAccuracy: 92.09%\n",
      "40\tValidation loss: 1.369648\tBest loss: 0.643341\tAccuracy: 86.33%\n",
      "41\tValidation loss: 3.730267\tBest loss: 0.643341\tAccuracy: 82.01%\n",
      "42\tValidation loss: 1.095370\tBest loss: 0.643341\tAccuracy: 94.24%\n",
      "43\tValidation loss: 1.357449\tBest loss: 0.643341\tAccuracy: 90.65%\n",
      "44\tValidation loss: 1.376127\tBest loss: 0.643341\tAccuracy: 92.09%\n",
      "45\tValidation loss: 2.104796\tBest loss: 0.643341\tAccuracy: 89.21%\n",
      "46\tValidation loss: 2.429506\tBest loss: 0.643341\tAccuracy: 87.77%\n",
      "47\tValidation loss: 1.836427\tBest loss: 0.643341\tAccuracy: 88.49%\n",
      "48\tValidation loss: 2.441266\tBest loss: 0.643341\tAccuracy: 87.77%\n",
      "49\tValidation loss: 2.918321\tBest loss: 0.643341\tAccuracy: 87.05%\n",
      "50\tValidation loss: 5.452275\tBest loss: 0.643341\tAccuracy: 79.86%\n",
      "51\tValidation loss: 5.840814\tBest loss: 0.643341\tAccuracy: 83.45%\n",
      "52\tValidation loss: 2.109308\tBest loss: 0.643341\tAccuracy: 91.37%\n",
      "53\tValidation loss: 1.454514\tBest loss: 0.643341\tAccuracy: 89.93%\n",
      "54\tValidation loss: 1.089441\tBest loss: 0.643341\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.830977\tBest loss: 0.643341\tAccuracy: 92.09%\n",
      "56\tValidation loss: 2.068320\tBest loss: 0.643341\tAccuracy: 89.93%\n",
      "57\tValidation loss: 3.697961\tBest loss: 0.643341\tAccuracy: 89.21%\n",
      "58\tValidation loss: 2.016191\tBest loss: 0.643341\tAccuracy: 90.65%\n",
      "59\tValidation loss: 5.706661\tBest loss: 0.643341\tAccuracy: 79.86%\n",
      "60\tValidation loss: 2.052051\tBest loss: 0.643341\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.3, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  10.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 11.323345\tBest loss: 11.323345\tAccuracy: 36.69%\n",
      "1\tValidation loss: 1.048821\tBest loss: 1.048821\tAccuracy: 77.70%\n",
      "2\tValidation loss: 0.843789\tBest loss: 0.843789\tAccuracy: 81.29%\n",
      "3\tValidation loss: 0.638292\tBest loss: 0.638292\tAccuracy: 82.73%\n",
      "4\tValidation loss: 0.611254\tBest loss: 0.611254\tAccuracy: 84.89%\n",
      "5\tValidation loss: 0.576854\tBest loss: 0.576854\tAccuracy: 85.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 0.591069\tBest loss: 0.576854\tAccuracy: 84.89%\n",
      "7\tValidation loss: 0.581148\tBest loss: 0.576854\tAccuracy: 87.05%\n",
      "8\tValidation loss: 0.562815\tBest loss: 0.562815\tAccuracy: 87.77%\n",
      "9\tValidation loss: 0.541517\tBest loss: 0.541517\tAccuracy: 88.49%\n",
      "10\tValidation loss: 0.544748\tBest loss: 0.541517\tAccuracy: 89.21%\n",
      "11\tValidation loss: 0.530316\tBest loss: 0.530316\tAccuracy: 89.21%\n",
      "12\tValidation loss: 0.535965\tBest loss: 0.530316\tAccuracy: 89.93%\n",
      "13\tValidation loss: 0.516733\tBest loss: 0.516733\tAccuracy: 90.65%\n",
      "14\tValidation loss: 0.520545\tBest loss: 0.516733\tAccuracy: 89.21%\n",
      "15\tValidation loss: 0.507961\tBest loss: 0.507961\tAccuracy: 89.21%\n",
      "16\tValidation loss: 0.509047\tBest loss: 0.507961\tAccuracy: 89.21%\n",
      "17\tValidation loss: 0.508754\tBest loss: 0.507961\tAccuracy: 89.21%\n",
      "18\tValidation loss: 0.497204\tBest loss: 0.497204\tAccuracy: 89.21%\n",
      "19\tValidation loss: 0.503971\tBest loss: 0.497204\tAccuracy: 89.21%\n",
      "20\tValidation loss: 0.497191\tBest loss: 0.497191\tAccuracy: 90.65%\n",
      "21\tValidation loss: 0.491644\tBest loss: 0.491644\tAccuracy: 90.65%\n",
      "22\tValidation loss: 0.483134\tBest loss: 0.483134\tAccuracy: 89.93%\n",
      "23\tValidation loss: 0.485357\tBest loss: 0.483134\tAccuracy: 89.93%\n",
      "24\tValidation loss: 0.483387\tBest loss: 0.483134\tAccuracy: 89.21%\n",
      "25\tValidation loss: 0.476345\tBest loss: 0.476345\tAccuracy: 89.93%\n",
      "26\tValidation loss: 0.473613\tBest loss: 0.473613\tAccuracy: 89.93%\n",
      "27\tValidation loss: 0.476997\tBest loss: 0.473613\tAccuracy: 89.21%\n",
      "28\tValidation loss: 0.475636\tBest loss: 0.473613\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.474499\tBest loss: 0.473613\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.472287\tBest loss: 0.472287\tAccuracy: 88.49%\n",
      "31\tValidation loss: 0.475140\tBest loss: 0.472287\tAccuracy: 89.21%\n",
      "32\tValidation loss: 0.472681\tBest loss: 0.472287\tAccuracy: 89.21%\n",
      "33\tValidation loss: 0.470724\tBest loss: 0.470724\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.465845\tBest loss: 0.465845\tAccuracy: 89.21%\n",
      "35\tValidation loss: 0.464129\tBest loss: 0.464129\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.467160\tBest loss: 0.464129\tAccuracy: 89.21%\n",
      "37\tValidation loss: 0.466927\tBest loss: 0.464129\tAccuracy: 89.21%\n",
      "38\tValidation loss: 0.464410\tBest loss: 0.464129\tAccuracy: 89.21%\n",
      "39\tValidation loss: 0.463647\tBest loss: 0.463647\tAccuracy: 89.21%\n",
      "40\tValidation loss: 0.459172\tBest loss: 0.459172\tAccuracy: 89.21%\n",
      "41\tValidation loss: 0.459344\tBest loss: 0.459172\tAccuracy: 89.21%\n",
      "42\tValidation loss: 0.456569\tBest loss: 0.456569\tAccuracy: 89.21%\n",
      "43\tValidation loss: 0.458934\tBest loss: 0.456569\tAccuracy: 89.21%\n",
      "44\tValidation loss: 0.456670\tBest loss: 0.456569\tAccuracy: 89.21%\n",
      "45\tValidation loss: 0.456260\tBest loss: 0.456260\tAccuracy: 89.21%\n",
      "46\tValidation loss: 0.455910\tBest loss: 0.455910\tAccuracy: 89.21%\n",
      "47\tValidation loss: 0.455987\tBest loss: 0.455910\tAccuracy: 89.21%\n",
      "48\tValidation loss: 0.456278\tBest loss: 0.455910\tAccuracy: 89.21%\n",
      "49\tValidation loss: 0.456063\tBest loss: 0.455910\tAccuracy: 89.21%\n",
      "50\tValidation loss: 0.456953\tBest loss: 0.455910\tAccuracy: 89.21%\n",
      "51\tValidation loss: 0.453112\tBest loss: 0.453112\tAccuracy: 88.49%\n",
      "52\tValidation loss: 0.452993\tBest loss: 0.452993\tAccuracy: 89.21%\n",
      "53\tValidation loss: 0.450687\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.451853\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "55\tValidation loss: 0.451856\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "56\tValidation loss: 0.451733\tBest loss: 0.450687\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.452339\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "58\tValidation loss: 0.452037\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "59\tValidation loss: 0.452598\tBest loss: 0.450687\tAccuracy: 89.21%\n",
      "60\tValidation loss: 0.450281\tBest loss: 0.450281\tAccuracy: 89.21%\n",
      "61\tValidation loss: 0.448542\tBest loss: 0.448542\tAccuracy: 89.21%\n",
      "62\tValidation loss: 0.447984\tBest loss: 0.447984\tAccuracy: 88.49%\n",
      "63\tValidation loss: 0.446803\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "64\tValidation loss: 0.446826\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.447748\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "66\tValidation loss: 0.448372\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "67\tValidation loss: 0.448807\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.448965\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "69\tValidation loss: 0.448170\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "70\tValidation loss: 0.450088\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "71\tValidation loss: 0.449991\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.449194\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "73\tValidation loss: 0.448992\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "74\tValidation loss: 0.447851\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "75\tValidation loss: 0.447743\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "76\tValidation loss: 0.447763\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "77\tValidation loss: 0.448623\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "78\tValidation loss: 0.448075\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "79\tValidation loss: 0.447008\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "80\tValidation loss: 0.447714\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "81\tValidation loss: 0.446957\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "82\tValidation loss: 0.447534\tBest loss: 0.446803\tAccuracy: 88.49%\n",
      "83\tValidation loss: 0.448075\tBest loss: 0.446803\tAccuracy: 87.77%\n",
      "84\tValidation loss: 0.446659\tBest loss: 0.446659\tAccuracy: 87.77%\n",
      "85\tValidation loss: 0.447292\tBest loss: 0.446659\tAccuracy: 87.77%\n",
      "86\tValidation loss: 0.446101\tBest loss: 0.446101\tAccuracy: 87.77%\n",
      "87\tValidation loss: 0.447036\tBest loss: 0.446101\tAccuracy: 87.77%\n",
      "88\tValidation loss: 0.446772\tBest loss: 0.446101\tAccuracy: 88.49%\n",
      "89\tValidation loss: 0.446544\tBest loss: 0.446101\tAccuracy: 87.77%\n",
      "90\tValidation loss: 0.446944\tBest loss: 0.446101\tAccuracy: 87.77%\n",
      "91\tValidation loss: 0.445983\tBest loss: 0.445983\tAccuracy: 87.77%\n",
      "92\tValidation loss: 0.445594\tBest loss: 0.445594\tAccuracy: 87.77%\n",
      "93\tValidation loss: 0.446112\tBest loss: 0.445594\tAccuracy: 87.77%\n",
      "94\tValidation loss: 0.445526\tBest loss: 0.445526\tAccuracy: 88.49%\n",
      "95\tValidation loss: 0.445256\tBest loss: 0.445256\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.444571\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "97\tValidation loss: 0.444992\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "98\tValidation loss: 0.444629\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "99\tValidation loss: 0.444961\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "100\tValidation loss: 0.444945\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "101\tValidation loss: 0.445428\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "102\tValidation loss: 0.445401\tBest loss: 0.444571\tAccuracy: 88.49%\n",
      "103\tValidation loss: 0.444703\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "104\tValidation loss: 0.445319\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "105\tValidation loss: 0.446375\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "106\tValidation loss: 0.445786\tBest loss: 0.444571\tAccuracy: 88.49%\n",
      "107\tValidation loss: 0.445414\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "108\tValidation loss: 0.446222\tBest loss: 0.444571\tAccuracy: 88.49%\n",
      "109\tValidation loss: 0.446020\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "110\tValidation loss: 0.445246\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "111\tValidation loss: 0.444707\tBest loss: 0.444571\tAccuracy: 87.77%\n",
      "112\tValidation loss: 0.444443\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "113\tValidation loss: 0.444661\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "114\tValidation loss: 0.444677\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "115\tValidation loss: 0.444897\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "116\tValidation loss: 0.445087\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "117\tValidation loss: 0.445849\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "118\tValidation loss: 0.445926\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "119\tValidation loss: 0.445608\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "120\tValidation loss: 0.445750\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "121\tValidation loss: 0.445187\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "122\tValidation loss: 0.445091\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "123\tValidation loss: 0.444630\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "124\tValidation loss: 0.444916\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "125\tValidation loss: 0.445338\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "126\tValidation loss: 0.445110\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "127\tValidation loss: 0.444862\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "128\tValidation loss: 0.444823\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "129\tValidation loss: 0.445439\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "130\tValidation loss: 0.445240\tBest loss: 0.444443\tAccuracy: 87.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\tValidation loss: 0.445460\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "132\tValidation loss: 0.444504\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "133\tValidation loss: 0.444724\tBest loss: 0.444443\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=  14.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 7.636544\tBest loss: 7.636544\tAccuracy: 44.60%\n",
      "1\tValidation loss: 0.865201\tBest loss: 0.865201\tAccuracy: 80.58%\n",
      "2\tValidation loss: 0.602074\tBest loss: 0.602074\tAccuracy: 83.45%\n",
      "3\tValidation loss: 0.498640\tBest loss: 0.498640\tAccuracy: 83.45%\n",
      "4\tValidation loss: 0.467606\tBest loss: 0.467606\tAccuracy: 83.45%\n",
      "5\tValidation loss: 0.449863\tBest loss: 0.449863\tAccuracy: 84.89%\n",
      "6\tValidation loss: 0.409743\tBest loss: 0.409743\tAccuracy: 84.89%\n",
      "7\tValidation loss: 0.398419\tBest loss: 0.398419\tAccuracy: 84.89%\n",
      "8\tValidation loss: 0.377911\tBest loss: 0.377911\tAccuracy: 86.33%\n",
      "9\tValidation loss: 0.378999\tBest loss: 0.377911\tAccuracy: 88.49%\n",
      "10\tValidation loss: 0.374534\tBest loss: 0.374534\tAccuracy: 87.77%\n",
      "11\tValidation loss: 0.355040\tBest loss: 0.355040\tAccuracy: 87.77%\n",
      "12\tValidation loss: 0.350843\tBest loss: 0.350843\tAccuracy: 87.77%\n",
      "13\tValidation loss: 0.360553\tBest loss: 0.350843\tAccuracy: 88.49%\n",
      "14\tValidation loss: 0.355587\tBest loss: 0.350843\tAccuracy: 88.49%\n",
      "15\tValidation loss: 0.349459\tBest loss: 0.349459\tAccuracy: 89.21%\n",
      "16\tValidation loss: 0.343322\tBest loss: 0.343322\tAccuracy: 88.49%\n",
      "17\tValidation loss: 0.348567\tBest loss: 0.343322\tAccuracy: 88.49%\n",
      "18\tValidation loss: 0.335847\tBest loss: 0.335847\tAccuracy: 89.21%\n",
      "19\tValidation loss: 0.330836\tBest loss: 0.330836\tAccuracy: 88.49%\n",
      "20\tValidation loss: 0.346574\tBest loss: 0.330836\tAccuracy: 89.21%\n",
      "21\tValidation loss: 0.339783\tBest loss: 0.330836\tAccuracy: 89.21%\n",
      "22\tValidation loss: 0.334140\tBest loss: 0.330836\tAccuracy: 89.21%\n",
      "23\tValidation loss: 0.329528\tBest loss: 0.329528\tAccuracy: 88.49%\n",
      "24\tValidation loss: 0.328529\tBest loss: 0.328529\tAccuracy: 88.49%\n",
      "25\tValidation loss: 0.326230\tBest loss: 0.326230\tAccuracy: 88.49%\n",
      "26\tValidation loss: 0.327856\tBest loss: 0.326230\tAccuracy: 88.49%\n",
      "27\tValidation loss: 0.323805\tBest loss: 0.323805\tAccuracy: 88.49%\n",
      "28\tValidation loss: 0.323527\tBest loss: 0.323527\tAccuracy: 88.49%\n",
      "29\tValidation loss: 0.323760\tBest loss: 0.323527\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.323512\tBest loss: 0.323512\tAccuracy: 89.21%\n",
      "31\tValidation loss: 0.324336\tBest loss: 0.323512\tAccuracy: 89.21%\n",
      "32\tValidation loss: 0.323967\tBest loss: 0.323512\tAccuracy: 89.21%\n",
      "33\tValidation loss: 0.322217\tBest loss: 0.322217\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.324379\tBest loss: 0.322217\tAccuracy: 88.49%\n",
      "35\tValidation loss: 0.321833\tBest loss: 0.321833\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.323607\tBest loss: 0.321833\tAccuracy: 89.21%\n",
      "37\tValidation loss: 0.324940\tBest loss: 0.321833\tAccuracy: 88.49%\n",
      "38\tValidation loss: 0.322758\tBest loss: 0.321833\tAccuracy: 88.49%\n",
      "39\tValidation loss: 0.320527\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "40\tValidation loss: 0.322894\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "41\tValidation loss: 0.324549\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "42\tValidation loss: 0.325875\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "43\tValidation loss: 0.323389\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "44\tValidation loss: 0.326636\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "45\tValidation loss: 0.325832\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "46\tValidation loss: 0.326812\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "47\tValidation loss: 0.324472\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "48\tValidation loss: 0.326776\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "49\tValidation loss: 0.328967\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.327648\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "51\tValidation loss: 0.328806\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.324362\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "53\tValidation loss: 0.324766\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "54\tValidation loss: 0.327545\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "55\tValidation loss: 0.328368\tBest loss: 0.320527\tAccuracy: 89.93%\n",
      "56\tValidation loss: 0.329806\tBest loss: 0.320527\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.331891\tBest loss: 0.320527\tAccuracy: 89.93%\n",
      "58\tValidation loss: 0.330722\tBest loss: 0.320527\tAccuracy: 89.93%\n",
      "59\tValidation loss: 0.331891\tBest loss: 0.320527\tAccuracy: 89.93%\n",
      "60\tValidation loss: 0.332672\tBest loss: 0.320527\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   6.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 3.886715\tBest loss: 3.886715\tAccuracy: 58.27%\n",
      "1\tValidation loss: 0.666731\tBest loss: 0.666731\tAccuracy: 82.01%\n",
      "2\tValidation loss: 0.543888\tBest loss: 0.543888\tAccuracy: 82.73%\n",
      "3\tValidation loss: 0.549397\tBest loss: 0.543888\tAccuracy: 84.17%\n",
      "4\tValidation loss: 0.488127\tBest loss: 0.488127\tAccuracy: 86.33%\n",
      "5\tValidation loss: 0.488334\tBest loss: 0.488127\tAccuracy: 86.33%\n",
      "6\tValidation loss: 0.476300\tBest loss: 0.476300\tAccuracy: 87.05%\n",
      "7\tValidation loss: 0.447842\tBest loss: 0.447842\tAccuracy: 87.77%\n",
      "8\tValidation loss: 0.453666\tBest loss: 0.447842\tAccuracy: 87.05%\n",
      "9\tValidation loss: 0.434088\tBest loss: 0.434088\tAccuracy: 88.49%\n",
      "10\tValidation loss: 0.434746\tBest loss: 0.434088\tAccuracy: 87.77%\n",
      "11\tValidation loss: 0.426626\tBest loss: 0.426626\tAccuracy: 88.49%\n",
      "12\tValidation loss: 0.421310\tBest loss: 0.421310\tAccuracy: 88.49%\n",
      "13\tValidation loss: 0.416743\tBest loss: 0.416743\tAccuracy: 87.77%\n",
      "14\tValidation loss: 0.409402\tBest loss: 0.409402\tAccuracy: 89.21%\n",
      "15\tValidation loss: 0.401888\tBest loss: 0.401888\tAccuracy: 88.49%\n",
      "16\tValidation loss: 0.399772\tBest loss: 0.399772\tAccuracy: 89.21%\n",
      "17\tValidation loss: 0.395807\tBest loss: 0.395807\tAccuracy: 88.49%\n",
      "18\tValidation loss: 0.399532\tBest loss: 0.395807\tAccuracy: 88.49%\n",
      "19\tValidation loss: 0.394834\tBest loss: 0.394834\tAccuracy: 88.49%\n",
      "20\tValidation loss: 0.394321\tBest loss: 0.394321\tAccuracy: 88.49%\n",
      "21\tValidation loss: 0.390387\tBest loss: 0.390387\tAccuracy: 88.49%\n",
      "22\tValidation loss: 0.392551\tBest loss: 0.390387\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.391307\tBest loss: 0.390387\tAccuracy: 88.49%\n",
      "24\tValidation loss: 0.391051\tBest loss: 0.390387\tAccuracy: 87.77%\n",
      "25\tValidation loss: 0.387656\tBest loss: 0.387656\tAccuracy: 89.21%\n",
      "26\tValidation loss: 0.389291\tBest loss: 0.387656\tAccuracy: 88.49%\n",
      "27\tValidation loss: 0.387730\tBest loss: 0.387656\tAccuracy: 89.21%\n",
      "28\tValidation loss: 0.387083\tBest loss: 0.387083\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.386467\tBest loss: 0.386467\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.385528\tBest loss: 0.385528\tAccuracy: 89.21%\n",
      "31\tValidation loss: 0.383583\tBest loss: 0.383583\tAccuracy: 89.21%\n",
      "32\tValidation loss: 0.383247\tBest loss: 0.383247\tAccuracy: 89.21%\n",
      "33\tValidation loss: 0.382029\tBest loss: 0.382029\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.383621\tBest loss: 0.382029\tAccuracy: 89.21%\n",
      "35\tValidation loss: 0.382145\tBest loss: 0.382029\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.381916\tBest loss: 0.381916\tAccuracy: 89.21%\n",
      "37\tValidation loss: 0.383476\tBest loss: 0.381916\tAccuracy: 89.21%\n",
      "38\tValidation loss: 0.384257\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "39\tValidation loss: 0.383107\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "40\tValidation loss: 0.384373\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "41\tValidation loss: 0.383805\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "42\tValidation loss: 0.382374\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "43\tValidation loss: 0.384415\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "44\tValidation loss: 0.384051\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "45\tValidation loss: 0.384348\tBest loss: 0.381916\tAccuracy: 87.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\tValidation loss: 0.385533\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "47\tValidation loss: 0.385684\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "48\tValidation loss: 0.385041\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.384315\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "50\tValidation loss: 0.384041\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "51\tValidation loss: 0.384010\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "52\tValidation loss: 0.384737\tBest loss: 0.381916\tAccuracy: 87.77%\n",
      "53\tValidation loss: 0.384698\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "54\tValidation loss: 0.383118\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "55\tValidation loss: 0.384444\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "56\tValidation loss: 0.384560\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.384974\tBest loss: 0.381916\tAccuracy: 88.49%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=50, activation=<function relu at 0x00000252A18B50D0>, total=   6.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 9.682422\tBest loss: 9.682422\tAccuracy: 0.72%\n",
      "1\tValidation loss: 4.136862\tBest loss: 4.136862\tAccuracy: 5.04%\n",
      "2\tValidation loss: 3.871359\tBest loss: 3.871359\tAccuracy: 5.04%\n",
      "3\tValidation loss: 3.869440\tBest loss: 3.869440\tAccuracy: 5.04%\n",
      "4\tValidation loss: 3.851295\tBest loss: 3.851295\tAccuracy: 5.04%\n",
      "5\tValidation loss: 3.838121\tBest loss: 3.838121\tAccuracy: 5.04%\n",
      "6\tValidation loss: 3.831679\tBest loss: 3.831679\tAccuracy: 1.44%\n",
      "7\tValidation loss: 3.831123\tBest loss: 3.831123\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.828659\tBest loss: 3.828659\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.825786\tBest loss: 3.825786\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.822654\tBest loss: 3.822654\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.820896\tBest loss: 3.820896\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.818956\tBest loss: 3.818956\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.817744\tBest loss: 3.817744\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.818027\tBest loss: 3.817744\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.815693\tBest loss: 3.815693\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.816701\tBest loss: 3.815693\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.812892\tBest loss: 3.812892\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.813399\tBest loss: 3.812892\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.811258\tBest loss: 3.811258\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.814109\tBest loss: 3.811258\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.811840\tBest loss: 3.811258\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.811594\tBest loss: 3.811258\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.809487\tBest loss: 3.809487\tAccuracy: 6.47%\n",
      "24\tValidation loss: 3.810219\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.810035\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.813683\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.812267\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.812368\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.809678\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.809938\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.810016\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.812693\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.812710\tBest loss: 3.809487\tAccuracy: 6.47%\n",
      "34\tValidation loss: 3.811757\tBest loss: 3.809487\tAccuracy: 6.47%\n",
      "35\tValidation loss: 3.813927\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.814417\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.813210\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.812372\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.812398\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.814055\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.810098\tBest loss: 3.809487\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.808040\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.812149\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.814914\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.816092\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.813489\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.814144\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.812882\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.813653\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.813787\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.812105\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.811878\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "53\tValidation loss: 3.811850\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "54\tValidation loss: 3.813958\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "55\tValidation loss: 3.813586\tBest loss: 3.808040\tAccuracy: 6.47%\n",
      "56\tValidation loss: 3.810002\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.811288\tBest loss: 3.808040\tAccuracy: 3.60%\n",
      "58\tValidation loss: 3.807264\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "59\tValidation loss: 3.810067\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "60\tValidation loss: 3.812726\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "61\tValidation loss: 3.811585\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "62\tValidation loss: 3.812553\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.812524\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "64\tValidation loss: 3.813639\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "65\tValidation loss: 3.815545\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "66\tValidation loss: 3.815809\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "67\tValidation loss: 3.815297\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "68\tValidation loss: 3.811145\tBest loss: 3.807264\tAccuracy: 6.47%\n",
      "69\tValidation loss: 3.809684\tBest loss: 3.807264\tAccuracy: 6.47%\n",
      "70\tValidation loss: 3.812035\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "71\tValidation loss: 3.812378\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "72\tValidation loss: 3.810619\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "73\tValidation loss: 3.813233\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "74\tValidation loss: 3.810086\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "75\tValidation loss: 3.814943\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "76\tValidation loss: 3.812129\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "77\tValidation loss: 3.811280\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "78\tValidation loss: 3.810697\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "79\tValidation loss: 3.811701\tBest loss: 3.807264\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   9.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 6.453365\tBest loss: 6.453365\tAccuracy: 4.32%\n",
      "1\tValidation loss: 3.870618\tBest loss: 3.870618\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.867259\tBest loss: 3.867259\tAccuracy: 2.16%\n",
      "3\tValidation loss: 3.845792\tBest loss: 3.845792\tAccuracy: 2.16%\n",
      "4\tValidation loss: 3.825205\tBest loss: 3.825205\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.816784\tBest loss: 3.816784\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.814150\tBest loss: 3.814150\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.813217\tBest loss: 3.813217\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.811134\tBest loss: 3.811134\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.810125\tBest loss: 3.810125\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.808712\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.808991\tBest loss: 3.808712\tAccuracy: 6.47%\n",
      "12\tValidation loss: 3.809686\tBest loss: 3.808712\tAccuracy: 6.47%\n",
      "13\tValidation loss: 3.809279\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.809619\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.809738\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.810548\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.809165\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.812654\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.810428\tBest loss: 3.808712\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.807290\tBest loss: 3.807290\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\tValidation loss: 3.807989\tBest loss: 3.807290\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.806610\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.808842\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.808591\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.811411\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.811579\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.814408\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.812163\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.810425\tBest loss: 3.806610\tAccuracy: 6.47%\n",
      "30\tValidation loss: 3.808473\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.809107\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.809272\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "33\tValidation loss: 3.809693\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.808664\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.811188\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.809447\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.811185\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.811779\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.809228\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.810348\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.808987\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.810227\tBest loss: 3.806610\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.810742\tBest loss: 3.806610\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   5.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 5.003564\tBest loss: 5.003564\tAccuracy: 0.00%\n",
      "1\tValidation loss: 4.754712\tBest loss: 4.754712\tAccuracy: 2.16%\n",
      "2\tValidation loss: 6.941487\tBest loss: 4.754712\tAccuracy: 5.04%\n",
      "3\tValidation loss: 10.462503\tBest loss: 4.754712\tAccuracy: 5.76%\n",
      "4\tValidation loss: 3.823202\tBest loss: 3.823202\tAccuracy: 5.04%\n",
      "5\tValidation loss: 3.830459\tBest loss: 3.823202\tAccuracy: 2.88%\n",
      "6\tValidation loss: 3.827344\tBest loss: 3.823202\tAccuracy: 3.60%\n",
      "7\tValidation loss: 3.828814\tBest loss: 3.823202\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.830265\tBest loss: 3.823202\tAccuracy: 3.60%\n",
      "9\tValidation loss: 3.828373\tBest loss: 3.823202\tAccuracy: 3.60%\n",
      "10\tValidation loss: 3.824274\tBest loss: 3.823202\tAccuracy: 3.60%\n",
      "11\tValidation loss: 3.820901\tBest loss: 3.820901\tAccuracy: 3.60%\n",
      "12\tValidation loss: 3.815213\tBest loss: 3.815213\tAccuracy: 3.60%\n",
      "13\tValidation loss: 3.813554\tBest loss: 3.813554\tAccuracy: 3.60%\n",
      "14\tValidation loss: 3.810472\tBest loss: 3.810472\tAccuracy: 3.60%\n",
      "15\tValidation loss: 3.809700\tBest loss: 3.809700\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.808424\tBest loss: 3.808424\tAccuracy: 3.60%\n",
      "17\tValidation loss: 3.809909\tBest loss: 3.808424\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.809794\tBest loss: 3.808424\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.808021\tBest loss: 3.808021\tAccuracy: 3.60%\n",
      "20\tValidation loss: 3.809099\tBest loss: 3.808021\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.809352\tBest loss: 3.808021\tAccuracy: 3.60%\n",
      "22\tValidation loss: 3.810434\tBest loss: 3.808021\tAccuracy: 3.60%\n",
      "23\tValidation loss: 3.809484\tBest loss: 3.808021\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.805448\tBest loss: 3.805448\tAccuracy: 3.60%\n",
      "25\tValidation loss: 3.804406\tBest loss: 3.804406\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.802314\tBest loss: 3.802314\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.805888\tBest loss: 3.802314\tAccuracy: 3.60%\n",
      "28\tValidation loss: 3.805212\tBest loss: 3.802314\tAccuracy: 2.16%\n",
      "29\tValidation loss: 3.811963\tBest loss: 3.802314\tAccuracy: 3.60%\n",
      "30\tValidation loss: 3.809039\tBest loss: 3.802314\tAccuracy: 2.16%\n",
      "31\tValidation loss: 3.806988\tBest loss: 3.802314\tAccuracy: 2.16%\n",
      "32\tValidation loss: 3.806048\tBest loss: 3.802314\tAccuracy: 2.16%\n",
      "33\tValidation loss: 3.803427\tBest loss: 3.802314\tAccuracy: 2.16%\n",
      "34\tValidation loss: 3.802078\tBest loss: 3.802078\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.797326\tBest loss: 3.797326\tAccuracy: 3.60%\n",
      "36\tValidation loss: 3.797646\tBest loss: 3.797326\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.795651\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "38\tValidation loss: 3.804014\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.804708\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.854735\tBest loss: 3.795651\tAccuracy: 2.88%\n",
      "41\tValidation loss: 3.810412\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "42\tValidation loss: 3.806195\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.804918\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.809025\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.814400\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.815959\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.806530\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.806292\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.806592\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.802045\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.806976\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.809484\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "53\tValidation loss: 3.809343\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "54\tValidation loss: 3.811347\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "55\tValidation loss: 3.812943\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "56\tValidation loss: 3.810060\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.807649\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "58\tValidation loss: 3.813065\tBest loss: 3.795651\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   7.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 149.243881\tBest loss: 149.243881\tAccuracy: 41.01%\n",
      "1\tValidation loss: 13.022842\tBest loss: 13.022842\tAccuracy: 76.98%\n",
      "2\tValidation loss: 3.064739\tBest loss: 3.064739\tAccuracy: 85.61%\n",
      "3\tValidation loss: 2.273248\tBest loss: 2.273248\tAccuracy: 87.77%\n",
      "4\tValidation loss: 1.692203\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "5\tValidation loss: 1.711377\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "6\tValidation loss: 1.706171\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "7\tValidation loss: 1.747848\tBest loss: 1.692203\tAccuracy: 89.21%\n",
      "8\tValidation loss: 1.835517\tBest loss: 1.692203\tAccuracy: 90.65%\n",
      "9\tValidation loss: 1.920583\tBest loss: 1.692203\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.312274\tBest loss: 1.312274\tAccuracy: 92.81%\n",
      "11\tValidation loss: 1.345087\tBest loss: 1.312274\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.337866\tBest loss: 1.312274\tAccuracy: 91.37%\n",
      "13\tValidation loss: 1.294053\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "14\tValidation loss: 1.311134\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "15\tValidation loss: 1.415579\tBest loss: 1.294053\tAccuracy: 92.09%\n",
      "16\tValidation loss: 1.386243\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "17\tValidation loss: 1.367903\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "18\tValidation loss: 1.358056\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "19\tValidation loss: 1.336080\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "20\tValidation loss: 1.333977\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "21\tValidation loss: 1.313326\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "22\tValidation loss: 1.305875\tBest loss: 1.294053\tAccuracy: 92.81%\n",
      "23\tValidation loss: 1.292080\tBest loss: 1.292080\tAccuracy: 92.81%\n",
      "24\tValidation loss: 1.282080\tBest loss: 1.282080\tAccuracy: 92.81%\n",
      "25\tValidation loss: 1.264940\tBest loss: 1.264940\tAccuracy: 92.81%\n",
      "26\tValidation loss: 1.251236\tBest loss: 1.251236\tAccuracy: 92.81%\n",
      "27\tValidation loss: 1.237349\tBest loss: 1.237349\tAccuracy: 92.81%\n",
      "28\tValidation loss: 1.230950\tBest loss: 1.230950\tAccuracy: 92.81%\n",
      "29\tValidation loss: 1.225333\tBest loss: 1.225333\tAccuracy: 92.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\tValidation loss: 1.221472\tBest loss: 1.221472\tAccuracy: 92.81%\n",
      "31\tValidation loss: 1.219496\tBest loss: 1.219496\tAccuracy: 92.81%\n",
      "32\tValidation loss: 1.217501\tBest loss: 1.217501\tAccuracy: 92.81%\n",
      "33\tValidation loss: 1.215929\tBest loss: 1.215929\tAccuracy: 92.81%\n",
      "34\tValidation loss: 1.213558\tBest loss: 1.213558\tAccuracy: 92.81%\n",
      "35\tValidation loss: 1.212316\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "36\tValidation loss: 1.213393\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "37\tValidation loss: 1.214216\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "38\tValidation loss: 1.212729\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "39\tValidation loss: 1.212647\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "40\tValidation loss: 1.213709\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "41\tValidation loss: 1.213682\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "42\tValidation loss: 1.213243\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "43\tValidation loss: 1.213021\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "44\tValidation loss: 1.213771\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "45\tValidation loss: 1.214675\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "46\tValidation loss: 1.215699\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "47\tValidation loss: 1.216275\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "48\tValidation loss: 1.216820\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "49\tValidation loss: 1.217206\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "50\tValidation loss: 1.217297\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "51\tValidation loss: 1.217452\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "52\tValidation loss: 1.217616\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "53\tValidation loss: 1.218500\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "54\tValidation loss: 1.219201\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "55\tValidation loss: 1.219640\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "56\tValidation loss: 1.220639\tBest loss: 1.212316\tAccuracy: 92.09%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total=   6.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 106.085571\tBest loss: 106.085571\tAccuracy: 43.17%\n",
      "1\tValidation loss: 7.470767\tBest loss: 7.470767\tAccuracy: 80.58%\n",
      "2\tValidation loss: 3.732459\tBest loss: 3.732459\tAccuracy: 84.17%\n",
      "3\tValidation loss: 2.476254\tBest loss: 2.476254\tAccuracy: 88.49%\n",
      "4\tValidation loss: 2.166965\tBest loss: 2.166965\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.884392\tBest loss: 1.884392\tAccuracy: 85.61%\n",
      "6\tValidation loss: 1.722733\tBest loss: 1.722733\tAccuracy: 88.49%\n",
      "7\tValidation loss: 1.640909\tBest loss: 1.640909\tAccuracy: 89.93%\n",
      "8\tValidation loss: 1.498040\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "9\tValidation loss: 1.592885\tBest loss: 1.498040\tAccuracy: 89.93%\n",
      "10\tValidation loss: 1.516133\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "11\tValidation loss: 1.520671\tBest loss: 1.498040\tAccuracy: 89.21%\n",
      "12\tValidation loss: 1.459917\tBest loss: 1.459917\tAccuracy: 89.21%\n",
      "13\tValidation loss: 1.449062\tBest loss: 1.449062\tAccuracy: 90.65%\n",
      "14\tValidation loss: 1.457271\tBest loss: 1.449062\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.442070\tBest loss: 1.442070\tAccuracy: 90.65%\n",
      "16\tValidation loss: 1.397251\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "17\tValidation loss: 1.409543\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "18\tValidation loss: 1.403412\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "19\tValidation loss: 1.399037\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "20\tValidation loss: 1.399575\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "21\tValidation loss: 1.398277\tBest loss: 1.397251\tAccuracy: 90.65%\n",
      "22\tValidation loss: 1.395848\tBest loss: 1.395848\tAccuracy: 90.65%\n",
      "23\tValidation loss: 1.395264\tBest loss: 1.395264\tAccuracy: 90.65%\n",
      "24\tValidation loss: 1.392942\tBest loss: 1.392942\tAccuracy: 90.65%\n",
      "25\tValidation loss: 1.389107\tBest loss: 1.389107\tAccuracy: 90.65%\n",
      "26\tValidation loss: 1.388084\tBest loss: 1.388084\tAccuracy: 90.65%\n",
      "27\tValidation loss: 1.388054\tBest loss: 1.388054\tAccuracy: 90.65%\n",
      "28\tValidation loss: 1.386218\tBest loss: 1.386218\tAccuracy: 90.65%\n",
      "29\tValidation loss: 1.385202\tBest loss: 1.385202\tAccuracy: 90.65%\n",
      "30\tValidation loss: 1.385309\tBest loss: 1.385202\tAccuracy: 90.65%\n",
      "31\tValidation loss: 1.384943\tBest loss: 1.384943\tAccuracy: 90.65%\n",
      "32\tValidation loss: 1.384230\tBest loss: 1.384230\tAccuracy: 90.65%\n",
      "33\tValidation loss: 1.383366\tBest loss: 1.383366\tAccuracy: 90.65%\n",
      "34\tValidation loss: 1.382838\tBest loss: 1.382838\tAccuracy: 90.65%\n",
      "35\tValidation loss: 1.382352\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "36\tValidation loss: 1.383041\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "37\tValidation loss: 1.382644\tBest loss: 1.382352\tAccuracy: 90.65%\n",
      "38\tValidation loss: 1.381945\tBest loss: 1.381945\tAccuracy: 90.65%\n",
      "39\tValidation loss: 1.381864\tBest loss: 1.381864\tAccuracy: 90.65%\n",
      "40\tValidation loss: 1.381380\tBest loss: 1.381380\tAccuracy: 89.93%\n",
      "41\tValidation loss: 1.380342\tBest loss: 1.380342\tAccuracy: 89.93%\n",
      "42\tValidation loss: 1.380001\tBest loss: 1.380001\tAccuracy: 89.93%\n",
      "43\tValidation loss: 1.379563\tBest loss: 1.379563\tAccuracy: 89.93%\n",
      "44\tValidation loss: 1.379130\tBest loss: 1.379130\tAccuracy: 89.93%\n",
      "45\tValidation loss: 1.378901\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "46\tValidation loss: 1.379094\tBest loss: 1.378901\tAccuracy: 89.93%\n",
      "47\tValidation loss: 1.378875\tBest loss: 1.378875\tAccuracy: 89.93%\n",
      "48\tValidation loss: 1.378456\tBest loss: 1.378456\tAccuracy: 89.93%\n",
      "49\tValidation loss: 1.378312\tBest loss: 1.378312\tAccuracy: 89.93%\n",
      "50\tValidation loss: 1.378067\tBest loss: 1.378067\tAccuracy: 89.93%\n",
      "51\tValidation loss: 1.377724\tBest loss: 1.377724\tAccuracy: 89.93%\n",
      "52\tValidation loss: 1.377167\tBest loss: 1.377167\tAccuracy: 89.93%\n",
      "53\tValidation loss: 1.376782\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "54\tValidation loss: 1.376867\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "55\tValidation loss: 1.376913\tBest loss: 1.376782\tAccuracy: 89.93%\n",
      "56\tValidation loss: 1.376736\tBest loss: 1.376736\tAccuracy: 89.93%\n",
      "57\tValidation loss: 1.376402\tBest loss: 1.376402\tAccuracy: 89.93%\n",
      "58\tValidation loss: 1.376336\tBest loss: 1.376336\tAccuracy: 89.93%\n",
      "59\tValidation loss: 1.375827\tBest loss: 1.375827\tAccuracy: 89.93%\n",
      "60\tValidation loss: 1.375190\tBest loss: 1.375190\tAccuracy: 89.93%\n",
      "61\tValidation loss: 1.375145\tBest loss: 1.375145\tAccuracy: 89.93%\n",
      "62\tValidation loss: 1.374501\tBest loss: 1.374501\tAccuracy: 90.65%\n",
      "63\tValidation loss: 1.374355\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "64\tValidation loss: 1.374605\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "65\tValidation loss: 1.374385\tBest loss: 1.374355\tAccuracy: 90.65%\n",
      "66\tValidation loss: 1.374017\tBest loss: 1.374017\tAccuracy: 90.65%\n",
      "67\tValidation loss: 1.373549\tBest loss: 1.373549\tAccuracy: 90.65%\n",
      "68\tValidation loss: 1.373207\tBest loss: 1.373207\tAccuracy: 90.65%\n",
      "69\tValidation loss: 1.373017\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "70\tValidation loss: 1.373183\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "71\tValidation loss: 1.373071\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "72\tValidation loss: 1.373060\tBest loss: 1.373017\tAccuracy: 90.65%\n",
      "73\tValidation loss: 1.372931\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "74\tValidation loss: 1.372952\tBest loss: 1.372931\tAccuracy: 90.65%\n",
      "75\tValidation loss: 1.372553\tBest loss: 1.372553\tAccuracy: 90.65%\n",
      "76\tValidation loss: 1.372201\tBest loss: 1.372201\tAccuracy: 90.65%\n",
      "77\tValidation loss: 1.372061\tBest loss: 1.372061\tAccuracy: 90.65%\n",
      "78\tValidation loss: 1.371762\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "79\tValidation loss: 1.371888\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "80\tValidation loss: 1.371850\tBest loss: 1.371762\tAccuracy: 90.65%\n",
      "81\tValidation loss: 1.371671\tBest loss: 1.371671\tAccuracy: 90.65%\n",
      "82\tValidation loss: 1.371479\tBest loss: 1.371479\tAccuracy: 90.65%\n",
      "83\tValidation loss: 1.371271\tBest loss: 1.371271\tAccuracy: 90.65%\n",
      "84\tValidation loss: 1.371223\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "85\tValidation loss: 1.371225\tBest loss: 1.371223\tAccuracy: 90.65%\n",
      "86\tValidation loss: 1.371065\tBest loss: 1.371065\tAccuracy: 90.65%\n",
      "87\tValidation loss: 1.370694\tBest loss: 1.370694\tAccuracy: 90.65%\n",
      "88\tValidation loss: 1.370362\tBest loss: 1.370362\tAccuracy: 90.65%\n",
      "89\tValidation loss: 1.370111\tBest loss: 1.370111\tAccuracy: 90.65%\n",
      "90\tValidation loss: 1.369944\tBest loss: 1.369944\tAccuracy: 90.65%\n",
      "91\tValidation loss: 1.369722\tBest loss: 1.369722\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\tValidation loss: 1.369701\tBest loss: 1.369701\tAccuracy: 90.65%\n",
      "93\tValidation loss: 1.369633\tBest loss: 1.369633\tAccuracy: 90.65%\n",
      "94\tValidation loss: 1.369630\tBest loss: 1.369630\tAccuracy: 90.65%\n",
      "95\tValidation loss: 1.369463\tBest loss: 1.369463\tAccuracy: 90.65%\n",
      "96\tValidation loss: 1.369438\tBest loss: 1.369438\tAccuracy: 90.65%\n",
      "97\tValidation loss: 1.369115\tBest loss: 1.369115\tAccuracy: 90.65%\n",
      "98\tValidation loss: 1.368974\tBest loss: 1.368974\tAccuracy: 90.65%\n",
      "99\tValidation loss: 1.368726\tBest loss: 1.368726\tAccuracy: 90.65%\n",
      "100\tValidation loss: 1.368736\tBest loss: 1.368726\tAccuracy: 90.65%\n",
      "101\tValidation loss: 1.368508\tBest loss: 1.368508\tAccuracy: 90.65%\n",
      "102\tValidation loss: 1.368246\tBest loss: 1.368246\tAccuracy: 90.65%\n",
      "103\tValidation loss: 1.368216\tBest loss: 1.368216\tAccuracy: 90.65%\n",
      "104\tValidation loss: 1.368142\tBest loss: 1.368142\tAccuracy: 90.65%\n",
      "105\tValidation loss: 1.367981\tBest loss: 1.367981\tAccuracy: 90.65%\n",
      "106\tValidation loss: 1.367801\tBest loss: 1.367801\tAccuracy: 90.65%\n",
      "107\tValidation loss: 1.367592\tBest loss: 1.367592\tAccuracy: 90.65%\n",
      "108\tValidation loss: 1.367494\tBest loss: 1.367494\tAccuracy: 90.65%\n",
      "109\tValidation loss: 1.367285\tBest loss: 1.367285\tAccuracy: 90.65%\n",
      "110\tValidation loss: 1.367244\tBest loss: 1.367244\tAccuracy: 90.65%\n",
      "111\tValidation loss: 1.367137\tBest loss: 1.367137\tAccuracy: 90.65%\n",
      "112\tValidation loss: 1.366981\tBest loss: 1.366981\tAccuracy: 90.65%\n",
      "113\tValidation loss: 1.366910\tBest loss: 1.366910\tAccuracy: 90.65%\n",
      "114\tValidation loss: 1.366804\tBest loss: 1.366804\tAccuracy: 90.65%\n",
      "115\tValidation loss: 1.366653\tBest loss: 1.366653\tAccuracy: 90.65%\n",
      "116\tValidation loss: 1.366652\tBest loss: 1.366652\tAccuracy: 90.65%\n",
      "117\tValidation loss: 1.366573\tBest loss: 1.366573\tAccuracy: 90.65%\n",
      "118\tValidation loss: 1.366432\tBest loss: 1.366432\tAccuracy: 90.65%\n",
      "119\tValidation loss: 1.366418\tBest loss: 1.366418\tAccuracy: 90.65%\n",
      "120\tValidation loss: 1.366286\tBest loss: 1.366286\tAccuracy: 90.65%\n",
      "121\tValidation loss: 1.366272\tBest loss: 1.366272\tAccuracy: 90.65%\n",
      "122\tValidation loss: 1.366105\tBest loss: 1.366105\tAccuracy: 90.65%\n",
      "123\tValidation loss: 1.365904\tBest loss: 1.365904\tAccuracy: 90.65%\n",
      "124\tValidation loss: 1.365771\tBest loss: 1.365771\tAccuracy: 90.65%\n",
      "125\tValidation loss: 1.365732\tBest loss: 1.365732\tAccuracy: 90.65%\n",
      "126\tValidation loss: 1.365605\tBest loss: 1.365605\tAccuracy: 90.65%\n",
      "127\tValidation loss: 1.365537\tBest loss: 1.365537\tAccuracy: 90.65%\n",
      "128\tValidation loss: 1.365500\tBest loss: 1.365500\tAccuracy: 90.65%\n",
      "129\tValidation loss: 1.365339\tBest loss: 1.365339\tAccuracy: 90.65%\n",
      "130\tValidation loss: 1.365180\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "131\tValidation loss: 1.365199\tBest loss: 1.365180\tAccuracy: 90.65%\n",
      "132\tValidation loss: 1.365084\tBest loss: 1.365084\tAccuracy: 90.65%\n",
      "133\tValidation loss: 1.364945\tBest loss: 1.364945\tAccuracy: 90.65%\n",
      "134\tValidation loss: 1.364810\tBest loss: 1.364810\tAccuracy: 90.65%\n",
      "135\tValidation loss: 1.364704\tBest loss: 1.364704\tAccuracy: 90.65%\n",
      "136\tValidation loss: 1.364617\tBest loss: 1.364617\tAccuracy: 90.65%\n",
      "137\tValidation loss: 1.364582\tBest loss: 1.364582\tAccuracy: 90.65%\n",
      "138\tValidation loss: 1.364433\tBest loss: 1.364433\tAccuracy: 90.65%\n",
      "139\tValidation loss: 1.364315\tBest loss: 1.364315\tAccuracy: 90.65%\n",
      "140\tValidation loss: 1.364292\tBest loss: 1.364292\tAccuracy: 90.65%\n",
      "141\tValidation loss: 1.364211\tBest loss: 1.364211\tAccuracy: 90.65%\n",
      "142\tValidation loss: 1.364155\tBest loss: 1.364155\tAccuracy: 90.65%\n",
      "143\tValidation loss: 1.364090\tBest loss: 1.364090\tAccuracy: 90.65%\n",
      "144\tValidation loss: 1.364098\tBest loss: 1.364090\tAccuracy: 90.65%\n",
      "145\tValidation loss: 1.364024\tBest loss: 1.364024\tAccuracy: 90.65%\n",
      "146\tValidation loss: 1.364007\tBest loss: 1.364007\tAccuracy: 90.65%\n",
      "147\tValidation loss: 1.363933\tBest loss: 1.363933\tAccuracy: 90.65%\n",
      "148\tValidation loss: 1.363901\tBest loss: 1.363901\tAccuracy: 90.65%\n",
      "149\tValidation loss: 1.363889\tBest loss: 1.363889\tAccuracy: 90.65%\n",
      "150\tValidation loss: 1.363727\tBest loss: 1.363727\tAccuracy: 90.65%\n",
      "151\tValidation loss: 1.363622\tBest loss: 1.363622\tAccuracy: 90.65%\n",
      "152\tValidation loss: 1.363590\tBest loss: 1.363590\tAccuracy: 90.65%\n",
      "153\tValidation loss: 1.363538\tBest loss: 1.363538\tAccuracy: 90.65%\n",
      "154\tValidation loss: 1.363504\tBest loss: 1.363504\tAccuracy: 90.65%\n",
      "155\tValidation loss: 1.363386\tBest loss: 1.363386\tAccuracy: 90.65%\n",
      "156\tValidation loss: 1.363268\tBest loss: 1.363268\tAccuracy: 90.65%\n",
      "157\tValidation loss: 1.363187\tBest loss: 1.363187\tAccuracy: 90.65%\n",
      "158\tValidation loss: 1.363079\tBest loss: 1.363079\tAccuracy: 90.65%\n",
      "159\tValidation loss: 1.362932\tBest loss: 1.362932\tAccuracy: 90.65%\n",
      "160\tValidation loss: 1.362914\tBest loss: 1.362914\tAccuracy: 90.65%\n",
      "161\tValidation loss: 1.362863\tBest loss: 1.362863\tAccuracy: 90.65%\n",
      "162\tValidation loss: 1.362810\tBest loss: 1.362810\tAccuracy: 90.65%\n",
      "163\tValidation loss: 1.362725\tBest loss: 1.362725\tAccuracy: 90.65%\n",
      "164\tValidation loss: 1.362710\tBest loss: 1.362710\tAccuracy: 90.65%\n",
      "165\tValidation loss: 1.362671\tBest loss: 1.362671\tAccuracy: 90.65%\n",
      "166\tValidation loss: 1.362583\tBest loss: 1.362583\tAccuracy: 90.65%\n",
      "167\tValidation loss: 1.362535\tBest loss: 1.362535\tAccuracy: 90.65%\n",
      "168\tValidation loss: 1.362467\tBest loss: 1.362467\tAccuracy: 90.65%\n",
      "169\tValidation loss: 1.362393\tBest loss: 1.362393\tAccuracy: 90.65%\n",
      "170\tValidation loss: 1.362326\tBest loss: 1.362326\tAccuracy: 90.65%\n",
      "171\tValidation loss: 1.362287\tBest loss: 1.362287\tAccuracy: 90.65%\n",
      "172\tValidation loss: 1.362193\tBest loss: 1.362193\tAccuracy: 90.65%\n",
      "173\tValidation loss: 1.362143\tBest loss: 1.362143\tAccuracy: 90.65%\n",
      "174\tValidation loss: 1.362107\tBest loss: 1.362107\tAccuracy: 90.65%\n",
      "175\tValidation loss: 1.362069\tBest loss: 1.362069\tAccuracy: 90.65%\n",
      "176\tValidation loss: 1.361972\tBest loss: 1.361972\tAccuracy: 90.65%\n",
      "177\tValidation loss: 1.361931\tBest loss: 1.361931\tAccuracy: 90.65%\n",
      "178\tValidation loss: 1.361834\tBest loss: 1.361834\tAccuracy: 90.65%\n",
      "179\tValidation loss: 1.361734\tBest loss: 1.361734\tAccuracy: 90.65%\n",
      "180\tValidation loss: 1.361679\tBest loss: 1.361679\tAccuracy: 90.65%\n",
      "181\tValidation loss: 1.361609\tBest loss: 1.361609\tAccuracy: 90.65%\n",
      "182\tValidation loss: 1.361547\tBest loss: 1.361547\tAccuracy: 90.65%\n",
      "183\tValidation loss: 1.361496\tBest loss: 1.361496\tAccuracy: 90.65%\n",
      "184\tValidation loss: 1.361399\tBest loss: 1.361399\tAccuracy: 90.65%\n",
      "185\tValidation loss: 1.361292\tBest loss: 1.361292\tAccuracy: 90.65%\n",
      "186\tValidation loss: 1.361284\tBest loss: 1.361284\tAccuracy: 90.65%\n",
      "187\tValidation loss: 1.361248\tBest loss: 1.361248\tAccuracy: 90.65%\n",
      "188\tValidation loss: 1.361247\tBest loss: 1.361247\tAccuracy: 90.65%\n",
      "189\tValidation loss: 1.361195\tBest loss: 1.361195\tAccuracy: 90.65%\n",
      "190\tValidation loss: 1.361111\tBest loss: 1.361111\tAccuracy: 90.65%\n",
      "191\tValidation loss: 1.361039\tBest loss: 1.361039\tAccuracy: 90.65%\n",
      "192\tValidation loss: 1.360950\tBest loss: 1.360950\tAccuracy: 90.65%\n",
      "193\tValidation loss: 1.360903\tBest loss: 1.360903\tAccuracy: 90.65%\n",
      "194\tValidation loss: 1.360811\tBest loss: 1.360811\tAccuracy: 90.65%\n",
      "195\tValidation loss: 1.360744\tBest loss: 1.360744\tAccuracy: 90.65%\n",
      "196\tValidation loss: 1.360727\tBest loss: 1.360727\tAccuracy: 90.65%\n",
      "197\tValidation loss: 1.360654\tBest loss: 1.360654\tAccuracy: 90.65%\n",
      "198\tValidation loss: 1.360600\tBest loss: 1.360600\tAccuracy: 90.65%\n",
      "199\tValidation loss: 1.360593\tBest loss: 1.360593\tAccuracy: 90.65%\n",
      "200\tValidation loss: 1.360552\tBest loss: 1.360552\tAccuracy: 90.65%\n",
      "201\tValidation loss: 1.360520\tBest loss: 1.360520\tAccuracy: 90.65%\n",
      "202\tValidation loss: 1.360448\tBest loss: 1.360448\tAccuracy: 90.65%\n",
      "203\tValidation loss: 1.360380\tBest loss: 1.360380\tAccuracy: 90.65%\n",
      "204\tValidation loss: 1.360336\tBest loss: 1.360336\tAccuracy: 90.65%\n",
      "205\tValidation loss: 1.360225\tBest loss: 1.360225\tAccuracy: 90.65%\n",
      "206\tValidation loss: 1.360179\tBest loss: 1.360179\tAccuracy: 90.65%\n",
      "207\tValidation loss: 1.360137\tBest loss: 1.360137\tAccuracy: 90.65%\n",
      "208\tValidation loss: 1.360098\tBest loss: 1.360098\tAccuracy: 90.65%\n",
      "209\tValidation loss: 1.360004\tBest loss: 1.360004\tAccuracy: 90.65%\n",
      "210\tValidation loss: 1.359919\tBest loss: 1.359919\tAccuracy: 90.65%\n",
      "211\tValidation loss: 1.359850\tBest loss: 1.359850\tAccuracy: 90.65%\n",
      "212\tValidation loss: 1.359799\tBest loss: 1.359799\tAccuracy: 90.65%\n",
      "213\tValidation loss: 1.359726\tBest loss: 1.359726\tAccuracy: 90.65%\n",
      "214\tValidation loss: 1.359684\tBest loss: 1.359684\tAccuracy: 90.65%\n",
      "215\tValidation loss: 1.359655\tBest loss: 1.359655\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\tValidation loss: 1.359659\tBest loss: 1.359655\tAccuracy: 90.65%\n",
      "217\tValidation loss: 1.359636\tBest loss: 1.359636\tAccuracy: 90.65%\n",
      "218\tValidation loss: 1.359626\tBest loss: 1.359626\tAccuracy: 90.65%\n",
      "219\tValidation loss: 1.359591\tBest loss: 1.359591\tAccuracy: 90.65%\n",
      "220\tValidation loss: 1.359488\tBest loss: 1.359488\tAccuracy: 90.65%\n",
      "221\tValidation loss: 1.359433\tBest loss: 1.359433\tAccuracy: 90.65%\n",
      "222\tValidation loss: 1.359385\tBest loss: 1.359385\tAccuracy: 90.65%\n",
      "223\tValidation loss: 1.359340\tBest loss: 1.359340\tAccuracy: 90.65%\n",
      "224\tValidation loss: 1.359301\tBest loss: 1.359301\tAccuracy: 90.65%\n",
      "225\tValidation loss: 1.359263\tBest loss: 1.359263\tAccuracy: 90.65%\n",
      "226\tValidation loss: 1.359231\tBest loss: 1.359231\tAccuracy: 90.65%\n",
      "227\tValidation loss: 1.359203\tBest loss: 1.359203\tAccuracy: 90.65%\n",
      "228\tValidation loss: 1.359149\tBest loss: 1.359149\tAccuracy: 90.65%\n",
      "229\tValidation loss: 1.359111\tBest loss: 1.359111\tAccuracy: 90.65%\n",
      "230\tValidation loss: 1.359068\tBest loss: 1.359068\tAccuracy: 90.65%\n",
      "231\tValidation loss: 1.359008\tBest loss: 1.359008\tAccuracy: 90.65%\n",
      "232\tValidation loss: 1.358955\tBest loss: 1.358955\tAccuracy: 90.65%\n",
      "233\tValidation loss: 1.358945\tBest loss: 1.358945\tAccuracy: 90.65%\n",
      "234\tValidation loss: 1.358918\tBest loss: 1.358918\tAccuracy: 90.65%\n",
      "235\tValidation loss: 1.358917\tBest loss: 1.358917\tAccuracy: 90.65%\n",
      "236\tValidation loss: 1.358853\tBest loss: 1.358853\tAccuracy: 90.65%\n",
      "237\tValidation loss: 1.358814\tBest loss: 1.358814\tAccuracy: 90.65%\n",
      "238\tValidation loss: 1.358807\tBest loss: 1.358807\tAccuracy: 90.65%\n",
      "239\tValidation loss: 1.358749\tBest loss: 1.358749\tAccuracy: 90.65%\n",
      "240\tValidation loss: 1.358672\tBest loss: 1.358672\tAccuracy: 90.65%\n",
      "241\tValidation loss: 1.358638\tBest loss: 1.358638\tAccuracy: 90.65%\n",
      "242\tValidation loss: 1.358585\tBest loss: 1.358585\tAccuracy: 90.65%\n",
      "243\tValidation loss: 1.358526\tBest loss: 1.358526\tAccuracy: 90.65%\n",
      "244\tValidation loss: 1.358477\tBest loss: 1.358477\tAccuracy: 90.65%\n",
      "245\tValidation loss: 1.358429\tBest loss: 1.358429\tAccuracy: 90.65%\n",
      "246\tValidation loss: 1.358401\tBest loss: 1.358401\tAccuracy: 90.65%\n",
      "247\tValidation loss: 1.358355\tBest loss: 1.358355\tAccuracy: 90.65%\n",
      "248\tValidation loss: 1.358314\tBest loss: 1.358314\tAccuracy: 90.65%\n",
      "249\tValidation loss: 1.358309\tBest loss: 1.358309\tAccuracy: 90.65%\n",
      "250\tValidation loss: 1.358236\tBest loss: 1.358236\tAccuracy: 90.65%\n",
      "251\tValidation loss: 1.358177\tBest loss: 1.358177\tAccuracy: 90.65%\n",
      "252\tValidation loss: 1.358172\tBest loss: 1.358172\tAccuracy: 90.65%\n",
      "253\tValidation loss: 1.358156\tBest loss: 1.358156\tAccuracy: 90.65%\n",
      "254\tValidation loss: 1.358108\tBest loss: 1.358108\tAccuracy: 90.65%\n",
      "255\tValidation loss: 1.358064\tBest loss: 1.358064\tAccuracy: 90.65%\n",
      "256\tValidation loss: 1.357977\tBest loss: 1.357977\tAccuracy: 90.65%\n",
      "257\tValidation loss: 1.357931\tBest loss: 1.357931\tAccuracy: 90.65%\n",
      "258\tValidation loss: 1.357858\tBest loss: 1.357858\tAccuracy: 90.65%\n",
      "259\tValidation loss: 1.357818\tBest loss: 1.357818\tAccuracy: 90.65%\n",
      "260\tValidation loss: 1.357802\tBest loss: 1.357802\tAccuracy: 90.65%\n",
      "261\tValidation loss: 1.357744\tBest loss: 1.357744\tAccuracy: 90.65%\n",
      "262\tValidation loss: 1.357704\tBest loss: 1.357704\tAccuracy: 90.65%\n",
      "263\tValidation loss: 1.357672\tBest loss: 1.357672\tAccuracy: 90.65%\n",
      "264\tValidation loss: 1.357629\tBest loss: 1.357629\tAccuracy: 90.65%\n",
      "265\tValidation loss: 1.357590\tBest loss: 1.357590\tAccuracy: 90.65%\n",
      "266\tValidation loss: 1.357564\tBest loss: 1.357564\tAccuracy: 90.65%\n",
      "267\tValidation loss: 1.357526\tBest loss: 1.357526\tAccuracy: 90.65%\n",
      "268\tValidation loss: 1.357510\tBest loss: 1.357510\tAccuracy: 90.65%\n",
      "269\tValidation loss: 1.357448\tBest loss: 1.357448\tAccuracy: 90.65%\n",
      "270\tValidation loss: 1.357448\tBest loss: 1.357448\tAccuracy: 90.65%\n",
      "271\tValidation loss: 1.357414\tBest loss: 1.357414\tAccuracy: 90.65%\n",
      "272\tValidation loss: 1.357350\tBest loss: 1.357350\tAccuracy: 90.65%\n",
      "273\tValidation loss: 1.357305\tBest loss: 1.357305\tAccuracy: 90.65%\n",
      "274\tValidation loss: 1.357242\tBest loss: 1.357242\tAccuracy: 90.65%\n",
      "275\tValidation loss: 1.357189\tBest loss: 1.357189\tAccuracy: 90.65%\n",
      "276\tValidation loss: 1.357168\tBest loss: 1.357168\tAccuracy: 90.65%\n",
      "277\tValidation loss: 1.357127\tBest loss: 1.357127\tAccuracy: 90.65%\n",
      "278\tValidation loss: 1.357077\tBest loss: 1.357077\tAccuracy: 90.65%\n",
      "279\tValidation loss: 1.357073\tBest loss: 1.357073\tAccuracy: 90.65%\n",
      "280\tValidation loss: 1.357020\tBest loss: 1.357020\tAccuracy: 90.65%\n",
      "281\tValidation loss: 1.356973\tBest loss: 1.356973\tAccuracy: 90.65%\n",
      "282\tValidation loss: 1.356918\tBest loss: 1.356918\tAccuracy: 90.65%\n",
      "283\tValidation loss: 1.356887\tBest loss: 1.356887\tAccuracy: 90.65%\n",
      "284\tValidation loss: 1.356825\tBest loss: 1.356825\tAccuracy: 90.65%\n",
      "285\tValidation loss: 1.356769\tBest loss: 1.356769\tAccuracy: 90.65%\n",
      "286\tValidation loss: 1.356749\tBest loss: 1.356749\tAccuracy: 90.65%\n",
      "287\tValidation loss: 1.356729\tBest loss: 1.356729\tAccuracy: 90.65%\n",
      "288\tValidation loss: 1.356692\tBest loss: 1.356692\tAccuracy: 90.65%\n",
      "289\tValidation loss: 1.356651\tBest loss: 1.356651\tAccuracy: 90.65%\n",
      "290\tValidation loss: 1.356634\tBest loss: 1.356634\tAccuracy: 90.65%\n",
      "291\tValidation loss: 1.356578\tBest loss: 1.356578\tAccuracy: 90.65%\n",
      "292\tValidation loss: 1.356493\tBest loss: 1.356493\tAccuracy: 90.65%\n",
      "293\tValidation loss: 1.356450\tBest loss: 1.356450\tAccuracy: 90.65%\n",
      "294\tValidation loss: 1.356451\tBest loss: 1.356450\tAccuracy: 90.65%\n",
      "295\tValidation loss: 1.356415\tBest loss: 1.356415\tAccuracy: 90.65%\n",
      "296\tValidation loss: 1.356352\tBest loss: 1.356352\tAccuracy: 90.65%\n",
      "297\tValidation loss: 1.356302\tBest loss: 1.356302\tAccuracy: 90.65%\n",
      "298\tValidation loss: 1.356249\tBest loss: 1.356249\tAccuracy: 90.65%\n",
      "299\tValidation loss: 1.356214\tBest loss: 1.356214\tAccuracy: 90.65%\n",
      "300\tValidation loss: 1.356166\tBest loss: 1.356166\tAccuracy: 90.65%\n",
      "301\tValidation loss: 1.356126\tBest loss: 1.356126\tAccuracy: 90.65%\n",
      "302\tValidation loss: 1.356099\tBest loss: 1.356099\tAccuracy: 90.65%\n",
      "303\tValidation loss: 1.356050\tBest loss: 1.356050\tAccuracy: 90.65%\n",
      "304\tValidation loss: 1.356008\tBest loss: 1.356008\tAccuracy: 90.65%\n",
      "305\tValidation loss: 1.355964\tBest loss: 1.355964\tAccuracy: 90.65%\n",
      "306\tValidation loss: 1.355915\tBest loss: 1.355915\tAccuracy: 90.65%\n",
      "307\tValidation loss: 1.355873\tBest loss: 1.355873\tAccuracy: 90.65%\n",
      "308\tValidation loss: 1.355817\tBest loss: 1.355817\tAccuracy: 90.65%\n",
      "309\tValidation loss: 1.355787\tBest loss: 1.355787\tAccuracy: 90.65%\n",
      "310\tValidation loss: 1.355756\tBest loss: 1.355756\tAccuracy: 90.65%\n",
      "311\tValidation loss: 1.355726\tBest loss: 1.355726\tAccuracy: 90.65%\n",
      "312\tValidation loss: 1.355670\tBest loss: 1.355670\tAccuracy: 90.65%\n",
      "313\tValidation loss: 1.355616\tBest loss: 1.355616\tAccuracy: 90.65%\n",
      "314\tValidation loss: 1.355590\tBest loss: 1.355590\tAccuracy: 90.65%\n",
      "315\tValidation loss: 1.355552\tBest loss: 1.355552\tAccuracy: 90.65%\n",
      "316\tValidation loss: 1.355504\tBest loss: 1.355504\tAccuracy: 90.65%\n",
      "317\tValidation loss: 1.355484\tBest loss: 1.355484\tAccuracy: 90.65%\n",
      "318\tValidation loss: 1.355468\tBest loss: 1.355468\tAccuracy: 90.65%\n",
      "319\tValidation loss: 1.355430\tBest loss: 1.355430\tAccuracy: 90.65%\n",
      "320\tValidation loss: 1.355395\tBest loss: 1.355395\tAccuracy: 90.65%\n",
      "321\tValidation loss: 1.355392\tBest loss: 1.355392\tAccuracy: 90.65%\n",
      "322\tValidation loss: 1.355369\tBest loss: 1.355369\tAccuracy: 90.65%\n",
      "323\tValidation loss: 1.355339\tBest loss: 1.355339\tAccuracy: 90.65%\n",
      "324\tValidation loss: 1.355298\tBest loss: 1.355298\tAccuracy: 90.65%\n",
      "325\tValidation loss: 1.355266\tBest loss: 1.355266\tAccuracy: 90.65%\n",
      "326\tValidation loss: 1.355243\tBest loss: 1.355243\tAccuracy: 90.65%\n",
      "327\tValidation loss: 1.355196\tBest loss: 1.355196\tAccuracy: 90.65%\n",
      "328\tValidation loss: 1.355159\tBest loss: 1.355159\tAccuracy: 90.65%\n",
      "329\tValidation loss: 1.355134\tBest loss: 1.355134\tAccuracy: 90.65%\n",
      "330\tValidation loss: 1.355118\tBest loss: 1.355118\tAccuracy: 90.65%\n",
      "331\tValidation loss: 1.355091\tBest loss: 1.355091\tAccuracy: 90.65%\n",
      "332\tValidation loss: 1.355044\tBest loss: 1.355044\tAccuracy: 90.65%\n",
      "333\tValidation loss: 1.355021\tBest loss: 1.355021\tAccuracy: 90.65%\n",
      "334\tValidation loss: 1.355003\tBest loss: 1.355003\tAccuracy: 90.65%\n",
      "335\tValidation loss: 1.354969\tBest loss: 1.354969\tAccuracy: 90.65%\n",
      "336\tValidation loss: 1.354929\tBest loss: 1.354929\tAccuracy: 90.65%\n",
      "337\tValidation loss: 1.354898\tBest loss: 1.354898\tAccuracy: 90.65%\n",
      "338\tValidation loss: 1.354861\tBest loss: 1.354861\tAccuracy: 90.65%\n",
      "339\tValidation loss: 1.354820\tBest loss: 1.354820\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\tValidation loss: 1.354779\tBest loss: 1.354779\tAccuracy: 90.65%\n",
      "341\tValidation loss: 1.354758\tBest loss: 1.354758\tAccuracy: 90.65%\n",
      "342\tValidation loss: 1.354708\tBest loss: 1.354708\tAccuracy: 90.65%\n",
      "343\tValidation loss: 1.354681\tBest loss: 1.354681\tAccuracy: 90.65%\n",
      "344\tValidation loss: 1.354670\tBest loss: 1.354670\tAccuracy: 90.65%\n",
      "345\tValidation loss: 1.354644\tBest loss: 1.354644\tAccuracy: 90.65%\n",
      "346\tValidation loss: 1.354613\tBest loss: 1.354613\tAccuracy: 90.65%\n",
      "347\tValidation loss: 1.354571\tBest loss: 1.354571\tAccuracy: 90.65%\n",
      "348\tValidation loss: 1.354526\tBest loss: 1.354526\tAccuracy: 90.65%\n",
      "349\tValidation loss: 1.354511\tBest loss: 1.354511\tAccuracy: 90.65%\n",
      "350\tValidation loss: 1.354487\tBest loss: 1.354487\tAccuracy: 90.65%\n",
      "351\tValidation loss: 1.354435\tBest loss: 1.354435\tAccuracy: 90.65%\n",
      "352\tValidation loss: 1.354397\tBest loss: 1.354397\tAccuracy: 90.65%\n",
      "353\tValidation loss: 1.354366\tBest loss: 1.354366\tAccuracy: 90.65%\n",
      "354\tValidation loss: 1.354363\tBest loss: 1.354363\tAccuracy: 90.65%\n",
      "355\tValidation loss: 1.354314\tBest loss: 1.354314\tAccuracy: 90.65%\n",
      "356\tValidation loss: 1.354274\tBest loss: 1.354274\tAccuracy: 90.65%\n",
      "357\tValidation loss: 1.354270\tBest loss: 1.354270\tAccuracy: 90.65%\n",
      "358\tValidation loss: 1.354234\tBest loss: 1.354234\tAccuracy: 90.65%\n",
      "359\tValidation loss: 1.354188\tBest loss: 1.354188\tAccuracy: 90.65%\n",
      "360\tValidation loss: 1.354172\tBest loss: 1.354172\tAccuracy: 90.65%\n",
      "361\tValidation loss: 1.354151\tBest loss: 1.354151\tAccuracy: 90.65%\n",
      "362\tValidation loss: 1.354128\tBest loss: 1.354128\tAccuracy: 90.65%\n",
      "363\tValidation loss: 1.354084\tBest loss: 1.354084\tAccuracy: 90.65%\n",
      "364\tValidation loss: 1.354037\tBest loss: 1.354037\tAccuracy: 90.65%\n",
      "365\tValidation loss: 1.354015\tBest loss: 1.354015\tAccuracy: 90.65%\n",
      "366\tValidation loss: 1.353944\tBest loss: 1.353944\tAccuracy: 90.65%\n",
      "367\tValidation loss: 1.353945\tBest loss: 1.353944\tAccuracy: 90.65%\n",
      "368\tValidation loss: 1.353909\tBest loss: 1.353909\tAccuracy: 90.65%\n",
      "369\tValidation loss: 1.353863\tBest loss: 1.353863\tAccuracy: 90.65%\n",
      "370\tValidation loss: 1.353849\tBest loss: 1.353849\tAccuracy: 90.65%\n",
      "371\tValidation loss: 1.353815\tBest loss: 1.353815\tAccuracy: 90.65%\n",
      "372\tValidation loss: 1.353783\tBest loss: 1.353783\tAccuracy: 90.65%\n",
      "373\tValidation loss: 1.353736\tBest loss: 1.353736\tAccuracy: 90.65%\n",
      "374\tValidation loss: 1.353717\tBest loss: 1.353717\tAccuracy: 90.65%\n",
      "375\tValidation loss: 1.353709\tBest loss: 1.353709\tAccuracy: 90.65%\n",
      "376\tValidation loss: 1.353699\tBest loss: 1.353699\tAccuracy: 90.65%\n",
      "377\tValidation loss: 1.353674\tBest loss: 1.353674\tAccuracy: 90.65%\n",
      "378\tValidation loss: 1.353633\tBest loss: 1.353633\tAccuracy: 90.65%\n",
      "379\tValidation loss: 1.353604\tBest loss: 1.353604\tAccuracy: 90.65%\n",
      "380\tValidation loss: 1.353585\tBest loss: 1.353585\tAccuracy: 90.65%\n",
      "381\tValidation loss: 1.353556\tBest loss: 1.353556\tAccuracy: 90.65%\n",
      "382\tValidation loss: 1.353521\tBest loss: 1.353521\tAccuracy: 90.65%\n",
      "383\tValidation loss: 1.353495\tBest loss: 1.353495\tAccuracy: 90.65%\n",
      "384\tValidation loss: 1.353481\tBest loss: 1.353481\tAccuracy: 90.65%\n",
      "385\tValidation loss: 1.353461\tBest loss: 1.353461\tAccuracy: 90.65%\n",
      "386\tValidation loss: 1.353435\tBest loss: 1.353435\tAccuracy: 90.65%\n",
      "387\tValidation loss: 1.353402\tBest loss: 1.353402\tAccuracy: 90.65%\n",
      "388\tValidation loss: 1.353371\tBest loss: 1.353371\tAccuracy: 90.65%\n",
      "389\tValidation loss: 1.353336\tBest loss: 1.353336\tAccuracy: 90.65%\n",
      "390\tValidation loss: 1.353293\tBest loss: 1.353293\tAccuracy: 90.65%\n",
      "391\tValidation loss: 1.353258\tBest loss: 1.353258\tAccuracy: 90.65%\n",
      "392\tValidation loss: 1.353237\tBest loss: 1.353237\tAccuracy: 90.65%\n",
      "393\tValidation loss: 1.353213\tBest loss: 1.353213\tAccuracy: 90.65%\n",
      "394\tValidation loss: 1.353166\tBest loss: 1.353166\tAccuracy: 90.65%\n",
      "395\tValidation loss: 1.353162\tBest loss: 1.353162\tAccuracy: 90.65%\n",
      "396\tValidation loss: 1.353142\tBest loss: 1.353142\tAccuracy: 90.65%\n",
      "397\tValidation loss: 1.353112\tBest loss: 1.353112\tAccuracy: 90.65%\n",
      "398\tValidation loss: 1.353080\tBest loss: 1.353080\tAccuracy: 90.65%\n",
      "399\tValidation loss: 1.353027\tBest loss: 1.353027\tAccuracy: 90.65%\n",
      "400\tValidation loss: 1.352990\tBest loss: 1.352990\tAccuracy: 90.65%\n",
      "401\tValidation loss: 1.352970\tBest loss: 1.352970\tAccuracy: 90.65%\n",
      "402\tValidation loss: 1.352942\tBest loss: 1.352942\tAccuracy: 90.65%\n",
      "403\tValidation loss: 1.352895\tBest loss: 1.352895\tAccuracy: 90.65%\n",
      "404\tValidation loss: 1.352872\tBest loss: 1.352872\tAccuracy: 90.65%\n",
      "405\tValidation loss: 1.352849\tBest loss: 1.352849\tAccuracy: 90.65%\n",
      "406\tValidation loss: 1.352809\tBest loss: 1.352809\tAccuracy: 90.65%\n",
      "407\tValidation loss: 1.352800\tBest loss: 1.352800\tAccuracy: 90.65%\n",
      "408\tValidation loss: 1.352788\tBest loss: 1.352788\tAccuracy: 90.65%\n",
      "409\tValidation loss: 1.352768\tBest loss: 1.352768\tAccuracy: 90.65%\n",
      "410\tValidation loss: 1.352738\tBest loss: 1.352738\tAccuracy: 90.65%\n",
      "411\tValidation loss: 1.352714\tBest loss: 1.352714\tAccuracy: 90.65%\n",
      "412\tValidation loss: 1.352699\tBest loss: 1.352699\tAccuracy: 90.65%\n",
      "413\tValidation loss: 1.352647\tBest loss: 1.352647\tAccuracy: 90.65%\n",
      "414\tValidation loss: 1.352612\tBest loss: 1.352612\tAccuracy: 90.65%\n",
      "415\tValidation loss: 1.352594\tBest loss: 1.352594\tAccuracy: 90.65%\n",
      "416\tValidation loss: 1.352552\tBest loss: 1.352552\tAccuracy: 90.65%\n",
      "417\tValidation loss: 1.352524\tBest loss: 1.352524\tAccuracy: 90.65%\n",
      "418\tValidation loss: 1.352499\tBest loss: 1.352499\tAccuracy: 90.65%\n",
      "419\tValidation loss: 1.352472\tBest loss: 1.352472\tAccuracy: 90.65%\n",
      "420\tValidation loss: 1.352441\tBest loss: 1.352441\tAccuracy: 90.65%\n",
      "421\tValidation loss: 1.352405\tBest loss: 1.352405\tAccuracy: 90.65%\n",
      "422\tValidation loss: 1.352366\tBest loss: 1.352366\tAccuracy: 90.65%\n",
      "423\tValidation loss: 1.352347\tBest loss: 1.352347\tAccuracy: 90.65%\n",
      "424\tValidation loss: 1.352332\tBest loss: 1.352332\tAccuracy: 90.65%\n",
      "425\tValidation loss: 1.352316\tBest loss: 1.352316\tAccuracy: 90.65%\n",
      "426\tValidation loss: 1.352278\tBest loss: 1.352278\tAccuracy: 90.65%\n",
      "427\tValidation loss: 1.352249\tBest loss: 1.352249\tAccuracy: 90.65%\n",
      "428\tValidation loss: 1.352200\tBest loss: 1.352200\tAccuracy: 90.65%\n",
      "429\tValidation loss: 1.352178\tBest loss: 1.352178\tAccuracy: 90.65%\n",
      "430\tValidation loss: 1.352174\tBest loss: 1.352174\tAccuracy: 90.65%\n",
      "431\tValidation loss: 1.352159\tBest loss: 1.352159\tAccuracy: 90.65%\n",
      "432\tValidation loss: 1.352125\tBest loss: 1.352125\tAccuracy: 90.65%\n",
      "433\tValidation loss: 1.352099\tBest loss: 1.352099\tAccuracy: 90.65%\n",
      "434\tValidation loss: 1.352070\tBest loss: 1.352070\tAccuracy: 90.65%\n",
      "435\tValidation loss: 1.352043\tBest loss: 1.352043\tAccuracy: 90.65%\n",
      "436\tValidation loss: 1.352006\tBest loss: 1.352006\tAccuracy: 90.65%\n",
      "437\tValidation loss: 1.352019\tBest loss: 1.352006\tAccuracy: 90.65%\n",
      "438\tValidation loss: 1.351991\tBest loss: 1.351991\tAccuracy: 90.65%\n",
      "439\tValidation loss: 1.351962\tBest loss: 1.351962\tAccuracy: 90.65%\n",
      "440\tValidation loss: 1.351940\tBest loss: 1.351940\tAccuracy: 90.65%\n",
      "441\tValidation loss: 1.351901\tBest loss: 1.351901\tAccuracy: 90.65%\n",
      "442\tValidation loss: 1.351870\tBest loss: 1.351870\tAccuracy: 90.65%\n",
      "443\tValidation loss: 1.351828\tBest loss: 1.351828\tAccuracy: 90.65%\n",
      "444\tValidation loss: 1.351820\tBest loss: 1.351820\tAccuracy: 90.65%\n",
      "445\tValidation loss: 1.351802\tBest loss: 1.351802\tAccuracy: 90.65%\n",
      "446\tValidation loss: 1.351792\tBest loss: 1.351792\tAccuracy: 90.65%\n",
      "447\tValidation loss: 1.351757\tBest loss: 1.351757\tAccuracy: 90.65%\n",
      "448\tValidation loss: 1.351727\tBest loss: 1.351727\tAccuracy: 90.65%\n",
      "449\tValidation loss: 1.351710\tBest loss: 1.351710\tAccuracy: 90.65%\n",
      "450\tValidation loss: 1.351680\tBest loss: 1.351680\tAccuracy: 90.65%\n",
      "451\tValidation loss: 1.351653\tBest loss: 1.351653\tAccuracy: 90.65%\n",
      "452\tValidation loss: 1.351627\tBest loss: 1.351627\tAccuracy: 90.65%\n",
      "453\tValidation loss: 1.351604\tBest loss: 1.351604\tAccuracy: 90.65%\n",
      "454\tValidation loss: 1.351579\tBest loss: 1.351579\tAccuracy: 90.65%\n",
      "455\tValidation loss: 1.351564\tBest loss: 1.351564\tAccuracy: 90.65%\n",
      "456\tValidation loss: 1.351530\tBest loss: 1.351530\tAccuracy: 90.65%\n",
      "457\tValidation loss: 1.351494\tBest loss: 1.351494\tAccuracy: 90.65%\n",
      "458\tValidation loss: 1.351452\tBest loss: 1.351452\tAccuracy: 90.65%\n",
      "459\tValidation loss: 1.351431\tBest loss: 1.351431\tAccuracy: 90.65%\n",
      "460\tValidation loss: 1.351408\tBest loss: 1.351408\tAccuracy: 90.65%\n",
      "461\tValidation loss: 1.351380\tBest loss: 1.351380\tAccuracy: 90.65%\n",
      "462\tValidation loss: 1.351332\tBest loss: 1.351332\tAccuracy: 90.65%\n",
      "463\tValidation loss: 1.351335\tBest loss: 1.351332\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\tValidation loss: 1.351301\tBest loss: 1.351301\tAccuracy: 90.65%\n",
      "465\tValidation loss: 1.351277\tBest loss: 1.351277\tAccuracy: 90.65%\n",
      "466\tValidation loss: 1.351257\tBest loss: 1.351257\tAccuracy: 90.65%\n",
      "467\tValidation loss: 1.351242\tBest loss: 1.351242\tAccuracy: 90.65%\n",
      "468\tValidation loss: 1.351235\tBest loss: 1.351235\tAccuracy: 90.65%\n",
      "469\tValidation loss: 1.351217\tBest loss: 1.351217\tAccuracy: 90.65%\n",
      "470\tValidation loss: 1.351196\tBest loss: 1.351196\tAccuracy: 90.65%\n",
      "471\tValidation loss: 1.351169\tBest loss: 1.351169\tAccuracy: 90.65%\n",
      "472\tValidation loss: 1.351148\tBest loss: 1.351148\tAccuracy: 90.65%\n",
      "473\tValidation loss: 1.351127\tBest loss: 1.351127\tAccuracy: 90.65%\n",
      "474\tValidation loss: 1.351110\tBest loss: 1.351110\tAccuracy: 90.65%\n",
      "475\tValidation loss: 1.351080\tBest loss: 1.351080\tAccuracy: 90.65%\n",
      "476\tValidation loss: 1.351061\tBest loss: 1.351061\tAccuracy: 90.65%\n",
      "477\tValidation loss: 1.351041\tBest loss: 1.351041\tAccuracy: 90.65%\n",
      "478\tValidation loss: 1.351012\tBest loss: 1.351012\tAccuracy: 90.65%\n",
      "479\tValidation loss: 1.350991\tBest loss: 1.350991\tAccuracy: 90.65%\n",
      "480\tValidation loss: 1.350980\tBest loss: 1.350980\tAccuracy: 90.65%\n",
      "481\tValidation loss: 1.350968\tBest loss: 1.350968\tAccuracy: 90.65%\n",
      "482\tValidation loss: 1.350943\tBest loss: 1.350943\tAccuracy: 90.65%\n",
      "483\tValidation loss: 1.350911\tBest loss: 1.350911\tAccuracy: 90.65%\n",
      "484\tValidation loss: 1.350887\tBest loss: 1.350887\tAccuracy: 90.65%\n",
      "485\tValidation loss: 1.350881\tBest loss: 1.350881\tAccuracy: 90.65%\n",
      "486\tValidation loss: 1.350849\tBest loss: 1.350849\tAccuracy: 90.65%\n",
      "487\tValidation loss: 1.350819\tBest loss: 1.350819\tAccuracy: 90.65%\n",
      "488\tValidation loss: 1.350784\tBest loss: 1.350784\tAccuracy: 90.65%\n",
      "489\tValidation loss: 1.350766\tBest loss: 1.350766\tAccuracy: 90.65%\n",
      "490\tValidation loss: 1.350726\tBest loss: 1.350726\tAccuracy: 90.65%\n",
      "491\tValidation loss: 1.350707\tBest loss: 1.350707\tAccuracy: 90.65%\n",
      "492\tValidation loss: 1.350664\tBest loss: 1.350664\tAccuracy: 90.65%\n",
      "493\tValidation loss: 1.350655\tBest loss: 1.350655\tAccuracy: 90.65%\n",
      "494\tValidation loss: 1.350626\tBest loss: 1.350626\tAccuracy: 90.65%\n",
      "495\tValidation loss: 1.350592\tBest loss: 1.350592\tAccuracy: 90.65%\n",
      "496\tValidation loss: 1.350575\tBest loss: 1.350575\tAccuracy: 90.65%\n",
      "497\tValidation loss: 1.350551\tBest loss: 1.350551\tAccuracy: 90.65%\n",
      "498\tValidation loss: 1.350527\tBest loss: 1.350527\tAccuracy: 90.65%\n",
      "499\tValidation loss: 1.350499\tBest loss: 1.350499\tAccuracy: 90.65%\n",
      "500\tValidation loss: 1.350462\tBest loss: 1.350462\tAccuracy: 90.65%\n",
      "501\tValidation loss: 1.350443\tBest loss: 1.350443\tAccuracy: 90.65%\n",
      "502\tValidation loss: 1.350422\tBest loss: 1.350422\tAccuracy: 90.65%\n",
      "503\tValidation loss: 1.350406\tBest loss: 1.350406\tAccuracy: 90.65%\n",
      "504\tValidation loss: 1.350378\tBest loss: 1.350378\tAccuracy: 90.65%\n",
      "505\tValidation loss: 1.350352\tBest loss: 1.350352\tAccuracy: 90.65%\n",
      "506\tValidation loss: 1.350331\tBest loss: 1.350331\tAccuracy: 90.65%\n",
      "507\tValidation loss: 1.350298\tBest loss: 1.350298\tAccuracy: 90.65%\n",
      "508\tValidation loss: 1.350270\tBest loss: 1.350270\tAccuracy: 90.65%\n",
      "509\tValidation loss: 1.350261\tBest loss: 1.350261\tAccuracy: 90.65%\n",
      "510\tValidation loss: 1.350244\tBest loss: 1.350244\tAccuracy: 90.65%\n",
      "511\tValidation loss: 1.350213\tBest loss: 1.350213\tAccuracy: 90.65%\n",
      "512\tValidation loss: 1.350185\tBest loss: 1.350185\tAccuracy: 90.65%\n",
      "513\tValidation loss: 1.350171\tBest loss: 1.350171\tAccuracy: 90.65%\n",
      "514\tValidation loss: 1.350158\tBest loss: 1.350158\tAccuracy: 90.65%\n",
      "515\tValidation loss: 1.350137\tBest loss: 1.350137\tAccuracy: 90.65%\n",
      "516\tValidation loss: 1.350103\tBest loss: 1.350103\tAccuracy: 90.65%\n",
      "517\tValidation loss: 1.350090\tBest loss: 1.350090\tAccuracy: 90.65%\n",
      "518\tValidation loss: 1.350050\tBest loss: 1.350050\tAccuracy: 90.65%\n",
      "519\tValidation loss: 1.350012\tBest loss: 1.350012\tAccuracy: 90.65%\n",
      "520\tValidation loss: 1.349994\tBest loss: 1.349994\tAccuracy: 90.65%\n",
      "521\tValidation loss: 1.349980\tBest loss: 1.349980\tAccuracy: 90.65%\n",
      "522\tValidation loss: 1.349957\tBest loss: 1.349957\tAccuracy: 90.65%\n",
      "523\tValidation loss: 1.349934\tBest loss: 1.349934\tAccuracy: 90.65%\n",
      "524\tValidation loss: 1.349897\tBest loss: 1.349897\tAccuracy: 90.65%\n",
      "525\tValidation loss: 1.349884\tBest loss: 1.349884\tAccuracy: 90.65%\n",
      "526\tValidation loss: 1.349849\tBest loss: 1.349849\tAccuracy: 90.65%\n",
      "527\tValidation loss: 1.349837\tBest loss: 1.349837\tAccuracy: 90.65%\n",
      "528\tValidation loss: 1.349818\tBest loss: 1.349818\tAccuracy: 90.65%\n",
      "529\tValidation loss: 1.349790\tBest loss: 1.349790\tAccuracy: 90.65%\n",
      "530\tValidation loss: 1.349776\tBest loss: 1.349776\tAccuracy: 90.65%\n",
      "531\tValidation loss: 1.349759\tBest loss: 1.349759\tAccuracy: 90.65%\n",
      "532\tValidation loss: 1.349737\tBest loss: 1.349737\tAccuracy: 90.65%\n",
      "533\tValidation loss: 1.349736\tBest loss: 1.349736\tAccuracy: 90.65%\n",
      "534\tValidation loss: 1.349720\tBest loss: 1.349720\tAccuracy: 90.65%\n",
      "535\tValidation loss: 1.349683\tBest loss: 1.349683\tAccuracy: 90.65%\n",
      "536\tValidation loss: 1.349666\tBest loss: 1.349666\tAccuracy: 90.65%\n",
      "537\tValidation loss: 1.349634\tBest loss: 1.349634\tAccuracy: 90.65%\n",
      "538\tValidation loss: 1.349626\tBest loss: 1.349626\tAccuracy: 90.65%\n",
      "539\tValidation loss: 1.349600\tBest loss: 1.349600\tAccuracy: 90.65%\n",
      "540\tValidation loss: 1.349577\tBest loss: 1.349577\tAccuracy: 90.65%\n",
      "541\tValidation loss: 1.349556\tBest loss: 1.349556\tAccuracy: 90.65%\n",
      "542\tValidation loss: 1.349526\tBest loss: 1.349526\tAccuracy: 90.65%\n",
      "543\tValidation loss: 1.349504\tBest loss: 1.349504\tAccuracy: 90.65%\n",
      "544\tValidation loss: 1.349490\tBest loss: 1.349490\tAccuracy: 90.65%\n",
      "545\tValidation loss: 1.349465\tBest loss: 1.349465\tAccuracy: 90.65%\n",
      "546\tValidation loss: 1.349447\tBest loss: 1.349447\tAccuracy: 90.65%\n",
      "547\tValidation loss: 1.349418\tBest loss: 1.349418\tAccuracy: 90.65%\n",
      "548\tValidation loss: 1.349417\tBest loss: 1.349417\tAccuracy: 90.65%\n",
      "549\tValidation loss: 1.349390\tBest loss: 1.349390\tAccuracy: 90.65%\n",
      "550\tValidation loss: 1.349370\tBest loss: 1.349370\tAccuracy: 90.65%\n",
      "551\tValidation loss: 1.349335\tBest loss: 1.349335\tAccuracy: 90.65%\n",
      "552\tValidation loss: 1.349313\tBest loss: 1.349313\tAccuracy: 90.65%\n",
      "553\tValidation loss: 1.349292\tBest loss: 1.349292\tAccuracy: 90.65%\n",
      "554\tValidation loss: 1.349267\tBest loss: 1.349267\tAccuracy: 90.65%\n",
      "555\tValidation loss: 1.349266\tBest loss: 1.349266\tAccuracy: 90.65%\n",
      "556\tValidation loss: 1.349230\tBest loss: 1.349230\tAccuracy: 90.65%\n",
      "557\tValidation loss: 1.349222\tBest loss: 1.349222\tAccuracy: 90.65%\n",
      "558\tValidation loss: 1.349188\tBest loss: 1.349188\tAccuracy: 90.65%\n",
      "559\tValidation loss: 1.349177\tBest loss: 1.349177\tAccuracy: 90.65%\n",
      "560\tValidation loss: 1.349156\tBest loss: 1.349156\tAccuracy: 90.65%\n",
      "561\tValidation loss: 1.349138\tBest loss: 1.349138\tAccuracy: 90.65%\n",
      "562\tValidation loss: 1.349129\tBest loss: 1.349129\tAccuracy: 90.65%\n",
      "563\tValidation loss: 1.349098\tBest loss: 1.349098\tAccuracy: 90.65%\n",
      "564\tValidation loss: 1.349083\tBest loss: 1.349083\tAccuracy: 90.65%\n",
      "565\tValidation loss: 1.349063\tBest loss: 1.349063\tAccuracy: 91.37%\n",
      "566\tValidation loss: 1.349050\tBest loss: 1.349050\tAccuracy: 91.37%\n",
      "567\tValidation loss: 1.349024\tBest loss: 1.349024\tAccuracy: 91.37%\n",
      "568\tValidation loss: 1.349003\tBest loss: 1.349003\tAccuracy: 91.37%\n",
      "569\tValidation loss: 1.348984\tBest loss: 1.348984\tAccuracy: 91.37%\n",
      "570\tValidation loss: 1.348961\tBest loss: 1.348961\tAccuracy: 91.37%\n",
      "571\tValidation loss: 1.348924\tBest loss: 1.348924\tAccuracy: 91.37%\n",
      "572\tValidation loss: 1.348914\tBest loss: 1.348914\tAccuracy: 91.37%\n",
      "573\tValidation loss: 1.348898\tBest loss: 1.348898\tAccuracy: 91.37%\n",
      "574\tValidation loss: 1.348880\tBest loss: 1.348880\tAccuracy: 91.37%\n",
      "575\tValidation loss: 1.348855\tBest loss: 1.348855\tAccuracy: 91.37%\n",
      "576\tValidation loss: 1.348848\tBest loss: 1.348848\tAccuracy: 91.37%\n",
      "577\tValidation loss: 1.348829\tBest loss: 1.348829\tAccuracy: 91.37%\n",
      "578\tValidation loss: 1.348817\tBest loss: 1.348817\tAccuracy: 91.37%\n",
      "579\tValidation loss: 1.348792\tBest loss: 1.348792\tAccuracy: 91.37%\n",
      "580\tValidation loss: 1.348771\tBest loss: 1.348771\tAccuracy: 91.37%\n",
      "581\tValidation loss: 1.348758\tBest loss: 1.348758\tAccuracy: 91.37%\n",
      "582\tValidation loss: 1.348754\tBest loss: 1.348754\tAccuracy: 91.37%\n",
      "583\tValidation loss: 1.348737\tBest loss: 1.348737\tAccuracy: 91.37%\n",
      "584\tValidation loss: 1.348713\tBest loss: 1.348713\tAccuracy: 91.37%\n",
      "585\tValidation loss: 1.348700\tBest loss: 1.348700\tAccuracy: 91.37%\n",
      "586\tValidation loss: 1.348699\tBest loss: 1.348699\tAccuracy: 91.37%\n",
      "587\tValidation loss: 1.348679\tBest loss: 1.348679\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\tValidation loss: 1.348656\tBest loss: 1.348656\tAccuracy: 91.37%\n",
      "589\tValidation loss: 1.348639\tBest loss: 1.348639\tAccuracy: 91.37%\n",
      "590\tValidation loss: 1.348625\tBest loss: 1.348625\tAccuracy: 91.37%\n",
      "591\tValidation loss: 1.348601\tBest loss: 1.348601\tAccuracy: 91.37%\n",
      "592\tValidation loss: 1.348575\tBest loss: 1.348575\tAccuracy: 91.37%\n",
      "593\tValidation loss: 1.348547\tBest loss: 1.348547\tAccuracy: 91.37%\n",
      "594\tValidation loss: 1.348543\tBest loss: 1.348543\tAccuracy: 91.37%\n",
      "595\tValidation loss: 1.348532\tBest loss: 1.348532\tAccuracy: 91.37%\n",
      "596\tValidation loss: 1.348514\tBest loss: 1.348514\tAccuracy: 91.37%\n",
      "597\tValidation loss: 1.348505\tBest loss: 1.348505\tAccuracy: 91.37%\n",
      "598\tValidation loss: 1.348488\tBest loss: 1.348488\tAccuracy: 91.37%\n",
      "599\tValidation loss: 1.348472\tBest loss: 1.348472\tAccuracy: 91.37%\n",
      "600\tValidation loss: 1.348453\tBest loss: 1.348453\tAccuracy: 91.37%\n",
      "601\tValidation loss: 1.348429\tBest loss: 1.348429\tAccuracy: 91.37%\n",
      "602\tValidation loss: 1.348401\tBest loss: 1.348401\tAccuracy: 91.37%\n",
      "603\tValidation loss: 1.348387\tBest loss: 1.348387\tAccuracy: 91.37%\n",
      "604\tValidation loss: 1.348366\tBest loss: 1.348366\tAccuracy: 91.37%\n",
      "605\tValidation loss: 1.348343\tBest loss: 1.348343\tAccuracy: 91.37%\n",
      "606\tValidation loss: 1.348331\tBest loss: 1.348331\tAccuracy: 91.37%\n",
      "607\tValidation loss: 1.348319\tBest loss: 1.348319\tAccuracy: 91.37%\n",
      "608\tValidation loss: 1.348312\tBest loss: 1.348312\tAccuracy: 91.37%\n",
      "609\tValidation loss: 1.348292\tBest loss: 1.348292\tAccuracy: 91.37%\n",
      "610\tValidation loss: 1.348258\tBest loss: 1.348258\tAccuracy: 91.37%\n",
      "611\tValidation loss: 1.348247\tBest loss: 1.348247\tAccuracy: 91.37%\n",
      "612\tValidation loss: 1.348220\tBest loss: 1.348220\tAccuracy: 91.37%\n",
      "613\tValidation loss: 1.348207\tBest loss: 1.348207\tAccuracy: 91.37%\n",
      "614\tValidation loss: 1.348188\tBest loss: 1.348188\tAccuracy: 91.37%\n",
      "615\tValidation loss: 1.348182\tBest loss: 1.348182\tAccuracy: 91.37%\n",
      "616\tValidation loss: 1.348151\tBest loss: 1.348151\tAccuracy: 91.37%\n",
      "617\tValidation loss: 1.348143\tBest loss: 1.348143\tAccuracy: 91.37%\n",
      "618\tValidation loss: 1.348124\tBest loss: 1.348124\tAccuracy: 91.37%\n",
      "619\tValidation loss: 1.348099\tBest loss: 1.348099\tAccuracy: 91.37%\n",
      "620\tValidation loss: 1.348078\tBest loss: 1.348078\tAccuracy: 91.37%\n",
      "621\tValidation loss: 1.348067\tBest loss: 1.348067\tAccuracy: 91.37%\n",
      "622\tValidation loss: 1.348037\tBest loss: 1.348037\tAccuracy: 91.37%\n",
      "623\tValidation loss: 1.348020\tBest loss: 1.348020\tAccuracy: 91.37%\n",
      "624\tValidation loss: 1.347999\tBest loss: 1.347999\tAccuracy: 91.37%\n",
      "625\tValidation loss: 1.347975\tBest loss: 1.347975\tAccuracy: 91.37%\n",
      "626\tValidation loss: 1.347961\tBest loss: 1.347961\tAccuracy: 91.37%\n",
      "627\tValidation loss: 1.347941\tBest loss: 1.347941\tAccuracy: 91.37%\n",
      "628\tValidation loss: 1.347917\tBest loss: 1.347917\tAccuracy: 91.37%\n",
      "629\tValidation loss: 1.347911\tBest loss: 1.347911\tAccuracy: 91.37%\n",
      "630\tValidation loss: 1.347897\tBest loss: 1.347897\tAccuracy: 91.37%\n",
      "631\tValidation loss: 1.347870\tBest loss: 1.347870\tAccuracy: 91.37%\n",
      "632\tValidation loss: 1.347857\tBest loss: 1.347857\tAccuracy: 91.37%\n",
      "633\tValidation loss: 1.347846\tBest loss: 1.347846\tAccuracy: 91.37%\n",
      "634\tValidation loss: 1.347822\tBest loss: 1.347822\tAccuracy: 91.37%\n",
      "635\tValidation loss: 1.347803\tBest loss: 1.347803\tAccuracy: 91.37%\n",
      "636\tValidation loss: 1.347794\tBest loss: 1.347794\tAccuracy: 91.37%\n",
      "637\tValidation loss: 1.347780\tBest loss: 1.347780\tAccuracy: 91.37%\n",
      "638\tValidation loss: 1.347765\tBest loss: 1.347765\tAccuracy: 91.37%\n",
      "639\tValidation loss: 1.347738\tBest loss: 1.347738\tAccuracy: 91.37%\n",
      "640\tValidation loss: 1.347717\tBest loss: 1.347717\tAccuracy: 91.37%\n",
      "641\tValidation loss: 1.347703\tBest loss: 1.347703\tAccuracy: 91.37%\n",
      "642\tValidation loss: 1.347692\tBest loss: 1.347692\tAccuracy: 91.37%\n",
      "643\tValidation loss: 1.347675\tBest loss: 1.347675\tAccuracy: 91.37%\n",
      "644\tValidation loss: 1.347672\tBest loss: 1.347672\tAccuracy: 91.37%\n",
      "645\tValidation loss: 1.347660\tBest loss: 1.347660\tAccuracy: 91.37%\n",
      "646\tValidation loss: 1.347645\tBest loss: 1.347645\tAccuracy: 91.37%\n",
      "647\tValidation loss: 1.347619\tBest loss: 1.347619\tAccuracy: 91.37%\n",
      "648\tValidation loss: 1.347602\tBest loss: 1.347602\tAccuracy: 91.37%\n",
      "649\tValidation loss: 1.347595\tBest loss: 1.347595\tAccuracy: 91.37%\n",
      "650\tValidation loss: 1.347577\tBest loss: 1.347577\tAccuracy: 91.37%\n",
      "651\tValidation loss: 1.347559\tBest loss: 1.347559\tAccuracy: 91.37%\n",
      "652\tValidation loss: 1.347544\tBest loss: 1.347544\tAccuracy: 91.37%\n",
      "653\tValidation loss: 1.347515\tBest loss: 1.347515\tAccuracy: 91.37%\n",
      "654\tValidation loss: 1.347493\tBest loss: 1.347493\tAccuracy: 91.37%\n",
      "655\tValidation loss: 1.347486\tBest loss: 1.347486\tAccuracy: 91.37%\n",
      "656\tValidation loss: 1.347470\tBest loss: 1.347470\tAccuracy: 91.37%\n",
      "657\tValidation loss: 1.347451\tBest loss: 1.347451\tAccuracy: 91.37%\n",
      "658\tValidation loss: 1.347435\tBest loss: 1.347435\tAccuracy: 91.37%\n",
      "659\tValidation loss: 1.347414\tBest loss: 1.347414\tAccuracy: 91.37%\n",
      "660\tValidation loss: 1.347398\tBest loss: 1.347398\tAccuracy: 91.37%\n",
      "661\tValidation loss: 1.347383\tBest loss: 1.347383\tAccuracy: 91.37%\n",
      "662\tValidation loss: 1.347368\tBest loss: 1.347368\tAccuracy: 91.37%\n",
      "663\tValidation loss: 1.347363\tBest loss: 1.347363\tAccuracy: 91.37%\n",
      "664\tValidation loss: 1.347356\tBest loss: 1.347356\tAccuracy: 91.37%\n",
      "665\tValidation loss: 1.347344\tBest loss: 1.347344\tAccuracy: 91.37%\n",
      "666\tValidation loss: 1.347320\tBest loss: 1.347320\tAccuracy: 91.37%\n",
      "667\tValidation loss: 1.347314\tBest loss: 1.347314\tAccuracy: 91.37%\n",
      "668\tValidation loss: 1.347295\tBest loss: 1.347295\tAccuracy: 91.37%\n",
      "669\tValidation loss: 1.347273\tBest loss: 1.347273\tAccuracy: 91.37%\n",
      "670\tValidation loss: 1.347251\tBest loss: 1.347251\tAccuracy: 91.37%\n",
      "671\tValidation loss: 1.347229\tBest loss: 1.347229\tAccuracy: 91.37%\n",
      "672\tValidation loss: 1.347215\tBest loss: 1.347215\tAccuracy: 91.37%\n",
      "673\tValidation loss: 1.347198\tBest loss: 1.347198\tAccuracy: 91.37%\n",
      "674\tValidation loss: 1.347183\tBest loss: 1.347183\tAccuracy: 91.37%\n",
      "675\tValidation loss: 1.347161\tBest loss: 1.347161\tAccuracy: 91.37%\n",
      "676\tValidation loss: 1.347151\tBest loss: 1.347151\tAccuracy: 91.37%\n",
      "677\tValidation loss: 1.347131\tBest loss: 1.347131\tAccuracy: 91.37%\n",
      "678\tValidation loss: 1.347112\tBest loss: 1.347112\tAccuracy: 91.37%\n",
      "679\tValidation loss: 1.347099\tBest loss: 1.347099\tAccuracy: 91.37%\n",
      "680\tValidation loss: 1.347090\tBest loss: 1.347090\tAccuracy: 91.37%\n",
      "681\tValidation loss: 1.347070\tBest loss: 1.347070\tAccuracy: 91.37%\n",
      "682\tValidation loss: 1.347053\tBest loss: 1.347053\tAccuracy: 91.37%\n",
      "683\tValidation loss: 1.347046\tBest loss: 1.347046\tAccuracy: 91.37%\n",
      "684\tValidation loss: 1.347037\tBest loss: 1.347037\tAccuracy: 91.37%\n",
      "685\tValidation loss: 1.347023\tBest loss: 1.347023\tAccuracy: 91.37%\n",
      "686\tValidation loss: 1.346999\tBest loss: 1.346999\tAccuracy: 91.37%\n",
      "687\tValidation loss: 1.346976\tBest loss: 1.346976\tAccuracy: 91.37%\n",
      "688\tValidation loss: 1.346960\tBest loss: 1.346960\tAccuracy: 91.37%\n",
      "689\tValidation loss: 1.346945\tBest loss: 1.346945\tAccuracy: 91.37%\n",
      "690\tValidation loss: 1.346928\tBest loss: 1.346928\tAccuracy: 91.37%\n",
      "691\tValidation loss: 1.346906\tBest loss: 1.346906\tAccuracy: 91.37%\n",
      "692\tValidation loss: 1.346898\tBest loss: 1.346898\tAccuracy: 91.37%\n",
      "693\tValidation loss: 1.346881\tBest loss: 1.346881\tAccuracy: 91.37%\n",
      "694\tValidation loss: 1.346867\tBest loss: 1.346867\tAccuracy: 91.37%\n",
      "695\tValidation loss: 1.346858\tBest loss: 1.346858\tAccuracy: 91.37%\n",
      "696\tValidation loss: 1.346853\tBest loss: 1.346853\tAccuracy: 91.37%\n",
      "697\tValidation loss: 1.346828\tBest loss: 1.346828\tAccuracy: 91.37%\n",
      "698\tValidation loss: 1.346818\tBest loss: 1.346818\tAccuracy: 91.37%\n",
      "699\tValidation loss: 1.346802\tBest loss: 1.346802\tAccuracy: 91.37%\n",
      "700\tValidation loss: 1.346792\tBest loss: 1.346792\tAccuracy: 91.37%\n",
      "701\tValidation loss: 1.346787\tBest loss: 1.346787\tAccuracy: 91.37%\n",
      "702\tValidation loss: 1.346771\tBest loss: 1.346771\tAccuracy: 91.37%\n",
      "703\tValidation loss: 1.346754\tBest loss: 1.346754\tAccuracy: 91.37%\n",
      "704\tValidation loss: 1.346748\tBest loss: 1.346748\tAccuracy: 91.37%\n",
      "705\tValidation loss: 1.346723\tBest loss: 1.346723\tAccuracy: 91.37%\n",
      "706\tValidation loss: 1.346698\tBest loss: 1.346698\tAccuracy: 91.37%\n",
      "707\tValidation loss: 1.346688\tBest loss: 1.346688\tAccuracy: 91.37%\n",
      "708\tValidation loss: 1.346678\tBest loss: 1.346678\tAccuracy: 91.37%\n",
      "709\tValidation loss: 1.346666\tBest loss: 1.346666\tAccuracy: 91.37%\n",
      "710\tValidation loss: 1.346654\tBest loss: 1.346654\tAccuracy: 91.37%\n",
      "711\tValidation loss: 1.346640\tBest loss: 1.346640\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\tValidation loss: 1.346625\tBest loss: 1.346625\tAccuracy: 91.37%\n",
      "713\tValidation loss: 1.346614\tBest loss: 1.346614\tAccuracy: 91.37%\n",
      "714\tValidation loss: 1.346595\tBest loss: 1.346595\tAccuracy: 91.37%\n",
      "715\tValidation loss: 1.346596\tBest loss: 1.346595\tAccuracy: 91.37%\n",
      "716\tValidation loss: 1.346583\tBest loss: 1.346583\tAccuracy: 91.37%\n",
      "717\tValidation loss: 1.346566\tBest loss: 1.346566\tAccuracy: 91.37%\n",
      "718\tValidation loss: 1.346543\tBest loss: 1.346543\tAccuracy: 91.37%\n",
      "719\tValidation loss: 1.346522\tBest loss: 1.346522\tAccuracy: 91.37%\n",
      "720\tValidation loss: 1.346505\tBest loss: 1.346505\tAccuracy: 91.37%\n",
      "721\tValidation loss: 1.346495\tBest loss: 1.346495\tAccuracy: 91.37%\n",
      "722\tValidation loss: 1.346483\tBest loss: 1.346483\tAccuracy: 91.37%\n",
      "723\tValidation loss: 1.346472\tBest loss: 1.346472\tAccuracy: 91.37%\n",
      "724\tValidation loss: 1.346458\tBest loss: 1.346458\tAccuracy: 91.37%\n",
      "725\tValidation loss: 1.346436\tBest loss: 1.346436\tAccuracy: 91.37%\n",
      "726\tValidation loss: 1.346418\tBest loss: 1.346418\tAccuracy: 91.37%\n",
      "727\tValidation loss: 1.346409\tBest loss: 1.346409\tAccuracy: 91.37%\n",
      "728\tValidation loss: 1.346399\tBest loss: 1.346399\tAccuracy: 91.37%\n",
      "729\tValidation loss: 1.346389\tBest loss: 1.346389\tAccuracy: 91.37%\n",
      "730\tValidation loss: 1.346372\tBest loss: 1.346372\tAccuracy: 91.37%\n",
      "731\tValidation loss: 1.346354\tBest loss: 1.346354\tAccuracy: 91.37%\n",
      "732\tValidation loss: 1.346345\tBest loss: 1.346345\tAccuracy: 91.37%\n",
      "733\tValidation loss: 1.346327\tBest loss: 1.346327\tAccuracy: 91.37%\n",
      "734\tValidation loss: 1.346321\tBest loss: 1.346321\tAccuracy: 91.37%\n",
      "735\tValidation loss: 1.346303\tBest loss: 1.346303\tAccuracy: 91.37%\n",
      "736\tValidation loss: 1.346289\tBest loss: 1.346289\tAccuracy: 91.37%\n",
      "737\tValidation loss: 1.346269\tBest loss: 1.346269\tAccuracy: 91.37%\n",
      "738\tValidation loss: 1.346247\tBest loss: 1.346247\tAccuracy: 91.37%\n",
      "739\tValidation loss: 1.346221\tBest loss: 1.346221\tAccuracy: 91.37%\n",
      "740\tValidation loss: 1.346198\tBest loss: 1.346198\tAccuracy: 91.37%\n",
      "741\tValidation loss: 1.346192\tBest loss: 1.346192\tAccuracy: 91.37%\n",
      "742\tValidation loss: 1.346180\tBest loss: 1.346180\tAccuracy: 91.37%\n",
      "743\tValidation loss: 1.346159\tBest loss: 1.346159\tAccuracy: 91.37%\n",
      "744\tValidation loss: 1.346144\tBest loss: 1.346144\tAccuracy: 91.37%\n",
      "745\tValidation loss: 1.346129\tBest loss: 1.346129\tAccuracy: 91.37%\n",
      "746\tValidation loss: 1.346127\tBest loss: 1.346127\tAccuracy: 91.37%\n",
      "747\tValidation loss: 1.346106\tBest loss: 1.346106\tAccuracy: 91.37%\n",
      "748\tValidation loss: 1.346096\tBest loss: 1.346096\tAccuracy: 91.37%\n",
      "749\tValidation loss: 1.346077\tBest loss: 1.346077\tAccuracy: 91.37%\n",
      "750\tValidation loss: 1.346069\tBest loss: 1.346069\tAccuracy: 91.37%\n",
      "751\tValidation loss: 1.346048\tBest loss: 1.346048\tAccuracy: 91.37%\n",
      "752\tValidation loss: 1.346034\tBest loss: 1.346034\tAccuracy: 91.37%\n",
      "753\tValidation loss: 1.346025\tBest loss: 1.346025\tAccuracy: 91.37%\n",
      "754\tValidation loss: 1.346020\tBest loss: 1.346020\tAccuracy: 91.37%\n",
      "755\tValidation loss: 1.346002\tBest loss: 1.346002\tAccuracy: 91.37%\n",
      "756\tValidation loss: 1.345985\tBest loss: 1.345985\tAccuracy: 91.37%\n",
      "757\tValidation loss: 1.345968\tBest loss: 1.345968\tAccuracy: 91.37%\n",
      "758\tValidation loss: 1.345963\tBest loss: 1.345963\tAccuracy: 91.37%\n",
      "759\tValidation loss: 1.345948\tBest loss: 1.345948\tAccuracy: 91.37%\n",
      "760\tValidation loss: 1.345949\tBest loss: 1.345948\tAccuracy: 91.37%\n",
      "761\tValidation loss: 1.345931\tBest loss: 1.345931\tAccuracy: 91.37%\n",
      "762\tValidation loss: 1.345911\tBest loss: 1.345911\tAccuracy: 91.37%\n",
      "763\tValidation loss: 1.345908\tBest loss: 1.345908\tAccuracy: 91.37%\n",
      "764\tValidation loss: 1.345889\tBest loss: 1.345889\tAccuracy: 91.37%\n",
      "765\tValidation loss: 1.345879\tBest loss: 1.345879\tAccuracy: 91.37%\n",
      "766\tValidation loss: 1.345858\tBest loss: 1.345858\tAccuracy: 91.37%\n",
      "767\tValidation loss: 1.345838\tBest loss: 1.345838\tAccuracy: 91.37%\n",
      "768\tValidation loss: 1.345818\tBest loss: 1.345818\tAccuracy: 91.37%\n",
      "769\tValidation loss: 1.345799\tBest loss: 1.345799\tAccuracy: 91.37%\n",
      "770\tValidation loss: 1.345786\tBest loss: 1.345786\tAccuracy: 91.37%\n",
      "771\tValidation loss: 1.345759\tBest loss: 1.345759\tAccuracy: 91.37%\n",
      "772\tValidation loss: 1.345748\tBest loss: 1.345748\tAccuracy: 91.37%\n",
      "773\tValidation loss: 1.345747\tBest loss: 1.345747\tAccuracy: 91.37%\n",
      "774\tValidation loss: 1.345735\tBest loss: 1.345735\tAccuracy: 91.37%\n",
      "775\tValidation loss: 1.345723\tBest loss: 1.345723\tAccuracy: 91.37%\n",
      "776\tValidation loss: 1.345722\tBest loss: 1.345722\tAccuracy: 91.37%\n",
      "777\tValidation loss: 1.345710\tBest loss: 1.345710\tAccuracy: 91.37%\n",
      "778\tValidation loss: 1.345696\tBest loss: 1.345696\tAccuracy: 91.37%\n",
      "779\tValidation loss: 1.345682\tBest loss: 1.345682\tAccuracy: 91.37%\n",
      "780\tValidation loss: 1.345677\tBest loss: 1.345677\tAccuracy: 91.37%\n",
      "781\tValidation loss: 1.345656\tBest loss: 1.345656\tAccuracy: 91.37%\n",
      "782\tValidation loss: 1.345641\tBest loss: 1.345641\tAccuracy: 91.37%\n",
      "783\tValidation loss: 1.345625\tBest loss: 1.345625\tAccuracy: 91.37%\n",
      "784\tValidation loss: 1.345620\tBest loss: 1.345620\tAccuracy: 91.37%\n",
      "785\tValidation loss: 1.345613\tBest loss: 1.345613\tAccuracy: 91.37%\n",
      "786\tValidation loss: 1.345610\tBest loss: 1.345610\tAccuracy: 91.37%\n",
      "787\tValidation loss: 1.345587\tBest loss: 1.345587\tAccuracy: 91.37%\n",
      "788\tValidation loss: 1.345578\tBest loss: 1.345578\tAccuracy: 91.37%\n",
      "789\tValidation loss: 1.345564\tBest loss: 1.345564\tAccuracy: 91.37%\n",
      "790\tValidation loss: 1.345556\tBest loss: 1.345556\tAccuracy: 91.37%\n",
      "791\tValidation loss: 1.345534\tBest loss: 1.345534\tAccuracy: 91.37%\n",
      "792\tValidation loss: 1.345504\tBest loss: 1.345504\tAccuracy: 91.37%\n",
      "793\tValidation loss: 1.345494\tBest loss: 1.345494\tAccuracy: 91.37%\n",
      "794\tValidation loss: 1.345485\tBest loss: 1.345485\tAccuracy: 91.37%\n",
      "795\tValidation loss: 1.345469\tBest loss: 1.345469\tAccuracy: 91.37%\n",
      "796\tValidation loss: 1.345450\tBest loss: 1.345450\tAccuracy: 91.37%\n",
      "797\tValidation loss: 1.345441\tBest loss: 1.345441\tAccuracy: 91.37%\n",
      "798\tValidation loss: 1.345424\tBest loss: 1.345424\tAccuracy: 91.37%\n",
      "799\tValidation loss: 1.345417\tBest loss: 1.345417\tAccuracy: 91.37%\n",
      "800\tValidation loss: 1.345417\tBest loss: 1.345417\tAccuracy: 91.37%\n",
      "801\tValidation loss: 1.345409\tBest loss: 1.345409\tAccuracy: 91.37%\n",
      "802\tValidation loss: 1.345410\tBest loss: 1.345409\tAccuracy: 91.37%\n",
      "803\tValidation loss: 1.345397\tBest loss: 1.345397\tAccuracy: 91.37%\n",
      "804\tValidation loss: 1.345376\tBest loss: 1.345376\tAccuracy: 91.37%\n",
      "805\tValidation loss: 1.345374\tBest loss: 1.345374\tAccuracy: 91.37%\n",
      "806\tValidation loss: 1.345353\tBest loss: 1.345353\tAccuracy: 91.37%\n",
      "807\tValidation loss: 1.345341\tBest loss: 1.345341\tAccuracy: 91.37%\n",
      "808\tValidation loss: 1.345324\tBest loss: 1.345324\tAccuracy: 91.37%\n",
      "809\tValidation loss: 1.345324\tBest loss: 1.345324\tAccuracy: 91.37%\n",
      "810\tValidation loss: 1.345301\tBest loss: 1.345301\tAccuracy: 91.37%\n",
      "811\tValidation loss: 1.345282\tBest loss: 1.345282\tAccuracy: 91.37%\n",
      "812\tValidation loss: 1.345281\tBest loss: 1.345281\tAccuracy: 91.37%\n",
      "813\tValidation loss: 1.345275\tBest loss: 1.345275\tAccuracy: 91.37%\n",
      "814\tValidation loss: 1.345264\tBest loss: 1.345264\tAccuracy: 91.37%\n",
      "815\tValidation loss: 1.345255\tBest loss: 1.345255\tAccuracy: 91.37%\n",
      "816\tValidation loss: 1.345234\tBest loss: 1.345234\tAccuracy: 91.37%\n",
      "817\tValidation loss: 1.345220\tBest loss: 1.345220\tAccuracy: 91.37%\n",
      "818\tValidation loss: 1.345219\tBest loss: 1.345219\tAccuracy: 91.37%\n",
      "819\tValidation loss: 1.345205\tBest loss: 1.345205\tAccuracy: 91.37%\n",
      "820\tValidation loss: 1.345190\tBest loss: 1.345190\tAccuracy: 91.37%\n",
      "821\tValidation loss: 1.345173\tBest loss: 1.345173\tAccuracy: 91.37%\n",
      "822\tValidation loss: 1.345171\tBest loss: 1.345171\tAccuracy: 91.37%\n",
      "823\tValidation loss: 1.345154\tBest loss: 1.345154\tAccuracy: 91.37%\n",
      "824\tValidation loss: 1.345158\tBest loss: 1.345154\tAccuracy: 91.37%\n",
      "825\tValidation loss: 1.345146\tBest loss: 1.345146\tAccuracy: 91.37%\n",
      "826\tValidation loss: 1.345135\tBest loss: 1.345135\tAccuracy: 91.37%\n",
      "827\tValidation loss: 1.345116\tBest loss: 1.345116\tAccuracy: 91.37%\n",
      "828\tValidation loss: 1.345096\tBest loss: 1.345096\tAccuracy: 91.37%\n",
      "829\tValidation loss: 1.345085\tBest loss: 1.345085\tAccuracy: 91.37%\n",
      "830\tValidation loss: 1.345073\tBest loss: 1.345073\tAccuracy: 91.37%\n",
      "831\tValidation loss: 1.345044\tBest loss: 1.345044\tAccuracy: 91.37%\n",
      "832\tValidation loss: 1.345043\tBest loss: 1.345043\tAccuracy: 91.37%\n",
      "833\tValidation loss: 1.345022\tBest loss: 1.345022\tAccuracy: 91.37%\n",
      "834\tValidation loss: 1.345018\tBest loss: 1.345018\tAccuracy: 91.37%\n",
      "835\tValidation loss: 1.345005\tBest loss: 1.345005\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\tValidation loss: 1.344990\tBest loss: 1.344990\tAccuracy: 91.37%\n",
      "837\tValidation loss: 1.344974\tBest loss: 1.344974\tAccuracy: 91.37%\n",
      "838\tValidation loss: 1.344960\tBest loss: 1.344960\tAccuracy: 91.37%\n",
      "839\tValidation loss: 1.344947\tBest loss: 1.344947\tAccuracy: 91.37%\n",
      "840\tValidation loss: 1.344945\tBest loss: 1.344945\tAccuracy: 91.37%\n",
      "841\tValidation loss: 1.344926\tBest loss: 1.344926\tAccuracy: 91.37%\n",
      "842\tValidation loss: 1.344916\tBest loss: 1.344916\tAccuracy: 91.37%\n",
      "843\tValidation loss: 1.344907\tBest loss: 1.344907\tAccuracy: 91.37%\n",
      "844\tValidation loss: 1.344904\tBest loss: 1.344904\tAccuracy: 91.37%\n",
      "845\tValidation loss: 1.344891\tBest loss: 1.344891\tAccuracy: 91.37%\n",
      "846\tValidation loss: 1.344885\tBest loss: 1.344885\tAccuracy: 91.37%\n",
      "847\tValidation loss: 1.344874\tBest loss: 1.344874\tAccuracy: 91.37%\n",
      "848\tValidation loss: 1.344863\tBest loss: 1.344863\tAccuracy: 91.37%\n",
      "849\tValidation loss: 1.344862\tBest loss: 1.344862\tAccuracy: 91.37%\n",
      "850\tValidation loss: 1.344841\tBest loss: 1.344841\tAccuracy: 91.37%\n",
      "851\tValidation loss: 1.344832\tBest loss: 1.344832\tAccuracy: 91.37%\n",
      "852\tValidation loss: 1.344820\tBest loss: 1.344820\tAccuracy: 91.37%\n",
      "853\tValidation loss: 1.344816\tBest loss: 1.344816\tAccuracy: 91.37%\n",
      "854\tValidation loss: 1.344810\tBest loss: 1.344810\tAccuracy: 91.37%\n",
      "855\tValidation loss: 1.344807\tBest loss: 1.344807\tAccuracy: 91.37%\n",
      "856\tValidation loss: 1.344787\tBest loss: 1.344787\tAccuracy: 91.37%\n",
      "857\tValidation loss: 1.344774\tBest loss: 1.344774\tAccuracy: 91.37%\n",
      "858\tValidation loss: 1.344759\tBest loss: 1.344759\tAccuracy: 91.37%\n",
      "859\tValidation loss: 1.344759\tBest loss: 1.344759\tAccuracy: 91.37%\n",
      "860\tValidation loss: 1.344747\tBest loss: 1.344747\tAccuracy: 91.37%\n",
      "861\tValidation loss: 1.344730\tBest loss: 1.344730\tAccuracy: 91.37%\n",
      "862\tValidation loss: 1.344724\tBest loss: 1.344724\tAccuracy: 91.37%\n",
      "863\tValidation loss: 1.344720\tBest loss: 1.344720\tAccuracy: 91.37%\n",
      "864\tValidation loss: 1.344693\tBest loss: 1.344693\tAccuracy: 91.37%\n",
      "865\tValidation loss: 1.344678\tBest loss: 1.344678\tAccuracy: 91.37%\n",
      "866\tValidation loss: 1.344664\tBest loss: 1.344664\tAccuracy: 91.37%\n",
      "867\tValidation loss: 1.344661\tBest loss: 1.344661\tAccuracy: 91.37%\n",
      "868\tValidation loss: 1.344651\tBest loss: 1.344651\tAccuracy: 91.37%\n",
      "869\tValidation loss: 1.344638\tBest loss: 1.344638\tAccuracy: 91.37%\n",
      "870\tValidation loss: 1.344624\tBest loss: 1.344624\tAccuracy: 91.37%\n",
      "871\tValidation loss: 1.344614\tBest loss: 1.344614\tAccuracy: 91.37%\n",
      "872\tValidation loss: 1.344597\tBest loss: 1.344597\tAccuracy: 91.37%\n",
      "873\tValidation loss: 1.344589\tBest loss: 1.344589\tAccuracy: 91.37%\n",
      "874\tValidation loss: 1.344574\tBest loss: 1.344574\tAccuracy: 91.37%\n",
      "875\tValidation loss: 1.344566\tBest loss: 1.344566\tAccuracy: 91.37%\n",
      "876\tValidation loss: 1.344554\tBest loss: 1.344554\tAccuracy: 91.37%\n",
      "877\tValidation loss: 1.344533\tBest loss: 1.344533\tAccuracy: 91.37%\n",
      "878\tValidation loss: 1.344514\tBest loss: 1.344514\tAccuracy: 91.37%\n",
      "879\tValidation loss: 1.344508\tBest loss: 1.344508\tAccuracy: 91.37%\n",
      "880\tValidation loss: 1.344494\tBest loss: 1.344494\tAccuracy: 91.37%\n",
      "881\tValidation loss: 1.344480\tBest loss: 1.344480\tAccuracy: 91.37%\n",
      "882\tValidation loss: 1.344476\tBest loss: 1.344476\tAccuracy: 91.37%\n",
      "883\tValidation loss: 1.344472\tBest loss: 1.344472\tAccuracy: 91.37%\n",
      "884\tValidation loss: 1.344461\tBest loss: 1.344461\tAccuracy: 91.37%\n",
      "885\tValidation loss: 1.344438\tBest loss: 1.344438\tAccuracy: 91.37%\n",
      "886\tValidation loss: 1.344418\tBest loss: 1.344418\tAccuracy: 91.37%\n",
      "887\tValidation loss: 1.344407\tBest loss: 1.344407\tAccuracy: 91.37%\n",
      "888\tValidation loss: 1.344396\tBest loss: 1.344396\tAccuracy: 91.37%\n",
      "889\tValidation loss: 1.344391\tBest loss: 1.344391\tAccuracy: 91.37%\n",
      "890\tValidation loss: 1.344381\tBest loss: 1.344381\tAccuracy: 91.37%\n",
      "891\tValidation loss: 1.344375\tBest loss: 1.344375\tAccuracy: 91.37%\n",
      "892\tValidation loss: 1.344351\tBest loss: 1.344351\tAccuracy: 91.37%\n",
      "893\tValidation loss: 1.344346\tBest loss: 1.344346\tAccuracy: 91.37%\n",
      "894\tValidation loss: 1.344339\tBest loss: 1.344339\tAccuracy: 91.37%\n",
      "895\tValidation loss: 1.344316\tBest loss: 1.344316\tAccuracy: 91.37%\n",
      "896\tValidation loss: 1.344298\tBest loss: 1.344298\tAccuracy: 91.37%\n",
      "897\tValidation loss: 1.344288\tBest loss: 1.344288\tAccuracy: 91.37%\n",
      "898\tValidation loss: 1.344281\tBest loss: 1.344281\tAccuracy: 91.37%\n",
      "899\tValidation loss: 1.344278\tBest loss: 1.344278\tAccuracy: 91.37%\n",
      "900\tValidation loss: 1.344269\tBest loss: 1.344269\tAccuracy: 91.37%\n",
      "901\tValidation loss: 1.344272\tBest loss: 1.344269\tAccuracy: 91.37%\n",
      "902\tValidation loss: 1.344259\tBest loss: 1.344259\tAccuracy: 91.37%\n",
      "903\tValidation loss: 1.344234\tBest loss: 1.344234\tAccuracy: 91.37%\n",
      "904\tValidation loss: 1.344230\tBest loss: 1.344230\tAccuracy: 91.37%\n",
      "905\tValidation loss: 1.344220\tBest loss: 1.344220\tAccuracy: 91.37%\n",
      "906\tValidation loss: 1.344202\tBest loss: 1.344202\tAccuracy: 91.37%\n",
      "907\tValidation loss: 1.344192\tBest loss: 1.344192\tAccuracy: 91.37%\n",
      "908\tValidation loss: 1.344187\tBest loss: 1.344187\tAccuracy: 91.37%\n",
      "909\tValidation loss: 1.344177\tBest loss: 1.344177\tAccuracy: 91.37%\n",
      "910\tValidation loss: 1.344155\tBest loss: 1.344155\tAccuracy: 91.37%\n",
      "911\tValidation loss: 1.344150\tBest loss: 1.344150\tAccuracy: 91.37%\n",
      "912\tValidation loss: 1.344132\tBest loss: 1.344132\tAccuracy: 91.37%\n",
      "913\tValidation loss: 1.344127\tBest loss: 1.344127\tAccuracy: 91.37%\n",
      "914\tValidation loss: 1.344115\tBest loss: 1.344115\tAccuracy: 91.37%\n",
      "915\tValidation loss: 1.344106\tBest loss: 1.344106\tAccuracy: 91.37%\n",
      "916\tValidation loss: 1.344092\tBest loss: 1.344092\tAccuracy: 91.37%\n",
      "917\tValidation loss: 1.344087\tBest loss: 1.344087\tAccuracy: 91.37%\n",
      "918\tValidation loss: 1.344087\tBest loss: 1.344087\tAccuracy: 91.37%\n",
      "919\tValidation loss: 1.344078\tBest loss: 1.344078\tAccuracy: 91.37%\n",
      "920\tValidation loss: 1.344064\tBest loss: 1.344064\tAccuracy: 91.37%\n",
      "921\tValidation loss: 1.344056\tBest loss: 1.344056\tAccuracy: 91.37%\n",
      "922\tValidation loss: 1.344038\tBest loss: 1.344038\tAccuracy: 91.37%\n",
      "923\tValidation loss: 1.344019\tBest loss: 1.344019\tAccuracy: 91.37%\n",
      "924\tValidation loss: 1.344012\tBest loss: 1.344012\tAccuracy: 91.37%\n",
      "925\tValidation loss: 1.344006\tBest loss: 1.344006\tAccuracy: 91.37%\n",
      "926\tValidation loss: 1.344003\tBest loss: 1.344003\tAccuracy: 91.37%\n",
      "927\tValidation loss: 1.343985\tBest loss: 1.343985\tAccuracy: 91.37%\n",
      "928\tValidation loss: 1.343975\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "929\tValidation loss: 1.343978\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "930\tValidation loss: 1.343979\tBest loss: 1.343975\tAccuracy: 91.37%\n",
      "931\tValidation loss: 1.343967\tBest loss: 1.343967\tAccuracy: 91.37%\n",
      "932\tValidation loss: 1.343947\tBest loss: 1.343947\tAccuracy: 91.37%\n",
      "933\tValidation loss: 1.343942\tBest loss: 1.343942\tAccuracy: 91.37%\n",
      "934\tValidation loss: 1.343943\tBest loss: 1.343942\tAccuracy: 91.37%\n",
      "935\tValidation loss: 1.343925\tBest loss: 1.343925\tAccuracy: 91.37%\n",
      "936\tValidation loss: 1.343921\tBest loss: 1.343921\tAccuracy: 91.37%\n",
      "937\tValidation loss: 1.343916\tBest loss: 1.343916\tAccuracy: 91.37%\n",
      "938\tValidation loss: 1.343906\tBest loss: 1.343906\tAccuracy: 91.37%\n",
      "939\tValidation loss: 1.343896\tBest loss: 1.343896\tAccuracy: 91.37%\n",
      "940\tValidation loss: 1.343889\tBest loss: 1.343889\tAccuracy: 91.37%\n",
      "941\tValidation loss: 1.343882\tBest loss: 1.343882\tAccuracy: 91.37%\n",
      "942\tValidation loss: 1.343869\tBest loss: 1.343869\tAccuracy: 91.37%\n",
      "943\tValidation loss: 1.343861\tBest loss: 1.343861\tAccuracy: 91.37%\n",
      "944\tValidation loss: 1.343841\tBest loss: 1.343841\tAccuracy: 91.37%\n",
      "945\tValidation loss: 1.343828\tBest loss: 1.343828\tAccuracy: 91.37%\n",
      "946\tValidation loss: 1.343828\tBest loss: 1.343828\tAccuracy: 91.37%\n",
      "947\tValidation loss: 1.343825\tBest loss: 1.343825\tAccuracy: 91.37%\n",
      "948\tValidation loss: 1.343808\tBest loss: 1.343808\tAccuracy: 91.37%\n",
      "949\tValidation loss: 1.343784\tBest loss: 1.343784\tAccuracy: 91.37%\n",
      "950\tValidation loss: 1.343769\tBest loss: 1.343769\tAccuracy: 91.37%\n",
      "951\tValidation loss: 1.343762\tBest loss: 1.343762\tAccuracy: 91.37%\n",
      "952\tValidation loss: 1.343745\tBest loss: 1.343745\tAccuracy: 91.37%\n",
      "953\tValidation loss: 1.343726\tBest loss: 1.343726\tAccuracy: 91.37%\n",
      "954\tValidation loss: 1.343712\tBest loss: 1.343712\tAccuracy: 91.37%\n",
      "955\tValidation loss: 1.343696\tBest loss: 1.343696\tAccuracy: 91.37%\n",
      "956\tValidation loss: 1.343686\tBest loss: 1.343686\tAccuracy: 91.37%\n",
      "957\tValidation loss: 1.343676\tBest loss: 1.343676\tAccuracy: 91.37%\n",
      "958\tValidation loss: 1.343669\tBest loss: 1.343669\tAccuracy: 91.37%\n",
      "959\tValidation loss: 1.343655\tBest loss: 1.343655\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\tValidation loss: 1.343647\tBest loss: 1.343647\tAccuracy: 91.37%\n",
      "961\tValidation loss: 1.343642\tBest loss: 1.343642\tAccuracy: 91.37%\n",
      "962\tValidation loss: 1.343637\tBest loss: 1.343637\tAccuracy: 91.37%\n",
      "963\tValidation loss: 1.343629\tBest loss: 1.343629\tAccuracy: 91.37%\n",
      "964\tValidation loss: 1.343615\tBest loss: 1.343615\tAccuracy: 91.37%\n",
      "965\tValidation loss: 1.343608\tBest loss: 1.343608\tAccuracy: 91.37%\n",
      "966\tValidation loss: 1.343594\tBest loss: 1.343594\tAccuracy: 91.37%\n",
      "967\tValidation loss: 1.343582\tBest loss: 1.343582\tAccuracy: 91.37%\n",
      "968\tValidation loss: 1.343577\tBest loss: 1.343577\tAccuracy: 91.37%\n",
      "969\tValidation loss: 1.343564\tBest loss: 1.343564\tAccuracy: 91.37%\n",
      "970\tValidation loss: 1.343545\tBest loss: 1.343545\tAccuracy: 91.37%\n",
      "971\tValidation loss: 1.343527\tBest loss: 1.343527\tAccuracy: 91.37%\n",
      "972\tValidation loss: 1.343517\tBest loss: 1.343517\tAccuracy: 91.37%\n",
      "973\tValidation loss: 1.343513\tBest loss: 1.343513\tAccuracy: 91.37%\n",
      "974\tValidation loss: 1.343499\tBest loss: 1.343499\tAccuracy: 91.37%\n",
      "975\tValidation loss: 1.343493\tBest loss: 1.343493\tAccuracy: 91.37%\n",
      "976\tValidation loss: 1.343480\tBest loss: 1.343480\tAccuracy: 91.37%\n",
      "977\tValidation loss: 1.343465\tBest loss: 1.343465\tAccuracy: 91.37%\n",
      "978\tValidation loss: 1.343457\tBest loss: 1.343457\tAccuracy: 91.37%\n",
      "979\tValidation loss: 1.343455\tBest loss: 1.343455\tAccuracy: 91.37%\n",
      "980\tValidation loss: 1.343451\tBest loss: 1.343451\tAccuracy: 91.37%\n",
      "981\tValidation loss: 1.343436\tBest loss: 1.343436\tAccuracy: 91.37%\n",
      "982\tValidation loss: 1.343431\tBest loss: 1.343431\tAccuracy: 91.37%\n",
      "983\tValidation loss: 1.343421\tBest loss: 1.343421\tAccuracy: 91.37%\n",
      "984\tValidation loss: 1.343414\tBest loss: 1.343414\tAccuracy: 91.37%\n",
      "985\tValidation loss: 1.343402\tBest loss: 1.343402\tAccuracy: 91.37%\n",
      "986\tValidation loss: 1.343398\tBest loss: 1.343398\tAccuracy: 91.37%\n",
      "987\tValidation loss: 1.343385\tBest loss: 1.343385\tAccuracy: 91.37%\n",
      "988\tValidation loss: 1.343380\tBest loss: 1.343380\tAccuracy: 91.37%\n",
      "989\tValidation loss: 1.343368\tBest loss: 1.343368\tAccuracy: 91.37%\n",
      "990\tValidation loss: 1.343350\tBest loss: 1.343350\tAccuracy: 91.37%\n",
      "991\tValidation loss: 1.343351\tBest loss: 1.343350\tAccuracy: 91.37%\n",
      "992\tValidation loss: 1.343347\tBest loss: 1.343347\tAccuracy: 91.37%\n",
      "993\tValidation loss: 1.343342\tBest loss: 1.343342\tAccuracy: 91.37%\n",
      "994\tValidation loss: 1.343328\tBest loss: 1.343328\tAccuracy: 91.37%\n",
      "995\tValidation loss: 1.343319\tBest loss: 1.343319\tAccuracy: 91.37%\n",
      "996\tValidation loss: 1.343313\tBest loss: 1.343313\tAccuracy: 91.37%\n",
      "997\tValidation loss: 1.343301\tBest loss: 1.343301\tAccuracy: 91.37%\n",
      "998\tValidation loss: 1.343308\tBest loss: 1.343301\tAccuracy: 91.37%\n",
      "999\tValidation loss: 1.343289\tBest loss: 1.343289\tAccuracy: 91.37%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total= 1.9min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 86.605972\tBest loss: 86.605972\tAccuracy: 43.88%\n",
      "1\tValidation loss: 4.071143\tBest loss: 4.071143\tAccuracy: 82.73%\n",
      "2\tValidation loss: 4.820080\tBest loss: 4.071143\tAccuracy: 81.29%\n",
      "3\tValidation loss: 1.532486\tBest loss: 1.532486\tAccuracy: 89.21%\n",
      "4\tValidation loss: 1.616773\tBest loss: 1.532486\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.491755\tBest loss: 1.491755\tAccuracy: 89.93%\n",
      "6\tValidation loss: 1.318320\tBest loss: 1.318320\tAccuracy: 89.93%\n",
      "7\tValidation loss: 1.380828\tBest loss: 1.318320\tAccuracy: 90.65%\n",
      "8\tValidation loss: 1.369809\tBest loss: 1.318320\tAccuracy: 91.37%\n",
      "9\tValidation loss: 1.212981\tBest loss: 1.212981\tAccuracy: 91.37%\n",
      "10\tValidation loss: 1.206968\tBest loss: 1.206968\tAccuracy: 89.93%\n",
      "11\tValidation loss: 1.167929\tBest loss: 1.167929\tAccuracy: 90.65%\n",
      "12\tValidation loss: 1.164988\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "13\tValidation loss: 1.168887\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "14\tValidation loss: 1.185780\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.218265\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "16\tValidation loss: 1.224380\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "17\tValidation loss: 1.223913\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "18\tValidation loss: 1.226741\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "19\tValidation loss: 1.211428\tBest loss: 1.164988\tAccuracy: 89.93%\n",
      "20\tValidation loss: 1.209963\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "21\tValidation loss: 1.205905\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "22\tValidation loss: 1.200270\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "23\tValidation loss: 1.196384\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "24\tValidation loss: 1.191661\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "25\tValidation loss: 1.190100\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "26\tValidation loss: 1.188881\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "27\tValidation loss: 1.185356\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "28\tValidation loss: 1.183044\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "29\tValidation loss: 1.179847\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "30\tValidation loss: 1.177564\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "31\tValidation loss: 1.175674\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "32\tValidation loss: 1.173679\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "33\tValidation loss: 1.170932\tBest loss: 1.164988\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function elu at 0x00000252A18B00D0>, total=   3.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 9.946479\tBest loss: 9.946479\tAccuracy: 25.90%\n",
      "1\tValidation loss: 6.643151\tBest loss: 6.643151\tAccuracy: 34.53%\n",
      "2\tValidation loss: 2.787068\tBest loss: 2.787068\tAccuracy: 38.85%\n",
      "3\tValidation loss: 2.719944\tBest loss: 2.719944\tAccuracy: 59.71%\n",
      "4\tValidation loss: 4.901257\tBest loss: 2.719944\tAccuracy: 44.60%\n",
      "5\tValidation loss: 6.780991\tBest loss: 2.719944\tAccuracy: 39.57%\n",
      "6\tValidation loss: 3.945056\tBest loss: 2.719944\tAccuracy: 56.83%\n",
      "7\tValidation loss: 2.632599\tBest loss: 2.632599\tAccuracy: 61.15%\n",
      "8\tValidation loss: 3.743078\tBest loss: 2.632599\tAccuracy: 60.43%\n",
      "9\tValidation loss: 3.193863\tBest loss: 2.632599\tAccuracy: 61.15%\n",
      "10\tValidation loss: 3.415813\tBest loss: 2.632599\tAccuracy: 53.96%\n",
      "11\tValidation loss: 9.575419\tBest loss: 2.632599\tAccuracy: 44.60%\n",
      "12\tValidation loss: 1.572659\tBest loss: 1.572659\tAccuracy: 64.75%\n",
      "13\tValidation loss: 2.085376\tBest loss: 1.572659\tAccuracy: 53.24%\n",
      "14\tValidation loss: 1.971476\tBest loss: 1.572659\tAccuracy: 58.99%\n",
      "15\tValidation loss: 10.065342\tBest loss: 1.572659\tAccuracy: 46.04%\n",
      "16\tValidation loss: 2.889704\tBest loss: 1.572659\tAccuracy: 60.43%\n",
      "17\tValidation loss: 2.371439\tBest loss: 1.572659\tAccuracy: 64.75%\n",
      "18\tValidation loss: 3.724053\tBest loss: 1.572659\tAccuracy: 56.83%\n",
      "19\tValidation loss: 2.158922\tBest loss: 1.572659\tAccuracy: 60.43%\n",
      "20\tValidation loss: 2.899836\tBest loss: 1.572659\tAccuracy: 58.27%\n",
      "21\tValidation loss: 5.173994\tBest loss: 1.572659\tAccuracy: 53.24%\n",
      "22\tValidation loss: 3.834062\tBest loss: 1.572659\tAccuracy: 43.88%\n",
      "23\tValidation loss: 2.087327\tBest loss: 1.572659\tAccuracy: 55.40%\n",
      "24\tValidation loss: 2.993811\tBest loss: 1.572659\tAccuracy: 55.40%\n",
      "25\tValidation loss: 2.743340\tBest loss: 1.572659\tAccuracy: 57.55%\n",
      "26\tValidation loss: 2.278859\tBest loss: 1.572659\tAccuracy: 54.68%\n",
      "27\tValidation loss: 2.513190\tBest loss: 1.572659\tAccuracy: 54.68%\n",
      "28\tValidation loss: 5.023087\tBest loss: 1.572659\tAccuracy: 46.76%\n",
      "29\tValidation loss: 2.693473\tBest loss: 1.572659\tAccuracy: 56.12%\n",
      "30\tValidation loss: 2.482397\tBest loss: 1.572659\tAccuracy: 53.96%\n",
      "31\tValidation loss: 2.892926\tBest loss: 1.572659\tAccuracy: 56.83%\n",
      "32\tValidation loss: 2.286411\tBest loss: 1.572659\tAccuracy: 56.83%\n",
      "33\tValidation loss: 2.236334\tBest loss: 1.572659\tAccuracy: 67.63%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=  12.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 6.688009\tBest loss: 6.688009\tAccuracy: 17.27%\n",
      "1\tValidation loss: 4.432528\tBest loss: 4.432528\tAccuracy: 41.73%\n",
      "2\tValidation loss: 10.318974\tBest loss: 4.432528\tAccuracy: 29.50%\n",
      "3\tValidation loss: 2.754390\tBest loss: 2.754390\tAccuracy: 59.71%\n",
      "4\tValidation loss: 1.652596\tBest loss: 1.652596\tAccuracy: 61.15%\n",
      "5\tValidation loss: 2.162957\tBest loss: 1.652596\tAccuracy: 64.75%\n",
      "6\tValidation loss: 1.972986\tBest loss: 1.652596\tAccuracy: 52.52%\n",
      "7\tValidation loss: 3.138603\tBest loss: 1.652596\tAccuracy: 48.20%\n",
      "8\tValidation loss: 2.224565\tBest loss: 1.652596\tAccuracy: 57.55%\n",
      "9\tValidation loss: 2.459632\tBest loss: 1.652596\tAccuracy: 58.99%\n",
      "10\tValidation loss: 1.819646\tBest loss: 1.652596\tAccuracy: 63.31%\n",
      "11\tValidation loss: 2.770712\tBest loss: 1.652596\tAccuracy: 58.99%\n",
      "12\tValidation loss: 2.805935\tBest loss: 1.652596\tAccuracy: 63.31%\n",
      "13\tValidation loss: 2.827809\tBest loss: 1.652596\tAccuracy: 58.99%\n",
      "14\tValidation loss: 4.436691\tBest loss: 1.652596\tAccuracy: 57.55%\n",
      "15\tValidation loss: 1.686749\tBest loss: 1.652596\tAccuracy: 64.75%\n",
      "16\tValidation loss: 1.826342\tBest loss: 1.652596\tAccuracy: 71.22%\n",
      "17\tValidation loss: 2.729484\tBest loss: 1.652596\tAccuracy: 64.03%\n",
      "18\tValidation loss: 3.610065\tBest loss: 1.652596\tAccuracy: 64.03%\n",
      "19\tValidation loss: 2.729152\tBest loss: 1.652596\tAccuracy: 70.50%\n",
      "20\tValidation loss: 3.793327\tBest loss: 1.652596\tAccuracy: 66.19%\n",
      "21\tValidation loss: 2.879687\tBest loss: 1.652596\tAccuracy: 69.06%\n",
      "22\tValidation loss: 3.389251\tBest loss: 1.652596\tAccuracy: 65.47%\n",
      "23\tValidation loss: 6.126390\tBest loss: 1.652596\tAccuracy: 58.27%\n",
      "24\tValidation loss: 1.656426\tBest loss: 1.652596\tAccuracy: 67.63%\n",
      "25\tValidation loss: 1.760386\tBest loss: 1.652596\tAccuracy: 70.50%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=   9.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 6.508360\tBest loss: 6.508360\tAccuracy: 27.34%\n",
      "1\tValidation loss: 3.258760\tBest loss: 3.258760\tAccuracy: 36.69%\n",
      "2\tValidation loss: 7.192332\tBest loss: 3.258760\tAccuracy: 30.94%\n",
      "3\tValidation loss: 3.940517\tBest loss: 3.258760\tAccuracy: 46.76%\n",
      "4\tValidation loss: 1.638575\tBest loss: 1.638575\tAccuracy: 62.59%\n",
      "5\tValidation loss: 3.323699\tBest loss: 1.638575\tAccuracy: 56.12%\n",
      "6\tValidation loss: 3.988412\tBest loss: 1.638575\tAccuracy: 54.68%\n",
      "7\tValidation loss: 5.991768\tBest loss: 1.638575\tAccuracy: 51.80%\n",
      "8\tValidation loss: 8.405606\tBest loss: 1.638575\tAccuracy: 53.24%\n",
      "9\tValidation loss: 2.095860\tBest loss: 1.638575\tAccuracy: 58.99%\n",
      "10\tValidation loss: 2.576813\tBest loss: 1.638575\tAccuracy: 59.71%\n",
      "11\tValidation loss: 2.489040\tBest loss: 1.638575\tAccuracy: 55.40%\n",
      "12\tValidation loss: 4.595520\tBest loss: 1.638575\tAccuracy: 52.52%\n",
      "13\tValidation loss: 4.969723\tBest loss: 1.638575\tAccuracy: 41.73%\n",
      "14\tValidation loss: 1.913298\tBest loss: 1.638575\tAccuracy: 59.71%\n",
      "15\tValidation loss: 2.951937\tBest loss: 1.638575\tAccuracy: 46.04%\n",
      "16\tValidation loss: 1.634120\tBest loss: 1.634120\tAccuracy: 56.12%\n",
      "17\tValidation loss: 3.609465\tBest loss: 1.634120\tAccuracy: 51.08%\n",
      "18\tValidation loss: 3.936803\tBest loss: 1.634120\tAccuracy: 50.36%\n",
      "19\tValidation loss: 2.844639\tBest loss: 1.634120\tAccuracy: 51.80%\n",
      "20\tValidation loss: 6.720976\tBest loss: 1.634120\tAccuracy: 45.32%\n",
      "21\tValidation loss: 4.071523\tBest loss: 1.634120\tAccuracy: 51.80%\n",
      "22\tValidation loss: 2.941464\tBest loss: 1.634120\tAccuracy: 53.24%\n",
      "23\tValidation loss: 2.218071\tBest loss: 1.634120\tAccuracy: 46.04%\n",
      "24\tValidation loss: 5.055427\tBest loss: 1.634120\tAccuracy: 34.53%\n",
      "25\tValidation loss: 2.327734\tBest loss: 1.634120\tAccuracy: 43.88%\n",
      "26\tValidation loss: 2.720202\tBest loss: 1.634120\tAccuracy: 40.29%\n",
      "27\tValidation loss: 2.514295\tBest loss: 1.634120\tAccuracy: 38.85%\n",
      "28\tValidation loss: 2.497511\tBest loss: 1.634120\tAccuracy: 30.94%\n",
      "29\tValidation loss: 2.408605\tBest loss: 1.634120\tAccuracy: 38.85%\n",
      "30\tValidation loss: 3.439005\tBest loss: 1.634120\tAccuracy: 30.22%\n",
      "31\tValidation loss: 2.689303\tBest loss: 1.634120\tAccuracy: 37.41%\n",
      "32\tValidation loss: 2.549045\tBest loss: 1.634120\tAccuracy: 37.41%\n",
      "33\tValidation loss: 2.186575\tBest loss: 1.634120\tAccuracy: 43.88%\n",
      "34\tValidation loss: 2.495644\tBest loss: 1.634120\tAccuracy: 46.76%\n",
      "35\tValidation loss: 2.671829\tBest loss: 1.634120\tAccuracy: 41.01%\n",
      "36\tValidation loss: 2.354453\tBest loss: 1.634120\tAccuracy: 38.13%\n",
      "37\tValidation loss: 2.519185\tBest loss: 1.634120\tAccuracy: 44.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=1, learning_rate=0.01, dropout_rate=0.4, batch_size=10, activation=<function relu at 0x00000252A18B50D0>, total=  14.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 129.023773\tBest loss: 129.023773\tAccuracy: 10.79%\n",
      "1\tValidation loss: 1041.981445\tBest loss: 129.023773\tAccuracy: 0.72%\n",
      "2\tValidation loss: 1023.608337\tBest loss: 129.023773\tAccuracy: 5.04%\n",
      "3\tValidation loss: 222.543701\tBest loss: 129.023773\tAccuracy: 7.19%\n",
      "4\tValidation loss: 60.596836\tBest loss: 60.596836\tAccuracy: 5.04%\n",
      "5\tValidation loss: 35.069271\tBest loss: 35.069271\tAccuracy: 5.04%\n",
      "6\tValidation loss: 42.210754\tBest loss: 35.069271\tAccuracy: 5.76%\n",
      "7\tValidation loss: 29.173388\tBest loss: 29.173388\tAccuracy: 1.44%\n",
      "8\tValidation loss: 22.616327\tBest loss: 22.616327\tAccuracy: 4.32%\n",
      "9\tValidation loss: 21.420635\tBest loss: 21.420635\tAccuracy: 9.35%\n",
      "10\tValidation loss: 25.607676\tBest loss: 21.420635\tAccuracy: 4.32%\n",
      "11\tValidation loss: 21.454748\tBest loss: 21.420635\tAccuracy: 6.47%\n",
      "12\tValidation loss: 23.863321\tBest loss: 21.420635\tAccuracy: 8.63%\n",
      "13\tValidation loss: 24.786671\tBest loss: 21.420635\tAccuracy: 0.72%\n",
      "14\tValidation loss: 19.960274\tBest loss: 19.960274\tAccuracy: 7.19%\n",
      "15\tValidation loss: 15.122550\tBest loss: 15.122550\tAccuracy: 3.60%\n",
      "16\tValidation loss: 12.904202\tBest loss: 12.904202\tAccuracy: 4.32%\n",
      "17\tValidation loss: 9.425835\tBest loss: 9.425835\tAccuracy: 4.32%\n",
      "18\tValidation loss: 8.467318\tBest loss: 8.467318\tAccuracy: 8.63%\n",
      "19\tValidation loss: 10.253515\tBest loss: 8.467318\tAccuracy: 3.60%\n",
      "20\tValidation loss: 9.343116\tBest loss: 8.467318\tAccuracy: 12.23%\n",
      "21\tValidation loss: 8.717854\tBest loss: 8.467318\tAccuracy: 3.60%\n",
      "22\tValidation loss: 10.041888\tBest loss: 8.467318\tAccuracy: 0.72%\n",
      "23\tValidation loss: 13.674472\tBest loss: 8.467318\tAccuracy: 3.60%\n",
      "24\tValidation loss: 9.473366\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "25\tValidation loss: 11.132879\tBest loss: 8.467318\tAccuracy: 5.76%\n",
      "26\tValidation loss: 14.841644\tBest loss: 8.467318\tAccuracy: 1.44%\n",
      "27\tValidation loss: 13.985962\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "28\tValidation loss: 19.192358\tBest loss: 8.467318\tAccuracy: 3.60%\n",
      "29\tValidation loss: 13.991261\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "30\tValidation loss: 17.889236\tBest loss: 8.467318\tAccuracy: 0.72%\n",
      "31\tValidation loss: 29.597843\tBest loss: 8.467318\tAccuracy: 1.44%\n",
      "32\tValidation loss: 21.849913\tBest loss: 8.467318\tAccuracy: 3.60%\n",
      "33\tValidation loss: 15.830796\tBest loss: 8.467318\tAccuracy: 4.32%\n",
      "34\tValidation loss: 23.281624\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "35\tValidation loss: 16.697277\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "36\tValidation loss: 34.978321\tBest loss: 8.467318\tAccuracy: 6.47%\n",
      "37\tValidation loss: 36.104691\tBest loss: 8.467318\tAccuracy: 1.44%\n",
      "38\tValidation loss: 17.115482\tBest loss: 8.467318\tAccuracy: 6.47%\n",
      "39\tValidation loss: 22.021969\tBest loss: 8.467318\tAccuracy: 5.04%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0>, total=   4.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 109.204544\tBest loss: 109.204544\tAccuracy: 9.35%\n",
      "1\tValidation loss: 764.690186\tBest loss: 109.204544\tAccuracy: 4.32%\n",
      "2\tValidation loss: 240.375549\tBest loss: 109.204544\tAccuracy: 5.76%\n",
      "3\tValidation loss: 100.532295\tBest loss: 100.532295\tAccuracy: 8.63%\n",
      "4\tValidation loss: 108.007614\tBest loss: 100.532295\tAccuracy: 2.88%\n",
      "5\tValidation loss: 158.034348\tBest loss: 100.532295\tAccuracy: 0.00%\n",
      "6\tValidation loss: 37.919449\tBest loss: 37.919449\tAccuracy: 10.07%\n",
      "7\tValidation loss: 24.803162\tBest loss: 24.803162\tAccuracy: 5.76%\n",
      "8\tValidation loss: 21.712151\tBest loss: 21.712151\tAccuracy: 5.04%\n",
      "9\tValidation loss: 18.430895\tBest loss: 18.430895\tAccuracy: 4.32%\n",
      "10\tValidation loss: 12.404076\tBest loss: 12.404076\tAccuracy: 3.60%\n",
      "11\tValidation loss: 15.834122\tBest loss: 12.404076\tAccuracy: 10.07%\n",
      "12\tValidation loss: 18.268206\tBest loss: 12.404076\tAccuracy: 3.60%\n",
      "13\tValidation loss: 13.139702\tBest loss: 12.404076\tAccuracy: 1.44%\n",
      "14\tValidation loss: 11.738166\tBest loss: 11.738166\tAccuracy: 3.60%\n",
      "15\tValidation loss: 10.177809\tBest loss: 10.177809\tAccuracy: 5.04%\n",
      "16\tValidation loss: 9.168207\tBest loss: 9.168207\tAccuracy: 4.32%\n",
      "17\tValidation loss: 8.518137\tBest loss: 8.518137\tAccuracy: 2.88%\n",
      "18\tValidation loss: 10.877661\tBest loss: 8.518137\tAccuracy: 2.88%\n",
      "19\tValidation loss: 9.041497\tBest loss: 8.518137\tAccuracy: 2.16%\n",
      "20\tValidation loss: 8.081188\tBest loss: 8.081188\tAccuracy: 0.72%\n",
      "21\tValidation loss: 7.154237\tBest loss: 7.154237\tAccuracy: 4.32%\n",
      "22\tValidation loss: 8.489809\tBest loss: 7.154237\tAccuracy: 3.60%\n",
      "23\tValidation loss: 11.590591\tBest loss: 7.154237\tAccuracy: 2.16%\n",
      "24\tValidation loss: 12.681192\tBest loss: 7.154237\tAccuracy: 7.19%\n",
      "25\tValidation loss: 41.946182\tBest loss: 7.154237\tAccuracy: 2.16%\n",
      "26\tValidation loss: 12.155319\tBest loss: 7.154237\tAccuracy: 5.04%\n",
      "27\tValidation loss: 13.376148\tBest loss: 7.154237\tAccuracy: 5.04%\n",
      "28\tValidation loss: 14.416493\tBest loss: 7.154237\tAccuracy: 3.60%\n",
      "29\tValidation loss: 27.493431\tBest loss: 7.154237\tAccuracy: 1.44%\n",
      "30\tValidation loss: 13.807493\tBest loss: 7.154237\tAccuracy: 2.88%\n",
      "31\tValidation loss: 15.594561\tBest loss: 7.154237\tAccuracy: 0.72%\n",
      "32\tValidation loss: 16.416479\tBest loss: 7.154237\tAccuracy: 2.88%\n",
      "33\tValidation loss: 13.577296\tBest loss: 7.154237\tAccuracy: 2.88%\n",
      "34\tValidation loss: 14.044417\tBest loss: 7.154237\tAccuracy: 4.32%\n",
      "35\tValidation loss: 14.235054\tBest loss: 7.154237\tAccuracy: 5.04%\n",
      "36\tValidation loss: 18.051016\tBest loss: 7.154237\tAccuracy: 6.47%\n",
      "37\tValidation loss: 18.103140\tBest loss: 7.154237\tAccuracy: 2.16%\n",
      "38\tValidation loss: 20.860203\tBest loss: 7.154237\tAccuracy: 2.88%\n",
      "39\tValidation loss: 26.129917\tBest loss: 7.154237\tAccuracy: 4.32%\n",
      "40\tValidation loss: 29.127234\tBest loss: 7.154237\tAccuracy: 3.60%\n",
      "41\tValidation loss: 20.565203\tBest loss: 7.154237\tAccuracy: 5.04%\n",
      "42\tValidation loss: 20.159470\tBest loss: 7.154237\tAccuracy: 1.44%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0>, total=   4.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 141.157791\tBest loss: 141.157791\tAccuracy: 7.91%\n",
      "1\tValidation loss: 986.869141\tBest loss: 141.157791\tAccuracy: 7.19%\n",
      "2\tValidation loss: 275.282806\tBest loss: 141.157791\tAccuracy: 5.04%\n",
      "3\tValidation loss: 107.387512\tBest loss: 107.387512\tAccuracy: 4.32%\n",
      "4\tValidation loss: 38.053688\tBest loss: 38.053688\tAccuracy: 1.44%\n",
      "5\tValidation loss: 54.788044\tBest loss: 38.053688\tAccuracy: 0.72%\n",
      "6\tValidation loss: 30.519861\tBest loss: 30.519861\tAccuracy: 4.32%\n",
      "7\tValidation loss: 20.256012\tBest loss: 20.256012\tAccuracy: 10.07%\n",
      "8\tValidation loss: 22.013302\tBest loss: 20.256012\tAccuracy: 4.32%\n",
      "9\tValidation loss: 21.999603\tBest loss: 20.256012\tAccuracy: 2.16%\n",
      "10\tValidation loss: 26.986099\tBest loss: 20.256012\tAccuracy: 5.76%\n",
      "11\tValidation loss: 22.682137\tBest loss: 20.256012\tAccuracy: 2.88%\n",
      "12\tValidation loss: 21.086496\tBest loss: 20.256012\tAccuracy: 5.76%\n",
      "13\tValidation loss: 19.825716\tBest loss: 19.825716\tAccuracy: 2.16%\n",
      "14\tValidation loss: 16.682255\tBest loss: 16.682255\tAccuracy: 1.44%\n",
      "15\tValidation loss: 13.803284\tBest loss: 13.803284\tAccuracy: 0.72%\n",
      "16\tValidation loss: 10.925444\tBest loss: 10.925444\tAccuracy: 7.91%\n",
      "17\tValidation loss: 12.422214\tBest loss: 10.925444\tAccuracy: 3.60%\n",
      "18\tValidation loss: 13.977761\tBest loss: 10.925444\tAccuracy: 2.88%\n",
      "19\tValidation loss: 9.783269\tBest loss: 9.783269\tAccuracy: 0.72%\n",
      "20\tValidation loss: 8.774055\tBest loss: 8.774055\tAccuracy: 6.47%\n",
      "21\tValidation loss: 7.240795\tBest loss: 7.240795\tAccuracy: 3.60%\n",
      "22\tValidation loss: 7.218964\tBest loss: 7.218964\tAccuracy: 7.19%\n",
      "23\tValidation loss: 8.492761\tBest loss: 7.218964\tAccuracy: 7.19%\n",
      "24\tValidation loss: 9.241848\tBest loss: 7.218964\tAccuracy: 0.72%\n",
      "25\tValidation loss: 10.642598\tBest loss: 7.218964\tAccuracy: 1.44%\n",
      "26\tValidation loss: 10.724161\tBest loss: 7.218964\tAccuracy: 0.72%\n",
      "27\tValidation loss: 8.602527\tBest loss: 7.218964\tAccuracy: 7.19%\n",
      "28\tValidation loss: 8.938553\tBest loss: 7.218964\tAccuracy: 1.44%\n",
      "29\tValidation loss: 14.067443\tBest loss: 7.218964\tAccuracy: 5.04%\n",
      "30\tValidation loss: 12.887659\tBest loss: 7.218964\tAccuracy: 5.76%\n",
      "31\tValidation loss: 10.917270\tBest loss: 7.218964\tAccuracy: 3.60%\n",
      "32\tValidation loss: 11.820557\tBest loss: 7.218964\tAccuracy: 1.44%\n",
      "33\tValidation loss: 10.398385\tBest loss: 7.218964\tAccuracy: 1.44%\n",
      "34\tValidation loss: 8.946638\tBest loss: 7.218964\tAccuracy: 3.60%\n",
      "35\tValidation loss: 9.718282\tBest loss: 7.218964\tAccuracy: 6.47%\n",
      "36\tValidation loss: 14.615623\tBest loss: 7.218964\tAccuracy: 2.16%\n",
      "37\tValidation loss: 10.256959\tBest loss: 7.218964\tAccuracy: 3.60%\n",
      "38\tValidation loss: 13.019875\tBest loss: 7.218964\tAccuracy: 0.72%\n",
      "39\tValidation loss: 9.827711\tBest loss: 7.218964\tAccuracy: 2.16%\n",
      "40\tValidation loss: 7.970222\tBest loss: 7.218964\tAccuracy: 5.76%\n",
      "41\tValidation loss: 17.582413\tBest loss: 7.218964\tAccuracy: 1.44%\n",
      "42\tValidation loss: 8.564445\tBest loss: 7.218964\tAccuracy: 5.04%\n",
      "43\tValidation loss: 8.665466\tBest loss: 7.218964\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=2, learning_rate=0.05, dropout_rate=0.3, batch_size=500, activation=<function elu at 0x00000252A18B00D0>, total=   4.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 5663567.500000\tBest loss: 5663567.500000\tAccuracy: 7.19%\n",
      "1\tValidation loss: 7964599.500000\tBest loss: 5663567.500000\tAccuracy: 5.04%\n",
      "2\tValidation loss: 36790668.000000\tBest loss: 5663567.500000\tAccuracy: 14.39%\n",
      "3\tValidation loss: 1821744384.000000\tBest loss: 5663567.500000\tAccuracy: 10.79%\n",
      "4\tValidation loss: 407235168.000000\tBest loss: 5663567.500000\tAccuracy: 20.86%\n",
      "5\tValidation loss: 390117632.000000\tBest loss: 5663567.500000\tAccuracy: 20.14%\n",
      "6\tValidation loss: 332532960.000000\tBest loss: 5663567.500000\tAccuracy: 33.09%\n",
      "7\tValidation loss: 172175952.000000\tBest loss: 5663567.500000\tAccuracy: 45.32%\n",
      "8\tValidation loss: 294691072.000000\tBest loss: 5663567.500000\tAccuracy: 38.13%\n",
      "9\tValidation loss: 317889376.000000\tBest loss: 5663567.500000\tAccuracy: 43.88%\n",
      "10\tValidation loss: 377683008.000000\tBest loss: 5663567.500000\tAccuracy: 46.76%\n",
      "11\tValidation loss: 177386032.000000\tBest loss: 5663567.500000\tAccuracy: 53.96%\n",
      "12\tValidation loss: 142783072.000000\tBest loss: 5663567.500000\tAccuracy: 58.27%\n",
      "13\tValidation loss: 216885488.000000\tBest loss: 5663567.500000\tAccuracy: 59.71%\n",
      "14\tValidation loss: 482212896.000000\tBest loss: 5663567.500000\tAccuracy: 57.55%\n",
      "15\tValidation loss: 692095040.000000\tBest loss: 5663567.500000\tAccuracy: 56.12%\n",
      "16\tValidation loss: 1439038464.000000\tBest loss: 5663567.500000\tAccuracy: 46.76%\n",
      "17\tValidation loss: 1699926656.000000\tBest loss: 5663567.500000\tAccuracy: 56.83%\n",
      "18\tValidation loss: 1285479296.000000\tBest loss: 5663567.500000\tAccuracy: 57.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\tValidation loss: 3228669952.000000\tBest loss: 5663567.500000\tAccuracy: 53.24%\n",
      "20\tValidation loss: 1956785280.000000\tBest loss: 5663567.500000\tAccuracy: 56.12%\n",
      "21\tValidation loss: 1096291584.000000\tBest loss: 5663567.500000\tAccuracy: 71.22%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  12.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 42955336.000000\tBest loss: 42955336.000000\tAccuracy: 1.44%\n",
      "1\tValidation loss: 47704496.000000\tBest loss: 42955336.000000\tAccuracy: 10.79%\n",
      "2\tValidation loss: 44448964.000000\tBest loss: 42955336.000000\tAccuracy: 16.55%\n",
      "3\tValidation loss: 74764992.000000\tBest loss: 42955336.000000\tAccuracy: 20.86%\n",
      "4\tValidation loss: 111538160.000000\tBest loss: 42955336.000000\tAccuracy: 26.62%\n",
      "5\tValidation loss: 427333760.000000\tBest loss: 42955336.000000\tAccuracy: 25.18%\n",
      "6\tValidation loss: 349398272.000000\tBest loss: 42955336.000000\tAccuracy: 37.41%\n",
      "7\tValidation loss: 893697600.000000\tBest loss: 42955336.000000\tAccuracy: 37.41%\n",
      "8\tValidation loss: 1019850816.000000\tBest loss: 42955336.000000\tAccuracy: 34.53%\n",
      "9\tValidation loss: 708761216.000000\tBest loss: 42955336.000000\tAccuracy: 43.17%\n",
      "10\tValidation loss: 412900000.000000\tBest loss: 42955336.000000\tAccuracy: 54.68%\n",
      "11\tValidation loss: 1223683456.000000\tBest loss: 42955336.000000\tAccuracy: 47.48%\n",
      "12\tValidation loss: 1140187008.000000\tBest loss: 42955336.000000\tAccuracy: 54.68%\n",
      "13\tValidation loss: 446866432.000000\tBest loss: 42955336.000000\tAccuracy: 61.87%\n",
      "14\tValidation loss: 804499072.000000\tBest loss: 42955336.000000\tAccuracy: 59.71%\n",
      "15\tValidation loss: 853756352.000000\tBest loss: 42955336.000000\tAccuracy: 61.15%\n",
      "16\tValidation loss: 916441728.000000\tBest loss: 42955336.000000\tAccuracy: 74.82%\n",
      "17\tValidation loss: 1066050752.000000\tBest loss: 42955336.000000\tAccuracy: 53.24%\n",
      "18\tValidation loss: 992309568.000000\tBest loss: 42955336.000000\tAccuracy: 67.63%\n",
      "19\tValidation loss: 1872172672.000000\tBest loss: 42955336.000000\tAccuracy: 67.63%\n",
      "20\tValidation loss: 933242752.000000\tBest loss: 42955336.000000\tAccuracy: 65.47%\n",
      "21\tValidation loss: 751970112.000000\tBest loss: 42955336.000000\tAccuracy: 69.78%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  12.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 16942812.000000\tBest loss: 16942812.000000\tAccuracy: 6.47%\n",
      "1\tValidation loss: 46769884.000000\tBest loss: 16942812.000000\tAccuracy: 7.91%\n",
      "2\tValidation loss: 500216320.000000\tBest loss: 16942812.000000\tAccuracy: 10.79%\n",
      "3\tValidation loss: 362068096.000000\tBest loss: 16942812.000000\tAccuracy: 15.11%\n",
      "4\tValidation loss: 208354560.000000\tBest loss: 16942812.000000\tAccuracy: 24.46%\n",
      "5\tValidation loss: 172527728.000000\tBest loss: 16942812.000000\tAccuracy: 30.94%\n",
      "6\tValidation loss: 174164704.000000\tBest loss: 16942812.000000\tAccuracy: 35.97%\n",
      "7\tValidation loss: 164565856.000000\tBest loss: 16942812.000000\tAccuracy: 50.36%\n",
      "8\tValidation loss: 211195008.000000\tBest loss: 16942812.000000\tAccuracy: 40.29%\n",
      "9\tValidation loss: 142161472.000000\tBest loss: 16942812.000000\tAccuracy: 50.36%\n",
      "10\tValidation loss: 186321280.000000\tBest loss: 16942812.000000\tAccuracy: 51.08%\n",
      "11\tValidation loss: 265268864.000000\tBest loss: 16942812.000000\tAccuracy: 58.99%\n",
      "12\tValidation loss: 478959872.000000\tBest loss: 16942812.000000\tAccuracy: 48.20%\n",
      "13\tValidation loss: 315649760.000000\tBest loss: 16942812.000000\tAccuracy: 57.55%\n",
      "14\tValidation loss: 1123107584.000000\tBest loss: 16942812.000000\tAccuracy: 56.12%\n",
      "15\tValidation loss: 1650668544.000000\tBest loss: 16942812.000000\tAccuracy: 52.52%\n",
      "16\tValidation loss: 2740452096.000000\tBest loss: 16942812.000000\tAccuracy: 41.73%\n",
      "17\tValidation loss: 1494274560.000000\tBest loss: 16942812.000000\tAccuracy: 59.71%\n",
      "18\tValidation loss: 1627370112.000000\tBest loss: 16942812.000000\tAccuracy: 53.96%\n",
      "19\tValidation loss: 775079488.000000\tBest loss: 16942812.000000\tAccuracy: 71.94%\n",
      "20\tValidation loss: 428956608.000000\tBest loss: 16942812.000000\tAccuracy: 78.42%\n",
      "21\tValidation loss: 1215889792.000000\tBest loss: 16942812.000000\tAccuracy: 66.19%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  13.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 420.616180\tBest loss: 420.616180\tAccuracy: 15.83%\n",
      "1\tValidation loss: 8.650027\tBest loss: 8.650027\tAccuracy: 17.99%\n",
      "2\tValidation loss: 4.169535\tBest loss: 4.169535\tAccuracy: 8.63%\n",
      "3\tValidation loss: 4.112975\tBest loss: 4.112975\tAccuracy: 6.47%\n",
      "4\tValidation loss: 3.999653\tBest loss: 3.999653\tAccuracy: 7.19%\n",
      "5\tValidation loss: 3.599303\tBest loss: 3.599303\tAccuracy: 10.07%\n",
      "6\tValidation loss: 3.642379\tBest loss: 3.599303\tAccuracy: 10.07%\n",
      "7\tValidation loss: 3.581797\tBest loss: 3.581797\tAccuracy: 9.35%\n",
      "8\tValidation loss: 3.673019\tBest loss: 3.581797\tAccuracy: 9.35%\n",
      "9\tValidation loss: 3.809811\tBest loss: 3.581797\tAccuracy: 7.91%\n",
      "10\tValidation loss: 3.823282\tBest loss: 3.581797\tAccuracy: 7.91%\n",
      "11\tValidation loss: 3.697780\tBest loss: 3.581797\tAccuracy: 7.19%\n",
      "12\tValidation loss: 3.696432\tBest loss: 3.581797\tAccuracy: 7.19%\n",
      "13\tValidation loss: 3.746895\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "14\tValidation loss: 3.630256\tBest loss: 3.581797\tAccuracy: 7.91%\n",
      "15\tValidation loss: 3.705434\tBest loss: 3.581797\tAccuracy: 7.19%\n",
      "16\tValidation loss: 3.712013\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.832745\tBest loss: 3.581797\tAccuracy: 5.76%\n",
      "18\tValidation loss: 3.731908\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "19\tValidation loss: 3.754799\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "20\tValidation loss: 3.656921\tBest loss: 3.581797\tAccuracy: 7.91%\n",
      "21\tValidation loss: 3.795683\tBest loss: 3.581797\tAccuracy: 5.04%\n",
      "22\tValidation loss: 5.418125\tBest loss: 3.581797\tAccuracy: 4.32%\n",
      "23\tValidation loss: 5.749523\tBest loss: 3.581797\tAccuracy: 5.76%\n",
      "24\tValidation loss: 6.015131\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "25\tValidation loss: 4.242256\tBest loss: 3.581797\tAccuracy: 7.19%\n",
      "26\tValidation loss: 3.902258\tBest loss: 3.581797\tAccuracy: 5.76%\n",
      "27\tValidation loss: 3.742893\tBest loss: 3.581797\tAccuracy: 6.47%\n",
      "28\tValidation loss: 3.684240\tBest loss: 3.581797\tAccuracy: 7.19%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   3.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 424.987518\tBest loss: 424.987518\tAccuracy: 11.51%\n",
      "1\tValidation loss: 33.971039\tBest loss: 33.971039\tAccuracy: 31.65%\n",
      "2\tValidation loss: 6.651038\tBest loss: 6.651038\tAccuracy: 20.14%\n",
      "3\tValidation loss: 3.671287\tBest loss: 3.671287\tAccuracy: 15.83%\n",
      "4\tValidation loss: 3.432821\tBest loss: 3.432821\tAccuracy: 15.83%\n",
      "5\tValidation loss: 3.541615\tBest loss: 3.432821\tAccuracy: 13.67%\n",
      "6\tValidation loss: 3.564882\tBest loss: 3.432821\tAccuracy: 13.67%\n",
      "7\tValidation loss: 3.338560\tBest loss: 3.338560\tAccuracy: 15.11%\n",
      "8\tValidation loss: 3.346937\tBest loss: 3.338560\tAccuracy: 15.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 3.291717\tBest loss: 3.291717\tAccuracy: 16.55%\n",
      "10\tValidation loss: 3.211760\tBest loss: 3.211760\tAccuracy: 16.55%\n",
      "11\tValidation loss: 3.194804\tBest loss: 3.194804\tAccuracy: 18.71%\n",
      "12\tValidation loss: 4.104104\tBest loss: 3.194804\tAccuracy: 15.83%\n",
      "13\tValidation loss: 3.321797\tBest loss: 3.194804\tAccuracy: 16.55%\n",
      "14\tValidation loss: 3.646861\tBest loss: 3.194804\tAccuracy: 14.39%\n",
      "15\tValidation loss: 3.427965\tBest loss: 3.194804\tAccuracy: 12.23%\n",
      "16\tValidation loss: 3.330370\tBest loss: 3.194804\tAccuracy: 15.11%\n",
      "17\tValidation loss: 3.365350\tBest loss: 3.194804\tAccuracy: 17.99%\n",
      "18\tValidation loss: 3.569012\tBest loss: 3.194804\tAccuracy: 15.83%\n",
      "19\tValidation loss: 3.450641\tBest loss: 3.194804\tAccuracy: 16.55%\n",
      "20\tValidation loss: 3.480793\tBest loss: 3.194804\tAccuracy: 14.39%\n",
      "21\tValidation loss: 3.538036\tBest loss: 3.194804\tAccuracy: 14.39%\n",
      "22\tValidation loss: 3.488985\tBest loss: 3.194804\tAccuracy: 14.39%\n",
      "23\tValidation loss: 3.468266\tBest loss: 3.194804\tAccuracy: 15.11%\n",
      "24\tValidation loss: 3.505305\tBest loss: 3.194804\tAccuracy: 17.99%\n",
      "25\tValidation loss: 3.231743\tBest loss: 3.194804\tAccuracy: 17.99%\n",
      "26\tValidation loss: 3.304313\tBest loss: 3.194804\tAccuracy: 15.83%\n",
      "27\tValidation loss: 3.389122\tBest loss: 3.194804\tAccuracy: 14.39%\n",
      "28\tValidation loss: 3.404896\tBest loss: 3.194804\tAccuracy: 13.67%\n",
      "29\tValidation loss: 3.425281\tBest loss: 3.194804\tAccuracy: 12.95%\n",
      "30\tValidation loss: 3.563799\tBest loss: 3.194804\tAccuracy: 11.51%\n",
      "31\tValidation loss: 3.399736\tBest loss: 3.194804\tAccuracy: 12.95%\n",
      "32\tValidation loss: 3.283244\tBest loss: 3.194804\tAccuracy: 15.83%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   3.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 545.639954\tBest loss: 545.639954\tAccuracy: 16.55%\n",
      "1\tValidation loss: 15.741074\tBest loss: 15.741074\tAccuracy: 19.42%\n",
      "2\tValidation loss: 4.188050\tBest loss: 4.188050\tAccuracy: 22.30%\n",
      "3\tValidation loss: 3.674685\tBest loss: 3.674685\tAccuracy: 15.83%\n",
      "4\tValidation loss: 4.048895\tBest loss: 3.674685\tAccuracy: 16.55%\n",
      "5\tValidation loss: 4.939569\tBest loss: 3.674685\tAccuracy: 15.11%\n",
      "6\tValidation loss: 3.636281\tBest loss: 3.636281\tAccuracy: 15.83%\n",
      "7\tValidation loss: 3.494024\tBest loss: 3.494024\tAccuracy: 16.55%\n",
      "8\tValidation loss: 3.368601\tBest loss: 3.368601\tAccuracy: 15.11%\n",
      "9\tValidation loss: 6.909194\tBest loss: 3.368601\tAccuracy: 20.14%\n",
      "10\tValidation loss: 3.274053\tBest loss: 3.274053\tAccuracy: 17.99%\n",
      "11\tValidation loss: 3.296237\tBest loss: 3.274053\tAccuracy: 18.71%\n",
      "12\tValidation loss: 3.294004\tBest loss: 3.274053\tAccuracy: 18.71%\n",
      "13\tValidation loss: 4.913224\tBest loss: 3.274053\tAccuracy: 17.27%\n",
      "14\tValidation loss: 4.735947\tBest loss: 3.274053\tAccuracy: 16.55%\n",
      "15\tValidation loss: 3.594947\tBest loss: 3.274053\tAccuracy: 11.51%\n",
      "16\tValidation loss: 3.625761\tBest loss: 3.274053\tAccuracy: 12.23%\n",
      "17\tValidation loss: 3.459907\tBest loss: 3.274053\tAccuracy: 12.23%\n",
      "18\tValidation loss: 3.296008\tBest loss: 3.274053\tAccuracy: 15.11%\n",
      "19\tValidation loss: 3.299104\tBest loss: 3.274053\tAccuracy: 14.39%\n",
      "20\tValidation loss: 5.165432\tBest loss: 3.274053\tAccuracy: 12.95%\n",
      "21\tValidation loss: 3.241055\tBest loss: 3.241055\tAccuracy: 17.27%\n",
      "22\tValidation loss: 3.263886\tBest loss: 3.241055\tAccuracy: 15.83%\n",
      "23\tValidation loss: 3.864673\tBest loss: 3.241055\tAccuracy: 15.83%\n",
      "24\tValidation loss: 3.356752\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "25\tValidation loss: 3.528270\tBest loss: 3.241055\tAccuracy: 10.79%\n",
      "26\tValidation loss: 3.470143\tBest loss: 3.241055\tAccuracy: 12.23%\n",
      "27\tValidation loss: 5.709888\tBest loss: 3.241055\tAccuracy: 17.27%\n",
      "28\tValidation loss: 5.027153\tBest loss: 3.241055\tAccuracy: 18.71%\n",
      "29\tValidation loss: 5.274715\tBest loss: 3.241055\tAccuracy: 17.27%\n",
      "30\tValidation loss: 4.540528\tBest loss: 3.241055\tAccuracy: 17.27%\n",
      "31\tValidation loss: 5.078588\tBest loss: 3.241055\tAccuracy: 18.71%\n",
      "32\tValidation loss: 7.877527\tBest loss: 3.241055\tAccuracy: 13.67%\n",
      "33\tValidation loss: 7.198347\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "34\tValidation loss: 7.710267\tBest loss: 3.241055\tAccuracy: 15.83%\n",
      "35\tValidation loss: 4.861833\tBest loss: 3.241055\tAccuracy: 13.67%\n",
      "36\tValidation loss: 3.619749\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "37\tValidation loss: 3.602937\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "38\tValidation loss: 4.509514\tBest loss: 3.241055\tAccuracy: 12.95%\n",
      "39\tValidation loss: 4.726098\tBest loss: 3.241055\tAccuracy: 12.23%\n",
      "40\tValidation loss: 4.220271\tBest loss: 3.241055\tAccuracy: 12.23%\n",
      "41\tValidation loss: 3.805487\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "42\tValidation loss: 3.758680\tBest loss: 3.241055\tAccuracy: 14.39%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.3, batch_size=100, activation=<function relu at 0x00000252A18B50D0>, total=   4.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 10102.373047\tBest loss: 10102.373047\tAccuracy: 41.73%\n",
      "1\tValidation loss: 6096.295898\tBest loss: 6096.295898\tAccuracy: 51.80%\n",
      "2\tValidation loss: 3115.489990\tBest loss: 3115.489990\tAccuracy: 71.22%\n",
      "3\tValidation loss: 8113.049805\tBest loss: 3115.489990\tAccuracy: 64.03%\n",
      "4\tValidation loss: 6679.270508\tBest loss: 3115.489990\tAccuracy: 76.26%\n",
      "5\tValidation loss: 4388.274414\tBest loss: 3115.489990\tAccuracy: 77.70%\n",
      "6\tValidation loss: 3788.098389\tBest loss: 3115.489990\tAccuracy: 82.73%\n",
      "7\tValidation loss: 4306.169922\tBest loss: 3115.489990\tAccuracy: 80.58%\n",
      "8\tValidation loss: 16647.783203\tBest loss: 3115.489990\tAccuracy: 66.91%\n",
      "9\tValidation loss: 6676.645508\tBest loss: 3115.489990\tAccuracy: 81.29%\n",
      "10\tValidation loss: 11318.166016\tBest loss: 3115.489990\tAccuracy: 79.14%\n",
      "11\tValidation loss: 18866.150391\tBest loss: 3115.489990\tAccuracy: 81.29%\n",
      "12\tValidation loss: 4023.656494\tBest loss: 3115.489990\tAccuracy: 84.17%\n",
      "13\tValidation loss: 27260.023438\tBest loss: 3115.489990\tAccuracy: 69.06%\n",
      "14\tValidation loss: 15114.011719\tBest loss: 3115.489990\tAccuracy: 79.14%\n",
      "15\tValidation loss: 7649.920898\tBest loss: 3115.489990\tAccuracy: 87.05%\n",
      "16\tValidation loss: 7431.206543\tBest loss: 3115.489990\tAccuracy: 86.33%\n",
      "17\tValidation loss: 5055.795898\tBest loss: 3115.489990\tAccuracy: 83.45%\n",
      "18\tValidation loss: 3780.592773\tBest loss: 3115.489990\tAccuracy: 87.77%\n",
      "19\tValidation loss: 2494.594238\tBest loss: 2494.594238\tAccuracy: 91.37%\n",
      "20\tValidation loss: 2564.530518\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "21\tValidation loss: 2615.324951\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "22\tValidation loss: 2625.191895\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "23\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "24\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "25\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "26\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "27\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "28\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "29\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "30\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "31\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "32\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "33\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "34\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "35\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "36\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "37\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "38\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "39\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\tValidation loss: 2625.195557\tBest loss: 2494.594238\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  12.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 7553.043457\tBest loss: 7553.043457\tAccuracy: 39.57%\n",
      "1\tValidation loss: 6222.626953\tBest loss: 6222.626953\tAccuracy: 58.27%\n",
      "2\tValidation loss: 12801.160156\tBest loss: 6222.626953\tAccuracy: 56.12%\n",
      "3\tValidation loss: 7210.991699\tBest loss: 6222.626953\tAccuracy: 69.78%\n",
      "4\tValidation loss: 7786.906250\tBest loss: 6222.626953\tAccuracy: 72.66%\n",
      "5\tValidation loss: 5316.800781\tBest loss: 5316.800781\tAccuracy: 79.14%\n",
      "6\tValidation loss: 6644.033691\tBest loss: 5316.800781\tAccuracy: 74.82%\n",
      "7\tValidation loss: 19024.759766\tBest loss: 5316.800781\tAccuracy: 74.10%\n",
      "8\tValidation loss: 7062.910156\tBest loss: 5316.800781\tAccuracy: 79.86%\n",
      "9\tValidation loss: 4446.217773\tBest loss: 4446.217773\tAccuracy: 83.45%\n",
      "10\tValidation loss: 2573.519043\tBest loss: 2573.519043\tAccuracy: 87.05%\n",
      "11\tValidation loss: 3460.276855\tBest loss: 2573.519043\tAccuracy: 86.33%\n",
      "12\tValidation loss: 2083.909424\tBest loss: 2083.909424\tAccuracy: 92.09%\n",
      "13\tValidation loss: 4578.995117\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "14\tValidation loss: 3318.931885\tBest loss: 2083.909424\tAccuracy: 85.61%\n",
      "15\tValidation loss: 8024.260254\tBest loss: 2083.909424\tAccuracy: 79.86%\n",
      "16\tValidation loss: 38610.679688\tBest loss: 2083.909424\tAccuracy: 71.22%\n",
      "17\tValidation loss: 11024.384766\tBest loss: 2083.909424\tAccuracy: 75.54%\n",
      "18\tValidation loss: 15527.136719\tBest loss: 2083.909424\tAccuracy: 79.14%\n",
      "19\tValidation loss: 9169.521484\tBest loss: 2083.909424\tAccuracy: 87.05%\n",
      "20\tValidation loss: 3913.739502\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "21\tValidation loss: 7888.304199\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "22\tValidation loss: 2612.438232\tBest loss: 2083.909424\tAccuracy: 89.93%\n",
      "23\tValidation loss: 6922.813477\tBest loss: 2083.909424\tAccuracy: 85.61%\n",
      "24\tValidation loss: 3961.616455\tBest loss: 2083.909424\tAccuracy: 88.49%\n",
      "25\tValidation loss: 11244.473633\tBest loss: 2083.909424\tAccuracy: 87.05%\n",
      "26\tValidation loss: 7538.176270\tBest loss: 2083.909424\tAccuracy: 89.21%\n",
      "27\tValidation loss: 7425.824707\tBest loss: 2083.909424\tAccuracy: 85.61%\n",
      "28\tValidation loss: 4437.237793\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "29\tValidation loss: 5213.383789\tBest loss: 2083.909424\tAccuracy: 89.21%\n",
      "30\tValidation loss: 5120.103516\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "31\tValidation loss: 4651.897461\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "32\tValidation loss: 4651.590820\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "33\tValidation loss: 4651.590820\tBest loss: 2083.909424\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  10.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 6261.767578\tBest loss: 6261.767578\tAccuracy: 44.60%\n",
      "1\tValidation loss: 6924.483398\tBest loss: 6261.767578\tAccuracy: 57.55%\n",
      "2\tValidation loss: 3669.206787\tBest loss: 3669.206787\tAccuracy: 72.66%\n",
      "3\tValidation loss: 4972.310547\tBest loss: 3669.206787\tAccuracy: 67.63%\n",
      "4\tValidation loss: 7406.511719\tBest loss: 3669.206787\tAccuracy: 72.66%\n",
      "5\tValidation loss: 6753.456055\tBest loss: 3669.206787\tAccuracy: 74.10%\n",
      "6\tValidation loss: 4275.853516\tBest loss: 3669.206787\tAccuracy: 79.14%\n",
      "7\tValidation loss: 4845.103027\tBest loss: 3669.206787\tAccuracy: 80.58%\n",
      "8\tValidation loss: 7974.233887\tBest loss: 3669.206787\tAccuracy: 82.01%\n",
      "9\tValidation loss: 8186.734375\tBest loss: 3669.206787\tAccuracy: 81.29%\n",
      "10\tValidation loss: 7070.091309\tBest loss: 3669.206787\tAccuracy: 82.73%\n",
      "11\tValidation loss: 8004.704590\tBest loss: 3669.206787\tAccuracy: 87.05%\n",
      "12\tValidation loss: 5556.521484\tBest loss: 3669.206787\tAccuracy: 87.77%\n",
      "13\tValidation loss: 4668.444336\tBest loss: 3669.206787\tAccuracy: 85.61%\n",
      "14\tValidation loss: 3085.887207\tBest loss: 3085.887207\tAccuracy: 89.21%\n",
      "15\tValidation loss: 2199.041016\tBest loss: 2199.041016\tAccuracy: 91.37%\n",
      "16\tValidation loss: 1764.762939\tBest loss: 1764.762939\tAccuracy: 93.53%\n",
      "17\tValidation loss: 1670.208252\tBest loss: 1670.208252\tAccuracy: 93.53%\n",
      "18\tValidation loss: 1124.142944\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "19\tValidation loss: 1710.754883\tBest loss: 1124.142944\tAccuracy: 92.09%\n",
      "20\tValidation loss: 1455.391602\tBest loss: 1124.142944\tAccuracy: 91.37%\n",
      "21\tValidation loss: 1482.861084\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "22\tValidation loss: 1530.482178\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "23\tValidation loss: 1517.485107\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "24\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "25\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "26\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "27\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "28\tValidation loss: 1517.481445\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "29\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "30\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "31\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "32\tValidation loss: 1517.481445\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "33\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "34\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "35\tValidation loss: 1517.481445\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "36\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "37\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "38\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "39\tValidation loss: 1517.481323\tBest loss: 1124.142944\tAccuracy: 92.81%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=500, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  12.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 18.987995\tBest loss: 18.987995\tAccuracy: 12.95%\n",
      "1\tValidation loss: 21.907055\tBest loss: 18.987995\tAccuracy: 25.18%\n",
      "2\tValidation loss: 24.702034\tBest loss: 18.987995\tAccuracy: 20.86%\n",
      "3\tValidation loss: 17.486546\tBest loss: 17.486546\tAccuracy: 33.09%\n",
      "4\tValidation loss: 14.201621\tBest loss: 14.201621\tAccuracy: 35.97%\n",
      "5\tValidation loss: 8.742226\tBest loss: 8.742226\tAccuracy: 48.92%\n",
      "6\tValidation loss: 3.343002\tBest loss: 3.343002\tAccuracy: 66.19%\n",
      "7\tValidation loss: 1.389047\tBest loss: 1.389047\tAccuracy: 74.10%\n",
      "8\tValidation loss: 1.012231\tBest loss: 1.012231\tAccuracy: 80.58%\n",
      "9\tValidation loss: 0.655459\tBest loss: 0.655459\tAccuracy: 83.45%\n",
      "10\tValidation loss: 0.595488\tBest loss: 0.595488\tAccuracy: 83.45%\n",
      "11\tValidation loss: 0.562617\tBest loss: 0.562617\tAccuracy: 83.45%\n",
      "12\tValidation loss: 0.534312\tBest loss: 0.534312\tAccuracy: 82.73%\n",
      "13\tValidation loss: 0.514142\tBest loss: 0.514142\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.498001\tBest loss: 0.498001\tAccuracy: 82.73%\n",
      "15\tValidation loss: 0.484709\tBest loss: 0.484709\tAccuracy: 83.45%\n",
      "16\tValidation loss: 0.473498\tBest loss: 0.473498\tAccuracy: 83.45%\n",
      "17\tValidation loss: 0.463910\tBest loss: 0.463910\tAccuracy: 83.45%\n",
      "18\tValidation loss: 0.455624\tBest loss: 0.455624\tAccuracy: 84.17%\n",
      "19\tValidation loss: 0.448407\tBest loss: 0.448407\tAccuracy: 84.17%\n",
      "20\tValidation loss: 0.442066\tBest loss: 0.442066\tAccuracy: 84.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\tValidation loss: 0.436457\tBest loss: 0.436457\tAccuracy: 84.17%\n",
      "22\tValidation loss: 0.431426\tBest loss: 0.431426\tAccuracy: 84.17%\n",
      "23\tValidation loss: 0.426865\tBest loss: 0.426865\tAccuracy: 84.89%\n",
      "24\tValidation loss: 0.422682\tBest loss: 0.422682\tAccuracy: 84.89%\n",
      "25\tValidation loss: 0.418814\tBest loss: 0.418814\tAccuracy: 84.89%\n",
      "26\tValidation loss: 0.415226\tBest loss: 0.415226\tAccuracy: 84.89%\n",
      "27\tValidation loss: 0.411875\tBest loss: 0.411875\tAccuracy: 84.89%\n",
      "28\tValidation loss: 0.408734\tBest loss: 0.408734\tAccuracy: 84.89%\n",
      "29\tValidation loss: 0.405778\tBest loss: 0.405778\tAccuracy: 84.89%\n",
      "30\tValidation loss: 0.402996\tBest loss: 0.402996\tAccuracy: 84.89%\n",
      "31\tValidation loss: 0.400363\tBest loss: 0.400363\tAccuracy: 85.61%\n",
      "32\tValidation loss: 0.397870\tBest loss: 0.397870\tAccuracy: 85.61%\n",
      "33\tValidation loss: 0.395503\tBest loss: 0.395503\tAccuracy: 87.05%\n",
      "34\tValidation loss: 0.393251\tBest loss: 0.393251\tAccuracy: 87.05%\n",
      "35\tValidation loss: 0.391105\tBest loss: 0.391105\tAccuracy: 87.05%\n",
      "36\tValidation loss: 0.389052\tBest loss: 0.389052\tAccuracy: 87.77%\n",
      "37\tValidation loss: 0.387088\tBest loss: 0.387088\tAccuracy: 87.77%\n",
      "38\tValidation loss: 0.385204\tBest loss: 0.385204\tAccuracy: 87.77%\n",
      "39\tValidation loss: 0.383395\tBest loss: 0.383395\tAccuracy: 87.77%\n",
      "40\tValidation loss: 0.381656\tBest loss: 0.381656\tAccuracy: 87.77%\n",
      "41\tValidation loss: 0.379979\tBest loss: 0.379979\tAccuracy: 87.77%\n",
      "42\tValidation loss: 0.378366\tBest loss: 0.378366\tAccuracy: 87.77%\n",
      "43\tValidation loss: 0.376805\tBest loss: 0.376805\tAccuracy: 87.77%\n",
      "44\tValidation loss: 0.375297\tBest loss: 0.375297\tAccuracy: 87.77%\n",
      "45\tValidation loss: 0.373845\tBest loss: 0.373845\tAccuracy: 88.49%\n",
      "46\tValidation loss: 0.372438\tBest loss: 0.372438\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.371075\tBest loss: 0.371075\tAccuracy: 89.21%\n",
      "48\tValidation loss: 0.369758\tBest loss: 0.369758\tAccuracy: 89.93%\n",
      "49\tValidation loss: 0.368481\tBest loss: 0.368481\tAccuracy: 89.93%\n",
      "50\tValidation loss: 0.367244\tBest loss: 0.367244\tAccuracy: 89.93%\n",
      "51\tValidation loss: 0.366050\tBest loss: 0.366050\tAccuracy: 89.93%\n",
      "52\tValidation loss: 0.364889\tBest loss: 0.364889\tAccuracy: 89.93%\n",
      "53\tValidation loss: 0.363766\tBest loss: 0.363766\tAccuracy: 89.93%\n",
      "54\tValidation loss: 0.362679\tBest loss: 0.362679\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.361627\tBest loss: 0.361627\tAccuracy: 89.93%\n",
      "56\tValidation loss: 0.360603\tBest loss: 0.360603\tAccuracy: 89.93%\n",
      "57\tValidation loss: 0.359617\tBest loss: 0.359617\tAccuracy: 89.93%\n",
      "58\tValidation loss: 0.358658\tBest loss: 0.358658\tAccuracy: 89.93%\n",
      "59\tValidation loss: 0.357731\tBest loss: 0.357731\tAccuracy: 89.93%\n",
      "60\tValidation loss: 0.356834\tBest loss: 0.356834\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.355966\tBest loss: 0.355966\tAccuracy: 89.93%\n",
      "62\tValidation loss: 0.355120\tBest loss: 0.355120\tAccuracy: 89.93%\n",
      "63\tValidation loss: 0.354307\tBest loss: 0.354307\tAccuracy: 89.93%\n",
      "64\tValidation loss: 0.353515\tBest loss: 0.353515\tAccuracy: 90.65%\n",
      "65\tValidation loss: 0.352749\tBest loss: 0.352749\tAccuracy: 90.65%\n",
      "66\tValidation loss: 0.352005\tBest loss: 0.352005\tAccuracy: 90.65%\n",
      "67\tValidation loss: 0.351287\tBest loss: 0.351287\tAccuracy: 90.65%\n",
      "68\tValidation loss: 0.350588\tBest loss: 0.350588\tAccuracy: 90.65%\n",
      "69\tValidation loss: 0.349911\tBest loss: 0.349911\tAccuracy: 90.65%\n",
      "70\tValidation loss: 0.349253\tBest loss: 0.349253\tAccuracy: 90.65%\n",
      "71\tValidation loss: 0.348616\tBest loss: 0.348616\tAccuracy: 90.65%\n",
      "72\tValidation loss: 0.347997\tBest loss: 0.347997\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.347399\tBest loss: 0.347399\tAccuracy: 90.65%\n",
      "74\tValidation loss: 0.346814\tBest loss: 0.346814\tAccuracy: 90.65%\n",
      "75\tValidation loss: 0.346249\tBest loss: 0.346249\tAccuracy: 90.65%\n",
      "76\tValidation loss: 0.345699\tBest loss: 0.345699\tAccuracy: 90.65%\n",
      "77\tValidation loss: 0.345166\tBest loss: 0.345166\tAccuracy: 90.65%\n",
      "78\tValidation loss: 0.344647\tBest loss: 0.344647\tAccuracy: 90.65%\n",
      "79\tValidation loss: 0.344143\tBest loss: 0.344143\tAccuracy: 90.65%\n",
      "80\tValidation loss: 0.343654\tBest loss: 0.343654\tAccuracy: 90.65%\n",
      "81\tValidation loss: 0.343177\tBest loss: 0.343177\tAccuracy: 90.65%\n",
      "82\tValidation loss: 0.342716\tBest loss: 0.342716\tAccuracy: 90.65%\n",
      "83\tValidation loss: 0.342266\tBest loss: 0.342266\tAccuracy: 90.65%\n",
      "84\tValidation loss: 0.341829\tBest loss: 0.341829\tAccuracy: 90.65%\n",
      "85\tValidation loss: 0.341406\tBest loss: 0.341406\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.340991\tBest loss: 0.340991\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.340586\tBest loss: 0.340586\tAccuracy: 90.65%\n",
      "88\tValidation loss: 0.340194\tBest loss: 0.340194\tAccuracy: 90.65%\n",
      "89\tValidation loss: 0.339810\tBest loss: 0.339810\tAccuracy: 90.65%\n",
      "90\tValidation loss: 0.339437\tBest loss: 0.339437\tAccuracy: 90.65%\n",
      "91\tValidation loss: 0.339075\tBest loss: 0.339075\tAccuracy: 90.65%\n",
      "92\tValidation loss: 0.338720\tBest loss: 0.338720\tAccuracy: 90.65%\n",
      "93\tValidation loss: 0.338376\tBest loss: 0.338376\tAccuracy: 90.65%\n",
      "94\tValidation loss: 0.338038\tBest loss: 0.338038\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.337712\tBest loss: 0.337712\tAccuracy: 90.65%\n",
      "96\tValidation loss: 0.337391\tBest loss: 0.337391\tAccuracy: 91.37%\n",
      "97\tValidation loss: 0.337082\tBest loss: 0.337082\tAccuracy: 91.37%\n",
      "98\tValidation loss: 0.336779\tBest loss: 0.336779\tAccuracy: 91.37%\n",
      "99\tValidation loss: 0.336480\tBest loss: 0.336480\tAccuracy: 91.37%\n",
      "100\tValidation loss: 0.336191\tBest loss: 0.336191\tAccuracy: 91.37%\n",
      "101\tValidation loss: 0.335910\tBest loss: 0.335910\tAccuracy: 91.37%\n",
      "102\tValidation loss: 0.335638\tBest loss: 0.335638\tAccuracy: 91.37%\n",
      "103\tValidation loss: 0.335372\tBest loss: 0.335372\tAccuracy: 91.37%\n",
      "104\tValidation loss: 0.335111\tBest loss: 0.335111\tAccuracy: 91.37%\n",
      "105\tValidation loss: 0.334856\tBest loss: 0.334856\tAccuracy: 91.37%\n",
      "106\tValidation loss: 0.334608\tBest loss: 0.334608\tAccuracy: 91.37%\n",
      "107\tValidation loss: 0.334366\tBest loss: 0.334366\tAccuracy: 91.37%\n",
      "108\tValidation loss: 0.334128\tBest loss: 0.334128\tAccuracy: 91.37%\n",
      "109\tValidation loss: 0.333898\tBest loss: 0.333898\tAccuracy: 91.37%\n",
      "110\tValidation loss: 0.333675\tBest loss: 0.333675\tAccuracy: 91.37%\n",
      "111\tValidation loss: 0.333454\tBest loss: 0.333454\tAccuracy: 91.37%\n",
      "112\tValidation loss: 0.333240\tBest loss: 0.333240\tAccuracy: 91.37%\n",
      "113\tValidation loss: 0.333033\tBest loss: 0.333033\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.332829\tBest loss: 0.332829\tAccuracy: 91.37%\n",
      "115\tValidation loss: 0.332632\tBest loss: 0.332632\tAccuracy: 91.37%\n",
      "116\tValidation loss: 0.332438\tBest loss: 0.332438\tAccuracy: 91.37%\n",
      "117\tValidation loss: 0.332249\tBest loss: 0.332249\tAccuracy: 91.37%\n",
      "118\tValidation loss: 0.332065\tBest loss: 0.332065\tAccuracy: 91.37%\n",
      "119\tValidation loss: 0.331889\tBest loss: 0.331889\tAccuracy: 91.37%\n",
      "120\tValidation loss: 0.331714\tBest loss: 0.331714\tAccuracy: 91.37%\n",
      "121\tValidation loss: 0.331541\tBest loss: 0.331541\tAccuracy: 91.37%\n",
      "122\tValidation loss: 0.331375\tBest loss: 0.331375\tAccuracy: 90.65%\n",
      "123\tValidation loss: 0.331216\tBest loss: 0.331216\tAccuracy: 90.65%\n",
      "124\tValidation loss: 0.331057\tBest loss: 0.331057\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.330904\tBest loss: 0.330904\tAccuracy: 90.65%\n",
      "126\tValidation loss: 0.330755\tBest loss: 0.330755\tAccuracy: 90.65%\n",
      "127\tValidation loss: 0.330609\tBest loss: 0.330609\tAccuracy: 90.65%\n",
      "128\tValidation loss: 0.330468\tBest loss: 0.330468\tAccuracy: 90.65%\n",
      "129\tValidation loss: 0.330332\tBest loss: 0.330332\tAccuracy: 90.65%\n",
      "130\tValidation loss: 0.330196\tBest loss: 0.330196\tAccuracy: 90.65%\n",
      "131\tValidation loss: 0.330067\tBest loss: 0.330067\tAccuracy: 90.65%\n",
      "132\tValidation loss: 0.329939\tBest loss: 0.329939\tAccuracy: 90.65%\n",
      "133\tValidation loss: 0.329816\tBest loss: 0.329816\tAccuracy: 90.65%\n",
      "134\tValidation loss: 0.329697\tBest loss: 0.329697\tAccuracy: 90.65%\n",
      "135\tValidation loss: 0.329582\tBest loss: 0.329582\tAccuracy: 90.65%\n",
      "136\tValidation loss: 0.329465\tBest loss: 0.329465\tAccuracy: 90.65%\n",
      "137\tValidation loss: 0.329356\tBest loss: 0.329356\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.329250\tBest loss: 0.329250\tAccuracy: 90.65%\n",
      "139\tValidation loss: 0.329147\tBest loss: 0.329147\tAccuracy: 90.65%\n",
      "140\tValidation loss: 0.329044\tBest loss: 0.329044\tAccuracy: 90.65%\n",
      "141\tValidation loss: 0.328947\tBest loss: 0.328947\tAccuracy: 90.65%\n",
      "142\tValidation loss: 0.328853\tBest loss: 0.328853\tAccuracy: 90.65%\n",
      "143\tValidation loss: 0.328759\tBest loss: 0.328759\tAccuracy: 90.65%\n",
      "144\tValidation loss: 0.328670\tBest loss: 0.328670\tAccuracy: 90.65%\n",
      "145\tValidation loss: 0.328584\tBest loss: 0.328584\tAccuracy: 90.65%\n",
      "146\tValidation loss: 0.328503\tBest loss: 0.328503\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\tValidation loss: 0.328421\tBest loss: 0.328421\tAccuracy: 90.65%\n",
      "148\tValidation loss: 0.328343\tBest loss: 0.328343\tAccuracy: 90.65%\n",
      "149\tValidation loss: 0.328268\tBest loss: 0.328268\tAccuracy: 90.65%\n",
      "150\tValidation loss: 0.328193\tBest loss: 0.328193\tAccuracy: 90.65%\n",
      "151\tValidation loss: 0.328123\tBest loss: 0.328123\tAccuracy: 90.65%\n",
      "152\tValidation loss: 0.328054\tBest loss: 0.328054\tAccuracy: 90.65%\n",
      "153\tValidation loss: 0.327987\tBest loss: 0.327987\tAccuracy: 90.65%\n",
      "154\tValidation loss: 0.327926\tBest loss: 0.327926\tAccuracy: 90.65%\n",
      "155\tValidation loss: 0.327865\tBest loss: 0.327865\tAccuracy: 90.65%\n",
      "156\tValidation loss: 0.327805\tBest loss: 0.327805\tAccuracy: 90.65%\n",
      "157\tValidation loss: 0.327750\tBest loss: 0.327750\tAccuracy: 90.65%\n",
      "158\tValidation loss: 0.327695\tBest loss: 0.327695\tAccuracy: 90.65%\n",
      "159\tValidation loss: 0.327644\tBest loss: 0.327644\tAccuracy: 90.65%\n",
      "160\tValidation loss: 0.327595\tBest loss: 0.327595\tAccuracy: 90.65%\n",
      "161\tValidation loss: 0.327547\tBest loss: 0.327547\tAccuracy: 90.65%\n",
      "162\tValidation loss: 0.327500\tBest loss: 0.327500\tAccuracy: 90.65%\n",
      "163\tValidation loss: 0.327455\tBest loss: 0.327455\tAccuracy: 90.65%\n",
      "164\tValidation loss: 0.327414\tBest loss: 0.327414\tAccuracy: 90.65%\n",
      "165\tValidation loss: 0.327375\tBest loss: 0.327375\tAccuracy: 90.65%\n",
      "166\tValidation loss: 0.327338\tBest loss: 0.327338\tAccuracy: 90.65%\n",
      "167\tValidation loss: 0.327302\tBest loss: 0.327302\tAccuracy: 90.65%\n",
      "168\tValidation loss: 0.327269\tBest loss: 0.327269\tAccuracy: 90.65%\n",
      "169\tValidation loss: 0.327239\tBest loss: 0.327239\tAccuracy: 90.65%\n",
      "170\tValidation loss: 0.327209\tBest loss: 0.327209\tAccuracy: 90.65%\n",
      "171\tValidation loss: 0.327181\tBest loss: 0.327181\tAccuracy: 90.65%\n",
      "172\tValidation loss: 0.327153\tBest loss: 0.327153\tAccuracy: 90.65%\n",
      "173\tValidation loss: 0.327129\tBest loss: 0.327129\tAccuracy: 90.65%\n",
      "174\tValidation loss: 0.327105\tBest loss: 0.327105\tAccuracy: 90.65%\n",
      "175\tValidation loss: 0.327083\tBest loss: 0.327083\tAccuracy: 90.65%\n",
      "176\tValidation loss: 0.327064\tBest loss: 0.327064\tAccuracy: 90.65%\n",
      "177\tValidation loss: 0.327047\tBest loss: 0.327047\tAccuracy: 90.65%\n",
      "178\tValidation loss: 0.327030\tBest loss: 0.327030\tAccuracy: 90.65%\n",
      "179\tValidation loss: 0.327016\tBest loss: 0.327016\tAccuracy: 90.65%\n",
      "180\tValidation loss: 0.327003\tBest loss: 0.327003\tAccuracy: 90.65%\n",
      "181\tValidation loss: 0.326993\tBest loss: 0.326993\tAccuracy: 90.65%\n",
      "182\tValidation loss: 0.326982\tBest loss: 0.326982\tAccuracy: 90.65%\n",
      "183\tValidation loss: 0.326975\tBest loss: 0.326975\tAccuracy: 90.65%\n",
      "184\tValidation loss: 0.326966\tBest loss: 0.326966\tAccuracy: 90.65%\n",
      "185\tValidation loss: 0.326960\tBest loss: 0.326960\tAccuracy: 90.65%\n",
      "186\tValidation loss: 0.326958\tBest loss: 0.326958\tAccuracy: 90.65%\n",
      "187\tValidation loss: 0.326953\tBest loss: 0.326953\tAccuracy: 90.65%\n",
      "188\tValidation loss: 0.326949\tBest loss: 0.326949\tAccuracy: 90.65%\n",
      "189\tValidation loss: 0.326947\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "190\tValidation loss: 0.326949\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "191\tValidation loss: 0.326949\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "192\tValidation loss: 0.326952\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "193\tValidation loss: 0.326958\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "194\tValidation loss: 0.326963\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "195\tValidation loss: 0.326969\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "196\tValidation loss: 0.326977\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "197\tValidation loss: 0.326982\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "198\tValidation loss: 0.326995\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "199\tValidation loss: 0.327006\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "200\tValidation loss: 0.327018\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "201\tValidation loss: 0.327031\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "202\tValidation loss: 0.327045\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "203\tValidation loss: 0.327059\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "204\tValidation loss: 0.327076\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "205\tValidation loss: 0.327092\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "206\tValidation loss: 0.327110\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "207\tValidation loss: 0.327126\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "208\tValidation loss: 0.327146\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "209\tValidation loss: 0.327166\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "210\tValidation loss: 0.327188\tBest loss: 0.326947\tAccuracy: 90.65%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  17.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 19.115341\tBest loss: 19.115341\tAccuracy: 17.27%\n",
      "1\tValidation loss: 25.561218\tBest loss: 19.115341\tAccuracy: 23.74%\n",
      "2\tValidation loss: 24.547226\tBest loss: 19.115341\tAccuracy: 25.18%\n",
      "3\tValidation loss: 19.428862\tBest loss: 19.115341\tAccuracy: 29.50%\n",
      "4\tValidation loss: 10.759021\tBest loss: 10.759021\tAccuracy: 28.78%\n",
      "5\tValidation loss: 5.092497\tBest loss: 5.092497\tAccuracy: 53.96%\n",
      "6\tValidation loss: 3.303063\tBest loss: 3.303063\tAccuracy: 55.40%\n",
      "7\tValidation loss: 1.871143\tBest loss: 1.871143\tAccuracy: 69.06%\n",
      "8\tValidation loss: 1.380992\tBest loss: 1.380992\tAccuracy: 76.26%\n",
      "9\tValidation loss: 1.170273\tBest loss: 1.170273\tAccuracy: 81.29%\n",
      "10\tValidation loss: 0.671942\tBest loss: 0.671942\tAccuracy: 82.01%\n",
      "11\tValidation loss: 0.568119\tBest loss: 0.568119\tAccuracy: 84.17%\n",
      "12\tValidation loss: 0.545298\tBest loss: 0.545298\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.527933\tBest loss: 0.527933\tAccuracy: 84.17%\n",
      "14\tValidation loss: 0.510167\tBest loss: 0.510167\tAccuracy: 83.45%\n",
      "15\tValidation loss: 0.495285\tBest loss: 0.495285\tAccuracy: 83.45%\n",
      "16\tValidation loss: 0.482710\tBest loss: 0.482710\tAccuracy: 82.73%\n",
      "17\tValidation loss: 0.471930\tBest loss: 0.471930\tAccuracy: 83.45%\n",
      "18\tValidation loss: 0.462570\tBest loss: 0.462570\tAccuracy: 83.45%\n",
      "19\tValidation loss: 0.454323\tBest loss: 0.454323\tAccuracy: 83.45%\n",
      "20\tValidation loss: 0.446980\tBest loss: 0.446980\tAccuracy: 83.45%\n",
      "21\tValidation loss: 0.440357\tBest loss: 0.440357\tAccuracy: 83.45%\n",
      "22\tValidation loss: 0.434343\tBest loss: 0.434343\tAccuracy: 84.89%\n",
      "23\tValidation loss: 0.428834\tBest loss: 0.428834\tAccuracy: 84.89%\n",
      "24\tValidation loss: 0.423772\tBest loss: 0.423772\tAccuracy: 84.89%\n",
      "25\tValidation loss: 0.419093\tBest loss: 0.419093\tAccuracy: 85.61%\n",
      "26\tValidation loss: 0.414761\tBest loss: 0.414761\tAccuracy: 85.61%\n",
      "27\tValidation loss: 0.410736\tBest loss: 0.410736\tAccuracy: 86.33%\n",
      "28\tValidation loss: 0.406991\tBest loss: 0.406991\tAccuracy: 86.33%\n",
      "29\tValidation loss: 0.403485\tBest loss: 0.403485\tAccuracy: 86.33%\n",
      "30\tValidation loss: 0.400205\tBest loss: 0.400205\tAccuracy: 86.33%\n",
      "31\tValidation loss: 0.397112\tBest loss: 0.397112\tAccuracy: 85.61%\n",
      "32\tValidation loss: 0.394203\tBest loss: 0.394203\tAccuracy: 85.61%\n",
      "33\tValidation loss: 0.391452\tBest loss: 0.391452\tAccuracy: 85.61%\n",
      "34\tValidation loss: 0.388841\tBest loss: 0.388841\tAccuracy: 85.61%\n",
      "35\tValidation loss: 0.386363\tBest loss: 0.386363\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.384010\tBest loss: 0.384010\tAccuracy: 85.61%\n",
      "37\tValidation loss: 0.381762\tBest loss: 0.381762\tAccuracy: 85.61%\n",
      "38\tValidation loss: 0.379618\tBest loss: 0.379618\tAccuracy: 85.61%\n",
      "39\tValidation loss: 0.377570\tBest loss: 0.377570\tAccuracy: 85.61%\n",
      "40\tValidation loss: 0.375608\tBest loss: 0.375608\tAccuracy: 85.61%\n",
      "41\tValidation loss: 0.373733\tBest loss: 0.373733\tAccuracy: 85.61%\n",
      "42\tValidation loss: 0.371934\tBest loss: 0.371934\tAccuracy: 85.61%\n",
      "43\tValidation loss: 0.370209\tBest loss: 0.370209\tAccuracy: 85.61%\n",
      "44\tValidation loss: 0.368552\tBest loss: 0.368552\tAccuracy: 85.61%\n",
      "45\tValidation loss: 0.366960\tBest loss: 0.366960\tAccuracy: 86.33%\n",
      "46\tValidation loss: 0.365433\tBest loss: 0.365433\tAccuracy: 86.33%\n",
      "47\tValidation loss: 0.363959\tBest loss: 0.363959\tAccuracy: 86.33%\n",
      "48\tValidation loss: 0.362542\tBest loss: 0.362542\tAccuracy: 86.33%\n",
      "49\tValidation loss: 0.361176\tBest loss: 0.361176\tAccuracy: 86.33%\n",
      "50\tValidation loss: 0.359863\tBest loss: 0.359863\tAccuracy: 86.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\tValidation loss: 0.358596\tBest loss: 0.358596\tAccuracy: 86.33%\n",
      "52\tValidation loss: 0.357372\tBest loss: 0.357372\tAccuracy: 86.33%\n",
      "53\tValidation loss: 0.356191\tBest loss: 0.356191\tAccuracy: 86.33%\n",
      "54\tValidation loss: 0.355048\tBest loss: 0.355048\tAccuracy: 86.33%\n",
      "55\tValidation loss: 0.353945\tBest loss: 0.353945\tAccuracy: 86.33%\n",
      "56\tValidation loss: 0.352878\tBest loss: 0.352878\tAccuracy: 86.33%\n",
      "57\tValidation loss: 0.351845\tBest loss: 0.351845\tAccuracy: 86.33%\n",
      "58\tValidation loss: 0.350844\tBest loss: 0.350844\tAccuracy: 86.33%\n",
      "59\tValidation loss: 0.349876\tBest loss: 0.349876\tAccuracy: 86.33%\n",
      "60\tValidation loss: 0.348938\tBest loss: 0.348938\tAccuracy: 86.33%\n",
      "61\tValidation loss: 0.348030\tBest loss: 0.348030\tAccuracy: 86.33%\n",
      "62\tValidation loss: 0.347145\tBest loss: 0.347145\tAccuracy: 87.05%\n",
      "63\tValidation loss: 0.346286\tBest loss: 0.346286\tAccuracy: 87.05%\n",
      "64\tValidation loss: 0.345457\tBest loss: 0.345457\tAccuracy: 87.05%\n",
      "65\tValidation loss: 0.344647\tBest loss: 0.344647\tAccuracy: 87.05%\n",
      "66\tValidation loss: 0.343860\tBest loss: 0.343860\tAccuracy: 87.77%\n",
      "67\tValidation loss: 0.343098\tBest loss: 0.343098\tAccuracy: 88.49%\n",
      "68\tValidation loss: 0.342359\tBest loss: 0.342359\tAccuracy: 89.21%\n",
      "69\tValidation loss: 0.341638\tBest loss: 0.341638\tAccuracy: 89.21%\n",
      "70\tValidation loss: 0.340937\tBest loss: 0.340937\tAccuracy: 89.21%\n",
      "71\tValidation loss: 0.340254\tBest loss: 0.340254\tAccuracy: 89.21%\n",
      "72\tValidation loss: 0.339587\tBest loss: 0.339587\tAccuracy: 89.21%\n",
      "73\tValidation loss: 0.338943\tBest loss: 0.338943\tAccuracy: 89.21%\n",
      "74\tValidation loss: 0.338314\tBest loss: 0.338314\tAccuracy: 89.21%\n",
      "75\tValidation loss: 0.337699\tBest loss: 0.337699\tAccuracy: 89.21%\n",
      "76\tValidation loss: 0.337103\tBest loss: 0.337103\tAccuracy: 89.21%\n",
      "77\tValidation loss: 0.336520\tBest loss: 0.336520\tAccuracy: 89.21%\n",
      "78\tValidation loss: 0.335953\tBest loss: 0.335953\tAccuracy: 89.21%\n",
      "79\tValidation loss: 0.335399\tBest loss: 0.335399\tAccuracy: 88.49%\n",
      "80\tValidation loss: 0.334860\tBest loss: 0.334860\tAccuracy: 88.49%\n",
      "81\tValidation loss: 0.334336\tBest loss: 0.334336\tAccuracy: 88.49%\n",
      "82\tValidation loss: 0.333825\tBest loss: 0.333825\tAccuracy: 88.49%\n",
      "83\tValidation loss: 0.333326\tBest loss: 0.333326\tAccuracy: 88.49%\n",
      "84\tValidation loss: 0.332838\tBest loss: 0.332838\tAccuracy: 88.49%\n",
      "85\tValidation loss: 0.332364\tBest loss: 0.332364\tAccuracy: 88.49%\n",
      "86\tValidation loss: 0.331903\tBest loss: 0.331903\tAccuracy: 88.49%\n",
      "87\tValidation loss: 0.331450\tBest loss: 0.331450\tAccuracy: 88.49%\n",
      "88\tValidation loss: 0.331007\tBest loss: 0.331007\tAccuracy: 88.49%\n",
      "89\tValidation loss: 0.330580\tBest loss: 0.330580\tAccuracy: 88.49%\n",
      "90\tValidation loss: 0.330162\tBest loss: 0.330162\tAccuracy: 88.49%\n",
      "91\tValidation loss: 0.329756\tBest loss: 0.329756\tAccuracy: 88.49%\n",
      "92\tValidation loss: 0.329358\tBest loss: 0.329358\tAccuracy: 88.49%\n",
      "93\tValidation loss: 0.328970\tBest loss: 0.328970\tAccuracy: 88.49%\n",
      "94\tValidation loss: 0.328593\tBest loss: 0.328593\tAccuracy: 88.49%\n",
      "95\tValidation loss: 0.328225\tBest loss: 0.328225\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.327863\tBest loss: 0.327863\tAccuracy: 88.49%\n",
      "97\tValidation loss: 0.327513\tBest loss: 0.327513\tAccuracy: 88.49%\n",
      "98\tValidation loss: 0.327168\tBest loss: 0.327168\tAccuracy: 88.49%\n",
      "99\tValidation loss: 0.326839\tBest loss: 0.326839\tAccuracy: 88.49%\n",
      "100\tValidation loss: 0.326514\tBest loss: 0.326514\tAccuracy: 88.49%\n",
      "101\tValidation loss: 0.326199\tBest loss: 0.326199\tAccuracy: 88.49%\n",
      "102\tValidation loss: 0.325891\tBest loss: 0.325891\tAccuracy: 88.49%\n",
      "103\tValidation loss: 0.325593\tBest loss: 0.325593\tAccuracy: 88.49%\n",
      "104\tValidation loss: 0.325299\tBest loss: 0.325299\tAccuracy: 88.49%\n",
      "105\tValidation loss: 0.325015\tBest loss: 0.325015\tAccuracy: 88.49%\n",
      "106\tValidation loss: 0.324740\tBest loss: 0.324740\tAccuracy: 88.49%\n",
      "107\tValidation loss: 0.324467\tBest loss: 0.324467\tAccuracy: 88.49%\n",
      "108\tValidation loss: 0.324205\tBest loss: 0.324205\tAccuracy: 88.49%\n",
      "109\tValidation loss: 0.323951\tBest loss: 0.323951\tAccuracy: 88.49%\n",
      "110\tValidation loss: 0.323701\tBest loss: 0.323701\tAccuracy: 88.49%\n",
      "111\tValidation loss: 0.323457\tBest loss: 0.323457\tAccuracy: 88.49%\n",
      "112\tValidation loss: 0.323222\tBest loss: 0.323222\tAccuracy: 88.49%\n",
      "113\tValidation loss: 0.322992\tBest loss: 0.322992\tAccuracy: 88.49%\n",
      "114\tValidation loss: 0.322770\tBest loss: 0.322770\tAccuracy: 88.49%\n",
      "115\tValidation loss: 0.322552\tBest loss: 0.322552\tAccuracy: 89.21%\n",
      "116\tValidation loss: 0.322342\tBest loss: 0.322342\tAccuracy: 89.21%\n",
      "117\tValidation loss: 0.322135\tBest loss: 0.322135\tAccuracy: 89.21%\n",
      "118\tValidation loss: 0.321932\tBest loss: 0.321932\tAccuracy: 89.21%\n",
      "119\tValidation loss: 0.321739\tBest loss: 0.321739\tAccuracy: 89.21%\n",
      "120\tValidation loss: 0.321552\tBest loss: 0.321552\tAccuracy: 89.21%\n",
      "121\tValidation loss: 0.321370\tBest loss: 0.321370\tAccuracy: 89.21%\n",
      "122\tValidation loss: 0.321190\tBest loss: 0.321190\tAccuracy: 89.21%\n",
      "123\tValidation loss: 0.321014\tBest loss: 0.321014\tAccuracy: 89.21%\n",
      "124\tValidation loss: 0.320849\tBest loss: 0.320849\tAccuracy: 89.21%\n",
      "125\tValidation loss: 0.320682\tBest loss: 0.320682\tAccuracy: 89.21%\n",
      "126\tValidation loss: 0.320525\tBest loss: 0.320525\tAccuracy: 89.21%\n",
      "127\tValidation loss: 0.320371\tBest loss: 0.320371\tAccuracy: 89.21%\n",
      "128\tValidation loss: 0.320221\tBest loss: 0.320221\tAccuracy: 89.21%\n",
      "129\tValidation loss: 0.320077\tBest loss: 0.320077\tAccuracy: 89.21%\n",
      "130\tValidation loss: 0.319935\tBest loss: 0.319935\tAccuracy: 89.21%\n",
      "131\tValidation loss: 0.319798\tBest loss: 0.319798\tAccuracy: 89.21%\n",
      "132\tValidation loss: 0.319666\tBest loss: 0.319666\tAccuracy: 89.21%\n",
      "133\tValidation loss: 0.319535\tBest loss: 0.319535\tAccuracy: 89.21%\n",
      "134\tValidation loss: 0.319410\tBest loss: 0.319410\tAccuracy: 89.21%\n",
      "135\tValidation loss: 0.319289\tBest loss: 0.319289\tAccuracy: 89.21%\n",
      "136\tValidation loss: 0.319173\tBest loss: 0.319173\tAccuracy: 89.21%\n",
      "137\tValidation loss: 0.319058\tBest loss: 0.319058\tAccuracy: 89.21%\n",
      "138\tValidation loss: 0.318947\tBest loss: 0.318947\tAccuracy: 88.49%\n",
      "139\tValidation loss: 0.318840\tBest loss: 0.318840\tAccuracy: 88.49%\n",
      "140\tValidation loss: 0.318733\tBest loss: 0.318733\tAccuracy: 88.49%\n",
      "141\tValidation loss: 0.318635\tBest loss: 0.318635\tAccuracy: 88.49%\n",
      "142\tValidation loss: 0.318538\tBest loss: 0.318538\tAccuracy: 88.49%\n",
      "143\tValidation loss: 0.318444\tBest loss: 0.318444\tAccuracy: 88.49%\n",
      "144\tValidation loss: 0.318354\tBest loss: 0.318354\tAccuracy: 88.49%\n",
      "145\tValidation loss: 0.318267\tBest loss: 0.318267\tAccuracy: 88.49%\n",
      "146\tValidation loss: 0.318178\tBest loss: 0.318178\tAccuracy: 88.49%\n",
      "147\tValidation loss: 0.318101\tBest loss: 0.318101\tAccuracy: 88.49%\n",
      "148\tValidation loss: 0.318022\tBest loss: 0.318022\tAccuracy: 88.49%\n",
      "149\tValidation loss: 0.317946\tBest loss: 0.317946\tAccuracy: 88.49%\n",
      "150\tValidation loss: 0.317873\tBest loss: 0.317873\tAccuracy: 88.49%\n",
      "151\tValidation loss: 0.317800\tBest loss: 0.317800\tAccuracy: 88.49%\n",
      "152\tValidation loss: 0.317730\tBest loss: 0.317730\tAccuracy: 88.49%\n",
      "153\tValidation loss: 0.317664\tBest loss: 0.317664\tAccuracy: 88.49%\n",
      "154\tValidation loss: 0.317600\tBest loss: 0.317600\tAccuracy: 88.49%\n",
      "155\tValidation loss: 0.317537\tBest loss: 0.317537\tAccuracy: 88.49%\n",
      "156\tValidation loss: 0.317480\tBest loss: 0.317480\tAccuracy: 88.49%\n",
      "157\tValidation loss: 0.317421\tBest loss: 0.317421\tAccuracy: 88.49%\n",
      "158\tValidation loss: 0.317367\tBest loss: 0.317367\tAccuracy: 88.49%\n",
      "159\tValidation loss: 0.317313\tBest loss: 0.317313\tAccuracy: 88.49%\n",
      "160\tValidation loss: 0.317260\tBest loss: 0.317260\tAccuracy: 88.49%\n",
      "161\tValidation loss: 0.317210\tBest loss: 0.317210\tAccuracy: 88.49%\n",
      "162\tValidation loss: 0.317163\tBest loss: 0.317163\tAccuracy: 88.49%\n",
      "163\tValidation loss: 0.317121\tBest loss: 0.317121\tAccuracy: 88.49%\n",
      "164\tValidation loss: 0.317076\tBest loss: 0.317076\tAccuracy: 88.49%\n",
      "165\tValidation loss: 0.317035\tBest loss: 0.317035\tAccuracy: 88.49%\n",
      "166\tValidation loss: 0.316994\tBest loss: 0.316994\tAccuracy: 88.49%\n",
      "167\tValidation loss: 0.316954\tBest loss: 0.316954\tAccuracy: 88.49%\n",
      "168\tValidation loss: 0.316919\tBest loss: 0.316919\tAccuracy: 88.49%\n",
      "169\tValidation loss: 0.316884\tBest loss: 0.316884\tAccuracy: 88.49%\n",
      "170\tValidation loss: 0.316851\tBest loss: 0.316851\tAccuracy: 88.49%\n",
      "171\tValidation loss: 0.316814\tBest loss: 0.316814\tAccuracy: 88.49%\n",
      "172\tValidation loss: 0.316786\tBest loss: 0.316786\tAccuracy: 88.49%\n",
      "173\tValidation loss: 0.316755\tBest loss: 0.316755\tAccuracy: 88.49%\n",
      "174\tValidation loss: 0.316729\tBest loss: 0.316729\tAccuracy: 88.49%\n",
      "175\tValidation loss: 0.316702\tBest loss: 0.316702\tAccuracy: 88.49%\n",
      "176\tValidation loss: 0.316676\tBest loss: 0.316676\tAccuracy: 88.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\tValidation loss: 0.316651\tBest loss: 0.316651\tAccuracy: 88.49%\n",
      "178\tValidation loss: 0.316629\tBest loss: 0.316629\tAccuracy: 88.49%\n",
      "179\tValidation loss: 0.316606\tBest loss: 0.316606\tAccuracy: 88.49%\n",
      "180\tValidation loss: 0.316584\tBest loss: 0.316584\tAccuracy: 88.49%\n",
      "181\tValidation loss: 0.316567\tBest loss: 0.316567\tAccuracy: 88.49%\n",
      "182\tValidation loss: 0.316550\tBest loss: 0.316550\tAccuracy: 88.49%\n",
      "183\tValidation loss: 0.316534\tBest loss: 0.316534\tAccuracy: 88.49%\n",
      "184\tValidation loss: 0.316517\tBest loss: 0.316517\tAccuracy: 88.49%\n",
      "185\tValidation loss: 0.316503\tBest loss: 0.316503\tAccuracy: 88.49%\n",
      "186\tValidation loss: 0.316487\tBest loss: 0.316487\tAccuracy: 88.49%\n",
      "187\tValidation loss: 0.316477\tBest loss: 0.316477\tAccuracy: 88.49%\n",
      "188\tValidation loss: 0.316463\tBest loss: 0.316463\tAccuracy: 88.49%\n",
      "189\tValidation loss: 0.316453\tBest loss: 0.316453\tAccuracy: 88.49%\n",
      "190\tValidation loss: 0.316441\tBest loss: 0.316441\tAccuracy: 88.49%\n",
      "191\tValidation loss: 0.316430\tBest loss: 0.316430\tAccuracy: 88.49%\n",
      "192\tValidation loss: 0.316424\tBest loss: 0.316424\tAccuracy: 88.49%\n",
      "193\tValidation loss: 0.316416\tBest loss: 0.316416\tAccuracy: 88.49%\n",
      "194\tValidation loss: 0.316410\tBest loss: 0.316410\tAccuracy: 88.49%\n",
      "195\tValidation loss: 0.316402\tBest loss: 0.316402\tAccuracy: 88.49%\n",
      "196\tValidation loss: 0.316397\tBest loss: 0.316397\tAccuracy: 88.49%\n",
      "197\tValidation loss: 0.316392\tBest loss: 0.316392\tAccuracy: 88.49%\n",
      "198\tValidation loss: 0.316383\tBest loss: 0.316383\tAccuracy: 88.49%\n",
      "199\tValidation loss: 0.316384\tBest loss: 0.316383\tAccuracy: 88.49%\n",
      "200\tValidation loss: 0.316379\tBest loss: 0.316379\tAccuracy: 88.49%\n",
      "201\tValidation loss: 0.316380\tBest loss: 0.316379\tAccuracy: 88.49%\n",
      "202\tValidation loss: 0.316377\tBest loss: 0.316377\tAccuracy: 88.49%\n",
      "203\tValidation loss: 0.316375\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "204\tValidation loss: 0.316375\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "205\tValidation loss: 0.316378\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "206\tValidation loss: 0.316376\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "207\tValidation loss: 0.316378\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "208\tValidation loss: 0.316379\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "209\tValidation loss: 0.316378\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "210\tValidation loss: 0.316381\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "211\tValidation loss: 0.316386\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "212\tValidation loss: 0.316388\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "213\tValidation loss: 0.316392\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "214\tValidation loss: 0.316395\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "215\tValidation loss: 0.316402\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "216\tValidation loss: 0.316404\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "217\tValidation loss: 0.316409\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "218\tValidation loss: 0.316412\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "219\tValidation loss: 0.316419\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "220\tValidation loss: 0.316425\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "221\tValidation loss: 0.316431\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "222\tValidation loss: 0.316435\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "223\tValidation loss: 0.316442\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "224\tValidation loss: 0.316448\tBest loss: 0.316375\tAccuracy: 88.49%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  18.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 18.940306\tBest loss: 18.940306\tAccuracy: 14.39%\n",
      "1\tValidation loss: 22.819454\tBest loss: 18.940306\tAccuracy: 28.78%\n",
      "2\tValidation loss: 27.893898\tBest loss: 18.940306\tAccuracy: 17.27%\n",
      "3\tValidation loss: 20.607983\tBest loss: 18.940306\tAccuracy: 28.06%\n",
      "4\tValidation loss: 9.974064\tBest loss: 9.974064\tAccuracy: 35.25%\n",
      "5\tValidation loss: 6.411111\tBest loss: 6.411111\tAccuracy: 43.88%\n",
      "6\tValidation loss: 3.063089\tBest loss: 3.063089\tAccuracy: 69.06%\n",
      "7\tValidation loss: 1.645670\tBest loss: 1.645670\tAccuracy: 73.38%\n",
      "8\tValidation loss: 0.813450\tBest loss: 0.813450\tAccuracy: 79.86%\n",
      "9\tValidation loss: 0.606113\tBest loss: 0.606113\tAccuracy: 82.01%\n",
      "10\tValidation loss: 0.551284\tBest loss: 0.551284\tAccuracy: 85.61%\n",
      "11\tValidation loss: 0.519023\tBest loss: 0.519023\tAccuracy: 84.89%\n",
      "12\tValidation loss: 0.497868\tBest loss: 0.497868\tAccuracy: 84.89%\n",
      "13\tValidation loss: 0.482144\tBest loss: 0.482144\tAccuracy: 85.61%\n",
      "14\tValidation loss: 0.469331\tBest loss: 0.469331\tAccuracy: 85.61%\n",
      "15\tValidation loss: 0.458477\tBest loss: 0.458477\tAccuracy: 85.61%\n",
      "16\tValidation loss: 0.449154\tBest loss: 0.449154\tAccuracy: 85.61%\n",
      "17\tValidation loss: 0.441099\tBest loss: 0.441099\tAccuracy: 86.33%\n",
      "18\tValidation loss: 0.434109\tBest loss: 0.434109\tAccuracy: 87.05%\n",
      "19\tValidation loss: 0.428040\tBest loss: 0.428040\tAccuracy: 87.77%\n",
      "20\tValidation loss: 0.422767\tBest loss: 0.422767\tAccuracy: 87.77%\n",
      "21\tValidation loss: 0.418190\tBest loss: 0.418190\tAccuracy: 87.77%\n",
      "22\tValidation loss: 0.414231\tBest loss: 0.414231\tAccuracy: 88.49%\n",
      "23\tValidation loss: 0.410813\tBest loss: 0.410813\tAccuracy: 89.21%\n",
      "24\tValidation loss: 0.407871\tBest loss: 0.407871\tAccuracy: 89.93%\n",
      "25\tValidation loss: 0.405350\tBest loss: 0.405350\tAccuracy: 89.21%\n",
      "26\tValidation loss: 0.403199\tBest loss: 0.403199\tAccuracy: 89.21%\n",
      "27\tValidation loss: 0.401373\tBest loss: 0.401373\tAccuracy: 89.21%\n",
      "28\tValidation loss: 0.399832\tBest loss: 0.399832\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.398540\tBest loss: 0.398540\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.397471\tBest loss: 0.397471\tAccuracy: 89.21%\n",
      "31\tValidation loss: 0.396592\tBest loss: 0.396592\tAccuracy: 89.21%\n",
      "32\tValidation loss: 0.395885\tBest loss: 0.395885\tAccuracy: 89.21%\n",
      "33\tValidation loss: 0.395321\tBest loss: 0.395321\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.394890\tBest loss: 0.394890\tAccuracy: 89.21%\n",
      "35\tValidation loss: 0.394573\tBest loss: 0.394573\tAccuracy: 89.21%\n",
      "36\tValidation loss: 0.394359\tBest loss: 0.394359\tAccuracy: 89.21%\n",
      "37\tValidation loss: 0.394234\tBest loss: 0.394234\tAccuracy: 89.21%\n",
      "38\tValidation loss: 0.394183\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "39\tValidation loss: 0.394207\tBest loss: 0.394183\tAccuracy: 89.21%\n",
      "40\tValidation loss: 0.394289\tBest loss: 0.394183\tAccuracy: 89.21%\n",
      "41\tValidation loss: 0.394428\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "42\tValidation loss: 0.394615\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "43\tValidation loss: 0.394844\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "44\tValidation loss: 0.395112\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "45\tValidation loss: 0.395413\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "46\tValidation loss: 0.395744\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.396104\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "48\tValidation loss: 0.396483\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "49\tValidation loss: 0.396888\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.397309\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "51\tValidation loss: 0.397747\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "52\tValidation loss: 0.398203\tBest loss: 0.394183\tAccuracy: 87.77%\n",
      "53\tValidation loss: 0.398669\tBest loss: 0.394183\tAccuracy: 87.77%\n",
      "54\tValidation loss: 0.399144\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "55\tValidation loss: 0.399635\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "56\tValidation loss: 0.400129\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.400634\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "58\tValidation loss: 0.401143\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.401660\tBest loss: 0.394183\tAccuracy: 88.49%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=0, learning_rate=0.01, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   5.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 118.829369\tBest loss: 118.829369\tAccuracy: 2.16%\n",
      "1\tValidation loss: 213.016800\tBest loss: 118.829369\tAccuracy: 3.60%\n",
      "2\tValidation loss: 216.889160\tBest loss: 118.829369\tAccuracy: 5.76%\n",
      "3\tValidation loss: 254.415970\tBest loss: 118.829369\tAccuracy: 1.44%\n",
      "4\tValidation loss: 111.679482\tBest loss: 111.679482\tAccuracy: 3.60%\n",
      "5\tValidation loss: 65.023468\tBest loss: 65.023468\tAccuracy: 8.63%\n",
      "6\tValidation loss: 124.163605\tBest loss: 65.023468\tAccuracy: 3.60%\n",
      "7\tValidation loss: 41.580742\tBest loss: 41.580742\tAccuracy: 10.07%\n",
      "8\tValidation loss: 14.432262\tBest loss: 14.432262\tAccuracy: 15.83%\n",
      "9\tValidation loss: 9.593517\tBest loss: 9.593517\tAccuracy: 20.86%\n",
      "10\tValidation loss: 7.460174\tBest loss: 7.460174\tAccuracy: 25.18%\n",
      "11\tValidation loss: 5.208498\tBest loss: 5.208498\tAccuracy: 38.13%\n",
      "12\tValidation loss: 6.403713\tBest loss: 5.208498\tAccuracy: 35.97%\n",
      "13\tValidation loss: 3.273002\tBest loss: 3.273002\tAccuracy: 43.88%\n",
      "14\tValidation loss: 2.496751\tBest loss: 2.496751\tAccuracy: 53.96%\n",
      "15\tValidation loss: 1.797961\tBest loss: 1.797961\tAccuracy: 60.43%\n",
      "16\tValidation loss: 1.444048\tBest loss: 1.444048\tAccuracy: 69.78%\n",
      "17\tValidation loss: 1.187137\tBest loss: 1.187137\tAccuracy: 71.94%\n",
      "18\tValidation loss: 1.080643\tBest loss: 1.080643\tAccuracy: 76.26%\n",
      "19\tValidation loss: 1.033211\tBest loss: 1.033211\tAccuracy: 77.70%\n",
      "20\tValidation loss: 0.997467\tBest loss: 0.997467\tAccuracy: 77.70%\n",
      "21\tValidation loss: 0.970583\tBest loss: 0.970583\tAccuracy: 79.14%\n",
      "22\tValidation loss: 0.949308\tBest loss: 0.949308\tAccuracy: 79.86%\n",
      "23\tValidation loss: 0.931177\tBest loss: 0.931177\tAccuracy: 79.86%\n",
      "24\tValidation loss: 0.914993\tBest loss: 0.914993\tAccuracy: 81.29%\n",
      "25\tValidation loss: 0.901012\tBest loss: 0.901012\tAccuracy: 81.29%\n",
      "26\tValidation loss: 0.888911\tBest loss: 0.888911\tAccuracy: 81.29%\n",
      "27\tValidation loss: 0.877011\tBest loss: 0.877011\tAccuracy: 80.58%\n",
      "28\tValidation loss: 0.866309\tBest loss: 0.866309\tAccuracy: 80.58%\n",
      "29\tValidation loss: 0.856497\tBest loss: 0.856497\tAccuracy: 80.58%\n",
      "30\tValidation loss: 0.847464\tBest loss: 0.847464\tAccuracy: 79.86%\n",
      "31\tValidation loss: 0.839512\tBest loss: 0.839512\tAccuracy: 79.86%\n",
      "32\tValidation loss: 0.831916\tBest loss: 0.831916\tAccuracy: 79.86%\n",
      "33\tValidation loss: 0.825639\tBest loss: 0.825639\tAccuracy: 79.86%\n",
      "34\tValidation loss: 0.819376\tBest loss: 0.819376\tAccuracy: 79.86%\n",
      "35\tValidation loss: 0.813594\tBest loss: 0.813594\tAccuracy: 79.86%\n",
      "36\tValidation loss: 0.807957\tBest loss: 0.807957\tAccuracy: 80.58%\n",
      "37\tValidation loss: 0.802258\tBest loss: 0.802258\tAccuracy: 80.58%\n",
      "38\tValidation loss: 0.797084\tBest loss: 0.797084\tAccuracy: 80.58%\n",
      "39\tValidation loss: 0.792480\tBest loss: 0.792480\tAccuracy: 80.58%\n",
      "40\tValidation loss: 0.788145\tBest loss: 0.788145\tAccuracy: 80.58%\n",
      "41\tValidation loss: 0.783990\tBest loss: 0.783990\tAccuracy: 80.58%\n",
      "42\tValidation loss: 0.780199\tBest loss: 0.780199\tAccuracy: 80.58%\n",
      "43\tValidation loss: 0.777047\tBest loss: 0.777047\tAccuracy: 80.58%\n",
      "44\tValidation loss: 0.774103\tBest loss: 0.774103\tAccuracy: 80.58%\n",
      "45\tValidation loss: 0.771136\tBest loss: 0.771136\tAccuracy: 80.58%\n",
      "46\tValidation loss: 0.768010\tBest loss: 0.768010\tAccuracy: 82.01%\n",
      "47\tValidation loss: 0.765238\tBest loss: 0.765238\tAccuracy: 82.73%\n",
      "48\tValidation loss: 0.762519\tBest loss: 0.762519\tAccuracy: 82.01%\n",
      "49\tValidation loss: 0.760148\tBest loss: 0.760148\tAccuracy: 81.29%\n",
      "50\tValidation loss: 0.757292\tBest loss: 0.757292\tAccuracy: 81.29%\n",
      "51\tValidation loss: 0.754106\tBest loss: 0.754106\tAccuracy: 81.29%\n",
      "52\tValidation loss: 0.751753\tBest loss: 0.751753\tAccuracy: 81.29%\n",
      "53\tValidation loss: 0.748363\tBest loss: 0.748363\tAccuracy: 81.29%\n",
      "54\tValidation loss: 0.745674\tBest loss: 0.745674\tAccuracy: 81.29%\n",
      "55\tValidation loss: 0.742469\tBest loss: 0.742469\tAccuracy: 81.29%\n",
      "56\tValidation loss: 0.739809\tBest loss: 0.739809\tAccuracy: 81.29%\n",
      "57\tValidation loss: 0.737003\tBest loss: 0.737003\tAccuracy: 81.29%\n",
      "58\tValidation loss: 0.734348\tBest loss: 0.734348\tAccuracy: 81.29%\n",
      "59\tValidation loss: 0.731636\tBest loss: 0.731636\tAccuracy: 81.29%\n",
      "60\tValidation loss: 0.729591\tBest loss: 0.729591\tAccuracy: 81.29%\n",
      "61\tValidation loss: 0.727169\tBest loss: 0.727169\tAccuracy: 81.29%\n",
      "62\tValidation loss: 0.724929\tBest loss: 0.724929\tAccuracy: 81.29%\n",
      "63\tValidation loss: 0.722358\tBest loss: 0.722358\tAccuracy: 81.29%\n",
      "64\tValidation loss: 0.720377\tBest loss: 0.720377\tAccuracy: 81.29%\n",
      "65\tValidation loss: 0.717933\tBest loss: 0.717933\tAccuracy: 81.29%\n",
      "66\tValidation loss: 0.716178\tBest loss: 0.716178\tAccuracy: 81.29%\n",
      "67\tValidation loss: 0.714113\tBest loss: 0.714113\tAccuracy: 82.01%\n",
      "68\tValidation loss: 0.712067\tBest loss: 0.712067\tAccuracy: 82.01%\n",
      "69\tValidation loss: 0.710007\tBest loss: 0.710007\tAccuracy: 82.01%\n",
      "70\tValidation loss: 0.707827\tBest loss: 0.707827\tAccuracy: 83.45%\n",
      "71\tValidation loss: 0.705692\tBest loss: 0.705692\tAccuracy: 84.17%\n",
      "72\tValidation loss: 0.703781\tBest loss: 0.703781\tAccuracy: 84.17%\n",
      "73\tValidation loss: 0.701623\tBest loss: 0.701623\tAccuracy: 84.17%\n",
      "74\tValidation loss: 0.699524\tBest loss: 0.699524\tAccuracy: 84.17%\n",
      "75\tValidation loss: 0.697611\tBest loss: 0.697611\tAccuracy: 84.17%\n",
      "76\tValidation loss: 0.695758\tBest loss: 0.695758\tAccuracy: 84.17%\n",
      "77\tValidation loss: 0.693520\tBest loss: 0.693520\tAccuracy: 84.17%\n",
      "78\tValidation loss: 0.691937\tBest loss: 0.691937\tAccuracy: 84.17%\n",
      "79\tValidation loss: 0.690105\tBest loss: 0.690105\tAccuracy: 84.17%\n",
      "80\tValidation loss: 0.688254\tBest loss: 0.688254\tAccuracy: 84.17%\n",
      "81\tValidation loss: 0.686301\tBest loss: 0.686301\tAccuracy: 84.17%\n",
      "82\tValidation loss: 0.684815\tBest loss: 0.684815\tAccuracy: 84.17%\n",
      "83\tValidation loss: 0.682671\tBest loss: 0.682671\tAccuracy: 84.17%\n",
      "84\tValidation loss: 0.681155\tBest loss: 0.681155\tAccuracy: 84.17%\n",
      "85\tValidation loss: 0.679567\tBest loss: 0.679567\tAccuracy: 84.17%\n",
      "86\tValidation loss: 0.677734\tBest loss: 0.677734\tAccuracy: 84.17%\n",
      "87\tValidation loss: 0.676341\tBest loss: 0.676341\tAccuracy: 84.17%\n",
      "88\tValidation loss: 0.674670\tBest loss: 0.674670\tAccuracy: 84.17%\n",
      "89\tValidation loss: 0.673210\tBest loss: 0.673210\tAccuracy: 84.17%\n",
      "90\tValidation loss: 0.671489\tBest loss: 0.671489\tAccuracy: 84.17%\n",
      "91\tValidation loss: 0.669883\tBest loss: 0.669883\tAccuracy: 84.17%\n",
      "92\tValidation loss: 0.668259\tBest loss: 0.668259\tAccuracy: 84.17%\n",
      "93\tValidation loss: 0.666914\tBest loss: 0.666914\tAccuracy: 84.17%\n",
      "94\tValidation loss: 0.665438\tBest loss: 0.665438\tAccuracy: 84.17%\n",
      "95\tValidation loss: 0.664134\tBest loss: 0.664134\tAccuracy: 84.17%\n",
      "96\tValidation loss: 0.662427\tBest loss: 0.662427\tAccuracy: 84.17%\n",
      "97\tValidation loss: 0.661242\tBest loss: 0.661242\tAccuracy: 84.17%\n",
      "98\tValidation loss: 0.659324\tBest loss: 0.659324\tAccuracy: 84.17%\n",
      "99\tValidation loss: 0.657977\tBest loss: 0.657977\tAccuracy: 84.17%\n",
      "100\tValidation loss: 0.656299\tBest loss: 0.656299\tAccuracy: 84.17%\n",
      "101\tValidation loss: 0.655111\tBest loss: 0.655111\tAccuracy: 84.17%\n",
      "102\tValidation loss: 0.653571\tBest loss: 0.653571\tAccuracy: 84.17%\n",
      "103\tValidation loss: 0.652686\tBest loss: 0.652686\tAccuracy: 84.17%\n",
      "104\tValidation loss: 0.651364\tBest loss: 0.651364\tAccuracy: 84.17%\n",
      "105\tValidation loss: 0.650108\tBest loss: 0.650108\tAccuracy: 84.17%\n",
      "106\tValidation loss: 0.648905\tBest loss: 0.648905\tAccuracy: 84.17%\n",
      "107\tValidation loss: 0.647768\tBest loss: 0.647768\tAccuracy: 84.17%\n",
      "108\tValidation loss: 0.646297\tBest loss: 0.646297\tAccuracy: 84.17%\n",
      "109\tValidation loss: 0.645095\tBest loss: 0.645095\tAccuracy: 84.17%\n",
      "110\tValidation loss: 0.643750\tBest loss: 0.643750\tAccuracy: 84.17%\n",
      "111\tValidation loss: 0.642446\tBest loss: 0.642446\tAccuracy: 84.17%\n",
      "112\tValidation loss: 0.640867\tBest loss: 0.640867\tAccuracy: 84.17%\n",
      "113\tValidation loss: 0.639769\tBest loss: 0.639769\tAccuracy: 84.17%\n",
      "114\tValidation loss: 0.638421\tBest loss: 0.638421\tAccuracy: 84.17%\n",
      "115\tValidation loss: 0.637425\tBest loss: 0.637425\tAccuracy: 84.17%\n",
      "116\tValidation loss: 0.636103\tBest loss: 0.636103\tAccuracy: 84.17%\n",
      "117\tValidation loss: 0.635199\tBest loss: 0.635199\tAccuracy: 84.17%\n",
      "118\tValidation loss: 0.634188\tBest loss: 0.634188\tAccuracy: 84.17%\n",
      "119\tValidation loss: 0.633153\tBest loss: 0.633153\tAccuracy: 84.17%\n",
      "120\tValidation loss: 0.632510\tBest loss: 0.632510\tAccuracy: 84.17%\n",
      "121\tValidation loss: 0.631671\tBest loss: 0.631671\tAccuracy: 84.17%\n",
      "122\tValidation loss: 0.630972\tBest loss: 0.630972\tAccuracy: 84.17%\n",
      "123\tValidation loss: 0.630216\tBest loss: 0.630216\tAccuracy: 84.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 0.629498\tBest loss: 0.629498\tAccuracy: 84.89%\n",
      "125\tValidation loss: 0.628485\tBest loss: 0.628485\tAccuracy: 84.89%\n",
      "126\tValidation loss: 0.627768\tBest loss: 0.627768\tAccuracy: 84.89%\n",
      "127\tValidation loss: 0.627172\tBest loss: 0.627172\tAccuracy: 84.89%\n",
      "128\tValidation loss: 0.626273\tBest loss: 0.626273\tAccuracy: 84.89%\n",
      "129\tValidation loss: 0.625608\tBest loss: 0.625608\tAccuracy: 84.89%\n",
      "130\tValidation loss: 0.624714\tBest loss: 0.624714\tAccuracy: 84.89%\n",
      "131\tValidation loss: 0.624012\tBest loss: 0.624012\tAccuracy: 84.89%\n",
      "132\tValidation loss: 0.623227\tBest loss: 0.623227\tAccuracy: 84.89%\n",
      "133\tValidation loss: 0.622623\tBest loss: 0.622623\tAccuracy: 84.17%\n",
      "134\tValidation loss: 0.621761\tBest loss: 0.621761\tAccuracy: 84.17%\n",
      "135\tValidation loss: 0.621120\tBest loss: 0.621120\tAccuracy: 84.17%\n",
      "136\tValidation loss: 0.620536\tBest loss: 0.620536\tAccuracy: 84.17%\n",
      "137\tValidation loss: 0.619809\tBest loss: 0.619809\tAccuracy: 84.17%\n",
      "138\tValidation loss: 0.619064\tBest loss: 0.619064\tAccuracy: 84.17%\n",
      "139\tValidation loss: 0.618430\tBest loss: 0.618430\tAccuracy: 84.17%\n",
      "140\tValidation loss: 0.617673\tBest loss: 0.617673\tAccuracy: 84.17%\n",
      "141\tValidation loss: 0.616680\tBest loss: 0.616680\tAccuracy: 84.17%\n",
      "142\tValidation loss: 0.616116\tBest loss: 0.616116\tAccuracy: 84.17%\n",
      "143\tValidation loss: 0.615464\tBest loss: 0.615464\tAccuracy: 84.17%\n",
      "144\tValidation loss: 0.614720\tBest loss: 0.614720\tAccuracy: 84.17%\n",
      "145\tValidation loss: 0.614164\tBest loss: 0.614164\tAccuracy: 84.17%\n",
      "146\tValidation loss: 0.613501\tBest loss: 0.613501\tAccuracy: 84.17%\n",
      "147\tValidation loss: 0.612959\tBest loss: 0.612959\tAccuracy: 84.17%\n",
      "148\tValidation loss: 0.612054\tBest loss: 0.612054\tAccuracy: 84.17%\n",
      "149\tValidation loss: 0.611474\tBest loss: 0.611474\tAccuracy: 84.17%\n",
      "150\tValidation loss: 0.611091\tBest loss: 0.611091\tAccuracy: 84.17%\n",
      "151\tValidation loss: 0.610222\tBest loss: 0.610222\tAccuracy: 84.17%\n",
      "152\tValidation loss: 0.609921\tBest loss: 0.609921\tAccuracy: 84.17%\n",
      "153\tValidation loss: 0.609344\tBest loss: 0.609344\tAccuracy: 84.17%\n",
      "154\tValidation loss: 0.608807\tBest loss: 0.608807\tAccuracy: 84.17%\n",
      "155\tValidation loss: 0.608178\tBest loss: 0.608178\tAccuracy: 84.17%\n",
      "156\tValidation loss: 0.607812\tBest loss: 0.607812\tAccuracy: 84.17%\n",
      "157\tValidation loss: 0.607039\tBest loss: 0.607039\tAccuracy: 84.17%\n",
      "158\tValidation loss: 0.606433\tBest loss: 0.606433\tAccuracy: 84.17%\n",
      "159\tValidation loss: 0.606100\tBest loss: 0.606100\tAccuracy: 84.17%\n",
      "160\tValidation loss: 0.605288\tBest loss: 0.605288\tAccuracy: 84.17%\n",
      "161\tValidation loss: 0.604793\tBest loss: 0.604793\tAccuracy: 84.17%\n",
      "162\tValidation loss: 0.604609\tBest loss: 0.604609\tAccuracy: 84.17%\n",
      "163\tValidation loss: 0.603637\tBest loss: 0.603637\tAccuracy: 84.17%\n",
      "164\tValidation loss: 0.603434\tBest loss: 0.603434\tAccuracy: 84.17%\n",
      "165\tValidation loss: 0.602441\tBest loss: 0.602441\tAccuracy: 84.17%\n",
      "166\tValidation loss: 0.602109\tBest loss: 0.602109\tAccuracy: 84.17%\n",
      "167\tValidation loss: 0.601618\tBest loss: 0.601618\tAccuracy: 84.17%\n",
      "168\tValidation loss: 0.601037\tBest loss: 0.601037\tAccuracy: 84.17%\n",
      "169\tValidation loss: 0.600291\tBest loss: 0.600291\tAccuracy: 84.89%\n",
      "170\tValidation loss: 0.599696\tBest loss: 0.599696\tAccuracy: 84.89%\n",
      "171\tValidation loss: 0.599171\tBest loss: 0.599171\tAccuracy: 84.89%\n",
      "172\tValidation loss: 0.598703\tBest loss: 0.598703\tAccuracy: 84.89%\n",
      "173\tValidation loss: 0.598102\tBest loss: 0.598102\tAccuracy: 84.89%\n",
      "174\tValidation loss: 0.597641\tBest loss: 0.597641\tAccuracy: 84.89%\n",
      "175\tValidation loss: 0.597119\tBest loss: 0.597119\tAccuracy: 85.61%\n",
      "176\tValidation loss: 0.596754\tBest loss: 0.596754\tAccuracy: 85.61%\n",
      "177\tValidation loss: 0.596054\tBest loss: 0.596054\tAccuracy: 85.61%\n",
      "178\tValidation loss: 0.595516\tBest loss: 0.595516\tAccuracy: 85.61%\n",
      "179\tValidation loss: 0.594993\tBest loss: 0.594993\tAccuracy: 85.61%\n",
      "180\tValidation loss: 0.594423\tBest loss: 0.594423\tAccuracy: 85.61%\n",
      "181\tValidation loss: 0.594052\tBest loss: 0.594052\tAccuracy: 85.61%\n",
      "182\tValidation loss: 0.593505\tBest loss: 0.593505\tAccuracy: 85.61%\n",
      "183\tValidation loss: 0.593003\tBest loss: 0.593003\tAccuracy: 85.61%\n",
      "184\tValidation loss: 0.592727\tBest loss: 0.592727\tAccuracy: 85.61%\n",
      "185\tValidation loss: 0.592018\tBest loss: 0.592018\tAccuracy: 85.61%\n",
      "186\tValidation loss: 0.591700\tBest loss: 0.591700\tAccuracy: 85.61%\n",
      "187\tValidation loss: 0.591152\tBest loss: 0.591152\tAccuracy: 85.61%\n",
      "188\tValidation loss: 0.590911\tBest loss: 0.590911\tAccuracy: 85.61%\n",
      "189\tValidation loss: 0.590390\tBest loss: 0.590390\tAccuracy: 85.61%\n",
      "190\tValidation loss: 0.589731\tBest loss: 0.589731\tAccuracy: 85.61%\n",
      "191\tValidation loss: 0.589494\tBest loss: 0.589494\tAccuracy: 85.61%\n",
      "192\tValidation loss: 0.588961\tBest loss: 0.588961\tAccuracy: 85.61%\n",
      "193\tValidation loss: 0.588450\tBest loss: 0.588450\tAccuracy: 85.61%\n",
      "194\tValidation loss: 0.588156\tBest loss: 0.588156\tAccuracy: 85.61%\n",
      "195\tValidation loss: 0.587727\tBest loss: 0.587727\tAccuracy: 85.61%\n",
      "196\tValidation loss: 0.587316\tBest loss: 0.587316\tAccuracy: 85.61%\n",
      "197\tValidation loss: 0.586889\tBest loss: 0.586889\tAccuracy: 85.61%\n",
      "198\tValidation loss: 0.586382\tBest loss: 0.586382\tAccuracy: 85.61%\n",
      "199\tValidation loss: 0.586375\tBest loss: 0.586375\tAccuracy: 85.61%\n",
      "200\tValidation loss: 0.585690\tBest loss: 0.585690\tAccuracy: 85.61%\n",
      "201\tValidation loss: 0.585267\tBest loss: 0.585267\tAccuracy: 85.61%\n",
      "202\tValidation loss: 0.584800\tBest loss: 0.584800\tAccuracy: 85.61%\n",
      "203\tValidation loss: 0.584503\tBest loss: 0.584503\tAccuracy: 85.61%\n",
      "204\tValidation loss: 0.584290\tBest loss: 0.584290\tAccuracy: 85.61%\n",
      "205\tValidation loss: 0.583747\tBest loss: 0.583747\tAccuracy: 85.61%\n",
      "206\tValidation loss: 0.583374\tBest loss: 0.583374\tAccuracy: 85.61%\n",
      "207\tValidation loss: 0.582968\tBest loss: 0.582968\tAccuracy: 85.61%\n",
      "208\tValidation loss: 0.582758\tBest loss: 0.582758\tAccuracy: 85.61%\n",
      "209\tValidation loss: 0.582226\tBest loss: 0.582226\tAccuracy: 85.61%\n",
      "210\tValidation loss: 0.581772\tBest loss: 0.581772\tAccuracy: 85.61%\n",
      "211\tValidation loss: 0.581381\tBest loss: 0.581381\tAccuracy: 85.61%\n",
      "212\tValidation loss: 0.581199\tBest loss: 0.581199\tAccuracy: 85.61%\n",
      "213\tValidation loss: 0.580428\tBest loss: 0.580428\tAccuracy: 85.61%\n",
      "214\tValidation loss: 0.580051\tBest loss: 0.580051\tAccuracy: 85.61%\n",
      "215\tValidation loss: 0.579786\tBest loss: 0.579786\tAccuracy: 85.61%\n",
      "216\tValidation loss: 0.579329\tBest loss: 0.579329\tAccuracy: 85.61%\n",
      "217\tValidation loss: 0.578923\tBest loss: 0.578923\tAccuracy: 85.61%\n",
      "218\tValidation loss: 0.578603\tBest loss: 0.578603\tAccuracy: 85.61%\n",
      "219\tValidation loss: 0.578199\tBest loss: 0.578199\tAccuracy: 85.61%\n",
      "220\tValidation loss: 0.577813\tBest loss: 0.577813\tAccuracy: 85.61%\n",
      "221\tValidation loss: 0.577325\tBest loss: 0.577325\tAccuracy: 85.61%\n",
      "222\tValidation loss: 0.576976\tBest loss: 0.576976\tAccuracy: 85.61%\n",
      "223\tValidation loss: 0.576718\tBest loss: 0.576718\tAccuracy: 85.61%\n",
      "224\tValidation loss: 0.576326\tBest loss: 0.576326\tAccuracy: 85.61%\n",
      "225\tValidation loss: 0.576117\tBest loss: 0.576117\tAccuracy: 85.61%\n",
      "226\tValidation loss: 0.575508\tBest loss: 0.575508\tAccuracy: 85.61%\n",
      "227\tValidation loss: 0.575318\tBest loss: 0.575318\tAccuracy: 85.61%\n",
      "228\tValidation loss: 0.575222\tBest loss: 0.575222\tAccuracy: 85.61%\n",
      "229\tValidation loss: 0.574703\tBest loss: 0.574703\tAccuracy: 85.61%\n",
      "230\tValidation loss: 0.574242\tBest loss: 0.574242\tAccuracy: 85.61%\n",
      "231\tValidation loss: 0.573970\tBest loss: 0.573970\tAccuracy: 85.61%\n",
      "232\tValidation loss: 0.573606\tBest loss: 0.573606\tAccuracy: 85.61%\n",
      "233\tValidation loss: 0.573287\tBest loss: 0.573287\tAccuracy: 85.61%\n",
      "234\tValidation loss: 0.573056\tBest loss: 0.573056\tAccuracy: 85.61%\n",
      "235\tValidation loss: 0.572692\tBest loss: 0.572692\tAccuracy: 85.61%\n",
      "236\tValidation loss: 0.572677\tBest loss: 0.572677\tAccuracy: 85.61%\n",
      "237\tValidation loss: 0.572096\tBest loss: 0.572096\tAccuracy: 85.61%\n",
      "238\tValidation loss: 0.572055\tBest loss: 0.572055\tAccuracy: 85.61%\n",
      "239\tValidation loss: 0.571484\tBest loss: 0.571484\tAccuracy: 85.61%\n",
      "240\tValidation loss: 0.571227\tBest loss: 0.571227\tAccuracy: 85.61%\n",
      "241\tValidation loss: 0.571051\tBest loss: 0.571051\tAccuracy: 85.61%\n",
      "242\tValidation loss: 0.570813\tBest loss: 0.570813\tAccuracy: 85.61%\n",
      "243\tValidation loss: 0.570243\tBest loss: 0.570243\tAccuracy: 85.61%\n",
      "244\tValidation loss: 0.570619\tBest loss: 0.570243\tAccuracy: 85.61%\n",
      "245\tValidation loss: 0.569918\tBest loss: 0.569918\tAccuracy: 85.61%\n",
      "246\tValidation loss: 0.569713\tBest loss: 0.569713\tAccuracy: 85.61%\n",
      "247\tValidation loss: 0.569300\tBest loss: 0.569300\tAccuracy: 85.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 0.569211\tBest loss: 0.569211\tAccuracy: 85.61%\n",
      "249\tValidation loss: 0.568663\tBest loss: 0.568663\tAccuracy: 85.61%\n",
      "250\tValidation loss: 0.568499\tBest loss: 0.568499\tAccuracy: 85.61%\n",
      "251\tValidation loss: 0.568164\tBest loss: 0.568164\tAccuracy: 86.33%\n",
      "252\tValidation loss: 0.568023\tBest loss: 0.568023\tAccuracy: 85.61%\n",
      "253\tValidation loss: 0.567654\tBest loss: 0.567654\tAccuracy: 85.61%\n",
      "254\tValidation loss: 0.567595\tBest loss: 0.567595\tAccuracy: 85.61%\n",
      "255\tValidation loss: 0.567084\tBest loss: 0.567084\tAccuracy: 85.61%\n",
      "256\tValidation loss: 0.567080\tBest loss: 0.567080\tAccuracy: 85.61%\n",
      "257\tValidation loss: 0.566495\tBest loss: 0.566495\tAccuracy: 85.61%\n",
      "258\tValidation loss: 0.566492\tBest loss: 0.566492\tAccuracy: 85.61%\n",
      "259\tValidation loss: 0.566191\tBest loss: 0.566191\tAccuracy: 85.61%\n",
      "260\tValidation loss: 0.566064\tBest loss: 0.566064\tAccuracy: 85.61%\n",
      "261\tValidation loss: 0.565722\tBest loss: 0.565722\tAccuracy: 85.61%\n",
      "262\tValidation loss: 0.565529\tBest loss: 0.565529\tAccuracy: 85.61%\n",
      "263\tValidation loss: 0.565255\tBest loss: 0.565255\tAccuracy: 85.61%\n",
      "264\tValidation loss: 0.565389\tBest loss: 0.565255\tAccuracy: 85.61%\n",
      "265\tValidation loss: 0.564822\tBest loss: 0.564822\tAccuracy: 85.61%\n",
      "266\tValidation loss: 0.564760\tBest loss: 0.564760\tAccuracy: 85.61%\n",
      "267\tValidation loss: 0.564473\tBest loss: 0.564473\tAccuracy: 85.61%\n",
      "268\tValidation loss: 0.564230\tBest loss: 0.564230\tAccuracy: 85.61%\n",
      "269\tValidation loss: 0.563975\tBest loss: 0.563975\tAccuracy: 85.61%\n",
      "270\tValidation loss: 0.563806\tBest loss: 0.563806\tAccuracy: 85.61%\n",
      "271\tValidation loss: 0.563621\tBest loss: 0.563621\tAccuracy: 85.61%\n",
      "272\tValidation loss: 0.563459\tBest loss: 0.563459\tAccuracy: 85.61%\n",
      "273\tValidation loss: 0.563115\tBest loss: 0.563115\tAccuracy: 85.61%\n",
      "274\tValidation loss: 0.562809\tBest loss: 0.562809\tAccuracy: 85.61%\n",
      "275\tValidation loss: 0.562661\tBest loss: 0.562661\tAccuracy: 85.61%\n",
      "276\tValidation loss: 0.562436\tBest loss: 0.562436\tAccuracy: 85.61%\n",
      "277\tValidation loss: 0.562058\tBest loss: 0.562058\tAccuracy: 85.61%\n",
      "278\tValidation loss: 0.562044\tBest loss: 0.562044\tAccuracy: 85.61%\n",
      "279\tValidation loss: 0.561627\tBest loss: 0.561627\tAccuracy: 85.61%\n",
      "280\tValidation loss: 0.561725\tBest loss: 0.561627\tAccuracy: 85.61%\n",
      "281\tValidation loss: 0.561250\tBest loss: 0.561250\tAccuracy: 85.61%\n",
      "282\tValidation loss: 0.561088\tBest loss: 0.561088\tAccuracy: 85.61%\n",
      "283\tValidation loss: 0.560978\tBest loss: 0.560978\tAccuracy: 85.61%\n",
      "284\tValidation loss: 0.560728\tBest loss: 0.560728\tAccuracy: 85.61%\n",
      "285\tValidation loss: 0.560552\tBest loss: 0.560552\tAccuracy: 85.61%\n",
      "286\tValidation loss: 0.560341\tBest loss: 0.560341\tAccuracy: 85.61%\n",
      "287\tValidation loss: 0.559994\tBest loss: 0.559994\tAccuracy: 85.61%\n",
      "288\tValidation loss: 0.560302\tBest loss: 0.559994\tAccuracy: 86.33%\n",
      "289\tValidation loss: 0.559716\tBest loss: 0.559716\tAccuracy: 85.61%\n",
      "290\tValidation loss: 0.559724\tBest loss: 0.559716\tAccuracy: 86.33%\n",
      "291\tValidation loss: 0.559426\tBest loss: 0.559426\tAccuracy: 86.33%\n",
      "292\tValidation loss: 0.559260\tBest loss: 0.559260\tAccuracy: 86.33%\n",
      "293\tValidation loss: 0.559094\tBest loss: 0.559094\tAccuracy: 86.33%\n",
      "294\tValidation loss: 0.558816\tBest loss: 0.558816\tAccuracy: 86.33%\n",
      "295\tValidation loss: 0.558801\tBest loss: 0.558801\tAccuracy: 86.33%\n",
      "296\tValidation loss: 0.558669\tBest loss: 0.558669\tAccuracy: 86.33%\n",
      "297\tValidation loss: 0.558339\tBest loss: 0.558339\tAccuracy: 86.33%\n",
      "298\tValidation loss: 0.558488\tBest loss: 0.558339\tAccuracy: 86.33%\n",
      "299\tValidation loss: 0.558116\tBest loss: 0.558116\tAccuracy: 86.33%\n",
      "300\tValidation loss: 0.558302\tBest loss: 0.558116\tAccuracy: 86.33%\n",
      "301\tValidation loss: 0.557803\tBest loss: 0.557803\tAccuracy: 86.33%\n",
      "302\tValidation loss: 0.557815\tBest loss: 0.557803\tAccuracy: 86.33%\n",
      "303\tValidation loss: 0.557611\tBest loss: 0.557611\tAccuracy: 86.33%\n",
      "304\tValidation loss: 0.557736\tBest loss: 0.557611\tAccuracy: 86.33%\n",
      "305\tValidation loss: 0.557237\tBest loss: 0.557237\tAccuracy: 86.33%\n",
      "306\tValidation loss: 0.557584\tBest loss: 0.557237\tAccuracy: 86.33%\n",
      "307\tValidation loss: 0.557077\tBest loss: 0.557077\tAccuracy: 86.33%\n",
      "308\tValidation loss: 0.557211\tBest loss: 0.557077\tAccuracy: 86.33%\n",
      "309\tValidation loss: 0.556975\tBest loss: 0.556975\tAccuracy: 86.33%\n",
      "310\tValidation loss: 0.557016\tBest loss: 0.556975\tAccuracy: 86.33%\n",
      "311\tValidation loss: 0.556707\tBest loss: 0.556707\tAccuracy: 86.33%\n",
      "312\tValidation loss: 0.556846\tBest loss: 0.556707\tAccuracy: 86.33%\n",
      "313\tValidation loss: 0.556354\tBest loss: 0.556354\tAccuracy: 86.33%\n",
      "314\tValidation loss: 0.556488\tBest loss: 0.556354\tAccuracy: 86.33%\n",
      "315\tValidation loss: 0.556194\tBest loss: 0.556194\tAccuracy: 86.33%\n",
      "316\tValidation loss: 0.556332\tBest loss: 0.556194\tAccuracy: 86.33%\n",
      "317\tValidation loss: 0.556158\tBest loss: 0.556158\tAccuracy: 86.33%\n",
      "318\tValidation loss: 0.556146\tBest loss: 0.556146\tAccuracy: 86.33%\n",
      "319\tValidation loss: 0.555989\tBest loss: 0.555989\tAccuracy: 86.33%\n",
      "320\tValidation loss: 0.556114\tBest loss: 0.555989\tAccuracy: 86.33%\n",
      "321\tValidation loss: 0.555598\tBest loss: 0.555598\tAccuracy: 86.33%\n",
      "322\tValidation loss: 0.555927\tBest loss: 0.555598\tAccuracy: 86.33%\n",
      "323\tValidation loss: 0.555428\tBest loss: 0.555428\tAccuracy: 86.33%\n",
      "324\tValidation loss: 0.555805\tBest loss: 0.555428\tAccuracy: 86.33%\n",
      "325\tValidation loss: 0.555198\tBest loss: 0.555198\tAccuracy: 86.33%\n",
      "326\tValidation loss: 0.555636\tBest loss: 0.555198\tAccuracy: 86.33%\n",
      "327\tValidation loss: 0.555088\tBest loss: 0.555088\tAccuracy: 86.33%\n",
      "328\tValidation loss: 0.555320\tBest loss: 0.555088\tAccuracy: 86.33%\n",
      "329\tValidation loss: 0.554770\tBest loss: 0.554770\tAccuracy: 86.33%\n",
      "330\tValidation loss: 0.555204\tBest loss: 0.554770\tAccuracy: 86.33%\n",
      "331\tValidation loss: 0.554576\tBest loss: 0.554576\tAccuracy: 86.33%\n",
      "332\tValidation loss: 0.555171\tBest loss: 0.554576\tAccuracy: 86.33%\n",
      "333\tValidation loss: 0.554491\tBest loss: 0.554491\tAccuracy: 86.33%\n",
      "334\tValidation loss: 0.554856\tBest loss: 0.554491\tAccuracy: 86.33%\n",
      "335\tValidation loss: 0.554404\tBest loss: 0.554404\tAccuracy: 86.33%\n",
      "336\tValidation loss: 0.554577\tBest loss: 0.554404\tAccuracy: 86.33%\n",
      "337\tValidation loss: 0.554281\tBest loss: 0.554281\tAccuracy: 86.33%\n",
      "338\tValidation loss: 0.554449\tBest loss: 0.554281\tAccuracy: 86.33%\n",
      "339\tValidation loss: 0.554192\tBest loss: 0.554192\tAccuracy: 86.33%\n",
      "340\tValidation loss: 0.554479\tBest loss: 0.554192\tAccuracy: 86.33%\n",
      "341\tValidation loss: 0.554055\tBest loss: 0.554055\tAccuracy: 86.33%\n",
      "342\tValidation loss: 0.554193\tBest loss: 0.554055\tAccuracy: 86.33%\n",
      "343\tValidation loss: 0.553890\tBest loss: 0.553890\tAccuracy: 86.33%\n",
      "344\tValidation loss: 0.554066\tBest loss: 0.553890\tAccuracy: 86.33%\n",
      "345\tValidation loss: 0.553902\tBest loss: 0.553890\tAccuracy: 86.33%\n",
      "346\tValidation loss: 0.553737\tBest loss: 0.553737\tAccuracy: 86.33%\n",
      "347\tValidation loss: 0.553776\tBest loss: 0.553737\tAccuracy: 86.33%\n",
      "348\tValidation loss: 0.553480\tBest loss: 0.553480\tAccuracy: 86.33%\n",
      "349\tValidation loss: 0.553759\tBest loss: 0.553480\tAccuracy: 86.33%\n",
      "350\tValidation loss: 0.553423\tBest loss: 0.553423\tAccuracy: 86.33%\n",
      "351\tValidation loss: 0.553693\tBest loss: 0.553423\tAccuracy: 86.33%\n",
      "352\tValidation loss: 0.553212\tBest loss: 0.553212\tAccuracy: 86.33%\n",
      "353\tValidation loss: 0.553559\tBest loss: 0.553212\tAccuracy: 86.33%\n",
      "354\tValidation loss: 0.553155\tBest loss: 0.553155\tAccuracy: 86.33%\n",
      "355\tValidation loss: 0.553258\tBest loss: 0.553155\tAccuracy: 86.33%\n",
      "356\tValidation loss: 0.553120\tBest loss: 0.553120\tAccuracy: 86.33%\n",
      "357\tValidation loss: 0.553131\tBest loss: 0.553120\tAccuracy: 86.33%\n",
      "358\tValidation loss: 0.553069\tBest loss: 0.553069\tAccuracy: 86.33%\n",
      "359\tValidation loss: 0.553113\tBest loss: 0.553069\tAccuracy: 86.33%\n",
      "360\tValidation loss: 0.553101\tBest loss: 0.553069\tAccuracy: 86.33%\n",
      "361\tValidation loss: 0.552898\tBest loss: 0.552898\tAccuracy: 86.33%\n",
      "362\tValidation loss: 0.552982\tBest loss: 0.552898\tAccuracy: 86.33%\n",
      "363\tValidation loss: 0.552700\tBest loss: 0.552700\tAccuracy: 86.33%\n",
      "364\tValidation loss: 0.552875\tBest loss: 0.552700\tAccuracy: 86.33%\n",
      "365\tValidation loss: 0.552725\tBest loss: 0.552700\tAccuracy: 86.33%\n",
      "366\tValidation loss: 0.552853\tBest loss: 0.552700\tAccuracy: 86.33%\n",
      "367\tValidation loss: 0.552562\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "368\tValidation loss: 0.552781\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "369\tValidation loss: 0.552628\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "370\tValidation loss: 0.552646\tBest loss: 0.552562\tAccuracy: 86.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\tValidation loss: 0.552624\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "372\tValidation loss: 0.552752\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "373\tValidation loss: 0.552659\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "374\tValidation loss: 0.552677\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "375\tValidation loss: 0.552713\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "376\tValidation loss: 0.552787\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "377\tValidation loss: 0.552677\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "378\tValidation loss: 0.552843\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "379\tValidation loss: 0.552730\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "380\tValidation loss: 0.552809\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "381\tValidation loss: 0.552983\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "382\tValidation loss: 0.552725\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "383\tValidation loss: 0.553123\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "384\tValidation loss: 0.552853\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "385\tValidation loss: 0.553144\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "386\tValidation loss: 0.553044\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "387\tValidation loss: 0.553336\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "388\tValidation loss: 0.553242\tBest loss: 0.552562\tAccuracy: 86.33%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  48.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 115.365036\tBest loss: 115.365036\tAccuracy: 1.44%\n",
      "1\tValidation loss: 156.165649\tBest loss: 115.365036\tAccuracy: 5.04%\n",
      "2\tValidation loss: 184.612198\tBest loss: 115.365036\tAccuracy: 7.19%\n",
      "3\tValidation loss: 242.010803\tBest loss: 115.365036\tAccuracy: 1.44%\n",
      "4\tValidation loss: 67.898003\tBest loss: 67.898003\tAccuracy: 8.63%\n",
      "5\tValidation loss: 121.247162\tBest loss: 67.898003\tAccuracy: 3.60%\n",
      "6\tValidation loss: 108.325714\tBest loss: 67.898003\tAccuracy: 9.35%\n",
      "7\tValidation loss: 44.885223\tBest loss: 44.885223\tAccuracy: 5.76%\n",
      "8\tValidation loss: 28.405079\tBest loss: 28.405079\tAccuracy: 16.55%\n",
      "9\tValidation loss: 18.555584\tBest loss: 18.555584\tAccuracy: 23.02%\n",
      "10\tValidation loss: 10.659528\tBest loss: 10.659528\tAccuracy: 25.18%\n",
      "11\tValidation loss: 4.696510\tBest loss: 4.696510\tAccuracy: 41.01%\n",
      "12\tValidation loss: 2.716495\tBest loss: 2.716495\tAccuracy: 46.04%\n",
      "13\tValidation loss: 2.826998\tBest loss: 2.716495\tAccuracy: 46.76%\n",
      "14\tValidation loss: 3.059544\tBest loss: 2.716495\tAccuracy: 55.40%\n",
      "15\tValidation loss: 1.517178\tBest loss: 1.517178\tAccuracy: 62.59%\n",
      "16\tValidation loss: 1.216768\tBest loss: 1.216768\tAccuracy: 69.78%\n",
      "17\tValidation loss: 1.068284\tBest loss: 1.068284\tAccuracy: 71.94%\n",
      "18\tValidation loss: 1.035172\tBest loss: 1.035172\tAccuracy: 71.22%\n",
      "19\tValidation loss: 0.996697\tBest loss: 0.996697\tAccuracy: 73.38%\n",
      "20\tValidation loss: 0.970716\tBest loss: 0.970716\tAccuracy: 73.38%\n",
      "21\tValidation loss: 0.949571\tBest loss: 0.949571\tAccuracy: 74.10%\n",
      "22\tValidation loss: 0.932875\tBest loss: 0.932875\tAccuracy: 74.10%\n",
      "23\tValidation loss: 0.918616\tBest loss: 0.918616\tAccuracy: 74.10%\n",
      "24\tValidation loss: 0.905881\tBest loss: 0.905881\tAccuracy: 74.10%\n",
      "25\tValidation loss: 0.894790\tBest loss: 0.894790\tAccuracy: 75.54%\n",
      "26\tValidation loss: 0.884776\tBest loss: 0.884776\tAccuracy: 76.26%\n",
      "27\tValidation loss: 0.875157\tBest loss: 0.875157\tAccuracy: 76.26%\n",
      "28\tValidation loss: 0.866196\tBest loss: 0.866196\tAccuracy: 76.26%\n",
      "29\tValidation loss: 0.857441\tBest loss: 0.857441\tAccuracy: 76.98%\n",
      "30\tValidation loss: 0.848902\tBest loss: 0.848902\tAccuracy: 76.98%\n",
      "31\tValidation loss: 0.841367\tBest loss: 0.841367\tAccuracy: 76.98%\n",
      "32\tValidation loss: 0.833156\tBest loss: 0.833156\tAccuracy: 76.26%\n",
      "33\tValidation loss: 0.826457\tBest loss: 0.826457\tAccuracy: 76.26%\n",
      "34\tValidation loss: 0.819019\tBest loss: 0.819019\tAccuracy: 76.26%\n",
      "35\tValidation loss: 0.812392\tBest loss: 0.812392\tAccuracy: 76.26%\n",
      "36\tValidation loss: 0.806033\tBest loss: 0.806033\tAccuracy: 76.98%\n",
      "37\tValidation loss: 0.800091\tBest loss: 0.800091\tAccuracy: 76.98%\n",
      "38\tValidation loss: 0.794032\tBest loss: 0.794032\tAccuracy: 76.98%\n",
      "39\tValidation loss: 0.788059\tBest loss: 0.788059\tAccuracy: 76.98%\n",
      "40\tValidation loss: 0.782132\tBest loss: 0.782132\tAccuracy: 76.98%\n",
      "41\tValidation loss: 0.776336\tBest loss: 0.776336\tAccuracy: 76.98%\n",
      "42\tValidation loss: 0.770632\tBest loss: 0.770632\tAccuracy: 76.98%\n",
      "43\tValidation loss: 0.764956\tBest loss: 0.764956\tAccuracy: 76.98%\n",
      "44\tValidation loss: 0.759192\tBest loss: 0.759192\tAccuracy: 76.98%\n",
      "45\tValidation loss: 0.753499\tBest loss: 0.753499\tAccuracy: 76.98%\n",
      "46\tValidation loss: 0.747643\tBest loss: 0.747643\tAccuracy: 77.70%\n",
      "47\tValidation loss: 0.741817\tBest loss: 0.741817\tAccuracy: 77.70%\n",
      "48\tValidation loss: 0.737047\tBest loss: 0.737047\tAccuracy: 77.70%\n",
      "49\tValidation loss: 0.732249\tBest loss: 0.732249\tAccuracy: 77.70%\n",
      "50\tValidation loss: 0.727349\tBest loss: 0.727349\tAccuracy: 77.70%\n",
      "51\tValidation loss: 0.722743\tBest loss: 0.722743\tAccuracy: 76.98%\n",
      "52\tValidation loss: 0.717868\tBest loss: 0.717868\tAccuracy: 76.98%\n",
      "53\tValidation loss: 0.713152\tBest loss: 0.713152\tAccuracy: 76.98%\n",
      "54\tValidation loss: 0.708348\tBest loss: 0.708348\tAccuracy: 76.98%\n",
      "55\tValidation loss: 0.703683\tBest loss: 0.703683\tAccuracy: 76.98%\n",
      "56\tValidation loss: 0.698795\tBest loss: 0.698795\tAccuracy: 76.98%\n",
      "57\tValidation loss: 0.694559\tBest loss: 0.694559\tAccuracy: 76.98%\n",
      "58\tValidation loss: 0.689501\tBest loss: 0.689501\tAccuracy: 76.98%\n",
      "59\tValidation loss: 0.684902\tBest loss: 0.684902\tAccuracy: 76.98%\n",
      "60\tValidation loss: 0.680443\tBest loss: 0.680443\tAccuracy: 78.42%\n",
      "61\tValidation loss: 0.676214\tBest loss: 0.676214\tAccuracy: 78.42%\n",
      "62\tValidation loss: 0.672046\tBest loss: 0.672046\tAccuracy: 78.42%\n",
      "63\tValidation loss: 0.668068\tBest loss: 0.668068\tAccuracy: 79.14%\n",
      "64\tValidation loss: 0.663948\tBest loss: 0.663948\tAccuracy: 79.14%\n",
      "65\tValidation loss: 0.659433\tBest loss: 0.659433\tAccuracy: 79.14%\n",
      "66\tValidation loss: 0.655480\tBest loss: 0.655480\tAccuracy: 79.86%\n",
      "67\tValidation loss: 0.651457\tBest loss: 0.651457\tAccuracy: 79.86%\n",
      "68\tValidation loss: 0.647879\tBest loss: 0.647879\tAccuracy: 80.58%\n",
      "69\tValidation loss: 0.644156\tBest loss: 0.644156\tAccuracy: 80.58%\n",
      "70\tValidation loss: 0.640584\tBest loss: 0.640584\tAccuracy: 80.58%\n",
      "71\tValidation loss: 0.636903\tBest loss: 0.636903\tAccuracy: 80.58%\n",
      "72\tValidation loss: 0.633743\tBest loss: 0.633743\tAccuracy: 80.58%\n",
      "73\tValidation loss: 0.630111\tBest loss: 0.630111\tAccuracy: 80.58%\n",
      "74\tValidation loss: 0.626663\tBest loss: 0.626663\tAccuracy: 80.58%\n",
      "75\tValidation loss: 0.623282\tBest loss: 0.623282\tAccuracy: 81.29%\n",
      "76\tValidation loss: 0.620001\tBest loss: 0.620001\tAccuracy: 81.29%\n",
      "77\tValidation loss: 0.617181\tBest loss: 0.617181\tAccuracy: 81.29%\n",
      "78\tValidation loss: 0.614146\tBest loss: 0.614146\tAccuracy: 81.29%\n",
      "79\tValidation loss: 0.611193\tBest loss: 0.611193\tAccuracy: 81.29%\n",
      "80\tValidation loss: 0.608227\tBest loss: 0.608227\tAccuracy: 81.29%\n",
      "81\tValidation loss: 0.605523\tBest loss: 0.605523\tAccuracy: 81.29%\n",
      "82\tValidation loss: 0.602924\tBest loss: 0.602924\tAccuracy: 81.29%\n",
      "83\tValidation loss: 0.600239\tBest loss: 0.600239\tAccuracy: 81.29%\n",
      "84\tValidation loss: 0.597556\tBest loss: 0.597556\tAccuracy: 81.29%\n",
      "85\tValidation loss: 0.594785\tBest loss: 0.594785\tAccuracy: 82.01%\n",
      "86\tValidation loss: 0.592340\tBest loss: 0.592340\tAccuracy: 82.01%\n",
      "87\tValidation loss: 0.589752\tBest loss: 0.589752\tAccuracy: 82.01%\n",
      "88\tValidation loss: 0.587423\tBest loss: 0.587423\tAccuracy: 82.01%\n",
      "89\tValidation loss: 0.585091\tBest loss: 0.585091\tAccuracy: 82.01%\n",
      "90\tValidation loss: 0.582756\tBest loss: 0.582756\tAccuracy: 82.01%\n",
      "91\tValidation loss: 0.580453\tBest loss: 0.580453\tAccuracy: 82.01%\n",
      "92\tValidation loss: 0.578337\tBest loss: 0.578337\tAccuracy: 82.01%\n",
      "93\tValidation loss: 0.576092\tBest loss: 0.576092\tAccuracy: 82.01%\n",
      "94\tValidation loss: 0.573741\tBest loss: 0.573741\tAccuracy: 82.01%\n",
      "95\tValidation loss: 0.571456\tBest loss: 0.571456\tAccuracy: 82.73%\n",
      "96\tValidation loss: 0.568935\tBest loss: 0.568935\tAccuracy: 82.73%\n",
      "97\tValidation loss: 0.566803\tBest loss: 0.566803\tAccuracy: 83.45%\n",
      "98\tValidation loss: 0.564622\tBest loss: 0.564622\tAccuracy: 83.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\tValidation loss: 0.562553\tBest loss: 0.562553\tAccuracy: 84.17%\n",
      "100\tValidation loss: 0.560419\tBest loss: 0.560419\tAccuracy: 83.45%\n",
      "101\tValidation loss: 0.558064\tBest loss: 0.558064\tAccuracy: 83.45%\n",
      "102\tValidation loss: 0.556422\tBest loss: 0.556422\tAccuracy: 83.45%\n",
      "103\tValidation loss: 0.554219\tBest loss: 0.554219\tAccuracy: 83.45%\n",
      "104\tValidation loss: 0.552417\tBest loss: 0.552417\tAccuracy: 83.45%\n",
      "105\tValidation loss: 0.550400\tBest loss: 0.550400\tAccuracy: 83.45%\n",
      "106\tValidation loss: 0.548703\tBest loss: 0.548703\tAccuracy: 84.17%\n",
      "107\tValidation loss: 0.546636\tBest loss: 0.546636\tAccuracy: 84.17%\n",
      "108\tValidation loss: 0.544867\tBest loss: 0.544867\tAccuracy: 84.17%\n",
      "109\tValidation loss: 0.542662\tBest loss: 0.542662\tAccuracy: 84.17%\n",
      "110\tValidation loss: 0.540706\tBest loss: 0.540706\tAccuracy: 84.17%\n",
      "111\tValidation loss: 0.538790\tBest loss: 0.538790\tAccuracy: 84.17%\n",
      "112\tValidation loss: 0.536945\tBest loss: 0.536945\tAccuracy: 84.17%\n",
      "113\tValidation loss: 0.535213\tBest loss: 0.535213\tAccuracy: 84.17%\n",
      "114\tValidation loss: 0.533307\tBest loss: 0.533307\tAccuracy: 84.17%\n",
      "115\tValidation loss: 0.531573\tBest loss: 0.531573\tAccuracy: 84.17%\n",
      "116\tValidation loss: 0.529839\tBest loss: 0.529839\tAccuracy: 84.17%\n",
      "117\tValidation loss: 0.528417\tBest loss: 0.528417\tAccuracy: 84.17%\n",
      "118\tValidation loss: 0.526709\tBest loss: 0.526709\tAccuracy: 84.17%\n",
      "119\tValidation loss: 0.525544\tBest loss: 0.525544\tAccuracy: 84.17%\n",
      "120\tValidation loss: 0.523956\tBest loss: 0.523956\tAccuracy: 84.17%\n",
      "121\tValidation loss: 0.522728\tBest loss: 0.522728\tAccuracy: 84.17%\n",
      "122\tValidation loss: 0.521218\tBest loss: 0.521218\tAccuracy: 84.17%\n",
      "123\tValidation loss: 0.520229\tBest loss: 0.520229\tAccuracy: 84.17%\n",
      "124\tValidation loss: 0.518929\tBest loss: 0.518929\tAccuracy: 84.17%\n",
      "125\tValidation loss: 0.517455\tBest loss: 0.517455\tAccuracy: 84.17%\n",
      "126\tValidation loss: 0.516123\tBest loss: 0.516123\tAccuracy: 84.17%\n",
      "127\tValidation loss: 0.515138\tBest loss: 0.515138\tAccuracy: 84.17%\n",
      "128\tValidation loss: 0.513349\tBest loss: 0.513349\tAccuracy: 84.17%\n",
      "129\tValidation loss: 0.512341\tBest loss: 0.512341\tAccuracy: 84.17%\n",
      "130\tValidation loss: 0.511009\tBest loss: 0.511009\tAccuracy: 84.17%\n",
      "131\tValidation loss: 0.509830\tBest loss: 0.509830\tAccuracy: 84.17%\n",
      "132\tValidation loss: 0.508521\tBest loss: 0.508521\tAccuracy: 84.17%\n",
      "133\tValidation loss: 0.507274\tBest loss: 0.507274\tAccuracy: 84.17%\n",
      "134\tValidation loss: 0.505809\tBest loss: 0.505809\tAccuracy: 84.17%\n",
      "135\tValidation loss: 0.504702\tBest loss: 0.504702\tAccuracy: 84.17%\n",
      "136\tValidation loss: 0.503221\tBest loss: 0.503221\tAccuracy: 84.17%\n",
      "137\tValidation loss: 0.502406\tBest loss: 0.502406\tAccuracy: 84.17%\n",
      "138\tValidation loss: 0.500694\tBest loss: 0.500694\tAccuracy: 84.17%\n",
      "139\tValidation loss: 0.499393\tBest loss: 0.499393\tAccuracy: 84.17%\n",
      "140\tValidation loss: 0.498087\tBest loss: 0.498087\tAccuracy: 84.17%\n",
      "141\tValidation loss: 0.496765\tBest loss: 0.496765\tAccuracy: 84.17%\n",
      "142\tValidation loss: 0.495520\tBest loss: 0.495520\tAccuracy: 84.17%\n",
      "143\tValidation loss: 0.494380\tBest loss: 0.494380\tAccuracy: 84.17%\n",
      "144\tValidation loss: 0.493314\tBest loss: 0.493314\tAccuracy: 84.17%\n",
      "145\tValidation loss: 0.492031\tBest loss: 0.492031\tAccuracy: 84.17%\n",
      "146\tValidation loss: 0.490933\tBest loss: 0.490933\tAccuracy: 84.17%\n",
      "147\tValidation loss: 0.489733\tBest loss: 0.489733\tAccuracy: 84.89%\n",
      "148\tValidation loss: 0.488573\tBest loss: 0.488573\tAccuracy: 84.89%\n",
      "149\tValidation loss: 0.487370\tBest loss: 0.487370\tAccuracy: 84.89%\n",
      "150\tValidation loss: 0.486147\tBest loss: 0.486147\tAccuracy: 85.61%\n",
      "151\tValidation loss: 0.485006\tBest loss: 0.485006\tAccuracy: 85.61%\n",
      "152\tValidation loss: 0.483973\tBest loss: 0.483973\tAccuracy: 85.61%\n",
      "153\tValidation loss: 0.482757\tBest loss: 0.482757\tAccuracy: 85.61%\n",
      "154\tValidation loss: 0.481835\tBest loss: 0.481835\tAccuracy: 85.61%\n",
      "155\tValidation loss: 0.480548\tBest loss: 0.480548\tAccuracy: 85.61%\n",
      "156\tValidation loss: 0.479492\tBest loss: 0.479492\tAccuracy: 85.61%\n",
      "157\tValidation loss: 0.478619\tBest loss: 0.478619\tAccuracy: 85.61%\n",
      "158\tValidation loss: 0.477273\tBest loss: 0.477273\tAccuracy: 85.61%\n",
      "159\tValidation loss: 0.476279\tBest loss: 0.476279\tAccuracy: 85.61%\n",
      "160\tValidation loss: 0.475252\tBest loss: 0.475252\tAccuracy: 85.61%\n",
      "161\tValidation loss: 0.474429\tBest loss: 0.474429\tAccuracy: 85.61%\n",
      "162\tValidation loss: 0.473146\tBest loss: 0.473146\tAccuracy: 86.33%\n",
      "163\tValidation loss: 0.472104\tBest loss: 0.472104\tAccuracy: 86.33%\n",
      "164\tValidation loss: 0.471142\tBest loss: 0.471142\tAccuracy: 86.33%\n",
      "165\tValidation loss: 0.470315\tBest loss: 0.470315\tAccuracy: 86.33%\n",
      "166\tValidation loss: 0.469353\tBest loss: 0.469353\tAccuracy: 86.33%\n",
      "167\tValidation loss: 0.468704\tBest loss: 0.468704\tAccuracy: 86.33%\n",
      "168\tValidation loss: 0.467548\tBest loss: 0.467548\tAccuracy: 86.33%\n",
      "169\tValidation loss: 0.467054\tBest loss: 0.467054\tAccuracy: 86.33%\n",
      "170\tValidation loss: 0.465868\tBest loss: 0.465868\tAccuracy: 87.05%\n",
      "171\tValidation loss: 0.465317\tBest loss: 0.465317\tAccuracy: 87.05%\n",
      "172\tValidation loss: 0.464263\tBest loss: 0.464263\tAccuracy: 87.05%\n",
      "173\tValidation loss: 0.463546\tBest loss: 0.463546\tAccuracy: 87.05%\n",
      "174\tValidation loss: 0.462705\tBest loss: 0.462705\tAccuracy: 87.05%\n",
      "175\tValidation loss: 0.462023\tBest loss: 0.462023\tAccuracy: 87.05%\n",
      "176\tValidation loss: 0.461237\tBest loss: 0.461237\tAccuracy: 87.05%\n",
      "177\tValidation loss: 0.460288\tBest loss: 0.460288\tAccuracy: 87.05%\n",
      "178\tValidation loss: 0.459724\tBest loss: 0.459724\tAccuracy: 87.05%\n",
      "179\tValidation loss: 0.458745\tBest loss: 0.458745\tAccuracy: 87.05%\n",
      "180\tValidation loss: 0.458334\tBest loss: 0.458334\tAccuracy: 87.05%\n",
      "181\tValidation loss: 0.457359\tBest loss: 0.457359\tAccuracy: 86.33%\n",
      "182\tValidation loss: 0.456841\tBest loss: 0.456841\tAccuracy: 86.33%\n",
      "183\tValidation loss: 0.455623\tBest loss: 0.455623\tAccuracy: 86.33%\n",
      "184\tValidation loss: 0.455126\tBest loss: 0.455126\tAccuracy: 85.61%\n",
      "185\tValidation loss: 0.454082\tBest loss: 0.454082\tAccuracy: 85.61%\n",
      "186\tValidation loss: 0.453608\tBest loss: 0.453608\tAccuracy: 85.61%\n",
      "187\tValidation loss: 0.452498\tBest loss: 0.452498\tAccuracy: 85.61%\n",
      "188\tValidation loss: 0.452183\tBest loss: 0.452183\tAccuracy: 85.61%\n",
      "189\tValidation loss: 0.450924\tBest loss: 0.450924\tAccuracy: 85.61%\n",
      "190\tValidation loss: 0.450437\tBest loss: 0.450437\tAccuracy: 85.61%\n",
      "191\tValidation loss: 0.449739\tBest loss: 0.449739\tAccuracy: 85.61%\n",
      "192\tValidation loss: 0.449025\tBest loss: 0.449025\tAccuracy: 85.61%\n",
      "193\tValidation loss: 0.448061\tBest loss: 0.448061\tAccuracy: 85.61%\n",
      "194\tValidation loss: 0.447570\tBest loss: 0.447570\tAccuracy: 85.61%\n",
      "195\tValidation loss: 0.446822\tBest loss: 0.446822\tAccuracy: 85.61%\n",
      "196\tValidation loss: 0.446307\tBest loss: 0.446307\tAccuracy: 85.61%\n",
      "197\tValidation loss: 0.445359\tBest loss: 0.445359\tAccuracy: 85.61%\n",
      "198\tValidation loss: 0.444862\tBest loss: 0.444862\tAccuracy: 85.61%\n",
      "199\tValidation loss: 0.444051\tBest loss: 0.444051\tAccuracy: 85.61%\n",
      "200\tValidation loss: 0.443416\tBest loss: 0.443416\tAccuracy: 85.61%\n",
      "201\tValidation loss: 0.442719\tBest loss: 0.442719\tAccuracy: 86.33%\n",
      "202\tValidation loss: 0.442093\tBest loss: 0.442093\tAccuracy: 86.33%\n",
      "203\tValidation loss: 0.441035\tBest loss: 0.441035\tAccuracy: 86.33%\n",
      "204\tValidation loss: 0.440591\tBest loss: 0.440591\tAccuracy: 86.33%\n",
      "205\tValidation loss: 0.439976\tBest loss: 0.439976\tAccuracy: 86.33%\n",
      "206\tValidation loss: 0.438954\tBest loss: 0.438954\tAccuracy: 86.33%\n",
      "207\tValidation loss: 0.438432\tBest loss: 0.438432\tAccuracy: 86.33%\n",
      "208\tValidation loss: 0.437712\tBest loss: 0.437712\tAccuracy: 86.33%\n",
      "209\tValidation loss: 0.436914\tBest loss: 0.436914\tAccuracy: 86.33%\n",
      "210\tValidation loss: 0.436404\tBest loss: 0.436404\tAccuracy: 87.05%\n",
      "211\tValidation loss: 0.435430\tBest loss: 0.435430\tAccuracy: 87.05%\n",
      "212\tValidation loss: 0.434924\tBest loss: 0.434924\tAccuracy: 87.05%\n",
      "213\tValidation loss: 0.434073\tBest loss: 0.434073\tAccuracy: 87.05%\n",
      "214\tValidation loss: 0.433538\tBest loss: 0.433538\tAccuracy: 87.05%\n",
      "215\tValidation loss: 0.432860\tBest loss: 0.432860\tAccuracy: 87.05%\n",
      "216\tValidation loss: 0.432262\tBest loss: 0.432262\tAccuracy: 87.05%\n",
      "217\tValidation loss: 0.431418\tBest loss: 0.431418\tAccuracy: 87.05%\n",
      "218\tValidation loss: 0.430929\tBest loss: 0.430929\tAccuracy: 87.05%\n",
      "219\tValidation loss: 0.430333\tBest loss: 0.430333\tAccuracy: 87.05%\n",
      "220\tValidation loss: 0.429386\tBest loss: 0.429386\tAccuracy: 87.05%\n",
      "221\tValidation loss: 0.429077\tBest loss: 0.429077\tAccuracy: 87.05%\n",
      "222\tValidation loss: 0.428509\tBest loss: 0.428509\tAccuracy: 87.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\tValidation loss: 0.427925\tBest loss: 0.427925\tAccuracy: 87.05%\n",
      "224\tValidation loss: 0.427051\tBest loss: 0.427051\tAccuracy: 87.05%\n",
      "225\tValidation loss: 0.426992\tBest loss: 0.426992\tAccuracy: 87.05%\n",
      "226\tValidation loss: 0.426008\tBest loss: 0.426008\tAccuracy: 87.05%\n",
      "227\tValidation loss: 0.425665\tBest loss: 0.425665\tAccuracy: 87.05%\n",
      "228\tValidation loss: 0.424875\tBest loss: 0.424875\tAccuracy: 87.05%\n",
      "229\tValidation loss: 0.424462\tBest loss: 0.424462\tAccuracy: 87.05%\n",
      "230\tValidation loss: 0.423865\tBest loss: 0.423865\tAccuracy: 87.05%\n",
      "231\tValidation loss: 0.423339\tBest loss: 0.423339\tAccuracy: 87.05%\n",
      "232\tValidation loss: 0.422807\tBest loss: 0.422807\tAccuracy: 87.77%\n",
      "233\tValidation loss: 0.422352\tBest loss: 0.422352\tAccuracy: 87.77%\n",
      "234\tValidation loss: 0.421938\tBest loss: 0.421938\tAccuracy: 87.77%\n",
      "235\tValidation loss: 0.421336\tBest loss: 0.421336\tAccuracy: 87.77%\n",
      "236\tValidation loss: 0.421001\tBest loss: 0.421001\tAccuracy: 87.77%\n",
      "237\tValidation loss: 0.420361\tBest loss: 0.420361\tAccuracy: 87.77%\n",
      "238\tValidation loss: 0.420010\tBest loss: 0.420010\tAccuracy: 87.77%\n",
      "239\tValidation loss: 0.419528\tBest loss: 0.419528\tAccuracy: 87.77%\n",
      "240\tValidation loss: 0.418917\tBest loss: 0.418917\tAccuracy: 87.77%\n",
      "241\tValidation loss: 0.418391\tBest loss: 0.418391\tAccuracy: 87.77%\n",
      "242\tValidation loss: 0.418047\tBest loss: 0.418047\tAccuracy: 87.77%\n",
      "243\tValidation loss: 0.417525\tBest loss: 0.417525\tAccuracy: 88.49%\n",
      "244\tValidation loss: 0.417338\tBest loss: 0.417338\tAccuracy: 88.49%\n",
      "245\tValidation loss: 0.416656\tBest loss: 0.416656\tAccuracy: 88.49%\n",
      "246\tValidation loss: 0.416339\tBest loss: 0.416339\tAccuracy: 88.49%\n",
      "247\tValidation loss: 0.416057\tBest loss: 0.416057\tAccuracy: 88.49%\n",
      "248\tValidation loss: 0.415561\tBest loss: 0.415561\tAccuracy: 88.49%\n",
      "249\tValidation loss: 0.415383\tBest loss: 0.415383\tAccuracy: 88.49%\n",
      "250\tValidation loss: 0.414890\tBest loss: 0.414890\tAccuracy: 88.49%\n",
      "251\tValidation loss: 0.414473\tBest loss: 0.414473\tAccuracy: 88.49%\n",
      "252\tValidation loss: 0.413918\tBest loss: 0.413918\tAccuracy: 88.49%\n",
      "253\tValidation loss: 0.413776\tBest loss: 0.413776\tAccuracy: 88.49%\n",
      "254\tValidation loss: 0.413439\tBest loss: 0.413439\tAccuracy: 88.49%\n",
      "255\tValidation loss: 0.413073\tBest loss: 0.413073\tAccuracy: 88.49%\n",
      "256\tValidation loss: 0.412633\tBest loss: 0.412633\tAccuracy: 88.49%\n",
      "257\tValidation loss: 0.412457\tBest loss: 0.412457\tAccuracy: 88.49%\n",
      "258\tValidation loss: 0.412003\tBest loss: 0.412003\tAccuracy: 88.49%\n",
      "259\tValidation loss: 0.411648\tBest loss: 0.411648\tAccuracy: 88.49%\n",
      "260\tValidation loss: 0.411115\tBest loss: 0.411115\tAccuracy: 88.49%\n",
      "261\tValidation loss: 0.410980\tBest loss: 0.410980\tAccuracy: 88.49%\n",
      "262\tValidation loss: 0.410618\tBest loss: 0.410618\tAccuracy: 88.49%\n",
      "263\tValidation loss: 0.410126\tBest loss: 0.410126\tAccuracy: 88.49%\n",
      "264\tValidation loss: 0.409849\tBest loss: 0.409849\tAccuracy: 88.49%\n",
      "265\tValidation loss: 0.409469\tBest loss: 0.409469\tAccuracy: 88.49%\n",
      "266\tValidation loss: 0.409173\tBest loss: 0.409173\tAccuracy: 88.49%\n",
      "267\tValidation loss: 0.408680\tBest loss: 0.408680\tAccuracy: 88.49%\n",
      "268\tValidation loss: 0.408404\tBest loss: 0.408404\tAccuracy: 88.49%\n",
      "269\tValidation loss: 0.408011\tBest loss: 0.408011\tAccuracy: 88.49%\n",
      "270\tValidation loss: 0.407694\tBest loss: 0.407694\tAccuracy: 88.49%\n",
      "271\tValidation loss: 0.407227\tBest loss: 0.407227\tAccuracy: 88.49%\n",
      "272\tValidation loss: 0.406946\tBest loss: 0.406946\tAccuracy: 88.49%\n",
      "273\tValidation loss: 0.406619\tBest loss: 0.406619\tAccuracy: 88.49%\n",
      "274\tValidation loss: 0.406408\tBest loss: 0.406408\tAccuracy: 88.49%\n",
      "275\tValidation loss: 0.405876\tBest loss: 0.405876\tAccuracy: 88.49%\n",
      "276\tValidation loss: 0.405560\tBest loss: 0.405560\tAccuracy: 88.49%\n",
      "277\tValidation loss: 0.405341\tBest loss: 0.405341\tAccuracy: 88.49%\n",
      "278\tValidation loss: 0.404964\tBest loss: 0.404964\tAccuracy: 88.49%\n",
      "279\tValidation loss: 0.404545\tBest loss: 0.404545\tAccuracy: 88.49%\n",
      "280\tValidation loss: 0.404409\tBest loss: 0.404409\tAccuracy: 88.49%\n",
      "281\tValidation loss: 0.403898\tBest loss: 0.403898\tAccuracy: 88.49%\n",
      "282\tValidation loss: 0.403744\tBest loss: 0.403744\tAccuracy: 88.49%\n",
      "283\tValidation loss: 0.403324\tBest loss: 0.403324\tAccuracy: 88.49%\n",
      "284\tValidation loss: 0.402984\tBest loss: 0.402984\tAccuracy: 88.49%\n",
      "285\tValidation loss: 0.402558\tBest loss: 0.402558\tAccuracy: 88.49%\n",
      "286\tValidation loss: 0.402510\tBest loss: 0.402510\tAccuracy: 88.49%\n",
      "287\tValidation loss: 0.401964\tBest loss: 0.401964\tAccuracy: 88.49%\n",
      "288\tValidation loss: 0.401880\tBest loss: 0.401880\tAccuracy: 88.49%\n",
      "289\tValidation loss: 0.401258\tBest loss: 0.401258\tAccuracy: 88.49%\n",
      "290\tValidation loss: 0.401270\tBest loss: 0.401258\tAccuracy: 88.49%\n",
      "291\tValidation loss: 0.400949\tBest loss: 0.400949\tAccuracy: 88.49%\n",
      "292\tValidation loss: 0.400725\tBest loss: 0.400725\tAccuracy: 88.49%\n",
      "293\tValidation loss: 0.400499\tBest loss: 0.400499\tAccuracy: 88.49%\n",
      "294\tValidation loss: 0.400485\tBest loss: 0.400485\tAccuracy: 88.49%\n",
      "295\tValidation loss: 0.400024\tBest loss: 0.400024\tAccuracy: 88.49%\n",
      "296\tValidation loss: 0.399917\tBest loss: 0.399917\tAccuracy: 88.49%\n",
      "297\tValidation loss: 0.399685\tBest loss: 0.399685\tAccuracy: 88.49%\n",
      "298\tValidation loss: 0.399354\tBest loss: 0.399354\tAccuracy: 88.49%\n",
      "299\tValidation loss: 0.399277\tBest loss: 0.399277\tAccuracy: 88.49%\n",
      "300\tValidation loss: 0.398897\tBest loss: 0.398897\tAccuracy: 88.49%\n",
      "301\tValidation loss: 0.398647\tBest loss: 0.398647\tAccuracy: 89.21%\n",
      "302\tValidation loss: 0.398559\tBest loss: 0.398559\tAccuracy: 88.49%\n",
      "303\tValidation loss: 0.398121\tBest loss: 0.398121\tAccuracy: 89.21%\n",
      "304\tValidation loss: 0.398057\tBest loss: 0.398057\tAccuracy: 89.21%\n",
      "305\tValidation loss: 0.397714\tBest loss: 0.397714\tAccuracy: 89.21%\n",
      "306\tValidation loss: 0.397532\tBest loss: 0.397532\tAccuracy: 89.21%\n",
      "307\tValidation loss: 0.397290\tBest loss: 0.397290\tAccuracy: 89.21%\n",
      "308\tValidation loss: 0.397035\tBest loss: 0.397035\tAccuracy: 89.21%\n",
      "309\tValidation loss: 0.396942\tBest loss: 0.396942\tAccuracy: 89.21%\n",
      "310\tValidation loss: 0.396483\tBest loss: 0.396483\tAccuracy: 89.21%\n",
      "311\tValidation loss: 0.396362\tBest loss: 0.396362\tAccuracy: 89.21%\n",
      "312\tValidation loss: 0.396075\tBest loss: 0.396075\tAccuracy: 89.21%\n",
      "313\tValidation loss: 0.395969\tBest loss: 0.395969\tAccuracy: 89.21%\n",
      "314\tValidation loss: 0.395759\tBest loss: 0.395759\tAccuracy: 88.49%\n",
      "315\tValidation loss: 0.395471\tBest loss: 0.395471\tAccuracy: 89.21%\n",
      "316\tValidation loss: 0.395352\tBest loss: 0.395352\tAccuracy: 89.21%\n",
      "317\tValidation loss: 0.394961\tBest loss: 0.394961\tAccuracy: 89.21%\n",
      "318\tValidation loss: 0.394935\tBest loss: 0.394935\tAccuracy: 89.21%\n",
      "319\tValidation loss: 0.394587\tBest loss: 0.394587\tAccuracy: 89.21%\n",
      "320\tValidation loss: 0.394331\tBest loss: 0.394331\tAccuracy: 89.21%\n",
      "321\tValidation loss: 0.394283\tBest loss: 0.394283\tAccuracy: 89.21%\n",
      "322\tValidation loss: 0.393774\tBest loss: 0.393774\tAccuracy: 89.21%\n",
      "323\tValidation loss: 0.393858\tBest loss: 0.393774\tAccuracy: 89.21%\n",
      "324\tValidation loss: 0.393374\tBest loss: 0.393374\tAccuracy: 89.21%\n",
      "325\tValidation loss: 0.393303\tBest loss: 0.393303\tAccuracy: 89.21%\n",
      "326\tValidation loss: 0.392915\tBest loss: 0.392915\tAccuracy: 89.21%\n",
      "327\tValidation loss: 0.392756\tBest loss: 0.392756\tAccuracy: 89.21%\n",
      "328\tValidation loss: 0.392617\tBest loss: 0.392617\tAccuracy: 89.21%\n",
      "329\tValidation loss: 0.392375\tBest loss: 0.392375\tAccuracy: 89.21%\n",
      "330\tValidation loss: 0.392041\tBest loss: 0.392041\tAccuracy: 89.21%\n",
      "331\tValidation loss: 0.391844\tBest loss: 0.391844\tAccuracy: 89.21%\n",
      "332\tValidation loss: 0.391512\tBest loss: 0.391512\tAccuracy: 89.21%\n",
      "333\tValidation loss: 0.391353\tBest loss: 0.391353\tAccuracy: 89.21%\n",
      "334\tValidation loss: 0.391215\tBest loss: 0.391215\tAccuracy: 89.21%\n",
      "335\tValidation loss: 0.391198\tBest loss: 0.391198\tAccuracy: 89.21%\n",
      "336\tValidation loss: 0.391022\tBest loss: 0.391022\tAccuracy: 89.21%\n",
      "337\tValidation loss: 0.390769\tBest loss: 0.390769\tAccuracy: 89.21%\n",
      "338\tValidation loss: 0.390760\tBest loss: 0.390760\tAccuracy: 89.21%\n",
      "339\tValidation loss: 0.390384\tBest loss: 0.390384\tAccuracy: 89.21%\n",
      "340\tValidation loss: 0.390428\tBest loss: 0.390384\tAccuracy: 89.21%\n",
      "341\tValidation loss: 0.390221\tBest loss: 0.390221\tAccuracy: 89.21%\n",
      "342\tValidation loss: 0.390252\tBest loss: 0.390221\tAccuracy: 89.21%\n",
      "343\tValidation loss: 0.390126\tBest loss: 0.390126\tAccuracy: 89.21%\n",
      "344\tValidation loss: 0.389896\tBest loss: 0.389896\tAccuracy: 89.21%\n",
      "345\tValidation loss: 0.389787\tBest loss: 0.389787\tAccuracy: 89.21%\n",
      "346\tValidation loss: 0.389583\tBest loss: 0.389583\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\tValidation loss: 0.389541\tBest loss: 0.389541\tAccuracy: 89.21%\n",
      "348\tValidation loss: 0.389446\tBest loss: 0.389446\tAccuracy: 89.21%\n",
      "349\tValidation loss: 0.389437\tBest loss: 0.389437\tAccuracy: 89.21%\n",
      "350\tValidation loss: 0.389186\tBest loss: 0.389186\tAccuracy: 89.21%\n",
      "351\tValidation loss: 0.389188\tBest loss: 0.389186\tAccuracy: 89.21%\n",
      "352\tValidation loss: 0.389118\tBest loss: 0.389118\tAccuracy: 89.21%\n",
      "353\tValidation loss: 0.388855\tBest loss: 0.388855\tAccuracy: 89.21%\n",
      "354\tValidation loss: 0.389141\tBest loss: 0.388855\tAccuracy: 89.21%\n",
      "355\tValidation loss: 0.389022\tBest loss: 0.388855\tAccuracy: 89.21%\n",
      "356\tValidation loss: 0.388891\tBest loss: 0.388855\tAccuracy: 89.21%\n",
      "357\tValidation loss: 0.388935\tBest loss: 0.388855\tAccuracy: 89.21%\n",
      "358\tValidation loss: 0.388742\tBest loss: 0.388742\tAccuracy: 89.21%\n",
      "359\tValidation loss: 0.388892\tBest loss: 0.388742\tAccuracy: 89.21%\n",
      "360\tValidation loss: 0.388897\tBest loss: 0.388742\tAccuracy: 89.21%\n",
      "361\tValidation loss: 0.388814\tBest loss: 0.388742\tAccuracy: 89.21%\n",
      "362\tValidation loss: 0.388549\tBest loss: 0.388549\tAccuracy: 89.21%\n",
      "363\tValidation loss: 0.388618\tBest loss: 0.388549\tAccuracy: 89.21%\n",
      "364\tValidation loss: 0.388609\tBest loss: 0.388549\tAccuracy: 89.21%\n",
      "365\tValidation loss: 0.388476\tBest loss: 0.388476\tAccuracy: 89.21%\n",
      "366\tValidation loss: 0.388469\tBest loss: 0.388469\tAccuracy: 89.21%\n",
      "367\tValidation loss: 0.388530\tBest loss: 0.388469\tAccuracy: 89.21%\n",
      "368\tValidation loss: 0.388530\tBest loss: 0.388469\tAccuracy: 89.21%\n",
      "369\tValidation loss: 0.388312\tBest loss: 0.388312\tAccuracy: 89.21%\n",
      "370\tValidation loss: 0.388497\tBest loss: 0.388312\tAccuracy: 89.21%\n",
      "371\tValidation loss: 0.388416\tBest loss: 0.388312\tAccuracy: 89.21%\n",
      "372\tValidation loss: 0.388518\tBest loss: 0.388312\tAccuracy: 88.49%\n",
      "373\tValidation loss: 0.388699\tBest loss: 0.388312\tAccuracy: 89.21%\n",
      "374\tValidation loss: 0.388403\tBest loss: 0.388312\tAccuracy: 88.49%\n",
      "375\tValidation loss: 0.388574\tBest loss: 0.388312\tAccuracy: 89.21%\n",
      "376\tValidation loss: 0.388297\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "377\tValidation loss: 0.388508\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "378\tValidation loss: 0.388425\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "379\tValidation loss: 0.388488\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "380\tValidation loss: 0.388329\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "381\tValidation loss: 0.388508\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "382\tValidation loss: 0.388480\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "383\tValidation loss: 0.388317\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "384\tValidation loss: 0.388585\tBest loss: 0.388297\tAccuracy: 88.49%\n",
      "385\tValidation loss: 0.388228\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "386\tValidation loss: 0.388668\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "387\tValidation loss: 0.388373\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "388\tValidation loss: 0.388619\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "389\tValidation loss: 0.388709\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "390\tValidation loss: 0.388531\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "391\tValidation loss: 0.388728\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "392\tValidation loss: 0.388705\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "393\tValidation loss: 0.388690\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "394\tValidation loss: 0.388818\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "395\tValidation loss: 0.388814\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "396\tValidation loss: 0.388826\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "397\tValidation loss: 0.388825\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "398\tValidation loss: 0.388932\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "399\tValidation loss: 0.388845\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "400\tValidation loss: 0.388931\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "401\tValidation loss: 0.389131\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "402\tValidation loss: 0.388961\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "403\tValidation loss: 0.389277\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "404\tValidation loss: 0.389240\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "405\tValidation loss: 0.389270\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "406\tValidation loss: 0.389352\tBest loss: 0.388228\tAccuracy: 88.49%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  51.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 116.787766\tBest loss: 116.787766\tAccuracy: 0.00%\n",
      "1\tValidation loss: 189.276657\tBest loss: 116.787766\tAccuracy: 3.60%\n",
      "2\tValidation loss: 254.184525\tBest loss: 116.787766\tAccuracy: 5.76%\n",
      "3\tValidation loss: 258.406372\tBest loss: 116.787766\tAccuracy: 2.88%\n",
      "4\tValidation loss: 102.473618\tBest loss: 102.473618\tAccuracy: 3.60%\n",
      "5\tValidation loss: 72.556030\tBest loss: 72.556030\tAccuracy: 4.32%\n",
      "6\tValidation loss: 63.623169\tBest loss: 63.623169\tAccuracy: 18.71%\n",
      "7\tValidation loss: 22.881693\tBest loss: 22.881693\tAccuracy: 16.55%\n",
      "8\tValidation loss: 20.256813\tBest loss: 20.256813\tAccuracy: 15.83%\n",
      "9\tValidation loss: 18.546873\tBest loss: 18.546873\tAccuracy: 14.39%\n",
      "10\tValidation loss: 7.825404\tBest loss: 7.825404\tAccuracy: 25.18%\n",
      "11\tValidation loss: 7.906748\tBest loss: 7.825404\tAccuracy: 28.78%\n",
      "12\tValidation loss: 4.226153\tBest loss: 4.226153\tAccuracy: 37.41%\n",
      "13\tValidation loss: 3.010358\tBest loss: 3.010358\tAccuracy: 48.92%\n",
      "14\tValidation loss: 2.056027\tBest loss: 2.056027\tAccuracy: 61.15%\n",
      "15\tValidation loss: 1.534482\tBest loss: 1.534482\tAccuracy: 69.78%\n",
      "16\tValidation loss: 1.528023\tBest loss: 1.528023\tAccuracy: 69.78%\n",
      "17\tValidation loss: 1.337593\tBest loss: 1.337593\tAccuracy: 74.82%\n",
      "18\tValidation loss: 1.320429\tBest loss: 1.320429\tAccuracy: 74.82%\n",
      "19\tValidation loss: 1.240458\tBest loss: 1.240458\tAccuracy: 77.70%\n",
      "20\tValidation loss: 1.234685\tBest loss: 1.234685\tAccuracy: 77.70%\n",
      "21\tValidation loss: 1.201177\tBest loss: 1.201177\tAccuracy: 77.70%\n",
      "22\tValidation loss: 1.190592\tBest loss: 1.190592\tAccuracy: 77.70%\n",
      "23\tValidation loss: 1.172465\tBest loss: 1.172465\tAccuracy: 79.14%\n",
      "24\tValidation loss: 1.161288\tBest loss: 1.161288\tAccuracy: 79.14%\n",
      "25\tValidation loss: 1.149039\tBest loss: 1.149039\tAccuracy: 79.14%\n",
      "26\tValidation loss: 1.139043\tBest loss: 1.139043\tAccuracy: 78.42%\n",
      "27\tValidation loss: 1.129649\tBest loss: 1.129649\tAccuracy: 78.42%\n",
      "28\tValidation loss: 1.119844\tBest loss: 1.119844\tAccuracy: 78.42%\n",
      "29\tValidation loss: 1.111359\tBest loss: 1.111359\tAccuracy: 79.14%\n",
      "30\tValidation loss: 1.103294\tBest loss: 1.103294\tAccuracy: 79.14%\n",
      "31\tValidation loss: 1.095636\tBest loss: 1.095636\tAccuracy: 79.14%\n",
      "32\tValidation loss: 1.088338\tBest loss: 1.088338\tAccuracy: 79.86%\n",
      "33\tValidation loss: 1.081200\tBest loss: 1.081200\tAccuracy: 79.86%\n",
      "34\tValidation loss: 1.074710\tBest loss: 1.074710\tAccuracy: 79.86%\n",
      "35\tValidation loss: 1.068062\tBest loss: 1.068062\tAccuracy: 79.86%\n",
      "36\tValidation loss: 1.062171\tBest loss: 1.062171\tAccuracy: 79.86%\n",
      "37\tValidation loss: 1.056121\tBest loss: 1.056121\tAccuracy: 80.58%\n",
      "38\tValidation loss: 1.050683\tBest loss: 1.050683\tAccuracy: 80.58%\n",
      "39\tValidation loss: 1.045629\tBest loss: 1.045629\tAccuracy: 80.58%\n",
      "40\tValidation loss: 1.040894\tBest loss: 1.040894\tAccuracy: 81.29%\n",
      "41\tValidation loss: 1.036170\tBest loss: 1.036170\tAccuracy: 81.29%\n",
      "42\tValidation loss: 1.031736\tBest loss: 1.031736\tAccuracy: 81.29%\n",
      "43\tValidation loss: 1.027357\tBest loss: 1.027357\tAccuracy: 81.29%\n",
      "44\tValidation loss: 1.023241\tBest loss: 1.023241\tAccuracy: 81.29%\n",
      "45\tValidation loss: 1.019014\tBest loss: 1.019014\tAccuracy: 81.29%\n",
      "46\tValidation loss: 1.015097\tBest loss: 1.015097\tAccuracy: 83.45%\n",
      "47\tValidation loss: 1.011535\tBest loss: 1.011535\tAccuracy: 83.45%\n",
      "48\tValidation loss: 1.008118\tBest loss: 1.008118\tAccuracy: 82.73%\n",
      "49\tValidation loss: 1.004809\tBest loss: 1.004809\tAccuracy: 82.73%\n",
      "50\tValidation loss: 1.001628\tBest loss: 1.001628\tAccuracy: 82.73%\n",
      "51\tValidation loss: 0.998757\tBest loss: 0.998757\tAccuracy: 82.73%\n",
      "52\tValidation loss: 0.995607\tBest loss: 0.995607\tAccuracy: 82.73%\n",
      "53\tValidation loss: 0.992871\tBest loss: 0.992871\tAccuracy: 83.45%\n",
      "54\tValidation loss: 0.990023\tBest loss: 0.990023\tAccuracy: 83.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\tValidation loss: 0.987165\tBest loss: 0.987165\tAccuracy: 83.45%\n",
      "56\tValidation loss: 0.984283\tBest loss: 0.984283\tAccuracy: 83.45%\n",
      "57\tValidation loss: 0.982037\tBest loss: 0.982037\tAccuracy: 83.45%\n",
      "58\tValidation loss: 0.979469\tBest loss: 0.979469\tAccuracy: 83.45%\n",
      "59\tValidation loss: 0.977009\tBest loss: 0.977009\tAccuracy: 83.45%\n",
      "60\tValidation loss: 0.974680\tBest loss: 0.974680\tAccuracy: 83.45%\n",
      "61\tValidation loss: 0.972033\tBest loss: 0.972033\tAccuracy: 83.45%\n",
      "62\tValidation loss: 0.969383\tBest loss: 0.969383\tAccuracy: 83.45%\n",
      "63\tValidation loss: 0.966746\tBest loss: 0.966746\tAccuracy: 83.45%\n",
      "64\tValidation loss: 0.963928\tBest loss: 0.963928\tAccuracy: 83.45%\n",
      "65\tValidation loss: 0.961738\tBest loss: 0.961738\tAccuracy: 83.45%\n",
      "66\tValidation loss: 0.959437\tBest loss: 0.959437\tAccuracy: 83.45%\n",
      "67\tValidation loss: 0.956739\tBest loss: 0.956739\tAccuracy: 83.45%\n",
      "68\tValidation loss: 0.954589\tBest loss: 0.954589\tAccuracy: 84.17%\n",
      "69\tValidation loss: 0.952151\tBest loss: 0.952151\tAccuracy: 84.17%\n",
      "70\tValidation loss: 0.950266\tBest loss: 0.950266\tAccuracy: 84.17%\n",
      "71\tValidation loss: 0.948212\tBest loss: 0.948212\tAccuracy: 84.17%\n",
      "72\tValidation loss: 0.945969\tBest loss: 0.945969\tAccuracy: 84.89%\n",
      "73\tValidation loss: 0.944037\tBest loss: 0.944037\tAccuracy: 84.89%\n",
      "74\tValidation loss: 0.942016\tBest loss: 0.942016\tAccuracy: 84.89%\n",
      "75\tValidation loss: 0.940237\tBest loss: 0.940237\tAccuracy: 87.05%\n",
      "76\tValidation loss: 0.938346\tBest loss: 0.938346\tAccuracy: 87.05%\n",
      "77\tValidation loss: 0.936776\tBest loss: 0.936776\tAccuracy: 87.05%\n",
      "78\tValidation loss: 0.934980\tBest loss: 0.934980\tAccuracy: 87.05%\n",
      "79\tValidation loss: 0.933405\tBest loss: 0.933405\tAccuracy: 87.05%\n",
      "80\tValidation loss: 0.931277\tBest loss: 0.931277\tAccuracy: 87.05%\n",
      "81\tValidation loss: 0.929896\tBest loss: 0.929896\tAccuracy: 87.05%\n",
      "82\tValidation loss: 0.927761\tBest loss: 0.927761\tAccuracy: 87.05%\n",
      "83\tValidation loss: 0.926253\tBest loss: 0.926253\tAccuracy: 87.05%\n",
      "84\tValidation loss: 0.924533\tBest loss: 0.924533\tAccuracy: 87.05%\n",
      "85\tValidation loss: 0.923056\tBest loss: 0.923056\tAccuracy: 87.05%\n",
      "86\tValidation loss: 0.921217\tBest loss: 0.921217\tAccuracy: 87.05%\n",
      "87\tValidation loss: 0.919703\tBest loss: 0.919703\tAccuracy: 87.05%\n",
      "88\tValidation loss: 0.918534\tBest loss: 0.918534\tAccuracy: 87.05%\n",
      "89\tValidation loss: 0.917319\tBest loss: 0.917319\tAccuracy: 87.05%\n",
      "90\tValidation loss: 0.915813\tBest loss: 0.915813\tAccuracy: 87.05%\n",
      "91\tValidation loss: 0.914639\tBest loss: 0.914639\tAccuracy: 87.05%\n",
      "92\tValidation loss: 0.913186\tBest loss: 0.913186\tAccuracy: 87.05%\n",
      "93\tValidation loss: 0.911957\tBest loss: 0.911957\tAccuracy: 87.05%\n",
      "94\tValidation loss: 0.910711\tBest loss: 0.910711\tAccuracy: 87.05%\n",
      "95\tValidation loss: 0.909421\tBest loss: 0.909421\tAccuracy: 87.05%\n",
      "96\tValidation loss: 0.908237\tBest loss: 0.908237\tAccuracy: 87.05%\n",
      "97\tValidation loss: 0.907040\tBest loss: 0.907040\tAccuracy: 87.05%\n",
      "98\tValidation loss: 0.905914\tBest loss: 0.905914\tAccuracy: 87.05%\n",
      "99\tValidation loss: 0.904731\tBest loss: 0.904731\tAccuracy: 86.33%\n",
      "100\tValidation loss: 0.903554\tBest loss: 0.903554\tAccuracy: 87.05%\n",
      "101\tValidation loss: 0.902347\tBest loss: 0.902347\tAccuracy: 86.33%\n",
      "102\tValidation loss: 0.900954\tBest loss: 0.900954\tAccuracy: 86.33%\n",
      "103\tValidation loss: 0.900450\tBest loss: 0.900450\tAccuracy: 86.33%\n",
      "104\tValidation loss: 0.898763\tBest loss: 0.898763\tAccuracy: 86.33%\n",
      "105\tValidation loss: 0.898191\tBest loss: 0.898191\tAccuracy: 86.33%\n",
      "106\tValidation loss: 0.896464\tBest loss: 0.896464\tAccuracy: 86.33%\n",
      "107\tValidation loss: 0.896011\tBest loss: 0.896011\tAccuracy: 86.33%\n",
      "108\tValidation loss: 0.894491\tBest loss: 0.894491\tAccuracy: 86.33%\n",
      "109\tValidation loss: 0.893572\tBest loss: 0.893572\tAccuracy: 86.33%\n",
      "110\tValidation loss: 0.892154\tBest loss: 0.892154\tAccuracy: 86.33%\n",
      "111\tValidation loss: 0.891605\tBest loss: 0.891605\tAccuracy: 86.33%\n",
      "112\tValidation loss: 0.890016\tBest loss: 0.890016\tAccuracy: 86.33%\n",
      "113\tValidation loss: 0.889364\tBest loss: 0.889364\tAccuracy: 86.33%\n",
      "114\tValidation loss: 0.888189\tBest loss: 0.888189\tAccuracy: 86.33%\n",
      "115\tValidation loss: 0.887672\tBest loss: 0.887672\tAccuracy: 86.33%\n",
      "116\tValidation loss: 0.886561\tBest loss: 0.886561\tAccuracy: 86.33%\n",
      "117\tValidation loss: 0.885924\tBest loss: 0.885924\tAccuracy: 86.33%\n",
      "118\tValidation loss: 0.885472\tBest loss: 0.885472\tAccuracy: 86.33%\n",
      "119\tValidation loss: 0.884478\tBest loss: 0.884478\tAccuracy: 86.33%\n",
      "120\tValidation loss: 0.883905\tBest loss: 0.883905\tAccuracy: 86.33%\n",
      "121\tValidation loss: 0.883307\tBest loss: 0.883307\tAccuracy: 86.33%\n",
      "122\tValidation loss: 0.882569\tBest loss: 0.882569\tAccuracy: 86.33%\n",
      "123\tValidation loss: 0.881932\tBest loss: 0.881932\tAccuracy: 86.33%\n",
      "124\tValidation loss: 0.881170\tBest loss: 0.881170\tAccuracy: 86.33%\n",
      "125\tValidation loss: 0.880577\tBest loss: 0.880577\tAccuracy: 86.33%\n",
      "126\tValidation loss: 0.879946\tBest loss: 0.879946\tAccuracy: 86.33%\n",
      "127\tValidation loss: 0.879393\tBest loss: 0.879393\tAccuracy: 86.33%\n",
      "128\tValidation loss: 0.878853\tBest loss: 0.878853\tAccuracy: 86.33%\n",
      "129\tValidation loss: 0.878147\tBest loss: 0.878147\tAccuracy: 86.33%\n",
      "130\tValidation loss: 0.877626\tBest loss: 0.877626\tAccuracy: 86.33%\n",
      "131\tValidation loss: 0.876650\tBest loss: 0.876650\tAccuracy: 86.33%\n",
      "132\tValidation loss: 0.876358\tBest loss: 0.876358\tAccuracy: 86.33%\n",
      "133\tValidation loss: 0.875422\tBest loss: 0.875422\tAccuracy: 86.33%\n",
      "134\tValidation loss: 0.874984\tBest loss: 0.874984\tAccuracy: 86.33%\n",
      "135\tValidation loss: 0.874078\tBest loss: 0.874078\tAccuracy: 86.33%\n",
      "136\tValidation loss: 0.873512\tBest loss: 0.873512\tAccuracy: 87.05%\n",
      "137\tValidation loss: 0.873082\tBest loss: 0.873082\tAccuracy: 87.05%\n",
      "138\tValidation loss: 0.872211\tBest loss: 0.872211\tAccuracy: 87.05%\n",
      "139\tValidation loss: 0.871699\tBest loss: 0.871699\tAccuracy: 87.05%\n",
      "140\tValidation loss: 0.871056\tBest loss: 0.871056\tAccuracy: 87.05%\n",
      "141\tValidation loss: 0.870503\tBest loss: 0.870503\tAccuracy: 87.05%\n",
      "142\tValidation loss: 0.869689\tBest loss: 0.869689\tAccuracy: 87.05%\n",
      "143\tValidation loss: 0.869264\tBest loss: 0.869264\tAccuracy: 87.05%\n",
      "144\tValidation loss: 0.868559\tBest loss: 0.868559\tAccuracy: 87.05%\n",
      "145\tValidation loss: 0.868403\tBest loss: 0.868403\tAccuracy: 87.05%\n",
      "146\tValidation loss: 0.867489\tBest loss: 0.867489\tAccuracy: 87.05%\n",
      "147\tValidation loss: 0.867696\tBest loss: 0.867489\tAccuracy: 87.05%\n",
      "148\tValidation loss: 0.866736\tBest loss: 0.866736\tAccuracy: 87.05%\n",
      "149\tValidation loss: 0.866589\tBest loss: 0.866589\tAccuracy: 87.05%\n",
      "150\tValidation loss: 0.865755\tBest loss: 0.865755\tAccuracy: 87.05%\n",
      "151\tValidation loss: 0.865508\tBest loss: 0.865508\tAccuracy: 87.05%\n",
      "152\tValidation loss: 0.864830\tBest loss: 0.864830\tAccuracy: 87.05%\n",
      "153\tValidation loss: 0.864861\tBest loss: 0.864830\tAccuracy: 87.05%\n",
      "154\tValidation loss: 0.864110\tBest loss: 0.864110\tAccuracy: 87.05%\n",
      "155\tValidation loss: 0.864125\tBest loss: 0.864110\tAccuracy: 87.05%\n",
      "156\tValidation loss: 0.863376\tBest loss: 0.863376\tAccuracy: 87.05%\n",
      "157\tValidation loss: 0.863211\tBest loss: 0.863211\tAccuracy: 87.05%\n",
      "158\tValidation loss: 0.862630\tBest loss: 0.862630\tAccuracy: 87.05%\n",
      "159\tValidation loss: 0.862363\tBest loss: 0.862363\tAccuracy: 87.05%\n",
      "160\tValidation loss: 0.861859\tBest loss: 0.861859\tAccuracy: 87.05%\n",
      "161\tValidation loss: 0.861575\tBest loss: 0.861575\tAccuracy: 87.05%\n",
      "162\tValidation loss: 0.861193\tBest loss: 0.861193\tAccuracy: 87.05%\n",
      "163\tValidation loss: 0.861073\tBest loss: 0.861073\tAccuracy: 87.05%\n",
      "164\tValidation loss: 0.860492\tBest loss: 0.860492\tAccuracy: 87.77%\n",
      "165\tValidation loss: 0.859930\tBest loss: 0.859930\tAccuracy: 87.77%\n",
      "166\tValidation loss: 0.859629\tBest loss: 0.859629\tAccuracy: 87.77%\n",
      "167\tValidation loss: 0.858813\tBest loss: 0.858813\tAccuracy: 87.77%\n",
      "168\tValidation loss: 0.858732\tBest loss: 0.858732\tAccuracy: 87.77%\n",
      "169\tValidation loss: 0.857764\tBest loss: 0.857764\tAccuracy: 87.77%\n",
      "170\tValidation loss: 0.857741\tBest loss: 0.857741\tAccuracy: 87.77%\n",
      "171\tValidation loss: 0.856987\tBest loss: 0.856987\tAccuracy: 87.77%\n",
      "172\tValidation loss: 0.856860\tBest loss: 0.856860\tAccuracy: 87.77%\n",
      "173\tValidation loss: 0.856073\tBest loss: 0.856073\tAccuracy: 87.77%\n",
      "174\tValidation loss: 0.856065\tBest loss: 0.856065\tAccuracy: 87.77%\n",
      "175\tValidation loss: 0.855411\tBest loss: 0.855411\tAccuracy: 87.77%\n",
      "176\tValidation loss: 0.855120\tBest loss: 0.855120\tAccuracy: 87.77%\n",
      "177\tValidation loss: 0.854644\tBest loss: 0.854644\tAccuracy: 87.77%\n",
      "178\tValidation loss: 0.854324\tBest loss: 0.854324\tAccuracy: 87.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\tValidation loss: 0.854092\tBest loss: 0.854092\tAccuracy: 87.77%\n",
      "180\tValidation loss: 0.853433\tBest loss: 0.853433\tAccuracy: 87.77%\n",
      "181\tValidation loss: 0.853332\tBest loss: 0.853332\tAccuracy: 87.77%\n",
      "182\tValidation loss: 0.852557\tBest loss: 0.852557\tAccuracy: 87.77%\n",
      "183\tValidation loss: 0.852401\tBest loss: 0.852401\tAccuracy: 87.77%\n",
      "184\tValidation loss: 0.851624\tBest loss: 0.851624\tAccuracy: 87.77%\n",
      "185\tValidation loss: 0.851812\tBest loss: 0.851624\tAccuracy: 87.77%\n",
      "186\tValidation loss: 0.850946\tBest loss: 0.850946\tAccuracy: 87.77%\n",
      "187\tValidation loss: 0.850809\tBest loss: 0.850809\tAccuracy: 87.77%\n",
      "188\tValidation loss: 0.850357\tBest loss: 0.850357\tAccuracy: 87.77%\n",
      "189\tValidation loss: 0.850076\tBest loss: 0.850076\tAccuracy: 87.77%\n",
      "190\tValidation loss: 0.849657\tBest loss: 0.849657\tAccuracy: 87.77%\n",
      "191\tValidation loss: 0.849669\tBest loss: 0.849657\tAccuracy: 87.77%\n",
      "192\tValidation loss: 0.849134\tBest loss: 0.849134\tAccuracy: 87.77%\n",
      "193\tValidation loss: 0.849181\tBest loss: 0.849134\tAccuracy: 87.77%\n",
      "194\tValidation loss: 0.848765\tBest loss: 0.848765\tAccuracy: 87.77%\n",
      "195\tValidation loss: 0.848693\tBest loss: 0.848693\tAccuracy: 87.77%\n",
      "196\tValidation loss: 0.848509\tBest loss: 0.848509\tAccuracy: 87.77%\n",
      "197\tValidation loss: 0.848367\tBest loss: 0.848367\tAccuracy: 87.77%\n",
      "198\tValidation loss: 0.848072\tBest loss: 0.848072\tAccuracy: 87.77%\n",
      "199\tValidation loss: 0.847922\tBest loss: 0.847922\tAccuracy: 87.77%\n",
      "200\tValidation loss: 0.847768\tBest loss: 0.847768\tAccuracy: 87.77%\n",
      "201\tValidation loss: 0.847694\tBest loss: 0.847694\tAccuracy: 87.77%\n",
      "202\tValidation loss: 0.847555\tBest loss: 0.847555\tAccuracy: 87.77%\n",
      "203\tValidation loss: 0.847412\tBest loss: 0.847412\tAccuracy: 87.77%\n",
      "204\tValidation loss: 0.847434\tBest loss: 0.847412\tAccuracy: 87.77%\n",
      "205\tValidation loss: 0.847312\tBest loss: 0.847312\tAccuracy: 87.77%\n",
      "206\tValidation loss: 0.847344\tBest loss: 0.847312\tAccuracy: 87.77%\n",
      "207\tValidation loss: 0.847471\tBest loss: 0.847312\tAccuracy: 87.77%\n",
      "208\tValidation loss: 0.847255\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "209\tValidation loss: 0.847422\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "210\tValidation loss: 0.847466\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "211\tValidation loss: 0.847412\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "212\tValidation loss: 0.847349\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "213\tValidation loss: 0.847490\tBest loss: 0.847255\tAccuracy: 87.77%\n",
      "214\tValidation loss: 0.847184\tBest loss: 0.847184\tAccuracy: 87.77%\n",
      "215\tValidation loss: 0.847492\tBest loss: 0.847184\tAccuracy: 87.77%\n",
      "216\tValidation loss: 0.847247\tBest loss: 0.847184\tAccuracy: 87.77%\n",
      "217\tValidation loss: 0.847481\tBest loss: 0.847184\tAccuracy: 87.77%\n",
      "218\tValidation loss: 0.847059\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "219\tValidation loss: 0.847462\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "220\tValidation loss: 0.847097\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "221\tValidation loss: 0.847495\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "222\tValidation loss: 0.847138\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "223\tValidation loss: 0.847242\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "224\tValidation loss: 0.847450\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "225\tValidation loss: 0.847188\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "226\tValidation loss: 0.847640\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "227\tValidation loss: 0.847152\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "228\tValidation loss: 0.847672\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "229\tValidation loss: 0.847369\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "230\tValidation loss: 0.847521\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "231\tValidation loss: 0.847532\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "232\tValidation loss: 0.847558\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "233\tValidation loss: 0.847539\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "234\tValidation loss: 0.847452\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "235\tValidation loss: 0.847349\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "236\tValidation loss: 0.847575\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "237\tValidation loss: 0.847298\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "238\tValidation loss: 0.847455\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "239\tValidation loss: 0.847370\tBest loss: 0.847059\tAccuracy: 87.77%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  30.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 3.063439\tBest loss: 3.063439\tAccuracy: 46.76%\n",
      "1\tValidation loss: 2.987054\tBest loss: 2.987054\tAccuracy: 41.73%\n",
      "2\tValidation loss: 1.965079\tBest loss: 1.965079\tAccuracy: 56.83%\n",
      "3\tValidation loss: 1.382616\tBest loss: 1.382616\tAccuracy: 65.47%\n",
      "4\tValidation loss: 0.986574\tBest loss: 0.986574\tAccuracy: 75.54%\n",
      "5\tValidation loss: 1.144853\tBest loss: 0.986574\tAccuracy: 67.63%\n",
      "6\tValidation loss: 0.874584\tBest loss: 0.874584\tAccuracy: 76.98%\n",
      "7\tValidation loss: 0.641541\tBest loss: 0.641541\tAccuracy: 85.61%\n",
      "8\tValidation loss: 0.583894\tBest loss: 0.583894\tAccuracy: 86.33%\n",
      "9\tValidation loss: 0.672548\tBest loss: 0.583894\tAccuracy: 82.73%\n",
      "10\tValidation loss: 0.621961\tBest loss: 0.583894\tAccuracy: 82.73%\n",
      "11\tValidation loss: 0.593692\tBest loss: 0.583894\tAccuracy: 87.05%\n",
      "12\tValidation loss: 0.552582\tBest loss: 0.552582\tAccuracy: 82.73%\n",
      "13\tValidation loss: 0.562629\tBest loss: 0.552582\tAccuracy: 87.77%\n",
      "14\tValidation loss: 0.550729\tBest loss: 0.550729\tAccuracy: 84.17%\n",
      "15\tValidation loss: 0.499595\tBest loss: 0.499595\tAccuracy: 87.05%\n",
      "16\tValidation loss: 0.403876\tBest loss: 0.403876\tAccuracy: 89.21%\n",
      "17\tValidation loss: 0.425435\tBest loss: 0.403876\tAccuracy: 87.05%\n",
      "18\tValidation loss: 0.522491\tBest loss: 0.403876\tAccuracy: 85.61%\n",
      "19\tValidation loss: 0.516653\tBest loss: 0.403876\tAccuracy: 86.33%\n",
      "20\tValidation loss: 0.372362\tBest loss: 0.372362\tAccuracy: 85.61%\n",
      "21\tValidation loss: 0.390051\tBest loss: 0.372362\tAccuracy: 89.93%\n",
      "22\tValidation loss: 0.354629\tBest loss: 0.354629\tAccuracy: 89.21%\n",
      "23\tValidation loss: 0.343775\tBest loss: 0.343775\tAccuracy: 89.93%\n",
      "24\tValidation loss: 0.450219\tBest loss: 0.343775\tAccuracy: 89.21%\n",
      "25\tValidation loss: 0.392722\tBest loss: 0.343775\tAccuracy: 88.49%\n",
      "26\tValidation loss: 0.299412\tBest loss: 0.299412\tAccuracy: 92.09%\n",
      "27\tValidation loss: 0.295224\tBest loss: 0.295224\tAccuracy: 92.81%\n",
      "28\tValidation loss: 0.338485\tBest loss: 0.295224\tAccuracy: 89.21%\n",
      "29\tValidation loss: 0.329225\tBest loss: 0.295224\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.575869\tBest loss: 0.295224\tAccuracy: 88.49%\n",
      "31\tValidation loss: 0.374463\tBest loss: 0.295224\tAccuracy: 88.49%\n",
      "32\tValidation loss: 0.296561\tBest loss: 0.295224\tAccuracy: 90.65%\n",
      "33\tValidation loss: 0.260098\tBest loss: 0.260098\tAccuracy: 92.09%\n",
      "34\tValidation loss: 0.316608\tBest loss: 0.260098\tAccuracy: 89.21%\n",
      "35\tValidation loss: 0.291638\tBest loss: 0.260098\tAccuracy: 90.65%\n",
      "36\tValidation loss: 0.257089\tBest loss: 0.257089\tAccuracy: 91.37%\n",
      "37\tValidation loss: 0.258303\tBest loss: 0.257089\tAccuracy: 92.81%\n",
      "38\tValidation loss: 0.329639\tBest loss: 0.257089\tAccuracy: 89.21%\n",
      "39\tValidation loss: 0.245777\tBest loss: 0.245777\tAccuracy: 92.81%\n",
      "40\tValidation loss: 0.237380\tBest loss: 0.237380\tAccuracy: 92.09%\n",
      "41\tValidation loss: 0.310937\tBest loss: 0.237380\tAccuracy: 91.37%\n",
      "42\tValidation loss: 0.241040\tBest loss: 0.237380\tAccuracy: 92.81%\n",
      "43\tValidation loss: 0.307271\tBest loss: 0.237380\tAccuracy: 90.65%\n",
      "44\tValidation loss: 0.264549\tBest loss: 0.237380\tAccuracy: 92.81%\n",
      "45\tValidation loss: 0.243049\tBest loss: 0.237380\tAccuracy: 91.37%\n",
      "46\tValidation loss: 0.269563\tBest loss: 0.237380\tAccuracy: 90.65%\n",
      "47\tValidation loss: 0.257198\tBest loss: 0.237380\tAccuracy: 89.93%\n",
      "48\tValidation loss: 0.288869\tBest loss: 0.237380\tAccuracy: 89.21%\n",
      "49\tValidation loss: 0.244466\tBest loss: 0.237380\tAccuracy: 92.09%\n",
      "50\tValidation loss: 0.242105\tBest loss: 0.237380\tAccuracy: 92.81%\n",
      "51\tValidation loss: 0.257582\tBest loss: 0.237380\tAccuracy: 90.65%\n",
      "52\tValidation loss: 0.271402\tBest loss: 0.237380\tAccuracy: 91.37%\n",
      "53\tValidation loss: 0.258503\tBest loss: 0.237380\tAccuracy: 92.09%\n",
      "54\tValidation loss: 0.267448\tBest loss: 0.237380\tAccuracy: 90.65%\n",
      "55\tValidation loss: 0.217498\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "56\tValidation loss: 0.260232\tBest loss: 0.217498\tAccuracy: 91.37%\n",
      "57\tValidation loss: 0.270641\tBest loss: 0.217498\tAccuracy: 93.53%\n",
      "58\tValidation loss: 0.331944\tBest loss: 0.217498\tAccuracy: 90.65%\n",
      "59\tValidation loss: 0.276056\tBest loss: 0.217498\tAccuracy: 91.37%\n",
      "60\tValidation loss: 0.300526\tBest loss: 0.217498\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.323888\tBest loss: 0.217498\tAccuracy: 89.93%\n",
      "62\tValidation loss: 0.288277\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "63\tValidation loss: 0.285909\tBest loss: 0.217498\tAccuracy: 92.09%\n",
      "64\tValidation loss: 0.262162\tBest loss: 0.217498\tAccuracy: 93.53%\n",
      "65\tValidation loss: 0.250609\tBest loss: 0.217498\tAccuracy: 93.53%\n",
      "66\tValidation loss: 0.261701\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "67\tValidation loss: 0.252041\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "68\tValidation loss: 0.257691\tBest loss: 0.217498\tAccuracy: 91.37%\n",
      "69\tValidation loss: 0.257827\tBest loss: 0.217498\tAccuracy: 92.09%\n",
      "70\tValidation loss: 0.239764\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "71\tValidation loss: 0.263279\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "72\tValidation loss: 0.234809\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "73\tValidation loss: 0.241604\tBest loss: 0.217498\tAccuracy: 92.81%\n",
      "74\tValidation loss: 0.263587\tBest loss: 0.217498\tAccuracy: 91.37%\n",
      "75\tValidation loss: 0.266104\tBest loss: 0.217498\tAccuracy: 92.09%\n",
      "76\tValidation loss: 0.280046\tBest loss: 0.217498\tAccuracy: 89.93%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  17.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 4.398331\tBest loss: 4.398331\tAccuracy: 35.25%\n",
      "1\tValidation loss: 2.744152\tBest loss: 2.744152\tAccuracy: 53.24%\n",
      "2\tValidation loss: 2.039116\tBest loss: 2.039116\tAccuracy: 50.36%\n",
      "3\tValidation loss: 2.030084\tBest loss: 2.030084\tAccuracy: 64.75%\n",
      "4\tValidation loss: 0.875569\tBest loss: 0.875569\tAccuracy: 76.98%\n",
      "5\tValidation loss: 0.810626\tBest loss: 0.810626\tAccuracy: 76.98%\n",
      "6\tValidation loss: 0.701932\tBest loss: 0.701932\tAccuracy: 79.14%\n",
      "7\tValidation loss: 0.749154\tBest loss: 0.701932\tAccuracy: 77.70%\n",
      "8\tValidation loss: 0.706073\tBest loss: 0.701932\tAccuracy: 77.70%\n",
      "9\tValidation loss: 0.571523\tBest loss: 0.571523\tAccuracy: 83.45%\n",
      "10\tValidation loss: 0.820036\tBest loss: 0.571523\tAccuracy: 78.42%\n",
      "11\tValidation loss: 0.581255\tBest loss: 0.571523\tAccuracy: 83.45%\n",
      "12\tValidation loss: 0.548466\tBest loss: 0.548466\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.543157\tBest loss: 0.543157\tAccuracy: 82.73%\n",
      "14\tValidation loss: 0.515766\tBest loss: 0.515766\tAccuracy: 84.89%\n",
      "15\tValidation loss: 0.447439\tBest loss: 0.447439\tAccuracy: 85.61%\n",
      "16\tValidation loss: 0.477122\tBest loss: 0.447439\tAccuracy: 82.73%\n",
      "17\tValidation loss: 0.444894\tBest loss: 0.444894\tAccuracy: 84.89%\n",
      "18\tValidation loss: 0.488929\tBest loss: 0.444894\tAccuracy: 82.73%\n",
      "19\tValidation loss: 0.377745\tBest loss: 0.377745\tAccuracy: 88.49%\n",
      "20\tValidation loss: 0.435818\tBest loss: 0.377745\tAccuracy: 87.05%\n",
      "21\tValidation loss: 0.301330\tBest loss: 0.301330\tAccuracy: 92.81%\n",
      "22\tValidation loss: 0.305165\tBest loss: 0.301330\tAccuracy: 91.37%\n",
      "23\tValidation loss: 0.433354\tBest loss: 0.301330\tAccuracy: 86.33%\n",
      "24\tValidation loss: 0.314270\tBest loss: 0.301330\tAccuracy: 90.65%\n",
      "25\tValidation loss: 0.298351\tBest loss: 0.298351\tAccuracy: 89.21%\n",
      "26\tValidation loss: 0.280332\tBest loss: 0.280332\tAccuracy: 88.49%\n",
      "27\tValidation loss: 0.333504\tBest loss: 0.280332\tAccuracy: 87.05%\n",
      "28\tValidation loss: 0.260662\tBest loss: 0.260662\tAccuracy: 89.93%\n",
      "29\tValidation loss: 0.349831\tBest loss: 0.260662\tAccuracy: 88.49%\n",
      "30\tValidation loss: 0.370331\tBest loss: 0.260662\tAccuracy: 85.61%\n",
      "31\tValidation loss: 0.314140\tBest loss: 0.260662\tAccuracy: 92.09%\n",
      "32\tValidation loss: 0.389037\tBest loss: 0.260662\tAccuracy: 89.93%\n",
      "33\tValidation loss: 0.360345\tBest loss: 0.260662\tAccuracy: 87.77%\n",
      "34\tValidation loss: 0.419574\tBest loss: 0.260662\tAccuracy: 89.93%\n",
      "35\tValidation loss: 0.286103\tBest loss: 0.260662\tAccuracy: 90.65%\n",
      "36\tValidation loss: 0.342854\tBest loss: 0.260662\tAccuracy: 91.37%\n",
      "37\tValidation loss: 0.260843\tBest loss: 0.260662\tAccuracy: 90.65%\n",
      "38\tValidation loss: 0.296097\tBest loss: 0.260662\tAccuracy: 87.05%\n",
      "39\tValidation loss: 0.241656\tBest loss: 0.241656\tAccuracy: 91.37%\n",
      "40\tValidation loss: 0.244061\tBest loss: 0.241656\tAccuracy: 92.09%\n",
      "41\tValidation loss: 0.274169\tBest loss: 0.241656\tAccuracy: 91.37%\n",
      "42\tValidation loss: 0.378427\tBest loss: 0.241656\tAccuracy: 89.93%\n",
      "43\tValidation loss: 0.302511\tBest loss: 0.241656\tAccuracy: 89.93%\n",
      "44\tValidation loss: 0.283737\tBest loss: 0.241656\tAccuracy: 89.21%\n",
      "45\tValidation loss: 0.341682\tBest loss: 0.241656\tAccuracy: 92.81%\n",
      "46\tValidation loss: 0.256352\tBest loss: 0.241656\tAccuracy: 90.65%\n",
      "47\tValidation loss: 0.261889\tBest loss: 0.241656\tAccuracy: 87.77%\n",
      "48\tValidation loss: 0.212548\tBest loss: 0.212548\tAccuracy: 93.53%\n",
      "49\tValidation loss: 0.198438\tBest loss: 0.198438\tAccuracy: 92.09%\n",
      "50\tValidation loss: 0.255200\tBest loss: 0.198438\tAccuracy: 91.37%\n",
      "51\tValidation loss: 0.202173\tBest loss: 0.198438\tAccuracy: 92.81%\n",
      "52\tValidation loss: 0.216568\tBest loss: 0.198438\tAccuracy: 92.81%\n",
      "53\tValidation loss: 0.208959\tBest loss: 0.198438\tAccuracy: 92.81%\n",
      "54\tValidation loss: 0.220129\tBest loss: 0.198438\tAccuracy: 93.53%\n",
      "55\tValidation loss: 0.217573\tBest loss: 0.198438\tAccuracy: 92.09%\n",
      "56\tValidation loss: 0.330102\tBest loss: 0.198438\tAccuracy: 91.37%\n",
      "57\tValidation loss: 0.247515\tBest loss: 0.198438\tAccuracy: 92.09%\n",
      "58\tValidation loss: 0.205574\tBest loss: 0.198438\tAccuracy: 92.81%\n",
      "59\tValidation loss: 0.198174\tBest loss: 0.198174\tAccuracy: 93.53%\n",
      "60\tValidation loss: 0.209261\tBest loss: 0.198174\tAccuracy: 92.81%\n",
      "61\tValidation loss: 0.222014\tBest loss: 0.198174\tAccuracy: 92.81%\n",
      "62\tValidation loss: 0.181222\tBest loss: 0.181222\tAccuracy: 93.53%\n",
      "63\tValidation loss: 0.200610\tBest loss: 0.181222\tAccuracy: 93.53%\n",
      "64\tValidation loss: 0.202632\tBest loss: 0.181222\tAccuracy: 93.53%\n",
      "65\tValidation loss: 0.209915\tBest loss: 0.181222\tAccuracy: 93.53%\n",
      "66\tValidation loss: 0.181778\tBest loss: 0.181222\tAccuracy: 92.81%\n",
      "67\tValidation loss: 0.171507\tBest loss: 0.171507\tAccuracy: 93.53%\n",
      "68\tValidation loss: 0.179353\tBest loss: 0.171507\tAccuracy: 92.81%\n",
      "69\tValidation loss: 0.176198\tBest loss: 0.171507\tAccuracy: 94.24%\n",
      "70\tValidation loss: 0.177391\tBest loss: 0.171507\tAccuracy: 94.24%\n",
      "71\tValidation loss: 0.196459\tBest loss: 0.171507\tAccuracy: 92.81%\n",
      "72\tValidation loss: 0.192466\tBest loss: 0.171507\tAccuracy: 91.37%\n",
      "73\tValidation loss: 0.173858\tBest loss: 0.171507\tAccuracy: 93.53%\n",
      "74\tValidation loss: 0.186791\tBest loss: 0.171507\tAccuracy: 92.09%\n",
      "75\tValidation loss: 0.164492\tBest loss: 0.164492\tAccuracy: 94.24%\n",
      "76\tValidation loss: 0.156243\tBest loss: 0.156243\tAccuracy: 94.24%\n",
      "77\tValidation loss: 0.171842\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "78\tValidation loss: 0.194852\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "79\tValidation loss: 0.171197\tBest loss: 0.156243\tAccuracy: 93.53%\n",
      "80\tValidation loss: 0.192140\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "81\tValidation loss: 0.190286\tBest loss: 0.156243\tAccuracy: 93.53%\n",
      "82\tValidation loss: 0.175687\tBest loss: 0.156243\tAccuracy: 93.53%\n",
      "83\tValidation loss: 0.166460\tBest loss: 0.156243\tAccuracy: 93.53%\n",
      "84\tValidation loss: 0.173369\tBest loss: 0.156243\tAccuracy: 94.24%\n",
      "85\tValidation loss: 0.188731\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "86\tValidation loss: 0.165031\tBest loss: 0.156243\tAccuracy: 93.53%\n",
      "87\tValidation loss: 0.190561\tBest loss: 0.156243\tAccuracy: 92.09%\n",
      "88\tValidation loss: 0.187121\tBest loss: 0.156243\tAccuracy: 92.09%\n",
      "89\tValidation loss: 0.186424\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "90\tValidation loss: 0.188245\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "91\tValidation loss: 0.194136\tBest loss: 0.156243\tAccuracy: 92.09%\n",
      "92\tValidation loss: 0.209553\tBest loss: 0.156243\tAccuracy: 91.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\tValidation loss: 0.183689\tBest loss: 0.156243\tAccuracy: 92.81%\n",
      "94\tValidation loss: 0.226286\tBest loss: 0.156243\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.209925\tBest loss: 0.156243\tAccuracy: 92.09%\n",
      "96\tValidation loss: 0.228015\tBest loss: 0.156243\tAccuracy: 92.09%\n",
      "97\tValidation loss: 0.194381\tBest loss: 0.156243\tAccuracy: 94.24%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  22.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 4.717387\tBest loss: 4.717387\tAccuracy: 35.97%\n",
      "1\tValidation loss: 1.858845\tBest loss: 1.858845\tAccuracy: 48.92%\n",
      "2\tValidation loss: 1.481776\tBest loss: 1.481776\tAccuracy: 61.15%\n",
      "3\tValidation loss: 1.188058\tBest loss: 1.188058\tAccuracy: 68.35%\n",
      "4\tValidation loss: 0.683044\tBest loss: 0.683044\tAccuracy: 79.14%\n",
      "5\tValidation loss: 0.669069\tBest loss: 0.669069\tAccuracy: 79.86%\n",
      "6\tValidation loss: 0.881208\tBest loss: 0.669069\tAccuracy: 74.82%\n",
      "7\tValidation loss: 0.767010\tBest loss: 0.669069\tAccuracy: 75.54%\n",
      "8\tValidation loss: 0.841008\tBest loss: 0.669069\tAccuracy: 82.73%\n",
      "9\tValidation loss: 0.591121\tBest loss: 0.591121\tAccuracy: 82.73%\n",
      "10\tValidation loss: 0.578892\tBest loss: 0.578892\tAccuracy: 82.73%\n",
      "11\tValidation loss: 0.884681\tBest loss: 0.578892\tAccuracy: 81.29%\n",
      "12\tValidation loss: 0.503568\tBest loss: 0.503568\tAccuracy: 84.17%\n",
      "13\tValidation loss: 0.512393\tBest loss: 0.503568\tAccuracy: 86.33%\n",
      "14\tValidation loss: 0.508723\tBest loss: 0.503568\tAccuracy: 87.05%\n",
      "15\tValidation loss: 0.453585\tBest loss: 0.453585\tAccuracy: 87.77%\n",
      "16\tValidation loss: 0.455677\tBest loss: 0.453585\tAccuracy: 87.77%\n",
      "17\tValidation loss: 0.447174\tBest loss: 0.447174\tAccuracy: 85.61%\n",
      "18\tValidation loss: 0.389982\tBest loss: 0.389982\tAccuracy: 89.21%\n",
      "19\tValidation loss: 0.385339\tBest loss: 0.385339\tAccuracy: 86.33%\n",
      "20\tValidation loss: 0.330572\tBest loss: 0.330572\tAccuracy: 91.37%\n",
      "21\tValidation loss: 0.389005\tBest loss: 0.330572\tAccuracy: 87.77%\n",
      "22\tValidation loss: 0.319369\tBest loss: 0.319369\tAccuracy: 89.93%\n",
      "23\tValidation loss: 0.360295\tBest loss: 0.319369\tAccuracy: 88.49%\n",
      "24\tValidation loss: 0.441157\tBest loss: 0.319369\tAccuracy: 89.93%\n",
      "25\tValidation loss: 0.320380\tBest loss: 0.319369\tAccuracy: 90.65%\n",
      "26\tValidation loss: 0.357577\tBest loss: 0.319369\tAccuracy: 87.77%\n",
      "27\tValidation loss: 0.349185\tBest loss: 0.319369\tAccuracy: 87.77%\n",
      "28\tValidation loss: 0.448320\tBest loss: 0.319369\tAccuracy: 88.49%\n",
      "29\tValidation loss: 0.375145\tBest loss: 0.319369\tAccuracy: 89.21%\n",
      "30\tValidation loss: 0.302112\tBest loss: 0.302112\tAccuracy: 90.65%\n",
      "31\tValidation loss: 0.481235\tBest loss: 0.302112\tAccuracy: 90.65%\n",
      "32\tValidation loss: 0.257031\tBest loss: 0.257031\tAccuracy: 92.09%\n",
      "33\tValidation loss: 0.290015\tBest loss: 0.257031\tAccuracy: 89.93%\n",
      "34\tValidation loss: 0.260538\tBest loss: 0.257031\tAccuracy: 92.81%\n",
      "35\tValidation loss: 0.224635\tBest loss: 0.224635\tAccuracy: 93.53%\n",
      "36\tValidation loss: 0.244276\tBest loss: 0.224635\tAccuracy: 92.09%\n",
      "37\tValidation loss: 0.282490\tBest loss: 0.224635\tAccuracy: 92.09%\n",
      "38\tValidation loss: 0.295567\tBest loss: 0.224635\tAccuracy: 92.09%\n",
      "39\tValidation loss: 0.283968\tBest loss: 0.224635\tAccuracy: 90.65%\n",
      "40\tValidation loss: 0.244568\tBest loss: 0.224635\tAccuracy: 91.37%\n",
      "41\tValidation loss: 0.301695\tBest loss: 0.224635\tAccuracy: 89.93%\n",
      "42\tValidation loss: 0.232502\tBest loss: 0.224635\tAccuracy: 92.81%\n",
      "43\tValidation loss: 0.207718\tBest loss: 0.207718\tAccuracy: 92.81%\n",
      "44\tValidation loss: 0.227192\tBest loss: 0.207718\tAccuracy: 92.09%\n",
      "45\tValidation loss: 0.247422\tBest loss: 0.207718\tAccuracy: 92.09%\n",
      "46\tValidation loss: 0.261690\tBest loss: 0.207718\tAccuracy: 90.65%\n",
      "47\tValidation loss: 0.238591\tBest loss: 0.207718\tAccuracy: 92.81%\n",
      "48\tValidation loss: 0.341047\tBest loss: 0.207718\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.235738\tBest loss: 0.207718\tAccuracy: 90.65%\n",
      "50\tValidation loss: 0.272897\tBest loss: 0.207718\tAccuracy: 89.21%\n",
      "51\tValidation loss: 0.289469\tBest loss: 0.207718\tAccuracy: 90.65%\n",
      "52\tValidation loss: 0.235385\tBest loss: 0.207718\tAccuracy: 92.09%\n",
      "53\tValidation loss: 0.236330\tBest loss: 0.207718\tAccuracy: 93.53%\n",
      "54\tValidation loss: 0.255970\tBest loss: 0.207718\tAccuracy: 93.53%\n",
      "55\tValidation loss: 0.282425\tBest loss: 0.207718\tAccuracy: 91.37%\n",
      "56\tValidation loss: 0.217295\tBest loss: 0.207718\tAccuracy: 94.24%\n",
      "57\tValidation loss: 0.422242\tBest loss: 0.207718\tAccuracy: 87.77%\n",
      "58\tValidation loss: 0.284682\tBest loss: 0.207718\tAccuracy: 91.37%\n",
      "59\tValidation loss: 0.278764\tBest loss: 0.207718\tAccuracy: 92.81%\n",
      "60\tValidation loss: 0.252917\tBest loss: 0.207718\tAccuracy: 92.81%\n",
      "61\tValidation loss: 0.289165\tBest loss: 0.207718\tAccuracy: 92.09%\n",
      "62\tValidation loss: 0.270095\tBest loss: 0.207718\tAccuracy: 92.09%\n",
      "63\tValidation loss: 0.283946\tBest loss: 0.207718\tAccuracy: 90.65%\n",
      "64\tValidation loss: 0.242092\tBest loss: 0.207718\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=1, learning_rate=0.05, dropout_rate=0.4, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  15.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 164026.375000\tBest loss: 164026.375000\tAccuracy: 5.76%\n",
      "1\tValidation loss: 19234.884766\tBest loss: 19234.884766\tAccuracy: 2.88%\n",
      "2\tValidation loss: 58748.761719\tBest loss: 19234.884766\tAccuracy: 0.00%\n",
      "3\tValidation loss: 84427.148438\tBest loss: 19234.884766\tAccuracy: 2.16%\n",
      "4\tValidation loss: 215870.375000\tBest loss: 19234.884766\tAccuracy: 0.72%\n",
      "5\tValidation loss: 98716.632812\tBest loss: 19234.884766\tAccuracy: 0.72%\n",
      "6\tValidation loss: 200560.421875\tBest loss: 19234.884766\tAccuracy: 11.51%\n",
      "7\tValidation loss: 78460.609375\tBest loss: 19234.884766\tAccuracy: 10.07%\n",
      "8\tValidation loss: 55300.023438\tBest loss: 19234.884766\tAccuracy: 15.83%\n",
      "9\tValidation loss: 130352.367188\tBest loss: 19234.884766\tAccuracy: 8.63%\n",
      "10\tValidation loss: 83599.968750\tBest loss: 19234.884766\tAccuracy: 29.50%\n",
      "11\tValidation loss: 59860.605469\tBest loss: 19234.884766\tAccuracy: 30.22%\n",
      "12\tValidation loss: 52672.191406\tBest loss: 19234.884766\tAccuracy: 33.81%\n",
      "13\tValidation loss: 28400.804688\tBest loss: 19234.884766\tAccuracy: 42.45%\n",
      "14\tValidation loss: 63125.558594\tBest loss: 19234.884766\tAccuracy: 29.50%\n",
      "15\tValidation loss: 55153.703125\tBest loss: 19234.884766\tAccuracy: 41.73%\n",
      "16\tValidation loss: 180611.781250\tBest loss: 19234.884766\tAccuracy: 23.02%\n",
      "17\tValidation loss: 19150.558594\tBest loss: 19150.558594\tAccuracy: 56.12%\n",
      "18\tValidation loss: 15659.637695\tBest loss: 15659.637695\tAccuracy: 68.35%\n",
      "19\tValidation loss: 27998.648438\tBest loss: 15659.637695\tAccuracy: 57.55%\n",
      "20\tValidation loss: 43255.867188\tBest loss: 15659.637695\tAccuracy: 51.08%\n",
      "21\tValidation loss: 26663.445312\tBest loss: 15659.637695\tAccuracy: 66.91%\n",
      "22\tValidation loss: 11357.592773\tBest loss: 11357.592773\tAccuracy: 69.06%\n",
      "23\tValidation loss: 135069.250000\tBest loss: 11357.592773\tAccuracy: 43.88%\n",
      "24\tValidation loss: 35969.742188\tBest loss: 11357.592773\tAccuracy: 64.75%\n",
      "25\tValidation loss: 11356.244141\tBest loss: 11356.244141\tAccuracy: 79.14%\n",
      "26\tValidation loss: 16927.869141\tBest loss: 11356.244141\tAccuracy: 80.58%\n",
      "27\tValidation loss: 23831.634766\tBest loss: 11356.244141\tAccuracy: 62.59%\n",
      "28\tValidation loss: 9318.620117\tBest loss: 9318.620117\tAccuracy: 74.10%\n",
      "29\tValidation loss: 34961.960938\tBest loss: 9318.620117\tAccuracy: 72.66%\n",
      "30\tValidation loss: 34409.429688\tBest loss: 9318.620117\tAccuracy: 64.75%\n",
      "31\tValidation loss: 18580.050781\tBest loss: 9318.620117\tAccuracy: 76.26%\n",
      "32\tValidation loss: 34198.207031\tBest loss: 9318.620117\tAccuracy: 66.91%\n",
      "33\tValidation loss: 25876.691406\tBest loss: 9318.620117\tAccuracy: 74.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\tValidation loss: 10694.275391\tBest loss: 9318.620117\tAccuracy: 81.29%\n",
      "35\tValidation loss: 32946.527344\tBest loss: 9318.620117\tAccuracy: 73.38%\n",
      "36\tValidation loss: 26720.625000\tBest loss: 9318.620117\tAccuracy: 83.45%\n",
      "37\tValidation loss: 27317.082031\tBest loss: 9318.620117\tAccuracy: 73.38%\n",
      "38\tValidation loss: 30177.445312\tBest loss: 9318.620117\tAccuracy: 81.29%\n",
      "39\tValidation loss: 68793.875000\tBest loss: 9318.620117\tAccuracy: 68.35%\n",
      "40\tValidation loss: 40448.031250\tBest loss: 9318.620117\tAccuracy: 76.26%\n",
      "41\tValidation loss: 25315.130859\tBest loss: 9318.620117\tAccuracy: 79.86%\n",
      "42\tValidation loss: 10076.015625\tBest loss: 9318.620117\tAccuracy: 82.01%\n",
      "43\tValidation loss: 12596.711914\tBest loss: 9318.620117\tAccuracy: 84.17%\n",
      "44\tValidation loss: 5747.903320\tBest loss: 5747.903320\tAccuracy: 88.49%\n",
      "45\tValidation loss: 6051.805176\tBest loss: 5747.903320\tAccuracy: 87.77%\n",
      "46\tValidation loss: 76124.609375\tBest loss: 5747.903320\tAccuracy: 68.35%\n",
      "47\tValidation loss: 30760.300781\tBest loss: 5747.903320\tAccuracy: 76.98%\n",
      "48\tValidation loss: 42925.304688\tBest loss: 5747.903320\tAccuracy: 76.98%\n",
      "49\tValidation loss: 38355.511719\tBest loss: 5747.903320\tAccuracy: 76.98%\n",
      "50\tValidation loss: 22277.039062\tBest loss: 5747.903320\tAccuracy: 85.61%\n",
      "51\tValidation loss: 46109.691406\tBest loss: 5747.903320\tAccuracy: 80.58%\n",
      "52\tValidation loss: 14465.791016\tBest loss: 5747.903320\tAccuracy: 84.17%\n",
      "53\tValidation loss: 19703.859375\tBest loss: 5747.903320\tAccuracy: 83.45%\n",
      "54\tValidation loss: 21037.441406\tBest loss: 5747.903320\tAccuracy: 84.17%\n",
      "55\tValidation loss: 18811.693359\tBest loss: 5747.903320\tAccuracy: 84.17%\n",
      "56\tValidation loss: 9676.064453\tBest loss: 5747.903320\tAccuracy: 88.49%\n",
      "57\tValidation loss: 12512.166992\tBest loss: 5747.903320\tAccuracy: 88.49%\n",
      "58\tValidation loss: 47743.730469\tBest loss: 5747.903320\tAccuracy: 78.42%\n",
      "59\tValidation loss: 27788.082031\tBest loss: 5747.903320\tAccuracy: 87.05%\n",
      "60\tValidation loss: 13716.474609\tBest loss: 5747.903320\tAccuracy: 86.33%\n",
      "61\tValidation loss: 162673.281250\tBest loss: 5747.903320\tAccuracy: 76.26%\n",
      "62\tValidation loss: 48258.695312\tBest loss: 5747.903320\tAccuracy: 85.61%\n",
      "63\tValidation loss: 13521.958984\tBest loss: 5747.903320\tAccuracy: 89.21%\n",
      "64\tValidation loss: 1583465.500000\tBest loss: 5747.903320\tAccuracy: 65.47%\n",
      "65\tValidation loss: 28674.326172\tBest loss: 5747.903320\tAccuracy: 76.98%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  13.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 11076.200195\tBest loss: 11076.200195\tAccuracy: 5.04%\n",
      "1\tValidation loss: 38850.679688\tBest loss: 11076.200195\tAccuracy: 4.32%\n",
      "2\tValidation loss: 164311.328125\tBest loss: 11076.200195\tAccuracy: 5.04%\n",
      "3\tValidation loss: 80152.773438\tBest loss: 11076.200195\tAccuracy: 10.07%\n",
      "4\tValidation loss: 135929.875000\tBest loss: 11076.200195\tAccuracy: 16.55%\n",
      "5\tValidation loss: 23704.203125\tBest loss: 11076.200195\tAccuracy: 27.34%\n",
      "6\tValidation loss: 31703.503906\tBest loss: 11076.200195\tAccuracy: 29.50%\n",
      "7\tValidation loss: 41334.761719\tBest loss: 11076.200195\tAccuracy: 33.09%\n",
      "8\tValidation loss: 11832.359375\tBest loss: 11076.200195\tAccuracy: 51.08%\n",
      "9\tValidation loss: 42345.039062\tBest loss: 11076.200195\tAccuracy: 35.97%\n",
      "10\tValidation loss: 13647.481445\tBest loss: 11076.200195\tAccuracy: 46.04%\n",
      "11\tValidation loss: 118433.585938\tBest loss: 11076.200195\tAccuracy: 33.81%\n",
      "12\tValidation loss: 28445.583984\tBest loss: 11076.200195\tAccuracy: 48.20%\n",
      "13\tValidation loss: 47868.058594\tBest loss: 11076.200195\tAccuracy: 55.40%\n",
      "14\tValidation loss: 20918.380859\tBest loss: 11076.200195\tAccuracy: 63.31%\n",
      "15\tValidation loss: 18241.712891\tBest loss: 11076.200195\tAccuracy: 59.71%\n",
      "16\tValidation loss: 23450.126953\tBest loss: 11076.200195\tAccuracy: 60.43%\n",
      "17\tValidation loss: 16697.203125\tBest loss: 11076.200195\tAccuracy: 66.91%\n",
      "18\tValidation loss: 36290.132812\tBest loss: 11076.200195\tAccuracy: 56.12%\n",
      "19\tValidation loss: 24331.810547\tBest loss: 11076.200195\tAccuracy: 64.03%\n",
      "20\tValidation loss: 65981.875000\tBest loss: 11076.200195\tAccuracy: 48.20%\n",
      "21\tValidation loss: 12858.069336\tBest loss: 11076.200195\tAccuracy: 76.26%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 33170.890625\tBest loss: 33170.890625\tAccuracy: 0.72%\n",
      "1\tValidation loss: 104609.343750\tBest loss: 33170.890625\tAccuracy: 0.72%\n",
      "2\tValidation loss: 149200.046875\tBest loss: 33170.890625\tAccuracy: 2.16%\n",
      "3\tValidation loss: 45580.511719\tBest loss: 33170.890625\tAccuracy: 0.72%\n",
      "4\tValidation loss: 31308.853516\tBest loss: 31308.853516\tAccuracy: 2.16%\n",
      "5\tValidation loss: 90749.898438\tBest loss: 31308.853516\tAccuracy: 9.35%\n",
      "6\tValidation loss: 82742.789062\tBest loss: 31308.853516\tAccuracy: 7.91%\n",
      "7\tValidation loss: 62037.449219\tBest loss: 31308.853516\tAccuracy: 17.99%\n",
      "8\tValidation loss: 54910.750000\tBest loss: 31308.853516\tAccuracy: 18.71%\n",
      "9\tValidation loss: 28624.207031\tBest loss: 28624.207031\tAccuracy: 23.02%\n",
      "10\tValidation loss: 62493.785156\tBest loss: 28624.207031\tAccuracy: 39.57%\n",
      "11\tValidation loss: 19479.802734\tBest loss: 19479.802734\tAccuracy: 49.64%\n",
      "12\tValidation loss: 25574.394531\tBest loss: 19479.802734\tAccuracy: 41.73%\n",
      "13\tValidation loss: 42663.421875\tBest loss: 19479.802734\tAccuracy: 41.73%\n",
      "14\tValidation loss: 12506.306641\tBest loss: 12506.306641\tAccuracy: 63.31%\n",
      "15\tValidation loss: 18857.789062\tBest loss: 12506.306641\tAccuracy: 58.27%\n",
      "16\tValidation loss: 37568.042969\tBest loss: 12506.306641\tAccuracy: 46.76%\n",
      "17\tValidation loss: 20778.914062\tBest loss: 12506.306641\tAccuracy: 60.43%\n",
      "18\tValidation loss: 17818.857422\tBest loss: 12506.306641\tAccuracy: 68.35%\n",
      "19\tValidation loss: 35983.195312\tBest loss: 12506.306641\tAccuracy: 56.83%\n",
      "20\tValidation loss: 31914.253906\tBest loss: 12506.306641\tAccuracy: 67.63%\n",
      "21\tValidation loss: 113078.359375\tBest loss: 12506.306641\tAccuracy: 57.55%\n",
      "22\tValidation loss: 32390.433594\tBest loss: 12506.306641\tAccuracy: 62.59%\n",
      "23\tValidation loss: 12297.125977\tBest loss: 12297.125977\tAccuracy: 71.22%\n",
      "24\tValidation loss: 36827.773438\tBest loss: 12297.125977\tAccuracy: 61.87%\n",
      "25\tValidation loss: 18090.425781\tBest loss: 12297.125977\tAccuracy: 70.50%\n",
      "26\tValidation loss: 8299.927734\tBest loss: 8299.927734\tAccuracy: 73.38%\n",
      "27\tValidation loss: 43815.855469\tBest loss: 8299.927734\tAccuracy: 64.75%\n",
      "28\tValidation loss: 18474.035156\tBest loss: 8299.927734\tAccuracy: 76.26%\n",
      "29\tValidation loss: 8248.750977\tBest loss: 8248.750977\tAccuracy: 81.29%\n",
      "30\tValidation loss: 54894.199219\tBest loss: 8248.750977\tAccuracy: 75.54%\n",
      "31\tValidation loss: 16058.929688\tBest loss: 8248.750977\tAccuracy: 78.42%\n",
      "32\tValidation loss: 10852.728516\tBest loss: 8248.750977\tAccuracy: 80.58%\n",
      "33\tValidation loss: 13525.441406\tBest loss: 8248.750977\tAccuracy: 80.58%\n",
      "34\tValidation loss: 28211.736328\tBest loss: 8248.750977\tAccuracy: 76.26%\n",
      "35\tValidation loss: 9705.062500\tBest loss: 8248.750977\tAccuracy: 84.89%\n",
      "36\tValidation loss: 75789.046875\tBest loss: 8248.750977\tAccuracy: 66.91%\n",
      "37\tValidation loss: 22801.458984\tBest loss: 8248.750977\tAccuracy: 78.42%\n",
      "38\tValidation loss: 10567.640625\tBest loss: 8248.750977\tAccuracy: 76.26%\n",
      "39\tValidation loss: 6264.952637\tBest loss: 6264.952637\tAccuracy: 84.89%\n",
      "40\tValidation loss: 23753.451172\tBest loss: 6264.952637\tAccuracy: 78.42%\n",
      "41\tValidation loss: 13162.230469\tBest loss: 6264.952637\tAccuracy: 84.17%\n",
      "42\tValidation loss: 93412.523438\tBest loss: 6264.952637\tAccuracy: 59.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\tValidation loss: 51386.945312\tBest loss: 6264.952637\tAccuracy: 70.50%\n",
      "44\tValidation loss: 20031.273438\tBest loss: 6264.952637\tAccuracy: 83.45%\n",
      "45\tValidation loss: 55580.777344\tBest loss: 6264.952637\tAccuracy: 77.70%\n",
      "46\tValidation loss: 13053.301758\tBest loss: 6264.952637\tAccuracy: 85.61%\n",
      "47\tValidation loss: 15452.805664\tBest loss: 6264.952637\tAccuracy: 84.17%\n",
      "48\tValidation loss: 116385.031250\tBest loss: 6264.952637\tAccuracy: 82.73%\n",
      "49\tValidation loss: 16332.880859\tBest loss: 6264.952637\tAccuracy: 79.86%\n",
      "50\tValidation loss: 19446.757812\tBest loss: 6264.952637\tAccuracy: 84.17%\n",
      "51\tValidation loss: 29086.585938\tBest loss: 6264.952637\tAccuracy: 82.01%\n",
      "52\tValidation loss: 50921.039062\tBest loss: 6264.952637\tAccuracy: 74.82%\n",
      "53\tValidation loss: 16498.902344\tBest loss: 6264.952637\tAccuracy: 85.61%\n",
      "54\tValidation loss: 25101.312500\tBest loss: 6264.952637\tAccuracy: 83.45%\n",
      "55\tValidation loss: 36025.308594\tBest loss: 6264.952637\tAccuracy: 86.33%\n",
      "56\tValidation loss: 33606.121094\tBest loss: 6264.952637\tAccuracy: 82.01%\n",
      "57\tValidation loss: 15265.781250\tBest loss: 6264.952637\tAccuracy: 84.89%\n",
      "58\tValidation loss: 15256.406250\tBest loss: 6264.952637\tAccuracy: 84.17%\n",
      "59\tValidation loss: 22431.287109\tBest loss: 6264.952637\tAccuracy: 85.61%\n",
      "60\tValidation loss: 35761.917969\tBest loss: 6264.952637\tAccuracy: 77.70%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=1000, n_hidden_layers=2, learning_rate=0.1, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=  13.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 4.114927\tBest loss: 4.114927\tAccuracy: 16.55%\n",
      "1\tValidation loss: 2.717968\tBest loss: 2.717968\tAccuracy: 32.37%\n",
      "2\tValidation loss: 2.444353\tBest loss: 2.444353\tAccuracy: 38.85%\n",
      "3\tValidation loss: 2.198611\tBest loss: 2.198611\tAccuracy: 43.88%\n",
      "4\tValidation loss: 1.989275\tBest loss: 1.989275\tAccuracy: 45.32%\n",
      "5\tValidation loss: 1.771594\tBest loss: 1.771594\tAccuracy: 51.08%\n",
      "6\tValidation loss: 1.617746\tBest loss: 1.617746\tAccuracy: 55.40%\n",
      "7\tValidation loss: 1.590540\tBest loss: 1.590540\tAccuracy: 56.83%\n",
      "8\tValidation loss: 1.440248\tBest loss: 1.440248\tAccuracy: 61.87%\n",
      "9\tValidation loss: 1.405592\tBest loss: 1.405592\tAccuracy: 60.43%\n",
      "10\tValidation loss: 1.313806\tBest loss: 1.313806\tAccuracy: 68.35%\n",
      "11\tValidation loss: 1.197857\tBest loss: 1.197857\tAccuracy: 70.50%\n",
      "12\tValidation loss: 1.112521\tBest loss: 1.112521\tAccuracy: 70.50%\n",
      "13\tValidation loss: 1.063239\tBest loss: 1.063239\tAccuracy: 69.06%\n",
      "14\tValidation loss: 0.967005\tBest loss: 0.967005\tAccuracy: 71.94%\n",
      "15\tValidation loss: 0.947491\tBest loss: 0.947491\tAccuracy: 74.82%\n",
      "16\tValidation loss: 0.874733\tBest loss: 0.874733\tAccuracy: 73.38%\n",
      "17\tValidation loss: 0.825562\tBest loss: 0.825562\tAccuracy: 76.26%\n",
      "18\tValidation loss: 0.766771\tBest loss: 0.766771\tAccuracy: 76.98%\n",
      "19\tValidation loss: 0.773135\tBest loss: 0.766771\tAccuracy: 72.66%\n",
      "20\tValidation loss: 0.686095\tBest loss: 0.686095\tAccuracy: 79.86%\n",
      "21\tValidation loss: 0.683049\tBest loss: 0.683049\tAccuracy: 79.86%\n",
      "22\tValidation loss: 0.678483\tBest loss: 0.678483\tAccuracy: 79.14%\n",
      "23\tValidation loss: 0.703651\tBest loss: 0.678483\tAccuracy: 77.70%\n",
      "24\tValidation loss: 0.663427\tBest loss: 0.663427\tAccuracy: 78.42%\n",
      "25\tValidation loss: 0.626644\tBest loss: 0.626644\tAccuracy: 81.29%\n",
      "26\tValidation loss: 0.594119\tBest loss: 0.594119\tAccuracy: 84.17%\n",
      "27\tValidation loss: 0.603645\tBest loss: 0.594119\tAccuracy: 83.45%\n",
      "28\tValidation loss: 0.587922\tBest loss: 0.587922\tAccuracy: 82.73%\n",
      "29\tValidation loss: 0.590248\tBest loss: 0.587922\tAccuracy: 83.45%\n",
      "30\tValidation loss: 0.555236\tBest loss: 0.555236\tAccuracy: 84.17%\n",
      "31\tValidation loss: 0.552823\tBest loss: 0.552823\tAccuracy: 84.17%\n",
      "32\tValidation loss: 0.510187\tBest loss: 0.510187\tAccuracy: 86.33%\n",
      "33\tValidation loss: 0.517036\tBest loss: 0.510187\tAccuracy: 86.33%\n",
      "34\tValidation loss: 0.500957\tBest loss: 0.500957\tAccuracy: 85.61%\n",
      "35\tValidation loss: 0.506782\tBest loss: 0.500957\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.495006\tBest loss: 0.495006\tAccuracy: 87.05%\n",
      "37\tValidation loss: 0.481775\tBest loss: 0.481775\tAccuracy: 87.05%\n",
      "38\tValidation loss: 0.460738\tBest loss: 0.460738\tAccuracy: 85.61%\n",
      "39\tValidation loss: 0.453395\tBest loss: 0.453395\tAccuracy: 87.05%\n",
      "40\tValidation loss: 0.467644\tBest loss: 0.453395\tAccuracy: 87.77%\n",
      "41\tValidation loss: 0.446080\tBest loss: 0.446080\tAccuracy: 86.33%\n",
      "42\tValidation loss: 0.457628\tBest loss: 0.446080\tAccuracy: 85.61%\n",
      "43\tValidation loss: 0.476428\tBest loss: 0.446080\tAccuracy: 85.61%\n",
      "44\tValidation loss: 0.455625\tBest loss: 0.446080\tAccuracy: 84.89%\n",
      "45\tValidation loss: 0.418813\tBest loss: 0.418813\tAccuracy: 87.05%\n",
      "46\tValidation loss: 0.410688\tBest loss: 0.410688\tAccuracy: 87.77%\n",
      "47\tValidation loss: 0.426765\tBest loss: 0.410688\tAccuracy: 87.77%\n",
      "48\tValidation loss: 0.414997\tBest loss: 0.410688\tAccuracy: 87.77%\n",
      "49\tValidation loss: 0.393613\tBest loss: 0.393613\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.406708\tBest loss: 0.393613\tAccuracy: 88.49%\n",
      "51\tValidation loss: 0.399103\tBest loss: 0.393613\tAccuracy: 89.21%\n",
      "52\tValidation loss: 0.381654\tBest loss: 0.381654\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.387209\tBest loss: 0.381654\tAccuracy: 87.77%\n",
      "54\tValidation loss: 0.388821\tBest loss: 0.381654\tAccuracy: 86.33%\n",
      "55\tValidation loss: 0.366564\tBest loss: 0.366564\tAccuracy: 89.21%\n",
      "56\tValidation loss: 0.382765\tBest loss: 0.366564\tAccuracy: 89.21%\n",
      "57\tValidation loss: 0.363651\tBest loss: 0.363651\tAccuracy: 88.49%\n",
      "58\tValidation loss: 0.379389\tBest loss: 0.363651\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.374311\tBest loss: 0.363651\tAccuracy: 88.49%\n",
      "60\tValidation loss: 0.375836\tBest loss: 0.363651\tAccuracy: 89.21%\n",
      "61\tValidation loss: 0.374857\tBest loss: 0.363651\tAccuracy: 88.49%\n",
      "62\tValidation loss: 0.391496\tBest loss: 0.363651\tAccuracy: 87.77%\n",
      "63\tValidation loss: 0.364855\tBest loss: 0.363651\tAccuracy: 89.21%\n",
      "64\tValidation loss: 0.355747\tBest loss: 0.355747\tAccuracy: 89.93%\n",
      "65\tValidation loss: 0.355134\tBest loss: 0.355134\tAccuracy: 89.21%\n",
      "66\tValidation loss: 0.357471\tBest loss: 0.355134\tAccuracy: 89.21%\n",
      "67\tValidation loss: 0.375197\tBest loss: 0.355134\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.366290\tBest loss: 0.355134\tAccuracy: 87.77%\n",
      "69\tValidation loss: 0.366890\tBest loss: 0.355134\tAccuracy: 87.77%\n",
      "70\tValidation loss: 0.374927\tBest loss: 0.355134\tAccuracy: 87.77%\n",
      "71\tValidation loss: 0.370698\tBest loss: 0.355134\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.329872\tBest loss: 0.329872\tAccuracy: 89.21%\n",
      "73\tValidation loss: 0.353000\tBest loss: 0.329872\tAccuracy: 87.77%\n",
      "74\tValidation loss: 0.355884\tBest loss: 0.329872\tAccuracy: 89.21%\n",
      "75\tValidation loss: 0.346403\tBest loss: 0.329872\tAccuracy: 88.49%\n",
      "76\tValidation loss: 0.329558\tBest loss: 0.329558\tAccuracy: 89.21%\n",
      "77\tValidation loss: 0.331484\tBest loss: 0.329558\tAccuracy: 89.93%\n",
      "78\tValidation loss: 0.335186\tBest loss: 0.329558\tAccuracy: 88.49%\n",
      "79\tValidation loss: 0.335356\tBest loss: 0.329558\tAccuracy: 87.77%\n",
      "80\tValidation loss: 0.326334\tBest loss: 0.326334\tAccuracy: 88.49%\n",
      "81\tValidation loss: 0.284435\tBest loss: 0.284435\tAccuracy: 90.65%\n",
      "82\tValidation loss: 0.292001\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "83\tValidation loss: 0.311029\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "84\tValidation loss: 0.316431\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "85\tValidation loss: 0.326203\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "86\tValidation loss: 0.327204\tBest loss: 0.284435\tAccuracy: 87.77%\n",
      "87\tValidation loss: 0.322070\tBest loss: 0.284435\tAccuracy: 88.49%\n",
      "88\tValidation loss: 0.298463\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "89\tValidation loss: 0.309035\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "90\tValidation loss: 0.300684\tBest loss: 0.284435\tAccuracy: 88.49%\n",
      "91\tValidation loss: 0.300639\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "92\tValidation loss: 0.303574\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "93\tValidation loss: 0.317594\tBest loss: 0.284435\tAccuracy: 88.49%\n",
      "94\tValidation loss: 0.321877\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "95\tValidation loss: 0.314083\tBest loss: 0.284435\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.322632\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "97\tValidation loss: 0.314498\tBest loss: 0.284435\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\tValidation loss: 0.300451\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "99\tValidation loss: 0.309103\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "100\tValidation loss: 0.308331\tBest loss: 0.284435\tAccuracy: 90.65%\n",
      "101\tValidation loss: 0.290151\tBest loss: 0.284435\tAccuracy: 89.93%\n",
      "102\tValidation loss: 0.302925\tBest loss: 0.284435\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  11.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 3.980611\tBest loss: 3.980611\tAccuracy: 16.55%\n",
      "1\tValidation loss: 3.364227\tBest loss: 3.364227\tAccuracy: 20.86%\n",
      "2\tValidation loss: 2.772403\tBest loss: 2.772403\tAccuracy: 29.50%\n",
      "3\tValidation loss: 2.681562\tBest loss: 2.681562\tAccuracy: 33.09%\n",
      "4\tValidation loss: 2.458810\tBest loss: 2.458810\tAccuracy: 39.57%\n",
      "5\tValidation loss: 2.207061\tBest loss: 2.207061\tAccuracy: 44.60%\n",
      "6\tValidation loss: 2.058029\tBest loss: 2.058029\tAccuracy: 43.88%\n",
      "7\tValidation loss: 1.949980\tBest loss: 1.949980\tAccuracy: 53.24%\n",
      "8\tValidation loss: 1.702861\tBest loss: 1.702861\tAccuracy: 55.40%\n",
      "9\tValidation loss: 1.484688\tBest loss: 1.484688\tAccuracy: 61.87%\n",
      "10\tValidation loss: 1.460434\tBest loss: 1.460434\tAccuracy: 60.43%\n",
      "11\tValidation loss: 1.353065\tBest loss: 1.353065\tAccuracy: 65.47%\n",
      "12\tValidation loss: 1.291692\tBest loss: 1.291692\tAccuracy: 66.91%\n",
      "13\tValidation loss: 1.164814\tBest loss: 1.164814\tAccuracy: 67.63%\n",
      "14\tValidation loss: 1.116791\tBest loss: 1.116791\tAccuracy: 66.19%\n",
      "15\tValidation loss: 1.005035\tBest loss: 1.005035\tAccuracy: 73.38%\n",
      "16\tValidation loss: 0.926613\tBest loss: 0.926613\tAccuracy: 76.98%\n",
      "17\tValidation loss: 0.874183\tBest loss: 0.874183\tAccuracy: 74.82%\n",
      "18\tValidation loss: 0.869394\tBest loss: 0.869394\tAccuracy: 75.54%\n",
      "19\tValidation loss: 0.817508\tBest loss: 0.817508\tAccuracy: 74.10%\n",
      "20\tValidation loss: 0.755012\tBest loss: 0.755012\tAccuracy: 79.14%\n",
      "21\tValidation loss: 0.785222\tBest loss: 0.755012\tAccuracy: 76.26%\n",
      "22\tValidation loss: 0.794196\tBest loss: 0.755012\tAccuracy: 77.70%\n",
      "23\tValidation loss: 0.745434\tBest loss: 0.745434\tAccuracy: 79.86%\n",
      "24\tValidation loss: 0.711502\tBest loss: 0.711502\tAccuracy: 79.86%\n",
      "25\tValidation loss: 0.690928\tBest loss: 0.690928\tAccuracy: 79.14%\n",
      "26\tValidation loss: 0.664194\tBest loss: 0.664194\tAccuracy: 79.86%\n",
      "27\tValidation loss: 0.630854\tBest loss: 0.630854\tAccuracy: 82.73%\n",
      "28\tValidation loss: 0.645596\tBest loss: 0.630854\tAccuracy: 77.70%\n",
      "29\tValidation loss: 0.572503\tBest loss: 0.572503\tAccuracy: 83.45%\n",
      "30\tValidation loss: 0.561464\tBest loss: 0.561464\tAccuracy: 81.29%\n",
      "31\tValidation loss: 0.564393\tBest loss: 0.561464\tAccuracy: 80.58%\n",
      "32\tValidation loss: 0.580828\tBest loss: 0.561464\tAccuracy: 82.73%\n",
      "33\tValidation loss: 0.572423\tBest loss: 0.561464\tAccuracy: 82.73%\n",
      "34\tValidation loss: 0.582269\tBest loss: 0.561464\tAccuracy: 80.58%\n",
      "35\tValidation loss: 0.532795\tBest loss: 0.532795\tAccuracy: 82.01%\n",
      "36\tValidation loss: 0.481745\tBest loss: 0.481745\tAccuracy: 84.17%\n",
      "37\tValidation loss: 0.465917\tBest loss: 0.465917\tAccuracy: 85.61%\n",
      "38\tValidation loss: 0.479265\tBest loss: 0.465917\tAccuracy: 84.89%\n",
      "39\tValidation loss: 0.473729\tBest loss: 0.465917\tAccuracy: 84.17%\n",
      "40\tValidation loss: 0.429613\tBest loss: 0.429613\tAccuracy: 86.33%\n",
      "41\tValidation loss: 0.475237\tBest loss: 0.429613\tAccuracy: 85.61%\n",
      "42\tValidation loss: 0.446972\tBest loss: 0.429613\tAccuracy: 82.73%\n",
      "43\tValidation loss: 0.425260\tBest loss: 0.425260\tAccuracy: 86.33%\n",
      "44\tValidation loss: 0.438446\tBest loss: 0.425260\tAccuracy: 86.33%\n",
      "45\tValidation loss: 0.453692\tBest loss: 0.425260\tAccuracy: 85.61%\n",
      "46\tValidation loss: 0.473948\tBest loss: 0.425260\tAccuracy: 84.17%\n",
      "47\tValidation loss: 0.413225\tBest loss: 0.413225\tAccuracy: 85.61%\n",
      "48\tValidation loss: 0.380140\tBest loss: 0.380140\tAccuracy: 87.05%\n",
      "49\tValidation loss: 0.388609\tBest loss: 0.380140\tAccuracy: 87.05%\n",
      "50\tValidation loss: 0.393509\tBest loss: 0.380140\tAccuracy: 85.61%\n",
      "51\tValidation loss: 0.392764\tBest loss: 0.380140\tAccuracy: 87.05%\n",
      "52\tValidation loss: 0.377570\tBest loss: 0.377570\tAccuracy: 87.05%\n",
      "53\tValidation loss: 0.372606\tBest loss: 0.372606\tAccuracy: 87.05%\n",
      "54\tValidation loss: 0.351204\tBest loss: 0.351204\tAccuracy: 88.49%\n",
      "55\tValidation loss: 0.355924\tBest loss: 0.351204\tAccuracy: 86.33%\n",
      "56\tValidation loss: 0.378986\tBest loss: 0.351204\tAccuracy: 87.05%\n",
      "57\tValidation loss: 0.379333\tBest loss: 0.351204\tAccuracy: 87.77%\n",
      "58\tValidation loss: 0.344386\tBest loss: 0.344386\tAccuracy: 88.49%\n",
      "59\tValidation loss: 0.362108\tBest loss: 0.344386\tAccuracy: 87.77%\n",
      "60\tValidation loss: 0.345319\tBest loss: 0.344386\tAccuracy: 87.77%\n",
      "61\tValidation loss: 0.375606\tBest loss: 0.344386\tAccuracy: 87.77%\n",
      "62\tValidation loss: 0.340714\tBest loss: 0.340714\tAccuracy: 89.93%\n",
      "63\tValidation loss: 0.325987\tBest loss: 0.325987\tAccuracy: 89.21%\n",
      "64\tValidation loss: 0.327532\tBest loss: 0.325987\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.334936\tBest loss: 0.325987\tAccuracy: 89.21%\n",
      "66\tValidation loss: 0.340259\tBest loss: 0.325987\tAccuracy: 87.77%\n",
      "67\tValidation loss: 0.320467\tBest loss: 0.320467\tAccuracy: 89.21%\n",
      "68\tValidation loss: 0.329764\tBest loss: 0.320467\tAccuracy: 87.77%\n",
      "69\tValidation loss: 0.356578\tBest loss: 0.320467\tAccuracy: 87.77%\n",
      "70\tValidation loss: 0.339928\tBest loss: 0.320467\tAccuracy: 88.49%\n",
      "71\tValidation loss: 0.314024\tBest loss: 0.314024\tAccuracy: 88.49%\n",
      "72\tValidation loss: 0.320339\tBest loss: 0.314024\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.338364\tBest loss: 0.314024\tAccuracy: 88.49%\n",
      "74\tValidation loss: 0.312574\tBest loss: 0.312574\tAccuracy: 89.93%\n",
      "75\tValidation loss: 0.297235\tBest loss: 0.297235\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.295181\tBest loss: 0.295181\tAccuracy: 89.21%\n",
      "77\tValidation loss: 0.291074\tBest loss: 0.291074\tAccuracy: 89.21%\n",
      "78\tValidation loss: 0.283683\tBest loss: 0.283683\tAccuracy: 90.65%\n",
      "79\tValidation loss: 0.301222\tBest loss: 0.283683\tAccuracy: 88.49%\n",
      "80\tValidation loss: 0.286756\tBest loss: 0.283683\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.279079\tBest loss: 0.279079\tAccuracy: 91.37%\n",
      "82\tValidation loss: 0.264803\tBest loss: 0.264803\tAccuracy: 91.37%\n",
      "83\tValidation loss: 0.254313\tBest loss: 0.254313\tAccuracy: 92.09%\n",
      "84\tValidation loss: 0.260804\tBest loss: 0.254313\tAccuracy: 92.09%\n",
      "85\tValidation loss: 0.313299\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.293021\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.338558\tBest loss: 0.254313\tAccuracy: 89.93%\n",
      "88\tValidation loss: 0.300021\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "89\tValidation loss: 0.292687\tBest loss: 0.254313\tAccuracy: 92.09%\n",
      "90\tValidation loss: 0.289310\tBest loss: 0.254313\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.283898\tBest loss: 0.254313\tAccuracy: 89.21%\n",
      "92\tValidation loss: 0.274059\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "93\tValidation loss: 0.290614\tBest loss: 0.254313\tAccuracy: 89.93%\n",
      "94\tValidation loss: 0.277709\tBest loss: 0.254313\tAccuracy: 91.37%\n",
      "95\tValidation loss: 0.271739\tBest loss: 0.254313\tAccuracy: 92.09%\n",
      "96\tValidation loss: 0.292230\tBest loss: 0.254313\tAccuracy: 92.09%\n",
      "97\tValidation loss: 0.282969\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "98\tValidation loss: 0.291533\tBest loss: 0.254313\tAccuracy: 89.21%\n",
      "99\tValidation loss: 0.307218\tBest loss: 0.254313\tAccuracy: 88.49%\n",
      "100\tValidation loss: 0.290617\tBest loss: 0.254313\tAccuracy: 90.65%\n",
      "101\tValidation loss: 0.316816\tBest loss: 0.254313\tAccuracy: 88.49%\n",
      "102\tValidation loss: 0.290088\tBest loss: 0.254313\tAccuracy: 89.93%\n",
      "103\tValidation loss: 0.283449\tBest loss: 0.254313\tAccuracy: 91.37%\n",
      "104\tValidation loss: 0.257885\tBest loss: 0.254313\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  12.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.000165\tBest loss: 4.000165\tAccuracy: 15.11%\n",
      "1\tValidation loss: 2.923105\tBest loss: 2.923105\tAccuracy: 31.65%\n",
      "2\tValidation loss: 2.786385\tBest loss: 2.786385\tAccuracy: 28.78%\n",
      "3\tValidation loss: 2.411719\tBest loss: 2.411719\tAccuracy: 38.13%\n",
      "4\tValidation loss: 2.223133\tBest loss: 2.223133\tAccuracy: 38.85%\n",
      "5\tValidation loss: 2.072809\tBest loss: 2.072809\tAccuracy: 44.60%\n",
      "6\tValidation loss: 1.893612\tBest loss: 1.893612\tAccuracy: 46.76%\n",
      "7\tValidation loss: 1.892972\tBest loss: 1.892972\tAccuracy: 48.20%\n",
      "8\tValidation loss: 1.664961\tBest loss: 1.664961\tAccuracy: 53.24%\n",
      "9\tValidation loss: 1.561428\tBest loss: 1.561428\tAccuracy: 54.68%\n",
      "10\tValidation loss: 1.535974\tBest loss: 1.535974\tAccuracy: 54.68%\n",
      "11\tValidation loss: 1.369217\tBest loss: 1.369217\tAccuracy: 57.55%\n",
      "12\tValidation loss: 1.258111\tBest loss: 1.258111\tAccuracy: 63.31%\n",
      "13\tValidation loss: 1.240322\tBest loss: 1.240322\tAccuracy: 61.87%\n",
      "14\tValidation loss: 1.113271\tBest loss: 1.113271\tAccuracy: 67.63%\n",
      "15\tValidation loss: 1.110527\tBest loss: 1.110527\tAccuracy: 66.19%\n",
      "16\tValidation loss: 0.999114\tBest loss: 0.999114\tAccuracy: 74.82%\n",
      "17\tValidation loss: 0.951815\tBest loss: 0.951815\tAccuracy: 72.66%\n",
      "18\tValidation loss: 0.937405\tBest loss: 0.937405\tAccuracy: 71.22%\n",
      "19\tValidation loss: 0.856960\tBest loss: 0.856960\tAccuracy: 76.26%\n",
      "20\tValidation loss: 0.890186\tBest loss: 0.856960\tAccuracy: 76.26%\n",
      "21\tValidation loss: 0.841501\tBest loss: 0.841501\tAccuracy: 76.26%\n",
      "22\tValidation loss: 0.775213\tBest loss: 0.775213\tAccuracy: 79.86%\n",
      "23\tValidation loss: 0.733871\tBest loss: 0.733871\tAccuracy: 78.42%\n",
      "24\tValidation loss: 0.752164\tBest loss: 0.733871\tAccuracy: 76.98%\n",
      "25\tValidation loss: 0.695981\tBest loss: 0.695981\tAccuracy: 80.58%\n",
      "26\tValidation loss: 0.710963\tBest loss: 0.695981\tAccuracy: 78.42%\n",
      "27\tValidation loss: 0.684296\tBest loss: 0.684296\tAccuracy: 82.01%\n",
      "28\tValidation loss: 0.647245\tBest loss: 0.647245\tAccuracy: 82.01%\n",
      "29\tValidation loss: 0.651022\tBest loss: 0.647245\tAccuracy: 80.58%\n",
      "30\tValidation loss: 0.695793\tBest loss: 0.647245\tAccuracy: 79.14%\n",
      "31\tValidation loss: 0.639681\tBest loss: 0.639681\tAccuracy: 79.14%\n",
      "32\tValidation loss: 0.610463\tBest loss: 0.610463\tAccuracy: 79.86%\n",
      "33\tValidation loss: 0.639550\tBest loss: 0.610463\tAccuracy: 81.29%\n",
      "34\tValidation loss: 0.589834\tBest loss: 0.589834\tAccuracy: 82.01%\n",
      "35\tValidation loss: 0.605517\tBest loss: 0.589834\tAccuracy: 82.01%\n",
      "36\tValidation loss: 0.579410\tBest loss: 0.579410\tAccuracy: 82.01%\n",
      "37\tValidation loss: 0.588729\tBest loss: 0.579410\tAccuracy: 79.86%\n",
      "38\tValidation loss: 0.556267\tBest loss: 0.556267\tAccuracy: 82.73%\n",
      "39\tValidation loss: 0.562387\tBest loss: 0.556267\tAccuracy: 81.29%\n",
      "40\tValidation loss: 0.568843\tBest loss: 0.556267\tAccuracy: 82.01%\n",
      "41\tValidation loss: 0.544007\tBest loss: 0.544007\tAccuracy: 83.45%\n",
      "42\tValidation loss: 0.519933\tBest loss: 0.519933\tAccuracy: 84.17%\n",
      "43\tValidation loss: 0.523325\tBest loss: 0.519933\tAccuracy: 84.17%\n",
      "44\tValidation loss: 0.540007\tBest loss: 0.519933\tAccuracy: 82.01%\n",
      "45\tValidation loss: 0.536872\tBest loss: 0.519933\tAccuracy: 85.61%\n",
      "46\tValidation loss: 0.520700\tBest loss: 0.519933\tAccuracy: 86.33%\n",
      "47\tValidation loss: 0.497429\tBest loss: 0.497429\tAccuracy: 84.89%\n",
      "48\tValidation loss: 0.473893\tBest loss: 0.473893\tAccuracy: 85.61%\n",
      "49\tValidation loss: 0.505178\tBest loss: 0.473893\tAccuracy: 83.45%\n",
      "50\tValidation loss: 0.527288\tBest loss: 0.473893\tAccuracy: 83.45%\n",
      "51\tValidation loss: 0.517726\tBest loss: 0.473893\tAccuracy: 83.45%\n",
      "52\tValidation loss: 0.504357\tBest loss: 0.473893\tAccuracy: 83.45%\n",
      "53\tValidation loss: 0.481726\tBest loss: 0.473893\tAccuracy: 84.89%\n",
      "54\tValidation loss: 0.467583\tBest loss: 0.467583\tAccuracy: 85.61%\n",
      "55\tValidation loss: 0.498704\tBest loss: 0.467583\tAccuracy: 82.01%\n",
      "56\tValidation loss: 0.467537\tBest loss: 0.467537\tAccuracy: 87.05%\n",
      "57\tValidation loss: 0.456854\tBest loss: 0.456854\tAccuracy: 87.05%\n",
      "58\tValidation loss: 0.462672\tBest loss: 0.456854\tAccuracy: 84.17%\n",
      "59\tValidation loss: 0.465252\tBest loss: 0.456854\tAccuracy: 84.89%\n",
      "60\tValidation loss: 0.454907\tBest loss: 0.454907\tAccuracy: 87.05%\n",
      "61\tValidation loss: 0.421672\tBest loss: 0.421672\tAccuracy: 88.49%\n",
      "62\tValidation loss: 0.434024\tBest loss: 0.421672\tAccuracy: 87.05%\n",
      "63\tValidation loss: 0.420995\tBest loss: 0.420995\tAccuracy: 89.21%\n",
      "64\tValidation loss: 0.418682\tBest loss: 0.418682\tAccuracy: 87.77%\n",
      "65\tValidation loss: 0.436598\tBest loss: 0.418682\tAccuracy: 86.33%\n",
      "66\tValidation loss: 0.433294\tBest loss: 0.418682\tAccuracy: 88.49%\n",
      "67\tValidation loss: 0.403167\tBest loss: 0.403167\tAccuracy: 87.77%\n",
      "68\tValidation loss: 0.407270\tBest loss: 0.403167\tAccuracy: 86.33%\n",
      "69\tValidation loss: 0.392829\tBest loss: 0.392829\tAccuracy: 87.77%\n",
      "70\tValidation loss: 0.416525\tBest loss: 0.392829\tAccuracy: 88.49%\n",
      "71\tValidation loss: 0.421440\tBest loss: 0.392829\tAccuracy: 87.05%\n",
      "72\tValidation loss: 0.417913\tBest loss: 0.392829\tAccuracy: 87.77%\n",
      "73\tValidation loss: 0.414113\tBest loss: 0.392829\tAccuracy: 87.05%\n",
      "74\tValidation loss: 0.415957\tBest loss: 0.392829\tAccuracy: 88.49%\n",
      "75\tValidation loss: 0.401615\tBest loss: 0.392829\tAccuracy: 87.77%\n",
      "76\tValidation loss: 0.369305\tBest loss: 0.369305\tAccuracy: 89.21%\n",
      "77\tValidation loss: 0.380103\tBest loss: 0.369305\tAccuracy: 89.21%\n",
      "78\tValidation loss: 0.384948\tBest loss: 0.369305\tAccuracy: 89.21%\n",
      "79\tValidation loss: 0.364215\tBest loss: 0.364215\tAccuracy: 88.49%\n",
      "80\tValidation loss: 0.372804\tBest loss: 0.364215\tAccuracy: 89.21%\n",
      "81\tValidation loss: 0.366291\tBest loss: 0.364215\tAccuracy: 89.21%\n",
      "82\tValidation loss: 0.376132\tBest loss: 0.364215\tAccuracy: 87.05%\n",
      "83\tValidation loss: 0.370803\tBest loss: 0.364215\tAccuracy: 90.65%\n",
      "84\tValidation loss: 0.396988\tBest loss: 0.364215\tAccuracy: 88.49%\n",
      "85\tValidation loss: 0.387073\tBest loss: 0.364215\tAccuracy: 88.49%\n",
      "86\tValidation loss: 0.372836\tBest loss: 0.364215\tAccuracy: 87.77%\n",
      "87\tValidation loss: 0.357706\tBest loss: 0.357706\tAccuracy: 87.77%\n",
      "88\tValidation loss: 0.365468\tBest loss: 0.357706\tAccuracy: 89.21%\n",
      "89\tValidation loss: 0.357184\tBest loss: 0.357184\tAccuracy: 89.21%\n",
      "90\tValidation loss: 0.359519\tBest loss: 0.357184\tAccuracy: 89.21%\n",
      "91\tValidation loss: 0.365223\tBest loss: 0.357184\tAccuracy: 87.77%\n",
      "92\tValidation loss: 0.369359\tBest loss: 0.357184\tAccuracy: 88.49%\n",
      "93\tValidation loss: 0.368276\tBest loss: 0.357184\tAccuracy: 90.65%\n",
      "94\tValidation loss: 0.364410\tBest loss: 0.357184\tAccuracy: 89.21%\n",
      "95\tValidation loss: 0.353839\tBest loss: 0.353839\tAccuracy: 88.49%\n",
      "96\tValidation loss: 0.347128\tBest loss: 0.347128\tAccuracy: 89.93%\n",
      "97\tValidation loss: 0.364123\tBest loss: 0.347128\tAccuracy: 89.93%\n",
      "98\tValidation loss: 0.369450\tBest loss: 0.347128\tAccuracy: 89.93%\n",
      "99\tValidation loss: 0.362597\tBest loss: 0.347128\tAccuracy: 89.93%\n",
      "100\tValidation loss: 0.345910\tBest loss: 0.345910\tAccuracy: 89.93%\n",
      "101\tValidation loss: 0.342726\tBest loss: 0.342726\tAccuracy: 90.65%\n",
      "102\tValidation loss: 0.336149\tBest loss: 0.336149\tAccuracy: 89.93%\n",
      "103\tValidation loss: 0.336971\tBest loss: 0.336149\tAccuracy: 89.93%\n",
      "104\tValidation loss: 0.333853\tBest loss: 0.333853\tAccuracy: 89.21%\n",
      "105\tValidation loss: 0.353313\tBest loss: 0.333853\tAccuracy: 89.93%\n",
      "106\tValidation loss: 0.366008\tBest loss: 0.333853\tAccuracy: 89.93%\n",
      "107\tValidation loss: 0.338246\tBest loss: 0.333853\tAccuracy: 89.93%\n",
      "108\tValidation loss: 0.334394\tBest loss: 0.333853\tAccuracy: 89.93%\n",
      "109\tValidation loss: 0.341868\tBest loss: 0.333853\tAccuracy: 89.21%\n",
      "110\tValidation loss: 0.358366\tBest loss: 0.333853\tAccuracy: 88.49%\n",
      "111\tValidation loss: 0.351999\tBest loss: 0.333853\tAccuracy: 89.93%\n",
      "112\tValidation loss: 0.300528\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "113\tValidation loss: 0.313932\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "114\tValidation loss: 0.354333\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "115\tValidation loss: 0.357869\tBest loss: 0.300528\tAccuracy: 89.21%\n",
      "116\tValidation loss: 0.339068\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "117\tValidation loss: 0.339169\tBest loss: 0.300528\tAccuracy: 88.49%\n",
      "118\tValidation loss: 0.329303\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "119\tValidation loss: 0.335889\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "120\tValidation loss: 0.332328\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.334761\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "122\tValidation loss: 0.338795\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "123\tValidation loss: 0.331497\tBest loss: 0.300528\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 0.319430\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.335289\tBest loss: 0.300528\tAccuracy: 89.21%\n",
      "126\tValidation loss: 0.335139\tBest loss: 0.300528\tAccuracy: 88.49%\n",
      "127\tValidation loss: 0.335011\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "128\tValidation loss: 0.315080\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "129\tValidation loss: 0.329876\tBest loss: 0.300528\tAccuracy: 89.21%\n",
      "130\tValidation loss: 0.332351\tBest loss: 0.300528\tAccuracy: 89.93%\n",
      "131\tValidation loss: 0.335862\tBest loss: 0.300528\tAccuracy: 90.65%\n",
      "132\tValidation loss: 0.326089\tBest loss: 0.300528\tAccuracy: 89.21%\n",
      "133\tValidation loss: 0.322326\tBest loss: 0.300528\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  15.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 47.834011\tBest loss: 47.834011\tAccuracy: 2.88%\n",
      "1\tValidation loss: 83.770653\tBest loss: 47.834011\tAccuracy: 2.16%\n",
      "2\tValidation loss: 68.968506\tBest loss: 47.834011\tAccuracy: 0.72%\n",
      "3\tValidation loss: 66.465103\tBest loss: 47.834011\tAccuracy: 5.76%\n",
      "4\tValidation loss: 49.870590\tBest loss: 47.834011\tAccuracy: 0.72%\n",
      "5\tValidation loss: 14.757264\tBest loss: 14.757264\tAccuracy: 5.04%\n",
      "6\tValidation loss: 5.244381\tBest loss: 5.244381\tAccuracy: 12.95%\n",
      "7\tValidation loss: 3.744179\tBest loss: 3.744179\tAccuracy: 9.35%\n",
      "8\tValidation loss: 3.477688\tBest loss: 3.477688\tAccuracy: 11.51%\n",
      "9\tValidation loss: 3.356569\tBest loss: 3.356569\tAccuracy: 17.27%\n",
      "10\tValidation loss: 3.274962\tBest loss: 3.274962\tAccuracy: 15.11%\n",
      "11\tValidation loss: 3.179298\tBest loss: 3.179298\tAccuracy: 20.14%\n",
      "12\tValidation loss: 3.038636\tBest loss: 3.038636\tAccuracy: 22.30%\n",
      "13\tValidation loss: 2.990522\tBest loss: 2.990522\tAccuracy: 23.02%\n",
      "14\tValidation loss: 2.780244\tBest loss: 2.780244\tAccuracy: 30.94%\n",
      "15\tValidation loss: 2.674868\tBest loss: 2.674868\tAccuracy: 30.94%\n",
      "16\tValidation loss: 2.704460\tBest loss: 2.674868\tAccuracy: 30.94%\n",
      "17\tValidation loss: 3.102478\tBest loss: 2.674868\tAccuracy: 30.94%\n",
      "18\tValidation loss: 3.121624\tBest loss: 2.674868\tAccuracy: 28.78%\n",
      "19\tValidation loss: 2.613738\tBest loss: 2.613738\tAccuracy: 44.60%\n",
      "20\tValidation loss: 2.518884\tBest loss: 2.518884\tAccuracy: 35.97%\n",
      "21\tValidation loss: 2.429881\tBest loss: 2.429881\tAccuracy: 42.45%\n",
      "22\tValidation loss: 2.409007\tBest loss: 2.409007\tAccuracy: 38.13%\n",
      "23\tValidation loss: 2.272636\tBest loss: 2.272636\tAccuracy: 42.45%\n",
      "24\tValidation loss: 2.562729\tBest loss: 2.272636\tAccuracy: 35.25%\n",
      "25\tValidation loss: 2.316122\tBest loss: 2.272636\tAccuracy: 41.01%\n",
      "26\tValidation loss: 2.573217\tBest loss: 2.272636\tAccuracy: 38.85%\n",
      "27\tValidation loss: 2.387959\tBest loss: 2.272636\tAccuracy: 36.69%\n",
      "28\tValidation loss: 2.067441\tBest loss: 2.067441\tAccuracy: 48.20%\n",
      "29\tValidation loss: 3.000391\tBest loss: 2.067441\tAccuracy: 36.69%\n",
      "30\tValidation loss: 3.923075\tBest loss: 2.067441\tAccuracy: 39.57%\n",
      "31\tValidation loss: 6.252503\tBest loss: 2.067441\tAccuracy: 15.83%\n",
      "32\tValidation loss: 5.593824\tBest loss: 2.067441\tAccuracy: 15.83%\n",
      "33\tValidation loss: 7.151298\tBest loss: 2.067441\tAccuracy: 10.79%\n",
      "34\tValidation loss: 4.493215\tBest loss: 2.067441\tAccuracy: 33.81%\n",
      "35\tValidation loss: 3.615561\tBest loss: 2.067441\tAccuracy: 23.02%\n",
      "36\tValidation loss: 3.817017\tBest loss: 2.067441\tAccuracy: 16.55%\n",
      "37\tValidation loss: 3.402573\tBest loss: 2.067441\tAccuracy: 23.02%\n",
      "38\tValidation loss: 3.015847\tBest loss: 2.067441\tAccuracy: 28.78%\n",
      "39\tValidation loss: 2.981335\tBest loss: 2.067441\tAccuracy: 28.78%\n",
      "40\tValidation loss: 2.801389\tBest loss: 2.067441\tAccuracy: 28.06%\n",
      "41\tValidation loss: 2.971200\tBest loss: 2.067441\tAccuracy: 25.18%\n",
      "42\tValidation loss: 3.009692\tBest loss: 2.067441\tAccuracy: 34.53%\n",
      "43\tValidation loss: 3.078256\tBest loss: 2.067441\tAccuracy: 30.22%\n",
      "44\tValidation loss: 4.142628\tBest loss: 2.067441\tAccuracy: 23.02%\n",
      "45\tValidation loss: 5.427996\tBest loss: 2.067441\tAccuracy: 13.67%\n",
      "46\tValidation loss: 6.224847\tBest loss: 2.067441\tAccuracy: 16.55%\n",
      "47\tValidation loss: 4.985146\tBest loss: 2.067441\tAccuracy: 6.47%\n",
      "48\tValidation loss: 3.565823\tBest loss: 2.067441\tAccuracy: 13.67%\n",
      "49\tValidation loss: 3.500692\tBest loss: 2.067441\tAccuracy: 13.67%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=   5.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 44.588604\tBest loss: 44.588604\tAccuracy: 0.00%\n",
      "1\tValidation loss: 78.058807\tBest loss: 44.588604\tAccuracy: 7.19%\n",
      "2\tValidation loss: 71.067146\tBest loss: 44.588604\tAccuracy: 0.00%\n",
      "3\tValidation loss: 55.035316\tBest loss: 44.588604\tAccuracy: 5.76%\n",
      "4\tValidation loss: 41.593113\tBest loss: 41.593113\tAccuracy: 0.72%\n",
      "5\tValidation loss: 23.480412\tBest loss: 23.480412\tAccuracy: 6.47%\n",
      "6\tValidation loss: 7.768948\tBest loss: 7.768948\tAccuracy: 5.04%\n",
      "7\tValidation loss: 4.783283\tBest loss: 4.783283\tAccuracy: 5.76%\n",
      "8\tValidation loss: 4.151641\tBest loss: 4.151641\tAccuracy: 8.63%\n",
      "9\tValidation loss: 3.423568\tBest loss: 3.423568\tAccuracy: 17.27%\n",
      "10\tValidation loss: 3.364474\tBest loss: 3.364474\tAccuracy: 16.55%\n",
      "11\tValidation loss: 3.233948\tBest loss: 3.233948\tAccuracy: 20.14%\n",
      "12\tValidation loss: 3.048557\tBest loss: 3.048557\tAccuracy: 27.34%\n",
      "13\tValidation loss: 2.953934\tBest loss: 2.953934\tAccuracy: 25.18%\n",
      "14\tValidation loss: 2.882655\tBest loss: 2.882655\tAccuracy: 28.78%\n",
      "15\tValidation loss: 2.857804\tBest loss: 2.857804\tAccuracy: 30.22%\n",
      "16\tValidation loss: 2.737692\tBest loss: 2.737692\tAccuracy: 28.78%\n",
      "17\tValidation loss: 2.553680\tBest loss: 2.553680\tAccuracy: 39.57%\n",
      "18\tValidation loss: 2.269958\tBest loss: 2.269958\tAccuracy: 46.76%\n",
      "19\tValidation loss: 2.451435\tBest loss: 2.269958\tAccuracy: 41.73%\n",
      "20\tValidation loss: 2.297209\tBest loss: 2.269958\tAccuracy: 46.76%\n",
      "21\tValidation loss: 2.366307\tBest loss: 2.269958\tAccuracy: 44.60%\n",
      "22\tValidation loss: 2.415520\tBest loss: 2.269958\tAccuracy: 43.88%\n",
      "23\tValidation loss: 2.336983\tBest loss: 2.269958\tAccuracy: 43.17%\n",
      "24\tValidation loss: 3.043830\tBest loss: 2.269958\tAccuracy: 30.22%\n",
      "25\tValidation loss: 2.628800\tBest loss: 2.269958\tAccuracy: 41.01%\n",
      "26\tValidation loss: 2.813545\tBest loss: 2.269958\tAccuracy: 34.53%\n",
      "27\tValidation loss: 2.904152\tBest loss: 2.269958\tAccuracy: 38.85%\n",
      "28\tValidation loss: 3.804931\tBest loss: 2.269958\tAccuracy: 24.46%\n",
      "29\tValidation loss: 5.473369\tBest loss: 2.269958\tAccuracy: 25.90%\n",
      "30\tValidation loss: 3.765152\tBest loss: 2.269958\tAccuracy: 28.06%\n",
      "31\tValidation loss: 3.485360\tBest loss: 2.269958\tAccuracy: 30.22%\n",
      "32\tValidation loss: 2.796339\tBest loss: 2.269958\tAccuracy: 38.13%\n",
      "33\tValidation loss: 2.393386\tBest loss: 2.269958\tAccuracy: 45.32%\n",
      "34\tValidation loss: 3.015845\tBest loss: 2.269958\tAccuracy: 35.97%\n",
      "35\tValidation loss: 2.884195\tBest loss: 2.269958\tAccuracy: 33.09%\n",
      "36\tValidation loss: 2.398807\tBest loss: 2.269958\tAccuracy: 38.13%\n",
      "37\tValidation loss: 2.428062\tBest loss: 2.269958\tAccuracy: 49.64%\n",
      "38\tValidation loss: 2.208345\tBest loss: 2.208345\tAccuracy: 44.60%\n",
      "39\tValidation loss: 2.079243\tBest loss: 2.079243\tAccuracy: 44.60%\n",
      "40\tValidation loss: 2.769952\tBest loss: 2.079243\tAccuracy: 33.81%\n",
      "41\tValidation loss: 5.022945\tBest loss: 2.079243\tAccuracy: 32.37%\n",
      "42\tValidation loss: 5.557879\tBest loss: 2.079243\tAccuracy: 20.14%\n",
      "43\tValidation loss: 8.610531\tBest loss: 2.079243\tAccuracy: 14.39%\n",
      "44\tValidation loss: 13.436765\tBest loss: 2.079243\tAccuracy: 12.23%\n",
      "45\tValidation loss: 14.416088\tBest loss: 2.079243\tAccuracy: 7.19%\n",
      "46\tValidation loss: 9.788660\tBest loss: 2.079243\tAccuracy: 15.11%\n",
      "47\tValidation loss: 4.226332\tBest loss: 2.079243\tAccuracy: 17.99%\n",
      "48\tValidation loss: 3.452050\tBest loss: 2.079243\tAccuracy: 16.55%\n",
      "49\tValidation loss: 3.128753\tBest loss: 2.079243\tAccuracy: 28.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\tValidation loss: 3.024799\tBest loss: 2.079243\tAccuracy: 28.78%\n",
      "51\tValidation loss: 3.022376\tBest loss: 2.079243\tAccuracy: 28.78%\n",
      "52\tValidation loss: 2.771321\tBest loss: 2.079243\tAccuracy: 30.22%\n",
      "53\tValidation loss: 2.630708\tBest loss: 2.079243\tAccuracy: 36.69%\n",
      "54\tValidation loss: 2.174120\tBest loss: 2.079243\tAccuracy: 40.29%\n",
      "55\tValidation loss: 2.345094\tBest loss: 2.079243\tAccuracy: 44.60%\n",
      "56\tValidation loss: 3.031317\tBest loss: 2.079243\tAccuracy: 35.25%\n",
      "57\tValidation loss: 5.583330\tBest loss: 2.079243\tAccuracy: 23.74%\n",
      "58\tValidation loss: 7.314203\tBest loss: 2.079243\tAccuracy: 20.14%\n",
      "59\tValidation loss: 4.744775\tBest loss: 2.079243\tAccuracy: 28.06%\n",
      "60\tValidation loss: 5.215952\tBest loss: 2.079243\tAccuracy: 15.83%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=   6.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0> \n",
      "0\tValidation loss: 46.679760\tBest loss: 46.679760\tAccuracy: 0.00%\n",
      "1\tValidation loss: 91.034538\tBest loss: 46.679760\tAccuracy: 1.44%\n",
      "2\tValidation loss: 102.994781\tBest loss: 46.679760\tAccuracy: 0.72%\n",
      "3\tValidation loss: 36.347752\tBest loss: 36.347752\tAccuracy: 2.88%\n",
      "4\tValidation loss: 23.556938\tBest loss: 23.556938\tAccuracy: 2.16%\n",
      "5\tValidation loss: 14.682962\tBest loss: 14.682962\tAccuracy: 9.35%\n",
      "6\tValidation loss: 10.018343\tBest loss: 10.018343\tAccuracy: 0.00%\n",
      "7\tValidation loss: 4.107654\tBest loss: 4.107654\tAccuracy: 12.95%\n",
      "8\tValidation loss: 3.605514\tBest loss: 3.605514\tAccuracy: 20.14%\n",
      "9\tValidation loss: 3.749037\tBest loss: 3.605514\tAccuracy: 18.71%\n",
      "10\tValidation loss: 3.425866\tBest loss: 3.425866\tAccuracy: 23.74%\n",
      "11\tValidation loss: 3.461855\tBest loss: 3.425866\tAccuracy: 15.83%\n",
      "12\tValidation loss: 3.367039\tBest loss: 3.367039\tAccuracy: 21.58%\n",
      "13\tValidation loss: 3.303152\tBest loss: 3.303152\tAccuracy: 22.30%\n",
      "14\tValidation loss: 3.132722\tBest loss: 3.132722\tAccuracy: 25.90%\n",
      "15\tValidation loss: 2.990767\tBest loss: 2.990767\tAccuracy: 25.90%\n",
      "16\tValidation loss: 2.862492\tBest loss: 2.862492\tAccuracy: 33.09%\n",
      "17\tValidation loss: 2.791422\tBest loss: 2.791422\tAccuracy: 31.65%\n",
      "18\tValidation loss: 2.812985\tBest loss: 2.791422\tAccuracy: 28.78%\n",
      "19\tValidation loss: 2.803743\tBest loss: 2.791422\tAccuracy: 30.94%\n",
      "20\tValidation loss: 2.804746\tBest loss: 2.791422\tAccuracy: 35.97%\n",
      "21\tValidation loss: 2.791566\tBest loss: 2.791422\tAccuracy: 31.65%\n",
      "22\tValidation loss: 2.953660\tBest loss: 2.791422\tAccuracy: 35.25%\n",
      "23\tValidation loss: 2.614937\tBest loss: 2.614937\tAccuracy: 32.37%\n",
      "24\tValidation loss: 2.742640\tBest loss: 2.614937\tAccuracy: 30.94%\n",
      "25\tValidation loss: 2.594756\tBest loss: 2.594756\tAccuracy: 35.97%\n",
      "26\tValidation loss: 2.651265\tBest loss: 2.594756\tAccuracy: 41.73%\n",
      "27\tValidation loss: 2.407030\tBest loss: 2.407030\tAccuracy: 41.01%\n",
      "28\tValidation loss: 2.361935\tBest loss: 2.361935\tAccuracy: 41.73%\n",
      "29\tValidation loss: 2.112435\tBest loss: 2.112435\tAccuracy: 50.36%\n",
      "30\tValidation loss: 2.498264\tBest loss: 2.112435\tAccuracy: 41.73%\n",
      "31\tValidation loss: 2.680900\tBest loss: 2.112435\tAccuracy: 39.57%\n",
      "32\tValidation loss: 2.967616\tBest loss: 2.112435\tAccuracy: 35.25%\n",
      "33\tValidation loss: 3.220694\tBest loss: 2.112435\tAccuracy: 31.65%\n",
      "34\tValidation loss: 3.179909\tBest loss: 2.112435\tAccuracy: 29.50%\n",
      "35\tValidation loss: 3.040082\tBest loss: 2.112435\tAccuracy: 25.90%\n",
      "36\tValidation loss: 3.340580\tBest loss: 2.112435\tAccuracy: 24.46%\n",
      "37\tValidation loss: 3.371330\tBest loss: 2.112435\tAccuracy: 22.30%\n",
      "38\tValidation loss: 6.573487\tBest loss: 2.112435\tAccuracy: 10.07%\n",
      "39\tValidation loss: 10.616151\tBest loss: 2.112435\tAccuracy: 8.63%\n",
      "40\tValidation loss: 8.192230\tBest loss: 2.112435\tAccuracy: 15.11%\n",
      "41\tValidation loss: 6.850704\tBest loss: 2.112435\tAccuracy: 10.07%\n",
      "42\tValidation loss: 3.420756\tBest loss: 2.112435\tAccuracy: 16.55%\n",
      "43\tValidation loss: 3.221347\tBest loss: 2.112435\tAccuracy: 23.74%\n",
      "44\tValidation loss: 3.124268\tBest loss: 2.112435\tAccuracy: 24.46%\n",
      "45\tValidation loss: 3.106217\tBest loss: 2.112435\tAccuracy: 30.22%\n",
      "46\tValidation loss: 3.170738\tBest loss: 2.112435\tAccuracy: 22.30%\n",
      "47\tValidation loss: 3.262775\tBest loss: 2.112435\tAccuracy: 22.30%\n",
      "48\tValidation loss: 3.185981\tBest loss: 2.112435\tAccuracy: 20.86%\n",
      "49\tValidation loss: 3.182069\tBest loss: 2.112435\tAccuracy: 23.02%\n",
      "50\tValidation loss: 3.447622\tBest loss: 2.112435\tAccuracy: 16.55%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=300, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0, batch_size=500, activation=<function relu at 0x00000252A18B50D0>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 6.834814\tBest loss: 6.834814\tAccuracy: 13.67%\n",
      "1\tValidation loss: 3.676623\tBest loss: 3.676623\tAccuracy: 30.22%\n",
      "2\tValidation loss: 4.563934\tBest loss: 3.676623\tAccuracy: 32.37%\n",
      "3\tValidation loss: 10.665338\tBest loss: 3.676623\tAccuracy: 17.99%\n",
      "4\tValidation loss: 8.843570\tBest loss: 3.676623\tAccuracy: 20.86%\n",
      "5\tValidation loss: 27.992466\tBest loss: 3.676623\tAccuracy: 9.35%\n",
      "6\tValidation loss: 20.432486\tBest loss: 3.676623\tAccuracy: 20.14%\n",
      "7\tValidation loss: 5.910553\tBest loss: 3.676623\tAccuracy: 20.86%\n",
      "8\tValidation loss: 18.734564\tBest loss: 3.676623\tAccuracy: 12.23%\n",
      "9\tValidation loss: 5.952853\tBest loss: 3.676623\tAccuracy: 20.14%\n",
      "10\tValidation loss: 5.198924\tBest loss: 3.676623\tAccuracy: 25.18%\n",
      "11\tValidation loss: 11.546963\tBest loss: 3.676623\tAccuracy: 22.30%\n",
      "12\tValidation loss: 8.103140\tBest loss: 3.676623\tAccuracy: 23.74%\n",
      "13\tValidation loss: 7.870464\tBest loss: 3.676623\tAccuracy: 14.39%\n",
      "14\tValidation loss: 8.141955\tBest loss: 3.676623\tAccuracy: 25.90%\n",
      "15\tValidation loss: 17.093168\tBest loss: 3.676623\tAccuracy: 16.55%\n",
      "16\tValidation loss: 6.410684\tBest loss: 3.676623\tAccuracy: 25.18%\n",
      "17\tValidation loss: 5.573224\tBest loss: 3.676623\tAccuracy: 30.22%\n",
      "18\tValidation loss: 8.664461\tBest loss: 3.676623\tAccuracy: 29.50%\n",
      "19\tValidation loss: 6.580418\tBest loss: 3.676623\tAccuracy: 36.69%\n",
      "20\tValidation loss: 9.186361\tBest loss: 3.676623\tAccuracy: 41.73%\n",
      "21\tValidation loss: 4.917040\tBest loss: 3.676623\tAccuracy: 41.73%\n",
      "22\tValidation loss: 6.082469\tBest loss: 3.676623\tAccuracy: 37.41%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=   3.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 9.720991\tBest loss: 9.720991\tAccuracy: 10.79%\n",
      "1\tValidation loss: 3.984398\tBest loss: 3.984398\tAccuracy: 26.62%\n",
      "2\tValidation loss: 3.550803\tBest loss: 3.550803\tAccuracy: 30.22%\n",
      "3\tValidation loss: 11.186654\tBest loss: 3.550803\tAccuracy: 22.30%\n",
      "4\tValidation loss: 12.380132\tBest loss: 3.550803\tAccuracy: 17.99%\n",
      "5\tValidation loss: 11.758670\tBest loss: 3.550803\tAccuracy: 17.99%\n",
      "6\tValidation loss: 7.805160\tBest loss: 3.550803\tAccuracy: 25.90%\n",
      "7\tValidation loss: 6.476921\tBest loss: 3.550803\tAccuracy: 19.42%\n",
      "8\tValidation loss: 5.638260\tBest loss: 3.550803\tAccuracy: 24.46%\n",
      "9\tValidation loss: 21.772530\tBest loss: 3.550803\tAccuracy: 20.86%\n",
      "10\tValidation loss: 7.238575\tBest loss: 3.550803\tAccuracy: 17.27%\n",
      "11\tValidation loss: 7.304043\tBest loss: 3.550803\tAccuracy: 18.71%\n",
      "12\tValidation loss: 8.281013\tBest loss: 3.550803\tAccuracy: 25.18%\n",
      "13\tValidation loss: 9.425030\tBest loss: 3.550803\tAccuracy: 16.55%\n",
      "14\tValidation loss: 8.836556\tBest loss: 3.550803\tAccuracy: 25.90%\n",
      "15\tValidation loss: 27.454369\tBest loss: 3.550803\tAccuracy: 14.39%\n",
      "16\tValidation loss: 7.542289\tBest loss: 3.550803\tAccuracy: 22.30%\n",
      "17\tValidation loss: 10.268783\tBest loss: 3.550803\tAccuracy: 27.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 8.094596\tBest loss: 3.550803\tAccuracy: 33.81%\n",
      "19\tValidation loss: 6.324184\tBest loss: 3.550803\tAccuracy: 36.69%\n",
      "20\tValidation loss: 7.133580\tBest loss: 3.550803\tAccuracy: 28.78%\n",
      "21\tValidation loss: 22.347704\tBest loss: 3.550803\tAccuracy: 36.69%\n",
      "22\tValidation loss: 4.720256\tBest loss: 3.550803\tAccuracy: 29.50%\n",
      "23\tValidation loss: 4.182920\tBest loss: 3.550803\tAccuracy: 47.48%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=   3.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 21.486883\tBest loss: 21.486883\tAccuracy: 9.35%\n",
      "1\tValidation loss: 4.098929\tBest loss: 4.098929\tAccuracy: 39.57%\n",
      "2\tValidation loss: 3.583502\tBest loss: 3.583502\tAccuracy: 41.01%\n",
      "3\tValidation loss: 12.921599\tBest loss: 3.583502\tAccuracy: 22.30%\n",
      "4\tValidation loss: 11.444817\tBest loss: 3.583502\tAccuracy: 21.58%\n",
      "5\tValidation loss: 8.841750\tBest loss: 3.583502\tAccuracy: 23.74%\n",
      "6\tValidation loss: 6.925415\tBest loss: 3.583502\tAccuracy: 28.06%\n",
      "7\tValidation loss: 51.632019\tBest loss: 3.583502\tAccuracy: 20.14%\n",
      "8\tValidation loss: 4.779915\tBest loss: 3.583502\tAccuracy: 32.37%\n",
      "9\tValidation loss: 2.714287\tBest loss: 2.714287\tAccuracy: 40.29%\n",
      "10\tValidation loss: 5.860233\tBest loss: 2.714287\tAccuracy: 29.50%\n",
      "11\tValidation loss: 5.402021\tBest loss: 2.714287\tAccuracy: 35.25%\n",
      "12\tValidation loss: 6.525114\tBest loss: 2.714287\tAccuracy: 23.74%\n",
      "13\tValidation loss: 7.078737\tBest loss: 2.714287\tAccuracy: 25.90%\n",
      "14\tValidation loss: 17.400902\tBest loss: 2.714287\tAccuracy: 33.81%\n",
      "15\tValidation loss: 8.024902\tBest loss: 2.714287\tAccuracy: 37.41%\n",
      "16\tValidation loss: 17.915852\tBest loss: 2.714287\tAccuracy: 41.01%\n",
      "17\tValidation loss: 5.810408\tBest loss: 2.714287\tAccuracy: 49.64%\n",
      "18\tValidation loss: 6.580411\tBest loss: 2.714287\tAccuracy: 38.13%\n",
      "19\tValidation loss: 8.204329\tBest loss: 2.714287\tAccuracy: 26.62%\n",
      "20\tValidation loss: 4.799433\tBest loss: 2.714287\tAccuracy: 41.73%\n",
      "21\tValidation loss: 22.478418\tBest loss: 2.714287\tAccuracy: 25.90%\n",
      "22\tValidation loss: 3.327447\tBest loss: 2.714287\tAccuracy: 53.24%\n",
      "23\tValidation loss: 6.785310\tBest loss: 2.714287\tAccuracy: 53.96%\n",
      "24\tValidation loss: 14.361265\tBest loss: 2.714287\tAccuracy: 40.29%\n",
      "25\tValidation loss: 5.266012\tBest loss: 2.714287\tAccuracy: 51.08%\n",
      "26\tValidation loss: 4.118998\tBest loss: 2.714287\tAccuracy: 57.55%\n",
      "27\tValidation loss: 5.571853\tBest loss: 2.714287\tAccuracy: 69.06%\n",
      "28\tValidation loss: 5.469354\tBest loss: 2.714287\tAccuracy: 57.55%\n",
      "29\tValidation loss: 4.797374\tBest loss: 2.714287\tAccuracy: 64.03%\n",
      "30\tValidation loss: 6.462876\tBest loss: 2.714287\tAccuracy: 47.48%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=2, learning_rate=0.01, dropout_rate=0.2, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=   4.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 1047.894531\tBest loss: 1047.894531\tAccuracy: 6.47%\n",
      "1\tValidation loss: 80432.062500\tBest loss: 1047.894531\tAccuracy: 3.60%\n",
      "2\tValidation loss: 125880096.000000\tBest loss: 1047.894531\tAccuracy: 6.47%\n",
      "3\tValidation loss: 701419456.000000\tBest loss: 1047.894531\tAccuracy: 6.47%\n",
      "4\tValidation loss: 673322880.000000\tBest loss: 1047.894531\tAccuracy: 2.88%\n",
      "5\tValidation loss: 62579696.000000\tBest loss: 1047.894531\tAccuracy: 2.16%\n",
      "6\tValidation loss: 94740656.000000\tBest loss: 1047.894531\tAccuracy: 6.47%\n",
      "7\tValidation loss: 393526144.000000\tBest loss: 1047.894531\tAccuracy: 1.44%\n",
      "8\tValidation loss: 40852084.000000\tBest loss: 1047.894531\tAccuracy: 0.72%\n",
      "9\tValidation loss: 22250476.000000\tBest loss: 1047.894531\tAccuracy: 7.19%\n",
      "10\tValidation loss: 166736016.000000\tBest loss: 1047.894531\tAccuracy: 0.00%\n",
      "11\tValidation loss: 31241412.000000\tBest loss: 1047.894531\tAccuracy: 1.44%\n",
      "12\tValidation loss: 18531598.000000\tBest loss: 1047.894531\tAccuracy: 1.44%\n",
      "13\tValidation loss: 11107954.000000\tBest loss: 1047.894531\tAccuracy: 3.60%\n",
      "14\tValidation loss: 5255047.000000\tBest loss: 1047.894531\tAccuracy: 1.44%\n",
      "15\tValidation loss: 2540660.000000\tBest loss: 1047.894531\tAccuracy: 5.04%\n",
      "16\tValidation loss: 1949040.875000\tBest loss: 1047.894531\tAccuracy: 5.04%\n",
      "17\tValidation loss: 1587529.375000\tBest loss: 1047.894531\tAccuracy: 7.19%\n",
      "18\tValidation loss: 1554555.375000\tBest loss: 1047.894531\tAccuracy: 3.60%\n",
      "19\tValidation loss: 1567635.500000\tBest loss: 1047.894531\tAccuracy: 3.60%\n",
      "20\tValidation loss: 1668008.375000\tBest loss: 1047.894531\tAccuracy: 3.60%\n",
      "21\tValidation loss: 948892.250000\tBest loss: 1047.894531\tAccuracy: 8.63%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 1144.572876\tBest loss: 1144.572876\tAccuracy: 6.47%\n",
      "1\tValidation loss: 6243.069824\tBest loss: 1144.572876\tAccuracy: 1.44%\n",
      "2\tValidation loss: 13648008.000000\tBest loss: 1144.572876\tAccuracy: 4.32%\n",
      "3\tValidation loss: 786807424.000000\tBest loss: 1144.572876\tAccuracy: 0.72%\n",
      "4\tValidation loss: 1138682112.000000\tBest loss: 1144.572876\tAccuracy: 2.16%\n",
      "5\tValidation loss: 1431522432.000000\tBest loss: 1144.572876\tAccuracy: 2.16%\n",
      "6\tValidation loss: 579571456.000000\tBest loss: 1144.572876\tAccuracy: 2.16%\n",
      "7\tValidation loss: 397321792.000000\tBest loss: 1144.572876\tAccuracy: 5.04%\n",
      "8\tValidation loss: 256614640.000000\tBest loss: 1144.572876\tAccuracy: 1.44%\n",
      "9\tValidation loss: 48609756.000000\tBest loss: 1144.572876\tAccuracy: 0.72%\n",
      "10\tValidation loss: 23387040.000000\tBest loss: 1144.572876\tAccuracy: 1.44%\n",
      "11\tValidation loss: 15179730.000000\tBest loss: 1144.572876\tAccuracy: 4.32%\n",
      "12\tValidation loss: 10244998.000000\tBest loss: 1144.572876\tAccuracy: 2.88%\n",
      "13\tValidation loss: 7379325.000000\tBest loss: 1144.572876\tAccuracy: 1.44%\n",
      "14\tValidation loss: 5150579.500000\tBest loss: 1144.572876\tAccuracy: 2.88%\n",
      "15\tValidation loss: 3982885.000000\tBest loss: 1144.572876\tAccuracy: 2.88%\n",
      "16\tValidation loss: 3722238.000000\tBest loss: 1144.572876\tAccuracy: 3.60%\n",
      "17\tValidation loss: 2770397.250000\tBest loss: 1144.572876\tAccuracy: 5.04%\n",
      "18\tValidation loss: 3419927.500000\tBest loss: 1144.572876\tAccuracy: 8.63%\n",
      "19\tValidation loss: 1787613.125000\tBest loss: 1144.572876\tAccuracy: 7.91%\n",
      "20\tValidation loss: 1918270.250000\tBest loss: 1144.572876\tAccuracy: 6.47%\n",
      "21\tValidation loss: 1540829.750000\tBest loss: 1144.572876\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 883.191467\tBest loss: 883.191467\tAccuracy: 6.47%\n",
      "1\tValidation loss: 5926.902832\tBest loss: 883.191467\tAccuracy: 1.44%\n",
      "2\tValidation loss: 4077448.250000\tBest loss: 883.191467\tAccuracy: 5.76%\n",
      "3\tValidation loss: 2279832576.000000\tBest loss: 883.191467\tAccuracy: 5.76%\n",
      "4\tValidation loss: 519028384.000000\tBest loss: 883.191467\tAccuracy: 4.32%\n",
      "5\tValidation loss: 695753408.000000\tBest loss: 883.191467\tAccuracy: 1.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 4325273600.000000\tBest loss: 883.191467\tAccuracy: 5.76%\n",
      "7\tValidation loss: 452611072.000000\tBest loss: 883.191467\tAccuracy: 3.60%\n",
      "8\tValidation loss: 231003616.000000\tBest loss: 883.191467\tAccuracy: 5.04%\n",
      "9\tValidation loss: 99389256.000000\tBest loss: 883.191467\tAccuracy: 5.04%\n",
      "10\tValidation loss: 45553276.000000\tBest loss: 883.191467\tAccuracy: 7.19%\n",
      "11\tValidation loss: 108558368.000000\tBest loss: 883.191467\tAccuracy: 0.72%\n",
      "12\tValidation loss: 45718108.000000\tBest loss: 883.191467\tAccuracy: 4.32%\n",
      "13\tValidation loss: 28025046.000000\tBest loss: 883.191467\tAccuracy: 2.88%\n",
      "14\tValidation loss: 19666126.000000\tBest loss: 883.191467\tAccuracy: 5.04%\n",
      "15\tValidation loss: 13881537.000000\tBest loss: 883.191467\tAccuracy: 2.88%\n",
      "16\tValidation loss: 8924449.000000\tBest loss: 883.191467\tAccuracy: 0.72%\n",
      "17\tValidation loss: 5044442.000000\tBest loss: 883.191467\tAccuracy: 2.16%\n",
      "18\tValidation loss: 13458162.000000\tBest loss: 883.191467\tAccuracy: 0.72%\n",
      "19\tValidation loss: 11725708.000000\tBest loss: 883.191467\tAccuracy: 4.32%\n",
      "20\tValidation loss: 9145372.000000\tBest loss: 883.191467\tAccuracy: 5.04%\n",
      "21\tValidation loss: 8834323.000000\tBest loss: 883.191467\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_neurons=700, n_hidden_layers=3, learning_rate=0.1, dropout_rate=0.4, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=   3.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 67700.914062\tBest loss: 67700.914062\tAccuracy: 0.00%\n",
      "1\tValidation loss: 155.684616\tBest loss: 155.684616\tAccuracy: 4.32%\n",
      "2\tValidation loss: 67.696220\tBest loss: 67.696220\tAccuracy: 1.44%\n",
      "3\tValidation loss: 46.658100\tBest loss: 46.658100\tAccuracy: 2.16%\n",
      "4\tValidation loss: 28.655596\tBest loss: 28.655596\tAccuracy: 4.32%\n",
      "5\tValidation loss: 18.846478\tBest loss: 18.846478\tAccuracy: 2.16%\n",
      "6\tValidation loss: 12.637439\tBest loss: 12.637439\tAccuracy: 0.72%\n",
      "7\tValidation loss: 8.498130\tBest loss: 8.498130\tAccuracy: 4.32%\n",
      "8\tValidation loss: 6.830965\tBest loss: 6.830965\tAccuracy: 2.16%\n",
      "9\tValidation loss: 5.910711\tBest loss: 5.910711\tAccuracy: 0.72%\n",
      "10\tValidation loss: 4.798105\tBest loss: 4.798105\tAccuracy: 0.72%\n",
      "11\tValidation loss: 4.345514\tBest loss: 4.345514\tAccuracy: 2.16%\n",
      "12\tValidation loss: 4.127373\tBest loss: 4.127373\tAccuracy: 2.16%\n",
      "13\tValidation loss: 4.012644\tBest loss: 4.012644\tAccuracy: 6.47%\n",
      "14\tValidation loss: 4.013126\tBest loss: 4.012644\tAccuracy: 1.44%\n",
      "15\tValidation loss: 4.064632\tBest loss: 4.012644\tAccuracy: 2.88%\n",
      "16\tValidation loss: 3.961683\tBest loss: 3.961683\tAccuracy: 6.47%\n",
      "17\tValidation loss: 3.985003\tBest loss: 3.961683\tAccuracy: 3.60%\n",
      "18\tValidation loss: 3.926630\tBest loss: 3.926630\tAccuracy: 1.44%\n",
      "19\tValidation loss: 4.002022\tBest loss: 3.926630\tAccuracy: 0.72%\n",
      "20\tValidation loss: 3.903247\tBest loss: 3.903247\tAccuracy: 6.47%\n",
      "21\tValidation loss: 3.965384\tBest loss: 3.903247\tAccuracy: 1.44%\n",
      "22\tValidation loss: 3.886680\tBest loss: 3.886680\tAccuracy: 3.60%\n",
      "23\tValidation loss: 4.031156\tBest loss: 3.886680\tAccuracy: 3.60%\n",
      "24\tValidation loss: 3.891206\tBest loss: 3.886680\tAccuracy: 2.16%\n",
      "25\tValidation loss: 3.934689\tBest loss: 3.886680\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.878313\tBest loss: 3.878313\tAccuracy: 0.72%\n",
      "27\tValidation loss: 3.908153\tBest loss: 3.878313\tAccuracy: 1.44%\n",
      "28\tValidation loss: 3.939174\tBest loss: 3.878313\tAccuracy: 3.60%\n",
      "29\tValidation loss: 3.919995\tBest loss: 3.878313\tAccuracy: 5.04%\n",
      "30\tValidation loss: 3.919110\tBest loss: 3.878313\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.950167\tBest loss: 3.878313\tAccuracy: 1.44%\n",
      "32\tValidation loss: 3.842307\tBest loss: 3.842307\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.964053\tBest loss: 3.842307\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.939952\tBest loss: 3.842307\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.973384\tBest loss: 3.842307\tAccuracy: 0.72%\n",
      "36\tValidation loss: 3.856460\tBest loss: 3.842307\tAccuracy: 1.44%\n",
      "37\tValidation loss: 3.919662\tBest loss: 3.842307\tAccuracy: 5.76%\n",
      "38\tValidation loss: 3.944685\tBest loss: 3.842307\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.897902\tBest loss: 3.842307\tAccuracy: 2.16%\n",
      "40\tValidation loss: 3.870589\tBest loss: 3.842307\tAccuracy: 3.60%\n",
      "41\tValidation loss: 3.924455\tBest loss: 3.842307\tAccuracy: 6.47%\n",
      "42\tValidation loss: 3.917233\tBest loss: 3.842307\tAccuracy: 5.04%\n",
      "43\tValidation loss: 3.944389\tBest loss: 3.842307\tAccuracy: 1.44%\n",
      "44\tValidation loss: 3.841640\tBest loss: 3.841640\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.858506\tBest loss: 3.841640\tAccuracy: 5.04%\n",
      "46\tValidation loss: 3.905758\tBest loss: 3.841640\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.856562\tBest loss: 3.841640\tAccuracy: 5.04%\n",
      "48\tValidation loss: 3.833016\tBest loss: 3.833016\tAccuracy: 6.47%\n",
      "49\tValidation loss: 3.865315\tBest loss: 3.833016\tAccuracy: 5.04%\n",
      "50\tValidation loss: 3.851716\tBest loss: 3.833016\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.878260\tBest loss: 3.833016\tAccuracy: 3.60%\n",
      "52\tValidation loss: 3.881751\tBest loss: 3.833016\tAccuracy: 2.16%\n",
      "53\tValidation loss: 3.891037\tBest loss: 3.833016\tAccuracy: 6.47%\n",
      "54\tValidation loss: 3.859819\tBest loss: 3.833016\tAccuracy: 2.88%\n",
      "55\tValidation loss: 3.829222\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "56\tValidation loss: 3.937635\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.884140\tBest loss: 3.829222\tAccuracy: 6.47%\n",
      "58\tValidation loss: 3.962159\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "59\tValidation loss: 3.895395\tBest loss: 3.829222\tAccuracy: 0.72%\n",
      "60\tValidation loss: 3.837120\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "61\tValidation loss: 3.894302\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "62\tValidation loss: 3.930305\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.921700\tBest loss: 3.829222\tAccuracy: 6.47%\n",
      "64\tValidation loss: 3.838675\tBest loss: 3.829222\tAccuracy: 6.47%\n",
      "65\tValidation loss: 3.865190\tBest loss: 3.829222\tAccuracy: 1.44%\n",
      "66\tValidation loss: 3.846291\tBest loss: 3.829222\tAccuracy: 6.47%\n",
      "67\tValidation loss: 3.897099\tBest loss: 3.829222\tAccuracy: 0.72%\n",
      "68\tValidation loss: 3.857545\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "69\tValidation loss: 3.895030\tBest loss: 3.829222\tAccuracy: 3.60%\n",
      "70\tValidation loss: 3.944949\tBest loss: 3.829222\tAccuracy: 1.44%\n",
      "71\tValidation loss: 3.827239\tBest loss: 3.827239\tAccuracy: 3.60%\n",
      "72\tValidation loss: 3.975584\tBest loss: 3.827239\tAccuracy: 2.16%\n",
      "73\tValidation loss: 3.876556\tBest loss: 3.827239\tAccuracy: 2.16%\n",
      "74\tValidation loss: 3.922882\tBest loss: 3.827239\tAccuracy: 6.47%\n",
      "75\tValidation loss: 3.802440\tBest loss: 3.802440\tAccuracy: 5.04%\n",
      "76\tValidation loss: 3.878172\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "77\tValidation loss: 3.847886\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "78\tValidation loss: 3.877170\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "79\tValidation loss: 3.873020\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "80\tValidation loss: 3.834447\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "81\tValidation loss: 3.880043\tBest loss: 3.802440\tAccuracy: 2.16%\n",
      "82\tValidation loss: 3.858114\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "83\tValidation loss: 3.868446\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "84\tValidation loss: 3.912051\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "85\tValidation loss: 3.875065\tBest loss: 3.802440\tAccuracy: 1.44%\n",
      "86\tValidation loss: 3.870989\tBest loss: 3.802440\tAccuracy: 0.72%\n",
      "87\tValidation loss: 3.841067\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "88\tValidation loss: 3.892749\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "89\tValidation loss: 3.849879\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "90\tValidation loss: 3.848367\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "91\tValidation loss: 3.876641\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "92\tValidation loss: 3.868786\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "93\tValidation loss: 3.824180\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "94\tValidation loss: 3.859462\tBest loss: 3.802440\tAccuracy: 1.44%\n",
      "95\tValidation loss: 3.826362\tBest loss: 3.802440\tAccuracy: 3.60%\n",
      "96\tValidation loss: 3.913020\tBest loss: 3.802440\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  15.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 141632.703125\tBest loss: 141632.703125\tAccuracy: 2.16%\n",
      "1\tValidation loss: 670.095276\tBest loss: 670.095276\tAccuracy: 3.60%\n",
      "2\tValidation loss: 339.363403\tBest loss: 339.363403\tAccuracy: 3.60%\n",
      "3\tValidation loss: 83.482689\tBest loss: 83.482689\tAccuracy: 0.72%\n",
      "4\tValidation loss: 44.004105\tBest loss: 44.004105\tAccuracy: 0.72%\n",
      "5\tValidation loss: 22.460327\tBest loss: 22.460327\tAccuracy: 0.72%\n",
      "6\tValidation loss: 12.176029\tBest loss: 12.176029\tAccuracy: 2.16%\n",
      "7\tValidation loss: 8.342578\tBest loss: 8.342578\tAccuracy: 2.16%\n",
      "8\tValidation loss: 6.916665\tBest loss: 6.916665\tAccuracy: 1.44%\n",
      "9\tValidation loss: 5.656411\tBest loss: 5.656411\tAccuracy: 1.44%\n",
      "10\tValidation loss: 5.088061\tBest loss: 5.088061\tAccuracy: 5.04%\n",
      "11\tValidation loss: 4.732539\tBest loss: 4.732539\tAccuracy: 2.88%\n",
      "12\tValidation loss: 4.566545\tBest loss: 4.566545\tAccuracy: 2.16%\n",
      "13\tValidation loss: 4.283520\tBest loss: 4.283520\tAccuracy: 2.88%\n",
      "14\tValidation loss: 4.331211\tBest loss: 4.283520\tAccuracy: 3.60%\n",
      "15\tValidation loss: 4.209921\tBest loss: 4.209921\tAccuracy: 6.47%\n",
      "16\tValidation loss: 4.450738\tBest loss: 4.209921\tAccuracy: 5.76%\n",
      "17\tValidation loss: 4.340692\tBest loss: 4.209921\tAccuracy: 0.72%\n",
      "18\tValidation loss: 4.118688\tBest loss: 4.118688\tAccuracy: 2.88%\n",
      "19\tValidation loss: 4.302356\tBest loss: 4.118688\tAccuracy: 0.72%\n",
      "20\tValidation loss: 4.091594\tBest loss: 4.091594\tAccuracy: 6.47%\n",
      "21\tValidation loss: 4.151718\tBest loss: 4.091594\tAccuracy: 3.60%\n",
      "22\tValidation loss: 4.306661\tBest loss: 4.091594\tAccuracy: 6.47%\n",
      "23\tValidation loss: 4.078146\tBest loss: 4.078146\tAccuracy: 1.44%\n",
      "24\tValidation loss: 4.331690\tBest loss: 4.078146\tAccuracy: 2.16%\n",
      "25\tValidation loss: 3.964360\tBest loss: 3.964360\tAccuracy: 3.60%\n",
      "26\tValidation loss: 3.941113\tBest loss: 3.941113\tAccuracy: 5.04%\n",
      "27\tValidation loss: 4.017357\tBest loss: 3.941113\tAccuracy: 5.04%\n",
      "28\tValidation loss: 3.938128\tBest loss: 3.938128\tAccuracy: 0.72%\n",
      "29\tValidation loss: 3.986012\tBest loss: 3.938128\tAccuracy: 5.04%\n",
      "30\tValidation loss: 4.005361\tBest loss: 3.938128\tAccuracy: 5.04%\n",
      "31\tValidation loss: 3.926591\tBest loss: 3.926591\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.915163\tBest loss: 3.915163\tAccuracy: 2.16%\n",
      "33\tValidation loss: 4.059769\tBest loss: 3.915163\tAccuracy: 2.88%\n",
      "34\tValidation loss: 3.989355\tBest loss: 3.915163\tAccuracy: 3.60%\n",
      "35\tValidation loss: 3.909189\tBest loss: 3.909189\tAccuracy: 0.00%\n",
      "36\tValidation loss: 4.021426\tBest loss: 3.909189\tAccuracy: 3.60%\n",
      "37\tValidation loss: 3.906970\tBest loss: 3.906970\tAccuracy: 2.16%\n",
      "38\tValidation loss: 3.847022\tBest loss: 3.847022\tAccuracy: 6.47%\n",
      "39\tValidation loss: 3.945887\tBest loss: 3.847022\tAccuracy: 0.00%\n",
      "40\tValidation loss: 3.899997\tBest loss: 3.847022\tAccuracy: 6.47%\n",
      "41\tValidation loss: 3.987272\tBest loss: 3.847022\tAccuracy: 5.76%\n",
      "42\tValidation loss: 3.885605\tBest loss: 3.847022\tAccuracy: 3.60%\n",
      "43\tValidation loss: 3.888674\tBest loss: 3.847022\tAccuracy: 3.60%\n",
      "44\tValidation loss: 4.008438\tBest loss: 3.847022\tAccuracy: 0.00%\n",
      "45\tValidation loss: 4.052441\tBest loss: 3.847022\tAccuracy: 2.16%\n",
      "46\tValidation loss: 4.024144\tBest loss: 3.847022\tAccuracy: 2.88%\n",
      "47\tValidation loss: 3.897174\tBest loss: 3.847022\tAccuracy: 3.60%\n",
      "48\tValidation loss: 3.941042\tBest loss: 3.847022\tAccuracy: 0.00%\n",
      "49\tValidation loss: 3.893947\tBest loss: 3.847022\tAccuracy: 1.44%\n",
      "50\tValidation loss: 3.954061\tBest loss: 3.847022\tAccuracy: 5.76%\n",
      "51\tValidation loss: 3.966997\tBest loss: 3.847022\tAccuracy: 4.32%\n",
      "52\tValidation loss: 3.928801\tBest loss: 3.847022\tAccuracy: 2.88%\n",
      "53\tValidation loss: 4.048238\tBest loss: 3.847022\tAccuracy: 1.44%\n",
      "54\tValidation loss: 3.960387\tBest loss: 3.847022\tAccuracy: 1.44%\n",
      "55\tValidation loss: 3.845408\tBest loss: 3.845408\tAccuracy: 3.60%\n",
      "56\tValidation loss: 3.916507\tBest loss: 3.845408\tAccuracy: 4.32%\n",
      "57\tValidation loss: 3.953420\tBest loss: 3.845408\tAccuracy: 3.60%\n",
      "58\tValidation loss: 3.916597\tBest loss: 3.845408\tAccuracy: 5.76%\n",
      "59\tValidation loss: 3.972774\tBest loss: 3.845408\tAccuracy: 6.47%\n",
      "60\tValidation loss: 3.832504\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "61\tValidation loss: 3.862532\tBest loss: 3.832504\tAccuracy: 1.44%\n",
      "62\tValidation loss: 3.906433\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.887639\tBest loss: 3.832504\tAccuracy: 1.44%\n",
      "64\tValidation loss: 3.885341\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "65\tValidation loss: 3.875482\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "66\tValidation loss: 3.952633\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "67\tValidation loss: 3.902580\tBest loss: 3.832504\tAccuracy: 6.47%\n",
      "68\tValidation loss: 3.879116\tBest loss: 3.832504\tAccuracy: 2.88%\n",
      "69\tValidation loss: 3.933647\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "70\tValidation loss: 4.000082\tBest loss: 3.832504\tAccuracy: 1.44%\n",
      "71\tValidation loss: 3.969778\tBest loss: 3.832504\tAccuracy: 0.72%\n",
      "72\tValidation loss: 3.951437\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "73\tValidation loss: 3.843807\tBest loss: 3.832504\tAccuracy: 6.47%\n",
      "74\tValidation loss: 4.032902\tBest loss: 3.832504\tAccuracy: 1.44%\n",
      "75\tValidation loss: 3.966042\tBest loss: 3.832504\tAccuracy: 2.16%\n",
      "76\tValidation loss: 3.924040\tBest loss: 3.832504\tAccuracy: 2.16%\n",
      "77\tValidation loss: 3.961260\tBest loss: 3.832504\tAccuracy: 0.72%\n",
      "78\tValidation loss: 3.867374\tBest loss: 3.832504\tAccuracy: 1.44%\n",
      "79\tValidation loss: 3.874926\tBest loss: 3.832504\tAccuracy: 5.04%\n",
      "80\tValidation loss: 3.978810\tBest loss: 3.832504\tAccuracy: 6.47%\n",
      "81\tValidation loss: 3.956426\tBest loss: 3.832504\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  13.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 346011.750000\tBest loss: 346011.750000\tAccuracy: 3.60%\n",
      "1\tValidation loss: 533.078125\tBest loss: 533.078125\tAccuracy: 2.16%\n",
      "2\tValidation loss: 98.099670\tBest loss: 98.099670\tAccuracy: 0.72%\n",
      "3\tValidation loss: 66.153877\tBest loss: 66.153877\tAccuracy: 0.72%\n",
      "4\tValidation loss: 50.244740\tBest loss: 50.244740\tAccuracy: 5.04%\n",
      "5\tValidation loss: 38.800858\tBest loss: 38.800858\tAccuracy: 5.04%\n",
      "6\tValidation loss: 31.721544\tBest loss: 31.721544\tAccuracy: 5.04%\n",
      "7\tValidation loss: 25.801451\tBest loss: 25.801451\tAccuracy: 5.04%\n",
      "8\tValidation loss: 21.265438\tBest loss: 21.265438\tAccuracy: 5.04%\n",
      "9\tValidation loss: 17.225174\tBest loss: 17.225174\tAccuracy: 5.04%\n",
      "10\tValidation loss: 14.312653\tBest loss: 14.312653\tAccuracy: 5.04%\n",
      "11\tValidation loss: 12.217853\tBest loss: 12.217853\tAccuracy: 5.04%\n",
      "12\tValidation loss: 10.628717\tBest loss: 10.628717\tAccuracy: 3.60%\n",
      "13\tValidation loss: 9.425938\tBest loss: 9.425938\tAccuracy: 3.60%\n",
      "14\tValidation loss: 8.552598\tBest loss: 8.552598\tAccuracy: 3.60%\n",
      "15\tValidation loss: 7.875082\tBest loss: 7.875082\tAccuracy: 3.60%\n",
      "16\tValidation loss: 7.359358\tBest loss: 7.359358\tAccuracy: 3.60%\n",
      "17\tValidation loss: 6.696472\tBest loss: 6.696472\tAccuracy: 2.16%\n",
      "18\tValidation loss: 6.248835\tBest loss: 6.248835\tAccuracy: 3.60%\n",
      "19\tValidation loss: 5.897759\tBest loss: 5.897759\tAccuracy: 3.60%\n",
      "20\tValidation loss: 5.571674\tBest loss: 5.571674\tAccuracy: 3.60%\n",
      "21\tValidation loss: 5.389766\tBest loss: 5.389766\tAccuracy: 3.60%\n",
      "22\tValidation loss: 5.131991\tBest loss: 5.131991\tAccuracy: 3.60%\n",
      "23\tValidation loss: 4.870991\tBest loss: 4.870991\tAccuracy: 3.60%\n",
      "24\tValidation loss: 4.676820\tBest loss: 4.676820\tAccuracy: 3.60%\n",
      "25\tValidation loss: 4.429106\tBest loss: 4.429106\tAccuracy: 3.60%\n",
      "26\tValidation loss: 4.352883\tBest loss: 4.352883\tAccuracy: 3.60%\n",
      "27\tValidation loss: 4.273962\tBest loss: 4.273962\tAccuracy: 0.72%\n",
      "28\tValidation loss: 4.158894\tBest loss: 4.158894\tAccuracy: 3.60%\n",
      "29\tValidation loss: 4.098971\tBest loss: 4.098971\tAccuracy: 3.60%\n",
      "30\tValidation loss: 4.021354\tBest loss: 4.021354\tAccuracy: 3.60%\n",
      "31\tValidation loss: 3.979688\tBest loss: 3.979688\tAccuracy: 3.60%\n",
      "32\tValidation loss: 3.870785\tBest loss: 3.870785\tAccuracy: 6.47%\n",
      "33\tValidation loss: 3.856108\tBest loss: 3.856108\tAccuracy: 3.60%\n",
      "34\tValidation loss: 3.830412\tBest loss: 3.830412\tAccuracy: 6.47%\n",
      "35\tValidation loss: 3.829152\tBest loss: 3.829152\tAccuracy: 6.47%\n",
      "36\tValidation loss: 3.888400\tBest loss: 3.829152\tAccuracy: 0.72%\n",
      "37\tValidation loss: 3.854863\tBest loss: 3.829152\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 3.856906\tBest loss: 3.829152\tAccuracy: 3.60%\n",
      "39\tValidation loss: 3.845302\tBest loss: 3.829152\tAccuracy: 3.60%\n",
      "40\tValidation loss: 3.857839\tBest loss: 3.829152\tAccuracy: 6.47%\n",
      "41\tValidation loss: 3.808904\tBest loss: 3.808904\tAccuracy: 2.16%\n",
      "42\tValidation loss: 3.859358\tBest loss: 3.808904\tAccuracy: 6.47%\n",
      "43\tValidation loss: 3.850429\tBest loss: 3.808904\tAccuracy: 3.60%\n",
      "44\tValidation loss: 3.788840\tBest loss: 3.788840\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.832977\tBest loss: 3.788840\tAccuracy: 3.60%\n",
      "46\tValidation loss: 3.776507\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "47\tValidation loss: 3.803081\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "48\tValidation loss: 3.810272\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "49\tValidation loss: 3.811087\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "50\tValidation loss: 3.877741\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "51\tValidation loss: 3.812966\tBest loss: 3.776507\tAccuracy: 2.16%\n",
      "52\tValidation loss: 3.814905\tBest loss: 3.776507\tAccuracy: 2.88%\n",
      "53\tValidation loss: 3.861961\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "54\tValidation loss: 3.822585\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "55\tValidation loss: 3.826935\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "56\tValidation loss: 3.844675\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "57\tValidation loss: 3.851899\tBest loss: 3.776507\tAccuracy: 2.88%\n",
      "58\tValidation loss: 3.805200\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "59\tValidation loss: 3.851380\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "60\tValidation loss: 3.853745\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "61\tValidation loss: 3.854737\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "62\tValidation loss: 3.823598\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "63\tValidation loss: 3.828512\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "64\tValidation loss: 3.867969\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "65\tValidation loss: 3.821373\tBest loss: 3.776507\tAccuracy: 6.47%\n",
      "66\tValidation loss: 3.838389\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "67\tValidation loss: 3.803035\tBest loss: 3.776507\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=4, learning_rate=0.1, dropout_rate=0.4, batch_size=100, activation=<function elu at 0x00000252A18B00D0>, total=  12.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 68.164696\tBest loss: 68.164696\tAccuracy: 37.41%\n",
      "1\tValidation loss: 8.027755\tBest loss: 8.027755\tAccuracy: 72.66%\n",
      "2\tValidation loss: 1.425863\tBest loss: 1.425863\tAccuracy: 87.05%\n",
      "3\tValidation loss: 1.646256\tBest loss: 1.425863\tAccuracy: 85.61%\n",
      "4\tValidation loss: 1.065101\tBest loss: 1.065101\tAccuracy: 89.93%\n",
      "5\tValidation loss: 0.913416\tBest loss: 0.913416\tAccuracy: 91.37%\n",
      "6\tValidation loss: 0.829653\tBest loss: 0.829653\tAccuracy: 90.65%\n",
      "7\tValidation loss: 0.728565\tBest loss: 0.728565\tAccuracy: 91.37%\n",
      "8\tValidation loss: 0.688238\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "9\tValidation loss: 0.710960\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "10\tValidation loss: 0.694657\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "11\tValidation loss: 0.693914\tBest loss: 0.688238\tAccuracy: 92.09%\n",
      "12\tValidation loss: 0.708910\tBest loss: 0.688238\tAccuracy: 92.09%\n",
      "13\tValidation loss: 0.695898\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "14\tValidation loss: 0.708007\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "15\tValidation loss: 0.698800\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "16\tValidation loss: 0.698793\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "17\tValidation loss: 0.691707\tBest loss: 0.688238\tAccuracy: 92.81%\n",
      "18\tValidation loss: 0.682505\tBest loss: 0.682505\tAccuracy: 92.09%\n",
      "19\tValidation loss: 0.676657\tBest loss: 0.676657\tAccuracy: 92.09%\n",
      "20\tValidation loss: 0.676147\tBest loss: 0.676147\tAccuracy: 92.09%\n",
      "21\tValidation loss: 0.673369\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "22\tValidation loss: 0.674544\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "23\tValidation loss: 0.677225\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "24\tValidation loss: 0.679305\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "25\tValidation loss: 0.680961\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "26\tValidation loss: 0.682911\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "27\tValidation loss: 0.682748\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "28\tValidation loss: 0.685920\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "29\tValidation loss: 0.688654\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "30\tValidation loss: 0.688202\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "31\tValidation loss: 0.688871\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "32\tValidation loss: 0.689891\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "33\tValidation loss: 0.691767\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "34\tValidation loss: 0.691280\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "35\tValidation loss: 0.691173\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "36\tValidation loss: 0.694824\tBest loss: 0.673369\tAccuracy: 92.09%\n",
      "37\tValidation loss: 0.697775\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "38\tValidation loss: 0.695837\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "39\tValidation loss: 0.696890\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "40\tValidation loss: 0.698950\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "41\tValidation loss: 0.699497\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "42\tValidation loss: 0.699642\tBest loss: 0.673369\tAccuracy: 92.81%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 60.922035\tBest loss: 60.922035\tAccuracy: 40.29%\n",
      "1\tValidation loss: 5.547050\tBest loss: 5.547050\tAccuracy: 74.82%\n",
      "2\tValidation loss: 1.705747\tBest loss: 1.705747\tAccuracy: 84.89%\n",
      "3\tValidation loss: 1.000865\tBest loss: 1.000865\tAccuracy: 89.93%\n",
      "4\tValidation loss: 0.913336\tBest loss: 0.913336\tAccuracy: 89.21%\n",
      "5\tValidation loss: 0.932659\tBest loss: 0.913336\tAccuracy: 87.77%\n",
      "6\tValidation loss: 0.889887\tBest loss: 0.889887\tAccuracy: 89.21%\n",
      "7\tValidation loss: 0.846396\tBest loss: 0.846396\tAccuracy: 89.93%\n",
      "8\tValidation loss: 0.815466\tBest loss: 0.815466\tAccuracy: 89.21%\n",
      "9\tValidation loss: 0.784137\tBest loss: 0.784137\tAccuracy: 89.93%\n",
      "10\tValidation loss: 0.787230\tBest loss: 0.784137\tAccuracy: 89.93%\n",
      "11\tValidation loss: 0.784878\tBest loss: 0.784137\tAccuracy: 89.21%\n",
      "12\tValidation loss: 0.759407\tBest loss: 0.759407\tAccuracy: 90.65%\n",
      "13\tValidation loss: 0.732010\tBest loss: 0.732010\tAccuracy: 90.65%\n",
      "14\tValidation loss: 0.745741\tBest loss: 0.732010\tAccuracy: 90.65%\n",
      "15\tValidation loss: 0.738955\tBest loss: 0.732010\tAccuracy: 90.65%\n",
      "16\tValidation loss: 0.729990\tBest loss: 0.729990\tAccuracy: 90.65%\n",
      "17\tValidation loss: 0.730312\tBest loss: 0.729990\tAccuracy: 90.65%\n",
      "18\tValidation loss: 0.729158\tBest loss: 0.729158\tAccuracy: 90.65%\n",
      "19\tValidation loss: 0.722028\tBest loss: 0.722028\tAccuracy: 90.65%\n",
      "20\tValidation loss: 0.719680\tBest loss: 0.719680\tAccuracy: 90.65%\n",
      "21\tValidation loss: 0.716485\tBest loss: 0.716485\tAccuracy: 90.65%\n",
      "22\tValidation loss: 0.702773\tBest loss: 0.702773\tAccuracy: 90.65%\n",
      "23\tValidation loss: 0.699327\tBest loss: 0.699327\tAccuracy: 90.65%\n",
      "24\tValidation loss: 0.693595\tBest loss: 0.693595\tAccuracy: 90.65%\n",
      "25\tValidation loss: 0.695255\tBest loss: 0.693595\tAccuracy: 90.65%\n",
      "26\tValidation loss: 0.686545\tBest loss: 0.686545\tAccuracy: 90.65%\n",
      "27\tValidation loss: 0.691111\tBest loss: 0.686545\tAccuracy: 90.65%\n",
      "28\tValidation loss: 0.689682\tBest loss: 0.686545\tAccuracy: 90.65%\n",
      "29\tValidation loss: 0.680807\tBest loss: 0.680807\tAccuracy: 90.65%\n",
      "30\tValidation loss: 0.684074\tBest loss: 0.680807\tAccuracy: 90.65%\n",
      "31\tValidation loss: 0.675377\tBest loss: 0.675377\tAccuracy: 90.65%\n",
      "32\tValidation loss: 0.678776\tBest loss: 0.675377\tAccuracy: 90.65%\n",
      "33\tValidation loss: 0.679889\tBest loss: 0.675377\tAccuracy: 90.65%\n",
      "34\tValidation loss: 0.670603\tBest loss: 0.670603\tAccuracy: 90.65%\n",
      "35\tValidation loss: 0.668409\tBest loss: 0.668409\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\tValidation loss: 0.672171\tBest loss: 0.668409\tAccuracy: 90.65%\n",
      "37\tValidation loss: 0.672072\tBest loss: 0.668409\tAccuracy: 90.65%\n",
      "38\tValidation loss: 0.670348\tBest loss: 0.668409\tAccuracy: 90.65%\n",
      "39\tValidation loss: 0.669365\tBest loss: 0.668409\tAccuracy: 90.65%\n",
      "40\tValidation loss: 0.663564\tBest loss: 0.663564\tAccuracy: 90.65%\n",
      "41\tValidation loss: 0.664697\tBest loss: 0.663564\tAccuracy: 90.65%\n",
      "42\tValidation loss: 0.664272\tBest loss: 0.663564\tAccuracy: 89.93%\n",
      "43\tValidation loss: 0.662677\tBest loss: 0.662677\tAccuracy: 89.93%\n",
      "44\tValidation loss: 0.661753\tBest loss: 0.661753\tAccuracy: 89.93%\n",
      "45\tValidation loss: 0.659975\tBest loss: 0.659975\tAccuracy: 89.93%\n",
      "46\tValidation loss: 0.658907\tBest loss: 0.658907\tAccuracy: 89.93%\n",
      "47\tValidation loss: 0.657172\tBest loss: 0.657172\tAccuracy: 89.93%\n",
      "48\tValidation loss: 0.656259\tBest loss: 0.656259\tAccuracy: 89.93%\n",
      "49\tValidation loss: 0.652856\tBest loss: 0.652856\tAccuracy: 89.93%\n",
      "50\tValidation loss: 0.651458\tBest loss: 0.651458\tAccuracy: 89.93%\n",
      "51\tValidation loss: 0.648600\tBest loss: 0.648600\tAccuracy: 89.93%\n",
      "52\tValidation loss: 0.649381\tBest loss: 0.648600\tAccuracy: 89.93%\n",
      "53\tValidation loss: 0.649388\tBest loss: 0.648600\tAccuracy: 89.93%\n",
      "54\tValidation loss: 0.649206\tBest loss: 0.648600\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.646984\tBest loss: 0.646984\tAccuracy: 89.93%\n",
      "56\tValidation loss: 0.646720\tBest loss: 0.646720\tAccuracy: 89.93%\n",
      "57\tValidation loss: 0.646281\tBest loss: 0.646281\tAccuracy: 89.93%\n",
      "58\tValidation loss: 0.643855\tBest loss: 0.643855\tAccuracy: 89.93%\n",
      "59\tValidation loss: 0.641951\tBest loss: 0.641951\tAccuracy: 89.93%\n",
      "60\tValidation loss: 0.641885\tBest loss: 0.641885\tAccuracy: 89.93%\n",
      "61\tValidation loss: 0.640419\tBest loss: 0.640419\tAccuracy: 89.93%\n",
      "62\tValidation loss: 0.638449\tBest loss: 0.638449\tAccuracy: 89.93%\n",
      "63\tValidation loss: 0.638941\tBest loss: 0.638449\tAccuracy: 89.93%\n",
      "64\tValidation loss: 0.637662\tBest loss: 0.637662\tAccuracy: 89.93%\n",
      "65\tValidation loss: 0.638129\tBest loss: 0.637662\tAccuracy: 89.93%\n",
      "66\tValidation loss: 0.638123\tBest loss: 0.637662\tAccuracy: 89.93%\n",
      "67\tValidation loss: 0.637303\tBest loss: 0.637303\tAccuracy: 89.93%\n",
      "68\tValidation loss: 0.637073\tBest loss: 0.637073\tAccuracy: 89.93%\n",
      "69\tValidation loss: 0.634881\tBest loss: 0.634881\tAccuracy: 89.93%\n",
      "70\tValidation loss: 0.634948\tBest loss: 0.634881\tAccuracy: 89.93%\n",
      "71\tValidation loss: 0.633321\tBest loss: 0.633321\tAccuracy: 89.93%\n",
      "72\tValidation loss: 0.633244\tBest loss: 0.633244\tAccuracy: 89.93%\n",
      "73\tValidation loss: 0.633242\tBest loss: 0.633242\tAccuracy: 89.93%\n",
      "74\tValidation loss: 0.632951\tBest loss: 0.632951\tAccuracy: 89.93%\n",
      "75\tValidation loss: 0.631244\tBest loss: 0.631244\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.629928\tBest loss: 0.629928\tAccuracy: 89.93%\n",
      "77\tValidation loss: 0.630066\tBest loss: 0.629928\tAccuracy: 89.93%\n",
      "78\tValidation loss: 0.628361\tBest loss: 0.628361\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.627507\tBest loss: 0.627507\tAccuracy: 89.93%\n",
      "80\tValidation loss: 0.626642\tBest loss: 0.626642\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.626983\tBest loss: 0.626642\tAccuracy: 89.93%\n",
      "82\tValidation loss: 0.626700\tBest loss: 0.626642\tAccuracy: 89.93%\n",
      "83\tValidation loss: 0.626504\tBest loss: 0.626504\tAccuracy: 89.93%\n",
      "84\tValidation loss: 0.626171\tBest loss: 0.626171\tAccuracy: 89.93%\n",
      "85\tValidation loss: 0.624917\tBest loss: 0.624917\tAccuracy: 89.93%\n",
      "86\tValidation loss: 0.624814\tBest loss: 0.624814\tAccuracy: 89.93%\n",
      "87\tValidation loss: 0.624036\tBest loss: 0.624036\tAccuracy: 89.93%\n",
      "88\tValidation loss: 0.622806\tBest loss: 0.622806\tAccuracy: 89.93%\n",
      "89\tValidation loss: 0.622860\tBest loss: 0.622806\tAccuracy: 89.93%\n",
      "90\tValidation loss: 0.621614\tBest loss: 0.621614\tAccuracy: 89.93%\n",
      "91\tValidation loss: 0.620853\tBest loss: 0.620853\tAccuracy: 89.93%\n",
      "92\tValidation loss: 0.621132\tBest loss: 0.620853\tAccuracy: 89.93%\n",
      "93\tValidation loss: 0.620903\tBest loss: 0.620853\tAccuracy: 89.93%\n",
      "94\tValidation loss: 0.621186\tBest loss: 0.620853\tAccuracy: 89.93%\n",
      "95\tValidation loss: 0.619943\tBest loss: 0.619943\tAccuracy: 89.93%\n",
      "96\tValidation loss: 0.619170\tBest loss: 0.619170\tAccuracy: 89.93%\n",
      "97\tValidation loss: 0.618958\tBest loss: 0.618958\tAccuracy: 89.93%\n",
      "98\tValidation loss: 0.618842\tBest loss: 0.618842\tAccuracy: 89.93%\n",
      "99\tValidation loss: 0.618515\tBest loss: 0.618515\tAccuracy: 89.93%\n",
      "100\tValidation loss: 0.617562\tBest loss: 0.617562\tAccuracy: 89.93%\n",
      "101\tValidation loss: 0.617231\tBest loss: 0.617231\tAccuracy: 89.93%\n",
      "102\tValidation loss: 0.616927\tBest loss: 0.616927\tAccuracy: 89.93%\n",
      "103\tValidation loss: 0.615919\tBest loss: 0.615919\tAccuracy: 89.93%\n",
      "104\tValidation loss: 0.615126\tBest loss: 0.615126\tAccuracy: 89.93%\n",
      "105\tValidation loss: 0.615118\tBest loss: 0.615118\tAccuracy: 89.93%\n",
      "106\tValidation loss: 0.615121\tBest loss: 0.615118\tAccuracy: 89.93%\n",
      "107\tValidation loss: 0.614250\tBest loss: 0.614250\tAccuracy: 89.93%\n",
      "108\tValidation loss: 0.614172\tBest loss: 0.614172\tAccuracy: 89.93%\n",
      "109\tValidation loss: 0.613262\tBest loss: 0.613262\tAccuracy: 89.93%\n",
      "110\tValidation loss: 0.613120\tBest loss: 0.613120\tAccuracy: 89.93%\n",
      "111\tValidation loss: 0.612788\tBest loss: 0.612788\tAccuracy: 89.93%\n",
      "112\tValidation loss: 0.612007\tBest loss: 0.612007\tAccuracy: 89.93%\n",
      "113\tValidation loss: 0.611687\tBest loss: 0.611687\tAccuracy: 89.93%\n",
      "114\tValidation loss: 0.611658\tBest loss: 0.611658\tAccuracy: 89.93%\n",
      "115\tValidation loss: 0.611339\tBest loss: 0.611339\tAccuracy: 89.93%\n",
      "116\tValidation loss: 0.611197\tBest loss: 0.611197\tAccuracy: 89.93%\n",
      "117\tValidation loss: 0.610913\tBest loss: 0.610913\tAccuracy: 89.93%\n",
      "118\tValidation loss: 0.610630\tBest loss: 0.610630\tAccuracy: 89.93%\n",
      "119\tValidation loss: 0.610286\tBest loss: 0.610286\tAccuracy: 89.93%\n",
      "120\tValidation loss: 0.610013\tBest loss: 0.610013\tAccuracy: 89.93%\n",
      "121\tValidation loss: 0.609743\tBest loss: 0.609743\tAccuracy: 89.93%\n",
      "122\tValidation loss: 0.609479\tBest loss: 0.609479\tAccuracy: 89.93%\n",
      "123\tValidation loss: 0.608610\tBest loss: 0.608610\tAccuracy: 89.93%\n",
      "124\tValidation loss: 0.608396\tBest loss: 0.608396\tAccuracy: 89.93%\n",
      "125\tValidation loss: 0.607958\tBest loss: 0.607958\tAccuracy: 89.93%\n",
      "126\tValidation loss: 0.607742\tBest loss: 0.607742\tAccuracy: 89.93%\n",
      "127\tValidation loss: 0.607271\tBest loss: 0.607271\tAccuracy: 89.93%\n",
      "128\tValidation loss: 0.606578\tBest loss: 0.606578\tAccuracy: 89.93%\n",
      "129\tValidation loss: 0.606401\tBest loss: 0.606401\tAccuracy: 89.93%\n",
      "130\tValidation loss: 0.606119\tBest loss: 0.606119\tAccuracy: 89.93%\n",
      "131\tValidation loss: 0.605415\tBest loss: 0.605415\tAccuracy: 89.93%\n",
      "132\tValidation loss: 0.605177\tBest loss: 0.605177\tAccuracy: 89.93%\n",
      "133\tValidation loss: 0.604609\tBest loss: 0.604609\tAccuracy: 89.93%\n",
      "134\tValidation loss: 0.604444\tBest loss: 0.604444\tAccuracy: 89.93%\n",
      "135\tValidation loss: 0.603865\tBest loss: 0.603865\tAccuracy: 89.93%\n",
      "136\tValidation loss: 0.603794\tBest loss: 0.603794\tAccuracy: 89.93%\n",
      "137\tValidation loss: 0.603529\tBest loss: 0.603529\tAccuracy: 89.93%\n",
      "138\tValidation loss: 0.603274\tBest loss: 0.603274\tAccuracy: 89.93%\n",
      "139\tValidation loss: 0.603027\tBest loss: 0.603027\tAccuracy: 89.93%\n",
      "140\tValidation loss: 0.602435\tBest loss: 0.602435\tAccuracy: 89.93%\n",
      "141\tValidation loss: 0.601821\tBest loss: 0.601821\tAccuracy: 89.93%\n",
      "142\tValidation loss: 0.601513\tBest loss: 0.601513\tAccuracy: 89.93%\n",
      "143\tValidation loss: 0.601489\tBest loss: 0.601489\tAccuracy: 89.93%\n",
      "144\tValidation loss: 0.601027\tBest loss: 0.601027\tAccuracy: 89.93%\n",
      "145\tValidation loss: 0.600464\tBest loss: 0.600464\tAccuracy: 89.93%\n",
      "146\tValidation loss: 0.600018\tBest loss: 0.600018\tAccuracy: 89.93%\n",
      "147\tValidation loss: 0.600006\tBest loss: 0.600006\tAccuracy: 89.93%\n",
      "148\tValidation loss: 0.599841\tBest loss: 0.599841\tAccuracy: 89.93%\n",
      "149\tValidation loss: 0.599676\tBest loss: 0.599676\tAccuracy: 89.93%\n",
      "150\tValidation loss: 0.599396\tBest loss: 0.599396\tAccuracy: 89.93%\n",
      "151\tValidation loss: 0.598954\tBest loss: 0.598954\tAccuracy: 89.93%\n",
      "152\tValidation loss: 0.598945\tBest loss: 0.598945\tAccuracy: 89.93%\n",
      "153\tValidation loss: 0.598506\tBest loss: 0.598506\tAccuracy: 89.93%\n",
      "154\tValidation loss: 0.598089\tBest loss: 0.598089\tAccuracy: 89.93%\n",
      "155\tValidation loss: 0.597846\tBest loss: 0.597846\tAccuracy: 89.93%\n",
      "156\tValidation loss: 0.597721\tBest loss: 0.597721\tAccuracy: 89.93%\n",
      "157\tValidation loss: 0.597263\tBest loss: 0.597263\tAccuracy: 89.93%\n",
      "158\tValidation loss: 0.597145\tBest loss: 0.597145\tAccuracy: 89.93%\n",
      "159\tValidation loss: 0.596665\tBest loss: 0.596665\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\tValidation loss: 0.596602\tBest loss: 0.596602\tAccuracy: 89.93%\n",
      "161\tValidation loss: 0.596416\tBest loss: 0.596416\tAccuracy: 89.93%\n",
      "162\tValidation loss: 0.595981\tBest loss: 0.595981\tAccuracy: 89.93%\n",
      "163\tValidation loss: 0.595611\tBest loss: 0.595611\tAccuracy: 89.93%\n",
      "164\tValidation loss: 0.595295\tBest loss: 0.595295\tAccuracy: 89.93%\n",
      "165\tValidation loss: 0.595255\tBest loss: 0.595255\tAccuracy: 89.93%\n",
      "166\tValidation loss: 0.595143\tBest loss: 0.595143\tAccuracy: 89.93%\n",
      "167\tValidation loss: 0.594999\tBest loss: 0.594999\tAccuracy: 89.93%\n",
      "168\tValidation loss: 0.594844\tBest loss: 0.594844\tAccuracy: 89.93%\n",
      "169\tValidation loss: 0.594364\tBest loss: 0.594364\tAccuracy: 89.93%\n",
      "170\tValidation loss: 0.594206\tBest loss: 0.594206\tAccuracy: 89.93%\n",
      "171\tValidation loss: 0.594150\tBest loss: 0.594150\tAccuracy: 89.93%\n",
      "172\tValidation loss: 0.593864\tBest loss: 0.593864\tAccuracy: 89.93%\n",
      "173\tValidation loss: 0.593690\tBest loss: 0.593690\tAccuracy: 89.93%\n",
      "174\tValidation loss: 0.593481\tBest loss: 0.593481\tAccuracy: 89.93%\n",
      "175\tValidation loss: 0.593328\tBest loss: 0.593328\tAccuracy: 89.93%\n",
      "176\tValidation loss: 0.593089\tBest loss: 0.593089\tAccuracy: 89.93%\n",
      "177\tValidation loss: 0.592672\tBest loss: 0.592672\tAccuracy: 89.93%\n",
      "178\tValidation loss: 0.592446\tBest loss: 0.592446\tAccuracy: 89.93%\n",
      "179\tValidation loss: 0.592285\tBest loss: 0.592285\tAccuracy: 89.93%\n",
      "180\tValidation loss: 0.591943\tBest loss: 0.591943\tAccuracy: 89.93%\n",
      "181\tValidation loss: 0.591837\tBest loss: 0.591837\tAccuracy: 89.93%\n",
      "182\tValidation loss: 0.591639\tBest loss: 0.591639\tAccuracy: 89.93%\n",
      "183\tValidation loss: 0.591265\tBest loss: 0.591265\tAccuracy: 89.93%\n",
      "184\tValidation loss: 0.591077\tBest loss: 0.591077\tAccuracy: 89.93%\n",
      "185\tValidation loss: 0.590940\tBest loss: 0.590940\tAccuracy: 89.93%\n",
      "186\tValidation loss: 0.590575\tBest loss: 0.590575\tAccuracy: 89.93%\n",
      "187\tValidation loss: 0.590377\tBest loss: 0.590377\tAccuracy: 89.93%\n",
      "188\tValidation loss: 0.589988\tBest loss: 0.589988\tAccuracy: 89.93%\n",
      "189\tValidation loss: 0.589900\tBest loss: 0.589900\tAccuracy: 89.93%\n",
      "190\tValidation loss: 0.589701\tBest loss: 0.589701\tAccuracy: 89.93%\n",
      "191\tValidation loss: 0.589463\tBest loss: 0.589463\tAccuracy: 89.93%\n",
      "192\tValidation loss: 0.589331\tBest loss: 0.589331\tAccuracy: 89.93%\n",
      "193\tValidation loss: 0.589034\tBest loss: 0.589034\tAccuracy: 89.93%\n",
      "194\tValidation loss: 0.588860\tBest loss: 0.588860\tAccuracy: 89.93%\n",
      "195\tValidation loss: 0.588642\tBest loss: 0.588642\tAccuracy: 89.93%\n",
      "196\tValidation loss: 0.588467\tBest loss: 0.588467\tAccuracy: 89.93%\n",
      "197\tValidation loss: 0.588309\tBest loss: 0.588309\tAccuracy: 89.93%\n",
      "198\tValidation loss: 0.588125\tBest loss: 0.588125\tAccuracy: 89.93%\n",
      "199\tValidation loss: 0.587951\tBest loss: 0.587951\tAccuracy: 89.93%\n",
      "200\tValidation loss: 0.587809\tBest loss: 0.587809\tAccuracy: 89.93%\n",
      "201\tValidation loss: 0.587473\tBest loss: 0.587473\tAccuracy: 89.93%\n",
      "202\tValidation loss: 0.587130\tBest loss: 0.587130\tAccuracy: 89.93%\n",
      "203\tValidation loss: 0.587038\tBest loss: 0.587038\tAccuracy: 89.93%\n",
      "204\tValidation loss: 0.586868\tBest loss: 0.586868\tAccuracy: 89.93%\n",
      "205\tValidation loss: 0.586556\tBest loss: 0.586556\tAccuracy: 89.93%\n",
      "206\tValidation loss: 0.586297\tBest loss: 0.586297\tAccuracy: 89.93%\n",
      "207\tValidation loss: 0.585958\tBest loss: 0.585958\tAccuracy: 89.93%\n",
      "208\tValidation loss: 0.585671\tBest loss: 0.585671\tAccuracy: 89.93%\n",
      "209\tValidation loss: 0.585562\tBest loss: 0.585562\tAccuracy: 89.93%\n",
      "210\tValidation loss: 0.585353\tBest loss: 0.585353\tAccuracy: 89.93%\n",
      "211\tValidation loss: 0.585219\tBest loss: 0.585219\tAccuracy: 89.93%\n",
      "212\tValidation loss: 0.585101\tBest loss: 0.585101\tAccuracy: 89.93%\n",
      "213\tValidation loss: 0.584935\tBest loss: 0.584935\tAccuracy: 89.93%\n",
      "214\tValidation loss: 0.584804\tBest loss: 0.584804\tAccuracy: 89.93%\n",
      "215\tValidation loss: 0.584586\tBest loss: 0.584586\tAccuracy: 89.93%\n",
      "216\tValidation loss: 0.584337\tBest loss: 0.584337\tAccuracy: 89.93%\n",
      "217\tValidation loss: 0.584090\tBest loss: 0.584090\tAccuracy: 89.93%\n",
      "218\tValidation loss: 0.583845\tBest loss: 0.583845\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.583786\tBest loss: 0.583786\tAccuracy: 89.93%\n",
      "220\tValidation loss: 0.583715\tBest loss: 0.583715\tAccuracy: 89.93%\n",
      "221\tValidation loss: 0.583585\tBest loss: 0.583585\tAccuracy: 89.93%\n",
      "222\tValidation loss: 0.583296\tBest loss: 0.583296\tAccuracy: 90.65%\n",
      "223\tValidation loss: 0.583078\tBest loss: 0.583078\tAccuracy: 90.65%\n",
      "224\tValidation loss: 0.582832\tBest loss: 0.582832\tAccuracy: 90.65%\n",
      "225\tValidation loss: 0.582725\tBest loss: 0.582725\tAccuracy: 90.65%\n",
      "226\tValidation loss: 0.582494\tBest loss: 0.582494\tAccuracy: 90.65%\n",
      "227\tValidation loss: 0.582325\tBest loss: 0.582325\tAccuracy: 90.65%\n",
      "228\tValidation loss: 0.582230\tBest loss: 0.582230\tAccuracy: 90.65%\n",
      "229\tValidation loss: 0.582000\tBest loss: 0.582000\tAccuracy: 90.65%\n",
      "230\tValidation loss: 0.581894\tBest loss: 0.581894\tAccuracy: 90.65%\n",
      "231\tValidation loss: 0.581772\tBest loss: 0.581772\tAccuracy: 90.65%\n",
      "232\tValidation loss: 0.581584\tBest loss: 0.581584\tAccuracy: 90.65%\n",
      "233\tValidation loss: 0.581508\tBest loss: 0.581508\tAccuracy: 90.65%\n",
      "234\tValidation loss: 0.581384\tBest loss: 0.581384\tAccuracy: 90.65%\n",
      "235\tValidation loss: 0.581258\tBest loss: 0.581258\tAccuracy: 90.65%\n",
      "236\tValidation loss: 0.581160\tBest loss: 0.581160\tAccuracy: 90.65%\n",
      "237\tValidation loss: 0.580963\tBest loss: 0.580963\tAccuracy: 90.65%\n",
      "238\tValidation loss: 0.580727\tBest loss: 0.580727\tAccuracy: 90.65%\n",
      "239\tValidation loss: 0.580601\tBest loss: 0.580601\tAccuracy: 90.65%\n",
      "240\tValidation loss: 0.580359\tBest loss: 0.580359\tAccuracy: 90.65%\n",
      "241\tValidation loss: 0.580216\tBest loss: 0.580216\tAccuracy: 90.65%\n",
      "242\tValidation loss: 0.580029\tBest loss: 0.580029\tAccuracy: 90.65%\n",
      "243\tValidation loss: 0.579885\tBest loss: 0.579885\tAccuracy: 90.65%\n",
      "244\tValidation loss: 0.579733\tBest loss: 0.579733\tAccuracy: 90.65%\n",
      "245\tValidation loss: 0.579620\tBest loss: 0.579620\tAccuracy: 90.65%\n",
      "246\tValidation loss: 0.579474\tBest loss: 0.579474\tAccuracy: 90.65%\n",
      "247\tValidation loss: 0.579404\tBest loss: 0.579404\tAccuracy: 90.65%\n",
      "248\tValidation loss: 0.579257\tBest loss: 0.579257\tAccuracy: 90.65%\n",
      "249\tValidation loss: 0.579072\tBest loss: 0.579072\tAccuracy: 90.65%\n",
      "250\tValidation loss: 0.578951\tBest loss: 0.578951\tAccuracy: 90.65%\n",
      "251\tValidation loss: 0.578734\tBest loss: 0.578734\tAccuracy: 90.65%\n",
      "252\tValidation loss: 0.578532\tBest loss: 0.578532\tAccuracy: 90.65%\n",
      "253\tValidation loss: 0.578308\tBest loss: 0.578308\tAccuracy: 90.65%\n",
      "254\tValidation loss: 0.578213\tBest loss: 0.578213\tAccuracy: 90.65%\n",
      "255\tValidation loss: 0.578045\tBest loss: 0.578045\tAccuracy: 90.65%\n",
      "256\tValidation loss: 0.577952\tBest loss: 0.577952\tAccuracy: 90.65%\n",
      "257\tValidation loss: 0.577888\tBest loss: 0.577888\tAccuracy: 90.65%\n",
      "258\tValidation loss: 0.577798\tBest loss: 0.577798\tAccuracy: 90.65%\n",
      "259\tValidation loss: 0.577601\tBest loss: 0.577601\tAccuracy: 90.65%\n",
      "260\tValidation loss: 0.577421\tBest loss: 0.577421\tAccuracy: 90.65%\n",
      "261\tValidation loss: 0.577245\tBest loss: 0.577245\tAccuracy: 90.65%\n",
      "262\tValidation loss: 0.577159\tBest loss: 0.577159\tAccuracy: 90.65%\n",
      "263\tValidation loss: 0.576970\tBest loss: 0.576970\tAccuracy: 90.65%\n",
      "264\tValidation loss: 0.576824\tBest loss: 0.576824\tAccuracy: 90.65%\n",
      "265\tValidation loss: 0.576626\tBest loss: 0.576626\tAccuracy: 90.65%\n",
      "266\tValidation loss: 0.576492\tBest loss: 0.576492\tAccuracy: 90.65%\n",
      "267\tValidation loss: 0.576318\tBest loss: 0.576318\tAccuracy: 90.65%\n",
      "268\tValidation loss: 0.576160\tBest loss: 0.576160\tAccuracy: 90.65%\n",
      "269\tValidation loss: 0.576081\tBest loss: 0.576081\tAccuracy: 90.65%\n",
      "270\tValidation loss: 0.575927\tBest loss: 0.575927\tAccuracy: 90.65%\n",
      "271\tValidation loss: 0.575823\tBest loss: 0.575823\tAccuracy: 90.65%\n",
      "272\tValidation loss: 0.575750\tBest loss: 0.575750\tAccuracy: 90.65%\n",
      "273\tValidation loss: 0.575599\tBest loss: 0.575599\tAccuracy: 90.65%\n",
      "274\tValidation loss: 0.575526\tBest loss: 0.575526\tAccuracy: 90.65%\n",
      "275\tValidation loss: 0.575428\tBest loss: 0.575428\tAccuracy: 90.65%\n",
      "276\tValidation loss: 0.575261\tBest loss: 0.575261\tAccuracy: 90.65%\n",
      "277\tValidation loss: 0.575091\tBest loss: 0.575091\tAccuracy: 90.65%\n",
      "278\tValidation loss: 0.574928\tBest loss: 0.574928\tAccuracy: 90.65%\n",
      "279\tValidation loss: 0.574822\tBest loss: 0.574822\tAccuracy: 90.65%\n",
      "280\tValidation loss: 0.574662\tBest loss: 0.574662\tAccuracy: 90.65%\n",
      "281\tValidation loss: 0.574623\tBest loss: 0.574623\tAccuracy: 90.65%\n",
      "282\tValidation loss: 0.574544\tBest loss: 0.574544\tAccuracy: 90.65%\n",
      "283\tValidation loss: 0.574404\tBest loss: 0.574404\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\tValidation loss: 0.574361\tBest loss: 0.574361\tAccuracy: 90.65%\n",
      "285\tValidation loss: 0.574303\tBest loss: 0.574303\tAccuracy: 90.65%\n",
      "286\tValidation loss: 0.574199\tBest loss: 0.574199\tAccuracy: 90.65%\n",
      "287\tValidation loss: 0.574069\tBest loss: 0.574069\tAccuracy: 90.65%\n",
      "288\tValidation loss: 0.574028\tBest loss: 0.574028\tAccuracy: 90.65%\n",
      "289\tValidation loss: 0.573951\tBest loss: 0.573951\tAccuracy: 90.65%\n",
      "290\tValidation loss: 0.573819\tBest loss: 0.573819\tAccuracy: 90.65%\n",
      "291\tValidation loss: 0.573745\tBest loss: 0.573745\tAccuracy: 90.65%\n",
      "292\tValidation loss: 0.573650\tBest loss: 0.573650\tAccuracy: 90.65%\n",
      "293\tValidation loss: 0.573508\tBest loss: 0.573508\tAccuracy: 90.65%\n",
      "294\tValidation loss: 0.573389\tBest loss: 0.573389\tAccuracy: 90.65%\n",
      "295\tValidation loss: 0.573305\tBest loss: 0.573305\tAccuracy: 90.65%\n",
      "296\tValidation loss: 0.573155\tBest loss: 0.573155\tAccuracy: 90.65%\n",
      "297\tValidation loss: 0.573106\tBest loss: 0.573106\tAccuracy: 90.65%\n",
      "298\tValidation loss: 0.573036\tBest loss: 0.573036\tAccuracy: 90.65%\n",
      "299\tValidation loss: 0.572984\tBest loss: 0.572984\tAccuracy: 90.65%\n",
      "300\tValidation loss: 0.572859\tBest loss: 0.572859\tAccuracy: 90.65%\n",
      "301\tValidation loss: 0.572783\tBest loss: 0.572783\tAccuracy: 90.65%\n",
      "302\tValidation loss: 0.572703\tBest loss: 0.572703\tAccuracy: 90.65%\n",
      "303\tValidation loss: 0.572579\tBest loss: 0.572579\tAccuracy: 90.65%\n",
      "304\tValidation loss: 0.572425\tBest loss: 0.572425\tAccuracy: 90.65%\n",
      "305\tValidation loss: 0.572350\tBest loss: 0.572350\tAccuracy: 90.65%\n",
      "306\tValidation loss: 0.572262\tBest loss: 0.572262\tAccuracy: 90.65%\n",
      "307\tValidation loss: 0.572139\tBest loss: 0.572139\tAccuracy: 90.65%\n",
      "308\tValidation loss: 0.572064\tBest loss: 0.572064\tAccuracy: 90.65%\n",
      "309\tValidation loss: 0.572015\tBest loss: 0.572015\tAccuracy: 90.65%\n",
      "310\tValidation loss: 0.571925\tBest loss: 0.571925\tAccuracy: 90.65%\n",
      "311\tValidation loss: 0.571829\tBest loss: 0.571829\tAccuracy: 90.65%\n",
      "312\tValidation loss: 0.571687\tBest loss: 0.571687\tAccuracy: 90.65%\n",
      "313\tValidation loss: 0.571625\tBest loss: 0.571625\tAccuracy: 90.65%\n",
      "314\tValidation loss: 0.571489\tBest loss: 0.571489\tAccuracy: 90.65%\n",
      "315\tValidation loss: 0.571418\tBest loss: 0.571418\tAccuracy: 90.65%\n",
      "316\tValidation loss: 0.571335\tBest loss: 0.571335\tAccuracy: 90.65%\n",
      "317\tValidation loss: 0.571262\tBest loss: 0.571262\tAccuracy: 90.65%\n",
      "318\tValidation loss: 0.571134\tBest loss: 0.571134\tAccuracy: 90.65%\n",
      "319\tValidation loss: 0.571027\tBest loss: 0.571027\tAccuracy: 90.65%\n",
      "320\tValidation loss: 0.570953\tBest loss: 0.570953\tAccuracy: 90.65%\n",
      "321\tValidation loss: 0.570873\tBest loss: 0.570873\tAccuracy: 90.65%\n",
      "322\tValidation loss: 0.570806\tBest loss: 0.570806\tAccuracy: 90.65%\n",
      "323\tValidation loss: 0.570743\tBest loss: 0.570743\tAccuracy: 90.65%\n",
      "324\tValidation loss: 0.570629\tBest loss: 0.570629\tAccuracy: 90.65%\n",
      "325\tValidation loss: 0.570504\tBest loss: 0.570504\tAccuracy: 90.65%\n",
      "326\tValidation loss: 0.570412\tBest loss: 0.570412\tAccuracy: 90.65%\n",
      "327\tValidation loss: 0.570375\tBest loss: 0.570375\tAccuracy: 90.65%\n",
      "328\tValidation loss: 0.570298\tBest loss: 0.570298\tAccuracy: 90.65%\n",
      "329\tValidation loss: 0.570241\tBest loss: 0.570241\tAccuracy: 90.65%\n",
      "330\tValidation loss: 0.570188\tBest loss: 0.570188\tAccuracy: 90.65%\n",
      "331\tValidation loss: 0.570130\tBest loss: 0.570130\tAccuracy: 90.65%\n",
      "332\tValidation loss: 0.570052\tBest loss: 0.570052\tAccuracy: 90.65%\n",
      "333\tValidation loss: 0.570006\tBest loss: 0.570006\tAccuracy: 90.65%\n",
      "334\tValidation loss: 0.569952\tBest loss: 0.569952\tAccuracy: 90.65%\n",
      "335\tValidation loss: 0.569828\tBest loss: 0.569828\tAccuracy: 90.65%\n",
      "336\tValidation loss: 0.569774\tBest loss: 0.569774\tAccuracy: 90.65%\n",
      "337\tValidation loss: 0.569691\tBest loss: 0.569691\tAccuracy: 90.65%\n",
      "338\tValidation loss: 0.569604\tBest loss: 0.569604\tAccuracy: 90.65%\n",
      "339\tValidation loss: 0.569546\tBest loss: 0.569546\tAccuracy: 90.65%\n",
      "340\tValidation loss: 0.569446\tBest loss: 0.569446\tAccuracy: 90.65%\n",
      "341\tValidation loss: 0.569392\tBest loss: 0.569392\tAccuracy: 90.65%\n",
      "342\tValidation loss: 0.569336\tBest loss: 0.569336\tAccuracy: 90.65%\n",
      "343\tValidation loss: 0.569270\tBest loss: 0.569270\tAccuracy: 90.65%\n",
      "344\tValidation loss: 0.569222\tBest loss: 0.569222\tAccuracy: 90.65%\n",
      "345\tValidation loss: 0.569129\tBest loss: 0.569129\tAccuracy: 90.65%\n",
      "346\tValidation loss: 0.569043\tBest loss: 0.569043\tAccuracy: 90.65%\n",
      "347\tValidation loss: 0.568999\tBest loss: 0.568999\tAccuracy: 90.65%\n",
      "348\tValidation loss: 0.568946\tBest loss: 0.568946\tAccuracy: 90.65%\n",
      "349\tValidation loss: 0.568862\tBest loss: 0.568862\tAccuracy: 90.65%\n",
      "350\tValidation loss: 0.568809\tBest loss: 0.568809\tAccuracy: 90.65%\n",
      "351\tValidation loss: 0.568781\tBest loss: 0.568781\tAccuracy: 90.65%\n",
      "352\tValidation loss: 0.568703\tBest loss: 0.568703\tAccuracy: 90.65%\n",
      "353\tValidation loss: 0.568672\tBest loss: 0.568672\tAccuracy: 90.65%\n",
      "354\tValidation loss: 0.568631\tBest loss: 0.568631\tAccuracy: 90.65%\n",
      "355\tValidation loss: 0.568553\tBest loss: 0.568553\tAccuracy: 90.65%\n",
      "356\tValidation loss: 0.568528\tBest loss: 0.568528\tAccuracy: 90.65%\n",
      "357\tValidation loss: 0.568448\tBest loss: 0.568448\tAccuracy: 90.65%\n",
      "358\tValidation loss: 0.568391\tBest loss: 0.568391\tAccuracy: 90.65%\n",
      "359\tValidation loss: 0.568329\tBest loss: 0.568329\tAccuracy: 90.65%\n",
      "360\tValidation loss: 0.568268\tBest loss: 0.568268\tAccuracy: 90.65%\n",
      "361\tValidation loss: 0.568223\tBest loss: 0.568223\tAccuracy: 90.65%\n",
      "362\tValidation loss: 0.568178\tBest loss: 0.568178\tAccuracy: 90.65%\n",
      "363\tValidation loss: 0.568134\tBest loss: 0.568134\tAccuracy: 90.65%\n",
      "364\tValidation loss: 0.568101\tBest loss: 0.568101\tAccuracy: 90.65%\n",
      "365\tValidation loss: 0.568059\tBest loss: 0.568059\tAccuracy: 90.65%\n",
      "366\tValidation loss: 0.568017\tBest loss: 0.568017\tAccuracy: 90.65%\n",
      "367\tValidation loss: 0.567949\tBest loss: 0.567949\tAccuracy: 90.65%\n",
      "368\tValidation loss: 0.567907\tBest loss: 0.567907\tAccuracy: 90.65%\n",
      "369\tValidation loss: 0.567857\tBest loss: 0.567857\tAccuracy: 90.65%\n",
      "370\tValidation loss: 0.567823\tBest loss: 0.567823\tAccuracy: 90.65%\n",
      "371\tValidation loss: 0.567787\tBest loss: 0.567787\tAccuracy: 90.65%\n",
      "372\tValidation loss: 0.567733\tBest loss: 0.567733\tAccuracy: 90.65%\n",
      "373\tValidation loss: 0.567685\tBest loss: 0.567685\tAccuracy: 90.65%\n",
      "374\tValidation loss: 0.567642\tBest loss: 0.567642\tAccuracy: 90.65%\n",
      "375\tValidation loss: 0.567575\tBest loss: 0.567575\tAccuracy: 90.65%\n",
      "376\tValidation loss: 0.567506\tBest loss: 0.567506\tAccuracy: 89.93%\n",
      "377\tValidation loss: 0.567444\tBest loss: 0.567444\tAccuracy: 90.65%\n",
      "378\tValidation loss: 0.567377\tBest loss: 0.567377\tAccuracy: 90.65%\n",
      "379\tValidation loss: 0.567360\tBest loss: 0.567360\tAccuracy: 90.65%\n",
      "380\tValidation loss: 0.567338\tBest loss: 0.567338\tAccuracy: 90.65%\n",
      "381\tValidation loss: 0.567301\tBest loss: 0.567301\tAccuracy: 90.65%\n",
      "382\tValidation loss: 0.567242\tBest loss: 0.567242\tAccuracy: 90.65%\n",
      "383\tValidation loss: 0.567213\tBest loss: 0.567213\tAccuracy: 90.65%\n",
      "384\tValidation loss: 0.567152\tBest loss: 0.567152\tAccuracy: 90.65%\n",
      "385\tValidation loss: 0.567110\tBest loss: 0.567110\tAccuracy: 90.65%\n",
      "386\tValidation loss: 0.567069\tBest loss: 0.567069\tAccuracy: 90.65%\n",
      "387\tValidation loss: 0.567010\tBest loss: 0.567010\tAccuracy: 90.65%\n",
      "388\tValidation loss: 0.566972\tBest loss: 0.566972\tAccuracy: 90.65%\n",
      "389\tValidation loss: 0.566945\tBest loss: 0.566945\tAccuracy: 90.65%\n",
      "390\tValidation loss: 0.566889\tBest loss: 0.566889\tAccuracy: 90.65%\n",
      "391\tValidation loss: 0.566853\tBest loss: 0.566853\tAccuracy: 90.65%\n",
      "392\tValidation loss: 0.566818\tBest loss: 0.566818\tAccuracy: 90.65%\n",
      "393\tValidation loss: 0.566785\tBest loss: 0.566785\tAccuracy: 90.65%\n",
      "394\tValidation loss: 0.566761\tBest loss: 0.566761\tAccuracy: 90.65%\n",
      "395\tValidation loss: 0.566716\tBest loss: 0.566716\tAccuracy: 90.65%\n",
      "396\tValidation loss: 0.566687\tBest loss: 0.566687\tAccuracy: 90.65%\n",
      "397\tValidation loss: 0.566650\tBest loss: 0.566650\tAccuracy: 90.65%\n",
      "398\tValidation loss: 0.566625\tBest loss: 0.566625\tAccuracy: 90.65%\n",
      "399\tValidation loss: 0.566601\tBest loss: 0.566601\tAccuracy: 90.65%\n",
      "400\tValidation loss: 0.566552\tBest loss: 0.566552\tAccuracy: 90.65%\n",
      "401\tValidation loss: 0.566519\tBest loss: 0.566519\tAccuracy: 90.65%\n",
      "402\tValidation loss: 0.566505\tBest loss: 0.566505\tAccuracy: 90.65%\n",
      "403\tValidation loss: 0.566489\tBest loss: 0.566489\tAccuracy: 90.65%\n",
      "404\tValidation loss: 0.566461\tBest loss: 0.566461\tAccuracy: 90.65%\n",
      "405\tValidation loss: 0.566421\tBest loss: 0.566421\tAccuracy: 90.65%\n",
      "406\tValidation loss: 0.566387\tBest loss: 0.566387\tAccuracy: 90.65%\n",
      "407\tValidation loss: 0.566365\tBest loss: 0.566365\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\tValidation loss: 0.566322\tBest loss: 0.566322\tAccuracy: 90.65%\n",
      "409\tValidation loss: 0.566292\tBest loss: 0.566292\tAccuracy: 90.65%\n",
      "410\tValidation loss: 0.566265\tBest loss: 0.566265\tAccuracy: 90.65%\n",
      "411\tValidation loss: 0.566255\tBest loss: 0.566255\tAccuracy: 90.65%\n",
      "412\tValidation loss: 0.566233\tBest loss: 0.566233\tAccuracy: 90.65%\n",
      "413\tValidation loss: 0.566210\tBest loss: 0.566210\tAccuracy: 90.65%\n",
      "414\tValidation loss: 0.566184\tBest loss: 0.566184\tAccuracy: 90.65%\n",
      "415\tValidation loss: 0.566136\tBest loss: 0.566136\tAccuracy: 90.65%\n",
      "416\tValidation loss: 0.566115\tBest loss: 0.566115\tAccuracy: 90.65%\n",
      "417\tValidation loss: 0.566106\tBest loss: 0.566106\tAccuracy: 90.65%\n",
      "418\tValidation loss: 0.566091\tBest loss: 0.566091\tAccuracy: 90.65%\n",
      "419\tValidation loss: 0.566044\tBest loss: 0.566044\tAccuracy: 90.65%\n",
      "420\tValidation loss: 0.566017\tBest loss: 0.566017\tAccuracy: 90.65%\n",
      "421\tValidation loss: 0.565988\tBest loss: 0.565988\tAccuracy: 90.65%\n",
      "422\tValidation loss: 0.565992\tBest loss: 0.565988\tAccuracy: 90.65%\n",
      "423\tValidation loss: 0.565979\tBest loss: 0.565979\tAccuracy: 90.65%\n",
      "424\tValidation loss: 0.565958\tBest loss: 0.565958\tAccuracy: 90.65%\n",
      "425\tValidation loss: 0.565926\tBest loss: 0.565926\tAccuracy: 90.65%\n",
      "426\tValidation loss: 0.565897\tBest loss: 0.565897\tAccuracy: 90.65%\n",
      "427\tValidation loss: 0.565877\tBest loss: 0.565877\tAccuracy: 90.65%\n",
      "428\tValidation loss: 0.565847\tBest loss: 0.565847\tAccuracy: 90.65%\n",
      "429\tValidation loss: 0.565823\tBest loss: 0.565823\tAccuracy: 90.65%\n",
      "430\tValidation loss: 0.565796\tBest loss: 0.565796\tAccuracy: 90.65%\n",
      "431\tValidation loss: 0.565773\tBest loss: 0.565773\tAccuracy: 90.65%\n",
      "432\tValidation loss: 0.565766\tBest loss: 0.565766\tAccuracy: 90.65%\n",
      "433\tValidation loss: 0.565757\tBest loss: 0.565757\tAccuracy: 90.65%\n",
      "434\tValidation loss: 0.565728\tBest loss: 0.565728\tAccuracy: 90.65%\n",
      "435\tValidation loss: 0.565691\tBest loss: 0.565691\tAccuracy: 90.65%\n",
      "436\tValidation loss: 0.565683\tBest loss: 0.565683\tAccuracy: 90.65%\n",
      "437\tValidation loss: 0.565660\tBest loss: 0.565660\tAccuracy: 90.65%\n",
      "438\tValidation loss: 0.565649\tBest loss: 0.565649\tAccuracy: 90.65%\n",
      "439\tValidation loss: 0.565648\tBest loss: 0.565648\tAccuracy: 90.65%\n",
      "440\tValidation loss: 0.565625\tBest loss: 0.565625\tAccuracy: 90.65%\n",
      "441\tValidation loss: 0.565626\tBest loss: 0.565625\tAccuracy: 90.65%\n",
      "442\tValidation loss: 0.565609\tBest loss: 0.565609\tAccuracy: 90.65%\n",
      "443\tValidation loss: 0.565582\tBest loss: 0.565582\tAccuracy: 90.65%\n",
      "444\tValidation loss: 0.565554\tBest loss: 0.565554\tAccuracy: 90.65%\n",
      "445\tValidation loss: 0.565535\tBest loss: 0.565535\tAccuracy: 90.65%\n",
      "446\tValidation loss: 0.565527\tBest loss: 0.565527\tAccuracy: 90.65%\n",
      "447\tValidation loss: 0.565532\tBest loss: 0.565527\tAccuracy: 90.65%\n",
      "448\tValidation loss: 0.565495\tBest loss: 0.565495\tAccuracy: 90.65%\n",
      "449\tValidation loss: 0.565481\tBest loss: 0.565481\tAccuracy: 90.65%\n",
      "450\tValidation loss: 0.565486\tBest loss: 0.565481\tAccuracy: 90.65%\n",
      "451\tValidation loss: 0.565470\tBest loss: 0.565470\tAccuracy: 90.65%\n",
      "452\tValidation loss: 0.565474\tBest loss: 0.565470\tAccuracy: 90.65%\n",
      "453\tValidation loss: 0.565439\tBest loss: 0.565439\tAccuracy: 90.65%\n",
      "454\tValidation loss: 0.565440\tBest loss: 0.565439\tAccuracy: 90.65%\n",
      "455\tValidation loss: 0.565433\tBest loss: 0.565433\tAccuracy: 90.65%\n",
      "456\tValidation loss: 0.565414\tBest loss: 0.565414\tAccuracy: 90.65%\n",
      "457\tValidation loss: 0.565402\tBest loss: 0.565402\tAccuracy: 90.65%\n",
      "458\tValidation loss: 0.565389\tBest loss: 0.565389\tAccuracy: 90.65%\n",
      "459\tValidation loss: 0.565383\tBest loss: 0.565383\tAccuracy: 90.65%\n",
      "460\tValidation loss: 0.565359\tBest loss: 0.565359\tAccuracy: 90.65%\n",
      "461\tValidation loss: 0.565355\tBest loss: 0.565355\tAccuracy: 90.65%\n",
      "462\tValidation loss: 0.565346\tBest loss: 0.565346\tAccuracy: 90.65%\n",
      "463\tValidation loss: 0.565337\tBest loss: 0.565337\tAccuracy: 90.65%\n",
      "464\tValidation loss: 0.565323\tBest loss: 0.565323\tAccuracy: 90.65%\n",
      "465\tValidation loss: 0.565313\tBest loss: 0.565313\tAccuracy: 90.65%\n",
      "466\tValidation loss: 0.565302\tBest loss: 0.565302\tAccuracy: 90.65%\n",
      "467\tValidation loss: 0.565284\tBest loss: 0.565284\tAccuracy: 90.65%\n",
      "468\tValidation loss: 0.565270\tBest loss: 0.565270\tAccuracy: 90.65%\n",
      "469\tValidation loss: 0.565257\tBest loss: 0.565257\tAccuracy: 90.65%\n",
      "470\tValidation loss: 0.565261\tBest loss: 0.565257\tAccuracy: 90.65%\n",
      "471\tValidation loss: 0.565271\tBest loss: 0.565257\tAccuracy: 90.65%\n",
      "472\tValidation loss: 0.565265\tBest loss: 0.565257\tAccuracy: 90.65%\n",
      "473\tValidation loss: 0.565265\tBest loss: 0.565257\tAccuracy: 90.65%\n",
      "474\tValidation loss: 0.565254\tBest loss: 0.565254\tAccuracy: 90.65%\n",
      "475\tValidation loss: 0.565252\tBest loss: 0.565252\tAccuracy: 90.65%\n",
      "476\tValidation loss: 0.565239\tBest loss: 0.565239\tAccuracy: 90.65%\n",
      "477\tValidation loss: 0.565229\tBest loss: 0.565229\tAccuracy: 90.65%\n",
      "478\tValidation loss: 0.565221\tBest loss: 0.565221\tAccuracy: 90.65%\n",
      "479\tValidation loss: 0.565209\tBest loss: 0.565209\tAccuracy: 90.65%\n",
      "480\tValidation loss: 0.565214\tBest loss: 0.565209\tAccuracy: 90.65%\n",
      "481\tValidation loss: 0.565201\tBest loss: 0.565201\tAccuracy: 90.65%\n",
      "482\tValidation loss: 0.565191\tBest loss: 0.565191\tAccuracy: 90.65%\n",
      "483\tValidation loss: 0.565181\tBest loss: 0.565181\tAccuracy: 90.65%\n",
      "484\tValidation loss: 0.565181\tBest loss: 0.565181\tAccuracy: 90.65%\n",
      "485\tValidation loss: 0.565168\tBest loss: 0.565168\tAccuracy: 90.65%\n",
      "486\tValidation loss: 0.565145\tBest loss: 0.565145\tAccuracy: 90.65%\n",
      "487\tValidation loss: 0.565148\tBest loss: 0.565145\tAccuracy: 90.65%\n",
      "488\tValidation loss: 0.565139\tBest loss: 0.565139\tAccuracy: 90.65%\n",
      "489\tValidation loss: 0.565150\tBest loss: 0.565139\tAccuracy: 90.65%\n",
      "490\tValidation loss: 0.565133\tBest loss: 0.565133\tAccuracy: 90.65%\n",
      "491\tValidation loss: 0.565120\tBest loss: 0.565120\tAccuracy: 90.65%\n",
      "492\tValidation loss: 0.565106\tBest loss: 0.565106\tAccuracy: 90.65%\n",
      "493\tValidation loss: 0.565105\tBest loss: 0.565105\tAccuracy: 90.65%\n",
      "494\tValidation loss: 0.565098\tBest loss: 0.565098\tAccuracy: 90.65%\n",
      "495\tValidation loss: 0.565095\tBest loss: 0.565095\tAccuracy: 90.65%\n",
      "496\tValidation loss: 0.565100\tBest loss: 0.565095\tAccuracy: 90.65%\n",
      "497\tValidation loss: 0.565097\tBest loss: 0.565095\tAccuracy: 90.65%\n",
      "498\tValidation loss: 0.565089\tBest loss: 0.565089\tAccuracy: 90.65%\n",
      "499\tValidation loss: 0.565081\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "500\tValidation loss: 0.565087\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "501\tValidation loss: 0.565085\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "502\tValidation loss: 0.565088\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "503\tValidation loss: 0.565087\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "504\tValidation loss: 0.565083\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "505\tValidation loss: 0.565096\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "506\tValidation loss: 0.565083\tBest loss: 0.565081\tAccuracy: 90.65%\n",
      "507\tValidation loss: 0.565069\tBest loss: 0.565069\tAccuracy: 90.65%\n",
      "508\tValidation loss: 0.565047\tBest loss: 0.565047\tAccuracy: 90.65%\n",
      "509\tValidation loss: 0.565032\tBest loss: 0.565032\tAccuracy: 90.65%\n",
      "510\tValidation loss: 0.565032\tBest loss: 0.565032\tAccuracy: 90.65%\n",
      "511\tValidation loss: 0.565030\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "512\tValidation loss: 0.565032\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "513\tValidation loss: 0.565035\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "514\tValidation loss: 0.565040\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "515\tValidation loss: 0.565052\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "516\tValidation loss: 0.565049\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "517\tValidation loss: 0.565059\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "518\tValidation loss: 0.565053\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "519\tValidation loss: 0.565039\tBest loss: 0.565030\tAccuracy: 90.65%\n",
      "520\tValidation loss: 0.565026\tBest loss: 0.565026\tAccuracy: 90.65%\n",
      "521\tValidation loss: 0.565024\tBest loss: 0.565024\tAccuracy: 90.65%\n",
      "522\tValidation loss: 0.565017\tBest loss: 0.565017\tAccuracy: 90.65%\n",
      "523\tValidation loss: 0.565015\tBest loss: 0.565015\tAccuracy: 90.65%\n",
      "524\tValidation loss: 0.565010\tBest loss: 0.565010\tAccuracy: 90.65%\n",
      "525\tValidation loss: 0.565011\tBest loss: 0.565010\tAccuracy: 90.65%\n",
      "526\tValidation loss: 0.565008\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "527\tValidation loss: 0.565016\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "528\tValidation loss: 0.565022\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "529\tValidation loss: 0.565024\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "530\tValidation loss: 0.565019\tBest loss: 0.565008\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531\tValidation loss: 0.565018\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "532\tValidation loss: 0.565016\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "533\tValidation loss: 0.565017\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "534\tValidation loss: 0.565027\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "535\tValidation loss: 0.565023\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "536\tValidation loss: 0.565033\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "537\tValidation loss: 0.565039\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "538\tValidation loss: 0.565027\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "539\tValidation loss: 0.565031\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "540\tValidation loss: 0.565023\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "541\tValidation loss: 0.565036\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "542\tValidation loss: 0.565038\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "543\tValidation loss: 0.565044\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "544\tValidation loss: 0.565037\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "545\tValidation loss: 0.565053\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "546\tValidation loss: 0.565058\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "547\tValidation loss: 0.565057\tBest loss: 0.565008\tAccuracy: 90.65%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total= 1.0min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 48.081127\tBest loss: 48.081127\tAccuracy: 46.76%\n",
      "1\tValidation loss: 2.120938\tBest loss: 2.120938\tAccuracy: 82.01%\n",
      "2\tValidation loss: 1.794505\tBest loss: 1.794505\tAccuracy: 83.45%\n",
      "3\tValidation loss: 1.120360\tBest loss: 1.120360\tAccuracy: 86.33%\n",
      "4\tValidation loss: 1.080191\tBest loss: 1.080191\tAccuracy: 85.61%\n",
      "5\tValidation loss: 0.908994\tBest loss: 0.908994\tAccuracy: 87.05%\n",
      "6\tValidation loss: 0.865980\tBest loss: 0.865980\tAccuracy: 89.93%\n",
      "7\tValidation loss: 0.884099\tBest loss: 0.865980\tAccuracy: 90.65%\n",
      "8\tValidation loss: 0.855361\tBest loss: 0.855361\tAccuracy: 91.37%\n",
      "9\tValidation loss: 0.849828\tBest loss: 0.849828\tAccuracy: 91.37%\n",
      "10\tValidation loss: 0.853313\tBest loss: 0.849828\tAccuracy: 91.37%\n",
      "11\tValidation loss: 0.850081\tBest loss: 0.849828\tAccuracy: 91.37%\n",
      "12\tValidation loss: 0.846259\tBest loss: 0.846259\tAccuracy: 91.37%\n",
      "13\tValidation loss: 0.850669\tBest loss: 0.846259\tAccuracy: 90.65%\n",
      "14\tValidation loss: 0.847284\tBest loss: 0.846259\tAccuracy: 89.93%\n",
      "15\tValidation loss: 0.848881\tBest loss: 0.846259\tAccuracy: 91.37%\n",
      "16\tValidation loss: 0.847770\tBest loss: 0.846259\tAccuracy: 91.37%\n",
      "17\tValidation loss: 0.844991\tBest loss: 0.844991\tAccuracy: 91.37%\n",
      "18\tValidation loss: 0.845020\tBest loss: 0.844991\tAccuracy: 91.37%\n",
      "19\tValidation loss: 0.840385\tBest loss: 0.840385\tAccuracy: 91.37%\n",
      "20\tValidation loss: 0.840136\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "21\tValidation loss: 0.840436\tBest loss: 0.840136\tAccuracy: 91.37%\n",
      "22\tValidation loss: 0.841871\tBest loss: 0.840136\tAccuracy: 91.37%\n",
      "23\tValidation loss: 0.843165\tBest loss: 0.840136\tAccuracy: 91.37%\n",
      "24\tValidation loss: 0.840662\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "25\tValidation loss: 0.841443\tBest loss: 0.840136\tAccuracy: 91.37%\n",
      "26\tValidation loss: 0.842230\tBest loss: 0.840136\tAccuracy: 91.37%\n",
      "27\tValidation loss: 0.840195\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "28\tValidation loss: 0.841367\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "29\tValidation loss: 0.840778\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "30\tValidation loss: 0.841075\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "31\tValidation loss: 0.840941\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "32\tValidation loss: 0.842459\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "33\tValidation loss: 0.841447\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "34\tValidation loss: 0.842813\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "35\tValidation loss: 0.842677\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "36\tValidation loss: 0.843427\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "37\tValidation loss: 0.844256\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "38\tValidation loss: 0.844788\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "39\tValidation loss: 0.844419\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "40\tValidation loss: 0.845415\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "41\tValidation loss: 0.845050\tBest loss: 0.840136\tAccuracy: 90.65%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=1000, n_hidden_layers=0, learning_rate=0.05, dropout_rate=0.2, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 264.603333\tBest loss: 264.603333\tAccuracy: 22.30%\n",
      "1\tValidation loss: 5.926252\tBest loss: 5.926252\tAccuracy: 84.89%\n",
      "2\tValidation loss: 3.124822\tBest loss: 3.124822\tAccuracy: 87.77%\n",
      "3\tValidation loss: 2.803972\tBest loss: 2.803972\tAccuracy: 85.61%\n",
      "4\tValidation loss: 2.245968\tBest loss: 2.245968\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.679658\tBest loss: 1.679658\tAccuracy: 91.37%\n",
      "6\tValidation loss: 1.902546\tBest loss: 1.679658\tAccuracy: 91.37%\n",
      "7\tValidation loss: 1.611009\tBest loss: 1.611009\tAccuracy: 90.65%\n",
      "8\tValidation loss: 1.572931\tBest loss: 1.572931\tAccuracy: 90.65%\n",
      "9\tValidation loss: 1.517227\tBest loss: 1.517227\tAccuracy: 92.09%\n",
      "10\tValidation loss: 1.583045\tBest loss: 1.517227\tAccuracy: 90.65%\n",
      "11\tValidation loss: 1.424120\tBest loss: 1.424120\tAccuracy: 89.93%\n",
      "12\tValidation loss: 1.406148\tBest loss: 1.406148\tAccuracy: 90.65%\n",
      "13\tValidation loss: 1.423060\tBest loss: 1.406148\tAccuracy: 89.93%\n",
      "14\tValidation loss: 1.445314\tBest loss: 1.406148\tAccuracy: 89.93%\n",
      "15\tValidation loss: 1.286324\tBest loss: 1.286324\tAccuracy: 90.65%\n",
      "16\tValidation loss: 1.269431\tBest loss: 1.269431\tAccuracy: 90.65%\n",
      "17\tValidation loss: 1.251448\tBest loss: 1.251448\tAccuracy: 90.65%\n",
      "18\tValidation loss: 1.233849\tBest loss: 1.233849\tAccuracy: 90.65%\n",
      "19\tValidation loss: 1.220318\tBest loss: 1.220318\tAccuracy: 90.65%\n",
      "20\tValidation loss: 1.211115\tBest loss: 1.211115\tAccuracy: 89.93%\n",
      "21\tValidation loss: 1.196882\tBest loss: 1.196882\tAccuracy: 90.65%\n",
      "22\tValidation loss: 1.191995\tBest loss: 1.191995\tAccuracy: 89.93%\n",
      "23\tValidation loss: 1.192252\tBest loss: 1.191995\tAccuracy: 90.65%\n",
      "24\tValidation loss: 1.189825\tBest loss: 1.189825\tAccuracy: 89.93%\n",
      "25\tValidation loss: 1.200467\tBest loss: 1.189825\tAccuracy: 90.65%\n",
      "26\tValidation loss: 1.188709\tBest loss: 1.188709\tAccuracy: 90.65%\n",
      "27\tValidation loss: 1.186837\tBest loss: 1.186837\tAccuracy: 89.93%\n",
      "28\tValidation loss: 1.188082\tBest loss: 1.186837\tAccuracy: 89.93%\n",
      "29\tValidation loss: 1.191328\tBest loss: 1.186837\tAccuracy: 90.65%\n",
      "30\tValidation loss: 1.188150\tBest loss: 1.186837\tAccuracy: 90.65%\n",
      "31\tValidation loss: 1.187767\tBest loss: 1.186837\tAccuracy: 90.65%\n",
      "32\tValidation loss: 1.186573\tBest loss: 1.186573\tAccuracy: 90.65%\n",
      "33\tValidation loss: 1.188132\tBest loss: 1.186573\tAccuracy: 90.65%\n",
      "34\tValidation loss: 1.187039\tBest loss: 1.186573\tAccuracy: 90.65%\n",
      "35\tValidation loss: 1.185462\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "36\tValidation loss: 1.188610\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "37\tValidation loss: 1.189509\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "38\tValidation loss: 1.187665\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "39\tValidation loss: 1.187099\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "40\tValidation loss: 1.188743\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "41\tValidation loss: 1.188589\tBest loss: 1.185462\tAccuracy: 89.93%\n",
      "42\tValidation loss: 1.188310\tBest loss: 1.185462\tAccuracy: 89.93%\n",
      "43\tValidation loss: 1.188098\tBest loss: 1.185462\tAccuracy: 89.93%\n",
      "44\tValidation loss: 1.187742\tBest loss: 1.185462\tAccuracy: 89.93%\n",
      "45\tValidation loss: 1.187287\tBest loss: 1.185462\tAccuracy: 91.37%\n",
      "46\tValidation loss: 1.188589\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "47\tValidation loss: 1.188888\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "48\tValidation loss: 1.189237\tBest loss: 1.185462\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\tValidation loss: 1.188895\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "50\tValidation loss: 1.188492\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "51\tValidation loss: 1.188630\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "52\tValidation loss: 1.188323\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "53\tValidation loss: 1.189032\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "54\tValidation loss: 1.189635\tBest loss: 1.185462\tAccuracy: 90.65%\n",
      "55\tValidation loss: 1.189249\tBest loss: 1.185462\tAccuracy: 91.37%\n",
      "56\tValidation loss: 1.190066\tBest loss: 1.185462\tAccuracy: 91.37%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   6.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 77.852982\tBest loss: 77.852982\tAccuracy: 41.73%\n",
      "1\tValidation loss: 6.148530\tBest loss: 6.148530\tAccuracy: 77.70%\n",
      "2\tValidation loss: 2.923082\tBest loss: 2.923082\tAccuracy: 84.89%\n",
      "3\tValidation loss: 2.835649\tBest loss: 2.835649\tAccuracy: 84.17%\n",
      "4\tValidation loss: 1.907888\tBest loss: 1.907888\tAccuracy: 87.77%\n",
      "5\tValidation loss: 1.817224\tBest loss: 1.817224\tAccuracy: 87.05%\n",
      "6\tValidation loss: 2.096705\tBest loss: 1.817224\tAccuracy: 87.77%\n",
      "7\tValidation loss: 1.706207\tBest loss: 1.706207\tAccuracy: 87.05%\n",
      "8\tValidation loss: 1.697463\tBest loss: 1.697463\tAccuracy: 87.05%\n",
      "9\tValidation loss: 1.709412\tBest loss: 1.697463\tAccuracy: 89.21%\n",
      "10\tValidation loss: 1.681118\tBest loss: 1.681118\tAccuracy: 88.49%\n",
      "11\tValidation loss: 1.750407\tBest loss: 1.681118\tAccuracy: 87.77%\n",
      "12\tValidation loss: 1.770966\tBest loss: 1.681118\tAccuracy: 87.77%\n",
      "13\tValidation loss: 1.534786\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "14\tValidation loss: 1.613275\tBest loss: 1.534786\tAccuracy: 88.49%\n",
      "15\tValidation loss: 1.553519\tBest loss: 1.534786\tAccuracy: 88.49%\n",
      "16\tValidation loss: 1.553790\tBest loss: 1.534786\tAccuracy: 88.49%\n",
      "17\tValidation loss: 1.571896\tBest loss: 1.534786\tAccuracy: 88.49%\n",
      "18\tValidation loss: 1.570088\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "19\tValidation loss: 1.568314\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "20\tValidation loss: 1.577765\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "21\tValidation loss: 1.579867\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "22\tValidation loss: 1.576818\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "23\tValidation loss: 1.575580\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "24\tValidation loss: 1.572168\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "25\tValidation loss: 1.573328\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "26\tValidation loss: 1.573462\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "27\tValidation loss: 1.570067\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "28\tValidation loss: 1.568825\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "29\tValidation loss: 1.570092\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "30\tValidation loss: 1.571319\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "31\tValidation loss: 1.568548\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "32\tValidation loss: 1.567806\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "33\tValidation loss: 1.567297\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "34\tValidation loss: 1.565796\tBest loss: 1.534786\tAccuracy: 89.21%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   4.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0> \n",
      "0\tValidation loss: 92.918701\tBest loss: 92.918701\tAccuracy: 43.17%\n",
      "1\tValidation loss: 11.863046\tBest loss: 11.863046\tAccuracy: 79.86%\n",
      "2\tValidation loss: 2.220313\tBest loss: 2.220313\tAccuracy: 86.33%\n",
      "3\tValidation loss: 1.465391\tBest loss: 1.465391\tAccuracy: 87.05%\n",
      "4\tValidation loss: 1.021281\tBest loss: 1.021281\tAccuracy: 89.21%\n",
      "5\tValidation loss: 0.890279\tBest loss: 0.890279\tAccuracy: 89.93%\n",
      "6\tValidation loss: 0.953245\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "7\tValidation loss: 1.041295\tBest loss: 0.890279\tAccuracy: 89.21%\n",
      "8\tValidation loss: 1.073476\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "9\tValidation loss: 1.139841\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "10\tValidation loss: 1.199764\tBest loss: 0.890279\tAccuracy: 87.05%\n",
      "11\tValidation loss: 1.185195\tBest loss: 0.890279\tAccuracy: 87.77%\n",
      "12\tValidation loss: 1.247326\tBest loss: 0.890279\tAccuracy: 87.05%\n",
      "13\tValidation loss: 1.256777\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "14\tValidation loss: 1.151878\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "15\tValidation loss: 1.275650\tBest loss: 0.890279\tAccuracy: 89.21%\n",
      "16\tValidation loss: 1.285214\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "17\tValidation loss: 1.259447\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "18\tValidation loss: 1.300278\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "19\tValidation loss: 1.271576\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "20\tValidation loss: 1.272333\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "21\tValidation loss: 1.282560\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "22\tValidation loss: 1.281278\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "23\tValidation loss: 1.279018\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "24\tValidation loss: 1.274913\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "25\tValidation loss: 1.279539\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "26\tValidation loss: 1.278718\tBest loss: 0.890279\tAccuracy: 88.49%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=300, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, total=   3.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 175.780731\tBest loss: 175.780731\tAccuracy: 11.51%\n",
      "1\tValidation loss: 151.364227\tBest loss: 151.364227\tAccuracy: 6.47%\n",
      "2\tValidation loss: 173.563965\tBest loss: 151.364227\tAccuracy: 5.04%\n",
      "3\tValidation loss: 163.271500\tBest loss: 151.364227\tAccuracy: 7.91%\n",
      "4\tValidation loss: 157.699936\tBest loss: 151.364227\tAccuracy: 3.60%\n",
      "5\tValidation loss: 150.828598\tBest loss: 150.828598\tAccuracy: 3.60%\n",
      "6\tValidation loss: 161.819855\tBest loss: 150.828598\tAccuracy: 4.32%\n",
      "7\tValidation loss: 119.134079\tBest loss: 119.134079\tAccuracy: 7.91%\n",
      "8\tValidation loss: 174.756516\tBest loss: 119.134079\tAccuracy: 3.60%\n",
      "9\tValidation loss: 151.291763\tBest loss: 119.134079\tAccuracy: 6.47%\n",
      "10\tValidation loss: 140.909698\tBest loss: 119.134079\tAccuracy: 2.88%\n",
      "11\tValidation loss: 249.328979\tBest loss: 119.134079\tAccuracy: 1.44%\n",
      "12\tValidation loss: 150.240692\tBest loss: 119.134079\tAccuracy: 2.16%\n",
      "13\tValidation loss: 144.583420\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "14\tValidation loss: 160.647202\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "15\tValidation loss: 270.309814\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "16\tValidation loss: 138.793671\tBest loss: 119.134079\tAccuracy: 1.44%\n",
      "17\tValidation loss: 163.401703\tBest loss: 119.134079\tAccuracy: 2.16%\n",
      "18\tValidation loss: 168.161469\tBest loss: 119.134079\tAccuracy: 3.60%\n",
      "19\tValidation loss: 185.540390\tBest loss: 119.134079\tAccuracy: 2.88%\n",
      "20\tValidation loss: 135.672180\tBest loss: 119.134079\tAccuracy: 7.19%\n",
      "21\tValidation loss: 145.322266\tBest loss: 119.134079\tAccuracy: 3.60%\n",
      "22\tValidation loss: 167.517242\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "23\tValidation loss: 145.366409\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "24\tValidation loss: 123.312241\tBest loss: 119.134079\tAccuracy: 1.44%\n",
      "25\tValidation loss: 211.878586\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "26\tValidation loss: 150.233322\tBest loss: 119.134079\tAccuracy: 2.16%\n",
      "27\tValidation loss: 158.747543\tBest loss: 119.134079\tAccuracy: 2.16%\n",
      "28\tValidation loss: 128.828323\tBest loss: 119.134079\tAccuracy: 4.32%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  13.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 170.433807\tBest loss: 170.433807\tAccuracy: 3.60%\n",
      "1\tValidation loss: 201.876694\tBest loss: 170.433807\tAccuracy: 2.16%\n",
      "2\tValidation loss: 135.895035\tBest loss: 135.895035\tAccuracy: 7.19%\n",
      "3\tValidation loss: 136.878830\tBest loss: 135.895035\tAccuracy: 6.47%\n",
      "4\tValidation loss: 168.188431\tBest loss: 135.895035\tAccuracy: 5.04%\n",
      "5\tValidation loss: 173.548615\tBest loss: 135.895035\tAccuracy: 3.60%\n",
      "6\tValidation loss: 161.053589\tBest loss: 135.895035\tAccuracy: 4.32%\n",
      "7\tValidation loss: 131.965958\tBest loss: 131.965958\tAccuracy: 7.19%\n",
      "8\tValidation loss: 133.224945\tBest loss: 131.965958\tAccuracy: 7.91%\n",
      "9\tValidation loss: 120.022766\tBest loss: 120.022766\tAccuracy: 6.47%\n",
      "10\tValidation loss: 141.343674\tBest loss: 120.022766\tAccuracy: 10.07%\n",
      "11\tValidation loss: 157.770737\tBest loss: 120.022766\tAccuracy: 5.04%\n",
      "12\tValidation loss: 158.820801\tBest loss: 120.022766\tAccuracy: 6.47%\n",
      "13\tValidation loss: 202.619415\tBest loss: 120.022766\tAccuracy: 6.47%\n",
      "14\tValidation loss: 181.324509\tBest loss: 120.022766\tAccuracy: 7.19%\n",
      "15\tValidation loss: 157.224533\tBest loss: 120.022766\tAccuracy: 3.60%\n",
      "16\tValidation loss: 141.545837\tBest loss: 120.022766\tAccuracy: 8.63%\n",
      "17\tValidation loss: 146.703537\tBest loss: 120.022766\tAccuracy: 2.16%\n",
      "18\tValidation loss: 160.258286\tBest loss: 120.022766\tAccuracy: 3.60%\n",
      "19\tValidation loss: 138.840714\tBest loss: 120.022766\tAccuracy: 2.16%\n",
      "20\tValidation loss: 133.602676\tBest loss: 120.022766\tAccuracy: 5.04%\n",
      "21\tValidation loss: 138.050034\tBest loss: 120.022766\tAccuracy: 2.88%\n",
      "22\tValidation loss: 151.746735\tBest loss: 120.022766\tAccuracy: 2.16%\n",
      "23\tValidation loss: 148.983521\tBest loss: 120.022766\tAccuracy: 2.16%\n",
      "24\tValidation loss: 161.068207\tBest loss: 120.022766\tAccuracy: 5.04%\n",
      "25\tValidation loss: 134.423813\tBest loss: 120.022766\tAccuracy: 7.91%\n",
      "26\tValidation loss: 175.655914\tBest loss: 120.022766\tAccuracy: 3.60%\n",
      "27\tValidation loss: 124.247131\tBest loss: 120.022766\tAccuracy: 6.47%\n",
      "28\tValidation loss: 149.906433\tBest loss: 120.022766\tAccuracy: 3.60%\n",
      "29\tValidation loss: 978.514709\tBest loss: 120.022766\tAccuracy: 4.32%\n",
      "30\tValidation loss: 198.139633\tBest loss: 120.022766\tAccuracy: 6.47%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  14.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0> \n",
      "0\tValidation loss: 180.498993\tBest loss: 180.498993\tAccuracy: 7.19%\n",
      "1\tValidation loss: 185.025635\tBest loss: 180.498993\tAccuracy: 3.60%\n",
      "2\tValidation loss: 150.113663\tBest loss: 150.113663\tAccuracy: 2.88%\n",
      "3\tValidation loss: 102.938866\tBest loss: 102.938866\tAccuracy: 2.88%\n",
      "4\tValidation loss: 173.633942\tBest loss: 102.938866\tAccuracy: 9.35%\n",
      "5\tValidation loss: 202.156219\tBest loss: 102.938866\tAccuracy: 3.60%\n",
      "6\tValidation loss: 226.547668\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "7\tValidation loss: 143.820862\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "8\tValidation loss: 153.150238\tBest loss: 102.938866\tAccuracy: 2.88%\n",
      "9\tValidation loss: 146.437988\tBest loss: 102.938866\tAccuracy: 2.16%\n",
      "10\tValidation loss: 130.290283\tBest loss: 102.938866\tAccuracy: 2.88%\n",
      "11\tValidation loss: 165.827789\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "12\tValidation loss: 144.243561\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "13\tValidation loss: 137.770035\tBest loss: 102.938866\tAccuracy: 3.60%\n",
      "14\tValidation loss: 150.786743\tBest loss: 102.938866\tAccuracy: 5.76%\n",
      "15\tValidation loss: 144.096771\tBest loss: 102.938866\tAccuracy: 5.76%\n",
      "16\tValidation loss: 152.612671\tBest loss: 102.938866\tAccuracy: 0.72%\n",
      "17\tValidation loss: 163.171371\tBest loss: 102.938866\tAccuracy: 0.72%\n",
      "18\tValidation loss: 143.124863\tBest loss: 102.938866\tAccuracy: 3.60%\n",
      "19\tValidation loss: 153.639236\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "20\tValidation loss: 160.649490\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "21\tValidation loss: 135.197281\tBest loss: 102.938866\tAccuracy: 0.00%\n",
      "22\tValidation loss: 270.814514\tBest loss: 102.938866\tAccuracy: 1.44%\n",
      "23\tValidation loss: 180.310013\tBest loss: 102.938866\tAccuracy: 5.76%\n",
      "24\tValidation loss: 193.459488\tBest loss: 102.938866\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_neurons=1000, n_hidden_layers=1, learning_rate=0.1, dropout_rate=0.2, batch_size=10, activation=<function elu at 0x00000252A18B00D0>, total=  11.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 148.889587\tBest loss: 148.889587\tAccuracy: 28.78%\n",
      "1\tValidation loss: 219.500809\tBest loss: 148.889587\tAccuracy: 30.94%\n",
      "2\tValidation loss: 249.280426\tBest loss: 148.889587\tAccuracy: 24.46%\n",
      "3\tValidation loss: 222.932343\tBest loss: 148.889587\tAccuracy: 32.37%\n",
      "4\tValidation loss: 201.596588\tBest loss: 148.889587\tAccuracy: 25.18%\n",
      "5\tValidation loss: 125.733612\tBest loss: 125.733612\tAccuracy: 33.09%\n",
      "6\tValidation loss: 85.904434\tBest loss: 85.904434\tAccuracy: 48.20%\n",
      "7\tValidation loss: 31.213266\tBest loss: 31.213266\tAccuracy: 66.19%\n",
      "8\tValidation loss: 23.797100\tBest loss: 23.797100\tAccuracy: 69.06%\n",
      "9\tValidation loss: 14.227380\tBest loss: 14.227380\tAccuracy: 74.82%\n",
      "10\tValidation loss: 6.010728\tBest loss: 6.010728\tAccuracy: 85.61%\n",
      "11\tValidation loss: 4.927205\tBest loss: 4.927205\tAccuracy: 84.17%\n",
      "12\tValidation loss: 4.171919\tBest loss: 4.171919\tAccuracy: 84.89%\n",
      "13\tValidation loss: 3.267046\tBest loss: 3.267046\tAccuracy: 86.33%\n",
      "14\tValidation loss: 3.082767\tBest loss: 3.082767\tAccuracy: 87.77%\n",
      "15\tValidation loss: 2.774832\tBest loss: 2.774832\tAccuracy: 89.21%\n",
      "16\tValidation loss: 2.493328\tBest loss: 2.493328\tAccuracy: 89.21%\n",
      "17\tValidation loss: 2.420995\tBest loss: 2.420995\tAccuracy: 88.49%\n",
      "18\tValidation loss: 2.343456\tBest loss: 2.343456\tAccuracy: 88.49%\n",
      "19\tValidation loss: 2.326802\tBest loss: 2.326802\tAccuracy: 88.49%\n",
      "20\tValidation loss: 2.292188\tBest loss: 2.292188\tAccuracy: 88.49%\n",
      "21\tValidation loss: 2.252609\tBest loss: 2.252609\tAccuracy: 88.49%\n",
      "22\tValidation loss: 2.212129\tBest loss: 2.212129\tAccuracy: 88.49%\n",
      "23\tValidation loss: 2.174010\tBest loss: 2.174010\tAccuracy: 87.77%\n",
      "24\tValidation loss: 2.133752\tBest loss: 2.133752\tAccuracy: 87.77%\n",
      "25\tValidation loss: 2.092397\tBest loss: 2.092397\tAccuracy: 87.77%\n",
      "26\tValidation loss: 2.051458\tBest loss: 2.051458\tAccuracy: 87.77%\n",
      "27\tValidation loss: 2.009548\tBest loss: 2.009548\tAccuracy: 87.77%\n",
      "28\tValidation loss: 1.969088\tBest loss: 1.969088\tAccuracy: 87.77%\n",
      "29\tValidation loss: 1.927109\tBest loss: 1.927109\tAccuracy: 87.77%\n",
      "30\tValidation loss: 1.886539\tBest loss: 1.886539\tAccuracy: 87.77%\n",
      "31\tValidation loss: 1.842440\tBest loss: 1.842440\tAccuracy: 87.77%\n",
      "32\tValidation loss: 1.796420\tBest loss: 1.796420\tAccuracy: 87.77%\n",
      "33\tValidation loss: 1.742626\tBest loss: 1.742626\tAccuracy: 88.49%\n",
      "34\tValidation loss: 1.681715\tBest loss: 1.681715\tAccuracy: 88.49%\n",
      "35\tValidation loss: 1.628097\tBest loss: 1.628097\tAccuracy: 88.49%\n",
      "36\tValidation loss: 1.575304\tBest loss: 1.575304\tAccuracy: 88.49%\n",
      "37\tValidation loss: 1.524558\tBest loss: 1.524558\tAccuracy: 88.49%\n",
      "38\tValidation loss: 1.475323\tBest loss: 1.475323\tAccuracy: 88.49%\n",
      "39\tValidation loss: 1.432334\tBest loss: 1.432334\tAccuracy: 88.49%\n",
      "40\tValidation loss: 1.394774\tBest loss: 1.394774\tAccuracy: 88.49%\n",
      "41\tValidation loss: 1.358964\tBest loss: 1.358964\tAccuracy: 88.49%\n",
      "42\tValidation loss: 1.322555\tBest loss: 1.322555\tAccuracy: 88.49%\n",
      "43\tValidation loss: 1.288742\tBest loss: 1.288742\tAccuracy: 88.49%\n",
      "44\tValidation loss: 1.253481\tBest loss: 1.253481\tAccuracy: 88.49%\n",
      "45\tValidation loss: 1.221495\tBest loss: 1.221495\tAccuracy: 88.49%\n",
      "46\tValidation loss: 1.187415\tBest loss: 1.187415\tAccuracy: 88.49%\n",
      "47\tValidation loss: 1.158576\tBest loss: 1.158576\tAccuracy: 88.49%\n",
      "48\tValidation loss: 1.130316\tBest loss: 1.130316\tAccuracy: 88.49%\n",
      "49\tValidation loss: 1.110803\tBest loss: 1.110803\tAccuracy: 88.49%\n",
      "50\tValidation loss: 1.089695\tBest loss: 1.089695\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\tValidation loss: 1.074737\tBest loss: 1.074737\tAccuracy: 89.21%\n",
      "52\tValidation loss: 1.057161\tBest loss: 1.057161\tAccuracy: 89.93%\n",
      "53\tValidation loss: 1.043839\tBest loss: 1.043839\tAccuracy: 89.93%\n",
      "54\tValidation loss: 1.028310\tBest loss: 1.028310\tAccuracy: 89.93%\n",
      "55\tValidation loss: 1.016520\tBest loss: 1.016520\tAccuracy: 89.93%\n",
      "56\tValidation loss: 1.003197\tBest loss: 1.003197\tAccuracy: 89.93%\n",
      "57\tValidation loss: 0.993068\tBest loss: 0.993068\tAccuracy: 90.65%\n",
      "58\tValidation loss: 0.982102\tBest loss: 0.982102\tAccuracy: 90.65%\n",
      "59\tValidation loss: 0.973460\tBest loss: 0.973460\tAccuracy: 90.65%\n",
      "60\tValidation loss: 0.964498\tBest loss: 0.964498\tAccuracy: 90.65%\n",
      "61\tValidation loss: 0.956933\tBest loss: 0.956933\tAccuracy: 90.65%\n",
      "62\tValidation loss: 0.949574\tBest loss: 0.949574\tAccuracy: 90.65%\n",
      "63\tValidation loss: 0.942875\tBest loss: 0.942875\tAccuracy: 90.65%\n",
      "64\tValidation loss: 0.936632\tBest loss: 0.936632\tAccuracy: 90.65%\n",
      "65\tValidation loss: 0.930826\tBest loss: 0.930826\tAccuracy: 90.65%\n",
      "66\tValidation loss: 0.925409\tBest loss: 0.925409\tAccuracy: 90.65%\n",
      "67\tValidation loss: 0.920307\tBest loss: 0.920307\tAccuracy: 90.65%\n",
      "68\tValidation loss: 0.915530\tBest loss: 0.915530\tAccuracy: 90.65%\n",
      "69\tValidation loss: 0.911046\tBest loss: 0.911046\tAccuracy: 90.65%\n",
      "70\tValidation loss: 0.906843\tBest loss: 0.906843\tAccuracy: 90.65%\n",
      "71\tValidation loss: 0.902878\tBest loss: 0.902878\tAccuracy: 90.65%\n",
      "72\tValidation loss: 0.899179\tBest loss: 0.899179\tAccuracy: 90.65%\n",
      "73\tValidation loss: 0.895683\tBest loss: 0.895683\tAccuracy: 90.65%\n",
      "74\tValidation loss: 0.892341\tBest loss: 0.892341\tAccuracy: 89.93%\n",
      "75\tValidation loss: 0.888926\tBest loss: 0.888926\tAccuracy: 89.93%\n",
      "76\tValidation loss: 0.885272\tBest loss: 0.885272\tAccuracy: 89.93%\n",
      "77\tValidation loss: 0.882168\tBest loss: 0.882168\tAccuracy: 89.93%\n",
      "78\tValidation loss: 0.879329\tBest loss: 0.879329\tAccuracy: 89.93%\n",
      "79\tValidation loss: 0.876857\tBest loss: 0.876857\tAccuracy: 89.93%\n",
      "80\tValidation loss: 0.874616\tBest loss: 0.874616\tAccuracy: 89.93%\n",
      "81\tValidation loss: 0.872564\tBest loss: 0.872564\tAccuracy: 89.93%\n",
      "82\tValidation loss: 0.870714\tBest loss: 0.870714\tAccuracy: 89.93%\n",
      "83\tValidation loss: 0.869006\tBest loss: 0.869006\tAccuracy: 90.65%\n",
      "84\tValidation loss: 0.867416\tBest loss: 0.867416\tAccuracy: 90.65%\n",
      "85\tValidation loss: 0.865940\tBest loss: 0.865940\tAccuracy: 90.65%\n",
      "86\tValidation loss: 0.864559\tBest loss: 0.864559\tAccuracy: 90.65%\n",
      "87\tValidation loss: 0.863240\tBest loss: 0.863240\tAccuracy: 90.65%\n",
      "88\tValidation loss: 0.861988\tBest loss: 0.861988\tAccuracy: 90.65%\n",
      "89\tValidation loss: 0.860764\tBest loss: 0.860764\tAccuracy: 90.65%\n",
      "90\tValidation loss: 0.859579\tBest loss: 0.859579\tAccuracy: 90.65%\n",
      "91\tValidation loss: 0.858413\tBest loss: 0.858413\tAccuracy: 90.65%\n",
      "92\tValidation loss: 0.857267\tBest loss: 0.857267\tAccuracy: 90.65%\n",
      "93\tValidation loss: 0.856117\tBest loss: 0.856117\tAccuracy: 90.65%\n",
      "94\tValidation loss: 0.854982\tBest loss: 0.854982\tAccuracy: 90.65%\n",
      "95\tValidation loss: 0.853865\tBest loss: 0.853865\tAccuracy: 90.65%\n",
      "96\tValidation loss: 0.852767\tBest loss: 0.852767\tAccuracy: 90.65%\n",
      "97\tValidation loss: 0.851669\tBest loss: 0.851669\tAccuracy: 90.65%\n",
      "98\tValidation loss: 0.850599\tBest loss: 0.850599\tAccuracy: 90.65%\n",
      "99\tValidation loss: 0.849547\tBest loss: 0.849547\tAccuracy: 90.65%\n",
      "100\tValidation loss: 0.848522\tBest loss: 0.848522\tAccuracy: 90.65%\n",
      "101\tValidation loss: 0.847558\tBest loss: 0.847558\tAccuracy: 90.65%\n",
      "102\tValidation loss: 0.846599\tBest loss: 0.846599\tAccuracy: 90.65%\n",
      "103\tValidation loss: 0.845679\tBest loss: 0.845679\tAccuracy: 90.65%\n",
      "104\tValidation loss: 0.844796\tBest loss: 0.844796\tAccuracy: 90.65%\n",
      "105\tValidation loss: 0.843934\tBest loss: 0.843934\tAccuracy: 90.65%\n",
      "106\tValidation loss: 0.843124\tBest loss: 0.843124\tAccuracy: 90.65%\n",
      "107\tValidation loss: 0.842340\tBest loss: 0.842340\tAccuracy: 90.65%\n",
      "108\tValidation loss: 0.841593\tBest loss: 0.841593\tAccuracy: 90.65%\n",
      "109\tValidation loss: 0.840877\tBest loss: 0.840877\tAccuracy: 90.65%\n",
      "110\tValidation loss: 0.840212\tBest loss: 0.840212\tAccuracy: 90.65%\n",
      "111\tValidation loss: 0.839564\tBest loss: 0.839564\tAccuracy: 90.65%\n",
      "112\tValidation loss: 0.838962\tBest loss: 0.838962\tAccuracy: 90.65%\n",
      "113\tValidation loss: 0.838389\tBest loss: 0.838389\tAccuracy: 90.65%\n",
      "114\tValidation loss: 0.837835\tBest loss: 0.837835\tAccuracy: 90.65%\n",
      "115\tValidation loss: 0.837333\tBest loss: 0.837333\tAccuracy: 90.65%\n",
      "116\tValidation loss: 0.836832\tBest loss: 0.836832\tAccuracy: 90.65%\n",
      "117\tValidation loss: 0.836375\tBest loss: 0.836375\tAccuracy: 90.65%\n",
      "118\tValidation loss: 0.835923\tBest loss: 0.835923\tAccuracy: 90.65%\n",
      "119\tValidation loss: 0.835500\tBest loss: 0.835500\tAccuracy: 90.65%\n",
      "120\tValidation loss: 0.835103\tBest loss: 0.835103\tAccuracy: 90.65%\n",
      "121\tValidation loss: 0.834718\tBest loss: 0.834718\tAccuracy: 90.65%\n",
      "122\tValidation loss: 0.834352\tBest loss: 0.834352\tAccuracy: 90.65%\n",
      "123\tValidation loss: 0.834003\tBest loss: 0.834003\tAccuracy: 90.65%\n",
      "124\tValidation loss: 0.833679\tBest loss: 0.833679\tAccuracy: 90.65%\n",
      "125\tValidation loss: 0.833368\tBest loss: 0.833368\tAccuracy: 90.65%\n",
      "126\tValidation loss: 0.833066\tBest loss: 0.833066\tAccuracy: 90.65%\n",
      "127\tValidation loss: 0.832759\tBest loss: 0.832759\tAccuracy: 90.65%\n",
      "128\tValidation loss: 0.832497\tBest loss: 0.832497\tAccuracy: 90.65%\n",
      "129\tValidation loss: 0.832228\tBest loss: 0.832228\tAccuracy: 90.65%\n",
      "130\tValidation loss: 0.831963\tBest loss: 0.831963\tAccuracy: 90.65%\n",
      "131\tValidation loss: 0.831725\tBest loss: 0.831725\tAccuracy: 90.65%\n",
      "132\tValidation loss: 0.831489\tBest loss: 0.831489\tAccuracy: 90.65%\n",
      "133\tValidation loss: 0.831263\tBest loss: 0.831263\tAccuracy: 90.65%\n",
      "134\tValidation loss: 0.831028\tBest loss: 0.831028\tAccuracy: 90.65%\n",
      "135\tValidation loss: 0.830818\tBest loss: 0.830818\tAccuracy: 90.65%\n",
      "136\tValidation loss: 0.830605\tBest loss: 0.830605\tAccuracy: 90.65%\n",
      "137\tValidation loss: 0.830406\tBest loss: 0.830406\tAccuracy: 90.65%\n",
      "138\tValidation loss: 0.830192\tBest loss: 0.830192\tAccuracy: 90.65%\n",
      "139\tValidation loss: 0.829999\tBest loss: 0.829999\tAccuracy: 90.65%\n",
      "140\tValidation loss: 0.829808\tBest loss: 0.829808\tAccuracy: 90.65%\n",
      "141\tValidation loss: 0.829614\tBest loss: 0.829614\tAccuracy: 90.65%\n",
      "142\tValidation loss: 0.829418\tBest loss: 0.829418\tAccuracy: 90.65%\n",
      "143\tValidation loss: 0.829272\tBest loss: 0.829272\tAccuracy: 90.65%\n",
      "144\tValidation loss: 0.829087\tBest loss: 0.829087\tAccuracy: 90.65%\n",
      "145\tValidation loss: 0.828919\tBest loss: 0.828919\tAccuracy: 90.65%\n",
      "146\tValidation loss: 0.828751\tBest loss: 0.828751\tAccuracy: 90.65%\n",
      "147\tValidation loss: 0.828597\tBest loss: 0.828597\tAccuracy: 90.65%\n",
      "148\tValidation loss: 0.828430\tBest loss: 0.828430\tAccuracy: 90.65%\n",
      "149\tValidation loss: 0.828261\tBest loss: 0.828261\tAccuracy: 90.65%\n",
      "150\tValidation loss: 0.828106\tBest loss: 0.828106\tAccuracy: 90.65%\n",
      "151\tValidation loss: 0.827965\tBest loss: 0.827965\tAccuracy: 90.65%\n",
      "152\tValidation loss: 0.827802\tBest loss: 0.827802\tAccuracy: 90.65%\n",
      "153\tValidation loss: 0.827657\tBest loss: 0.827657\tAccuracy: 90.65%\n",
      "154\tValidation loss: 0.827503\tBest loss: 0.827503\tAccuracy: 90.65%\n",
      "155\tValidation loss: 0.827348\tBest loss: 0.827348\tAccuracy: 90.65%\n",
      "156\tValidation loss: 0.827209\tBest loss: 0.827209\tAccuracy: 90.65%\n",
      "157\tValidation loss: 0.827075\tBest loss: 0.827075\tAccuracy: 90.65%\n",
      "158\tValidation loss: 0.826927\tBest loss: 0.826927\tAccuracy: 90.65%\n",
      "159\tValidation loss: 0.826772\tBest loss: 0.826772\tAccuracy: 90.65%\n",
      "160\tValidation loss: 0.826641\tBest loss: 0.826641\tAccuracy: 90.65%\n",
      "161\tValidation loss: 0.826498\tBest loss: 0.826498\tAccuracy: 90.65%\n",
      "162\tValidation loss: 0.826368\tBest loss: 0.826368\tAccuracy: 90.65%\n",
      "163\tValidation loss: 0.826224\tBest loss: 0.826224\tAccuracy: 90.65%\n",
      "164\tValidation loss: 0.826098\tBest loss: 0.826098\tAccuracy: 90.65%\n",
      "165\tValidation loss: 0.825978\tBest loss: 0.825978\tAccuracy: 90.65%\n",
      "166\tValidation loss: 0.825849\tBest loss: 0.825849\tAccuracy: 90.65%\n",
      "167\tValidation loss: 0.825722\tBest loss: 0.825722\tAccuracy: 90.65%\n",
      "168\tValidation loss: 0.825603\tBest loss: 0.825603\tAccuracy: 90.65%\n",
      "169\tValidation loss: 0.825471\tBest loss: 0.825471\tAccuracy: 90.65%\n",
      "170\tValidation loss: 0.825357\tBest loss: 0.825357\tAccuracy: 90.65%\n",
      "171\tValidation loss: 0.825229\tBest loss: 0.825229\tAccuracy: 90.65%\n",
      "172\tValidation loss: 0.825106\tBest loss: 0.825106\tAccuracy: 90.65%\n",
      "173\tValidation loss: 0.824990\tBest loss: 0.824990\tAccuracy: 90.65%\n",
      "174\tValidation loss: 0.824872\tBest loss: 0.824872\tAccuracy: 90.65%\n",
      "175\tValidation loss: 0.824759\tBest loss: 0.824759\tAccuracy: 90.65%\n",
      "176\tValidation loss: 0.824640\tBest loss: 0.824640\tAccuracy: 90.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\tValidation loss: 0.824514\tBest loss: 0.824514\tAccuracy: 90.65%\n",
      "178\tValidation loss: 0.824407\tBest loss: 0.824407\tAccuracy: 90.65%\n",
      "179\tValidation loss: 0.824295\tBest loss: 0.824295\tAccuracy: 90.65%\n",
      "180\tValidation loss: 0.824188\tBest loss: 0.824188\tAccuracy: 90.65%\n",
      "181\tValidation loss: 0.824068\tBest loss: 0.824068\tAccuracy: 90.65%\n",
      "182\tValidation loss: 0.823965\tBest loss: 0.823965\tAccuracy: 90.65%\n",
      "183\tValidation loss: 0.823855\tBest loss: 0.823855\tAccuracy: 90.65%\n",
      "184\tValidation loss: 0.823735\tBest loss: 0.823735\tAccuracy: 90.65%\n",
      "185\tValidation loss: 0.823633\tBest loss: 0.823633\tAccuracy: 90.65%\n",
      "186\tValidation loss: 0.823530\tBest loss: 0.823530\tAccuracy: 90.65%\n",
      "187\tValidation loss: 0.823414\tBest loss: 0.823414\tAccuracy: 90.65%\n",
      "188\tValidation loss: 0.823298\tBest loss: 0.823298\tAccuracy: 90.65%\n",
      "189\tValidation loss: 0.823186\tBest loss: 0.823186\tAccuracy: 90.65%\n",
      "190\tValidation loss: 0.823082\tBest loss: 0.823082\tAccuracy: 90.65%\n",
      "191\tValidation loss: 0.822983\tBest loss: 0.822983\tAccuracy: 90.65%\n",
      "192\tValidation loss: 0.822878\tBest loss: 0.822878\tAccuracy: 90.65%\n",
      "193\tValidation loss: 0.822767\tBest loss: 0.822767\tAccuracy: 90.65%\n",
      "194\tValidation loss: 0.822664\tBest loss: 0.822664\tAccuracy: 90.65%\n",
      "195\tValidation loss: 0.822570\tBest loss: 0.822570\tAccuracy: 90.65%\n",
      "196\tValidation loss: 0.822471\tBest loss: 0.822471\tAccuracy: 90.65%\n",
      "197\tValidation loss: 0.822371\tBest loss: 0.822371\tAccuracy: 90.65%\n",
      "198\tValidation loss: 0.822271\tBest loss: 0.822271\tAccuracy: 90.65%\n",
      "199\tValidation loss: 0.822166\tBest loss: 0.822166\tAccuracy: 90.65%\n",
      "200\tValidation loss: 0.822069\tBest loss: 0.822069\tAccuracy: 90.65%\n",
      "201\tValidation loss: 0.821963\tBest loss: 0.821963\tAccuracy: 90.65%\n",
      "202\tValidation loss: 0.821870\tBest loss: 0.821870\tAccuracy: 90.65%\n",
      "203\tValidation loss: 0.821773\tBest loss: 0.821773\tAccuracy: 90.65%\n",
      "204\tValidation loss: 0.821686\tBest loss: 0.821686\tAccuracy: 89.93%\n",
      "205\tValidation loss: 0.821582\tBest loss: 0.821582\tAccuracy: 89.93%\n",
      "206\tValidation loss: 0.821488\tBest loss: 0.821488\tAccuracy: 89.93%\n",
      "207\tValidation loss: 0.821402\tBest loss: 0.821402\tAccuracy: 89.93%\n",
      "208\tValidation loss: 0.821305\tBest loss: 0.821305\tAccuracy: 89.93%\n",
      "209\tValidation loss: 0.821214\tBest loss: 0.821214\tAccuracy: 89.93%\n",
      "210\tValidation loss: 0.821114\tBest loss: 0.821114\tAccuracy: 89.93%\n",
      "211\tValidation loss: 0.821021\tBest loss: 0.821021\tAccuracy: 89.93%\n",
      "212\tValidation loss: 0.820928\tBest loss: 0.820928\tAccuracy: 89.93%\n",
      "213\tValidation loss: 0.820836\tBest loss: 0.820836\tAccuracy: 89.93%\n",
      "214\tValidation loss: 0.820735\tBest loss: 0.820735\tAccuracy: 89.93%\n",
      "215\tValidation loss: 0.820647\tBest loss: 0.820647\tAccuracy: 89.93%\n",
      "216\tValidation loss: 0.820554\tBest loss: 0.820554\tAccuracy: 89.93%\n",
      "217\tValidation loss: 0.820452\tBest loss: 0.820452\tAccuracy: 89.93%\n",
      "218\tValidation loss: 0.820368\tBest loss: 0.820368\tAccuracy: 89.93%\n",
      "219\tValidation loss: 0.820274\tBest loss: 0.820274\tAccuracy: 89.93%\n",
      "220\tValidation loss: 0.820195\tBest loss: 0.820195\tAccuracy: 89.93%\n",
      "221\tValidation loss: 0.820111\tBest loss: 0.820111\tAccuracy: 89.93%\n",
      "222\tValidation loss: 0.820016\tBest loss: 0.820016\tAccuracy: 89.93%\n",
      "223\tValidation loss: 0.819933\tBest loss: 0.819933\tAccuracy: 89.93%\n",
      "224\tValidation loss: 0.819847\tBest loss: 0.819847\tAccuracy: 89.93%\n",
      "225\tValidation loss: 0.819740\tBest loss: 0.819740\tAccuracy: 89.93%\n",
      "226\tValidation loss: 0.819649\tBest loss: 0.819649\tAccuracy: 89.93%\n",
      "227\tValidation loss: 0.819559\tBest loss: 0.819559\tAccuracy: 89.93%\n",
      "228\tValidation loss: 0.819481\tBest loss: 0.819481\tAccuracy: 89.93%\n",
      "229\tValidation loss: 0.819397\tBest loss: 0.819397\tAccuracy: 89.93%\n",
      "230\tValidation loss: 0.819323\tBest loss: 0.819323\tAccuracy: 89.93%\n",
      "231\tValidation loss: 0.819221\tBest loss: 0.819221\tAccuracy: 89.93%\n",
      "232\tValidation loss: 0.819137\tBest loss: 0.819137\tAccuracy: 89.93%\n",
      "233\tValidation loss: 0.819049\tBest loss: 0.819049\tAccuracy: 89.93%\n",
      "234\tValidation loss: 0.818974\tBest loss: 0.818974\tAccuracy: 89.93%\n",
      "235\tValidation loss: 0.818896\tBest loss: 0.818896\tAccuracy: 89.93%\n",
      "236\tValidation loss: 0.818802\tBest loss: 0.818802\tAccuracy: 89.93%\n",
      "237\tValidation loss: 0.818716\tBest loss: 0.818716\tAccuracy: 89.93%\n",
      "238\tValidation loss: 0.818623\tBest loss: 0.818623\tAccuracy: 89.93%\n",
      "239\tValidation loss: 0.818544\tBest loss: 0.818544\tAccuracy: 89.93%\n",
      "240\tValidation loss: 0.818463\tBest loss: 0.818463\tAccuracy: 89.93%\n",
      "241\tValidation loss: 0.818386\tBest loss: 0.818386\tAccuracy: 89.93%\n",
      "242\tValidation loss: 0.818303\tBest loss: 0.818303\tAccuracy: 89.93%\n",
      "243\tValidation loss: 0.818222\tBest loss: 0.818222\tAccuracy: 89.93%\n",
      "244\tValidation loss: 0.818141\tBest loss: 0.818141\tAccuracy: 89.93%\n",
      "245\tValidation loss: 0.818050\tBest loss: 0.818050\tAccuracy: 89.93%\n",
      "246\tValidation loss: 0.817984\tBest loss: 0.817984\tAccuracy: 89.93%\n",
      "247\tValidation loss: 0.817903\tBest loss: 0.817903\tAccuracy: 89.93%\n",
      "248\tValidation loss: 0.817818\tBest loss: 0.817818\tAccuracy: 89.93%\n",
      "249\tValidation loss: 0.817727\tBest loss: 0.817727\tAccuracy: 89.93%\n",
      "250\tValidation loss: 0.817656\tBest loss: 0.817656\tAccuracy: 89.93%\n",
      "251\tValidation loss: 0.817579\tBest loss: 0.817579\tAccuracy: 89.93%\n",
      "252\tValidation loss: 0.817501\tBest loss: 0.817501\tAccuracy: 89.93%\n",
      "253\tValidation loss: 0.817414\tBest loss: 0.817414\tAccuracy: 89.93%\n",
      "254\tValidation loss: 0.817340\tBest loss: 0.817340\tAccuracy: 89.93%\n",
      "255\tValidation loss: 0.817247\tBest loss: 0.817247\tAccuracy: 89.93%\n",
      "256\tValidation loss: 0.817165\tBest loss: 0.817165\tAccuracy: 89.93%\n",
      "257\tValidation loss: 0.817087\tBest loss: 0.817087\tAccuracy: 89.93%\n",
      "258\tValidation loss: 0.817026\tBest loss: 0.817026\tAccuracy: 89.93%\n",
      "259\tValidation loss: 0.816946\tBest loss: 0.816946\tAccuracy: 89.93%\n",
      "260\tValidation loss: 0.816859\tBest loss: 0.816859\tAccuracy: 89.93%\n",
      "261\tValidation loss: 0.816781\tBest loss: 0.816781\tAccuracy: 89.93%\n",
      "262\tValidation loss: 0.816704\tBest loss: 0.816704\tAccuracy: 89.93%\n",
      "263\tValidation loss: 0.816619\tBest loss: 0.816619\tAccuracy: 89.93%\n",
      "264\tValidation loss: 0.816541\tBest loss: 0.816541\tAccuracy: 89.93%\n",
      "265\tValidation loss: 0.816472\tBest loss: 0.816472\tAccuracy: 89.93%\n",
      "266\tValidation loss: 0.816391\tBest loss: 0.816391\tAccuracy: 89.93%\n",
      "267\tValidation loss: 0.816310\tBest loss: 0.816310\tAccuracy: 89.93%\n",
      "268\tValidation loss: 0.816227\tBest loss: 0.816227\tAccuracy: 89.93%\n",
      "269\tValidation loss: 0.816151\tBest loss: 0.816151\tAccuracy: 89.93%\n",
      "270\tValidation loss: 0.816077\tBest loss: 0.816077\tAccuracy: 89.93%\n",
      "271\tValidation loss: 0.816007\tBest loss: 0.816007\tAccuracy: 89.93%\n",
      "272\tValidation loss: 0.815936\tBest loss: 0.815936\tAccuracy: 89.93%\n",
      "273\tValidation loss: 0.815849\tBest loss: 0.815849\tAccuracy: 89.93%\n",
      "274\tValidation loss: 0.815770\tBest loss: 0.815770\tAccuracy: 89.93%\n",
      "275\tValidation loss: 0.815689\tBest loss: 0.815689\tAccuracy: 89.93%\n",
      "276\tValidation loss: 0.815624\tBest loss: 0.815624\tAccuracy: 89.93%\n",
      "277\tValidation loss: 0.815550\tBest loss: 0.815550\tAccuracy: 89.93%\n",
      "278\tValidation loss: 0.815469\tBest loss: 0.815469\tAccuracy: 89.93%\n",
      "279\tValidation loss: 0.815403\tBest loss: 0.815403\tAccuracy: 89.93%\n",
      "280\tValidation loss: 0.815330\tBest loss: 0.815330\tAccuracy: 89.93%\n",
      "281\tValidation loss: 0.815237\tBest loss: 0.815237\tAccuracy: 89.93%\n",
      "282\tValidation loss: 0.815160\tBest loss: 0.815160\tAccuracy: 89.93%\n",
      "283\tValidation loss: 0.815089\tBest loss: 0.815089\tAccuracy: 89.93%\n",
      "284\tValidation loss: 0.815009\tBest loss: 0.815009\tAccuracy: 89.93%\n",
      "285\tValidation loss: 0.814949\tBest loss: 0.814949\tAccuracy: 89.93%\n",
      "286\tValidation loss: 0.814878\tBest loss: 0.814878\tAccuracy: 89.93%\n",
      "287\tValidation loss: 0.814807\tBest loss: 0.814807\tAccuracy: 89.93%\n",
      "288\tValidation loss: 0.814730\tBest loss: 0.814730\tAccuracy: 89.93%\n",
      "289\tValidation loss: 0.814654\tBest loss: 0.814654\tAccuracy: 89.93%\n",
      "290\tValidation loss: 0.814587\tBest loss: 0.814587\tAccuracy: 89.93%\n",
      "291\tValidation loss: 0.814509\tBest loss: 0.814509\tAccuracy: 89.93%\n",
      "292\tValidation loss: 0.814443\tBest loss: 0.814443\tAccuracy: 89.93%\n",
      "293\tValidation loss: 0.814370\tBest loss: 0.814370\tAccuracy: 89.93%\n",
      "294\tValidation loss: 0.814298\tBest loss: 0.814298\tAccuracy: 89.93%\n",
      "295\tValidation loss: 0.814230\tBest loss: 0.814230\tAccuracy: 89.93%\n",
      "296\tValidation loss: 0.814150\tBest loss: 0.814150\tAccuracy: 89.93%\n",
      "297\tValidation loss: 0.814078\tBest loss: 0.814078\tAccuracy: 89.93%\n",
      "298\tValidation loss: 0.814001\tBest loss: 0.814001\tAccuracy: 89.93%\n",
      "299\tValidation loss: 0.813929\tBest loss: 0.813929\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\tValidation loss: 0.813857\tBest loss: 0.813857\tAccuracy: 89.93%\n",
      "301\tValidation loss: 0.813790\tBest loss: 0.813790\tAccuracy: 89.93%\n",
      "302\tValidation loss: 0.813722\tBest loss: 0.813722\tAccuracy: 89.93%\n",
      "303\tValidation loss: 0.813654\tBest loss: 0.813654\tAccuracy: 89.93%\n",
      "304\tValidation loss: 0.813593\tBest loss: 0.813593\tAccuracy: 89.93%\n",
      "305\tValidation loss: 0.813516\tBest loss: 0.813516\tAccuracy: 89.93%\n",
      "306\tValidation loss: 0.813459\tBest loss: 0.813459\tAccuracy: 89.93%\n",
      "307\tValidation loss: 0.813389\tBest loss: 0.813389\tAccuracy: 89.93%\n",
      "308\tValidation loss: 0.813309\tBest loss: 0.813309\tAccuracy: 89.93%\n",
      "309\tValidation loss: 0.813240\tBest loss: 0.813240\tAccuracy: 89.93%\n",
      "310\tValidation loss: 0.813168\tBest loss: 0.813168\tAccuracy: 89.93%\n",
      "311\tValidation loss: 0.813108\tBest loss: 0.813108\tAccuracy: 89.93%\n",
      "312\tValidation loss: 0.813041\tBest loss: 0.813041\tAccuracy: 89.93%\n",
      "313\tValidation loss: 0.812968\tBest loss: 0.812968\tAccuracy: 89.93%\n",
      "314\tValidation loss: 0.812896\tBest loss: 0.812896\tAccuracy: 89.93%\n",
      "315\tValidation loss: 0.812812\tBest loss: 0.812812\tAccuracy: 89.93%\n",
      "316\tValidation loss: 0.812754\tBest loss: 0.812754\tAccuracy: 89.93%\n",
      "317\tValidation loss: 0.812680\tBest loss: 0.812680\tAccuracy: 89.93%\n",
      "318\tValidation loss: 0.812621\tBest loss: 0.812621\tAccuracy: 89.93%\n",
      "319\tValidation loss: 0.812556\tBest loss: 0.812556\tAccuracy: 89.93%\n",
      "320\tValidation loss: 0.812490\tBest loss: 0.812490\tAccuracy: 89.93%\n",
      "321\tValidation loss: 0.812420\tBest loss: 0.812420\tAccuracy: 89.93%\n",
      "322\tValidation loss: 0.812348\tBest loss: 0.812348\tAccuracy: 89.93%\n",
      "323\tValidation loss: 0.812284\tBest loss: 0.812284\tAccuracy: 89.93%\n",
      "324\tValidation loss: 0.812226\tBest loss: 0.812226\tAccuracy: 89.93%\n",
      "325\tValidation loss: 0.812151\tBest loss: 0.812151\tAccuracy: 89.93%\n",
      "326\tValidation loss: 0.812084\tBest loss: 0.812084\tAccuracy: 89.93%\n",
      "327\tValidation loss: 0.812017\tBest loss: 0.812017\tAccuracy: 89.93%\n",
      "328\tValidation loss: 0.811961\tBest loss: 0.811961\tAccuracy: 89.93%\n",
      "329\tValidation loss: 0.811893\tBest loss: 0.811893\tAccuracy: 89.93%\n",
      "330\tValidation loss: 0.811840\tBest loss: 0.811840\tAccuracy: 89.93%\n",
      "331\tValidation loss: 0.811779\tBest loss: 0.811779\tAccuracy: 89.93%\n",
      "332\tValidation loss: 0.811702\tBest loss: 0.811702\tAccuracy: 89.93%\n",
      "333\tValidation loss: 0.811632\tBest loss: 0.811632\tAccuracy: 89.93%\n",
      "334\tValidation loss: 0.811556\tBest loss: 0.811556\tAccuracy: 89.93%\n",
      "335\tValidation loss: 0.811508\tBest loss: 0.811508\tAccuracy: 89.93%\n",
      "336\tValidation loss: 0.811451\tBest loss: 0.811451\tAccuracy: 89.93%\n",
      "337\tValidation loss: 0.811375\tBest loss: 0.811375\tAccuracy: 89.93%\n",
      "338\tValidation loss: 0.811318\tBest loss: 0.811318\tAccuracy: 89.93%\n",
      "339\tValidation loss: 0.811251\tBest loss: 0.811251\tAccuracy: 89.93%\n",
      "340\tValidation loss: 0.811186\tBest loss: 0.811186\tAccuracy: 89.93%\n",
      "341\tValidation loss: 0.811128\tBest loss: 0.811128\tAccuracy: 89.93%\n",
      "342\tValidation loss: 0.811052\tBest loss: 0.811052\tAccuracy: 89.93%\n",
      "343\tValidation loss: 0.810989\tBest loss: 0.810989\tAccuracy: 89.93%\n",
      "344\tValidation loss: 0.810936\tBest loss: 0.810936\tAccuracy: 89.93%\n",
      "345\tValidation loss: 0.810866\tBest loss: 0.810866\tAccuracy: 89.93%\n",
      "346\tValidation loss: 0.810805\tBest loss: 0.810805\tAccuracy: 89.93%\n",
      "347\tValidation loss: 0.810733\tBest loss: 0.810733\tAccuracy: 89.93%\n",
      "348\tValidation loss: 0.810677\tBest loss: 0.810677\tAccuracy: 89.93%\n",
      "349\tValidation loss: 0.810621\tBest loss: 0.810621\tAccuracy: 89.93%\n",
      "350\tValidation loss: 0.810554\tBest loss: 0.810554\tAccuracy: 89.93%\n",
      "351\tValidation loss: 0.810477\tBest loss: 0.810477\tAccuracy: 89.93%\n",
      "352\tValidation loss: 0.810409\tBest loss: 0.810409\tAccuracy: 89.93%\n",
      "353\tValidation loss: 0.810345\tBest loss: 0.810345\tAccuracy: 89.93%\n",
      "354\tValidation loss: 0.810289\tBest loss: 0.810289\tAccuracy: 89.93%\n",
      "355\tValidation loss: 0.810232\tBest loss: 0.810232\tAccuracy: 89.93%\n",
      "356\tValidation loss: 0.810173\tBest loss: 0.810173\tAccuracy: 89.93%\n",
      "357\tValidation loss: 0.810114\tBest loss: 0.810114\tAccuracy: 89.93%\n",
      "358\tValidation loss: 0.810059\tBest loss: 0.810059\tAccuracy: 89.93%\n",
      "359\tValidation loss: 0.809991\tBest loss: 0.809991\tAccuracy: 89.93%\n",
      "360\tValidation loss: 0.809924\tBest loss: 0.809924\tAccuracy: 89.93%\n",
      "361\tValidation loss: 0.809867\tBest loss: 0.809867\tAccuracy: 89.93%\n",
      "362\tValidation loss: 0.809804\tBest loss: 0.809804\tAccuracy: 89.93%\n",
      "363\tValidation loss: 0.809736\tBest loss: 0.809736\tAccuracy: 89.93%\n",
      "364\tValidation loss: 0.809674\tBest loss: 0.809674\tAccuracy: 89.93%\n",
      "365\tValidation loss: 0.809623\tBest loss: 0.809623\tAccuracy: 89.93%\n",
      "366\tValidation loss: 0.809563\tBest loss: 0.809563\tAccuracy: 89.93%\n",
      "367\tValidation loss: 0.809482\tBest loss: 0.809482\tAccuracy: 89.93%\n",
      "368\tValidation loss: 0.809427\tBest loss: 0.809427\tAccuracy: 89.93%\n",
      "369\tValidation loss: 0.809377\tBest loss: 0.809377\tAccuracy: 89.93%\n",
      "370\tValidation loss: 0.809320\tBest loss: 0.809320\tAccuracy: 89.93%\n",
      "371\tValidation loss: 0.809252\tBest loss: 0.809252\tAccuracy: 89.93%\n",
      "372\tValidation loss: 0.809198\tBest loss: 0.809198\tAccuracy: 89.93%\n",
      "373\tValidation loss: 0.809137\tBest loss: 0.809137\tAccuracy: 89.93%\n",
      "374\tValidation loss: 0.809090\tBest loss: 0.809090\tAccuracy: 89.93%\n",
      "375\tValidation loss: 0.809015\tBest loss: 0.809015\tAccuracy: 89.93%\n",
      "376\tValidation loss: 0.808954\tBest loss: 0.808954\tAccuracy: 89.93%\n",
      "377\tValidation loss: 0.808894\tBest loss: 0.808894\tAccuracy: 89.93%\n",
      "378\tValidation loss: 0.808842\tBest loss: 0.808842\tAccuracy: 89.93%\n",
      "379\tValidation loss: 0.808784\tBest loss: 0.808784\tAccuracy: 89.93%\n",
      "380\tValidation loss: 0.808721\tBest loss: 0.808721\tAccuracy: 89.93%\n",
      "381\tValidation loss: 0.808661\tBest loss: 0.808661\tAccuracy: 89.93%\n",
      "382\tValidation loss: 0.808603\tBest loss: 0.808603\tAccuracy: 89.93%\n",
      "383\tValidation loss: 0.808554\tBest loss: 0.808554\tAccuracy: 89.93%\n",
      "384\tValidation loss: 0.808500\tBest loss: 0.808500\tAccuracy: 89.93%\n",
      "385\tValidation loss: 0.808438\tBest loss: 0.808438\tAccuracy: 89.93%\n",
      "386\tValidation loss: 0.808382\tBest loss: 0.808382\tAccuracy: 89.93%\n",
      "387\tValidation loss: 0.808330\tBest loss: 0.808330\tAccuracy: 89.93%\n",
      "388\tValidation loss: 0.808272\tBest loss: 0.808272\tAccuracy: 89.93%\n",
      "389\tValidation loss: 0.808200\tBest loss: 0.808200\tAccuracy: 89.93%\n",
      "390\tValidation loss: 0.808151\tBest loss: 0.808151\tAccuracy: 89.93%\n",
      "391\tValidation loss: 0.808090\tBest loss: 0.808090\tAccuracy: 89.93%\n",
      "392\tValidation loss: 0.808035\tBest loss: 0.808035\tAccuracy: 89.93%\n",
      "393\tValidation loss: 0.807984\tBest loss: 0.807984\tAccuracy: 89.93%\n",
      "394\tValidation loss: 0.807921\tBest loss: 0.807921\tAccuracy: 89.93%\n",
      "395\tValidation loss: 0.807876\tBest loss: 0.807876\tAccuracy: 89.93%\n",
      "396\tValidation loss: 0.807820\tBest loss: 0.807820\tAccuracy: 89.93%\n",
      "397\tValidation loss: 0.807768\tBest loss: 0.807768\tAccuracy: 89.93%\n",
      "398\tValidation loss: 0.807709\tBest loss: 0.807709\tAccuracy: 89.93%\n",
      "399\tValidation loss: 0.807648\tBest loss: 0.807648\tAccuracy: 89.93%\n",
      "400\tValidation loss: 0.807586\tBest loss: 0.807586\tAccuracy: 89.93%\n",
      "401\tValidation loss: 0.807542\tBest loss: 0.807542\tAccuracy: 89.93%\n",
      "402\tValidation loss: 0.807486\tBest loss: 0.807486\tAccuracy: 89.93%\n",
      "403\tValidation loss: 0.807433\tBest loss: 0.807433\tAccuracy: 89.93%\n",
      "404\tValidation loss: 0.807373\tBest loss: 0.807373\tAccuracy: 89.93%\n",
      "405\tValidation loss: 0.807317\tBest loss: 0.807317\tAccuracy: 89.93%\n",
      "406\tValidation loss: 0.807252\tBest loss: 0.807252\tAccuracy: 89.93%\n",
      "407\tValidation loss: 0.807199\tBest loss: 0.807199\tAccuracy: 89.93%\n",
      "408\tValidation loss: 0.807147\tBest loss: 0.807147\tAccuracy: 89.93%\n",
      "409\tValidation loss: 0.807090\tBest loss: 0.807090\tAccuracy: 89.93%\n",
      "410\tValidation loss: 0.807025\tBest loss: 0.807025\tAccuracy: 89.93%\n",
      "411\tValidation loss: 0.806972\tBest loss: 0.806972\tAccuracy: 89.93%\n",
      "412\tValidation loss: 0.806921\tBest loss: 0.806921\tAccuracy: 89.93%\n",
      "413\tValidation loss: 0.806863\tBest loss: 0.806863\tAccuracy: 89.93%\n",
      "414\tValidation loss: 0.806809\tBest loss: 0.806809\tAccuracy: 89.93%\n",
      "415\tValidation loss: 0.806758\tBest loss: 0.806758\tAccuracy: 89.93%\n",
      "416\tValidation loss: 0.806697\tBest loss: 0.806697\tAccuracy: 89.93%\n",
      "417\tValidation loss: 0.806640\tBest loss: 0.806640\tAccuracy: 89.93%\n",
      "418\tValidation loss: 0.806590\tBest loss: 0.806590\tAccuracy: 89.93%\n",
      "419\tValidation loss: 0.806535\tBest loss: 0.806535\tAccuracy: 89.93%\n",
      "420\tValidation loss: 0.806479\tBest loss: 0.806479\tAccuracy: 89.93%\n",
      "421\tValidation loss: 0.806431\tBest loss: 0.806431\tAccuracy: 89.93%\n",
      "422\tValidation loss: 0.806372\tBest loss: 0.806372\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\tValidation loss: 0.806326\tBest loss: 0.806326\tAccuracy: 89.93%\n",
      "424\tValidation loss: 0.806270\tBest loss: 0.806270\tAccuracy: 89.93%\n",
      "425\tValidation loss: 0.806220\tBest loss: 0.806220\tAccuracy: 89.93%\n",
      "426\tValidation loss: 0.806165\tBest loss: 0.806165\tAccuracy: 89.93%\n",
      "427\tValidation loss: 0.806114\tBest loss: 0.806114\tAccuracy: 89.93%\n",
      "428\tValidation loss: 0.806058\tBest loss: 0.806058\tAccuracy: 89.93%\n",
      "429\tValidation loss: 0.806004\tBest loss: 0.806004\tAccuracy: 89.93%\n",
      "430\tValidation loss: 0.805955\tBest loss: 0.805955\tAccuracy: 89.93%\n",
      "431\tValidation loss: 0.805904\tBest loss: 0.805904\tAccuracy: 89.93%\n",
      "432\tValidation loss: 0.805848\tBest loss: 0.805848\tAccuracy: 89.93%\n",
      "433\tValidation loss: 0.805802\tBest loss: 0.805802\tAccuracy: 89.93%\n",
      "434\tValidation loss: 0.805746\tBest loss: 0.805746\tAccuracy: 89.93%\n",
      "435\tValidation loss: 0.805698\tBest loss: 0.805698\tAccuracy: 89.93%\n",
      "436\tValidation loss: 0.805642\tBest loss: 0.805642\tAccuracy: 89.93%\n",
      "437\tValidation loss: 0.805585\tBest loss: 0.805585\tAccuracy: 89.93%\n",
      "438\tValidation loss: 0.805519\tBest loss: 0.805519\tAccuracy: 89.93%\n",
      "439\tValidation loss: 0.805475\tBest loss: 0.805475\tAccuracy: 89.93%\n",
      "440\tValidation loss: 0.805423\tBest loss: 0.805423\tAccuracy: 89.93%\n",
      "441\tValidation loss: 0.805362\tBest loss: 0.805362\tAccuracy: 89.93%\n",
      "442\tValidation loss: 0.805314\tBest loss: 0.805314\tAccuracy: 89.93%\n",
      "443\tValidation loss: 0.805263\tBest loss: 0.805263\tAccuracy: 89.93%\n",
      "444\tValidation loss: 0.805203\tBest loss: 0.805203\tAccuracy: 89.93%\n",
      "445\tValidation loss: 0.805155\tBest loss: 0.805155\tAccuracy: 89.93%\n",
      "446\tValidation loss: 0.805108\tBest loss: 0.805108\tAccuracy: 89.93%\n",
      "447\tValidation loss: 0.805059\tBest loss: 0.805059\tAccuracy: 89.93%\n",
      "448\tValidation loss: 0.805016\tBest loss: 0.805016\tAccuracy: 89.93%\n",
      "449\tValidation loss: 0.804964\tBest loss: 0.804964\tAccuracy: 89.93%\n",
      "450\tValidation loss: 0.804917\tBest loss: 0.804917\tAccuracy: 89.93%\n",
      "451\tValidation loss: 0.804859\tBest loss: 0.804859\tAccuracy: 89.93%\n",
      "452\tValidation loss: 0.804809\tBest loss: 0.804809\tAccuracy: 89.93%\n",
      "453\tValidation loss: 0.804754\tBest loss: 0.804754\tAccuracy: 89.93%\n",
      "454\tValidation loss: 0.804709\tBest loss: 0.804709\tAccuracy: 89.93%\n",
      "455\tValidation loss: 0.804664\tBest loss: 0.804664\tAccuracy: 89.93%\n",
      "456\tValidation loss: 0.804618\tBest loss: 0.804618\tAccuracy: 89.93%\n",
      "457\tValidation loss: 0.804571\tBest loss: 0.804571\tAccuracy: 89.93%\n",
      "458\tValidation loss: 0.804518\tBest loss: 0.804518\tAccuracy: 89.93%\n",
      "459\tValidation loss: 0.804468\tBest loss: 0.804468\tAccuracy: 89.93%\n",
      "460\tValidation loss: 0.804418\tBest loss: 0.804418\tAccuracy: 89.93%\n",
      "461\tValidation loss: 0.804367\tBest loss: 0.804367\tAccuracy: 89.93%\n",
      "462\tValidation loss: 0.804309\tBest loss: 0.804309\tAccuracy: 89.93%\n",
      "463\tValidation loss: 0.804258\tBest loss: 0.804258\tAccuracy: 89.93%\n",
      "464\tValidation loss: 0.804203\tBest loss: 0.804203\tAccuracy: 89.93%\n",
      "465\tValidation loss: 0.804162\tBest loss: 0.804162\tAccuracy: 89.93%\n",
      "466\tValidation loss: 0.804110\tBest loss: 0.804110\tAccuracy: 89.93%\n",
      "467\tValidation loss: 0.804070\tBest loss: 0.804070\tAccuracy: 89.93%\n",
      "468\tValidation loss: 0.804019\tBest loss: 0.804019\tAccuracy: 89.93%\n",
      "469\tValidation loss: 0.803963\tBest loss: 0.803963\tAccuracy: 89.93%\n",
      "470\tValidation loss: 0.803910\tBest loss: 0.803910\tAccuracy: 89.93%\n",
      "471\tValidation loss: 0.803869\tBest loss: 0.803869\tAccuracy: 89.93%\n",
      "472\tValidation loss: 0.803812\tBest loss: 0.803812\tAccuracy: 89.93%\n",
      "473\tValidation loss: 0.803770\tBest loss: 0.803770\tAccuracy: 89.93%\n",
      "474\tValidation loss: 0.803720\tBest loss: 0.803720\tAccuracy: 89.93%\n",
      "475\tValidation loss: 0.803670\tBest loss: 0.803670\tAccuracy: 89.93%\n",
      "476\tValidation loss: 0.803623\tBest loss: 0.803623\tAccuracy: 89.93%\n",
      "477\tValidation loss: 0.803575\tBest loss: 0.803575\tAccuracy: 89.93%\n",
      "478\tValidation loss: 0.803530\tBest loss: 0.803530\tAccuracy: 89.93%\n",
      "479\tValidation loss: 0.803486\tBest loss: 0.803486\tAccuracy: 89.93%\n",
      "480\tValidation loss: 0.803436\tBest loss: 0.803436\tAccuracy: 89.93%\n",
      "481\tValidation loss: 0.803387\tBest loss: 0.803387\tAccuracy: 89.93%\n",
      "482\tValidation loss: 0.803333\tBest loss: 0.803333\tAccuracy: 89.93%\n",
      "483\tValidation loss: 0.803288\tBest loss: 0.803288\tAccuracy: 89.93%\n",
      "484\tValidation loss: 0.803250\tBest loss: 0.803250\tAccuracy: 89.93%\n",
      "485\tValidation loss: 0.803206\tBest loss: 0.803206\tAccuracy: 89.93%\n",
      "486\tValidation loss: 0.803157\tBest loss: 0.803157\tAccuracy: 89.93%\n",
      "487\tValidation loss: 0.803104\tBest loss: 0.803104\tAccuracy: 89.93%\n",
      "488\tValidation loss: 0.803053\tBest loss: 0.803053\tAccuracy: 89.93%\n",
      "489\tValidation loss: 0.802999\tBest loss: 0.802999\tAccuracy: 89.93%\n",
      "490\tValidation loss: 0.802955\tBest loss: 0.802955\tAccuracy: 89.93%\n",
      "491\tValidation loss: 0.802910\tBest loss: 0.802910\tAccuracy: 89.93%\n",
      "492\tValidation loss: 0.802860\tBest loss: 0.802860\tAccuracy: 89.93%\n",
      "493\tValidation loss: 0.802815\tBest loss: 0.802815\tAccuracy: 89.93%\n",
      "494\tValidation loss: 0.802770\tBest loss: 0.802770\tAccuracy: 89.93%\n",
      "495\tValidation loss: 0.802727\tBest loss: 0.802727\tAccuracy: 89.93%\n",
      "496\tValidation loss: 0.802681\tBest loss: 0.802681\tAccuracy: 89.93%\n",
      "497\tValidation loss: 0.802636\tBest loss: 0.802636\tAccuracy: 89.93%\n",
      "498\tValidation loss: 0.802590\tBest loss: 0.802590\tAccuracy: 89.93%\n",
      "499\tValidation loss: 0.802545\tBest loss: 0.802545\tAccuracy: 89.93%\n",
      "500\tValidation loss: 0.802490\tBest loss: 0.802490\tAccuracy: 89.93%\n",
      "501\tValidation loss: 0.802440\tBest loss: 0.802440\tAccuracy: 89.93%\n",
      "502\tValidation loss: 0.802397\tBest loss: 0.802397\tAccuracy: 89.93%\n",
      "503\tValidation loss: 0.802353\tBest loss: 0.802353\tAccuracy: 89.93%\n",
      "504\tValidation loss: 0.802303\tBest loss: 0.802303\tAccuracy: 89.93%\n",
      "505\tValidation loss: 0.802263\tBest loss: 0.802263\tAccuracy: 89.93%\n",
      "506\tValidation loss: 0.802217\tBest loss: 0.802217\tAccuracy: 89.93%\n",
      "507\tValidation loss: 0.802174\tBest loss: 0.802174\tAccuracy: 89.93%\n",
      "508\tValidation loss: 0.802140\tBest loss: 0.802140\tAccuracy: 89.93%\n",
      "509\tValidation loss: 0.802094\tBest loss: 0.802094\tAccuracy: 89.93%\n",
      "510\tValidation loss: 0.802048\tBest loss: 0.802048\tAccuracy: 89.93%\n",
      "511\tValidation loss: 0.802001\tBest loss: 0.802001\tAccuracy: 89.93%\n",
      "512\tValidation loss: 0.801948\tBest loss: 0.801948\tAccuracy: 89.93%\n",
      "513\tValidation loss: 0.801903\tBest loss: 0.801903\tAccuracy: 89.93%\n",
      "514\tValidation loss: 0.801864\tBest loss: 0.801864\tAccuracy: 89.93%\n",
      "515\tValidation loss: 0.801816\tBest loss: 0.801816\tAccuracy: 89.93%\n",
      "516\tValidation loss: 0.801774\tBest loss: 0.801774\tAccuracy: 89.93%\n",
      "517\tValidation loss: 0.801726\tBest loss: 0.801726\tAccuracy: 89.93%\n",
      "518\tValidation loss: 0.801692\tBest loss: 0.801692\tAccuracy: 89.93%\n",
      "519\tValidation loss: 0.801642\tBest loss: 0.801642\tAccuracy: 89.93%\n",
      "520\tValidation loss: 0.801602\tBest loss: 0.801602\tAccuracy: 89.93%\n",
      "521\tValidation loss: 0.801558\tBest loss: 0.801558\tAccuracy: 89.93%\n",
      "522\tValidation loss: 0.801524\tBest loss: 0.801524\tAccuracy: 89.93%\n",
      "523\tValidation loss: 0.801483\tBest loss: 0.801483\tAccuracy: 89.93%\n",
      "524\tValidation loss: 0.801432\tBest loss: 0.801432\tAccuracy: 89.93%\n",
      "525\tValidation loss: 0.801386\tBest loss: 0.801386\tAccuracy: 89.93%\n",
      "526\tValidation loss: 0.801349\tBest loss: 0.801349\tAccuracy: 89.93%\n",
      "527\tValidation loss: 0.801289\tBest loss: 0.801289\tAccuracy: 89.93%\n",
      "528\tValidation loss: 0.801244\tBest loss: 0.801244\tAccuracy: 89.93%\n",
      "529\tValidation loss: 0.801203\tBest loss: 0.801203\tAccuracy: 89.93%\n",
      "530\tValidation loss: 0.801164\tBest loss: 0.801164\tAccuracy: 89.93%\n",
      "531\tValidation loss: 0.801118\tBest loss: 0.801118\tAccuracy: 89.93%\n",
      "532\tValidation loss: 0.801081\tBest loss: 0.801081\tAccuracy: 89.93%\n",
      "533\tValidation loss: 0.801042\tBest loss: 0.801042\tAccuracy: 89.93%\n",
      "534\tValidation loss: 0.801003\tBest loss: 0.801003\tAccuracy: 89.93%\n",
      "535\tValidation loss: 0.800958\tBest loss: 0.800958\tAccuracy: 89.93%\n",
      "536\tValidation loss: 0.800910\tBest loss: 0.800910\tAccuracy: 89.93%\n",
      "537\tValidation loss: 0.800858\tBest loss: 0.800858\tAccuracy: 89.93%\n",
      "538\tValidation loss: 0.800814\tBest loss: 0.800814\tAccuracy: 89.93%\n",
      "539\tValidation loss: 0.800774\tBest loss: 0.800774\tAccuracy: 89.93%\n",
      "540\tValidation loss: 0.800736\tBest loss: 0.800736\tAccuracy: 89.93%\n",
      "541\tValidation loss: 0.800693\tBest loss: 0.800693\tAccuracy: 89.93%\n",
      "542\tValidation loss: 0.800646\tBest loss: 0.800646\tAccuracy: 89.93%\n",
      "543\tValidation loss: 0.800596\tBest loss: 0.800596\tAccuracy: 89.93%\n",
      "544\tValidation loss: 0.800558\tBest loss: 0.800558\tAccuracy: 89.93%\n",
      "545\tValidation loss: 0.800516\tBest loss: 0.800516\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\tValidation loss: 0.800471\tBest loss: 0.800471\tAccuracy: 89.93%\n",
      "547\tValidation loss: 0.800425\tBest loss: 0.800425\tAccuracy: 89.93%\n",
      "548\tValidation loss: 0.800379\tBest loss: 0.800379\tAccuracy: 89.93%\n",
      "549\tValidation loss: 0.800344\tBest loss: 0.800344\tAccuracy: 89.93%\n",
      "550\tValidation loss: 0.800297\tBest loss: 0.800297\tAccuracy: 89.93%\n",
      "551\tValidation loss: 0.800251\tBest loss: 0.800251\tAccuracy: 89.93%\n",
      "552\tValidation loss: 0.800212\tBest loss: 0.800212\tAccuracy: 89.93%\n",
      "553\tValidation loss: 0.800178\tBest loss: 0.800178\tAccuracy: 89.93%\n",
      "554\tValidation loss: 0.800127\tBest loss: 0.800127\tAccuracy: 89.93%\n",
      "555\tValidation loss: 0.800091\tBest loss: 0.800091\tAccuracy: 89.93%\n",
      "556\tValidation loss: 0.800048\tBest loss: 0.800048\tAccuracy: 89.93%\n",
      "557\tValidation loss: 0.800012\tBest loss: 0.800012\tAccuracy: 89.93%\n",
      "558\tValidation loss: 0.799970\tBest loss: 0.799970\tAccuracy: 89.93%\n",
      "559\tValidation loss: 0.799927\tBest loss: 0.799927\tAccuracy: 89.93%\n",
      "560\tValidation loss: 0.799885\tBest loss: 0.799885\tAccuracy: 89.93%\n",
      "561\tValidation loss: 0.799832\tBest loss: 0.799832\tAccuracy: 89.93%\n",
      "562\tValidation loss: 0.799800\tBest loss: 0.799800\tAccuracy: 89.93%\n",
      "563\tValidation loss: 0.799768\tBest loss: 0.799768\tAccuracy: 89.93%\n",
      "564\tValidation loss: 0.799728\tBest loss: 0.799728\tAccuracy: 89.93%\n",
      "565\tValidation loss: 0.799675\tBest loss: 0.799675\tAccuracy: 89.93%\n",
      "566\tValidation loss: 0.799630\tBest loss: 0.799630\tAccuracy: 89.93%\n",
      "567\tValidation loss: 0.799602\tBest loss: 0.799602\tAccuracy: 89.93%\n",
      "568\tValidation loss: 0.799556\tBest loss: 0.799556\tAccuracy: 89.93%\n",
      "569\tValidation loss: 0.799528\tBest loss: 0.799528\tAccuracy: 89.93%\n",
      "570\tValidation loss: 0.799494\tBest loss: 0.799494\tAccuracy: 89.93%\n",
      "571\tValidation loss: 0.799450\tBest loss: 0.799450\tAccuracy: 89.93%\n",
      "572\tValidation loss: 0.799403\tBest loss: 0.799403\tAccuracy: 89.93%\n",
      "573\tValidation loss: 0.799355\tBest loss: 0.799355\tAccuracy: 89.93%\n",
      "574\tValidation loss: 0.799316\tBest loss: 0.799316\tAccuracy: 89.93%\n",
      "575\tValidation loss: 0.799279\tBest loss: 0.799279\tAccuracy: 89.93%\n",
      "576\tValidation loss: 0.799242\tBest loss: 0.799242\tAccuracy: 89.93%\n",
      "577\tValidation loss: 0.799208\tBest loss: 0.799208\tAccuracy: 89.93%\n",
      "578\tValidation loss: 0.799169\tBest loss: 0.799169\tAccuracy: 89.93%\n",
      "579\tValidation loss: 0.799121\tBest loss: 0.799121\tAccuracy: 89.93%\n",
      "580\tValidation loss: 0.799088\tBest loss: 0.799088\tAccuracy: 89.93%\n",
      "581\tValidation loss: 0.799044\tBest loss: 0.799044\tAccuracy: 89.93%\n",
      "582\tValidation loss: 0.799004\tBest loss: 0.799004\tAccuracy: 89.93%\n",
      "583\tValidation loss: 0.798957\tBest loss: 0.798957\tAccuracy: 89.93%\n",
      "584\tValidation loss: 0.798925\tBest loss: 0.798925\tAccuracy: 89.93%\n",
      "585\tValidation loss: 0.798869\tBest loss: 0.798869\tAccuracy: 89.93%\n",
      "586\tValidation loss: 0.798828\tBest loss: 0.798828\tAccuracy: 89.93%\n",
      "587\tValidation loss: 0.798801\tBest loss: 0.798801\tAccuracy: 89.93%\n",
      "588\tValidation loss: 0.798755\tBest loss: 0.798755\tAccuracy: 89.93%\n",
      "589\tValidation loss: 0.798711\tBest loss: 0.798711\tAccuracy: 89.93%\n",
      "590\tValidation loss: 0.798680\tBest loss: 0.798680\tAccuracy: 89.93%\n",
      "591\tValidation loss: 0.798645\tBest loss: 0.798645\tAccuracy: 89.93%\n",
      "592\tValidation loss: 0.798599\tBest loss: 0.798599\tAccuracy: 89.93%\n",
      "593\tValidation loss: 0.798551\tBest loss: 0.798551\tAccuracy: 89.93%\n",
      "594\tValidation loss: 0.798521\tBest loss: 0.798521\tAccuracy: 89.93%\n",
      "595\tValidation loss: 0.798478\tBest loss: 0.798478\tAccuracy: 89.93%\n",
      "596\tValidation loss: 0.798436\tBest loss: 0.798436\tAccuracy: 89.93%\n",
      "597\tValidation loss: 0.798401\tBest loss: 0.798401\tAccuracy: 89.93%\n",
      "598\tValidation loss: 0.798362\tBest loss: 0.798362\tAccuracy: 89.93%\n",
      "599\tValidation loss: 0.798320\tBest loss: 0.798320\tAccuracy: 89.93%\n",
      "600\tValidation loss: 0.798278\tBest loss: 0.798278\tAccuracy: 89.93%\n",
      "601\tValidation loss: 0.798249\tBest loss: 0.798249\tAccuracy: 89.93%\n",
      "602\tValidation loss: 0.798209\tBest loss: 0.798209\tAccuracy: 89.93%\n",
      "603\tValidation loss: 0.798172\tBest loss: 0.798172\tAccuracy: 89.93%\n",
      "604\tValidation loss: 0.798131\tBest loss: 0.798131\tAccuracy: 89.93%\n",
      "605\tValidation loss: 0.798102\tBest loss: 0.798102\tAccuracy: 89.93%\n",
      "606\tValidation loss: 0.798057\tBest loss: 0.798057\tAccuracy: 89.93%\n",
      "607\tValidation loss: 0.798016\tBest loss: 0.798016\tAccuracy: 89.93%\n",
      "608\tValidation loss: 0.797980\tBest loss: 0.797980\tAccuracy: 89.93%\n",
      "609\tValidation loss: 0.797949\tBest loss: 0.797949\tAccuracy: 89.93%\n",
      "610\tValidation loss: 0.797916\tBest loss: 0.797916\tAccuracy: 89.93%\n",
      "611\tValidation loss: 0.797881\tBest loss: 0.797881\tAccuracy: 89.93%\n",
      "612\tValidation loss: 0.797838\tBest loss: 0.797838\tAccuracy: 89.93%\n",
      "613\tValidation loss: 0.797812\tBest loss: 0.797812\tAccuracy: 89.93%\n",
      "614\tValidation loss: 0.797767\tBest loss: 0.797767\tAccuracy: 89.93%\n",
      "615\tValidation loss: 0.797728\tBest loss: 0.797728\tAccuracy: 89.93%\n",
      "616\tValidation loss: 0.797692\tBest loss: 0.797692\tAccuracy: 89.93%\n",
      "617\tValidation loss: 0.797653\tBest loss: 0.797653\tAccuracy: 89.93%\n",
      "618\tValidation loss: 0.797615\tBest loss: 0.797615\tAccuracy: 89.93%\n",
      "619\tValidation loss: 0.797595\tBest loss: 0.797595\tAccuracy: 89.93%\n",
      "620\tValidation loss: 0.797554\tBest loss: 0.797554\tAccuracy: 89.93%\n",
      "621\tValidation loss: 0.797515\tBest loss: 0.797515\tAccuracy: 89.93%\n",
      "622\tValidation loss: 0.797464\tBest loss: 0.797464\tAccuracy: 89.93%\n",
      "623\tValidation loss: 0.797440\tBest loss: 0.797440\tAccuracy: 89.93%\n",
      "624\tValidation loss: 0.797396\tBest loss: 0.797396\tAccuracy: 89.93%\n",
      "625\tValidation loss: 0.797358\tBest loss: 0.797358\tAccuracy: 89.93%\n",
      "626\tValidation loss: 0.797324\tBest loss: 0.797324\tAccuracy: 89.93%\n",
      "627\tValidation loss: 0.797283\tBest loss: 0.797283\tAccuracy: 89.93%\n",
      "628\tValidation loss: 0.797243\tBest loss: 0.797243\tAccuracy: 89.93%\n",
      "629\tValidation loss: 0.797209\tBest loss: 0.797209\tAccuracy: 89.93%\n",
      "630\tValidation loss: 0.797175\tBest loss: 0.797175\tAccuracy: 89.93%\n",
      "631\tValidation loss: 0.797142\tBest loss: 0.797142\tAccuracy: 89.93%\n",
      "632\tValidation loss: 0.797110\tBest loss: 0.797110\tAccuracy: 89.93%\n",
      "633\tValidation loss: 0.797072\tBest loss: 0.797072\tAccuracy: 89.93%\n",
      "634\tValidation loss: 0.797037\tBest loss: 0.797037\tAccuracy: 89.93%\n",
      "635\tValidation loss: 0.796996\tBest loss: 0.796996\tAccuracy: 89.93%\n",
      "636\tValidation loss: 0.796958\tBest loss: 0.796958\tAccuracy: 89.93%\n",
      "637\tValidation loss: 0.796914\tBest loss: 0.796914\tAccuracy: 89.93%\n",
      "638\tValidation loss: 0.796875\tBest loss: 0.796875\tAccuracy: 89.93%\n",
      "639\tValidation loss: 0.796835\tBest loss: 0.796835\tAccuracy: 89.93%\n",
      "640\tValidation loss: 0.796803\tBest loss: 0.796803\tAccuracy: 89.93%\n",
      "641\tValidation loss: 0.796770\tBest loss: 0.796770\tAccuracy: 89.93%\n",
      "642\tValidation loss: 0.796728\tBest loss: 0.796728\tAccuracy: 89.93%\n",
      "643\tValidation loss: 0.796697\tBest loss: 0.796697\tAccuracy: 89.93%\n",
      "644\tValidation loss: 0.796660\tBest loss: 0.796660\tAccuracy: 89.93%\n",
      "645\tValidation loss: 0.796632\tBest loss: 0.796632\tAccuracy: 89.93%\n",
      "646\tValidation loss: 0.796593\tBest loss: 0.796593\tAccuracy: 89.93%\n",
      "647\tValidation loss: 0.796560\tBest loss: 0.796560\tAccuracy: 89.93%\n",
      "648\tValidation loss: 0.796522\tBest loss: 0.796522\tAccuracy: 89.93%\n",
      "649\tValidation loss: 0.796493\tBest loss: 0.796493\tAccuracy: 89.93%\n",
      "650\tValidation loss: 0.796457\tBest loss: 0.796457\tAccuracy: 89.93%\n",
      "651\tValidation loss: 0.796414\tBest loss: 0.796414\tAccuracy: 89.93%\n",
      "652\tValidation loss: 0.796376\tBest loss: 0.796376\tAccuracy: 89.93%\n",
      "653\tValidation loss: 0.796347\tBest loss: 0.796347\tAccuracy: 89.93%\n",
      "654\tValidation loss: 0.796315\tBest loss: 0.796315\tAccuracy: 89.93%\n",
      "655\tValidation loss: 0.796281\tBest loss: 0.796281\tAccuracy: 89.93%\n",
      "656\tValidation loss: 0.796237\tBest loss: 0.796237\tAccuracy: 89.93%\n",
      "657\tValidation loss: 0.796206\tBest loss: 0.796206\tAccuracy: 89.93%\n",
      "658\tValidation loss: 0.796184\tBest loss: 0.796184\tAccuracy: 89.93%\n",
      "659\tValidation loss: 0.796148\tBest loss: 0.796148\tAccuracy: 89.93%\n",
      "660\tValidation loss: 0.796111\tBest loss: 0.796111\tAccuracy: 89.93%\n",
      "661\tValidation loss: 0.796077\tBest loss: 0.796077\tAccuracy: 89.93%\n",
      "662\tValidation loss: 0.796047\tBest loss: 0.796047\tAccuracy: 89.93%\n",
      "663\tValidation loss: 0.796016\tBest loss: 0.796016\tAccuracy: 89.93%\n",
      "664\tValidation loss: 0.795975\tBest loss: 0.795975\tAccuracy: 89.93%\n",
      "665\tValidation loss: 0.795937\tBest loss: 0.795937\tAccuracy: 89.93%\n",
      "666\tValidation loss: 0.795908\tBest loss: 0.795908\tAccuracy: 89.93%\n",
      "667\tValidation loss: 0.795871\tBest loss: 0.795871\tAccuracy: 89.93%\n",
      "668\tValidation loss: 0.795835\tBest loss: 0.795835\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\tValidation loss: 0.795797\tBest loss: 0.795797\tAccuracy: 89.93%\n",
      "670\tValidation loss: 0.795765\tBest loss: 0.795765\tAccuracy: 89.93%\n",
      "671\tValidation loss: 0.795716\tBest loss: 0.795716\tAccuracy: 89.93%\n",
      "672\tValidation loss: 0.795684\tBest loss: 0.795684\tAccuracy: 89.93%\n",
      "673\tValidation loss: 0.795650\tBest loss: 0.795650\tAccuracy: 89.93%\n",
      "674\tValidation loss: 0.795616\tBest loss: 0.795616\tAccuracy: 89.93%\n",
      "675\tValidation loss: 0.795588\tBest loss: 0.795588\tAccuracy: 89.93%\n",
      "676\tValidation loss: 0.795555\tBest loss: 0.795555\tAccuracy: 89.93%\n",
      "677\tValidation loss: 0.795520\tBest loss: 0.795520\tAccuracy: 89.93%\n",
      "678\tValidation loss: 0.795479\tBest loss: 0.795479\tAccuracy: 89.93%\n",
      "679\tValidation loss: 0.795456\tBest loss: 0.795456\tAccuracy: 89.93%\n",
      "680\tValidation loss: 0.795422\tBest loss: 0.795422\tAccuracy: 89.93%\n",
      "681\tValidation loss: 0.795380\tBest loss: 0.795380\tAccuracy: 89.93%\n",
      "682\tValidation loss: 0.795347\tBest loss: 0.795347\tAccuracy: 89.93%\n",
      "683\tValidation loss: 0.795316\tBest loss: 0.795316\tAccuracy: 89.93%\n",
      "684\tValidation loss: 0.795286\tBest loss: 0.795286\tAccuracy: 89.93%\n",
      "685\tValidation loss: 0.795256\tBest loss: 0.795256\tAccuracy: 89.93%\n",
      "686\tValidation loss: 0.795220\tBest loss: 0.795220\tAccuracy: 89.93%\n",
      "687\tValidation loss: 0.795191\tBest loss: 0.795191\tAccuracy: 89.93%\n",
      "688\tValidation loss: 0.795147\tBest loss: 0.795147\tAccuracy: 89.93%\n",
      "689\tValidation loss: 0.795127\tBest loss: 0.795127\tAccuracy: 89.93%\n",
      "690\tValidation loss: 0.795090\tBest loss: 0.795090\tAccuracy: 89.93%\n",
      "691\tValidation loss: 0.795056\tBest loss: 0.795056\tAccuracy: 89.93%\n",
      "692\tValidation loss: 0.795024\tBest loss: 0.795024\tAccuracy: 89.93%\n",
      "693\tValidation loss: 0.794992\tBest loss: 0.794992\tAccuracy: 89.93%\n",
      "694\tValidation loss: 0.794955\tBest loss: 0.794955\tAccuracy: 89.93%\n",
      "695\tValidation loss: 0.794924\tBest loss: 0.794924\tAccuracy: 89.93%\n",
      "696\tValidation loss: 0.794891\tBest loss: 0.794891\tAccuracy: 89.93%\n",
      "697\tValidation loss: 0.794860\tBest loss: 0.794860\tAccuracy: 89.93%\n",
      "698\tValidation loss: 0.794825\tBest loss: 0.794825\tAccuracy: 89.93%\n",
      "699\tValidation loss: 0.794795\tBest loss: 0.794795\tAccuracy: 89.93%\n",
      "700\tValidation loss: 0.794762\tBest loss: 0.794762\tAccuracy: 89.93%\n",
      "701\tValidation loss: 0.794721\tBest loss: 0.794721\tAccuracy: 89.93%\n",
      "702\tValidation loss: 0.794686\tBest loss: 0.794686\tAccuracy: 89.93%\n",
      "703\tValidation loss: 0.794658\tBest loss: 0.794658\tAccuracy: 89.93%\n",
      "704\tValidation loss: 0.794632\tBest loss: 0.794632\tAccuracy: 89.93%\n",
      "705\tValidation loss: 0.794596\tBest loss: 0.794596\tAccuracy: 89.93%\n",
      "706\tValidation loss: 0.794562\tBest loss: 0.794562\tAccuracy: 89.93%\n",
      "707\tValidation loss: 0.794536\tBest loss: 0.794536\tAccuracy: 89.93%\n",
      "708\tValidation loss: 0.794510\tBest loss: 0.794510\tAccuracy: 89.93%\n",
      "709\tValidation loss: 0.794477\tBest loss: 0.794477\tAccuracy: 89.93%\n",
      "710\tValidation loss: 0.794439\tBest loss: 0.794439\tAccuracy: 89.93%\n",
      "711\tValidation loss: 0.794403\tBest loss: 0.794403\tAccuracy: 89.93%\n",
      "712\tValidation loss: 0.794372\tBest loss: 0.794372\tAccuracy: 89.93%\n",
      "713\tValidation loss: 0.794340\tBest loss: 0.794340\tAccuracy: 89.93%\n",
      "714\tValidation loss: 0.794299\tBest loss: 0.794299\tAccuracy: 89.93%\n",
      "715\tValidation loss: 0.794281\tBest loss: 0.794281\tAccuracy: 89.93%\n",
      "716\tValidation loss: 0.794245\tBest loss: 0.794245\tAccuracy: 89.93%\n",
      "717\tValidation loss: 0.794216\tBest loss: 0.794216\tAccuracy: 89.93%\n",
      "718\tValidation loss: 0.794183\tBest loss: 0.794183\tAccuracy: 89.93%\n",
      "719\tValidation loss: 0.794152\tBest loss: 0.794152\tAccuracy: 89.93%\n",
      "720\tValidation loss: 0.794123\tBest loss: 0.794123\tAccuracy: 89.93%\n",
      "721\tValidation loss: 0.794096\tBest loss: 0.794096\tAccuracy: 89.93%\n",
      "722\tValidation loss: 0.794060\tBest loss: 0.794060\tAccuracy: 89.93%\n",
      "723\tValidation loss: 0.794035\tBest loss: 0.794035\tAccuracy: 89.93%\n",
      "724\tValidation loss: 0.794009\tBest loss: 0.794009\tAccuracy: 89.93%\n",
      "725\tValidation loss: 0.793969\tBest loss: 0.793969\tAccuracy: 89.93%\n",
      "726\tValidation loss: 0.793930\tBest loss: 0.793930\tAccuracy: 89.93%\n",
      "727\tValidation loss: 0.793904\tBest loss: 0.793904\tAccuracy: 89.93%\n",
      "728\tValidation loss: 0.793871\tBest loss: 0.793871\tAccuracy: 89.93%\n",
      "729\tValidation loss: 0.793831\tBest loss: 0.793831\tAccuracy: 89.93%\n",
      "730\tValidation loss: 0.793801\tBest loss: 0.793801\tAccuracy: 89.93%\n",
      "731\tValidation loss: 0.793774\tBest loss: 0.793774\tAccuracy: 89.93%\n",
      "732\tValidation loss: 0.793750\tBest loss: 0.793750\tAccuracy: 89.93%\n",
      "733\tValidation loss: 0.793713\tBest loss: 0.793713\tAccuracy: 89.93%\n",
      "734\tValidation loss: 0.793684\tBest loss: 0.793684\tAccuracy: 89.93%\n",
      "735\tValidation loss: 0.793645\tBest loss: 0.793645\tAccuracy: 89.93%\n",
      "736\tValidation loss: 0.793606\tBest loss: 0.793606\tAccuracy: 89.93%\n",
      "737\tValidation loss: 0.793570\tBest loss: 0.793570\tAccuracy: 89.93%\n",
      "738\tValidation loss: 0.793540\tBest loss: 0.793540\tAccuracy: 89.93%\n",
      "739\tValidation loss: 0.793515\tBest loss: 0.793515\tAccuracy: 89.93%\n",
      "740\tValidation loss: 0.793490\tBest loss: 0.793490\tAccuracy: 89.93%\n",
      "741\tValidation loss: 0.793453\tBest loss: 0.793453\tAccuracy: 89.93%\n",
      "742\tValidation loss: 0.793429\tBest loss: 0.793429\tAccuracy: 89.93%\n",
      "743\tValidation loss: 0.793399\tBest loss: 0.793399\tAccuracy: 89.93%\n",
      "744\tValidation loss: 0.793369\tBest loss: 0.793369\tAccuracy: 89.93%\n",
      "745\tValidation loss: 0.793342\tBest loss: 0.793342\tAccuracy: 89.93%\n",
      "746\tValidation loss: 0.793317\tBest loss: 0.793317\tAccuracy: 89.93%\n",
      "747\tValidation loss: 0.793290\tBest loss: 0.793290\tAccuracy: 89.93%\n",
      "748\tValidation loss: 0.793259\tBest loss: 0.793259\tAccuracy: 89.93%\n",
      "749\tValidation loss: 0.793229\tBest loss: 0.793229\tAccuracy: 89.93%\n",
      "750\tValidation loss: 0.793195\tBest loss: 0.793195\tAccuracy: 89.93%\n",
      "751\tValidation loss: 0.793160\tBest loss: 0.793160\tAccuracy: 89.93%\n",
      "752\tValidation loss: 0.793122\tBest loss: 0.793122\tAccuracy: 89.93%\n",
      "753\tValidation loss: 0.793083\tBest loss: 0.793083\tAccuracy: 89.93%\n",
      "754\tValidation loss: 0.793049\tBest loss: 0.793049\tAccuracy: 89.93%\n",
      "755\tValidation loss: 0.793027\tBest loss: 0.793027\tAccuracy: 89.93%\n",
      "756\tValidation loss: 0.792991\tBest loss: 0.792991\tAccuracy: 89.93%\n",
      "757\tValidation loss: 0.792962\tBest loss: 0.792962\tAccuracy: 89.93%\n",
      "758\tValidation loss: 0.792943\tBest loss: 0.792943\tAccuracy: 89.93%\n",
      "759\tValidation loss: 0.792911\tBest loss: 0.792911\tAccuracy: 89.93%\n",
      "760\tValidation loss: 0.792879\tBest loss: 0.792879\tAccuracy: 89.93%\n",
      "761\tValidation loss: 0.792853\tBest loss: 0.792853\tAccuracy: 89.93%\n",
      "762\tValidation loss: 0.792820\tBest loss: 0.792820\tAccuracy: 89.93%\n",
      "763\tValidation loss: 0.792786\tBest loss: 0.792786\tAccuracy: 89.93%\n",
      "764\tValidation loss: 0.792761\tBest loss: 0.792761\tAccuracy: 89.93%\n",
      "765\tValidation loss: 0.792731\tBest loss: 0.792731\tAccuracy: 89.93%\n",
      "766\tValidation loss: 0.792702\tBest loss: 0.792702\tAccuracy: 89.93%\n",
      "767\tValidation loss: 0.792673\tBest loss: 0.792673\tAccuracy: 89.93%\n",
      "768\tValidation loss: 0.792640\tBest loss: 0.792640\tAccuracy: 89.93%\n",
      "769\tValidation loss: 0.792605\tBest loss: 0.792605\tAccuracy: 89.93%\n",
      "770\tValidation loss: 0.792585\tBest loss: 0.792585\tAccuracy: 89.93%\n",
      "771\tValidation loss: 0.792559\tBest loss: 0.792559\tAccuracy: 89.93%\n",
      "772\tValidation loss: 0.792529\tBest loss: 0.792529\tAccuracy: 89.93%\n",
      "773\tValidation loss: 0.792491\tBest loss: 0.792491\tAccuracy: 89.93%\n",
      "774\tValidation loss: 0.792469\tBest loss: 0.792469\tAccuracy: 89.93%\n",
      "775\tValidation loss: 0.792433\tBest loss: 0.792433\tAccuracy: 89.93%\n",
      "776\tValidation loss: 0.792403\tBest loss: 0.792403\tAccuracy: 89.93%\n",
      "777\tValidation loss: 0.792371\tBest loss: 0.792371\tAccuracy: 89.93%\n",
      "778\tValidation loss: 0.792336\tBest loss: 0.792336\tAccuracy: 89.93%\n",
      "779\tValidation loss: 0.792311\tBest loss: 0.792311\tAccuracy: 89.93%\n",
      "780\tValidation loss: 0.792284\tBest loss: 0.792284\tAccuracy: 89.93%\n",
      "781\tValidation loss: 0.792255\tBest loss: 0.792255\tAccuracy: 89.93%\n",
      "782\tValidation loss: 0.792219\tBest loss: 0.792219\tAccuracy: 89.93%\n",
      "783\tValidation loss: 0.792201\tBest loss: 0.792201\tAccuracy: 89.93%\n",
      "784\tValidation loss: 0.792164\tBest loss: 0.792164\tAccuracy: 89.93%\n",
      "785\tValidation loss: 0.792132\tBest loss: 0.792132\tAccuracy: 89.93%\n",
      "786\tValidation loss: 0.792102\tBest loss: 0.792102\tAccuracy: 89.93%\n",
      "787\tValidation loss: 0.792073\tBest loss: 0.792073\tAccuracy: 89.93%\n",
      "788\tValidation loss: 0.792043\tBest loss: 0.792043\tAccuracy: 89.93%\n",
      "789\tValidation loss: 0.792016\tBest loss: 0.792016\tAccuracy: 89.93%\n",
      "790\tValidation loss: 0.791981\tBest loss: 0.791981\tAccuracy: 89.93%\n",
      "791\tValidation loss: 0.791958\tBest loss: 0.791958\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\tValidation loss: 0.791932\tBest loss: 0.791932\tAccuracy: 89.93%\n",
      "793\tValidation loss: 0.791911\tBest loss: 0.791911\tAccuracy: 89.93%\n",
      "794\tValidation loss: 0.791879\tBest loss: 0.791879\tAccuracy: 89.93%\n",
      "795\tValidation loss: 0.791845\tBest loss: 0.791845\tAccuracy: 89.93%\n",
      "796\tValidation loss: 0.791817\tBest loss: 0.791817\tAccuracy: 89.93%\n",
      "797\tValidation loss: 0.791784\tBest loss: 0.791784\tAccuracy: 89.93%\n",
      "798\tValidation loss: 0.791756\tBest loss: 0.791756\tAccuracy: 89.93%\n",
      "799\tValidation loss: 0.791726\tBest loss: 0.791726\tAccuracy: 89.93%\n",
      "800\tValidation loss: 0.791700\tBest loss: 0.791700\tAccuracy: 89.93%\n",
      "801\tValidation loss: 0.791673\tBest loss: 0.791673\tAccuracy: 89.93%\n",
      "802\tValidation loss: 0.791649\tBest loss: 0.791649\tAccuracy: 89.93%\n",
      "803\tValidation loss: 0.791620\tBest loss: 0.791620\tAccuracy: 89.93%\n",
      "804\tValidation loss: 0.791598\tBest loss: 0.791598\tAccuracy: 89.93%\n",
      "805\tValidation loss: 0.791567\tBest loss: 0.791567\tAccuracy: 89.93%\n",
      "806\tValidation loss: 0.791544\tBest loss: 0.791544\tAccuracy: 89.93%\n",
      "807\tValidation loss: 0.791512\tBest loss: 0.791512\tAccuracy: 89.93%\n",
      "808\tValidation loss: 0.791483\tBest loss: 0.791483\tAccuracy: 89.93%\n",
      "809\tValidation loss: 0.791449\tBest loss: 0.791449\tAccuracy: 89.93%\n",
      "810\tValidation loss: 0.791429\tBest loss: 0.791429\tAccuracy: 89.93%\n",
      "811\tValidation loss: 0.791394\tBest loss: 0.791394\tAccuracy: 89.93%\n",
      "812\tValidation loss: 0.791362\tBest loss: 0.791362\tAccuracy: 89.93%\n",
      "813\tValidation loss: 0.791339\tBest loss: 0.791339\tAccuracy: 89.93%\n",
      "814\tValidation loss: 0.791314\tBest loss: 0.791314\tAccuracy: 89.93%\n",
      "815\tValidation loss: 0.791285\tBest loss: 0.791285\tAccuracy: 89.93%\n",
      "816\tValidation loss: 0.791249\tBest loss: 0.791249\tAccuracy: 89.93%\n",
      "817\tValidation loss: 0.791224\tBest loss: 0.791224\tAccuracy: 89.93%\n",
      "818\tValidation loss: 0.791194\tBest loss: 0.791194\tAccuracy: 89.93%\n",
      "819\tValidation loss: 0.791164\tBest loss: 0.791164\tAccuracy: 89.93%\n",
      "820\tValidation loss: 0.791140\tBest loss: 0.791140\tAccuracy: 89.93%\n",
      "821\tValidation loss: 0.791110\tBest loss: 0.791110\tAccuracy: 89.93%\n",
      "822\tValidation loss: 0.791083\tBest loss: 0.791083\tAccuracy: 89.93%\n",
      "823\tValidation loss: 0.791062\tBest loss: 0.791062\tAccuracy: 89.93%\n",
      "824\tValidation loss: 0.791034\tBest loss: 0.791034\tAccuracy: 89.93%\n",
      "825\tValidation loss: 0.791006\tBest loss: 0.791006\tAccuracy: 89.93%\n",
      "826\tValidation loss: 0.790971\tBest loss: 0.790971\tAccuracy: 89.93%\n",
      "827\tValidation loss: 0.790949\tBest loss: 0.790949\tAccuracy: 89.93%\n",
      "828\tValidation loss: 0.790921\tBest loss: 0.790921\tAccuracy: 89.93%\n",
      "829\tValidation loss: 0.790892\tBest loss: 0.790892\tAccuracy: 89.93%\n",
      "830\tValidation loss: 0.790870\tBest loss: 0.790870\tAccuracy: 89.93%\n",
      "831\tValidation loss: 0.790839\tBest loss: 0.790839\tAccuracy: 89.93%\n",
      "832\tValidation loss: 0.790806\tBest loss: 0.790806\tAccuracy: 89.93%\n",
      "833\tValidation loss: 0.790784\tBest loss: 0.790784\tAccuracy: 89.93%\n",
      "834\tValidation loss: 0.790751\tBest loss: 0.790751\tAccuracy: 89.93%\n",
      "835\tValidation loss: 0.790724\tBest loss: 0.790724\tAccuracy: 89.93%\n",
      "836\tValidation loss: 0.790694\tBest loss: 0.790694\tAccuracy: 89.93%\n",
      "837\tValidation loss: 0.790672\tBest loss: 0.790672\tAccuracy: 89.93%\n",
      "838\tValidation loss: 0.790641\tBest loss: 0.790641\tAccuracy: 89.93%\n",
      "839\tValidation loss: 0.790617\tBest loss: 0.790617\tAccuracy: 89.93%\n",
      "840\tValidation loss: 0.790597\tBest loss: 0.790597\tAccuracy: 89.93%\n",
      "841\tValidation loss: 0.790573\tBest loss: 0.790573\tAccuracy: 89.93%\n",
      "842\tValidation loss: 0.790553\tBest loss: 0.790553\tAccuracy: 89.93%\n",
      "843\tValidation loss: 0.790531\tBest loss: 0.790531\tAccuracy: 89.93%\n",
      "844\tValidation loss: 0.790508\tBest loss: 0.790508\tAccuracy: 89.93%\n",
      "845\tValidation loss: 0.790474\tBest loss: 0.790474\tAccuracy: 89.93%\n",
      "846\tValidation loss: 0.790442\tBest loss: 0.790442\tAccuracy: 89.93%\n",
      "847\tValidation loss: 0.790407\tBest loss: 0.790407\tAccuracy: 89.93%\n",
      "848\tValidation loss: 0.790385\tBest loss: 0.790385\tAccuracy: 89.93%\n",
      "849\tValidation loss: 0.790358\tBest loss: 0.790358\tAccuracy: 89.93%\n",
      "850\tValidation loss: 0.790324\tBest loss: 0.790324\tAccuracy: 89.93%\n",
      "851\tValidation loss: 0.790305\tBest loss: 0.790305\tAccuracy: 89.93%\n",
      "852\tValidation loss: 0.790280\tBest loss: 0.790280\tAccuracy: 89.93%\n",
      "853\tValidation loss: 0.790256\tBest loss: 0.790256\tAccuracy: 89.93%\n",
      "854\tValidation loss: 0.790234\tBest loss: 0.790234\tAccuracy: 89.93%\n",
      "855\tValidation loss: 0.790207\tBest loss: 0.790207\tAccuracy: 89.93%\n",
      "856\tValidation loss: 0.790179\tBest loss: 0.790179\tAccuracy: 89.93%\n",
      "857\tValidation loss: 0.790153\tBest loss: 0.790153\tAccuracy: 89.93%\n",
      "858\tValidation loss: 0.790123\tBest loss: 0.790123\tAccuracy: 89.93%\n",
      "859\tValidation loss: 0.790098\tBest loss: 0.790098\tAccuracy: 89.93%\n",
      "860\tValidation loss: 0.790069\tBest loss: 0.790069\tAccuracy: 89.93%\n",
      "861\tValidation loss: 0.790040\tBest loss: 0.790040\tAccuracy: 89.93%\n",
      "862\tValidation loss: 0.790010\tBest loss: 0.790010\tAccuracy: 89.93%\n",
      "863\tValidation loss: 0.789985\tBest loss: 0.789985\tAccuracy: 89.93%\n",
      "864\tValidation loss: 0.789967\tBest loss: 0.789967\tAccuracy: 89.93%\n",
      "865\tValidation loss: 0.789933\tBest loss: 0.789933\tAccuracy: 89.93%\n",
      "866\tValidation loss: 0.789923\tBest loss: 0.789923\tAccuracy: 89.93%\n",
      "867\tValidation loss: 0.789891\tBest loss: 0.789891\tAccuracy: 89.93%\n",
      "868\tValidation loss: 0.789859\tBest loss: 0.789859\tAccuracy: 89.93%\n",
      "869\tValidation loss: 0.789833\tBest loss: 0.789833\tAccuracy: 89.93%\n",
      "870\tValidation loss: 0.789814\tBest loss: 0.789814\tAccuracy: 89.93%\n",
      "871\tValidation loss: 0.789789\tBest loss: 0.789789\tAccuracy: 89.93%\n",
      "872\tValidation loss: 0.789760\tBest loss: 0.789760\tAccuracy: 89.93%\n",
      "873\tValidation loss: 0.789740\tBest loss: 0.789740\tAccuracy: 89.93%\n",
      "874\tValidation loss: 0.789713\tBest loss: 0.789713\tAccuracy: 89.93%\n",
      "875\tValidation loss: 0.789688\tBest loss: 0.789688\tAccuracy: 89.93%\n",
      "876\tValidation loss: 0.789667\tBest loss: 0.789667\tAccuracy: 89.93%\n",
      "877\tValidation loss: 0.789635\tBest loss: 0.789635\tAccuracy: 89.93%\n",
      "878\tValidation loss: 0.789606\tBest loss: 0.789606\tAccuracy: 89.93%\n",
      "879\tValidation loss: 0.789587\tBest loss: 0.789587\tAccuracy: 89.93%\n",
      "880\tValidation loss: 0.789560\tBest loss: 0.789560\tAccuracy: 89.93%\n",
      "881\tValidation loss: 0.789536\tBest loss: 0.789536\tAccuracy: 89.93%\n",
      "882\tValidation loss: 0.789513\tBest loss: 0.789513\tAccuracy: 89.93%\n",
      "883\tValidation loss: 0.789485\tBest loss: 0.789485\tAccuracy: 89.93%\n",
      "884\tValidation loss: 0.789459\tBest loss: 0.789459\tAccuracy: 89.93%\n",
      "885\tValidation loss: 0.789434\tBest loss: 0.789434\tAccuracy: 89.93%\n",
      "886\tValidation loss: 0.789412\tBest loss: 0.789412\tAccuracy: 89.93%\n",
      "887\tValidation loss: 0.789392\tBest loss: 0.789392\tAccuracy: 89.93%\n",
      "888\tValidation loss: 0.789371\tBest loss: 0.789371\tAccuracy: 89.93%\n",
      "889\tValidation loss: 0.789341\tBest loss: 0.789341\tAccuracy: 89.93%\n",
      "890\tValidation loss: 0.789319\tBest loss: 0.789319\tAccuracy: 89.93%\n",
      "891\tValidation loss: 0.789295\tBest loss: 0.789295\tAccuracy: 89.93%\n",
      "892\tValidation loss: 0.789265\tBest loss: 0.789265\tAccuracy: 89.93%\n",
      "893\tValidation loss: 0.789239\tBest loss: 0.789239\tAccuracy: 89.93%\n",
      "894\tValidation loss: 0.789210\tBest loss: 0.789210\tAccuracy: 89.93%\n",
      "895\tValidation loss: 0.789186\tBest loss: 0.789186\tAccuracy: 89.93%\n",
      "896\tValidation loss: 0.789161\tBest loss: 0.789161\tAccuracy: 89.93%\n",
      "897\tValidation loss: 0.789128\tBest loss: 0.789128\tAccuracy: 89.93%\n",
      "898\tValidation loss: 0.789108\tBest loss: 0.789108\tAccuracy: 89.93%\n",
      "899\tValidation loss: 0.789090\tBest loss: 0.789090\tAccuracy: 89.93%\n",
      "900\tValidation loss: 0.789065\tBest loss: 0.789065\tAccuracy: 89.93%\n",
      "901\tValidation loss: 0.789036\tBest loss: 0.789036\tAccuracy: 89.93%\n",
      "902\tValidation loss: 0.789024\tBest loss: 0.789024\tAccuracy: 89.93%\n",
      "903\tValidation loss: 0.788999\tBest loss: 0.788999\tAccuracy: 89.93%\n",
      "904\tValidation loss: 0.788969\tBest loss: 0.788969\tAccuracy: 89.93%\n",
      "905\tValidation loss: 0.788941\tBest loss: 0.788941\tAccuracy: 89.93%\n",
      "906\tValidation loss: 0.788915\tBest loss: 0.788915\tAccuracy: 89.93%\n",
      "907\tValidation loss: 0.788890\tBest loss: 0.788890\tAccuracy: 89.93%\n",
      "908\tValidation loss: 0.788858\tBest loss: 0.788858\tAccuracy: 89.93%\n",
      "909\tValidation loss: 0.788832\tBest loss: 0.788832\tAccuracy: 89.93%\n",
      "910\tValidation loss: 0.788811\tBest loss: 0.788811\tAccuracy: 89.93%\n",
      "911\tValidation loss: 0.788787\tBest loss: 0.788787\tAccuracy: 89.93%\n",
      "912\tValidation loss: 0.788765\tBest loss: 0.788765\tAccuracy: 89.93%\n",
      "913\tValidation loss: 0.788740\tBest loss: 0.788740\tAccuracy: 89.93%\n",
      "914\tValidation loss: 0.788708\tBest loss: 0.788708\tAccuracy: 89.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\tValidation loss: 0.788685\tBest loss: 0.788685\tAccuracy: 89.93%\n",
      "916\tValidation loss: 0.788662\tBest loss: 0.788662\tAccuracy: 89.93%\n",
      "917\tValidation loss: 0.788645\tBest loss: 0.788645\tAccuracy: 89.93%\n",
      "918\tValidation loss: 0.788610\tBest loss: 0.788610\tAccuracy: 89.93%\n",
      "919\tValidation loss: 0.788587\tBest loss: 0.788587\tAccuracy: 89.93%\n",
      "920\tValidation loss: 0.788567\tBest loss: 0.788567\tAccuracy: 89.93%\n",
      "921\tValidation loss: 0.788542\tBest loss: 0.788542\tAccuracy: 89.93%\n",
      "922\tValidation loss: 0.788515\tBest loss: 0.788515\tAccuracy: 89.93%\n",
      "923\tValidation loss: 0.788490\tBest loss: 0.788490\tAccuracy: 89.93%\n",
      "924\tValidation loss: 0.788465\tBest loss: 0.788465\tAccuracy: 89.93%\n",
      "925\tValidation loss: 0.788438\tBest loss: 0.788438\tAccuracy: 89.93%\n",
      "926\tValidation loss: 0.788417\tBest loss: 0.788417\tAccuracy: 89.93%\n",
      "927\tValidation loss: 0.788391\tBest loss: 0.788391\tAccuracy: 89.93%\n",
      "928\tValidation loss: 0.788368\tBest loss: 0.788368\tAccuracy: 89.93%\n",
      "929\tValidation loss: 0.788344\tBest loss: 0.788344\tAccuracy: 89.93%\n",
      "930\tValidation loss: 0.788324\tBest loss: 0.788324\tAccuracy: 89.93%\n",
      "931\tValidation loss: 0.788301\tBest loss: 0.788301\tAccuracy: 89.93%\n",
      "932\tValidation loss: 0.788275\tBest loss: 0.788275\tAccuracy: 89.93%\n",
      "933\tValidation loss: 0.788257\tBest loss: 0.788257\tAccuracy: 89.93%\n",
      "934\tValidation loss: 0.788232\tBest loss: 0.788232\tAccuracy: 89.93%\n",
      "935\tValidation loss: 0.788200\tBest loss: 0.788200\tAccuracy: 89.93%\n",
      "936\tValidation loss: 0.788183\tBest loss: 0.788183\tAccuracy: 89.93%\n",
      "937\tValidation loss: 0.788157\tBest loss: 0.788157\tAccuracy: 89.93%\n",
      "938\tValidation loss: 0.788133\tBest loss: 0.788133\tAccuracy: 89.93%\n",
      "939\tValidation loss: 0.788117\tBest loss: 0.788117\tAccuracy: 89.93%\n",
      "940\tValidation loss: 0.788089\tBest loss: 0.788089\tAccuracy: 89.93%\n",
      "941\tValidation loss: 0.788069\tBest loss: 0.788069\tAccuracy: 89.93%\n",
      "942\tValidation loss: 0.788045\tBest loss: 0.788045\tAccuracy: 89.93%\n",
      "943\tValidation loss: 0.788019\tBest loss: 0.788019\tAccuracy: 89.93%\n",
      "944\tValidation loss: 0.787998\tBest loss: 0.787998\tAccuracy: 89.93%\n",
      "945\tValidation loss: 0.787976\tBest loss: 0.787976\tAccuracy: 89.93%\n",
      "946\tValidation loss: 0.787955\tBest loss: 0.787955\tAccuracy: 89.93%\n",
      "947\tValidation loss: 0.787931\tBest loss: 0.787931\tAccuracy: 89.93%\n",
      "948\tValidation loss: 0.787904\tBest loss: 0.787904\tAccuracy: 89.93%\n",
      "949\tValidation loss: 0.787887\tBest loss: 0.787887\tAccuracy: 89.93%\n",
      "950\tValidation loss: 0.787866\tBest loss: 0.787866\tAccuracy: 89.93%\n",
      "951\tValidation loss: 0.787848\tBest loss: 0.787848\tAccuracy: 89.93%\n",
      "952\tValidation loss: 0.787830\tBest loss: 0.787830\tAccuracy: 89.93%\n",
      "953\tValidation loss: 0.787796\tBest loss: 0.787796\tAccuracy: 89.93%\n",
      "954\tValidation loss: 0.787775\tBest loss: 0.787775\tAccuracy: 89.93%\n",
      "955\tValidation loss: 0.787744\tBest loss: 0.787744\tAccuracy: 89.93%\n",
      "956\tValidation loss: 0.787725\tBest loss: 0.787725\tAccuracy: 89.93%\n",
      "957\tValidation loss: 0.787697\tBest loss: 0.787697\tAccuracy: 89.93%\n",
      "958\tValidation loss: 0.787682\tBest loss: 0.787682\tAccuracy: 89.93%\n",
      "959\tValidation loss: 0.787654\tBest loss: 0.787654\tAccuracy: 89.93%\n",
      "960\tValidation loss: 0.787631\tBest loss: 0.787631\tAccuracy: 89.93%\n",
      "961\tValidation loss: 0.787612\tBest loss: 0.787612\tAccuracy: 89.93%\n",
      "962\tValidation loss: 0.787586\tBest loss: 0.787586\tAccuracy: 89.93%\n",
      "963\tValidation loss: 0.787565\tBest loss: 0.787565\tAccuracy: 89.93%\n",
      "964\tValidation loss: 0.787537\tBest loss: 0.787537\tAccuracy: 89.93%\n",
      "965\tValidation loss: 0.787515\tBest loss: 0.787515\tAccuracy: 89.93%\n",
      "966\tValidation loss: 0.787497\tBest loss: 0.787497\tAccuracy: 89.93%\n",
      "967\tValidation loss: 0.787474\tBest loss: 0.787474\tAccuracy: 89.93%\n",
      "968\tValidation loss: 0.787458\tBest loss: 0.787458\tAccuracy: 89.93%\n",
      "969\tValidation loss: 0.787436\tBest loss: 0.787436\tAccuracy: 89.93%\n",
      "970\tValidation loss: 0.787412\tBest loss: 0.787412\tAccuracy: 89.93%\n",
      "971\tValidation loss: 0.787395\tBest loss: 0.787395\tAccuracy: 89.93%\n",
      "972\tValidation loss: 0.787369\tBest loss: 0.787369\tAccuracy: 89.93%\n",
      "973\tValidation loss: 0.787342\tBest loss: 0.787342\tAccuracy: 89.93%\n",
      "974\tValidation loss: 0.787316\tBest loss: 0.787316\tAccuracy: 89.93%\n",
      "975\tValidation loss: 0.787300\tBest loss: 0.787300\tAccuracy: 89.93%\n",
      "976\tValidation loss: 0.787276\tBest loss: 0.787276\tAccuracy: 89.93%\n",
      "977\tValidation loss: 0.787249\tBest loss: 0.787249\tAccuracy: 89.93%\n",
      "978\tValidation loss: 0.787227\tBest loss: 0.787227\tAccuracy: 89.93%\n",
      "979\tValidation loss: 0.787205\tBest loss: 0.787205\tAccuracy: 89.93%\n",
      "980\tValidation loss: 0.787177\tBest loss: 0.787177\tAccuracy: 89.93%\n",
      "981\tValidation loss: 0.787158\tBest loss: 0.787158\tAccuracy: 89.93%\n",
      "982\tValidation loss: 0.787129\tBest loss: 0.787129\tAccuracy: 89.93%\n",
      "983\tValidation loss: 0.787100\tBest loss: 0.787100\tAccuracy: 89.93%\n",
      "984\tValidation loss: 0.787079\tBest loss: 0.787079\tAccuracy: 89.93%\n",
      "985\tValidation loss: 0.787057\tBest loss: 0.787057\tAccuracy: 89.93%\n",
      "986\tValidation loss: 0.787033\tBest loss: 0.787033\tAccuracy: 89.93%\n",
      "987\tValidation loss: 0.787016\tBest loss: 0.787016\tAccuracy: 89.93%\n",
      "988\tValidation loss: 0.786993\tBest loss: 0.786993\tAccuracy: 89.93%\n",
      "989\tValidation loss: 0.786972\tBest loss: 0.786972\tAccuracy: 89.93%\n",
      "990\tValidation loss: 0.786948\tBest loss: 0.786948\tAccuracy: 89.93%\n",
      "991\tValidation loss: 0.786928\tBest loss: 0.786928\tAccuracy: 89.93%\n",
      "992\tValidation loss: 0.786900\tBest loss: 0.786900\tAccuracy: 89.93%\n",
      "993\tValidation loss: 0.786880\tBest loss: 0.786880\tAccuracy: 89.93%\n",
      "994\tValidation loss: 0.786849\tBest loss: 0.786849\tAccuracy: 89.93%\n",
      "995\tValidation loss: 0.786828\tBest loss: 0.786828\tAccuracy: 89.93%\n",
      "996\tValidation loss: 0.786808\tBest loss: 0.786808\tAccuracy: 89.93%\n",
      "997\tValidation loss: 0.786785\tBest loss: 0.786785\tAccuracy: 89.93%\n",
      "998\tValidation loss: 0.786762\tBest loss: 0.786762\tAccuracy: 89.93%\n",
      "999\tValidation loss: 0.786743\tBest loss: 0.786743\tAccuracy: 89.93%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total= 1.4min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 148.523682\tBest loss: 148.523682\tAccuracy: 29.50%\n",
      "1\tValidation loss: 265.349731\tBest loss: 148.523682\tAccuracy: 30.22%\n",
      "2\tValidation loss: 308.680481\tBest loss: 148.523682\tAccuracy: 10.07%\n",
      "3\tValidation loss: 265.347626\tBest loss: 148.523682\tAccuracy: 17.99%\n",
      "4\tValidation loss: 169.078720\tBest loss: 148.523682\tAccuracy: 37.41%\n",
      "5\tValidation loss: 154.880066\tBest loss: 148.523682\tAccuracy: 24.46%\n",
      "6\tValidation loss: 93.980019\tBest loss: 93.980019\tAccuracy: 45.32%\n",
      "7\tValidation loss: 48.535480\tBest loss: 48.535480\tAccuracy: 58.27%\n",
      "8\tValidation loss: 28.683884\tBest loss: 28.683884\tAccuracy: 69.06%\n",
      "9\tValidation loss: 21.685001\tBest loss: 21.685001\tAccuracy: 72.66%\n",
      "10\tValidation loss: 10.049359\tBest loss: 10.049359\tAccuracy: 78.42%\n",
      "11\tValidation loss: 6.921554\tBest loss: 6.921554\tAccuracy: 83.45%\n",
      "12\tValidation loss: 3.905205\tBest loss: 3.905205\tAccuracy: 85.61%\n",
      "13\tValidation loss: 3.599005\tBest loss: 3.599005\tAccuracy: 88.49%\n",
      "14\tValidation loss: 3.397519\tBest loss: 3.397519\tAccuracy: 88.49%\n",
      "15\tValidation loss: 3.193042\tBest loss: 3.193042\tAccuracy: 87.77%\n",
      "16\tValidation loss: 3.091462\tBest loss: 3.091462\tAccuracy: 88.49%\n",
      "17\tValidation loss: 2.977916\tBest loss: 2.977916\tAccuracy: 87.05%\n",
      "18\tValidation loss: 2.962154\tBest loss: 2.962154\tAccuracy: 87.77%\n",
      "19\tValidation loss: 2.807715\tBest loss: 2.807715\tAccuracy: 87.05%\n",
      "20\tValidation loss: 2.722101\tBest loss: 2.722101\tAccuracy: 87.77%\n",
      "21\tValidation loss: 2.635613\tBest loss: 2.635613\tAccuracy: 87.77%\n",
      "22\tValidation loss: 2.583584\tBest loss: 2.583584\tAccuracy: 87.77%\n",
      "23\tValidation loss: 2.515509\tBest loss: 2.515509\tAccuracy: 87.77%\n",
      "24\tValidation loss: 2.468781\tBest loss: 2.468781\tAccuracy: 87.77%\n",
      "25\tValidation loss: 2.397019\tBest loss: 2.397019\tAccuracy: 87.77%\n",
      "26\tValidation loss: 2.374967\tBest loss: 2.374967\tAccuracy: 86.33%\n",
      "27\tValidation loss: 2.311406\tBest loss: 2.311406\tAccuracy: 86.33%\n",
      "28\tValidation loss: 2.256001\tBest loss: 2.256001\tAccuracy: 85.61%\n",
      "29\tValidation loss: 2.228849\tBest loss: 2.228849\tAccuracy: 85.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\tValidation loss: 2.182904\tBest loss: 2.182904\tAccuracy: 84.89%\n",
      "31\tValidation loss: 2.151710\tBest loss: 2.151710\tAccuracy: 84.89%\n",
      "32\tValidation loss: 2.124474\tBest loss: 2.124474\tAccuracy: 84.89%\n",
      "33\tValidation loss: 2.097989\tBest loss: 2.097989\tAccuracy: 85.61%\n",
      "34\tValidation loss: 2.074135\tBest loss: 2.074135\tAccuracy: 86.33%\n",
      "35\tValidation loss: 2.054802\tBest loss: 2.054802\tAccuracy: 85.61%\n",
      "36\tValidation loss: 2.040361\tBest loss: 2.040361\tAccuracy: 85.61%\n",
      "37\tValidation loss: 2.027752\tBest loss: 2.027752\tAccuracy: 85.61%\n",
      "38\tValidation loss: 2.016296\tBest loss: 2.016296\tAccuracy: 85.61%\n",
      "39\tValidation loss: 2.007034\tBest loss: 2.007034\tAccuracy: 85.61%\n",
      "40\tValidation loss: 2.000670\tBest loss: 2.000670\tAccuracy: 84.89%\n",
      "41\tValidation loss: 1.996749\tBest loss: 1.996749\tAccuracy: 85.61%\n",
      "42\tValidation loss: 1.993756\tBest loss: 1.993756\tAccuracy: 85.61%\n",
      "43\tValidation loss: 1.989690\tBest loss: 1.989690\tAccuracy: 85.61%\n",
      "44\tValidation loss: 1.984439\tBest loss: 1.984439\tAccuracy: 85.61%\n",
      "45\tValidation loss: 1.979152\tBest loss: 1.979152\tAccuracy: 85.61%\n",
      "46\tValidation loss: 1.974483\tBest loss: 1.974483\tAccuracy: 85.61%\n",
      "47\tValidation loss: 1.970556\tBest loss: 1.970556\tAccuracy: 85.61%\n",
      "48\tValidation loss: 1.967160\tBest loss: 1.967160\tAccuracy: 85.61%\n",
      "49\tValidation loss: 1.964318\tBest loss: 1.964318\tAccuracy: 86.33%\n",
      "50\tValidation loss: 1.961820\tBest loss: 1.961820\tAccuracy: 86.33%\n",
      "51\tValidation loss: 1.959792\tBest loss: 1.959792\tAccuracy: 86.33%\n",
      "52\tValidation loss: 1.958068\tBest loss: 1.958068\tAccuracy: 86.33%\n",
      "53\tValidation loss: 1.956585\tBest loss: 1.956585\tAccuracy: 86.33%\n",
      "54\tValidation loss: 1.955317\tBest loss: 1.955317\tAccuracy: 86.33%\n",
      "55\tValidation loss: 1.954256\tBest loss: 1.954256\tAccuracy: 86.33%\n",
      "56\tValidation loss: 1.953253\tBest loss: 1.953253\tAccuracy: 86.33%\n",
      "57\tValidation loss: 1.952388\tBest loss: 1.952388\tAccuracy: 86.33%\n",
      "58\tValidation loss: 1.951614\tBest loss: 1.951614\tAccuracy: 87.05%\n",
      "59\tValidation loss: 1.950669\tBest loss: 1.950669\tAccuracy: 87.05%\n",
      "60\tValidation loss: 1.949669\tBest loss: 1.949669\tAccuracy: 87.05%\n",
      "61\tValidation loss: 1.948467\tBest loss: 1.948467\tAccuracy: 87.05%\n",
      "62\tValidation loss: 1.947024\tBest loss: 1.947024\tAccuracy: 87.05%\n",
      "63\tValidation loss: 1.945182\tBest loss: 1.945182\tAccuracy: 87.05%\n",
      "64\tValidation loss: 1.942884\tBest loss: 1.942884\tAccuracy: 87.05%\n",
      "65\tValidation loss: 1.940182\tBest loss: 1.940182\tAccuracy: 87.05%\n",
      "66\tValidation loss: 1.937212\tBest loss: 1.937212\tAccuracy: 87.05%\n",
      "67\tValidation loss: 1.933942\tBest loss: 1.933942\tAccuracy: 87.05%\n",
      "68\tValidation loss: 1.930528\tBest loss: 1.930528\tAccuracy: 87.05%\n",
      "69\tValidation loss: 1.926978\tBest loss: 1.926978\tAccuracy: 87.77%\n",
      "70\tValidation loss: 1.923461\tBest loss: 1.923461\tAccuracy: 87.77%\n",
      "71\tValidation loss: 1.919902\tBest loss: 1.919902\tAccuracy: 87.77%\n",
      "72\tValidation loss: 1.916424\tBest loss: 1.916424\tAccuracy: 87.77%\n",
      "73\tValidation loss: 1.912957\tBest loss: 1.912957\tAccuracy: 87.77%\n",
      "74\tValidation loss: 1.909585\tBest loss: 1.909585\tAccuracy: 87.77%\n",
      "75\tValidation loss: 1.906283\tBest loss: 1.906283\tAccuracy: 87.77%\n",
      "76\tValidation loss: 1.903040\tBest loss: 1.903040\tAccuracy: 87.77%\n",
      "77\tValidation loss: 1.899971\tBest loss: 1.899971\tAccuracy: 87.77%\n",
      "78\tValidation loss: 1.897003\tBest loss: 1.897003\tAccuracy: 87.77%\n",
      "79\tValidation loss: 1.894180\tBest loss: 1.894180\tAccuracy: 87.77%\n",
      "80\tValidation loss: 1.891541\tBest loss: 1.891541\tAccuracy: 87.77%\n",
      "81\tValidation loss: 1.889026\tBest loss: 1.889026\tAccuracy: 87.77%\n",
      "82\tValidation loss: 1.886655\tBest loss: 1.886655\tAccuracy: 87.77%\n",
      "83\tValidation loss: 1.884330\tBest loss: 1.884330\tAccuracy: 87.77%\n",
      "84\tValidation loss: 1.882125\tBest loss: 1.882125\tAccuracy: 87.77%\n",
      "85\tValidation loss: 1.880000\tBest loss: 1.880000\tAccuracy: 87.77%\n",
      "86\tValidation loss: 1.877954\tBest loss: 1.877954\tAccuracy: 87.77%\n",
      "87\tValidation loss: 1.875982\tBest loss: 1.875982\tAccuracy: 87.77%\n",
      "88\tValidation loss: 1.874106\tBest loss: 1.874106\tAccuracy: 87.77%\n",
      "89\tValidation loss: 1.872233\tBest loss: 1.872233\tAccuracy: 87.77%\n",
      "90\tValidation loss: 1.870444\tBest loss: 1.870444\tAccuracy: 87.77%\n",
      "91\tValidation loss: 1.868680\tBest loss: 1.868680\tAccuracy: 87.77%\n",
      "92\tValidation loss: 1.866998\tBest loss: 1.866998\tAccuracy: 87.77%\n",
      "93\tValidation loss: 1.865365\tBest loss: 1.865365\tAccuracy: 87.77%\n",
      "94\tValidation loss: 1.863761\tBest loss: 1.863761\tAccuracy: 87.77%\n",
      "95\tValidation loss: 1.862204\tBest loss: 1.862204\tAccuracy: 87.77%\n",
      "96\tValidation loss: 1.860676\tBest loss: 1.860676\tAccuracy: 87.77%\n",
      "97\tValidation loss: 1.859177\tBest loss: 1.859177\tAccuracy: 87.77%\n",
      "98\tValidation loss: 1.857731\tBest loss: 1.857731\tAccuracy: 87.77%\n",
      "99\tValidation loss: 1.856349\tBest loss: 1.856349\tAccuracy: 87.77%\n",
      "100\tValidation loss: 1.854961\tBest loss: 1.854961\tAccuracy: 87.77%\n",
      "101\tValidation loss: 1.853582\tBest loss: 1.853582\tAccuracy: 87.77%\n",
      "102\tValidation loss: 1.852294\tBest loss: 1.852294\tAccuracy: 87.77%\n",
      "103\tValidation loss: 1.850989\tBest loss: 1.850989\tAccuracy: 87.77%\n",
      "104\tValidation loss: 1.849727\tBest loss: 1.849727\tAccuracy: 87.77%\n",
      "105\tValidation loss: 1.848489\tBest loss: 1.848489\tAccuracy: 87.77%\n",
      "106\tValidation loss: 1.847298\tBest loss: 1.847298\tAccuracy: 87.77%\n",
      "107\tValidation loss: 1.846109\tBest loss: 1.846109\tAccuracy: 87.77%\n",
      "108\tValidation loss: 1.844948\tBest loss: 1.844948\tAccuracy: 87.77%\n",
      "109\tValidation loss: 1.843824\tBest loss: 1.843824\tAccuracy: 87.77%\n",
      "110\tValidation loss: 1.842712\tBest loss: 1.842712\tAccuracy: 87.77%\n",
      "111\tValidation loss: 1.841647\tBest loss: 1.841647\tAccuracy: 87.77%\n",
      "112\tValidation loss: 1.840580\tBest loss: 1.840580\tAccuracy: 87.77%\n",
      "113\tValidation loss: 1.839547\tBest loss: 1.839547\tAccuracy: 87.77%\n",
      "114\tValidation loss: 1.838532\tBest loss: 1.838532\tAccuracy: 87.77%\n",
      "115\tValidation loss: 1.837526\tBest loss: 1.837526\tAccuracy: 87.77%\n",
      "116\tValidation loss: 1.836573\tBest loss: 1.836573\tAccuracy: 87.77%\n",
      "117\tValidation loss: 1.835612\tBest loss: 1.835612\tAccuracy: 87.77%\n",
      "118\tValidation loss: 1.834707\tBest loss: 1.834707\tAccuracy: 87.77%\n",
      "119\tValidation loss: 1.833784\tBest loss: 1.833784\tAccuracy: 87.77%\n",
      "120\tValidation loss: 1.832915\tBest loss: 1.832915\tAccuracy: 87.77%\n",
      "121\tValidation loss: 1.831995\tBest loss: 1.831995\tAccuracy: 87.77%\n",
      "122\tValidation loss: 1.831128\tBest loss: 1.831128\tAccuracy: 87.77%\n",
      "123\tValidation loss: 1.830249\tBest loss: 1.830249\tAccuracy: 87.77%\n",
      "124\tValidation loss: 1.829338\tBest loss: 1.829338\tAccuracy: 87.77%\n",
      "125\tValidation loss: 1.828460\tBest loss: 1.828460\tAccuracy: 87.77%\n",
      "126\tValidation loss: 1.827573\tBest loss: 1.827573\tAccuracy: 87.77%\n",
      "127\tValidation loss: 1.826691\tBest loss: 1.826691\tAccuracy: 87.77%\n",
      "128\tValidation loss: 1.825771\tBest loss: 1.825771\tAccuracy: 87.77%\n",
      "129\tValidation loss: 1.824892\tBest loss: 1.824892\tAccuracy: 87.77%\n",
      "130\tValidation loss: 1.823933\tBest loss: 1.823933\tAccuracy: 87.77%\n",
      "131\tValidation loss: 1.822964\tBest loss: 1.822964\tAccuracy: 87.77%\n",
      "132\tValidation loss: 1.821951\tBest loss: 1.821951\tAccuracy: 87.77%\n",
      "133\tValidation loss: 1.820898\tBest loss: 1.820898\tAccuracy: 87.77%\n",
      "134\tValidation loss: 1.819798\tBest loss: 1.819798\tAccuracy: 87.77%\n",
      "135\tValidation loss: 1.818668\tBest loss: 1.818668\tAccuracy: 87.77%\n",
      "136\tValidation loss: 1.817510\tBest loss: 1.817510\tAccuracy: 87.77%\n",
      "137\tValidation loss: 1.816337\tBest loss: 1.816337\tAccuracy: 87.77%\n",
      "138\tValidation loss: 1.815139\tBest loss: 1.815139\tAccuracy: 87.77%\n",
      "139\tValidation loss: 1.813956\tBest loss: 1.813956\tAccuracy: 87.77%\n",
      "140\tValidation loss: 1.812782\tBest loss: 1.812782\tAccuracy: 87.77%\n",
      "141\tValidation loss: 1.811628\tBest loss: 1.811628\tAccuracy: 87.77%\n",
      "142\tValidation loss: 1.810507\tBest loss: 1.810507\tAccuracy: 87.77%\n",
      "143\tValidation loss: 1.809424\tBest loss: 1.809424\tAccuracy: 87.77%\n",
      "144\tValidation loss: 1.808403\tBest loss: 1.808403\tAccuracy: 87.77%\n",
      "145\tValidation loss: 1.807448\tBest loss: 1.807448\tAccuracy: 87.77%\n",
      "146\tValidation loss: 1.806579\tBest loss: 1.806579\tAccuracy: 87.77%\n",
      "147\tValidation loss: 1.805786\tBest loss: 1.805786\tAccuracy: 88.49%\n",
      "148\tValidation loss: 1.805051\tBest loss: 1.805051\tAccuracy: 88.49%\n",
      "149\tValidation loss: 1.804398\tBest loss: 1.804398\tAccuracy: 88.49%\n",
      "150\tValidation loss: 1.803808\tBest loss: 1.803808\tAccuracy: 88.49%\n",
      "151\tValidation loss: 1.803303\tBest loss: 1.803303\tAccuracy: 88.49%\n",
      "152\tValidation loss: 1.802845\tBest loss: 1.802845\tAccuracy: 88.49%\n",
      "153\tValidation loss: 1.802455\tBest loss: 1.802455\tAccuracy: 88.49%\n",
      "154\tValidation loss: 1.802101\tBest loss: 1.802101\tAccuracy: 88.49%\n",
      "155\tValidation loss: 1.801819\tBest loss: 1.801819\tAccuracy: 88.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\tValidation loss: 1.801528\tBest loss: 1.801528\tAccuracy: 88.49%\n",
      "157\tValidation loss: 1.801302\tBest loss: 1.801302\tAccuracy: 88.49%\n",
      "158\tValidation loss: 1.801100\tBest loss: 1.801100\tAccuracy: 88.49%\n",
      "159\tValidation loss: 1.800912\tBest loss: 1.800912\tAccuracy: 88.49%\n",
      "160\tValidation loss: 1.800749\tBest loss: 1.800749\tAccuracy: 88.49%\n",
      "161\tValidation loss: 1.800624\tBest loss: 1.800624\tAccuracy: 88.49%\n",
      "162\tValidation loss: 1.800505\tBest loss: 1.800505\tAccuracy: 88.49%\n",
      "163\tValidation loss: 1.800365\tBest loss: 1.800365\tAccuracy: 88.49%\n",
      "164\tValidation loss: 1.800273\tBest loss: 1.800273\tAccuracy: 88.49%\n",
      "165\tValidation loss: 1.800179\tBest loss: 1.800179\tAccuracy: 88.49%\n",
      "166\tValidation loss: 1.800066\tBest loss: 1.800066\tAccuracy: 88.49%\n",
      "167\tValidation loss: 1.799981\tBest loss: 1.799981\tAccuracy: 88.49%\n",
      "168\tValidation loss: 1.799895\tBest loss: 1.799895\tAccuracy: 88.49%\n",
      "169\tValidation loss: 1.799777\tBest loss: 1.799777\tAccuracy: 88.49%\n",
      "170\tValidation loss: 1.799684\tBest loss: 1.799684\tAccuracy: 88.49%\n",
      "171\tValidation loss: 1.799602\tBest loss: 1.799602\tAccuracy: 88.49%\n",
      "172\tValidation loss: 1.799515\tBest loss: 1.799515\tAccuracy: 88.49%\n",
      "173\tValidation loss: 1.799413\tBest loss: 1.799413\tAccuracy: 88.49%\n",
      "174\tValidation loss: 1.799319\tBest loss: 1.799319\tAccuracy: 88.49%\n",
      "175\tValidation loss: 1.799223\tBest loss: 1.799223\tAccuracy: 88.49%\n",
      "176\tValidation loss: 1.799136\tBest loss: 1.799136\tAccuracy: 88.49%\n",
      "177\tValidation loss: 1.799056\tBest loss: 1.799056\tAccuracy: 88.49%\n",
      "178\tValidation loss: 1.798942\tBest loss: 1.798942\tAccuracy: 88.49%\n",
      "179\tValidation loss: 1.798846\tBest loss: 1.798846\tAccuracy: 88.49%\n",
      "180\tValidation loss: 1.798719\tBest loss: 1.798719\tAccuracy: 88.49%\n",
      "181\tValidation loss: 1.798629\tBest loss: 1.798629\tAccuracy: 88.49%\n",
      "182\tValidation loss: 1.798502\tBest loss: 1.798502\tAccuracy: 88.49%\n",
      "183\tValidation loss: 1.798392\tBest loss: 1.798392\tAccuracy: 88.49%\n",
      "184\tValidation loss: 1.798284\tBest loss: 1.798284\tAccuracy: 88.49%\n",
      "185\tValidation loss: 1.798166\tBest loss: 1.798166\tAccuracy: 88.49%\n",
      "186\tValidation loss: 1.798066\tBest loss: 1.798066\tAccuracy: 88.49%\n",
      "187\tValidation loss: 1.797943\tBest loss: 1.797943\tAccuracy: 88.49%\n",
      "188\tValidation loss: 1.797835\tBest loss: 1.797835\tAccuracy: 88.49%\n",
      "189\tValidation loss: 1.797711\tBest loss: 1.797711\tAccuracy: 88.49%\n",
      "190\tValidation loss: 1.797600\tBest loss: 1.797600\tAccuracy: 88.49%\n",
      "191\tValidation loss: 1.797459\tBest loss: 1.797459\tAccuracy: 88.49%\n",
      "192\tValidation loss: 1.797331\tBest loss: 1.797331\tAccuracy: 88.49%\n",
      "193\tValidation loss: 1.797196\tBest loss: 1.797196\tAccuracy: 88.49%\n",
      "194\tValidation loss: 1.797110\tBest loss: 1.797110\tAccuracy: 88.49%\n",
      "195\tValidation loss: 1.796971\tBest loss: 1.796971\tAccuracy: 88.49%\n",
      "196\tValidation loss: 1.796858\tBest loss: 1.796858\tAccuracy: 88.49%\n",
      "197\tValidation loss: 1.796731\tBest loss: 1.796731\tAccuracy: 88.49%\n",
      "198\tValidation loss: 1.796585\tBest loss: 1.796585\tAccuracy: 88.49%\n",
      "199\tValidation loss: 1.796453\tBest loss: 1.796453\tAccuracy: 88.49%\n",
      "200\tValidation loss: 1.796310\tBest loss: 1.796310\tAccuracy: 88.49%\n",
      "201\tValidation loss: 1.796198\tBest loss: 1.796198\tAccuracy: 88.49%\n",
      "202\tValidation loss: 1.796048\tBest loss: 1.796048\tAccuracy: 88.49%\n",
      "203\tValidation loss: 1.795918\tBest loss: 1.795918\tAccuracy: 88.49%\n",
      "204\tValidation loss: 1.795792\tBest loss: 1.795792\tAccuracy: 88.49%\n",
      "205\tValidation loss: 1.795652\tBest loss: 1.795652\tAccuracy: 88.49%\n",
      "206\tValidation loss: 1.795496\tBest loss: 1.795496\tAccuracy: 88.49%\n",
      "207\tValidation loss: 1.795363\tBest loss: 1.795363\tAccuracy: 88.49%\n",
      "208\tValidation loss: 1.795239\tBest loss: 1.795239\tAccuracy: 88.49%\n",
      "209\tValidation loss: 1.795108\tBest loss: 1.795108\tAccuracy: 88.49%\n",
      "210\tValidation loss: 1.794957\tBest loss: 1.794957\tAccuracy: 88.49%\n",
      "211\tValidation loss: 1.794812\tBest loss: 1.794812\tAccuracy: 88.49%\n",
      "212\tValidation loss: 1.794678\tBest loss: 1.794678\tAccuracy: 88.49%\n",
      "213\tValidation loss: 1.794557\tBest loss: 1.794557\tAccuracy: 88.49%\n",
      "214\tValidation loss: 1.794399\tBest loss: 1.794399\tAccuracy: 88.49%\n",
      "215\tValidation loss: 1.794287\tBest loss: 1.794287\tAccuracy: 88.49%\n",
      "216\tValidation loss: 1.794143\tBest loss: 1.794143\tAccuracy: 88.49%\n",
      "217\tValidation loss: 1.793989\tBest loss: 1.793989\tAccuracy: 88.49%\n",
      "218\tValidation loss: 1.793837\tBest loss: 1.793837\tAccuracy: 88.49%\n",
      "219\tValidation loss: 1.793696\tBest loss: 1.793696\tAccuracy: 88.49%\n",
      "220\tValidation loss: 1.793572\tBest loss: 1.793572\tAccuracy: 88.49%\n",
      "221\tValidation loss: 1.793436\tBest loss: 1.793436\tAccuracy: 88.49%\n",
      "222\tValidation loss: 1.793276\tBest loss: 1.793276\tAccuracy: 88.49%\n",
      "223\tValidation loss: 1.793118\tBest loss: 1.793118\tAccuracy: 88.49%\n",
      "224\tValidation loss: 1.792968\tBest loss: 1.792968\tAccuracy: 88.49%\n",
      "225\tValidation loss: 1.792813\tBest loss: 1.792813\tAccuracy: 88.49%\n",
      "226\tValidation loss: 1.792688\tBest loss: 1.792688\tAccuracy: 88.49%\n",
      "227\tValidation loss: 1.792545\tBest loss: 1.792545\tAccuracy: 88.49%\n",
      "228\tValidation loss: 1.792398\tBest loss: 1.792398\tAccuracy: 88.49%\n",
      "229\tValidation loss: 1.792249\tBest loss: 1.792249\tAccuracy: 88.49%\n",
      "230\tValidation loss: 1.792107\tBest loss: 1.792107\tAccuracy: 88.49%\n",
      "231\tValidation loss: 1.791958\tBest loss: 1.791958\tAccuracy: 88.49%\n",
      "232\tValidation loss: 1.791824\tBest loss: 1.791824\tAccuracy: 88.49%\n",
      "233\tValidation loss: 1.791698\tBest loss: 1.791698\tAccuracy: 88.49%\n",
      "234\tValidation loss: 1.791558\tBest loss: 1.791558\tAccuracy: 88.49%\n",
      "235\tValidation loss: 1.791426\tBest loss: 1.791426\tAccuracy: 88.49%\n",
      "236\tValidation loss: 1.791291\tBest loss: 1.791291\tAccuracy: 88.49%\n",
      "237\tValidation loss: 1.791134\tBest loss: 1.791134\tAccuracy: 88.49%\n",
      "238\tValidation loss: 1.790977\tBest loss: 1.790977\tAccuracy: 88.49%\n",
      "239\tValidation loss: 1.790825\tBest loss: 1.790825\tAccuracy: 88.49%\n",
      "240\tValidation loss: 1.790706\tBest loss: 1.790706\tAccuracy: 88.49%\n",
      "241\tValidation loss: 1.790563\tBest loss: 1.790563\tAccuracy: 88.49%\n",
      "242\tValidation loss: 1.790427\tBest loss: 1.790427\tAccuracy: 88.49%\n",
      "243\tValidation loss: 1.790287\tBest loss: 1.790287\tAccuracy: 88.49%\n",
      "244\tValidation loss: 1.790171\tBest loss: 1.790171\tAccuracy: 88.49%\n",
      "245\tValidation loss: 1.790022\tBest loss: 1.790022\tAccuracy: 88.49%\n",
      "246\tValidation loss: 1.789869\tBest loss: 1.789869\tAccuracy: 88.49%\n",
      "247\tValidation loss: 1.789732\tBest loss: 1.789732\tAccuracy: 88.49%\n",
      "248\tValidation loss: 1.789590\tBest loss: 1.789590\tAccuracy: 88.49%\n",
      "249\tValidation loss: 1.789459\tBest loss: 1.789459\tAccuracy: 88.49%\n",
      "250\tValidation loss: 1.789317\tBest loss: 1.789317\tAccuracy: 88.49%\n",
      "251\tValidation loss: 1.789171\tBest loss: 1.789171\tAccuracy: 88.49%\n",
      "252\tValidation loss: 1.789027\tBest loss: 1.789027\tAccuracy: 88.49%\n",
      "253\tValidation loss: 1.788906\tBest loss: 1.788906\tAccuracy: 88.49%\n",
      "254\tValidation loss: 1.788761\tBest loss: 1.788761\tAccuracy: 88.49%\n",
      "255\tValidation loss: 1.788648\tBest loss: 1.788648\tAccuracy: 88.49%\n",
      "256\tValidation loss: 1.788523\tBest loss: 1.788523\tAccuracy: 88.49%\n",
      "257\tValidation loss: 1.788384\tBest loss: 1.788384\tAccuracy: 88.49%\n",
      "258\tValidation loss: 1.788246\tBest loss: 1.788246\tAccuracy: 88.49%\n",
      "259\tValidation loss: 1.788090\tBest loss: 1.788090\tAccuracy: 88.49%\n",
      "260\tValidation loss: 1.787960\tBest loss: 1.787960\tAccuracy: 88.49%\n",
      "261\tValidation loss: 1.787812\tBest loss: 1.787812\tAccuracy: 88.49%\n",
      "262\tValidation loss: 1.787697\tBest loss: 1.787697\tAccuracy: 88.49%\n",
      "263\tValidation loss: 1.787567\tBest loss: 1.787567\tAccuracy: 88.49%\n",
      "264\tValidation loss: 1.787446\tBest loss: 1.787446\tAccuracy: 88.49%\n",
      "265\tValidation loss: 1.787321\tBest loss: 1.787321\tAccuracy: 88.49%\n",
      "266\tValidation loss: 1.787185\tBest loss: 1.787185\tAccuracy: 88.49%\n",
      "267\tValidation loss: 1.787043\tBest loss: 1.787043\tAccuracy: 88.49%\n",
      "268\tValidation loss: 1.786916\tBest loss: 1.786916\tAccuracy: 88.49%\n",
      "269\tValidation loss: 1.786782\tBest loss: 1.786782\tAccuracy: 88.49%\n",
      "270\tValidation loss: 1.786670\tBest loss: 1.786670\tAccuracy: 88.49%\n",
      "271\tValidation loss: 1.786547\tBest loss: 1.786547\tAccuracy: 88.49%\n",
      "272\tValidation loss: 1.786416\tBest loss: 1.786416\tAccuracy: 88.49%\n",
      "273\tValidation loss: 1.786283\tBest loss: 1.786283\tAccuracy: 88.49%\n",
      "274\tValidation loss: 1.786134\tBest loss: 1.786134\tAccuracy: 88.49%\n",
      "275\tValidation loss: 1.786018\tBest loss: 1.786018\tAccuracy: 88.49%\n",
      "276\tValidation loss: 1.785892\tBest loss: 1.785892\tAccuracy: 89.21%\n",
      "277\tValidation loss: 1.785780\tBest loss: 1.785780\tAccuracy: 89.21%\n",
      "278\tValidation loss: 1.785635\tBest loss: 1.785635\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\tValidation loss: 1.785504\tBest loss: 1.785504\tAccuracy: 89.21%\n",
      "280\tValidation loss: 1.785378\tBest loss: 1.785378\tAccuracy: 89.21%\n",
      "281\tValidation loss: 1.785253\tBest loss: 1.785253\tAccuracy: 89.21%\n",
      "282\tValidation loss: 1.785117\tBest loss: 1.785117\tAccuracy: 89.21%\n",
      "283\tValidation loss: 1.784993\tBest loss: 1.784993\tAccuracy: 89.21%\n",
      "284\tValidation loss: 1.784853\tBest loss: 1.784853\tAccuracy: 89.21%\n",
      "285\tValidation loss: 1.784739\tBest loss: 1.784739\tAccuracy: 89.21%\n",
      "286\tValidation loss: 1.784618\tBest loss: 1.784618\tAccuracy: 89.21%\n",
      "287\tValidation loss: 1.784503\tBest loss: 1.784503\tAccuracy: 89.21%\n",
      "288\tValidation loss: 1.784385\tBest loss: 1.784385\tAccuracy: 89.21%\n",
      "289\tValidation loss: 1.784240\tBest loss: 1.784240\tAccuracy: 89.21%\n",
      "290\tValidation loss: 1.784128\tBest loss: 1.784128\tAccuracy: 89.21%\n",
      "291\tValidation loss: 1.784016\tBest loss: 1.784016\tAccuracy: 89.21%\n",
      "292\tValidation loss: 1.783909\tBest loss: 1.783909\tAccuracy: 89.21%\n",
      "293\tValidation loss: 1.783777\tBest loss: 1.783777\tAccuracy: 89.21%\n",
      "294\tValidation loss: 1.783665\tBest loss: 1.783665\tAccuracy: 89.21%\n",
      "295\tValidation loss: 1.783551\tBest loss: 1.783551\tAccuracy: 89.21%\n",
      "296\tValidation loss: 1.783443\tBest loss: 1.783443\tAccuracy: 89.21%\n",
      "297\tValidation loss: 1.783309\tBest loss: 1.783309\tAccuracy: 89.21%\n",
      "298\tValidation loss: 1.783167\tBest loss: 1.783167\tAccuracy: 89.21%\n",
      "299\tValidation loss: 1.783053\tBest loss: 1.783053\tAccuracy: 89.21%\n",
      "300\tValidation loss: 1.782940\tBest loss: 1.782940\tAccuracy: 89.21%\n",
      "301\tValidation loss: 1.782823\tBest loss: 1.782823\tAccuracy: 89.21%\n",
      "302\tValidation loss: 1.782711\tBest loss: 1.782711\tAccuracy: 89.21%\n",
      "303\tValidation loss: 1.782593\tBest loss: 1.782593\tAccuracy: 89.21%\n",
      "304\tValidation loss: 1.782493\tBest loss: 1.782493\tAccuracy: 89.21%\n",
      "305\tValidation loss: 1.782384\tBest loss: 1.782384\tAccuracy: 89.21%\n",
      "306\tValidation loss: 1.782251\tBest loss: 1.782251\tAccuracy: 89.21%\n",
      "307\tValidation loss: 1.782140\tBest loss: 1.782140\tAccuracy: 89.21%\n",
      "308\tValidation loss: 1.782023\tBest loss: 1.782023\tAccuracy: 89.21%\n",
      "309\tValidation loss: 1.781895\tBest loss: 1.781895\tAccuracy: 89.21%\n",
      "310\tValidation loss: 1.781810\tBest loss: 1.781810\tAccuracy: 89.21%\n",
      "311\tValidation loss: 1.781697\tBest loss: 1.781697\tAccuracy: 89.21%\n",
      "312\tValidation loss: 1.781590\tBest loss: 1.781590\tAccuracy: 89.21%\n",
      "313\tValidation loss: 1.781477\tBest loss: 1.781477\tAccuracy: 89.21%\n",
      "314\tValidation loss: 1.781363\tBest loss: 1.781363\tAccuracy: 89.21%\n",
      "315\tValidation loss: 1.781249\tBest loss: 1.781249\tAccuracy: 89.21%\n",
      "316\tValidation loss: 1.781133\tBest loss: 1.781133\tAccuracy: 89.21%\n",
      "317\tValidation loss: 1.781014\tBest loss: 1.781014\tAccuracy: 89.21%\n",
      "318\tValidation loss: 1.780928\tBest loss: 1.780928\tAccuracy: 89.21%\n",
      "319\tValidation loss: 1.780815\tBest loss: 1.780815\tAccuracy: 89.21%\n",
      "320\tValidation loss: 1.780698\tBest loss: 1.780698\tAccuracy: 89.21%\n",
      "321\tValidation loss: 1.780580\tBest loss: 1.780580\tAccuracy: 89.21%\n",
      "322\tValidation loss: 1.780473\tBest loss: 1.780473\tAccuracy: 89.21%\n",
      "323\tValidation loss: 1.780369\tBest loss: 1.780369\tAccuracy: 89.21%\n",
      "324\tValidation loss: 1.780254\tBest loss: 1.780254\tAccuracy: 89.21%\n",
      "325\tValidation loss: 1.780144\tBest loss: 1.780144\tAccuracy: 89.21%\n",
      "326\tValidation loss: 1.780044\tBest loss: 1.780044\tAccuracy: 89.21%\n",
      "327\tValidation loss: 1.779943\tBest loss: 1.779943\tAccuracy: 89.21%\n",
      "328\tValidation loss: 1.779818\tBest loss: 1.779818\tAccuracy: 89.21%\n",
      "329\tValidation loss: 1.779709\tBest loss: 1.779709\tAccuracy: 89.21%\n",
      "330\tValidation loss: 1.779611\tBest loss: 1.779611\tAccuracy: 89.21%\n",
      "331\tValidation loss: 1.779499\tBest loss: 1.779499\tAccuracy: 89.21%\n",
      "332\tValidation loss: 1.779400\tBest loss: 1.779400\tAccuracy: 89.21%\n",
      "333\tValidation loss: 1.779277\tBest loss: 1.779277\tAccuracy: 89.21%\n",
      "334\tValidation loss: 1.779182\tBest loss: 1.779182\tAccuracy: 89.21%\n",
      "335\tValidation loss: 1.779088\tBest loss: 1.779088\tAccuracy: 89.21%\n",
      "336\tValidation loss: 1.778972\tBest loss: 1.778972\tAccuracy: 89.21%\n",
      "337\tValidation loss: 1.778866\tBest loss: 1.778866\tAccuracy: 89.21%\n",
      "338\tValidation loss: 1.778762\tBest loss: 1.778762\tAccuracy: 89.21%\n",
      "339\tValidation loss: 1.778670\tBest loss: 1.778670\tAccuracy: 89.21%\n",
      "340\tValidation loss: 1.778576\tBest loss: 1.778576\tAccuracy: 89.21%\n",
      "341\tValidation loss: 1.778470\tBest loss: 1.778470\tAccuracy: 89.21%\n",
      "342\tValidation loss: 1.778365\tBest loss: 1.778365\tAccuracy: 89.21%\n",
      "343\tValidation loss: 1.778253\tBest loss: 1.778253\tAccuracy: 89.21%\n",
      "344\tValidation loss: 1.778149\tBest loss: 1.778149\tAccuracy: 89.21%\n",
      "345\tValidation loss: 1.778065\tBest loss: 1.778065\tAccuracy: 89.21%\n",
      "346\tValidation loss: 1.777976\tBest loss: 1.777976\tAccuracy: 89.21%\n",
      "347\tValidation loss: 1.777883\tBest loss: 1.777883\tAccuracy: 89.21%\n",
      "348\tValidation loss: 1.777770\tBest loss: 1.777770\tAccuracy: 89.21%\n",
      "349\tValidation loss: 1.777664\tBest loss: 1.777664\tAccuracy: 89.21%\n",
      "350\tValidation loss: 1.777584\tBest loss: 1.777584\tAccuracy: 89.21%\n",
      "351\tValidation loss: 1.777494\tBest loss: 1.777494\tAccuracy: 89.21%\n",
      "352\tValidation loss: 1.777411\tBest loss: 1.777411\tAccuracy: 89.21%\n",
      "353\tValidation loss: 1.777298\tBest loss: 1.777298\tAccuracy: 89.21%\n",
      "354\tValidation loss: 1.777212\tBest loss: 1.777212\tAccuracy: 89.21%\n",
      "355\tValidation loss: 1.777112\tBest loss: 1.777112\tAccuracy: 89.21%\n",
      "356\tValidation loss: 1.776997\tBest loss: 1.776997\tAccuracy: 89.21%\n",
      "357\tValidation loss: 1.776895\tBest loss: 1.776895\tAccuracy: 89.21%\n",
      "358\tValidation loss: 1.776790\tBest loss: 1.776790\tAccuracy: 89.21%\n",
      "359\tValidation loss: 1.776721\tBest loss: 1.776721\tAccuracy: 89.21%\n",
      "360\tValidation loss: 1.776623\tBest loss: 1.776623\tAccuracy: 89.21%\n",
      "361\tValidation loss: 1.776529\tBest loss: 1.776529\tAccuracy: 89.21%\n",
      "362\tValidation loss: 1.776443\tBest loss: 1.776443\tAccuracy: 89.21%\n",
      "363\tValidation loss: 1.776345\tBest loss: 1.776345\tAccuracy: 89.21%\n",
      "364\tValidation loss: 1.776263\tBest loss: 1.776263\tAccuracy: 89.21%\n",
      "365\tValidation loss: 1.776177\tBest loss: 1.776177\tAccuracy: 89.21%\n",
      "366\tValidation loss: 1.776091\tBest loss: 1.776091\tAccuracy: 89.21%\n",
      "367\tValidation loss: 1.775998\tBest loss: 1.775998\tAccuracy: 89.21%\n",
      "368\tValidation loss: 1.775905\tBest loss: 1.775905\tAccuracy: 89.21%\n",
      "369\tValidation loss: 1.775809\tBest loss: 1.775809\tAccuracy: 89.21%\n",
      "370\tValidation loss: 1.775737\tBest loss: 1.775737\tAccuracy: 89.21%\n",
      "371\tValidation loss: 1.775631\tBest loss: 1.775631\tAccuracy: 89.21%\n",
      "372\tValidation loss: 1.775534\tBest loss: 1.775534\tAccuracy: 89.21%\n",
      "373\tValidation loss: 1.775439\tBest loss: 1.775439\tAccuracy: 89.21%\n",
      "374\tValidation loss: 1.775365\tBest loss: 1.775365\tAccuracy: 89.21%\n",
      "375\tValidation loss: 1.775275\tBest loss: 1.775275\tAccuracy: 89.21%\n",
      "376\tValidation loss: 1.775203\tBest loss: 1.775203\tAccuracy: 89.21%\n",
      "377\tValidation loss: 1.775099\tBest loss: 1.775099\tAccuracy: 89.21%\n",
      "378\tValidation loss: 1.775009\tBest loss: 1.775009\tAccuracy: 89.21%\n",
      "379\tValidation loss: 1.774916\tBest loss: 1.774916\tAccuracy: 89.21%\n",
      "380\tValidation loss: 1.774817\tBest loss: 1.774817\tAccuracy: 89.21%\n",
      "381\tValidation loss: 1.774723\tBest loss: 1.774723\tAccuracy: 89.21%\n",
      "382\tValidation loss: 1.774629\tBest loss: 1.774629\tAccuracy: 89.21%\n",
      "383\tValidation loss: 1.774551\tBest loss: 1.774551\tAccuracy: 89.21%\n",
      "384\tValidation loss: 1.774459\tBest loss: 1.774459\tAccuracy: 89.21%\n",
      "385\tValidation loss: 1.774372\tBest loss: 1.774372\tAccuracy: 89.21%\n",
      "386\tValidation loss: 1.774281\tBest loss: 1.774281\tAccuracy: 89.21%\n",
      "387\tValidation loss: 1.774201\tBest loss: 1.774201\tAccuracy: 89.21%\n",
      "388\tValidation loss: 1.774093\tBest loss: 1.774093\tAccuracy: 89.21%\n",
      "389\tValidation loss: 1.774009\tBest loss: 1.774009\tAccuracy: 89.21%\n",
      "390\tValidation loss: 1.773933\tBest loss: 1.773933\tAccuracy: 89.21%\n",
      "391\tValidation loss: 1.773854\tBest loss: 1.773854\tAccuracy: 89.21%\n",
      "392\tValidation loss: 1.773766\tBest loss: 1.773766\tAccuracy: 89.21%\n",
      "393\tValidation loss: 1.773677\tBest loss: 1.773677\tAccuracy: 89.21%\n",
      "394\tValidation loss: 1.773595\tBest loss: 1.773595\tAccuracy: 89.21%\n",
      "395\tValidation loss: 1.773516\tBest loss: 1.773516\tAccuracy: 89.21%\n",
      "396\tValidation loss: 1.773430\tBest loss: 1.773430\tAccuracy: 89.21%\n",
      "397\tValidation loss: 1.773350\tBest loss: 1.773350\tAccuracy: 89.21%\n",
      "398\tValidation loss: 1.773270\tBest loss: 1.773270\tAccuracy: 89.21%\n",
      "399\tValidation loss: 1.773206\tBest loss: 1.773206\tAccuracy: 89.21%\n",
      "400\tValidation loss: 1.773119\tBest loss: 1.773119\tAccuracy: 89.21%\n",
      "401\tValidation loss: 1.773031\tBest loss: 1.773031\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\tValidation loss: 1.772958\tBest loss: 1.772958\tAccuracy: 89.21%\n",
      "403\tValidation loss: 1.772865\tBest loss: 1.772865\tAccuracy: 89.21%\n",
      "404\tValidation loss: 1.772793\tBest loss: 1.772793\tAccuracy: 89.21%\n",
      "405\tValidation loss: 1.772710\tBest loss: 1.772710\tAccuracy: 89.21%\n",
      "406\tValidation loss: 1.772631\tBest loss: 1.772631\tAccuracy: 89.21%\n",
      "407\tValidation loss: 1.772552\tBest loss: 1.772552\tAccuracy: 89.21%\n",
      "408\tValidation loss: 1.772478\tBest loss: 1.772478\tAccuracy: 89.21%\n",
      "409\tValidation loss: 1.772389\tBest loss: 1.772389\tAccuracy: 89.21%\n",
      "410\tValidation loss: 1.772327\tBest loss: 1.772327\tAccuracy: 89.21%\n",
      "411\tValidation loss: 1.772232\tBest loss: 1.772232\tAccuracy: 89.21%\n",
      "412\tValidation loss: 1.772156\tBest loss: 1.772156\tAccuracy: 89.21%\n",
      "413\tValidation loss: 1.772077\tBest loss: 1.772077\tAccuracy: 89.21%\n",
      "414\tValidation loss: 1.771999\tBest loss: 1.771999\tAccuracy: 89.21%\n",
      "415\tValidation loss: 1.771933\tBest loss: 1.771933\tAccuracy: 89.21%\n",
      "416\tValidation loss: 1.771837\tBest loss: 1.771837\tAccuracy: 89.21%\n",
      "417\tValidation loss: 1.771767\tBest loss: 1.771767\tAccuracy: 89.21%\n",
      "418\tValidation loss: 1.771699\tBest loss: 1.771699\tAccuracy: 89.21%\n",
      "419\tValidation loss: 1.771613\tBest loss: 1.771613\tAccuracy: 89.21%\n",
      "420\tValidation loss: 1.771524\tBest loss: 1.771524\tAccuracy: 89.21%\n",
      "421\tValidation loss: 1.771468\tBest loss: 1.771468\tAccuracy: 89.21%\n",
      "422\tValidation loss: 1.771394\tBest loss: 1.771394\tAccuracy: 89.21%\n",
      "423\tValidation loss: 1.771328\tBest loss: 1.771328\tAccuracy: 89.21%\n",
      "424\tValidation loss: 1.771234\tBest loss: 1.771234\tAccuracy: 89.21%\n",
      "425\tValidation loss: 1.771150\tBest loss: 1.771150\tAccuracy: 89.21%\n",
      "426\tValidation loss: 1.771079\tBest loss: 1.771079\tAccuracy: 89.21%\n",
      "427\tValidation loss: 1.771016\tBest loss: 1.771016\tAccuracy: 89.21%\n",
      "428\tValidation loss: 1.770926\tBest loss: 1.770926\tAccuracy: 89.21%\n",
      "429\tValidation loss: 1.770845\tBest loss: 1.770845\tAccuracy: 89.21%\n",
      "430\tValidation loss: 1.770777\tBest loss: 1.770777\tAccuracy: 89.21%\n",
      "431\tValidation loss: 1.770711\tBest loss: 1.770711\tAccuracy: 89.21%\n",
      "432\tValidation loss: 1.770620\tBest loss: 1.770620\tAccuracy: 89.21%\n",
      "433\tValidation loss: 1.770544\tBest loss: 1.770544\tAccuracy: 89.21%\n",
      "434\tValidation loss: 1.770463\tBest loss: 1.770463\tAccuracy: 89.21%\n",
      "435\tValidation loss: 1.770378\tBest loss: 1.770378\tAccuracy: 89.21%\n",
      "436\tValidation loss: 1.770327\tBest loss: 1.770327\tAccuracy: 89.21%\n",
      "437\tValidation loss: 1.770250\tBest loss: 1.770250\tAccuracy: 89.21%\n",
      "438\tValidation loss: 1.770177\tBest loss: 1.770177\tAccuracy: 89.21%\n",
      "439\tValidation loss: 1.770113\tBest loss: 1.770113\tAccuracy: 89.21%\n",
      "440\tValidation loss: 1.770040\tBest loss: 1.770040\tAccuracy: 89.21%\n",
      "441\tValidation loss: 1.769956\tBest loss: 1.769956\tAccuracy: 89.21%\n",
      "442\tValidation loss: 1.769907\tBest loss: 1.769907\tAccuracy: 89.21%\n",
      "443\tValidation loss: 1.769825\tBest loss: 1.769825\tAccuracy: 89.21%\n",
      "444\tValidation loss: 1.769756\tBest loss: 1.769756\tAccuracy: 89.21%\n",
      "445\tValidation loss: 1.769681\tBest loss: 1.769681\tAccuracy: 89.21%\n",
      "446\tValidation loss: 1.769600\tBest loss: 1.769600\tAccuracy: 89.21%\n",
      "447\tValidation loss: 1.769554\tBest loss: 1.769554\tAccuracy: 89.21%\n",
      "448\tValidation loss: 1.769476\tBest loss: 1.769476\tAccuracy: 89.21%\n",
      "449\tValidation loss: 1.769411\tBest loss: 1.769411\tAccuracy: 89.21%\n",
      "450\tValidation loss: 1.769332\tBest loss: 1.769332\tAccuracy: 89.21%\n",
      "451\tValidation loss: 1.769263\tBest loss: 1.769263\tAccuracy: 89.21%\n",
      "452\tValidation loss: 1.769220\tBest loss: 1.769220\tAccuracy: 89.21%\n",
      "453\tValidation loss: 1.769139\tBest loss: 1.769139\tAccuracy: 89.21%\n",
      "454\tValidation loss: 1.769060\tBest loss: 1.769060\tAccuracy: 89.21%\n",
      "455\tValidation loss: 1.768986\tBest loss: 1.768986\tAccuracy: 89.21%\n",
      "456\tValidation loss: 1.768915\tBest loss: 1.768915\tAccuracy: 89.21%\n",
      "457\tValidation loss: 1.768857\tBest loss: 1.768857\tAccuracy: 89.21%\n",
      "458\tValidation loss: 1.768778\tBest loss: 1.768778\tAccuracy: 89.21%\n",
      "459\tValidation loss: 1.768709\tBest loss: 1.768709\tAccuracy: 89.21%\n",
      "460\tValidation loss: 1.768643\tBest loss: 1.768643\tAccuracy: 89.21%\n",
      "461\tValidation loss: 1.768574\tBest loss: 1.768574\tAccuracy: 89.21%\n",
      "462\tValidation loss: 1.768517\tBest loss: 1.768517\tAccuracy: 89.21%\n",
      "463\tValidation loss: 1.768435\tBest loss: 1.768435\tAccuracy: 89.21%\n",
      "464\tValidation loss: 1.768361\tBest loss: 1.768361\tAccuracy: 89.21%\n",
      "465\tValidation loss: 1.768301\tBest loss: 1.768301\tAccuracy: 89.21%\n",
      "466\tValidation loss: 1.768234\tBest loss: 1.768234\tAccuracy: 89.21%\n",
      "467\tValidation loss: 1.768156\tBest loss: 1.768156\tAccuracy: 89.21%\n",
      "468\tValidation loss: 1.768095\tBest loss: 1.768095\tAccuracy: 89.21%\n",
      "469\tValidation loss: 1.768040\tBest loss: 1.768040\tAccuracy: 89.21%\n",
      "470\tValidation loss: 1.767964\tBest loss: 1.767964\tAccuracy: 89.21%\n",
      "471\tValidation loss: 1.767905\tBest loss: 1.767905\tAccuracy: 89.21%\n",
      "472\tValidation loss: 1.767843\tBest loss: 1.767843\tAccuracy: 89.21%\n",
      "473\tValidation loss: 1.767770\tBest loss: 1.767770\tAccuracy: 89.21%\n",
      "474\tValidation loss: 1.767684\tBest loss: 1.767684\tAccuracy: 89.21%\n",
      "475\tValidation loss: 1.767609\tBest loss: 1.767609\tAccuracy: 89.21%\n",
      "476\tValidation loss: 1.767540\tBest loss: 1.767540\tAccuracy: 89.21%\n",
      "477\tValidation loss: 1.767481\tBest loss: 1.767481\tAccuracy: 89.21%\n",
      "478\tValidation loss: 1.767403\tBest loss: 1.767403\tAccuracy: 89.21%\n",
      "479\tValidation loss: 1.767348\tBest loss: 1.767348\tAccuracy: 89.21%\n",
      "480\tValidation loss: 1.767295\tBest loss: 1.767295\tAccuracy: 89.21%\n",
      "481\tValidation loss: 1.767231\tBest loss: 1.767231\tAccuracy: 89.21%\n",
      "482\tValidation loss: 1.767154\tBest loss: 1.767154\tAccuracy: 89.21%\n",
      "483\tValidation loss: 1.767095\tBest loss: 1.767095\tAccuracy: 89.21%\n",
      "484\tValidation loss: 1.767031\tBest loss: 1.767031\tAccuracy: 89.21%\n",
      "485\tValidation loss: 1.766966\tBest loss: 1.766966\tAccuracy: 89.21%\n",
      "486\tValidation loss: 1.766896\tBest loss: 1.766896\tAccuracy: 89.21%\n",
      "487\tValidation loss: 1.766840\tBest loss: 1.766840\tAccuracy: 89.21%\n",
      "488\tValidation loss: 1.766767\tBest loss: 1.766767\tAccuracy: 89.21%\n",
      "489\tValidation loss: 1.766701\tBest loss: 1.766701\tAccuracy: 89.21%\n",
      "490\tValidation loss: 1.766635\tBest loss: 1.766635\tAccuracy: 89.21%\n",
      "491\tValidation loss: 1.766567\tBest loss: 1.766567\tAccuracy: 89.21%\n",
      "492\tValidation loss: 1.766512\tBest loss: 1.766512\tAccuracy: 89.21%\n",
      "493\tValidation loss: 1.766440\tBest loss: 1.766440\tAccuracy: 89.21%\n",
      "494\tValidation loss: 1.766361\tBest loss: 1.766361\tAccuracy: 89.21%\n",
      "495\tValidation loss: 1.766309\tBest loss: 1.766309\tAccuracy: 89.21%\n",
      "496\tValidation loss: 1.766254\tBest loss: 1.766254\tAccuracy: 89.21%\n",
      "497\tValidation loss: 1.766193\tBest loss: 1.766193\tAccuracy: 89.21%\n",
      "498\tValidation loss: 1.766127\tBest loss: 1.766127\tAccuracy: 89.21%\n",
      "499\tValidation loss: 1.766063\tBest loss: 1.766063\tAccuracy: 89.21%\n",
      "500\tValidation loss: 1.765991\tBest loss: 1.765991\tAccuracy: 89.21%\n",
      "501\tValidation loss: 1.765931\tBest loss: 1.765931\tAccuracy: 89.21%\n",
      "502\tValidation loss: 1.765870\tBest loss: 1.765870\tAccuracy: 89.21%\n",
      "503\tValidation loss: 1.765813\tBest loss: 1.765813\tAccuracy: 89.21%\n",
      "504\tValidation loss: 1.765749\tBest loss: 1.765749\tAccuracy: 89.21%\n",
      "505\tValidation loss: 1.765696\tBest loss: 1.765696\tAccuracy: 89.21%\n",
      "506\tValidation loss: 1.765642\tBest loss: 1.765642\tAccuracy: 89.21%\n",
      "507\tValidation loss: 1.765568\tBest loss: 1.765568\tAccuracy: 89.21%\n",
      "508\tValidation loss: 1.765507\tBest loss: 1.765507\tAccuracy: 89.21%\n",
      "509\tValidation loss: 1.765450\tBest loss: 1.765450\tAccuracy: 89.21%\n",
      "510\tValidation loss: 1.765384\tBest loss: 1.765384\tAccuracy: 89.21%\n",
      "511\tValidation loss: 1.765332\tBest loss: 1.765332\tAccuracy: 89.21%\n",
      "512\tValidation loss: 1.765270\tBest loss: 1.765270\tAccuracy: 89.21%\n",
      "513\tValidation loss: 1.765218\tBest loss: 1.765218\tAccuracy: 89.21%\n",
      "514\tValidation loss: 1.765170\tBest loss: 1.765170\tAccuracy: 89.21%\n",
      "515\tValidation loss: 1.765124\tBest loss: 1.765124\tAccuracy: 89.21%\n",
      "516\tValidation loss: 1.765051\tBest loss: 1.765051\tAccuracy: 89.21%\n",
      "517\tValidation loss: 1.764977\tBest loss: 1.764977\tAccuracy: 89.21%\n",
      "518\tValidation loss: 1.764918\tBest loss: 1.764918\tAccuracy: 89.21%\n",
      "519\tValidation loss: 1.764847\tBest loss: 1.764847\tAccuracy: 89.21%\n",
      "520\tValidation loss: 1.764779\tBest loss: 1.764779\tAccuracy: 89.21%\n",
      "521\tValidation loss: 1.764711\tBest loss: 1.764711\tAccuracy: 89.21%\n",
      "522\tValidation loss: 1.764666\tBest loss: 1.764666\tAccuracy: 89.21%\n",
      "523\tValidation loss: 1.764606\tBest loss: 1.764606\tAccuracy: 89.21%\n",
      "524\tValidation loss: 1.764546\tBest loss: 1.764546\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\tValidation loss: 1.764500\tBest loss: 1.764500\tAccuracy: 89.21%\n",
      "526\tValidation loss: 1.764448\tBest loss: 1.764448\tAccuracy: 89.21%\n",
      "527\tValidation loss: 1.764391\tBest loss: 1.764391\tAccuracy: 89.21%\n",
      "528\tValidation loss: 1.764335\tBest loss: 1.764335\tAccuracy: 89.21%\n",
      "529\tValidation loss: 1.764280\tBest loss: 1.764280\tAccuracy: 89.21%\n",
      "530\tValidation loss: 1.764207\tBest loss: 1.764207\tAccuracy: 89.21%\n",
      "531\tValidation loss: 1.764153\tBest loss: 1.764153\tAccuracy: 89.21%\n",
      "532\tValidation loss: 1.764091\tBest loss: 1.764091\tAccuracy: 89.21%\n",
      "533\tValidation loss: 1.764045\tBest loss: 1.764045\tAccuracy: 89.21%\n",
      "534\tValidation loss: 1.763986\tBest loss: 1.763986\tAccuracy: 89.21%\n",
      "535\tValidation loss: 1.763910\tBest loss: 1.763910\tAccuracy: 89.21%\n",
      "536\tValidation loss: 1.763857\tBest loss: 1.763857\tAccuracy: 89.21%\n",
      "537\tValidation loss: 1.763800\tBest loss: 1.763800\tAccuracy: 89.21%\n",
      "538\tValidation loss: 1.763744\tBest loss: 1.763744\tAccuracy: 89.21%\n",
      "539\tValidation loss: 1.763687\tBest loss: 1.763687\tAccuracy: 89.21%\n",
      "540\tValidation loss: 1.763639\tBest loss: 1.763639\tAccuracy: 89.21%\n",
      "541\tValidation loss: 1.763593\tBest loss: 1.763593\tAccuracy: 89.21%\n",
      "542\tValidation loss: 1.763523\tBest loss: 1.763523\tAccuracy: 89.21%\n",
      "543\tValidation loss: 1.763467\tBest loss: 1.763467\tAccuracy: 89.21%\n",
      "544\tValidation loss: 1.763416\tBest loss: 1.763416\tAccuracy: 89.21%\n",
      "545\tValidation loss: 1.763366\tBest loss: 1.763366\tAccuracy: 89.21%\n",
      "546\tValidation loss: 1.763313\tBest loss: 1.763313\tAccuracy: 89.21%\n",
      "547\tValidation loss: 1.763247\tBest loss: 1.763247\tAccuracy: 89.21%\n",
      "548\tValidation loss: 1.763181\tBest loss: 1.763181\tAccuracy: 89.21%\n",
      "549\tValidation loss: 1.763142\tBest loss: 1.763142\tAccuracy: 89.21%\n",
      "550\tValidation loss: 1.763078\tBest loss: 1.763078\tAccuracy: 89.21%\n",
      "551\tValidation loss: 1.763036\tBest loss: 1.763036\tAccuracy: 89.21%\n",
      "552\tValidation loss: 1.762956\tBest loss: 1.762956\tAccuracy: 89.21%\n",
      "553\tValidation loss: 1.762897\tBest loss: 1.762897\tAccuracy: 89.21%\n",
      "554\tValidation loss: 1.762849\tBest loss: 1.762849\tAccuracy: 89.21%\n",
      "555\tValidation loss: 1.762786\tBest loss: 1.762786\tAccuracy: 89.21%\n",
      "556\tValidation loss: 1.762738\tBest loss: 1.762738\tAccuracy: 89.21%\n",
      "557\tValidation loss: 1.762676\tBest loss: 1.762676\tAccuracy: 89.21%\n",
      "558\tValidation loss: 1.762607\tBest loss: 1.762607\tAccuracy: 89.21%\n",
      "559\tValidation loss: 1.762555\tBest loss: 1.762555\tAccuracy: 89.21%\n",
      "560\tValidation loss: 1.762506\tBest loss: 1.762506\tAccuracy: 89.21%\n",
      "561\tValidation loss: 1.762453\tBest loss: 1.762453\tAccuracy: 89.21%\n",
      "562\tValidation loss: 1.762397\tBest loss: 1.762397\tAccuracy: 89.21%\n",
      "563\tValidation loss: 1.762332\tBest loss: 1.762332\tAccuracy: 89.21%\n",
      "564\tValidation loss: 1.762282\tBest loss: 1.762282\tAccuracy: 89.21%\n",
      "565\tValidation loss: 1.762221\tBest loss: 1.762221\tAccuracy: 89.21%\n",
      "566\tValidation loss: 1.762170\tBest loss: 1.762170\tAccuracy: 89.21%\n",
      "567\tValidation loss: 1.762121\tBest loss: 1.762121\tAccuracy: 89.21%\n",
      "568\tValidation loss: 1.762066\tBest loss: 1.762066\tAccuracy: 89.21%\n",
      "569\tValidation loss: 1.761999\tBest loss: 1.761999\tAccuracy: 89.21%\n",
      "570\tValidation loss: 1.761966\tBest loss: 1.761966\tAccuracy: 89.21%\n",
      "571\tValidation loss: 1.761903\tBest loss: 1.761903\tAccuracy: 89.21%\n",
      "572\tValidation loss: 1.761862\tBest loss: 1.761862\tAccuracy: 89.21%\n",
      "573\tValidation loss: 1.761798\tBest loss: 1.761798\tAccuracy: 89.21%\n",
      "574\tValidation loss: 1.761752\tBest loss: 1.761752\tAccuracy: 89.21%\n",
      "575\tValidation loss: 1.761694\tBest loss: 1.761694\tAccuracy: 89.21%\n",
      "576\tValidation loss: 1.761643\tBest loss: 1.761643\tAccuracy: 89.21%\n",
      "577\tValidation loss: 1.761582\tBest loss: 1.761582\tAccuracy: 89.21%\n",
      "578\tValidation loss: 1.761519\tBest loss: 1.761519\tAccuracy: 89.21%\n",
      "579\tValidation loss: 1.761466\tBest loss: 1.761466\tAccuracy: 89.21%\n",
      "580\tValidation loss: 1.761407\tBest loss: 1.761407\tAccuracy: 89.21%\n",
      "581\tValidation loss: 1.761362\tBest loss: 1.761362\tAccuracy: 89.21%\n",
      "582\tValidation loss: 1.761305\tBest loss: 1.761305\tAccuracy: 89.21%\n",
      "583\tValidation loss: 1.761267\tBest loss: 1.761267\tAccuracy: 89.21%\n",
      "584\tValidation loss: 1.761209\tBest loss: 1.761209\tAccuracy: 89.21%\n",
      "585\tValidation loss: 1.761150\tBest loss: 1.761150\tAccuracy: 89.21%\n",
      "586\tValidation loss: 1.761096\tBest loss: 1.761096\tAccuracy: 89.21%\n",
      "587\tValidation loss: 1.761045\tBest loss: 1.761045\tAccuracy: 89.21%\n",
      "588\tValidation loss: 1.760989\tBest loss: 1.760989\tAccuracy: 89.21%\n",
      "589\tValidation loss: 1.760926\tBest loss: 1.760926\tAccuracy: 89.21%\n",
      "590\tValidation loss: 1.760899\tBest loss: 1.760899\tAccuracy: 89.21%\n",
      "591\tValidation loss: 1.760855\tBest loss: 1.760855\tAccuracy: 89.21%\n",
      "592\tValidation loss: 1.760802\tBest loss: 1.760802\tAccuracy: 89.21%\n",
      "593\tValidation loss: 1.760754\tBest loss: 1.760754\tAccuracy: 89.21%\n",
      "594\tValidation loss: 1.760710\tBest loss: 1.760710\tAccuracy: 89.21%\n",
      "595\tValidation loss: 1.760662\tBest loss: 1.760662\tAccuracy: 89.21%\n",
      "596\tValidation loss: 1.760616\tBest loss: 1.760616\tAccuracy: 89.21%\n",
      "597\tValidation loss: 1.760553\tBest loss: 1.760553\tAccuracy: 89.21%\n",
      "598\tValidation loss: 1.760506\tBest loss: 1.760506\tAccuracy: 89.21%\n",
      "599\tValidation loss: 1.760452\tBest loss: 1.760452\tAccuracy: 89.21%\n",
      "600\tValidation loss: 1.760395\tBest loss: 1.760395\tAccuracy: 89.21%\n",
      "601\tValidation loss: 1.760335\tBest loss: 1.760335\tAccuracy: 89.21%\n",
      "602\tValidation loss: 1.760280\tBest loss: 1.760280\tAccuracy: 89.21%\n",
      "603\tValidation loss: 1.760243\tBest loss: 1.760243\tAccuracy: 89.21%\n",
      "604\tValidation loss: 1.760195\tBest loss: 1.760195\tAccuracy: 89.21%\n",
      "605\tValidation loss: 1.760160\tBest loss: 1.760160\tAccuracy: 89.21%\n",
      "606\tValidation loss: 1.760113\tBest loss: 1.760113\tAccuracy: 89.21%\n",
      "607\tValidation loss: 1.760059\tBest loss: 1.760059\tAccuracy: 89.21%\n",
      "608\tValidation loss: 1.760000\tBest loss: 1.760000\tAccuracy: 89.21%\n",
      "609\tValidation loss: 1.759952\tBest loss: 1.759952\tAccuracy: 89.21%\n",
      "610\tValidation loss: 1.759912\tBest loss: 1.759912\tAccuracy: 89.21%\n",
      "611\tValidation loss: 1.759857\tBest loss: 1.759857\tAccuracy: 89.21%\n",
      "612\tValidation loss: 1.759808\tBest loss: 1.759808\tAccuracy: 89.21%\n",
      "613\tValidation loss: 1.759756\tBest loss: 1.759756\tAccuracy: 89.21%\n",
      "614\tValidation loss: 1.759694\tBest loss: 1.759694\tAccuracy: 89.21%\n",
      "615\tValidation loss: 1.759676\tBest loss: 1.759676\tAccuracy: 89.21%\n",
      "616\tValidation loss: 1.759624\tBest loss: 1.759624\tAccuracy: 89.21%\n",
      "617\tValidation loss: 1.759567\tBest loss: 1.759567\tAccuracy: 89.21%\n",
      "618\tValidation loss: 1.759543\tBest loss: 1.759543\tAccuracy: 89.21%\n",
      "619\tValidation loss: 1.759491\tBest loss: 1.759491\tAccuracy: 89.21%\n",
      "620\tValidation loss: 1.759442\tBest loss: 1.759442\tAccuracy: 89.21%\n",
      "621\tValidation loss: 1.759386\tBest loss: 1.759386\tAccuracy: 89.21%\n",
      "622\tValidation loss: 1.759325\tBest loss: 1.759325\tAccuracy: 89.21%\n",
      "623\tValidation loss: 1.759276\tBest loss: 1.759276\tAccuracy: 89.21%\n",
      "624\tValidation loss: 1.759227\tBest loss: 1.759227\tAccuracy: 89.21%\n",
      "625\tValidation loss: 1.759186\tBest loss: 1.759186\tAccuracy: 89.21%\n",
      "626\tValidation loss: 1.759130\tBest loss: 1.759130\tAccuracy: 89.21%\n",
      "627\tValidation loss: 1.759082\tBest loss: 1.759082\tAccuracy: 89.21%\n",
      "628\tValidation loss: 1.759035\tBest loss: 1.759035\tAccuracy: 89.21%\n",
      "629\tValidation loss: 1.759000\tBest loss: 1.759000\tAccuracy: 89.21%\n",
      "630\tValidation loss: 1.758942\tBest loss: 1.758942\tAccuracy: 89.21%\n",
      "631\tValidation loss: 1.758896\tBest loss: 1.758896\tAccuracy: 89.21%\n",
      "632\tValidation loss: 1.758864\tBest loss: 1.758864\tAccuracy: 89.21%\n",
      "633\tValidation loss: 1.758796\tBest loss: 1.758796\tAccuracy: 89.21%\n",
      "634\tValidation loss: 1.758758\tBest loss: 1.758758\tAccuracy: 89.21%\n",
      "635\tValidation loss: 1.758699\tBest loss: 1.758699\tAccuracy: 89.21%\n",
      "636\tValidation loss: 1.758638\tBest loss: 1.758638\tAccuracy: 89.21%\n",
      "637\tValidation loss: 1.758596\tBest loss: 1.758596\tAccuracy: 89.21%\n",
      "638\tValidation loss: 1.758558\tBest loss: 1.758558\tAccuracy: 89.21%\n",
      "639\tValidation loss: 1.758513\tBest loss: 1.758513\tAccuracy: 89.21%\n",
      "640\tValidation loss: 1.758458\tBest loss: 1.758458\tAccuracy: 89.21%\n",
      "641\tValidation loss: 1.758406\tBest loss: 1.758406\tAccuracy: 89.21%\n",
      "642\tValidation loss: 1.758359\tBest loss: 1.758359\tAccuracy: 89.21%\n",
      "643\tValidation loss: 1.758315\tBest loss: 1.758315\tAccuracy: 89.21%\n",
      "644\tValidation loss: 1.758270\tBest loss: 1.758270\tAccuracy: 89.21%\n",
      "645\tValidation loss: 1.758219\tBest loss: 1.758219\tAccuracy: 89.21%\n",
      "646\tValidation loss: 1.758182\tBest loss: 1.758182\tAccuracy: 89.21%\n",
      "647\tValidation loss: 1.758129\tBest loss: 1.758129\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\tValidation loss: 1.758082\tBest loss: 1.758082\tAccuracy: 89.21%\n",
      "649\tValidation loss: 1.758046\tBest loss: 1.758046\tAccuracy: 89.21%\n",
      "650\tValidation loss: 1.758004\tBest loss: 1.758004\tAccuracy: 89.21%\n",
      "651\tValidation loss: 1.757954\tBest loss: 1.757954\tAccuracy: 89.21%\n",
      "652\tValidation loss: 1.757898\tBest loss: 1.757898\tAccuracy: 89.21%\n",
      "653\tValidation loss: 1.757849\tBest loss: 1.757849\tAccuracy: 89.21%\n",
      "654\tValidation loss: 1.757802\tBest loss: 1.757802\tAccuracy: 89.21%\n",
      "655\tValidation loss: 1.757753\tBest loss: 1.757753\tAccuracy: 89.21%\n",
      "656\tValidation loss: 1.757700\tBest loss: 1.757700\tAccuracy: 89.21%\n",
      "657\tValidation loss: 1.757663\tBest loss: 1.757663\tAccuracy: 89.21%\n",
      "658\tValidation loss: 1.757609\tBest loss: 1.757609\tAccuracy: 89.21%\n",
      "659\tValidation loss: 1.757567\tBest loss: 1.757567\tAccuracy: 89.21%\n",
      "660\tValidation loss: 1.757518\tBest loss: 1.757518\tAccuracy: 89.21%\n",
      "661\tValidation loss: 1.757477\tBest loss: 1.757477\tAccuracy: 89.21%\n",
      "662\tValidation loss: 1.757425\tBest loss: 1.757425\tAccuracy: 89.21%\n",
      "663\tValidation loss: 1.757393\tBest loss: 1.757393\tAccuracy: 89.21%\n",
      "664\tValidation loss: 1.757350\tBest loss: 1.757350\tAccuracy: 89.21%\n",
      "665\tValidation loss: 1.757285\tBest loss: 1.757285\tAccuracy: 89.21%\n",
      "666\tValidation loss: 1.757242\tBest loss: 1.757242\tAccuracy: 89.21%\n",
      "667\tValidation loss: 1.757199\tBest loss: 1.757199\tAccuracy: 89.21%\n",
      "668\tValidation loss: 1.757139\tBest loss: 1.757139\tAccuracy: 89.21%\n",
      "669\tValidation loss: 1.757098\tBest loss: 1.757098\tAccuracy: 89.21%\n",
      "670\tValidation loss: 1.757057\tBest loss: 1.757057\tAccuracy: 89.21%\n",
      "671\tValidation loss: 1.757023\tBest loss: 1.757023\tAccuracy: 89.21%\n",
      "672\tValidation loss: 1.756982\tBest loss: 1.756982\tAccuracy: 89.21%\n",
      "673\tValidation loss: 1.756930\tBest loss: 1.756930\tAccuracy: 89.21%\n",
      "674\tValidation loss: 1.756886\tBest loss: 1.756886\tAccuracy: 89.21%\n",
      "675\tValidation loss: 1.756840\tBest loss: 1.756840\tAccuracy: 89.21%\n",
      "676\tValidation loss: 1.756801\tBest loss: 1.756801\tAccuracy: 89.21%\n",
      "677\tValidation loss: 1.756750\tBest loss: 1.756750\tAccuracy: 89.21%\n",
      "678\tValidation loss: 1.756713\tBest loss: 1.756713\tAccuracy: 89.21%\n",
      "679\tValidation loss: 1.756668\tBest loss: 1.756668\tAccuracy: 89.21%\n",
      "680\tValidation loss: 1.756620\tBest loss: 1.756620\tAccuracy: 89.21%\n",
      "681\tValidation loss: 1.756586\tBest loss: 1.756586\tAccuracy: 89.21%\n",
      "682\tValidation loss: 1.756543\tBest loss: 1.756543\tAccuracy: 89.21%\n",
      "683\tValidation loss: 1.756494\tBest loss: 1.756494\tAccuracy: 89.21%\n",
      "684\tValidation loss: 1.756453\tBest loss: 1.756453\tAccuracy: 89.21%\n",
      "685\tValidation loss: 1.756405\tBest loss: 1.756405\tAccuracy: 89.21%\n",
      "686\tValidation loss: 1.756374\tBest loss: 1.756374\tAccuracy: 89.21%\n",
      "687\tValidation loss: 1.756318\tBest loss: 1.756318\tAccuracy: 89.21%\n",
      "688\tValidation loss: 1.756287\tBest loss: 1.756287\tAccuracy: 89.21%\n",
      "689\tValidation loss: 1.756247\tBest loss: 1.756247\tAccuracy: 89.21%\n",
      "690\tValidation loss: 1.756219\tBest loss: 1.756219\tAccuracy: 89.21%\n",
      "691\tValidation loss: 1.756172\tBest loss: 1.756172\tAccuracy: 89.21%\n",
      "692\tValidation loss: 1.756118\tBest loss: 1.756118\tAccuracy: 89.21%\n",
      "693\tValidation loss: 1.756086\tBest loss: 1.756086\tAccuracy: 89.21%\n",
      "694\tValidation loss: 1.756044\tBest loss: 1.756044\tAccuracy: 89.21%\n",
      "695\tValidation loss: 1.755994\tBest loss: 1.755994\tAccuracy: 89.21%\n",
      "696\tValidation loss: 1.755940\tBest loss: 1.755940\tAccuracy: 89.21%\n",
      "697\tValidation loss: 1.755901\tBest loss: 1.755901\tAccuracy: 89.21%\n",
      "698\tValidation loss: 1.755849\tBest loss: 1.755849\tAccuracy: 89.21%\n",
      "699\tValidation loss: 1.755799\tBest loss: 1.755799\tAccuracy: 89.21%\n",
      "700\tValidation loss: 1.755776\tBest loss: 1.755776\tAccuracy: 89.21%\n",
      "701\tValidation loss: 1.755723\tBest loss: 1.755723\tAccuracy: 89.21%\n",
      "702\tValidation loss: 1.755672\tBest loss: 1.755672\tAccuracy: 89.21%\n",
      "703\tValidation loss: 1.755619\tBest loss: 1.755619\tAccuracy: 89.21%\n",
      "704\tValidation loss: 1.755579\tBest loss: 1.755579\tAccuracy: 89.21%\n",
      "705\tValidation loss: 1.755545\tBest loss: 1.755545\tAccuracy: 89.21%\n",
      "706\tValidation loss: 1.755505\tBest loss: 1.755505\tAccuracy: 89.21%\n",
      "707\tValidation loss: 1.755464\tBest loss: 1.755464\tAccuracy: 89.21%\n",
      "708\tValidation loss: 1.755402\tBest loss: 1.755402\tAccuracy: 89.21%\n",
      "709\tValidation loss: 1.755355\tBest loss: 1.755355\tAccuracy: 89.21%\n",
      "710\tValidation loss: 1.755316\tBest loss: 1.755316\tAccuracy: 89.21%\n",
      "711\tValidation loss: 1.755275\tBest loss: 1.755275\tAccuracy: 89.21%\n",
      "712\tValidation loss: 1.755222\tBest loss: 1.755222\tAccuracy: 89.21%\n",
      "713\tValidation loss: 1.755170\tBest loss: 1.755170\tAccuracy: 89.21%\n",
      "714\tValidation loss: 1.755144\tBest loss: 1.755144\tAccuracy: 89.21%\n",
      "715\tValidation loss: 1.755109\tBest loss: 1.755109\tAccuracy: 89.21%\n",
      "716\tValidation loss: 1.755068\tBest loss: 1.755068\tAccuracy: 89.21%\n",
      "717\tValidation loss: 1.755030\tBest loss: 1.755030\tAccuracy: 89.21%\n",
      "718\tValidation loss: 1.754987\tBest loss: 1.754987\tAccuracy: 89.21%\n",
      "719\tValidation loss: 1.754946\tBest loss: 1.754946\tAccuracy: 89.21%\n",
      "720\tValidation loss: 1.754910\tBest loss: 1.754910\tAccuracy: 89.21%\n",
      "721\tValidation loss: 1.754869\tBest loss: 1.754869\tAccuracy: 89.21%\n",
      "722\tValidation loss: 1.754829\tBest loss: 1.754829\tAccuracy: 89.21%\n",
      "723\tValidation loss: 1.754781\tBest loss: 1.754781\tAccuracy: 89.21%\n",
      "724\tValidation loss: 1.754745\tBest loss: 1.754745\tAccuracy: 89.21%\n",
      "725\tValidation loss: 1.754696\tBest loss: 1.754696\tAccuracy: 89.21%\n",
      "726\tValidation loss: 1.754659\tBest loss: 1.754659\tAccuracy: 89.21%\n",
      "727\tValidation loss: 1.754613\tBest loss: 1.754613\tAccuracy: 89.21%\n",
      "728\tValidation loss: 1.754560\tBest loss: 1.754560\tAccuracy: 89.21%\n",
      "729\tValidation loss: 1.754511\tBest loss: 1.754511\tAccuracy: 89.21%\n",
      "730\tValidation loss: 1.754472\tBest loss: 1.754472\tAccuracy: 89.21%\n",
      "731\tValidation loss: 1.754438\tBest loss: 1.754438\tAccuracy: 89.21%\n",
      "732\tValidation loss: 1.754395\tBest loss: 1.754395\tAccuracy: 89.21%\n",
      "733\tValidation loss: 1.754360\tBest loss: 1.754360\tAccuracy: 89.21%\n",
      "734\tValidation loss: 1.754318\tBest loss: 1.754318\tAccuracy: 89.21%\n",
      "735\tValidation loss: 1.754275\tBest loss: 1.754275\tAccuracy: 89.21%\n",
      "736\tValidation loss: 1.754222\tBest loss: 1.754222\tAccuracy: 89.21%\n",
      "737\tValidation loss: 1.754183\tBest loss: 1.754183\tAccuracy: 89.21%\n",
      "738\tValidation loss: 1.754149\tBest loss: 1.754149\tAccuracy: 89.21%\n",
      "739\tValidation loss: 1.754098\tBest loss: 1.754098\tAccuracy: 89.21%\n",
      "740\tValidation loss: 1.754057\tBest loss: 1.754057\tAccuracy: 89.21%\n",
      "741\tValidation loss: 1.754014\tBest loss: 1.754014\tAccuracy: 89.21%\n",
      "742\tValidation loss: 1.753973\tBest loss: 1.753973\tAccuracy: 89.21%\n",
      "743\tValidation loss: 1.753930\tBest loss: 1.753930\tAccuracy: 89.21%\n",
      "744\tValidation loss: 1.753890\tBest loss: 1.753890\tAccuracy: 89.21%\n",
      "745\tValidation loss: 1.753854\tBest loss: 1.753854\tAccuracy: 89.21%\n",
      "746\tValidation loss: 1.753817\tBest loss: 1.753817\tAccuracy: 89.21%\n",
      "747\tValidation loss: 1.753781\tBest loss: 1.753781\tAccuracy: 89.21%\n",
      "748\tValidation loss: 1.753728\tBest loss: 1.753728\tAccuracy: 89.21%\n",
      "749\tValidation loss: 1.753677\tBest loss: 1.753677\tAccuracy: 89.21%\n",
      "750\tValidation loss: 1.753637\tBest loss: 1.753637\tAccuracy: 89.21%\n",
      "751\tValidation loss: 1.753598\tBest loss: 1.753598\tAccuracy: 89.21%\n",
      "752\tValidation loss: 1.753552\tBest loss: 1.753552\tAccuracy: 89.21%\n",
      "753\tValidation loss: 1.753513\tBest loss: 1.753513\tAccuracy: 89.21%\n",
      "754\tValidation loss: 1.753468\tBest loss: 1.753468\tAccuracy: 89.21%\n",
      "755\tValidation loss: 1.753425\tBest loss: 1.753425\tAccuracy: 89.21%\n",
      "756\tValidation loss: 1.753384\tBest loss: 1.753384\tAccuracy: 89.21%\n",
      "757\tValidation loss: 1.753347\tBest loss: 1.753347\tAccuracy: 89.21%\n",
      "758\tValidation loss: 1.753307\tBest loss: 1.753307\tAccuracy: 89.21%\n",
      "759\tValidation loss: 1.753264\tBest loss: 1.753264\tAccuracy: 89.21%\n",
      "760\tValidation loss: 1.753223\tBest loss: 1.753223\tAccuracy: 89.21%\n",
      "761\tValidation loss: 1.753178\tBest loss: 1.753178\tAccuracy: 89.21%\n",
      "762\tValidation loss: 1.753151\tBest loss: 1.753151\tAccuracy: 89.21%\n",
      "763\tValidation loss: 1.753093\tBest loss: 1.753093\tAccuracy: 89.21%\n",
      "764\tValidation loss: 1.753056\tBest loss: 1.753056\tAccuracy: 89.21%\n",
      "765\tValidation loss: 1.753013\tBest loss: 1.753013\tAccuracy: 89.21%\n",
      "766\tValidation loss: 1.752975\tBest loss: 1.752975\tAccuracy: 89.21%\n",
      "767\tValidation loss: 1.752947\tBest loss: 1.752947\tAccuracy: 89.21%\n",
      "768\tValidation loss: 1.752900\tBest loss: 1.752900\tAccuracy: 89.21%\n",
      "769\tValidation loss: 1.752859\tBest loss: 1.752859\tAccuracy: 89.21%\n",
      "770\tValidation loss: 1.752829\tBest loss: 1.752829\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\tValidation loss: 1.752784\tBest loss: 1.752784\tAccuracy: 89.21%\n",
      "772\tValidation loss: 1.752742\tBest loss: 1.752742\tAccuracy: 89.21%\n",
      "773\tValidation loss: 1.752696\tBest loss: 1.752696\tAccuracy: 89.21%\n",
      "774\tValidation loss: 1.752672\tBest loss: 1.752672\tAccuracy: 89.21%\n",
      "775\tValidation loss: 1.752625\tBest loss: 1.752625\tAccuracy: 89.21%\n",
      "776\tValidation loss: 1.752575\tBest loss: 1.752575\tAccuracy: 89.21%\n",
      "777\tValidation loss: 1.752550\tBest loss: 1.752550\tAccuracy: 89.21%\n",
      "778\tValidation loss: 1.752508\tBest loss: 1.752508\tAccuracy: 89.21%\n",
      "779\tValidation loss: 1.752461\tBest loss: 1.752461\tAccuracy: 89.21%\n",
      "780\tValidation loss: 1.752411\tBest loss: 1.752411\tAccuracy: 89.21%\n",
      "781\tValidation loss: 1.752369\tBest loss: 1.752369\tAccuracy: 89.21%\n",
      "782\tValidation loss: 1.752317\tBest loss: 1.752317\tAccuracy: 89.21%\n",
      "783\tValidation loss: 1.752283\tBest loss: 1.752283\tAccuracy: 89.21%\n",
      "784\tValidation loss: 1.752244\tBest loss: 1.752244\tAccuracy: 89.21%\n",
      "785\tValidation loss: 1.752207\tBest loss: 1.752207\tAccuracy: 89.21%\n",
      "786\tValidation loss: 1.752165\tBest loss: 1.752165\tAccuracy: 89.21%\n",
      "787\tValidation loss: 1.752131\tBest loss: 1.752131\tAccuracy: 89.21%\n",
      "788\tValidation loss: 1.752074\tBest loss: 1.752074\tAccuracy: 89.21%\n",
      "789\tValidation loss: 1.752021\tBest loss: 1.752021\tAccuracy: 89.21%\n",
      "790\tValidation loss: 1.751973\tBest loss: 1.751973\tAccuracy: 89.21%\n",
      "791\tValidation loss: 1.751935\tBest loss: 1.751935\tAccuracy: 89.21%\n",
      "792\tValidation loss: 1.751896\tBest loss: 1.751896\tAccuracy: 89.21%\n",
      "793\tValidation loss: 1.751859\tBest loss: 1.751859\tAccuracy: 89.21%\n",
      "794\tValidation loss: 1.751833\tBest loss: 1.751833\tAccuracy: 89.21%\n",
      "795\tValidation loss: 1.751796\tBest loss: 1.751796\tAccuracy: 89.21%\n",
      "796\tValidation loss: 1.751750\tBest loss: 1.751750\tAccuracy: 89.21%\n",
      "797\tValidation loss: 1.751711\tBest loss: 1.751711\tAccuracy: 89.21%\n",
      "798\tValidation loss: 1.751676\tBest loss: 1.751676\tAccuracy: 89.21%\n",
      "799\tValidation loss: 1.751638\tBest loss: 1.751638\tAccuracy: 89.21%\n",
      "800\tValidation loss: 1.751603\tBest loss: 1.751603\tAccuracy: 89.21%\n",
      "801\tValidation loss: 1.751568\tBest loss: 1.751568\tAccuracy: 89.21%\n",
      "802\tValidation loss: 1.751530\tBest loss: 1.751530\tAccuracy: 89.21%\n",
      "803\tValidation loss: 1.751496\tBest loss: 1.751496\tAccuracy: 89.21%\n",
      "804\tValidation loss: 1.751461\tBest loss: 1.751461\tAccuracy: 89.21%\n",
      "805\tValidation loss: 1.751405\tBest loss: 1.751405\tAccuracy: 89.21%\n",
      "806\tValidation loss: 1.751379\tBest loss: 1.751379\tAccuracy: 89.21%\n",
      "807\tValidation loss: 1.751338\tBest loss: 1.751338\tAccuracy: 89.21%\n",
      "808\tValidation loss: 1.751292\tBest loss: 1.751292\tAccuracy: 89.21%\n",
      "809\tValidation loss: 1.751258\tBest loss: 1.751258\tAccuracy: 89.21%\n",
      "810\tValidation loss: 1.751230\tBest loss: 1.751230\tAccuracy: 89.21%\n",
      "811\tValidation loss: 1.751186\tBest loss: 1.751186\tAccuracy: 89.21%\n",
      "812\tValidation loss: 1.751137\tBest loss: 1.751137\tAccuracy: 89.21%\n",
      "813\tValidation loss: 1.751097\tBest loss: 1.751097\tAccuracy: 89.21%\n",
      "814\tValidation loss: 1.751068\tBest loss: 1.751068\tAccuracy: 89.21%\n",
      "815\tValidation loss: 1.751025\tBest loss: 1.751025\tAccuracy: 89.21%\n",
      "816\tValidation loss: 1.750995\tBest loss: 1.750995\tAccuracy: 89.21%\n",
      "817\tValidation loss: 1.750954\tBest loss: 1.750954\tAccuracy: 89.21%\n",
      "818\tValidation loss: 1.750909\tBest loss: 1.750909\tAccuracy: 89.21%\n",
      "819\tValidation loss: 1.750879\tBest loss: 1.750879\tAccuracy: 89.21%\n",
      "820\tValidation loss: 1.750843\tBest loss: 1.750843\tAccuracy: 89.21%\n",
      "821\tValidation loss: 1.750808\tBest loss: 1.750808\tAccuracy: 89.21%\n",
      "822\tValidation loss: 1.750779\tBest loss: 1.750779\tAccuracy: 89.21%\n",
      "823\tValidation loss: 1.750735\tBest loss: 1.750735\tAccuracy: 89.21%\n",
      "824\tValidation loss: 1.750695\tBest loss: 1.750695\tAccuracy: 89.21%\n",
      "825\tValidation loss: 1.750651\tBest loss: 1.750651\tAccuracy: 89.21%\n",
      "826\tValidation loss: 1.750619\tBest loss: 1.750619\tAccuracy: 89.21%\n",
      "827\tValidation loss: 1.750587\tBest loss: 1.750587\tAccuracy: 89.21%\n",
      "828\tValidation loss: 1.750545\tBest loss: 1.750545\tAccuracy: 89.21%\n",
      "829\tValidation loss: 1.750505\tBest loss: 1.750505\tAccuracy: 89.21%\n",
      "830\tValidation loss: 1.750464\tBest loss: 1.750464\tAccuracy: 89.21%\n",
      "831\tValidation loss: 1.750429\tBest loss: 1.750429\tAccuracy: 89.21%\n",
      "832\tValidation loss: 1.750388\tBest loss: 1.750388\tAccuracy: 89.21%\n",
      "833\tValidation loss: 1.750358\tBest loss: 1.750358\tAccuracy: 89.21%\n",
      "834\tValidation loss: 1.750314\tBest loss: 1.750314\tAccuracy: 89.21%\n",
      "835\tValidation loss: 1.750288\tBest loss: 1.750288\tAccuracy: 89.21%\n",
      "836\tValidation loss: 1.750257\tBest loss: 1.750257\tAccuracy: 89.21%\n",
      "837\tValidation loss: 1.750229\tBest loss: 1.750229\tAccuracy: 89.21%\n",
      "838\tValidation loss: 1.750184\tBest loss: 1.750184\tAccuracy: 89.21%\n",
      "839\tValidation loss: 1.750140\tBest loss: 1.750140\tAccuracy: 89.21%\n",
      "840\tValidation loss: 1.750094\tBest loss: 1.750094\tAccuracy: 89.21%\n",
      "841\tValidation loss: 1.750067\tBest loss: 1.750067\tAccuracy: 89.21%\n",
      "842\tValidation loss: 1.750044\tBest loss: 1.750044\tAccuracy: 89.21%\n",
      "843\tValidation loss: 1.749999\tBest loss: 1.749999\tAccuracy: 89.21%\n",
      "844\tValidation loss: 1.749962\tBest loss: 1.749962\tAccuracy: 89.21%\n",
      "845\tValidation loss: 1.749932\tBest loss: 1.749932\tAccuracy: 89.21%\n",
      "846\tValidation loss: 1.749893\tBest loss: 1.749893\tAccuracy: 89.21%\n",
      "847\tValidation loss: 1.749856\tBest loss: 1.749856\tAccuracy: 89.21%\n",
      "848\tValidation loss: 1.749813\tBest loss: 1.749813\tAccuracy: 89.21%\n",
      "849\tValidation loss: 1.749771\tBest loss: 1.749771\tAccuracy: 89.21%\n",
      "850\tValidation loss: 1.749733\tBest loss: 1.749733\tAccuracy: 89.21%\n",
      "851\tValidation loss: 1.749701\tBest loss: 1.749701\tAccuracy: 89.21%\n",
      "852\tValidation loss: 1.749663\tBest loss: 1.749663\tAccuracy: 89.21%\n",
      "853\tValidation loss: 1.749626\tBest loss: 1.749626\tAccuracy: 89.21%\n",
      "854\tValidation loss: 1.749589\tBest loss: 1.749589\tAccuracy: 89.21%\n",
      "855\tValidation loss: 1.749549\tBest loss: 1.749549\tAccuracy: 89.21%\n",
      "856\tValidation loss: 1.749510\tBest loss: 1.749510\tAccuracy: 89.21%\n",
      "857\tValidation loss: 1.749471\tBest loss: 1.749471\tAccuracy: 89.21%\n",
      "858\tValidation loss: 1.749429\tBest loss: 1.749429\tAccuracy: 89.21%\n",
      "859\tValidation loss: 1.749400\tBest loss: 1.749400\tAccuracy: 89.21%\n",
      "860\tValidation loss: 1.749364\tBest loss: 1.749364\tAccuracy: 89.21%\n",
      "861\tValidation loss: 1.749318\tBest loss: 1.749318\tAccuracy: 89.21%\n",
      "862\tValidation loss: 1.749283\tBest loss: 1.749283\tAccuracy: 89.21%\n",
      "863\tValidation loss: 1.749242\tBest loss: 1.749242\tAccuracy: 89.21%\n",
      "864\tValidation loss: 1.749213\tBest loss: 1.749213\tAccuracy: 89.21%\n",
      "865\tValidation loss: 1.749176\tBest loss: 1.749176\tAccuracy: 89.21%\n",
      "866\tValidation loss: 1.749135\tBest loss: 1.749135\tAccuracy: 89.21%\n",
      "867\tValidation loss: 1.749107\tBest loss: 1.749107\tAccuracy: 89.21%\n",
      "868\tValidation loss: 1.749073\tBest loss: 1.749073\tAccuracy: 89.21%\n",
      "869\tValidation loss: 1.749030\tBest loss: 1.749030\tAccuracy: 89.21%\n",
      "870\tValidation loss: 1.748993\tBest loss: 1.748993\tAccuracy: 89.21%\n",
      "871\tValidation loss: 1.748946\tBest loss: 1.748946\tAccuracy: 89.21%\n",
      "872\tValidation loss: 1.748920\tBest loss: 1.748920\tAccuracy: 89.21%\n",
      "873\tValidation loss: 1.748878\tBest loss: 1.748878\tAccuracy: 89.21%\n",
      "874\tValidation loss: 1.748842\tBest loss: 1.748842\tAccuracy: 89.21%\n",
      "875\tValidation loss: 1.748806\tBest loss: 1.748806\tAccuracy: 89.21%\n",
      "876\tValidation loss: 1.748778\tBest loss: 1.748778\tAccuracy: 89.21%\n",
      "877\tValidation loss: 1.748745\tBest loss: 1.748745\tAccuracy: 89.21%\n",
      "878\tValidation loss: 1.748704\tBest loss: 1.748704\tAccuracy: 89.21%\n",
      "879\tValidation loss: 1.748666\tBest loss: 1.748666\tAccuracy: 89.21%\n",
      "880\tValidation loss: 1.748615\tBest loss: 1.748615\tAccuracy: 89.21%\n",
      "881\tValidation loss: 1.748576\tBest loss: 1.748576\tAccuracy: 89.21%\n",
      "882\tValidation loss: 1.748540\tBest loss: 1.748540\tAccuracy: 89.21%\n",
      "883\tValidation loss: 1.748500\tBest loss: 1.748500\tAccuracy: 89.21%\n",
      "884\tValidation loss: 1.748473\tBest loss: 1.748473\tAccuracy: 89.21%\n",
      "885\tValidation loss: 1.748449\tBest loss: 1.748449\tAccuracy: 89.21%\n",
      "886\tValidation loss: 1.748412\tBest loss: 1.748412\tAccuracy: 89.21%\n",
      "887\tValidation loss: 1.748377\tBest loss: 1.748377\tAccuracy: 89.21%\n",
      "888\tValidation loss: 1.748331\tBest loss: 1.748331\tAccuracy: 89.21%\n",
      "889\tValidation loss: 1.748279\tBest loss: 1.748279\tAccuracy: 89.21%\n",
      "890\tValidation loss: 1.748248\tBest loss: 1.748248\tAccuracy: 89.21%\n",
      "891\tValidation loss: 1.748190\tBest loss: 1.748190\tAccuracy: 89.21%\n",
      "892\tValidation loss: 1.748170\tBest loss: 1.748170\tAccuracy: 89.21%\n",
      "893\tValidation loss: 1.748124\tBest loss: 1.748124\tAccuracy: 89.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894\tValidation loss: 1.748091\tBest loss: 1.748091\tAccuracy: 89.21%\n",
      "895\tValidation loss: 1.748055\tBest loss: 1.748055\tAccuracy: 89.21%\n",
      "896\tValidation loss: 1.748015\tBest loss: 1.748015\tAccuracy: 89.21%\n",
      "897\tValidation loss: 1.747972\tBest loss: 1.747972\tAccuracy: 89.21%\n",
      "898\tValidation loss: 1.747938\tBest loss: 1.747938\tAccuracy: 89.21%\n",
      "899\tValidation loss: 1.747910\tBest loss: 1.747910\tAccuracy: 89.21%\n",
      "900\tValidation loss: 1.747876\tBest loss: 1.747876\tAccuracy: 89.21%\n",
      "901\tValidation loss: 1.747826\tBest loss: 1.747826\tAccuracy: 89.21%\n",
      "902\tValidation loss: 1.747799\tBest loss: 1.747799\tAccuracy: 89.21%\n",
      "903\tValidation loss: 1.747769\tBest loss: 1.747769\tAccuracy: 89.21%\n",
      "904\tValidation loss: 1.747726\tBest loss: 1.747726\tAccuracy: 89.21%\n",
      "905\tValidation loss: 1.747687\tBest loss: 1.747687\tAccuracy: 89.21%\n",
      "906\tValidation loss: 1.747654\tBest loss: 1.747654\tAccuracy: 89.21%\n",
      "907\tValidation loss: 1.747616\tBest loss: 1.747616\tAccuracy: 89.21%\n",
      "908\tValidation loss: 1.747588\tBest loss: 1.747588\tAccuracy: 89.21%\n",
      "909\tValidation loss: 1.747560\tBest loss: 1.747560\tAccuracy: 89.21%\n",
      "910\tValidation loss: 1.747520\tBest loss: 1.747520\tAccuracy: 89.21%\n",
      "911\tValidation loss: 1.747477\tBest loss: 1.747477\tAccuracy: 89.21%\n",
      "912\tValidation loss: 1.747446\tBest loss: 1.747446\tAccuracy: 89.21%\n",
      "913\tValidation loss: 1.747411\tBest loss: 1.747411\tAccuracy: 89.21%\n",
      "914\tValidation loss: 1.747375\tBest loss: 1.747375\tAccuracy: 89.21%\n",
      "915\tValidation loss: 1.747336\tBest loss: 1.747336\tAccuracy: 89.21%\n",
      "916\tValidation loss: 1.747307\tBest loss: 1.747307\tAccuracy: 89.21%\n",
      "917\tValidation loss: 1.747262\tBest loss: 1.747262\tAccuracy: 89.21%\n",
      "918\tValidation loss: 1.747225\tBest loss: 1.747225\tAccuracy: 89.21%\n",
      "919\tValidation loss: 1.747183\tBest loss: 1.747183\tAccuracy: 89.21%\n",
      "920\tValidation loss: 1.747149\tBest loss: 1.747149\tAccuracy: 89.21%\n",
      "921\tValidation loss: 1.747116\tBest loss: 1.747116\tAccuracy: 89.21%\n",
      "922\tValidation loss: 1.747089\tBest loss: 1.747089\tAccuracy: 89.21%\n",
      "923\tValidation loss: 1.747045\tBest loss: 1.747045\tAccuracy: 89.21%\n",
      "924\tValidation loss: 1.746998\tBest loss: 1.746998\tAccuracy: 89.21%\n",
      "925\tValidation loss: 1.746978\tBest loss: 1.746978\tAccuracy: 89.21%\n",
      "926\tValidation loss: 1.746948\tBest loss: 1.746948\tAccuracy: 89.21%\n",
      "927\tValidation loss: 1.746906\tBest loss: 1.746906\tAccuracy: 89.21%\n",
      "928\tValidation loss: 1.746876\tBest loss: 1.746876\tAccuracy: 89.21%\n",
      "929\tValidation loss: 1.746832\tBest loss: 1.746832\tAccuracy: 89.21%\n",
      "930\tValidation loss: 1.746805\tBest loss: 1.746805\tAccuracy: 89.21%\n",
      "931\tValidation loss: 1.746767\tBest loss: 1.746767\tAccuracy: 89.21%\n",
      "932\tValidation loss: 1.746724\tBest loss: 1.746724\tAccuracy: 89.21%\n",
      "933\tValidation loss: 1.746682\tBest loss: 1.746682\tAccuracy: 89.21%\n",
      "934\tValidation loss: 1.746647\tBest loss: 1.746647\tAccuracy: 89.21%\n",
      "935\tValidation loss: 1.746616\tBest loss: 1.746616\tAccuracy: 89.21%\n",
      "936\tValidation loss: 1.746582\tBest loss: 1.746582\tAccuracy: 89.21%\n",
      "937\tValidation loss: 1.746554\tBest loss: 1.746554\tAccuracy: 89.21%\n",
      "938\tValidation loss: 1.746518\tBest loss: 1.746518\tAccuracy: 89.21%\n",
      "939\tValidation loss: 1.746490\tBest loss: 1.746490\tAccuracy: 89.21%\n",
      "940\tValidation loss: 1.746455\tBest loss: 1.746455\tAccuracy: 89.21%\n",
      "941\tValidation loss: 1.746423\tBest loss: 1.746423\tAccuracy: 89.21%\n",
      "942\tValidation loss: 1.746389\tBest loss: 1.746389\tAccuracy: 89.21%\n",
      "943\tValidation loss: 1.746353\tBest loss: 1.746353\tAccuracy: 89.21%\n",
      "944\tValidation loss: 1.746309\tBest loss: 1.746309\tAccuracy: 89.21%\n",
      "945\tValidation loss: 1.746285\tBest loss: 1.746285\tAccuracy: 89.21%\n",
      "946\tValidation loss: 1.746256\tBest loss: 1.746256\tAccuracy: 89.21%\n",
      "947\tValidation loss: 1.746225\tBest loss: 1.746225\tAccuracy: 89.21%\n",
      "948\tValidation loss: 1.746185\tBest loss: 1.746185\tAccuracy: 89.21%\n",
      "949\tValidation loss: 1.746136\tBest loss: 1.746136\tAccuracy: 89.21%\n",
      "950\tValidation loss: 1.746100\tBest loss: 1.746100\tAccuracy: 89.21%\n",
      "951\tValidation loss: 1.746069\tBest loss: 1.746069\tAccuracy: 89.21%\n",
      "952\tValidation loss: 1.746033\tBest loss: 1.746033\tAccuracy: 89.21%\n",
      "953\tValidation loss: 1.746002\tBest loss: 1.746002\tAccuracy: 89.21%\n",
      "954\tValidation loss: 1.745975\tBest loss: 1.745975\tAccuracy: 89.21%\n",
      "955\tValidation loss: 1.745935\tBest loss: 1.745935\tAccuracy: 89.21%\n",
      "956\tValidation loss: 1.745897\tBest loss: 1.745897\tAccuracy: 89.21%\n",
      "957\tValidation loss: 1.745867\tBest loss: 1.745867\tAccuracy: 89.21%\n",
      "958\tValidation loss: 1.745835\tBest loss: 1.745835\tAccuracy: 89.21%\n",
      "959\tValidation loss: 1.745785\tBest loss: 1.745785\tAccuracy: 89.21%\n",
      "960\tValidation loss: 1.745746\tBest loss: 1.745746\tAccuracy: 89.21%\n",
      "961\tValidation loss: 1.745716\tBest loss: 1.745716\tAccuracy: 89.21%\n",
      "962\tValidation loss: 1.745687\tBest loss: 1.745687\tAccuracy: 89.21%\n",
      "963\tValidation loss: 1.745656\tBest loss: 1.745656\tAccuracy: 89.21%\n",
      "964\tValidation loss: 1.745623\tBest loss: 1.745623\tAccuracy: 89.21%\n",
      "965\tValidation loss: 1.745586\tBest loss: 1.745586\tAccuracy: 89.21%\n",
      "966\tValidation loss: 1.745546\tBest loss: 1.745546\tAccuracy: 89.21%\n",
      "967\tValidation loss: 1.745514\tBest loss: 1.745514\tAccuracy: 89.21%\n",
      "968\tValidation loss: 1.745483\tBest loss: 1.745483\tAccuracy: 89.21%\n",
      "969\tValidation loss: 1.745449\tBest loss: 1.745449\tAccuracy: 89.21%\n",
      "970\tValidation loss: 1.745408\tBest loss: 1.745408\tAccuracy: 89.21%\n",
      "971\tValidation loss: 1.745372\tBest loss: 1.745372\tAccuracy: 89.21%\n",
      "972\tValidation loss: 1.745344\tBest loss: 1.745344\tAccuracy: 89.21%\n",
      "973\tValidation loss: 1.745302\tBest loss: 1.745302\tAccuracy: 89.21%\n",
      "974\tValidation loss: 1.745271\tBest loss: 1.745271\tAccuracy: 89.21%\n",
      "975\tValidation loss: 1.745235\tBest loss: 1.745235\tAccuracy: 89.21%\n",
      "976\tValidation loss: 1.745210\tBest loss: 1.745210\tAccuracy: 89.21%\n",
      "977\tValidation loss: 1.745176\tBest loss: 1.745176\tAccuracy: 89.21%\n",
      "978\tValidation loss: 1.745132\tBest loss: 1.745132\tAccuracy: 89.21%\n",
      "979\tValidation loss: 1.745106\tBest loss: 1.745106\tAccuracy: 89.21%\n",
      "980\tValidation loss: 1.745077\tBest loss: 1.745077\tAccuracy: 89.21%\n",
      "981\tValidation loss: 1.745043\tBest loss: 1.745043\tAccuracy: 89.21%\n",
      "982\tValidation loss: 1.744997\tBest loss: 1.744997\tAccuracy: 89.21%\n",
      "983\tValidation loss: 1.744968\tBest loss: 1.744968\tAccuracy: 89.21%\n",
      "984\tValidation loss: 1.744928\tBest loss: 1.744928\tAccuracy: 89.21%\n",
      "985\tValidation loss: 1.744899\tBest loss: 1.744899\tAccuracy: 89.21%\n",
      "986\tValidation loss: 1.744855\tBest loss: 1.744855\tAccuracy: 89.21%\n",
      "987\tValidation loss: 1.744820\tBest loss: 1.744820\tAccuracy: 89.21%\n",
      "988\tValidation loss: 1.744786\tBest loss: 1.744786\tAccuracy: 89.21%\n",
      "989\tValidation loss: 1.744763\tBest loss: 1.744763\tAccuracy: 89.21%\n",
      "990\tValidation loss: 1.744726\tBest loss: 1.744726\tAccuracy: 89.21%\n",
      "991\tValidation loss: 1.744678\tBest loss: 1.744678\tAccuracy: 89.21%\n",
      "992\tValidation loss: 1.744648\tBest loss: 1.744648\tAccuracy: 89.21%\n",
      "993\tValidation loss: 1.744615\tBest loss: 1.744615\tAccuracy: 89.21%\n",
      "994\tValidation loss: 1.744578\tBest loss: 1.744578\tAccuracy: 89.21%\n",
      "995\tValidation loss: 1.744536\tBest loss: 1.744536\tAccuracy: 89.21%\n",
      "996\tValidation loss: 1.744493\tBest loss: 1.744493\tAccuracy: 89.21%\n",
      "997\tValidation loss: 1.744464\tBest loss: 1.744464\tAccuracy: 89.21%\n",
      "998\tValidation loss: 1.744436\tBest loss: 1.744436\tAccuracy: 89.21%\n",
      "999\tValidation loss: 1.744399\tBest loss: 1.744399\tAccuracy: 89.21%\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total= 1.4min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488> \n",
      "0\tValidation loss: 147.205139\tBest loss: 147.205139\tAccuracy: 26.62%\n",
      "1\tValidation loss: 252.704224\tBest loss: 147.205139\tAccuracy: 27.34%\n",
      "2\tValidation loss: 223.427567\tBest loss: 147.205139\tAccuracy: 19.42%\n",
      "3\tValidation loss: 211.469421\tBest loss: 147.205139\tAccuracy: 23.02%\n",
      "4\tValidation loss: 157.941498\tBest loss: 147.205139\tAccuracy: 33.09%\n",
      "5\tValidation loss: 112.100937\tBest loss: 112.100937\tAccuracy: 35.97%\n",
      "6\tValidation loss: 102.305786\tBest loss: 102.305786\tAccuracy: 32.37%\n",
      "7\tValidation loss: 49.645180\tBest loss: 49.645180\tAccuracy: 45.32%\n",
      "8\tValidation loss: 21.012646\tBest loss: 21.012646\tAccuracy: 68.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 13.187709\tBest loss: 13.187709\tAccuracy: 78.42%\n",
      "10\tValidation loss: 5.364727\tBest loss: 5.364727\tAccuracy: 84.17%\n",
      "11\tValidation loss: 5.613732\tBest loss: 5.364727\tAccuracy: 80.58%\n",
      "12\tValidation loss: 3.669387\tBest loss: 3.669387\tAccuracy: 83.45%\n",
      "13\tValidation loss: 3.233160\tBest loss: 3.233160\tAccuracy: 84.89%\n",
      "14\tValidation loss: 3.000579\tBest loss: 3.000579\tAccuracy: 85.61%\n",
      "15\tValidation loss: 2.800872\tBest loss: 2.800872\tAccuracy: 85.61%\n",
      "16\tValidation loss: 2.646345\tBest loss: 2.646345\tAccuracy: 85.61%\n",
      "17\tValidation loss: 2.510475\tBest loss: 2.510475\tAccuracy: 86.33%\n",
      "18\tValidation loss: 2.425151\tBest loss: 2.425151\tAccuracy: 85.61%\n",
      "19\tValidation loss: 2.375011\tBest loss: 2.375011\tAccuracy: 85.61%\n",
      "20\tValidation loss: 2.319110\tBest loss: 2.319110\tAccuracy: 84.89%\n",
      "21\tValidation loss: 2.280554\tBest loss: 2.280554\tAccuracy: 84.89%\n",
      "22\tValidation loss: 2.248701\tBest loss: 2.248701\tAccuracy: 84.17%\n",
      "23\tValidation loss: 2.212605\tBest loss: 2.212605\tAccuracy: 84.17%\n",
      "24\tValidation loss: 2.186977\tBest loss: 2.186977\tAccuracy: 84.89%\n",
      "25\tValidation loss: 2.153351\tBest loss: 2.153351\tAccuracy: 84.89%\n",
      "26\tValidation loss: 2.119199\tBest loss: 2.119199\tAccuracy: 84.89%\n",
      "27\tValidation loss: 2.087845\tBest loss: 2.087845\tAccuracy: 85.61%\n",
      "28\tValidation loss: 2.060378\tBest loss: 2.060378\tAccuracy: 85.61%\n",
      "29\tValidation loss: 2.029101\tBest loss: 2.029101\tAccuracy: 85.61%\n",
      "30\tValidation loss: 2.009296\tBest loss: 2.009296\tAccuracy: 85.61%\n",
      "31\tValidation loss: 1.984356\tBest loss: 1.984356\tAccuracy: 85.61%\n",
      "32\tValidation loss: 1.968547\tBest loss: 1.968547\tAccuracy: 85.61%\n",
      "33\tValidation loss: 1.952985\tBest loss: 1.952985\tAccuracy: 85.61%\n",
      "34\tValidation loss: 1.938962\tBest loss: 1.938962\tAccuracy: 85.61%\n",
      "35\tValidation loss: 1.923977\tBest loss: 1.923977\tAccuracy: 85.61%\n",
      "36\tValidation loss: 1.911695\tBest loss: 1.911695\tAccuracy: 85.61%\n",
      "37\tValidation loss: 1.896993\tBest loss: 1.896993\tAccuracy: 85.61%\n",
      "38\tValidation loss: 1.882534\tBest loss: 1.882534\tAccuracy: 85.61%\n",
      "39\tValidation loss: 1.864954\tBest loss: 1.864954\tAccuracy: 85.61%\n",
      "40\tValidation loss: 1.847923\tBest loss: 1.847923\tAccuracy: 85.61%\n",
      "41\tValidation loss: 1.828913\tBest loss: 1.828913\tAccuracy: 85.61%\n",
      "42\tValidation loss: 1.811086\tBest loss: 1.811086\tAccuracy: 85.61%\n",
      "43\tValidation loss: 1.791959\tBest loss: 1.791959\tAccuracy: 85.61%\n",
      "44\tValidation loss: 1.774271\tBest loss: 1.774271\tAccuracy: 85.61%\n",
      "45\tValidation loss: 1.755676\tBest loss: 1.755676\tAccuracy: 85.61%\n",
      "46\tValidation loss: 1.738427\tBest loss: 1.738427\tAccuracy: 85.61%\n",
      "47\tValidation loss: 1.720536\tBest loss: 1.720536\tAccuracy: 85.61%\n",
      "48\tValidation loss: 1.703812\tBest loss: 1.703812\tAccuracy: 85.61%\n",
      "49\tValidation loss: 1.686641\tBest loss: 1.686641\tAccuracy: 85.61%\n",
      "50\tValidation loss: 1.670451\tBest loss: 1.670451\tAccuracy: 85.61%\n",
      "51\tValidation loss: 1.653964\tBest loss: 1.653964\tAccuracy: 85.61%\n",
      "52\tValidation loss: 1.638242\tBest loss: 1.638242\tAccuracy: 85.61%\n",
      "53\tValidation loss: 1.622402\tBest loss: 1.622402\tAccuracy: 85.61%\n",
      "54\tValidation loss: 1.607400\tBest loss: 1.607400\tAccuracy: 85.61%\n",
      "55\tValidation loss: 1.592488\tBest loss: 1.592488\tAccuracy: 85.61%\n",
      "56\tValidation loss: 1.578555\tBest loss: 1.578555\tAccuracy: 85.61%\n",
      "57\tValidation loss: 1.565261\tBest loss: 1.565261\tAccuracy: 85.61%\n",
      "58\tValidation loss: 1.553362\tBest loss: 1.553362\tAccuracy: 85.61%\n",
      "59\tValidation loss: 1.542937\tBest loss: 1.542937\tAccuracy: 85.61%\n",
      "60\tValidation loss: 1.533979\tBest loss: 1.533979\tAccuracy: 85.61%\n",
      "61\tValidation loss: 1.526766\tBest loss: 1.526766\tAccuracy: 85.61%\n",
      "62\tValidation loss: 1.520513\tBest loss: 1.520513\tAccuracy: 85.61%\n",
      "63\tValidation loss: 1.515338\tBest loss: 1.515338\tAccuracy: 85.61%\n",
      "64\tValidation loss: 1.510769\tBest loss: 1.510769\tAccuracy: 85.61%\n",
      "65\tValidation loss: 1.506673\tBest loss: 1.506673\tAccuracy: 85.61%\n",
      "66\tValidation loss: 1.503015\tBest loss: 1.503015\tAccuracy: 85.61%\n",
      "67\tValidation loss: 1.499621\tBest loss: 1.499621\tAccuracy: 85.61%\n",
      "68\tValidation loss: 1.496432\tBest loss: 1.496432\tAccuracy: 85.61%\n",
      "69\tValidation loss: 1.493423\tBest loss: 1.493423\tAccuracy: 85.61%\n",
      "70\tValidation loss: 1.490555\tBest loss: 1.490555\tAccuracy: 85.61%\n",
      "71\tValidation loss: 1.487807\tBest loss: 1.487807\tAccuracy: 85.61%\n",
      "72\tValidation loss: 1.485147\tBest loss: 1.485147\tAccuracy: 85.61%\n",
      "73\tValidation loss: 1.482558\tBest loss: 1.482558\tAccuracy: 85.61%\n",
      "74\tValidation loss: 1.480025\tBest loss: 1.480025\tAccuracy: 86.33%\n",
      "75\tValidation loss: 1.477590\tBest loss: 1.477590\tAccuracy: 86.33%\n",
      "76\tValidation loss: 1.475190\tBest loss: 1.475190\tAccuracy: 87.05%\n",
      "77\tValidation loss: 1.472810\tBest loss: 1.472810\tAccuracy: 87.05%\n",
      "78\tValidation loss: 1.470464\tBest loss: 1.470464\tAccuracy: 87.05%\n",
      "79\tValidation loss: 1.468166\tBest loss: 1.468166\tAccuracy: 87.05%\n",
      "80\tValidation loss: 1.465895\tBest loss: 1.465895\tAccuracy: 87.05%\n",
      "81\tValidation loss: 1.463637\tBest loss: 1.463637\tAccuracy: 87.05%\n",
      "82\tValidation loss: 1.461426\tBest loss: 1.461426\tAccuracy: 87.05%\n",
      "83\tValidation loss: 1.459206\tBest loss: 1.459206\tAccuracy: 87.05%\n",
      "84\tValidation loss: 1.457010\tBest loss: 1.457010\tAccuracy: 87.05%\n",
      "85\tValidation loss: 1.454808\tBest loss: 1.454808\tAccuracy: 87.05%\n",
      "86\tValidation loss: 1.452617\tBest loss: 1.452617\tAccuracy: 87.05%\n",
      "87\tValidation loss: 1.450460\tBest loss: 1.450460\tAccuracy: 87.05%\n",
      "88\tValidation loss: 1.448267\tBest loss: 1.448267\tAccuracy: 87.05%\n",
      "89\tValidation loss: 1.446051\tBest loss: 1.446051\tAccuracy: 87.05%\n",
      "90\tValidation loss: 1.443825\tBest loss: 1.443825\tAccuracy: 87.05%\n",
      "91\tValidation loss: 1.441527\tBest loss: 1.441527\tAccuracy: 87.05%\n",
      "92\tValidation loss: 1.439210\tBest loss: 1.439210\tAccuracy: 87.05%\n",
      "93\tValidation loss: 1.436864\tBest loss: 1.436864\tAccuracy: 87.05%\n",
      "94\tValidation loss: 1.434463\tBest loss: 1.434463\tAccuracy: 87.05%\n",
      "95\tValidation loss: 1.432025\tBest loss: 1.432025\tAccuracy: 87.05%\n",
      "96\tValidation loss: 1.429492\tBest loss: 1.429492\tAccuracy: 87.05%\n",
      "97\tValidation loss: 1.426888\tBest loss: 1.426888\tAccuracy: 87.05%\n",
      "98\tValidation loss: 1.424172\tBest loss: 1.424172\tAccuracy: 87.05%\n",
      "99\tValidation loss: 1.421332\tBest loss: 1.421332\tAccuracy: 87.05%\n",
      "100\tValidation loss: 1.418350\tBest loss: 1.418350\tAccuracy: 87.05%\n",
      "101\tValidation loss: 1.415210\tBest loss: 1.415210\tAccuracy: 87.05%\n",
      "102\tValidation loss: 1.411972\tBest loss: 1.411972\tAccuracy: 87.05%\n",
      "103\tValidation loss: 1.408677\tBest loss: 1.408677\tAccuracy: 87.05%\n",
      "104\tValidation loss: 1.405305\tBest loss: 1.405305\tAccuracy: 87.05%\n",
      "105\tValidation loss: 1.401952\tBest loss: 1.401952\tAccuracy: 87.05%\n",
      "106\tValidation loss: 1.398584\tBest loss: 1.398584\tAccuracy: 87.05%\n",
      "107\tValidation loss: 1.395250\tBest loss: 1.395250\tAccuracy: 87.05%\n",
      "108\tValidation loss: 1.391981\tBest loss: 1.391981\tAccuracy: 87.05%\n",
      "109\tValidation loss: 1.388738\tBest loss: 1.388738\tAccuracy: 87.05%\n",
      "110\tValidation loss: 1.385540\tBest loss: 1.385540\tAccuracy: 87.05%\n",
      "111\tValidation loss: 1.382422\tBest loss: 1.382422\tAccuracy: 87.05%\n",
      "112\tValidation loss: 1.379360\tBest loss: 1.379360\tAccuracy: 87.05%\n",
      "113\tValidation loss: 1.376350\tBest loss: 1.376350\tAccuracy: 87.05%\n",
      "114\tValidation loss: 1.373431\tBest loss: 1.373431\tAccuracy: 87.05%\n",
      "115\tValidation loss: 1.370522\tBest loss: 1.370522\tAccuracy: 87.05%\n",
      "116\tValidation loss: 1.367698\tBest loss: 1.367698\tAccuracy: 87.05%\n",
      "117\tValidation loss: 1.364913\tBest loss: 1.364913\tAccuracy: 87.05%\n",
      "118\tValidation loss: 1.362179\tBest loss: 1.362179\tAccuracy: 87.05%\n",
      "119\tValidation loss: 1.359530\tBest loss: 1.359530\tAccuracy: 87.05%\n",
      "120\tValidation loss: 1.356945\tBest loss: 1.356945\tAccuracy: 87.05%\n",
      "121\tValidation loss: 1.354397\tBest loss: 1.354397\tAccuracy: 87.05%\n",
      "122\tValidation loss: 1.351901\tBest loss: 1.351901\tAccuracy: 87.05%\n",
      "123\tValidation loss: 1.349499\tBest loss: 1.349499\tAccuracy: 87.05%\n",
      "124\tValidation loss: 1.347154\tBest loss: 1.347154\tAccuracy: 87.05%\n",
      "125\tValidation loss: 1.344873\tBest loss: 1.344873\tAccuracy: 87.05%\n",
      "126\tValidation loss: 1.342665\tBest loss: 1.342665\tAccuracy: 87.05%\n",
      "127\tValidation loss: 1.340570\tBest loss: 1.340570\tAccuracy: 87.05%\n",
      "128\tValidation loss: 1.338524\tBest loss: 1.338524\tAccuracy: 87.05%\n",
      "129\tValidation loss: 1.336564\tBest loss: 1.336564\tAccuracy: 87.05%\n",
      "130\tValidation loss: 1.334666\tBest loss: 1.334666\tAccuracy: 87.05%\n",
      "131\tValidation loss: 1.332864\tBest loss: 1.332864\tAccuracy: 87.05%\n",
      "132\tValidation loss: 1.331147\tBest loss: 1.331147\tAccuracy: 87.05%\n",
      "133\tValidation loss: 1.329478\tBest loss: 1.329478\tAccuracy: 87.05%\n",
      "134\tValidation loss: 1.327889\tBest loss: 1.327889\tAccuracy: 87.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\tValidation loss: 1.326341\tBest loss: 1.326341\tAccuracy: 87.05%\n",
      "136\tValidation loss: 1.324880\tBest loss: 1.324880\tAccuracy: 87.05%\n",
      "137\tValidation loss: 1.323467\tBest loss: 1.323467\tAccuracy: 87.05%\n",
      "138\tValidation loss: 1.322131\tBest loss: 1.322131\tAccuracy: 87.05%\n",
      "139\tValidation loss: 1.320847\tBest loss: 1.320847\tAccuracy: 87.77%\n",
      "140\tValidation loss: 1.319612\tBest loss: 1.319612\tAccuracy: 87.77%\n",
      "141\tValidation loss: 1.318434\tBest loss: 1.318434\tAccuracy: 87.77%\n",
      "142\tValidation loss: 1.317302\tBest loss: 1.317302\tAccuracy: 87.77%\n",
      "143\tValidation loss: 1.316226\tBest loss: 1.316226\tAccuracy: 87.77%\n",
      "144\tValidation loss: 1.315177\tBest loss: 1.315177\tAccuracy: 87.77%\n",
      "145\tValidation loss: 1.314167\tBest loss: 1.314167\tAccuracy: 87.77%\n",
      "146\tValidation loss: 1.313225\tBest loss: 1.313225\tAccuracy: 87.77%\n",
      "147\tValidation loss: 1.312292\tBest loss: 1.312292\tAccuracy: 87.77%\n",
      "148\tValidation loss: 1.311425\tBest loss: 1.311425\tAccuracy: 87.77%\n",
      "149\tValidation loss: 1.310576\tBest loss: 1.310576\tAccuracy: 87.77%\n",
      "150\tValidation loss: 1.309768\tBest loss: 1.309768\tAccuracy: 87.77%\n",
      "151\tValidation loss: 1.309001\tBest loss: 1.309001\tAccuracy: 87.77%\n",
      "152\tValidation loss: 1.308240\tBest loss: 1.308240\tAccuracy: 87.77%\n",
      "153\tValidation loss: 1.307516\tBest loss: 1.307516\tAccuracy: 87.77%\n",
      "154\tValidation loss: 1.306834\tBest loss: 1.306834\tAccuracy: 87.77%\n",
      "155\tValidation loss: 1.306152\tBest loss: 1.306152\tAccuracy: 87.77%\n",
      "156\tValidation loss: 1.305508\tBest loss: 1.305508\tAccuracy: 87.77%\n",
      "157\tValidation loss: 1.304901\tBest loss: 1.304901\tAccuracy: 87.77%\n",
      "158\tValidation loss: 1.304311\tBest loss: 1.304311\tAccuracy: 87.77%\n",
      "159\tValidation loss: 1.303757\tBest loss: 1.303757\tAccuracy: 87.77%\n",
      "160\tValidation loss: 1.303214\tBest loss: 1.303214\tAccuracy: 87.77%\n",
      "161\tValidation loss: 1.302681\tBest loss: 1.302681\tAccuracy: 87.77%\n",
      "162\tValidation loss: 1.302159\tBest loss: 1.302159\tAccuracy: 87.77%\n",
      "163\tValidation loss: 1.301671\tBest loss: 1.301671\tAccuracy: 87.77%\n",
      "164\tValidation loss: 1.301202\tBest loss: 1.301202\tAccuracy: 87.77%\n",
      "165\tValidation loss: 1.300734\tBest loss: 1.300734\tAccuracy: 87.77%\n",
      "166\tValidation loss: 1.300282\tBest loss: 1.300282\tAccuracy: 87.77%\n",
      "167\tValidation loss: 1.299848\tBest loss: 1.299848\tAccuracy: 87.77%\n",
      "168\tValidation loss: 1.299439\tBest loss: 1.299439\tAccuracy: 87.77%\n",
      "169\tValidation loss: 1.299040\tBest loss: 1.299040\tAccuracy: 87.77%\n",
      "170\tValidation loss: 1.298663\tBest loss: 1.298663\tAccuracy: 87.77%\n",
      "171\tValidation loss: 1.298282\tBest loss: 1.298282\tAccuracy: 87.77%\n",
      "172\tValidation loss: 1.297914\tBest loss: 1.297914\tAccuracy: 87.77%\n",
      "173\tValidation loss: 1.297571\tBest loss: 1.297571\tAccuracy: 87.77%\n",
      "174\tValidation loss: 1.297245\tBest loss: 1.297245\tAccuracy: 87.77%\n",
      "175\tValidation loss: 1.296906\tBest loss: 1.296906\tAccuracy: 87.77%\n",
      "176\tValidation loss: 1.296585\tBest loss: 1.296585\tAccuracy: 87.77%\n",
      "177\tValidation loss: 1.296310\tBest loss: 1.296310\tAccuracy: 87.77%\n",
      "178\tValidation loss: 1.296005\tBest loss: 1.296005\tAccuracy: 87.77%\n",
      "179\tValidation loss: 1.295713\tBest loss: 1.295713\tAccuracy: 87.77%\n",
      "180\tValidation loss: 1.295438\tBest loss: 1.295438\tAccuracy: 87.77%\n",
      "181\tValidation loss: 1.295170\tBest loss: 1.295170\tAccuracy: 87.77%\n",
      "182\tValidation loss: 1.294917\tBest loss: 1.294917\tAccuracy: 87.77%\n",
      "183\tValidation loss: 1.294669\tBest loss: 1.294669\tAccuracy: 87.77%\n",
      "184\tValidation loss: 1.294437\tBest loss: 1.294437\tAccuracy: 87.77%\n",
      "185\tValidation loss: 1.294198\tBest loss: 1.294198\tAccuracy: 87.77%\n",
      "186\tValidation loss: 1.293982\tBest loss: 1.293982\tAccuracy: 87.77%\n",
      "187\tValidation loss: 1.293755\tBest loss: 1.293755\tAccuracy: 87.77%\n",
      "188\tValidation loss: 1.293540\tBest loss: 1.293540\tAccuracy: 87.77%\n",
      "189\tValidation loss: 1.293333\tBest loss: 1.293333\tAccuracy: 87.77%\n",
      "190\tValidation loss: 1.293149\tBest loss: 1.293149\tAccuracy: 87.77%\n",
      "191\tValidation loss: 1.292954\tBest loss: 1.292954\tAccuracy: 87.77%\n",
      "192\tValidation loss: 1.292776\tBest loss: 1.292776\tAccuracy: 87.77%\n",
      "193\tValidation loss: 1.292612\tBest loss: 1.292612\tAccuracy: 87.77%\n",
      "194\tValidation loss: 1.292428\tBest loss: 1.292428\tAccuracy: 87.77%\n",
      "195\tValidation loss: 1.292269\tBest loss: 1.292269\tAccuracy: 87.77%\n",
      "196\tValidation loss: 1.292114\tBest loss: 1.292114\tAccuracy: 87.77%\n",
      "197\tValidation loss: 1.291968\tBest loss: 1.291968\tAccuracy: 87.77%\n",
      "198\tValidation loss: 1.291831\tBest loss: 1.291831\tAccuracy: 87.77%\n",
      "199\tValidation loss: 1.291692\tBest loss: 1.291692\tAccuracy: 87.77%\n",
      "200\tValidation loss: 1.291546\tBest loss: 1.291546\tAccuracy: 87.77%\n",
      "201\tValidation loss: 1.291415\tBest loss: 1.291415\tAccuracy: 87.77%\n",
      "202\tValidation loss: 1.291277\tBest loss: 1.291277\tAccuracy: 87.77%\n",
      "203\tValidation loss: 1.291142\tBest loss: 1.291142\tAccuracy: 87.77%\n",
      "204\tValidation loss: 1.291006\tBest loss: 1.291006\tAccuracy: 87.77%\n",
      "205\tValidation loss: 1.290854\tBest loss: 1.290854\tAccuracy: 87.77%\n",
      "206\tValidation loss: 1.290679\tBest loss: 1.290679\tAccuracy: 87.77%\n",
      "207\tValidation loss: 1.290481\tBest loss: 1.290481\tAccuracy: 87.77%\n",
      "208\tValidation loss: 1.290223\tBest loss: 1.290223\tAccuracy: 87.77%\n",
      "209\tValidation loss: 1.289963\tBest loss: 1.289963\tAccuracy: 87.77%\n",
      "210\tValidation loss: 1.289683\tBest loss: 1.289683\tAccuracy: 87.77%\n",
      "211\tValidation loss: 1.289420\tBest loss: 1.289420\tAccuracy: 87.77%\n",
      "212\tValidation loss: 1.289174\tBest loss: 1.289174\tAccuracy: 87.77%\n",
      "213\tValidation loss: 1.288936\tBest loss: 1.288936\tAccuracy: 87.77%\n",
      "214\tValidation loss: 1.288702\tBest loss: 1.288702\tAccuracy: 87.77%\n",
      "215\tValidation loss: 1.288493\tBest loss: 1.288493\tAccuracy: 87.77%\n",
      "216\tValidation loss: 1.288291\tBest loss: 1.288291\tAccuracy: 87.77%\n",
      "217\tValidation loss: 1.288104\tBest loss: 1.288104\tAccuracy: 87.77%\n",
      "218\tValidation loss: 1.287893\tBest loss: 1.287893\tAccuracy: 87.77%\n",
      "219\tValidation loss: 1.287714\tBest loss: 1.287714\tAccuracy: 87.77%\n",
      "220\tValidation loss: 1.287545\tBest loss: 1.287545\tAccuracy: 87.05%\n",
      "221\tValidation loss: 1.287367\tBest loss: 1.287367\tAccuracy: 87.05%\n",
      "222\tValidation loss: 1.287211\tBest loss: 1.287211\tAccuracy: 87.05%\n",
      "223\tValidation loss: 1.287045\tBest loss: 1.287045\tAccuracy: 87.05%\n",
      "224\tValidation loss: 1.286910\tBest loss: 1.286910\tAccuracy: 87.05%\n",
      "225\tValidation loss: 1.286763\tBest loss: 1.286763\tAccuracy: 87.05%\n",
      "226\tValidation loss: 1.286620\tBest loss: 1.286620\tAccuracy: 87.05%\n",
      "227\tValidation loss: 1.286485\tBest loss: 1.286485\tAccuracy: 87.05%\n",
      "228\tValidation loss: 1.286379\tBest loss: 1.286379\tAccuracy: 87.05%\n",
      "229\tValidation loss: 1.286256\tBest loss: 1.286256\tAccuracy: 87.05%\n",
      "230\tValidation loss: 1.286156\tBest loss: 1.286156\tAccuracy: 87.05%\n",
      "231\tValidation loss: 1.286072\tBest loss: 1.286072\tAccuracy: 87.05%\n",
      "232\tValidation loss: 1.285967\tBest loss: 1.285967\tAccuracy: 87.05%\n",
      "233\tValidation loss: 1.285885\tBest loss: 1.285885\tAccuracy: 87.05%\n",
      "234\tValidation loss: 1.285801\tBest loss: 1.285801\tAccuracy: 87.05%\n",
      "235\tValidation loss: 1.285717\tBest loss: 1.285717\tAccuracy: 87.05%\n",
      "236\tValidation loss: 1.285660\tBest loss: 1.285660\tAccuracy: 87.05%\n",
      "237\tValidation loss: 1.285587\tBest loss: 1.285587\tAccuracy: 87.05%\n",
      "238\tValidation loss: 1.285545\tBest loss: 1.285545\tAccuracy: 87.05%\n",
      "239\tValidation loss: 1.285517\tBest loss: 1.285517\tAccuracy: 87.05%\n",
      "240\tValidation loss: 1.285472\tBest loss: 1.285472\tAccuracy: 87.05%\n",
      "241\tValidation loss: 1.285438\tBest loss: 1.285438\tAccuracy: 87.05%\n",
      "242\tValidation loss: 1.285407\tBest loss: 1.285407\tAccuracy: 87.05%\n",
      "243\tValidation loss: 1.285390\tBest loss: 1.285390\tAccuracy: 87.05%\n",
      "244\tValidation loss: 1.285370\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "245\tValidation loss: 1.285384\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "246\tValidation loss: 1.285381\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "247\tValidation loss: 1.285397\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "248\tValidation loss: 1.285429\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "249\tValidation loss: 1.285468\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "250\tValidation loss: 1.285497\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "251\tValidation loss: 1.285553\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "252\tValidation loss: 1.285623\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "253\tValidation loss: 1.285690\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "254\tValidation loss: 1.285776\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "255\tValidation loss: 1.285855\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "256\tValidation loss: 1.285954\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "257\tValidation loss: 1.286059\tBest loss: 1.285370\tAccuracy: 87.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\tValidation loss: 1.286156\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "259\tValidation loss: 1.286281\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "260\tValidation loss: 1.286423\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "261\tValidation loss: 1.286572\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "262\tValidation loss: 1.286699\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "263\tValidation loss: 1.286843\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "264\tValidation loss: 1.286998\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "265\tValidation loss: 1.287171\tBest loss: 1.285370\tAccuracy: 87.05%\n",
      "Early stopping!\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, n_neurons=500, n_hidden_layers=0, learning_rate=0.1, dropout_rate=0.2, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>, total=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 42.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.860301\tBest loss: 2.860301\tAccuracy: 20.14%\n",
      "1\tValidation loss: 2.618865\tBest loss: 2.618865\tAccuracy: 34.53%\n",
      "2\tValidation loss: 2.435524\tBest loss: 2.435524\tAccuracy: 41.01%\n",
      "3\tValidation loss: 2.232359\tBest loss: 2.232359\tAccuracy: 54.68%\n",
      "4\tValidation loss: 2.073282\tBest loss: 2.073282\tAccuracy: 48.92%\n",
      "5\tValidation loss: 1.821338\tBest loss: 1.821338\tAccuracy: 63.31%\n",
      "6\tValidation loss: 1.651603\tBest loss: 1.651603\tAccuracy: 60.43%\n",
      "7\tValidation loss: 1.462459\tBest loss: 1.462459\tAccuracy: 69.78%\n",
      "8\tValidation loss: 1.407527\tBest loss: 1.407527\tAccuracy: 69.06%\n",
      "9\tValidation loss: 1.332617\tBest loss: 1.332617\tAccuracy: 74.10%\n",
      "10\tValidation loss: 1.305397\tBest loss: 1.305397\tAccuracy: 74.10%\n",
      "11\tValidation loss: 1.185599\tBest loss: 1.185599\tAccuracy: 74.10%\n",
      "12\tValidation loss: 1.119776\tBest loss: 1.119776\tAccuracy: 75.54%\n",
      "13\tValidation loss: 1.019388\tBest loss: 1.019388\tAccuracy: 79.86%\n",
      "14\tValidation loss: 1.023872\tBest loss: 1.019388\tAccuracy: 77.70%\n",
      "15\tValidation loss: 0.975402\tBest loss: 0.975402\tAccuracy: 76.26%\n",
      "16\tValidation loss: 0.993836\tBest loss: 0.975402\tAccuracy: 76.98%\n",
      "17\tValidation loss: 0.845062\tBest loss: 0.845062\tAccuracy: 79.14%\n",
      "18\tValidation loss: 0.834912\tBest loss: 0.834912\tAccuracy: 83.45%\n",
      "19\tValidation loss: 0.797059\tBest loss: 0.797059\tAccuracy: 82.01%\n",
      "20\tValidation loss: 0.806127\tBest loss: 0.797059\tAccuracy: 79.86%\n",
      "21\tValidation loss: 0.788088\tBest loss: 0.788088\tAccuracy: 81.29%\n",
      "22\tValidation loss: 0.777130\tBest loss: 0.777130\tAccuracy: 80.58%\n",
      "23\tValidation loss: 0.721941\tBest loss: 0.721941\tAccuracy: 79.86%\n",
      "24\tValidation loss: 0.716986\tBest loss: 0.716986\tAccuracy: 82.01%\n",
      "25\tValidation loss: 0.672162\tBest loss: 0.672162\tAccuracy: 83.45%\n",
      "26\tValidation loss: 0.646961\tBest loss: 0.646961\tAccuracy: 85.61%\n",
      "27\tValidation loss: 0.641701\tBest loss: 0.641701\tAccuracy: 84.89%\n",
      "28\tValidation loss: 0.595737\tBest loss: 0.595737\tAccuracy: 87.77%\n",
      "29\tValidation loss: 0.600414\tBest loss: 0.595737\tAccuracy: 87.77%\n",
      "30\tValidation loss: 0.562440\tBest loss: 0.562440\tAccuracy: 87.05%\n",
      "31\tValidation loss: 0.545674\tBest loss: 0.545674\tAccuracy: 87.05%\n",
      "32\tValidation loss: 0.541912\tBest loss: 0.541912\tAccuracy: 84.89%\n",
      "33\tValidation loss: 0.531688\tBest loss: 0.531688\tAccuracy: 89.21%\n",
      "34\tValidation loss: 0.549036\tBest loss: 0.531688\tAccuracy: 86.33%\n",
      "35\tValidation loss: 0.546807\tBest loss: 0.531688\tAccuracy: 85.61%\n",
      "36\tValidation loss: 0.552242\tBest loss: 0.531688\tAccuracy: 87.77%\n",
      "37\tValidation loss: 0.525934\tBest loss: 0.525934\tAccuracy: 86.33%\n",
      "38\tValidation loss: 0.473245\tBest loss: 0.473245\tAccuracy: 87.05%\n",
      "39\tValidation loss: 0.486795\tBest loss: 0.473245\tAccuracy: 88.49%\n",
      "40\tValidation loss: 0.501553\tBest loss: 0.473245\tAccuracy: 88.49%\n",
      "41\tValidation loss: 0.461843\tBest loss: 0.461843\tAccuracy: 89.93%\n",
      "42\tValidation loss: 0.461106\tBest loss: 0.461106\tAccuracy: 87.05%\n",
      "43\tValidation loss: 0.451644\tBest loss: 0.451644\tAccuracy: 86.33%\n",
      "44\tValidation loss: 0.426914\tBest loss: 0.426914\tAccuracy: 88.49%\n",
      "45\tValidation loss: 0.439436\tBest loss: 0.426914\tAccuracy: 87.77%\n",
      "46\tValidation loss: 0.441851\tBest loss: 0.426914\tAccuracy: 88.49%\n",
      "47\tValidation loss: 0.449620\tBest loss: 0.426914\tAccuracy: 89.21%\n",
      "48\tValidation loss: 0.422116\tBest loss: 0.422116\tAccuracy: 88.49%\n",
      "49\tValidation loss: 0.405623\tBest loss: 0.405623\tAccuracy: 88.49%\n",
      "50\tValidation loss: 0.424601\tBest loss: 0.405623\tAccuracy: 87.05%\n",
      "51\tValidation loss: 0.429438\tBest loss: 0.405623\tAccuracy: 84.17%\n",
      "52\tValidation loss: 0.409932\tBest loss: 0.405623\tAccuracy: 89.93%\n",
      "53\tValidation loss: 0.393753\tBest loss: 0.393753\tAccuracy: 89.21%\n",
      "54\tValidation loss: 0.385049\tBest loss: 0.385049\tAccuracy: 89.93%\n",
      "55\tValidation loss: 0.377457\tBest loss: 0.377457\tAccuracy: 90.65%\n",
      "56\tValidation loss: 0.379447\tBest loss: 0.377457\tAccuracy: 88.49%\n",
      "57\tValidation loss: 0.375816\tBest loss: 0.375816\tAccuracy: 90.65%\n",
      "58\tValidation loss: 0.381931\tBest loss: 0.375816\tAccuracy: 91.37%\n",
      "59\tValidation loss: 0.377429\tBest loss: 0.375816\tAccuracy: 89.93%\n",
      "60\tValidation loss: 0.342451\tBest loss: 0.342451\tAccuracy: 90.65%\n",
      "61\tValidation loss: 0.361621\tBest loss: 0.342451\tAccuracy: 89.21%\n",
      "62\tValidation loss: 0.350895\tBest loss: 0.342451\tAccuracy: 92.09%\n",
      "63\tValidation loss: 0.367538\tBest loss: 0.342451\tAccuracy: 90.65%\n",
      "64\tValidation loss: 0.382366\tBest loss: 0.342451\tAccuracy: 89.93%\n",
      "65\tValidation loss: 0.356515\tBest loss: 0.342451\tAccuracy: 89.21%\n",
      "66\tValidation loss: 0.335959\tBest loss: 0.335959\tAccuracy: 92.09%\n",
      "67\tValidation loss: 0.332590\tBest loss: 0.332590\tAccuracy: 91.37%\n",
      "68\tValidation loss: 0.329739\tBest loss: 0.329739\tAccuracy: 92.09%\n",
      "69\tValidation loss: 0.328499\tBest loss: 0.328499\tAccuracy: 90.65%\n",
      "70\tValidation loss: 0.320847\tBest loss: 0.320847\tAccuracy: 91.37%\n",
      "71\tValidation loss: 0.315209\tBest loss: 0.315209\tAccuracy: 91.37%\n",
      "72\tValidation loss: 0.314262\tBest loss: 0.314262\tAccuracy: 89.93%\n",
      "73\tValidation loss: 0.323264\tBest loss: 0.314262\tAccuracy: 91.37%\n",
      "74\tValidation loss: 0.314889\tBest loss: 0.314262\tAccuracy: 90.65%\n",
      "75\tValidation loss: 0.292197\tBest loss: 0.292197\tAccuracy: 92.81%\n",
      "76\tValidation loss: 0.291725\tBest loss: 0.291725\tAccuracy: 91.37%\n",
      "77\tValidation loss: 0.300265\tBest loss: 0.291725\tAccuracy: 92.81%\n",
      "78\tValidation loss: 0.296246\tBest loss: 0.291725\tAccuracy: 92.81%\n",
      "79\tValidation loss: 0.296760\tBest loss: 0.291725\tAccuracy: 92.09%\n",
      "80\tValidation loss: 0.305922\tBest loss: 0.291725\tAccuracy: 91.37%\n",
      "81\tValidation loss: 0.308125\tBest loss: 0.291725\tAccuracy: 92.09%\n",
      "82\tValidation loss: 0.304595\tBest loss: 0.291725\tAccuracy: 91.37%\n",
      "83\tValidation loss: 0.289282\tBest loss: 0.289282\tAccuracy: 92.09%\n",
      "84\tValidation loss: 0.299889\tBest loss: 0.289282\tAccuracy: 91.37%\n",
      "85\tValidation loss: 0.284391\tBest loss: 0.284391\tAccuracy: 94.24%\n",
      "86\tValidation loss: 0.284952\tBest loss: 0.284391\tAccuracy: 92.09%\n",
      "87\tValidation loss: 0.265122\tBest loss: 0.265122\tAccuracy: 94.24%\n",
      "88\tValidation loss: 0.263185\tBest loss: 0.263185\tAccuracy: 93.53%\n",
      "89\tValidation loss: 0.265277\tBest loss: 0.263185\tAccuracy: 93.53%\n",
      "90\tValidation loss: 0.251451\tBest loss: 0.251451\tAccuracy: 92.09%\n",
      "91\tValidation loss: 0.241221\tBest loss: 0.241221\tAccuracy: 92.09%\n",
      "92\tValidation loss: 0.255050\tBest loss: 0.241221\tAccuracy: 92.09%\n",
      "93\tValidation loss: 0.265020\tBest loss: 0.241221\tAccuracy: 92.81%\n",
      "94\tValidation loss: 0.263829\tBest loss: 0.241221\tAccuracy: 93.53%\n",
      "95\tValidation loss: 0.251728\tBest loss: 0.241221\tAccuracy: 92.09%\n",
      "96\tValidation loss: 0.240629\tBest loss: 0.240629\tAccuracy: 92.81%\n",
      "97\tValidation loss: 0.241089\tBest loss: 0.240629\tAccuracy: 94.24%\n",
      "98\tValidation loss: 0.231760\tBest loss: 0.231760\tAccuracy: 93.53%\n",
      "99\tValidation loss: 0.248464\tBest loss: 0.231760\tAccuracy: 92.09%\n",
      "100\tValidation loss: 0.236447\tBest loss: 0.231760\tAccuracy: 93.53%\n",
      "101\tValidation loss: 0.232179\tBest loss: 0.231760\tAccuracy: 94.24%\n",
      "102\tValidation loss: 0.229282\tBest loss: 0.229282\tAccuracy: 94.96%\n",
      "103\tValidation loss: 0.243989\tBest loss: 0.229282\tAccuracy: 94.24%\n",
      "104\tValidation loss: 0.248908\tBest loss: 0.229282\tAccuracy: 92.09%\n",
      "105\tValidation loss: 0.242055\tBest loss: 0.229282\tAccuracy: 92.81%\n",
      "106\tValidation loss: 0.261891\tBest loss: 0.229282\tAccuracy: 92.81%\n",
      "107\tValidation loss: 0.267899\tBest loss: 0.229282\tAccuracy: 92.09%\n",
      "108\tValidation loss: 0.257733\tBest loss: 0.229282\tAccuracy: 92.81%\n",
      "109\tValidation loss: 0.254875\tBest loss: 0.229282\tAccuracy: 93.53%\n",
      "110\tValidation loss: 0.259436\tBest loss: 0.229282\tAccuracy: 92.81%\n",
      "111\tValidation loss: 0.261515\tBest loss: 0.229282\tAccuracy: 91.37%\n",
      "112\tValidation loss: 0.246594\tBest loss: 0.229282\tAccuracy: 93.53%\n",
      "113\tValidation loss: 0.257433\tBest loss: 0.229282\tAccuracy: 91.37%\n",
      "114\tValidation loss: 0.277434\tBest loss: 0.229282\tAccuracy: 90.65%\n",
      "115\tValidation loss: 0.251622\tBest loss: 0.229282\tAccuracy: 92.81%\n",
      "116\tValidation loss: 0.229370\tBest loss: 0.229282\tAccuracy: 94.96%\n",
      "117\tValidation loss: 0.241191\tBest loss: 0.229282\tAccuracy: 94.24%\n",
      "118\tValidation loss: 0.221495\tBest loss: 0.221495\tAccuracy: 94.24%\n",
      "119\tValidation loss: 0.244127\tBest loss: 0.221495\tAccuracy: 93.53%\n",
      "120\tValidation loss: 0.219011\tBest loss: 0.219011\tAccuracy: 94.24%\n",
      "121\tValidation loss: 0.215847\tBest loss: 0.215847\tAccuracy: 94.24%\n",
      "122\tValidation loss: 0.230902\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "123\tValidation loss: 0.235447\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "124\tValidation loss: 0.225355\tBest loss: 0.215847\tAccuracy: 93.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.231348\tBest loss: 0.215847\tAccuracy: 92.81%\n",
      "126\tValidation loss: 0.234544\tBest loss: 0.215847\tAccuracy: 92.81%\n",
      "127\tValidation loss: 0.216587\tBest loss: 0.215847\tAccuracy: 94.24%\n",
      "128\tValidation loss: 0.223359\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "129\tValidation loss: 0.218677\tBest loss: 0.215847\tAccuracy: 94.96%\n",
      "130\tValidation loss: 0.216134\tBest loss: 0.215847\tAccuracy: 94.96%\n",
      "131\tValidation loss: 0.217583\tBest loss: 0.215847\tAccuracy: 94.96%\n",
      "132\tValidation loss: 0.234868\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "133\tValidation loss: 0.224467\tBest loss: 0.215847\tAccuracy: 94.96%\n",
      "134\tValidation loss: 0.221161\tBest loss: 0.215847\tAccuracy: 94.96%\n",
      "135\tValidation loss: 0.222788\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "136\tValidation loss: 0.219483\tBest loss: 0.215847\tAccuracy: 93.53%\n",
      "137\tValidation loss: 0.211975\tBest loss: 0.211975\tAccuracy: 94.24%\n",
      "138\tValidation loss: 0.206933\tBest loss: 0.206933\tAccuracy: 94.24%\n",
      "139\tValidation loss: 0.206518\tBest loss: 0.206518\tAccuracy: 94.96%\n",
      "140\tValidation loss: 0.200274\tBest loss: 0.200274\tAccuracy: 93.53%\n",
      "141\tValidation loss: 0.192687\tBest loss: 0.192687\tAccuracy: 94.24%\n",
      "142\tValidation loss: 0.187905\tBest loss: 0.187905\tAccuracy: 93.53%\n",
      "143\tValidation loss: 0.197780\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "144\tValidation loss: 0.204508\tBest loss: 0.187905\tAccuracy: 94.96%\n",
      "145\tValidation loss: 0.197823\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "146\tValidation loss: 0.210742\tBest loss: 0.187905\tAccuracy: 92.81%\n",
      "147\tValidation loss: 0.204116\tBest loss: 0.187905\tAccuracy: 93.53%\n",
      "148\tValidation loss: 0.196282\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "149\tValidation loss: 0.199134\tBest loss: 0.187905\tAccuracy: 94.96%\n",
      "150\tValidation loss: 0.197797\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "151\tValidation loss: 0.199939\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "152\tValidation loss: 0.195923\tBest loss: 0.187905\tAccuracy: 94.24%\n",
      "153\tValidation loss: 0.189919\tBest loss: 0.187905\tAccuracy: 94.96%\n",
      "154\tValidation loss: 0.185643\tBest loss: 0.185643\tAccuracy: 94.96%\n",
      "155\tValidation loss: 0.184572\tBest loss: 0.184572\tAccuracy: 94.96%\n",
      "156\tValidation loss: 0.195934\tBest loss: 0.184572\tAccuracy: 93.53%\n",
      "157\tValidation loss: 0.204563\tBest loss: 0.184572\tAccuracy: 94.24%\n",
      "158\tValidation loss: 0.181668\tBest loss: 0.181668\tAccuracy: 94.24%\n",
      "159\tValidation loss: 0.179136\tBest loss: 0.179136\tAccuracy: 94.96%\n",
      "160\tValidation loss: 0.187445\tBest loss: 0.179136\tAccuracy: 94.96%\n",
      "161\tValidation loss: 0.197393\tBest loss: 0.179136\tAccuracy: 94.24%\n",
      "162\tValidation loss: 0.188351\tBest loss: 0.179136\tAccuracy: 94.24%\n",
      "163\tValidation loss: 0.191672\tBest loss: 0.179136\tAccuracy: 94.24%\n",
      "164\tValidation loss: 0.186351\tBest loss: 0.179136\tAccuracy: 93.53%\n",
      "165\tValidation loss: 0.172935\tBest loss: 0.172935\tAccuracy: 94.96%\n",
      "166\tValidation loss: 0.184235\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "167\tValidation loss: 0.184426\tBest loss: 0.172935\tAccuracy: 94.96%\n",
      "168\tValidation loss: 0.180175\tBest loss: 0.172935\tAccuracy: 94.96%\n",
      "169\tValidation loss: 0.182855\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "170\tValidation loss: 0.189225\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "171\tValidation loss: 0.186977\tBest loss: 0.172935\tAccuracy: 92.09%\n",
      "172\tValidation loss: 0.181719\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "173\tValidation loss: 0.179162\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "174\tValidation loss: 0.179987\tBest loss: 0.172935\tAccuracy: 94.96%\n",
      "175\tValidation loss: 0.197695\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "176\tValidation loss: 0.214684\tBest loss: 0.172935\tAccuracy: 92.09%\n",
      "177\tValidation loss: 0.217643\tBest loss: 0.172935\tAccuracy: 92.09%\n",
      "178\tValidation loss: 0.210075\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "179\tValidation loss: 0.200649\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "180\tValidation loss: 0.194994\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "181\tValidation loss: 0.191300\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "182\tValidation loss: 0.188982\tBest loss: 0.172935\tAccuracy: 93.53%\n",
      "183\tValidation loss: 0.178388\tBest loss: 0.172935\tAccuracy: 94.96%\n",
      "184\tValidation loss: 0.179662\tBest loss: 0.172935\tAccuracy: 94.24%\n",
      "185\tValidation loss: 0.170216\tBest loss: 0.170216\tAccuracy: 94.24%\n",
      "186\tValidation loss: 0.176455\tBest loss: 0.170216\tAccuracy: 93.53%\n",
      "187\tValidation loss: 0.181000\tBest loss: 0.170216\tAccuracy: 93.53%\n",
      "188\tValidation loss: 0.180618\tBest loss: 0.170216\tAccuracy: 94.96%\n",
      "189\tValidation loss: 0.175456\tBest loss: 0.170216\tAccuracy: 95.68%\n",
      "190\tValidation loss: 0.179959\tBest loss: 0.170216\tAccuracy: 94.24%\n",
      "191\tValidation loss: 0.184191\tBest loss: 0.170216\tAccuracy: 93.53%\n",
      "192\tValidation loss: 0.184282\tBest loss: 0.170216\tAccuracy: 92.81%\n",
      "193\tValidation loss: 0.172511\tBest loss: 0.170216\tAccuracy: 94.24%\n",
      "194\tValidation loss: 0.160449\tBest loss: 0.160449\tAccuracy: 94.96%\n",
      "195\tValidation loss: 0.169856\tBest loss: 0.160449\tAccuracy: 94.24%\n",
      "196\tValidation loss: 0.164936\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "197\tValidation loss: 0.174732\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "198\tValidation loss: 0.181368\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "199\tValidation loss: 0.180951\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "200\tValidation loss: 0.162193\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "201\tValidation loss: 0.174869\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "202\tValidation loss: 0.174749\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "203\tValidation loss: 0.178081\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "204\tValidation loss: 0.165880\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "205\tValidation loss: 0.172657\tBest loss: 0.160449\tAccuracy: 92.81%\n",
      "206\tValidation loss: 0.169415\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "207\tValidation loss: 0.164984\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "208\tValidation loss: 0.171448\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "209\tValidation loss: 0.167445\tBest loss: 0.160449\tAccuracy: 93.53%\n",
      "210\tValidation loss: 0.165778\tBest loss: 0.160449\tAccuracy: 94.24%\n",
      "211\tValidation loss: 0.157354\tBest loss: 0.157354\tAccuracy: 94.96%\n",
      "212\tValidation loss: 0.168687\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "213\tValidation loss: 0.165542\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "214\tValidation loss: 0.168685\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "215\tValidation loss: 0.177360\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "216\tValidation loss: 0.172791\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "217\tValidation loss: 0.172279\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "218\tValidation loss: 0.176158\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "219\tValidation loss: 0.174408\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "220\tValidation loss: 0.168755\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "221\tValidation loss: 0.166930\tBest loss: 0.157354\tAccuracy: 92.81%\n",
      "222\tValidation loss: 0.165736\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "223\tValidation loss: 0.161528\tBest loss: 0.157354\tAccuracy: 94.96%\n",
      "224\tValidation loss: 0.163716\tBest loss: 0.157354\tAccuracy: 94.96%\n",
      "225\tValidation loss: 0.167333\tBest loss: 0.157354\tAccuracy: 94.96%\n",
      "226\tValidation loss: 0.160242\tBest loss: 0.157354\tAccuracy: 95.68%\n",
      "227\tValidation loss: 0.166298\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "228\tValidation loss: 0.179971\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "229\tValidation loss: 0.178080\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "230\tValidation loss: 0.176593\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "231\tValidation loss: 0.174201\tBest loss: 0.157354\tAccuracy: 94.24%\n",
      "232\tValidation loss: 0.181236\tBest loss: 0.157354\tAccuracy: 93.53%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x00000252A18B00D0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x000002529EEAA840>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'X_valid': array([[ 0.73635,  0.73922, ...,  0.01206,  0.01206],\n",
       "       [ 0.37816,  0.34719, ...,  0.00849,  0.00849],\n",
       "       ...,\n",
       "       [ 0.56511,  0.58633, ...,  0.01732,  0.01732],\n",
       "       [ 0.54829,  0.72283, ...,  0.013  ,  0.013  ]]), 'y_valid': array([  9.,  10., ...,  28.,   6.]), 'n_epochs': 1000},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'n_neurons': [300, 500, 700, 1000], 'batch_size': [10, 50, 100, 500], 'learning_rate': [0.01, 0.05, 0.1], 'activation': [<function elu at 0x00000252A18B00D0>, <function relu at 0x00000252A18B50D0>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9EA0>, <fu...training.rmsprop.RMSPropOptimizer'>, <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [300, 500, 700, 1000],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.elu, tf.nn.relu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    \"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6],\n",
    "    \"dropout_rate\": [0.2, 0.3, 0.4, 0],\n",
    "    \"optimizer_class\": [tf.train.AdamOptimizer, tf.train.RMSPropOptimizer, tf.train.AdagradOptimizer],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                fit_params={\"X_valid\": X_valid_reshaped, \"y_valid\": y_valid, \"n_epochs\": 1000},\n",
    "#                                 fit_params={\"n_epochs\": 50},\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_class': <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, 'n_neurons': 300, 'n_hidden_layers': 5, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'batch_size': 50, 'activation': <function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000252A56A9488>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98378378378378384"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(rnd_search.best_params_)\n",
    "y_pred = rnd_search.predict(X_test_reshaped)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Second CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('../CachedData.csv')\n",
    "\n",
    "X_load = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "y_load = np.array(df.iloc[:,-1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 641)\n",
      "(12, 40)\n",
      "9.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEYCAYAAAAXsVIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5b66fdef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAEYCAYAAAAwBWxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyaJkiRJ2otJoiRJkvZikihJkqS9/P8izE0Hy/XZRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5962004a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "sample = librosa.core.stft(y=X_load[0], n_fft=400, win_length=128, window='hamming', center=True, dtype=np.float, pad_mode='reflect')\n",
    "\n",
    "sample_chroma = librosa.feature.chroma_stft(y=X_load[6], sr=44100, n_fft=20480, hop_length=520)\n",
    "\n",
    "print(sample.shape)\n",
    "print(sample_chroma.shape)\n",
    "print(y_load[40])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "librosa.display.specshow(librosa.amplitude_to_db(sample,ref=np.max),y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(sample_chroma, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa.display\n",
    "\n",
    "processedData_path = \"preprocessedSamples_spect.data\"\n",
    "processedX = np.zeros((len(X_load),256,16,1), dtype=np.float)\n",
    "processedy = np.zeros(len(y_load), dtype=np.float)\n",
    "\n",
    "for i in range(len(X_load)):\n",
    "    sample = librosa.core.stft(y=X_load[i], n_fft=511, hop_length=None, win_length=256, window='hamming', center=True, dtype=np.float32, pad_mode='reflect')\n",
    "    sample = np.atleast_3d(sample)\n",
    "    processedX[i] = sample\n",
    "    processedy[i] = y_load[i]\n",
    "\n",
    "print(processedX[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "[[[ -3.23619366e+00]\n",
      "  [  1.16145933e+00]\n",
      "  [  1.21057081e+00]\n",
      "  ..., \n",
      "  [  8.59650016e-01]\n",
      "  [  4.54807669e-01]\n",
      "  [ -1.19688570e+00]]\n",
      "\n",
      " [[  4.64826250e+00]\n",
      "  [ -2.10059786e+00]\n",
      "  [ -1.34036231e+00]\n",
      "  ..., \n",
      "  [ -2.12062287e+00]\n",
      "  [ -6.82256743e-02]\n",
      "  [  1.45642459e+00]]\n",
      "\n",
      " [[ -6.66698265e+00]\n",
      "  [  3.38708758e+00]\n",
      "  [  1.96856248e+00]\n",
      "  ..., \n",
      "  [  5.07859612e+00]\n",
      "  [ -1.27503741e+00]\n",
      "  [ -1.46690404e+00]]\n",
      "\n",
      " ..., \n",
      " [[  7.42667494e-03]\n",
      "  [ -4.38474258e-03]\n",
      "  [  4.27595153e-03]\n",
      "  ..., \n",
      "  [  1.88071874e-03]\n",
      "  [ -2.20070337e-03]\n",
      "  [  1.06912935e-02]]\n",
      "\n",
      " [[  7.41749862e-03]\n",
      "  [ -7.36583082e-04]\n",
      "  [  4.51048696e-03]\n",
      "  ..., \n",
      "  [  1.76071131e-03]\n",
      "  [ -1.98100437e-03]\n",
      "  [ -1.39174249e-03]]\n",
      "\n",
      " [[ -7.44780758e-03]\n",
      "  [  1.76233775e-03]\n",
      "  [ -4.39368002e-03]\n",
      "  ..., \n",
      "  [ -1.82072457e-03]\n",
      "  [  2.09195470e-03]\n",
      "  [ -2.17995001e-03]]]\n",
      "(12377, 256, 16, 1) (12377,) (1000, 256, 16, 1) (1000,)\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "shufled_processedX, shufled_processedy = shuffle(processedX, processedy)\n",
    "\n",
    "for i in range(len(shufled_processedy)):\n",
    "\tshufled_processedy[i] = (shufled_processedy[i]) - 1\n",
    "\n",
    "X_train = np.array(shufled_processedX[:-2000], dtype=np.float)\n",
    "y_train = np.array(shufled_processedy[:-2000], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(shufled_processedX[-2000:-1000], dtype=np.float)\n",
    "y_valid = np.array(shufled_processedy[-2000:-1000], dtype=np.float)\n",
    "\n",
    "X_test = np.array(shufled_processedX[-1000:], dtype=np.float)\n",
    "y_test = np.array(shufled_processedy[-1000:], dtype=np.float)\n",
    "print(y_test[999])\n",
    "print(X_test[999])\n",
    "\n",
    "print(X_train.shape,y_train.shape, X_valid.shape, y_valid.shape)\n",
    "\n",
    "n_outputs = len(np.unique(shufled_processedy))\n",
    "print(np.unique(shufled_processedy))\n",
    "n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "height = 12\n",
    "width = 80\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "n_outputs = 48\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "conv1_fmaps = 32 #filters\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "pool1_fmaps = conv1_fmaps\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    \n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.2\n",
    "conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "pool2_fmaps = conv2_fmaps\n",
    "with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 3 * 20 * pool2_fmaps])\n",
    "    pool2_flat_drop = tf.layers.dropout(pool2_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "n_fc1 = 600\n",
    "fc1_dropout_rate = 0.2\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool2_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1_drop, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84185\n",
      "3.55779\n",
      "2.94268\n",
      "Epoch 0, train accuracy: 37.5000%, valid. accuracy: 40.4624%, valid. best loss: 2.942683\n",
      "2.17021\n",
      "1.5232\n",
      "1.37907\n",
      "Epoch 1, train accuracy: 67.5000%, valid. accuracy: 66.4740%, valid. best loss: 1.379066\n",
      "1.25059\n",
      "0.963855\n",
      "0.991217\n",
      "Epoch 2, train accuracy: 82.5000%, valid. accuracy: 75.1445%, valid. best loss: 0.963855\n",
      "0.880133\n",
      "0.911894\n",
      "0.762544\n",
      "Epoch 3, train accuracy: 77.5000%, valid. accuracy: 72.8324%, valid. best loss: 0.762544\n",
      "0.768554\n",
      "0.73361\n",
      "0.771953\n",
      "Epoch 4, train accuracy: 90.0000%, valid. accuracy: 76.8786%, valid. best loss: 0.733610\n",
      "0.762853\n",
      "0.757052\n",
      "0.725783\n",
      "Epoch 5, train accuracy: 97.5000%, valid. accuracy: 78.0347%, valid. best loss: 0.725783\n",
      "0.814985\n",
      "0.719421\n",
      "0.702218\n",
      "Epoch 6, train accuracy: 87.5000%, valid. accuracy: 78.6127%, valid. best loss: 0.702218\n",
      "0.781102\n",
      "0.678829\n",
      "0.631197\n",
      "Epoch 7, train accuracy: 95.0000%, valid. accuracy: 80.3468%, valid. best loss: 0.631197\n",
      "0.614668\n",
      "0.610057\n",
      "0.677138\n",
      "Epoch 8, train accuracy: 92.5000%, valid. accuracy: 79.1907%, valid. best loss: 0.610057\n",
      "0.710185\n",
      "0.578408\n",
      "0.761038\n",
      "Epoch 9, train accuracy: 100.0000%, valid. accuracy: 83.2370%, valid. best loss: 0.578408\n",
      "0.631957\n",
      "0.687201\n",
      "0.726155\n",
      "Epoch 10, train accuracy: 100.0000%, valid. accuracy: 83.8150%, valid. best loss: 0.578408\n",
      "0.618363\n",
      "0.584697\n",
      "0.72389\n",
      "Epoch 11, train accuracy: 97.5000%, valid. accuracy: 82.0809%, valid. best loss: 0.578408\n",
      "0.73696\n",
      "0.621735\n",
      "0.577859\n",
      "Epoch 12, train accuracy: 100.0000%, valid. accuracy: 83.8150%, valid. best loss: 0.577859\n",
      "0.656727\n",
      "0.760306\n",
      "0.701035\n",
      "Epoch 13, train accuracy: 100.0000%, valid. accuracy: 83.2370%, valid. best loss: 0.577859\n",
      "0.716497\n",
      "0.652096\n",
      "0.675264\n",
      "Epoch 14, train accuracy: 97.5000%, valid. accuracy: 84.3931%, valid. best loss: 0.577859\n",
      "0.674909\n",
      "0.691543\n",
      "0.624599\n",
      "Epoch 15, train accuracy: 97.5000%, valid. accuracy: 85.5491%, valid. best loss: 0.577859\n",
      "0.633135\n",
      "0.561318\n",
      "0.691011\n",
      "Epoch 16, train accuracy: 100.0000%, valid. accuracy: 87.2832%, valid. best loss: 0.561318\n",
      "0.717321\n",
      "0.714534\n",
      "0.664836\n",
      "Epoch 17, train accuracy: 100.0000%, valid. accuracy: 83.8150%, valid. best loss: 0.561318\n",
      "0.722297\n",
      "0.644576\n",
      "0.694376\n",
      "Epoch 18, train accuracy: 100.0000%, valid. accuracy: 84.9711%, valid. best loss: 0.561318\n",
      "0.666811\n",
      "0.711396\n",
      "0.602245\n",
      "Epoch 19, train accuracy: 100.0000%, valid. accuracy: 86.1272%, valid. best loss: 0.561318\n",
      "0.572193\n",
      "0.5638\n",
      "0.655361\n",
      "Epoch 20, train accuracy: 100.0000%, valid. accuracy: 86.7052%, valid. best loss: 0.561318\n",
      "0.627343\n",
      "0.585288\n",
      "0.619921\n",
      "Epoch 21, train accuracy: 100.0000%, valid. accuracy: 86.1272%, valid. best loss: 0.561318\n",
      "0.559587\n",
      "0.673097\n",
      "0.744718\n",
      "Epoch 22, train accuracy: 100.0000%, valid. accuracy: 85.5491%, valid. best loss: 0.559587\n",
      "0.773287\n",
      "0.705039\n",
      "0.651309\n",
      "Epoch 23, train accuracy: 100.0000%, valid. accuracy: 86.1272%, valid. best loss: 0.559587\n",
      "0.691518\n",
      "0.684305\n",
      "0.656381\n",
      "Epoch 24, train accuracy: 100.0000%, valid. accuracy: 85.5491%, valid. best loss: 0.559587\n",
      "0.704034\n",
      "0.899792\n",
      "0.758833\n",
      "Epoch 25, train accuracy: 95.0000%, valid. accuracy: 84.9711%, valid. best loss: 0.559587\n",
      "0.727823\n",
      "0.699265\n",
      "0.731984\n",
      "Epoch 26, train accuracy: 100.0000%, valid. accuracy: 86.1272%, valid. best loss: 0.559587\n",
      "0.659452\n",
      "0.605592\n",
      "0.612894\n",
      "Epoch 27, train accuracy: 100.0000%, valid. accuracy: 87.8613%, valid. best loss: 0.559587\n",
      "0.606984\n",
      "0.584255\n",
      "0.623157\n",
      "Epoch 28, train accuracy: 100.0000%, valid. accuracy: 84.9711%, valid. best loss: 0.559587\n",
      "0.713631\n",
      "0.725222\n",
      "0.839203\n",
      "Epoch 29, train accuracy: 100.0000%, valid. accuracy: 84.9711%, valid. best loss: 0.559587\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.96087\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 40\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 10\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        idx = 0\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "        #for idx in range(len(X_train) // batch_size):\n",
    "#             print(idx)\n",
    "#             X_reshaped = np.reshape(X_train[idx],(1, -1))\n",
    "#             y_reshaped = np.reshape(y_train[idx],(-1))\n",
    "#             print(X_reshaped.shape)\n",
    "#             print(y_reshaped.shape)\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices].astype(int)\n",
    "            X_batch_reshaped = np.reshape(X_batch,(len(X_batch), -1))\n",
    "            y_batch_reshaped = np.reshape(y_batch,(-1))\n",
    "            sess.run(training_op, feed_dict={X: X_batch_reshaped, y: y_batch, training: True})\n",
    "            if idx % check_interval == 0:\n",
    "                X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "                loss_val = loss.eval(feed_dict={X: X_valid_reshaped,\n",
    "                                                y: y_valid})\n",
    "                print(loss_val)\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "            idx += 1\n",
    "        X_batch_reshaped = np.reshape(X_batch,(len(X_batch), -1))\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch_reshaped, y: y_batch})\n",
    "        X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid_reshaped,\n",
    "                                           y: y_valid})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    X_test_reshaped = np.reshape(X_test,(len(X_test), -1))\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test_reshaped,\n",
    "                                        y: y_test})\n",
    "    print(\"Final accuracy on test set:\", acc_test)\n",
    "    #save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
