{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('samples_nylonGuitar_1024_Mm7_R03.csv')\n",
    "\n",
    "X = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "y = np.array(df.iloc[:,-1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "processedData_path = \"preprocessedSamples.data\"\n",
    "\n",
    "if os.path.isfile(processedData_path): #if already preprocessed\n",
    "    df_new = pd.read_pickle(processedData_path)\n",
    "else:\n",
    "    for i in range(len(X)):\n",
    "        sample = np.array(X[i], dtype=np.float)\n",
    "        sample = sample*np.hamming(1024)\n",
    "        sample = np.abs(np.fft.rfft(sample))[1:]\n",
    "        sample = np.append(sample, y[i])\n",
    "        try:\n",
    "            df_new = np.vstack([df_new, sample])\n",
    "        except:\n",
    "            df_new = np.array(sample, dtype=np.float)\n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "            df_new[i]\n",
    "    \n",
    "    df_new = pd.DataFrame(df_new)\n",
    "    \n",
    "    df_new.to_pickle(processedData_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160538</td>\n",
       "      <td>1.097057</td>\n",
       "      <td>2.579230</td>\n",
       "      <td>1.012018</td>\n",
       "      <td>4.476512</td>\n",
       "      <td>6.392529</td>\n",
       "      <td>2.835823</td>\n",
       "      <td>1.202161</td>\n",
       "      <td>8.097132</td>\n",
       "      <td>4.129657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038044</td>\n",
       "      <td>0.682103</td>\n",
       "      <td>2.181458</td>\n",
       "      <td>2.754363</td>\n",
       "      <td>4.384825</td>\n",
       "      <td>11.662422</td>\n",
       "      <td>7.668046</td>\n",
       "      <td>4.351508</td>\n",
       "      <td>4.368506</td>\n",
       "      <td>1.970593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018266</td>\n",
       "      <td>0.255641</td>\n",
       "      <td>1.787614</td>\n",
       "      <td>3.312136</td>\n",
       "      <td>5.729467</td>\n",
       "      <td>11.709544</td>\n",
       "      <td>5.990989</td>\n",
       "      <td>4.220113</td>\n",
       "      <td>4.843519</td>\n",
       "      <td>2.247771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041934</td>\n",
       "      <td>0.154276</td>\n",
       "      <td>1.223503</td>\n",
       "      <td>1.839473</td>\n",
       "      <td>1.740634</td>\n",
       "      <td>4.190585</td>\n",
       "      <td>2.284470</td>\n",
       "      <td>1.819566</td>\n",
       "      <td>1.732903</td>\n",
       "      <td>0.897682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101857</td>\n",
       "      <td>0.338243</td>\n",
       "      <td>0.466170</td>\n",
       "      <td>0.463306</td>\n",
       "      <td>3.051501</td>\n",
       "      <td>8.259836</td>\n",
       "      <td>3.682422</td>\n",
       "      <td>1.958645</td>\n",
       "      <td>7.499066</td>\n",
       "      <td>3.915087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040850</td>\n",
       "      <td>0.081194</td>\n",
       "      <td>0.334677</td>\n",
       "      <td>0.605658</td>\n",
       "      <td>3.903348</td>\n",
       "      <td>10.505771</td>\n",
       "      <td>4.703594</td>\n",
       "      <td>4.652761</td>\n",
       "      <td>13.386301</td>\n",
       "      <td>6.945506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.105481</td>\n",
       "      <td>0.532195</td>\n",
       "      <td>1.397383</td>\n",
       "      <td>1.331524</td>\n",
       "      <td>1.253465</td>\n",
       "      <td>4.397543</td>\n",
       "      <td>3.680579</td>\n",
       "      <td>2.930381</td>\n",
       "      <td>11.623168</td>\n",
       "      <td>6.416892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.106103</td>\n",
       "      <td>1.701259</td>\n",
       "      <td>5.742784</td>\n",
       "      <td>4.986935</td>\n",
       "      <td>1.507656</td>\n",
       "      <td>2.306115</td>\n",
       "      <td>4.750925</td>\n",
       "      <td>9.202651</td>\n",
       "      <td>42.217820</td>\n",
       "      <td>22.440398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040706</td>\n",
       "      <td>0.480354</td>\n",
       "      <td>3.827296</td>\n",
       "      <td>6.021511</td>\n",
       "      <td>0.968685</td>\n",
       "      <td>4.803226</td>\n",
       "      <td>5.350049</td>\n",
       "      <td>10.248151</td>\n",
       "      <td>19.165113</td>\n",
       "      <td>9.344392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.077678</td>\n",
       "      <td>0.176397</td>\n",
       "      <td>1.468389</td>\n",
       "      <td>2.157226</td>\n",
       "      <td>0.984026</td>\n",
       "      <td>2.110112</td>\n",
       "      <td>3.219406</td>\n",
       "      <td>5.492588</td>\n",
       "      <td>10.765436</td>\n",
       "      <td>5.424180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.128774</td>\n",
       "      <td>1.444365</td>\n",
       "      <td>2.177193</td>\n",
       "      <td>0.459292</td>\n",
       "      <td>0.784937</td>\n",
       "      <td>1.294625</td>\n",
       "      <td>2.857264</td>\n",
       "      <td>7.525758</td>\n",
       "      <td>3.619497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.266881</td>\n",
       "      <td>0.355779</td>\n",
       "      <td>3.021940</td>\n",
       "      <td>6.151220</td>\n",
       "      <td>6.598042</td>\n",
       "      <td>14.051604</td>\n",
       "      <td>5.559722</td>\n",
       "      <td>5.761228</td>\n",
       "      <td>12.838594</td>\n",
       "      <td>6.303104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.510408</td>\n",
       "      <td>2.373615</td>\n",
       "      <td>4.019623</td>\n",
       "      <td>5.496548</td>\n",
       "      <td>8.144357</td>\n",
       "      <td>6.373972</td>\n",
       "      <td>2.693568</td>\n",
       "      <td>0.487677</td>\n",
       "      <td>10.686451</td>\n",
       "      <td>6.396017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.730094</td>\n",
       "      <td>0.531236</td>\n",
       "      <td>1.856519</td>\n",
       "      <td>1.917044</td>\n",
       "      <td>4.421652</td>\n",
       "      <td>5.016493</td>\n",
       "      <td>3.296573</td>\n",
       "      <td>1.593588</td>\n",
       "      <td>0.365908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.519922</td>\n",
       "      <td>0.696026</td>\n",
       "      <td>0.582653</td>\n",
       "      <td>4.059979</td>\n",
       "      <td>10.152088</td>\n",
       "      <td>4.705362</td>\n",
       "      <td>5.869228</td>\n",
       "      <td>11.313011</td>\n",
       "      <td>5.579475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.038932</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>0.540924</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>3.382246</td>\n",
       "      <td>8.705749</td>\n",
       "      <td>5.443950</td>\n",
       "      <td>5.491937</td>\n",
       "      <td>16.240331</td>\n",
       "      <td>8.173362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.143798</td>\n",
       "      <td>0.231257</td>\n",
       "      <td>0.517093</td>\n",
       "      <td>0.370103</td>\n",
       "      <td>1.055709</td>\n",
       "      <td>0.996568</td>\n",
       "      <td>1.416133</td>\n",
       "      <td>3.729812</td>\n",
       "      <td>1.776112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.456393</td>\n",
       "      <td>0.870020</td>\n",
       "      <td>0.479554</td>\n",
       "      <td>1.061137</td>\n",
       "      <td>2.832232</td>\n",
       "      <td>2.392142</td>\n",
       "      <td>3.779474</td>\n",
       "      <td>6.558137</td>\n",
       "      <td>3.425337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.152697</td>\n",
       "      <td>0.716401</td>\n",
       "      <td>0.915419</td>\n",
       "      <td>0.979435</td>\n",
       "      <td>1.098984</td>\n",
       "      <td>2.412460</td>\n",
       "      <td>0.468729</td>\n",
       "      <td>2.429865</td>\n",
       "      <td>2.461548</td>\n",
       "      <td>1.234980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.357175</td>\n",
       "      <td>1.107716</td>\n",
       "      <td>0.649423</td>\n",
       "      <td>2.240258</td>\n",
       "      <td>4.697817</td>\n",
       "      <td>2.039797</td>\n",
       "      <td>0.782496</td>\n",
       "      <td>2.208509</td>\n",
       "      <td>1.205793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.033110</td>\n",
       "      <td>0.072417</td>\n",
       "      <td>1.105920</td>\n",
       "      <td>2.122932</td>\n",
       "      <td>1.818074</td>\n",
       "      <td>2.976293</td>\n",
       "      <td>1.415892</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>2.195019</td>\n",
       "      <td>1.342802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.018226</td>\n",
       "      <td>0.171578</td>\n",
       "      <td>1.379562</td>\n",
       "      <td>1.796498</td>\n",
       "      <td>1.161723</td>\n",
       "      <td>1.693148</td>\n",
       "      <td>1.067095</td>\n",
       "      <td>1.361180</td>\n",
       "      <td>3.267875</td>\n",
       "      <td>1.550720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.195622</td>\n",
       "      <td>0.772386</td>\n",
       "      <td>1.524316</td>\n",
       "      <td>1.203886</td>\n",
       "      <td>1.959756</td>\n",
       "      <td>1.346507</td>\n",
       "      <td>0.585960</td>\n",
       "      <td>3.200511</td>\n",
       "      <td>1.742746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.123247</td>\n",
       "      <td>1.209410</td>\n",
       "      <td>2.371360</td>\n",
       "      <td>0.527818</td>\n",
       "      <td>3.129227</td>\n",
       "      <td>1.204163</td>\n",
       "      <td>0.753213</td>\n",
       "      <td>2.251429</td>\n",
       "      <td>1.233257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.059331</td>\n",
       "      <td>0.132883</td>\n",
       "      <td>0.336626</td>\n",
       "      <td>0.540617</td>\n",
       "      <td>1.835852</td>\n",
       "      <td>5.120322</td>\n",
       "      <td>1.421194</td>\n",
       "      <td>2.315210</td>\n",
       "      <td>3.849741</td>\n",
       "      <td>1.852601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.184015</td>\n",
       "      <td>1.576577</td>\n",
       "      <td>2.526204</td>\n",
       "      <td>1.059388</td>\n",
       "      <td>1.775217</td>\n",
       "      <td>1.596976</td>\n",
       "      <td>1.979109</td>\n",
       "      <td>2.508898</td>\n",
       "      <td>1.452735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.050297</td>\n",
       "      <td>0.211754</td>\n",
       "      <td>1.062658</td>\n",
       "      <td>0.295846</td>\n",
       "      <td>0.326546</td>\n",
       "      <td>1.146326</td>\n",
       "      <td>0.518628</td>\n",
       "      <td>3.434998</td>\n",
       "      <td>4.444546</td>\n",
       "      <td>1.439643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.245666</td>\n",
       "      <td>0.369129</td>\n",
       "      <td>1.247930</td>\n",
       "      <td>1.899678</td>\n",
       "      <td>4.378119</td>\n",
       "      <td>3.089463</td>\n",
       "      <td>2.736913</td>\n",
       "      <td>4.401640</td>\n",
       "      <td>2.000504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.030129</td>\n",
       "      <td>0.309778</td>\n",
       "      <td>0.525158</td>\n",
       "      <td>0.443551</td>\n",
       "      <td>0.282123</td>\n",
       "      <td>0.996912</td>\n",
       "      <td>1.070193</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.877458</td>\n",
       "      <td>0.574386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.154472</td>\n",
       "      <td>0.223878</td>\n",
       "      <td>0.985571</td>\n",
       "      <td>1.746151</td>\n",
       "      <td>3.831430</td>\n",
       "      <td>3.235063</td>\n",
       "      <td>3.356056</td>\n",
       "      <td>5.476443</td>\n",
       "      <td>2.553496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>0.133001</td>\n",
       "      <td>0.121989</td>\n",
       "      <td>0.491264</td>\n",
       "      <td>0.239137</td>\n",
       "      <td>1.151545</td>\n",
       "      <td>3.275361</td>\n",
       "      <td>7.714350</td>\n",
       "      <td>5.038309</td>\n",
       "      <td>22.231028</td>\n",
       "      <td>12.319779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.154904</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>1.341710</td>\n",
       "      <td>0.446842</td>\n",
       "      <td>0.383684</td>\n",
       "      <td>1.902050</td>\n",
       "      <td>0.810468</td>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.301683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>0.259734</td>\n",
       "      <td>2.203576</td>\n",
       "      <td>1.301117</td>\n",
       "      <td>3.629562</td>\n",
       "      <td>8.160042</td>\n",
       "      <td>11.875620</td>\n",
       "      <td>12.044557</td>\n",
       "      <td>12.057507</td>\n",
       "      <td>34.403261</td>\n",
       "      <td>19.275711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>0.221867</td>\n",
       "      <td>0.552379</td>\n",
       "      <td>1.803526</td>\n",
       "      <td>1.739064</td>\n",
       "      <td>5.311072</td>\n",
       "      <td>5.262351</td>\n",
       "      <td>9.575081</td>\n",
       "      <td>9.390610</td>\n",
       "      <td>19.660178</td>\n",
       "      <td>10.861000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.141473</td>\n",
       "      <td>0.685645</td>\n",
       "      <td>1.095577</td>\n",
       "      <td>2.277471</td>\n",
       "      <td>3.763104</td>\n",
       "      <td>4.424763</td>\n",
       "      <td>0.255541</td>\n",
       "      <td>5.441439</td>\n",
       "      <td>2.731518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14352</th>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.206378</td>\n",
       "      <td>0.726317</td>\n",
       "      <td>1.211146</td>\n",
       "      <td>1.958067</td>\n",
       "      <td>3.463979</td>\n",
       "      <td>2.583131</td>\n",
       "      <td>2.697368</td>\n",
       "      <td>4.145763</td>\n",
       "      <td>2.085824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>0.195383</td>\n",
       "      <td>0.932897</td>\n",
       "      <td>2.288374</td>\n",
       "      <td>3.054594</td>\n",
       "      <td>3.674179</td>\n",
       "      <td>5.614014</td>\n",
       "      <td>6.777233</td>\n",
       "      <td>3.691108</td>\n",
       "      <td>11.764996</td>\n",
       "      <td>6.568670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>0.747925</td>\n",
       "      <td>3.977492</td>\n",
       "      <td>5.579396</td>\n",
       "      <td>8.643272</td>\n",
       "      <td>6.898350</td>\n",
       "      <td>6.254712</td>\n",
       "      <td>35.049140</td>\n",
       "      <td>20.902505</td>\n",
       "      <td>31.436301</td>\n",
       "      <td>17.499320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>0.011785</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>0.296367</td>\n",
       "      <td>2.897062</td>\n",
       "      <td>4.720489</td>\n",
       "      <td>4.567702</td>\n",
       "      <td>9.023767</td>\n",
       "      <td>18.958120</td>\n",
       "      <td>16.853487</td>\n",
       "      <td>14.286596</td>\n",
       "      <td>26.534160</td>\n",
       "      <td>15.219227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>0.247681</td>\n",
       "      <td>0.352058</td>\n",
       "      <td>0.619193</td>\n",
       "      <td>0.632059</td>\n",
       "      <td>3.367074</td>\n",
       "      <td>3.393917</td>\n",
       "      <td>0.217917</td>\n",
       "      <td>1.307545</td>\n",
       "      <td>1.350632</td>\n",
       "      <td>0.902873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>0.387182</td>\n",
       "      <td>1.575286</td>\n",
       "      <td>3.553341</td>\n",
       "      <td>3.653650</td>\n",
       "      <td>7.474724</td>\n",
       "      <td>17.670169</td>\n",
       "      <td>14.768580</td>\n",
       "      <td>9.721302</td>\n",
       "      <td>18.915611</td>\n",
       "      <td>10.275729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14358</th>\n",
       "      <td>0.038531</td>\n",
       "      <td>0.172336</td>\n",
       "      <td>0.711356</td>\n",
       "      <td>0.836362</td>\n",
       "      <td>2.845895</td>\n",
       "      <td>3.201506</td>\n",
       "      <td>0.704921</td>\n",
       "      <td>2.106691</td>\n",
       "      <td>4.600009</td>\n",
       "      <td>2.349636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14359</th>\n",
       "      <td>0.156862</td>\n",
       "      <td>2.452721</td>\n",
       "      <td>0.702132</td>\n",
       "      <td>5.207757</td>\n",
       "      <td>14.547520</td>\n",
       "      <td>26.447577</td>\n",
       "      <td>25.721802</td>\n",
       "      <td>20.375862</td>\n",
       "      <td>42.058041</td>\n",
       "      <td>24.481226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14360</th>\n",
       "      <td>0.062293</td>\n",
       "      <td>0.293533</td>\n",
       "      <td>1.143653</td>\n",
       "      <td>1.645301</td>\n",
       "      <td>4.659331</td>\n",
       "      <td>4.037520</td>\n",
       "      <td>5.492921</td>\n",
       "      <td>7.635987</td>\n",
       "      <td>15.445057</td>\n",
       "      <td>8.306014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14361</th>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>0.056625</td>\n",
       "      <td>0.070555</td>\n",
       "      <td>0.230797</td>\n",
       "      <td>0.118010</td>\n",
       "      <td>0.392492</td>\n",
       "      <td>0.322462</td>\n",
       "      <td>0.450379</td>\n",
       "      <td>0.228158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14362</th>\n",
       "      <td>0.852743</td>\n",
       "      <td>3.946200</td>\n",
       "      <td>4.242042</td>\n",
       "      <td>10.065298</td>\n",
       "      <td>28.298547</td>\n",
       "      <td>45.310828</td>\n",
       "      <td>21.586447</td>\n",
       "      <td>26.369138</td>\n",
       "      <td>49.836884</td>\n",
       "      <td>30.176218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14363</th>\n",
       "      <td>0.685924</td>\n",
       "      <td>2.493649</td>\n",
       "      <td>6.185336</td>\n",
       "      <td>6.568541</td>\n",
       "      <td>22.867865</td>\n",
       "      <td>28.589625</td>\n",
       "      <td>12.905906</td>\n",
       "      <td>13.120321</td>\n",
       "      <td>32.724241</td>\n",
       "      <td>20.795579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14364</th>\n",
       "      <td>0.295462</td>\n",
       "      <td>1.000266</td>\n",
       "      <td>2.967980</td>\n",
       "      <td>5.544236</td>\n",
       "      <td>19.181718</td>\n",
       "      <td>33.600524</td>\n",
       "      <td>22.783884</td>\n",
       "      <td>11.746232</td>\n",
       "      <td>17.034901</td>\n",
       "      <td>10.876460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.012045</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14365</th>\n",
       "      <td>0.074668</td>\n",
       "      <td>0.482791</td>\n",
       "      <td>1.389039</td>\n",
       "      <td>1.705551</td>\n",
       "      <td>2.166289</td>\n",
       "      <td>2.522254</td>\n",
       "      <td>4.712438</td>\n",
       "      <td>4.018516</td>\n",
       "      <td>7.816526</td>\n",
       "      <td>5.114222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14366</th>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.086233</td>\n",
       "      <td>0.168468</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>1.975305</td>\n",
       "      <td>4.187659</td>\n",
       "      <td>3.762081</td>\n",
       "      <td>1.085393</td>\n",
       "      <td>3.346082</td>\n",
       "      <td>1.640984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14367</th>\n",
       "      <td>0.122257</td>\n",
       "      <td>0.512128</td>\n",
       "      <td>0.413890</td>\n",
       "      <td>0.019082</td>\n",
       "      <td>5.015470</td>\n",
       "      <td>5.689785</td>\n",
       "      <td>9.439730</td>\n",
       "      <td>6.781539</td>\n",
       "      <td>15.617436</td>\n",
       "      <td>7.012260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14368</th>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.167281</td>\n",
       "      <td>0.295190</td>\n",
       "      <td>0.405347</td>\n",
       "      <td>0.955119</td>\n",
       "      <td>2.003681</td>\n",
       "      <td>2.898550</td>\n",
       "      <td>1.094338</td>\n",
       "      <td>2.147725</td>\n",
       "      <td>0.923953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14369</th>\n",
       "      <td>0.449699</td>\n",
       "      <td>2.643874</td>\n",
       "      <td>4.309592</td>\n",
       "      <td>10.278496</td>\n",
       "      <td>34.508376</td>\n",
       "      <td>61.729713</td>\n",
       "      <td>49.396734</td>\n",
       "      <td>26.947018</td>\n",
       "      <td>64.233896</td>\n",
       "      <td>41.112391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.026390</td>\n",
       "      <td>0.026456</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14370</th>\n",
       "      <td>0.284322</td>\n",
       "      <td>2.841545</td>\n",
       "      <td>6.383975</td>\n",
       "      <td>7.101405</td>\n",
       "      <td>22.803709</td>\n",
       "      <td>23.518685</td>\n",
       "      <td>16.377892</td>\n",
       "      <td>22.206718</td>\n",
       "      <td>41.033442</td>\n",
       "      <td>20.617108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14371</th>\n",
       "      <td>0.135393</td>\n",
       "      <td>0.886009</td>\n",
       "      <td>2.186299</td>\n",
       "      <td>4.382034</td>\n",
       "      <td>16.973103</td>\n",
       "      <td>28.299778</td>\n",
       "      <td>19.036774</td>\n",
       "      <td>14.905121</td>\n",
       "      <td>26.491886</td>\n",
       "      <td>12.497950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>0.197514</td>\n",
       "      <td>0.916207</td>\n",
       "      <td>0.531126</td>\n",
       "      <td>2.776535</td>\n",
       "      <td>9.888253</td>\n",
       "      <td>19.202340</td>\n",
       "      <td>13.490815</td>\n",
       "      <td>6.158388</td>\n",
       "      <td>9.475800</td>\n",
       "      <td>5.650832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14373</th>\n",
       "      <td>0.447264</td>\n",
       "      <td>3.524665</td>\n",
       "      <td>2.445509</td>\n",
       "      <td>2.656039</td>\n",
       "      <td>3.646256</td>\n",
       "      <td>13.212610</td>\n",
       "      <td>16.296420</td>\n",
       "      <td>11.283158</td>\n",
       "      <td>16.503250</td>\n",
       "      <td>8.923536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14374</th>\n",
       "      <td>0.738648</td>\n",
       "      <td>1.897509</td>\n",
       "      <td>6.084515</td>\n",
       "      <td>20.270646</td>\n",
       "      <td>32.296109</td>\n",
       "      <td>44.607216</td>\n",
       "      <td>34.949312</td>\n",
       "      <td>11.261158</td>\n",
       "      <td>4.075122</td>\n",
       "      <td>4.974788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.717661</td>\n",
       "      <td>2.681136</td>\n",
       "      <td>2.734866</td>\n",
       "      <td>5.461510</td>\n",
       "      <td>10.376974</td>\n",
       "      <td>5.511980</td>\n",
       "      <td>14.944524</td>\n",
       "      <td>8.314484</td>\n",
       "      <td>29.284820</td>\n",
       "      <td>15.703415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.197580</td>\n",
       "      <td>0.521369</td>\n",
       "      <td>1.424619</td>\n",
       "      <td>1.476271</td>\n",
       "      <td>5.519096</td>\n",
       "      <td>9.331763</td>\n",
       "      <td>9.367298</td>\n",
       "      <td>1.786685</td>\n",
       "      <td>13.871401</td>\n",
       "      <td>8.471966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14377 rows  513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2          3          4          5    \\\n",
       "0      0.160538  1.097057  2.579230   1.012018   4.476512   6.392529   \n",
       "1      0.038044  0.682103  2.181458   2.754363   4.384825  11.662422   \n",
       "2      0.018266  0.255641  1.787614   3.312136   5.729467  11.709544   \n",
       "3      0.041934  0.154276  1.223503   1.839473   1.740634   4.190585   \n",
       "4      0.101857  0.338243  0.466170   0.463306   3.051501   8.259836   \n",
       "5      0.040850  0.081194  0.334677   0.605658   3.903348  10.505771   \n",
       "6      0.105481  0.532195  1.397383   1.331524   1.253465   4.397543   \n",
       "7      0.106103  1.701259  5.742784   4.986935   1.507656   2.306115   \n",
       "8      0.040706  0.480354  3.827296   6.021511   0.968685   4.803226   \n",
       "9      0.077678  0.176397  1.468389   2.157226   0.984026   2.110112   \n",
       "10     0.011308  0.128774  1.444365   2.177193   0.459292   0.784937   \n",
       "11     0.266881  0.355779  3.021940   6.151220   6.598042  14.051604   \n",
       "12     0.510408  2.373615  4.019623   5.496548   8.144357   6.373972   \n",
       "13     0.050740  0.730094  0.531236   1.856519   1.917044   4.421652   \n",
       "14     0.039370  0.519922  0.696026   0.582653   4.059979  10.152088   \n",
       "15     0.038932  0.245820  0.540924   0.072869   3.382246   8.705749   \n",
       "16     0.016189  0.143798  0.231257   0.517093   0.370103   1.055709   \n",
       "17     0.007283  0.456393  0.870020   0.479554   1.061137   2.832232   \n",
       "18     0.152697  0.716401  0.915419   0.979435   1.098984   2.412460   \n",
       "19     0.002916  0.357175  1.107716   0.649423   2.240258   4.697817   \n",
       "20     0.033110  0.072417  1.105920   2.122932   1.818074   2.976293   \n",
       "21     0.018226  0.171578  1.379562   1.796498   1.161723   1.693148   \n",
       "22     0.007608  0.195622  0.772386   1.524316   1.203886   1.959756   \n",
       "23     0.004951  0.123247  1.209410   2.371360   0.527818   3.129227   \n",
       "24     0.059331  0.132883  0.336626   0.540617   1.835852   5.120322   \n",
       "25     0.010035  0.184015  1.576577   2.526204   1.059388   1.775217   \n",
       "26     0.050297  0.211754  1.062658   0.295846   0.326546   1.146326   \n",
       "27     0.035396  0.245666  0.369129   1.247930   1.899678   4.378119   \n",
       "28     0.030129  0.309778  0.525158   0.443551   0.282123   0.996912   \n",
       "29     0.001630  0.154472  0.223878   0.985571   1.746151   3.831430   \n",
       "...         ...       ...       ...        ...        ...        ...   \n",
       "14347  0.133001  0.121989  0.491264   0.239137   1.151545   3.275361   \n",
       "14348  0.031315  0.154904  0.874424   1.341710   0.446842   0.383684   \n",
       "14349  0.259734  2.203576  1.301117   3.629562   8.160042  11.875620   \n",
       "14350  0.221867  0.552379  1.803526   1.739064   5.311072   5.262351   \n",
       "14351  0.026416  0.141473  0.685645   1.095577   2.277471   3.763104   \n",
       "14352  0.035480  0.206378  0.726317   1.211146   1.958067   3.463979   \n",
       "14353  0.195383  0.932897  2.288374   3.054594   3.674179   5.614014   \n",
       "14354  0.747925  3.977492  5.579396   8.643272   6.898350   6.254712   \n",
       "14355  0.296367  2.897062  4.720489   4.567702   9.023767  18.958120   \n",
       "14356  0.247681  0.352058  0.619193   0.632059   3.367074   3.393917   \n",
       "14357  0.387182  1.575286  3.553341   3.653650   7.474724  17.670169   \n",
       "14358  0.038531  0.172336  0.711356   0.836362   2.845895   3.201506   \n",
       "14359  0.156862  2.452721  0.702132   5.207757  14.547520  26.447577   \n",
       "14360  0.062293  0.293533  1.143653   1.645301   4.659331   4.037520   \n",
       "14361  0.007781  0.019354  0.056625   0.070555   0.230797   0.118010   \n",
       "14362  0.852743  3.946200  4.242042  10.065298  28.298547  45.310828   \n",
       "14363  0.685924  2.493649  6.185336   6.568541  22.867865  28.589625   \n",
       "14364  0.295462  1.000266  2.967980   5.544236  19.181718  33.600524   \n",
       "14365  0.074668  0.482791  1.389039   1.705551   2.166289   2.522254   \n",
       "14366  0.019407  0.086233  0.168468   0.270781   1.975305   4.187659   \n",
       "14367  0.122257  0.512128  0.413890   0.019082   5.015470   5.689785   \n",
       "14368  0.022881  0.167281  0.295190   0.405347   0.955119   2.003681   \n",
       "14369  0.449699  2.643874  4.309592  10.278496  34.508376  61.729713   \n",
       "14370  0.284322  2.841545  6.383975   7.101405  22.803709  23.518685   \n",
       "14371  0.135393  0.886009  2.186299   4.382034  16.973103  28.299778   \n",
       "14372  0.197514  0.916207  0.531126   2.776535   9.888253  19.202340   \n",
       "14373  0.447264  3.524665  2.445509   2.656039   3.646256  13.212610   \n",
       "14374  0.738648  1.897509  6.084515  20.270646  32.296109  44.607216   \n",
       "14375  0.717661  2.681136  2.734866   5.461510  10.376974   5.511980   \n",
       "14376  0.197580  0.521369  1.424619   1.476271   5.519096   9.331763   \n",
       "\n",
       "             6          7          8          9    ...        503       504  \\\n",
       "0       2.835823   1.202161   8.097132   4.129657  ...   0.000648  0.000647   \n",
       "1       7.668046   4.351508   4.368506   1.970593  ...   0.001000  0.000981   \n",
       "2       5.990989   4.220113   4.843519   2.247771  ...   0.001238  0.001240   \n",
       "3       2.284470   1.819566   1.732903   0.897682  ...   0.000768  0.000768   \n",
       "4       3.682422   1.958645   7.499066   3.915087  ...   0.001133  0.001133   \n",
       "5       4.703594   4.652761  13.386301   6.945506  ...   0.002101  0.002100   \n",
       "6       3.680579   2.930381  11.623168   6.416892  ...   0.000996  0.000997   \n",
       "7       4.750925   9.202651  42.217820  22.440398  ...   0.001326  0.001326   \n",
       "8       5.350049  10.248151  19.165113   9.344392  ...   0.000391  0.000393   \n",
       "9       3.219406   5.492588  10.765436   5.424180  ...   0.000256  0.000259   \n",
       "10      1.294625   2.857264   7.525758   3.619497  ...   0.000669  0.000668   \n",
       "11      5.559722   5.761228  12.838594   6.303104  ...   0.001423  0.001420   \n",
       "12      2.693568   0.487677  10.686451   6.396017  ...   0.002220  0.002197   \n",
       "13      5.016493   3.296573   1.593588   0.365908  ...   0.000145  0.000199   \n",
       "14      4.705362   5.869228  11.313011   5.579475  ...   0.000288  0.000289   \n",
       "15      5.443950   5.491937  16.240331   8.173362  ...   0.000657  0.000654   \n",
       "16      0.996568   1.416133   3.729812   1.776112  ...   0.000506  0.000506   \n",
       "17      2.392142   3.779474   6.558137   3.425337  ...   0.000816  0.000814   \n",
       "18      0.468729   2.429865   2.461548   1.234980  ...   0.000478  0.000508   \n",
       "19      2.039797   0.782496   2.208509   1.205793  ...   0.000834  0.000834   \n",
       "20      1.415892   0.658363   2.195019   1.342802  ...   0.000295  0.000293   \n",
       "21      1.067095   1.361180   3.267875   1.550720  ...   0.000307  0.000305   \n",
       "22      1.346507   0.585960   3.200511   1.742746  ...   0.000428  0.000428   \n",
       "23      1.204163   0.753213   2.251429   1.233257  ...   0.000752  0.000753   \n",
       "24      1.421194   2.315210   3.849741   1.852601  ...   0.000549  0.000550   \n",
       "25      1.596976   1.979109   2.508898   1.452735  ...   0.000927  0.000885   \n",
       "26      0.518628   3.434998   4.444546   1.439643  ...   0.000315  0.000361   \n",
       "27      3.089463   2.736913   4.401640   2.000504  ...   0.000424  0.000424   \n",
       "28      1.070193   0.976190   0.877458   0.574386  ...   0.000449  0.000450   \n",
       "29      3.235063   3.356056   5.476443   2.553496  ...   0.000854  0.000853   \n",
       "...          ...        ...        ...        ...  ...        ...       ...   \n",
       "14347   7.714350   5.038309  22.231028  12.319779  ...   0.001659  0.001664   \n",
       "14348   1.902050   0.810468   0.747396   0.301683  ...   0.000452  0.000453   \n",
       "14349  12.044557  12.057507  34.403261  19.275711  ...   0.000515  0.000552   \n",
       "14350   9.575081   9.390610  19.660178  10.861000  ...   0.005484  0.005475   \n",
       "14351   4.424763   0.255541   5.441439   2.731518  ...   0.000792  0.000779   \n",
       "14352   2.583131   2.697368   4.145763   2.085824  ...   0.000424  0.000423   \n",
       "14353   6.777233   3.691108  11.764996   6.568670  ...   0.006281  0.006284   \n",
       "14354  35.049140  20.902505  31.436301  17.499320  ...   0.011754  0.011759   \n",
       "14355  16.853487  14.286596  26.534160  15.219227  ...   0.002997  0.002991   \n",
       "14356   0.217917   1.307545   1.350632   0.902873  ...   0.001305  0.001289   \n",
       "14357  14.768580   9.721302  18.915611  10.275729  ...   0.003950  0.003949   \n",
       "14358   0.704921   2.106691   4.600009   2.349636  ...   0.000540  0.000534   \n",
       "14359  25.721802  20.375862  42.058041  24.481226  ...   0.015412  0.015323   \n",
       "14360   5.492921   7.635987  15.445057   8.306014  ...   0.003843  0.003843   \n",
       "14361   0.392492   0.322462   0.450379   0.228158  ...   0.000006  0.000005   \n",
       "14362  21.586447  26.369138  49.836884  30.176218  ...   0.017955  0.017978   \n",
       "14363  12.905906  13.120321  32.724241  20.795579  ...   0.006382  0.006384   \n",
       "14364  22.783884  11.746232  17.034901  10.876460  ...   0.012057  0.012054   \n",
       "14365   4.712438   4.018516   7.816526   5.114222  ...   0.000240  0.000252   \n",
       "14366   3.762081   1.085393   3.346082   1.640984  ...   0.000513  0.000480   \n",
       "14367   9.439730   6.781539  15.617436   7.012260  ...   0.001732  0.001728   \n",
       "14368   2.898550   1.094338   2.147725   0.923953  ...   0.000219  0.000218   \n",
       "14369  49.396734  26.947018  64.233896  41.112391  ...   0.026525  0.026390   \n",
       "14370  16.377892  22.206718  41.033442  20.617108  ...   0.015056  0.015082   \n",
       "14371  19.036774  14.905121  26.491886  12.497950  ...   0.001353  0.001358   \n",
       "14372  13.490815   6.158388   9.475800   5.650832  ...   0.001548  0.001539   \n",
       "14373  16.296420  11.283158  16.503250   8.923536  ...   0.001180  0.001182   \n",
       "14374  34.949312  11.261158   4.075122   4.974788  ...   0.004738  0.004822   \n",
       "14375  14.944524   8.314484  29.284820  15.703415  ...   0.006043  0.006033   \n",
       "14376   9.367298   1.786685  13.871401   8.471966  ...   0.005505  0.005502   \n",
       "\n",
       "            505       506       507       508       509       510       511  \\\n",
       "0      0.000652  0.000649  0.000648  0.000649  0.000649  0.000649  0.000649   \n",
       "1      0.000994  0.000984  0.000991  0.000989  0.000988  0.000989  0.000989   \n",
       "2      0.001239  0.001240  0.001239  0.001239  0.001239  0.001239  0.001239   \n",
       "3      0.000767  0.000768  0.000768  0.000768  0.000768  0.000768  0.000768   \n",
       "4      0.001133  0.001133  0.001132  0.001132  0.001132  0.001132  0.001132   \n",
       "5      0.002100  0.002100  0.002100  0.002100  0.002100  0.002100  0.002100   \n",
       "6      0.000996  0.000997  0.000996  0.000997  0.000996  0.000996  0.000996   \n",
       "7      0.001325  0.001324  0.001325  0.001324  0.001325  0.001325  0.001325   \n",
       "8      0.000392  0.000392  0.000392  0.000392  0.000392  0.000392  0.000392   \n",
       "9      0.000258  0.000260  0.000257  0.000258  0.000258  0.000258  0.000258   \n",
       "10     0.000669  0.000669  0.000668  0.000669  0.000668  0.000669  0.000668   \n",
       "11     0.001421  0.001420  0.001421  0.001421  0.001421  0.001420  0.001421   \n",
       "12     0.002206  0.002199  0.002202  0.002203  0.002202  0.002202  0.002202   \n",
       "13     0.000150  0.000176  0.000174  0.000165  0.000177  0.000171  0.000172   \n",
       "14     0.000287  0.000289  0.000288  0.000288  0.000289  0.000288  0.000288   \n",
       "15     0.000657  0.000656  0.000656  0.000655  0.000656  0.000656  0.000656   \n",
       "16     0.000506  0.000506  0.000506  0.000506  0.000506  0.000506  0.000506   \n",
       "17     0.000816  0.000816  0.000815  0.000815  0.000815  0.000815  0.000815   \n",
       "18     0.000486  0.000482  0.000496  0.000490  0.000489  0.000490  0.000489   \n",
       "19     0.000834  0.000834  0.000834  0.000834  0.000834  0.000834  0.000834   \n",
       "20     0.000294  0.000294  0.000293  0.000294  0.000294  0.000294  0.000294   \n",
       "21     0.000306  0.000306  0.000307  0.000305  0.000307  0.000306  0.000306   \n",
       "22     0.000428  0.000428  0.000428  0.000428  0.000428  0.000428  0.000428   \n",
       "23     0.000753  0.000752  0.000752  0.000752  0.000752  0.000752  0.000752   \n",
       "24     0.000550  0.000549  0.000550  0.000550  0.000550  0.000550  0.000550   \n",
       "25     0.000919  0.000895  0.000899  0.000906  0.000900  0.000902  0.000901   \n",
       "26     0.000325  0.000333  0.000330  0.000335  0.000329  0.000331  0.000331   \n",
       "27     0.000425  0.000424  0.000424  0.000424  0.000424  0.000424  0.000424   \n",
       "28     0.000449  0.000449  0.000449  0.000449  0.000449  0.000449  0.000449   \n",
       "29     0.000853  0.000854  0.000853  0.000853  0.000853  0.000853  0.000853   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14347  0.001661  0.001664  0.001663  0.001662  0.001663  0.001663  0.001662   \n",
       "14348  0.000452  0.000453  0.000452  0.000452  0.000452  0.000452  0.000452   \n",
       "14349  0.000507  0.000539  0.000529  0.000530  0.000527  0.000528  0.000528   \n",
       "14350  0.005483  0.005480  0.005479  0.005480  0.005479  0.005479  0.005479   \n",
       "14351  0.000787  0.000784  0.000784  0.000785  0.000785  0.000785  0.000785   \n",
       "14352  0.000422  0.000423  0.000422  0.000423  0.000423  0.000423  0.000423   \n",
       "14353  0.006293  0.006282  0.006284  0.006284  0.006286  0.006284  0.006284   \n",
       "14354  0.011813  0.011783  0.011793  0.011785  0.011782  0.011788  0.011786   \n",
       "14355  0.002997  0.002988  0.002995  0.002992  0.002992  0.002992  0.002992   \n",
       "14356  0.001297  0.001297  0.001285  0.001294  0.001294  0.001292  0.001292   \n",
       "14357  0.003952  0.003949  0.003948  0.003949  0.003948  0.003949  0.003948   \n",
       "14358  0.000537  0.000537  0.000538  0.000538  0.000537  0.000537  0.000538   \n",
       "14359  0.015441  0.015407  0.015402  0.015387  0.015395  0.015394  0.015392   \n",
       "14360  0.003842  0.003843  0.003841  0.003843  0.003841  0.003842  0.003842   \n",
       "14361  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  0.000005   \n",
       "14362  0.017937  0.017967  0.017948  0.017959  0.017952  0.017954  0.017954   \n",
       "14363  0.006381  0.006382  0.006382  0.006381  0.006381  0.006382  0.006381   \n",
       "14364  0.012043  0.012059  0.012045  0.012051  0.012051  0.012049  0.012050   \n",
       "14365  0.000257  0.000255  0.000248  0.000253  0.000251  0.000252  0.000252   \n",
       "14366  0.000506  0.000482  0.000496  0.000489  0.000494  0.000492  0.000493   \n",
       "14367  0.001729  0.001729  0.001729  0.001728  0.001729  0.001729  0.001729   \n",
       "14368  0.000218  0.000218  0.000218  0.000218  0.000218  0.000218  0.000218   \n",
       "14369  0.026456  0.026502  0.026476  0.026484  0.026485  0.026487  0.026486   \n",
       "14370  0.015055  0.015075  0.015066  0.015068  0.015066  0.015066  0.015067   \n",
       "14371  0.001355  0.001356  0.001357  0.001357  0.001356  0.001356  0.001357   \n",
       "14372  0.001533  0.001540  0.001538  0.001539  0.001539  0.001538  0.001539   \n",
       "14373  0.001198  0.001177  0.001183  0.001187  0.001184  0.001185  0.001185   \n",
       "14374  0.004764  0.004760  0.004765  0.004766  0.004760  0.004759  0.004760   \n",
       "14375  0.006034  0.006026  0.006037  0.006034  0.006034  0.006033  0.006034   \n",
       "14376  0.005504  0.005502  0.005502  0.005503  0.005502  0.005502  0.005502   \n",
       "\n",
       "        512  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  \n",
       "5       1.0  \n",
       "6       1.0  \n",
       "7       1.0  \n",
       "8       1.0  \n",
       "9       1.0  \n",
       "10      1.0  \n",
       "11      1.0  \n",
       "12      1.0  \n",
       "13      1.0  \n",
       "14      1.0  \n",
       "15      1.0  \n",
       "16      1.0  \n",
       "17      1.0  \n",
       "18      1.0  \n",
       "19      1.0  \n",
       "20      1.0  \n",
       "21      1.0  \n",
       "22      1.0  \n",
       "23      1.0  \n",
       "24      1.0  \n",
       "25      1.0  \n",
       "26      1.0  \n",
       "27      1.0  \n",
       "28      1.0  \n",
       "29      1.0  \n",
       "...     ...  \n",
       "14347  20.0  \n",
       "14348  20.0  \n",
       "14349  20.0  \n",
       "14350  20.0  \n",
       "14351  20.0  \n",
       "14352  20.0  \n",
       "14353  20.0  \n",
       "14354  20.0  \n",
       "14355  20.0  \n",
       "14356  20.0  \n",
       "14357  20.0  \n",
       "14358  20.0  \n",
       "14359  20.0  \n",
       "14360  20.0  \n",
       "14361  20.0  \n",
       "14362  20.0  \n",
       "14363  20.0  \n",
       "14364  20.0  \n",
       "14365  20.0  \n",
       "14366  20.0  \n",
       "14367  20.0  \n",
       "14368  20.0  \n",
       "14369  20.0  \n",
       "14370  20.0  \n",
       "14371  20.0  \n",
       "14372  20.0  \n",
       "14373  20.0  \n",
       "14374  20.0  \n",
       "14375  20.0  \n",
       "14376  20.0  \n",
       "\n",
       "[14377 rows x 513 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD/CAYAAADllv3BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsxbjYDczazEOdjOzFuNgNzNrMf8fL9e+WhqA3M4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae57d0ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "npArrayDF = np.array(df_new.iloc[:,:], dtype=np.float) #shuffle randomly all samples\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "\n",
    "for i in range(len(npArrayDF)):\n",
    "    npArrayDF[i,-1] = (npArrayDF[i, -1]) - 1\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "    \n",
    "np.random.shuffle(npArrayDF)\n",
    "\n",
    "X_train = np.array(npArrayDF[:-3000,:-1], dtype=np.float)\n",
    "y_train = np.array(npArrayDF[:-3000,-1], dtype=np.float)\n",
    "\n",
    "X_test = np.array(npArrayDF[-3000:-1000,:-1], dtype=np.float)\n",
    "y_test = np.array(npArrayDF[-3000:-1000,-1], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(npArrayDF[-1000:,:-1], dtype=np.float)\n",
    "y_valid = np.array(npArrayDF[-1000:,-1], dtype=np.float)\n",
    "\n",
    "plt.plot(X_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11377, 512)\n",
      "(2000, 512)\n",
      "(1000, 512)\n"
     ]
    }
   ],
   "source": [
    "X_test[0,511]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "startY = 1\n",
    "for i in range(999):\n",
    "    for i2 in range(len(X)):\n",
    "        if startY == y[i]:\n",
    "            startY += 1\n",
    "\n",
    "notfound = 0\n",
    "n_outputs = 0\n",
    "for num in range(1,80):\n",
    "    temp = n_outputs\n",
    "    try:\n",
    "        for i in range(len(y)):\n",
    "            if int(y[i]) == num:\n",
    "                n_outputs += 1\n",
    "                raise StopIteration\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    if temp == n_outputs:\n",
    "        notfound += 1\n",
    "    if notfound == 3:\n",
    "        break\n",
    "\n",
    "print(n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 512\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.823591 Test accuracy: 0.746\n",
      "1 Train accuracy: 0.982596 Test accuracy: 0.837\n",
      "2 Train accuracy: 0.988925 Test accuracy: 0.8425\n",
      "3 Train accuracy: 0.991386 Test accuracy: 0.841\n",
      "4 Train accuracy: 0.993407 Test accuracy: 0.8405\n",
      "5 Train accuracy: 0.994462 Test accuracy: 0.8385\n",
      "6 Train accuracy: 0.995429 Test accuracy: 0.833\n",
      "7 Train accuracy: 0.996044 Test accuracy: 0.83\n",
      "8 Train accuracy: 0.996748 Test accuracy: 0.83\n",
      "9 Train accuracy: 0.99789 Test accuracy: 0.8265\n",
      "10 Train accuracy: 0.998857 Test accuracy: 0.827\n",
      "11 Train accuracy: 0.999472 Test accuracy: 0.822\n",
      "12 Train accuracy: 0.999736 Test accuracy: 0.8165\n",
      "13 Train accuracy: 0.0418388 Test accuracy: 0.038\n",
      "14 Train accuracy: 0.0706689 Test accuracy: 0.0655\n",
      "15 Train accuracy: 0.0860508 Test accuracy: 0.082\n",
      "16 Train accuracy: 0.103454 Test accuracy: 0.092\n",
      "17 Train accuracy: 0.116463 Test accuracy: 0.0955\n",
      "18 Train accuracy: 0.117694 Test accuracy: 0.1045\n",
      "19 Train accuracy: 0.126483 Test accuracy: 0.1045\n",
      "20 Train accuracy: 0.134042 Test accuracy: 0.111\n",
      "21 Train accuracy: 0.143008 Test accuracy: 0.1145\n",
      "22 Train accuracy: 0.201723 Test accuracy: 0.1615\n",
      "23 Train accuracy: 0.286191 Test accuracy: 0.231\n",
      "24 Train accuracy: 0.350532 Test accuracy: 0.271\n",
      "25 Train accuracy: 0.382614 Test accuracy: 0.2915\n",
      "26 Train accuracy: 0.427529 Test accuracy: 0.3295\n",
      "27 Train accuracy: 0.547244 Test accuracy: 0.4375\n",
      "28 Train accuracy: 0.597609 Test accuracy: 0.4735\n",
      "29 Train accuracy: 0.649292 Test accuracy: 0.505\n",
      "30 Train accuracy: 0.687615 Test accuracy: 0.5275\n",
      "31 Train accuracy: 0.700888 Test accuracy: 0.5385\n",
      "32 Train accuracy: 0.800387 Test accuracy: 0.603\n",
      "33 Train accuracy: 0.836336 Test accuracy: 0.624\n",
      "34 Train accuracy: 0.86042 Test accuracy: 0.632\n",
      "35 Train accuracy: 0.851454 Test accuracy: 0.6415\n",
      "36 Train accuracy: 0.899358 Test accuracy: 0.6675\n",
      "37 Train accuracy: 0.931792 Test accuracy: 0.671\n",
      "38 Train accuracy: 0.937505 Test accuracy: 0.683\n",
      "39 Train accuracy: 0.951129 Test accuracy: 0.6795\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range((len(X_train)+len(X_test)) // batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test,\n",
    "                                            y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Y_proba_19:0\", shape=(?, 49), dtype=float32)\n",
      "(1, 512)\n",
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    941\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[1;32m--> 942\u001b[1;33m                                                     allow_operation=False)\n\u001b[0m\u001b[0;32m    943\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2584\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2625\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2626\u001b[1;33m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[0;32m   2627\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-4d2c83ef24dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./my_model_final.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_proba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1548\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    943\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[1;32m--> 945\u001b[1;33m                             + e.args[0])\n\u001b[0m\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph."
     ]
    }
   ],
   "source": [
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "print(Y_proba)\n",
    "print(sample.shape)\n",
    "\n",
    "feed_dict = {X: sample}\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    y = Y_proba.eval(feed_dict=feed_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-133a448e9269>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhe_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_scaling_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m def dnn(inputs, n_hidden_layers=2, n_neurons=300, name=None,\n\u001b[0;32m      4\u001b[0m         activation=tf.nn.elu):\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=2, n_neurons=300, name=None,\n",
    "        activation=tf.nn.elu):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=he_init,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initializer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-3d4245d2d084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdnn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdnn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhe_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-c2dc629b815c>\u001b[0m in \u001b[0;36mdnn\u001b[1;34m(inputs, n_hidden_layers, n_neurons, name, activation)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n\u001b[1;32m----> 8\u001b[1;33m                                      \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                                      name=\"hidden%d\" % (layer + 1))\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'initializer' is not defined"
     ]
    }
   ],
   "source": [
    "n_inputs = 512\n",
    "n_outputs = 48\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 30\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./chord_recognizer_model.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./chord_recognizer_model.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae5cfbb5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "npArrayDF = np.array(df_new.iloc[:,:], dtype=np.float) #shuffle randomly all samples\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "\n",
    "for i in range(len(npArrayDF)):\n",
    "    npArrayDF[i,-1] = (npArrayDF[i, -1]) - 1\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "    \n",
    "np.random.shuffle(npArrayDF)\n",
    "\n",
    "X_train = np.array(npArrayDF[:-2000,:-1], dtype=np.float)\n",
    "y_train = np.array(npArrayDF[:-2000,-1], dtype=np.float)\n",
    "\n",
    "X_test = np.array(npArrayDF[-2000:-1000,:-1], dtype=np.float)\n",
    "y_test = np.array(npArrayDF[-2000:-1000,-1], dtype=np.float)\n",
    "\n",
    "plt.plot(X_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "\n",
    "        # extra ops for batch normalization\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tLast training batch loss: 0.844442\tAccuracy: 78.00%\n",
      "1\tLast training batch loss: 0.561057\tAccuracy: 86.00%\n",
      "2\tLast training batch loss: 0.347946\tAccuracy: 92.00%\n",
      "3\tLast training batch loss: 0.445414\tAccuracy: 86.00%\n",
      "4\tLast training batch loss: 0.439080\tAccuracy: 90.00%\n",
      "5\tLast training batch loss: 0.197648\tAccuracy: 93.00%\n",
      "6\tLast training batch loss: 0.285157\tAccuracy: 95.00%\n",
      "7\tLast training batch loss: 0.178918\tAccuracy: 98.00%\n",
      "8\tLast training batch loss: 0.161102\tAccuracy: 97.00%\n",
      "9\tLast training batch loss: 0.133783\tAccuracy: 97.00%\n",
      "10\tLast training batch loss: 0.080056\tAccuracy: 98.00%\n",
      "11\tLast training batch loss: 0.083353\tAccuracy: 98.00%\n",
      "12\tLast training batch loss: 0.117787\tAccuracy: 97.00%\n",
      "13\tLast training batch loss: 0.072403\tAccuracy: 99.00%\n",
      "14\tLast training batch loss: 0.119134\tAccuracy: 97.00%\n",
      "15\tLast training batch loss: 0.031925\tAccuracy: 99.00%\n",
      "16\tLast training batch loss: 0.088253\tAccuracy: 98.00%\n",
      "17\tLast training batch loss: 0.018628\tAccuracy: 100.00%\n",
      "18\tLast training batch loss: 0.078030\tAccuracy: 99.00%\n",
      "19\tLast training batch loss: 0.163154\tAccuracy: 95.00%\n",
      "20\tLast training batch loss: 0.052145\tAccuracy: 99.00%\n",
      "21\tLast training batch loss: 0.059638\tAccuracy: 98.00%\n",
      "22\tLast training batch loss: 0.093283\tAccuracy: 98.00%\n",
      "23\tLast training batch loss: 0.078314\tAccuracy: 98.00%\n",
      "24\tLast training batch loss: 0.050932\tAccuracy: 99.00%\n",
      "25\tLast training batch loss: 0.009264\tAccuracy: 100.00%\n",
      "26\tLast training batch loss: 0.011971\tAccuracy: 100.00%\n",
      "27\tLast training batch loss: 0.158708\tAccuracy: 97.00%\n",
      "28\tLast training batch loss: 0.027315\tAccuracy: 100.00%\n",
      "29\tLast training batch loss: 0.118169\tAccuracy: 97.00%\n",
      "30\tLast training batch loss: 0.009774\tAccuracy: 100.00%\n",
      "31\tLast training batch loss: 0.075973\tAccuracy: 99.00%\n",
      "32\tLast training batch loss: 0.010438\tAccuracy: 100.00%\n",
      "33\tLast training batch loss: 0.075237\tAccuracy: 98.00%\n",
      "34\tLast training batch loss: 0.082202\tAccuracy: 98.00%\n",
      "35\tLast training batch loss: 0.044630\tAccuracy: 99.00%\n",
      "36\tLast training batch loss: 0.028449\tAccuracy: 99.00%\n",
      "37\tLast training batch loss: 0.018786\tAccuracy: 100.00%\n",
      "38\tLast training batch loss: 0.012996\tAccuracy: 100.00%\n",
      "39\tLast training batch loss: 0.052810\tAccuracy: 99.00%\n",
      "40\tLast training batch loss: 0.065157\tAccuracy: 98.00%\n",
      "41\tLast training batch loss: 0.057832\tAccuracy: 99.00%\n",
      "42\tLast training batch loss: 0.141104\tAccuracy: 97.00%\n",
      "43\tLast training batch loss: 0.023552\tAccuracy: 100.00%\n",
      "44\tLast training batch loss: 0.090668\tAccuracy: 98.00%\n",
      "45\tLast training batch loss: 0.045260\tAccuracy: 99.00%\n",
      "46\tLast training batch loss: 0.036864\tAccuracy: 99.00%\n",
      "47\tLast training batch loss: 0.048691\tAccuracy: 99.00%\n",
      "48\tLast training batch loss: 0.042704\tAccuracy: 99.00%\n",
      "49\tLast training batch loss: 0.043228\tAccuracy: 100.00%\n",
      "50\tLast training batch loss: 0.033943\tAccuracy: 99.00%\n",
      "51\tLast training batch loss: 0.005960\tAccuracy: 100.00%\n",
      "52\tLast training batch loss: 0.014122\tAccuracy: 100.00%\n",
      "53\tLast training batch loss: 0.065511\tAccuracy: 99.00%\n",
      "54\tLast training batch loss: 0.014047\tAccuracy: 100.00%\n",
      "55\tLast training batch loss: 0.004451\tAccuracy: 100.00%\n",
      "56\tLast training batch loss: 0.003243\tAccuracy: 100.00%\n",
      "57\tLast training batch loss: 0.005571\tAccuracy: 100.00%\n",
      "58\tLast training batch loss: 0.083799\tAccuracy: 98.00%\n",
      "59\tLast training batch loss: 0.003012\tAccuracy: 100.00%\n",
      "60\tLast training batch loss: 0.003645\tAccuracy: 100.00%\n",
      "61\tLast training batch loss: 0.004766\tAccuracy: 100.00%\n",
      "62\tLast training batch loss: 0.004540\tAccuracy: 100.00%\n",
      "63\tLast training batch loss: 0.007475\tAccuracy: 100.00%\n",
      "64\tLast training batch loss: 0.038402\tAccuracy: 99.00%\n",
      "65\tLast training batch loss: 0.068157\tAccuracy: 99.00%\n",
      "66\tLast training batch loss: 0.031558\tAccuracy: 99.00%\n",
      "67\tLast training batch loss: 0.067375\tAccuracy: 98.00%\n",
      "68\tLast training batch loss: 0.015726\tAccuracy: 100.00%\n",
      "69\tLast training batch loss: 0.097294\tAccuracy: 98.00%\n",
      "70\tLast training batch loss: 0.032552\tAccuracy: 99.00%\n",
      "71\tLast training batch loss: 0.004488\tAccuracy: 100.00%\n",
      "72\tLast training batch loss: 0.003017\tAccuracy: 100.00%\n",
      "73\tLast training batch loss: 0.003701\tAccuracy: 100.00%\n",
      "74\tLast training batch loss: 0.109339\tAccuracy: 97.00%\n",
      "75\tLast training batch loss: 0.036457\tAccuracy: 99.00%\n",
      "76\tLast training batch loss: 0.005852\tAccuracy: 100.00%\n",
      "77\tLast training batch loss: 0.043617\tAccuracy: 99.00%\n",
      "78\tLast training batch loss: 0.001224\tAccuracy: 100.00%\n",
      "79\tLast training batch loss: 0.027722\tAccuracy: 100.00%\n",
      "80\tLast training batch loss: 0.027564\tAccuracy: 100.00%\n",
      "81\tLast training batch loss: 0.077842\tAccuracy: 98.00%\n",
      "82\tLast training batch loss: 0.012645\tAccuracy: 100.00%\n",
      "83\tLast training batch loss: 0.002699\tAccuracy: 100.00%\n",
      "84\tLast training batch loss: 0.042620\tAccuracy: 99.00%\n",
      "85\tLast training batch loss: 0.001162\tAccuracy: 100.00%\n",
      "86\tLast training batch loss: 0.037191\tAccuracy: 99.00%\n",
      "87\tLast training batch loss: 0.036907\tAccuracy: 99.00%\n",
      "88\tLast training batch loss: 0.075887\tAccuracy: 98.00%\n",
      "89\tLast training batch loss: 0.062822\tAccuracy: 98.00%\n",
      "90\tLast training batch loss: 0.039749\tAccuracy: 100.00%\n",
      "91\tLast training batch loss: 0.011000\tAccuracy: 100.00%\n",
      "92\tLast training batch loss: 0.052713\tAccuracy: 99.00%\n",
      "93\tLast training batch loss: 0.047848\tAccuracy: 99.00%\n",
      "94\tLast training batch loss: 0.002076\tAccuracy: 100.00%\n",
      "95\tLast training batch loss: 0.076710\tAccuracy: 98.00%\n",
      "96\tLast training batch loss: 0.001098\tAccuracy: 100.00%\n",
      "97\tLast training batch loss: 0.010705\tAccuracy: 100.00%\n",
      "98\tLast training batch loss: 0.065621\tAccuracy: 99.00%\n",
      "99\tLast training batch loss: 0.037800\tAccuracy: 99.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000001AE0BB34F28>,\n",
       "       batch_norm_momentum=None, batch_size=100, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x000001AE5CCCEE18>,\n",
       "       learning_rate=0.05, n_hidden_layers=3, n_neurons=700,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>,\n",
       "       random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "dnn_clf = DNNClassifier(activation=leaky_relu(alpha=0.01), batch_size=100, learning_rate=0.05, n_hidden_layers= 3, n_neurons=700, optimizer_class=tf.train.AdagradOptimizer)\n",
    "dnn_clf.fit(X_train, y_train, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36]]\n"
     ]
    }
   ],
   "source": [
    "predicted = dnn_clf.predict(X_train[0:1])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85899999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "sample = [-0.02391236,-0.02401346,-0.02304432,-0.02232109,-0.02331689,-0.0258386,-0.02858969,-0.03040644,-0.03112304,-0.03168886,-0.03283628,-0.0351015,-0.03763041,-0.03891725,-0.03901085,-0.03814701,-0.03626293,-0.0330695,-0.02851345,-0.02368637,-0.01984248,-0.01779807,-0.01773845,-0.01989635,-0.02408022,-0.02918308,-0.03411988,-0.03793591,-0.0403269,-0.04154911,-0.04193868,-0.04129041,-0.03916448,-0.03582506,-0.03257488,-0.03132863,-0.03349824,-0.03846546,-0.04356793,-0.04591354,-0.04392288,-0.03880485,-0.03294274,-0.0282093,-0.02515284,-0.02271261,-0.0200773,-0.01741949,-0.01553463,-0.01544506,-0.0175374,-0.02084977,-0.02406257,-0.02597514,-0.02594609,-0.02466504,-0.02348314,-0.02293226,-0.02295778,-0.02305757,-0.02174928,-0.0184349,-0.01387513,-0.009189017,-0.005035891,-0.001206686,0.003229616,0.00843022,0.0131362,0.01641172,0.01850698,0.02087323,0.02481208,0.03092131,0.03810782,0.04379837,0.04682411,0.04722739,0.04549902,0.04255692,0.03923116,0.03616657,0.03440865,0.03519834,0.03853251,0.04392754,0.05055304,0.05645185,0.06057678,0.062757,0.06245447,0.05960844,0.05505928,0.05017454,0.04697504,0.04676327,0.04857934,0.05100656,0.05326637,0.05525162,0.05699965,0.05849614,0.05976528,0.06040889,0.06040481,0.05983401,0.05889866,0.05831151,0.05822816,0.05806053,0.05763836,0.05741212,0.05783129,0.05870188,0.0591037,0.05839689,0.05698404,0.05603458,0.05578876,0.05563734,0.05521099,0.05480082,0.05522781,0.05658178,0.05825201,0.0591101,0.05847391,0.05712539,0.05551309,0.05291662,0.04828094,0.04102418,0.03220097,0.0237774,0.01700579,0.01190846,0.007639391,0.003838554,0.0009326132,-0.0008099893,-0.002109752,-0.004645566,-0.009141147,-0.01430209,-0.01794333,-0.01838132,-0.01641358,-0.01510614,-0.0162402,-0.01987496,-0.02497706,-0.02948548,-0.03235643,-0.03361415,-0.03329426,-0.03155388,-0.029214,-0.02731988,-0.02699729,-0.028972,-0.03281584,-0.03745592,-0.04194412,-0.04609481,-0.04942491,-0.05129777,-0.05197957,-0.05257464,-0.0544029,-0.05765013,-0.06126725,-0.06420563,-0.06611189,-0.06761904,-0.06941789,-0.0714158,-0.07327206,-0.07455141,-0.07593182,-0.07807858,-0.08018938,-0.08108212,-0.07923824,-0.07408096,-0.06659276,-0.05824123,-0.04996498,-0.04195376,-0.03425384,-0.02738338,-0.02284305,-0.02191244,-0.0239592,-0.02674143,-0.02871127,-0.02930006,-0.02810761,-0.02548219,-0.0217294,-0.01679538,-0.0109615,-0.004971754,0.0002982662,0.004159415,0.005931876,0.005717668,0.004497997,0.003475004,0.003942537,0.007010522,0.01270533,0.0193109,0.02499103,0.02953281,0.03352785,0.03736404,0.04088317,0.04306739,0.04314912,0.04128818,0.03816605,0.03438256,0.0300893,0.0246639,0.01787076,0.01095161,0.005890665,0.004962845,0.008651981,0.01515301,0.02190124,0.02643057,0.02775551,0.0261908,0.02268923,0.01928843,0.0180059,0.01977362,0.02430175,0.02986214,0.03488313,0.03864121,0.04085036,0.0420278,0.04255805,0.04237188,0.04141724,0.03933855,0.03624,0.03307051,0.03066473,0.02932922,0.02885374,0.02891277,0.0294814,0.03027626,0.03088149,0.03066164,0.02861133,0.02480291,0.01967945,0.0139042,0.008395929,0.003379839,-0.0004100446,-0.00235041,-0.002719749,-0.001855956,0.0001474619,0.002991769,0.006329281,0.009678183,0.01218774,0.0130645,0.01158648,0.00806026,0.003494851,-0.00091275,-0.004027618,-0.005255461,-0.00484397,-0.003952427,-0.003319674,-0.003557903,-0.004709277,-0.006092385,-0.007246929,-0.007995353,-0.008655882,-0.00923902,-0.009619901,-0.009461221,-0.00856333,-0.007728244,-0.007677517,-0.008256256,-0.008379353,-0.00721566,-0.005090886,-0.003278495,-0.003479698,-0.006853782,-0.01331931,-0.02112216,-0.02813205,-0.03301932,-0.03487443,-0.03374653,-0.03007868,-0.02404566,-0.01654356,-0.009193661,-0.003624718,-0.0005399215,-0.0003839956,-0.003627216,-0.009388311,-0.01564712,-0.01978187,-0.0199959,-0.01658805,-0.01115212,-0.006018455,-0.002911539,-0.001935948,-0.002206178,-0.002618897,-0.002934259,-0.002841322,-0.001914406,-0.0002983099,0.002130863,0.00496951,0.00739141,0.008935563,0.009317585,0.008579995,0.007677803,0.007526307,0.008225136,0.009466618,0.01079687,0.01201497,0.01207337,0.01069341,0.008674024,0.005988427,0.00315102,6.725502e-05,-0.003948947,-0.008516536,-0.01294499,-0.01627953,-0.01742501,-0.01630514,-0.0143415,-0.01346097,-0.01535006,-0.02012266,-0.0261742,-0.0317664,-0.0359843,-0.0387353,-0.03993634,-0.03958501,-0.03766431,-0.03453567,-0.03093684,-0.02765529,-0.02550576,-0.02446407,-0.02368537,-0.02231547,-0.02016634,-0.01751173,-0.01490899,-0.01275547,-0.01143139,-0.01128906,-0.01211191,-0.01373649,-0.01591905,-0.01775041,-0.01779528,-0.01590291,-0.01298872,-0.009995041,-0.008018756,-0.007297331,-0.007865296,-0.009470091,-0.01133957,-0.0129769,-0.0138044,-0.01339336,-0.01159519,-0.008764775,-0.006731522,-0.007157572,-0.01020335,-0.01506185,-0.01968937,-0.02228183,-0.0221278,-0.01963116,-0.01615243,-0.01254291,-0.008786621,-0.004496505,0.0004787685,0.005695369,0.0103476,0.01334258,0.0139171,0.01274378,0.01077393,0.008587917,0.007206251,0.007307578,0.008647363,0.01055732,0.01209962,0.01268876,0.01262866,0.01274742,0.013855,0.01575701,0.01815938,0.02089319,0.02329315,0.02537067,0.02724684,0.0285311,0.02906468,0.02910316,0.02917355,0.03061882,0.03502725,0.04231926,0.05086768,0.05837074,0.06270157,0.06330257,0.06085024,0.05628234,0.05074602,0.04514338,0.03992373,0.03522291,0.03092827,0.02740397,0.02528952,0.0248322,0.02619362,0.02860715,0.03047961,0.03088679,0.02982307,0.02813342,0.02662345,0.02592074,0.0256526,0.02460991,0.0229127,0.02209379,0.0235921,0.02695277,0.03070488,0.03293201,0.03227367,0.02951018,0.02619287,0.02350687,0.02169919,0.02026329,0.01828574,0.01525219,0.0117254,0.008146133,0.004955495,0.00200235,-0.001549178,-0.005867711,-0.0111958,-0.01772647,-0.02479376,-0.03090982,-0.03492464,-0.03680582,-0.03763293,-0.03911871,-0.04162211,-0.04410304,-0.04512397,-0.04395516,-0.04178826,-0.03990566,-0.0391627,-0.03997897,-0.04146709,-0.04281729,-0.04414773,-0.04614341,-0.04905885,-0.05233373,-0.05486087,-0.05570639,-0.05478191,-0.05279836,-0.0509258,-0.05030936,-0.05181486,-0.05526382,-0.05958953,-0.06360298,-0.06612254,-0.06633901,-0.0644689,-0.06144837,-0.05820885,-0.05517979,-0.05193457,-0.0484629,-0.0452808,-0.04262187,-0.04109769,-0.04097512,-0.0415266,-0.04185368,-0.04146442,-0.04053735,-0.03943633,-0.03844426,-0.0374719,-0.035827,-0.03265274,-0.02753599,-0.02140655,-0.01549952,-0.01078625,-0.00775161,-0.005553331,-0.003567734,-0.001976444,-0.0007438411,0.0004343414,0.001936937,0.004714599,0.009185517,0.01469168,0.020395,0.02526567,0.02875079,0.03064772,0.03110996,0.03058057,0.02922258,0.02738628,0.02534666,0.0233711,0.02172191,0.02086639,0.02201361,0.02575129,0.03182805,0.03934946,0.0464784,0.05123629,0.05242416,0.05061183,0.04743492,0.04423019,0.04207539,0.04152281,0.04206675,0.0430888,0.04418951,0.04467835,0.0447074,0.04488502,0.04505503,0.04478649,0.04328403,0.04020632,0.03655726,0.03381814,0.03296883,0.03377675,0.03494441,0.03493499,0.03283663,0.029186,0.02547077,0.02277206,0.02163548,0.02247864,0.0256724,0.03109401,0.03801415,0.04527452,0.05095037,0.05350524,0.05283185,0.04993296,0.04633341,0.04318412,0.04129367,0.04103348,0.04189758,0.04311463,0.04343672,0.04132398,0.03662727,0.03047808,0.02455721,0.01998372,0.01649464,0.01320594,0.009612436,0.006337341,0.004397781,0.003540323,0.002417389,3.551343e-05,-0.003593007,-0.007550889,-0.01116957,-0.01418594,-0.01644606,-0.01750741,-0.01677595,-0.01435268,-0.01076822,-0.006970763,-0.003590183,-0.0006973795,0.001488794,0.002441452,0.001718483,-0.0009576908,-0.005530358,-0.01096854,-0.01579775,-0.01900267,-0.02040968,-0.02013311,-0.01852793,-0.01606886,-0.01322508,-0.01096815,-0.01028257,-0.0114972,-0.01402292,-0.01666104,-0.01828884,-0.01851356,-0.0171006,-0.01392389,-0.009049616,-0.00266445,0.004421202,0.01137685,0.01745786,0.0222325,0.02531605,0.02614144,0.0242726,0.01970593,0.01369977,0.008089415,0.00381556,0.001309815,0.0006377233,0.0009876337,0.00174264,0.002174912,0.001675003,0.0003028167,-0.002005034,-0.005311786,-0.009889479,-0.01571694,-0.02215401,-0.02839199,-0.03354897,-0.03733404,-0.03991388,-0.04113502,-0.0407746,-0.03854984,-0.03445727,-0.0296818,-0.02566652,-0.02346778,-0.02356359,-0.02500586,-0.0262368,-0.02625026,-0.02518277,-0.02380398,-0.02278488,-0.02299548,-0.02474818,-0.02773707,-0.03125773,-0.03412679,-0.0355508,-0.03526576,-0.03351343,-0.03076547,-0.02749047,-0.02420052,-0.0214724,-0.02005456,-0.02043462,-0.02226074,-0.02469288,-0.02705267,-0.02861044,-0.02913826,-0.02926,-0.02960872,-0.03024601,-0.03082813,-0.03105722,-0.03113341,-0.03176385,-0.03322997,-0.03489855,-0.03604721,-0.03611095,-0.03456288,-0.03176518,-0.02807105,-0.023567,-0.018611,-0.01329369,-0.00803986,-0.003358467,0.0006072252,0.003362858,0.004503148,0.004510677,0.003826268,0.003127517,0.003279254,0.004152123,0.005363394,0.006651428,0.007733743,0.00871152,0.01005354,0.01206407,0.01481274,0.01816246,0.02160928,0.02413395,0.0251486,0.02464003,0.02280022,0.02054639,0.01873272,0.01784333,0.01809045,0.01918421,0.02044143,0.02137879,0.02171585,0.02150724,0.02119504,0.02127865,0.0225738,0.02608196,0.03208696,0.03935995,0.0463521,0.05166797,0.05463909,0.05555665,0.05476691,0.05296234,0.05053723,0.0475504,0.04454101,0.04207124,0.0403528,0.03975949,0.04024226,0.04136649,0.04295426,0.04435221,0.04475356,0.04365417,0.04103515,0.03763731,0.03440787,0.0317445,0.02976455,0.02793897,0.02525878,0.02176335,0.01778225,0.01362266,0.009975272,0.007516502,0.006591106,0.006938063,0.007454738,0.006829746,0.00443481,0.0002338128,-0.005019045,-0.01003521,-0.01364812,-0.01532597,-0.01551168,-0.01499475,-0.01430695,-0.01415951,-0.01508943,-0.01701054,-0.01958835,-0.02189519,-0.02298841,-0.0230476,-0.02292909,-0.02360432,-0.02559918,-0.02887444,-0.0330747,-0.03724108,-0.04047106,-0.04221147,-0.04262361,-0.04240306,-0.04241547,-0.04344551,-0.04504665,-0.04657849,-0.04788784,-0.04904304,-0.05041205,-0.05223875,-0.0544702,-0.05688471,-0.05940063,-0.06223957,-0.065774,-0.07009321,-0.07468967,-0.07841258,-0.08022705,-0.07991008,-0.07804499,-0.07539563,-0.07216774,-0.06830915,-0.0636594,-0.05805051,-0.05168097,-0.04569591,-0.04162296,-0.04026723,-0.04160479,-0.0441736,-0.04610717,-0.04613687,-0.04399988,-0.04064788,-0.03710688,-0.03386264,-0.03055399,-0.02681049,-0.02268409,-0.01846798,-0.01465201,-0.01121944,-0.007760615,-0.003819122,0.0005868947,0.00484336,0.008548028,0.01156172,0.01462944,0.01867278,0.02357635,0.0289599,0.03424801,0.03883241,0.04173851,0.04204613,0.0395755,0.03460471,0.02807618,0.02162894,0.01719103,0.01546707,0.01610133,0.0184412,0.02141093,0.02403608,0.02603186,0.02757966,0.02915934,0.03140577,0.03434543,0.03785862,0.04165704,0.04537398,0.04867245,0.05122584,0.05285337,0.05371227,0.05440297,0.05528465,0.05698483,0.05983861,0.06371872,0.0683084,0.07276724,0.07623785,0.07795686,0.07765839,0.07554362,0.07226602,0.06867181,0.06530607,0.06285381,0.06141511,0.06054004,0.06013886,0.06014499,0.0602788,0.06014314,0.05979432,0.05927179,0.05852139,0.05776251,0.05669535,0.05531536,0.0539859,0.05292982,0.05244674,0.05239599,0.05248183,0.05202961,0.05020169,0.04666658,0.04131097,0.03464427,0.02716921,0.01943705,0.01251239,0.006969108,0.003041883,0.0005859265,-0.0009098022,-0.001864627,-0.002794749,-0.003859443,-0.005130325,-0.00668412,-0.008032655,-0.008904566,-0.009434703,-0.01002492,-0.01122652,-0.01320132,-0.0156334,-0.01785011,-0.01925435,-0.01996361,-0.02062924,-0.02193512,-0.02417574,-0.02708997,-0.03001502,-0.03179429,-0.03188293,-0.03042311,-0.02790886,-0.02571351,-0.02479655,-0.02561357,-0.027946,-0.0308333,-0.03382578,-0.0361929,-0.03757889,-0.03815586,-0.03781454,-0.03693895,-0.03598428,-0.03518353,-0.03464964,-0.03409746,-0.0329521,-0.0308737,-0.02810783,-0.02508289,-0.02228859,-0.02041316,-0.01949235,-0.01905358,-0.01874065,-0.01827577,-0.01729853,-0.01556894,-0.01319002,-0.01017591,-0.007119098,-0.004458143,-0.002245322,-0.001082517,-0.001289722,-0.002786158,-0.005126263,-0.007586861,-0.009733456,-0.01157296,-0.01314118,-0.01437431,-0.01511917,-0.01498565]\n",
    "\n",
    "sample = sample * np.hamming(1024)\n",
    "sample = np.fft.rfft(sample)[1:]\n",
    "sample = np.reshape(sample,(1, 512))\n",
    "\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700 \n",
      "0\tValidation loss: 2.314646\tBest loss: 2.314646\tAccuracy: 40.80%\n",
      "1\tValidation loss: 1.390910\tBest loss: 1.390910\tAccuracy: 63.10%\n",
      "2\tValidation loss: 2.290230\tBest loss: 1.390910\tAccuracy: 54.30%\n",
      "3\tValidation loss: 1.301718\tBest loss: 1.301718\tAccuracy: 71.10%\n",
      "4\tValidation loss: 1.818812\tBest loss: 1.301718\tAccuracy: 71.60%\n",
      "5\tValidation loss: 2.204970\tBest loss: 1.301718\tAccuracy: 66.90%\n",
      "6\tValidation loss: 2.080270\tBest loss: 1.301718\tAccuracy: 72.00%\n",
      "7\tValidation loss: 0.953815\tBest loss: 0.953815\tAccuracy: 80.30%\n",
      "8\tValidation loss: 1.325924\tBest loss: 0.953815\tAccuracy: 78.30%\n",
      "9\tValidation loss: 1.937431\tBest loss: 0.953815\tAccuracy: 76.30%\n",
      "10\tValidation loss: 1.363180\tBest loss: 0.953815\tAccuracy: 80.70%\n",
      "11\tValidation loss: 2.001485\tBest loss: 0.953815\tAccuracy: 78.00%\n",
      "12\tValidation loss: 1.780425\tBest loss: 0.953815\tAccuracy: 81.20%\n",
      "13\tValidation loss: 2.707939\tBest loss: 0.953815\tAccuracy: 76.60%\n",
      "14\tValidation loss: 1.781380\tBest loss: 0.953815\tAccuracy: 81.70%\n",
      "15\tValidation loss: 1.936949\tBest loss: 0.953815\tAccuracy: 82.00%\n",
      "16\tValidation loss: 1.895478\tBest loss: 0.953815\tAccuracy: 81.60%\n",
      "17\tValidation loss: 2.995108\tBest loss: 0.953815\tAccuracy: 80.10%\n",
      "18\tValidation loss: 1.911286\tBest loss: 0.953815\tAccuracy: 83.20%\n",
      "19\tValidation loss: 2.330416\tBest loss: 0.953815\tAccuracy: 82.20%\n",
      "20\tValidation loss: 2.716375\tBest loss: 0.953815\tAccuracy: 81.40%\n",
      "21\tValidation loss: 3.002048\tBest loss: 0.953815\tAccuracy: 83.60%\n",
      "22\tValidation loss: 2.337040\tBest loss: 0.953815\tAccuracy: 84.60%\n",
      "23\tValidation loss: 2.965856\tBest loss: 0.953815\tAccuracy: 83.00%\n",
      "24\tValidation loss: 3.304529\tBest loss: 0.953815\tAccuracy: 81.90%\n",
      "25\tValidation loss: 4.134768\tBest loss: 0.953815\tAccuracy: 80.10%\n",
      "26\tValidation loss: 4.035994\tBest loss: 0.953815\tAccuracy: 83.20%\n",
      "27\tValidation loss: 3.091686\tBest loss: 0.953815\tAccuracy: 83.30%\n",
      "28\tValidation loss: 3.457498\tBest loss: 0.953815\tAccuracy: 81.60%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700, total=  15.8s\n",
      "[CV] learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.497272\tBest loss: 2.497272\tAccuracy: 41.40%\n",
      "1\tValidation loss: 2.008939\tBest loss: 2.008939\tAccuracy: 57.10%\n",
      "2\tValidation loss: 1.003438\tBest loss: 1.003438\tAccuracy: 71.90%\n",
      "3\tValidation loss: 0.942467\tBest loss: 0.942467\tAccuracy: 75.80%\n",
      "4\tValidation loss: 1.751076\tBest loss: 0.942467\tAccuracy: 71.90%\n",
      "5\tValidation loss: 1.694284\tBest loss: 0.942467\tAccuracy: 70.90%\n",
      "6\tValidation loss: 2.319034\tBest loss: 0.942467\tAccuracy: 69.00%\n",
      "7\tValidation loss: 1.416481\tBest loss: 0.942467\tAccuracy: 80.00%\n",
      "8\tValidation loss: 1.658523\tBest loss: 0.942467\tAccuracy: 76.50%\n",
      "9\tValidation loss: 1.170043\tBest loss: 0.942467\tAccuracy: 79.40%\n",
      "10\tValidation loss: 1.653339\tBest loss: 0.942467\tAccuracy: 77.60%\n",
      "11\tValidation loss: 1.440795\tBest loss: 0.942467\tAccuracy: 80.90%\n",
      "12\tValidation loss: 2.249920\tBest loss: 0.942467\tAccuracy: 78.80%\n",
      "13\tValidation loss: 4.553644\tBest loss: 0.942467\tAccuracy: 72.20%\n",
      "14\tValidation loss: 1.905302\tBest loss: 0.942467\tAccuracy: 80.60%\n",
      "15\tValidation loss: 2.758775\tBest loss: 0.942467\tAccuracy: 78.40%\n",
      "16\tValidation loss: 2.284809\tBest loss: 0.942467\tAccuracy: 81.90%\n",
      "17\tValidation loss: 2.367578\tBest loss: 0.942467\tAccuracy: 79.80%\n",
      "18\tValidation loss: 2.371346\tBest loss: 0.942467\tAccuracy: 81.10%\n",
      "19\tValidation loss: 1.891929\tBest loss: 0.942467\tAccuracy: 84.00%\n",
      "20\tValidation loss: 2.764576\tBest loss: 0.942467\tAccuracy: 81.00%\n",
      "21\tValidation loss: 1.923009\tBest loss: 0.942467\tAccuracy: 84.70%\n",
      "22\tValidation loss: 2.594818\tBest loss: 0.942467\tAccuracy: 82.60%\n",
      "23\tValidation loss: 3.620364\tBest loss: 0.942467\tAccuracy: 78.00%\n",
      "24\tValidation loss: 2.657249\tBest loss: 0.942467\tAccuracy: 84.00%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700, total=  13.6s\n",
      "[CV] learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700 \n",
      "0\tValidation loss: 2.545393\tBest loss: 2.545393\tAccuracy: 40.80%\n",
      "1\tValidation loss: 3.118683\tBest loss: 2.545393\tAccuracy: 39.50%\n",
      "2\tValidation loss: 1.667188\tBest loss: 1.667188\tAccuracy: 61.10%\n",
      "3\tValidation loss: 2.074232\tBest loss: 1.667188\tAccuracy: 63.50%\n",
      "4\tValidation loss: 1.805175\tBest loss: 1.667188\tAccuracy: 68.00%\n",
      "5\tValidation loss: 1.403456\tBest loss: 1.403456\tAccuracy: 73.90%\n",
      "6\tValidation loss: 1.385257\tBest loss: 1.385257\tAccuracy: 76.40%\n",
      "7\tValidation loss: 1.469492\tBest loss: 1.385257\tAccuracy: 78.50%\n",
      "8\tValidation loss: 2.752130\tBest loss: 1.385257\tAccuracy: 72.70%\n",
      "9\tValidation loss: 1.895822\tBest loss: 1.385257\tAccuracy: 75.70%\n",
      "10\tValidation loss: 2.445250\tBest loss: 1.385257\tAccuracy: 74.90%\n",
      "11\tValidation loss: 2.064937\tBest loss: 1.385257\tAccuracy: 79.70%\n",
      "12\tValidation loss: 2.291232\tBest loss: 1.385257\tAccuracy: 79.40%\n",
      "13\tValidation loss: 1.853683\tBest loss: 1.385257\tAccuracy: 82.40%\n",
      "14\tValidation loss: 1.660519\tBest loss: 1.385257\tAccuracy: 83.30%\n",
      "15\tValidation loss: 2.046950\tBest loss: 1.385257\tAccuracy: 81.70%\n",
      "16\tValidation loss: 2.441540\tBest loss: 1.385257\tAccuracy: 80.80%\n",
      "17\tValidation loss: 1.591464\tBest loss: 1.385257\tAccuracy: 83.90%\n",
      "18\tValidation loss: 1.895184\tBest loss: 1.385257\tAccuracy: 84.00%\n",
      "19\tValidation loss: 2.669899\tBest loss: 1.385257\tAccuracy: 81.20%\n",
      "20\tValidation loss: 3.350355\tBest loss: 1.385257\tAccuracy: 79.40%\n",
      "21\tValidation loss: 2.914986\tBest loss: 1.385257\tAccuracy: 81.70%\n",
      "22\tValidation loss: 2.446820\tBest loss: 1.385257\tAccuracy: 83.20%\n",
      "23\tValidation loss: 3.834085\tBest loss: 1.385257\tAccuracy: 81.30%\n",
      "24\tValidation loss: 3.070323\tBest loss: 1.385257\tAccuracy: 83.10%\n",
      "25\tValidation loss: 3.033229\tBest loss: 1.385257\tAccuracy: 83.30%\n",
      "26\tValidation loss: 4.262497\tBest loss: 1.385257\tAccuracy: 82.00%\n",
      "27\tValidation loss: 5.135621\tBest loss: 1.385257\tAccuracy: 80.50%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=100, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x00000284187BAE18>, n_neurons=700, total=  15.1s\n",
      "[CV] learning_rate=0.01, batch_size=50, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_hidden_layers=3, activation=<function relu at 0x0000028475A89BF8>, n_neurons=700 \n",
      "0\tValidation loss: 1.829652\tBest loss: 1.829652\tAccuracy: 44.60%\n",
      "1\tValidation loss: 1.515973\tBest loss: 1.515973\tAccuracy: 54.60%\n",
      "2\tValidation loss: 1.305954\tBest loss: 1.305954\tAccuracy: 62.90%\n",
      "3\tValidation loss: 1.079865\tBest loss: 1.079865\tAccuracy: 68.60%\n",
      "4\tValidation loss: 1.118697\tBest loss: 1.079865\tAccuracy: 65.20%\n",
      "5\tValidation loss: 1.034335\tBest loss: 1.034335\tAccuracy: 71.10%\n",
      "6\tValidation loss: 1.026151\tBest loss: 1.026151\tAccuracy: 70.10%\n",
      "7\tValidation loss: 1.039363\tBest loss: 1.026151\tAccuracy: 69.60%\n",
      "8\tValidation loss: 1.027916\tBest loss: 1.026151\tAccuracy: 72.30%\n",
      "9\tValidation loss: 0.992281\tBest loss: 0.992281\tAccuracy: 70.30%\n",
      "10\tValidation loss: 0.928251\tBest loss: 0.928251\tAccuracy: 75.20%\n",
      "11\tValidation loss: 0.887825\tBest loss: 0.887825\tAccuracy: 73.80%\n",
      "12\tValidation loss: 0.836606\tBest loss: 0.836606\tAccuracy: 76.90%\n",
      "13\tValidation loss: 0.866437\tBest loss: 0.836606\tAccuracy: 76.30%\n",
      "14\tValidation loss: 0.945596\tBest loss: 0.836606\tAccuracy: 76.60%\n",
      "15\tValidation loss: 1.112018\tBest loss: 0.836606\tAccuracy: 68.90%\n",
      "16\tValidation loss: 1.050262\tBest loss: 0.836606\tAccuracy: 73.20%\n",
      "17\tValidation loss: 0.967140\tBest loss: 0.836606\tAccuracy: 75.70%\n",
      "18\tValidation loss: 1.029503\tBest loss: 0.836606\tAccuracy: 73.70%\n",
      "19\tValidation loss: 0.942632\tBest loss: 0.836606\tAccuracy: 75.50%\n",
      "20\tValidation loss: 1.068512\tBest loss: 0.836606\tAccuracy: 74.80%\n",
      "21\tValidation loss: 1.115117\tBest loss: 0.836606\tAccuracy: 74.50%\n",
      "22\tValidation loss: 0.960369\tBest loss: 0.836606\tAccuracy: 75.30%\n",
      "23\tValidation loss: 1.239208\tBest loss: 0.836606\tAccuracy: 72.90%\n",
      "24\tValidation loss: 0.971825\tBest loss: 0.836606\tAccuracy: 76.40%\n",
      "25\tValidation loss: 0.895725\tBest loss: 0.836606\tAccuracy: 77.80%\n",
      "26\tValidation loss: 0.956705\tBest loss: 0.836606\tAccuracy: 76.90%\n",
      "27\tValidation loss: 1.042129\tBest loss: 0.836606\tAccuracy: 73.90%\n",
      "28\tValidation loss: 1.144032\tBest loss: 0.836606\tAccuracy: 72.50%\n",
      "29\tValidation loss: 0.892487\tBest loss: 0.836606\tAccuracy: 76.70%\n",
      "30\tValidation loss: 1.087908\tBest loss: 0.836606\tAccuracy: 75.60%\n",
      "31\tValidation loss: 1.031734\tBest loss: 0.836606\tAccuracy: 76.60%\n",
      "32\tValidation loss: 1.096295\tBest loss: 0.836606\tAccuracy: 76.90%\n",
      "33\tValidation loss: 1.112900\tBest loss: 0.836606\tAccuracy: 77.10%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_hidden_layers=3, activation=<function relu at 0x0000028475A89BF8>, n_neurons=700, total=  54.6s\n",
      "[CV] learning_rate=0.01, batch_size=50, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_hidden_layers=3, activation=<function relu at 0x0000028475A89BF8>, n_neurons=700 \n",
      "0\tValidation loss: 1.605415\tBest loss: 1.605415\tAccuracy: 53.90%\n",
      "1\tValidation loss: 1.314965\tBest loss: 1.314965\tAccuracy: 59.50%\n",
      "2\tValidation loss: 1.017726\tBest loss: 1.017726\tAccuracy: 68.30%\n",
      "3\tValidation loss: 1.116456\tBest loss: 1.017726\tAccuracy: 66.60%\n",
      "4\tValidation loss: 1.048216\tBest loss: 1.017726\tAccuracy: 70.50%\n",
      "5\tValidation loss: 0.972837\tBest loss: 0.972837\tAccuracy: 70.90%\n",
      "6\tValidation loss: 0.961899\tBest loss: 0.961899\tAccuracy: 71.90%\n",
      "7\tValidation loss: 0.972174\tBest loss: 0.961899\tAccuracy: 72.90%\n",
      "8\tValidation loss: 0.937298\tBest loss: 0.937298\tAccuracy: 74.00%\n",
      "9\tValidation loss: 0.883866\tBest loss: 0.883866\tAccuracy: 76.30%\n",
      "10\tValidation loss: 1.129820\tBest loss: 0.883866\tAccuracy: 74.50%\n",
      "11\tValidation loss: 0.985680\tBest loss: 0.883866\tAccuracy: 72.80%\n",
      "12\tValidation loss: 1.128126\tBest loss: 0.883866\tAccuracy: 70.40%\n",
      "13\tValidation loss: 0.959400\tBest loss: 0.883866\tAccuracy: 76.40%\n",
      "14\tValidation loss: 0.853439\tBest loss: 0.853439\tAccuracy: 79.30%\n",
      "15\tValidation loss: 1.207702\tBest loss: 0.853439\tAccuracy: 72.00%\n",
      "16\tValidation loss: 1.522154\tBest loss: 0.853439\tAccuracy: 67.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\tValidation loss: 0.928185\tBest loss: 0.853439\tAccuracy: 77.30%\n",
      "18\tValidation loss: 0.903285\tBest loss: 0.853439\tAccuracy: 77.30%\n",
      "19\tValidation loss: 1.205702\tBest loss: 0.853439\tAccuracy: 72.40%\n",
      "20\tValidation loss: 1.136536\tBest loss: 0.853439\tAccuracy: 73.70%\n",
      "21\tValidation loss: 1.194995\tBest loss: 0.853439\tAccuracy: 71.80%\n",
      "22\tValidation loss: 0.977946\tBest loss: 0.853439\tAccuracy: 77.90%\n",
      "23\tValidation loss: 1.079709\tBest loss: 0.853439\tAccuracy: 76.10%\n",
      "24\tValidation loss: 1.168423\tBest loss: 0.853439\tAccuracy: 76.30%\n",
      "25\tValidation loss: 1.156636\tBest loss: 0.853439\tAccuracy: 75.10%\n",
      "26\tValidation loss: 1.074973\tBest loss: 0.853439\tAccuracy: 77.10%\n",
      "27\tValidation loss: 1.099588\tBest loss: 0.853439\tAccuracy: 75.10%\n",
      "28\tValidation loss: 1.021259\tBest loss: 0.853439\tAccuracy: 76.40%\n",
      "29\tValidation loss: 1.240057\tBest loss: 0.853439\tAccuracy: 74.80%\n",
      "30\tValidation loss: 1.151514\tBest loss: 0.853439\tAccuracy: 76.30%\n",
      "31\tValidation loss: 1.154872\tBest loss: 0.853439\tAccuracy: 75.80%\n",
      "32\tValidation loss: 1.222230\tBest loss: 0.853439\tAccuracy: 76.90%\n",
      "33\tValidation loss: 1.151050\tBest loss: 0.853439\tAccuracy: 75.30%\n",
      "34\tValidation loss: 1.297135\tBest loss: 0.853439\tAccuracy: 76.00%\n",
      "35\tValidation loss: 1.109655\tBest loss: 0.853439\tAccuracy: 76.40%\n",
      "Early stopping!\n",
      "[CV]  learning_rate=0.01, batch_size=50, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_hidden_layers=3, activation=<function relu at 0x0000028475A89BF8>, n_neurons=700, total=  57.1s\n",
      "[CV] learning_rate=0.01, batch_size=50, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, n_hidden_layers=3, activation=<function relu at 0x0000028475A89BF8>, n_neurons=700 \n",
      "0\tValidation loss: 1.909469\tBest loss: 1.909469\tAccuracy: 45.00%\n",
      "1\tValidation loss: 1.342086\tBest loss: 1.342086\tAccuracy: 59.40%\n",
      "2\tValidation loss: 1.215861\tBest loss: 1.215861\tAccuracy: 63.20%\n",
      "3\tValidation loss: 1.246966\tBest loss: 1.215861\tAccuracy: 66.40%\n",
      "4\tValidation loss: 1.299142\tBest loss: 1.215861\tAccuracy: 65.10%\n",
      "5\tValidation loss: 1.027012\tBest loss: 1.027012\tAccuracy: 70.40%\n",
      "6\tValidation loss: 1.049814\tBest loss: 1.027012\tAccuracy: 72.20%\n",
      "7\tValidation loss: 1.188929\tBest loss: 1.027012\tAccuracy: 65.60%\n",
      "8\tValidation loss: 1.275430\tBest loss: 1.027012\tAccuracy: 66.70%\n",
      "9\tValidation loss: 1.628657\tBest loss: 1.027012\tAccuracy: 65.80%\n",
      "10\tValidation loss: 1.053601\tBest loss: 1.027012\tAccuracy: 73.00%\n",
      "11\tValidation loss: 1.176319\tBest loss: 1.027012\tAccuracy: 68.10%\n",
      "12\tValidation loss: 0.982183\tBest loss: 0.982183\tAccuracy: 74.80%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dbac6323f10f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"X_valid\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_valid\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_epochs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                 random_state=42, verbose=2)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mrnd_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m--> 564\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f45e43c43f41>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[0;32m    135\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mextra_update_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_update_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [100, 120, 150, 200, 250, 300, 400, 500, 700],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    \"n_hidden_layers\": [0, 1, 2, 3, 4],\n",
    "    \"optimizer_class\": [tf.train.AdamOptimizer, tf.train.GradientDescentOptimizer, \n",
    "                        tf.train.RMSPropOptimizer, tf.train.AdagradOptimizer],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                fit_params={\"X_valid\": X_valid, \"y_valid\": y_valid, \"n_epochs\": 1000},\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function __main__.leaky_relu.<locals>.parametrized_leaky_relu>,\n",
       " 'batch_size': 100,\n",
       " 'learning_rate': 0.05,\n",
       " 'n_hidden_layers': 3,\n",
       " 'n_neurons': 700,\n",
       " 'optimizer_class': tensorflow.python.training.adagrad.AdagradOptimizer}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96099999999999997"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rnd_search.best_params_)\n",
    "y_pred = rnd_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 10.500569\tBest loss: 10.500569\tAccuracy: 6.70%\n",
      "1\tValidation loss: 27.925407\tBest loss: 10.500569\tAccuracy: 19.70%\n",
      "2\tValidation loss: 6.595257\tBest loss: 6.595257\tAccuracy: 48.90%\n",
      "3\tValidation loss: 13.910976\tBest loss: 6.595257\tAccuracy: 49.60%\n",
      "4\tValidation loss: 5.750655\tBest loss: 5.750655\tAccuracy: 69.00%\n",
      "5\tValidation loss: 12.882465\tBest loss: 5.750655\tAccuracy: 60.50%\n",
      "6\tValidation loss: 11.399697\tBest loss: 5.750655\tAccuracy: 65.70%\n",
      "7\tValidation loss: 31.486816\tBest loss: 5.750655\tAccuracy: 56.40%\n",
      "8\tValidation loss: 12.682405\tBest loss: 5.750655\tAccuracy: 75.00%\n",
      "9\tValidation loss: 11.575658\tBest loss: 5.750655\tAccuracy: 74.90%\n",
      "10\tValidation loss: 12.945943\tBest loss: 5.750655\tAccuracy: 76.90%\n",
      "11\tValidation loss: 12.876818\tBest loss: 5.750655\tAccuracy: 76.40%\n",
      "12\tValidation loss: 14.664954\tBest loss: 5.750655\tAccuracy: 74.30%\n",
      "13\tValidation loss: 7.819799\tBest loss: 5.750655\tAccuracy: 84.10%\n",
      "14\tValidation loss: 9.364475\tBest loss: 5.750655\tAccuracy: 83.50%\n",
      "15\tValidation loss: 9.772760\tBest loss: 5.750655\tAccuracy: 82.80%\n",
      "16\tValidation loss: 10.676304\tBest loss: 5.750655\tAccuracy: 82.90%\n",
      "17\tValidation loss: 14.914840\tBest loss: 5.750655\tAccuracy: 82.40%\n",
      "18\tValidation loss: 7.933196\tBest loss: 5.750655\tAccuracy: 87.50%\n",
      "19\tValidation loss: 11.532923\tBest loss: 5.750655\tAccuracy: 84.80%\n",
      "20\tValidation loss: 14.631235\tBest loss: 5.750655\tAccuracy: 83.80%\n",
      "21\tValidation loss: 12.330421\tBest loss: 5.750655\tAccuracy: 87.80%\n",
      "22\tValidation loss: 11.064606\tBest loss: 5.750655\tAccuracy: 85.20%\n",
      "23\tValidation loss: 19.133551\tBest loss: 5.750655\tAccuracy: 82.50%\n",
      "24\tValidation loss: 15.774838\tBest loss: 5.750655\tAccuracy: 87.30%\n",
      "25\tValidation loss: 13.198932\tBest loss: 5.750655\tAccuracy: 88.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.0s\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 6.542073\tBest loss: 6.542073\tAccuracy: 8.20%\n",
      "1\tValidation loss: 17.828554\tBest loss: 6.542073\tAccuracy: 19.10%\n",
      "2\tValidation loss: 14.132567\tBest loss: 6.542073\tAccuracy: 35.50%\n",
      "3\tValidation loss: 11.482405\tBest loss: 6.542073\tAccuracy: 47.30%\n",
      "4\tValidation loss: 20.546711\tBest loss: 6.542073\tAccuracy: 45.40%\n",
      "5\tValidation loss: 6.417468\tBest loss: 6.417468\tAccuracy: 73.00%\n",
      "6\tValidation loss: 7.378170\tBest loss: 6.417468\tAccuracy: 77.40%\n",
      "7\tValidation loss: 5.694453\tBest loss: 5.694453\tAccuracy: 77.20%\n",
      "8\tValidation loss: 8.961076\tBest loss: 5.694453\tAccuracy: 72.40%\n",
      "9\tValidation loss: 13.406515\tBest loss: 5.694453\tAccuracy: 72.90%\n",
      "10\tValidation loss: 8.029335\tBest loss: 5.694453\tAccuracy: 78.40%\n",
      "11\tValidation loss: 21.812704\tBest loss: 5.694453\tAccuracy: 67.40%\n",
      "12\tValidation loss: 19.514095\tBest loss: 5.694453\tAccuracy: 70.70%\n",
      "13\tValidation loss: 8.602746\tBest loss: 5.694453\tAccuracy: 83.20%\n",
      "14\tValidation loss: 10.055219\tBest loss: 5.694453\tAccuracy: 79.00%\n",
      "15\tValidation loss: 12.855941\tBest loss: 5.694453\tAccuracy: 80.80%\n",
      "16\tValidation loss: 25.820059\tBest loss: 5.694453\tAccuracy: 71.60%\n",
      "17\tValidation loss: 11.929857\tBest loss: 5.694453\tAccuracy: 82.60%\n",
      "18\tValidation loss: 12.852680\tBest loss: 5.694453\tAccuracy: 82.30%\n",
      "19\tValidation loss: 14.650685\tBest loss: 5.694453\tAccuracy: 82.00%\n",
      "20\tValidation loss: 14.744617\tBest loss: 5.694453\tAccuracy: 86.60%\n",
      "21\tValidation loss: 17.100700\tBest loss: 5.694453\tAccuracy: 84.30%\n",
      "22\tValidation loss: 20.483099\tBest loss: 5.694453\tAccuracy: 84.60%\n",
      "23\tValidation loss: 16.397699\tBest loss: 5.694453\tAccuracy: 86.30%\n",
      "24\tValidation loss: 21.181837\tBest loss: 5.694453\tAccuracy: 83.90%\n",
      "25\tValidation loss: 19.541761\tBest loss: 5.694453\tAccuracy: 85.60%\n",
      "26\tValidation loss: 14.531348\tBest loss: 5.694453\tAccuracy: 87.10%\n",
      "27\tValidation loss: 18.898508\tBest loss: 5.694453\tAccuracy: 87.40%\n",
      "28\tValidation loss: 13.156891\tBest loss: 5.694453\tAccuracy: 88.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.6s\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 15.657029\tBest loss: 15.657029\tAccuracy: 6.00%\n",
      "1\tValidation loss: 33.859409\tBest loss: 15.657029\tAccuracy: 14.70%\n",
      "2\tValidation loss: 22.111256\tBest loss: 15.657029\tAccuracy: 32.00%\n",
      "3\tValidation loss: 16.131144\tBest loss: 15.657029\tAccuracy: 48.20%\n",
      "4\tValidation loss: 16.047173\tBest loss: 15.657029\tAccuracy: 50.30%\n",
      "5\tValidation loss: 16.495838\tBest loss: 15.657029\tAccuracy: 64.20%\n",
      "6\tValidation loss: 8.682490\tBest loss: 8.682490\tAccuracy: 68.70%\n",
      "7\tValidation loss: 7.736249\tBest loss: 7.736249\tAccuracy: 75.50%\n",
      "8\tValidation loss: 8.896375\tBest loss: 7.736249\tAccuracy: 75.20%\n",
      "9\tValidation loss: 53.011677\tBest loss: 7.736249\tAccuracy: 51.00%\n",
      "10\tValidation loss: 9.522351\tBest loss: 7.736249\tAccuracy: 79.30%\n",
      "11\tValidation loss: 8.288167\tBest loss: 7.736249\tAccuracy: 78.50%\n",
      "12\tValidation loss: 5.891658\tBest loss: 5.891658\tAccuracy: 84.80%\n",
      "13\tValidation loss: 10.774980\tBest loss: 5.891658\tAccuracy: 81.00%\n",
      "14\tValidation loss: 17.001507\tBest loss: 5.891658\tAccuracy: 74.70%\n",
      "15\tValidation loss: 14.237633\tBest loss: 5.891658\tAccuracy: 76.60%\n",
      "16\tValidation loss: 8.508482\tBest loss: 5.891658\tAccuracy: 84.20%\n",
      "17\tValidation loss: 11.030994\tBest loss: 5.891658\tAccuracy: 83.50%\n",
      "18\tValidation loss: 11.250738\tBest loss: 5.891658\tAccuracy: 84.70%\n",
      "19\tValidation loss: 10.676663\tBest loss: 5.891658\tAccuracy: 86.30%\n",
      "20\tValidation loss: 12.478385\tBest loss: 5.891658\tAccuracy: 84.60%\n",
      "21\tValidation loss: 12.423035\tBest loss: 5.891658\tAccuracy: 84.00%\n",
      "22\tValidation loss: 12.678794\tBest loss: 5.891658\tAccuracy: 84.10%\n",
      "23\tValidation loss: 10.551786\tBest loss: 5.891658\tAccuracy: 87.60%\n",
      "24\tValidation loss: 12.874102\tBest loss: 5.891658\tAccuracy: 86.70%\n",
      "25\tValidation loss: 12.958742\tBest loss: 5.891658\tAccuracy: 86.80%\n",
      "26\tValidation loss: 14.083036\tBest loss: 5.891658\tAccuracy: 87.80%\n",
      "27\tValidation loss: 18.363514\tBest loss: 5.891658\tAccuracy: 85.30%\n",
      "28\tValidation loss: 17.483877\tBest loss: 5.891658\tAccuracy: 87.40%\n",
      "29\tValidation loss: 15.275974\tBest loss: 5.891658\tAccuracy: 86.20%\n",
      "30\tValidation loss: 13.006330\tBest loss: 5.891658\tAccuracy: 89.30%\n",
      "31\tValidation loss: 16.166307\tBest loss: 5.891658\tAccuracy: 88.10%\n",
      "32\tValidation loss: 18.244919\tBest loss: 5.891658\tAccuracy: 87.50%\n",
      "33\tValidation loss: 13.864162\tBest loss: 5.891658\tAccuracy: 89.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   5.1s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 0.987025\tBest loss: 0.987025\tAccuracy: 78.10%\n",
      "1\tValidation loss: 0.731216\tBest loss: 0.731216\tAccuracy: 81.10%\n",
      "2\tValidation loss: 0.844862\tBest loss: 0.731216\tAccuracy: 80.70%\n",
      "3\tValidation loss: 0.648123\tBest loss: 0.648123\tAccuracy: 83.80%\n",
      "4\tValidation loss: 0.819893\tBest loss: 0.648123\tAccuracy: 82.30%\n",
      "5\tValidation loss: 0.667668\tBest loss: 0.648123\tAccuracy: 85.70%\n",
      "6\tValidation loss: 0.598147\tBest loss: 0.598147\tAccuracy: 87.40%\n",
      "7\tValidation loss: 0.597891\tBest loss: 0.597891\tAccuracy: 86.40%\n",
      "8\tValidation loss: 0.629022\tBest loss: 0.597891\tAccuracy: 85.50%\n",
      "9\tValidation loss: 0.544510\tBest loss: 0.544510\tAccuracy: 88.30%\n",
      "10\tValidation loss: 0.520177\tBest loss: 0.520177\tAccuracy: 88.80%\n",
      "11\tValidation loss: 0.558719\tBest loss: 0.520177\tAccuracy: 89.20%\n",
      "12\tValidation loss: 0.659582\tBest loss: 0.520177\tAccuracy: 88.40%\n",
      "13\tValidation loss: 0.535049\tBest loss: 0.520177\tAccuracy: 88.80%\n",
      "14\tValidation loss: 0.641515\tBest loss: 0.520177\tAccuracy: 88.40%\n",
      "15\tValidation loss: 0.697527\tBest loss: 0.520177\tAccuracy: 88.40%\n",
      "16\tValidation loss: 0.588334\tBest loss: 0.520177\tAccuracy: 89.00%\n",
      "17\tValidation loss: 0.753264\tBest loss: 0.520177\tAccuracy: 86.30%\n",
      "18\tValidation loss: 0.920410\tBest loss: 0.520177\tAccuracy: 85.50%\n",
      "19\tValidation loss: 0.572982\tBest loss: 0.520177\tAccuracy: 89.50%\n",
      "20\tValidation loss: 0.719812\tBest loss: 0.520177\tAccuracy: 89.20%\n",
      "21\tValidation loss: 0.714806\tBest loss: 0.520177\tAccuracy: 87.50%\n",
      "22\tValidation loss: 0.560167\tBest loss: 0.520177\tAccuracy: 89.50%\n",
      "23\tValidation loss: 0.580345\tBest loss: 0.520177\tAccuracy: 90.20%\n",
      "24\tValidation loss: 0.650337\tBest loss: 0.520177\tAccuracy: 90.30%\n",
      "25\tValidation loss: 0.788229\tBest loss: 0.520177\tAccuracy: 87.40%\n",
      "26\tValidation loss: 0.798587\tBest loss: 0.520177\tAccuracy: 89.30%\n",
      "27\tValidation loss: 0.598872\tBest loss: 0.520177\tAccuracy: 91.00%\n",
      "28\tValidation loss: 0.876740\tBest loss: 0.520177\tAccuracy: 88.70%\n",
      "29\tValidation loss: 0.787986\tBest loss: 0.520177\tAccuracy: 89.40%\n",
      "30\tValidation loss: 0.848098\tBest loss: 0.520177\tAccuracy: 89.70%\n",
      "31\tValidation loss: 0.745567\tBest loss: 0.520177\tAccuracy: 90.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.0s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.027084\tBest loss: 1.027084\tAccuracy: 77.00%\n",
      "1\tValidation loss: 0.679735\tBest loss: 0.679735\tAccuracy: 84.00%\n",
      "2\tValidation loss: 0.806222\tBest loss: 0.679735\tAccuracy: 82.30%\n",
      "3\tValidation loss: 0.676128\tBest loss: 0.676128\tAccuracy: 84.40%\n",
      "4\tValidation loss: 0.866159\tBest loss: 0.676128\tAccuracy: 80.90%\n",
      "5\tValidation loss: 0.733782\tBest loss: 0.676128\tAccuracy: 85.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 0.807656\tBest loss: 0.676128\tAccuracy: 85.80%\n",
      "7\tValidation loss: 0.660496\tBest loss: 0.660496\tAccuracy: 87.30%\n",
      "8\tValidation loss: 0.803381\tBest loss: 0.660496\tAccuracy: 86.60%\n",
      "9\tValidation loss: 0.811492\tBest loss: 0.660496\tAccuracy: 86.30%\n",
      "10\tValidation loss: 0.923456\tBest loss: 0.660496\tAccuracy: 84.90%\n",
      "11\tValidation loss: 0.806064\tBest loss: 0.660496\tAccuracy: 86.90%\n",
      "12\tValidation loss: 0.935771\tBest loss: 0.660496\tAccuracy: 86.10%\n",
      "13\tValidation loss: 0.804587\tBest loss: 0.660496\tAccuracy: 86.70%\n",
      "14\tValidation loss: 0.864607\tBest loss: 0.660496\tAccuracy: 88.20%\n",
      "15\tValidation loss: 0.783238\tBest loss: 0.660496\tAccuracy: 89.30%\n",
      "16\tValidation loss: 0.777757\tBest loss: 0.660496\tAccuracy: 88.00%\n",
      "17\tValidation loss: 0.745081\tBest loss: 0.660496\tAccuracy: 90.10%\n",
      "18\tValidation loss: 0.777485\tBest loss: 0.660496\tAccuracy: 89.30%\n",
      "19\tValidation loss: 0.911563\tBest loss: 0.660496\tAccuracy: 90.60%\n",
      "20\tValidation loss: 0.921117\tBest loss: 0.660496\tAccuracy: 88.90%\n",
      "21\tValidation loss: 1.074617\tBest loss: 0.660496\tAccuracy: 85.90%\n",
      "22\tValidation loss: 1.126712\tBest loss: 0.660496\tAccuracy: 88.60%\n",
      "23\tValidation loss: 1.077214\tBest loss: 0.660496\tAccuracy: 86.80%\n",
      "24\tValidation loss: 0.995137\tBest loss: 0.660496\tAccuracy: 88.40%\n",
      "25\tValidation loss: 1.047461\tBest loss: 0.660496\tAccuracy: 85.90%\n",
      "26\tValidation loss: 1.008943\tBest loss: 0.660496\tAccuracy: 88.00%\n",
      "27\tValidation loss: 1.122300\tBest loss: 0.660496\tAccuracy: 88.40%\n",
      "28\tValidation loss: 1.222453\tBest loss: 0.660496\tAccuracy: 86.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   3.5s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 0.944481\tBest loss: 0.944481\tAccuracy: 77.80%\n",
      "1\tValidation loss: 0.924394\tBest loss: 0.924394\tAccuracy: 79.40%\n",
      "2\tValidation loss: 0.697458\tBest loss: 0.697458\tAccuracy: 84.40%\n",
      "3\tValidation loss: 0.934554\tBest loss: 0.697458\tAccuracy: 77.60%\n",
      "4\tValidation loss: 0.638499\tBest loss: 0.638499\tAccuracy: 84.80%\n",
      "5\tValidation loss: 0.642257\tBest loss: 0.638499\tAccuracy: 85.20%\n",
      "6\tValidation loss: 0.561057\tBest loss: 0.561057\tAccuracy: 88.20%\n",
      "7\tValidation loss: 0.705388\tBest loss: 0.561057\tAccuracy: 84.30%\n",
      "8\tValidation loss: 0.618132\tBest loss: 0.561057\tAccuracy: 87.60%\n",
      "9\tValidation loss: 0.724581\tBest loss: 0.561057\tAccuracy: 85.80%\n",
      "10\tValidation loss: 0.729915\tBest loss: 0.561057\tAccuracy: 86.90%\n",
      "11\tValidation loss: 0.652106\tBest loss: 0.561057\tAccuracy: 87.20%\n",
      "12\tValidation loss: 0.834356\tBest loss: 0.561057\tAccuracy: 86.00%\n",
      "13\tValidation loss: 0.593272\tBest loss: 0.561057\tAccuracy: 88.90%\n",
      "14\tValidation loss: 0.633235\tBest loss: 0.561057\tAccuracy: 88.00%\n",
      "15\tValidation loss: 0.765591\tBest loss: 0.561057\tAccuracy: 86.00%\n",
      "16\tValidation loss: 0.808641\tBest loss: 0.561057\tAccuracy: 86.00%\n",
      "17\tValidation loss: 0.895830\tBest loss: 0.561057\tAccuracy: 86.40%\n",
      "18\tValidation loss: 0.806028\tBest loss: 0.561057\tAccuracy: 88.20%\n",
      "19\tValidation loss: 0.762659\tBest loss: 0.561057\tAccuracy: 88.40%\n",
      "20\tValidation loss: 0.815989\tBest loss: 0.561057\tAccuracy: 89.20%\n",
      "21\tValidation loss: 1.182433\tBest loss: 0.561057\tAccuracy: 87.00%\n",
      "22\tValidation loss: 0.999438\tBest loss: 0.561057\tAccuracy: 85.80%\n",
      "23\tValidation loss: 0.681186\tBest loss: 0.561057\tAccuracy: 91.00%\n",
      "24\tValidation loss: 0.948459\tBest loss: 0.561057\tAccuracy: 85.80%\n",
      "25\tValidation loss: 0.744341\tBest loss: 0.561057\tAccuracy: 90.50%\n",
      "26\tValidation loss: 0.881751\tBest loss: 0.561057\tAccuracy: 89.90%\n",
      "27\tValidation loss: 0.756708\tBest loss: 0.561057\tAccuracy: 91.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   3.3s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 6.502098\tBest loss: 6.502098\tAccuracy: 30.20%\n",
      "1\tValidation loss: 2.487385\tBest loss: 2.487385\tAccuracy: 56.00%\n",
      "2\tValidation loss: 2.163932\tBest loss: 2.163932\tAccuracy: 61.60%\n",
      "3\tValidation loss: 2.831586\tBest loss: 2.163932\tAccuracy: 62.20%\n",
      "4\tValidation loss: 3.663310\tBest loss: 2.163932\tAccuracy: 62.30%\n",
      "5\tValidation loss: 2.493311\tBest loss: 2.163932\tAccuracy: 69.30%\n",
      "6\tValidation loss: 3.183877\tBest loss: 2.163932\tAccuracy: 67.80%\n",
      "7\tValidation loss: 3.387545\tBest loss: 2.163932\tAccuracy: 69.40%\n",
      "8\tValidation loss: 3.235254\tBest loss: 2.163932\tAccuracy: 71.40%\n",
      "9\tValidation loss: 2.631800\tBest loss: 2.163932\tAccuracy: 74.20%\n",
      "10\tValidation loss: 3.056049\tBest loss: 2.163932\tAccuracy: 73.80%\n",
      "11\tValidation loss: 3.777886\tBest loss: 2.163932\tAccuracy: 73.30%\n",
      "12\tValidation loss: 3.583498\tBest loss: 2.163932\tAccuracy: 74.10%\n",
      "13\tValidation loss: 3.014954\tBest loss: 2.163932\tAccuracy: 78.60%\n",
      "14\tValidation loss: 3.326233\tBest loss: 2.163932\tAccuracy: 76.70%\n",
      "15\tValidation loss: 4.219761\tBest loss: 2.163932\tAccuracy: 76.30%\n",
      "16\tValidation loss: 3.402792\tBest loss: 2.163932\tAccuracy: 77.70%\n",
      "17\tValidation loss: 3.812512\tBest loss: 2.163932\tAccuracy: 79.20%\n",
      "18\tValidation loss: 4.858726\tBest loss: 2.163932\tAccuracy: 78.30%\n",
      "19\tValidation loss: 4.255474\tBest loss: 2.163932\tAccuracy: 79.70%\n",
      "20\tValidation loss: 3.847841\tBest loss: 2.163932\tAccuracy: 80.80%\n",
      "21\tValidation loss: 4.352661\tBest loss: 2.163932\tAccuracy: 77.70%\n",
      "22\tValidation loss: 3.857828\tBest loss: 2.163932\tAccuracy: 81.80%\n",
      "23\tValidation loss: 5.024739\tBest loss: 2.163932\tAccuracy: 79.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.0s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 9.618463\tBest loss: 9.618463\tAccuracy: 16.70%\n",
      "1\tValidation loss: 2.886492\tBest loss: 2.886492\tAccuracy: 43.70%\n",
      "2\tValidation loss: 2.392406\tBest loss: 2.392406\tAccuracy: 51.00%\n",
      "3\tValidation loss: 2.352580\tBest loss: 2.352580\tAccuracy: 58.60%\n",
      "4\tValidation loss: 2.105419\tBest loss: 2.105419\tAccuracy: 65.40%\n",
      "5\tValidation loss: 2.873175\tBest loss: 2.105419\tAccuracy: 59.60%\n",
      "6\tValidation loss: 2.091186\tBest loss: 2.091186\tAccuracy: 70.30%\n",
      "7\tValidation loss: 2.806704\tBest loss: 2.091186\tAccuracy: 67.60%\n",
      "8\tValidation loss: 2.913069\tBest loss: 2.091186\tAccuracy: 67.90%\n",
      "9\tValidation loss: 2.991357\tBest loss: 2.091186\tAccuracy: 67.00%\n",
      "10\tValidation loss: 3.478549\tBest loss: 2.091186\tAccuracy: 69.00%\n",
      "11\tValidation loss: 3.209918\tBest loss: 2.091186\tAccuracy: 70.80%\n",
      "12\tValidation loss: 3.963885\tBest loss: 2.091186\tAccuracy: 67.30%\n",
      "13\tValidation loss: 3.492354\tBest loss: 2.091186\tAccuracy: 71.10%\n",
      "14\tValidation loss: 3.288830\tBest loss: 2.091186\tAccuracy: 73.60%\n",
      "15\tValidation loss: 3.572994\tBest loss: 2.091186\tAccuracy: 68.30%\n",
      "16\tValidation loss: 3.884339\tBest loss: 2.091186\tAccuracy: 71.20%\n",
      "17\tValidation loss: 4.028991\tBest loss: 2.091186\tAccuracy: 74.60%\n",
      "18\tValidation loss: 3.877094\tBest loss: 2.091186\tAccuracy: 73.30%\n",
      "19\tValidation loss: 3.614717\tBest loss: 2.091186\tAccuracy: 75.80%\n",
      "20\tValidation loss: 3.996204\tBest loss: 2.091186\tAccuracy: 72.20%\n",
      "21\tValidation loss: 3.164629\tBest loss: 2.091186\tAccuracy: 76.30%\n",
      "22\tValidation loss: 4.388188\tBest loss: 2.091186\tAccuracy: 77.00%\n",
      "23\tValidation loss: 3.626955\tBest loss: 2.091186\tAccuracy: 76.20%\n",
      "24\tValidation loss: 3.876385\tBest loss: 2.091186\tAccuracy: 79.80%\n",
      "25\tValidation loss: 4.330705\tBest loss: 2.091186\tAccuracy: 77.20%\n",
      "26\tValidation loss: 4.423837\tBest loss: 2.091186\tAccuracy: 79.70%\n",
      "27\tValidation loss: 3.633504\tBest loss: 2.091186\tAccuracy: 80.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.9s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 8.029907\tBest loss: 8.029907\tAccuracy: 18.00%\n",
      "1\tValidation loss: 4.471700\tBest loss: 4.471700\tAccuracy: 30.60%\n",
      "2\tValidation loss: 2.325081\tBest loss: 2.325081\tAccuracy: 51.30%\n",
      "3\tValidation loss: 2.099647\tBest loss: 2.099647\tAccuracy: 56.20%\n",
      "4\tValidation loss: 2.237613\tBest loss: 2.099647\tAccuracy: 60.20%\n",
      "5\tValidation loss: 3.765262\tBest loss: 2.099647\tAccuracy: 51.60%\n",
      "6\tValidation loss: 2.787287\tBest loss: 2.099647\tAccuracy: 61.80%\n",
      "7\tValidation loss: 2.590311\tBest loss: 2.099647\tAccuracy: 62.90%\n",
      "8\tValidation loss: 3.267946\tBest loss: 2.099647\tAccuracy: 61.90%\n",
      "9\tValidation loss: 2.809268\tBest loss: 2.099647\tAccuracy: 66.90%\n",
      "10\tValidation loss: 2.824849\tBest loss: 2.099647\tAccuracy: 71.60%\n",
      "11\tValidation loss: 3.961679\tBest loss: 2.099647\tAccuracy: 67.40%\n",
      "12\tValidation loss: 3.643234\tBest loss: 2.099647\tAccuracy: 66.90%\n",
      "13\tValidation loss: 3.946844\tBest loss: 2.099647\tAccuracy: 69.30%\n",
      "14\tValidation loss: 3.364081\tBest loss: 2.099647\tAccuracy: 70.40%\n",
      "15\tValidation loss: 3.339498\tBest loss: 2.099647\tAccuracy: 72.80%\n",
      "16\tValidation loss: 3.580751\tBest loss: 2.099647\tAccuracy: 74.30%\n",
      "17\tValidation loss: 4.803946\tBest loss: 2.099647\tAccuracy: 68.00%\n",
      "18\tValidation loss: 3.552215\tBest loss: 2.099647\tAccuracy: 70.60%\n",
      "19\tValidation loss: 4.142045\tBest loss: 2.099647\tAccuracy: 75.00%\n",
      "20\tValidation loss: 4.032001\tBest loss: 2.099647\tAccuracy: 73.90%\n",
      "21\tValidation loss: 4.275703\tBest loss: 2.099647\tAccuracy: 72.80%\n",
      "22\tValidation loss: 4.131434\tBest loss: 2.099647\tAccuracy: 75.70%\n",
      "23\tValidation loss: 4.466420\tBest loss: 2.099647\tAccuracy: 72.80%\n",
      "24\tValidation loss: 4.824343\tBest loss: 2.099647\tAccuracy: 73.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.5s\n",
      "[CV] batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.018332\tBest loss: 1.018332\tAccuracy: 68.80%\n",
      "1\tValidation loss: 0.736072\tBest loss: 0.736072\tAccuracy: 79.00%\n",
      "2\tValidation loss: 0.783105\tBest loss: 0.736072\tAccuracy: 77.30%\n",
      "3\tValidation loss: 0.609101\tBest loss: 0.609101\tAccuracy: 83.50%\n",
      "4\tValidation loss: 0.557354\tBest loss: 0.557354\tAccuracy: 83.90%\n",
      "5\tValidation loss: 0.480701\tBest loss: 0.480701\tAccuracy: 86.80%\n",
      "6\tValidation loss: 0.509936\tBest loss: 0.480701\tAccuracy: 86.60%\n",
      "7\tValidation loss: 0.556136\tBest loss: 0.480701\tAccuracy: 84.40%\n",
      "8\tValidation loss: 0.427913\tBest loss: 0.427913\tAccuracy: 88.20%\n",
      "9\tValidation loss: 0.605084\tBest loss: 0.427913\tAccuracy: 84.50%\n",
      "10\tValidation loss: 0.555080\tBest loss: 0.427913\tAccuracy: 84.80%\n",
      "11\tValidation loss: 0.435686\tBest loss: 0.427913\tAccuracy: 88.50%\n",
      "12\tValidation loss: 0.520064\tBest loss: 0.427913\tAccuracy: 86.20%\n",
      "13\tValidation loss: 0.544385\tBest loss: 0.427913\tAccuracy: 86.60%\n",
      "14\tValidation loss: 0.516125\tBest loss: 0.427913\tAccuracy: 89.30%\n",
      "15\tValidation loss: 0.629978\tBest loss: 0.427913\tAccuracy: 86.10%\n",
      "16\tValidation loss: 0.611260\tBest loss: 0.427913\tAccuracy: 87.50%\n",
      "17\tValidation loss: 0.572528\tBest loss: 0.427913\tAccuracy: 87.50%\n",
      "18\tValidation loss: 0.589833\tBest loss: 0.427913\tAccuracy: 88.30%\n",
      "19\tValidation loss: 0.592807\tBest loss: 0.427913\tAccuracy: 87.50%\n",
      "20\tValidation loss: 0.568464\tBest loss: 0.427913\tAccuracy: 87.80%\n",
      "21\tValidation loss: 0.491225\tBest loss: 0.427913\tAccuracy: 90.40%\n",
      "22\tValidation loss: 0.539380\tBest loss: 0.427913\tAccuracy: 89.10%\n",
      "23\tValidation loss: 0.592868\tBest loss: 0.427913\tAccuracy: 88.50%\n",
      "24\tValidation loss: 0.592198\tBest loss: 0.427913\tAccuracy: 89.10%\n",
      "25\tValidation loss: 0.692673\tBest loss: 0.427913\tAccuracy: 87.40%\n",
      "26\tValidation loss: 0.713424\tBest loss: 0.427913\tAccuracy: 87.30%\n",
      "27\tValidation loss: 0.657541\tBest loss: 0.427913\tAccuracy: 88.80%\n",
      "28\tValidation loss: 0.770472\tBest loss: 0.427913\tAccuracy: 87.40%\n",
      "29\tValidation loss: 0.851696\tBest loss: 0.427913\tAccuracy: 87.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   5.1s\n",
      "[CV] batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.032408\tBest loss: 1.032408\tAccuracy: 70.20%\n",
      "1\tValidation loss: 0.772962\tBest loss: 0.772962\tAccuracy: 79.40%\n",
      "2\tValidation loss: 0.703224\tBest loss: 0.703224\tAccuracy: 79.60%\n",
      "3\tValidation loss: 0.651667\tBest loss: 0.651667\tAccuracy: 81.20%\n",
      "4\tValidation loss: 0.625156\tBest loss: 0.625156\tAccuracy: 83.30%\n",
      "5\tValidation loss: 0.517847\tBest loss: 0.517847\tAccuracy: 86.60%\n",
      "6\tValidation loss: 0.596897\tBest loss: 0.517847\tAccuracy: 84.20%\n",
      "7\tValidation loss: 0.590369\tBest loss: 0.517847\tAccuracy: 86.10%\n",
      "8\tValidation loss: 0.592208\tBest loss: 0.517847\tAccuracy: 84.80%\n",
      "9\tValidation loss: 0.573093\tBest loss: 0.517847\tAccuracy: 85.00%\n",
      "10\tValidation loss: 0.684012\tBest loss: 0.517847\tAccuracy: 84.00%\n",
      "11\tValidation loss: 0.618113\tBest loss: 0.517847\tAccuracy: 85.00%\n",
      "12\tValidation loss: 0.621208\tBest loss: 0.517847\tAccuracy: 86.60%\n",
      "13\tValidation loss: 0.504479\tBest loss: 0.504479\tAccuracy: 88.10%\n",
      "14\tValidation loss: 0.609650\tBest loss: 0.504479\tAccuracy: 85.60%\n",
      "15\tValidation loss: 0.553474\tBest loss: 0.504479\tAccuracy: 87.60%\n",
      "16\tValidation loss: 0.886563\tBest loss: 0.504479\tAccuracy: 82.30%\n",
      "17\tValidation loss: 0.618298\tBest loss: 0.504479\tAccuracy: 85.50%\n",
      "18\tValidation loss: 0.635210\tBest loss: 0.504479\tAccuracy: 86.10%\n",
      "19\tValidation loss: 0.824391\tBest loss: 0.504479\tAccuracy: 83.80%\n",
      "20\tValidation loss: 0.697950\tBest loss: 0.504479\tAccuracy: 86.70%\n",
      "21\tValidation loss: 0.729938\tBest loss: 0.504479\tAccuracy: 87.00%\n",
      "22\tValidation loss: 0.609376\tBest loss: 0.504479\tAccuracy: 88.70%\n",
      "23\tValidation loss: 0.863861\tBest loss: 0.504479\tAccuracy: 84.20%\n",
      "24\tValidation loss: 0.787984\tBest loss: 0.504479\tAccuracy: 85.40%\n",
      "25\tValidation loss: 0.757710\tBest loss: 0.504479\tAccuracy: 85.20%\n",
      "26\tValidation loss: 0.725945\tBest loss: 0.504479\tAccuracy: 87.00%\n",
      "27\tValidation loss: 0.711308\tBest loss: 0.504479\tAccuracy: 88.80%\n",
      "28\tValidation loss: 0.689808\tBest loss: 0.504479\tAccuracy: 88.40%\n",
      "29\tValidation loss: 0.944248\tBest loss: 0.504479\tAccuracy: 85.90%\n",
      "30\tValidation loss: 0.711618\tBest loss: 0.504479\tAccuracy: 88.00%\n",
      "31\tValidation loss: 0.596449\tBest loss: 0.504479\tAccuracy: 87.70%\n",
      "32\tValidation loss: 0.862971\tBest loss: 0.504479\tAccuracy: 88.00%\n",
      "33\tValidation loss: 0.729218\tBest loss: 0.504479\tAccuracy: 89.20%\n",
      "34\tValidation loss: 0.797949\tBest loss: 0.504479\tAccuracy: 88.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   5.9s\n",
      "[CV] batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 0.987502\tBest loss: 0.987502\tAccuracy: 72.40%\n",
      "1\tValidation loss: 1.012464\tBest loss: 0.987502\tAccuracy: 71.00%\n",
      "2\tValidation loss: 0.706412\tBest loss: 0.706412\tAccuracy: 79.80%\n",
      "3\tValidation loss: 0.651692\tBest loss: 0.651692\tAccuracy: 81.30%\n",
      "4\tValidation loss: 0.660964\tBest loss: 0.651692\tAccuracy: 82.90%\n",
      "5\tValidation loss: 0.648003\tBest loss: 0.648003\tAccuracy: 82.50%\n",
      "6\tValidation loss: 0.587972\tBest loss: 0.587972\tAccuracy: 84.00%\n",
      "7\tValidation loss: 0.534776\tBest loss: 0.534776\tAccuracy: 87.00%\n",
      "8\tValidation loss: 0.558003\tBest loss: 0.534776\tAccuracy: 85.10%\n",
      "9\tValidation loss: 0.497093\tBest loss: 0.497093\tAccuracy: 87.20%\n",
      "10\tValidation loss: 0.577182\tBest loss: 0.497093\tAccuracy: 85.10%\n",
      "11\tValidation loss: 0.587213\tBest loss: 0.497093\tAccuracy: 86.70%\n",
      "12\tValidation loss: 0.485028\tBest loss: 0.485028\tAccuracy: 87.00%\n",
      "13\tValidation loss: 0.440021\tBest loss: 0.440021\tAccuracy: 88.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\tValidation loss: 0.508523\tBest loss: 0.440021\tAccuracy: 88.00%\n",
      "15\tValidation loss: 0.521032\tBest loss: 0.440021\tAccuracy: 88.40%\n",
      "16\tValidation loss: 0.613481\tBest loss: 0.440021\tAccuracy: 86.30%\n",
      "17\tValidation loss: 0.569248\tBest loss: 0.440021\tAccuracy: 86.60%\n",
      "18\tValidation loss: 0.505016\tBest loss: 0.440021\tAccuracy: 88.20%\n",
      "19\tValidation loss: 0.630683\tBest loss: 0.440021\tAccuracy: 86.80%\n",
      "20\tValidation loss: 0.495761\tBest loss: 0.440021\tAccuracy: 88.90%\n",
      "21\tValidation loss: 0.669219\tBest loss: 0.440021\tAccuracy: 85.90%\n",
      "22\tValidation loss: 0.529323\tBest loss: 0.440021\tAccuracy: 87.80%\n",
      "23\tValidation loss: 0.635436\tBest loss: 0.440021\tAccuracy: 86.80%\n",
      "24\tValidation loss: 0.628428\tBest loss: 0.440021\tAccuracy: 89.00%\n",
      "25\tValidation loss: 0.646020\tBest loss: 0.440021\tAccuracy: 88.10%\n",
      "26\tValidation loss: 0.615585\tBest loss: 0.440021\tAccuracy: 88.90%\n",
      "27\tValidation loss: 0.598901\tBest loss: 0.440021\tAccuracy: 87.70%\n",
      "28\tValidation loss: 0.767053\tBest loss: 0.440021\tAccuracy: 87.10%\n",
      "29\tValidation loss: 0.672163\tBest loss: 0.440021\tAccuracy: 87.80%\n",
      "30\tValidation loss: 0.807437\tBest loss: 0.440021\tAccuracy: 86.00%\n",
      "31\tValidation loss: 0.607896\tBest loss: 0.440021\tAccuracy: 88.80%\n",
      "32\tValidation loss: 0.789244\tBest loss: 0.440021\tAccuracy: 86.60%\n",
      "33\tValidation loss: 0.744043\tBest loss: 0.440021\tAccuracy: 87.60%\n",
      "34\tValidation loss: 0.615126\tBest loss: 0.440021\tAccuracy: 90.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   5.6s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.076404\tBest loss: 2.076404\tAccuracy: 48.90%\n",
      "1\tValidation loss: 1.528953\tBest loss: 1.528953\tAccuracy: 63.30%\n",
      "2\tValidation loss: 1.276702\tBest loss: 1.276702\tAccuracy: 68.70%\n",
      "3\tValidation loss: 1.106133\tBest loss: 1.106133\tAccuracy: 74.20%\n",
      "4\tValidation loss: 0.998482\tBest loss: 0.998482\tAccuracy: 76.20%\n",
      "5\tValidation loss: 0.928215\tBest loss: 0.928215\tAccuracy: 78.50%\n",
      "6\tValidation loss: 0.850100\tBest loss: 0.850100\tAccuracy: 80.00%\n",
      "7\tValidation loss: 0.804010\tBest loss: 0.804010\tAccuracy: 80.10%\n",
      "8\tValidation loss: 0.778201\tBest loss: 0.778201\tAccuracy: 82.40%\n",
      "9\tValidation loss: 0.740568\tBest loss: 0.740568\tAccuracy: 82.10%\n",
      "10\tValidation loss: 0.709104\tBest loss: 0.709104\tAccuracy: 82.40%\n",
      "11\tValidation loss: 0.678472\tBest loss: 0.678472\tAccuracy: 83.80%\n",
      "12\tValidation loss: 0.660000\tBest loss: 0.660000\tAccuracy: 84.10%\n",
      "13\tValidation loss: 0.637894\tBest loss: 0.637894\tAccuracy: 84.10%\n",
      "14\tValidation loss: 0.616823\tBest loss: 0.616823\tAccuracy: 85.00%\n",
      "15\tValidation loss: 0.608195\tBest loss: 0.608195\tAccuracy: 85.50%\n",
      "16\tValidation loss: 0.591565\tBest loss: 0.591565\tAccuracy: 86.10%\n",
      "17\tValidation loss: 0.576611\tBest loss: 0.576611\tAccuracy: 86.30%\n",
      "18\tValidation loss: 0.565710\tBest loss: 0.565710\tAccuracy: 86.00%\n",
      "19\tValidation loss: 0.548640\tBest loss: 0.548640\tAccuracy: 86.70%\n",
      "20\tValidation loss: 0.550431\tBest loss: 0.548640\tAccuracy: 86.90%\n",
      "21\tValidation loss: 0.532573\tBest loss: 0.532573\tAccuracy: 86.50%\n",
      "22\tValidation loss: 0.524032\tBest loss: 0.524032\tAccuracy: 87.90%\n",
      "23\tValidation loss: 0.516013\tBest loss: 0.516013\tAccuracy: 86.80%\n",
      "24\tValidation loss: 0.507925\tBest loss: 0.507925\tAccuracy: 88.20%\n",
      "25\tValidation loss: 0.509186\tBest loss: 0.507925\tAccuracy: 87.40%\n",
      "26\tValidation loss: 0.497372\tBest loss: 0.497372\tAccuracy: 86.60%\n",
      "27\tValidation loss: 0.491781\tBest loss: 0.491781\tAccuracy: 87.70%\n",
      "28\tValidation loss: 0.487043\tBest loss: 0.487043\tAccuracy: 88.40%\n",
      "29\tValidation loss: 0.486373\tBest loss: 0.486373\tAccuracy: 88.00%\n",
      "30\tValidation loss: 0.486739\tBest loss: 0.486373\tAccuracy: 87.50%\n",
      "31\tValidation loss: 0.469334\tBest loss: 0.469334\tAccuracy: 87.50%\n",
      "32\tValidation loss: 0.467276\tBest loss: 0.467276\tAccuracy: 87.60%\n",
      "33\tValidation loss: 0.462551\tBest loss: 0.462551\tAccuracy: 88.50%\n",
      "34\tValidation loss: 0.459528\tBest loss: 0.459528\tAccuracy: 88.30%\n",
      "35\tValidation loss: 0.453084\tBest loss: 0.453084\tAccuracy: 88.40%\n",
      "36\tValidation loss: 0.444526\tBest loss: 0.444526\tAccuracy: 88.40%\n",
      "37\tValidation loss: 0.444842\tBest loss: 0.444526\tAccuracy: 88.40%\n",
      "38\tValidation loss: 0.444531\tBest loss: 0.444526\tAccuracy: 88.70%\n",
      "39\tValidation loss: 0.434420\tBest loss: 0.434420\tAccuracy: 88.50%\n",
      "40\tValidation loss: 0.440443\tBest loss: 0.434420\tAccuracy: 88.40%\n",
      "41\tValidation loss: 0.432648\tBest loss: 0.432648\tAccuracy: 88.70%\n",
      "42\tValidation loss: 0.422174\tBest loss: 0.422174\tAccuracy: 89.30%\n",
      "43\tValidation loss: 0.417020\tBest loss: 0.417020\tAccuracy: 89.30%\n",
      "44\tValidation loss: 0.427030\tBest loss: 0.417020\tAccuracy: 89.00%\n",
      "45\tValidation loss: 0.407574\tBest loss: 0.407574\tAccuracy: 89.70%\n",
      "46\tValidation loss: 0.412209\tBest loss: 0.407574\tAccuracy: 89.20%\n",
      "47\tValidation loss: 0.408878\tBest loss: 0.407574\tAccuracy: 89.30%\n",
      "48\tValidation loss: 0.408492\tBest loss: 0.407574\tAccuracy: 89.40%\n",
      "49\tValidation loss: 0.411208\tBest loss: 0.407574\tAccuracy: 89.70%\n",
      "50\tValidation loss: 0.410633\tBest loss: 0.407574\tAccuracy: 89.80%\n",
      "51\tValidation loss: 0.413108\tBest loss: 0.407574\tAccuracy: 89.50%\n",
      "52\tValidation loss: 0.395628\tBest loss: 0.395628\tAccuracy: 90.20%\n",
      "53\tValidation loss: 0.406221\tBest loss: 0.395628\tAccuracy: 90.10%\n",
      "54\tValidation loss: 0.388825\tBest loss: 0.388825\tAccuracy: 90.10%\n",
      "55\tValidation loss: 0.389441\tBest loss: 0.388825\tAccuracy: 90.60%\n",
      "56\tValidation loss: 0.398644\tBest loss: 0.388825\tAccuracy: 89.80%\n",
      "57\tValidation loss: 0.394731\tBest loss: 0.388825\tAccuracy: 89.30%\n",
      "58\tValidation loss: 0.387179\tBest loss: 0.387179\tAccuracy: 90.40%\n",
      "59\tValidation loss: 0.384446\tBest loss: 0.384446\tAccuracy: 89.90%\n",
      "60\tValidation loss: 0.382672\tBest loss: 0.382672\tAccuracy: 90.00%\n",
      "61\tValidation loss: 0.380244\tBest loss: 0.380244\tAccuracy: 90.30%\n",
      "62\tValidation loss: 0.377233\tBest loss: 0.377233\tAccuracy: 90.00%\n",
      "63\tValidation loss: 0.375664\tBest loss: 0.375664\tAccuracy: 90.80%\n",
      "64\tValidation loss: 0.372830\tBest loss: 0.372830\tAccuracy: 91.00%\n",
      "65\tValidation loss: 0.372671\tBest loss: 0.372671\tAccuracy: 90.60%\n",
      "66\tValidation loss: 0.368519\tBest loss: 0.368519\tAccuracy: 90.60%\n",
      "67\tValidation loss: 0.375763\tBest loss: 0.368519\tAccuracy: 91.10%\n",
      "68\tValidation loss: 0.371259\tBest loss: 0.368519\tAccuracy: 90.50%\n",
      "69\tValidation loss: 0.364876\tBest loss: 0.364876\tAccuracy: 91.10%\n",
      "70\tValidation loss: 0.368347\tBest loss: 0.364876\tAccuracy: 90.30%\n",
      "71\tValidation loss: 0.364057\tBest loss: 0.364057\tAccuracy: 91.10%\n",
      "72\tValidation loss: 0.361457\tBest loss: 0.361457\tAccuracy: 91.00%\n",
      "73\tValidation loss: 0.363763\tBest loss: 0.361457\tAccuracy: 91.30%\n",
      "74\tValidation loss: 0.369059\tBest loss: 0.361457\tAccuracy: 90.40%\n",
      "75\tValidation loss: 0.357743\tBest loss: 0.357743\tAccuracy: 90.90%\n",
      "76\tValidation loss: 0.359537\tBest loss: 0.357743\tAccuracy: 90.60%\n",
      "77\tValidation loss: 0.363990\tBest loss: 0.357743\tAccuracy: 90.30%\n",
      "78\tValidation loss: 0.353894\tBest loss: 0.353894\tAccuracy: 91.40%\n",
      "79\tValidation loss: 0.348817\tBest loss: 0.348817\tAccuracy: 91.20%\n",
      "80\tValidation loss: 0.359710\tBest loss: 0.348817\tAccuracy: 91.10%\n",
      "81\tValidation loss: 0.356473\tBest loss: 0.348817\tAccuracy: 91.00%\n",
      "82\tValidation loss: 0.359813\tBest loss: 0.348817\tAccuracy: 90.90%\n",
      "83\tValidation loss: 0.343815\tBest loss: 0.343815\tAccuracy: 91.40%\n",
      "84\tValidation loss: 0.348368\tBest loss: 0.343815\tAccuracy: 91.60%\n",
      "85\tValidation loss: 0.346237\tBest loss: 0.343815\tAccuracy: 91.40%\n",
      "86\tValidation loss: 0.348502\tBest loss: 0.343815\tAccuracy: 91.20%\n",
      "87\tValidation loss: 0.345620\tBest loss: 0.343815\tAccuracy: 92.00%\n",
      "88\tValidation loss: 0.343175\tBest loss: 0.343175\tAccuracy: 91.80%\n",
      "89\tValidation loss: 0.348092\tBest loss: 0.343175\tAccuracy: 91.10%\n",
      "90\tValidation loss: 0.345557\tBest loss: 0.343175\tAccuracy: 91.20%\n",
      "91\tValidation loss: 0.337435\tBest loss: 0.337435\tAccuracy: 91.80%\n",
      "92\tValidation loss: 0.345303\tBest loss: 0.337435\tAccuracy: 91.60%\n",
      "93\tValidation loss: 0.339119\tBest loss: 0.337435\tAccuracy: 91.90%\n",
      "94\tValidation loss: 0.343472\tBest loss: 0.337435\tAccuracy: 91.90%\n",
      "95\tValidation loss: 0.336006\tBest loss: 0.336006\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\tValidation loss: 0.336132\tBest loss: 0.336006\tAccuracy: 91.60%\n",
      "97\tValidation loss: 0.336605\tBest loss: 0.336006\tAccuracy: 92.30%\n",
      "98\tValidation loss: 0.335442\tBest loss: 0.335442\tAccuracy: 92.10%\n",
      "99\tValidation loss: 0.333296\tBest loss: 0.333296\tAccuracy: 92.10%\n",
      "100\tValidation loss: 0.329488\tBest loss: 0.329488\tAccuracy: 91.90%\n",
      "101\tValidation loss: 0.329012\tBest loss: 0.329012\tAccuracy: 92.10%\n",
      "102\tValidation loss: 0.328466\tBest loss: 0.328466\tAccuracy: 92.40%\n",
      "103\tValidation loss: 0.335085\tBest loss: 0.328466\tAccuracy: 92.00%\n",
      "104\tValidation loss: 0.329164\tBest loss: 0.328466\tAccuracy: 92.20%\n",
      "105\tValidation loss: 0.326645\tBest loss: 0.326645\tAccuracy: 92.30%\n",
      "106\tValidation loss: 0.330000\tBest loss: 0.326645\tAccuracy: 92.30%\n",
      "107\tValidation loss: 0.330608\tBest loss: 0.326645\tAccuracy: 92.30%\n",
      "108\tValidation loss: 0.332029\tBest loss: 0.326645\tAccuracy: 92.00%\n",
      "109\tValidation loss: 0.323811\tBest loss: 0.323811\tAccuracy: 92.50%\n",
      "110\tValidation loss: 0.329481\tBest loss: 0.323811\tAccuracy: 92.40%\n",
      "111\tValidation loss: 0.334117\tBest loss: 0.323811\tAccuracy: 92.10%\n",
      "112\tValidation loss: 0.328098\tBest loss: 0.323811\tAccuracy: 92.50%\n",
      "113\tValidation loss: 0.322871\tBest loss: 0.322871\tAccuracy: 92.30%\n",
      "114\tValidation loss: 0.326044\tBest loss: 0.322871\tAccuracy: 92.90%\n",
      "115\tValidation loss: 0.325340\tBest loss: 0.322871\tAccuracy: 92.30%\n",
      "116\tValidation loss: 0.324421\tBest loss: 0.322871\tAccuracy: 92.70%\n",
      "117\tValidation loss: 0.322435\tBest loss: 0.322435\tAccuracy: 92.50%\n",
      "118\tValidation loss: 0.320302\tBest loss: 0.320302\tAccuracy: 92.30%\n",
      "119\tValidation loss: 0.321944\tBest loss: 0.320302\tAccuracy: 92.60%\n",
      "120\tValidation loss: 0.322983\tBest loss: 0.320302\tAccuracy: 92.70%\n",
      "121\tValidation loss: 0.321933\tBest loss: 0.320302\tAccuracy: 92.80%\n",
      "122\tValidation loss: 0.318275\tBest loss: 0.318275\tAccuracy: 92.40%\n",
      "123\tValidation loss: 0.322495\tBest loss: 0.318275\tAccuracy: 92.30%\n",
      "124\tValidation loss: 0.320385\tBest loss: 0.318275\tAccuracy: 92.40%\n",
      "125\tValidation loss: 0.315525\tBest loss: 0.315525\tAccuracy: 92.80%\n",
      "126\tValidation loss: 0.322200\tBest loss: 0.315525\tAccuracy: 92.30%\n",
      "127\tValidation loss: 0.323178\tBest loss: 0.315525\tAccuracy: 92.20%\n",
      "128\tValidation loss: 0.314468\tBest loss: 0.314468\tAccuracy: 92.60%\n",
      "129\tValidation loss: 0.317696\tBest loss: 0.314468\tAccuracy: 92.80%\n",
      "130\tValidation loss: 0.321117\tBest loss: 0.314468\tAccuracy: 92.70%\n",
      "131\tValidation loss: 0.313147\tBest loss: 0.313147\tAccuracy: 93.00%\n",
      "132\tValidation loss: 0.320965\tBest loss: 0.313147\tAccuracy: 92.60%\n",
      "133\tValidation loss: 0.316299\tBest loss: 0.313147\tAccuracy: 92.90%\n",
      "134\tValidation loss: 0.318014\tBest loss: 0.313147\tAccuracy: 92.60%\n",
      "135\tValidation loss: 0.317003\tBest loss: 0.313147\tAccuracy: 92.60%\n",
      "136\tValidation loss: 0.315293\tBest loss: 0.313147\tAccuracy: 93.20%\n",
      "137\tValidation loss: 0.312388\tBest loss: 0.312388\tAccuracy: 92.50%\n",
      "138\tValidation loss: 0.310403\tBest loss: 0.310403\tAccuracy: 92.30%\n",
      "139\tValidation loss: 0.310630\tBest loss: 0.310403\tAccuracy: 92.80%\n",
      "140\tValidation loss: 0.311869\tBest loss: 0.310403\tAccuracy: 92.80%\n",
      "141\tValidation loss: 0.315702\tBest loss: 0.310403\tAccuracy: 92.90%\n",
      "142\tValidation loss: 0.314753\tBest loss: 0.310403\tAccuracy: 92.80%\n",
      "143\tValidation loss: 0.305867\tBest loss: 0.305867\tAccuracy: 92.70%\n",
      "144\tValidation loss: 0.308438\tBest loss: 0.305867\tAccuracy: 92.70%\n",
      "145\tValidation loss: 0.306981\tBest loss: 0.305867\tAccuracy: 93.00%\n",
      "146\tValidation loss: 0.304175\tBest loss: 0.304175\tAccuracy: 92.70%\n",
      "147\tValidation loss: 0.305742\tBest loss: 0.304175\tAccuracy: 92.90%\n",
      "148\tValidation loss: 0.309646\tBest loss: 0.304175\tAccuracy: 92.30%\n",
      "149\tValidation loss: 0.309054\tBest loss: 0.304175\tAccuracy: 92.70%\n",
      "150\tValidation loss: 0.305435\tBest loss: 0.304175\tAccuracy: 92.80%\n",
      "151\tValidation loss: 0.303335\tBest loss: 0.303335\tAccuracy: 93.00%\n",
      "152\tValidation loss: 0.305554\tBest loss: 0.303335\tAccuracy: 92.90%\n",
      "153\tValidation loss: 0.300677\tBest loss: 0.300677\tAccuracy: 92.70%\n",
      "154\tValidation loss: 0.307239\tBest loss: 0.300677\tAccuracy: 93.00%\n",
      "155\tValidation loss: 0.305455\tBest loss: 0.300677\tAccuracy: 93.10%\n",
      "156\tValidation loss: 0.311375\tBest loss: 0.300677\tAccuracy: 92.80%\n",
      "157\tValidation loss: 0.312127\tBest loss: 0.300677\tAccuracy: 92.80%\n",
      "158\tValidation loss: 0.307228\tBest loss: 0.300677\tAccuracy: 92.50%\n",
      "159\tValidation loss: 0.303853\tBest loss: 0.300677\tAccuracy: 92.70%\n",
      "160\tValidation loss: 0.306573\tBest loss: 0.300677\tAccuracy: 92.50%\n",
      "161\tValidation loss: 0.309532\tBest loss: 0.300677\tAccuracy: 92.70%\n",
      "162\tValidation loss: 0.300746\tBest loss: 0.300677\tAccuracy: 92.40%\n",
      "163\tValidation loss: 0.301201\tBest loss: 0.300677\tAccuracy: 92.90%\n",
      "164\tValidation loss: 0.301642\tBest loss: 0.300677\tAccuracy: 92.80%\n",
      "165\tValidation loss: 0.303710\tBest loss: 0.300677\tAccuracy: 92.90%\n",
      "166\tValidation loss: 0.302568\tBest loss: 0.300677\tAccuracy: 92.90%\n",
      "167\tValidation loss: 0.300944\tBest loss: 0.300677\tAccuracy: 92.60%\n",
      "168\tValidation loss: 0.306789\tBest loss: 0.300677\tAccuracy: 93.20%\n",
      "169\tValidation loss: 0.300800\tBest loss: 0.300677\tAccuracy: 93.00%\n",
      "170\tValidation loss: 0.302301\tBest loss: 0.300677\tAccuracy: 92.60%\n",
      "171\tValidation loss: 0.299245\tBest loss: 0.299245\tAccuracy: 93.00%\n",
      "172\tValidation loss: 0.298123\tBest loss: 0.298123\tAccuracy: 93.20%\n",
      "173\tValidation loss: 0.304172\tBest loss: 0.298123\tAccuracy: 93.20%\n",
      "174\tValidation loss: 0.296630\tBest loss: 0.296630\tAccuracy: 92.70%\n",
      "175\tValidation loss: 0.297487\tBest loss: 0.296630\tAccuracy: 93.00%\n",
      "176\tValidation loss: 0.305277\tBest loss: 0.296630\tAccuracy: 92.80%\n",
      "177\tValidation loss: 0.301924\tBest loss: 0.296630\tAccuracy: 93.20%\n",
      "178\tValidation loss: 0.301926\tBest loss: 0.296630\tAccuracy: 93.00%\n",
      "179\tValidation loss: 0.296249\tBest loss: 0.296249\tAccuracy: 93.10%\n",
      "180\tValidation loss: 0.297550\tBest loss: 0.296249\tAccuracy: 93.00%\n",
      "181\tValidation loss: 0.297097\tBest loss: 0.296249\tAccuracy: 92.80%\n",
      "182\tValidation loss: 0.298485\tBest loss: 0.296249\tAccuracy: 92.90%\n",
      "183\tValidation loss: 0.299862\tBest loss: 0.296249\tAccuracy: 93.10%\n",
      "184\tValidation loss: 0.299173\tBest loss: 0.296249\tAccuracy: 93.00%\n",
      "185\tValidation loss: 0.299774\tBest loss: 0.296249\tAccuracy: 93.10%\n",
      "186\tValidation loss: 0.294660\tBest loss: 0.294660\tAccuracy: 93.20%\n",
      "187\tValidation loss: 0.295371\tBest loss: 0.294660\tAccuracy: 93.00%\n",
      "188\tValidation loss: 0.298044\tBest loss: 0.294660\tAccuracy: 93.20%\n",
      "189\tValidation loss: 0.296212\tBest loss: 0.294660\tAccuracy: 93.40%\n",
      "190\tValidation loss: 0.298010\tBest loss: 0.294660\tAccuracy: 93.30%\n",
      "191\tValidation loss: 0.297504\tBest loss: 0.294660\tAccuracy: 93.20%\n",
      "192\tValidation loss: 0.295425\tBest loss: 0.294660\tAccuracy: 93.20%\n",
      "193\tValidation loss: 0.296854\tBest loss: 0.294660\tAccuracy: 93.20%\n",
      "194\tValidation loss: 0.294390\tBest loss: 0.294390\tAccuracy: 93.00%\n",
      "195\tValidation loss: 0.289478\tBest loss: 0.289478\tAccuracy: 93.00%\n",
      "196\tValidation loss: 0.292650\tBest loss: 0.289478\tAccuracy: 93.30%\n",
      "197\tValidation loss: 0.294903\tBest loss: 0.289478\tAccuracy: 93.40%\n",
      "198\tValidation loss: 0.296742\tBest loss: 0.289478\tAccuracy: 93.20%\n",
      "199\tValidation loss: 0.294505\tBest loss: 0.289478\tAccuracy: 93.20%\n",
      "200\tValidation loss: 0.301222\tBest loss: 0.289478\tAccuracy: 93.00%\n",
      "201\tValidation loss: 0.297788\tBest loss: 0.289478\tAccuracy: 93.00%\n",
      "202\tValidation loss: 0.297257\tBest loss: 0.289478\tAccuracy: 93.40%\n",
      "203\tValidation loss: 0.294567\tBest loss: 0.289478\tAccuracy: 93.10%\n",
      "204\tValidation loss: 0.298812\tBest loss: 0.289478\tAccuracy: 93.10%\n",
      "205\tValidation loss: 0.295234\tBest loss: 0.289478\tAccuracy: 93.20%\n",
      "206\tValidation loss: 0.289171\tBest loss: 0.289171\tAccuracy: 93.20%\n",
      "207\tValidation loss: 0.292274\tBest loss: 0.289171\tAccuracy: 93.40%\n",
      "208\tValidation loss: 0.294797\tBest loss: 0.289171\tAccuracy: 93.50%\n",
      "209\tValidation loss: 0.288958\tBest loss: 0.288958\tAccuracy: 93.20%\n",
      "210\tValidation loss: 0.289292\tBest loss: 0.288958\tAccuracy: 93.20%\n",
      "211\tValidation loss: 0.290648\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "212\tValidation loss: 0.290259\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "213\tValidation loss: 0.291317\tBest loss: 0.288958\tAccuracy: 93.50%\n",
      "214\tValidation loss: 0.289662\tBest loss: 0.288958\tAccuracy: 93.20%\n",
      "215\tValidation loss: 0.289508\tBest loss: 0.288958\tAccuracy: 93.30%\n",
      "216\tValidation loss: 0.289946\tBest loss: 0.288958\tAccuracy: 93.20%\n",
      "217\tValidation loss: 0.290958\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "218\tValidation loss: 0.292271\tBest loss: 0.288958\tAccuracy: 93.20%\n",
      "219\tValidation loss: 0.292282\tBest loss: 0.288958\tAccuracy: 93.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\tValidation loss: 0.295255\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "221\tValidation loss: 0.290656\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "222\tValidation loss: 0.293690\tBest loss: 0.288958\tAccuracy: 93.40%\n",
      "223\tValidation loss: 0.294614\tBest loss: 0.288958\tAccuracy: 93.70%\n",
      "224\tValidation loss: 0.288018\tBest loss: 0.288018\tAccuracy: 93.40%\n",
      "225\tValidation loss: 0.288369\tBest loss: 0.288018\tAccuracy: 93.30%\n",
      "226\tValidation loss: 0.290113\tBest loss: 0.288018\tAccuracy: 93.30%\n",
      "227\tValidation loss: 0.285280\tBest loss: 0.285280\tAccuracy: 93.30%\n",
      "228\tValidation loss: 0.291321\tBest loss: 0.285280\tAccuracy: 93.30%\n",
      "229\tValidation loss: 0.293874\tBest loss: 0.285280\tAccuracy: 93.80%\n",
      "230\tValidation loss: 0.290471\tBest loss: 0.285280\tAccuracy: 92.90%\n",
      "231\tValidation loss: 0.292345\tBest loss: 0.285280\tAccuracy: 93.40%\n",
      "232\tValidation loss: 0.289167\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "233\tValidation loss: 0.290959\tBest loss: 0.285280\tAccuracy: 93.20%\n",
      "234\tValidation loss: 0.292566\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "235\tValidation loss: 0.291617\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "236\tValidation loss: 0.292290\tBest loss: 0.285280\tAccuracy: 93.40%\n",
      "237\tValidation loss: 0.289687\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "238\tValidation loss: 0.290710\tBest loss: 0.285280\tAccuracy: 93.70%\n",
      "239\tValidation loss: 0.286894\tBest loss: 0.285280\tAccuracy: 93.30%\n",
      "240\tValidation loss: 0.290733\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "241\tValidation loss: 0.291780\tBest loss: 0.285280\tAccuracy: 93.70%\n",
      "242\tValidation loss: 0.288160\tBest loss: 0.285280\tAccuracy: 93.40%\n",
      "243\tValidation loss: 0.289742\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "244\tValidation loss: 0.291904\tBest loss: 0.285280\tAccuracy: 93.70%\n",
      "245\tValidation loss: 0.290247\tBest loss: 0.285280\tAccuracy: 93.60%\n",
      "246\tValidation loss: 0.287141\tBest loss: 0.285280\tAccuracy: 93.70%\n",
      "247\tValidation loss: 0.286595\tBest loss: 0.285280\tAccuracy: 93.30%\n",
      "248\tValidation loss: 0.288405\tBest loss: 0.285280\tAccuracy: 93.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  39.4s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.106335\tBest loss: 2.106335\tAccuracy: 49.80%\n",
      "1\tValidation loss: 1.592957\tBest loss: 1.592957\tAccuracy: 60.70%\n",
      "2\tValidation loss: 1.277092\tBest loss: 1.277092\tAccuracy: 69.80%\n",
      "3\tValidation loss: 1.095989\tBest loss: 1.095989\tAccuracy: 74.40%\n",
      "4\tValidation loss: 1.014997\tBest loss: 1.014997\tAccuracy: 76.30%\n",
      "5\tValidation loss: 0.960958\tBest loss: 0.960958\tAccuracy: 75.30%\n",
      "6\tValidation loss: 0.876219\tBest loss: 0.876219\tAccuracy: 78.70%\n",
      "7\tValidation loss: 0.822513\tBest loss: 0.822513\tAccuracy: 79.10%\n",
      "8\tValidation loss: 0.784141\tBest loss: 0.784141\tAccuracy: 80.90%\n",
      "9\tValidation loss: 0.770138\tBest loss: 0.770138\tAccuracy: 80.00%\n",
      "10\tValidation loss: 0.730588\tBest loss: 0.730588\tAccuracy: 82.80%\n",
      "11\tValidation loss: 0.703078\tBest loss: 0.703078\tAccuracy: 82.70%\n",
      "12\tValidation loss: 0.683200\tBest loss: 0.683200\tAccuracy: 83.50%\n",
      "13\tValidation loss: 0.649925\tBest loss: 0.649925\tAccuracy: 84.50%\n",
      "14\tValidation loss: 0.623441\tBest loss: 0.623441\tAccuracy: 86.10%\n",
      "15\tValidation loss: 0.615475\tBest loss: 0.615475\tAccuracy: 85.60%\n",
      "16\tValidation loss: 0.600290\tBest loss: 0.600290\tAccuracy: 85.90%\n",
      "17\tValidation loss: 0.600667\tBest loss: 0.600290\tAccuracy: 85.40%\n",
      "18\tValidation loss: 0.588973\tBest loss: 0.588973\tAccuracy: 85.70%\n",
      "19\tValidation loss: 0.576983\tBest loss: 0.576983\tAccuracy: 87.10%\n",
      "20\tValidation loss: 0.558121\tBest loss: 0.558121\tAccuracy: 86.90%\n",
      "21\tValidation loss: 0.557084\tBest loss: 0.557084\tAccuracy: 87.00%\n",
      "22\tValidation loss: 0.543917\tBest loss: 0.543917\tAccuracy: 86.30%\n",
      "23\tValidation loss: 0.540259\tBest loss: 0.540259\tAccuracy: 86.40%\n",
      "24\tValidation loss: 0.528993\tBest loss: 0.528993\tAccuracy: 87.00%\n",
      "25\tValidation loss: 0.533610\tBest loss: 0.528993\tAccuracy: 87.00%\n",
      "26\tValidation loss: 0.517661\tBest loss: 0.517661\tAccuracy: 88.30%\n",
      "27\tValidation loss: 0.526471\tBest loss: 0.517661\tAccuracy: 87.10%\n",
      "28\tValidation loss: 0.514111\tBest loss: 0.514111\tAccuracy: 88.30%\n",
      "29\tValidation loss: 0.504007\tBest loss: 0.504007\tAccuracy: 87.90%\n",
      "30\tValidation loss: 0.489401\tBest loss: 0.489401\tAccuracy: 88.20%\n",
      "31\tValidation loss: 0.495127\tBest loss: 0.489401\tAccuracy: 88.30%\n",
      "32\tValidation loss: 0.494215\tBest loss: 0.489401\tAccuracy: 88.50%\n",
      "33\tValidation loss: 0.480721\tBest loss: 0.480721\tAccuracy: 88.20%\n",
      "34\tValidation loss: 0.485106\tBest loss: 0.480721\tAccuracy: 88.60%\n",
      "35\tValidation loss: 0.473224\tBest loss: 0.473224\tAccuracy: 88.20%\n",
      "36\tValidation loss: 0.470498\tBest loss: 0.470498\tAccuracy: 88.00%\n",
      "37\tValidation loss: 0.472147\tBest loss: 0.470498\tAccuracy: 88.70%\n",
      "38\tValidation loss: 0.466748\tBest loss: 0.466748\tAccuracy: 88.30%\n",
      "39\tValidation loss: 0.468656\tBest loss: 0.466748\tAccuracy: 88.40%\n",
      "40\tValidation loss: 0.464571\tBest loss: 0.464571\tAccuracy: 88.60%\n",
      "41\tValidation loss: 0.456154\tBest loss: 0.456154\tAccuracy: 88.70%\n",
      "42\tValidation loss: 0.453913\tBest loss: 0.453913\tAccuracy: 89.10%\n",
      "43\tValidation loss: 0.439371\tBest loss: 0.439371\tAccuracy: 89.00%\n",
      "44\tValidation loss: 0.447476\tBest loss: 0.439371\tAccuracy: 89.40%\n",
      "45\tValidation loss: 0.442329\tBest loss: 0.439371\tAccuracy: 88.80%\n",
      "46\tValidation loss: 0.450629\tBest loss: 0.439371\tAccuracy: 89.60%\n",
      "47\tValidation loss: 0.450941\tBest loss: 0.439371\tAccuracy: 89.20%\n",
      "48\tValidation loss: 0.443337\tBest loss: 0.439371\tAccuracy: 89.40%\n",
      "49\tValidation loss: 0.440245\tBest loss: 0.439371\tAccuracy: 89.30%\n",
      "50\tValidation loss: 0.435936\tBest loss: 0.435936\tAccuracy: 89.30%\n",
      "51\tValidation loss: 0.439445\tBest loss: 0.435936\tAccuracy: 89.50%\n",
      "52\tValidation loss: 0.427241\tBest loss: 0.427241\tAccuracy: 89.30%\n",
      "53\tValidation loss: 0.431975\tBest loss: 0.427241\tAccuracy: 89.70%\n",
      "54\tValidation loss: 0.429664\tBest loss: 0.427241\tAccuracy: 90.00%\n",
      "55\tValidation loss: 0.425463\tBest loss: 0.425463\tAccuracy: 89.80%\n",
      "56\tValidation loss: 0.425800\tBest loss: 0.425463\tAccuracy: 89.70%\n",
      "57\tValidation loss: 0.423914\tBest loss: 0.423914\tAccuracy: 89.70%\n",
      "58\tValidation loss: 0.427305\tBest loss: 0.423914\tAccuracy: 90.00%\n",
      "59\tValidation loss: 0.419106\tBest loss: 0.419106\tAccuracy: 90.20%\n",
      "60\tValidation loss: 0.431379\tBest loss: 0.419106\tAccuracy: 89.80%\n",
      "61\tValidation loss: 0.418050\tBest loss: 0.418050\tAccuracy: 90.10%\n",
      "62\tValidation loss: 0.420532\tBest loss: 0.418050\tAccuracy: 91.00%\n",
      "63\tValidation loss: 0.411834\tBest loss: 0.411834\tAccuracy: 90.90%\n",
      "64\tValidation loss: 0.408233\tBest loss: 0.408233\tAccuracy: 90.70%\n",
      "65\tValidation loss: 0.406756\tBest loss: 0.406756\tAccuracy: 90.40%\n",
      "66\tValidation loss: 0.408336\tBest loss: 0.406756\tAccuracy: 90.50%\n",
      "67\tValidation loss: 0.415561\tBest loss: 0.406756\tAccuracy: 90.60%\n",
      "68\tValidation loss: 0.410334\tBest loss: 0.406756\tAccuracy: 90.20%\n",
      "69\tValidation loss: 0.408464\tBest loss: 0.406756\tAccuracy: 90.90%\n",
      "70\tValidation loss: 0.410072\tBest loss: 0.406756\tAccuracy: 90.70%\n",
      "71\tValidation loss: 0.408756\tBest loss: 0.406756\tAccuracy: 90.90%\n",
      "72\tValidation loss: 0.416302\tBest loss: 0.406756\tAccuracy: 90.60%\n",
      "73\tValidation loss: 0.403093\tBest loss: 0.403093\tAccuracy: 91.10%\n",
      "74\tValidation loss: 0.411730\tBest loss: 0.403093\tAccuracy: 91.40%\n",
      "75\tValidation loss: 0.401672\tBest loss: 0.401672\tAccuracy: 91.40%\n",
      "76\tValidation loss: 0.399664\tBest loss: 0.399664\tAccuracy: 90.60%\n",
      "77\tValidation loss: 0.409184\tBest loss: 0.399664\tAccuracy: 90.90%\n",
      "78\tValidation loss: 0.397734\tBest loss: 0.397734\tAccuracy: 91.40%\n",
      "79\tValidation loss: 0.399293\tBest loss: 0.397734\tAccuracy: 91.60%\n",
      "80\tValidation loss: 0.400315\tBest loss: 0.397734\tAccuracy: 91.30%\n",
      "81\tValidation loss: 0.399919\tBest loss: 0.397734\tAccuracy: 91.60%\n",
      "82\tValidation loss: 0.393745\tBest loss: 0.393745\tAccuracy: 91.60%\n",
      "83\tValidation loss: 0.396422\tBest loss: 0.393745\tAccuracy: 91.60%\n",
      "84\tValidation loss: 0.394340\tBest loss: 0.393745\tAccuracy: 91.60%\n",
      "85\tValidation loss: 0.393095\tBest loss: 0.393095\tAccuracy: 91.50%\n",
      "86\tValidation loss: 0.395481\tBest loss: 0.393095\tAccuracy: 91.30%\n",
      "87\tValidation loss: 0.397108\tBest loss: 0.393095\tAccuracy: 91.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\tValidation loss: 0.392828\tBest loss: 0.392828\tAccuracy: 91.50%\n",
      "89\tValidation loss: 0.399078\tBest loss: 0.392828\tAccuracy: 91.60%\n",
      "90\tValidation loss: 0.390157\tBest loss: 0.390157\tAccuracy: 91.90%\n",
      "91\tValidation loss: 0.387276\tBest loss: 0.387276\tAccuracy: 91.20%\n",
      "92\tValidation loss: 0.392095\tBest loss: 0.387276\tAccuracy: 91.50%\n",
      "93\tValidation loss: 0.387828\tBest loss: 0.387276\tAccuracy: 91.60%\n",
      "94\tValidation loss: 0.391037\tBest loss: 0.387276\tAccuracy: 91.90%\n",
      "95\tValidation loss: 0.387758\tBest loss: 0.387276\tAccuracy: 91.50%\n",
      "96\tValidation loss: 0.389458\tBest loss: 0.387276\tAccuracy: 91.70%\n",
      "97\tValidation loss: 0.386832\tBest loss: 0.386832\tAccuracy: 91.80%\n",
      "98\tValidation loss: 0.387350\tBest loss: 0.386832\tAccuracy: 91.70%\n",
      "99\tValidation loss: 0.394791\tBest loss: 0.386832\tAccuracy: 92.00%\n",
      "100\tValidation loss: 0.388192\tBest loss: 0.386832\tAccuracy: 92.00%\n",
      "101\tValidation loss: 0.388996\tBest loss: 0.386832\tAccuracy: 91.60%\n",
      "102\tValidation loss: 0.387475\tBest loss: 0.386832\tAccuracy: 91.60%\n",
      "103\tValidation loss: 0.385253\tBest loss: 0.385253\tAccuracy: 91.90%\n",
      "104\tValidation loss: 0.384211\tBest loss: 0.384211\tAccuracy: 92.30%\n",
      "105\tValidation loss: 0.384847\tBest loss: 0.384211\tAccuracy: 91.90%\n",
      "106\tValidation loss: 0.381611\tBest loss: 0.381611\tAccuracy: 92.00%\n",
      "107\tValidation loss: 0.384593\tBest loss: 0.381611\tAccuracy: 92.20%\n",
      "108\tValidation loss: 0.391055\tBest loss: 0.381611\tAccuracy: 91.50%\n",
      "109\tValidation loss: 0.389300\tBest loss: 0.381611\tAccuracy: 91.70%\n",
      "110\tValidation loss: 0.388367\tBest loss: 0.381611\tAccuracy: 91.90%\n",
      "111\tValidation loss: 0.382159\tBest loss: 0.381611\tAccuracy: 92.30%\n",
      "112\tValidation loss: 0.382990\tBest loss: 0.381611\tAccuracy: 91.90%\n",
      "113\tValidation loss: 0.383709\tBest loss: 0.381611\tAccuracy: 92.10%\n",
      "114\tValidation loss: 0.382429\tBest loss: 0.381611\tAccuracy: 92.00%\n",
      "115\tValidation loss: 0.387480\tBest loss: 0.381611\tAccuracy: 92.10%\n",
      "116\tValidation loss: 0.381561\tBest loss: 0.381561\tAccuracy: 92.00%\n",
      "117\tValidation loss: 0.379058\tBest loss: 0.379058\tAccuracy: 92.20%\n",
      "118\tValidation loss: 0.382032\tBest loss: 0.379058\tAccuracy: 92.10%\n",
      "119\tValidation loss: 0.385211\tBest loss: 0.379058\tAccuracy: 92.40%\n",
      "120\tValidation loss: 0.381765\tBest loss: 0.379058\tAccuracy: 92.10%\n",
      "121\tValidation loss: 0.386314\tBest loss: 0.379058\tAccuracy: 92.40%\n",
      "122\tValidation loss: 0.378244\tBest loss: 0.378244\tAccuracy: 92.40%\n",
      "123\tValidation loss: 0.379887\tBest loss: 0.378244\tAccuracy: 92.30%\n",
      "124\tValidation loss: 0.385735\tBest loss: 0.378244\tAccuracy: 92.40%\n",
      "125\tValidation loss: 0.376715\tBest loss: 0.376715\tAccuracy: 92.30%\n",
      "126\tValidation loss: 0.383922\tBest loss: 0.376715\tAccuracy: 92.20%\n",
      "127\tValidation loss: 0.383294\tBest loss: 0.376715\tAccuracy: 92.30%\n",
      "128\tValidation loss: 0.383221\tBest loss: 0.376715\tAccuracy: 92.10%\n",
      "129\tValidation loss: 0.378743\tBest loss: 0.376715\tAccuracy: 92.30%\n",
      "130\tValidation loss: 0.373441\tBest loss: 0.373441\tAccuracy: 92.60%\n",
      "131\tValidation loss: 0.377410\tBest loss: 0.373441\tAccuracy: 92.40%\n",
      "132\tValidation loss: 0.377159\tBest loss: 0.373441\tAccuracy: 92.30%\n",
      "133\tValidation loss: 0.379696\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "134\tValidation loss: 0.376071\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "135\tValidation loss: 0.381311\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "136\tValidation loss: 0.380315\tBest loss: 0.373441\tAccuracy: 92.40%\n",
      "137\tValidation loss: 0.378622\tBest loss: 0.373441\tAccuracy: 92.10%\n",
      "138\tValidation loss: 0.378329\tBest loss: 0.373441\tAccuracy: 92.30%\n",
      "139\tValidation loss: 0.382648\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "140\tValidation loss: 0.380785\tBest loss: 0.373441\tAccuracy: 92.60%\n",
      "141\tValidation loss: 0.381891\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "142\tValidation loss: 0.381194\tBest loss: 0.373441\tAccuracy: 92.60%\n",
      "143\tValidation loss: 0.377346\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "144\tValidation loss: 0.380363\tBest loss: 0.373441\tAccuracy: 92.50%\n",
      "145\tValidation loss: 0.383048\tBest loss: 0.373441\tAccuracy: 92.30%\n",
      "146\tValidation loss: 0.379510\tBest loss: 0.373441\tAccuracy: 92.20%\n",
      "147\tValidation loss: 0.376475\tBest loss: 0.373441\tAccuracy: 92.70%\n",
      "148\tValidation loss: 0.385309\tBest loss: 0.373441\tAccuracy: 92.60%\n",
      "149\tValidation loss: 0.379839\tBest loss: 0.373441\tAccuracy: 92.30%\n",
      "150\tValidation loss: 0.378218\tBest loss: 0.373441\tAccuracy: 92.80%\n",
      "151\tValidation loss: 0.378995\tBest loss: 0.373441\tAccuracy: 92.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  24.4s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.065108\tBest loss: 2.065108\tAccuracy: 50.50%\n",
      "1\tValidation loss: 1.569215\tBest loss: 1.569215\tAccuracy: 62.30%\n",
      "2\tValidation loss: 1.268571\tBest loss: 1.268571\tAccuracy: 69.50%\n",
      "3\tValidation loss: 1.118671\tBest loss: 1.118671\tAccuracy: 73.10%\n",
      "4\tValidation loss: 1.003985\tBest loss: 1.003985\tAccuracy: 75.60%\n",
      "5\tValidation loss: 0.942505\tBest loss: 0.942505\tAccuracy: 76.90%\n",
      "6\tValidation loss: 0.877291\tBest loss: 0.877291\tAccuracy: 78.40%\n",
      "7\tValidation loss: 0.827197\tBest loss: 0.827197\tAccuracy: 80.40%\n",
      "8\tValidation loss: 0.778000\tBest loss: 0.778000\tAccuracy: 81.50%\n",
      "9\tValidation loss: 0.769016\tBest loss: 0.769016\tAccuracy: 79.80%\n",
      "10\tValidation loss: 0.718786\tBest loss: 0.718786\tAccuracy: 83.00%\n",
      "11\tValidation loss: 0.697490\tBest loss: 0.697490\tAccuracy: 83.50%\n",
      "12\tValidation loss: 0.684733\tBest loss: 0.684733\tAccuracy: 83.20%\n",
      "13\tValidation loss: 0.657266\tBest loss: 0.657266\tAccuracy: 84.90%\n",
      "14\tValidation loss: 0.643620\tBest loss: 0.643620\tAccuracy: 84.90%\n",
      "15\tValidation loss: 0.627192\tBest loss: 0.627192\tAccuracy: 84.70%\n",
      "16\tValidation loss: 0.627018\tBest loss: 0.627018\tAccuracy: 84.70%\n",
      "17\tValidation loss: 0.601397\tBest loss: 0.601397\tAccuracy: 84.40%\n",
      "18\tValidation loss: 0.600090\tBest loss: 0.600090\tAccuracy: 85.60%\n",
      "19\tValidation loss: 0.574358\tBest loss: 0.574358\tAccuracy: 86.40%\n",
      "20\tValidation loss: 0.575707\tBest loss: 0.574358\tAccuracy: 86.20%\n",
      "21\tValidation loss: 0.576017\tBest loss: 0.574358\tAccuracy: 85.60%\n",
      "22\tValidation loss: 0.545627\tBest loss: 0.545627\tAccuracy: 87.70%\n",
      "23\tValidation loss: 0.548649\tBest loss: 0.545627\tAccuracy: 87.50%\n",
      "24\tValidation loss: 0.537095\tBest loss: 0.537095\tAccuracy: 86.40%\n",
      "25\tValidation loss: 0.532950\tBest loss: 0.532950\tAccuracy: 87.10%\n",
      "26\tValidation loss: 0.515048\tBest loss: 0.515048\tAccuracy: 88.70%\n",
      "27\tValidation loss: 0.518440\tBest loss: 0.515048\tAccuracy: 87.90%\n",
      "28\tValidation loss: 0.512124\tBest loss: 0.512124\tAccuracy: 87.90%\n",
      "29\tValidation loss: 0.505282\tBest loss: 0.505282\tAccuracy: 88.10%\n",
      "30\tValidation loss: 0.498902\tBest loss: 0.498902\tAccuracy: 87.50%\n",
      "31\tValidation loss: 0.504933\tBest loss: 0.498902\tAccuracy: 87.80%\n",
      "32\tValidation loss: 0.498528\tBest loss: 0.498528\tAccuracy: 87.50%\n",
      "33\tValidation loss: 0.490375\tBest loss: 0.490375\tAccuracy: 87.80%\n",
      "34\tValidation loss: 0.485029\tBest loss: 0.485029\tAccuracy: 88.30%\n",
      "35\tValidation loss: 0.480662\tBest loss: 0.480662\tAccuracy: 88.50%\n",
      "36\tValidation loss: 0.480492\tBest loss: 0.480492\tAccuracy: 88.90%\n",
      "37\tValidation loss: 0.465051\tBest loss: 0.465051\tAccuracy: 89.30%\n",
      "38\tValidation loss: 0.463169\tBest loss: 0.463169\tAccuracy: 88.80%\n",
      "39\tValidation loss: 0.454440\tBest loss: 0.454440\tAccuracy: 89.70%\n",
      "40\tValidation loss: 0.458499\tBest loss: 0.454440\tAccuracy: 89.10%\n",
      "41\tValidation loss: 0.448487\tBest loss: 0.448487\tAccuracy: 89.80%\n",
      "42\tValidation loss: 0.454885\tBest loss: 0.448487\tAccuracy: 89.60%\n",
      "43\tValidation loss: 0.450426\tBest loss: 0.448487\tAccuracy: 89.60%\n",
      "44\tValidation loss: 0.438375\tBest loss: 0.438375\tAccuracy: 89.80%\n",
      "45\tValidation loss: 0.443686\tBest loss: 0.438375\tAccuracy: 89.80%\n",
      "46\tValidation loss: 0.448565\tBest loss: 0.438375\tAccuracy: 89.80%\n",
      "47\tValidation loss: 0.439884\tBest loss: 0.438375\tAccuracy: 89.50%\n",
      "48\tValidation loss: 0.433487\tBest loss: 0.433487\tAccuracy: 90.20%\n",
      "49\tValidation loss: 0.427123\tBest loss: 0.427123\tAccuracy: 90.30%\n",
      "50\tValidation loss: 0.431642\tBest loss: 0.427123\tAccuracy: 89.70%\n",
      "51\tValidation loss: 0.423730\tBest loss: 0.423730\tAccuracy: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\tValidation loss: 0.426069\tBest loss: 0.423730\tAccuracy: 89.40%\n",
      "53\tValidation loss: 0.424958\tBest loss: 0.423730\tAccuracy: 90.10%\n",
      "54\tValidation loss: 0.421540\tBest loss: 0.421540\tAccuracy: 90.30%\n",
      "55\tValidation loss: 0.427878\tBest loss: 0.421540\tAccuracy: 90.00%\n",
      "56\tValidation loss: 0.419569\tBest loss: 0.419569\tAccuracy: 89.60%\n",
      "57\tValidation loss: 0.419718\tBest loss: 0.419569\tAccuracy: 89.50%\n",
      "58\tValidation loss: 0.412621\tBest loss: 0.412621\tAccuracy: 90.60%\n",
      "59\tValidation loss: 0.416192\tBest loss: 0.412621\tAccuracy: 89.70%\n",
      "60\tValidation loss: 0.413007\tBest loss: 0.412621\tAccuracy: 90.20%\n",
      "61\tValidation loss: 0.418524\tBest loss: 0.412621\tAccuracy: 89.80%\n",
      "62\tValidation loss: 0.412548\tBest loss: 0.412548\tAccuracy: 90.20%\n",
      "63\tValidation loss: 0.401280\tBest loss: 0.401280\tAccuracy: 90.70%\n",
      "64\tValidation loss: 0.399972\tBest loss: 0.399972\tAccuracy: 90.80%\n",
      "65\tValidation loss: 0.404979\tBest loss: 0.399972\tAccuracy: 90.80%\n",
      "66\tValidation loss: 0.399134\tBest loss: 0.399134\tAccuracy: 90.60%\n",
      "67\tValidation loss: 0.400189\tBest loss: 0.399134\tAccuracy: 90.60%\n",
      "68\tValidation loss: 0.390861\tBest loss: 0.390861\tAccuracy: 91.20%\n",
      "69\tValidation loss: 0.397268\tBest loss: 0.390861\tAccuracy: 91.00%\n",
      "70\tValidation loss: 0.396283\tBest loss: 0.390861\tAccuracy: 90.30%\n",
      "71\tValidation loss: 0.394509\tBest loss: 0.390861\tAccuracy: 91.00%\n",
      "72\tValidation loss: 0.394060\tBest loss: 0.390861\tAccuracy: 90.80%\n",
      "73\tValidation loss: 0.393162\tBest loss: 0.390861\tAccuracy: 90.60%\n",
      "74\tValidation loss: 0.392739\tBest loss: 0.390861\tAccuracy: 91.20%\n",
      "75\tValidation loss: 0.391602\tBest loss: 0.390861\tAccuracy: 90.30%\n",
      "76\tValidation loss: 0.389200\tBest loss: 0.389200\tAccuracy: 90.70%\n",
      "77\tValidation loss: 0.394823\tBest loss: 0.389200\tAccuracy: 90.60%\n",
      "78\tValidation loss: 0.382583\tBest loss: 0.382583\tAccuracy: 91.10%\n",
      "79\tValidation loss: 0.390427\tBest loss: 0.382583\tAccuracy: 91.10%\n",
      "80\tValidation loss: 0.385501\tBest loss: 0.382583\tAccuracy: 90.50%\n",
      "81\tValidation loss: 0.382047\tBest loss: 0.382047\tAccuracy: 91.10%\n",
      "82\tValidation loss: 0.383058\tBest loss: 0.382047\tAccuracy: 90.80%\n",
      "83\tValidation loss: 0.383997\tBest loss: 0.382047\tAccuracy: 90.90%\n",
      "84\tValidation loss: 0.379489\tBest loss: 0.379489\tAccuracy: 90.90%\n",
      "85\tValidation loss: 0.377944\tBest loss: 0.377944\tAccuracy: 90.60%\n",
      "86\tValidation loss: 0.376382\tBest loss: 0.376382\tAccuracy: 90.90%\n",
      "87\tValidation loss: 0.375318\tBest loss: 0.375318\tAccuracy: 91.10%\n",
      "88\tValidation loss: 0.368923\tBest loss: 0.368923\tAccuracy: 91.00%\n",
      "89\tValidation loss: 0.371301\tBest loss: 0.368923\tAccuracy: 91.00%\n",
      "90\tValidation loss: 0.373600\tBest loss: 0.368923\tAccuracy: 91.10%\n",
      "91\tValidation loss: 0.371609\tBest loss: 0.368923\tAccuracy: 91.60%\n",
      "92\tValidation loss: 0.375322\tBest loss: 0.368923\tAccuracy: 91.00%\n",
      "93\tValidation loss: 0.369707\tBest loss: 0.368923\tAccuracy: 91.50%\n",
      "94\tValidation loss: 0.375302\tBest loss: 0.368923\tAccuracy: 90.60%\n",
      "95\tValidation loss: 0.366598\tBest loss: 0.366598\tAccuracy: 91.60%\n",
      "96\tValidation loss: 0.367214\tBest loss: 0.366598\tAccuracy: 91.20%\n",
      "97\tValidation loss: 0.370154\tBest loss: 0.366598\tAccuracy: 91.10%\n",
      "98\tValidation loss: 0.366904\tBest loss: 0.366598\tAccuracy: 91.10%\n",
      "99\tValidation loss: 0.361241\tBest loss: 0.361241\tAccuracy: 91.50%\n",
      "100\tValidation loss: 0.370074\tBest loss: 0.361241\tAccuracy: 91.30%\n",
      "101\tValidation loss: 0.360424\tBest loss: 0.360424\tAccuracy: 91.30%\n",
      "102\tValidation loss: 0.359689\tBest loss: 0.359689\tAccuracy: 91.50%\n",
      "103\tValidation loss: 0.360270\tBest loss: 0.359689\tAccuracy: 91.10%\n",
      "104\tValidation loss: 0.362140\tBest loss: 0.359689\tAccuracy: 91.50%\n",
      "105\tValidation loss: 0.369695\tBest loss: 0.359689\tAccuracy: 91.30%\n",
      "106\tValidation loss: 0.360224\tBest loss: 0.359689\tAccuracy: 91.30%\n",
      "107\tValidation loss: 0.365136\tBest loss: 0.359689\tAccuracy: 90.80%\n",
      "108\tValidation loss: 0.362505\tBest loss: 0.359689\tAccuracy: 91.40%\n",
      "109\tValidation loss: 0.353917\tBest loss: 0.353917\tAccuracy: 91.30%\n",
      "110\tValidation loss: 0.358244\tBest loss: 0.353917\tAccuracy: 91.10%\n",
      "111\tValidation loss: 0.364692\tBest loss: 0.353917\tAccuracy: 91.10%\n",
      "112\tValidation loss: 0.356289\tBest loss: 0.353917\tAccuracy: 91.60%\n",
      "113\tValidation loss: 0.356474\tBest loss: 0.353917\tAccuracy: 91.60%\n",
      "114\tValidation loss: 0.359025\tBest loss: 0.353917\tAccuracy: 91.40%\n",
      "115\tValidation loss: 0.352607\tBest loss: 0.352607\tAccuracy: 91.80%\n",
      "116\tValidation loss: 0.357673\tBest loss: 0.352607\tAccuracy: 91.20%\n",
      "117\tValidation loss: 0.352237\tBest loss: 0.352237\tAccuracy: 91.70%\n",
      "118\tValidation loss: 0.345893\tBest loss: 0.345893\tAccuracy: 92.00%\n",
      "119\tValidation loss: 0.352758\tBest loss: 0.345893\tAccuracy: 92.10%\n",
      "120\tValidation loss: 0.349378\tBest loss: 0.345893\tAccuracy: 92.00%\n",
      "121\tValidation loss: 0.350050\tBest loss: 0.345893\tAccuracy: 92.20%\n",
      "122\tValidation loss: 0.352735\tBest loss: 0.345893\tAccuracy: 91.30%\n",
      "123\tValidation loss: 0.352852\tBest loss: 0.345893\tAccuracy: 91.90%\n",
      "124\tValidation loss: 0.346419\tBest loss: 0.345893\tAccuracy: 92.00%\n",
      "125\tValidation loss: 0.348886\tBest loss: 0.345893\tAccuracy: 91.90%\n",
      "126\tValidation loss: 0.351161\tBest loss: 0.345893\tAccuracy: 91.60%\n",
      "127\tValidation loss: 0.351993\tBest loss: 0.345893\tAccuracy: 91.40%\n",
      "128\tValidation loss: 0.348867\tBest loss: 0.345893\tAccuracy: 91.80%\n",
      "129\tValidation loss: 0.346472\tBest loss: 0.345893\tAccuracy: 91.40%\n",
      "130\tValidation loss: 0.346780\tBest loss: 0.345893\tAccuracy: 91.90%\n",
      "131\tValidation loss: 0.346296\tBest loss: 0.345893\tAccuracy: 91.90%\n",
      "132\tValidation loss: 0.348403\tBest loss: 0.345893\tAccuracy: 91.90%\n",
      "133\tValidation loss: 0.351153\tBest loss: 0.345893\tAccuracy: 92.00%\n",
      "134\tValidation loss: 0.343137\tBest loss: 0.343137\tAccuracy: 92.30%\n",
      "135\tValidation loss: 0.347096\tBest loss: 0.343137\tAccuracy: 91.90%\n",
      "136\tValidation loss: 0.345275\tBest loss: 0.343137\tAccuracy: 91.60%\n",
      "137\tValidation loss: 0.345519\tBest loss: 0.343137\tAccuracy: 92.10%\n",
      "138\tValidation loss: 0.341239\tBest loss: 0.341239\tAccuracy: 92.30%\n",
      "139\tValidation loss: 0.342190\tBest loss: 0.341239\tAccuracy: 91.70%\n",
      "140\tValidation loss: 0.341484\tBest loss: 0.341239\tAccuracy: 92.30%\n",
      "141\tValidation loss: 0.342300\tBest loss: 0.341239\tAccuracy: 92.00%\n",
      "142\tValidation loss: 0.337411\tBest loss: 0.337411\tAccuracy: 92.20%\n",
      "143\tValidation loss: 0.343454\tBest loss: 0.337411\tAccuracy: 92.30%\n",
      "144\tValidation loss: 0.339544\tBest loss: 0.337411\tAccuracy: 92.70%\n",
      "145\tValidation loss: 0.342075\tBest loss: 0.337411\tAccuracy: 92.40%\n",
      "146\tValidation loss: 0.340747\tBest loss: 0.337411\tAccuracy: 92.30%\n",
      "147\tValidation loss: 0.344476\tBest loss: 0.337411\tAccuracy: 91.80%\n",
      "148\tValidation loss: 0.339664\tBest loss: 0.337411\tAccuracy: 91.80%\n",
      "149\tValidation loss: 0.340257\tBest loss: 0.337411\tAccuracy: 91.80%\n",
      "150\tValidation loss: 0.342285\tBest loss: 0.337411\tAccuracy: 91.70%\n",
      "151\tValidation loss: 0.335632\tBest loss: 0.335632\tAccuracy: 92.70%\n",
      "152\tValidation loss: 0.337127\tBest loss: 0.335632\tAccuracy: 92.30%\n",
      "153\tValidation loss: 0.339027\tBest loss: 0.335632\tAccuracy: 92.40%\n",
      "154\tValidation loss: 0.338724\tBest loss: 0.335632\tAccuracy: 92.60%\n",
      "155\tValidation loss: 0.339618\tBest loss: 0.335632\tAccuracy: 92.60%\n",
      "156\tValidation loss: 0.336101\tBest loss: 0.335632\tAccuracy: 92.60%\n",
      "157\tValidation loss: 0.342602\tBest loss: 0.335632\tAccuracy: 92.00%\n",
      "158\tValidation loss: 0.335209\tBest loss: 0.335209\tAccuracy: 92.80%\n",
      "159\tValidation loss: 0.336542\tBest loss: 0.335209\tAccuracy: 92.50%\n",
      "160\tValidation loss: 0.337753\tBest loss: 0.335209\tAccuracy: 92.20%\n",
      "161\tValidation loss: 0.335304\tBest loss: 0.335209\tAccuracy: 92.50%\n",
      "162\tValidation loss: 0.332899\tBest loss: 0.332899\tAccuracy: 92.50%\n",
      "163\tValidation loss: 0.332534\tBest loss: 0.332534\tAccuracy: 92.70%\n",
      "164\tValidation loss: 0.338019\tBest loss: 0.332534\tAccuracy: 92.60%\n",
      "165\tValidation loss: 0.334313\tBest loss: 0.332534\tAccuracy: 92.50%\n",
      "166\tValidation loss: 0.337738\tBest loss: 0.332534\tAccuracy: 92.20%\n",
      "167\tValidation loss: 0.332230\tBest loss: 0.332230\tAccuracy: 92.70%\n",
      "168\tValidation loss: 0.334476\tBest loss: 0.332230\tAccuracy: 92.70%\n",
      "169\tValidation loss: 0.336781\tBest loss: 0.332230\tAccuracy: 92.50%\n",
      "170\tValidation loss: 0.336956\tBest loss: 0.332230\tAccuracy: 92.50%\n",
      "171\tValidation loss: 0.337043\tBest loss: 0.332230\tAccuracy: 92.40%\n",
      "172\tValidation loss: 0.331989\tBest loss: 0.331989\tAccuracy: 92.50%\n",
      "173\tValidation loss: 0.332494\tBest loss: 0.331989\tAccuracy: 92.80%\n",
      "174\tValidation loss: 0.334716\tBest loss: 0.331989\tAccuracy: 92.80%\n",
      "175\tValidation loss: 0.335874\tBest loss: 0.331989\tAccuracy: 92.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\tValidation loss: 0.332267\tBest loss: 0.331989\tAccuracy: 92.80%\n",
      "177\tValidation loss: 0.330198\tBest loss: 0.330198\tAccuracy: 93.10%\n",
      "178\tValidation loss: 0.336827\tBest loss: 0.330198\tAccuracy: 92.60%\n",
      "179\tValidation loss: 0.334567\tBest loss: 0.330198\tAccuracy: 92.50%\n",
      "180\tValidation loss: 0.333949\tBest loss: 0.330198\tAccuracy: 92.40%\n",
      "181\tValidation loss: 0.335332\tBest loss: 0.330198\tAccuracy: 92.10%\n",
      "182\tValidation loss: 0.332736\tBest loss: 0.330198\tAccuracy: 92.50%\n",
      "183\tValidation loss: 0.331406\tBest loss: 0.330198\tAccuracy: 92.80%\n",
      "184\tValidation loss: 0.335011\tBest loss: 0.330198\tAccuracy: 92.60%\n",
      "185\tValidation loss: 0.328870\tBest loss: 0.328870\tAccuracy: 92.90%\n",
      "186\tValidation loss: 0.328052\tBest loss: 0.328052\tAccuracy: 92.90%\n",
      "187\tValidation loss: 0.328357\tBest loss: 0.328052\tAccuracy: 92.80%\n",
      "188\tValidation loss: 0.329132\tBest loss: 0.328052\tAccuracy: 92.80%\n",
      "189\tValidation loss: 0.329197\tBest loss: 0.328052\tAccuracy: 92.90%\n",
      "190\tValidation loss: 0.332980\tBest loss: 0.328052\tAccuracy: 93.10%\n",
      "191\tValidation loss: 0.330528\tBest loss: 0.328052\tAccuracy: 92.50%\n",
      "192\tValidation loss: 0.330163\tBest loss: 0.328052\tAccuracy: 92.60%\n",
      "193\tValidation loss: 0.330780\tBest loss: 0.328052\tAccuracy: 93.00%\n",
      "194\tValidation loss: 0.334344\tBest loss: 0.328052\tAccuracy: 92.60%\n",
      "195\tValidation loss: 0.330476\tBest loss: 0.328052\tAccuracy: 92.70%\n",
      "196\tValidation loss: 0.327760\tBest loss: 0.327760\tAccuracy: 92.90%\n",
      "197\tValidation loss: 0.330592\tBest loss: 0.327760\tAccuracy: 92.40%\n",
      "198\tValidation loss: 0.332622\tBest loss: 0.327760\tAccuracy: 92.50%\n",
      "199\tValidation loss: 0.332814\tBest loss: 0.327760\tAccuracy: 93.00%\n",
      "200\tValidation loss: 0.328874\tBest loss: 0.327760\tAccuracy: 92.80%\n",
      "201\tValidation loss: 0.327613\tBest loss: 0.327613\tAccuracy: 92.80%\n",
      "202\tValidation loss: 0.324343\tBest loss: 0.324343\tAccuracy: 93.00%\n",
      "203\tValidation loss: 0.327991\tBest loss: 0.324343\tAccuracy: 93.10%\n",
      "204\tValidation loss: 0.328250\tBest loss: 0.324343\tAccuracy: 93.30%\n",
      "205\tValidation loss: 0.332787\tBest loss: 0.324343\tAccuracy: 92.80%\n",
      "206\tValidation loss: 0.325478\tBest loss: 0.324343\tAccuracy: 92.70%\n",
      "207\tValidation loss: 0.332584\tBest loss: 0.324343\tAccuracy: 93.00%\n",
      "208\tValidation loss: 0.333315\tBest loss: 0.324343\tAccuracy: 92.60%\n",
      "209\tValidation loss: 0.328765\tBest loss: 0.324343\tAccuracy: 92.80%\n",
      "210\tValidation loss: 0.333716\tBest loss: 0.324343\tAccuracy: 93.00%\n",
      "211\tValidation loss: 0.330642\tBest loss: 0.324343\tAccuracy: 93.10%\n",
      "212\tValidation loss: 0.329739\tBest loss: 0.324343\tAccuracy: 92.80%\n",
      "213\tValidation loss: 0.330157\tBest loss: 0.324343\tAccuracy: 92.80%\n",
      "214\tValidation loss: 0.328362\tBest loss: 0.324343\tAccuracy: 92.90%\n",
      "215\tValidation loss: 0.332381\tBest loss: 0.324343\tAccuracy: 93.00%\n",
      "216\tValidation loss: 0.328271\tBest loss: 0.324343\tAccuracy: 93.00%\n",
      "217\tValidation loss: 0.329693\tBest loss: 0.324343\tAccuracy: 92.90%\n",
      "218\tValidation loss: 0.329743\tBest loss: 0.324343\tAccuracy: 92.80%\n",
      "219\tValidation loss: 0.329918\tBest loss: 0.324343\tAccuracy: 92.90%\n",
      "220\tValidation loss: 0.328307\tBest loss: 0.324343\tAccuracy: 93.10%\n",
      "221\tValidation loss: 0.329408\tBest loss: 0.324343\tAccuracy: 92.70%\n",
      "222\tValidation loss: 0.329402\tBest loss: 0.324343\tAccuracy: 92.90%\n",
      "223\tValidation loss: 0.327825\tBest loss: 0.324343\tAccuracy: 92.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  35.6s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.026461\tBest loss: 1.026461\tAccuracy: 73.40%\n",
      "1\tValidation loss: 0.798710\tBest loss: 0.798710\tAccuracy: 78.50%\n",
      "2\tValidation loss: 0.679542\tBest loss: 0.679542\tAccuracy: 82.30%\n",
      "3\tValidation loss: 0.588042\tBest loss: 0.588042\tAccuracy: 84.70%\n",
      "4\tValidation loss: 0.558439\tBest loss: 0.558439\tAccuracy: 85.60%\n",
      "5\tValidation loss: 0.513868\tBest loss: 0.513868\tAccuracy: 86.30%\n",
      "6\tValidation loss: 0.479859\tBest loss: 0.479859\tAccuracy: 87.70%\n",
      "7\tValidation loss: 0.466333\tBest loss: 0.466333\tAccuracy: 86.80%\n",
      "8\tValidation loss: 0.436976\tBest loss: 0.436976\tAccuracy: 89.00%\n",
      "9\tValidation loss: 0.431413\tBest loss: 0.431413\tAccuracy: 88.20%\n",
      "10\tValidation loss: 0.433562\tBest loss: 0.431413\tAccuracy: 89.60%\n",
      "11\tValidation loss: 0.408227\tBest loss: 0.408227\tAccuracy: 90.10%\n",
      "12\tValidation loss: 0.390337\tBest loss: 0.390337\tAccuracy: 90.60%\n",
      "13\tValidation loss: 0.390976\tBest loss: 0.390337\tAccuracy: 90.80%\n",
      "14\tValidation loss: 0.383663\tBest loss: 0.383663\tAccuracy: 90.90%\n",
      "15\tValidation loss: 0.376942\tBest loss: 0.376942\tAccuracy: 90.40%\n",
      "16\tValidation loss: 0.377096\tBest loss: 0.376942\tAccuracy: 90.40%\n",
      "17\tValidation loss: 0.363701\tBest loss: 0.363701\tAccuracy: 90.50%\n",
      "18\tValidation loss: 0.358467\tBest loss: 0.358467\tAccuracy: 91.00%\n",
      "19\tValidation loss: 0.361695\tBest loss: 0.358467\tAccuracy: 90.90%\n",
      "20\tValidation loss: 0.347211\tBest loss: 0.347211\tAccuracy: 90.90%\n",
      "21\tValidation loss: 0.350400\tBest loss: 0.347211\tAccuracy: 91.20%\n",
      "22\tValidation loss: 0.344152\tBest loss: 0.344152\tAccuracy: 91.60%\n",
      "23\tValidation loss: 0.335372\tBest loss: 0.335372\tAccuracy: 92.40%\n",
      "24\tValidation loss: 0.338426\tBest loss: 0.335372\tAccuracy: 92.10%\n",
      "25\tValidation loss: 0.336672\tBest loss: 0.335372\tAccuracy: 92.10%\n",
      "26\tValidation loss: 0.329873\tBest loss: 0.329873\tAccuracy: 91.90%\n",
      "27\tValidation loss: 0.323581\tBest loss: 0.323581\tAccuracy: 92.40%\n",
      "28\tValidation loss: 0.324349\tBest loss: 0.323581\tAccuracy: 92.60%\n",
      "29\tValidation loss: 0.323435\tBest loss: 0.323435\tAccuracy: 92.20%\n",
      "30\tValidation loss: 0.317614\tBest loss: 0.317614\tAccuracy: 92.20%\n",
      "31\tValidation loss: 0.313868\tBest loss: 0.313868\tAccuracy: 93.00%\n",
      "32\tValidation loss: 0.313211\tBest loss: 0.313211\tAccuracy: 92.50%\n",
      "33\tValidation loss: 0.311980\tBest loss: 0.311980\tAccuracy: 93.00%\n",
      "34\tValidation loss: 0.311621\tBest loss: 0.311621\tAccuracy: 93.40%\n",
      "35\tValidation loss: 0.304703\tBest loss: 0.304703\tAccuracy: 93.00%\n",
      "36\tValidation loss: 0.310613\tBest loss: 0.304703\tAccuracy: 92.40%\n",
      "37\tValidation loss: 0.302678\tBest loss: 0.302678\tAccuracy: 92.80%\n",
      "38\tValidation loss: 0.304924\tBest loss: 0.302678\tAccuracy: 92.60%\n",
      "39\tValidation loss: 0.314022\tBest loss: 0.302678\tAccuracy: 92.90%\n",
      "40\tValidation loss: 0.305397\tBest loss: 0.302678\tAccuracy: 93.00%\n",
      "41\tValidation loss: 0.305135\tBest loss: 0.302678\tAccuracy: 92.50%\n",
      "42\tValidation loss: 0.301292\tBest loss: 0.301292\tAccuracy: 93.70%\n",
      "43\tValidation loss: 0.298833\tBest loss: 0.298833\tAccuracy: 93.40%\n",
      "44\tValidation loss: 0.308923\tBest loss: 0.298833\tAccuracy: 92.90%\n",
      "45\tValidation loss: 0.297523\tBest loss: 0.297523\tAccuracy: 93.50%\n",
      "46\tValidation loss: 0.302560\tBest loss: 0.297523\tAccuracy: 93.90%\n",
      "47\tValidation loss: 0.294214\tBest loss: 0.294214\tAccuracy: 94.10%\n",
      "48\tValidation loss: 0.304107\tBest loss: 0.294214\tAccuracy: 93.20%\n",
      "49\tValidation loss: 0.302525\tBest loss: 0.294214\tAccuracy: 93.40%\n",
      "50\tValidation loss: 0.307603\tBest loss: 0.294214\tAccuracy: 93.00%\n",
      "51\tValidation loss: 0.299740\tBest loss: 0.294214\tAccuracy: 93.10%\n",
      "52\tValidation loss: 0.295256\tBest loss: 0.294214\tAccuracy: 92.90%\n",
      "53\tValidation loss: 0.303150\tBest loss: 0.294214\tAccuracy: 93.50%\n",
      "54\tValidation loss: 0.295186\tBest loss: 0.294214\tAccuracy: 93.50%\n",
      "55\tValidation loss: 0.298106\tBest loss: 0.294214\tAccuracy: 93.70%\n",
      "56\tValidation loss: 0.301597\tBest loss: 0.294214\tAccuracy: 93.70%\n",
      "57\tValidation loss: 0.295678\tBest loss: 0.294214\tAccuracy: 94.40%\n",
      "58\tValidation loss: 0.291748\tBest loss: 0.291748\tAccuracy: 93.80%\n",
      "59\tValidation loss: 0.298251\tBest loss: 0.291748\tAccuracy: 94.10%\n",
      "60\tValidation loss: 0.297524\tBest loss: 0.291748\tAccuracy: 93.70%\n",
      "61\tValidation loss: 0.298318\tBest loss: 0.291748\tAccuracy: 93.20%\n",
      "62\tValidation loss: 0.291302\tBest loss: 0.291302\tAccuracy: 93.90%\n",
      "63\tValidation loss: 0.295790\tBest loss: 0.291302\tAccuracy: 93.70%\n",
      "64\tValidation loss: 0.296557\tBest loss: 0.291302\tAccuracy: 94.00%\n",
      "65\tValidation loss: 0.297438\tBest loss: 0.291302\tAccuracy: 94.10%\n",
      "66\tValidation loss: 0.294016\tBest loss: 0.291302\tAccuracy: 93.80%\n",
      "67\tValidation loss: 0.296618\tBest loss: 0.291302\tAccuracy: 94.00%\n",
      "68\tValidation loss: 0.299677\tBest loss: 0.291302\tAccuracy: 93.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\tValidation loss: 0.296745\tBest loss: 0.291302\tAccuracy: 94.20%\n",
      "70\tValidation loss: 0.300469\tBest loss: 0.291302\tAccuracy: 93.70%\n",
      "71\tValidation loss: 0.299974\tBest loss: 0.291302\tAccuracy: 94.00%\n",
      "72\tValidation loss: 0.302184\tBest loss: 0.291302\tAccuracy: 94.00%\n",
      "73\tValidation loss: 0.301051\tBest loss: 0.291302\tAccuracy: 93.50%\n",
      "74\tValidation loss: 0.300738\tBest loss: 0.291302\tAccuracy: 93.50%\n",
      "75\tValidation loss: 0.300545\tBest loss: 0.291302\tAccuracy: 94.30%\n",
      "76\tValidation loss: 0.299996\tBest loss: 0.291302\tAccuracy: 93.80%\n",
      "77\tValidation loss: 0.302321\tBest loss: 0.291302\tAccuracy: 93.90%\n",
      "78\tValidation loss: 0.298369\tBest loss: 0.291302\tAccuracy: 94.40%\n",
      "79\tValidation loss: 0.299063\tBest loss: 0.291302\tAccuracy: 94.10%\n",
      "80\tValidation loss: 0.305179\tBest loss: 0.291302\tAccuracy: 94.10%\n",
      "81\tValidation loss: 0.295147\tBest loss: 0.291302\tAccuracy: 94.30%\n",
      "82\tValidation loss: 0.305521\tBest loss: 0.291302\tAccuracy: 94.20%\n",
      "83\tValidation loss: 0.300861\tBest loss: 0.291302\tAccuracy: 93.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  17.5s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.115712\tBest loss: 1.115712\tAccuracy: 71.00%\n",
      "1\tValidation loss: 0.768335\tBest loss: 0.768335\tAccuracy: 80.70%\n",
      "2\tValidation loss: 0.673782\tBest loss: 0.673782\tAccuracy: 83.50%\n",
      "3\tValidation loss: 0.576911\tBest loss: 0.576911\tAccuracy: 85.70%\n",
      "4\tValidation loss: 0.550018\tBest loss: 0.550018\tAccuracy: 86.80%\n",
      "5\tValidation loss: 0.524089\tBest loss: 0.524089\tAccuracy: 86.90%\n",
      "6\tValidation loss: 0.500356\tBest loss: 0.500356\tAccuracy: 87.20%\n",
      "7\tValidation loss: 0.492374\tBest loss: 0.492374\tAccuracy: 86.60%\n",
      "8\tValidation loss: 0.466023\tBest loss: 0.466023\tAccuracy: 87.90%\n",
      "9\tValidation loss: 0.449240\tBest loss: 0.449240\tAccuracy: 88.20%\n",
      "10\tValidation loss: 0.439846\tBest loss: 0.439846\tAccuracy: 88.80%\n",
      "11\tValidation loss: 0.423605\tBest loss: 0.423605\tAccuracy: 90.10%\n",
      "12\tValidation loss: 0.421049\tBest loss: 0.421049\tAccuracy: 89.20%\n",
      "13\tValidation loss: 0.404864\tBest loss: 0.404864\tAccuracy: 89.60%\n",
      "14\tValidation loss: 0.384618\tBest loss: 0.384618\tAccuracy: 90.40%\n",
      "15\tValidation loss: 0.393296\tBest loss: 0.384618\tAccuracy: 90.50%\n",
      "16\tValidation loss: 0.381409\tBest loss: 0.381409\tAccuracy: 90.40%\n",
      "17\tValidation loss: 0.376151\tBest loss: 0.376151\tAccuracy: 91.20%\n",
      "18\tValidation loss: 0.378471\tBest loss: 0.376151\tAccuracy: 91.10%\n",
      "19\tValidation loss: 0.369376\tBest loss: 0.369376\tAccuracy: 91.30%\n",
      "20\tValidation loss: 0.369963\tBest loss: 0.369376\tAccuracy: 90.80%\n",
      "21\tValidation loss: 0.368118\tBest loss: 0.368118\tAccuracy: 91.30%\n",
      "22\tValidation loss: 0.358919\tBest loss: 0.358919\tAccuracy: 91.60%\n",
      "23\tValidation loss: 0.358357\tBest loss: 0.358357\tAccuracy: 91.50%\n",
      "24\tValidation loss: 0.355598\tBest loss: 0.355598\tAccuracy: 92.00%\n",
      "25\tValidation loss: 0.353398\tBest loss: 0.353398\tAccuracy: 92.20%\n",
      "26\tValidation loss: 0.366426\tBest loss: 0.353398\tAccuracy: 91.90%\n",
      "27\tValidation loss: 0.354994\tBest loss: 0.353398\tAccuracy: 92.90%\n",
      "28\tValidation loss: 0.349966\tBest loss: 0.349966\tAccuracy: 92.50%\n",
      "29\tValidation loss: 0.353851\tBest loss: 0.349966\tAccuracy: 92.20%\n",
      "30\tValidation loss: 0.356363\tBest loss: 0.349966\tAccuracy: 92.80%\n",
      "31\tValidation loss: 0.354894\tBest loss: 0.349966\tAccuracy: 92.80%\n",
      "32\tValidation loss: 0.367833\tBest loss: 0.349966\tAccuracy: 92.30%\n",
      "33\tValidation loss: 0.348735\tBest loss: 0.348735\tAccuracy: 93.20%\n",
      "34\tValidation loss: 0.358939\tBest loss: 0.348735\tAccuracy: 92.50%\n",
      "35\tValidation loss: 0.352231\tBest loss: 0.348735\tAccuracy: 92.50%\n",
      "36\tValidation loss: 0.350500\tBest loss: 0.348735\tAccuracy: 92.40%\n",
      "37\tValidation loss: 0.349785\tBest loss: 0.348735\tAccuracy: 92.70%\n",
      "38\tValidation loss: 0.355255\tBest loss: 0.348735\tAccuracy: 92.00%\n",
      "39\tValidation loss: 0.349270\tBest loss: 0.348735\tAccuracy: 92.80%\n",
      "40\tValidation loss: 0.348741\tBest loss: 0.348735\tAccuracy: 92.60%\n",
      "41\tValidation loss: 0.346058\tBest loss: 0.346058\tAccuracy: 93.10%\n",
      "42\tValidation loss: 0.344991\tBest loss: 0.344991\tAccuracy: 93.10%\n",
      "43\tValidation loss: 0.336434\tBest loss: 0.336434\tAccuracy: 93.20%\n",
      "44\tValidation loss: 0.347897\tBest loss: 0.336434\tAccuracy: 93.20%\n",
      "45\tValidation loss: 0.347041\tBest loss: 0.336434\tAccuracy: 93.60%\n",
      "46\tValidation loss: 0.346862\tBest loss: 0.336434\tAccuracy: 93.60%\n",
      "47\tValidation loss: 0.360349\tBest loss: 0.336434\tAccuracy: 93.00%\n",
      "48\tValidation loss: 0.355922\tBest loss: 0.336434\tAccuracy: 93.20%\n",
      "49\tValidation loss: 0.352104\tBest loss: 0.336434\tAccuracy: 93.10%\n",
      "50\tValidation loss: 0.348062\tBest loss: 0.336434\tAccuracy: 92.90%\n",
      "51\tValidation loss: 0.352938\tBest loss: 0.336434\tAccuracy: 93.80%\n",
      "52\tValidation loss: 0.349175\tBest loss: 0.336434\tAccuracy: 93.50%\n",
      "53\tValidation loss: 0.352903\tBest loss: 0.336434\tAccuracy: 93.50%\n",
      "54\tValidation loss: 0.344678\tBest loss: 0.336434\tAccuracy: 93.90%\n",
      "55\tValidation loss: 0.353731\tBest loss: 0.336434\tAccuracy: 93.50%\n",
      "56\tValidation loss: 0.351684\tBest loss: 0.336434\tAccuracy: 93.50%\n",
      "57\tValidation loss: 0.353818\tBest loss: 0.336434\tAccuracy: 93.80%\n",
      "58\tValidation loss: 0.355005\tBest loss: 0.336434\tAccuracy: 93.30%\n",
      "59\tValidation loss: 0.351979\tBest loss: 0.336434\tAccuracy: 93.90%\n",
      "60\tValidation loss: 0.368742\tBest loss: 0.336434\tAccuracy: 93.30%\n",
      "61\tValidation loss: 0.353975\tBest loss: 0.336434\tAccuracy: 93.90%\n",
      "62\tValidation loss: 0.360105\tBest loss: 0.336434\tAccuracy: 93.80%\n",
      "63\tValidation loss: 0.358361\tBest loss: 0.336434\tAccuracy: 94.00%\n",
      "64\tValidation loss: 0.352600\tBest loss: 0.336434\tAccuracy: 93.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  14.3s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.179165\tBest loss: 1.179165\tAccuracy: 67.00%\n",
      "1\tValidation loss: 0.811033\tBest loss: 0.811033\tAccuracy: 80.20%\n",
      "2\tValidation loss: 0.661931\tBest loss: 0.661931\tAccuracy: 84.30%\n",
      "3\tValidation loss: 0.620862\tBest loss: 0.620862\tAccuracy: 83.60%\n",
      "4\tValidation loss: 0.564521\tBest loss: 0.564521\tAccuracy: 87.30%\n",
      "5\tValidation loss: 0.532694\tBest loss: 0.532694\tAccuracy: 85.60%\n",
      "6\tValidation loss: 0.490879\tBest loss: 0.490879\tAccuracy: 87.30%\n",
      "7\tValidation loss: 0.466828\tBest loss: 0.466828\tAccuracy: 88.40%\n",
      "8\tValidation loss: 0.474304\tBest loss: 0.466828\tAccuracy: 87.60%\n",
      "9\tValidation loss: 0.448223\tBest loss: 0.448223\tAccuracy: 88.50%\n",
      "10\tValidation loss: 0.433389\tBest loss: 0.433389\tAccuracy: 89.30%\n",
      "11\tValidation loss: 0.428093\tBest loss: 0.428093\tAccuracy: 89.10%\n",
      "12\tValidation loss: 0.415968\tBest loss: 0.415968\tAccuracy: 89.10%\n",
      "13\tValidation loss: 0.400193\tBest loss: 0.400193\tAccuracy: 90.00%\n",
      "14\tValidation loss: 0.393736\tBest loss: 0.393736\tAccuracy: 90.30%\n",
      "15\tValidation loss: 0.392885\tBest loss: 0.392885\tAccuracy: 90.20%\n",
      "16\tValidation loss: 0.399415\tBest loss: 0.392885\tAccuracy: 90.10%\n",
      "17\tValidation loss: 0.379626\tBest loss: 0.379626\tAccuracy: 90.40%\n",
      "18\tValidation loss: 0.365968\tBest loss: 0.365968\tAccuracy: 91.60%\n",
      "19\tValidation loss: 0.365548\tBest loss: 0.365548\tAccuracy: 91.50%\n",
      "20\tValidation loss: 0.366848\tBest loss: 0.365548\tAccuracy: 91.20%\n",
      "21\tValidation loss: 0.360776\tBest loss: 0.360776\tAccuracy: 91.20%\n",
      "22\tValidation loss: 0.342891\tBest loss: 0.342891\tAccuracy: 91.60%\n",
      "23\tValidation loss: 0.341006\tBest loss: 0.341006\tAccuracy: 92.10%\n",
      "24\tValidation loss: 0.341127\tBest loss: 0.341006\tAccuracy: 92.40%\n",
      "25\tValidation loss: 0.338966\tBest loss: 0.338966\tAccuracy: 92.40%\n",
      "26\tValidation loss: 0.338259\tBest loss: 0.338259\tAccuracy: 92.00%\n",
      "27\tValidation loss: 0.334783\tBest loss: 0.334783\tAccuracy: 92.60%\n",
      "28\tValidation loss: 0.332016\tBest loss: 0.332016\tAccuracy: 92.00%\n",
      "29\tValidation loss: 0.340802\tBest loss: 0.332016\tAccuracy: 92.30%\n",
      "30\tValidation loss: 0.326175\tBest loss: 0.326175\tAccuracy: 92.10%\n",
      "31\tValidation loss: 0.333929\tBest loss: 0.326175\tAccuracy: 92.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\tValidation loss: 0.324282\tBest loss: 0.324282\tAccuracy: 92.30%\n",
      "33\tValidation loss: 0.333083\tBest loss: 0.324282\tAccuracy: 92.20%\n",
      "34\tValidation loss: 0.323955\tBest loss: 0.323955\tAccuracy: 92.80%\n",
      "35\tValidation loss: 0.319428\tBest loss: 0.319428\tAccuracy: 92.50%\n",
      "36\tValidation loss: 0.325155\tBest loss: 0.319428\tAccuracy: 92.30%\n",
      "37\tValidation loss: 0.309449\tBest loss: 0.309449\tAccuracy: 93.00%\n",
      "38\tValidation loss: 0.322537\tBest loss: 0.309449\tAccuracy: 92.60%\n",
      "39\tValidation loss: 0.313711\tBest loss: 0.309449\tAccuracy: 93.00%\n",
      "40\tValidation loss: 0.311747\tBest loss: 0.309449\tAccuracy: 92.60%\n",
      "41\tValidation loss: 0.304622\tBest loss: 0.304622\tAccuracy: 93.10%\n",
      "42\tValidation loss: 0.312355\tBest loss: 0.304622\tAccuracy: 92.60%\n",
      "43\tValidation loss: 0.306062\tBest loss: 0.304622\tAccuracy: 92.80%\n",
      "44\tValidation loss: 0.311636\tBest loss: 0.304622\tAccuracy: 93.20%\n",
      "45\tValidation loss: 0.308384\tBest loss: 0.304622\tAccuracy: 93.10%\n",
      "46\tValidation loss: 0.311139\tBest loss: 0.304622\tAccuracy: 93.30%\n",
      "47\tValidation loss: 0.311031\tBest loss: 0.304622\tAccuracy: 92.70%\n",
      "48\tValidation loss: 0.302501\tBest loss: 0.302501\tAccuracy: 92.90%\n",
      "49\tValidation loss: 0.305792\tBest loss: 0.302501\tAccuracy: 92.90%\n",
      "50\tValidation loss: 0.314678\tBest loss: 0.302501\tAccuracy: 92.50%\n",
      "51\tValidation loss: 0.297136\tBest loss: 0.297136\tAccuracy: 93.20%\n",
      "52\tValidation loss: 0.299897\tBest loss: 0.297136\tAccuracy: 92.80%\n",
      "53\tValidation loss: 0.306071\tBest loss: 0.297136\tAccuracy: 93.10%\n",
      "54\tValidation loss: 0.300114\tBest loss: 0.297136\tAccuracy: 93.50%\n",
      "55\tValidation loss: 0.300592\tBest loss: 0.297136\tAccuracy: 93.40%\n",
      "56\tValidation loss: 0.306278\tBest loss: 0.297136\tAccuracy: 93.10%\n",
      "57\tValidation loss: 0.310432\tBest loss: 0.297136\tAccuracy: 93.00%\n",
      "58\tValidation loss: 0.299995\tBest loss: 0.297136\tAccuracy: 93.40%\n",
      "59\tValidation loss: 0.310385\tBest loss: 0.297136\tAccuracy: 92.80%\n",
      "60\tValidation loss: 0.304329\tBest loss: 0.297136\tAccuracy: 93.10%\n",
      "61\tValidation loss: 0.307765\tBest loss: 0.297136\tAccuracy: 93.20%\n",
      "62\tValidation loss: 0.302950\tBest loss: 0.297136\tAccuracy: 93.50%\n",
      "63\tValidation loss: 0.296367\tBest loss: 0.296367\tAccuracy: 93.70%\n",
      "64\tValidation loss: 0.299504\tBest loss: 0.296367\tAccuracy: 93.40%\n",
      "65\tValidation loss: 0.303073\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "66\tValidation loss: 0.303887\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "67\tValidation loss: 0.299155\tBest loss: 0.296367\tAccuracy: 93.40%\n",
      "68\tValidation loss: 0.298629\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "69\tValidation loss: 0.304228\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "70\tValidation loss: 0.305558\tBest loss: 0.296367\tAccuracy: 93.10%\n",
      "71\tValidation loss: 0.304700\tBest loss: 0.296367\tAccuracy: 93.00%\n",
      "72\tValidation loss: 0.302895\tBest loss: 0.296367\tAccuracy: 93.20%\n",
      "73\tValidation loss: 0.306494\tBest loss: 0.296367\tAccuracy: 92.90%\n",
      "74\tValidation loss: 0.299869\tBest loss: 0.296367\tAccuracy: 93.60%\n",
      "75\tValidation loss: 0.306614\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "76\tValidation loss: 0.302079\tBest loss: 0.296367\tAccuracy: 93.00%\n",
      "77\tValidation loss: 0.302833\tBest loss: 0.296367\tAccuracy: 93.30%\n",
      "78\tValidation loss: 0.303408\tBest loss: 0.296367\tAccuracy: 93.90%\n",
      "79\tValidation loss: 0.301513\tBest loss: 0.296367\tAccuracy: 93.70%\n",
      "80\tValidation loss: 0.308909\tBest loss: 0.296367\tAccuracy: 93.40%\n",
      "81\tValidation loss: 0.302340\tBest loss: 0.296367\tAccuracy: 93.70%\n",
      "82\tValidation loss: 0.307982\tBest loss: 0.296367\tAccuracy: 93.60%\n",
      "83\tValidation loss: 0.301353\tBest loss: 0.296367\tAccuracy: 93.40%\n",
      "84\tValidation loss: 0.303705\tBest loss: 0.296367\tAccuracy: 93.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  18.1s\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.591405\tBest loss: 1.591405\tAccuracy: 64.30%\n",
      "1\tValidation loss: 1.280251\tBest loss: 1.280251\tAccuracy: 73.10%\n",
      "2\tValidation loss: 1.125142\tBest loss: 1.125142\tAccuracy: 76.10%\n",
      "3\tValidation loss: 1.028833\tBest loss: 1.028833\tAccuracy: 78.20%\n",
      "4\tValidation loss: 0.964038\tBest loss: 0.964038\tAccuracy: 80.70%\n",
      "5\tValidation loss: 0.910916\tBest loss: 0.910916\tAccuracy: 82.10%\n",
      "6\tValidation loss: 0.871734\tBest loss: 0.871734\tAccuracy: 82.10%\n",
      "7\tValidation loss: 0.837953\tBest loss: 0.837953\tAccuracy: 82.20%\n",
      "8\tValidation loss: 0.818952\tBest loss: 0.818952\tAccuracy: 84.00%\n",
      "9\tValidation loss: 0.794196\tBest loss: 0.794196\tAccuracy: 82.80%\n",
      "10\tValidation loss: 0.771695\tBest loss: 0.771695\tAccuracy: 84.50%\n",
      "11\tValidation loss: 0.749558\tBest loss: 0.749558\tAccuracy: 84.80%\n",
      "12\tValidation loss: 0.733766\tBest loss: 0.733766\tAccuracy: 84.80%\n",
      "13\tValidation loss: 0.723644\tBest loss: 0.723644\tAccuracy: 84.80%\n",
      "14\tValidation loss: 0.710780\tBest loss: 0.710780\tAccuracy: 85.50%\n",
      "15\tValidation loss: 0.696926\tBest loss: 0.696926\tAccuracy: 84.80%\n",
      "16\tValidation loss: 0.681262\tBest loss: 0.681262\tAccuracy: 86.70%\n",
      "17\tValidation loss: 0.673130\tBest loss: 0.673130\tAccuracy: 86.30%\n",
      "18\tValidation loss: 0.664238\tBest loss: 0.664238\tAccuracy: 86.60%\n",
      "19\tValidation loss: 0.652606\tBest loss: 0.652606\tAccuracy: 86.70%\n",
      "20\tValidation loss: 0.643490\tBest loss: 0.643490\tAccuracy: 86.00%\n",
      "21\tValidation loss: 0.634827\tBest loss: 0.634827\tAccuracy: 86.70%\n",
      "22\tValidation loss: 0.629951\tBest loss: 0.629951\tAccuracy: 86.20%\n",
      "23\tValidation loss: 0.619378\tBest loss: 0.619378\tAccuracy: 86.90%\n",
      "24\tValidation loss: 0.617438\tBest loss: 0.617438\tAccuracy: 87.10%\n",
      "25\tValidation loss: 0.614527\tBest loss: 0.614527\tAccuracy: 86.90%\n",
      "26\tValidation loss: 0.609573\tBest loss: 0.609573\tAccuracy: 87.30%\n",
      "27\tValidation loss: 0.604932\tBest loss: 0.604932\tAccuracy: 87.50%\n",
      "28\tValidation loss: 0.596835\tBest loss: 0.596835\tAccuracy: 87.30%\n",
      "29\tValidation loss: 0.593052\tBest loss: 0.593052\tAccuracy: 87.40%\n",
      "30\tValidation loss: 0.588382\tBest loss: 0.588382\tAccuracy: 87.20%\n",
      "31\tValidation loss: 0.577681\tBest loss: 0.577681\tAccuracy: 87.80%\n",
      "32\tValidation loss: 0.577443\tBest loss: 0.577443\tAccuracy: 87.70%\n",
      "33\tValidation loss: 0.574748\tBest loss: 0.574748\tAccuracy: 87.80%\n",
      "34\tValidation loss: 0.570615\tBest loss: 0.570615\tAccuracy: 87.60%\n",
      "35\tValidation loss: 0.563848\tBest loss: 0.563848\tAccuracy: 87.90%\n",
      "36\tValidation loss: 0.557184\tBest loss: 0.557184\tAccuracy: 88.40%\n",
      "37\tValidation loss: 0.560327\tBest loss: 0.557184\tAccuracy: 87.70%\n",
      "38\tValidation loss: 0.556037\tBest loss: 0.556037\tAccuracy: 88.40%\n",
      "39\tValidation loss: 0.549592\tBest loss: 0.549592\tAccuracy: 88.00%\n",
      "40\tValidation loss: 0.549978\tBest loss: 0.549592\tAccuracy: 88.10%\n",
      "41\tValidation loss: 0.548225\tBest loss: 0.548225\tAccuracy: 88.20%\n",
      "42\tValidation loss: 0.540309\tBest loss: 0.540309\tAccuracy: 87.90%\n",
      "43\tValidation loss: 0.536808\tBest loss: 0.536808\tAccuracy: 88.50%\n",
      "44\tValidation loss: 0.540467\tBest loss: 0.536808\tAccuracy: 87.70%\n",
      "45\tValidation loss: 0.530604\tBest loss: 0.530604\tAccuracy: 88.30%\n",
      "46\tValidation loss: 0.532076\tBest loss: 0.530604\tAccuracy: 88.10%\n",
      "47\tValidation loss: 0.531449\tBest loss: 0.530604\tAccuracy: 88.00%\n",
      "48\tValidation loss: 0.528785\tBest loss: 0.528785\tAccuracy: 88.50%\n",
      "49\tValidation loss: 0.526039\tBest loss: 0.526039\tAccuracy: 88.60%\n",
      "50\tValidation loss: 0.526831\tBest loss: 0.526039\tAccuracy: 88.30%\n",
      "51\tValidation loss: 0.524951\tBest loss: 0.524951\tAccuracy: 88.20%\n",
      "52\tValidation loss: 0.517794\tBest loss: 0.517794\tAccuracy: 88.60%\n",
      "53\tValidation loss: 0.520564\tBest loss: 0.517794\tAccuracy: 88.40%\n",
      "54\tValidation loss: 0.511143\tBest loss: 0.511143\tAccuracy: 88.60%\n",
      "55\tValidation loss: 0.513699\tBest loss: 0.511143\tAccuracy: 88.40%\n",
      "56\tValidation loss: 0.514811\tBest loss: 0.511143\tAccuracy: 88.40%\n",
      "57\tValidation loss: 0.509335\tBest loss: 0.509335\tAccuracy: 88.50%\n",
      "58\tValidation loss: 0.508914\tBest loss: 0.508914\tAccuracy: 88.70%\n",
      "59\tValidation loss: 0.506510\tBest loss: 0.506510\tAccuracy: 88.50%\n",
      "60\tValidation loss: 0.504636\tBest loss: 0.504636\tAccuracy: 88.70%\n",
      "61\tValidation loss: 0.502265\tBest loss: 0.502265\tAccuracy: 88.60%\n",
      "62\tValidation loss: 0.498064\tBest loss: 0.498064\tAccuracy: 89.00%\n",
      "63\tValidation loss: 0.498029\tBest loss: 0.498029\tAccuracy: 88.80%\n",
      "64\tValidation loss: 0.494894\tBest loss: 0.494894\tAccuracy: 88.70%\n",
      "65\tValidation loss: 0.494154\tBest loss: 0.494154\tAccuracy: 88.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\tValidation loss: 0.492184\tBest loss: 0.492184\tAccuracy: 88.80%\n",
      "67\tValidation loss: 0.489499\tBest loss: 0.489499\tAccuracy: 88.50%\n",
      "68\tValidation loss: 0.490397\tBest loss: 0.489499\tAccuracy: 88.40%\n",
      "69\tValidation loss: 0.487742\tBest loss: 0.487742\tAccuracy: 88.90%\n",
      "70\tValidation loss: 0.491280\tBest loss: 0.487742\tAccuracy: 88.70%\n",
      "71\tValidation loss: 0.487513\tBest loss: 0.487513\tAccuracy: 88.50%\n",
      "72\tValidation loss: 0.483095\tBest loss: 0.483095\tAccuracy: 89.00%\n",
      "73\tValidation loss: 0.483899\tBest loss: 0.483095\tAccuracy: 88.90%\n",
      "74\tValidation loss: 0.484281\tBest loss: 0.483095\tAccuracy: 89.30%\n",
      "75\tValidation loss: 0.481468\tBest loss: 0.481468\tAccuracy: 89.10%\n",
      "76\tValidation loss: 0.481129\tBest loss: 0.481129\tAccuracy: 88.80%\n",
      "77\tValidation loss: 0.480888\tBest loss: 0.480888\tAccuracy: 88.40%\n",
      "78\tValidation loss: 0.477488\tBest loss: 0.477488\tAccuracy: 88.70%\n",
      "79\tValidation loss: 0.474267\tBest loss: 0.474267\tAccuracy: 88.80%\n",
      "80\tValidation loss: 0.478528\tBest loss: 0.474267\tAccuracy: 88.60%\n",
      "81\tValidation loss: 0.474892\tBest loss: 0.474267\tAccuracy: 89.30%\n",
      "82\tValidation loss: 0.476018\tBest loss: 0.474267\tAccuracy: 89.00%\n",
      "83\tValidation loss: 0.471605\tBest loss: 0.471605\tAccuracy: 88.80%\n",
      "84\tValidation loss: 0.471720\tBest loss: 0.471605\tAccuracy: 88.90%\n",
      "85\tValidation loss: 0.466405\tBest loss: 0.466405\tAccuracy: 89.50%\n",
      "86\tValidation loss: 0.470324\tBest loss: 0.466405\tAccuracy: 88.80%\n",
      "87\tValidation loss: 0.468706\tBest loss: 0.466405\tAccuracy: 89.50%\n",
      "88\tValidation loss: 0.467239\tBest loss: 0.466405\tAccuracy: 89.50%\n",
      "89\tValidation loss: 0.467429\tBest loss: 0.466405\tAccuracy: 89.20%\n",
      "90\tValidation loss: 0.467991\tBest loss: 0.466405\tAccuracy: 89.00%\n",
      "91\tValidation loss: 0.461702\tBest loss: 0.461702\tAccuracy: 89.30%\n",
      "92\tValidation loss: 0.463104\tBest loss: 0.461702\tAccuracy: 89.60%\n",
      "93\tValidation loss: 0.462654\tBest loss: 0.461702\tAccuracy: 89.30%\n",
      "94\tValidation loss: 0.463267\tBest loss: 0.461702\tAccuracy: 89.20%\n",
      "95\tValidation loss: 0.460077\tBest loss: 0.460077\tAccuracy: 89.40%\n",
      "96\tValidation loss: 0.460025\tBest loss: 0.460025\tAccuracy: 89.20%\n",
      "97\tValidation loss: 0.458494\tBest loss: 0.458494\tAccuracy: 89.50%\n",
      "98\tValidation loss: 0.457042\tBest loss: 0.457042\tAccuracy: 89.50%\n",
      "99\tValidation loss: 0.456231\tBest loss: 0.456231\tAccuracy: 89.70%\n",
      "100\tValidation loss: 0.455113\tBest loss: 0.455113\tAccuracy: 89.80%\n",
      "101\tValidation loss: 0.452491\tBest loss: 0.452491\tAccuracy: 89.60%\n",
      "102\tValidation loss: 0.453224\tBest loss: 0.452491\tAccuracy: 89.70%\n",
      "103\tValidation loss: 0.452126\tBest loss: 0.452126\tAccuracy: 89.70%\n",
      "104\tValidation loss: 0.452496\tBest loss: 0.452126\tAccuracy: 89.40%\n",
      "105\tValidation loss: 0.450048\tBest loss: 0.450048\tAccuracy: 89.20%\n",
      "106\tValidation loss: 0.450576\tBest loss: 0.450048\tAccuracy: 89.70%\n",
      "107\tValidation loss: 0.451912\tBest loss: 0.450048\tAccuracy: 89.30%\n",
      "108\tValidation loss: 0.449699\tBest loss: 0.449699\tAccuracy: 90.10%\n",
      "109\tValidation loss: 0.448987\tBest loss: 0.448987\tAccuracy: 89.70%\n",
      "110\tValidation loss: 0.447568\tBest loss: 0.447568\tAccuracy: 89.70%\n",
      "111\tValidation loss: 0.447735\tBest loss: 0.447568\tAccuracy: 89.80%\n",
      "112\tValidation loss: 0.446033\tBest loss: 0.446033\tAccuracy: 89.20%\n",
      "113\tValidation loss: 0.443815\tBest loss: 0.443815\tAccuracy: 89.80%\n",
      "114\tValidation loss: 0.444872\tBest loss: 0.443815\tAccuracy: 90.00%\n",
      "115\tValidation loss: 0.445614\tBest loss: 0.443815\tAccuracy: 89.50%\n",
      "116\tValidation loss: 0.444227\tBest loss: 0.443815\tAccuracy: 89.60%\n",
      "117\tValidation loss: 0.439639\tBest loss: 0.439639\tAccuracy: 90.10%\n",
      "118\tValidation loss: 0.440895\tBest loss: 0.439639\tAccuracy: 89.70%\n",
      "119\tValidation loss: 0.440188\tBest loss: 0.439639\tAccuracy: 89.60%\n",
      "120\tValidation loss: 0.442399\tBest loss: 0.439639\tAccuracy: 89.50%\n",
      "121\tValidation loss: 0.441415\tBest loss: 0.439639\tAccuracy: 89.30%\n",
      "122\tValidation loss: 0.440731\tBest loss: 0.439639\tAccuracy: 90.00%\n",
      "123\tValidation loss: 0.439692\tBest loss: 0.439639\tAccuracy: 89.50%\n",
      "124\tValidation loss: 0.439626\tBest loss: 0.439626\tAccuracy: 89.80%\n",
      "125\tValidation loss: 0.438109\tBest loss: 0.438109\tAccuracy: 89.70%\n",
      "126\tValidation loss: 0.436851\tBest loss: 0.436851\tAccuracy: 90.00%\n",
      "127\tValidation loss: 0.437671\tBest loss: 0.436851\tAccuracy: 89.80%\n",
      "128\tValidation loss: 0.434187\tBest loss: 0.434187\tAccuracy: 89.90%\n",
      "129\tValidation loss: 0.434980\tBest loss: 0.434187\tAccuracy: 90.20%\n",
      "130\tValidation loss: 0.436923\tBest loss: 0.434187\tAccuracy: 89.60%\n",
      "131\tValidation loss: 0.432325\tBest loss: 0.432325\tAccuracy: 90.20%\n",
      "132\tValidation loss: 0.433227\tBest loss: 0.432325\tAccuracy: 89.90%\n",
      "133\tValidation loss: 0.433727\tBest loss: 0.432325\tAccuracy: 89.60%\n",
      "134\tValidation loss: 0.433681\tBest loss: 0.432325\tAccuracy: 90.00%\n",
      "135\tValidation loss: 0.433640\tBest loss: 0.432325\tAccuracy: 89.90%\n",
      "136\tValidation loss: 0.430613\tBest loss: 0.430613\tAccuracy: 89.70%\n",
      "137\tValidation loss: 0.429896\tBest loss: 0.429896\tAccuracy: 90.40%\n",
      "138\tValidation loss: 0.429113\tBest loss: 0.429113\tAccuracy: 89.90%\n",
      "139\tValidation loss: 0.429204\tBest loss: 0.429113\tAccuracy: 90.20%\n",
      "140\tValidation loss: 0.429842\tBest loss: 0.429113\tAccuracy: 90.00%\n",
      "141\tValidation loss: 0.429034\tBest loss: 0.429034\tAccuracy: 90.00%\n",
      "142\tValidation loss: 0.429086\tBest loss: 0.429034\tAccuracy: 89.90%\n",
      "143\tValidation loss: 0.426346\tBest loss: 0.426346\tAccuracy: 90.20%\n",
      "144\tValidation loss: 0.425943\tBest loss: 0.425943\tAccuracy: 90.40%\n",
      "145\tValidation loss: 0.426145\tBest loss: 0.425943\tAccuracy: 90.50%\n",
      "146\tValidation loss: 0.424677\tBest loss: 0.424677\tAccuracy: 90.60%\n",
      "147\tValidation loss: 0.424161\tBest loss: 0.424161\tAccuracy: 90.40%\n",
      "148\tValidation loss: 0.425592\tBest loss: 0.424161\tAccuracy: 90.50%\n",
      "149\tValidation loss: 0.425482\tBest loss: 0.424161\tAccuracy: 90.20%\n",
      "150\tValidation loss: 0.425287\tBest loss: 0.424161\tAccuracy: 90.50%\n",
      "151\tValidation loss: 0.425453\tBest loss: 0.424161\tAccuracy: 90.20%\n",
      "152\tValidation loss: 0.422668\tBest loss: 0.422668\tAccuracy: 90.60%\n",
      "153\tValidation loss: 0.420957\tBest loss: 0.420957\tAccuracy: 90.60%\n",
      "154\tValidation loss: 0.421735\tBest loss: 0.420957\tAccuracy: 90.40%\n",
      "155\tValidation loss: 0.421825\tBest loss: 0.420957\tAccuracy: 90.20%\n",
      "156\tValidation loss: 0.422334\tBest loss: 0.420957\tAccuracy: 90.30%\n",
      "157\tValidation loss: 0.422697\tBest loss: 0.420957\tAccuracy: 90.10%\n",
      "158\tValidation loss: 0.420091\tBest loss: 0.420091\tAccuracy: 90.70%\n",
      "159\tValidation loss: 0.419138\tBest loss: 0.419138\tAccuracy: 90.20%\n",
      "160\tValidation loss: 0.421382\tBest loss: 0.419138\tAccuracy: 90.40%\n",
      "161\tValidation loss: 0.420338\tBest loss: 0.419138\tAccuracy: 90.10%\n",
      "162\tValidation loss: 0.419740\tBest loss: 0.419138\tAccuracy: 90.10%\n",
      "163\tValidation loss: 0.418683\tBest loss: 0.418683\tAccuracy: 90.10%\n",
      "164\tValidation loss: 0.416802\tBest loss: 0.416802\tAccuracy: 90.40%\n",
      "165\tValidation loss: 0.418110\tBest loss: 0.416802\tAccuracy: 90.60%\n",
      "166\tValidation loss: 0.417145\tBest loss: 0.416802\tAccuracy: 90.30%\n",
      "167\tValidation loss: 0.416474\tBest loss: 0.416474\tAccuracy: 90.40%\n",
      "168\tValidation loss: 0.417232\tBest loss: 0.416474\tAccuracy: 90.40%\n",
      "169\tValidation loss: 0.415207\tBest loss: 0.415207\tAccuracy: 90.80%\n",
      "170\tValidation loss: 0.416954\tBest loss: 0.415207\tAccuracy: 90.40%\n",
      "171\tValidation loss: 0.416242\tBest loss: 0.415207\tAccuracy: 90.40%\n",
      "172\tValidation loss: 0.414062\tBest loss: 0.414062\tAccuracy: 90.50%\n",
      "173\tValidation loss: 0.415784\tBest loss: 0.414062\tAccuracy: 90.30%\n",
      "174\tValidation loss: 0.414368\tBest loss: 0.414062\tAccuracy: 90.50%\n",
      "175\tValidation loss: 0.413419\tBest loss: 0.413419\tAccuracy: 90.60%\n",
      "176\tValidation loss: 0.415157\tBest loss: 0.413419\tAccuracy: 90.20%\n",
      "177\tValidation loss: 0.411456\tBest loss: 0.411456\tAccuracy: 90.70%\n",
      "178\tValidation loss: 0.413389\tBest loss: 0.411456\tAccuracy: 90.30%\n",
      "179\tValidation loss: 0.411830\tBest loss: 0.411456\tAccuracy: 90.80%\n",
      "180\tValidation loss: 0.411096\tBest loss: 0.411096\tAccuracy: 90.80%\n",
      "181\tValidation loss: 0.411718\tBest loss: 0.411096\tAccuracy: 90.40%\n",
      "182\tValidation loss: 0.412422\tBest loss: 0.411096\tAccuracy: 90.30%\n",
      "183\tValidation loss: 0.411558\tBest loss: 0.411096\tAccuracy: 90.70%\n",
      "184\tValidation loss: 0.411397\tBest loss: 0.411096\tAccuracy: 90.70%\n",
      "185\tValidation loss: 0.410052\tBest loss: 0.410052\tAccuracy: 90.70%\n",
      "186\tValidation loss: 0.408640\tBest loss: 0.408640\tAccuracy: 90.70%\n",
      "187\tValidation loss: 0.409873\tBest loss: 0.408640\tAccuracy: 90.80%\n",
      "188\tValidation loss: 0.408975\tBest loss: 0.408640\tAccuracy: 90.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\tValidation loss: 0.409923\tBest loss: 0.408640\tAccuracy: 90.90%\n",
      "190\tValidation loss: 0.408319\tBest loss: 0.408319\tAccuracy: 90.60%\n",
      "191\tValidation loss: 0.407912\tBest loss: 0.407912\tAccuracy: 90.90%\n",
      "192\tValidation loss: 0.407289\tBest loss: 0.407289\tAccuracy: 90.90%\n",
      "193\tValidation loss: 0.406574\tBest loss: 0.406574\tAccuracy: 91.00%\n",
      "194\tValidation loss: 0.408114\tBest loss: 0.406574\tAccuracy: 91.10%\n",
      "195\tValidation loss: 0.406023\tBest loss: 0.406023\tAccuracy: 91.10%\n",
      "196\tValidation loss: 0.405856\tBest loss: 0.405856\tAccuracy: 91.00%\n",
      "197\tValidation loss: 0.404127\tBest loss: 0.404127\tAccuracy: 91.00%\n",
      "198\tValidation loss: 0.405123\tBest loss: 0.404127\tAccuracy: 91.00%\n",
      "199\tValidation loss: 0.406040\tBest loss: 0.404127\tAccuracy: 90.90%\n",
      "200\tValidation loss: 0.406434\tBest loss: 0.404127\tAccuracy: 90.70%\n",
      "201\tValidation loss: 0.405517\tBest loss: 0.404127\tAccuracy: 91.10%\n",
      "202\tValidation loss: 0.404758\tBest loss: 0.404127\tAccuracy: 91.00%\n",
      "203\tValidation loss: 0.406556\tBest loss: 0.404127\tAccuracy: 90.90%\n",
      "204\tValidation loss: 0.405184\tBest loss: 0.404127\tAccuracy: 91.00%\n",
      "205\tValidation loss: 0.404135\tBest loss: 0.404127\tAccuracy: 91.20%\n",
      "206\tValidation loss: 0.402590\tBest loss: 0.402590\tAccuracy: 90.90%\n",
      "207\tValidation loss: 0.404802\tBest loss: 0.402590\tAccuracy: 90.90%\n",
      "208\tValidation loss: 0.404795\tBest loss: 0.402590\tAccuracy: 90.80%\n",
      "209\tValidation loss: 0.401108\tBest loss: 0.401108\tAccuracy: 91.50%\n",
      "210\tValidation loss: 0.400508\tBest loss: 0.400508\tAccuracy: 91.40%\n",
      "211\tValidation loss: 0.402211\tBest loss: 0.400508\tAccuracy: 91.10%\n",
      "212\tValidation loss: 0.400463\tBest loss: 0.400463\tAccuracy: 91.10%\n",
      "213\tValidation loss: 0.400846\tBest loss: 0.400463\tAccuracy: 91.00%\n",
      "214\tValidation loss: 0.400569\tBest loss: 0.400463\tAccuracy: 91.10%\n",
      "215\tValidation loss: 0.400129\tBest loss: 0.400129\tAccuracy: 90.90%\n",
      "216\tValidation loss: 0.399325\tBest loss: 0.399325\tAccuracy: 91.30%\n",
      "217\tValidation loss: 0.400032\tBest loss: 0.399325\tAccuracy: 91.10%\n",
      "218\tValidation loss: 0.400335\tBest loss: 0.399325\tAccuracy: 91.40%\n",
      "219\tValidation loss: 0.399950\tBest loss: 0.399325\tAccuracy: 91.40%\n",
      "220\tValidation loss: 0.399201\tBest loss: 0.399201\tAccuracy: 91.20%\n",
      "221\tValidation loss: 0.400880\tBest loss: 0.399201\tAccuracy: 91.30%\n",
      "222\tValidation loss: 0.400231\tBest loss: 0.399201\tAccuracy: 91.20%\n",
      "223\tValidation loss: 0.399054\tBest loss: 0.399054\tAccuracy: 91.20%\n",
      "224\tValidation loss: 0.397002\tBest loss: 0.397002\tAccuracy: 91.40%\n",
      "225\tValidation loss: 0.398560\tBest loss: 0.397002\tAccuracy: 91.10%\n",
      "226\tValidation loss: 0.397968\tBest loss: 0.397002\tAccuracy: 91.70%\n",
      "227\tValidation loss: 0.397265\tBest loss: 0.397002\tAccuracy: 91.50%\n",
      "228\tValidation loss: 0.396363\tBest loss: 0.396363\tAccuracy: 91.10%\n",
      "229\tValidation loss: 0.397441\tBest loss: 0.396363\tAccuracy: 91.40%\n",
      "230\tValidation loss: 0.396896\tBest loss: 0.396363\tAccuracy: 91.50%\n",
      "231\tValidation loss: 0.397829\tBest loss: 0.396363\tAccuracy: 91.40%\n",
      "232\tValidation loss: 0.395628\tBest loss: 0.395628\tAccuracy: 91.50%\n",
      "233\tValidation loss: 0.396918\tBest loss: 0.395628\tAccuracy: 91.60%\n",
      "234\tValidation loss: 0.394999\tBest loss: 0.394999\tAccuracy: 91.50%\n",
      "235\tValidation loss: 0.395580\tBest loss: 0.394999\tAccuracy: 91.40%\n",
      "236\tValidation loss: 0.396499\tBest loss: 0.394999\tAccuracy: 91.30%\n",
      "237\tValidation loss: 0.394431\tBest loss: 0.394431\tAccuracy: 91.30%\n",
      "238\tValidation loss: 0.395370\tBest loss: 0.394431\tAccuracy: 91.30%\n",
      "239\tValidation loss: 0.393821\tBest loss: 0.393821\tAccuracy: 91.40%\n",
      "240\tValidation loss: 0.396720\tBest loss: 0.393821\tAccuracy: 91.40%\n",
      "241\tValidation loss: 0.395321\tBest loss: 0.393821\tAccuracy: 91.30%\n",
      "242\tValidation loss: 0.394375\tBest loss: 0.393821\tAccuracy: 91.40%\n",
      "243\tValidation loss: 0.393548\tBest loss: 0.393548\tAccuracy: 91.60%\n",
      "244\tValidation loss: 0.393887\tBest loss: 0.393548\tAccuracy: 91.50%\n",
      "245\tValidation loss: 0.394088\tBest loss: 0.393548\tAccuracy: 91.60%\n",
      "246\tValidation loss: 0.392471\tBest loss: 0.392471\tAccuracy: 91.70%\n",
      "247\tValidation loss: 0.392755\tBest loss: 0.392471\tAccuracy: 91.60%\n",
      "248\tValidation loss: 0.392331\tBest loss: 0.392331\tAccuracy: 91.70%\n",
      "249\tValidation loss: 0.391769\tBest loss: 0.391769\tAccuracy: 91.60%\n",
      "250\tValidation loss: 0.394050\tBest loss: 0.391769\tAccuracy: 91.20%\n",
      "251\tValidation loss: 0.393077\tBest loss: 0.391769\tAccuracy: 91.30%\n",
      "252\tValidation loss: 0.391869\tBest loss: 0.391769\tAccuracy: 91.70%\n",
      "253\tValidation loss: 0.392735\tBest loss: 0.391769\tAccuracy: 91.60%\n",
      "254\tValidation loss: 0.392202\tBest loss: 0.391769\tAccuracy: 91.70%\n",
      "255\tValidation loss: 0.392360\tBest loss: 0.391769\tAccuracy: 91.40%\n",
      "256\tValidation loss: 0.391556\tBest loss: 0.391556\tAccuracy: 91.60%\n",
      "257\tValidation loss: 0.392308\tBest loss: 0.391556\tAccuracy: 91.60%\n",
      "258\tValidation loss: 0.391402\tBest loss: 0.391402\tAccuracy: 91.90%\n",
      "259\tValidation loss: 0.389148\tBest loss: 0.389148\tAccuracy: 91.90%\n",
      "260\tValidation loss: 0.389611\tBest loss: 0.389148\tAccuracy: 91.80%\n",
      "261\tValidation loss: 0.389354\tBest loss: 0.389148\tAccuracy: 91.90%\n",
      "262\tValidation loss: 0.391891\tBest loss: 0.389148\tAccuracy: 91.70%\n",
      "263\tValidation loss: 0.391118\tBest loss: 0.389148\tAccuracy: 91.80%\n",
      "264\tValidation loss: 0.390613\tBest loss: 0.389148\tAccuracy: 91.50%\n",
      "265\tValidation loss: 0.390569\tBest loss: 0.389148\tAccuracy: 91.70%\n",
      "266\tValidation loss: 0.391085\tBest loss: 0.389148\tAccuracy: 91.90%\n",
      "267\tValidation loss: 0.390170\tBest loss: 0.389148\tAccuracy: 91.90%\n",
      "268\tValidation loss: 0.391534\tBest loss: 0.389148\tAccuracy: 91.80%\n",
      "269\tValidation loss: 0.389729\tBest loss: 0.389148\tAccuracy: 91.70%\n",
      "270\tValidation loss: 0.389322\tBest loss: 0.389148\tAccuracy: 91.50%\n",
      "271\tValidation loss: 0.388417\tBest loss: 0.388417\tAccuracy: 91.70%\n",
      "272\tValidation loss: 0.387956\tBest loss: 0.387956\tAccuracy: 91.80%\n",
      "273\tValidation loss: 0.388190\tBest loss: 0.387956\tAccuracy: 91.80%\n",
      "274\tValidation loss: 0.388489\tBest loss: 0.387956\tAccuracy: 91.50%\n",
      "275\tValidation loss: 0.387189\tBest loss: 0.387189\tAccuracy: 91.90%\n",
      "276\tValidation loss: 0.387635\tBest loss: 0.387189\tAccuracy: 91.50%\n",
      "277\tValidation loss: 0.387839\tBest loss: 0.387189\tAccuracy: 91.90%\n",
      "278\tValidation loss: 0.387380\tBest loss: 0.387189\tAccuracy: 91.90%\n",
      "279\tValidation loss: 0.386400\tBest loss: 0.386400\tAccuracy: 91.60%\n",
      "280\tValidation loss: 0.388571\tBest loss: 0.386400\tAccuracy: 91.80%\n",
      "281\tValidation loss: 0.388167\tBest loss: 0.386400\tAccuracy: 91.60%\n",
      "282\tValidation loss: 0.387523\tBest loss: 0.386400\tAccuracy: 91.90%\n",
      "283\tValidation loss: 0.386635\tBest loss: 0.386400\tAccuracy: 91.70%\n",
      "284\tValidation loss: 0.387752\tBest loss: 0.386400\tAccuracy: 91.60%\n",
      "285\tValidation loss: 0.386622\tBest loss: 0.386400\tAccuracy: 91.80%\n",
      "286\tValidation loss: 0.387374\tBest loss: 0.386400\tAccuracy: 91.50%\n",
      "287\tValidation loss: 0.387074\tBest loss: 0.386400\tAccuracy: 91.70%\n",
      "288\tValidation loss: 0.385293\tBest loss: 0.385293\tAccuracy: 91.80%\n",
      "289\tValidation loss: 0.385183\tBest loss: 0.385183\tAccuracy: 91.80%\n",
      "290\tValidation loss: 0.385708\tBest loss: 0.385183\tAccuracy: 91.90%\n",
      "291\tValidation loss: 0.384564\tBest loss: 0.384564\tAccuracy: 91.90%\n",
      "292\tValidation loss: 0.385443\tBest loss: 0.384564\tAccuracy: 91.90%\n",
      "293\tValidation loss: 0.385560\tBest loss: 0.384564\tAccuracy: 91.90%\n",
      "294\tValidation loss: 0.386053\tBest loss: 0.384564\tAccuracy: 91.80%\n",
      "295\tValidation loss: 0.384966\tBest loss: 0.384564\tAccuracy: 91.90%\n",
      "296\tValidation loss: 0.384958\tBest loss: 0.384564\tAccuracy: 92.00%\n",
      "297\tValidation loss: 0.385600\tBest loss: 0.384564\tAccuracy: 91.80%\n",
      "298\tValidation loss: 0.386298\tBest loss: 0.384564\tAccuracy: 92.00%\n",
      "299\tValidation loss: 0.383680\tBest loss: 0.383680\tAccuracy: 91.90%\n",
      "300\tValidation loss: 0.384110\tBest loss: 0.383680\tAccuracy: 92.00%\n",
      "301\tValidation loss: 0.384206\tBest loss: 0.383680\tAccuracy: 92.00%\n",
      "302\tValidation loss: 0.383574\tBest loss: 0.383574\tAccuracy: 91.70%\n",
      "303\tValidation loss: 0.382670\tBest loss: 0.382670\tAccuracy: 92.10%\n",
      "304\tValidation loss: 0.385589\tBest loss: 0.382670\tAccuracy: 91.80%\n",
      "305\tValidation loss: 0.383701\tBest loss: 0.382670\tAccuracy: 92.00%\n",
      "306\tValidation loss: 0.382665\tBest loss: 0.382665\tAccuracy: 92.20%\n",
      "307\tValidation loss: 0.382919\tBest loss: 0.382665\tAccuracy: 92.10%\n",
      "308\tValidation loss: 0.382985\tBest loss: 0.382665\tAccuracy: 91.90%\n",
      "309\tValidation loss: 0.383053\tBest loss: 0.382665\tAccuracy: 92.00%\n",
      "310\tValidation loss: 0.381604\tBest loss: 0.381604\tAccuracy: 92.00%\n",
      "311\tValidation loss: 0.382023\tBest loss: 0.381604\tAccuracy: 91.90%\n",
      "312\tValidation loss: 0.382992\tBest loss: 0.381604\tAccuracy: 92.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\tValidation loss: 0.381110\tBest loss: 0.381110\tAccuracy: 92.20%\n",
      "314\tValidation loss: 0.382694\tBest loss: 0.381110\tAccuracy: 91.80%\n",
      "315\tValidation loss: 0.380761\tBest loss: 0.380761\tAccuracy: 92.20%\n",
      "316\tValidation loss: 0.380261\tBest loss: 0.380261\tAccuracy: 92.00%\n",
      "317\tValidation loss: 0.381983\tBest loss: 0.380261\tAccuracy: 92.10%\n",
      "318\tValidation loss: 0.380492\tBest loss: 0.380261\tAccuracy: 92.00%\n",
      "319\tValidation loss: 0.380582\tBest loss: 0.380261\tAccuracy: 92.20%\n",
      "320\tValidation loss: 0.381235\tBest loss: 0.380261\tAccuracy: 92.00%\n",
      "321\tValidation loss: 0.380245\tBest loss: 0.380245\tAccuracy: 92.20%\n",
      "322\tValidation loss: 0.379651\tBest loss: 0.379651\tAccuracy: 92.30%\n",
      "323\tValidation loss: 0.379530\tBest loss: 0.379530\tAccuracy: 92.00%\n",
      "324\tValidation loss: 0.379309\tBest loss: 0.379309\tAccuracy: 91.90%\n",
      "325\tValidation loss: 0.379553\tBest loss: 0.379309\tAccuracy: 92.00%\n",
      "326\tValidation loss: 0.381123\tBest loss: 0.379309\tAccuracy: 92.00%\n",
      "327\tValidation loss: 0.380204\tBest loss: 0.379309\tAccuracy: 91.90%\n",
      "328\tValidation loss: 0.380345\tBest loss: 0.379309\tAccuracy: 92.30%\n",
      "329\tValidation loss: 0.380399\tBest loss: 0.379309\tAccuracy: 92.00%\n",
      "330\tValidation loss: 0.380933\tBest loss: 0.379309\tAccuracy: 91.80%\n",
      "331\tValidation loss: 0.380567\tBest loss: 0.379309\tAccuracy: 92.20%\n",
      "332\tValidation loss: 0.380017\tBest loss: 0.379309\tAccuracy: 92.20%\n",
      "333\tValidation loss: 0.378494\tBest loss: 0.378494\tAccuracy: 92.10%\n",
      "334\tValidation loss: 0.380640\tBest loss: 0.378494\tAccuracy: 92.10%\n",
      "335\tValidation loss: 0.378895\tBest loss: 0.378494\tAccuracy: 92.40%\n",
      "336\tValidation loss: 0.377707\tBest loss: 0.377707\tAccuracy: 92.10%\n",
      "337\tValidation loss: 0.379492\tBest loss: 0.377707\tAccuracy: 92.30%\n",
      "338\tValidation loss: 0.377849\tBest loss: 0.377707\tAccuracy: 92.10%\n",
      "339\tValidation loss: 0.378865\tBest loss: 0.377707\tAccuracy: 92.30%\n",
      "340\tValidation loss: 0.378887\tBest loss: 0.377707\tAccuracy: 92.40%\n",
      "341\tValidation loss: 0.378501\tBest loss: 0.377707\tAccuracy: 92.10%\n",
      "342\tValidation loss: 0.377835\tBest loss: 0.377707\tAccuracy: 92.00%\n",
      "343\tValidation loss: 0.377398\tBest loss: 0.377398\tAccuracy: 92.00%\n",
      "344\tValidation loss: 0.378003\tBest loss: 0.377398\tAccuracy: 92.30%\n",
      "345\tValidation loss: 0.378364\tBest loss: 0.377398\tAccuracy: 92.20%\n",
      "346\tValidation loss: 0.377720\tBest loss: 0.377398\tAccuracy: 92.20%\n",
      "347\tValidation loss: 0.378598\tBest loss: 0.377398\tAccuracy: 92.50%\n",
      "348\tValidation loss: 0.378615\tBest loss: 0.377398\tAccuracy: 92.30%\n",
      "349\tValidation loss: 0.378313\tBest loss: 0.377398\tAccuracy: 92.30%\n",
      "350\tValidation loss: 0.377014\tBest loss: 0.377014\tAccuracy: 92.10%\n",
      "351\tValidation loss: 0.378522\tBest loss: 0.377014\tAccuracy: 92.30%\n",
      "352\tValidation loss: 0.377598\tBest loss: 0.377014\tAccuracy: 92.40%\n",
      "353\tValidation loss: 0.376737\tBest loss: 0.376737\tAccuracy: 92.10%\n",
      "354\tValidation loss: 0.376948\tBest loss: 0.376737\tAccuracy: 92.40%\n",
      "355\tValidation loss: 0.376490\tBest loss: 0.376490\tAccuracy: 92.20%\n",
      "356\tValidation loss: 0.377761\tBest loss: 0.376490\tAccuracy: 92.20%\n",
      "357\tValidation loss: 0.375426\tBest loss: 0.375426\tAccuracy: 92.30%\n",
      "358\tValidation loss: 0.376999\tBest loss: 0.375426\tAccuracy: 92.40%\n",
      "359\tValidation loss: 0.376711\tBest loss: 0.375426\tAccuracy: 92.20%\n",
      "360\tValidation loss: 0.376765\tBest loss: 0.375426\tAccuracy: 92.20%\n",
      "361\tValidation loss: 0.375920\tBest loss: 0.375426\tAccuracy: 92.30%\n",
      "362\tValidation loss: 0.376749\tBest loss: 0.375426\tAccuracy: 92.40%\n",
      "363\tValidation loss: 0.375741\tBest loss: 0.375426\tAccuracy: 92.40%\n",
      "364\tValidation loss: 0.375716\tBest loss: 0.375426\tAccuracy: 92.30%\n",
      "365\tValidation loss: 0.377112\tBest loss: 0.375426\tAccuracy: 92.40%\n",
      "366\tValidation loss: 0.375243\tBest loss: 0.375243\tAccuracy: 92.40%\n",
      "367\tValidation loss: 0.374892\tBest loss: 0.374892\tAccuracy: 92.50%\n",
      "368\tValidation loss: 0.375326\tBest loss: 0.374892\tAccuracy: 92.20%\n",
      "369\tValidation loss: 0.374472\tBest loss: 0.374472\tAccuracy: 92.40%\n",
      "370\tValidation loss: 0.374883\tBest loss: 0.374472\tAccuracy: 92.30%\n",
      "371\tValidation loss: 0.374652\tBest loss: 0.374472\tAccuracy: 92.40%\n",
      "372\tValidation loss: 0.374189\tBest loss: 0.374189\tAccuracy: 92.30%\n",
      "373\tValidation loss: 0.375321\tBest loss: 0.374189\tAccuracy: 92.40%\n",
      "374\tValidation loss: 0.374768\tBest loss: 0.374189\tAccuracy: 92.30%\n",
      "375\tValidation loss: 0.374242\tBest loss: 0.374189\tAccuracy: 92.40%\n",
      "376\tValidation loss: 0.375176\tBest loss: 0.374189\tAccuracy: 92.20%\n",
      "377\tValidation loss: 0.374376\tBest loss: 0.374189\tAccuracy: 92.50%\n",
      "378\tValidation loss: 0.373617\tBest loss: 0.373617\tAccuracy: 92.30%\n",
      "379\tValidation loss: 0.374403\tBest loss: 0.373617\tAccuracy: 92.40%\n",
      "380\tValidation loss: 0.374029\tBest loss: 0.373617\tAccuracy: 92.50%\n",
      "381\tValidation loss: 0.373397\tBest loss: 0.373397\tAccuracy: 92.30%\n",
      "382\tValidation loss: 0.374157\tBest loss: 0.373397\tAccuracy: 92.30%\n",
      "383\tValidation loss: 0.373564\tBest loss: 0.373397\tAccuracy: 92.30%\n",
      "384\tValidation loss: 0.374477\tBest loss: 0.373397\tAccuracy: 92.40%\n",
      "385\tValidation loss: 0.372691\tBest loss: 0.372691\tAccuracy: 92.30%\n",
      "386\tValidation loss: 0.374407\tBest loss: 0.372691\tAccuracy: 92.50%\n",
      "387\tValidation loss: 0.373916\tBest loss: 0.372691\tAccuracy: 92.30%\n",
      "388\tValidation loss: 0.372710\tBest loss: 0.372691\tAccuracy: 92.50%\n",
      "389\tValidation loss: 0.374336\tBest loss: 0.372691\tAccuracy: 92.30%\n",
      "390\tValidation loss: 0.373270\tBest loss: 0.372691\tAccuracy: 92.20%\n",
      "391\tValidation loss: 0.371996\tBest loss: 0.371996\tAccuracy: 92.30%\n",
      "392\tValidation loss: 0.372870\tBest loss: 0.371996\tAccuracy: 92.30%\n",
      "393\tValidation loss: 0.372482\tBest loss: 0.371996\tAccuracy: 92.40%\n",
      "394\tValidation loss: 0.371895\tBest loss: 0.371895\tAccuracy: 92.50%\n",
      "395\tValidation loss: 0.373303\tBest loss: 0.371895\tAccuracy: 92.30%\n",
      "396\tValidation loss: 0.372540\tBest loss: 0.371895\tAccuracy: 92.50%\n",
      "397\tValidation loss: 0.372313\tBest loss: 0.371895\tAccuracy: 92.30%\n",
      "398\tValidation loss: 0.371834\tBest loss: 0.371834\tAccuracy: 92.40%\n",
      "399\tValidation loss: 0.372414\tBest loss: 0.371834\tAccuracy: 92.40%\n",
      "400\tValidation loss: 0.371508\tBest loss: 0.371508\tAccuracy: 92.30%\n",
      "401\tValidation loss: 0.372746\tBest loss: 0.371508\tAccuracy: 92.30%\n",
      "402\tValidation loss: 0.372089\tBest loss: 0.371508\tAccuracy: 92.30%\n",
      "403\tValidation loss: 0.372054\tBest loss: 0.371508\tAccuracy: 92.40%\n",
      "404\tValidation loss: 0.371086\tBest loss: 0.371086\tAccuracy: 92.50%\n",
      "405\tValidation loss: 0.372343\tBest loss: 0.371086\tAccuracy: 92.40%\n",
      "406\tValidation loss: 0.372964\tBest loss: 0.371086\tAccuracy: 92.30%\n",
      "407\tValidation loss: 0.370723\tBest loss: 0.370723\tAccuracy: 92.40%\n",
      "408\tValidation loss: 0.370226\tBest loss: 0.370226\tAccuracy: 92.40%\n",
      "409\tValidation loss: 0.370724\tBest loss: 0.370226\tAccuracy: 92.50%\n",
      "410\tValidation loss: 0.370447\tBest loss: 0.370226\tAccuracy: 92.30%\n",
      "411\tValidation loss: 0.370830\tBest loss: 0.370226\tAccuracy: 92.30%\n",
      "412\tValidation loss: 0.369287\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "413\tValidation loss: 0.371355\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "414\tValidation loss: 0.370665\tBest loss: 0.369287\tAccuracy: 92.30%\n",
      "415\tValidation loss: 0.371093\tBest loss: 0.369287\tAccuracy: 92.30%\n",
      "416\tValidation loss: 0.371831\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "417\tValidation loss: 0.370115\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "418\tValidation loss: 0.370164\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "419\tValidation loss: 0.369911\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "420\tValidation loss: 0.370702\tBest loss: 0.369287\tAccuracy: 92.50%\n",
      "421\tValidation loss: 0.370307\tBest loss: 0.369287\tAccuracy: 92.40%\n",
      "422\tValidation loss: 0.369192\tBest loss: 0.369192\tAccuracy: 92.40%\n",
      "423\tValidation loss: 0.369923\tBest loss: 0.369192\tAccuracy: 92.30%\n",
      "424\tValidation loss: 0.369253\tBest loss: 0.369192\tAccuracy: 92.40%\n",
      "425\tValidation loss: 0.370440\tBest loss: 0.369192\tAccuracy: 92.30%\n",
      "426\tValidation loss: 0.370630\tBest loss: 0.369192\tAccuracy: 92.40%\n",
      "427\tValidation loss: 0.369137\tBest loss: 0.369137\tAccuracy: 92.30%\n",
      "428\tValidation loss: 0.369168\tBest loss: 0.369137\tAccuracy: 92.40%\n",
      "429\tValidation loss: 0.369995\tBest loss: 0.369137\tAccuracy: 92.40%\n",
      "430\tValidation loss: 0.369259\tBest loss: 0.369137\tAccuracy: 92.40%\n",
      "431\tValidation loss: 0.369778\tBest loss: 0.369137\tAccuracy: 92.30%\n",
      "432\tValidation loss: 0.369417\tBest loss: 0.369137\tAccuracy: 92.30%\n",
      "433\tValidation loss: 0.369358\tBest loss: 0.369137\tAccuracy: 92.30%\n",
      "434\tValidation loss: 0.368981\tBest loss: 0.368981\tAccuracy: 92.30%\n",
      "435\tValidation loss: 0.368573\tBest loss: 0.368573\tAccuracy: 92.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\tValidation loss: 0.369917\tBest loss: 0.368573\tAccuracy: 92.40%\n",
      "437\tValidation loss: 0.368972\tBest loss: 0.368573\tAccuracy: 92.30%\n",
      "438\tValidation loss: 0.368402\tBest loss: 0.368402\tAccuracy: 92.40%\n",
      "439\tValidation loss: 0.369360\tBest loss: 0.368402\tAccuracy: 92.50%\n",
      "440\tValidation loss: 0.369084\tBest loss: 0.368402\tAccuracy: 92.50%\n",
      "441\tValidation loss: 0.368703\tBest loss: 0.368402\tAccuracy: 92.50%\n",
      "442\tValidation loss: 0.369484\tBest loss: 0.368402\tAccuracy: 92.40%\n",
      "443\tValidation loss: 0.368117\tBest loss: 0.368117\tAccuracy: 92.40%\n",
      "444\tValidation loss: 0.368343\tBest loss: 0.368117\tAccuracy: 92.50%\n",
      "445\tValidation loss: 0.368665\tBest loss: 0.368117\tAccuracy: 92.30%\n",
      "446\tValidation loss: 0.368874\tBest loss: 0.368117\tAccuracy: 92.50%\n",
      "447\tValidation loss: 0.367683\tBest loss: 0.367683\tAccuracy: 92.40%\n",
      "448\tValidation loss: 0.368524\tBest loss: 0.367683\tAccuracy: 92.40%\n",
      "449\tValidation loss: 0.368162\tBest loss: 0.367683\tAccuracy: 92.50%\n",
      "450\tValidation loss: 0.368303\tBest loss: 0.367683\tAccuracy: 92.40%\n",
      "451\tValidation loss: 0.367504\tBest loss: 0.367504\tAccuracy: 92.50%\n",
      "452\tValidation loss: 0.368586\tBest loss: 0.367504\tAccuracy: 92.30%\n",
      "453\tValidation loss: 0.368530\tBest loss: 0.367504\tAccuracy: 92.40%\n",
      "454\tValidation loss: 0.367806\tBest loss: 0.367504\tAccuracy: 92.40%\n",
      "455\tValidation loss: 0.369024\tBest loss: 0.367504\tAccuracy: 92.40%\n",
      "456\tValidation loss: 0.367391\tBest loss: 0.367391\tAccuracy: 92.40%\n",
      "457\tValidation loss: 0.368155\tBest loss: 0.367391\tAccuracy: 92.40%\n",
      "458\tValidation loss: 0.369246\tBest loss: 0.367391\tAccuracy: 92.50%\n",
      "459\tValidation loss: 0.367713\tBest loss: 0.367391\tAccuracy: 92.40%\n",
      "460\tValidation loss: 0.367226\tBest loss: 0.367226\tAccuracy: 92.30%\n",
      "461\tValidation loss: 0.368211\tBest loss: 0.367226\tAccuracy: 92.30%\n",
      "462\tValidation loss: 0.367545\tBest loss: 0.367226\tAccuracy: 92.40%\n",
      "463\tValidation loss: 0.367541\tBest loss: 0.367226\tAccuracy: 92.60%\n",
      "464\tValidation loss: 0.367716\tBest loss: 0.367226\tAccuracy: 92.30%\n",
      "465\tValidation loss: 0.367894\tBest loss: 0.367226\tAccuracy: 92.30%\n",
      "466\tValidation loss: 0.367089\tBest loss: 0.367089\tAccuracy: 92.40%\n",
      "467\tValidation loss: 0.366916\tBest loss: 0.366916\tAccuracy: 92.30%\n",
      "468\tValidation loss: 0.367926\tBest loss: 0.366916\tAccuracy: 92.40%\n",
      "469\tValidation loss: 0.367188\tBest loss: 0.366916\tAccuracy: 92.50%\n",
      "470\tValidation loss: 0.366706\tBest loss: 0.366706\tAccuracy: 92.50%\n",
      "471\tValidation loss: 0.366735\tBest loss: 0.366706\tAccuracy: 92.40%\n",
      "472\tValidation loss: 0.366448\tBest loss: 0.366448\tAccuracy: 92.50%\n",
      "473\tValidation loss: 0.366566\tBest loss: 0.366448\tAccuracy: 92.40%\n",
      "474\tValidation loss: 0.366976\tBest loss: 0.366448\tAccuracy: 92.50%\n",
      "475\tValidation loss: 0.366014\tBest loss: 0.366014\tAccuracy: 92.40%\n",
      "476\tValidation loss: 0.366722\tBest loss: 0.366014\tAccuracy: 92.40%\n",
      "477\tValidation loss: 0.367331\tBest loss: 0.366014\tAccuracy: 92.50%\n",
      "478\tValidation loss: 0.366164\tBest loss: 0.366014\tAccuracy: 92.30%\n",
      "479\tValidation loss: 0.366426\tBest loss: 0.366014\tAccuracy: 92.40%\n",
      "480\tValidation loss: 0.365593\tBest loss: 0.365593\tAccuracy: 92.40%\n",
      "481\tValidation loss: 0.365788\tBest loss: 0.365593\tAccuracy: 92.40%\n",
      "482\tValidation loss: 0.365713\tBest loss: 0.365593\tAccuracy: 92.40%\n",
      "483\tValidation loss: 0.365907\tBest loss: 0.365593\tAccuracy: 92.50%\n",
      "484\tValidation loss: 0.365987\tBest loss: 0.365593\tAccuracy: 92.60%\n",
      "485\tValidation loss: 0.365794\tBest loss: 0.365593\tAccuracy: 92.40%\n",
      "486\tValidation loss: 0.365048\tBest loss: 0.365048\tAccuracy: 92.40%\n",
      "487\tValidation loss: 0.364720\tBest loss: 0.364720\tAccuracy: 92.40%\n",
      "488\tValidation loss: 0.365359\tBest loss: 0.364720\tAccuracy: 92.40%\n",
      "489\tValidation loss: 0.366645\tBest loss: 0.364720\tAccuracy: 92.50%\n",
      "490\tValidation loss: 0.365819\tBest loss: 0.364720\tAccuracy: 92.40%\n",
      "491\tValidation loss: 0.364509\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "492\tValidation loss: 0.365328\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "493\tValidation loss: 0.365812\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "494\tValidation loss: 0.364666\tBest loss: 0.364509\tAccuracy: 92.50%\n",
      "495\tValidation loss: 0.365143\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "496\tValidation loss: 0.364845\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "497\tValidation loss: 0.364886\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "498\tValidation loss: 0.365823\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "499\tValidation loss: 0.365889\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "500\tValidation loss: 0.365096\tBest loss: 0.364509\tAccuracy: 92.50%\n",
      "501\tValidation loss: 0.365343\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "502\tValidation loss: 0.364994\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "503\tValidation loss: 0.364564\tBest loss: 0.364509\tAccuracy: 92.40%\n",
      "504\tValidation loss: 0.364055\tBest loss: 0.364055\tAccuracy: 92.40%\n",
      "505\tValidation loss: 0.364716\tBest loss: 0.364055\tAccuracy: 92.50%\n",
      "506\tValidation loss: 0.364637\tBest loss: 0.364055\tAccuracy: 92.60%\n",
      "507\tValidation loss: 0.364972\tBest loss: 0.364055\tAccuracy: 92.40%\n",
      "508\tValidation loss: 0.364238\tBest loss: 0.364055\tAccuracy: 92.40%\n",
      "509\tValidation loss: 0.363807\tBest loss: 0.363807\tAccuracy: 92.40%\n",
      "510\tValidation loss: 0.364315\tBest loss: 0.363807\tAccuracy: 92.50%\n",
      "511\tValidation loss: 0.364338\tBest loss: 0.363807\tAccuracy: 92.40%\n",
      "512\tValidation loss: 0.364736\tBest loss: 0.363807\tAccuracy: 92.40%\n",
      "513\tValidation loss: 0.364958\tBest loss: 0.363807\tAccuracy: 92.40%\n",
      "514\tValidation loss: 0.363819\tBest loss: 0.363807\tAccuracy: 92.40%\n",
      "515\tValidation loss: 0.363373\tBest loss: 0.363373\tAccuracy: 92.40%\n",
      "516\tValidation loss: 0.363638\tBest loss: 0.363373\tAccuracy: 92.40%\n",
      "517\tValidation loss: 0.363271\tBest loss: 0.363271\tAccuracy: 92.40%\n",
      "518\tValidation loss: 0.364144\tBest loss: 0.363271\tAccuracy: 92.50%\n",
      "519\tValidation loss: 0.363622\tBest loss: 0.363271\tAccuracy: 92.50%\n",
      "520\tValidation loss: 0.363559\tBest loss: 0.363271\tAccuracy: 92.40%\n",
      "521\tValidation loss: 0.363949\tBest loss: 0.363271\tAccuracy: 92.40%\n",
      "522\tValidation loss: 0.364995\tBest loss: 0.363271\tAccuracy: 92.50%\n",
      "523\tValidation loss: 0.362653\tBest loss: 0.362653\tAccuracy: 92.50%\n",
      "524\tValidation loss: 0.364203\tBest loss: 0.362653\tAccuracy: 92.60%\n",
      "525\tValidation loss: 0.364343\tBest loss: 0.362653\tAccuracy: 92.50%\n",
      "526\tValidation loss: 0.363347\tBest loss: 0.362653\tAccuracy: 92.40%\n",
      "527\tValidation loss: 0.362109\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "528\tValidation loss: 0.363504\tBest loss: 0.362109\tAccuracy: 92.60%\n",
      "529\tValidation loss: 0.362832\tBest loss: 0.362109\tAccuracy: 92.50%\n",
      "530\tValidation loss: 0.363588\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "531\tValidation loss: 0.362856\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "532\tValidation loss: 0.363317\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "533\tValidation loss: 0.363379\tBest loss: 0.362109\tAccuracy: 92.60%\n",
      "534\tValidation loss: 0.363240\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "535\tValidation loss: 0.362865\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "536\tValidation loss: 0.362310\tBest loss: 0.362109\tAccuracy: 92.40%\n",
      "537\tValidation loss: 0.361942\tBest loss: 0.361942\tAccuracy: 92.40%\n",
      "538\tValidation loss: 0.362903\tBest loss: 0.361942\tAccuracy: 92.50%\n",
      "539\tValidation loss: 0.363946\tBest loss: 0.361942\tAccuracy: 92.50%\n",
      "540\tValidation loss: 0.362321\tBest loss: 0.361942\tAccuracy: 92.40%\n",
      "541\tValidation loss: 0.362905\tBest loss: 0.361942\tAccuracy: 92.40%\n",
      "542\tValidation loss: 0.362824\tBest loss: 0.361942\tAccuracy: 92.50%\n",
      "543\tValidation loss: 0.363066\tBest loss: 0.361942\tAccuracy: 92.50%\n",
      "544\tValidation loss: 0.363089\tBest loss: 0.361942\tAccuracy: 92.50%\n",
      "545\tValidation loss: 0.362771\tBest loss: 0.361942\tAccuracy: 92.60%\n",
      "546\tValidation loss: 0.362236\tBest loss: 0.361942\tAccuracy: 92.30%\n",
      "547\tValidation loss: 0.361421\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "548\tValidation loss: 0.361667\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "549\tValidation loss: 0.362248\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "550\tValidation loss: 0.362684\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "551\tValidation loss: 0.361811\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "552\tValidation loss: 0.362739\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "553\tValidation loss: 0.362243\tBest loss: 0.361421\tAccuracy: 92.60%\n",
      "554\tValidation loss: 0.362553\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "555\tValidation loss: 0.362920\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "556\tValidation loss: 0.361818\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "557\tValidation loss: 0.361915\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "558\tValidation loss: 0.362708\tBest loss: 0.361421\tAccuracy: 92.40%\n",
      "559\tValidation loss: 0.362425\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "560\tValidation loss: 0.361589\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "561\tValidation loss: 0.361695\tBest loss: 0.361421\tAccuracy: 92.50%\n",
      "562\tValidation loss: 0.361029\tBest loss: 0.361029\tAccuracy: 92.50%\n",
      "563\tValidation loss: 0.361537\tBest loss: 0.361029\tAccuracy: 92.60%\n",
      "564\tValidation loss: 0.361883\tBest loss: 0.361029\tAccuracy: 92.40%\n",
      "565\tValidation loss: 0.361788\tBest loss: 0.361029\tAccuracy: 92.50%\n",
      "566\tValidation loss: 0.361257\tBest loss: 0.361029\tAccuracy: 92.50%\n",
      "567\tValidation loss: 0.362126\tBest loss: 0.361029\tAccuracy: 92.70%\n",
      "568\tValidation loss: 0.360990\tBest loss: 0.360990\tAccuracy: 92.50%\n",
      "569\tValidation loss: 0.361292\tBest loss: 0.360990\tAccuracy: 92.50%\n",
      "570\tValidation loss: 0.360788\tBest loss: 0.360788\tAccuracy: 92.60%\n",
      "571\tValidation loss: 0.361337\tBest loss: 0.360788\tAccuracy: 92.50%\n",
      "572\tValidation loss: 0.360125\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "573\tValidation loss: 0.360752\tBest loss: 0.360125\tAccuracy: 92.40%\n",
      "574\tValidation loss: 0.361433\tBest loss: 0.360125\tAccuracy: 92.60%\n",
      "575\tValidation loss: 0.362090\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "576\tValidation loss: 0.360838\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "577\tValidation loss: 0.361649\tBest loss: 0.360125\tAccuracy: 92.40%\n",
      "578\tValidation loss: 0.360902\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "579\tValidation loss: 0.360763\tBest loss: 0.360125\tAccuracy: 92.40%\n",
      "580\tValidation loss: 0.361072\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "581\tValidation loss: 0.361485\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "582\tValidation loss: 0.361500\tBest loss: 0.360125\tAccuracy: 92.70%\n",
      "583\tValidation loss: 0.360343\tBest loss: 0.360125\tAccuracy: 92.80%\n",
      "584\tValidation loss: 0.360660\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "585\tValidation loss: 0.361374\tBest loss: 0.360125\tAccuracy: 92.60%\n",
      "586\tValidation loss: 0.361106\tBest loss: 0.360125\tAccuracy: 92.80%\n",
      "587\tValidation loss: 0.360429\tBest loss: 0.360125\tAccuracy: 92.70%\n",
      "588\tValidation loss: 0.360672\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "589\tValidation loss: 0.361247\tBest loss: 0.360125\tAccuracy: 92.70%\n",
      "590\tValidation loss: 0.360410\tBest loss: 0.360125\tAccuracy: 92.50%\n",
      "591\tValidation loss: 0.360669\tBest loss: 0.360125\tAccuracy: 92.70%\n",
      "592\tValidation loss: 0.360593\tBest loss: 0.360125\tAccuracy: 92.70%\n",
      "593\tValidation loss: 0.360060\tBest loss: 0.360060\tAccuracy: 92.60%\n",
      "594\tValidation loss: 0.359294\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "595\tValidation loss: 0.360644\tBest loss: 0.359294\tAccuracy: 92.90%\n",
      "596\tValidation loss: 0.360476\tBest loss: 0.359294\tAccuracy: 92.70%\n",
      "597\tValidation loss: 0.360338\tBest loss: 0.359294\tAccuracy: 92.40%\n",
      "598\tValidation loss: 0.360402\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "599\tValidation loss: 0.360107\tBest loss: 0.359294\tAccuracy: 92.70%\n",
      "600\tValidation loss: 0.361287\tBest loss: 0.359294\tAccuracy: 92.50%\n",
      "601\tValidation loss: 0.359491\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "602\tValidation loss: 0.360883\tBest loss: 0.359294\tAccuracy: 93.10%\n",
      "603\tValidation loss: 0.359724\tBest loss: 0.359294\tAccuracy: 92.70%\n",
      "604\tValidation loss: 0.360385\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "605\tValidation loss: 0.360241\tBest loss: 0.359294\tAccuracy: 92.80%\n",
      "606\tValidation loss: 0.360080\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "607\tValidation loss: 0.359731\tBest loss: 0.359294\tAccuracy: 92.80%\n",
      "608\tValidation loss: 0.359310\tBest loss: 0.359294\tAccuracy: 92.70%\n",
      "609\tValidation loss: 0.359325\tBest loss: 0.359294\tAccuracy: 92.60%\n",
      "610\tValidation loss: 0.360377\tBest loss: 0.359294\tAccuracy: 92.70%\n",
      "611\tValidation loss: 0.358711\tBest loss: 0.358711\tAccuracy: 92.70%\n",
      "612\tValidation loss: 0.359679\tBest loss: 0.358711\tAccuracy: 92.90%\n",
      "613\tValidation loss: 0.359881\tBest loss: 0.358711\tAccuracy: 92.80%\n",
      "614\tValidation loss: 0.359452\tBest loss: 0.358711\tAccuracy: 92.50%\n",
      "615\tValidation loss: 0.359589\tBest loss: 0.358711\tAccuracy: 92.80%\n",
      "616\tValidation loss: 0.359482\tBest loss: 0.358711\tAccuracy: 92.70%\n",
      "617\tValidation loss: 0.358981\tBest loss: 0.358711\tAccuracy: 92.70%\n",
      "618\tValidation loss: 0.359582\tBest loss: 0.358711\tAccuracy: 92.80%\n",
      "619\tValidation loss: 0.359295\tBest loss: 0.358711\tAccuracy: 92.80%\n",
      "620\tValidation loss: 0.358243\tBest loss: 0.358243\tAccuracy: 92.60%\n",
      "621\tValidation loss: 0.359363\tBest loss: 0.358243\tAccuracy: 92.80%\n",
      "622\tValidation loss: 0.359224\tBest loss: 0.358243\tAccuracy: 92.60%\n",
      "623\tValidation loss: 0.358488\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "624\tValidation loss: 0.358701\tBest loss: 0.358243\tAccuracy: 92.60%\n",
      "625\tValidation loss: 0.359491\tBest loss: 0.358243\tAccuracy: 92.80%\n",
      "626\tValidation loss: 0.359699\tBest loss: 0.358243\tAccuracy: 92.80%\n",
      "627\tValidation loss: 0.359202\tBest loss: 0.358243\tAccuracy: 92.90%\n",
      "628\tValidation loss: 0.359978\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "629\tValidation loss: 0.358699\tBest loss: 0.358243\tAccuracy: 92.80%\n",
      "630\tValidation loss: 0.359136\tBest loss: 0.358243\tAccuracy: 92.90%\n",
      "631\tValidation loss: 0.359117\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "632\tValidation loss: 0.358859\tBest loss: 0.358243\tAccuracy: 92.90%\n",
      "633\tValidation loss: 0.358986\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "634\tValidation loss: 0.359217\tBest loss: 0.358243\tAccuracy: 92.80%\n",
      "635\tValidation loss: 0.358833\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "636\tValidation loss: 0.358272\tBest loss: 0.358243\tAccuracy: 92.90%\n",
      "637\tValidation loss: 0.358340\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "638\tValidation loss: 0.358545\tBest loss: 0.358243\tAccuracy: 92.70%\n",
      "639\tValidation loss: 0.358985\tBest loss: 0.358243\tAccuracy: 92.90%\n",
      "640\tValidation loss: 0.358138\tBest loss: 0.358138\tAccuracy: 92.90%\n",
      "641\tValidation loss: 0.357562\tBest loss: 0.357562\tAccuracy: 92.90%\n",
      "642\tValidation loss: 0.358206\tBest loss: 0.357562\tAccuracy: 93.00%\n",
      "643\tValidation loss: 0.358335\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "644\tValidation loss: 0.359428\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "645\tValidation loss: 0.358557\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "646\tValidation loss: 0.358549\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "647\tValidation loss: 0.358686\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "648\tValidation loss: 0.357932\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "649\tValidation loss: 0.358895\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "650\tValidation loss: 0.358564\tBest loss: 0.357562\tAccuracy: 93.00%\n",
      "651\tValidation loss: 0.358709\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "652\tValidation loss: 0.358241\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "653\tValidation loss: 0.358304\tBest loss: 0.357562\tAccuracy: 93.00%\n",
      "654\tValidation loss: 0.358264\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "655\tValidation loss: 0.358760\tBest loss: 0.357562\tAccuracy: 92.70%\n",
      "656\tValidation loss: 0.359459\tBest loss: 0.357562\tAccuracy: 92.90%\n",
      "657\tValidation loss: 0.358682\tBest loss: 0.357562\tAccuracy: 92.90%\n",
      "658\tValidation loss: 0.358698\tBest loss: 0.357562\tAccuracy: 93.10%\n",
      "659\tValidation loss: 0.358245\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "660\tValidation loss: 0.358184\tBest loss: 0.357562\tAccuracy: 92.80%\n",
      "661\tValidation loss: 0.357853\tBest loss: 0.357562\tAccuracy: 93.00%\n",
      "662\tValidation loss: 0.357031\tBest loss: 0.357031\tAccuracy: 92.90%\n",
      "663\tValidation loss: 0.357741\tBest loss: 0.357031\tAccuracy: 92.70%\n",
      "664\tValidation loss: 0.358798\tBest loss: 0.357031\tAccuracy: 93.00%\n",
      "665\tValidation loss: 0.358235\tBest loss: 0.357031\tAccuracy: 92.70%\n",
      "666\tValidation loss: 0.358352\tBest loss: 0.357031\tAccuracy: 92.80%\n",
      "667\tValidation loss: 0.357552\tBest loss: 0.357031\tAccuracy: 93.10%\n",
      "668\tValidation loss: 0.358079\tBest loss: 0.357031\tAccuracy: 92.80%\n",
      "669\tValidation loss: 0.357983\tBest loss: 0.357031\tAccuracy: 92.80%\n",
      "670\tValidation loss: 0.358597\tBest loss: 0.357031\tAccuracy: 92.90%\n",
      "671\tValidation loss: 0.357386\tBest loss: 0.357031\tAccuracy: 92.70%\n",
      "672\tValidation loss: 0.357437\tBest loss: 0.357031\tAccuracy: 92.90%\n",
      "673\tValidation loss: 0.358498\tBest loss: 0.357031\tAccuracy: 92.90%\n",
      "674\tValidation loss: 0.356641\tBest loss: 0.356641\tAccuracy: 92.80%\n",
      "675\tValidation loss: 0.357153\tBest loss: 0.356641\tAccuracy: 93.00%\n",
      "676\tValidation loss: 0.356912\tBest loss: 0.356641\tAccuracy: 92.90%\n",
      "677\tValidation loss: 0.357288\tBest loss: 0.356641\tAccuracy: 92.90%\n",
      "678\tValidation loss: 0.357590\tBest loss: 0.356641\tAccuracy: 92.80%\n",
      "679\tValidation loss: 0.358010\tBest loss: 0.356641\tAccuracy: 92.80%\n",
      "680\tValidation loss: 0.356412\tBest loss: 0.356412\tAccuracy: 92.90%\n",
      "681\tValidation loss: 0.356941\tBest loss: 0.356412\tAccuracy: 92.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\tValidation loss: 0.357387\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "683\tValidation loss: 0.357695\tBest loss: 0.356412\tAccuracy: 92.70%\n",
      "684\tValidation loss: 0.357691\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "685\tValidation loss: 0.357850\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "686\tValidation loss: 0.356646\tBest loss: 0.356412\tAccuracy: 92.70%\n",
      "687\tValidation loss: 0.356858\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "688\tValidation loss: 0.356745\tBest loss: 0.356412\tAccuracy: 92.70%\n",
      "689\tValidation loss: 0.357211\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "690\tValidation loss: 0.356764\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "691\tValidation loss: 0.356788\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "692\tValidation loss: 0.356712\tBest loss: 0.356412\tAccuracy: 92.80%\n",
      "693\tValidation loss: 0.357313\tBest loss: 0.356412\tAccuracy: 92.90%\n",
      "694\tValidation loss: 0.357568\tBest loss: 0.356412\tAccuracy: 92.90%\n",
      "695\tValidation loss: 0.356854\tBest loss: 0.356412\tAccuracy: 93.00%\n",
      "696\tValidation loss: 0.357380\tBest loss: 0.356412\tAccuracy: 93.20%\n",
      "697\tValidation loss: 0.357156\tBest loss: 0.356412\tAccuracy: 93.00%\n",
      "698\tValidation loss: 0.357183\tBest loss: 0.356412\tAccuracy: 92.70%\n",
      "699\tValidation loss: 0.357332\tBest loss: 0.356412\tAccuracy: 93.00%\n",
      "700\tValidation loss: 0.358351\tBest loss: 0.356412\tAccuracy: 92.90%\n",
      "701\tValidation loss: 0.356369\tBest loss: 0.356369\tAccuracy: 92.70%\n",
      "702\tValidation loss: 0.357456\tBest loss: 0.356369\tAccuracy: 92.70%\n",
      "703\tValidation loss: 0.356525\tBest loss: 0.356369\tAccuracy: 92.90%\n",
      "704\tValidation loss: 0.357441\tBest loss: 0.356369\tAccuracy: 92.70%\n",
      "705\tValidation loss: 0.356841\tBest loss: 0.356369\tAccuracy: 92.90%\n",
      "706\tValidation loss: 0.355821\tBest loss: 0.355821\tAccuracy: 93.10%\n",
      "707\tValidation loss: 0.356543\tBest loss: 0.355821\tAccuracy: 92.70%\n",
      "708\tValidation loss: 0.356134\tBest loss: 0.355821\tAccuracy: 92.70%\n",
      "709\tValidation loss: 0.355940\tBest loss: 0.355821\tAccuracy: 93.00%\n",
      "710\tValidation loss: 0.356766\tBest loss: 0.355821\tAccuracy: 92.90%\n",
      "711\tValidation loss: 0.356186\tBest loss: 0.355821\tAccuracy: 92.70%\n",
      "712\tValidation loss: 0.356714\tBest loss: 0.355821\tAccuracy: 92.70%\n",
      "713\tValidation loss: 0.357087\tBest loss: 0.355821\tAccuracy: 92.70%\n",
      "714\tValidation loss: 0.356647\tBest loss: 0.355821\tAccuracy: 93.00%\n",
      "715\tValidation loss: 0.356699\tBest loss: 0.355821\tAccuracy: 92.90%\n",
      "716\tValidation loss: 0.356798\tBest loss: 0.355821\tAccuracy: 92.90%\n",
      "717\tValidation loss: 0.355644\tBest loss: 0.355644\tAccuracy: 93.00%\n",
      "718\tValidation loss: 0.356291\tBest loss: 0.355644\tAccuracy: 92.90%\n",
      "719\tValidation loss: 0.356350\tBest loss: 0.355644\tAccuracy: 93.00%\n",
      "720\tValidation loss: 0.356991\tBest loss: 0.355644\tAccuracy: 93.00%\n",
      "721\tValidation loss: 0.357450\tBest loss: 0.355644\tAccuracy: 93.10%\n",
      "722\tValidation loss: 0.356380\tBest loss: 0.355644\tAccuracy: 93.00%\n",
      "723\tValidation loss: 0.356326\tBest loss: 0.355644\tAccuracy: 93.10%\n",
      "724\tValidation loss: 0.356774\tBest loss: 0.355644\tAccuracy: 93.10%\n",
      "725\tValidation loss: 0.355582\tBest loss: 0.355582\tAccuracy: 93.20%\n",
      "726\tValidation loss: 0.356103\tBest loss: 0.355582\tAccuracy: 92.90%\n",
      "727\tValidation loss: 0.356945\tBest loss: 0.355582\tAccuracy: 93.00%\n",
      "728\tValidation loss: 0.356747\tBest loss: 0.355582\tAccuracy: 93.00%\n",
      "729\tValidation loss: 0.356882\tBest loss: 0.355582\tAccuracy: 93.00%\n",
      "730\tValidation loss: 0.355994\tBest loss: 0.355582\tAccuracy: 93.10%\n",
      "731\tValidation loss: 0.356806\tBest loss: 0.355582\tAccuracy: 93.00%\n",
      "732\tValidation loss: 0.356811\tBest loss: 0.355582\tAccuracy: 93.30%\n",
      "733\tValidation loss: 0.355779\tBest loss: 0.355582\tAccuracy: 93.30%\n",
      "734\tValidation loss: 0.355096\tBest loss: 0.355096\tAccuracy: 93.20%\n",
      "735\tValidation loss: 0.356023\tBest loss: 0.355096\tAccuracy: 93.20%\n",
      "736\tValidation loss: 0.355677\tBest loss: 0.355096\tAccuracy: 92.80%\n",
      "737\tValidation loss: 0.355108\tBest loss: 0.355096\tAccuracy: 93.00%\n",
      "738\tValidation loss: 0.355371\tBest loss: 0.355096\tAccuracy: 93.20%\n",
      "739\tValidation loss: 0.356386\tBest loss: 0.355096\tAccuracy: 93.20%\n",
      "740\tValidation loss: 0.356082\tBest loss: 0.355096\tAccuracy: 93.10%\n",
      "741\tValidation loss: 0.355677\tBest loss: 0.355096\tAccuracy: 93.00%\n",
      "742\tValidation loss: 0.355735\tBest loss: 0.355096\tAccuracy: 93.30%\n",
      "743\tValidation loss: 0.355225\tBest loss: 0.355096\tAccuracy: 93.10%\n",
      "744\tValidation loss: 0.356205\tBest loss: 0.355096\tAccuracy: 92.90%\n",
      "745\tValidation loss: 0.354929\tBest loss: 0.354929\tAccuracy: 93.20%\n",
      "746\tValidation loss: 0.355322\tBest loss: 0.354929\tAccuracy: 92.80%\n",
      "747\tValidation loss: 0.354588\tBest loss: 0.354588\tAccuracy: 93.10%\n",
      "748\tValidation loss: 0.354533\tBest loss: 0.354533\tAccuracy: 92.90%\n",
      "749\tValidation loss: 0.355258\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "750\tValidation loss: 0.354869\tBest loss: 0.354533\tAccuracy: 92.80%\n",
      "751\tValidation loss: 0.354799\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "752\tValidation loss: 0.354979\tBest loss: 0.354533\tAccuracy: 92.80%\n",
      "753\tValidation loss: 0.355204\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "754\tValidation loss: 0.355868\tBest loss: 0.354533\tAccuracy: 93.00%\n",
      "755\tValidation loss: 0.355433\tBest loss: 0.354533\tAccuracy: 93.20%\n",
      "756\tValidation loss: 0.356068\tBest loss: 0.354533\tAccuracy: 93.00%\n",
      "757\tValidation loss: 0.356036\tBest loss: 0.354533\tAccuracy: 93.40%\n",
      "758\tValidation loss: 0.355992\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "759\tValidation loss: 0.354928\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "760\tValidation loss: 0.355770\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "761\tValidation loss: 0.355592\tBest loss: 0.354533\tAccuracy: 93.20%\n",
      "762\tValidation loss: 0.355335\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "763\tValidation loss: 0.355934\tBest loss: 0.354533\tAccuracy: 93.20%\n",
      "764\tValidation loss: 0.354568\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "765\tValidation loss: 0.355602\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "766\tValidation loss: 0.355202\tBest loss: 0.354533\tAccuracy: 93.20%\n",
      "767\tValidation loss: 0.355382\tBest loss: 0.354533\tAccuracy: 93.10%\n",
      "768\tValidation loss: 0.355477\tBest loss: 0.354533\tAccuracy: 93.00%\n",
      "769\tValidation loss: 0.355713\tBest loss: 0.354533\tAccuracy: 93.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total= 1.4min\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.627415\tBest loss: 1.627415\tAccuracy: 64.80%\n",
      "1\tValidation loss: 1.283565\tBest loss: 1.283565\tAccuracy: 73.50%\n",
      "2\tValidation loss: 1.147013\tBest loss: 1.147013\tAccuracy: 77.80%\n",
      "3\tValidation loss: 1.031745\tBest loss: 1.031745\tAccuracy: 79.30%\n",
      "4\tValidation loss: 0.972450\tBest loss: 0.972450\tAccuracy: 80.20%\n",
      "5\tValidation loss: 0.923802\tBest loss: 0.923802\tAccuracy: 80.80%\n",
      "6\tValidation loss: 0.893202\tBest loss: 0.893202\tAccuracy: 81.40%\n",
      "7\tValidation loss: 0.852784\tBest loss: 0.852784\tAccuracy: 82.00%\n",
      "8\tValidation loss: 0.822006\tBest loss: 0.822006\tAccuracy: 82.80%\n",
      "9\tValidation loss: 0.807255\tBest loss: 0.807255\tAccuracy: 82.60%\n",
      "10\tValidation loss: 0.782091\tBest loss: 0.782091\tAccuracy: 84.10%\n",
      "11\tValidation loss: 0.764233\tBest loss: 0.764233\tAccuracy: 84.30%\n",
      "12\tValidation loss: 0.744350\tBest loss: 0.744350\tAccuracy: 84.10%\n",
      "13\tValidation loss: 0.731863\tBest loss: 0.731863\tAccuracy: 84.80%\n",
      "14\tValidation loss: 0.711892\tBest loss: 0.711892\tAccuracy: 85.10%\n",
      "15\tValidation loss: 0.701785\tBest loss: 0.701785\tAccuracy: 84.90%\n",
      "16\tValidation loss: 0.691467\tBest loss: 0.691467\tAccuracy: 84.20%\n",
      "17\tValidation loss: 0.684087\tBest loss: 0.684087\tAccuracy: 85.00%\n",
      "18\tValidation loss: 0.676305\tBest loss: 0.676305\tAccuracy: 85.20%\n",
      "19\tValidation loss: 0.669790\tBest loss: 0.669790\tAccuracy: 85.10%\n",
      "20\tValidation loss: 0.654181\tBest loss: 0.654181\tAccuracy: 85.90%\n",
      "21\tValidation loss: 0.650374\tBest loss: 0.650374\tAccuracy: 86.20%\n",
      "22\tValidation loss: 0.639703\tBest loss: 0.639703\tAccuracy: 87.00%\n",
      "23\tValidation loss: 0.638908\tBest loss: 0.638908\tAccuracy: 86.80%\n",
      "24\tValidation loss: 0.634167\tBest loss: 0.634167\tAccuracy: 86.60%\n",
      "25\tValidation loss: 0.623614\tBest loss: 0.623614\tAccuracy: 86.60%\n",
      "26\tValidation loss: 0.622605\tBest loss: 0.622605\tAccuracy: 87.00%\n",
      "27\tValidation loss: 0.613529\tBest loss: 0.613529\tAccuracy: 86.70%\n",
      "28\tValidation loss: 0.613073\tBest loss: 0.613073\tAccuracy: 87.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\tValidation loss: 0.608421\tBest loss: 0.608421\tAccuracy: 86.50%\n",
      "30\tValidation loss: 0.600674\tBest loss: 0.600674\tAccuracy: 86.80%\n",
      "31\tValidation loss: 0.594187\tBest loss: 0.594187\tAccuracy: 87.40%\n",
      "32\tValidation loss: 0.593973\tBest loss: 0.593973\tAccuracy: 87.20%\n",
      "33\tValidation loss: 0.588205\tBest loss: 0.588205\tAccuracy: 86.80%\n",
      "34\tValidation loss: 0.584192\tBest loss: 0.584192\tAccuracy: 87.30%\n",
      "35\tValidation loss: 0.582328\tBest loss: 0.582328\tAccuracy: 86.60%\n",
      "36\tValidation loss: 0.580261\tBest loss: 0.580261\tAccuracy: 87.80%\n",
      "37\tValidation loss: 0.572315\tBest loss: 0.572315\tAccuracy: 87.80%\n",
      "38\tValidation loss: 0.572146\tBest loss: 0.572146\tAccuracy: 88.00%\n",
      "39\tValidation loss: 0.569223\tBest loss: 0.569223\tAccuracy: 87.40%\n",
      "40\tValidation loss: 0.568572\tBest loss: 0.568572\tAccuracy: 87.10%\n",
      "41\tValidation loss: 0.561175\tBest loss: 0.561175\tAccuracy: 87.40%\n",
      "42\tValidation loss: 0.558477\tBest loss: 0.558477\tAccuracy: 88.10%\n",
      "43\tValidation loss: 0.552304\tBest loss: 0.552304\tAccuracy: 88.00%\n",
      "44\tValidation loss: 0.552649\tBest loss: 0.552304\tAccuracy: 87.90%\n",
      "45\tValidation loss: 0.551055\tBest loss: 0.551055\tAccuracy: 87.50%\n",
      "46\tValidation loss: 0.551925\tBest loss: 0.551055\tAccuracy: 87.30%\n",
      "47\tValidation loss: 0.547624\tBest loss: 0.547624\tAccuracy: 87.60%\n",
      "48\tValidation loss: 0.543706\tBest loss: 0.543706\tAccuracy: 87.60%\n",
      "49\tValidation loss: 0.543961\tBest loss: 0.543706\tAccuracy: 87.50%\n",
      "50\tValidation loss: 0.540701\tBest loss: 0.540701\tAccuracy: 87.90%\n",
      "51\tValidation loss: 0.537822\tBest loss: 0.537822\tAccuracy: 87.50%\n",
      "52\tValidation loss: 0.535338\tBest loss: 0.535338\tAccuracy: 87.90%\n",
      "53\tValidation loss: 0.531508\tBest loss: 0.531508\tAccuracy: 87.60%\n",
      "54\tValidation loss: 0.529507\tBest loss: 0.529507\tAccuracy: 88.10%\n",
      "55\tValidation loss: 0.529335\tBest loss: 0.529335\tAccuracy: 88.20%\n",
      "56\tValidation loss: 0.530270\tBest loss: 0.529335\tAccuracy: 87.70%\n",
      "57\tValidation loss: 0.525201\tBest loss: 0.525201\tAccuracy: 87.70%\n",
      "58\tValidation loss: 0.526125\tBest loss: 0.525201\tAccuracy: 87.80%\n",
      "59\tValidation loss: 0.523602\tBest loss: 0.523602\tAccuracy: 87.90%\n",
      "60\tValidation loss: 0.524026\tBest loss: 0.523602\tAccuracy: 88.10%\n",
      "61\tValidation loss: 0.522875\tBest loss: 0.522875\tAccuracy: 88.00%\n",
      "62\tValidation loss: 0.518996\tBest loss: 0.518996\tAccuracy: 88.30%\n",
      "63\tValidation loss: 0.515338\tBest loss: 0.515338\tAccuracy: 88.60%\n",
      "64\tValidation loss: 0.513582\tBest loss: 0.513582\tAccuracy: 88.00%\n",
      "65\tValidation loss: 0.511488\tBest loss: 0.511488\tAccuracy: 88.30%\n",
      "66\tValidation loss: 0.512688\tBest loss: 0.511488\tAccuracy: 88.60%\n",
      "67\tValidation loss: 0.513944\tBest loss: 0.511488\tAccuracy: 88.10%\n",
      "68\tValidation loss: 0.508716\tBest loss: 0.508716\tAccuracy: 88.40%\n",
      "69\tValidation loss: 0.510442\tBest loss: 0.508716\tAccuracy: 88.90%\n",
      "70\tValidation loss: 0.508545\tBest loss: 0.508545\tAccuracy: 88.20%\n",
      "71\tValidation loss: 0.503877\tBest loss: 0.503877\tAccuracy: 88.10%\n",
      "72\tValidation loss: 0.509368\tBest loss: 0.503877\tAccuracy: 88.50%\n",
      "73\tValidation loss: 0.503595\tBest loss: 0.503595\tAccuracy: 88.50%\n",
      "74\tValidation loss: 0.501682\tBest loss: 0.501682\tAccuracy: 89.00%\n",
      "75\tValidation loss: 0.502704\tBest loss: 0.501682\tAccuracy: 88.50%\n",
      "76\tValidation loss: 0.496823\tBest loss: 0.496823\tAccuracy: 89.10%\n",
      "77\tValidation loss: 0.499094\tBest loss: 0.496823\tAccuracy: 88.40%\n",
      "78\tValidation loss: 0.494531\tBest loss: 0.494531\tAccuracy: 89.00%\n",
      "79\tValidation loss: 0.495262\tBest loss: 0.494531\tAccuracy: 88.90%\n",
      "80\tValidation loss: 0.495033\tBest loss: 0.494531\tAccuracy: 88.90%\n",
      "81\tValidation loss: 0.495283\tBest loss: 0.494531\tAccuracy: 88.90%\n",
      "82\tValidation loss: 0.491695\tBest loss: 0.491695\tAccuracy: 88.90%\n",
      "83\tValidation loss: 0.495354\tBest loss: 0.491695\tAccuracy: 88.90%\n",
      "84\tValidation loss: 0.491625\tBest loss: 0.491625\tAccuracy: 89.10%\n",
      "85\tValidation loss: 0.488327\tBest loss: 0.488327\tAccuracy: 89.40%\n",
      "86\tValidation loss: 0.489576\tBest loss: 0.488327\tAccuracy: 89.00%\n",
      "87\tValidation loss: 0.486292\tBest loss: 0.486292\tAccuracy: 88.80%\n",
      "88\tValidation loss: 0.486380\tBest loss: 0.486292\tAccuracy: 89.20%\n",
      "89\tValidation loss: 0.487812\tBest loss: 0.486292\tAccuracy: 89.30%\n",
      "90\tValidation loss: 0.484477\tBest loss: 0.484477\tAccuracy: 89.70%\n",
      "91\tValidation loss: 0.483054\tBest loss: 0.483054\tAccuracy: 89.30%\n",
      "92\tValidation loss: 0.484345\tBest loss: 0.483054\tAccuracy: 88.80%\n",
      "93\tValidation loss: 0.482019\tBest loss: 0.482019\tAccuracy: 89.30%\n",
      "94\tValidation loss: 0.481831\tBest loss: 0.481831\tAccuracy: 89.70%\n",
      "95\tValidation loss: 0.479792\tBest loss: 0.479792\tAccuracy: 89.50%\n",
      "96\tValidation loss: 0.478846\tBest loss: 0.478846\tAccuracy: 89.30%\n",
      "97\tValidation loss: 0.478687\tBest loss: 0.478687\tAccuracy: 89.70%\n",
      "98\tValidation loss: 0.478973\tBest loss: 0.478687\tAccuracy: 89.70%\n",
      "99\tValidation loss: 0.480196\tBest loss: 0.478687\tAccuracy: 89.20%\n",
      "100\tValidation loss: 0.478126\tBest loss: 0.478126\tAccuracy: 89.50%\n",
      "101\tValidation loss: 0.476823\tBest loss: 0.476823\tAccuracy: 89.60%\n",
      "102\tValidation loss: 0.475231\tBest loss: 0.475231\tAccuracy: 89.70%\n",
      "103\tValidation loss: 0.473702\tBest loss: 0.473702\tAccuracy: 89.50%\n",
      "104\tValidation loss: 0.474065\tBest loss: 0.473702\tAccuracy: 89.60%\n",
      "105\tValidation loss: 0.474253\tBest loss: 0.473702\tAccuracy: 89.80%\n",
      "106\tValidation loss: 0.472237\tBest loss: 0.472237\tAccuracy: 89.90%\n",
      "107\tValidation loss: 0.474251\tBest loss: 0.472237\tAccuracy: 89.90%\n",
      "108\tValidation loss: 0.472576\tBest loss: 0.472237\tAccuracy: 89.90%\n",
      "109\tValidation loss: 0.471414\tBest loss: 0.471414\tAccuracy: 89.90%\n",
      "110\tValidation loss: 0.470771\tBest loss: 0.470771\tAccuracy: 89.90%\n",
      "111\tValidation loss: 0.468357\tBest loss: 0.468357\tAccuracy: 90.00%\n",
      "112\tValidation loss: 0.470899\tBest loss: 0.468357\tAccuracy: 89.90%\n",
      "113\tValidation loss: 0.467910\tBest loss: 0.467910\tAccuracy: 89.60%\n",
      "114\tValidation loss: 0.467731\tBest loss: 0.467731\tAccuracy: 89.70%\n",
      "115\tValidation loss: 0.468488\tBest loss: 0.467731\tAccuracy: 89.50%\n",
      "116\tValidation loss: 0.468143\tBest loss: 0.467731\tAccuracy: 89.70%\n",
      "117\tValidation loss: 0.466551\tBest loss: 0.466551\tAccuracy: 89.80%\n",
      "118\tValidation loss: 0.464586\tBest loss: 0.464586\tAccuracy: 90.10%\n",
      "119\tValidation loss: 0.464234\tBest loss: 0.464234\tAccuracy: 90.10%\n",
      "120\tValidation loss: 0.463919\tBest loss: 0.463919\tAccuracy: 89.80%\n",
      "121\tValidation loss: 0.464488\tBest loss: 0.463919\tAccuracy: 89.90%\n",
      "122\tValidation loss: 0.462009\tBest loss: 0.462009\tAccuracy: 90.30%\n",
      "123\tValidation loss: 0.460594\tBest loss: 0.460594\tAccuracy: 90.00%\n",
      "124\tValidation loss: 0.460787\tBest loss: 0.460594\tAccuracy: 89.90%\n",
      "125\tValidation loss: 0.460787\tBest loss: 0.460594\tAccuracy: 90.10%\n",
      "126\tValidation loss: 0.460892\tBest loss: 0.460594\tAccuracy: 90.10%\n",
      "127\tValidation loss: 0.459382\tBest loss: 0.459382\tAccuracy: 90.30%\n",
      "128\tValidation loss: 0.460441\tBest loss: 0.459382\tAccuracy: 90.10%\n",
      "129\tValidation loss: 0.457914\tBest loss: 0.457914\tAccuracy: 90.00%\n",
      "130\tValidation loss: 0.456489\tBest loss: 0.456489\tAccuracy: 89.90%\n",
      "131\tValidation loss: 0.456869\tBest loss: 0.456489\tAccuracy: 90.40%\n",
      "132\tValidation loss: 0.457086\tBest loss: 0.456489\tAccuracy: 90.40%\n",
      "133\tValidation loss: 0.457813\tBest loss: 0.456489\tAccuracy: 90.10%\n",
      "134\tValidation loss: 0.457193\tBest loss: 0.456489\tAccuracy: 90.50%\n",
      "135\tValidation loss: 0.458291\tBest loss: 0.456489\tAccuracy: 90.30%\n",
      "136\tValidation loss: 0.456706\tBest loss: 0.456489\tAccuracy: 90.50%\n",
      "137\tValidation loss: 0.456756\tBest loss: 0.456489\tAccuracy: 90.60%\n",
      "138\tValidation loss: 0.453316\tBest loss: 0.453316\tAccuracy: 90.20%\n",
      "139\tValidation loss: 0.455378\tBest loss: 0.453316\tAccuracy: 90.50%\n",
      "140\tValidation loss: 0.454574\tBest loss: 0.453316\tAccuracy: 90.40%\n",
      "141\tValidation loss: 0.454734\tBest loss: 0.453316\tAccuracy: 90.60%\n",
      "142\tValidation loss: 0.453345\tBest loss: 0.453316\tAccuracy: 90.20%\n",
      "143\tValidation loss: 0.453562\tBest loss: 0.453316\tAccuracy: 90.60%\n",
      "144\tValidation loss: 0.451266\tBest loss: 0.451266\tAccuracy: 90.80%\n",
      "145\tValidation loss: 0.452672\tBest loss: 0.451266\tAccuracy: 90.70%\n",
      "146\tValidation loss: 0.450288\tBest loss: 0.450288\tAccuracy: 90.50%\n",
      "147\tValidation loss: 0.450064\tBest loss: 0.450064\tAccuracy: 90.80%\n",
      "148\tValidation loss: 0.450499\tBest loss: 0.450064\tAccuracy: 90.70%\n",
      "149\tValidation loss: 0.449815\tBest loss: 0.449815\tAccuracy: 90.80%\n",
      "150\tValidation loss: 0.449813\tBest loss: 0.449813\tAccuracy: 90.40%\n",
      "151\tValidation loss: 0.448536\tBest loss: 0.448536\tAccuracy: 91.00%\n",
      "152\tValidation loss: 0.447114\tBest loss: 0.447114\tAccuracy: 90.90%\n",
      "153\tValidation loss: 0.448691\tBest loss: 0.447114\tAccuracy: 90.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\tValidation loss: 0.449460\tBest loss: 0.447114\tAccuracy: 90.70%\n",
      "155\tValidation loss: 0.448738\tBest loss: 0.447114\tAccuracy: 91.00%\n",
      "156\tValidation loss: 0.448338\tBest loss: 0.447114\tAccuracy: 91.00%\n",
      "157\tValidation loss: 0.446437\tBest loss: 0.446437\tAccuracy: 90.90%\n",
      "158\tValidation loss: 0.445181\tBest loss: 0.445181\tAccuracy: 90.80%\n",
      "159\tValidation loss: 0.446704\tBest loss: 0.445181\tAccuracy: 90.80%\n",
      "160\tValidation loss: 0.444406\tBest loss: 0.444406\tAccuracy: 90.60%\n",
      "161\tValidation loss: 0.446742\tBest loss: 0.444406\tAccuracy: 90.80%\n",
      "162\tValidation loss: 0.445922\tBest loss: 0.444406\tAccuracy: 91.10%\n",
      "163\tValidation loss: 0.446093\tBest loss: 0.444406\tAccuracy: 91.10%\n",
      "164\tValidation loss: 0.443204\tBest loss: 0.443204\tAccuracy: 91.00%\n",
      "165\tValidation loss: 0.444368\tBest loss: 0.443204\tAccuracy: 90.90%\n",
      "166\tValidation loss: 0.442405\tBest loss: 0.442405\tAccuracy: 91.00%\n",
      "167\tValidation loss: 0.442654\tBest loss: 0.442405\tAccuracy: 91.00%\n",
      "168\tValidation loss: 0.441491\tBest loss: 0.441491\tAccuracy: 91.00%\n",
      "169\tValidation loss: 0.443503\tBest loss: 0.441491\tAccuracy: 91.10%\n",
      "170\tValidation loss: 0.440712\tBest loss: 0.440712\tAccuracy: 91.00%\n",
      "171\tValidation loss: 0.441878\tBest loss: 0.440712\tAccuracy: 90.90%\n",
      "172\tValidation loss: 0.440278\tBest loss: 0.440278\tAccuracy: 91.00%\n",
      "173\tValidation loss: 0.442316\tBest loss: 0.440278\tAccuracy: 90.90%\n",
      "174\tValidation loss: 0.439513\tBest loss: 0.439513\tAccuracy: 91.10%\n",
      "175\tValidation loss: 0.440947\tBest loss: 0.439513\tAccuracy: 90.90%\n",
      "176\tValidation loss: 0.441124\tBest loss: 0.439513\tAccuracy: 90.90%\n",
      "177\tValidation loss: 0.440423\tBest loss: 0.439513\tAccuracy: 91.00%\n",
      "178\tValidation loss: 0.440389\tBest loss: 0.439513\tAccuracy: 91.40%\n",
      "179\tValidation loss: 0.440167\tBest loss: 0.439513\tAccuracy: 91.30%\n",
      "180\tValidation loss: 0.439738\tBest loss: 0.439513\tAccuracy: 90.80%\n",
      "181\tValidation loss: 0.437937\tBest loss: 0.437937\tAccuracy: 91.20%\n",
      "182\tValidation loss: 0.436814\tBest loss: 0.436814\tAccuracy: 91.10%\n",
      "183\tValidation loss: 0.438387\tBest loss: 0.436814\tAccuracy: 91.30%\n",
      "184\tValidation loss: 0.437536\tBest loss: 0.436814\tAccuracy: 91.10%\n",
      "185\tValidation loss: 0.436948\tBest loss: 0.436814\tAccuracy: 90.90%\n",
      "186\tValidation loss: 0.438621\tBest loss: 0.436814\tAccuracy: 90.80%\n",
      "187\tValidation loss: 0.436915\tBest loss: 0.436814\tAccuracy: 91.10%\n",
      "188\tValidation loss: 0.436473\tBest loss: 0.436473\tAccuracy: 91.20%\n",
      "189\tValidation loss: 0.436247\tBest loss: 0.436247\tAccuracy: 91.00%\n",
      "190\tValidation loss: 0.435577\tBest loss: 0.435577\tAccuracy: 91.30%\n",
      "191\tValidation loss: 0.436073\tBest loss: 0.435577\tAccuracy: 91.10%\n",
      "192\tValidation loss: 0.436066\tBest loss: 0.435577\tAccuracy: 90.80%\n",
      "193\tValidation loss: 0.435679\tBest loss: 0.435577\tAccuracy: 91.10%\n",
      "194\tValidation loss: 0.435010\tBest loss: 0.435010\tAccuracy: 91.10%\n",
      "195\tValidation loss: 0.434064\tBest loss: 0.434064\tAccuracy: 91.10%\n",
      "196\tValidation loss: 0.434097\tBest loss: 0.434064\tAccuracy: 91.00%\n",
      "197\tValidation loss: 0.435637\tBest loss: 0.434064\tAccuracy: 91.00%\n",
      "198\tValidation loss: 0.432765\tBest loss: 0.432765\tAccuracy: 91.40%\n",
      "199\tValidation loss: 0.434251\tBest loss: 0.432765\tAccuracy: 90.90%\n",
      "200\tValidation loss: 0.433829\tBest loss: 0.432765\tAccuracy: 91.20%\n",
      "201\tValidation loss: 0.433847\tBest loss: 0.432765\tAccuracy: 90.90%\n",
      "202\tValidation loss: 0.431357\tBest loss: 0.431357\tAccuracy: 91.10%\n",
      "203\tValidation loss: 0.433550\tBest loss: 0.431357\tAccuracy: 91.20%\n",
      "204\tValidation loss: 0.432658\tBest loss: 0.431357\tAccuracy: 91.10%\n",
      "205\tValidation loss: 0.431700\tBest loss: 0.431357\tAccuracy: 91.00%\n",
      "206\tValidation loss: 0.434095\tBest loss: 0.431357\tAccuracy: 91.30%\n",
      "207\tValidation loss: 0.430403\tBest loss: 0.430403\tAccuracy: 91.30%\n",
      "208\tValidation loss: 0.432124\tBest loss: 0.430403\tAccuracy: 90.80%\n",
      "209\tValidation loss: 0.431742\tBest loss: 0.430403\tAccuracy: 91.20%\n",
      "210\tValidation loss: 0.433013\tBest loss: 0.430403\tAccuracy: 90.80%\n",
      "211\tValidation loss: 0.431081\tBest loss: 0.430403\tAccuracy: 91.20%\n",
      "212\tValidation loss: 0.430837\tBest loss: 0.430403\tAccuracy: 91.10%\n",
      "213\tValidation loss: 0.430684\tBest loss: 0.430403\tAccuracy: 91.40%\n",
      "214\tValidation loss: 0.430609\tBest loss: 0.430403\tAccuracy: 91.30%\n",
      "215\tValidation loss: 0.431947\tBest loss: 0.430403\tAccuracy: 91.40%\n",
      "216\tValidation loss: 0.430073\tBest loss: 0.430073\tAccuracy: 91.30%\n",
      "217\tValidation loss: 0.428585\tBest loss: 0.428585\tAccuracy: 91.10%\n",
      "218\tValidation loss: 0.430841\tBest loss: 0.428585\tAccuracy: 91.20%\n",
      "219\tValidation loss: 0.429707\tBest loss: 0.428585\tAccuracy: 91.20%\n",
      "220\tValidation loss: 0.428155\tBest loss: 0.428155\tAccuracy: 91.30%\n",
      "221\tValidation loss: 0.429949\tBest loss: 0.428155\tAccuracy: 91.50%\n",
      "222\tValidation loss: 0.430834\tBest loss: 0.428155\tAccuracy: 91.20%\n",
      "223\tValidation loss: 0.428160\tBest loss: 0.428155\tAccuracy: 91.10%\n",
      "224\tValidation loss: 0.427691\tBest loss: 0.427691\tAccuracy: 91.60%\n",
      "225\tValidation loss: 0.428585\tBest loss: 0.427691\tAccuracy: 91.60%\n",
      "226\tValidation loss: 0.427114\tBest loss: 0.427114\tAccuracy: 91.20%\n",
      "227\tValidation loss: 0.427284\tBest loss: 0.427114\tAccuracy: 91.40%\n",
      "228\tValidation loss: 0.427921\tBest loss: 0.427114\tAccuracy: 91.30%\n",
      "229\tValidation loss: 0.427937\tBest loss: 0.427114\tAccuracy: 91.30%\n",
      "230\tValidation loss: 0.426259\tBest loss: 0.426259\tAccuracy: 91.40%\n",
      "231\tValidation loss: 0.426411\tBest loss: 0.426259\tAccuracy: 91.50%\n",
      "232\tValidation loss: 0.427113\tBest loss: 0.426259\tAccuracy: 91.40%\n",
      "233\tValidation loss: 0.426589\tBest loss: 0.426259\tAccuracy: 91.30%\n",
      "234\tValidation loss: 0.425622\tBest loss: 0.425622\tAccuracy: 91.30%\n",
      "235\tValidation loss: 0.426993\tBest loss: 0.425622\tAccuracy: 91.60%\n",
      "236\tValidation loss: 0.425397\tBest loss: 0.425397\tAccuracy: 91.40%\n",
      "237\tValidation loss: 0.425888\tBest loss: 0.425397\tAccuracy: 91.20%\n",
      "238\tValidation loss: 0.427438\tBest loss: 0.425397\tAccuracy: 91.50%\n",
      "239\tValidation loss: 0.427577\tBest loss: 0.425397\tAccuracy: 91.30%\n",
      "240\tValidation loss: 0.425639\tBest loss: 0.425397\tAccuracy: 91.50%\n",
      "241\tValidation loss: 0.426045\tBest loss: 0.425397\tAccuracy: 91.50%\n",
      "242\tValidation loss: 0.427714\tBest loss: 0.425397\tAccuracy: 91.50%\n",
      "243\tValidation loss: 0.424927\tBest loss: 0.424927\tAccuracy: 91.60%\n",
      "244\tValidation loss: 0.425519\tBest loss: 0.424927\tAccuracy: 91.20%\n",
      "245\tValidation loss: 0.425047\tBest loss: 0.424927\tAccuracy: 91.40%\n",
      "246\tValidation loss: 0.425740\tBest loss: 0.424927\tAccuracy: 91.60%\n",
      "247\tValidation loss: 0.424737\tBest loss: 0.424737\tAccuracy: 91.50%\n",
      "248\tValidation loss: 0.424969\tBest loss: 0.424737\tAccuracy: 91.40%\n",
      "249\tValidation loss: 0.423996\tBest loss: 0.423996\tAccuracy: 91.40%\n",
      "250\tValidation loss: 0.424875\tBest loss: 0.423996\tAccuracy: 91.30%\n",
      "251\tValidation loss: 0.423651\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "252\tValidation loss: 0.424742\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "253\tValidation loss: 0.424293\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "254\tValidation loss: 0.424098\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "255\tValidation loss: 0.425562\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "256\tValidation loss: 0.424071\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "257\tValidation loss: 0.424587\tBest loss: 0.423651\tAccuracy: 91.50%\n",
      "258\tValidation loss: 0.423543\tBest loss: 0.423543\tAccuracy: 91.50%\n",
      "259\tValidation loss: 0.421701\tBest loss: 0.421701\tAccuracy: 91.60%\n",
      "260\tValidation loss: 0.423119\tBest loss: 0.421701\tAccuracy: 91.40%\n",
      "261\tValidation loss: 0.422428\tBest loss: 0.421701\tAccuracy: 91.40%\n",
      "262\tValidation loss: 0.422389\tBest loss: 0.421701\tAccuracy: 91.30%\n",
      "263\tValidation loss: 0.423280\tBest loss: 0.421701\tAccuracy: 91.50%\n",
      "264\tValidation loss: 0.423861\tBest loss: 0.421701\tAccuracy: 91.50%\n",
      "265\tValidation loss: 0.422198\tBest loss: 0.421701\tAccuracy: 91.50%\n",
      "266\tValidation loss: 0.422335\tBest loss: 0.421701\tAccuracy: 91.80%\n",
      "267\tValidation loss: 0.422589\tBest loss: 0.421701\tAccuracy: 91.30%\n",
      "268\tValidation loss: 0.421449\tBest loss: 0.421449\tAccuracy: 91.40%\n",
      "269\tValidation loss: 0.421753\tBest loss: 0.421449\tAccuracy: 91.70%\n",
      "270\tValidation loss: 0.421440\tBest loss: 0.421440\tAccuracy: 91.30%\n",
      "271\tValidation loss: 0.420871\tBest loss: 0.420871\tAccuracy: 91.40%\n",
      "272\tValidation loss: 0.421866\tBest loss: 0.420871\tAccuracy: 91.70%\n",
      "273\tValidation loss: 0.421503\tBest loss: 0.420871\tAccuracy: 91.60%\n",
      "274\tValidation loss: 0.422560\tBest loss: 0.420871\tAccuracy: 91.50%\n",
      "275\tValidation loss: 0.420253\tBest loss: 0.420253\tAccuracy: 91.40%\n",
      "276\tValidation loss: 0.421107\tBest loss: 0.420253\tAccuracy: 91.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\tValidation loss: 0.422394\tBest loss: 0.420253\tAccuracy: 91.60%\n",
      "278\tValidation loss: 0.420328\tBest loss: 0.420253\tAccuracy: 91.70%\n",
      "279\tValidation loss: 0.420815\tBest loss: 0.420253\tAccuracy: 91.30%\n",
      "280\tValidation loss: 0.420249\tBest loss: 0.420249\tAccuracy: 91.60%\n",
      "281\tValidation loss: 0.420453\tBest loss: 0.420249\tAccuracy: 91.70%\n",
      "282\tValidation loss: 0.421471\tBest loss: 0.420249\tAccuracy: 91.40%\n",
      "283\tValidation loss: 0.421309\tBest loss: 0.420249\tAccuracy: 91.50%\n",
      "284\tValidation loss: 0.419647\tBest loss: 0.419647\tAccuracy: 91.50%\n",
      "285\tValidation loss: 0.419787\tBest loss: 0.419647\tAccuracy: 91.90%\n",
      "286\tValidation loss: 0.419981\tBest loss: 0.419647\tAccuracy: 91.50%\n",
      "287\tValidation loss: 0.420879\tBest loss: 0.419647\tAccuracy: 91.80%\n",
      "288\tValidation loss: 0.419516\tBest loss: 0.419516\tAccuracy: 91.30%\n",
      "289\tValidation loss: 0.419301\tBest loss: 0.419301\tAccuracy: 91.40%\n",
      "290\tValidation loss: 0.419177\tBest loss: 0.419177\tAccuracy: 91.50%\n",
      "291\tValidation loss: 0.419749\tBest loss: 0.419177\tAccuracy: 91.70%\n",
      "292\tValidation loss: 0.421182\tBest loss: 0.419177\tAccuracy: 91.60%\n",
      "293\tValidation loss: 0.420318\tBest loss: 0.419177\tAccuracy: 91.80%\n",
      "294\tValidation loss: 0.417637\tBest loss: 0.417637\tAccuracy: 91.90%\n",
      "295\tValidation loss: 0.419767\tBest loss: 0.417637\tAccuracy: 91.60%\n",
      "296\tValidation loss: 0.419734\tBest loss: 0.417637\tAccuracy: 91.60%\n",
      "297\tValidation loss: 0.419004\tBest loss: 0.417637\tAccuracy: 91.70%\n",
      "298\tValidation loss: 0.418913\tBest loss: 0.417637\tAccuracy: 91.80%\n",
      "299\tValidation loss: 0.418930\tBest loss: 0.417637\tAccuracy: 91.90%\n",
      "300\tValidation loss: 0.419902\tBest loss: 0.417637\tAccuracy: 91.70%\n",
      "301\tValidation loss: 0.419381\tBest loss: 0.417637\tAccuracy: 91.50%\n",
      "302\tValidation loss: 0.418403\tBest loss: 0.417637\tAccuracy: 91.70%\n",
      "303\tValidation loss: 0.418473\tBest loss: 0.417637\tAccuracy: 91.80%\n",
      "304\tValidation loss: 0.417576\tBest loss: 0.417576\tAccuracy: 91.80%\n",
      "305\tValidation loss: 0.417186\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "306\tValidation loss: 0.417836\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "307\tValidation loss: 0.418610\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "308\tValidation loss: 0.418533\tBest loss: 0.417186\tAccuracy: 91.60%\n",
      "309\tValidation loss: 0.418558\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "310\tValidation loss: 0.417346\tBest loss: 0.417186\tAccuracy: 91.80%\n",
      "311\tValidation loss: 0.418575\tBest loss: 0.417186\tAccuracy: 91.80%\n",
      "312\tValidation loss: 0.419155\tBest loss: 0.417186\tAccuracy: 91.80%\n",
      "313\tValidation loss: 0.418153\tBest loss: 0.417186\tAccuracy: 91.60%\n",
      "314\tValidation loss: 0.418770\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "315\tValidation loss: 0.418140\tBest loss: 0.417186\tAccuracy: 91.60%\n",
      "316\tValidation loss: 0.418358\tBest loss: 0.417186\tAccuracy: 91.50%\n",
      "317\tValidation loss: 0.417289\tBest loss: 0.417186\tAccuracy: 91.70%\n",
      "318\tValidation loss: 0.417861\tBest loss: 0.417186\tAccuracy: 91.80%\n",
      "319\tValidation loss: 0.418092\tBest loss: 0.417186\tAccuracy: 91.80%\n",
      "320\tValidation loss: 0.417011\tBest loss: 0.417011\tAccuracy: 91.80%\n",
      "321\tValidation loss: 0.418644\tBest loss: 0.417011\tAccuracy: 91.90%\n",
      "322\tValidation loss: 0.418011\tBest loss: 0.417011\tAccuracy: 91.70%\n",
      "323\tValidation loss: 0.417980\tBest loss: 0.417011\tAccuracy: 91.70%\n",
      "324\tValidation loss: 0.418045\tBest loss: 0.417011\tAccuracy: 91.70%\n",
      "325\tValidation loss: 0.418427\tBest loss: 0.417011\tAccuracy: 91.60%\n",
      "326\tValidation loss: 0.416779\tBest loss: 0.416779\tAccuracy: 91.80%\n",
      "327\tValidation loss: 0.416777\tBest loss: 0.416777\tAccuracy: 91.40%\n",
      "328\tValidation loss: 0.417565\tBest loss: 0.416777\tAccuracy: 91.80%\n",
      "329\tValidation loss: 0.416342\tBest loss: 0.416342\tAccuracy: 91.70%\n",
      "330\tValidation loss: 0.416706\tBest loss: 0.416342\tAccuracy: 91.60%\n",
      "331\tValidation loss: 0.417344\tBest loss: 0.416342\tAccuracy: 91.60%\n",
      "332\tValidation loss: 0.416497\tBest loss: 0.416342\tAccuracy: 91.60%\n",
      "333\tValidation loss: 0.416767\tBest loss: 0.416342\tAccuracy: 91.70%\n",
      "334\tValidation loss: 0.416959\tBest loss: 0.416342\tAccuracy: 91.70%\n",
      "335\tValidation loss: 0.416938\tBest loss: 0.416342\tAccuracy: 91.70%\n",
      "336\tValidation loss: 0.416265\tBest loss: 0.416265\tAccuracy: 91.70%\n",
      "337\tValidation loss: 0.417387\tBest loss: 0.416265\tAccuracy: 91.80%\n",
      "338\tValidation loss: 0.416435\tBest loss: 0.416265\tAccuracy: 91.80%\n",
      "339\tValidation loss: 0.416170\tBest loss: 0.416170\tAccuracy: 91.80%\n",
      "340\tValidation loss: 0.416365\tBest loss: 0.416170\tAccuracy: 91.60%\n",
      "341\tValidation loss: 0.415679\tBest loss: 0.415679\tAccuracy: 91.60%\n",
      "342\tValidation loss: 0.415875\tBest loss: 0.415679\tAccuracy: 91.70%\n",
      "343\tValidation loss: 0.417208\tBest loss: 0.415679\tAccuracy: 91.80%\n",
      "344\tValidation loss: 0.415477\tBest loss: 0.415477\tAccuracy: 91.90%\n",
      "345\tValidation loss: 0.416047\tBest loss: 0.415477\tAccuracy: 91.90%\n",
      "346\tValidation loss: 0.415279\tBest loss: 0.415279\tAccuracy: 91.70%\n",
      "347\tValidation loss: 0.417008\tBest loss: 0.415279\tAccuracy: 91.80%\n",
      "348\tValidation loss: 0.416467\tBest loss: 0.415279\tAccuracy: 91.60%\n",
      "349\tValidation loss: 0.416280\tBest loss: 0.415279\tAccuracy: 91.70%\n",
      "350\tValidation loss: 0.416448\tBest loss: 0.415279\tAccuracy: 91.80%\n",
      "351\tValidation loss: 0.417971\tBest loss: 0.415279\tAccuracy: 91.80%\n",
      "352\tValidation loss: 0.415962\tBest loss: 0.415279\tAccuracy: 91.70%\n",
      "353\tValidation loss: 0.415591\tBest loss: 0.415279\tAccuracy: 91.80%\n",
      "354\tValidation loss: 0.416552\tBest loss: 0.415279\tAccuracy: 91.70%\n",
      "355\tValidation loss: 0.415933\tBest loss: 0.415279\tAccuracy: 91.90%\n",
      "356\tValidation loss: 0.415474\tBest loss: 0.415279\tAccuracy: 91.60%\n",
      "357\tValidation loss: 0.415315\tBest loss: 0.415279\tAccuracy: 91.60%\n",
      "358\tValidation loss: 0.416655\tBest loss: 0.415279\tAccuracy: 91.80%\n",
      "359\tValidation loss: 0.415238\tBest loss: 0.415238\tAccuracy: 91.80%\n",
      "360\tValidation loss: 0.414742\tBest loss: 0.414742\tAccuracy: 91.80%\n",
      "361\tValidation loss: 0.416556\tBest loss: 0.414742\tAccuracy: 91.80%\n",
      "362\tValidation loss: 0.416307\tBest loss: 0.414742\tAccuracy: 92.00%\n",
      "363\tValidation loss: 0.415562\tBest loss: 0.414742\tAccuracy: 91.90%\n",
      "364\tValidation loss: 0.415353\tBest loss: 0.414742\tAccuracy: 91.80%\n",
      "365\tValidation loss: 0.416660\tBest loss: 0.414742\tAccuracy: 91.60%\n",
      "366\tValidation loss: 0.415648\tBest loss: 0.414742\tAccuracy: 91.60%\n",
      "367\tValidation loss: 0.414866\tBest loss: 0.414742\tAccuracy: 91.80%\n",
      "368\tValidation loss: 0.414294\tBest loss: 0.414294\tAccuracy: 91.70%\n",
      "369\tValidation loss: 0.415720\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "370\tValidation loss: 0.415547\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "371\tValidation loss: 0.415172\tBest loss: 0.414294\tAccuracy: 91.70%\n",
      "372\tValidation loss: 0.416225\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "373\tValidation loss: 0.415381\tBest loss: 0.414294\tAccuracy: 91.70%\n",
      "374\tValidation loss: 0.414441\tBest loss: 0.414294\tAccuracy: 91.70%\n",
      "375\tValidation loss: 0.415331\tBest loss: 0.414294\tAccuracy: 92.00%\n",
      "376\tValidation loss: 0.415952\tBest loss: 0.414294\tAccuracy: 91.60%\n",
      "377\tValidation loss: 0.416238\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "378\tValidation loss: 0.414763\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "379\tValidation loss: 0.415260\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "380\tValidation loss: 0.415475\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "381\tValidation loss: 0.416063\tBest loss: 0.414294\tAccuracy: 92.00%\n",
      "382\tValidation loss: 0.414954\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "383\tValidation loss: 0.415234\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "384\tValidation loss: 0.415166\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "385\tValidation loss: 0.415537\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "386\tValidation loss: 0.414780\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "387\tValidation loss: 0.414569\tBest loss: 0.414294\tAccuracy: 92.00%\n",
      "388\tValidation loss: 0.414415\tBest loss: 0.414294\tAccuracy: 91.80%\n",
      "389\tValidation loss: 0.415735\tBest loss: 0.414294\tAccuracy: 91.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  42.2s\n",
      "[CV] batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 1.636036\tBest loss: 1.636036\tAccuracy: 63.50%\n",
      "1\tValidation loss: 1.303244\tBest loss: 1.303244\tAccuracy: 71.50%\n",
      "2\tValidation loss: 1.136788\tBest loss: 1.136788\tAccuracy: 76.50%\n",
      "3\tValidation loss: 1.055484\tBest loss: 1.055484\tAccuracy: 78.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\tValidation loss: 0.972984\tBest loss: 0.972984\tAccuracy: 80.70%\n",
      "5\tValidation loss: 0.928907\tBest loss: 0.928907\tAccuracy: 79.80%\n",
      "6\tValidation loss: 0.878085\tBest loss: 0.878085\tAccuracy: 81.40%\n",
      "7\tValidation loss: 0.844090\tBest loss: 0.844090\tAccuracy: 82.70%\n",
      "8\tValidation loss: 0.827775\tBest loss: 0.827775\tAccuracy: 82.50%\n",
      "9\tValidation loss: 0.808043\tBest loss: 0.808043\tAccuracy: 83.10%\n",
      "10\tValidation loss: 0.777428\tBest loss: 0.777428\tAccuracy: 83.50%\n",
      "11\tValidation loss: 0.763633\tBest loss: 0.763633\tAccuracy: 83.50%\n",
      "12\tValidation loss: 0.742852\tBest loss: 0.742852\tAccuracy: 84.60%\n",
      "13\tValidation loss: 0.724385\tBest loss: 0.724385\tAccuracy: 84.30%\n",
      "14\tValidation loss: 0.717153\tBest loss: 0.717153\tAccuracy: 85.10%\n",
      "15\tValidation loss: 0.704501\tBest loss: 0.704501\tAccuracy: 84.70%\n",
      "16\tValidation loss: 0.697488\tBest loss: 0.697488\tAccuracy: 83.80%\n",
      "17\tValidation loss: 0.679909\tBest loss: 0.679909\tAccuracy: 85.40%\n",
      "18\tValidation loss: 0.674085\tBest loss: 0.674085\tAccuracy: 85.60%\n",
      "19\tValidation loss: 0.660930\tBest loss: 0.660930\tAccuracy: 86.20%\n",
      "20\tValidation loss: 0.656301\tBest loss: 0.656301\tAccuracy: 86.10%\n",
      "21\tValidation loss: 0.647965\tBest loss: 0.647965\tAccuracy: 86.10%\n",
      "22\tValidation loss: 0.636448\tBest loss: 0.636448\tAccuracy: 86.20%\n",
      "23\tValidation loss: 0.635308\tBest loss: 0.635308\tAccuracy: 86.50%\n",
      "24\tValidation loss: 0.630595\tBest loss: 0.630595\tAccuracy: 86.10%\n",
      "25\tValidation loss: 0.618438\tBest loss: 0.618438\tAccuracy: 87.20%\n",
      "26\tValidation loss: 0.615172\tBest loss: 0.615172\tAccuracy: 87.10%\n",
      "27\tValidation loss: 0.608161\tBest loss: 0.608161\tAccuracy: 87.50%\n",
      "28\tValidation loss: 0.605708\tBest loss: 0.605708\tAccuracy: 86.70%\n",
      "29\tValidation loss: 0.599016\tBest loss: 0.599016\tAccuracy: 87.10%\n",
      "30\tValidation loss: 0.593960\tBest loss: 0.593960\tAccuracy: 86.70%\n",
      "31\tValidation loss: 0.591235\tBest loss: 0.591235\tAccuracy: 87.40%\n",
      "32\tValidation loss: 0.587378\tBest loss: 0.587378\tAccuracy: 87.10%\n",
      "33\tValidation loss: 0.582715\tBest loss: 0.582715\tAccuracy: 87.70%\n",
      "34\tValidation loss: 0.578007\tBest loss: 0.578007\tAccuracy: 87.30%\n",
      "35\tValidation loss: 0.575538\tBest loss: 0.575538\tAccuracy: 87.60%\n",
      "36\tValidation loss: 0.577302\tBest loss: 0.575538\tAccuracy: 87.30%\n",
      "37\tValidation loss: 0.563903\tBest loss: 0.563903\tAccuracy: 87.80%\n",
      "38\tValidation loss: 0.559938\tBest loss: 0.559938\tAccuracy: 88.50%\n",
      "39\tValidation loss: 0.556074\tBest loss: 0.556074\tAccuracy: 87.80%\n",
      "40\tValidation loss: 0.559407\tBest loss: 0.556074\tAccuracy: 88.40%\n",
      "41\tValidation loss: 0.549258\tBest loss: 0.549258\tAccuracy: 88.40%\n",
      "42\tValidation loss: 0.554075\tBest loss: 0.549258\tAccuracy: 88.00%\n",
      "43\tValidation loss: 0.546427\tBest loss: 0.546427\tAccuracy: 88.60%\n",
      "44\tValidation loss: 0.542807\tBest loss: 0.542807\tAccuracy: 88.30%\n",
      "45\tValidation loss: 0.546601\tBest loss: 0.542807\tAccuracy: 88.40%\n",
      "46\tValidation loss: 0.541253\tBest loss: 0.541253\tAccuracy: 88.50%\n",
      "47\tValidation loss: 0.535974\tBest loss: 0.535974\tAccuracy: 88.30%\n",
      "48\tValidation loss: 0.533787\tBest loss: 0.533787\tAccuracy: 88.50%\n",
      "49\tValidation loss: 0.530473\tBest loss: 0.530473\tAccuracy: 88.20%\n",
      "50\tValidation loss: 0.530077\tBest loss: 0.530077\tAccuracy: 88.00%\n",
      "51\tValidation loss: 0.525583\tBest loss: 0.525583\tAccuracy: 88.50%\n",
      "52\tValidation loss: 0.525817\tBest loss: 0.525583\tAccuracy: 88.40%\n",
      "53\tValidation loss: 0.521598\tBest loss: 0.521598\tAccuracy: 89.20%\n",
      "54\tValidation loss: 0.519428\tBest loss: 0.519428\tAccuracy: 88.50%\n",
      "55\tValidation loss: 0.516641\tBest loss: 0.516641\tAccuracy: 88.70%\n",
      "56\tValidation loss: 0.517473\tBest loss: 0.516641\tAccuracy: 88.20%\n",
      "57\tValidation loss: 0.512265\tBest loss: 0.512265\tAccuracy: 89.30%\n",
      "58\tValidation loss: 0.512840\tBest loss: 0.512265\tAccuracy: 88.50%\n",
      "59\tValidation loss: 0.510805\tBest loss: 0.510805\tAccuracy: 88.90%\n",
      "60\tValidation loss: 0.509676\tBest loss: 0.509676\tAccuracy: 89.30%\n",
      "61\tValidation loss: 0.512617\tBest loss: 0.509676\tAccuracy: 88.90%\n",
      "62\tValidation loss: 0.508371\tBest loss: 0.508371\tAccuracy: 88.90%\n",
      "63\tValidation loss: 0.503982\tBest loss: 0.503982\tAccuracy: 88.90%\n",
      "64\tValidation loss: 0.501660\tBest loss: 0.501660\tAccuracy: 89.20%\n",
      "65\tValidation loss: 0.502932\tBest loss: 0.501660\tAccuracy: 89.00%\n",
      "66\tValidation loss: 0.499556\tBest loss: 0.499556\tAccuracy: 89.20%\n",
      "67\tValidation loss: 0.498275\tBest loss: 0.498275\tAccuracy: 89.10%\n",
      "68\tValidation loss: 0.492336\tBest loss: 0.492336\tAccuracy: 89.10%\n",
      "69\tValidation loss: 0.497360\tBest loss: 0.492336\tAccuracy: 89.10%\n",
      "70\tValidation loss: 0.493651\tBest loss: 0.492336\tAccuracy: 89.00%\n",
      "71\tValidation loss: 0.493532\tBest loss: 0.492336\tAccuracy: 89.00%\n",
      "72\tValidation loss: 0.492663\tBest loss: 0.492336\tAccuracy: 88.90%\n",
      "73\tValidation loss: 0.490531\tBest loss: 0.490531\tAccuracy: 89.30%\n",
      "74\tValidation loss: 0.489729\tBest loss: 0.489729\tAccuracy: 89.20%\n",
      "75\tValidation loss: 0.487176\tBest loss: 0.487176\tAccuracy: 89.40%\n",
      "76\tValidation loss: 0.491163\tBest loss: 0.487176\tAccuracy: 89.10%\n",
      "77\tValidation loss: 0.483559\tBest loss: 0.483559\tAccuracy: 89.60%\n",
      "78\tValidation loss: 0.479605\tBest loss: 0.479605\tAccuracy: 89.90%\n",
      "79\tValidation loss: 0.484489\tBest loss: 0.479605\tAccuracy: 89.40%\n",
      "80\tValidation loss: 0.479780\tBest loss: 0.479605\tAccuracy: 89.30%\n",
      "81\tValidation loss: 0.482206\tBest loss: 0.479605\tAccuracy: 89.90%\n",
      "82\tValidation loss: 0.479270\tBest loss: 0.479270\tAccuracy: 89.70%\n",
      "83\tValidation loss: 0.476814\tBest loss: 0.476814\tAccuracy: 89.60%\n",
      "84\tValidation loss: 0.476548\tBest loss: 0.476548\tAccuracy: 89.60%\n",
      "85\tValidation loss: 0.472077\tBest loss: 0.472077\tAccuracy: 89.60%\n",
      "86\tValidation loss: 0.473632\tBest loss: 0.472077\tAccuracy: 89.90%\n",
      "87\tValidation loss: 0.472962\tBest loss: 0.472077\tAccuracy: 89.60%\n",
      "88\tValidation loss: 0.469399\tBest loss: 0.469399\tAccuracy: 89.60%\n",
      "89\tValidation loss: 0.470866\tBest loss: 0.469399\tAccuracy: 89.60%\n",
      "90\tValidation loss: 0.468947\tBest loss: 0.468947\tAccuracy: 89.70%\n",
      "91\tValidation loss: 0.467202\tBest loss: 0.467202\tAccuracy: 90.30%\n",
      "92\tValidation loss: 0.471312\tBest loss: 0.467202\tAccuracy: 90.10%\n",
      "93\tValidation loss: 0.464253\tBest loss: 0.464253\tAccuracy: 90.00%\n",
      "94\tValidation loss: 0.465691\tBest loss: 0.464253\tAccuracy: 89.90%\n",
      "95\tValidation loss: 0.463750\tBest loss: 0.463750\tAccuracy: 89.90%\n",
      "96\tValidation loss: 0.462085\tBest loss: 0.462085\tAccuracy: 90.20%\n",
      "97\tValidation loss: 0.466771\tBest loss: 0.462085\tAccuracy: 89.80%\n",
      "98\tValidation loss: 0.462111\tBest loss: 0.462085\tAccuracy: 89.90%\n",
      "99\tValidation loss: 0.460382\tBest loss: 0.460382\tAccuracy: 89.90%\n",
      "100\tValidation loss: 0.459767\tBest loss: 0.459767\tAccuracy: 89.90%\n",
      "101\tValidation loss: 0.459588\tBest loss: 0.459588\tAccuracy: 89.90%\n",
      "102\tValidation loss: 0.456671\tBest loss: 0.456671\tAccuracy: 90.10%\n",
      "103\tValidation loss: 0.456164\tBest loss: 0.456164\tAccuracy: 90.10%\n",
      "104\tValidation loss: 0.457934\tBest loss: 0.456164\tAccuracy: 89.90%\n",
      "105\tValidation loss: 0.459817\tBest loss: 0.456164\tAccuracy: 90.20%\n",
      "106\tValidation loss: 0.456547\tBest loss: 0.456164\tAccuracy: 90.40%\n",
      "107\tValidation loss: 0.456194\tBest loss: 0.456164\tAccuracy: 90.40%\n",
      "108\tValidation loss: 0.454743\tBest loss: 0.454743\tAccuracy: 90.10%\n",
      "109\tValidation loss: 0.451968\tBest loss: 0.451968\tAccuracy: 90.30%\n",
      "110\tValidation loss: 0.452915\tBest loss: 0.451968\tAccuracy: 90.50%\n",
      "111\tValidation loss: 0.452420\tBest loss: 0.451968\tAccuracy: 90.40%\n",
      "112\tValidation loss: 0.451305\tBest loss: 0.451305\tAccuracy: 90.20%\n",
      "113\tValidation loss: 0.451654\tBest loss: 0.451305\tAccuracy: 90.60%\n",
      "114\tValidation loss: 0.452354\tBest loss: 0.451305\tAccuracy: 90.30%\n",
      "115\tValidation loss: 0.448277\tBest loss: 0.448277\tAccuracy: 90.60%\n",
      "116\tValidation loss: 0.450691\tBest loss: 0.448277\tAccuracy: 90.50%\n",
      "117\tValidation loss: 0.448159\tBest loss: 0.448159\tAccuracy: 90.20%\n",
      "118\tValidation loss: 0.445146\tBest loss: 0.445146\tAccuracy: 90.40%\n",
      "119\tValidation loss: 0.444335\tBest loss: 0.444335\tAccuracy: 90.30%\n",
      "120\tValidation loss: 0.444562\tBest loss: 0.444335\tAccuracy: 90.60%\n",
      "121\tValidation loss: 0.444479\tBest loss: 0.444335\tAccuracy: 90.60%\n",
      "122\tValidation loss: 0.445468\tBest loss: 0.444335\tAccuracy: 90.30%\n",
      "123\tValidation loss: 0.445150\tBest loss: 0.444335\tAccuracy: 90.20%\n",
      "124\tValidation loss: 0.444378\tBest loss: 0.444335\tAccuracy: 90.30%\n",
      "125\tValidation loss: 0.442404\tBest loss: 0.442404\tAccuracy: 90.40%\n",
      "126\tValidation loss: 0.442799\tBest loss: 0.442404\tAccuracy: 90.70%\n",
      "127\tValidation loss: 0.440638\tBest loss: 0.440638\tAccuracy: 90.60%\n",
      "128\tValidation loss: 0.439990\tBest loss: 0.439990\tAccuracy: 90.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\tValidation loss: 0.439748\tBest loss: 0.439748\tAccuracy: 90.60%\n",
      "130\tValidation loss: 0.439220\tBest loss: 0.439220\tAccuracy: 90.90%\n",
      "131\tValidation loss: 0.439070\tBest loss: 0.439070\tAccuracy: 90.70%\n",
      "132\tValidation loss: 0.436831\tBest loss: 0.436831\tAccuracy: 90.60%\n",
      "133\tValidation loss: 0.440667\tBest loss: 0.436831\tAccuracy: 90.30%\n",
      "134\tValidation loss: 0.438828\tBest loss: 0.436831\tAccuracy: 90.90%\n",
      "135\tValidation loss: 0.438606\tBest loss: 0.436831\tAccuracy: 90.90%\n",
      "136\tValidation loss: 0.437396\tBest loss: 0.436831\tAccuracy: 90.60%\n",
      "137\tValidation loss: 0.435654\tBest loss: 0.435654\tAccuracy: 90.70%\n",
      "138\tValidation loss: 0.434602\tBest loss: 0.434602\tAccuracy: 90.70%\n",
      "139\tValidation loss: 0.434083\tBest loss: 0.434083\tAccuracy: 90.80%\n",
      "140\tValidation loss: 0.433219\tBest loss: 0.433219\tAccuracy: 90.80%\n",
      "141\tValidation loss: 0.431196\tBest loss: 0.431196\tAccuracy: 90.80%\n",
      "142\tValidation loss: 0.433151\tBest loss: 0.431196\tAccuracy: 90.80%\n",
      "143\tValidation loss: 0.432268\tBest loss: 0.431196\tAccuracy: 91.10%\n",
      "144\tValidation loss: 0.432686\tBest loss: 0.431196\tAccuracy: 91.20%\n",
      "145\tValidation loss: 0.430697\tBest loss: 0.430697\tAccuracy: 91.10%\n",
      "146\tValidation loss: 0.431061\tBest loss: 0.430697\tAccuracy: 90.70%\n",
      "147\tValidation loss: 0.431632\tBest loss: 0.430697\tAccuracy: 90.60%\n",
      "148\tValidation loss: 0.431928\tBest loss: 0.430697\tAccuracy: 90.80%\n",
      "149\tValidation loss: 0.430198\tBest loss: 0.430198\tAccuracy: 90.70%\n",
      "150\tValidation loss: 0.428618\tBest loss: 0.428618\tAccuracy: 90.80%\n",
      "151\tValidation loss: 0.427879\tBest loss: 0.427879\tAccuracy: 91.00%\n",
      "152\tValidation loss: 0.427622\tBest loss: 0.427622\tAccuracy: 90.70%\n",
      "153\tValidation loss: 0.427060\tBest loss: 0.427060\tAccuracy: 91.00%\n",
      "154\tValidation loss: 0.427698\tBest loss: 0.427060\tAccuracy: 91.00%\n",
      "155\tValidation loss: 0.429468\tBest loss: 0.427060\tAccuracy: 90.90%\n",
      "156\tValidation loss: 0.428985\tBest loss: 0.427060\tAccuracy: 90.70%\n",
      "157\tValidation loss: 0.427532\tBest loss: 0.427060\tAccuracy: 90.90%\n",
      "158\tValidation loss: 0.425251\tBest loss: 0.425251\tAccuracy: 90.80%\n",
      "159\tValidation loss: 0.422720\tBest loss: 0.422720\tAccuracy: 91.10%\n",
      "160\tValidation loss: 0.427753\tBest loss: 0.422720\tAccuracy: 90.70%\n",
      "161\tValidation loss: 0.423369\tBest loss: 0.422720\tAccuracy: 90.90%\n",
      "162\tValidation loss: 0.422745\tBest loss: 0.422720\tAccuracy: 90.90%\n",
      "163\tValidation loss: 0.422698\tBest loss: 0.422698\tAccuracy: 91.00%\n",
      "164\tValidation loss: 0.424405\tBest loss: 0.422698\tAccuracy: 90.90%\n",
      "165\tValidation loss: 0.424387\tBest loss: 0.422698\tAccuracy: 90.80%\n",
      "166\tValidation loss: 0.424087\tBest loss: 0.422698\tAccuracy: 90.90%\n",
      "167\tValidation loss: 0.420894\tBest loss: 0.420894\tAccuracy: 91.00%\n",
      "168\tValidation loss: 0.420925\tBest loss: 0.420894\tAccuracy: 91.10%\n",
      "169\tValidation loss: 0.421120\tBest loss: 0.420894\tAccuracy: 91.00%\n",
      "170\tValidation loss: 0.422056\tBest loss: 0.420894\tAccuracy: 90.60%\n",
      "171\tValidation loss: 0.421729\tBest loss: 0.420894\tAccuracy: 90.70%\n",
      "172\tValidation loss: 0.420663\tBest loss: 0.420663\tAccuracy: 90.90%\n",
      "173\tValidation loss: 0.419742\tBest loss: 0.419742\tAccuracy: 90.80%\n",
      "174\tValidation loss: 0.420736\tBest loss: 0.419742\tAccuracy: 90.80%\n",
      "175\tValidation loss: 0.420746\tBest loss: 0.419742\tAccuracy: 90.80%\n",
      "176\tValidation loss: 0.420356\tBest loss: 0.419742\tAccuracy: 90.90%\n",
      "177\tValidation loss: 0.418273\tBest loss: 0.418273\tAccuracy: 91.10%\n",
      "178\tValidation loss: 0.417618\tBest loss: 0.417618\tAccuracy: 91.00%\n",
      "179\tValidation loss: 0.418274\tBest loss: 0.417618\tAccuracy: 90.80%\n",
      "180\tValidation loss: 0.416854\tBest loss: 0.416854\tAccuracy: 90.80%\n",
      "181\tValidation loss: 0.415766\tBest loss: 0.415766\tAccuracy: 90.90%\n",
      "182\tValidation loss: 0.417506\tBest loss: 0.415766\tAccuracy: 91.10%\n",
      "183\tValidation loss: 0.416062\tBest loss: 0.415766\tAccuracy: 91.10%\n",
      "184\tValidation loss: 0.417761\tBest loss: 0.415766\tAccuracy: 91.10%\n",
      "185\tValidation loss: 0.414553\tBest loss: 0.414553\tAccuracy: 91.10%\n",
      "186\tValidation loss: 0.417361\tBest loss: 0.414553\tAccuracy: 91.00%\n",
      "187\tValidation loss: 0.412755\tBest loss: 0.412755\tAccuracy: 91.10%\n",
      "188\tValidation loss: 0.415455\tBest loss: 0.412755\tAccuracy: 91.10%\n",
      "189\tValidation loss: 0.413445\tBest loss: 0.412755\tAccuracy: 91.20%\n",
      "190\tValidation loss: 0.413260\tBest loss: 0.412755\tAccuracy: 91.20%\n",
      "191\tValidation loss: 0.412542\tBest loss: 0.412542\tAccuracy: 91.20%\n",
      "192\tValidation loss: 0.412173\tBest loss: 0.412173\tAccuracy: 91.00%\n",
      "193\tValidation loss: 0.412561\tBest loss: 0.412173\tAccuracy: 90.90%\n",
      "194\tValidation loss: 0.415069\tBest loss: 0.412173\tAccuracy: 91.00%\n",
      "195\tValidation loss: 0.413522\tBest loss: 0.412173\tAccuracy: 91.10%\n",
      "196\tValidation loss: 0.411024\tBest loss: 0.411024\tAccuracy: 91.00%\n",
      "197\tValidation loss: 0.411228\tBest loss: 0.411024\tAccuracy: 91.40%\n",
      "198\tValidation loss: 0.412757\tBest loss: 0.411024\tAccuracy: 91.20%\n",
      "199\tValidation loss: 0.412854\tBest loss: 0.411024\tAccuracy: 90.90%\n",
      "200\tValidation loss: 0.410771\tBest loss: 0.410771\tAccuracy: 91.20%\n",
      "201\tValidation loss: 0.413005\tBest loss: 0.410771\tAccuracy: 91.10%\n",
      "202\tValidation loss: 0.410119\tBest loss: 0.410119\tAccuracy: 91.20%\n",
      "203\tValidation loss: 0.409882\tBest loss: 0.409882\tAccuracy: 91.30%\n",
      "204\tValidation loss: 0.410601\tBest loss: 0.409882\tAccuracy: 91.40%\n",
      "205\tValidation loss: 0.409531\tBest loss: 0.409531\tAccuracy: 91.30%\n",
      "206\tValidation loss: 0.409123\tBest loss: 0.409123\tAccuracy: 91.40%\n",
      "207\tValidation loss: 0.410018\tBest loss: 0.409123\tAccuracy: 91.20%\n",
      "208\tValidation loss: 0.409289\tBest loss: 0.409123\tAccuracy: 91.20%\n",
      "209\tValidation loss: 0.409844\tBest loss: 0.409123\tAccuracy: 91.20%\n",
      "210\tValidation loss: 0.409871\tBest loss: 0.409123\tAccuracy: 91.30%\n",
      "211\tValidation loss: 0.407361\tBest loss: 0.407361\tAccuracy: 91.30%\n",
      "212\tValidation loss: 0.407352\tBest loss: 0.407352\tAccuracy: 91.40%\n",
      "213\tValidation loss: 0.409403\tBest loss: 0.407352\tAccuracy: 91.20%\n",
      "214\tValidation loss: 0.405997\tBest loss: 0.405997\tAccuracy: 91.30%\n",
      "215\tValidation loss: 0.407832\tBest loss: 0.405997\tAccuracy: 91.70%\n",
      "216\tValidation loss: 0.407953\tBest loss: 0.405997\tAccuracy: 91.30%\n",
      "217\tValidation loss: 0.407351\tBest loss: 0.405997\tAccuracy: 91.10%\n",
      "218\tValidation loss: 0.405452\tBest loss: 0.405452\tAccuracy: 91.30%\n",
      "219\tValidation loss: 0.407180\tBest loss: 0.405452\tAccuracy: 91.40%\n",
      "220\tValidation loss: 0.403987\tBest loss: 0.403987\tAccuracy: 91.50%\n",
      "221\tValidation loss: 0.406228\tBest loss: 0.403987\tAccuracy: 91.30%\n",
      "222\tValidation loss: 0.406555\tBest loss: 0.403987\tAccuracy: 91.40%\n",
      "223\tValidation loss: 0.405534\tBest loss: 0.403987\tAccuracy: 91.50%\n",
      "224\tValidation loss: 0.406048\tBest loss: 0.403987\tAccuracy: 91.50%\n",
      "225\tValidation loss: 0.405224\tBest loss: 0.403987\tAccuracy: 91.60%\n",
      "226\tValidation loss: 0.403943\tBest loss: 0.403943\tAccuracy: 91.20%\n",
      "227\tValidation loss: 0.402905\tBest loss: 0.402905\tAccuracy: 91.50%\n",
      "228\tValidation loss: 0.403416\tBest loss: 0.402905\tAccuracy: 91.40%\n",
      "229\tValidation loss: 0.403880\tBest loss: 0.402905\tAccuracy: 91.00%\n",
      "230\tValidation loss: 0.402810\tBest loss: 0.402810\tAccuracy: 91.20%\n",
      "231\tValidation loss: 0.402580\tBest loss: 0.402580\tAccuracy: 91.30%\n",
      "232\tValidation loss: 0.402215\tBest loss: 0.402215\tAccuracy: 91.40%\n",
      "233\tValidation loss: 0.402244\tBest loss: 0.402215\tAccuracy: 91.30%\n",
      "234\tValidation loss: 0.402830\tBest loss: 0.402215\tAccuracy: 91.30%\n",
      "235\tValidation loss: 0.402973\tBest loss: 0.402215\tAccuracy: 91.40%\n",
      "236\tValidation loss: 0.402807\tBest loss: 0.402215\tAccuracy: 91.40%\n",
      "237\tValidation loss: 0.403840\tBest loss: 0.402215\tAccuracy: 91.40%\n",
      "238\tValidation loss: 0.402877\tBest loss: 0.402215\tAccuracy: 91.60%\n",
      "239\tValidation loss: 0.401123\tBest loss: 0.401123\tAccuracy: 91.70%\n",
      "240\tValidation loss: 0.401797\tBest loss: 0.401123\tAccuracy: 91.40%\n",
      "241\tValidation loss: 0.403133\tBest loss: 0.401123\tAccuracy: 91.20%\n",
      "242\tValidation loss: 0.399731\tBest loss: 0.399731\tAccuracy: 91.40%\n",
      "243\tValidation loss: 0.399986\tBest loss: 0.399731\tAccuracy: 91.70%\n",
      "244\tValidation loss: 0.401840\tBest loss: 0.399731\tAccuracy: 91.50%\n",
      "245\tValidation loss: 0.400418\tBest loss: 0.399731\tAccuracy: 91.00%\n",
      "246\tValidation loss: 0.400679\tBest loss: 0.399731\tAccuracy: 91.50%\n",
      "247\tValidation loss: 0.398592\tBest loss: 0.398592\tAccuracy: 91.80%\n",
      "248\tValidation loss: 0.397990\tBest loss: 0.397990\tAccuracy: 91.20%\n",
      "249\tValidation loss: 0.398965\tBest loss: 0.397990\tAccuracy: 91.30%\n",
      "250\tValidation loss: 0.399819\tBest loss: 0.397990\tAccuracy: 91.60%\n",
      "251\tValidation loss: 0.398937\tBest loss: 0.397990\tAccuracy: 91.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\tValidation loss: 0.397438\tBest loss: 0.397438\tAccuracy: 91.40%\n",
      "253\tValidation loss: 0.398321\tBest loss: 0.397438\tAccuracy: 91.70%\n",
      "254\tValidation loss: 0.397260\tBest loss: 0.397260\tAccuracy: 91.60%\n",
      "255\tValidation loss: 0.398697\tBest loss: 0.397260\tAccuracy: 91.50%\n",
      "256\tValidation loss: 0.397685\tBest loss: 0.397260\tAccuracy: 91.50%\n",
      "257\tValidation loss: 0.399576\tBest loss: 0.397260\tAccuracy: 91.50%\n",
      "258\tValidation loss: 0.398597\tBest loss: 0.397260\tAccuracy: 91.80%\n",
      "259\tValidation loss: 0.400215\tBest loss: 0.397260\tAccuracy: 91.70%\n",
      "260\tValidation loss: 0.397204\tBest loss: 0.397204\tAccuracy: 91.40%\n",
      "261\tValidation loss: 0.397290\tBest loss: 0.397204\tAccuracy: 91.60%\n",
      "262\tValidation loss: 0.398346\tBest loss: 0.397204\tAccuracy: 92.00%\n",
      "263\tValidation loss: 0.394850\tBest loss: 0.394850\tAccuracy: 91.70%\n",
      "264\tValidation loss: 0.395841\tBest loss: 0.394850\tAccuracy: 91.50%\n",
      "265\tValidation loss: 0.395090\tBest loss: 0.394850\tAccuracy: 91.60%\n",
      "266\tValidation loss: 0.396083\tBest loss: 0.394850\tAccuracy: 91.40%\n",
      "267\tValidation loss: 0.395384\tBest loss: 0.394850\tAccuracy: 91.50%\n",
      "268\tValidation loss: 0.395644\tBest loss: 0.394850\tAccuracy: 91.80%\n",
      "269\tValidation loss: 0.395013\tBest loss: 0.394850\tAccuracy: 91.70%\n",
      "270\tValidation loss: 0.396481\tBest loss: 0.394850\tAccuracy: 92.00%\n",
      "271\tValidation loss: 0.395549\tBest loss: 0.394850\tAccuracy: 91.70%\n",
      "272\tValidation loss: 0.393735\tBest loss: 0.393735\tAccuracy: 91.60%\n",
      "273\tValidation loss: 0.395452\tBest loss: 0.393735\tAccuracy: 92.00%\n",
      "274\tValidation loss: 0.394180\tBest loss: 0.393735\tAccuracy: 91.90%\n",
      "275\tValidation loss: 0.396112\tBest loss: 0.393735\tAccuracy: 92.00%\n",
      "276\tValidation loss: 0.394892\tBest loss: 0.393735\tAccuracy: 91.70%\n",
      "277\tValidation loss: 0.394033\tBest loss: 0.393735\tAccuracy: 91.60%\n",
      "278\tValidation loss: 0.394834\tBest loss: 0.393735\tAccuracy: 92.00%\n",
      "279\tValidation loss: 0.394983\tBest loss: 0.393735\tAccuracy: 92.00%\n",
      "280\tValidation loss: 0.393521\tBest loss: 0.393521\tAccuracy: 91.90%\n",
      "281\tValidation loss: 0.394033\tBest loss: 0.393521\tAccuracy: 91.90%\n",
      "282\tValidation loss: 0.393472\tBest loss: 0.393472\tAccuracy: 91.80%\n",
      "283\tValidation loss: 0.393235\tBest loss: 0.393235\tAccuracy: 91.90%\n",
      "284\tValidation loss: 0.393801\tBest loss: 0.393235\tAccuracy: 92.00%\n",
      "285\tValidation loss: 0.392644\tBest loss: 0.392644\tAccuracy: 92.00%\n",
      "286\tValidation loss: 0.392550\tBest loss: 0.392550\tAccuracy: 92.10%\n",
      "287\tValidation loss: 0.392692\tBest loss: 0.392550\tAccuracy: 91.90%\n",
      "288\tValidation loss: 0.390671\tBest loss: 0.390671\tAccuracy: 92.00%\n",
      "289\tValidation loss: 0.392805\tBest loss: 0.390671\tAccuracy: 92.00%\n",
      "290\tValidation loss: 0.391395\tBest loss: 0.390671\tAccuracy: 91.90%\n",
      "291\tValidation loss: 0.391940\tBest loss: 0.390671\tAccuracy: 92.10%\n",
      "292\tValidation loss: 0.392544\tBest loss: 0.390671\tAccuracy: 92.20%\n",
      "293\tValidation loss: 0.392378\tBest loss: 0.390671\tAccuracy: 91.90%\n",
      "294\tValidation loss: 0.391979\tBest loss: 0.390671\tAccuracy: 92.00%\n",
      "295\tValidation loss: 0.391753\tBest loss: 0.390671\tAccuracy: 92.10%\n",
      "296\tValidation loss: 0.391492\tBest loss: 0.390671\tAccuracy: 92.10%\n",
      "297\tValidation loss: 0.391137\tBest loss: 0.390671\tAccuracy: 91.80%\n",
      "298\tValidation loss: 0.390652\tBest loss: 0.390652\tAccuracy: 91.70%\n",
      "299\tValidation loss: 0.390462\tBest loss: 0.390462\tAccuracy: 92.10%\n",
      "300\tValidation loss: 0.390708\tBest loss: 0.390462\tAccuracy: 92.10%\n",
      "301\tValidation loss: 0.390074\tBest loss: 0.390074\tAccuracy: 92.00%\n",
      "302\tValidation loss: 0.391954\tBest loss: 0.390074\tAccuracy: 92.00%\n",
      "303\tValidation loss: 0.391464\tBest loss: 0.390074\tAccuracy: 92.00%\n",
      "304\tValidation loss: 0.389908\tBest loss: 0.389908\tAccuracy: 92.10%\n",
      "305\tValidation loss: 0.388553\tBest loss: 0.388553\tAccuracy: 92.20%\n",
      "306\tValidation loss: 0.389586\tBest loss: 0.388553\tAccuracy: 92.00%\n",
      "307\tValidation loss: 0.389172\tBest loss: 0.388553\tAccuracy: 92.10%\n",
      "308\tValidation loss: 0.389294\tBest loss: 0.388553\tAccuracy: 92.00%\n",
      "309\tValidation loss: 0.388815\tBest loss: 0.388553\tAccuracy: 92.10%\n",
      "310\tValidation loss: 0.387692\tBest loss: 0.387692\tAccuracy: 92.10%\n",
      "311\tValidation loss: 0.389633\tBest loss: 0.387692\tAccuracy: 92.10%\n",
      "312\tValidation loss: 0.388138\tBest loss: 0.387692\tAccuracy: 92.10%\n",
      "313\tValidation loss: 0.389933\tBest loss: 0.387692\tAccuracy: 92.00%\n",
      "314\tValidation loss: 0.388819\tBest loss: 0.387692\tAccuracy: 92.10%\n",
      "315\tValidation loss: 0.389621\tBest loss: 0.387692\tAccuracy: 92.00%\n",
      "316\tValidation loss: 0.389542\tBest loss: 0.387692\tAccuracy: 92.10%\n",
      "317\tValidation loss: 0.388961\tBest loss: 0.387692\tAccuracy: 92.00%\n",
      "318\tValidation loss: 0.387305\tBest loss: 0.387305\tAccuracy: 92.00%\n",
      "319\tValidation loss: 0.387864\tBest loss: 0.387305\tAccuracy: 92.30%\n",
      "320\tValidation loss: 0.387365\tBest loss: 0.387305\tAccuracy: 92.00%\n",
      "321\tValidation loss: 0.387231\tBest loss: 0.387231\tAccuracy: 92.20%\n",
      "322\tValidation loss: 0.388393\tBest loss: 0.387231\tAccuracy: 92.00%\n",
      "323\tValidation loss: 0.389008\tBest loss: 0.387231\tAccuracy: 92.20%\n",
      "324\tValidation loss: 0.387237\tBest loss: 0.387231\tAccuracy: 92.20%\n",
      "325\tValidation loss: 0.387816\tBest loss: 0.387231\tAccuracy: 92.30%\n",
      "326\tValidation loss: 0.385810\tBest loss: 0.385810\tAccuracy: 92.20%\n",
      "327\tValidation loss: 0.386362\tBest loss: 0.385810\tAccuracy: 92.10%\n",
      "328\tValidation loss: 0.386968\tBest loss: 0.385810\tAccuracy: 92.00%\n",
      "329\tValidation loss: 0.387860\tBest loss: 0.385810\tAccuracy: 92.20%\n",
      "330\tValidation loss: 0.386667\tBest loss: 0.385810\tAccuracy: 92.20%\n",
      "331\tValidation loss: 0.386789\tBest loss: 0.385810\tAccuracy: 92.00%\n",
      "332\tValidation loss: 0.385798\tBest loss: 0.385798\tAccuracy: 92.20%\n",
      "333\tValidation loss: 0.386584\tBest loss: 0.385798\tAccuracy: 92.10%\n",
      "334\tValidation loss: 0.385822\tBest loss: 0.385798\tAccuracy: 92.10%\n",
      "335\tValidation loss: 0.385529\tBest loss: 0.385529\tAccuracy: 92.10%\n",
      "336\tValidation loss: 0.383500\tBest loss: 0.383500\tAccuracy: 92.20%\n",
      "337\tValidation loss: 0.385333\tBest loss: 0.383500\tAccuracy: 92.20%\n",
      "338\tValidation loss: 0.384205\tBest loss: 0.383500\tAccuracy: 92.00%\n",
      "339\tValidation loss: 0.384607\tBest loss: 0.383500\tAccuracy: 92.20%\n",
      "340\tValidation loss: 0.385714\tBest loss: 0.383500\tAccuracy: 92.10%\n",
      "341\tValidation loss: 0.384570\tBest loss: 0.383500\tAccuracy: 92.10%\n",
      "342\tValidation loss: 0.384716\tBest loss: 0.383500\tAccuracy: 92.20%\n",
      "343\tValidation loss: 0.383115\tBest loss: 0.383115\tAccuracy: 92.20%\n",
      "344\tValidation loss: 0.384620\tBest loss: 0.383115\tAccuracy: 92.00%\n",
      "345\tValidation loss: 0.385058\tBest loss: 0.383115\tAccuracy: 92.10%\n",
      "346\tValidation loss: 0.384175\tBest loss: 0.383115\tAccuracy: 92.10%\n",
      "347\tValidation loss: 0.385461\tBest loss: 0.383115\tAccuracy: 92.10%\n",
      "348\tValidation loss: 0.384895\tBest loss: 0.383115\tAccuracy: 92.20%\n",
      "349\tValidation loss: 0.384670\tBest loss: 0.383115\tAccuracy: 92.30%\n",
      "350\tValidation loss: 0.383512\tBest loss: 0.383115\tAccuracy: 92.20%\n",
      "351\tValidation loss: 0.383929\tBest loss: 0.383115\tAccuracy: 92.30%\n",
      "352\tValidation loss: 0.383416\tBest loss: 0.383115\tAccuracy: 92.20%\n",
      "353\tValidation loss: 0.384525\tBest loss: 0.383115\tAccuracy: 92.30%\n",
      "354\tValidation loss: 0.383886\tBest loss: 0.383115\tAccuracy: 92.20%\n",
      "355\tValidation loss: 0.383383\tBest loss: 0.383115\tAccuracy: 92.00%\n",
      "356\tValidation loss: 0.382732\tBest loss: 0.382732\tAccuracy: 92.20%\n",
      "357\tValidation loss: 0.384207\tBest loss: 0.382732\tAccuracy: 92.30%\n",
      "358\tValidation loss: 0.383116\tBest loss: 0.382732\tAccuracy: 92.30%\n",
      "359\tValidation loss: 0.382989\tBest loss: 0.382732\tAccuracy: 92.20%\n",
      "360\tValidation loss: 0.382524\tBest loss: 0.382524\tAccuracy: 92.20%\n",
      "361\tValidation loss: 0.383222\tBest loss: 0.382524\tAccuracy: 92.20%\n",
      "362\tValidation loss: 0.383074\tBest loss: 0.382524\tAccuracy: 92.30%\n",
      "363\tValidation loss: 0.382739\tBest loss: 0.382524\tAccuracy: 92.30%\n",
      "364\tValidation loss: 0.382453\tBest loss: 0.382453\tAccuracy: 92.30%\n",
      "365\tValidation loss: 0.383300\tBest loss: 0.382453\tAccuracy: 92.20%\n",
      "366\tValidation loss: 0.383137\tBest loss: 0.382453\tAccuracy: 92.30%\n",
      "367\tValidation loss: 0.382556\tBest loss: 0.382453\tAccuracy: 92.30%\n",
      "368\tValidation loss: 0.383354\tBest loss: 0.382453\tAccuracy: 92.40%\n",
      "369\tValidation loss: 0.381671\tBest loss: 0.381671\tAccuracy: 92.50%\n",
      "370\tValidation loss: 0.381916\tBest loss: 0.381671\tAccuracy: 92.30%\n",
      "371\tValidation loss: 0.382365\tBest loss: 0.381671\tAccuracy: 92.20%\n",
      "372\tValidation loss: 0.381428\tBest loss: 0.381428\tAccuracy: 92.40%\n",
      "373\tValidation loss: 0.381415\tBest loss: 0.381415\tAccuracy: 92.40%\n",
      "374\tValidation loss: 0.382578\tBest loss: 0.381415\tAccuracy: 92.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\tValidation loss: 0.381096\tBest loss: 0.381096\tAccuracy: 92.40%\n",
      "376\tValidation loss: 0.381186\tBest loss: 0.381096\tAccuracy: 92.30%\n",
      "377\tValidation loss: 0.381579\tBest loss: 0.381096\tAccuracy: 92.20%\n",
      "378\tValidation loss: 0.382112\tBest loss: 0.381096\tAccuracy: 92.30%\n",
      "379\tValidation loss: 0.381044\tBest loss: 0.381044\tAccuracy: 92.40%\n",
      "380\tValidation loss: 0.381789\tBest loss: 0.381044\tAccuracy: 92.30%\n",
      "381\tValidation loss: 0.381330\tBest loss: 0.381044\tAccuracy: 92.40%\n",
      "382\tValidation loss: 0.381350\tBest loss: 0.381044\tAccuracy: 92.30%\n",
      "383\tValidation loss: 0.380409\tBest loss: 0.380409\tAccuracy: 92.60%\n",
      "384\tValidation loss: 0.380597\tBest loss: 0.380409\tAccuracy: 92.40%\n",
      "385\tValidation loss: 0.381426\tBest loss: 0.380409\tAccuracy: 92.30%\n",
      "386\tValidation loss: 0.380893\tBest loss: 0.380409\tAccuracy: 92.60%\n",
      "387\tValidation loss: 0.380853\tBest loss: 0.380409\tAccuracy: 92.50%\n",
      "388\tValidation loss: 0.379842\tBest loss: 0.379842\tAccuracy: 92.40%\n",
      "389\tValidation loss: 0.380575\tBest loss: 0.379842\tAccuracy: 92.50%\n",
      "390\tValidation loss: 0.381663\tBest loss: 0.379842\tAccuracy: 92.40%\n",
      "391\tValidation loss: 0.380644\tBest loss: 0.379842\tAccuracy: 92.50%\n",
      "392\tValidation loss: 0.381429\tBest loss: 0.379842\tAccuracy: 92.40%\n",
      "393\tValidation loss: 0.380055\tBest loss: 0.379842\tAccuracy: 92.50%\n",
      "394\tValidation loss: 0.380611\tBest loss: 0.379842\tAccuracy: 92.30%\n",
      "395\tValidation loss: 0.378794\tBest loss: 0.378794\tAccuracy: 92.40%\n",
      "396\tValidation loss: 0.380603\tBest loss: 0.378794\tAccuracy: 92.30%\n",
      "397\tValidation loss: 0.380206\tBest loss: 0.378794\tAccuracy: 92.60%\n",
      "398\tValidation loss: 0.378721\tBest loss: 0.378721\tAccuracy: 92.40%\n",
      "399\tValidation loss: 0.380428\tBest loss: 0.378721\tAccuracy: 92.40%\n",
      "400\tValidation loss: 0.379657\tBest loss: 0.378721\tAccuracy: 92.30%\n",
      "401\tValidation loss: 0.379578\tBest loss: 0.378721\tAccuracy: 92.40%\n",
      "402\tValidation loss: 0.378145\tBest loss: 0.378145\tAccuracy: 92.30%\n",
      "403\tValidation loss: 0.379232\tBest loss: 0.378145\tAccuracy: 92.40%\n",
      "404\tValidation loss: 0.379407\tBest loss: 0.378145\tAccuracy: 92.40%\n",
      "405\tValidation loss: 0.378799\tBest loss: 0.378145\tAccuracy: 92.40%\n",
      "406\tValidation loss: 0.379495\tBest loss: 0.378145\tAccuracy: 92.50%\n",
      "407\tValidation loss: 0.380631\tBest loss: 0.378145\tAccuracy: 92.40%\n",
      "408\tValidation loss: 0.378939\tBest loss: 0.378145\tAccuracy: 92.50%\n",
      "409\tValidation loss: 0.377877\tBest loss: 0.377877\tAccuracy: 92.50%\n",
      "410\tValidation loss: 0.379526\tBest loss: 0.377877\tAccuracy: 92.60%\n",
      "411\tValidation loss: 0.378220\tBest loss: 0.377877\tAccuracy: 92.40%\n",
      "412\tValidation loss: 0.378363\tBest loss: 0.377877\tAccuracy: 92.40%\n",
      "413\tValidation loss: 0.377599\tBest loss: 0.377599\tAccuracy: 92.50%\n",
      "414\tValidation loss: 0.377809\tBest loss: 0.377599\tAccuracy: 92.40%\n",
      "415\tValidation loss: 0.376993\tBest loss: 0.376993\tAccuracy: 92.50%\n",
      "416\tValidation loss: 0.377439\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "417\tValidation loss: 0.377565\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "418\tValidation loss: 0.378458\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "419\tValidation loss: 0.377590\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "420\tValidation loss: 0.377166\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "421\tValidation loss: 0.377242\tBest loss: 0.376993\tAccuracy: 92.30%\n",
      "422\tValidation loss: 0.377592\tBest loss: 0.376993\tAccuracy: 92.40%\n",
      "423\tValidation loss: 0.377939\tBest loss: 0.376993\tAccuracy: 92.50%\n",
      "424\tValidation loss: 0.376762\tBest loss: 0.376762\tAccuracy: 92.60%\n",
      "425\tValidation loss: 0.376814\tBest loss: 0.376762\tAccuracy: 92.50%\n",
      "426\tValidation loss: 0.378565\tBest loss: 0.376762\tAccuracy: 92.50%\n",
      "427\tValidation loss: 0.378768\tBest loss: 0.376762\tAccuracy: 92.70%\n",
      "428\tValidation loss: 0.377205\tBest loss: 0.376762\tAccuracy: 92.60%\n",
      "429\tValidation loss: 0.377626\tBest loss: 0.376762\tAccuracy: 92.40%\n",
      "430\tValidation loss: 0.377098\tBest loss: 0.376762\tAccuracy: 92.60%\n",
      "431\tValidation loss: 0.378559\tBest loss: 0.376762\tAccuracy: 92.60%\n",
      "432\tValidation loss: 0.377590\tBest loss: 0.376762\tAccuracy: 92.50%\n",
      "433\tValidation loss: 0.377144\tBest loss: 0.376762\tAccuracy: 92.50%\n",
      "434\tValidation loss: 0.377777\tBest loss: 0.376762\tAccuracy: 92.50%\n",
      "435\tValidation loss: 0.376897\tBest loss: 0.376762\tAccuracy: 92.40%\n",
      "436\tValidation loss: 0.378803\tBest loss: 0.376762\tAccuracy: 92.40%\n",
      "437\tValidation loss: 0.376508\tBest loss: 0.376508\tAccuracy: 92.60%\n",
      "438\tValidation loss: 0.377610\tBest loss: 0.376508\tAccuracy: 92.40%\n",
      "439\tValidation loss: 0.376155\tBest loss: 0.376155\tAccuracy: 92.60%\n",
      "440\tValidation loss: 0.376498\tBest loss: 0.376155\tAccuracy: 92.50%\n",
      "441\tValidation loss: 0.376268\tBest loss: 0.376155\tAccuracy: 92.40%\n",
      "442\tValidation loss: 0.377065\tBest loss: 0.376155\tAccuracy: 92.40%\n",
      "443\tValidation loss: 0.376493\tBest loss: 0.376155\tAccuracy: 92.40%\n",
      "444\tValidation loss: 0.376059\tBest loss: 0.376059\tAccuracy: 92.40%\n",
      "445\tValidation loss: 0.375924\tBest loss: 0.375924\tAccuracy: 92.60%\n",
      "446\tValidation loss: 0.374815\tBest loss: 0.374815\tAccuracy: 92.40%\n",
      "447\tValidation loss: 0.377147\tBest loss: 0.374815\tAccuracy: 92.40%\n",
      "448\tValidation loss: 0.375605\tBest loss: 0.374815\tAccuracy: 92.50%\n",
      "449\tValidation loss: 0.374777\tBest loss: 0.374777\tAccuracy: 92.50%\n",
      "450\tValidation loss: 0.375563\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "451\tValidation loss: 0.376148\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "452\tValidation loss: 0.375851\tBest loss: 0.374777\tAccuracy: 92.70%\n",
      "453\tValidation loss: 0.375269\tBest loss: 0.374777\tAccuracy: 92.60%\n",
      "454\tValidation loss: 0.375577\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "455\tValidation loss: 0.374907\tBest loss: 0.374777\tAccuracy: 92.50%\n",
      "456\tValidation loss: 0.375678\tBest loss: 0.374777\tAccuracy: 92.60%\n",
      "457\tValidation loss: 0.375563\tBest loss: 0.374777\tAccuracy: 92.60%\n",
      "458\tValidation loss: 0.374831\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "459\tValidation loss: 0.375093\tBest loss: 0.374777\tAccuracy: 92.30%\n",
      "460\tValidation loss: 0.375325\tBest loss: 0.374777\tAccuracy: 92.70%\n",
      "461\tValidation loss: 0.375071\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "462\tValidation loss: 0.375307\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "463\tValidation loss: 0.374860\tBest loss: 0.374777\tAccuracy: 92.40%\n",
      "464\tValidation loss: 0.374734\tBest loss: 0.374734\tAccuracy: 92.50%\n",
      "465\tValidation loss: 0.374879\tBest loss: 0.374734\tAccuracy: 92.60%\n",
      "466\tValidation loss: 0.375533\tBest loss: 0.374734\tAccuracy: 92.70%\n",
      "467\tValidation loss: 0.373251\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "468\tValidation loss: 0.375495\tBest loss: 0.373251\tAccuracy: 92.60%\n",
      "469\tValidation loss: 0.374159\tBest loss: 0.373251\tAccuracy: 92.40%\n",
      "470\tValidation loss: 0.375101\tBest loss: 0.373251\tAccuracy: 92.70%\n",
      "471\tValidation loss: 0.374960\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "472\tValidation loss: 0.374910\tBest loss: 0.373251\tAccuracy: 92.70%\n",
      "473\tValidation loss: 0.374764\tBest loss: 0.373251\tAccuracy: 92.40%\n",
      "474\tValidation loss: 0.376000\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "475\tValidation loss: 0.374590\tBest loss: 0.373251\tAccuracy: 92.40%\n",
      "476\tValidation loss: 0.374881\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "477\tValidation loss: 0.375078\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "478\tValidation loss: 0.374197\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "479\tValidation loss: 0.374219\tBest loss: 0.373251\tAccuracy: 92.50%\n",
      "480\tValidation loss: 0.375249\tBest loss: 0.373251\tAccuracy: 92.60%\n",
      "481\tValidation loss: 0.374173\tBest loss: 0.373251\tAccuracy: 92.60%\n",
      "482\tValidation loss: 0.373407\tBest loss: 0.373251\tAccuracy: 92.60%\n",
      "483\tValidation loss: 0.372777\tBest loss: 0.372777\tAccuracy: 92.60%\n",
      "484\tValidation loss: 0.373447\tBest loss: 0.372777\tAccuracy: 92.60%\n",
      "485\tValidation loss: 0.374019\tBest loss: 0.372777\tAccuracy: 92.70%\n",
      "486\tValidation loss: 0.374157\tBest loss: 0.372777\tAccuracy: 92.70%\n",
      "487\tValidation loss: 0.373540\tBest loss: 0.372777\tAccuracy: 92.60%\n",
      "488\tValidation loss: 0.374060\tBest loss: 0.372777\tAccuracy: 92.50%\n",
      "489\tValidation loss: 0.374106\tBest loss: 0.372777\tAccuracy: 92.60%\n",
      "490\tValidation loss: 0.373295\tBest loss: 0.372777\tAccuracy: 92.50%\n",
      "491\tValidation loss: 0.372985\tBest loss: 0.372777\tAccuracy: 92.50%\n",
      "492\tValidation loss: 0.373295\tBest loss: 0.372777\tAccuracy: 92.60%\n",
      "493\tValidation loss: 0.374381\tBest loss: 0.372777\tAccuracy: 92.80%\n",
      "494\tValidation loss: 0.373414\tBest loss: 0.372777\tAccuracy: 92.50%\n",
      "495\tValidation loss: 0.373633\tBest loss: 0.372777\tAccuracy: 92.50%\n",
      "496\tValidation loss: 0.372200\tBest loss: 0.372200\tAccuracy: 92.50%\n",
      "497\tValidation loss: 0.372877\tBest loss: 0.372200\tAccuracy: 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\tValidation loss: 0.373580\tBest loss: 0.372200\tAccuracy: 92.60%\n",
      "499\tValidation loss: 0.373620\tBest loss: 0.372200\tAccuracy: 92.60%\n",
      "500\tValidation loss: 0.373909\tBest loss: 0.372200\tAccuracy: 92.70%\n",
      "501\tValidation loss: 0.373277\tBest loss: 0.372200\tAccuracy: 92.60%\n",
      "502\tValidation loss: 0.373194\tBest loss: 0.372200\tAccuracy: 93.00%\n",
      "503\tValidation loss: 0.372478\tBest loss: 0.372200\tAccuracy: 92.70%\n",
      "504\tValidation loss: 0.372803\tBest loss: 0.372200\tAccuracy: 92.70%\n",
      "505\tValidation loss: 0.372910\tBest loss: 0.372200\tAccuracy: 92.70%\n",
      "506\tValidation loss: 0.373299\tBest loss: 0.372200\tAccuracy: 92.80%\n",
      "507\tValidation loss: 0.372641\tBest loss: 0.372200\tAccuracy: 92.50%\n",
      "508\tValidation loss: 0.372439\tBest loss: 0.372200\tAccuracy: 92.60%\n",
      "509\tValidation loss: 0.373623\tBest loss: 0.372200\tAccuracy: 92.70%\n",
      "510\tValidation loss: 0.372308\tBest loss: 0.372200\tAccuracy: 92.50%\n",
      "511\tValidation loss: 0.372182\tBest loss: 0.372182\tAccuracy: 92.50%\n",
      "512\tValidation loss: 0.372311\tBest loss: 0.372182\tAccuracy: 92.60%\n",
      "513\tValidation loss: 0.372956\tBest loss: 0.372182\tAccuracy: 93.00%\n",
      "514\tValidation loss: 0.372148\tBest loss: 0.372148\tAccuracy: 92.60%\n",
      "515\tValidation loss: 0.372554\tBest loss: 0.372148\tAccuracy: 92.90%\n",
      "516\tValidation loss: 0.372255\tBest loss: 0.372148\tAccuracy: 92.60%\n",
      "517\tValidation loss: 0.371628\tBest loss: 0.371628\tAccuracy: 92.60%\n",
      "518\tValidation loss: 0.373319\tBest loss: 0.371628\tAccuracy: 92.90%\n",
      "519\tValidation loss: 0.372147\tBest loss: 0.371628\tAccuracy: 92.60%\n",
      "520\tValidation loss: 0.372225\tBest loss: 0.371628\tAccuracy: 92.50%\n",
      "521\tValidation loss: 0.372406\tBest loss: 0.371628\tAccuracy: 92.90%\n",
      "522\tValidation loss: 0.372657\tBest loss: 0.371628\tAccuracy: 92.70%\n",
      "523\tValidation loss: 0.371423\tBest loss: 0.371423\tAccuracy: 92.60%\n",
      "524\tValidation loss: 0.371063\tBest loss: 0.371063\tAccuracy: 92.60%\n",
      "525\tValidation loss: 0.372846\tBest loss: 0.371063\tAccuracy: 92.70%\n",
      "526\tValidation loss: 0.371901\tBest loss: 0.371063\tAccuracy: 92.70%\n",
      "527\tValidation loss: 0.371038\tBest loss: 0.371038\tAccuracy: 92.70%\n",
      "528\tValidation loss: 0.372137\tBest loss: 0.371038\tAccuracy: 92.90%\n",
      "529\tValidation loss: 0.371286\tBest loss: 0.371038\tAccuracy: 92.80%\n",
      "530\tValidation loss: 0.371511\tBest loss: 0.371038\tAccuracy: 92.70%\n",
      "531\tValidation loss: 0.371799\tBest loss: 0.371038\tAccuracy: 92.80%\n",
      "532\tValidation loss: 0.372657\tBest loss: 0.371038\tAccuracy: 93.00%\n",
      "533\tValidation loss: 0.371567\tBest loss: 0.371038\tAccuracy: 92.90%\n",
      "534\tValidation loss: 0.371004\tBest loss: 0.371004\tAccuracy: 92.80%\n",
      "535\tValidation loss: 0.371459\tBest loss: 0.371004\tAccuracy: 92.90%\n",
      "536\tValidation loss: 0.370821\tBest loss: 0.370821\tAccuracy: 92.80%\n",
      "537\tValidation loss: 0.371389\tBest loss: 0.370821\tAccuracy: 92.90%\n",
      "538\tValidation loss: 0.372214\tBest loss: 0.370821\tAccuracy: 92.90%\n",
      "539\tValidation loss: 0.371593\tBest loss: 0.370821\tAccuracy: 92.80%\n",
      "540\tValidation loss: 0.369947\tBest loss: 0.369947\tAccuracy: 92.50%\n",
      "541\tValidation loss: 0.371506\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "542\tValidation loss: 0.371845\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "543\tValidation loss: 0.372004\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "544\tValidation loss: 0.370829\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "545\tValidation loss: 0.371222\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "546\tValidation loss: 0.371390\tBest loss: 0.369947\tAccuracy: 92.60%\n",
      "547\tValidation loss: 0.371062\tBest loss: 0.369947\tAccuracy: 93.00%\n",
      "548\tValidation loss: 0.370835\tBest loss: 0.369947\tAccuracy: 92.70%\n",
      "549\tValidation loss: 0.371625\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "550\tValidation loss: 0.370499\tBest loss: 0.369947\tAccuracy: 92.70%\n",
      "551\tValidation loss: 0.372357\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "552\tValidation loss: 0.370780\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "553\tValidation loss: 0.370326\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "554\tValidation loss: 0.371487\tBest loss: 0.369947\tAccuracy: 92.80%\n",
      "555\tValidation loss: 0.369722\tBest loss: 0.369722\tAccuracy: 92.90%\n",
      "556\tValidation loss: 0.370969\tBest loss: 0.369722\tAccuracy: 92.80%\n",
      "557\tValidation loss: 0.371428\tBest loss: 0.369722\tAccuracy: 92.80%\n",
      "558\tValidation loss: 0.370465\tBest loss: 0.369722\tAccuracy: 92.80%\n",
      "559\tValidation loss: 0.371311\tBest loss: 0.369722\tAccuracy: 92.90%\n",
      "560\tValidation loss: 0.370983\tBest loss: 0.369722\tAccuracy: 92.90%\n",
      "561\tValidation loss: 0.370828\tBest loss: 0.369722\tAccuracy: 92.80%\n",
      "562\tValidation loss: 0.370630\tBest loss: 0.369722\tAccuracy: 92.90%\n",
      "563\tValidation loss: 0.371034\tBest loss: 0.369722\tAccuracy: 93.00%\n",
      "564\tValidation loss: 0.369639\tBest loss: 0.369639\tAccuracy: 93.00%\n",
      "565\tValidation loss: 0.369652\tBest loss: 0.369639\tAccuracy: 92.80%\n",
      "566\tValidation loss: 0.370291\tBest loss: 0.369639\tAccuracy: 92.80%\n",
      "567\tValidation loss: 0.369630\tBest loss: 0.369630\tAccuracy: 92.80%\n",
      "568\tValidation loss: 0.369594\tBest loss: 0.369594\tAccuracy: 92.80%\n",
      "569\tValidation loss: 0.370938\tBest loss: 0.369594\tAccuracy: 92.70%\n",
      "570\tValidation loss: 0.370343\tBest loss: 0.369594\tAccuracy: 92.60%\n",
      "571\tValidation loss: 0.369691\tBest loss: 0.369594\tAccuracy: 92.90%\n",
      "572\tValidation loss: 0.369690\tBest loss: 0.369594\tAccuracy: 92.90%\n",
      "573\tValidation loss: 0.369143\tBest loss: 0.369143\tAccuracy: 92.90%\n",
      "574\tValidation loss: 0.370603\tBest loss: 0.369143\tAccuracy: 92.90%\n",
      "575\tValidation loss: 0.370248\tBest loss: 0.369143\tAccuracy: 92.80%\n",
      "576\tValidation loss: 0.369910\tBest loss: 0.369143\tAccuracy: 92.90%\n",
      "577\tValidation loss: 0.370382\tBest loss: 0.369143\tAccuracy: 92.80%\n",
      "578\tValidation loss: 0.371220\tBest loss: 0.369143\tAccuracy: 93.00%\n",
      "579\tValidation loss: 0.370359\tBest loss: 0.369143\tAccuracy: 92.90%\n",
      "580\tValidation loss: 0.369105\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "581\tValidation loss: 0.370223\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "582\tValidation loss: 0.370530\tBest loss: 0.369105\tAccuracy: 92.90%\n",
      "583\tValidation loss: 0.369411\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "584\tValidation loss: 0.370229\tBest loss: 0.369105\tAccuracy: 92.90%\n",
      "585\tValidation loss: 0.370158\tBest loss: 0.369105\tAccuracy: 92.90%\n",
      "586\tValidation loss: 0.369181\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "587\tValidation loss: 0.369866\tBest loss: 0.369105\tAccuracy: 92.90%\n",
      "588\tValidation loss: 0.370296\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "589\tValidation loss: 0.369649\tBest loss: 0.369105\tAccuracy: 92.80%\n",
      "590\tValidation loss: 0.368588\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "591\tValidation loss: 0.369975\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "592\tValidation loss: 0.369939\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "593\tValidation loss: 0.369270\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "594\tValidation loss: 0.368777\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "595\tValidation loss: 0.369136\tBest loss: 0.368588\tAccuracy: 92.70%\n",
      "596\tValidation loss: 0.369171\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "597\tValidation loss: 0.368808\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "598\tValidation loss: 0.369183\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "599\tValidation loss: 0.369004\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "600\tValidation loss: 0.370238\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "601\tValidation loss: 0.370166\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "602\tValidation loss: 0.369571\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "603\tValidation loss: 0.369414\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "604\tValidation loss: 0.370273\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "605\tValidation loss: 0.370307\tBest loss: 0.368588\tAccuracy: 92.80%\n",
      "606\tValidation loss: 0.368860\tBest loss: 0.368588\tAccuracy: 92.90%\n",
      "607\tValidation loss: 0.368576\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "608\tValidation loss: 0.369121\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "609\tValidation loss: 0.368631\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "610\tValidation loss: 0.368578\tBest loss: 0.368576\tAccuracy: 92.80%\n",
      "611\tValidation loss: 0.369401\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "612\tValidation loss: 0.369151\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "613\tValidation loss: 0.368591\tBest loss: 0.368576\tAccuracy: 92.80%\n",
      "614\tValidation loss: 0.369713\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "615\tValidation loss: 0.369351\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "616\tValidation loss: 0.369442\tBest loss: 0.368576\tAccuracy: 92.80%\n",
      "617\tValidation loss: 0.369499\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "618\tValidation loss: 0.368679\tBest loss: 0.368576\tAccuracy: 92.90%\n",
      "619\tValidation loss: 0.367932\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "620\tValidation loss: 0.368226\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "621\tValidation loss: 0.368819\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "622\tValidation loss: 0.369514\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "623\tValidation loss: 0.368006\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "624\tValidation loss: 0.368562\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "625\tValidation loss: 0.368794\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "626\tValidation loss: 0.368880\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "627\tValidation loss: 0.368728\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "628\tValidation loss: 0.368697\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "629\tValidation loss: 0.368102\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "630\tValidation loss: 0.368049\tBest loss: 0.367932\tAccuracy: 92.70%\n",
      "631\tValidation loss: 0.368047\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "632\tValidation loss: 0.369064\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "633\tValidation loss: 0.368499\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "634\tValidation loss: 0.368388\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "635\tValidation loss: 0.368441\tBest loss: 0.367932\tAccuracy: 92.90%\n",
      "636\tValidation loss: 0.368147\tBest loss: 0.367932\tAccuracy: 92.80%\n",
      "637\tValidation loss: 0.367789\tBest loss: 0.367789\tAccuracy: 92.90%\n",
      "638\tValidation loss: 0.367526\tBest loss: 0.367526\tAccuracy: 92.90%\n",
      "639\tValidation loss: 0.367746\tBest loss: 0.367526\tAccuracy: 92.80%\n",
      "640\tValidation loss: 0.368697\tBest loss: 0.367526\tAccuracy: 92.90%\n",
      "641\tValidation loss: 0.368564\tBest loss: 0.367526\tAccuracy: 92.80%\n",
      "642\tValidation loss: 0.369458\tBest loss: 0.367526\tAccuracy: 92.80%\n",
      "643\tValidation loss: 0.367579\tBest loss: 0.367526\tAccuracy: 92.80%\n",
      "644\tValidation loss: 0.367746\tBest loss: 0.367526\tAccuracy: 92.90%\n",
      "645\tValidation loss: 0.368259\tBest loss: 0.367526\tAccuracy: 92.90%\n",
      "646\tValidation loss: 0.368519\tBest loss: 0.367526\tAccuracy: 92.90%\n",
      "647\tValidation loss: 0.368037\tBest loss: 0.367526\tAccuracy: 92.70%\n",
      "648\tValidation loss: 0.367211\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "649\tValidation loss: 0.367910\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "650\tValidation loss: 0.368085\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "651\tValidation loss: 0.367421\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "652\tValidation loss: 0.367936\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "653\tValidation loss: 0.368013\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "654\tValidation loss: 0.368501\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "655\tValidation loss: 0.367314\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "656\tValidation loss: 0.368189\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "657\tValidation loss: 0.368004\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "658\tValidation loss: 0.368372\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "659\tValidation loss: 0.367436\tBest loss: 0.367211\tAccuracy: 92.90%\n",
      "660\tValidation loss: 0.368616\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "661\tValidation loss: 0.367692\tBest loss: 0.367211\tAccuracy: 92.80%\n",
      "662\tValidation loss: 0.367092\tBest loss: 0.367092\tAccuracy: 92.90%\n",
      "663\tValidation loss: 0.366708\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "664\tValidation loss: 0.368045\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "665\tValidation loss: 0.367735\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "666\tValidation loss: 0.367943\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "667\tValidation loss: 0.368454\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "668\tValidation loss: 0.367557\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "669\tValidation loss: 0.368468\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "670\tValidation loss: 0.368689\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "671\tValidation loss: 0.367797\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "672\tValidation loss: 0.366796\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "673\tValidation loss: 0.367703\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "674\tValidation loss: 0.368452\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "675\tValidation loss: 0.368178\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "676\tValidation loss: 0.367370\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "677\tValidation loss: 0.368021\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "678\tValidation loss: 0.368075\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "679\tValidation loss: 0.368029\tBest loss: 0.366708\tAccuracy: 92.90%\n",
      "680\tValidation loss: 0.367402\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "681\tValidation loss: 0.367707\tBest loss: 0.366708\tAccuracy: 92.80%\n",
      "682\tValidation loss: 0.366576\tBest loss: 0.366576\tAccuracy: 92.90%\n",
      "683\tValidation loss: 0.367146\tBest loss: 0.366576\tAccuracy: 92.80%\n",
      "684\tValidation loss: 0.366207\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "685\tValidation loss: 0.367513\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "686\tValidation loss: 0.367371\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "687\tValidation loss: 0.367506\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "688\tValidation loss: 0.367450\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "689\tValidation loss: 0.367248\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "690\tValidation loss: 0.368022\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "691\tValidation loss: 0.366839\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "692\tValidation loss: 0.366715\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "693\tValidation loss: 0.367515\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "694\tValidation loss: 0.367659\tBest loss: 0.366207\tAccuracy: 92.70%\n",
      "695\tValidation loss: 0.366735\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "696\tValidation loss: 0.367144\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "697\tValidation loss: 0.366786\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "698\tValidation loss: 0.366532\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "699\tValidation loss: 0.366547\tBest loss: 0.366207\tAccuracy: 92.90%\n",
      "700\tValidation loss: 0.366426\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "701\tValidation loss: 0.367621\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "702\tValidation loss: 0.366707\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "703\tValidation loss: 0.366431\tBest loss: 0.366207\tAccuracy: 92.80%\n",
      "704\tValidation loss: 0.366170\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "705\tValidation loss: 0.367546\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "706\tValidation loss: 0.367565\tBest loss: 0.366170\tAccuracy: 92.70%\n",
      "707\tValidation loss: 0.367198\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "708\tValidation loss: 0.367695\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "709\tValidation loss: 0.368057\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "710\tValidation loss: 0.367111\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "711\tValidation loss: 0.367910\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "712\tValidation loss: 0.366782\tBest loss: 0.366170\tAccuracy: 92.80%\n",
      "713\tValidation loss: 0.366228\tBest loss: 0.366170\tAccuracy: 92.90%\n",
      "714\tValidation loss: 0.365931\tBest loss: 0.365931\tAccuracy: 92.90%\n",
      "715\tValidation loss: 0.366600\tBest loss: 0.365931\tAccuracy: 92.80%\n",
      "716\tValidation loss: 0.366541\tBest loss: 0.365931\tAccuracy: 92.80%\n",
      "717\tValidation loss: 0.366378\tBest loss: 0.365931\tAccuracy: 92.80%\n",
      "718\tValidation loss: 0.366666\tBest loss: 0.365931\tAccuracy: 92.80%\n",
      "719\tValidation loss: 0.366114\tBest loss: 0.365931\tAccuracy: 92.90%\n",
      "720\tValidation loss: 0.366901\tBest loss: 0.365931\tAccuracy: 92.90%\n",
      "721\tValidation loss: 0.367046\tBest loss: 0.365931\tAccuracy: 92.90%\n",
      "722\tValidation loss: 0.365861\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "723\tValidation loss: 0.367105\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "724\tValidation loss: 0.367090\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "725\tValidation loss: 0.366677\tBest loss: 0.365861\tAccuracy: 92.90%\n",
      "726\tValidation loss: 0.366826\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "727\tValidation loss: 0.366531\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "728\tValidation loss: 0.366531\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "729\tValidation loss: 0.366602\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "730\tValidation loss: 0.366981\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "731\tValidation loss: 0.366624\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "732\tValidation loss: 0.366818\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "733\tValidation loss: 0.366763\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "734\tValidation loss: 0.366572\tBest loss: 0.365861\tAccuracy: 92.90%\n",
      "735\tValidation loss: 0.366836\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "736\tValidation loss: 0.366581\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "737\tValidation loss: 0.366184\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "738\tValidation loss: 0.367330\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "739\tValidation loss: 0.366388\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "740\tValidation loss: 0.366265\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "741\tValidation loss: 0.366100\tBest loss: 0.365861\tAccuracy: 92.80%\n",
      "742\tValidation loss: 0.366446\tBest loss: 0.365861\tAccuracy: 92.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743\tValidation loss: 0.366256\tBest loss: 0.365861\tAccuracy: 92.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=400, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total= 1.3min\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 3075.766602\tBest loss: 3075.766602\tAccuracy: 2.90%\n",
      "1\tValidation loss: 4775.121582\tBest loss: 3075.766602\tAccuracy: 1.70%\n",
      "2\tValidation loss: 2971.058838\tBest loss: 2971.058838\tAccuracy: 1.40%\n",
      "3\tValidation loss: 8594.105469\tBest loss: 2971.058838\tAccuracy: 2.50%\n",
      "4\tValidation loss: 15900.371094\tBest loss: 2971.058838\tAccuracy: 1.10%\n",
      "5\tValidation loss: 15768.256836\tBest loss: 2971.058838\tAccuracy: 2.10%\n",
      "6\tValidation loss: 29526.964844\tBest loss: 2971.058838\tAccuracy: 1.40%\n",
      "7\tValidation loss: 18189.578125\tBest loss: 2971.058838\tAccuracy: 1.60%\n",
      "8\tValidation loss: 25731.558594\tBest loss: 2971.058838\tAccuracy: 3.10%\n",
      "9\tValidation loss: 33151.812500\tBest loss: 2971.058838\tAccuracy: 2.30%\n",
      "10\tValidation loss: 80475.179688\tBest loss: 2971.058838\tAccuracy: 4.30%\n",
      "11\tValidation loss: 24337.998047\tBest loss: 2971.058838\tAccuracy: 3.30%\n",
      "12\tValidation loss: 298655.750000\tBest loss: 2971.058838\tAccuracy: 2.30%\n",
      "13\tValidation loss: 24941.962891\tBest loss: 2971.058838\tAccuracy: 3.00%\n",
      "14\tValidation loss: 22474.683594\tBest loss: 2971.058838\tAccuracy: 2.40%\n",
      "15\tValidation loss: 20379.136719\tBest loss: 2971.058838\tAccuracy: 2.00%\n",
      "16\tValidation loss: 14041.269531\tBest loss: 2971.058838\tAccuracy: 4.30%\n",
      "17\tValidation loss: 16984.728516\tBest loss: 2971.058838\tAccuracy: 2.50%\n",
      "18\tValidation loss: 9496.065430\tBest loss: 2971.058838\tAccuracy: 4.60%\n",
      "19\tValidation loss: 21029.457031\tBest loss: 2971.058838\tAccuracy: 4.20%\n",
      "20\tValidation loss: 8852.310547\tBest loss: 2971.058838\tAccuracy: 4.60%\n",
      "21\tValidation loss: 6668.947754\tBest loss: 2971.058838\tAccuracy: 4.20%\n",
      "22\tValidation loss: 11095.928711\tBest loss: 2971.058838\tAccuracy: 4.00%\n",
      "23\tValidation loss: 7435.982422\tBest loss: 2971.058838\tAccuracy: 6.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   9.2s\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 59.627342\tBest loss: 59.627342\tAccuracy: 2.00%\n",
      "1\tValidation loss: 4184.344727\tBest loss: 59.627342\tAccuracy: 1.30%\n",
      "2\tValidation loss: 8295.829102\tBest loss: 59.627342\tAccuracy: 3.00%\n",
      "3\tValidation loss: 20867.197266\tBest loss: 59.627342\tAccuracy: 1.30%\n",
      "4\tValidation loss: 13449.336914\tBest loss: 59.627342\tAccuracy: 1.00%\n",
      "5\tValidation loss: 21802.072266\tBest loss: 59.627342\tAccuracy: 1.40%\n",
      "6\tValidation loss: 9334.653320\tBest loss: 59.627342\tAccuracy: 1.70%\n",
      "7\tValidation loss: 18993.341797\tBest loss: 59.627342\tAccuracy: 1.70%\n",
      "8\tValidation loss: 18559.197266\tBest loss: 59.627342\tAccuracy: 1.50%\n",
      "9\tValidation loss: 19087.587891\tBest loss: 59.627342\tAccuracy: 1.70%\n",
      "10\tValidation loss: 24135.310547\tBest loss: 59.627342\tAccuracy: 2.10%\n",
      "11\tValidation loss: 36710.089844\tBest loss: 59.627342\tAccuracy: 3.50%\n",
      "12\tValidation loss: 48942.597656\tBest loss: 59.627342\tAccuracy: 1.40%\n",
      "13\tValidation loss: 45858.320312\tBest loss: 59.627342\tAccuracy: 1.50%\n",
      "14\tValidation loss: 43539.203125\tBest loss: 59.627342\tAccuracy: 3.20%\n",
      "15\tValidation loss: 43851.027344\tBest loss: 59.627342\tAccuracy: 2.20%\n",
      "16\tValidation loss: 59305.089844\tBest loss: 59.627342\tAccuracy: 3.00%\n",
      "17\tValidation loss: 89880.835938\tBest loss: 59.627342\tAccuracy: 1.80%\n",
      "18\tValidation loss: 52783.234375\tBest loss: 59.627342\tAccuracy: 1.50%\n",
      "19\tValidation loss: 106555.351562\tBest loss: 59.627342\tAccuracy: 1.10%\n",
      "20\tValidation loss: 76442.335938\tBest loss: 59.627342\tAccuracy: 2.50%\n",
      "21\tValidation loss: 81758.101562\tBest loss: 59.627342\tAccuracy: 1.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   8.2s\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 515.341980\tBest loss: 515.341980\tAccuracy: 0.80%\n",
      "1\tValidation loss: 10573.112305\tBest loss: 515.341980\tAccuracy: 1.40%\n",
      "2\tValidation loss: 21750.929688\tBest loss: 515.341980\tAccuracy: 1.50%\n",
      "3\tValidation loss: 168523.171875\tBest loss: 515.341980\tAccuracy: 1.50%\n",
      "4\tValidation loss: 16432.648438\tBest loss: 515.341980\tAccuracy: 1.90%\n",
      "5\tValidation loss: 20999.308594\tBest loss: 515.341980\tAccuracy: 1.20%\n",
      "6\tValidation loss: 31067.136719\tBest loss: 515.341980\tAccuracy: 3.00%\n",
      "7\tValidation loss: 36605.320312\tBest loss: 515.341980\tAccuracy: 1.10%\n",
      "8\tValidation loss: 91894.085938\tBest loss: 515.341980\tAccuracy: 2.40%\n",
      "9\tValidation loss: 103555.804688\tBest loss: 515.341980\tAccuracy: 1.60%\n",
      "10\tValidation loss: 45398.671875\tBest loss: 515.341980\tAccuracy: 1.60%\n",
      "11\tValidation loss: 106266.296875\tBest loss: 515.341980\tAccuracy: 3.10%\n",
      "12\tValidation loss: 63532.050781\tBest loss: 515.341980\tAccuracy: 3.10%\n",
      "13\tValidation loss: 78462.437500\tBest loss: 515.341980\tAccuracy: 4.90%\n",
      "14\tValidation loss: 85843.140625\tBest loss: 515.341980\tAccuracy: 3.60%\n",
      "15\tValidation loss: 152719.359375\tBest loss: 515.341980\tAccuracy: 3.90%\n",
      "16\tValidation loss: 86643.625000\tBest loss: 515.341980\tAccuracy: 2.00%\n",
      "17\tValidation loss: 71936.289062\tBest loss: 515.341980\tAccuracy: 3.60%\n",
      "18\tValidation loss: 78180.914062\tBest loss: 515.341980\tAccuracy: 2.90%\n",
      "19\tValidation loss: 47456.476562\tBest loss: 515.341980\tAccuracy: 3.80%\n",
      "20\tValidation loss: 48588.949219\tBest loss: 515.341980\tAccuracy: 3.20%\n",
      "21\tValidation loss: 25661.925781\tBest loss: 515.341980\tAccuracy: 2.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   8.2s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.944624\tBest loss: 2.944624\tAccuracy: 24.00%\n",
      "1\tValidation loss: 3.546111\tBest loss: 2.944624\tAccuracy: 23.00%\n",
      "2\tValidation loss: 2.945933\tBest loss: 2.944624\tAccuracy: 37.60%\n",
      "3\tValidation loss: 3.437745\tBest loss: 2.944624\tAccuracy: 31.30%\n",
      "4\tValidation loss: 2.365015\tBest loss: 2.365015\tAccuracy: 43.50%\n",
      "5\tValidation loss: 1.186005\tBest loss: 1.186005\tAccuracy: 66.70%\n",
      "6\tValidation loss: 1.850483\tBest loss: 1.186005\tAccuracy: 54.60%\n",
      "7\tValidation loss: 1.292821\tBest loss: 1.186005\tAccuracy: 64.90%\n",
      "8\tValidation loss: 0.787047\tBest loss: 0.787047\tAccuracy: 77.00%\n",
      "9\tValidation loss: 1.227119\tBest loss: 0.787047\tAccuracy: 69.40%\n",
      "10\tValidation loss: 0.908161\tBest loss: 0.787047\tAccuracy: 75.80%\n",
      "11\tValidation loss: 1.705269\tBest loss: 0.787047\tAccuracy: 63.80%\n",
      "12\tValidation loss: 0.694904\tBest loss: 0.694904\tAccuracy: 80.30%\n",
      "13\tValidation loss: 0.620115\tBest loss: 0.620115\tAccuracy: 83.40%\n",
      "14\tValidation loss: 1.394247\tBest loss: 0.620115\tAccuracy: 68.60%\n",
      "15\tValidation loss: 1.760994\tBest loss: 0.620115\tAccuracy: 69.20%\n",
      "16\tValidation loss: 1.802897\tBest loss: 0.620115\tAccuracy: 62.80%\n",
      "17\tValidation loss: 5.499799\tBest loss: 0.620115\tAccuracy: 50.60%\n",
      "18\tValidation loss: 0.457539\tBest loss: 0.457539\tAccuracy: 86.50%\n",
      "19\tValidation loss: 0.470389\tBest loss: 0.457539\tAccuracy: 87.30%\n",
      "20\tValidation loss: 0.450751\tBest loss: 0.450751\tAccuracy: 87.00%\n",
      "21\tValidation loss: 0.988883\tBest loss: 0.450751\tAccuracy: 82.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tValidation loss: 2.468046\tBest loss: 0.450751\tAccuracy: 75.00%\n",
      "23\tValidation loss: 0.914480\tBest loss: 0.450751\tAccuracy: 82.90%\n",
      "24\tValidation loss: 0.634503\tBest loss: 0.450751\tAccuracy: 86.60%\n",
      "25\tValidation loss: 0.799288\tBest loss: 0.450751\tAccuracy: 82.70%\n",
      "26\tValidation loss: 2.614145\tBest loss: 0.450751\tAccuracy: 73.10%\n",
      "27\tValidation loss: 0.538279\tBest loss: 0.450751\tAccuracy: 88.80%\n",
      "28\tValidation loss: 0.496541\tBest loss: 0.450751\tAccuracy: 90.60%\n",
      "29\tValidation loss: 0.569548\tBest loss: 0.450751\tAccuracy: 89.90%\n",
      "30\tValidation loss: 0.491040\tBest loss: 0.450751\tAccuracy: 90.30%\n",
      "31\tValidation loss: 0.467596\tBest loss: 0.450751\tAccuracy: 91.90%\n",
      "32\tValidation loss: 0.445579\tBest loss: 0.445579\tAccuracy: 91.10%\n",
      "33\tValidation loss: 0.593303\tBest loss: 0.445579\tAccuracy: 89.70%\n",
      "34\tValidation loss: 1.112022\tBest loss: 0.445579\tAccuracy: 87.70%\n",
      "35\tValidation loss: 0.637861\tBest loss: 0.445579\tAccuracy: 88.60%\n",
      "36\tValidation loss: 2.486202\tBest loss: 0.445579\tAccuracy: 75.10%\n",
      "37\tValidation loss: 0.829711\tBest loss: 0.445579\tAccuracy: 88.30%\n",
      "38\tValidation loss: 0.536943\tBest loss: 0.445579\tAccuracy: 92.20%\n",
      "39\tValidation loss: 0.584093\tBest loss: 0.445579\tAccuracy: 91.60%\n",
      "40\tValidation loss: 0.519662\tBest loss: 0.445579\tAccuracy: 92.60%\n",
      "41\tValidation loss: 0.647040\tBest loss: 0.445579\tAccuracy: 91.00%\n",
      "42\tValidation loss: 0.633097\tBest loss: 0.445579\tAccuracy: 92.50%\n",
      "43\tValidation loss: 0.738417\tBest loss: 0.445579\tAccuracy: 92.30%\n",
      "44\tValidation loss: 0.676429\tBest loss: 0.445579\tAccuracy: 93.00%\n",
      "45\tValidation loss: 0.814901\tBest loss: 0.445579\tAccuracy: 92.40%\n",
      "46\tValidation loss: 0.591290\tBest loss: 0.445579\tAccuracy: 92.10%\n",
      "47\tValidation loss: 0.837755\tBest loss: 0.445579\tAccuracy: 92.50%\n",
      "48\tValidation loss: 0.902903\tBest loss: 0.445579\tAccuracy: 90.10%\n",
      "49\tValidation loss: 0.960344\tBest loss: 0.445579\tAccuracy: 91.90%\n",
      "50\tValidation loss: 0.647771\tBest loss: 0.445579\tAccuracy: 93.80%\n",
      "51\tValidation loss: 0.677851\tBest loss: 0.445579\tAccuracy: 93.80%\n",
      "52\tValidation loss: 1.858427\tBest loss: 0.445579\tAccuracy: 87.10%\n",
      "53\tValidation loss: 0.832843\tBest loss: 0.445579\tAccuracy: 92.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   6.1s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.149770\tBest loss: 3.149770\tAccuracy: 25.80%\n",
      "1\tValidation loss: 2.720985\tBest loss: 2.720985\tAccuracy: 35.20%\n",
      "2\tValidation loss: 2.648618\tBest loss: 2.648618\tAccuracy: 39.00%\n",
      "3\tValidation loss: 6.411229\tBest loss: 2.648618\tAccuracy: 20.00%\n",
      "4\tValidation loss: 5.483107\tBest loss: 2.648618\tAccuracy: 25.20%\n",
      "5\tValidation loss: 7.360376\tBest loss: 2.648618\tAccuracy: 15.10%\n",
      "6\tValidation loss: 2.417511\tBest loss: 2.417511\tAccuracy: 51.00%\n",
      "7\tValidation loss: 1.104852\tBest loss: 1.104852\tAccuracy: 70.20%\n",
      "8\tValidation loss: 1.232082\tBest loss: 1.104852\tAccuracy: 68.90%\n",
      "9\tValidation loss: 0.713970\tBest loss: 0.713970\tAccuracy: 79.30%\n",
      "10\tValidation loss: 1.500913\tBest loss: 0.713970\tAccuracy: 69.00%\n",
      "11\tValidation loss: 0.617049\tBest loss: 0.617049\tAccuracy: 82.00%\n",
      "12\tValidation loss: 1.178709\tBest loss: 0.617049\tAccuracy: 75.00%\n",
      "13\tValidation loss: 1.293739\tBest loss: 0.617049\tAccuracy: 67.10%\n",
      "14\tValidation loss: 1.352391\tBest loss: 0.617049\tAccuracy: 70.40%\n",
      "15\tValidation loss: 1.900290\tBest loss: 0.617049\tAccuracy: 62.80%\n",
      "16\tValidation loss: 1.292269\tBest loss: 0.617049\tAccuracy: 69.20%\n",
      "17\tValidation loss: 1.184647\tBest loss: 0.617049\tAccuracy: 77.10%\n",
      "18\tValidation loss: 0.493112\tBest loss: 0.493112\tAccuracy: 85.80%\n",
      "19\tValidation loss: 0.551014\tBest loss: 0.493112\tAccuracy: 83.50%\n",
      "20\tValidation loss: 0.540881\tBest loss: 0.493112\tAccuracy: 86.10%\n",
      "21\tValidation loss: 0.762881\tBest loss: 0.493112\tAccuracy: 82.60%\n",
      "22\tValidation loss: 0.526317\tBest loss: 0.493112\tAccuracy: 87.30%\n",
      "23\tValidation loss: 0.468675\tBest loss: 0.468675\tAccuracy: 89.80%\n",
      "24\tValidation loss: 0.522683\tBest loss: 0.468675\tAccuracy: 89.50%\n",
      "25\tValidation loss: 0.717218\tBest loss: 0.468675\tAccuracy: 88.70%\n",
      "26\tValidation loss: 0.608845\tBest loss: 0.468675\tAccuracy: 89.20%\n",
      "27\tValidation loss: 0.479759\tBest loss: 0.468675\tAccuracy: 89.30%\n",
      "28\tValidation loss: 1.523611\tBest loss: 0.468675\tAccuracy: 82.00%\n",
      "29\tValidation loss: 1.275278\tBest loss: 0.468675\tAccuracy: 80.50%\n",
      "30\tValidation loss: 0.837332\tBest loss: 0.468675\tAccuracy: 84.30%\n",
      "31\tValidation loss: 0.548262\tBest loss: 0.468675\tAccuracy: 89.80%\n",
      "32\tValidation loss: 0.600572\tBest loss: 0.468675\tAccuracy: 90.30%\n",
      "33\tValidation loss: 0.731842\tBest loss: 0.468675\tAccuracy: 89.00%\n",
      "34\tValidation loss: 0.547786\tBest loss: 0.468675\tAccuracy: 92.60%\n",
      "35\tValidation loss: 0.515752\tBest loss: 0.468675\tAccuracy: 92.70%\n",
      "36\tValidation loss: 0.521311\tBest loss: 0.468675\tAccuracy: 92.30%\n",
      "37\tValidation loss: 0.642216\tBest loss: 0.468675\tAccuracy: 92.00%\n",
      "38\tValidation loss: 0.859979\tBest loss: 0.468675\tAccuracy: 90.90%\n",
      "39\tValidation loss: 1.550555\tBest loss: 0.468675\tAccuracy: 83.50%\n",
      "40\tValidation loss: 2.468071\tBest loss: 0.468675\tAccuracy: 77.30%\n",
      "41\tValidation loss: 0.714598\tBest loss: 0.468675\tAccuracy: 91.10%\n",
      "42\tValidation loss: 0.778477\tBest loss: 0.468675\tAccuracy: 90.60%\n",
      "43\tValidation loss: 3.798459\tBest loss: 0.468675\tAccuracy: 75.70%\n",
      "44\tValidation loss: 1.583068\tBest loss: 0.468675\tAccuracy: 83.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   5.3s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.355760\tBest loss: 3.355760\tAccuracy: 19.30%\n",
      "1\tValidation loss: 2.863069\tBest loss: 2.863069\tAccuracy: 33.00%\n",
      "2\tValidation loss: 6.435414\tBest loss: 2.863069\tAccuracy: 21.10%\n",
      "3\tValidation loss: 10.574477\tBest loss: 2.863069\tAccuracy: 17.40%\n",
      "4\tValidation loss: 2.965153\tBest loss: 2.863069\tAccuracy: 42.70%\n",
      "5\tValidation loss: 3.841075\tBest loss: 2.863069\tAccuracy: 42.00%\n",
      "6\tValidation loss: 3.252078\tBest loss: 2.863069\tAccuracy: 47.40%\n",
      "7\tValidation loss: 2.623923\tBest loss: 2.623923\tAccuracy: 50.00%\n",
      "8\tValidation loss: 1.204307\tBest loss: 1.204307\tAccuracy: 68.90%\n",
      "9\tValidation loss: 2.223043\tBest loss: 1.204307\tAccuracy: 58.40%\n",
      "10\tValidation loss: 2.337511\tBest loss: 1.204307\tAccuracy: 53.70%\n",
      "11\tValidation loss: 1.346883\tBest loss: 1.204307\tAccuracy: 66.20%\n",
      "12\tValidation loss: 4.910673\tBest loss: 1.204307\tAccuracy: 41.90%\n",
      "13\tValidation loss: 4.939299\tBest loss: 1.204307\tAccuracy: 56.90%\n",
      "14\tValidation loss: 2.288853\tBest loss: 1.204307\tAccuracy: 63.60%\n",
      "15\tValidation loss: 4.051472\tBest loss: 1.204307\tAccuracy: 50.10%\n",
      "16\tValidation loss: 0.600030\tBest loss: 0.600030\tAccuracy: 84.00%\n",
      "17\tValidation loss: 0.728402\tBest loss: 0.600030\tAccuracy: 83.70%\n",
      "18\tValidation loss: 1.043850\tBest loss: 0.600030\tAccuracy: 81.00%\n",
      "19\tValidation loss: 1.129767\tBest loss: 0.600030\tAccuracy: 77.20%\n",
      "20\tValidation loss: 0.565940\tBest loss: 0.565940\tAccuracy: 86.70%\n",
      "21\tValidation loss: 0.558016\tBest loss: 0.558016\tAccuracy: 87.40%\n",
      "22\tValidation loss: 2.297438\tBest loss: 0.558016\tAccuracy: 68.40%\n",
      "23\tValidation loss: 0.770992\tBest loss: 0.558016\tAccuracy: 85.20%\n",
      "24\tValidation loss: 0.442102\tBest loss: 0.442102\tAccuracy: 89.10%\n",
      "25\tValidation loss: 1.448718\tBest loss: 0.442102\tAccuracy: 77.50%\n",
      "26\tValidation loss: 1.157658\tBest loss: 0.442102\tAccuracy: 83.30%\n",
      "27\tValidation loss: 0.640647\tBest loss: 0.442102\tAccuracy: 88.50%\n",
      "28\tValidation loss: 0.676055\tBest loss: 0.442102\tAccuracy: 89.00%\n",
      "29\tValidation loss: 1.976995\tBest loss: 0.442102\tAccuracy: 76.80%\n",
      "30\tValidation loss: 0.625941\tBest loss: 0.442102\tAccuracy: 89.80%\n",
      "31\tValidation loss: 0.684563\tBest loss: 0.442102\tAccuracy: 88.60%\n",
      "32\tValidation loss: 1.065348\tBest loss: 0.442102\tAccuracy: 85.30%\n",
      "33\tValidation loss: 0.674846\tBest loss: 0.442102\tAccuracy: 90.90%\n",
      "34\tValidation loss: 0.701954\tBest loss: 0.442102\tAccuracy: 90.80%\n",
      "35\tValidation loss: 0.899333\tBest loss: 0.442102\tAccuracy: 88.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\tValidation loss: 1.102148\tBest loss: 0.442102\tAccuracy: 88.50%\n",
      "37\tValidation loss: 0.757845\tBest loss: 0.442102\tAccuracy: 91.70%\n",
      "38\tValidation loss: 0.746958\tBest loss: 0.442102\tAccuracy: 90.70%\n",
      "39\tValidation loss: 0.599628\tBest loss: 0.442102\tAccuracy: 90.90%\n",
      "40\tValidation loss: 0.605121\tBest loss: 0.442102\tAccuracy: 92.20%\n",
      "41\tValidation loss: 0.736009\tBest loss: 0.442102\tAccuracy: 90.70%\n",
      "42\tValidation loss: 0.880041\tBest loss: 0.442102\tAccuracy: 91.20%\n",
      "43\tValidation loss: 1.119045\tBest loss: 0.442102\tAccuracy: 89.20%\n",
      "44\tValidation loss: 1.106152\tBest loss: 0.442102\tAccuracy: 88.80%\n",
      "45\tValidation loss: 0.771727\tBest loss: 0.442102\tAccuracy: 91.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   5.3s\n",
      "[CV] batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.197859\tBest loss: 3.197859\tAccuracy: 19.20%\n",
      "1\tValidation loss: 2.806997\tBest loss: 2.806997\tAccuracy: 36.40%\n",
      "2\tValidation loss: 1.776440\tBest loss: 1.776440\tAccuracy: 46.50%\n",
      "3\tValidation loss: 2.331857\tBest loss: 1.776440\tAccuracy: 56.20%\n",
      "4\tValidation loss: 2.489861\tBest loss: 1.776440\tAccuracy: 52.30%\n",
      "5\tValidation loss: 1.039748\tBest loss: 1.039748\tAccuracy: 69.80%\n",
      "6\tValidation loss: 1.475373\tBest loss: 1.039748\tAccuracy: 67.30%\n",
      "7\tValidation loss: 1.461597\tBest loss: 1.039748\tAccuracy: 72.70%\n",
      "8\tValidation loss: 1.296881\tBest loss: 1.039748\tAccuracy: 74.50%\n",
      "9\tValidation loss: 2.041660\tBest loss: 1.039748\tAccuracy: 67.00%\n",
      "10\tValidation loss: 1.797056\tBest loss: 1.039748\tAccuracy: 72.20%\n",
      "11\tValidation loss: 1.709538\tBest loss: 1.039748\tAccuracy: 71.50%\n",
      "12\tValidation loss: 1.524070\tBest loss: 1.039748\tAccuracy: 74.40%\n",
      "13\tValidation loss: 1.043200\tBest loss: 1.039748\tAccuracy: 76.20%\n",
      "14\tValidation loss: 1.659081\tBest loss: 1.039748\tAccuracy: 73.70%\n",
      "15\tValidation loss: 2.059187\tBest loss: 1.039748\tAccuracy: 69.30%\n",
      "16\tValidation loss: 1.764007\tBest loss: 1.039748\tAccuracy: 72.50%\n",
      "17\tValidation loss: 1.542322\tBest loss: 1.039748\tAccuracy: 77.60%\n",
      "18\tValidation loss: 1.220000\tBest loss: 1.039748\tAccuracy: 79.10%\n",
      "19\tValidation loss: 2.617178\tBest loss: 1.039748\tAccuracy: 74.90%\n",
      "20\tValidation loss: 4.251783\tBest loss: 1.039748\tAccuracy: 63.90%\n",
      "21\tValidation loss: 2.860965\tBest loss: 1.039748\tAccuracy: 73.40%\n",
      "22\tValidation loss: 1.487863\tBest loss: 1.039748\tAccuracy: 77.20%\n",
      "23\tValidation loss: 1.855639\tBest loss: 1.039748\tAccuracy: 77.50%\n",
      "24\tValidation loss: 1.814937\tBest loss: 1.039748\tAccuracy: 81.80%\n",
      "25\tValidation loss: 2.606538\tBest loss: 1.039748\tAccuracy: 77.60%\n",
      "26\tValidation loss: 4.377844\tBest loss: 1.039748\tAccuracy: 75.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   9.7s\n",
      "[CV] batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.604736\tBest loss: 3.604736\tAccuracy: 21.30%\n",
      "1\tValidation loss: 6.195430\tBest loss: 3.604736\tAccuracy: 19.80%\n",
      "2\tValidation loss: 1.823485\tBest loss: 1.823485\tAccuracy: 49.70%\n",
      "3\tValidation loss: 1.048959\tBest loss: 1.048959\tAccuracy: 71.20%\n",
      "4\tValidation loss: 2.124933\tBest loss: 1.048959\tAccuracy: 57.90%\n",
      "5\tValidation loss: 1.209055\tBest loss: 1.048959\tAccuracy: 72.40%\n",
      "6\tValidation loss: 1.896192\tBest loss: 1.048959\tAccuracy: 63.40%\n",
      "7\tValidation loss: 1.235676\tBest loss: 1.048959\tAccuracy: 68.90%\n",
      "8\tValidation loss: 2.258718\tBest loss: 1.048959\tAccuracy: 66.80%\n",
      "9\tValidation loss: 1.276965\tBest loss: 1.048959\tAccuracy: 70.50%\n",
      "10\tValidation loss: 1.608331\tBest loss: 1.048959\tAccuracy: 73.70%\n",
      "11\tValidation loss: 1.520409\tBest loss: 1.048959\tAccuracy: 72.90%\n",
      "12\tValidation loss: 0.996144\tBest loss: 0.996144\tAccuracy: 77.70%\n",
      "13\tValidation loss: 1.659518\tBest loss: 0.996144\tAccuracy: 71.20%\n",
      "14\tValidation loss: 2.658333\tBest loss: 0.996144\tAccuracy: 73.40%\n",
      "15\tValidation loss: 0.975584\tBest loss: 0.975584\tAccuracy: 81.10%\n",
      "16\tValidation loss: 1.620244\tBest loss: 0.975584\tAccuracy: 77.50%\n",
      "17\tValidation loss: 2.382537\tBest loss: 0.975584\tAccuracy: 74.80%\n",
      "18\tValidation loss: 1.372478\tBest loss: 0.975584\tAccuracy: 81.40%\n",
      "19\tValidation loss: 2.222572\tBest loss: 0.975584\tAccuracy: 73.10%\n",
      "20\tValidation loss: 3.617668\tBest loss: 0.975584\tAccuracy: 73.90%\n",
      "21\tValidation loss: 1.392285\tBest loss: 0.975584\tAccuracy: 80.20%\n",
      "22\tValidation loss: 8.951865\tBest loss: 0.975584\tAccuracy: 68.40%\n",
      "23\tValidation loss: 1.667322\tBest loss: 0.975584\tAccuracy: 82.90%\n",
      "24\tValidation loss: 2.649496\tBest loss: 0.975584\tAccuracy: 76.50%\n",
      "25\tValidation loss: 3.258873\tBest loss: 0.975584\tAccuracy: 81.50%\n",
      "26\tValidation loss: 1.799293\tBest loss: 0.975584\tAccuracy: 82.50%\n",
      "27\tValidation loss: 2.691334\tBest loss: 0.975584\tAccuracy: 82.50%\n",
      "28\tValidation loss: 4.829028\tBest loss: 0.975584\tAccuracy: 76.00%\n",
      "29\tValidation loss: 7.408401\tBest loss: 0.975584\tAccuracy: 74.30%\n",
      "30\tValidation loss: 16.134201\tBest loss: 0.975584\tAccuracy: 67.90%\n",
      "31\tValidation loss: 2.845695\tBest loss: 0.975584\tAccuracy: 79.40%\n",
      "32\tValidation loss: 6.194483\tBest loss: 0.975584\tAccuracy: 77.30%\n",
      "33\tValidation loss: 16.270166\tBest loss: 0.975584\tAccuracy: 67.20%\n",
      "34\tValidation loss: 2.046885\tBest loss: 0.975584\tAccuracy: 84.00%\n",
      "35\tValidation loss: 11.944584\tBest loss: 0.975584\tAccuracy: 68.70%\n",
      "36\tValidation loss: 3.699206\tBest loss: 0.975584\tAccuracy: 82.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=  13.0s\n",
      "[CV] batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.288764\tBest loss: 3.288764\tAccuracy: 19.80%\n",
      "1\tValidation loss: 2.106819\tBest loss: 2.106819\tAccuracy: 44.50%\n",
      "2\tValidation loss: 1.883054\tBest loss: 1.883054\tAccuracy: 55.90%\n",
      "3\tValidation loss: 2.106948\tBest loss: 1.883054\tAccuracy: 57.80%\n",
      "4\tValidation loss: 1.803679\tBest loss: 1.803679\tAccuracy: 63.10%\n",
      "5\tValidation loss: 2.016139\tBest loss: 1.803679\tAccuracy: 58.40%\n",
      "6\tValidation loss: 1.498252\tBest loss: 1.498252\tAccuracy: 69.00%\n",
      "7\tValidation loss: 2.271132\tBest loss: 1.498252\tAccuracy: 64.40%\n",
      "8\tValidation loss: 1.361581\tBest loss: 1.361581\tAccuracy: 72.60%\n",
      "9\tValidation loss: 1.560905\tBest loss: 1.361581\tAccuracy: 73.30%\n",
      "10\tValidation loss: 4.462920\tBest loss: 1.361581\tAccuracy: 63.60%\n",
      "11\tValidation loss: 1.795469\tBest loss: 1.361581\tAccuracy: 69.80%\n",
      "12\tValidation loss: 0.890596\tBest loss: 0.890596\tAccuracy: 81.90%\n",
      "13\tValidation loss: 1.384497\tBest loss: 0.890596\tAccuracy: 74.20%\n",
      "14\tValidation loss: 1.437288\tBest loss: 0.890596\tAccuracy: 78.10%\n",
      "15\tValidation loss: 1.189361\tBest loss: 0.890596\tAccuracy: 79.70%\n",
      "16\tValidation loss: 1.312710\tBest loss: 0.890596\tAccuracy: 74.90%\n",
      "17\tValidation loss: 3.541288\tBest loss: 0.890596\tAccuracy: 74.00%\n",
      "18\tValidation loss: 1.580492\tBest loss: 0.890596\tAccuracy: 76.60%\n",
      "19\tValidation loss: 1.996692\tBest loss: 0.890596\tAccuracy: 79.30%\n",
      "20\tValidation loss: 1.568137\tBest loss: 0.890596\tAccuracy: 76.00%\n",
      "21\tValidation loss: 2.201087\tBest loss: 0.890596\tAccuracy: 77.60%\n",
      "22\tValidation loss: 2.428666\tBest loss: 0.890596\tAccuracy: 69.50%\n",
      "23\tValidation loss: 1.821112\tBest loss: 0.890596\tAccuracy: 77.00%\n",
      "24\tValidation loss: 3.165292\tBest loss: 0.890596\tAccuracy: 76.90%\n",
      "25\tValidation loss: 4.987618\tBest loss: 0.890596\tAccuracy: 74.70%\n",
      "26\tValidation loss: 2.649856\tBest loss: 0.890596\tAccuracy: 77.80%\n",
      "27\tValidation loss: 4.204782\tBest loss: 0.890596\tAccuracy: 79.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 2.049709\tBest loss: 0.890596\tAccuracy: 80.60%\n",
      "29\tValidation loss: 2.695688\tBest loss: 0.890596\tAccuracy: 79.70%\n",
      "30\tValidation loss: 2.524346\tBest loss: 0.890596\tAccuracy: 75.20%\n",
      "31\tValidation loss: 3.825193\tBest loss: 0.890596\tAccuracy: 76.50%\n",
      "32\tValidation loss: 2.762280\tBest loss: 0.890596\tAccuracy: 77.40%\n",
      "33\tValidation loss: 4.828418\tBest loss: 0.890596\tAccuracy: 77.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=  11.9s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.134111\tBest loss: 2.134111\tAccuracy: 61.50%\n",
      "1\tValidation loss: 0.909108\tBest loss: 0.909108\tAccuracy: 79.50%\n",
      "2\tValidation loss: 0.616560\tBest loss: 0.616560\tAccuracy: 84.60%\n",
      "3\tValidation loss: 0.569072\tBest loss: 0.569072\tAccuracy: 86.60%\n",
      "4\tValidation loss: 0.539033\tBest loss: 0.539033\tAccuracy: 86.70%\n",
      "5\tValidation loss: 0.513256\tBest loss: 0.513256\tAccuracy: 87.90%\n",
      "6\tValidation loss: 0.501450\tBest loss: 0.501450\tAccuracy: 87.70%\n",
      "7\tValidation loss: 0.489464\tBest loss: 0.489464\tAccuracy: 88.30%\n",
      "8\tValidation loss: 0.509271\tBest loss: 0.489464\tAccuracy: 87.70%\n",
      "9\tValidation loss: 0.524853\tBest loss: 0.489464\tAccuracy: 87.90%\n",
      "10\tValidation loss: 0.436348\tBest loss: 0.436348\tAccuracy: 89.70%\n",
      "11\tValidation loss: 0.439278\tBest loss: 0.436348\tAccuracy: 90.00%\n",
      "12\tValidation loss: 0.445280\tBest loss: 0.436348\tAccuracy: 90.70%\n",
      "13\tValidation loss: 0.433834\tBest loss: 0.433834\tAccuracy: 90.50%\n",
      "14\tValidation loss: 0.436922\tBest loss: 0.433834\tAccuracy: 91.20%\n",
      "15\tValidation loss: 0.454574\tBest loss: 0.433834\tAccuracy: 89.90%\n",
      "16\tValidation loss: 0.448795\tBest loss: 0.433834\tAccuracy: 89.30%\n",
      "17\tValidation loss: 0.413693\tBest loss: 0.413693\tAccuracy: 90.60%\n",
      "18\tValidation loss: 0.437308\tBest loss: 0.413693\tAccuracy: 90.10%\n",
      "19\tValidation loss: 0.428746\tBest loss: 0.413693\tAccuracy: 91.00%\n",
      "20\tValidation loss: 0.415979\tBest loss: 0.413693\tAccuracy: 90.80%\n",
      "21\tValidation loss: 0.489794\tBest loss: 0.413693\tAccuracy: 90.50%\n",
      "22\tValidation loss: 0.413195\tBest loss: 0.413195\tAccuracy: 90.80%\n",
      "23\tValidation loss: 0.402757\tBest loss: 0.402757\tAccuracy: 91.20%\n",
      "24\tValidation loss: 0.476563\tBest loss: 0.402757\tAccuracy: 91.00%\n",
      "25\tValidation loss: 0.484844\tBest loss: 0.402757\tAccuracy: 90.40%\n",
      "26\tValidation loss: 0.488849\tBest loss: 0.402757\tAccuracy: 91.00%\n",
      "27\tValidation loss: 0.501812\tBest loss: 0.402757\tAccuracy: 90.50%\n",
      "28\tValidation loss: 0.437445\tBest loss: 0.402757\tAccuracy: 90.90%\n",
      "29\tValidation loss: 0.478335\tBest loss: 0.402757\tAccuracy: 90.80%\n",
      "30\tValidation loss: 0.488080\tBest loss: 0.402757\tAccuracy: 90.30%\n",
      "31\tValidation loss: 0.467256\tBest loss: 0.402757\tAccuracy: 91.00%\n",
      "32\tValidation loss: 0.435678\tBest loss: 0.402757\tAccuracy: 91.60%\n",
      "33\tValidation loss: 0.578269\tBest loss: 0.402757\tAccuracy: 90.50%\n",
      "34\tValidation loss: 0.537333\tBest loss: 0.402757\tAccuracy: 91.20%\n",
      "35\tValidation loss: 0.489274\tBest loss: 0.402757\tAccuracy: 91.40%\n",
      "36\tValidation loss: 0.488348\tBest loss: 0.402757\tAccuracy: 92.30%\n",
      "37\tValidation loss: 0.550033\tBest loss: 0.402757\tAccuracy: 90.30%\n",
      "38\tValidation loss: 0.496369\tBest loss: 0.402757\tAccuracy: 90.00%\n",
      "39\tValidation loss: 0.537201\tBest loss: 0.402757\tAccuracy: 91.00%\n",
      "40\tValidation loss: 0.695020\tBest loss: 0.402757\tAccuracy: 88.50%\n",
      "41\tValidation loss: 0.463071\tBest loss: 0.402757\tAccuracy: 91.50%\n",
      "42\tValidation loss: 0.463581\tBest loss: 0.402757\tAccuracy: 92.20%\n",
      "43\tValidation loss: 0.619581\tBest loss: 0.402757\tAccuracy: 89.50%\n",
      "44\tValidation loss: 0.490167\tBest loss: 0.402757\tAccuracy: 90.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.3s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.294550\tBest loss: 2.294550\tAccuracy: 63.70%\n",
      "1\tValidation loss: 0.893706\tBest loss: 0.893706\tAccuracy: 80.00%\n",
      "2\tValidation loss: 0.650181\tBest loss: 0.650181\tAccuracy: 84.00%\n",
      "3\tValidation loss: 0.613464\tBest loss: 0.613464\tAccuracy: 85.50%\n",
      "4\tValidation loss: 0.604627\tBest loss: 0.604627\tAccuracy: 86.10%\n",
      "5\tValidation loss: 0.580357\tBest loss: 0.580357\tAccuracy: 85.90%\n",
      "6\tValidation loss: 0.493305\tBest loss: 0.493305\tAccuracy: 89.10%\n",
      "7\tValidation loss: 0.497428\tBest loss: 0.493305\tAccuracy: 89.00%\n",
      "8\tValidation loss: 0.481398\tBest loss: 0.481398\tAccuracy: 89.90%\n",
      "9\tValidation loss: 0.462807\tBest loss: 0.462807\tAccuracy: 89.40%\n",
      "10\tValidation loss: 0.518228\tBest loss: 0.462807\tAccuracy: 89.10%\n",
      "11\tValidation loss: 0.523106\tBest loss: 0.462807\tAccuracy: 88.30%\n",
      "12\tValidation loss: 0.485081\tBest loss: 0.462807\tAccuracy: 88.90%\n",
      "13\tValidation loss: 0.456319\tBest loss: 0.456319\tAccuracy: 91.00%\n",
      "14\tValidation loss: 0.489963\tBest loss: 0.456319\tAccuracy: 89.60%\n",
      "15\tValidation loss: 0.517311\tBest loss: 0.456319\tAccuracy: 90.10%\n",
      "16\tValidation loss: 0.502315\tBest loss: 0.456319\tAccuracy: 89.60%\n",
      "17\tValidation loss: 0.498534\tBest loss: 0.456319\tAccuracy: 90.30%\n",
      "18\tValidation loss: 0.467787\tBest loss: 0.456319\tAccuracy: 90.60%\n",
      "19\tValidation loss: 0.486704\tBest loss: 0.456319\tAccuracy: 89.90%\n",
      "20\tValidation loss: 0.487136\tBest loss: 0.456319\tAccuracy: 90.70%\n",
      "21\tValidation loss: 0.522900\tBest loss: 0.456319\tAccuracy: 90.20%\n",
      "22\tValidation loss: 0.483012\tBest loss: 0.456319\tAccuracy: 91.00%\n",
      "23\tValidation loss: 0.500530\tBest loss: 0.456319\tAccuracy: 90.80%\n",
      "24\tValidation loss: 0.527938\tBest loss: 0.456319\tAccuracy: 91.50%\n",
      "25\tValidation loss: 0.495256\tBest loss: 0.456319\tAccuracy: 91.30%\n",
      "26\tValidation loss: 0.484109\tBest loss: 0.456319\tAccuracy: 91.60%\n",
      "27\tValidation loss: 0.479658\tBest loss: 0.456319\tAccuracy: 90.90%\n",
      "28\tValidation loss: 0.478980\tBest loss: 0.456319\tAccuracy: 91.30%\n",
      "29\tValidation loss: 0.491143\tBest loss: 0.456319\tAccuracy: 90.90%\n",
      "30\tValidation loss: 0.533946\tBest loss: 0.456319\tAccuracy: 90.30%\n",
      "31\tValidation loss: 0.531667\tBest loss: 0.456319\tAccuracy: 91.10%\n",
      "32\tValidation loss: 0.487964\tBest loss: 0.456319\tAccuracy: 92.40%\n",
      "33\tValidation loss: 0.584606\tBest loss: 0.456319\tAccuracy: 90.10%\n",
      "34\tValidation loss: 0.647741\tBest loss: 0.456319\tAccuracy: 91.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   3.4s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.130904\tBest loss: 2.130904\tAccuracy: 62.40%\n",
      "1\tValidation loss: 0.887878\tBest loss: 0.887878\tAccuracy: 79.30%\n",
      "2\tValidation loss: 0.719082\tBest loss: 0.719082\tAccuracy: 82.60%\n",
      "3\tValidation loss: 0.575011\tBest loss: 0.575011\tAccuracy: 86.00%\n",
      "4\tValidation loss: 0.559172\tBest loss: 0.559172\tAccuracy: 86.40%\n",
      "5\tValidation loss: 0.569655\tBest loss: 0.559172\tAccuracy: 87.50%\n",
      "6\tValidation loss: 0.544142\tBest loss: 0.544142\tAccuracy: 87.40%\n",
      "7\tValidation loss: 0.478718\tBest loss: 0.478718\tAccuracy: 88.40%\n",
      "8\tValidation loss: 0.476845\tBest loss: 0.476845\tAccuracy: 88.70%\n",
      "9\tValidation loss: 0.470473\tBest loss: 0.470473\tAccuracy: 89.20%\n",
      "10\tValidation loss: 0.454590\tBest loss: 0.454590\tAccuracy: 89.60%\n",
      "11\tValidation loss: 0.445948\tBest loss: 0.445948\tAccuracy: 90.60%\n",
      "12\tValidation loss: 0.499991\tBest loss: 0.445948\tAccuracy: 89.10%\n",
      "13\tValidation loss: 0.462032\tBest loss: 0.445948\tAccuracy: 89.30%\n",
      "14\tValidation loss: 0.440902\tBest loss: 0.440902\tAccuracy: 90.70%\n",
      "15\tValidation loss: 0.441005\tBest loss: 0.440902\tAccuracy: 90.80%\n",
      "16\tValidation loss: 0.444494\tBest loss: 0.440902\tAccuracy: 91.40%\n",
      "17\tValidation loss: 0.456935\tBest loss: 0.440902\tAccuracy: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 0.419559\tBest loss: 0.419559\tAccuracy: 91.40%\n",
      "19\tValidation loss: 0.441726\tBest loss: 0.419559\tAccuracy: 90.90%\n",
      "20\tValidation loss: 0.468423\tBest loss: 0.419559\tAccuracy: 90.10%\n",
      "21\tValidation loss: 0.490968\tBest loss: 0.419559\tAccuracy: 90.30%\n",
      "22\tValidation loss: 0.494410\tBest loss: 0.419559\tAccuracy: 90.10%\n",
      "23\tValidation loss: 0.602513\tBest loss: 0.419559\tAccuracy: 88.70%\n",
      "24\tValidation loss: 0.532617\tBest loss: 0.419559\tAccuracy: 88.90%\n",
      "25\tValidation loss: 0.468464\tBest loss: 0.419559\tAccuracy: 91.00%\n",
      "26\tValidation loss: 0.480398\tBest loss: 0.419559\tAccuracy: 91.60%\n",
      "27\tValidation loss: 0.494395\tBest loss: 0.419559\tAccuracy: 91.10%\n",
      "28\tValidation loss: 0.443151\tBest loss: 0.419559\tAccuracy: 91.70%\n",
      "29\tValidation loss: 0.476992\tBest loss: 0.419559\tAccuracy: 90.30%\n",
      "30\tValidation loss: 0.411206\tBest loss: 0.411206\tAccuracy: 91.80%\n",
      "31\tValidation loss: 0.424871\tBest loss: 0.411206\tAccuracy: 91.30%\n",
      "32\tValidation loss: 0.440289\tBest loss: 0.411206\tAccuracy: 92.00%\n",
      "33\tValidation loss: 0.492924\tBest loss: 0.411206\tAccuracy: 91.00%\n",
      "34\tValidation loss: 0.456239\tBest loss: 0.411206\tAccuracy: 91.90%\n",
      "35\tValidation loss: 0.447560\tBest loss: 0.411206\tAccuracy: 91.70%\n",
      "36\tValidation loss: 0.557627\tBest loss: 0.411206\tAccuracy: 90.50%\n",
      "37\tValidation loss: 0.489521\tBest loss: 0.411206\tAccuracy: 91.60%\n",
      "38\tValidation loss: 0.428165\tBest loss: 0.411206\tAccuracy: 92.10%\n",
      "39\tValidation loss: 0.454454\tBest loss: 0.411206\tAccuracy: 92.40%\n",
      "40\tValidation loss: 0.474174\tBest loss: 0.411206\tAccuracy: 91.80%\n",
      "41\tValidation loss: 0.489464\tBest loss: 0.411206\tAccuracy: 92.00%\n",
      "42\tValidation loss: 0.462705\tBest loss: 0.411206\tAccuracy: 92.40%\n",
      "43\tValidation loss: 0.465827\tBest loss: 0.411206\tAccuracy: 92.70%\n",
      "44\tValidation loss: 0.465067\tBest loss: 0.411206\tAccuracy: 93.40%\n",
      "45\tValidation loss: 0.470795\tBest loss: 0.411206\tAccuracy: 92.20%\n",
      "46\tValidation loss: 0.532283\tBest loss: 0.411206\tAccuracy: 92.30%\n",
      "47\tValidation loss: 0.473295\tBest loss: 0.411206\tAccuracy: 92.60%\n",
      "48\tValidation loss: 0.472931\tBest loss: 0.411206\tAccuracy: 93.40%\n",
      "49\tValidation loss: 0.553290\tBest loss: 0.411206\tAccuracy: 91.90%\n",
      "50\tValidation loss: 0.486732\tBest loss: 0.411206\tAccuracy: 92.50%\n",
      "51\tValidation loss: 0.481128\tBest loss: 0.411206\tAccuracy: 92.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   5.2s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.914080\tBest loss: 1.914080\tAccuracy: 51.30%\n",
      "1\tValidation loss: 1.235197\tBest loss: 1.235197\tAccuracy: 68.00%\n",
      "2\tValidation loss: 0.964259\tBest loss: 0.964259\tAccuracy: 76.00%\n",
      "3\tValidation loss: 0.776238\tBest loss: 0.776238\tAccuracy: 81.30%\n",
      "4\tValidation loss: 0.781408\tBest loss: 0.776238\tAccuracy: 81.20%\n",
      "5\tValidation loss: 0.619346\tBest loss: 0.619346\tAccuracy: 84.20%\n",
      "6\tValidation loss: 0.543801\tBest loss: 0.543801\tAccuracy: 86.60%\n",
      "7\tValidation loss: 0.602416\tBest loss: 0.543801\tAccuracy: 84.70%\n",
      "8\tValidation loss: 0.571659\tBest loss: 0.543801\tAccuracy: 85.60%\n",
      "9\tValidation loss: 0.534423\tBest loss: 0.534423\tAccuracy: 86.90%\n",
      "10\tValidation loss: 0.568936\tBest loss: 0.534423\tAccuracy: 86.20%\n",
      "11\tValidation loss: 0.460590\tBest loss: 0.460590\tAccuracy: 88.50%\n",
      "12\tValidation loss: 0.494448\tBest loss: 0.460590\tAccuracy: 88.40%\n",
      "13\tValidation loss: 0.404947\tBest loss: 0.404947\tAccuracy: 90.60%\n",
      "14\tValidation loss: 0.452298\tBest loss: 0.404947\tAccuracy: 88.60%\n",
      "15\tValidation loss: 0.492470\tBest loss: 0.404947\tAccuracy: 88.30%\n",
      "16\tValidation loss: 0.490981\tBest loss: 0.404947\tAccuracy: 88.90%\n",
      "17\tValidation loss: 0.414979\tBest loss: 0.404947\tAccuracy: 90.10%\n",
      "18\tValidation loss: 0.392770\tBest loss: 0.392770\tAccuracy: 91.00%\n",
      "19\tValidation loss: 0.459994\tBest loss: 0.392770\tAccuracy: 89.60%\n",
      "20\tValidation loss: 0.433923\tBest loss: 0.392770\tAccuracy: 90.80%\n",
      "21\tValidation loss: 0.436147\tBest loss: 0.392770\tAccuracy: 90.70%\n",
      "22\tValidation loss: 0.449476\tBest loss: 0.392770\tAccuracy: 91.00%\n",
      "23\tValidation loss: 0.407201\tBest loss: 0.392770\tAccuracy: 91.30%\n",
      "24\tValidation loss: 0.419251\tBest loss: 0.392770\tAccuracy: 91.80%\n",
      "25\tValidation loss: 0.430324\tBest loss: 0.392770\tAccuracy: 91.30%\n",
      "26\tValidation loss: 0.420948\tBest loss: 0.392770\tAccuracy: 91.60%\n",
      "27\tValidation loss: 0.422474\tBest loss: 0.392770\tAccuracy: 92.50%\n",
      "28\tValidation loss: 0.385287\tBest loss: 0.385287\tAccuracy: 92.80%\n",
      "29\tValidation loss: 0.502591\tBest loss: 0.385287\tAccuracy: 90.30%\n",
      "30\tValidation loss: 0.406232\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "31\tValidation loss: 0.401978\tBest loss: 0.385287\tAccuracy: 92.80%\n",
      "32\tValidation loss: 0.443681\tBest loss: 0.385287\tAccuracy: 91.50%\n",
      "33\tValidation loss: 0.442683\tBest loss: 0.385287\tAccuracy: 91.40%\n",
      "34\tValidation loss: 0.406975\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "35\tValidation loss: 0.419494\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "36\tValidation loss: 0.407613\tBest loss: 0.385287\tAccuracy: 92.20%\n",
      "37\tValidation loss: 0.493804\tBest loss: 0.385287\tAccuracy: 91.00%\n",
      "38\tValidation loss: 0.415527\tBest loss: 0.385287\tAccuracy: 92.50%\n",
      "39\tValidation loss: 0.439876\tBest loss: 0.385287\tAccuracy: 93.00%\n",
      "40\tValidation loss: 0.411445\tBest loss: 0.385287\tAccuracy: 92.20%\n",
      "41\tValidation loss: 0.517564\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "42\tValidation loss: 0.435904\tBest loss: 0.385287\tAccuracy: 92.40%\n",
      "43\tValidation loss: 0.410740\tBest loss: 0.385287\tAccuracy: 93.50%\n",
      "44\tValidation loss: 0.498035\tBest loss: 0.385287\tAccuracy: 91.60%\n",
      "45\tValidation loss: 0.417218\tBest loss: 0.385287\tAccuracy: 93.20%\n",
      "46\tValidation loss: 0.402101\tBest loss: 0.385287\tAccuracy: 93.90%\n",
      "47\tValidation loss: 0.423826\tBest loss: 0.385287\tAccuracy: 93.70%\n",
      "48\tValidation loss: 0.465466\tBest loss: 0.385287\tAccuracy: 93.10%\n",
      "49\tValidation loss: 0.459280\tBest loss: 0.385287\tAccuracy: 92.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   5.9s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.950605\tBest loss: 1.950605\tAccuracy: 53.00%\n",
      "1\tValidation loss: 1.274241\tBest loss: 1.274241\tAccuracy: 68.80%\n",
      "2\tValidation loss: 1.028974\tBest loss: 1.028974\tAccuracy: 76.50%\n",
      "3\tValidation loss: 0.743559\tBest loss: 0.743559\tAccuracy: 84.00%\n",
      "4\tValidation loss: 0.645790\tBest loss: 0.645790\tAccuracy: 86.20%\n",
      "5\tValidation loss: 0.653030\tBest loss: 0.645790\tAccuracy: 85.10%\n",
      "6\tValidation loss: 0.594943\tBest loss: 0.594943\tAccuracy: 87.00%\n",
      "7\tValidation loss: 0.739267\tBest loss: 0.594943\tAccuracy: 82.50%\n",
      "8\tValidation loss: 0.594453\tBest loss: 0.594453\tAccuracy: 85.60%\n",
      "9\tValidation loss: 0.500172\tBest loss: 0.500172\tAccuracy: 89.00%\n",
      "10\tValidation loss: 0.626974\tBest loss: 0.500172\tAccuracy: 86.20%\n",
      "11\tValidation loss: 0.506601\tBest loss: 0.500172\tAccuracy: 89.10%\n",
      "12\tValidation loss: 0.576890\tBest loss: 0.500172\tAccuracy: 88.40%\n",
      "13\tValidation loss: 0.516304\tBest loss: 0.500172\tAccuracy: 88.70%\n",
      "14\tValidation loss: 0.465496\tBest loss: 0.465496\tAccuracy: 89.30%\n",
      "15\tValidation loss: 0.519588\tBest loss: 0.465496\tAccuracy: 89.90%\n",
      "16\tValidation loss: 0.480979\tBest loss: 0.465496\tAccuracy: 89.60%\n",
      "17\tValidation loss: 0.572699\tBest loss: 0.465496\tAccuracy: 88.10%\n",
      "18\tValidation loss: 0.503359\tBest loss: 0.465496\tAccuracy: 90.30%\n",
      "19\tValidation loss: 0.459516\tBest loss: 0.459516\tAccuracy: 91.00%\n",
      "20\tValidation loss: 0.462797\tBest loss: 0.459516\tAccuracy: 90.80%\n",
      "21\tValidation loss: 0.511371\tBest loss: 0.459516\tAccuracy: 90.00%\n",
      "22\tValidation loss: 0.523574\tBest loss: 0.459516\tAccuracy: 89.30%\n",
      "23\tValidation loss: 0.475942\tBest loss: 0.459516\tAccuracy: 91.90%\n",
      "24\tValidation loss: 0.476943\tBest loss: 0.459516\tAccuracy: 91.50%\n",
      "25\tValidation loss: 0.467174\tBest loss: 0.459516\tAccuracy: 92.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\tValidation loss: 0.538206\tBest loss: 0.459516\tAccuracy: 91.70%\n",
      "27\tValidation loss: 0.493537\tBest loss: 0.459516\tAccuracy: 91.90%\n",
      "28\tValidation loss: 0.473731\tBest loss: 0.459516\tAccuracy: 91.70%\n",
      "29\tValidation loss: 0.523062\tBest loss: 0.459516\tAccuracy: 90.00%\n",
      "30\tValidation loss: 0.556503\tBest loss: 0.459516\tAccuracy: 90.80%\n",
      "31\tValidation loss: 0.519532\tBest loss: 0.459516\tAccuracy: 91.80%\n",
      "32\tValidation loss: 0.543210\tBest loss: 0.459516\tAccuracy: 91.40%\n",
      "33\tValidation loss: 0.513967\tBest loss: 0.459516\tAccuracy: 91.60%\n",
      "34\tValidation loss: 0.530547\tBest loss: 0.459516\tAccuracy: 91.90%\n",
      "35\tValidation loss: 0.513417\tBest loss: 0.459516\tAccuracy: 92.40%\n",
      "36\tValidation loss: 0.544377\tBest loss: 0.459516\tAccuracy: 91.70%\n",
      "37\tValidation loss: 0.557797\tBest loss: 0.459516\tAccuracy: 90.90%\n",
      "38\tValidation loss: 0.520383\tBest loss: 0.459516\tAccuracy: 92.70%\n",
      "39\tValidation loss: 0.576168\tBest loss: 0.459516\tAccuracy: 91.00%\n",
      "40\tValidation loss: 0.632231\tBest loss: 0.459516\tAccuracy: 90.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.5s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.963814\tBest loss: 1.963814\tAccuracy: 50.50%\n",
      "1\tValidation loss: 1.337067\tBest loss: 1.337067\tAccuracy: 70.00%\n",
      "2\tValidation loss: 0.879694\tBest loss: 0.879694\tAccuracy: 78.70%\n",
      "3\tValidation loss: 0.848006\tBest loss: 0.848006\tAccuracy: 78.60%\n",
      "4\tValidation loss: 0.728734\tBest loss: 0.728734\tAccuracy: 81.60%\n",
      "5\tValidation loss: 0.680272\tBest loss: 0.680272\tAccuracy: 82.80%\n",
      "6\tValidation loss: 0.615964\tBest loss: 0.615964\tAccuracy: 85.10%\n",
      "7\tValidation loss: 0.521591\tBest loss: 0.521591\tAccuracy: 87.80%\n",
      "8\tValidation loss: 0.530983\tBest loss: 0.521591\tAccuracy: 87.70%\n",
      "9\tValidation loss: 0.534299\tBest loss: 0.521591\tAccuracy: 87.80%\n",
      "10\tValidation loss: 0.549402\tBest loss: 0.521591\tAccuracy: 87.00%\n",
      "11\tValidation loss: 0.516009\tBest loss: 0.516009\tAccuracy: 87.50%\n",
      "12\tValidation loss: 0.527307\tBest loss: 0.516009\tAccuracy: 88.30%\n",
      "13\tValidation loss: 0.484622\tBest loss: 0.484622\tAccuracy: 88.50%\n",
      "14\tValidation loss: 0.477145\tBest loss: 0.477145\tAccuracy: 88.80%\n",
      "15\tValidation loss: 0.436307\tBest loss: 0.436307\tAccuracy: 90.10%\n",
      "16\tValidation loss: 0.509468\tBest loss: 0.436307\tAccuracy: 87.80%\n",
      "17\tValidation loss: 0.476193\tBest loss: 0.436307\tAccuracy: 89.10%\n",
      "18\tValidation loss: 0.465034\tBest loss: 0.436307\tAccuracy: 88.90%\n",
      "19\tValidation loss: 0.393807\tBest loss: 0.393807\tAccuracy: 91.80%\n",
      "20\tValidation loss: 0.527904\tBest loss: 0.393807\tAccuracy: 87.90%\n",
      "21\tValidation loss: 0.512127\tBest loss: 0.393807\tAccuracy: 88.40%\n",
      "22\tValidation loss: 0.473180\tBest loss: 0.393807\tAccuracy: 89.90%\n",
      "23\tValidation loss: 0.418599\tBest loss: 0.393807\tAccuracy: 91.60%\n",
      "24\tValidation loss: 0.447011\tBest loss: 0.393807\tAccuracy: 90.20%\n",
      "25\tValidation loss: 0.459795\tBest loss: 0.393807\tAccuracy: 90.60%\n",
      "26\tValidation loss: 0.432998\tBest loss: 0.393807\tAccuracy: 91.20%\n",
      "27\tValidation loss: 0.465779\tBest loss: 0.393807\tAccuracy: 90.60%\n",
      "28\tValidation loss: 0.420780\tBest loss: 0.393807\tAccuracy: 91.70%\n",
      "29\tValidation loss: 0.464661\tBest loss: 0.393807\tAccuracy: 90.20%\n",
      "30\tValidation loss: 0.426456\tBest loss: 0.393807\tAccuracy: 91.70%\n",
      "31\tValidation loss: 0.490606\tBest loss: 0.393807\tAccuracy: 90.30%\n",
      "32\tValidation loss: 0.440710\tBest loss: 0.393807\tAccuracy: 92.10%\n",
      "33\tValidation loss: 0.431372\tBest loss: 0.393807\tAccuracy: 92.00%\n",
      "34\tValidation loss: 0.428620\tBest loss: 0.393807\tAccuracy: 92.30%\n",
      "35\tValidation loss: 0.458047\tBest loss: 0.393807\tAccuracy: 90.50%\n",
      "36\tValidation loss: 0.444681\tBest loss: 0.393807\tAccuracy: 92.10%\n",
      "37\tValidation loss: 0.438901\tBest loss: 0.393807\tAccuracy: 91.60%\n",
      "38\tValidation loss: 0.484024\tBest loss: 0.393807\tAccuracy: 91.70%\n",
      "39\tValidation loss: 0.437493\tBest loss: 0.393807\tAccuracy: 92.20%\n",
      "40\tValidation loss: 0.469991\tBest loss: 0.393807\tAccuracy: 91.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.7s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.802513\tBest loss: 1.802513\tAccuracy: 53.00%\n",
      "1\tValidation loss: 1.268403\tBest loss: 1.268403\tAccuracy: 66.90%\n",
      "2\tValidation loss: 0.999562\tBest loss: 0.999562\tAccuracy: 73.30%\n",
      "3\tValidation loss: 0.846260\tBest loss: 0.846260\tAccuracy: 78.90%\n",
      "4\tValidation loss: 0.773430\tBest loss: 0.773430\tAccuracy: 80.40%\n",
      "5\tValidation loss: 0.690820\tBest loss: 0.690820\tAccuracy: 83.30%\n",
      "6\tValidation loss: 0.637812\tBest loss: 0.637812\tAccuracy: 83.70%\n",
      "7\tValidation loss: 0.606471\tBest loss: 0.606471\tAccuracy: 84.10%\n",
      "8\tValidation loss: 0.579535\tBest loss: 0.579535\tAccuracy: 85.40%\n",
      "9\tValidation loss: 0.557945\tBest loss: 0.557945\tAccuracy: 86.30%\n",
      "10\tValidation loss: 0.555808\tBest loss: 0.555808\tAccuracy: 85.60%\n",
      "11\tValidation loss: 0.529328\tBest loss: 0.529328\tAccuracy: 86.20%\n",
      "12\tValidation loss: 0.513810\tBest loss: 0.513810\tAccuracy: 87.50%\n",
      "13\tValidation loss: 0.489321\tBest loss: 0.489321\tAccuracy: 89.10%\n",
      "14\tValidation loss: 0.482283\tBest loss: 0.482283\tAccuracy: 88.80%\n",
      "15\tValidation loss: 0.485224\tBest loss: 0.482283\tAccuracy: 88.60%\n",
      "16\tValidation loss: 0.476675\tBest loss: 0.476675\tAccuracy: 88.60%\n",
      "17\tValidation loss: 0.460193\tBest loss: 0.460193\tAccuracy: 89.20%\n",
      "18\tValidation loss: 0.449304\tBest loss: 0.449304\tAccuracy: 89.00%\n",
      "19\tValidation loss: 0.445020\tBest loss: 0.445020\tAccuracy: 89.10%\n",
      "20\tValidation loss: 0.431153\tBest loss: 0.431153\tAccuracy: 89.60%\n",
      "21\tValidation loss: 0.427577\tBest loss: 0.427577\tAccuracy: 89.10%\n",
      "22\tValidation loss: 0.422642\tBest loss: 0.422642\tAccuracy: 89.90%\n",
      "23\tValidation loss: 0.412200\tBest loss: 0.412200\tAccuracy: 89.90%\n",
      "24\tValidation loss: 0.417136\tBest loss: 0.412200\tAccuracy: 90.40%\n",
      "25\tValidation loss: 0.414287\tBest loss: 0.412200\tAccuracy: 90.40%\n",
      "26\tValidation loss: 0.399548\tBest loss: 0.399548\tAccuracy: 89.30%\n",
      "27\tValidation loss: 0.399344\tBest loss: 0.399344\tAccuracy: 90.70%\n",
      "28\tValidation loss: 0.405949\tBest loss: 0.399344\tAccuracy: 90.60%\n",
      "29\tValidation loss: 0.398103\tBest loss: 0.398103\tAccuracy: 90.80%\n",
      "30\tValidation loss: 0.401771\tBest loss: 0.398103\tAccuracy: 91.10%\n",
      "31\tValidation loss: 0.383219\tBest loss: 0.383219\tAccuracy: 91.00%\n",
      "32\tValidation loss: 0.381697\tBest loss: 0.381697\tAccuracy: 90.90%\n",
      "33\tValidation loss: 0.383269\tBest loss: 0.381697\tAccuracy: 91.60%\n",
      "34\tValidation loss: 0.379535\tBest loss: 0.379535\tAccuracy: 91.50%\n",
      "35\tValidation loss: 0.367625\tBest loss: 0.367625\tAccuracy: 91.50%\n",
      "36\tValidation loss: 0.371829\tBest loss: 0.367625\tAccuracy: 91.30%\n",
      "37\tValidation loss: 0.371654\tBest loss: 0.367625\tAccuracy: 91.70%\n",
      "38\tValidation loss: 0.370637\tBest loss: 0.367625\tAccuracy: 91.10%\n",
      "39\tValidation loss: 0.367486\tBest loss: 0.367486\tAccuracy: 91.50%\n",
      "40\tValidation loss: 0.366353\tBest loss: 0.366353\tAccuracy: 90.60%\n",
      "41\tValidation loss: 0.367784\tBest loss: 0.366353\tAccuracy: 91.50%\n",
      "42\tValidation loss: 0.352079\tBest loss: 0.352079\tAccuracy: 92.00%\n",
      "43\tValidation loss: 0.347284\tBest loss: 0.347284\tAccuracy: 91.60%\n",
      "44\tValidation loss: 0.355111\tBest loss: 0.347284\tAccuracy: 91.60%\n",
      "45\tValidation loss: 0.337631\tBest loss: 0.337631\tAccuracy: 92.30%\n",
      "46\tValidation loss: 0.350253\tBest loss: 0.337631\tAccuracy: 91.60%\n",
      "47\tValidation loss: 0.340043\tBest loss: 0.337631\tAccuracy: 92.40%\n",
      "48\tValidation loss: 0.352096\tBest loss: 0.337631\tAccuracy: 91.60%\n",
      "49\tValidation loss: 0.345604\tBest loss: 0.337631\tAccuracy: 92.50%\n",
      "50\tValidation loss: 0.352193\tBest loss: 0.337631\tAccuracy: 92.20%\n",
      "51\tValidation loss: 0.344885\tBest loss: 0.337631\tAccuracy: 92.00%\n",
      "52\tValidation loss: 0.338839\tBest loss: 0.337631\tAccuracy: 92.20%\n",
      "53\tValidation loss: 0.343341\tBest loss: 0.337631\tAccuracy: 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\tValidation loss: 0.332299\tBest loss: 0.332299\tAccuracy: 92.40%\n",
      "55\tValidation loss: 0.336107\tBest loss: 0.332299\tAccuracy: 92.50%\n",
      "56\tValidation loss: 0.343229\tBest loss: 0.332299\tAccuracy: 92.60%\n",
      "57\tValidation loss: 0.338890\tBest loss: 0.332299\tAccuracy: 92.60%\n",
      "58\tValidation loss: 0.335204\tBest loss: 0.332299\tAccuracy: 92.40%\n",
      "59\tValidation loss: 0.334870\tBest loss: 0.332299\tAccuracy: 92.20%\n",
      "60\tValidation loss: 0.331301\tBest loss: 0.331301\tAccuracy: 92.50%\n",
      "61\tValidation loss: 0.329168\tBest loss: 0.329168\tAccuracy: 92.60%\n",
      "62\tValidation loss: 0.325486\tBest loss: 0.325486\tAccuracy: 92.60%\n",
      "63\tValidation loss: 0.323646\tBest loss: 0.323646\tAccuracy: 92.50%\n",
      "64\tValidation loss: 0.320364\tBest loss: 0.320364\tAccuracy: 92.70%\n",
      "65\tValidation loss: 0.324272\tBest loss: 0.320364\tAccuracy: 92.40%\n",
      "66\tValidation loss: 0.324043\tBest loss: 0.320364\tAccuracy: 92.60%\n",
      "67\tValidation loss: 0.325759\tBest loss: 0.320364\tAccuracy: 92.50%\n",
      "68\tValidation loss: 0.326384\tBest loss: 0.320364\tAccuracy: 92.40%\n",
      "69\tValidation loss: 0.321139\tBest loss: 0.320364\tAccuracy: 92.90%\n",
      "70\tValidation loss: 0.331807\tBest loss: 0.320364\tAccuracy: 92.90%\n",
      "71\tValidation loss: 0.326589\tBest loss: 0.320364\tAccuracy: 92.90%\n",
      "72\tValidation loss: 0.321459\tBest loss: 0.320364\tAccuracy: 93.20%\n",
      "73\tValidation loss: 0.320219\tBest loss: 0.320219\tAccuracy: 93.10%\n",
      "74\tValidation loss: 0.327895\tBest loss: 0.320219\tAccuracy: 92.80%\n",
      "75\tValidation loss: 0.316459\tBest loss: 0.316459\tAccuracy: 93.10%\n",
      "76\tValidation loss: 0.315811\tBest loss: 0.315811\tAccuracy: 93.00%\n",
      "77\tValidation loss: 0.320383\tBest loss: 0.315811\tAccuracy: 92.70%\n",
      "78\tValidation loss: 0.310708\tBest loss: 0.310708\tAccuracy: 93.30%\n",
      "79\tValidation loss: 0.311044\tBest loss: 0.310708\tAccuracy: 93.10%\n",
      "80\tValidation loss: 0.320546\tBest loss: 0.310708\tAccuracy: 93.40%\n",
      "81\tValidation loss: 0.319736\tBest loss: 0.310708\tAccuracy: 93.20%\n",
      "82\tValidation loss: 0.313979\tBest loss: 0.310708\tAccuracy: 93.10%\n",
      "83\tValidation loss: 0.310298\tBest loss: 0.310298\tAccuracy: 93.40%\n",
      "84\tValidation loss: 0.308584\tBest loss: 0.308584\tAccuracy: 93.20%\n",
      "85\tValidation loss: 0.308949\tBest loss: 0.308584\tAccuracy: 93.10%\n",
      "86\tValidation loss: 0.309080\tBest loss: 0.308584\tAccuracy: 93.40%\n",
      "87\tValidation loss: 0.313207\tBest loss: 0.308584\tAccuracy: 93.30%\n",
      "88\tValidation loss: 0.312552\tBest loss: 0.308584\tAccuracy: 93.30%\n",
      "89\tValidation loss: 0.313238\tBest loss: 0.308584\tAccuracy: 93.40%\n",
      "90\tValidation loss: 0.311537\tBest loss: 0.308584\tAccuracy: 92.80%\n",
      "91\tValidation loss: 0.310339\tBest loss: 0.308584\tAccuracy: 93.40%\n",
      "92\tValidation loss: 0.308321\tBest loss: 0.308321\tAccuracy: 93.00%\n",
      "93\tValidation loss: 0.308874\tBest loss: 0.308321\tAccuracy: 93.30%\n",
      "94\tValidation loss: 0.310980\tBest loss: 0.308321\tAccuracy: 93.30%\n",
      "95\tValidation loss: 0.307887\tBest loss: 0.307887\tAccuracy: 93.30%\n",
      "96\tValidation loss: 0.306468\tBest loss: 0.306468\tAccuracy: 93.00%\n",
      "97\tValidation loss: 0.310055\tBest loss: 0.306468\tAccuracy: 93.30%\n",
      "98\tValidation loss: 0.311887\tBest loss: 0.306468\tAccuracy: 93.30%\n",
      "99\tValidation loss: 0.312822\tBest loss: 0.306468\tAccuracy: 93.40%\n",
      "100\tValidation loss: 0.313245\tBest loss: 0.306468\tAccuracy: 93.30%\n",
      "101\tValidation loss: 0.305099\tBest loss: 0.305099\tAccuracy: 93.40%\n",
      "102\tValidation loss: 0.305785\tBest loss: 0.305099\tAccuracy: 93.30%\n",
      "103\tValidation loss: 0.309362\tBest loss: 0.305099\tAccuracy: 93.30%\n",
      "104\tValidation loss: 0.308623\tBest loss: 0.305099\tAccuracy: 93.60%\n",
      "105\tValidation loss: 0.305824\tBest loss: 0.305099\tAccuracy: 93.30%\n",
      "106\tValidation loss: 0.306829\tBest loss: 0.305099\tAccuracy: 93.50%\n",
      "107\tValidation loss: 0.322874\tBest loss: 0.305099\tAccuracy: 93.20%\n",
      "108\tValidation loss: 0.313944\tBest loss: 0.305099\tAccuracy: 93.40%\n",
      "109\tValidation loss: 0.301179\tBest loss: 0.301179\tAccuracy: 93.70%\n",
      "110\tValidation loss: 0.309404\tBest loss: 0.301179\tAccuracy: 93.40%\n",
      "111\tValidation loss: 0.306909\tBest loss: 0.301179\tAccuracy: 93.70%\n",
      "112\tValidation loss: 0.313213\tBest loss: 0.301179\tAccuracy: 93.60%\n",
      "113\tValidation loss: 0.302449\tBest loss: 0.301179\tAccuracy: 93.70%\n",
      "114\tValidation loss: 0.310550\tBest loss: 0.301179\tAccuracy: 93.50%\n",
      "115\tValidation loss: 0.308442\tBest loss: 0.301179\tAccuracy: 93.30%\n",
      "116\tValidation loss: 0.309018\tBest loss: 0.301179\tAccuracy: 93.30%\n",
      "117\tValidation loss: 0.306316\tBest loss: 0.301179\tAccuracy: 93.40%\n",
      "118\tValidation loss: 0.304597\tBest loss: 0.301179\tAccuracy: 93.80%\n",
      "119\tValidation loss: 0.307454\tBest loss: 0.301179\tAccuracy: 93.40%\n",
      "120\tValidation loss: 0.314527\tBest loss: 0.301179\tAccuracy: 93.30%\n",
      "121\tValidation loss: 0.308967\tBest loss: 0.301179\tAccuracy: 93.60%\n",
      "122\tValidation loss: 0.308373\tBest loss: 0.301179\tAccuracy: 93.30%\n",
      "123\tValidation loss: 0.308556\tBest loss: 0.301179\tAccuracy: 93.60%\n",
      "124\tValidation loss: 0.315764\tBest loss: 0.301179\tAccuracy: 93.50%\n",
      "125\tValidation loss: 0.312823\tBest loss: 0.301179\tAccuracy: 93.80%\n",
      "126\tValidation loss: 0.316687\tBest loss: 0.301179\tAccuracy: 93.30%\n",
      "127\tValidation loss: 0.320909\tBest loss: 0.301179\tAccuracy: 93.40%\n",
      "128\tValidation loss: 0.312823\tBest loss: 0.301179\tAccuracy: 93.60%\n",
      "129\tValidation loss: 0.313766\tBest loss: 0.301179\tAccuracy: 93.10%\n",
      "130\tValidation loss: 0.317225\tBest loss: 0.301179\tAccuracy: 93.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  18.5s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.768633\tBest loss: 1.768633\tAccuracy: 54.50%\n",
      "1\tValidation loss: 1.219061\tBest loss: 1.219061\tAccuracy: 68.30%\n",
      "2\tValidation loss: 0.985195\tBest loss: 0.985195\tAccuracy: 75.70%\n",
      "3\tValidation loss: 0.828728\tBest loss: 0.828728\tAccuracy: 78.80%\n",
      "4\tValidation loss: 0.758243\tBest loss: 0.758243\tAccuracy: 80.70%\n",
      "5\tValidation loss: 0.707134\tBest loss: 0.707134\tAccuracy: 83.10%\n",
      "6\tValidation loss: 0.668285\tBest loss: 0.668285\tAccuracy: 83.60%\n",
      "7\tValidation loss: 0.637594\tBest loss: 0.637594\tAccuracy: 83.80%\n",
      "8\tValidation loss: 0.592362\tBest loss: 0.592362\tAccuracy: 85.20%\n",
      "9\tValidation loss: 0.584359\tBest loss: 0.584359\tAccuracy: 84.80%\n",
      "10\tValidation loss: 0.569403\tBest loss: 0.569403\tAccuracy: 86.10%\n",
      "11\tValidation loss: 0.549865\tBest loss: 0.549865\tAccuracy: 86.50%\n",
      "12\tValidation loss: 0.531662\tBest loss: 0.531662\tAccuracy: 86.10%\n",
      "13\tValidation loss: 0.510767\tBest loss: 0.510767\tAccuracy: 86.90%\n",
      "14\tValidation loss: 0.493883\tBest loss: 0.493883\tAccuracy: 87.60%\n",
      "15\tValidation loss: 0.498318\tBest loss: 0.493883\tAccuracy: 87.60%\n",
      "16\tValidation loss: 0.482417\tBest loss: 0.482417\tAccuracy: 88.00%\n",
      "17\tValidation loss: 0.479716\tBest loss: 0.479716\tAccuracy: 87.80%\n",
      "18\tValidation loss: 0.473388\tBest loss: 0.473388\tAccuracy: 88.90%\n",
      "19\tValidation loss: 0.467967\tBest loss: 0.467967\tAccuracy: 88.90%\n",
      "20\tValidation loss: 0.453291\tBest loss: 0.453291\tAccuracy: 88.70%\n",
      "21\tValidation loss: 0.450301\tBest loss: 0.450301\tAccuracy: 89.10%\n",
      "22\tValidation loss: 0.439528\tBest loss: 0.439528\tAccuracy: 89.50%\n",
      "23\tValidation loss: 0.448079\tBest loss: 0.439528\tAccuracy: 89.00%\n",
      "24\tValidation loss: 0.440212\tBest loss: 0.439528\tAccuracy: 89.30%\n",
      "25\tValidation loss: 0.441985\tBest loss: 0.439528\tAccuracy: 90.00%\n",
      "26\tValidation loss: 0.445665\tBest loss: 0.439528\tAccuracy: 89.90%\n",
      "27\tValidation loss: 0.435051\tBest loss: 0.435051\tAccuracy: 90.00%\n",
      "28\tValidation loss: 0.428522\tBest loss: 0.428522\tAccuracy: 89.70%\n",
      "29\tValidation loss: 0.431501\tBest loss: 0.428522\tAccuracy: 89.80%\n",
      "30\tValidation loss: 0.424440\tBest loss: 0.424440\tAccuracy: 90.00%\n",
      "31\tValidation loss: 0.426755\tBest loss: 0.424440\tAccuracy: 89.60%\n",
      "32\tValidation loss: 0.441717\tBest loss: 0.424440\tAccuracy: 89.90%\n",
      "33\tValidation loss: 0.422089\tBest loss: 0.422089\tAccuracy: 90.30%\n",
      "34\tValidation loss: 0.430565\tBest loss: 0.422089\tAccuracy: 89.90%\n",
      "35\tValidation loss: 0.409311\tBest loss: 0.409311\tAccuracy: 90.90%\n",
      "36\tValidation loss: 0.417235\tBest loss: 0.409311\tAccuracy: 90.70%\n",
      "37\tValidation loss: 0.414290\tBest loss: 0.409311\tAccuracy: 90.40%\n",
      "38\tValidation loss: 0.414818\tBest loss: 0.409311\tAccuracy: 90.30%\n",
      "39\tValidation loss: 0.413921\tBest loss: 0.409311\tAccuracy: 90.50%\n",
      "40\tValidation loss: 0.406623\tBest loss: 0.406623\tAccuracy: 90.20%\n",
      "41\tValidation loss: 0.409528\tBest loss: 0.406623\tAccuracy: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\tValidation loss: 0.396834\tBest loss: 0.396834\tAccuracy: 90.70%\n",
      "43\tValidation loss: 0.395832\tBest loss: 0.395832\tAccuracy: 90.90%\n",
      "44\tValidation loss: 0.398823\tBest loss: 0.395832\tAccuracy: 91.10%\n",
      "45\tValidation loss: 0.398680\tBest loss: 0.395832\tAccuracy: 91.40%\n",
      "46\tValidation loss: 0.413689\tBest loss: 0.395832\tAccuracy: 91.20%\n",
      "47\tValidation loss: 0.421109\tBest loss: 0.395832\tAccuracy: 90.50%\n",
      "48\tValidation loss: 0.402256\tBest loss: 0.395832\tAccuracy: 91.30%\n",
      "49\tValidation loss: 0.399197\tBest loss: 0.395832\tAccuracy: 91.40%\n",
      "50\tValidation loss: 0.397048\tBest loss: 0.395832\tAccuracy: 91.20%\n",
      "51\tValidation loss: 0.396628\tBest loss: 0.395832\tAccuracy: 91.00%\n",
      "52\tValidation loss: 0.400324\tBest loss: 0.395832\tAccuracy: 91.00%\n",
      "53\tValidation loss: 0.393296\tBest loss: 0.393296\tAccuracy: 91.40%\n",
      "54\tValidation loss: 0.391463\tBest loss: 0.391463\tAccuracy: 91.60%\n",
      "55\tValidation loss: 0.398978\tBest loss: 0.391463\tAccuracy: 91.00%\n",
      "56\tValidation loss: 0.394780\tBest loss: 0.391463\tAccuracy: 91.70%\n",
      "57\tValidation loss: 0.394691\tBest loss: 0.391463\tAccuracy: 91.20%\n",
      "58\tValidation loss: 0.402519\tBest loss: 0.391463\tAccuracy: 91.40%\n",
      "59\tValidation loss: 0.392894\tBest loss: 0.391463\tAccuracy: 91.50%\n",
      "60\tValidation loss: 0.407156\tBest loss: 0.391463\tAccuracy: 91.10%\n",
      "61\tValidation loss: 0.394709\tBest loss: 0.391463\tAccuracy: 91.10%\n",
      "62\tValidation loss: 0.404499\tBest loss: 0.391463\tAccuracy: 91.70%\n",
      "63\tValidation loss: 0.392389\tBest loss: 0.391463\tAccuracy: 91.70%\n",
      "64\tValidation loss: 0.390899\tBest loss: 0.390899\tAccuracy: 92.10%\n",
      "65\tValidation loss: 0.397169\tBest loss: 0.390899\tAccuracy: 92.00%\n",
      "66\tValidation loss: 0.391499\tBest loss: 0.390899\tAccuracy: 91.90%\n",
      "67\tValidation loss: 0.402430\tBest loss: 0.390899\tAccuracy: 92.10%\n",
      "68\tValidation loss: 0.397987\tBest loss: 0.390899\tAccuracy: 92.00%\n",
      "69\tValidation loss: 0.401108\tBest loss: 0.390899\tAccuracy: 92.10%\n",
      "70\tValidation loss: 0.395048\tBest loss: 0.390899\tAccuracy: 92.30%\n",
      "71\tValidation loss: 0.397796\tBest loss: 0.390899\tAccuracy: 92.00%\n",
      "72\tValidation loss: 0.410071\tBest loss: 0.390899\tAccuracy: 91.70%\n",
      "73\tValidation loss: 0.400431\tBest loss: 0.390899\tAccuracy: 91.90%\n",
      "74\tValidation loss: 0.409951\tBest loss: 0.390899\tAccuracy: 91.80%\n",
      "75\tValidation loss: 0.402880\tBest loss: 0.390899\tAccuracy: 92.00%\n",
      "76\tValidation loss: 0.394255\tBest loss: 0.390899\tAccuracy: 92.20%\n",
      "77\tValidation loss: 0.397643\tBest loss: 0.390899\tAccuracy: 92.50%\n",
      "78\tValidation loss: 0.391749\tBest loss: 0.390899\tAccuracy: 92.20%\n",
      "79\tValidation loss: 0.400722\tBest loss: 0.390899\tAccuracy: 91.90%\n",
      "80\tValidation loss: 0.401433\tBest loss: 0.390899\tAccuracy: 92.30%\n",
      "81\tValidation loss: 0.398645\tBest loss: 0.390899\tAccuracy: 92.30%\n",
      "82\tValidation loss: 0.396427\tBest loss: 0.390899\tAccuracy: 92.40%\n",
      "83\tValidation loss: 0.397143\tBest loss: 0.390899\tAccuracy: 92.50%\n",
      "84\tValidation loss: 0.398920\tBest loss: 0.390899\tAccuracy: 92.40%\n",
      "85\tValidation loss: 0.399950\tBest loss: 0.390899\tAccuracy: 92.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  12.6s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.815452\tBest loss: 1.815452\tAccuracy: 53.50%\n",
      "1\tValidation loss: 1.256417\tBest loss: 1.256417\tAccuracy: 67.80%\n",
      "2\tValidation loss: 0.999726\tBest loss: 0.999726\tAccuracy: 73.80%\n",
      "3\tValidation loss: 0.858220\tBest loss: 0.858220\tAccuracy: 78.80%\n",
      "4\tValidation loss: 0.771060\tBest loss: 0.771060\tAccuracy: 81.30%\n",
      "5\tValidation loss: 0.709593\tBest loss: 0.709593\tAccuracy: 81.60%\n",
      "6\tValidation loss: 0.661310\tBest loss: 0.661310\tAccuracy: 83.40%\n",
      "7\tValidation loss: 0.621037\tBest loss: 0.621037\tAccuracy: 85.00%\n",
      "8\tValidation loss: 0.618657\tBest loss: 0.618657\tAccuracy: 85.00%\n",
      "9\tValidation loss: 0.578851\tBest loss: 0.578851\tAccuracy: 85.00%\n",
      "10\tValidation loss: 0.558389\tBest loss: 0.558389\tAccuracy: 86.80%\n",
      "11\tValidation loss: 0.534845\tBest loss: 0.534845\tAccuracy: 86.80%\n",
      "12\tValidation loss: 0.528795\tBest loss: 0.528795\tAccuracy: 87.50%\n",
      "13\tValidation loss: 0.495956\tBest loss: 0.495956\tAccuracy: 87.70%\n",
      "14\tValidation loss: 0.493802\tBest loss: 0.493802\tAccuracy: 88.20%\n",
      "15\tValidation loss: 0.475803\tBest loss: 0.475803\tAccuracy: 88.50%\n",
      "16\tValidation loss: 0.481431\tBest loss: 0.475803\tAccuracy: 87.90%\n",
      "17\tValidation loss: 0.458986\tBest loss: 0.458986\tAccuracy: 88.40%\n",
      "18\tValidation loss: 0.449843\tBest loss: 0.449843\tAccuracy: 88.80%\n",
      "19\tValidation loss: 0.444135\tBest loss: 0.444135\tAccuracy: 89.00%\n",
      "20\tValidation loss: 0.458648\tBest loss: 0.444135\tAccuracy: 88.90%\n",
      "21\tValidation loss: 0.436690\tBest loss: 0.436690\tAccuracy: 89.20%\n",
      "22\tValidation loss: 0.429572\tBest loss: 0.429572\tAccuracy: 90.30%\n",
      "23\tValidation loss: 0.420778\tBest loss: 0.420778\tAccuracy: 89.50%\n",
      "24\tValidation loss: 0.414085\tBest loss: 0.414085\tAccuracy: 90.00%\n",
      "25\tValidation loss: 0.418179\tBest loss: 0.414085\tAccuracy: 89.60%\n",
      "26\tValidation loss: 0.407164\tBest loss: 0.407164\tAccuracy: 90.20%\n",
      "27\tValidation loss: 0.404098\tBest loss: 0.404098\tAccuracy: 90.40%\n",
      "28\tValidation loss: 0.401035\tBest loss: 0.401035\tAccuracy: 90.30%\n",
      "29\tValidation loss: 0.406221\tBest loss: 0.401035\tAccuracy: 89.60%\n",
      "30\tValidation loss: 0.393703\tBest loss: 0.393703\tAccuracy: 90.20%\n",
      "31\tValidation loss: 0.398389\tBest loss: 0.393703\tAccuracy: 90.30%\n",
      "32\tValidation loss: 0.398748\tBest loss: 0.393703\tAccuracy: 90.50%\n",
      "33\tValidation loss: 0.390823\tBest loss: 0.390823\tAccuracy: 90.50%\n",
      "34\tValidation loss: 0.382730\tBest loss: 0.382730\tAccuracy: 91.00%\n",
      "35\tValidation loss: 0.386703\tBest loss: 0.382730\tAccuracy: 90.30%\n",
      "36\tValidation loss: 0.382373\tBest loss: 0.382373\tAccuracy: 91.10%\n",
      "37\tValidation loss: 0.372444\tBest loss: 0.372444\tAccuracy: 90.80%\n",
      "38\tValidation loss: 0.373474\tBest loss: 0.372444\tAccuracy: 90.60%\n",
      "39\tValidation loss: 0.369183\tBest loss: 0.369183\tAccuracy: 91.50%\n",
      "40\tValidation loss: 0.373740\tBest loss: 0.369183\tAccuracy: 90.80%\n",
      "41\tValidation loss: 0.366177\tBest loss: 0.366177\tAccuracy: 91.20%\n",
      "42\tValidation loss: 0.370791\tBest loss: 0.366177\tAccuracy: 90.60%\n",
      "43\tValidation loss: 0.365679\tBest loss: 0.365679\tAccuracy: 91.50%\n",
      "44\tValidation loss: 0.357457\tBest loss: 0.357457\tAccuracy: 91.50%\n",
      "45\tValidation loss: 0.358942\tBest loss: 0.357457\tAccuracy: 91.50%\n",
      "46\tValidation loss: 0.373237\tBest loss: 0.357457\tAccuracy: 90.80%\n",
      "47\tValidation loss: 0.362510\tBest loss: 0.357457\tAccuracy: 91.20%\n",
      "48\tValidation loss: 0.355178\tBest loss: 0.355178\tAccuracy: 92.00%\n",
      "49\tValidation loss: 0.345618\tBest loss: 0.345618\tAccuracy: 92.20%\n",
      "50\tValidation loss: 0.353761\tBest loss: 0.345618\tAccuracy: 91.90%\n",
      "51\tValidation loss: 0.344223\tBest loss: 0.344223\tAccuracy: 92.20%\n",
      "52\tValidation loss: 0.354568\tBest loss: 0.344223\tAccuracy: 91.60%\n",
      "53\tValidation loss: 0.347143\tBest loss: 0.344223\tAccuracy: 91.90%\n",
      "54\tValidation loss: 0.347094\tBest loss: 0.344223\tAccuracy: 91.80%\n",
      "55\tValidation loss: 0.350948\tBest loss: 0.344223\tAccuracy: 92.40%\n",
      "56\tValidation loss: 0.344819\tBest loss: 0.344223\tAccuracy: 92.30%\n",
      "57\tValidation loss: 0.350634\tBest loss: 0.344223\tAccuracy: 91.70%\n",
      "58\tValidation loss: 0.338407\tBest loss: 0.338407\tAccuracy: 92.00%\n",
      "59\tValidation loss: 0.350299\tBest loss: 0.338407\tAccuracy: 91.90%\n",
      "60\tValidation loss: 0.345017\tBest loss: 0.338407\tAccuracy: 91.70%\n",
      "61\tValidation loss: 0.347082\tBest loss: 0.338407\tAccuracy: 91.40%\n",
      "62\tValidation loss: 0.339150\tBest loss: 0.338407\tAccuracy: 92.10%\n",
      "63\tValidation loss: 0.333155\tBest loss: 0.333155\tAccuracy: 92.70%\n",
      "64\tValidation loss: 0.337470\tBest loss: 0.333155\tAccuracy: 92.20%\n",
      "65\tValidation loss: 0.341555\tBest loss: 0.333155\tAccuracy: 91.70%\n",
      "66\tValidation loss: 0.339223\tBest loss: 0.333155\tAccuracy: 92.20%\n",
      "67\tValidation loss: 0.335708\tBest loss: 0.333155\tAccuracy: 92.40%\n",
      "68\tValidation loss: 0.334316\tBest loss: 0.333155\tAccuracy: 92.80%\n",
      "69\tValidation loss: 0.331762\tBest loss: 0.331762\tAccuracy: 92.40%\n",
      "70\tValidation loss: 0.332580\tBest loss: 0.331762\tAccuracy: 92.60%\n",
      "71\tValidation loss: 0.341408\tBest loss: 0.331762\tAccuracy: 92.50%\n",
      "72\tValidation loss: 0.329081\tBest loss: 0.329081\tAccuracy: 92.50%\n",
      "73\tValidation loss: 0.341249\tBest loss: 0.329081\tAccuracy: 92.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\tValidation loss: 0.330800\tBest loss: 0.329081\tAccuracy: 92.40%\n",
      "75\tValidation loss: 0.325430\tBest loss: 0.325430\tAccuracy: 93.20%\n",
      "76\tValidation loss: 0.332232\tBest loss: 0.325430\tAccuracy: 92.60%\n",
      "77\tValidation loss: 0.333399\tBest loss: 0.325430\tAccuracy: 92.70%\n",
      "78\tValidation loss: 0.331542\tBest loss: 0.325430\tAccuracy: 92.60%\n",
      "79\tValidation loss: 0.327870\tBest loss: 0.325430\tAccuracy: 92.80%\n",
      "80\tValidation loss: 0.332467\tBest loss: 0.325430\tAccuracy: 92.70%\n",
      "81\tValidation loss: 0.329542\tBest loss: 0.325430\tAccuracy: 92.60%\n",
      "82\tValidation loss: 0.331661\tBest loss: 0.325430\tAccuracy: 92.80%\n",
      "83\tValidation loss: 0.327816\tBest loss: 0.325430\tAccuracy: 92.10%\n",
      "84\tValidation loss: 0.327336\tBest loss: 0.325430\tAccuracy: 92.40%\n",
      "85\tValidation loss: 0.337985\tBest loss: 0.325430\tAccuracy: 92.30%\n",
      "86\tValidation loss: 0.324671\tBest loss: 0.324671\tAccuracy: 92.80%\n",
      "87\tValidation loss: 0.323722\tBest loss: 0.323722\tAccuracy: 92.90%\n",
      "88\tValidation loss: 0.321325\tBest loss: 0.321325\tAccuracy: 93.30%\n",
      "89\tValidation loss: 0.321894\tBest loss: 0.321325\tAccuracy: 93.30%\n",
      "90\tValidation loss: 0.320164\tBest loss: 0.320164\tAccuracy: 93.00%\n",
      "91\tValidation loss: 0.326114\tBest loss: 0.320164\tAccuracy: 93.00%\n",
      "92\tValidation loss: 0.328983\tBest loss: 0.320164\tAccuracy: 93.00%\n",
      "93\tValidation loss: 0.325799\tBest loss: 0.320164\tAccuracy: 93.00%\n",
      "94\tValidation loss: 0.326203\tBest loss: 0.320164\tAccuracy: 92.60%\n",
      "95\tValidation loss: 0.311453\tBest loss: 0.311453\tAccuracy: 93.50%\n",
      "96\tValidation loss: 0.321232\tBest loss: 0.311453\tAccuracy: 93.20%\n",
      "97\tValidation loss: 0.322820\tBest loss: 0.311453\tAccuracy: 93.20%\n",
      "98\tValidation loss: 0.325937\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "99\tValidation loss: 0.318276\tBest loss: 0.311453\tAccuracy: 92.90%\n",
      "100\tValidation loss: 0.322764\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "101\tValidation loss: 0.320021\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "102\tValidation loss: 0.325055\tBest loss: 0.311453\tAccuracy: 93.30%\n",
      "103\tValidation loss: 0.325533\tBest loss: 0.311453\tAccuracy: 93.10%\n",
      "104\tValidation loss: 0.325133\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "105\tValidation loss: 0.326311\tBest loss: 0.311453\tAccuracy: 93.10%\n",
      "106\tValidation loss: 0.321270\tBest loss: 0.311453\tAccuracy: 93.50%\n",
      "107\tValidation loss: 0.327428\tBest loss: 0.311453\tAccuracy: 92.90%\n",
      "108\tValidation loss: 0.325548\tBest loss: 0.311453\tAccuracy: 93.50%\n",
      "109\tValidation loss: 0.318613\tBest loss: 0.311453\tAccuracy: 93.70%\n",
      "110\tValidation loss: 0.323055\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "111\tValidation loss: 0.331547\tBest loss: 0.311453\tAccuracy: 93.30%\n",
      "112\tValidation loss: 0.323949\tBest loss: 0.311453\tAccuracy: 93.40%\n",
      "113\tValidation loss: 0.329345\tBest loss: 0.311453\tAccuracy: 93.20%\n",
      "114\tValidation loss: 0.331685\tBest loss: 0.311453\tAccuracy: 93.30%\n",
      "115\tValidation loss: 0.322354\tBest loss: 0.311453\tAccuracy: 93.60%\n",
      "116\tValidation loss: 0.324886\tBest loss: 0.311453\tAccuracy: 93.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  16.8s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.065351\tBest loss: 3.065351\tAccuracy: 22.10%\n",
      "1\tValidation loss: 2.531207\tBest loss: 2.531207\tAccuracy: 37.00%\n",
      "2\tValidation loss: 2.183536\tBest loss: 2.183536\tAccuracy: 45.90%\n",
      "3\tValidation loss: 1.956129\tBest loss: 1.956129\tAccuracy: 53.00%\n",
      "4\tValidation loss: 1.776954\tBest loss: 1.776954\tAccuracy: 57.30%\n",
      "5\tValidation loss: 1.636480\tBest loss: 1.636480\tAccuracy: 59.50%\n",
      "6\tValidation loss: 1.530311\tBest loss: 1.530311\tAccuracy: 62.60%\n",
      "7\tValidation loss: 1.443575\tBest loss: 1.443575\tAccuracy: 64.00%\n",
      "8\tValidation loss: 1.371599\tBest loss: 1.371599\tAccuracy: 65.00%\n",
      "9\tValidation loss: 1.311356\tBest loss: 1.311356\tAccuracy: 67.50%\n",
      "10\tValidation loss: 1.259646\tBest loss: 1.259646\tAccuracy: 69.80%\n",
      "11\tValidation loss: 1.213524\tBest loss: 1.213524\tAccuracy: 71.20%\n",
      "12\tValidation loss: 1.184198\tBest loss: 1.184198\tAccuracy: 71.60%\n",
      "13\tValidation loss: 1.143984\tBest loss: 1.143984\tAccuracy: 72.70%\n",
      "14\tValidation loss: 1.108564\tBest loss: 1.108564\tAccuracy: 74.60%\n",
      "15\tValidation loss: 1.079810\tBest loss: 1.079810\tAccuracy: 74.70%\n",
      "16\tValidation loss: 1.051024\tBest loss: 1.051024\tAccuracy: 75.30%\n",
      "17\tValidation loss: 1.031717\tBest loss: 1.031717\tAccuracy: 75.50%\n",
      "18\tValidation loss: 1.004958\tBest loss: 1.004958\tAccuracy: 76.60%\n",
      "19\tValidation loss: 0.986905\tBest loss: 0.986905\tAccuracy: 77.40%\n",
      "20\tValidation loss: 0.967393\tBest loss: 0.967393\tAccuracy: 77.30%\n",
      "21\tValidation loss: 0.950388\tBest loss: 0.950388\tAccuracy: 78.50%\n",
      "22\tValidation loss: 0.935280\tBest loss: 0.935280\tAccuracy: 78.40%\n",
      "23\tValidation loss: 0.921745\tBest loss: 0.921745\tAccuracy: 79.40%\n",
      "24\tValidation loss: 0.911484\tBest loss: 0.911484\tAccuracy: 79.30%\n",
      "25\tValidation loss: 0.894407\tBest loss: 0.894407\tAccuracy: 79.70%\n",
      "26\tValidation loss: 0.879603\tBest loss: 0.879603\tAccuracy: 79.90%\n",
      "27\tValidation loss: 0.871889\tBest loss: 0.871889\tAccuracy: 80.50%\n",
      "28\tValidation loss: 0.859140\tBest loss: 0.859140\tAccuracy: 80.20%\n",
      "29\tValidation loss: 0.849727\tBest loss: 0.849727\tAccuracy: 80.40%\n",
      "30\tValidation loss: 0.841475\tBest loss: 0.841475\tAccuracy: 80.90%\n",
      "31\tValidation loss: 0.822752\tBest loss: 0.822752\tAccuracy: 81.80%\n",
      "32\tValidation loss: 0.815807\tBest loss: 0.815807\tAccuracy: 81.10%\n",
      "33\tValidation loss: 0.813874\tBest loss: 0.813874\tAccuracy: 81.80%\n",
      "34\tValidation loss: 0.802542\tBest loss: 0.802542\tAccuracy: 81.30%\n",
      "35\tValidation loss: 0.792222\tBest loss: 0.792222\tAccuracy: 82.00%\n",
      "36\tValidation loss: 0.780277\tBest loss: 0.780277\tAccuracy: 82.50%\n",
      "37\tValidation loss: 0.778090\tBest loss: 0.778090\tAccuracy: 82.30%\n",
      "38\tValidation loss: 0.772217\tBest loss: 0.772217\tAccuracy: 82.20%\n",
      "39\tValidation loss: 0.763720\tBest loss: 0.763720\tAccuracy: 82.80%\n",
      "40\tValidation loss: 0.759096\tBest loss: 0.759096\tAccuracy: 82.30%\n",
      "41\tValidation loss: 0.753910\tBest loss: 0.753910\tAccuracy: 83.20%\n",
      "42\tValidation loss: 0.742193\tBest loss: 0.742193\tAccuracy: 83.20%\n",
      "43\tValidation loss: 0.735729\tBest loss: 0.735729\tAccuracy: 83.10%\n",
      "44\tValidation loss: 0.731345\tBest loss: 0.731345\tAccuracy: 83.60%\n",
      "45\tValidation loss: 0.725590\tBest loss: 0.725590\tAccuracy: 83.50%\n",
      "46\tValidation loss: 0.722662\tBest loss: 0.722662\tAccuracy: 83.70%\n",
      "47\tValidation loss: 0.716071\tBest loss: 0.716071\tAccuracy: 84.60%\n",
      "48\tValidation loss: 0.712193\tBest loss: 0.712193\tAccuracy: 83.80%\n",
      "49\tValidation loss: 0.709738\tBest loss: 0.709738\tAccuracy: 84.10%\n",
      "50\tValidation loss: 0.701413\tBest loss: 0.701413\tAccuracy: 83.70%\n",
      "51\tValidation loss: 0.698586\tBest loss: 0.698586\tAccuracy: 84.80%\n",
      "52\tValidation loss: 0.692003\tBest loss: 0.692003\tAccuracy: 84.60%\n",
      "53\tValidation loss: 0.689485\tBest loss: 0.689485\tAccuracy: 84.30%\n",
      "54\tValidation loss: 0.681952\tBest loss: 0.681952\tAccuracy: 84.80%\n",
      "55\tValidation loss: 0.679077\tBest loss: 0.679077\tAccuracy: 85.00%\n",
      "56\tValidation loss: 0.677949\tBest loss: 0.677949\tAccuracy: 84.90%\n",
      "57\tValidation loss: 0.672316\tBest loss: 0.672316\tAccuracy: 85.30%\n",
      "58\tValidation loss: 0.669369\tBest loss: 0.669369\tAccuracy: 85.20%\n",
      "59\tValidation loss: 0.665400\tBest loss: 0.665400\tAccuracy: 85.60%\n",
      "60\tValidation loss: 0.664510\tBest loss: 0.664510\tAccuracy: 85.00%\n",
      "61\tValidation loss: 0.658104\tBest loss: 0.658104\tAccuracy: 85.20%\n",
      "62\tValidation loss: 0.654276\tBest loss: 0.654276\tAccuracy: 85.40%\n",
      "63\tValidation loss: 0.650361\tBest loss: 0.650361\tAccuracy: 85.50%\n",
      "64\tValidation loss: 0.646083\tBest loss: 0.646083\tAccuracy: 85.70%\n",
      "65\tValidation loss: 0.645319\tBest loss: 0.645319\tAccuracy: 85.50%\n",
      "66\tValidation loss: 0.641256\tBest loss: 0.641256\tAccuracy: 85.40%\n",
      "67\tValidation loss: 0.636795\tBest loss: 0.636795\tAccuracy: 85.90%\n",
      "68\tValidation loss: 0.635303\tBest loss: 0.635303\tAccuracy: 85.70%\n",
      "69\tValidation loss: 0.630102\tBest loss: 0.630102\tAccuracy: 86.00%\n",
      "70\tValidation loss: 0.631490\tBest loss: 0.630102\tAccuracy: 85.70%\n",
      "71\tValidation loss: 0.627883\tBest loss: 0.627883\tAccuracy: 85.80%\n",
      "72\tValidation loss: 0.620673\tBest loss: 0.620673\tAccuracy: 85.80%\n",
      "73\tValidation loss: 0.620947\tBest loss: 0.620673\tAccuracy: 86.00%\n",
      "74\tValidation loss: 0.620613\tBest loss: 0.620613\tAccuracy: 85.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\tValidation loss: 0.618023\tBest loss: 0.618023\tAccuracy: 85.40%\n",
      "76\tValidation loss: 0.616609\tBest loss: 0.616609\tAccuracy: 85.80%\n",
      "77\tValidation loss: 0.613832\tBest loss: 0.613832\tAccuracy: 85.80%\n",
      "78\tValidation loss: 0.609466\tBest loss: 0.609466\tAccuracy: 86.10%\n",
      "79\tValidation loss: 0.604391\tBest loss: 0.604391\tAccuracy: 86.10%\n",
      "80\tValidation loss: 0.608115\tBest loss: 0.604391\tAccuracy: 85.80%\n",
      "81\tValidation loss: 0.607617\tBest loss: 0.604391\tAccuracy: 85.70%\n",
      "82\tValidation loss: 0.603019\tBest loss: 0.603019\tAccuracy: 86.00%\n",
      "83\tValidation loss: 0.597992\tBest loss: 0.597992\tAccuracy: 86.00%\n",
      "84\tValidation loss: 0.597374\tBest loss: 0.597374\tAccuracy: 85.90%\n",
      "85\tValidation loss: 0.590780\tBest loss: 0.590780\tAccuracy: 86.20%\n",
      "86\tValidation loss: 0.593135\tBest loss: 0.590780\tAccuracy: 86.00%\n",
      "87\tValidation loss: 0.590848\tBest loss: 0.590780\tAccuracy: 86.10%\n",
      "88\tValidation loss: 0.587934\tBest loss: 0.587934\tAccuracy: 86.20%\n",
      "89\tValidation loss: 0.589216\tBest loss: 0.587934\tAccuracy: 85.50%\n",
      "90\tValidation loss: 0.585311\tBest loss: 0.585311\tAccuracy: 86.30%\n",
      "91\tValidation loss: 0.579062\tBest loss: 0.579062\tAccuracy: 86.40%\n",
      "92\tValidation loss: 0.580327\tBest loss: 0.579062\tAccuracy: 86.20%\n",
      "93\tValidation loss: 0.579013\tBest loss: 0.579013\tAccuracy: 86.30%\n",
      "94\tValidation loss: 0.577735\tBest loss: 0.577735\tAccuracy: 85.90%\n",
      "95\tValidation loss: 0.575941\tBest loss: 0.575941\tAccuracy: 86.20%\n",
      "96\tValidation loss: 0.574486\tBest loss: 0.574486\tAccuracy: 86.20%\n",
      "97\tValidation loss: 0.574855\tBest loss: 0.574486\tAccuracy: 86.00%\n",
      "98\tValidation loss: 0.567919\tBest loss: 0.567919\tAccuracy: 86.30%\n",
      "99\tValidation loss: 0.570882\tBest loss: 0.567919\tAccuracy: 86.80%\n",
      "100\tValidation loss: 0.568839\tBest loss: 0.567919\tAccuracy: 86.20%\n",
      "101\tValidation loss: 0.562908\tBest loss: 0.562908\tAccuracy: 86.40%\n",
      "102\tValidation loss: 0.562386\tBest loss: 0.562386\tAccuracy: 86.40%\n",
      "103\tValidation loss: 0.561586\tBest loss: 0.561586\tAccuracy: 86.40%\n",
      "104\tValidation loss: 0.561623\tBest loss: 0.561586\tAccuracy: 86.70%\n",
      "105\tValidation loss: 0.557843\tBest loss: 0.557843\tAccuracy: 86.80%\n",
      "106\tValidation loss: 0.557575\tBest loss: 0.557575\tAccuracy: 86.40%\n",
      "107\tValidation loss: 0.558185\tBest loss: 0.557575\tAccuracy: 86.30%\n",
      "108\tValidation loss: 0.557025\tBest loss: 0.557025\tAccuracy: 86.20%\n",
      "109\tValidation loss: 0.555317\tBest loss: 0.555317\tAccuracy: 86.50%\n",
      "110\tValidation loss: 0.553658\tBest loss: 0.553658\tAccuracy: 86.10%\n",
      "111\tValidation loss: 0.551238\tBest loss: 0.551238\tAccuracy: 86.20%\n",
      "112\tValidation loss: 0.549855\tBest loss: 0.549855\tAccuracy: 86.10%\n",
      "113\tValidation loss: 0.546210\tBest loss: 0.546210\tAccuracy: 86.40%\n",
      "114\tValidation loss: 0.545423\tBest loss: 0.545423\tAccuracy: 87.00%\n",
      "115\tValidation loss: 0.547737\tBest loss: 0.545423\tAccuracy: 86.40%\n",
      "116\tValidation loss: 0.544686\tBest loss: 0.544686\tAccuracy: 87.30%\n",
      "117\tValidation loss: 0.541380\tBest loss: 0.541380\tAccuracy: 87.20%\n",
      "118\tValidation loss: 0.540091\tBest loss: 0.540091\tAccuracy: 86.90%\n",
      "119\tValidation loss: 0.540668\tBest loss: 0.540091\tAccuracy: 86.90%\n",
      "120\tValidation loss: 0.541631\tBest loss: 0.540091\tAccuracy: 86.80%\n",
      "121\tValidation loss: 0.539417\tBest loss: 0.539417\tAccuracy: 87.10%\n",
      "122\tValidation loss: 0.538606\tBest loss: 0.538606\tAccuracy: 87.10%\n",
      "123\tValidation loss: 0.537278\tBest loss: 0.537278\tAccuracy: 86.70%\n",
      "124\tValidation loss: 0.535965\tBest loss: 0.535965\tAccuracy: 87.20%\n",
      "125\tValidation loss: 0.534799\tBest loss: 0.534799\tAccuracy: 87.10%\n",
      "126\tValidation loss: 0.531780\tBest loss: 0.531780\tAccuracy: 87.30%\n",
      "127\tValidation loss: 0.532337\tBest loss: 0.531780\tAccuracy: 87.20%\n",
      "128\tValidation loss: 0.528838\tBest loss: 0.528838\tAccuracy: 87.70%\n",
      "129\tValidation loss: 0.529145\tBest loss: 0.528838\tAccuracy: 87.00%\n",
      "130\tValidation loss: 0.530303\tBest loss: 0.528838\tAccuracy: 87.60%\n",
      "131\tValidation loss: 0.526956\tBest loss: 0.526956\tAccuracy: 87.30%\n",
      "132\tValidation loss: 0.526720\tBest loss: 0.526720\tAccuracy: 87.20%\n",
      "133\tValidation loss: 0.527496\tBest loss: 0.526720\tAccuracy: 87.00%\n",
      "134\tValidation loss: 0.525253\tBest loss: 0.525253\tAccuracy: 87.70%\n",
      "135\tValidation loss: 0.526313\tBest loss: 0.525253\tAccuracy: 87.10%\n",
      "136\tValidation loss: 0.521903\tBest loss: 0.521903\tAccuracy: 87.50%\n",
      "137\tValidation loss: 0.521542\tBest loss: 0.521542\tAccuracy: 87.10%\n",
      "138\tValidation loss: 0.519551\tBest loss: 0.519551\tAccuracy: 87.70%\n",
      "139\tValidation loss: 0.517826\tBest loss: 0.517826\tAccuracy: 87.80%\n",
      "140\tValidation loss: 0.518616\tBest loss: 0.517826\tAccuracy: 87.50%\n",
      "141\tValidation loss: 0.517925\tBest loss: 0.517826\tAccuracy: 87.90%\n",
      "142\tValidation loss: 0.518899\tBest loss: 0.517826\tAccuracy: 87.10%\n",
      "143\tValidation loss: 0.515560\tBest loss: 0.515560\tAccuracy: 87.80%\n",
      "144\tValidation loss: 0.514411\tBest loss: 0.514411\tAccuracy: 87.80%\n",
      "145\tValidation loss: 0.515497\tBest loss: 0.514411\tAccuracy: 87.20%\n",
      "146\tValidation loss: 0.513080\tBest loss: 0.513080\tAccuracy: 87.60%\n",
      "147\tValidation loss: 0.510692\tBest loss: 0.510692\tAccuracy: 88.40%\n",
      "148\tValidation loss: 0.511459\tBest loss: 0.510692\tAccuracy: 88.10%\n",
      "149\tValidation loss: 0.511941\tBest loss: 0.510692\tAccuracy: 87.80%\n",
      "150\tValidation loss: 0.510716\tBest loss: 0.510692\tAccuracy: 87.80%\n",
      "151\tValidation loss: 0.511625\tBest loss: 0.510692\tAccuracy: 87.70%\n",
      "152\tValidation loss: 0.506676\tBest loss: 0.506676\tAccuracy: 88.10%\n",
      "153\tValidation loss: 0.506629\tBest loss: 0.506629\tAccuracy: 88.10%\n",
      "154\tValidation loss: 0.507731\tBest loss: 0.506629\tAccuracy: 87.80%\n",
      "155\tValidation loss: 0.507095\tBest loss: 0.506629\tAccuracy: 88.10%\n",
      "156\tValidation loss: 0.505847\tBest loss: 0.505847\tAccuracy: 88.30%\n",
      "157\tValidation loss: 0.505222\tBest loss: 0.505222\tAccuracy: 88.50%\n",
      "158\tValidation loss: 0.502211\tBest loss: 0.502211\tAccuracy: 88.20%\n",
      "159\tValidation loss: 0.501941\tBest loss: 0.501941\tAccuracy: 88.10%\n",
      "160\tValidation loss: 0.505796\tBest loss: 0.501941\tAccuracy: 87.50%\n",
      "161\tValidation loss: 0.502392\tBest loss: 0.501941\tAccuracy: 87.70%\n",
      "162\tValidation loss: 0.502227\tBest loss: 0.501941\tAccuracy: 87.60%\n",
      "163\tValidation loss: 0.501224\tBest loss: 0.501224\tAccuracy: 87.80%\n",
      "164\tValidation loss: 0.497160\tBest loss: 0.497160\tAccuracy: 88.30%\n",
      "165\tValidation loss: 0.498121\tBest loss: 0.497160\tAccuracy: 88.10%\n",
      "166\tValidation loss: 0.497562\tBest loss: 0.497160\tAccuracy: 88.30%\n",
      "167\tValidation loss: 0.495576\tBest loss: 0.495576\tAccuracy: 88.10%\n",
      "168\tValidation loss: 0.496787\tBest loss: 0.495576\tAccuracy: 88.50%\n",
      "169\tValidation loss: 0.494792\tBest loss: 0.494792\tAccuracy: 88.50%\n",
      "170\tValidation loss: 0.496836\tBest loss: 0.494792\tAccuracy: 88.00%\n",
      "171\tValidation loss: 0.494197\tBest loss: 0.494197\tAccuracy: 88.40%\n",
      "172\tValidation loss: 0.492436\tBest loss: 0.492436\tAccuracy: 88.20%\n",
      "173\tValidation loss: 0.495319\tBest loss: 0.492436\tAccuracy: 88.00%\n",
      "174\tValidation loss: 0.492495\tBest loss: 0.492436\tAccuracy: 87.90%\n",
      "175\tValidation loss: 0.492366\tBest loss: 0.492366\tAccuracy: 87.70%\n",
      "176\tValidation loss: 0.493583\tBest loss: 0.492366\tAccuracy: 88.10%\n",
      "177\tValidation loss: 0.490838\tBest loss: 0.490838\tAccuracy: 87.90%\n",
      "178\tValidation loss: 0.490972\tBest loss: 0.490838\tAccuracy: 87.90%\n",
      "179\tValidation loss: 0.488654\tBest loss: 0.488654\tAccuracy: 88.30%\n",
      "180\tValidation loss: 0.488056\tBest loss: 0.488056\tAccuracy: 88.50%\n",
      "181\tValidation loss: 0.487427\tBest loss: 0.487427\tAccuracy: 87.80%\n",
      "182\tValidation loss: 0.489466\tBest loss: 0.487427\tAccuracy: 88.30%\n",
      "183\tValidation loss: 0.487073\tBest loss: 0.487073\tAccuracy: 88.70%\n",
      "184\tValidation loss: 0.488391\tBest loss: 0.487073\tAccuracy: 87.90%\n",
      "185\tValidation loss: 0.486528\tBest loss: 0.486528\tAccuracy: 88.40%\n",
      "186\tValidation loss: 0.484556\tBest loss: 0.484556\tAccuracy: 88.50%\n",
      "187\tValidation loss: 0.483354\tBest loss: 0.483354\tAccuracy: 88.60%\n",
      "188\tValidation loss: 0.484165\tBest loss: 0.483354\tAccuracy: 88.20%\n",
      "189\tValidation loss: 0.483704\tBest loss: 0.483354\tAccuracy: 88.00%\n",
      "190\tValidation loss: 0.481825\tBest loss: 0.481825\tAccuracy: 88.40%\n",
      "191\tValidation loss: 0.482754\tBest loss: 0.481825\tAccuracy: 88.20%\n",
      "192\tValidation loss: 0.481064\tBest loss: 0.481064\tAccuracy: 88.60%\n",
      "193\tValidation loss: 0.480438\tBest loss: 0.480438\tAccuracy: 88.50%\n",
      "194\tValidation loss: 0.481302\tBest loss: 0.480438\tAccuracy: 88.30%\n",
      "195\tValidation loss: 0.479927\tBest loss: 0.479927\tAccuracy: 88.50%\n",
      "196\tValidation loss: 0.479562\tBest loss: 0.479562\tAccuracy: 88.00%\n",
      "197\tValidation loss: 0.478203\tBest loss: 0.478203\tAccuracy: 88.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\tValidation loss: 0.477958\tBest loss: 0.477958\tAccuracy: 88.50%\n",
      "199\tValidation loss: 0.478118\tBest loss: 0.477958\tAccuracy: 88.30%\n",
      "200\tValidation loss: 0.479089\tBest loss: 0.477958\tAccuracy: 88.30%\n",
      "201\tValidation loss: 0.477815\tBest loss: 0.477815\tAccuracy: 88.30%\n",
      "202\tValidation loss: 0.477312\tBest loss: 0.477312\tAccuracy: 88.60%\n",
      "203\tValidation loss: 0.476669\tBest loss: 0.476669\tAccuracy: 88.70%\n",
      "204\tValidation loss: 0.477376\tBest loss: 0.476669\tAccuracy: 88.30%\n",
      "205\tValidation loss: 0.476081\tBest loss: 0.476081\tAccuracy: 88.50%\n",
      "206\tValidation loss: 0.474090\tBest loss: 0.474090\tAccuracy: 88.80%\n",
      "207\tValidation loss: 0.474882\tBest loss: 0.474090\tAccuracy: 88.20%\n",
      "208\tValidation loss: 0.475222\tBest loss: 0.474090\tAccuracy: 88.50%\n",
      "209\tValidation loss: 0.471294\tBest loss: 0.471294\tAccuracy: 88.60%\n",
      "210\tValidation loss: 0.471350\tBest loss: 0.471294\tAccuracy: 88.30%\n",
      "211\tValidation loss: 0.471803\tBest loss: 0.471294\tAccuracy: 88.60%\n",
      "212\tValidation loss: 0.470441\tBest loss: 0.470441\tAccuracy: 88.70%\n",
      "213\tValidation loss: 0.470031\tBest loss: 0.470031\tAccuracy: 88.80%\n",
      "214\tValidation loss: 0.469611\tBest loss: 0.469611\tAccuracy: 88.80%\n",
      "215\tValidation loss: 0.468959\tBest loss: 0.468959\tAccuracy: 88.60%\n",
      "216\tValidation loss: 0.467627\tBest loss: 0.467627\tAccuracy: 88.70%\n",
      "217\tValidation loss: 0.468579\tBest loss: 0.467627\tAccuracy: 88.90%\n",
      "218\tValidation loss: 0.469855\tBest loss: 0.467627\tAccuracy: 88.30%\n",
      "219\tValidation loss: 0.468351\tBest loss: 0.467627\tAccuracy: 88.60%\n",
      "220\tValidation loss: 0.467124\tBest loss: 0.467124\tAccuracy: 88.90%\n",
      "221\tValidation loss: 0.468893\tBest loss: 0.467124\tAccuracy: 88.80%\n",
      "222\tValidation loss: 0.468492\tBest loss: 0.467124\tAccuracy: 88.60%\n",
      "223\tValidation loss: 0.467111\tBest loss: 0.467111\tAccuracy: 88.60%\n",
      "224\tValidation loss: 0.465365\tBest loss: 0.465365\tAccuracy: 88.70%\n",
      "225\tValidation loss: 0.465372\tBest loss: 0.465365\tAccuracy: 88.90%\n",
      "226\tValidation loss: 0.463966\tBest loss: 0.463966\tAccuracy: 88.80%\n",
      "227\tValidation loss: 0.463178\tBest loss: 0.463178\tAccuracy: 89.10%\n",
      "228\tValidation loss: 0.463502\tBest loss: 0.463178\tAccuracy: 89.00%\n",
      "229\tValidation loss: 0.465202\tBest loss: 0.463178\tAccuracy: 88.70%\n",
      "230\tValidation loss: 0.464140\tBest loss: 0.463178\tAccuracy: 88.70%\n",
      "231\tValidation loss: 0.463299\tBest loss: 0.463178\tAccuracy: 88.90%\n",
      "232\tValidation loss: 0.462584\tBest loss: 0.462584\tAccuracy: 88.90%\n",
      "233\tValidation loss: 0.463221\tBest loss: 0.462584\tAccuracy: 88.90%\n",
      "234\tValidation loss: 0.461084\tBest loss: 0.461084\tAccuracy: 89.40%\n",
      "235\tValidation loss: 0.461032\tBest loss: 0.461032\tAccuracy: 88.70%\n",
      "236\tValidation loss: 0.462064\tBest loss: 0.461032\tAccuracy: 88.90%\n",
      "237\tValidation loss: 0.459898\tBest loss: 0.459898\tAccuracy: 88.90%\n",
      "238\tValidation loss: 0.459898\tBest loss: 0.459898\tAccuracy: 88.80%\n",
      "239\tValidation loss: 0.457996\tBest loss: 0.457996\tAccuracy: 89.00%\n",
      "240\tValidation loss: 0.460006\tBest loss: 0.457996\tAccuracy: 89.00%\n",
      "241\tValidation loss: 0.459080\tBest loss: 0.457996\tAccuracy: 89.20%\n",
      "242\tValidation loss: 0.457898\tBest loss: 0.457898\tAccuracy: 89.30%\n",
      "243\tValidation loss: 0.457632\tBest loss: 0.457632\tAccuracy: 89.20%\n",
      "244\tValidation loss: 0.457985\tBest loss: 0.457632\tAccuracy: 88.90%\n",
      "245\tValidation loss: 0.457509\tBest loss: 0.457509\tAccuracy: 89.00%\n",
      "246\tValidation loss: 0.457178\tBest loss: 0.457178\tAccuracy: 89.20%\n",
      "247\tValidation loss: 0.456316\tBest loss: 0.456316\tAccuracy: 89.10%\n",
      "248\tValidation loss: 0.455535\tBest loss: 0.455535\tAccuracy: 89.20%\n",
      "249\tValidation loss: 0.453932\tBest loss: 0.453932\tAccuracy: 89.30%\n",
      "250\tValidation loss: 0.457342\tBest loss: 0.453932\tAccuracy: 88.90%\n",
      "251\tValidation loss: 0.455447\tBest loss: 0.453932\tAccuracy: 89.10%\n",
      "252\tValidation loss: 0.454048\tBest loss: 0.453932\tAccuracy: 89.20%\n",
      "253\tValidation loss: 0.454522\tBest loss: 0.453932\tAccuracy: 89.20%\n",
      "254\tValidation loss: 0.455263\tBest loss: 0.453932\tAccuracy: 88.80%\n",
      "255\tValidation loss: 0.453931\tBest loss: 0.453931\tAccuracy: 89.00%\n",
      "256\tValidation loss: 0.453810\tBest loss: 0.453810\tAccuracy: 88.80%\n",
      "257\tValidation loss: 0.453903\tBest loss: 0.453810\tAccuracy: 88.90%\n",
      "258\tValidation loss: 0.452373\tBest loss: 0.452373\tAccuracy: 89.20%\n",
      "259\tValidation loss: 0.451189\tBest loss: 0.451189\tAccuracy: 89.10%\n",
      "260\tValidation loss: 0.451964\tBest loss: 0.451189\tAccuracy: 89.00%\n",
      "261\tValidation loss: 0.450279\tBest loss: 0.450279\tAccuracy: 89.30%\n",
      "262\tValidation loss: 0.452798\tBest loss: 0.450279\tAccuracy: 89.10%\n",
      "263\tValidation loss: 0.452329\tBest loss: 0.450279\tAccuracy: 89.00%\n",
      "264\tValidation loss: 0.451088\tBest loss: 0.450279\tAccuracy: 88.80%\n",
      "265\tValidation loss: 0.450740\tBest loss: 0.450279\tAccuracy: 89.10%\n",
      "266\tValidation loss: 0.450896\tBest loss: 0.450279\tAccuracy: 88.60%\n",
      "267\tValidation loss: 0.451151\tBest loss: 0.450279\tAccuracy: 89.00%\n",
      "268\tValidation loss: 0.451459\tBest loss: 0.450279\tAccuracy: 89.00%\n",
      "269\tValidation loss: 0.449191\tBest loss: 0.449191\tAccuracy: 88.90%\n",
      "270\tValidation loss: 0.449505\tBest loss: 0.449191\tAccuracy: 89.30%\n",
      "271\tValidation loss: 0.448201\tBest loss: 0.448201\tAccuracy: 89.00%\n",
      "272\tValidation loss: 0.447264\tBest loss: 0.447264\tAccuracy: 89.10%\n",
      "273\tValidation loss: 0.449156\tBest loss: 0.447264\tAccuracy: 89.00%\n",
      "274\tValidation loss: 0.447534\tBest loss: 0.447264\tAccuracy: 89.30%\n",
      "275\tValidation loss: 0.445920\tBest loss: 0.445920\tAccuracy: 89.10%\n",
      "276\tValidation loss: 0.447236\tBest loss: 0.445920\tAccuracy: 88.90%\n",
      "277\tValidation loss: 0.447072\tBest loss: 0.445920\tAccuracy: 88.90%\n",
      "278\tValidation loss: 0.445691\tBest loss: 0.445691\tAccuracy: 89.20%\n",
      "279\tValidation loss: 0.444928\tBest loss: 0.444928\tAccuracy: 89.20%\n",
      "280\tValidation loss: 0.447451\tBest loss: 0.444928\tAccuracy: 89.00%\n",
      "281\tValidation loss: 0.446023\tBest loss: 0.444928\tAccuracy: 89.10%\n",
      "282\tValidation loss: 0.444779\tBest loss: 0.444779\tAccuracy: 89.20%\n",
      "283\tValidation loss: 0.444031\tBest loss: 0.444031\tAccuracy: 89.00%\n",
      "284\tValidation loss: 0.445207\tBest loss: 0.444031\tAccuracy: 89.30%\n",
      "285\tValidation loss: 0.444515\tBest loss: 0.444031\tAccuracy: 89.40%\n",
      "286\tValidation loss: 0.443274\tBest loss: 0.443274\tAccuracy: 89.40%\n",
      "287\tValidation loss: 0.444321\tBest loss: 0.443274\tAccuracy: 88.90%\n",
      "288\tValidation loss: 0.443023\tBest loss: 0.443023\tAccuracy: 89.20%\n",
      "289\tValidation loss: 0.443048\tBest loss: 0.443023\tAccuracy: 89.20%\n",
      "290\tValidation loss: 0.442790\tBest loss: 0.442790\tAccuracy: 89.20%\n",
      "291\tValidation loss: 0.441239\tBest loss: 0.441239\tAccuracy: 89.50%\n",
      "292\tValidation loss: 0.441804\tBest loss: 0.441239\tAccuracy: 89.30%\n",
      "293\tValidation loss: 0.441466\tBest loss: 0.441239\tAccuracy: 89.20%\n",
      "294\tValidation loss: 0.441407\tBest loss: 0.441239\tAccuracy: 89.00%\n",
      "295\tValidation loss: 0.441676\tBest loss: 0.441239\tAccuracy: 89.50%\n",
      "296\tValidation loss: 0.441426\tBest loss: 0.441239\tAccuracy: 89.40%\n",
      "297\tValidation loss: 0.441052\tBest loss: 0.441052\tAccuracy: 89.10%\n",
      "298\tValidation loss: 0.442250\tBest loss: 0.441052\tAccuracy: 89.30%\n",
      "299\tValidation loss: 0.440107\tBest loss: 0.440107\tAccuracy: 89.60%\n",
      "300\tValidation loss: 0.440345\tBest loss: 0.440107\tAccuracy: 89.10%\n",
      "301\tValidation loss: 0.439962\tBest loss: 0.439962\tAccuracy: 89.20%\n",
      "302\tValidation loss: 0.439152\tBest loss: 0.439152\tAccuracy: 89.30%\n",
      "303\tValidation loss: 0.438724\tBest loss: 0.438724\tAccuracy: 89.60%\n",
      "304\tValidation loss: 0.439285\tBest loss: 0.438724\tAccuracy: 89.00%\n",
      "305\tValidation loss: 0.438475\tBest loss: 0.438475\tAccuracy: 89.20%\n",
      "306\tValidation loss: 0.437629\tBest loss: 0.437629\tAccuracy: 89.20%\n",
      "307\tValidation loss: 0.437290\tBest loss: 0.437290\tAccuracy: 89.40%\n",
      "308\tValidation loss: 0.437438\tBest loss: 0.437290\tAccuracy: 89.50%\n",
      "309\tValidation loss: 0.436978\tBest loss: 0.436978\tAccuracy: 89.30%\n",
      "310\tValidation loss: 0.436450\tBest loss: 0.436450\tAccuracy: 89.60%\n",
      "311\tValidation loss: 0.436130\tBest loss: 0.436130\tAccuracy: 89.60%\n",
      "312\tValidation loss: 0.436931\tBest loss: 0.436130\tAccuracy: 89.20%\n",
      "313\tValidation loss: 0.434978\tBest loss: 0.434978\tAccuracy: 89.60%\n",
      "314\tValidation loss: 0.435492\tBest loss: 0.434978\tAccuracy: 89.50%\n",
      "315\tValidation loss: 0.434793\tBest loss: 0.434793\tAccuracy: 89.50%\n",
      "316\tValidation loss: 0.434293\tBest loss: 0.434293\tAccuracy: 89.70%\n",
      "317\tValidation loss: 0.436360\tBest loss: 0.434293\tAccuracy: 89.30%\n",
      "318\tValidation loss: 0.433919\tBest loss: 0.433919\tAccuracy: 89.60%\n",
      "319\tValidation loss: 0.435016\tBest loss: 0.433919\tAccuracy: 89.60%\n",
      "320\tValidation loss: 0.434159\tBest loss: 0.433919\tAccuracy: 89.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\tValidation loss: 0.433278\tBest loss: 0.433278\tAccuracy: 89.60%\n",
      "322\tValidation loss: 0.433664\tBest loss: 0.433278\tAccuracy: 89.40%\n",
      "323\tValidation loss: 0.432914\tBest loss: 0.432914\tAccuracy: 89.70%\n",
      "324\tValidation loss: 0.431671\tBest loss: 0.431671\tAccuracy: 89.80%\n",
      "325\tValidation loss: 0.432884\tBest loss: 0.431671\tAccuracy: 89.60%\n",
      "326\tValidation loss: 0.433816\tBest loss: 0.431671\tAccuracy: 89.60%\n",
      "327\tValidation loss: 0.432939\tBest loss: 0.431671\tAccuracy: 89.30%\n",
      "328\tValidation loss: 0.432779\tBest loss: 0.431671\tAccuracy: 89.60%\n",
      "329\tValidation loss: 0.432230\tBest loss: 0.431671\tAccuracy: 89.50%\n",
      "330\tValidation loss: 0.432365\tBest loss: 0.431671\tAccuracy: 89.40%\n",
      "331\tValidation loss: 0.431393\tBest loss: 0.431393\tAccuracy: 89.40%\n",
      "332\tValidation loss: 0.432325\tBest loss: 0.431393\tAccuracy: 89.10%\n",
      "333\tValidation loss: 0.430915\tBest loss: 0.430915\tAccuracy: 89.80%\n",
      "334\tValidation loss: 0.432248\tBest loss: 0.430915\tAccuracy: 89.60%\n",
      "335\tValidation loss: 0.430506\tBest loss: 0.430506\tAccuracy: 89.40%\n",
      "336\tValidation loss: 0.428981\tBest loss: 0.428981\tAccuracy: 89.90%\n",
      "337\tValidation loss: 0.429584\tBest loss: 0.428981\tAccuracy: 89.60%\n",
      "338\tValidation loss: 0.428543\tBest loss: 0.428543\tAccuracy: 89.70%\n",
      "339\tValidation loss: 0.429196\tBest loss: 0.428543\tAccuracy: 89.50%\n",
      "340\tValidation loss: 0.429555\tBest loss: 0.428543\tAccuracy: 89.70%\n",
      "341\tValidation loss: 0.429644\tBest loss: 0.428543\tAccuracy: 89.30%\n",
      "342\tValidation loss: 0.428496\tBest loss: 0.428496\tAccuracy: 89.70%\n",
      "343\tValidation loss: 0.428259\tBest loss: 0.428259\tAccuracy: 89.30%\n",
      "344\tValidation loss: 0.428300\tBest loss: 0.428259\tAccuracy: 89.70%\n",
      "345\tValidation loss: 0.428801\tBest loss: 0.428259\tAccuracy: 89.50%\n",
      "346\tValidation loss: 0.427573\tBest loss: 0.427573\tAccuracy: 89.50%\n",
      "347\tValidation loss: 0.427947\tBest loss: 0.427573\tAccuracy: 89.30%\n",
      "348\tValidation loss: 0.428034\tBest loss: 0.427573\tAccuracy: 89.60%\n",
      "349\tValidation loss: 0.427644\tBest loss: 0.427573\tAccuracy: 89.50%\n",
      "350\tValidation loss: 0.426832\tBest loss: 0.426832\tAccuracy: 89.90%\n",
      "351\tValidation loss: 0.427754\tBest loss: 0.426832\tAccuracy: 90.00%\n",
      "352\tValidation loss: 0.427460\tBest loss: 0.426832\tAccuracy: 89.60%\n",
      "353\tValidation loss: 0.426000\tBest loss: 0.426000\tAccuracy: 90.00%\n",
      "354\tValidation loss: 0.427268\tBest loss: 0.426000\tAccuracy: 89.20%\n",
      "355\tValidation loss: 0.425472\tBest loss: 0.425472\tAccuracy: 89.90%\n",
      "356\tValidation loss: 0.425340\tBest loss: 0.425340\tAccuracy: 89.70%\n",
      "357\tValidation loss: 0.424435\tBest loss: 0.424435\tAccuracy: 89.80%\n",
      "358\tValidation loss: 0.426101\tBest loss: 0.424435\tAccuracy: 89.60%\n",
      "359\tValidation loss: 0.426967\tBest loss: 0.424435\tAccuracy: 89.50%\n",
      "360\tValidation loss: 0.425443\tBest loss: 0.424435\tAccuracy: 89.90%\n",
      "361\tValidation loss: 0.424486\tBest loss: 0.424435\tAccuracy: 89.90%\n",
      "362\tValidation loss: 0.424018\tBest loss: 0.424018\tAccuracy: 89.70%\n",
      "363\tValidation loss: 0.423741\tBest loss: 0.423741\tAccuracy: 89.80%\n",
      "364\tValidation loss: 0.424966\tBest loss: 0.423741\tAccuracy: 90.10%\n",
      "365\tValidation loss: 0.424814\tBest loss: 0.423741\tAccuracy: 89.90%\n",
      "366\tValidation loss: 0.422898\tBest loss: 0.422898\tAccuracy: 90.00%\n",
      "367\tValidation loss: 0.422354\tBest loss: 0.422354\tAccuracy: 89.80%\n",
      "368\tValidation loss: 0.422057\tBest loss: 0.422057\tAccuracy: 89.60%\n",
      "369\tValidation loss: 0.421830\tBest loss: 0.421830\tAccuracy: 89.80%\n",
      "370\tValidation loss: 0.422183\tBest loss: 0.421830\tAccuracy: 89.90%\n",
      "371\tValidation loss: 0.421692\tBest loss: 0.421692\tAccuracy: 90.20%\n",
      "372\tValidation loss: 0.421412\tBest loss: 0.421412\tAccuracy: 90.20%\n",
      "373\tValidation loss: 0.422655\tBest loss: 0.421412\tAccuracy: 89.60%\n",
      "374\tValidation loss: 0.421042\tBest loss: 0.421042\tAccuracy: 90.10%\n",
      "375\tValidation loss: 0.420111\tBest loss: 0.420111\tAccuracy: 89.80%\n",
      "376\tValidation loss: 0.421692\tBest loss: 0.420111\tAccuracy: 89.90%\n",
      "377\tValidation loss: 0.421349\tBest loss: 0.420111\tAccuracy: 89.60%\n",
      "378\tValidation loss: 0.420608\tBest loss: 0.420111\tAccuracy: 89.70%\n",
      "379\tValidation loss: 0.420872\tBest loss: 0.420111\tAccuracy: 89.90%\n",
      "380\tValidation loss: 0.420466\tBest loss: 0.420111\tAccuracy: 89.90%\n",
      "381\tValidation loss: 0.419879\tBest loss: 0.419879\tAccuracy: 90.10%\n",
      "382\tValidation loss: 0.420681\tBest loss: 0.419879\tAccuracy: 89.80%\n",
      "383\tValidation loss: 0.419119\tBest loss: 0.419119\tAccuracy: 90.00%\n",
      "384\tValidation loss: 0.420315\tBest loss: 0.419119\tAccuracy: 89.80%\n",
      "385\tValidation loss: 0.418310\tBest loss: 0.418310\tAccuracy: 90.10%\n",
      "386\tValidation loss: 0.420160\tBest loss: 0.418310\tAccuracy: 89.90%\n",
      "387\tValidation loss: 0.419439\tBest loss: 0.418310\tAccuracy: 89.60%\n",
      "388\tValidation loss: 0.417751\tBest loss: 0.417751\tAccuracy: 89.90%\n",
      "389\tValidation loss: 0.419536\tBest loss: 0.417751\tAccuracy: 90.00%\n",
      "390\tValidation loss: 0.417755\tBest loss: 0.417751\tAccuracy: 89.80%\n",
      "391\tValidation loss: 0.417307\tBest loss: 0.417307\tAccuracy: 90.00%\n",
      "392\tValidation loss: 0.417472\tBest loss: 0.417307\tAccuracy: 90.10%\n",
      "393\tValidation loss: 0.417838\tBest loss: 0.417307\tAccuracy: 90.00%\n",
      "394\tValidation loss: 0.416476\tBest loss: 0.416476\tAccuracy: 90.10%\n",
      "395\tValidation loss: 0.418284\tBest loss: 0.416476\tAccuracy: 89.90%\n",
      "396\tValidation loss: 0.416729\tBest loss: 0.416476\tAccuracy: 90.10%\n",
      "397\tValidation loss: 0.416392\tBest loss: 0.416392\tAccuracy: 90.00%\n",
      "398\tValidation loss: 0.416213\tBest loss: 0.416213\tAccuracy: 90.10%\n",
      "399\tValidation loss: 0.416772\tBest loss: 0.416213\tAccuracy: 89.90%\n",
      "400\tValidation loss: 0.415623\tBest loss: 0.415623\tAccuracy: 89.90%\n",
      "401\tValidation loss: 0.416625\tBest loss: 0.415623\tAccuracy: 89.90%\n",
      "402\tValidation loss: 0.414969\tBest loss: 0.414969\tAccuracy: 90.00%\n",
      "403\tValidation loss: 0.415880\tBest loss: 0.414969\tAccuracy: 90.00%\n",
      "404\tValidation loss: 0.415284\tBest loss: 0.414969\tAccuracy: 89.90%\n",
      "405\tValidation loss: 0.416086\tBest loss: 0.414969\tAccuracy: 90.00%\n",
      "406\tValidation loss: 0.416005\tBest loss: 0.414969\tAccuracy: 89.90%\n",
      "407\tValidation loss: 0.413478\tBest loss: 0.413478\tAccuracy: 90.00%\n",
      "408\tValidation loss: 0.413837\tBest loss: 0.413478\tAccuracy: 89.80%\n",
      "409\tValidation loss: 0.414293\tBest loss: 0.413478\tAccuracy: 89.90%\n",
      "410\tValidation loss: 0.413905\tBest loss: 0.413478\tAccuracy: 90.10%\n",
      "411\tValidation loss: 0.414739\tBest loss: 0.413478\tAccuracy: 90.10%\n",
      "412\tValidation loss: 0.412700\tBest loss: 0.412700\tAccuracy: 89.90%\n",
      "413\tValidation loss: 0.413326\tBest loss: 0.412700\tAccuracy: 89.80%\n",
      "414\tValidation loss: 0.413396\tBest loss: 0.412700\tAccuracy: 90.20%\n",
      "415\tValidation loss: 0.414143\tBest loss: 0.412700\tAccuracy: 90.00%\n",
      "416\tValidation loss: 0.413896\tBest loss: 0.412700\tAccuracy: 89.90%\n",
      "417\tValidation loss: 0.413130\tBest loss: 0.412700\tAccuracy: 90.00%\n",
      "418\tValidation loss: 0.412779\tBest loss: 0.412700\tAccuracy: 90.10%\n",
      "419\tValidation loss: 0.412748\tBest loss: 0.412700\tAccuracy: 90.20%\n",
      "420\tValidation loss: 0.412729\tBest loss: 0.412700\tAccuracy: 90.00%\n",
      "421\tValidation loss: 0.412327\tBest loss: 0.412327\tAccuracy: 89.90%\n",
      "422\tValidation loss: 0.412236\tBest loss: 0.412236\tAccuracy: 90.20%\n",
      "423\tValidation loss: 0.411879\tBest loss: 0.411879\tAccuracy: 90.20%\n",
      "424\tValidation loss: 0.412135\tBest loss: 0.411879\tAccuracy: 90.10%\n",
      "425\tValidation loss: 0.413026\tBest loss: 0.411879\tAccuracy: 90.20%\n",
      "426\tValidation loss: 0.411839\tBest loss: 0.411839\tAccuracy: 90.20%\n",
      "427\tValidation loss: 0.410730\tBest loss: 0.410730\tAccuracy: 90.20%\n",
      "428\tValidation loss: 0.411283\tBest loss: 0.410730\tAccuracy: 90.20%\n",
      "429\tValidation loss: 0.412317\tBest loss: 0.410730\tAccuracy: 90.10%\n",
      "430\tValidation loss: 0.410191\tBest loss: 0.410191\tAccuracy: 90.20%\n",
      "431\tValidation loss: 0.411399\tBest loss: 0.410191\tAccuracy: 90.30%\n",
      "432\tValidation loss: 0.411527\tBest loss: 0.410191\tAccuracy: 90.30%\n",
      "433\tValidation loss: 0.410554\tBest loss: 0.410191\tAccuracy: 90.20%\n",
      "434\tValidation loss: 0.410488\tBest loss: 0.410191\tAccuracy: 90.40%\n",
      "435\tValidation loss: 0.410241\tBest loss: 0.410191\tAccuracy: 90.60%\n",
      "436\tValidation loss: 0.410706\tBest loss: 0.410191\tAccuracy: 90.40%\n",
      "437\tValidation loss: 0.410411\tBest loss: 0.410191\tAccuracy: 90.20%\n",
      "438\tValidation loss: 0.409809\tBest loss: 0.409809\tAccuracy: 90.40%\n",
      "439\tValidation loss: 0.409973\tBest loss: 0.409809\tAccuracy: 90.50%\n",
      "440\tValidation loss: 0.409459\tBest loss: 0.409459\tAccuracy: 90.20%\n",
      "441\tValidation loss: 0.409541\tBest loss: 0.409459\tAccuracy: 90.30%\n",
      "442\tValidation loss: 0.410425\tBest loss: 0.409459\tAccuracy: 90.50%\n",
      "443\tValidation loss: 0.408569\tBest loss: 0.408569\tAccuracy: 90.50%\n",
      "444\tValidation loss: 0.409067\tBest loss: 0.408569\tAccuracy: 90.60%\n",
      "445\tValidation loss: 0.409163\tBest loss: 0.408569\tAccuracy: 90.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\tValidation loss: 0.408938\tBest loss: 0.408569\tAccuracy: 90.30%\n",
      "447\tValidation loss: 0.407988\tBest loss: 0.407988\tAccuracy: 90.50%\n",
      "448\tValidation loss: 0.408744\tBest loss: 0.407988\tAccuracy: 90.40%\n",
      "449\tValidation loss: 0.407861\tBest loss: 0.407861\tAccuracy: 90.50%\n",
      "450\tValidation loss: 0.408076\tBest loss: 0.407861\tAccuracy: 90.60%\n",
      "451\tValidation loss: 0.406090\tBest loss: 0.406090\tAccuracy: 90.50%\n",
      "452\tValidation loss: 0.408696\tBest loss: 0.406090\tAccuracy: 90.40%\n",
      "453\tValidation loss: 0.408790\tBest loss: 0.406090\tAccuracy: 90.40%\n",
      "454\tValidation loss: 0.407711\tBest loss: 0.406090\tAccuracy: 90.60%\n",
      "455\tValidation loss: 0.408499\tBest loss: 0.406090\tAccuracy: 90.40%\n",
      "456\tValidation loss: 0.406777\tBest loss: 0.406090\tAccuracy: 90.30%\n",
      "457\tValidation loss: 0.407745\tBest loss: 0.406090\tAccuracy: 90.30%\n",
      "458\tValidation loss: 0.407758\tBest loss: 0.406090\tAccuracy: 90.40%\n",
      "459\tValidation loss: 0.406402\tBest loss: 0.406090\tAccuracy: 90.80%\n",
      "460\tValidation loss: 0.407124\tBest loss: 0.406090\tAccuracy: 90.50%\n",
      "461\tValidation loss: 0.406837\tBest loss: 0.406090\tAccuracy: 90.70%\n",
      "462\tValidation loss: 0.406670\tBest loss: 0.406090\tAccuracy: 90.40%\n",
      "463\tValidation loss: 0.406401\tBest loss: 0.406090\tAccuracy: 90.50%\n",
      "464\tValidation loss: 0.406142\tBest loss: 0.406090\tAccuracy: 90.60%\n",
      "465\tValidation loss: 0.406094\tBest loss: 0.406090\tAccuracy: 90.70%\n",
      "466\tValidation loss: 0.406423\tBest loss: 0.406090\tAccuracy: 90.50%\n",
      "467\tValidation loss: 0.406234\tBest loss: 0.406090\tAccuracy: 90.80%\n",
      "468\tValidation loss: 0.406497\tBest loss: 0.406090\tAccuracy: 90.50%\n",
      "469\tValidation loss: 0.405421\tBest loss: 0.405421\tAccuracy: 90.40%\n",
      "470\tValidation loss: 0.405546\tBest loss: 0.405421\tAccuracy: 90.60%\n",
      "471\tValidation loss: 0.405067\tBest loss: 0.405067\tAccuracy: 90.60%\n",
      "472\tValidation loss: 0.404391\tBest loss: 0.404391\tAccuracy: 90.50%\n",
      "473\tValidation loss: 0.404971\tBest loss: 0.404391\tAccuracy: 90.60%\n",
      "474\tValidation loss: 0.405151\tBest loss: 0.404391\tAccuracy: 90.30%\n",
      "475\tValidation loss: 0.404274\tBest loss: 0.404274\tAccuracy: 90.70%\n",
      "476\tValidation loss: 0.404561\tBest loss: 0.404274\tAccuracy: 90.50%\n",
      "477\tValidation loss: 0.404340\tBest loss: 0.404274\tAccuracy: 90.50%\n",
      "478\tValidation loss: 0.404399\tBest loss: 0.404274\tAccuracy: 90.60%\n",
      "479\tValidation loss: 0.405404\tBest loss: 0.404274\tAccuracy: 90.60%\n",
      "480\tValidation loss: 0.404101\tBest loss: 0.404101\tAccuracy: 90.60%\n",
      "481\tValidation loss: 0.403573\tBest loss: 0.403573\tAccuracy: 90.70%\n",
      "482\tValidation loss: 0.403239\tBest loss: 0.403239\tAccuracy: 90.50%\n",
      "483\tValidation loss: 0.403537\tBest loss: 0.403239\tAccuracy: 90.60%\n",
      "484\tValidation loss: 0.402881\tBest loss: 0.402881\tAccuracy: 90.60%\n",
      "485\tValidation loss: 0.402943\tBest loss: 0.402881\tAccuracy: 90.60%\n",
      "486\tValidation loss: 0.402150\tBest loss: 0.402150\tAccuracy: 90.50%\n",
      "487\tValidation loss: 0.401878\tBest loss: 0.401878\tAccuracy: 90.70%\n",
      "488\tValidation loss: 0.402416\tBest loss: 0.401878\tAccuracy: 90.80%\n",
      "489\tValidation loss: 0.403123\tBest loss: 0.401878\tAccuracy: 90.80%\n",
      "490\tValidation loss: 0.402768\tBest loss: 0.401878\tAccuracy: 90.70%\n",
      "491\tValidation loss: 0.402338\tBest loss: 0.401878\tAccuracy: 90.70%\n",
      "492\tValidation loss: 0.402779\tBest loss: 0.401878\tAccuracy: 90.80%\n",
      "493\tValidation loss: 0.402263\tBest loss: 0.401878\tAccuracy: 90.90%\n",
      "494\tValidation loss: 0.402430\tBest loss: 0.401878\tAccuracy: 91.10%\n",
      "495\tValidation loss: 0.401842\tBest loss: 0.401842\tAccuracy: 91.00%\n",
      "496\tValidation loss: 0.401469\tBest loss: 0.401469\tAccuracy: 91.00%\n",
      "497\tValidation loss: 0.401630\tBest loss: 0.401469\tAccuracy: 91.10%\n",
      "498\tValidation loss: 0.402751\tBest loss: 0.401469\tAccuracy: 90.70%\n",
      "499\tValidation loss: 0.402231\tBest loss: 0.401469\tAccuracy: 90.70%\n",
      "500\tValidation loss: 0.401209\tBest loss: 0.401209\tAccuracy: 90.90%\n",
      "501\tValidation loss: 0.401447\tBest loss: 0.401209\tAccuracy: 90.70%\n",
      "502\tValidation loss: 0.402094\tBest loss: 0.401209\tAccuracy: 90.90%\n",
      "503\tValidation loss: 0.400846\tBest loss: 0.400846\tAccuracy: 90.90%\n",
      "504\tValidation loss: 0.399587\tBest loss: 0.399587\tAccuracy: 91.00%\n",
      "505\tValidation loss: 0.400184\tBest loss: 0.399587\tAccuracy: 90.70%\n",
      "506\tValidation loss: 0.400869\tBest loss: 0.399587\tAccuracy: 90.80%\n",
      "507\tValidation loss: 0.400831\tBest loss: 0.399587\tAccuracy: 90.90%\n",
      "508\tValidation loss: 0.399767\tBest loss: 0.399587\tAccuracy: 90.80%\n",
      "509\tValidation loss: 0.399513\tBest loss: 0.399513\tAccuracy: 90.90%\n",
      "510\tValidation loss: 0.400334\tBest loss: 0.399513\tAccuracy: 91.10%\n",
      "511\tValidation loss: 0.400448\tBest loss: 0.399513\tAccuracy: 90.90%\n",
      "512\tValidation loss: 0.399884\tBest loss: 0.399513\tAccuracy: 91.00%\n",
      "513\tValidation loss: 0.399863\tBest loss: 0.399513\tAccuracy: 91.00%\n",
      "514\tValidation loss: 0.398647\tBest loss: 0.398647\tAccuracy: 90.70%\n",
      "515\tValidation loss: 0.398400\tBest loss: 0.398400\tAccuracy: 91.00%\n",
      "516\tValidation loss: 0.398940\tBest loss: 0.398400\tAccuracy: 91.00%\n",
      "517\tValidation loss: 0.398223\tBest loss: 0.398223\tAccuracy: 90.90%\n",
      "518\tValidation loss: 0.399235\tBest loss: 0.398223\tAccuracy: 90.90%\n",
      "519\tValidation loss: 0.399139\tBest loss: 0.398223\tAccuracy: 90.80%\n",
      "520\tValidation loss: 0.398379\tBest loss: 0.398223\tAccuracy: 90.90%\n",
      "521\tValidation loss: 0.398180\tBest loss: 0.398180\tAccuracy: 90.80%\n",
      "522\tValidation loss: 0.399594\tBest loss: 0.398180\tAccuracy: 90.90%\n",
      "523\tValidation loss: 0.399011\tBest loss: 0.398180\tAccuracy: 91.20%\n",
      "524\tValidation loss: 0.399213\tBest loss: 0.398180\tAccuracy: 90.90%\n",
      "525\tValidation loss: 0.399108\tBest loss: 0.398180\tAccuracy: 90.90%\n",
      "526\tValidation loss: 0.397706\tBest loss: 0.397706\tAccuracy: 90.60%\n",
      "527\tValidation loss: 0.397570\tBest loss: 0.397570\tAccuracy: 90.90%\n",
      "528\tValidation loss: 0.398448\tBest loss: 0.397570\tAccuracy: 91.10%\n",
      "529\tValidation loss: 0.398289\tBest loss: 0.397570\tAccuracy: 91.10%\n",
      "530\tValidation loss: 0.397649\tBest loss: 0.397570\tAccuracy: 91.30%\n",
      "531\tValidation loss: 0.397298\tBest loss: 0.397298\tAccuracy: 91.00%\n",
      "532\tValidation loss: 0.397845\tBest loss: 0.397298\tAccuracy: 91.10%\n",
      "533\tValidation loss: 0.397548\tBest loss: 0.397298\tAccuracy: 90.90%\n",
      "534\tValidation loss: 0.397432\tBest loss: 0.397298\tAccuracy: 91.20%\n",
      "535\tValidation loss: 0.395648\tBest loss: 0.395648\tAccuracy: 90.90%\n",
      "536\tValidation loss: 0.396292\tBest loss: 0.395648\tAccuracy: 91.20%\n",
      "537\tValidation loss: 0.395802\tBest loss: 0.395648\tAccuracy: 91.10%\n",
      "538\tValidation loss: 0.397252\tBest loss: 0.395648\tAccuracy: 91.10%\n",
      "539\tValidation loss: 0.397443\tBest loss: 0.395648\tAccuracy: 90.90%\n",
      "540\tValidation loss: 0.396399\tBest loss: 0.395648\tAccuracy: 91.10%\n",
      "541\tValidation loss: 0.397395\tBest loss: 0.395648\tAccuracy: 91.10%\n",
      "542\tValidation loss: 0.396463\tBest loss: 0.395648\tAccuracy: 91.20%\n",
      "543\tValidation loss: 0.395998\tBest loss: 0.395648\tAccuracy: 90.90%\n",
      "544\tValidation loss: 0.396411\tBest loss: 0.395648\tAccuracy: 91.30%\n",
      "545\tValidation loss: 0.395770\tBest loss: 0.395648\tAccuracy: 91.00%\n",
      "546\tValidation loss: 0.395458\tBest loss: 0.395458\tAccuracy: 91.00%\n",
      "547\tValidation loss: 0.395187\tBest loss: 0.395187\tAccuracy: 91.20%\n",
      "548\tValidation loss: 0.395067\tBest loss: 0.395067\tAccuracy: 91.00%\n",
      "549\tValidation loss: 0.395532\tBest loss: 0.395067\tAccuracy: 91.20%\n",
      "550\tValidation loss: 0.395588\tBest loss: 0.395067\tAccuracy: 91.10%\n",
      "551\tValidation loss: 0.394759\tBest loss: 0.394759\tAccuracy: 91.20%\n",
      "552\tValidation loss: 0.395632\tBest loss: 0.394759\tAccuracy: 91.20%\n",
      "553\tValidation loss: 0.395153\tBest loss: 0.394759\tAccuracy: 91.20%\n",
      "554\tValidation loss: 0.395434\tBest loss: 0.394759\tAccuracy: 91.10%\n",
      "555\tValidation loss: 0.395717\tBest loss: 0.394759\tAccuracy: 91.20%\n",
      "556\tValidation loss: 0.394224\tBest loss: 0.394224\tAccuracy: 91.20%\n",
      "557\tValidation loss: 0.394477\tBest loss: 0.394224\tAccuracy: 91.20%\n",
      "558\tValidation loss: 0.394993\tBest loss: 0.394224\tAccuracy: 91.20%\n",
      "559\tValidation loss: 0.394254\tBest loss: 0.394224\tAccuracy: 91.00%\n",
      "560\tValidation loss: 0.394303\tBest loss: 0.394224\tAccuracy: 91.10%\n",
      "561\tValidation loss: 0.394051\tBest loss: 0.394051\tAccuracy: 91.00%\n",
      "562\tValidation loss: 0.393683\tBest loss: 0.393683\tAccuracy: 91.10%\n",
      "563\tValidation loss: 0.393993\tBest loss: 0.393683\tAccuracy: 91.20%\n",
      "564\tValidation loss: 0.393429\tBest loss: 0.393429\tAccuracy: 91.00%\n",
      "565\tValidation loss: 0.393827\tBest loss: 0.393429\tAccuracy: 91.10%\n",
      "566\tValidation loss: 0.393387\tBest loss: 0.393387\tAccuracy: 91.10%\n",
      "567\tValidation loss: 0.394410\tBest loss: 0.393387\tAccuracy: 91.20%\n",
      "568\tValidation loss: 0.392644\tBest loss: 0.392644\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\tValidation loss: 0.393763\tBest loss: 0.392644\tAccuracy: 91.10%\n",
      "570\tValidation loss: 0.392299\tBest loss: 0.392299\tAccuracy: 91.00%\n",
      "571\tValidation loss: 0.393364\tBest loss: 0.392299\tAccuracy: 91.20%\n",
      "572\tValidation loss: 0.392326\tBest loss: 0.392299\tAccuracy: 91.10%\n",
      "573\tValidation loss: 0.393319\tBest loss: 0.392299\tAccuracy: 91.30%\n",
      "574\tValidation loss: 0.392481\tBest loss: 0.392299\tAccuracy: 91.10%\n",
      "575\tValidation loss: 0.392867\tBest loss: 0.392299\tAccuracy: 91.00%\n",
      "576\tValidation loss: 0.392697\tBest loss: 0.392299\tAccuracy: 91.10%\n",
      "577\tValidation loss: 0.393371\tBest loss: 0.392299\tAccuracy: 91.10%\n",
      "578\tValidation loss: 0.392727\tBest loss: 0.392299\tAccuracy: 91.20%\n",
      "579\tValidation loss: 0.392477\tBest loss: 0.392299\tAccuracy: 91.20%\n",
      "580\tValidation loss: 0.392733\tBest loss: 0.392299\tAccuracy: 91.30%\n",
      "581\tValidation loss: 0.392281\tBest loss: 0.392281\tAccuracy: 91.20%\n",
      "582\tValidation loss: 0.392216\tBest loss: 0.392216\tAccuracy: 91.10%\n",
      "583\tValidation loss: 0.391802\tBest loss: 0.391802\tAccuracy: 91.10%\n",
      "584\tValidation loss: 0.391409\tBest loss: 0.391409\tAccuracy: 91.20%\n",
      "585\tValidation loss: 0.391891\tBest loss: 0.391409\tAccuracy: 91.20%\n",
      "586\tValidation loss: 0.391756\tBest loss: 0.391409\tAccuracy: 91.10%\n",
      "587\tValidation loss: 0.391280\tBest loss: 0.391280\tAccuracy: 91.10%\n",
      "588\tValidation loss: 0.391414\tBest loss: 0.391280\tAccuracy: 91.10%\n",
      "589\tValidation loss: 0.391835\tBest loss: 0.391280\tAccuracy: 91.20%\n",
      "590\tValidation loss: 0.391556\tBest loss: 0.391280\tAccuracy: 91.20%\n",
      "591\tValidation loss: 0.390801\tBest loss: 0.390801\tAccuracy: 91.20%\n",
      "592\tValidation loss: 0.391328\tBest loss: 0.390801\tAccuracy: 91.30%\n",
      "593\tValidation loss: 0.390216\tBest loss: 0.390216\tAccuracy: 91.10%\n",
      "594\tValidation loss: 0.390284\tBest loss: 0.390216\tAccuracy: 91.20%\n",
      "595\tValidation loss: 0.390663\tBest loss: 0.390216\tAccuracy: 91.30%\n",
      "596\tValidation loss: 0.390870\tBest loss: 0.390216\tAccuracy: 91.30%\n",
      "597\tValidation loss: 0.391325\tBest loss: 0.390216\tAccuracy: 91.30%\n",
      "598\tValidation loss: 0.390968\tBest loss: 0.390216\tAccuracy: 91.00%\n",
      "599\tValidation loss: 0.391334\tBest loss: 0.390216\tAccuracy: 91.20%\n",
      "600\tValidation loss: 0.390989\tBest loss: 0.390216\tAccuracy: 91.10%\n",
      "601\tValidation loss: 0.389725\tBest loss: 0.389725\tAccuracy: 91.30%\n",
      "602\tValidation loss: 0.391263\tBest loss: 0.389725\tAccuracy: 91.20%\n",
      "603\tValidation loss: 0.389582\tBest loss: 0.389582\tAccuracy: 91.20%\n",
      "604\tValidation loss: 0.389412\tBest loss: 0.389412\tAccuracy: 91.00%\n",
      "605\tValidation loss: 0.389906\tBest loss: 0.389412\tAccuracy: 91.20%\n",
      "606\tValidation loss: 0.390453\tBest loss: 0.389412\tAccuracy: 91.30%\n",
      "607\tValidation loss: 0.389731\tBest loss: 0.389412\tAccuracy: 91.10%\n",
      "608\tValidation loss: 0.389113\tBest loss: 0.389113\tAccuracy: 91.40%\n",
      "609\tValidation loss: 0.388717\tBest loss: 0.388717\tAccuracy: 91.20%\n",
      "610\tValidation loss: 0.389288\tBest loss: 0.388717\tAccuracy: 91.20%\n",
      "611\tValidation loss: 0.388298\tBest loss: 0.388298\tAccuracy: 91.20%\n",
      "612\tValidation loss: 0.389266\tBest loss: 0.388298\tAccuracy: 91.20%\n",
      "613\tValidation loss: 0.389072\tBest loss: 0.388298\tAccuracy: 91.40%\n",
      "614\tValidation loss: 0.388534\tBest loss: 0.388298\tAccuracy: 91.10%\n",
      "615\tValidation loss: 0.389335\tBest loss: 0.388298\tAccuracy: 91.30%\n",
      "616\tValidation loss: 0.388933\tBest loss: 0.388298\tAccuracy: 91.40%\n",
      "617\tValidation loss: 0.389009\tBest loss: 0.388298\tAccuracy: 91.20%\n",
      "618\tValidation loss: 0.388770\tBest loss: 0.388298\tAccuracy: 91.50%\n",
      "619\tValidation loss: 0.388666\tBest loss: 0.388298\tAccuracy: 91.30%\n",
      "620\tValidation loss: 0.387052\tBest loss: 0.387052\tAccuracy: 91.30%\n",
      "621\tValidation loss: 0.387647\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "622\tValidation loss: 0.388176\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "623\tValidation loss: 0.387562\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "624\tValidation loss: 0.388001\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "625\tValidation loss: 0.387580\tBest loss: 0.387052\tAccuracy: 91.30%\n",
      "626\tValidation loss: 0.388333\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "627\tValidation loss: 0.387690\tBest loss: 0.387052\tAccuracy: 91.40%\n",
      "628\tValidation loss: 0.388446\tBest loss: 0.387052\tAccuracy: 91.30%\n",
      "629\tValidation loss: 0.387319\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "630\tValidation loss: 0.388033\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "631\tValidation loss: 0.387322\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "632\tValidation loss: 0.387711\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "633\tValidation loss: 0.387595\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "634\tValidation loss: 0.387636\tBest loss: 0.387052\tAccuracy: 91.20%\n",
      "635\tValidation loss: 0.387275\tBest loss: 0.387052\tAccuracy: 91.30%\n",
      "636\tValidation loss: 0.386475\tBest loss: 0.386475\tAccuracy: 91.20%\n",
      "637\tValidation loss: 0.386346\tBest loss: 0.386346\tAccuracy: 91.30%\n",
      "638\tValidation loss: 0.386454\tBest loss: 0.386346\tAccuracy: 91.30%\n",
      "639\tValidation loss: 0.386579\tBest loss: 0.386346\tAccuracy: 91.20%\n",
      "640\tValidation loss: 0.386108\tBest loss: 0.386108\tAccuracy: 91.40%\n",
      "641\tValidation loss: 0.385683\tBest loss: 0.385683\tAccuracy: 91.30%\n",
      "642\tValidation loss: 0.386027\tBest loss: 0.385683\tAccuracy: 91.20%\n",
      "643\tValidation loss: 0.386632\tBest loss: 0.385683\tAccuracy: 91.50%\n",
      "644\tValidation loss: 0.386031\tBest loss: 0.385683\tAccuracy: 91.10%\n",
      "645\tValidation loss: 0.386118\tBest loss: 0.385683\tAccuracy: 91.20%\n",
      "646\tValidation loss: 0.385935\tBest loss: 0.385683\tAccuracy: 91.40%\n",
      "647\tValidation loss: 0.386346\tBest loss: 0.385683\tAccuracy: 91.20%\n",
      "648\tValidation loss: 0.385452\tBest loss: 0.385452\tAccuracy: 91.20%\n",
      "649\tValidation loss: 0.385962\tBest loss: 0.385452\tAccuracy: 91.10%\n",
      "650\tValidation loss: 0.385549\tBest loss: 0.385452\tAccuracy: 91.30%\n",
      "651\tValidation loss: 0.385822\tBest loss: 0.385452\tAccuracy: 91.30%\n",
      "652\tValidation loss: 0.385817\tBest loss: 0.385452\tAccuracy: 91.30%\n",
      "653\tValidation loss: 0.385278\tBest loss: 0.385278\tAccuracy: 91.30%\n",
      "654\tValidation loss: 0.385420\tBest loss: 0.385278\tAccuracy: 91.20%\n",
      "655\tValidation loss: 0.385386\tBest loss: 0.385278\tAccuracy: 91.30%\n",
      "656\tValidation loss: 0.385866\tBest loss: 0.385278\tAccuracy: 91.40%\n",
      "657\tValidation loss: 0.385281\tBest loss: 0.385278\tAccuracy: 91.30%\n",
      "658\tValidation loss: 0.385380\tBest loss: 0.385278\tAccuracy: 91.30%\n",
      "659\tValidation loss: 0.385048\tBest loss: 0.385048\tAccuracy: 91.50%\n",
      "660\tValidation loss: 0.385127\tBest loss: 0.385048\tAccuracy: 91.30%\n",
      "661\tValidation loss: 0.384424\tBest loss: 0.384424\tAccuracy: 91.30%\n",
      "662\tValidation loss: 0.383804\tBest loss: 0.383804\tAccuracy: 91.40%\n",
      "663\tValidation loss: 0.384485\tBest loss: 0.383804\tAccuracy: 91.30%\n",
      "664\tValidation loss: 0.384906\tBest loss: 0.383804\tAccuracy: 91.40%\n",
      "665\tValidation loss: 0.384616\tBest loss: 0.383804\tAccuracy: 91.60%\n",
      "666\tValidation loss: 0.384899\tBest loss: 0.383804\tAccuracy: 91.40%\n",
      "667\tValidation loss: 0.383659\tBest loss: 0.383659\tAccuracy: 91.60%\n",
      "668\tValidation loss: 0.384581\tBest loss: 0.383659\tAccuracy: 91.50%\n",
      "669\tValidation loss: 0.384183\tBest loss: 0.383659\tAccuracy: 91.50%\n",
      "670\tValidation loss: 0.384883\tBest loss: 0.383659\tAccuracy: 91.50%\n",
      "671\tValidation loss: 0.384357\tBest loss: 0.383659\tAccuracy: 91.60%\n",
      "672\tValidation loss: 0.384439\tBest loss: 0.383659\tAccuracy: 91.60%\n",
      "673\tValidation loss: 0.384726\tBest loss: 0.383659\tAccuracy: 91.70%\n",
      "674\tValidation loss: 0.383146\tBest loss: 0.383146\tAccuracy: 91.30%\n",
      "675\tValidation loss: 0.383321\tBest loss: 0.383146\tAccuracy: 91.60%\n",
      "676\tValidation loss: 0.383236\tBest loss: 0.383146\tAccuracy: 91.40%\n",
      "677\tValidation loss: 0.383541\tBest loss: 0.383146\tAccuracy: 91.70%\n",
      "678\tValidation loss: 0.383297\tBest loss: 0.383146\tAccuracy: 91.50%\n",
      "679\tValidation loss: 0.383753\tBest loss: 0.383146\tAccuracy: 91.50%\n",
      "680\tValidation loss: 0.382343\tBest loss: 0.382343\tAccuracy: 91.30%\n",
      "681\tValidation loss: 0.382906\tBest loss: 0.382343\tAccuracy: 91.30%\n",
      "682\tValidation loss: 0.383047\tBest loss: 0.382343\tAccuracy: 91.40%\n",
      "683\tValidation loss: 0.383553\tBest loss: 0.382343\tAccuracy: 91.50%\n",
      "684\tValidation loss: 0.383202\tBest loss: 0.382343\tAccuracy: 91.70%\n",
      "685\tValidation loss: 0.383160\tBest loss: 0.382343\tAccuracy: 91.50%\n",
      "686\tValidation loss: 0.382002\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "687\tValidation loss: 0.382408\tBest loss: 0.382002\tAccuracy: 91.50%\n",
      "688\tValidation loss: 0.383215\tBest loss: 0.382002\tAccuracy: 91.80%\n",
      "689\tValidation loss: 0.383105\tBest loss: 0.382002\tAccuracy: 91.30%\n",
      "690\tValidation loss: 0.382740\tBest loss: 0.382002\tAccuracy: 91.40%\n",
      "691\tValidation loss: 0.382357\tBest loss: 0.382002\tAccuracy: 91.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\tValidation loss: 0.382304\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "693\tValidation loss: 0.382824\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "694\tValidation loss: 0.382920\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "695\tValidation loss: 0.382854\tBest loss: 0.382002\tAccuracy: 91.70%\n",
      "696\tValidation loss: 0.382539\tBest loss: 0.382002\tAccuracy: 91.70%\n",
      "697\tValidation loss: 0.382646\tBest loss: 0.382002\tAccuracy: 91.70%\n",
      "698\tValidation loss: 0.382310\tBest loss: 0.382002\tAccuracy: 91.80%\n",
      "699\tValidation loss: 0.382647\tBest loss: 0.382002\tAccuracy: 91.70%\n",
      "700\tValidation loss: 0.383018\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "701\tValidation loss: 0.382092\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "702\tValidation loss: 0.382627\tBest loss: 0.382002\tAccuracy: 91.60%\n",
      "703\tValidation loss: 0.381019\tBest loss: 0.381019\tAccuracy: 91.60%\n",
      "704\tValidation loss: 0.381714\tBest loss: 0.381019\tAccuracy: 91.70%\n",
      "705\tValidation loss: 0.381570\tBest loss: 0.381019\tAccuracy: 91.50%\n",
      "706\tValidation loss: 0.380950\tBest loss: 0.380950\tAccuracy: 91.60%\n",
      "707\tValidation loss: 0.381745\tBest loss: 0.380950\tAccuracy: 91.60%\n",
      "708\tValidation loss: 0.381001\tBest loss: 0.380950\tAccuracy: 91.60%\n",
      "709\tValidation loss: 0.380902\tBest loss: 0.380902\tAccuracy: 91.70%\n",
      "710\tValidation loss: 0.381802\tBest loss: 0.380902\tAccuracy: 91.60%\n",
      "711\tValidation loss: 0.381104\tBest loss: 0.380902\tAccuracy: 91.70%\n",
      "712\tValidation loss: 0.381815\tBest loss: 0.380902\tAccuracy: 91.80%\n",
      "713\tValidation loss: 0.380966\tBest loss: 0.380902\tAccuracy: 91.60%\n",
      "714\tValidation loss: 0.380661\tBest loss: 0.380661\tAccuracy: 91.60%\n",
      "715\tValidation loss: 0.381191\tBest loss: 0.380661\tAccuracy: 91.60%\n",
      "716\tValidation loss: 0.380982\tBest loss: 0.380661\tAccuracy: 91.70%\n",
      "717\tValidation loss: 0.380193\tBest loss: 0.380193\tAccuracy: 91.60%\n",
      "718\tValidation loss: 0.381020\tBest loss: 0.380193\tAccuracy: 91.60%\n",
      "719\tValidation loss: 0.380920\tBest loss: 0.380193\tAccuracy: 91.70%\n",
      "720\tValidation loss: 0.381177\tBest loss: 0.380193\tAccuracy: 91.70%\n",
      "721\tValidation loss: 0.381685\tBest loss: 0.380193\tAccuracy: 91.90%\n",
      "722\tValidation loss: 0.381013\tBest loss: 0.380193\tAccuracy: 91.80%\n",
      "723\tValidation loss: 0.380376\tBest loss: 0.380193\tAccuracy: 91.60%\n",
      "724\tValidation loss: 0.381106\tBest loss: 0.380193\tAccuracy: 91.70%\n",
      "725\tValidation loss: 0.379818\tBest loss: 0.379818\tAccuracy: 91.90%\n",
      "726\tValidation loss: 0.380092\tBest loss: 0.379818\tAccuracy: 91.70%\n",
      "727\tValidation loss: 0.380312\tBest loss: 0.379818\tAccuracy: 91.70%\n",
      "728\tValidation loss: 0.380701\tBest loss: 0.379818\tAccuracy: 91.70%\n",
      "729\tValidation loss: 0.380350\tBest loss: 0.379818\tAccuracy: 91.50%\n",
      "730\tValidation loss: 0.379684\tBest loss: 0.379684\tAccuracy: 91.60%\n",
      "731\tValidation loss: 0.380727\tBest loss: 0.379684\tAccuracy: 91.70%\n",
      "732\tValidation loss: 0.380631\tBest loss: 0.379684\tAccuracy: 91.70%\n",
      "733\tValidation loss: 0.380027\tBest loss: 0.379684\tAccuracy: 91.70%\n",
      "734\tValidation loss: 0.379029\tBest loss: 0.379029\tAccuracy: 91.70%\n",
      "735\tValidation loss: 0.380005\tBest loss: 0.379029\tAccuracy: 91.70%\n",
      "736\tValidation loss: 0.378877\tBest loss: 0.378877\tAccuracy: 91.60%\n",
      "737\tValidation loss: 0.378634\tBest loss: 0.378634\tAccuracy: 91.80%\n",
      "738\tValidation loss: 0.378736\tBest loss: 0.378634\tAccuracy: 91.70%\n",
      "739\tValidation loss: 0.379787\tBest loss: 0.378634\tAccuracy: 91.70%\n",
      "740\tValidation loss: 0.379609\tBest loss: 0.378634\tAccuracy: 91.60%\n",
      "741\tValidation loss: 0.379476\tBest loss: 0.378634\tAccuracy: 91.90%\n",
      "742\tValidation loss: 0.378506\tBest loss: 0.378506\tAccuracy: 91.80%\n",
      "743\tValidation loss: 0.378859\tBest loss: 0.378506\tAccuracy: 91.80%\n",
      "744\tValidation loss: 0.380182\tBest loss: 0.378506\tAccuracy: 91.80%\n",
      "745\tValidation loss: 0.378685\tBest loss: 0.378506\tAccuracy: 91.80%\n",
      "746\tValidation loss: 0.379072\tBest loss: 0.378506\tAccuracy: 91.80%\n",
      "747\tValidation loss: 0.377894\tBest loss: 0.377894\tAccuracy: 91.90%\n",
      "748\tValidation loss: 0.377811\tBest loss: 0.377811\tAccuracy: 91.70%\n",
      "749\tValidation loss: 0.378431\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "750\tValidation loss: 0.378170\tBest loss: 0.377811\tAccuracy: 91.60%\n",
      "751\tValidation loss: 0.378287\tBest loss: 0.377811\tAccuracy: 92.00%\n",
      "752\tValidation loss: 0.378673\tBest loss: 0.377811\tAccuracy: 91.90%\n",
      "753\tValidation loss: 0.378365\tBest loss: 0.377811\tAccuracy: 91.90%\n",
      "754\tValidation loss: 0.378161\tBest loss: 0.377811\tAccuracy: 91.60%\n",
      "755\tValidation loss: 0.378633\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "756\tValidation loss: 0.378698\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "757\tValidation loss: 0.378556\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "758\tValidation loss: 0.378977\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "759\tValidation loss: 0.378171\tBest loss: 0.377811\tAccuracy: 91.90%\n",
      "760\tValidation loss: 0.378450\tBest loss: 0.377811\tAccuracy: 91.90%\n",
      "761\tValidation loss: 0.378424\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "762\tValidation loss: 0.377991\tBest loss: 0.377811\tAccuracy: 91.80%\n",
      "763\tValidation loss: 0.377693\tBest loss: 0.377693\tAccuracy: 91.80%\n",
      "764\tValidation loss: 0.376987\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "765\tValidation loss: 0.377519\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "766\tValidation loss: 0.378302\tBest loss: 0.376987\tAccuracy: 91.90%\n",
      "767\tValidation loss: 0.377815\tBest loss: 0.376987\tAccuracy: 91.90%\n",
      "768\tValidation loss: 0.377315\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "769\tValidation loss: 0.377597\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "770\tValidation loss: 0.377539\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "771\tValidation loss: 0.377113\tBest loss: 0.376987\tAccuracy: 91.90%\n",
      "772\tValidation loss: 0.377371\tBest loss: 0.376987\tAccuracy: 91.90%\n",
      "773\tValidation loss: 0.377170\tBest loss: 0.376987\tAccuracy: 91.90%\n",
      "774\tValidation loss: 0.377676\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "775\tValidation loss: 0.377872\tBest loss: 0.376987\tAccuracy: 91.80%\n",
      "776\tValidation loss: 0.376948\tBest loss: 0.376948\tAccuracy: 91.80%\n",
      "777\tValidation loss: 0.376937\tBest loss: 0.376937\tAccuracy: 91.90%\n",
      "778\tValidation loss: 0.376191\tBest loss: 0.376191\tAccuracy: 91.70%\n",
      "779\tValidation loss: 0.376603\tBest loss: 0.376191\tAccuracy: 91.90%\n",
      "780\tValidation loss: 0.376776\tBest loss: 0.376191\tAccuracy: 91.90%\n",
      "781\tValidation loss: 0.377722\tBest loss: 0.376191\tAccuracy: 91.90%\n",
      "782\tValidation loss: 0.376999\tBest loss: 0.376191\tAccuracy: 91.70%\n",
      "783\tValidation loss: 0.376911\tBest loss: 0.376191\tAccuracy: 92.00%\n",
      "784\tValidation loss: 0.375901\tBest loss: 0.375901\tAccuracy: 91.90%\n",
      "785\tValidation loss: 0.376548\tBest loss: 0.375901\tAccuracy: 92.00%\n",
      "786\tValidation loss: 0.376072\tBest loss: 0.375901\tAccuracy: 91.90%\n",
      "787\tValidation loss: 0.376615\tBest loss: 0.375901\tAccuracy: 91.90%\n",
      "788\tValidation loss: 0.376827\tBest loss: 0.375901\tAccuracy: 91.80%\n",
      "789\tValidation loss: 0.377113\tBest loss: 0.375901\tAccuracy: 92.00%\n",
      "790\tValidation loss: 0.376836\tBest loss: 0.375901\tAccuracy: 91.90%\n",
      "791\tValidation loss: 0.375695\tBest loss: 0.375695\tAccuracy: 92.10%\n",
      "792\tValidation loss: 0.376067\tBest loss: 0.375695\tAccuracy: 91.80%\n",
      "793\tValidation loss: 0.376968\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "794\tValidation loss: 0.376091\tBest loss: 0.375695\tAccuracy: 91.80%\n",
      "795\tValidation loss: 0.376240\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "796\tValidation loss: 0.376902\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "797\tValidation loss: 0.376266\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "798\tValidation loss: 0.376216\tBest loss: 0.375695\tAccuracy: 91.80%\n",
      "799\tValidation loss: 0.375959\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "800\tValidation loss: 0.375816\tBest loss: 0.375695\tAccuracy: 91.90%\n",
      "801\tValidation loss: 0.375935\tBest loss: 0.375695\tAccuracy: 91.80%\n",
      "802\tValidation loss: 0.375370\tBest loss: 0.375370\tAccuracy: 91.80%\n",
      "803\tValidation loss: 0.375319\tBest loss: 0.375319\tAccuracy: 91.90%\n",
      "804\tValidation loss: 0.375829\tBest loss: 0.375319\tAccuracy: 91.90%\n",
      "805\tValidation loss: 0.376158\tBest loss: 0.375319\tAccuracy: 91.80%\n",
      "806\tValidation loss: 0.375640\tBest loss: 0.375319\tAccuracy: 91.90%\n",
      "807\tValidation loss: 0.375437\tBest loss: 0.375319\tAccuracy: 92.00%\n",
      "808\tValidation loss: 0.374826\tBest loss: 0.374826\tAccuracy: 92.00%\n",
      "809\tValidation loss: 0.375364\tBest loss: 0.374826\tAccuracy: 91.90%\n",
      "810\tValidation loss: 0.374699\tBest loss: 0.374699\tAccuracy: 91.90%\n",
      "811\tValidation loss: 0.375192\tBest loss: 0.374699\tAccuracy: 92.00%\n",
      "812\tValidation loss: 0.375482\tBest loss: 0.374699\tAccuracy: 91.90%\n",
      "813\tValidation loss: 0.375495\tBest loss: 0.374699\tAccuracy: 92.00%\n",
      "814\tValidation loss: 0.375132\tBest loss: 0.374699\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815\tValidation loss: 0.374899\tBest loss: 0.374699\tAccuracy: 91.90%\n",
      "816\tValidation loss: 0.375848\tBest loss: 0.374699\tAccuracy: 91.90%\n",
      "817\tValidation loss: 0.375509\tBest loss: 0.374699\tAccuracy: 92.00%\n",
      "818\tValidation loss: 0.375313\tBest loss: 0.374699\tAccuracy: 92.00%\n",
      "819\tValidation loss: 0.375357\tBest loss: 0.374699\tAccuracy: 92.00%\n",
      "820\tValidation loss: 0.374908\tBest loss: 0.374699\tAccuracy: 91.90%\n",
      "821\tValidation loss: 0.374009\tBest loss: 0.374009\tAccuracy: 92.00%\n",
      "822\tValidation loss: 0.374713\tBest loss: 0.374009\tAccuracy: 92.00%\n",
      "823\tValidation loss: 0.373540\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "824\tValidation loss: 0.375364\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "825\tValidation loss: 0.375658\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "826\tValidation loss: 0.374637\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "827\tValidation loss: 0.374737\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "828\tValidation loss: 0.374176\tBest loss: 0.373540\tAccuracy: 92.20%\n",
      "829\tValidation loss: 0.374340\tBest loss: 0.373540\tAccuracy: 91.80%\n",
      "830\tValidation loss: 0.375216\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "831\tValidation loss: 0.374151\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "832\tValidation loss: 0.374393\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "833\tValidation loss: 0.374431\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "834\tValidation loss: 0.374618\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "835\tValidation loss: 0.373682\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "836\tValidation loss: 0.374188\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "837\tValidation loss: 0.374023\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "838\tValidation loss: 0.373780\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "839\tValidation loss: 0.373896\tBest loss: 0.373540\tAccuracy: 91.90%\n",
      "840\tValidation loss: 0.373868\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "841\tValidation loss: 0.374058\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "842\tValidation loss: 0.373640\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "843\tValidation loss: 0.374148\tBest loss: 0.373540\tAccuracy: 92.00%\n",
      "844\tValidation loss: 0.373539\tBest loss: 0.373539\tAccuracy: 91.90%\n",
      "845\tValidation loss: 0.373044\tBest loss: 0.373044\tAccuracy: 91.90%\n",
      "846\tValidation loss: 0.373663\tBest loss: 0.373044\tAccuracy: 91.90%\n",
      "847\tValidation loss: 0.373676\tBest loss: 0.373044\tAccuracy: 92.00%\n",
      "848\tValidation loss: 0.373923\tBest loss: 0.373044\tAccuracy: 92.10%\n",
      "849\tValidation loss: 0.373887\tBest loss: 0.373044\tAccuracy: 92.10%\n",
      "850\tValidation loss: 0.374265\tBest loss: 0.373044\tAccuracy: 92.00%\n",
      "851\tValidation loss: 0.372911\tBest loss: 0.372911\tAccuracy: 92.00%\n",
      "852\tValidation loss: 0.373998\tBest loss: 0.372911\tAccuracy: 92.00%\n",
      "853\tValidation loss: 0.373157\tBest loss: 0.372911\tAccuracy: 92.10%\n",
      "854\tValidation loss: 0.372748\tBest loss: 0.372748\tAccuracy: 92.00%\n",
      "855\tValidation loss: 0.372849\tBest loss: 0.372748\tAccuracy: 92.00%\n",
      "856\tValidation loss: 0.373599\tBest loss: 0.372748\tAccuracy: 92.00%\n",
      "857\tValidation loss: 0.373254\tBest loss: 0.372748\tAccuracy: 92.10%\n",
      "858\tValidation loss: 0.372722\tBest loss: 0.372722\tAccuracy: 92.10%\n",
      "859\tValidation loss: 0.372872\tBest loss: 0.372722\tAccuracy: 92.10%\n",
      "860\tValidation loss: 0.373431\tBest loss: 0.372722\tAccuracy: 92.00%\n",
      "861\tValidation loss: 0.373556\tBest loss: 0.372722\tAccuracy: 92.00%\n",
      "862\tValidation loss: 0.373048\tBest loss: 0.372722\tAccuracy: 92.10%\n",
      "863\tValidation loss: 0.373063\tBest loss: 0.372722\tAccuracy: 92.00%\n",
      "864\tValidation loss: 0.372005\tBest loss: 0.372005\tAccuracy: 91.90%\n",
      "865\tValidation loss: 0.373831\tBest loss: 0.372005\tAccuracy: 92.10%\n",
      "866\tValidation loss: 0.372793\tBest loss: 0.372005\tAccuracy: 92.00%\n",
      "867\tValidation loss: 0.372983\tBest loss: 0.372005\tAccuracy: 92.00%\n",
      "868\tValidation loss: 0.372532\tBest loss: 0.372005\tAccuracy: 92.10%\n",
      "869\tValidation loss: 0.372961\tBest loss: 0.372005\tAccuracy: 92.10%\n",
      "870\tValidation loss: 0.373301\tBest loss: 0.372005\tAccuracy: 91.90%\n",
      "871\tValidation loss: 0.373399\tBest loss: 0.372005\tAccuracy: 92.10%\n",
      "872\tValidation loss: 0.373247\tBest loss: 0.372005\tAccuracy: 92.00%\n",
      "873\tValidation loss: 0.373492\tBest loss: 0.372005\tAccuracy: 92.00%\n",
      "874\tValidation loss: 0.372682\tBest loss: 0.372005\tAccuracy: 92.10%\n",
      "875\tValidation loss: 0.371908\tBest loss: 0.371908\tAccuracy: 92.10%\n",
      "876\tValidation loss: 0.372277\tBest loss: 0.371908\tAccuracy: 92.00%\n",
      "877\tValidation loss: 0.372093\tBest loss: 0.371908\tAccuracy: 92.00%\n",
      "878\tValidation loss: 0.372305\tBest loss: 0.371908\tAccuracy: 92.30%\n",
      "879\tValidation loss: 0.371787\tBest loss: 0.371787\tAccuracy: 92.00%\n",
      "880\tValidation loss: 0.371896\tBest loss: 0.371787\tAccuracy: 92.00%\n",
      "881\tValidation loss: 0.371360\tBest loss: 0.371360\tAccuracy: 92.00%\n",
      "882\tValidation loss: 0.372242\tBest loss: 0.371360\tAccuracy: 91.90%\n",
      "883\tValidation loss: 0.371855\tBest loss: 0.371360\tAccuracy: 92.10%\n",
      "884\tValidation loss: 0.372017\tBest loss: 0.371360\tAccuracy: 91.90%\n",
      "885\tValidation loss: 0.371407\tBest loss: 0.371360\tAccuracy: 92.00%\n",
      "886\tValidation loss: 0.372305\tBest loss: 0.371360\tAccuracy: 92.10%\n",
      "887\tValidation loss: 0.371351\tBest loss: 0.371351\tAccuracy: 92.10%\n",
      "888\tValidation loss: 0.371500\tBest loss: 0.371351\tAccuracy: 92.10%\n",
      "889\tValidation loss: 0.371536\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "890\tValidation loss: 0.371441\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "891\tValidation loss: 0.371880\tBest loss: 0.371351\tAccuracy: 92.20%\n",
      "892\tValidation loss: 0.372331\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "893\tValidation loss: 0.371843\tBest loss: 0.371351\tAccuracy: 92.10%\n",
      "894\tValidation loss: 0.371469\tBest loss: 0.371351\tAccuracy: 92.10%\n",
      "895\tValidation loss: 0.372593\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "896\tValidation loss: 0.372439\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "897\tValidation loss: 0.371638\tBest loss: 0.371351\tAccuracy: 92.00%\n",
      "898\tValidation loss: 0.371701\tBest loss: 0.371351\tAccuracy: 92.10%\n",
      "899\tValidation loss: 0.371449\tBest loss: 0.371351\tAccuracy: 92.20%\n",
      "900\tValidation loss: 0.371536\tBest loss: 0.371351\tAccuracy: 92.20%\n",
      "901\tValidation loss: 0.371091\tBest loss: 0.371091\tAccuracy: 92.10%\n",
      "902\tValidation loss: 0.371913\tBest loss: 0.371091\tAccuracy: 92.10%\n",
      "903\tValidation loss: 0.371189\tBest loss: 0.371091\tAccuracy: 92.10%\n",
      "904\tValidation loss: 0.371065\tBest loss: 0.371065\tAccuracy: 92.10%\n",
      "905\tValidation loss: 0.371139\tBest loss: 0.371065\tAccuracy: 92.10%\n",
      "906\tValidation loss: 0.371565\tBest loss: 0.371065\tAccuracy: 92.10%\n",
      "907\tValidation loss: 0.371404\tBest loss: 0.371065\tAccuracy: 92.10%\n",
      "908\tValidation loss: 0.370757\tBest loss: 0.370757\tAccuracy: 92.00%\n",
      "909\tValidation loss: 0.371219\tBest loss: 0.370757\tAccuracy: 92.20%\n",
      "910\tValidation loss: 0.370966\tBest loss: 0.370757\tAccuracy: 92.30%\n",
      "911\tValidation loss: 0.371125\tBest loss: 0.370757\tAccuracy: 92.20%\n",
      "912\tValidation loss: 0.371103\tBest loss: 0.370757\tAccuracy: 92.20%\n",
      "913\tValidation loss: 0.371400\tBest loss: 0.370757\tAccuracy: 92.20%\n",
      "914\tValidation loss: 0.371494\tBest loss: 0.370757\tAccuracy: 92.10%\n",
      "915\tValidation loss: 0.370885\tBest loss: 0.370757\tAccuracy: 92.10%\n",
      "916\tValidation loss: 0.371708\tBest loss: 0.370757\tAccuracy: 92.30%\n",
      "917\tValidation loss: 0.371036\tBest loss: 0.370757\tAccuracy: 92.30%\n",
      "918\tValidation loss: 0.371065\tBest loss: 0.370757\tAccuracy: 92.20%\n",
      "919\tValidation loss: 0.370749\tBest loss: 0.370749\tAccuracy: 92.20%\n",
      "920\tValidation loss: 0.371416\tBest loss: 0.370749\tAccuracy: 92.10%\n",
      "921\tValidation loss: 0.371303\tBest loss: 0.370749\tAccuracy: 92.20%\n",
      "922\tValidation loss: 0.371185\tBest loss: 0.370749\tAccuracy: 92.10%\n",
      "923\tValidation loss: 0.370520\tBest loss: 0.370520\tAccuracy: 92.20%\n",
      "924\tValidation loss: 0.369850\tBest loss: 0.369850\tAccuracy: 92.00%\n",
      "925\tValidation loss: 0.371336\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "926\tValidation loss: 0.370092\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "927\tValidation loss: 0.371276\tBest loss: 0.369850\tAccuracy: 92.20%\n",
      "928\tValidation loss: 0.371108\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "929\tValidation loss: 0.370410\tBest loss: 0.369850\tAccuracy: 92.20%\n",
      "930\tValidation loss: 0.370042\tBest loss: 0.369850\tAccuracy: 92.00%\n",
      "931\tValidation loss: 0.370628\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "932\tValidation loss: 0.370951\tBest loss: 0.369850\tAccuracy: 92.20%\n",
      "933\tValidation loss: 0.370194\tBest loss: 0.369850\tAccuracy: 92.00%\n",
      "934\tValidation loss: 0.369990\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "935\tValidation loss: 0.370959\tBest loss: 0.369850\tAccuracy: 92.20%\n",
      "936\tValidation loss: 0.370419\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "937\tValidation loss: 0.369984\tBest loss: 0.369850\tAccuracy: 92.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\tValidation loss: 0.370052\tBest loss: 0.369850\tAccuracy: 92.30%\n",
      "939\tValidation loss: 0.370212\tBest loss: 0.369850\tAccuracy: 92.10%\n",
      "940\tValidation loss: 0.368763\tBest loss: 0.368763\tAccuracy: 92.00%\n",
      "941\tValidation loss: 0.369688\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "942\tValidation loss: 0.369961\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "943\tValidation loss: 0.369585\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "944\tValidation loss: 0.369589\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "945\tValidation loss: 0.369615\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "946\tValidation loss: 0.370102\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "947\tValidation loss: 0.369451\tBest loss: 0.368763\tAccuracy: 92.40%\n",
      "948\tValidation loss: 0.369983\tBest loss: 0.368763\tAccuracy: 92.10%\n",
      "949\tValidation loss: 0.370575\tBest loss: 0.368763\tAccuracy: 92.10%\n",
      "950\tValidation loss: 0.369187\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "951\tValidation loss: 0.368767\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "952\tValidation loss: 0.369165\tBest loss: 0.368763\tAccuracy: 92.40%\n",
      "953\tValidation loss: 0.369679\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "954\tValidation loss: 0.369815\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "955\tValidation loss: 0.369991\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "956\tValidation loss: 0.369425\tBest loss: 0.368763\tAccuracy: 92.20%\n",
      "957\tValidation loss: 0.369207\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "958\tValidation loss: 0.369382\tBest loss: 0.368763\tAccuracy: 92.30%\n",
      "959\tValidation loss: 0.368824\tBest loss: 0.368763\tAccuracy: 92.10%\n",
      "960\tValidation loss: 0.368061\tBest loss: 0.368061\tAccuracy: 92.20%\n",
      "961\tValidation loss: 0.368986\tBest loss: 0.368061\tAccuracy: 92.30%\n",
      "962\tValidation loss: 0.369313\tBest loss: 0.368061\tAccuracy: 92.20%\n",
      "963\tValidation loss: 0.368821\tBest loss: 0.368061\tAccuracy: 92.20%\n",
      "964\tValidation loss: 0.369006\tBest loss: 0.368061\tAccuracy: 92.20%\n",
      "965\tValidation loss: 0.369366\tBest loss: 0.368061\tAccuracy: 92.20%\n",
      "966\tValidation loss: 0.369182\tBest loss: 0.368061\tAccuracy: 92.30%\n",
      "967\tValidation loss: 0.369018\tBest loss: 0.368061\tAccuracy: 92.10%\n",
      "968\tValidation loss: 0.369143\tBest loss: 0.368061\tAccuracy: 92.30%\n",
      "969\tValidation loss: 0.369064\tBest loss: 0.368061\tAccuracy: 92.30%\n",
      "970\tValidation loss: 0.367930\tBest loss: 0.367930\tAccuracy: 92.20%\n",
      "971\tValidation loss: 0.368298\tBest loss: 0.367930\tAccuracy: 92.20%\n",
      "972\tValidation loss: 0.368412\tBest loss: 0.367930\tAccuracy: 92.20%\n",
      "973\tValidation loss: 0.369183\tBest loss: 0.367930\tAccuracy: 92.30%\n",
      "974\tValidation loss: 0.369118\tBest loss: 0.367930\tAccuracy: 92.30%\n",
      "975\tValidation loss: 0.369701\tBest loss: 0.367930\tAccuracy: 92.20%\n",
      "976\tValidation loss: 0.368723\tBest loss: 0.367930\tAccuracy: 92.30%\n",
      "977\tValidation loss: 0.367602\tBest loss: 0.367602\tAccuracy: 92.20%\n",
      "978\tValidation loss: 0.368820\tBest loss: 0.367602\tAccuracy: 92.40%\n",
      "979\tValidation loss: 0.368819\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "980\tValidation loss: 0.367793\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "981\tValidation loss: 0.369040\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "982\tValidation loss: 0.368669\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "983\tValidation loss: 0.368193\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "984\tValidation loss: 0.368503\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "985\tValidation loss: 0.368673\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "986\tValidation loss: 0.368018\tBest loss: 0.367602\tAccuracy: 92.20%\n",
      "987\tValidation loss: 0.368311\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "988\tValidation loss: 0.367758\tBest loss: 0.367602\tAccuracy: 92.20%\n",
      "989\tValidation loss: 0.368108\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "990\tValidation loss: 0.368100\tBest loss: 0.367602\tAccuracy: 92.20%\n",
      "991\tValidation loss: 0.367734\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "992\tValidation loss: 0.368669\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "993\tValidation loss: 0.368369\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "994\tValidation loss: 0.367998\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "995\tValidation loss: 0.368208\tBest loss: 0.367602\tAccuracy: 92.40%\n",
      "996\tValidation loss: 0.367945\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "997\tValidation loss: 0.368313\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "998\tValidation loss: 0.368231\tBest loss: 0.367602\tAccuracy: 92.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.6min\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.090306\tBest loss: 3.090306\tAccuracy: 20.80%\n",
      "1\tValidation loss: 2.537552\tBest loss: 2.537552\tAccuracy: 36.80%\n",
      "2\tValidation loss: 2.193222\tBest loss: 2.193222\tAccuracy: 46.90%\n",
      "3\tValidation loss: 1.956406\tBest loss: 1.956406\tAccuracy: 52.20%\n",
      "4\tValidation loss: 1.776403\tBest loss: 1.776403\tAccuracy: 56.60%\n",
      "5\tValidation loss: 1.646950\tBest loss: 1.646950\tAccuracy: 60.10%\n",
      "6\tValidation loss: 1.543583\tBest loss: 1.543583\tAccuracy: 61.00%\n",
      "7\tValidation loss: 1.455422\tBest loss: 1.455422\tAccuracy: 63.10%\n",
      "8\tValidation loss: 1.380239\tBest loss: 1.380239\tAccuracy: 65.10%\n",
      "9\tValidation loss: 1.329315\tBest loss: 1.329315\tAccuracy: 68.10%\n",
      "10\tValidation loss: 1.267990\tBest loss: 1.267990\tAccuracy: 69.60%\n",
      "11\tValidation loss: 1.223774\tBest loss: 1.223774\tAccuracy: 70.60%\n",
      "12\tValidation loss: 1.185668\tBest loss: 1.185668\tAccuracy: 71.30%\n",
      "13\tValidation loss: 1.150045\tBest loss: 1.150045\tAccuracy: 72.80%\n",
      "14\tValidation loss: 1.113620\tBest loss: 1.113620\tAccuracy: 73.80%\n",
      "15\tValidation loss: 1.086818\tBest loss: 1.086818\tAccuracy: 75.00%\n",
      "16\tValidation loss: 1.062124\tBest loss: 1.062124\tAccuracy: 74.80%\n",
      "17\tValidation loss: 1.034389\tBest loss: 1.034389\tAccuracy: 75.60%\n",
      "18\tValidation loss: 1.015756\tBest loss: 1.015756\tAccuracy: 76.40%\n",
      "19\tValidation loss: 0.997696\tBest loss: 0.997696\tAccuracy: 76.90%\n",
      "20\tValidation loss: 0.975583\tBest loss: 0.975583\tAccuracy: 77.20%\n",
      "21\tValidation loss: 0.957308\tBest loss: 0.957308\tAccuracy: 77.70%\n",
      "22\tValidation loss: 0.942464\tBest loss: 0.942464\tAccuracy: 77.70%\n",
      "23\tValidation loss: 0.926309\tBest loss: 0.926309\tAccuracy: 78.10%\n",
      "24\tValidation loss: 0.913154\tBest loss: 0.913154\tAccuracy: 78.90%\n",
      "25\tValidation loss: 0.899318\tBest loss: 0.899318\tAccuracy: 79.30%\n",
      "26\tValidation loss: 0.888956\tBest loss: 0.888956\tAccuracy: 78.70%\n",
      "27\tValidation loss: 0.872399\tBest loss: 0.872399\tAccuracy: 79.40%\n",
      "28\tValidation loss: 0.863982\tBest loss: 0.863982\tAccuracy: 79.90%\n",
      "29\tValidation loss: 0.853403\tBest loss: 0.853403\tAccuracy: 80.20%\n",
      "30\tValidation loss: 0.842286\tBest loss: 0.842286\tAccuracy: 80.40%\n",
      "31\tValidation loss: 0.829259\tBest loss: 0.829259\tAccuracy: 80.20%\n",
      "32\tValidation loss: 0.824936\tBest loss: 0.824936\tAccuracy: 80.10%\n",
      "33\tValidation loss: 0.814997\tBest loss: 0.814997\tAccuracy: 80.40%\n",
      "34\tValidation loss: 0.808791\tBest loss: 0.808791\tAccuracy: 80.60%\n",
      "35\tValidation loss: 0.799227\tBest loss: 0.799227\tAccuracy: 80.90%\n",
      "36\tValidation loss: 0.793060\tBest loss: 0.793060\tAccuracy: 81.10%\n",
      "37\tValidation loss: 0.782142\tBest loss: 0.782142\tAccuracy: 81.70%\n",
      "38\tValidation loss: 0.777055\tBest loss: 0.777055\tAccuracy: 81.30%\n",
      "39\tValidation loss: 0.769865\tBest loss: 0.769865\tAccuracy: 82.00%\n",
      "40\tValidation loss: 0.765256\tBest loss: 0.765256\tAccuracy: 81.80%\n",
      "41\tValidation loss: 0.756777\tBest loss: 0.756777\tAccuracy: 82.00%\n",
      "42\tValidation loss: 0.749298\tBest loss: 0.749298\tAccuracy: 82.50%\n",
      "43\tValidation loss: 0.740210\tBest loss: 0.740210\tAccuracy: 82.20%\n",
      "44\tValidation loss: 0.737892\tBest loss: 0.737892\tAccuracy: 82.40%\n",
      "45\tValidation loss: 0.732890\tBest loss: 0.732890\tAccuracy: 82.50%\n",
      "46\tValidation loss: 0.729673\tBest loss: 0.729673\tAccuracy: 82.30%\n",
      "47\tValidation loss: 0.721794\tBest loss: 0.721794\tAccuracy: 82.80%\n",
      "48\tValidation loss: 0.714149\tBest loss: 0.714149\tAccuracy: 82.70%\n",
      "49\tValidation loss: 0.713975\tBest loss: 0.713975\tAccuracy: 82.80%\n",
      "50\tValidation loss: 0.708380\tBest loss: 0.708380\tAccuracy: 82.90%\n",
      "51\tValidation loss: 0.701601\tBest loss: 0.701601\tAccuracy: 83.30%\n",
      "52\tValidation loss: 0.696182\tBest loss: 0.696182\tAccuracy: 83.50%\n",
      "53\tValidation loss: 0.687893\tBest loss: 0.687893\tAccuracy: 83.30%\n",
      "54\tValidation loss: 0.689346\tBest loss: 0.687893\tAccuracy: 83.50%\n",
      "55\tValidation loss: 0.682894\tBest loss: 0.682894\tAccuracy: 83.30%\n",
      "56\tValidation loss: 0.679132\tBest loss: 0.679132\tAccuracy: 83.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\tValidation loss: 0.676044\tBest loss: 0.676044\tAccuracy: 83.30%\n",
      "58\tValidation loss: 0.676236\tBest loss: 0.676044\tAccuracy: 83.60%\n",
      "59\tValidation loss: 0.668459\tBest loss: 0.668459\tAccuracy: 83.80%\n",
      "60\tValidation loss: 0.664870\tBest loss: 0.664870\tAccuracy: 83.70%\n",
      "61\tValidation loss: 0.661961\tBest loss: 0.661961\tAccuracy: 83.70%\n",
      "62\tValidation loss: 0.655757\tBest loss: 0.655757\tAccuracy: 84.20%\n",
      "63\tValidation loss: 0.651689\tBest loss: 0.651689\tAccuracy: 83.90%\n",
      "64\tValidation loss: 0.647982\tBest loss: 0.647982\tAccuracy: 83.90%\n",
      "65\tValidation loss: 0.642762\tBest loss: 0.642762\tAccuracy: 84.40%\n",
      "66\tValidation loss: 0.643661\tBest loss: 0.642762\tAccuracy: 84.30%\n",
      "67\tValidation loss: 0.644722\tBest loss: 0.642762\tAccuracy: 83.80%\n",
      "68\tValidation loss: 0.636283\tBest loss: 0.636283\tAccuracy: 83.90%\n",
      "69\tValidation loss: 0.636958\tBest loss: 0.636283\tAccuracy: 83.60%\n",
      "70\tValidation loss: 0.631944\tBest loss: 0.631944\tAccuracy: 84.00%\n",
      "71\tValidation loss: 0.627917\tBest loss: 0.627917\tAccuracy: 84.50%\n",
      "72\tValidation loss: 0.631088\tBest loss: 0.627917\tAccuracy: 84.30%\n",
      "73\tValidation loss: 0.624077\tBest loss: 0.624077\tAccuracy: 83.90%\n",
      "74\tValidation loss: 0.620019\tBest loss: 0.620019\tAccuracy: 84.40%\n",
      "75\tValidation loss: 0.621032\tBest loss: 0.620019\tAccuracy: 84.70%\n",
      "76\tValidation loss: 0.612497\tBest loss: 0.612497\tAccuracy: 85.00%\n",
      "77\tValidation loss: 0.613090\tBest loss: 0.612497\tAccuracy: 85.20%\n",
      "78\tValidation loss: 0.609556\tBest loss: 0.609556\tAccuracy: 84.90%\n",
      "79\tValidation loss: 0.609109\tBest loss: 0.609109\tAccuracy: 85.00%\n",
      "80\tValidation loss: 0.607464\tBest loss: 0.607464\tAccuracy: 85.20%\n",
      "81\tValidation loss: 0.606950\tBest loss: 0.606950\tAccuracy: 85.40%\n",
      "82\tValidation loss: 0.600384\tBest loss: 0.600384\tAccuracy: 85.20%\n",
      "83\tValidation loss: 0.604889\tBest loss: 0.600384\tAccuracy: 85.00%\n",
      "84\tValidation loss: 0.597718\tBest loss: 0.597718\tAccuracy: 85.20%\n",
      "85\tValidation loss: 0.594747\tBest loss: 0.594747\tAccuracy: 86.00%\n",
      "86\tValidation loss: 0.594535\tBest loss: 0.594535\tAccuracy: 85.40%\n",
      "87\tValidation loss: 0.590696\tBest loss: 0.590696\tAccuracy: 85.50%\n",
      "88\tValidation loss: 0.589727\tBest loss: 0.589727\tAccuracy: 85.70%\n",
      "89\tValidation loss: 0.588198\tBest loss: 0.588198\tAccuracy: 85.40%\n",
      "90\tValidation loss: 0.585508\tBest loss: 0.585508\tAccuracy: 85.70%\n",
      "91\tValidation loss: 0.581927\tBest loss: 0.581927\tAccuracy: 86.10%\n",
      "92\tValidation loss: 0.587337\tBest loss: 0.581927\tAccuracy: 85.70%\n",
      "93\tValidation loss: 0.579784\tBest loss: 0.579784\tAccuracy: 86.00%\n",
      "94\tValidation loss: 0.577726\tBest loss: 0.577726\tAccuracy: 86.00%\n",
      "95\tValidation loss: 0.575433\tBest loss: 0.575433\tAccuracy: 86.30%\n",
      "96\tValidation loss: 0.575271\tBest loss: 0.575271\tAccuracy: 86.00%\n",
      "97\tValidation loss: 0.572745\tBest loss: 0.572745\tAccuracy: 86.10%\n",
      "98\tValidation loss: 0.572572\tBest loss: 0.572572\tAccuracy: 85.90%\n",
      "99\tValidation loss: 0.572467\tBest loss: 0.572467\tAccuracy: 86.20%\n",
      "100\tValidation loss: 0.568864\tBest loss: 0.568864\tAccuracy: 86.40%\n",
      "101\tValidation loss: 0.567697\tBest loss: 0.567697\tAccuracy: 86.80%\n",
      "102\tValidation loss: 0.564398\tBest loss: 0.564398\tAccuracy: 87.20%\n",
      "103\tValidation loss: 0.563637\tBest loss: 0.563637\tAccuracy: 86.50%\n",
      "104\tValidation loss: 0.564795\tBest loss: 0.563637\tAccuracy: 86.40%\n",
      "105\tValidation loss: 0.561910\tBest loss: 0.561910\tAccuracy: 86.70%\n",
      "106\tValidation loss: 0.558897\tBest loss: 0.558897\tAccuracy: 87.10%\n",
      "107\tValidation loss: 0.559851\tBest loss: 0.558897\tAccuracy: 87.00%\n",
      "108\tValidation loss: 0.558671\tBest loss: 0.558671\tAccuracy: 86.70%\n",
      "109\tValidation loss: 0.555689\tBest loss: 0.555689\tAccuracy: 87.00%\n",
      "110\tValidation loss: 0.556009\tBest loss: 0.555689\tAccuracy: 86.90%\n",
      "111\tValidation loss: 0.554929\tBest loss: 0.554929\tAccuracy: 87.10%\n",
      "112\tValidation loss: 0.554916\tBest loss: 0.554916\tAccuracy: 86.80%\n",
      "113\tValidation loss: 0.550578\tBest loss: 0.550578\tAccuracy: 87.40%\n",
      "114\tValidation loss: 0.551310\tBest loss: 0.550578\tAccuracy: 86.80%\n",
      "115\tValidation loss: 0.549026\tBest loss: 0.549026\tAccuracy: 87.30%\n",
      "116\tValidation loss: 0.550963\tBest loss: 0.549026\tAccuracy: 87.00%\n",
      "117\tValidation loss: 0.545984\tBest loss: 0.545984\tAccuracy: 87.80%\n",
      "118\tValidation loss: 0.545005\tBest loss: 0.545005\tAccuracy: 87.80%\n",
      "119\tValidation loss: 0.544874\tBest loss: 0.544874\tAccuracy: 87.50%\n",
      "120\tValidation loss: 0.542325\tBest loss: 0.542325\tAccuracy: 87.60%\n",
      "121\tValidation loss: 0.542503\tBest loss: 0.542325\tAccuracy: 87.40%\n",
      "122\tValidation loss: 0.539195\tBest loss: 0.539195\tAccuracy: 87.90%\n",
      "123\tValidation loss: 0.537719\tBest loss: 0.537719\tAccuracy: 87.90%\n",
      "124\tValidation loss: 0.539420\tBest loss: 0.537719\tAccuracy: 87.60%\n",
      "125\tValidation loss: 0.537980\tBest loss: 0.537719\tAccuracy: 87.60%\n",
      "126\tValidation loss: 0.535649\tBest loss: 0.535649\tAccuracy: 87.60%\n",
      "127\tValidation loss: 0.535765\tBest loss: 0.535649\tAccuracy: 87.70%\n",
      "128\tValidation loss: 0.534847\tBest loss: 0.534847\tAccuracy: 87.90%\n",
      "129\tValidation loss: 0.532534\tBest loss: 0.532534\tAccuracy: 87.90%\n",
      "130\tValidation loss: 0.529360\tBest loss: 0.529360\tAccuracy: 88.30%\n",
      "131\tValidation loss: 0.528622\tBest loss: 0.528622\tAccuracy: 87.70%\n",
      "132\tValidation loss: 0.528265\tBest loss: 0.528265\tAccuracy: 88.00%\n",
      "133\tValidation loss: 0.530628\tBest loss: 0.528265\tAccuracy: 87.90%\n",
      "134\tValidation loss: 0.528583\tBest loss: 0.528265\tAccuracy: 87.90%\n",
      "135\tValidation loss: 0.530190\tBest loss: 0.528265\tAccuracy: 87.80%\n",
      "136\tValidation loss: 0.527408\tBest loss: 0.527408\tAccuracy: 87.70%\n",
      "137\tValidation loss: 0.527680\tBest loss: 0.527408\tAccuracy: 88.10%\n",
      "138\tValidation loss: 0.522611\tBest loss: 0.522611\tAccuracy: 88.00%\n",
      "139\tValidation loss: 0.522694\tBest loss: 0.522611\tAccuracy: 87.80%\n",
      "140\tValidation loss: 0.523726\tBest loss: 0.522611\tAccuracy: 88.30%\n",
      "141\tValidation loss: 0.523232\tBest loss: 0.522611\tAccuracy: 87.80%\n",
      "142\tValidation loss: 0.521293\tBest loss: 0.521293\tAccuracy: 88.10%\n",
      "143\tValidation loss: 0.519531\tBest loss: 0.519531\tAccuracy: 88.10%\n",
      "144\tValidation loss: 0.518018\tBest loss: 0.518018\tAccuracy: 87.90%\n",
      "145\tValidation loss: 0.519052\tBest loss: 0.518018\tAccuracy: 88.20%\n",
      "146\tValidation loss: 0.518773\tBest loss: 0.518018\tAccuracy: 88.50%\n",
      "147\tValidation loss: 0.515486\tBest loss: 0.515486\tAccuracy: 88.10%\n",
      "148\tValidation loss: 0.516881\tBest loss: 0.515486\tAccuracy: 88.10%\n",
      "149\tValidation loss: 0.515148\tBest loss: 0.515148\tAccuracy: 88.20%\n",
      "150\tValidation loss: 0.514035\tBest loss: 0.514035\tAccuracy: 88.60%\n",
      "151\tValidation loss: 0.513361\tBest loss: 0.513361\tAccuracy: 88.20%\n",
      "152\tValidation loss: 0.511649\tBest loss: 0.511649\tAccuracy: 88.60%\n",
      "153\tValidation loss: 0.513695\tBest loss: 0.511649\tAccuracy: 88.30%\n",
      "154\tValidation loss: 0.513725\tBest loss: 0.511649\tAccuracy: 88.30%\n",
      "155\tValidation loss: 0.511041\tBest loss: 0.511041\tAccuracy: 88.30%\n",
      "156\tValidation loss: 0.510973\tBest loss: 0.510973\tAccuracy: 88.30%\n",
      "157\tValidation loss: 0.509452\tBest loss: 0.509452\tAccuracy: 88.10%\n",
      "158\tValidation loss: 0.508105\tBest loss: 0.508105\tAccuracy: 88.30%\n",
      "159\tValidation loss: 0.508994\tBest loss: 0.508105\tAccuracy: 88.30%\n",
      "160\tValidation loss: 0.506737\tBest loss: 0.506737\tAccuracy: 88.20%\n",
      "161\tValidation loss: 0.508041\tBest loss: 0.506737\tAccuracy: 88.30%\n",
      "162\tValidation loss: 0.506774\tBest loss: 0.506737\tAccuracy: 88.30%\n",
      "163\tValidation loss: 0.507869\tBest loss: 0.506737\tAccuracy: 88.40%\n",
      "164\tValidation loss: 0.504538\tBest loss: 0.504538\tAccuracy: 88.50%\n",
      "165\tValidation loss: 0.504936\tBest loss: 0.504538\tAccuracy: 88.60%\n",
      "166\tValidation loss: 0.502286\tBest loss: 0.502286\tAccuracy: 88.60%\n",
      "167\tValidation loss: 0.502808\tBest loss: 0.502286\tAccuracy: 88.40%\n",
      "168\tValidation loss: 0.500894\tBest loss: 0.500894\tAccuracy: 88.60%\n",
      "169\tValidation loss: 0.501873\tBest loss: 0.500894\tAccuracy: 88.50%\n",
      "170\tValidation loss: 0.499308\tBest loss: 0.499308\tAccuracy: 88.70%\n",
      "171\tValidation loss: 0.501476\tBest loss: 0.499308\tAccuracy: 88.60%\n",
      "172\tValidation loss: 0.498723\tBest loss: 0.498723\tAccuracy: 88.40%\n",
      "173\tValidation loss: 0.500242\tBest loss: 0.498723\tAccuracy: 88.50%\n",
      "174\tValidation loss: 0.497862\tBest loss: 0.497862\tAccuracy: 88.60%\n",
      "175\tValidation loss: 0.498562\tBest loss: 0.497862\tAccuracy: 88.70%\n",
      "176\tValidation loss: 0.497423\tBest loss: 0.497423\tAccuracy: 88.60%\n",
      "177\tValidation loss: 0.497244\tBest loss: 0.497244\tAccuracy: 88.50%\n",
      "178\tValidation loss: 0.496134\tBest loss: 0.496134\tAccuracy: 88.60%\n",
      "179\tValidation loss: 0.496479\tBest loss: 0.496134\tAccuracy: 88.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\tValidation loss: 0.494336\tBest loss: 0.494336\tAccuracy: 88.70%\n",
      "181\tValidation loss: 0.494258\tBest loss: 0.494258\tAccuracy: 88.60%\n",
      "182\tValidation loss: 0.492477\tBest loss: 0.492477\tAccuracy: 88.60%\n",
      "183\tValidation loss: 0.493395\tBest loss: 0.492477\tAccuracy: 88.50%\n",
      "184\tValidation loss: 0.493900\tBest loss: 0.492477\tAccuracy: 88.70%\n",
      "185\tValidation loss: 0.492477\tBest loss: 0.492477\tAccuracy: 88.70%\n",
      "186\tValidation loss: 0.493263\tBest loss: 0.492477\tAccuracy: 88.60%\n",
      "187\tValidation loss: 0.492002\tBest loss: 0.492002\tAccuracy: 88.90%\n",
      "188\tValidation loss: 0.489688\tBest loss: 0.489688\tAccuracy: 88.60%\n",
      "189\tValidation loss: 0.489774\tBest loss: 0.489688\tAccuracy: 88.70%\n",
      "190\tValidation loss: 0.489639\tBest loss: 0.489639\tAccuracy: 88.70%\n",
      "191\tValidation loss: 0.488506\tBest loss: 0.488506\tAccuracy: 89.00%\n",
      "192\tValidation loss: 0.489560\tBest loss: 0.488506\tAccuracy: 88.90%\n",
      "193\tValidation loss: 0.488043\tBest loss: 0.488043\tAccuracy: 88.50%\n",
      "194\tValidation loss: 0.487953\tBest loss: 0.487953\tAccuracy: 88.80%\n",
      "195\tValidation loss: 0.486069\tBest loss: 0.486069\tAccuracy: 88.80%\n",
      "196\tValidation loss: 0.486216\tBest loss: 0.486069\tAccuracy: 88.90%\n",
      "197\tValidation loss: 0.488789\tBest loss: 0.486069\tAccuracy: 88.80%\n",
      "198\tValidation loss: 0.485770\tBest loss: 0.485770\tAccuracy: 88.60%\n",
      "199\tValidation loss: 0.485070\tBest loss: 0.485070\tAccuracy: 88.60%\n",
      "200\tValidation loss: 0.485402\tBest loss: 0.485070\tAccuracy: 88.60%\n",
      "201\tValidation loss: 0.485352\tBest loss: 0.485070\tAccuracy: 88.70%\n",
      "202\tValidation loss: 0.482973\tBest loss: 0.482973\tAccuracy: 89.10%\n",
      "203\tValidation loss: 0.484252\tBest loss: 0.482973\tAccuracy: 88.90%\n",
      "204\tValidation loss: 0.483107\tBest loss: 0.482973\tAccuracy: 89.10%\n",
      "205\tValidation loss: 0.481546\tBest loss: 0.481546\tAccuracy: 88.90%\n",
      "206\tValidation loss: 0.484029\tBest loss: 0.481546\tAccuracy: 88.80%\n",
      "207\tValidation loss: 0.480198\tBest loss: 0.480198\tAccuracy: 89.00%\n",
      "208\tValidation loss: 0.481965\tBest loss: 0.480198\tAccuracy: 88.90%\n",
      "209\tValidation loss: 0.481682\tBest loss: 0.480198\tAccuracy: 88.80%\n",
      "210\tValidation loss: 0.482535\tBest loss: 0.480198\tAccuracy: 88.80%\n",
      "211\tValidation loss: 0.480426\tBest loss: 0.480198\tAccuracy: 88.90%\n",
      "212\tValidation loss: 0.478400\tBest loss: 0.478400\tAccuracy: 88.90%\n",
      "213\tValidation loss: 0.479576\tBest loss: 0.478400\tAccuracy: 88.90%\n",
      "214\tValidation loss: 0.478693\tBest loss: 0.478400\tAccuracy: 88.80%\n",
      "215\tValidation loss: 0.479677\tBest loss: 0.478400\tAccuracy: 88.80%\n",
      "216\tValidation loss: 0.478237\tBest loss: 0.478237\tAccuracy: 89.00%\n",
      "217\tValidation loss: 0.476297\tBest loss: 0.476297\tAccuracy: 88.90%\n",
      "218\tValidation loss: 0.479101\tBest loss: 0.476297\tAccuracy: 89.00%\n",
      "219\tValidation loss: 0.477135\tBest loss: 0.476297\tAccuracy: 88.80%\n",
      "220\tValidation loss: 0.474613\tBest loss: 0.474613\tAccuracy: 89.20%\n",
      "221\tValidation loss: 0.475744\tBest loss: 0.474613\tAccuracy: 88.80%\n",
      "222\tValidation loss: 0.476052\tBest loss: 0.474613\tAccuracy: 88.80%\n",
      "223\tValidation loss: 0.475123\tBest loss: 0.474613\tAccuracy: 89.30%\n",
      "224\tValidation loss: 0.473944\tBest loss: 0.473944\tAccuracy: 89.00%\n",
      "225\tValidation loss: 0.475758\tBest loss: 0.473944\tAccuracy: 88.80%\n",
      "226\tValidation loss: 0.473081\tBest loss: 0.473081\tAccuracy: 89.10%\n",
      "227\tValidation loss: 0.472332\tBest loss: 0.472332\tAccuracy: 88.90%\n",
      "228\tValidation loss: 0.472608\tBest loss: 0.472332\tAccuracy: 88.90%\n",
      "229\tValidation loss: 0.472503\tBest loss: 0.472332\tAccuracy: 89.00%\n",
      "230\tValidation loss: 0.471276\tBest loss: 0.471276\tAccuracy: 89.10%\n",
      "231\tValidation loss: 0.472266\tBest loss: 0.471276\tAccuracy: 89.00%\n",
      "232\tValidation loss: 0.471987\tBest loss: 0.471276\tAccuracy: 89.00%\n",
      "233\tValidation loss: 0.470549\tBest loss: 0.470549\tAccuracy: 89.10%\n",
      "234\tValidation loss: 0.470199\tBest loss: 0.470199\tAccuracy: 89.10%\n",
      "235\tValidation loss: 0.470886\tBest loss: 0.470199\tAccuracy: 89.20%\n",
      "236\tValidation loss: 0.469561\tBest loss: 0.469561\tAccuracy: 89.00%\n",
      "237\tValidation loss: 0.470342\tBest loss: 0.469561\tAccuracy: 89.10%\n",
      "238\tValidation loss: 0.470864\tBest loss: 0.469561\tAccuracy: 89.20%\n",
      "239\tValidation loss: 0.471552\tBest loss: 0.469561\tAccuracy: 89.00%\n",
      "240\tValidation loss: 0.469534\tBest loss: 0.469534\tAccuracy: 89.00%\n",
      "241\tValidation loss: 0.470268\tBest loss: 0.469534\tAccuracy: 89.00%\n",
      "242\tValidation loss: 0.471814\tBest loss: 0.469534\tAccuracy: 88.80%\n",
      "243\tValidation loss: 0.468466\tBest loss: 0.468466\tAccuracy: 89.10%\n",
      "244\tValidation loss: 0.468030\tBest loss: 0.468030\tAccuracy: 89.20%\n",
      "245\tValidation loss: 0.467116\tBest loss: 0.467116\tAccuracy: 89.30%\n",
      "246\tValidation loss: 0.467823\tBest loss: 0.467116\tAccuracy: 89.30%\n",
      "247\tValidation loss: 0.466269\tBest loss: 0.466269\tAccuracy: 89.40%\n",
      "248\tValidation loss: 0.465636\tBest loss: 0.465636\tAccuracy: 89.40%\n",
      "249\tValidation loss: 0.465851\tBest loss: 0.465636\tAccuracy: 89.10%\n",
      "250\tValidation loss: 0.467257\tBest loss: 0.465636\tAccuracy: 89.10%\n",
      "251\tValidation loss: 0.464622\tBest loss: 0.464622\tAccuracy: 89.30%\n",
      "252\tValidation loss: 0.467106\tBest loss: 0.464622\tAccuracy: 89.10%\n",
      "253\tValidation loss: 0.464311\tBest loss: 0.464311\tAccuracy: 89.20%\n",
      "254\tValidation loss: 0.465937\tBest loss: 0.464311\tAccuracy: 89.20%\n",
      "255\tValidation loss: 0.465520\tBest loss: 0.464311\tAccuracy: 89.10%\n",
      "256\tValidation loss: 0.464405\tBest loss: 0.464311\tAccuracy: 89.30%\n",
      "257\tValidation loss: 0.465729\tBest loss: 0.464311\tAccuracy: 89.30%\n",
      "258\tValidation loss: 0.463143\tBest loss: 0.463143\tAccuracy: 89.30%\n",
      "259\tValidation loss: 0.462383\tBest loss: 0.462383\tAccuracy: 89.40%\n",
      "260\tValidation loss: 0.464636\tBest loss: 0.462383\tAccuracy: 89.40%\n",
      "261\tValidation loss: 0.463215\tBest loss: 0.462383\tAccuracy: 89.20%\n",
      "262\tValidation loss: 0.463015\tBest loss: 0.462383\tAccuracy: 89.50%\n",
      "263\tValidation loss: 0.462479\tBest loss: 0.462383\tAccuracy: 89.30%\n",
      "264\tValidation loss: 0.464175\tBest loss: 0.462383\tAccuracy: 89.30%\n",
      "265\tValidation loss: 0.461510\tBest loss: 0.461510\tAccuracy: 89.40%\n",
      "266\tValidation loss: 0.461049\tBest loss: 0.461049\tAccuracy: 89.70%\n",
      "267\tValidation loss: 0.461877\tBest loss: 0.461049\tAccuracy: 89.60%\n",
      "268\tValidation loss: 0.461619\tBest loss: 0.461049\tAccuracy: 89.30%\n",
      "269\tValidation loss: 0.460755\tBest loss: 0.460755\tAccuracy: 89.30%\n",
      "270\tValidation loss: 0.459712\tBest loss: 0.459712\tAccuracy: 89.50%\n",
      "271\tValidation loss: 0.459237\tBest loss: 0.459237\tAccuracy: 89.60%\n",
      "272\tValidation loss: 0.460011\tBest loss: 0.459237\tAccuracy: 89.50%\n",
      "273\tValidation loss: 0.459018\tBest loss: 0.459018\tAccuracy: 89.60%\n",
      "274\tValidation loss: 0.460435\tBest loss: 0.459018\tAccuracy: 89.50%\n",
      "275\tValidation loss: 0.457972\tBest loss: 0.457972\tAccuracy: 89.60%\n",
      "276\tValidation loss: 0.458281\tBest loss: 0.457972\tAccuracy: 89.40%\n",
      "277\tValidation loss: 0.459510\tBest loss: 0.457972\tAccuracy: 89.40%\n",
      "278\tValidation loss: 0.457670\tBest loss: 0.457670\tAccuracy: 89.60%\n",
      "279\tValidation loss: 0.458062\tBest loss: 0.457670\tAccuracy: 89.50%\n",
      "280\tValidation loss: 0.456868\tBest loss: 0.456868\tAccuracy: 89.60%\n",
      "281\tValidation loss: 0.456659\tBest loss: 0.456659\tAccuracy: 89.50%\n",
      "282\tValidation loss: 0.457502\tBest loss: 0.456659\tAccuracy: 89.50%\n",
      "283\tValidation loss: 0.457969\tBest loss: 0.456659\tAccuracy: 89.40%\n",
      "284\tValidation loss: 0.455556\tBest loss: 0.455556\tAccuracy: 89.60%\n",
      "285\tValidation loss: 0.456428\tBest loss: 0.455556\tAccuracy: 89.70%\n",
      "286\tValidation loss: 0.455698\tBest loss: 0.455556\tAccuracy: 89.50%\n",
      "287\tValidation loss: 0.455252\tBest loss: 0.455252\tAccuracy: 89.70%\n",
      "288\tValidation loss: 0.454788\tBest loss: 0.454788\tAccuracy: 89.60%\n",
      "289\tValidation loss: 0.454737\tBest loss: 0.454737\tAccuracy: 89.50%\n",
      "290\tValidation loss: 0.455414\tBest loss: 0.454737\tAccuracy: 89.50%\n",
      "291\tValidation loss: 0.455528\tBest loss: 0.454737\tAccuracy: 89.50%\n",
      "292\tValidation loss: 0.456364\tBest loss: 0.454737\tAccuracy: 89.40%\n",
      "293\tValidation loss: 0.454598\tBest loss: 0.454598\tAccuracy: 89.30%\n",
      "294\tValidation loss: 0.452361\tBest loss: 0.452361\tAccuracy: 89.50%\n",
      "295\tValidation loss: 0.453523\tBest loss: 0.452361\tAccuracy: 89.40%\n",
      "296\tValidation loss: 0.454589\tBest loss: 0.452361\tAccuracy: 89.40%\n",
      "297\tValidation loss: 0.453702\tBest loss: 0.452361\tAccuracy: 89.50%\n",
      "298\tValidation loss: 0.452609\tBest loss: 0.452361\tAccuracy: 89.50%\n",
      "299\tValidation loss: 0.452781\tBest loss: 0.452361\tAccuracy: 89.30%\n",
      "300\tValidation loss: 0.453185\tBest loss: 0.452361\tAccuracy: 89.40%\n",
      "301\tValidation loss: 0.452613\tBest loss: 0.452361\tAccuracy: 89.70%\n",
      "302\tValidation loss: 0.452373\tBest loss: 0.452361\tAccuracy: 89.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\tValidation loss: 0.452951\tBest loss: 0.452361\tAccuracy: 89.50%\n",
      "304\tValidation loss: 0.450748\tBest loss: 0.450748\tAccuracy: 89.40%\n",
      "305\tValidation loss: 0.450586\tBest loss: 0.450586\tAccuracy: 89.80%\n",
      "306\tValidation loss: 0.452293\tBest loss: 0.450586\tAccuracy: 89.50%\n",
      "307\tValidation loss: 0.452363\tBest loss: 0.450586\tAccuracy: 89.60%\n",
      "308\tValidation loss: 0.451328\tBest loss: 0.450586\tAccuracy: 89.60%\n",
      "309\tValidation loss: 0.451858\tBest loss: 0.450586\tAccuracy: 89.60%\n",
      "310\tValidation loss: 0.450165\tBest loss: 0.450165\tAccuracy: 89.30%\n",
      "311\tValidation loss: 0.450299\tBest loss: 0.450165\tAccuracy: 89.40%\n",
      "312\tValidation loss: 0.451321\tBest loss: 0.450165\tAccuracy: 89.50%\n",
      "313\tValidation loss: 0.450722\tBest loss: 0.450165\tAccuracy: 89.40%\n",
      "314\tValidation loss: 0.451738\tBest loss: 0.450165\tAccuracy: 89.70%\n",
      "315\tValidation loss: 0.449155\tBest loss: 0.449155\tAccuracy: 89.80%\n",
      "316\tValidation loss: 0.450620\tBest loss: 0.449155\tAccuracy: 89.40%\n",
      "317\tValidation loss: 0.449352\tBest loss: 0.449155\tAccuracy: 89.50%\n",
      "318\tValidation loss: 0.449536\tBest loss: 0.449155\tAccuracy: 89.40%\n",
      "319\tValidation loss: 0.449631\tBest loss: 0.449155\tAccuracy: 89.70%\n",
      "320\tValidation loss: 0.448172\tBest loss: 0.448172\tAccuracy: 89.70%\n",
      "321\tValidation loss: 0.448992\tBest loss: 0.448172\tAccuracy: 89.70%\n",
      "322\tValidation loss: 0.449189\tBest loss: 0.448172\tAccuracy: 90.00%\n",
      "323\tValidation loss: 0.448735\tBest loss: 0.448172\tAccuracy: 89.70%\n",
      "324\tValidation loss: 0.448792\tBest loss: 0.448172\tAccuracy: 89.60%\n",
      "325\tValidation loss: 0.449678\tBest loss: 0.448172\tAccuracy: 89.70%\n",
      "326\tValidation loss: 0.447302\tBest loss: 0.447302\tAccuracy: 89.50%\n",
      "327\tValidation loss: 0.447503\tBest loss: 0.447302\tAccuracy: 89.70%\n",
      "328\tValidation loss: 0.447733\tBest loss: 0.447302\tAccuracy: 89.80%\n",
      "329\tValidation loss: 0.446883\tBest loss: 0.446883\tAccuracy: 89.90%\n",
      "330\tValidation loss: 0.447335\tBest loss: 0.446883\tAccuracy: 89.60%\n",
      "331\tValidation loss: 0.446474\tBest loss: 0.446474\tAccuracy: 89.80%\n",
      "332\tValidation loss: 0.446350\tBest loss: 0.446350\tAccuracy: 89.80%\n",
      "333\tValidation loss: 0.444853\tBest loss: 0.444853\tAccuracy: 89.70%\n",
      "334\tValidation loss: 0.445952\tBest loss: 0.444853\tAccuracy: 89.80%\n",
      "335\tValidation loss: 0.446420\tBest loss: 0.444853\tAccuracy: 89.90%\n",
      "336\tValidation loss: 0.446028\tBest loss: 0.444853\tAccuracy: 89.80%\n",
      "337\tValidation loss: 0.446366\tBest loss: 0.444853\tAccuracy: 89.70%\n",
      "338\tValidation loss: 0.445437\tBest loss: 0.444853\tAccuracy: 89.60%\n",
      "339\tValidation loss: 0.444274\tBest loss: 0.444274\tAccuracy: 89.80%\n",
      "340\tValidation loss: 0.445128\tBest loss: 0.444274\tAccuracy: 89.80%\n",
      "341\tValidation loss: 0.445368\tBest loss: 0.444274\tAccuracy: 89.90%\n",
      "342\tValidation loss: 0.444006\tBest loss: 0.444006\tAccuracy: 89.90%\n",
      "343\tValidation loss: 0.445395\tBest loss: 0.444006\tAccuracy: 89.70%\n",
      "344\tValidation loss: 0.443827\tBest loss: 0.443827\tAccuracy: 89.80%\n",
      "345\tValidation loss: 0.443259\tBest loss: 0.443259\tAccuracy: 89.80%\n",
      "346\tValidation loss: 0.442829\tBest loss: 0.442829\tAccuracy: 89.80%\n",
      "347\tValidation loss: 0.444330\tBest loss: 0.442829\tAccuracy: 89.70%\n",
      "348\tValidation loss: 0.443307\tBest loss: 0.442829\tAccuracy: 89.90%\n",
      "349\tValidation loss: 0.443368\tBest loss: 0.442829\tAccuracy: 90.10%\n",
      "350\tValidation loss: 0.443784\tBest loss: 0.442829\tAccuracy: 90.00%\n",
      "351\tValidation loss: 0.445259\tBest loss: 0.442829\tAccuracy: 89.80%\n",
      "352\tValidation loss: 0.442337\tBest loss: 0.442337\tAccuracy: 90.00%\n",
      "353\tValidation loss: 0.443578\tBest loss: 0.442337\tAccuracy: 90.00%\n",
      "354\tValidation loss: 0.443765\tBest loss: 0.442337\tAccuracy: 90.00%\n",
      "355\tValidation loss: 0.443362\tBest loss: 0.442337\tAccuracy: 90.00%\n",
      "356\tValidation loss: 0.441654\tBest loss: 0.441654\tAccuracy: 90.20%\n",
      "357\tValidation loss: 0.441799\tBest loss: 0.441654\tAccuracy: 89.90%\n",
      "358\tValidation loss: 0.442751\tBest loss: 0.441654\tAccuracy: 89.70%\n",
      "359\tValidation loss: 0.441450\tBest loss: 0.441450\tAccuracy: 89.90%\n",
      "360\tValidation loss: 0.439541\tBest loss: 0.439541\tAccuracy: 89.90%\n",
      "361\tValidation loss: 0.442253\tBest loss: 0.439541\tAccuracy: 89.90%\n",
      "362\tValidation loss: 0.441484\tBest loss: 0.439541\tAccuracy: 90.00%\n",
      "363\tValidation loss: 0.441415\tBest loss: 0.439541\tAccuracy: 89.90%\n",
      "364\tValidation loss: 0.441159\tBest loss: 0.439541\tAccuracy: 89.80%\n",
      "365\tValidation loss: 0.441916\tBest loss: 0.439541\tAccuracy: 89.90%\n",
      "366\tValidation loss: 0.439698\tBest loss: 0.439541\tAccuracy: 90.10%\n",
      "367\tValidation loss: 0.440589\tBest loss: 0.439541\tAccuracy: 89.90%\n",
      "368\tValidation loss: 0.439910\tBest loss: 0.439541\tAccuracy: 89.80%\n",
      "369\tValidation loss: 0.441530\tBest loss: 0.439541\tAccuracy: 89.70%\n",
      "370\tValidation loss: 0.439861\tBest loss: 0.439541\tAccuracy: 90.00%\n",
      "371\tValidation loss: 0.439869\tBest loss: 0.439541\tAccuracy: 90.10%\n",
      "372\tValidation loss: 0.441019\tBest loss: 0.439541\tAccuracy: 90.10%\n",
      "373\tValidation loss: 0.440113\tBest loss: 0.439541\tAccuracy: 90.00%\n",
      "374\tValidation loss: 0.438385\tBest loss: 0.438385\tAccuracy: 89.80%\n",
      "375\tValidation loss: 0.439244\tBest loss: 0.438385\tAccuracy: 90.10%\n",
      "376\tValidation loss: 0.439367\tBest loss: 0.438385\tAccuracy: 90.10%\n",
      "377\tValidation loss: 0.440004\tBest loss: 0.438385\tAccuracy: 90.20%\n",
      "378\tValidation loss: 0.439046\tBest loss: 0.438385\tAccuracy: 90.00%\n",
      "379\tValidation loss: 0.439700\tBest loss: 0.438385\tAccuracy: 90.00%\n",
      "380\tValidation loss: 0.437740\tBest loss: 0.437740\tAccuracy: 90.20%\n",
      "381\tValidation loss: 0.438371\tBest loss: 0.437740\tAccuracy: 90.10%\n",
      "382\tValidation loss: 0.439512\tBest loss: 0.437740\tAccuracy: 90.00%\n",
      "383\tValidation loss: 0.439135\tBest loss: 0.437740\tAccuracy: 89.90%\n",
      "384\tValidation loss: 0.438608\tBest loss: 0.437740\tAccuracy: 90.10%\n",
      "385\tValidation loss: 0.438615\tBest loss: 0.437740\tAccuracy: 90.00%\n",
      "386\tValidation loss: 0.436386\tBest loss: 0.436386\tAccuracy: 90.20%\n",
      "387\tValidation loss: 0.436472\tBest loss: 0.436386\tAccuracy: 90.20%\n",
      "388\tValidation loss: 0.436589\tBest loss: 0.436386\tAccuracy: 90.10%\n",
      "389\tValidation loss: 0.437778\tBest loss: 0.436386\tAccuracy: 90.10%\n",
      "390\tValidation loss: 0.436256\tBest loss: 0.436256\tAccuracy: 90.10%\n",
      "391\tValidation loss: 0.437040\tBest loss: 0.436256\tAccuracy: 90.00%\n",
      "392\tValidation loss: 0.436966\tBest loss: 0.436256\tAccuracy: 89.90%\n",
      "393\tValidation loss: 0.436675\tBest loss: 0.436256\tAccuracy: 90.00%\n",
      "394\tValidation loss: 0.435836\tBest loss: 0.435836\tAccuracy: 90.30%\n",
      "395\tValidation loss: 0.436386\tBest loss: 0.435836\tAccuracy: 90.20%\n",
      "396\tValidation loss: 0.436774\tBest loss: 0.435836\tAccuracy: 90.20%\n",
      "397\tValidation loss: 0.437189\tBest loss: 0.435836\tAccuracy: 90.20%\n",
      "398\tValidation loss: 0.435393\tBest loss: 0.435393\tAccuracy: 90.10%\n",
      "399\tValidation loss: 0.437605\tBest loss: 0.435393\tAccuracy: 90.40%\n",
      "400\tValidation loss: 0.436693\tBest loss: 0.435393\tAccuracy: 90.00%\n",
      "401\tValidation loss: 0.435954\tBest loss: 0.435393\tAccuracy: 90.10%\n",
      "402\tValidation loss: 0.435503\tBest loss: 0.435393\tAccuracy: 90.10%\n",
      "403\tValidation loss: 0.434031\tBest loss: 0.434031\tAccuracy: 90.20%\n",
      "404\tValidation loss: 0.434468\tBest loss: 0.434031\tAccuracy: 90.20%\n",
      "405\tValidation loss: 0.435251\tBest loss: 0.434031\tAccuracy: 90.20%\n",
      "406\tValidation loss: 0.434606\tBest loss: 0.434031\tAccuracy: 90.10%\n",
      "407\tValidation loss: 0.435893\tBest loss: 0.434031\tAccuracy: 90.20%\n",
      "408\tValidation loss: 0.435068\tBest loss: 0.434031\tAccuracy: 90.10%\n",
      "409\tValidation loss: 0.433324\tBest loss: 0.433324\tAccuracy: 90.40%\n",
      "410\tValidation loss: 0.434251\tBest loss: 0.433324\tAccuracy: 90.40%\n",
      "411\tValidation loss: 0.433952\tBest loss: 0.433324\tAccuracy: 90.20%\n",
      "412\tValidation loss: 0.434395\tBest loss: 0.433324\tAccuracy: 90.20%\n",
      "413\tValidation loss: 0.434480\tBest loss: 0.433324\tAccuracy: 90.10%\n",
      "414\tValidation loss: 0.433425\tBest loss: 0.433324\tAccuracy: 90.10%\n",
      "415\tValidation loss: 0.433370\tBest loss: 0.433324\tAccuracy: 90.10%\n",
      "416\tValidation loss: 0.433045\tBest loss: 0.433045\tAccuracy: 90.20%\n",
      "417\tValidation loss: 0.434123\tBest loss: 0.433045\tAccuracy: 90.20%\n",
      "418\tValidation loss: 0.433675\tBest loss: 0.433045\tAccuracy: 90.30%\n",
      "419\tValidation loss: 0.431405\tBest loss: 0.431405\tAccuracy: 90.20%\n",
      "420\tValidation loss: 0.434059\tBest loss: 0.431405\tAccuracy: 90.20%\n",
      "421\tValidation loss: 0.433852\tBest loss: 0.431405\tAccuracy: 90.50%\n",
      "422\tValidation loss: 0.431561\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "423\tValidation loss: 0.432810\tBest loss: 0.431405\tAccuracy: 90.20%\n",
      "424\tValidation loss: 0.432272\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "425\tValidation loss: 0.433838\tBest loss: 0.431405\tAccuracy: 90.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\tValidation loss: 0.432648\tBest loss: 0.431405\tAccuracy: 90.50%\n",
      "427\tValidation loss: 0.432612\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "428\tValidation loss: 0.431623\tBest loss: 0.431405\tAccuracy: 90.20%\n",
      "429\tValidation loss: 0.431438\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "430\tValidation loss: 0.432579\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "431\tValidation loss: 0.432640\tBest loss: 0.431405\tAccuracy: 90.30%\n",
      "432\tValidation loss: 0.432116\tBest loss: 0.431405\tAccuracy: 90.10%\n",
      "433\tValidation loss: 0.431711\tBest loss: 0.431405\tAccuracy: 90.10%\n",
      "434\tValidation loss: 0.431280\tBest loss: 0.431280\tAccuracy: 90.00%\n",
      "435\tValidation loss: 0.432059\tBest loss: 0.431280\tAccuracy: 90.60%\n",
      "436\tValidation loss: 0.431027\tBest loss: 0.431027\tAccuracy: 90.40%\n",
      "437\tValidation loss: 0.431434\tBest loss: 0.431027\tAccuracy: 90.40%\n",
      "438\tValidation loss: 0.430315\tBest loss: 0.430315\tAccuracy: 90.50%\n",
      "439\tValidation loss: 0.431630\tBest loss: 0.430315\tAccuracy: 90.30%\n",
      "440\tValidation loss: 0.430697\tBest loss: 0.430315\tAccuracy: 90.30%\n",
      "441\tValidation loss: 0.430079\tBest loss: 0.430079\tAccuracy: 90.40%\n",
      "442\tValidation loss: 0.430653\tBest loss: 0.430079\tAccuracy: 90.50%\n",
      "443\tValidation loss: 0.431037\tBest loss: 0.430079\tAccuracy: 90.60%\n",
      "444\tValidation loss: 0.429269\tBest loss: 0.429269\tAccuracy: 90.70%\n",
      "445\tValidation loss: 0.431131\tBest loss: 0.429269\tAccuracy: 90.50%\n",
      "446\tValidation loss: 0.430347\tBest loss: 0.429269\tAccuracy: 90.70%\n",
      "447\tValidation loss: 0.429977\tBest loss: 0.429269\tAccuracy: 90.40%\n",
      "448\tValidation loss: 0.430074\tBest loss: 0.429269\tAccuracy: 90.60%\n",
      "449\tValidation loss: 0.429484\tBest loss: 0.429269\tAccuracy: 90.70%\n",
      "450\tValidation loss: 0.429703\tBest loss: 0.429269\tAccuracy: 90.60%\n",
      "451\tValidation loss: 0.430094\tBest loss: 0.429269\tAccuracy: 90.60%\n",
      "452\tValidation loss: 0.430238\tBest loss: 0.429269\tAccuracy: 90.50%\n",
      "453\tValidation loss: 0.430866\tBest loss: 0.429269\tAccuracy: 90.60%\n",
      "454\tValidation loss: 0.429757\tBest loss: 0.429269\tAccuracy: 90.70%\n",
      "455\tValidation loss: 0.430107\tBest loss: 0.429269\tAccuracy: 90.50%\n",
      "456\tValidation loss: 0.428582\tBest loss: 0.428582\tAccuracy: 90.60%\n",
      "457\tValidation loss: 0.428336\tBest loss: 0.428336\tAccuracy: 90.70%\n",
      "458\tValidation loss: 0.428838\tBest loss: 0.428336\tAccuracy: 90.90%\n",
      "459\tValidation loss: 0.428855\tBest loss: 0.428336\tAccuracy: 90.70%\n",
      "460\tValidation loss: 0.428702\tBest loss: 0.428336\tAccuracy: 90.60%\n",
      "461\tValidation loss: 0.430044\tBest loss: 0.428336\tAccuracy: 90.60%\n",
      "462\tValidation loss: 0.428574\tBest loss: 0.428336\tAccuracy: 90.90%\n",
      "463\tValidation loss: 0.428066\tBest loss: 0.428066\tAccuracy: 90.70%\n",
      "464\tValidation loss: 0.428593\tBest loss: 0.428066\tAccuracy: 90.70%\n",
      "465\tValidation loss: 0.428839\tBest loss: 0.428066\tAccuracy: 90.80%\n",
      "466\tValidation loss: 0.428579\tBest loss: 0.428066\tAccuracy: 90.70%\n",
      "467\tValidation loss: 0.427984\tBest loss: 0.427984\tAccuracy: 90.80%\n",
      "468\tValidation loss: 0.429677\tBest loss: 0.427984\tAccuracy: 90.70%\n",
      "469\tValidation loss: 0.428476\tBest loss: 0.427984\tAccuracy: 91.00%\n",
      "470\tValidation loss: 0.427947\tBest loss: 0.427947\tAccuracy: 91.00%\n",
      "471\tValidation loss: 0.428371\tBest loss: 0.427947\tAccuracy: 91.00%\n",
      "472\tValidation loss: 0.428040\tBest loss: 0.427947\tAccuracy: 90.90%\n",
      "473\tValidation loss: 0.428346\tBest loss: 0.427947\tAccuracy: 90.90%\n",
      "474\tValidation loss: 0.428433\tBest loss: 0.427947\tAccuracy: 90.50%\n",
      "475\tValidation loss: 0.427613\tBest loss: 0.427613\tAccuracy: 90.80%\n",
      "476\tValidation loss: 0.428383\tBest loss: 0.427613\tAccuracy: 90.80%\n",
      "477\tValidation loss: 0.427123\tBest loss: 0.427123\tAccuracy: 90.80%\n",
      "478\tValidation loss: 0.426976\tBest loss: 0.426976\tAccuracy: 90.90%\n",
      "479\tValidation loss: 0.427682\tBest loss: 0.426976\tAccuracy: 90.80%\n",
      "480\tValidation loss: 0.427759\tBest loss: 0.426976\tAccuracy: 90.80%\n",
      "481\tValidation loss: 0.427816\tBest loss: 0.426976\tAccuracy: 90.90%\n",
      "482\tValidation loss: 0.426419\tBest loss: 0.426419\tAccuracy: 91.10%\n",
      "483\tValidation loss: 0.426391\tBest loss: 0.426391\tAccuracy: 91.10%\n",
      "484\tValidation loss: 0.426748\tBest loss: 0.426391\tAccuracy: 91.20%\n",
      "485\tValidation loss: 0.426143\tBest loss: 0.426143\tAccuracy: 91.00%\n",
      "486\tValidation loss: 0.427198\tBest loss: 0.426143\tAccuracy: 91.00%\n",
      "487\tValidation loss: 0.426937\tBest loss: 0.426143\tAccuracy: 90.80%\n",
      "488\tValidation loss: 0.427354\tBest loss: 0.426143\tAccuracy: 91.00%\n",
      "489\tValidation loss: 0.425991\tBest loss: 0.425991\tAccuracy: 91.10%\n",
      "490\tValidation loss: 0.424859\tBest loss: 0.424859\tAccuracy: 90.90%\n",
      "491\tValidation loss: 0.426357\tBest loss: 0.424859\tAccuracy: 90.60%\n",
      "492\tValidation loss: 0.426354\tBest loss: 0.424859\tAccuracy: 91.00%\n",
      "493\tValidation loss: 0.426463\tBest loss: 0.424859\tAccuracy: 90.90%\n",
      "494\tValidation loss: 0.426635\tBest loss: 0.424859\tAccuracy: 91.00%\n",
      "495\tValidation loss: 0.426000\tBest loss: 0.424859\tAccuracy: 91.10%\n",
      "496\tValidation loss: 0.424984\tBest loss: 0.424859\tAccuracy: 91.20%\n",
      "497\tValidation loss: 0.424892\tBest loss: 0.424859\tAccuracy: 91.20%\n",
      "498\tValidation loss: 0.425624\tBest loss: 0.424859\tAccuracy: 91.00%\n",
      "499\tValidation loss: 0.424847\tBest loss: 0.424847\tAccuracy: 91.10%\n",
      "500\tValidation loss: 0.426631\tBest loss: 0.424847\tAccuracy: 91.20%\n",
      "501\tValidation loss: 0.425633\tBest loss: 0.424847\tAccuracy: 91.20%\n",
      "502\tValidation loss: 0.424668\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "503\tValidation loss: 0.425614\tBest loss: 0.424668\tAccuracy: 90.90%\n",
      "504\tValidation loss: 0.425744\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "505\tValidation loss: 0.425256\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "506\tValidation loss: 0.425160\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "507\tValidation loss: 0.424917\tBest loss: 0.424668\tAccuracy: 91.10%\n",
      "508\tValidation loss: 0.425464\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "509\tValidation loss: 0.424931\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "510\tValidation loss: 0.426306\tBest loss: 0.424668\tAccuracy: 91.10%\n",
      "511\tValidation loss: 0.424940\tBest loss: 0.424668\tAccuracy: 91.30%\n",
      "512\tValidation loss: 0.424682\tBest loss: 0.424668\tAccuracy: 91.20%\n",
      "513\tValidation loss: 0.424871\tBest loss: 0.424668\tAccuracy: 91.10%\n",
      "514\tValidation loss: 0.425666\tBest loss: 0.424668\tAccuracy: 91.30%\n",
      "515\tValidation loss: 0.424431\tBest loss: 0.424431\tAccuracy: 91.30%\n",
      "516\tValidation loss: 0.424604\tBest loss: 0.424431\tAccuracy: 91.30%\n",
      "517\tValidation loss: 0.425239\tBest loss: 0.424431\tAccuracy: 91.30%\n",
      "518\tValidation loss: 0.425554\tBest loss: 0.424431\tAccuracy: 91.30%\n",
      "519\tValidation loss: 0.425167\tBest loss: 0.424431\tAccuracy: 91.20%\n",
      "520\tValidation loss: 0.425291\tBest loss: 0.424431\tAccuracy: 91.30%\n",
      "521\tValidation loss: 0.423707\tBest loss: 0.423707\tAccuracy: 91.20%\n",
      "522\tValidation loss: 0.423924\tBest loss: 0.423707\tAccuracy: 91.30%\n",
      "523\tValidation loss: 0.424170\tBest loss: 0.423707\tAccuracy: 91.30%\n",
      "524\tValidation loss: 0.423819\tBest loss: 0.423707\tAccuracy: 91.20%\n",
      "525\tValidation loss: 0.423975\tBest loss: 0.423707\tAccuracy: 91.30%\n",
      "526\tValidation loss: 0.423484\tBest loss: 0.423484\tAccuracy: 91.30%\n",
      "527\tValidation loss: 0.423770\tBest loss: 0.423484\tAccuracy: 91.30%\n",
      "528\tValidation loss: 0.423448\tBest loss: 0.423448\tAccuracy: 91.30%\n",
      "529\tValidation loss: 0.423986\tBest loss: 0.423448\tAccuracy: 91.20%\n",
      "530\tValidation loss: 0.423219\tBest loss: 0.423219\tAccuracy: 91.20%\n",
      "531\tValidation loss: 0.423350\tBest loss: 0.423219\tAccuracy: 91.30%\n",
      "532\tValidation loss: 0.424672\tBest loss: 0.423219\tAccuracy: 91.20%\n",
      "533\tValidation loss: 0.422385\tBest loss: 0.422385\tAccuracy: 91.20%\n",
      "534\tValidation loss: 0.422707\tBest loss: 0.422385\tAccuracy: 91.20%\n",
      "535\tValidation loss: 0.423567\tBest loss: 0.422385\tAccuracy: 91.30%\n",
      "536\tValidation loss: 0.421855\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "537\tValidation loss: 0.423777\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "538\tValidation loss: 0.423134\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "539\tValidation loss: 0.424126\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "540\tValidation loss: 0.422262\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "541\tValidation loss: 0.422432\tBest loss: 0.421855\tAccuracy: 91.40%\n",
      "542\tValidation loss: 0.422536\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "543\tValidation loss: 0.422136\tBest loss: 0.421855\tAccuracy: 91.20%\n",
      "544\tValidation loss: 0.423355\tBest loss: 0.421855\tAccuracy: 91.20%\n",
      "545\tValidation loss: 0.422958\tBest loss: 0.421855\tAccuracy: 91.20%\n",
      "546\tValidation loss: 0.422217\tBest loss: 0.421855\tAccuracy: 91.10%\n",
      "547\tValidation loss: 0.421943\tBest loss: 0.421855\tAccuracy: 91.30%\n",
      "548\tValidation loss: 0.420772\tBest loss: 0.420772\tAccuracy: 91.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\tValidation loss: 0.421740\tBest loss: 0.420772\tAccuracy: 91.20%\n",
      "550\tValidation loss: 0.421857\tBest loss: 0.420772\tAccuracy: 91.30%\n",
      "551\tValidation loss: 0.423711\tBest loss: 0.420772\tAccuracy: 91.30%\n",
      "552\tValidation loss: 0.421399\tBest loss: 0.420772\tAccuracy: 91.40%\n",
      "553\tValidation loss: 0.421581\tBest loss: 0.420772\tAccuracy: 91.40%\n",
      "554\tValidation loss: 0.422167\tBest loss: 0.420772\tAccuracy: 91.30%\n",
      "555\tValidation loss: 0.421065\tBest loss: 0.420772\tAccuracy: 91.50%\n",
      "556\tValidation loss: 0.421858\tBest loss: 0.420772\tAccuracy: 91.30%\n",
      "557\tValidation loss: 0.420195\tBest loss: 0.420195\tAccuracy: 91.40%\n",
      "558\tValidation loss: 0.421806\tBest loss: 0.420195\tAccuracy: 91.20%\n",
      "559\tValidation loss: 0.421201\tBest loss: 0.420195\tAccuracy: 91.60%\n",
      "560\tValidation loss: 0.421895\tBest loss: 0.420195\tAccuracy: 91.50%\n",
      "561\tValidation loss: 0.421266\tBest loss: 0.420195\tAccuracy: 91.50%\n",
      "562\tValidation loss: 0.421218\tBest loss: 0.420195\tAccuracy: 91.30%\n",
      "563\tValidation loss: 0.421296\tBest loss: 0.420195\tAccuracy: 91.30%\n",
      "564\tValidation loss: 0.420318\tBest loss: 0.420195\tAccuracy: 91.30%\n",
      "565\tValidation loss: 0.419778\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "566\tValidation loss: 0.421563\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "567\tValidation loss: 0.420199\tBest loss: 0.419778\tAccuracy: 91.50%\n",
      "568\tValidation loss: 0.420012\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "569\tValidation loss: 0.421858\tBest loss: 0.419778\tAccuracy: 91.30%\n",
      "570\tValidation loss: 0.421428\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "571\tValidation loss: 0.421074\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "572\tValidation loss: 0.421201\tBest loss: 0.419778\tAccuracy: 91.60%\n",
      "573\tValidation loss: 0.421043\tBest loss: 0.419778\tAccuracy: 91.50%\n",
      "574\tValidation loss: 0.419906\tBest loss: 0.419778\tAccuracy: 91.50%\n",
      "575\tValidation loss: 0.421192\tBest loss: 0.419778\tAccuracy: 91.60%\n",
      "576\tValidation loss: 0.421045\tBest loss: 0.419778\tAccuracy: 91.60%\n",
      "577\tValidation loss: 0.420830\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "578\tValidation loss: 0.421157\tBest loss: 0.419778\tAccuracy: 91.60%\n",
      "579\tValidation loss: 0.420128\tBest loss: 0.419778\tAccuracy: 91.40%\n",
      "580\tValidation loss: 0.419577\tBest loss: 0.419577\tAccuracy: 91.50%\n",
      "581\tValidation loss: 0.420119\tBest loss: 0.419577\tAccuracy: 91.60%\n",
      "582\tValidation loss: 0.419862\tBest loss: 0.419577\tAccuracy: 91.50%\n",
      "583\tValidation loss: 0.420561\tBest loss: 0.419577\tAccuracy: 91.60%\n",
      "584\tValidation loss: 0.420296\tBest loss: 0.419577\tAccuracy: 91.40%\n",
      "585\tValidation loss: 0.420710\tBest loss: 0.419577\tAccuracy: 91.60%\n",
      "586\tValidation loss: 0.419391\tBest loss: 0.419391\tAccuracy: 91.70%\n",
      "587\tValidation loss: 0.420267\tBest loss: 0.419391\tAccuracy: 91.90%\n",
      "588\tValidation loss: 0.420023\tBest loss: 0.419391\tAccuracy: 91.60%\n",
      "589\tValidation loss: 0.419708\tBest loss: 0.419391\tAccuracy: 91.90%\n",
      "590\tValidation loss: 0.419301\tBest loss: 0.419301\tAccuracy: 91.80%\n",
      "591\tValidation loss: 0.420823\tBest loss: 0.419301\tAccuracy: 91.70%\n",
      "592\tValidation loss: 0.419121\tBest loss: 0.419121\tAccuracy: 92.00%\n",
      "593\tValidation loss: 0.421102\tBest loss: 0.419121\tAccuracy: 91.70%\n",
      "594\tValidation loss: 0.420203\tBest loss: 0.419121\tAccuracy: 91.70%\n",
      "595\tValidation loss: 0.419828\tBest loss: 0.419121\tAccuracy: 92.00%\n",
      "596\tValidation loss: 0.419225\tBest loss: 0.419121\tAccuracy: 91.80%\n",
      "597\tValidation loss: 0.419768\tBest loss: 0.419121\tAccuracy: 91.80%\n",
      "598\tValidation loss: 0.419734\tBest loss: 0.419121\tAccuracy: 92.00%\n",
      "599\tValidation loss: 0.418849\tBest loss: 0.418849\tAccuracy: 92.00%\n",
      "600\tValidation loss: 0.420127\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "601\tValidation loss: 0.419735\tBest loss: 0.418849\tAccuracy: 91.70%\n",
      "602\tValidation loss: 0.419326\tBest loss: 0.418849\tAccuracy: 92.00%\n",
      "603\tValidation loss: 0.419474\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "604\tValidation loss: 0.419003\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "605\tValidation loss: 0.419312\tBest loss: 0.418849\tAccuracy: 92.00%\n",
      "606\tValidation loss: 0.419313\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "607\tValidation loss: 0.419196\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "608\tValidation loss: 0.420780\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "609\tValidation loss: 0.419698\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "610\tValidation loss: 0.420231\tBest loss: 0.418849\tAccuracy: 92.10%\n",
      "611\tValidation loss: 0.419374\tBest loss: 0.418849\tAccuracy: 91.90%\n",
      "612\tValidation loss: 0.418778\tBest loss: 0.418778\tAccuracy: 91.70%\n",
      "613\tValidation loss: 0.419260\tBest loss: 0.418778\tAccuracy: 91.90%\n",
      "614\tValidation loss: 0.418550\tBest loss: 0.418550\tAccuracy: 91.90%\n",
      "615\tValidation loss: 0.419075\tBest loss: 0.418550\tAccuracy: 91.90%\n",
      "616\tValidation loss: 0.418709\tBest loss: 0.418550\tAccuracy: 91.90%\n",
      "617\tValidation loss: 0.418123\tBest loss: 0.418123\tAccuracy: 91.90%\n",
      "618\tValidation loss: 0.419333\tBest loss: 0.418123\tAccuracy: 91.90%\n",
      "619\tValidation loss: 0.418836\tBest loss: 0.418123\tAccuracy: 92.00%\n",
      "620\tValidation loss: 0.418738\tBest loss: 0.418123\tAccuracy: 91.90%\n",
      "621\tValidation loss: 0.418142\tBest loss: 0.418123\tAccuracy: 91.90%\n",
      "622\tValidation loss: 0.419042\tBest loss: 0.418123\tAccuracy: 92.00%\n",
      "623\tValidation loss: 0.419264\tBest loss: 0.418123\tAccuracy: 91.90%\n",
      "624\tValidation loss: 0.419021\tBest loss: 0.418123\tAccuracy: 92.00%\n",
      "625\tValidation loss: 0.418813\tBest loss: 0.418123\tAccuracy: 92.00%\n",
      "626\tValidation loss: 0.417056\tBest loss: 0.417056\tAccuracy: 92.10%\n",
      "627\tValidation loss: 0.418472\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "628\tValidation loss: 0.418186\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "629\tValidation loss: 0.417856\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "630\tValidation loss: 0.417470\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "631\tValidation loss: 0.418078\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "632\tValidation loss: 0.418936\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "633\tValidation loss: 0.418149\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "634\tValidation loss: 0.417881\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "635\tValidation loss: 0.418436\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "636\tValidation loss: 0.418202\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "637\tValidation loss: 0.418020\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "638\tValidation loss: 0.418693\tBest loss: 0.417056\tAccuracy: 92.10%\n",
      "639\tValidation loss: 0.418223\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "640\tValidation loss: 0.417385\tBest loss: 0.417056\tAccuracy: 91.90%\n",
      "641\tValidation loss: 0.417395\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "642\tValidation loss: 0.417932\tBest loss: 0.417056\tAccuracy: 92.20%\n",
      "643\tValidation loss: 0.418285\tBest loss: 0.417056\tAccuracy: 92.00%\n",
      "644\tValidation loss: 0.416761\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "645\tValidation loss: 0.417628\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "646\tValidation loss: 0.416979\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "647\tValidation loss: 0.418079\tBest loss: 0.416761\tAccuracy: 91.90%\n",
      "648\tValidation loss: 0.417519\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "649\tValidation loss: 0.417845\tBest loss: 0.416761\tAccuracy: 92.10%\n",
      "650\tValidation loss: 0.417118\tBest loss: 0.416761\tAccuracy: 92.20%\n",
      "651\tValidation loss: 0.417245\tBest loss: 0.416761\tAccuracy: 92.10%\n",
      "652\tValidation loss: 0.417475\tBest loss: 0.416761\tAccuracy: 91.90%\n",
      "653\tValidation loss: 0.417406\tBest loss: 0.416761\tAccuracy: 91.90%\n",
      "654\tValidation loss: 0.418239\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "655\tValidation loss: 0.417269\tBest loss: 0.416761\tAccuracy: 92.10%\n",
      "656\tValidation loss: 0.418347\tBest loss: 0.416761\tAccuracy: 92.00%\n",
      "657\tValidation loss: 0.417718\tBest loss: 0.416761\tAccuracy: 92.10%\n",
      "658\tValidation loss: 0.416731\tBest loss: 0.416731\tAccuracy: 92.00%\n",
      "659\tValidation loss: 0.417110\tBest loss: 0.416731\tAccuracy: 92.10%\n",
      "660\tValidation loss: 0.417906\tBest loss: 0.416731\tAccuracy: 92.10%\n",
      "661\tValidation loss: 0.416546\tBest loss: 0.416546\tAccuracy: 92.00%\n",
      "662\tValidation loss: 0.417665\tBest loss: 0.416546\tAccuracy: 92.00%\n",
      "663\tValidation loss: 0.416636\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "664\tValidation loss: 0.417608\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "665\tValidation loss: 0.417431\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "666\tValidation loss: 0.417054\tBest loss: 0.416546\tAccuracy: 92.00%\n",
      "667\tValidation loss: 0.416908\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "668\tValidation loss: 0.417001\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "669\tValidation loss: 0.417129\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "670\tValidation loss: 0.416632\tBest loss: 0.416546\tAccuracy: 92.00%\n",
      "671\tValidation loss: 0.416763\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "672\tValidation loss: 0.416973\tBest loss: 0.416546\tAccuracy: 92.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673\tValidation loss: 0.416559\tBest loss: 0.416546\tAccuracy: 92.20%\n",
      "674\tValidation loss: 0.416698\tBest loss: 0.416546\tAccuracy: 92.10%\n",
      "675\tValidation loss: 0.416035\tBest loss: 0.416035\tAccuracy: 92.10%\n",
      "676\tValidation loss: 0.417076\tBest loss: 0.416035\tAccuracy: 92.10%\n",
      "677\tValidation loss: 0.416216\tBest loss: 0.416035\tAccuracy: 92.20%\n",
      "678\tValidation loss: 0.416791\tBest loss: 0.416035\tAccuracy: 92.30%\n",
      "679\tValidation loss: 0.415447\tBest loss: 0.415447\tAccuracy: 92.00%\n",
      "680\tValidation loss: 0.417166\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "681\tValidation loss: 0.416258\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "682\tValidation loss: 0.416113\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "683\tValidation loss: 0.416218\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "684\tValidation loss: 0.417055\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "685\tValidation loss: 0.416513\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "686\tValidation loss: 0.416611\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "687\tValidation loss: 0.416397\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "688\tValidation loss: 0.416337\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "689\tValidation loss: 0.415835\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "690\tValidation loss: 0.416562\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "691\tValidation loss: 0.416486\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "692\tValidation loss: 0.416330\tBest loss: 0.415447\tAccuracy: 92.00%\n",
      "693\tValidation loss: 0.417234\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "694\tValidation loss: 0.416199\tBest loss: 0.415447\tAccuracy: 92.30%\n",
      "695\tValidation loss: 0.415704\tBest loss: 0.415447\tAccuracy: 92.10%\n",
      "696\tValidation loss: 0.415795\tBest loss: 0.415447\tAccuracy: 92.20%\n",
      "697\tValidation loss: 0.415233\tBest loss: 0.415233\tAccuracy: 92.20%\n",
      "698\tValidation loss: 0.415566\tBest loss: 0.415233\tAccuracy: 92.20%\n",
      "699\tValidation loss: 0.415963\tBest loss: 0.415233\tAccuracy: 92.20%\n",
      "700\tValidation loss: 0.416574\tBest loss: 0.415233\tAccuracy: 92.30%\n",
      "701\tValidation loss: 0.415587\tBest loss: 0.415233\tAccuracy: 92.20%\n",
      "702\tValidation loss: 0.415737\tBest loss: 0.415233\tAccuracy: 92.10%\n",
      "703\tValidation loss: 0.415981\tBest loss: 0.415233\tAccuracy: 92.30%\n",
      "704\tValidation loss: 0.415743\tBest loss: 0.415233\tAccuracy: 92.20%\n",
      "705\tValidation loss: 0.414747\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "706\tValidation loss: 0.415465\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "707\tValidation loss: 0.415257\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "708\tValidation loss: 0.416717\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "709\tValidation loss: 0.416019\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "710\tValidation loss: 0.415978\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "711\tValidation loss: 0.415781\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "712\tValidation loss: 0.415330\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "713\tValidation loss: 0.415042\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "714\tValidation loss: 0.415623\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "715\tValidation loss: 0.414887\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "716\tValidation loss: 0.414841\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "717\tValidation loss: 0.415339\tBest loss: 0.414747\tAccuracy: 92.30%\n",
      "718\tValidation loss: 0.415891\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "719\tValidation loss: 0.416095\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "720\tValidation loss: 0.414891\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "721\tValidation loss: 0.415076\tBest loss: 0.414747\tAccuracy: 92.20%\n",
      "722\tValidation loss: 0.415715\tBest loss: 0.414747\tAccuracy: 92.30%\n",
      "723\tValidation loss: 0.414582\tBest loss: 0.414582\tAccuracy: 92.20%\n",
      "724\tValidation loss: 0.415938\tBest loss: 0.414582\tAccuracy: 92.20%\n",
      "725\tValidation loss: 0.415901\tBest loss: 0.414582\tAccuracy: 92.20%\n",
      "726\tValidation loss: 0.415558\tBest loss: 0.414582\tAccuracy: 92.20%\n",
      "727\tValidation loss: 0.416223\tBest loss: 0.414582\tAccuracy: 92.30%\n",
      "728\tValidation loss: 0.415677\tBest loss: 0.414582\tAccuracy: 92.20%\n",
      "729\tValidation loss: 0.415234\tBest loss: 0.414582\tAccuracy: 92.30%\n",
      "730\tValidation loss: 0.414906\tBest loss: 0.414582\tAccuracy: 92.30%\n",
      "731\tValidation loss: 0.414516\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "732\tValidation loss: 0.416594\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "733\tValidation loss: 0.415272\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "734\tValidation loss: 0.416263\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "735\tValidation loss: 0.415504\tBest loss: 0.414516\tAccuracy: 92.20%\n",
      "736\tValidation loss: 0.415249\tBest loss: 0.414516\tAccuracy: 92.20%\n",
      "737\tValidation loss: 0.415624\tBest loss: 0.414516\tAccuracy: 92.20%\n",
      "738\tValidation loss: 0.415313\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "739\tValidation loss: 0.416361\tBest loss: 0.414516\tAccuracy: 92.20%\n",
      "740\tValidation loss: 0.415039\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "741\tValidation loss: 0.414757\tBest loss: 0.414516\tAccuracy: 92.30%\n",
      "742\tValidation loss: 0.415094\tBest loss: 0.414516\tAccuracy: 92.20%\n",
      "743\tValidation loss: 0.414479\tBest loss: 0.414479\tAccuracy: 92.20%\n",
      "744\tValidation loss: 0.415359\tBest loss: 0.414479\tAccuracy: 92.40%\n",
      "745\tValidation loss: 0.413615\tBest loss: 0.413615\tAccuracy: 92.30%\n",
      "746\tValidation loss: 0.413316\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "747\tValidation loss: 0.415034\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "748\tValidation loss: 0.415291\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "749\tValidation loss: 0.415394\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "750\tValidation loss: 0.415071\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "751\tValidation loss: 0.415285\tBest loss: 0.413316\tAccuracy: 92.50%\n",
      "752\tValidation loss: 0.415511\tBest loss: 0.413316\tAccuracy: 92.40%\n",
      "753\tValidation loss: 0.413728\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "754\tValidation loss: 0.414779\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "755\tValidation loss: 0.415171\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "756\tValidation loss: 0.415927\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "757\tValidation loss: 0.415074\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "758\tValidation loss: 0.415061\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "759\tValidation loss: 0.415416\tBest loss: 0.413316\tAccuracy: 92.20%\n",
      "760\tValidation loss: 0.414599\tBest loss: 0.413316\tAccuracy: 92.40%\n",
      "761\tValidation loss: 0.415286\tBest loss: 0.413316\tAccuracy: 92.40%\n",
      "762\tValidation loss: 0.416124\tBest loss: 0.413316\tAccuracy: 92.50%\n",
      "763\tValidation loss: 0.414811\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "764\tValidation loss: 0.415790\tBest loss: 0.413316\tAccuracy: 92.40%\n",
      "765\tValidation loss: 0.414656\tBest loss: 0.413316\tAccuracy: 92.40%\n",
      "766\tValidation loss: 0.414554\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "767\tValidation loss: 0.414950\tBest loss: 0.413316\tAccuracy: 92.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.2min\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.078236\tBest loss: 3.078236\tAccuracy: 20.60%\n",
      "1\tValidation loss: 2.525757\tBest loss: 2.525757\tAccuracy: 37.50%\n",
      "2\tValidation loss: 2.185558\tBest loss: 2.185558\tAccuracy: 46.30%\n",
      "3\tValidation loss: 1.955922\tBest loss: 1.955922\tAccuracy: 52.70%\n",
      "4\tValidation loss: 1.773627\tBest loss: 1.773627\tAccuracy: 57.90%\n",
      "5\tValidation loss: 1.637614\tBest loss: 1.637614\tAccuracy: 60.30%\n",
      "6\tValidation loss: 1.536175\tBest loss: 1.536175\tAccuracy: 62.80%\n",
      "7\tValidation loss: 1.451578\tBest loss: 1.451578\tAccuracy: 64.60%\n",
      "8\tValidation loss: 1.382481\tBest loss: 1.382481\tAccuracy: 65.60%\n",
      "9\tValidation loss: 1.330016\tBest loss: 1.330016\tAccuracy: 67.30%\n",
      "10\tValidation loss: 1.266336\tBest loss: 1.266336\tAccuracy: 69.90%\n",
      "11\tValidation loss: 1.224585\tBest loss: 1.224585\tAccuracy: 70.50%\n",
      "12\tValidation loss: 1.190095\tBest loss: 1.190095\tAccuracy: 71.70%\n",
      "13\tValidation loss: 1.152176\tBest loss: 1.152176\tAccuracy: 72.20%\n",
      "14\tValidation loss: 1.115095\tBest loss: 1.115095\tAccuracy: 73.70%\n",
      "15\tValidation loss: 1.087323\tBest loss: 1.087323\tAccuracy: 74.40%\n",
      "16\tValidation loss: 1.066608\tBest loss: 1.066608\tAccuracy: 74.20%\n",
      "17\tValidation loss: 1.039166\tBest loss: 1.039166\tAccuracy: 75.70%\n",
      "18\tValidation loss: 1.019015\tBest loss: 1.019015\tAccuracy: 75.40%\n",
      "19\tValidation loss: 0.998841\tBest loss: 0.998841\tAccuracy: 76.10%\n",
      "20\tValidation loss: 0.983020\tBest loss: 0.983020\tAccuracy: 76.50%\n",
      "21\tValidation loss: 0.963306\tBest loss: 0.963306\tAccuracy: 76.10%\n",
      "22\tValidation loss: 0.947684\tBest loss: 0.947684\tAccuracy: 76.80%\n",
      "23\tValidation loss: 0.933655\tBest loss: 0.933655\tAccuracy: 77.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\tValidation loss: 0.917210\tBest loss: 0.917210\tAccuracy: 78.10%\n",
      "25\tValidation loss: 0.912612\tBest loss: 0.912612\tAccuracy: 78.10%\n",
      "26\tValidation loss: 0.892843\tBest loss: 0.892843\tAccuracy: 78.80%\n",
      "27\tValidation loss: 0.878825\tBest loss: 0.878825\tAccuracy: 78.40%\n",
      "28\tValidation loss: 0.872121\tBest loss: 0.872121\tAccuracy: 78.60%\n",
      "29\tValidation loss: 0.859355\tBest loss: 0.859355\tAccuracy: 79.30%\n",
      "30\tValidation loss: 0.849429\tBest loss: 0.849429\tAccuracy: 79.10%\n",
      "31\tValidation loss: 0.836931\tBest loss: 0.836931\tAccuracy: 80.00%\n",
      "32\tValidation loss: 0.830545\tBest loss: 0.830545\tAccuracy: 80.50%\n",
      "33\tValidation loss: 0.824780\tBest loss: 0.824780\tAccuracy: 80.10%\n",
      "34\tValidation loss: 0.813795\tBest loss: 0.813795\tAccuracy: 81.00%\n",
      "35\tValidation loss: 0.809119\tBest loss: 0.809119\tAccuracy: 80.70%\n",
      "36\tValidation loss: 0.803554\tBest loss: 0.803554\tAccuracy: 81.30%\n",
      "37\tValidation loss: 0.788761\tBest loss: 0.788761\tAccuracy: 81.00%\n",
      "38\tValidation loss: 0.780989\tBest loss: 0.780989\tAccuracy: 81.70%\n",
      "39\tValidation loss: 0.775253\tBest loss: 0.775253\tAccuracy: 81.50%\n",
      "40\tValidation loss: 0.769443\tBest loss: 0.769443\tAccuracy: 82.00%\n",
      "41\tValidation loss: 0.760116\tBest loss: 0.760116\tAccuracy: 82.30%\n",
      "42\tValidation loss: 0.756884\tBest loss: 0.756884\tAccuracy: 81.90%\n",
      "43\tValidation loss: 0.746293\tBest loss: 0.746293\tAccuracy: 82.20%\n",
      "44\tValidation loss: 0.742681\tBest loss: 0.742681\tAccuracy: 82.70%\n",
      "45\tValidation loss: 0.739975\tBest loss: 0.739975\tAccuracy: 82.80%\n",
      "46\tValidation loss: 0.734670\tBest loss: 0.734670\tAccuracy: 81.90%\n",
      "47\tValidation loss: 0.726514\tBest loss: 0.726514\tAccuracy: 82.60%\n",
      "48\tValidation loss: 0.721691\tBest loss: 0.721691\tAccuracy: 83.10%\n",
      "49\tValidation loss: 0.718119\tBest loss: 0.718119\tAccuracy: 83.00%\n",
      "50\tValidation loss: 0.711578\tBest loss: 0.711578\tAccuracy: 83.20%\n",
      "51\tValidation loss: 0.707143\tBest loss: 0.707143\tAccuracy: 83.00%\n",
      "52\tValidation loss: 0.703539\tBest loss: 0.703539\tAccuracy: 83.80%\n",
      "53\tValidation loss: 0.696966\tBest loss: 0.696966\tAccuracy: 83.50%\n",
      "54\tValidation loss: 0.693153\tBest loss: 0.693153\tAccuracy: 83.90%\n",
      "55\tValidation loss: 0.689083\tBest loss: 0.689083\tAccuracy: 83.60%\n",
      "56\tValidation loss: 0.685656\tBest loss: 0.685656\tAccuracy: 84.10%\n",
      "57\tValidation loss: 0.680707\tBest loss: 0.680707\tAccuracy: 84.50%\n",
      "58\tValidation loss: 0.679774\tBest loss: 0.679774\tAccuracy: 83.90%\n",
      "59\tValidation loss: 0.673214\tBest loss: 0.673214\tAccuracy: 83.90%\n",
      "60\tValidation loss: 0.669709\tBest loss: 0.669709\tAccuracy: 84.40%\n",
      "61\tValidation loss: 0.669630\tBest loss: 0.669630\tAccuracy: 84.40%\n",
      "62\tValidation loss: 0.662594\tBest loss: 0.662594\tAccuracy: 84.50%\n",
      "63\tValidation loss: 0.660673\tBest loss: 0.660673\tAccuracy: 84.60%\n",
      "64\tValidation loss: 0.655941\tBest loss: 0.655941\tAccuracy: 84.70%\n",
      "65\tValidation loss: 0.653846\tBest loss: 0.653846\tAccuracy: 84.40%\n",
      "66\tValidation loss: 0.649158\tBest loss: 0.649158\tAccuracy: 85.00%\n",
      "67\tValidation loss: 0.646824\tBest loss: 0.646824\tAccuracy: 84.70%\n",
      "68\tValidation loss: 0.641420\tBest loss: 0.641420\tAccuracy: 84.70%\n",
      "69\tValidation loss: 0.642627\tBest loss: 0.641420\tAccuracy: 84.90%\n",
      "70\tValidation loss: 0.636841\tBest loss: 0.636841\tAccuracy: 85.40%\n",
      "71\tValidation loss: 0.635019\tBest loss: 0.635019\tAccuracy: 85.30%\n",
      "72\tValidation loss: 0.631797\tBest loss: 0.631797\tAccuracy: 85.10%\n",
      "73\tValidation loss: 0.630620\tBest loss: 0.630620\tAccuracy: 85.20%\n",
      "74\tValidation loss: 0.627137\tBest loss: 0.627137\tAccuracy: 85.50%\n",
      "75\tValidation loss: 0.624649\tBest loss: 0.624649\tAccuracy: 85.70%\n",
      "76\tValidation loss: 0.626968\tBest loss: 0.624649\tAccuracy: 85.00%\n",
      "77\tValidation loss: 0.618299\tBest loss: 0.618299\tAccuracy: 85.70%\n",
      "78\tValidation loss: 0.613251\tBest loss: 0.613251\tAccuracy: 85.70%\n",
      "79\tValidation loss: 0.616337\tBest loss: 0.613251\tAccuracy: 85.50%\n",
      "80\tValidation loss: 0.610432\tBest loss: 0.610432\tAccuracy: 86.20%\n",
      "81\tValidation loss: 0.611781\tBest loss: 0.610432\tAccuracy: 85.30%\n",
      "82\tValidation loss: 0.607575\tBest loss: 0.607575\tAccuracy: 85.90%\n",
      "83\tValidation loss: 0.603959\tBest loss: 0.603959\tAccuracy: 86.40%\n",
      "84\tValidation loss: 0.602779\tBest loss: 0.602779\tAccuracy: 85.80%\n",
      "85\tValidation loss: 0.598797\tBest loss: 0.598797\tAccuracy: 86.10%\n",
      "86\tValidation loss: 0.598199\tBest loss: 0.598199\tAccuracy: 86.60%\n",
      "87\tValidation loss: 0.596122\tBest loss: 0.596122\tAccuracy: 86.20%\n",
      "88\tValidation loss: 0.595854\tBest loss: 0.595854\tAccuracy: 85.90%\n",
      "89\tValidation loss: 0.593662\tBest loss: 0.593662\tAccuracy: 85.90%\n",
      "90\tValidation loss: 0.590141\tBest loss: 0.590141\tAccuracy: 86.50%\n",
      "91\tValidation loss: 0.585947\tBest loss: 0.585947\tAccuracy: 86.80%\n",
      "92\tValidation loss: 0.590129\tBest loss: 0.585947\tAccuracy: 85.90%\n",
      "93\tValidation loss: 0.582780\tBest loss: 0.582780\tAccuracy: 87.00%\n",
      "94\tValidation loss: 0.581509\tBest loss: 0.581509\tAccuracy: 86.90%\n",
      "95\tValidation loss: 0.579219\tBest loss: 0.579219\tAccuracy: 86.90%\n",
      "96\tValidation loss: 0.575483\tBest loss: 0.575483\tAccuracy: 86.70%\n",
      "97\tValidation loss: 0.579833\tBest loss: 0.575483\tAccuracy: 86.60%\n",
      "98\tValidation loss: 0.574502\tBest loss: 0.574502\tAccuracy: 86.80%\n",
      "99\tValidation loss: 0.572253\tBest loss: 0.572253\tAccuracy: 87.20%\n",
      "100\tValidation loss: 0.572876\tBest loss: 0.572253\tAccuracy: 86.70%\n",
      "101\tValidation loss: 0.571021\tBest loss: 0.571021\tAccuracy: 87.20%\n",
      "102\tValidation loss: 0.566286\tBest loss: 0.566286\tAccuracy: 86.90%\n",
      "103\tValidation loss: 0.565413\tBest loss: 0.565413\tAccuracy: 87.00%\n",
      "104\tValidation loss: 0.567211\tBest loss: 0.565413\tAccuracy: 86.90%\n",
      "105\tValidation loss: 0.568446\tBest loss: 0.565413\tAccuracy: 86.70%\n",
      "106\tValidation loss: 0.562653\tBest loss: 0.562653\tAccuracy: 86.90%\n",
      "107\tValidation loss: 0.561276\tBest loss: 0.561276\tAccuracy: 86.90%\n",
      "108\tValidation loss: 0.560057\tBest loss: 0.560057\tAccuracy: 87.20%\n",
      "109\tValidation loss: 0.558149\tBest loss: 0.558149\tAccuracy: 87.00%\n",
      "110\tValidation loss: 0.557220\tBest loss: 0.557220\tAccuracy: 87.20%\n",
      "111\tValidation loss: 0.558595\tBest loss: 0.557220\tAccuracy: 87.00%\n",
      "112\tValidation loss: 0.552633\tBest loss: 0.552633\tAccuracy: 87.40%\n",
      "113\tValidation loss: 0.552840\tBest loss: 0.552633\tAccuracy: 87.10%\n",
      "114\tValidation loss: 0.554794\tBest loss: 0.552633\tAccuracy: 87.20%\n",
      "115\tValidation loss: 0.548943\tBest loss: 0.548943\tAccuracy: 87.30%\n",
      "116\tValidation loss: 0.551436\tBest loss: 0.548943\tAccuracy: 86.80%\n",
      "117\tValidation loss: 0.549228\tBest loss: 0.548943\tAccuracy: 87.40%\n",
      "118\tValidation loss: 0.543291\tBest loss: 0.543291\tAccuracy: 88.00%\n",
      "119\tValidation loss: 0.543138\tBest loss: 0.543138\tAccuracy: 87.30%\n",
      "120\tValidation loss: 0.541963\tBest loss: 0.541963\tAccuracy: 87.60%\n",
      "121\tValidation loss: 0.540508\tBest loss: 0.540508\tAccuracy: 87.50%\n",
      "122\tValidation loss: 0.542262\tBest loss: 0.540508\tAccuracy: 87.30%\n",
      "123\tValidation loss: 0.541361\tBest loss: 0.540508\tAccuracy: 87.90%\n",
      "124\tValidation loss: 0.540586\tBest loss: 0.540508\tAccuracy: 87.80%\n",
      "125\tValidation loss: 0.535965\tBest loss: 0.535965\tAccuracy: 87.80%\n",
      "126\tValidation loss: 0.535306\tBest loss: 0.535306\tAccuracy: 88.20%\n",
      "127\tValidation loss: 0.535017\tBest loss: 0.535017\tAccuracy: 87.40%\n",
      "128\tValidation loss: 0.532550\tBest loss: 0.532550\tAccuracy: 88.10%\n",
      "129\tValidation loss: 0.531266\tBest loss: 0.531266\tAccuracy: 88.30%\n",
      "130\tValidation loss: 0.531063\tBest loss: 0.531063\tAccuracy: 87.70%\n",
      "131\tValidation loss: 0.531068\tBest loss: 0.531063\tAccuracy: 88.00%\n",
      "132\tValidation loss: 0.527869\tBest loss: 0.527869\tAccuracy: 88.00%\n",
      "133\tValidation loss: 0.529958\tBest loss: 0.527869\tAccuracy: 87.80%\n",
      "134\tValidation loss: 0.527700\tBest loss: 0.527700\tAccuracy: 87.90%\n",
      "135\tValidation loss: 0.527601\tBest loss: 0.527601\tAccuracy: 88.00%\n",
      "136\tValidation loss: 0.524965\tBest loss: 0.524965\tAccuracy: 88.20%\n",
      "137\tValidation loss: 0.523595\tBest loss: 0.523595\tAccuracy: 88.10%\n",
      "138\tValidation loss: 0.524622\tBest loss: 0.523595\tAccuracy: 88.00%\n",
      "139\tValidation loss: 0.521365\tBest loss: 0.521365\tAccuracy: 88.10%\n",
      "140\tValidation loss: 0.519107\tBest loss: 0.519107\tAccuracy: 88.30%\n",
      "141\tValidation loss: 0.517853\tBest loss: 0.517853\tAccuracy: 88.00%\n",
      "142\tValidation loss: 0.518533\tBest loss: 0.517853\tAccuracy: 88.70%\n",
      "143\tValidation loss: 0.517741\tBest loss: 0.517741\tAccuracy: 87.80%\n",
      "144\tValidation loss: 0.517862\tBest loss: 0.517741\tAccuracy: 88.10%\n",
      "145\tValidation loss: 0.513304\tBest loss: 0.513304\tAccuracy: 88.10%\n",
      "146\tValidation loss: 0.514211\tBest loss: 0.513304\tAccuracy: 87.70%\n",
      "147\tValidation loss: 0.515024\tBest loss: 0.513304\tAccuracy: 88.30%\n",
      "148\tValidation loss: 0.514098\tBest loss: 0.513304\tAccuracy: 88.20%\n",
      "149\tValidation loss: 0.512863\tBest loss: 0.512863\tAccuracy: 88.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\tValidation loss: 0.511997\tBest loss: 0.511997\tAccuracy: 88.20%\n",
      "151\tValidation loss: 0.508936\tBest loss: 0.508936\tAccuracy: 88.40%\n",
      "152\tValidation loss: 0.509027\tBest loss: 0.508936\tAccuracy: 88.00%\n",
      "153\tValidation loss: 0.506912\tBest loss: 0.506912\tAccuracy: 88.60%\n",
      "154\tValidation loss: 0.508259\tBest loss: 0.506912\tAccuracy: 88.30%\n",
      "155\tValidation loss: 0.508661\tBest loss: 0.506912\tAccuracy: 88.10%\n",
      "156\tValidation loss: 0.508433\tBest loss: 0.506912\tAccuracy: 88.00%\n",
      "157\tValidation loss: 0.506974\tBest loss: 0.506912\tAccuracy: 88.60%\n",
      "158\tValidation loss: 0.503457\tBest loss: 0.503457\tAccuracy: 88.20%\n",
      "159\tValidation loss: 0.501862\tBest loss: 0.501862\tAccuracy: 88.10%\n",
      "160\tValidation loss: 0.506369\tBest loss: 0.501862\tAccuracy: 88.10%\n",
      "161\tValidation loss: 0.500996\tBest loss: 0.500996\tAccuracy: 88.60%\n",
      "162\tValidation loss: 0.498744\tBest loss: 0.498744\tAccuracy: 88.30%\n",
      "163\tValidation loss: 0.499785\tBest loss: 0.498744\tAccuracy: 89.00%\n",
      "164\tValidation loss: 0.499697\tBest loss: 0.498744\tAccuracy: 88.50%\n",
      "165\tValidation loss: 0.499382\tBest loss: 0.498744\tAccuracy: 88.70%\n",
      "166\tValidation loss: 0.498935\tBest loss: 0.498744\tAccuracy: 88.50%\n",
      "167\tValidation loss: 0.495408\tBest loss: 0.495408\tAccuracy: 88.30%\n",
      "168\tValidation loss: 0.494612\tBest loss: 0.494612\tAccuracy: 88.70%\n",
      "169\tValidation loss: 0.496939\tBest loss: 0.494612\tAccuracy: 88.60%\n",
      "170\tValidation loss: 0.495101\tBest loss: 0.494612\tAccuracy: 88.50%\n",
      "171\tValidation loss: 0.494370\tBest loss: 0.494370\tAccuracy: 88.90%\n",
      "172\tValidation loss: 0.493505\tBest loss: 0.493505\tAccuracy: 88.60%\n",
      "173\tValidation loss: 0.492705\tBest loss: 0.492705\tAccuracy: 88.80%\n",
      "174\tValidation loss: 0.492445\tBest loss: 0.492445\tAccuracy: 88.60%\n",
      "175\tValidation loss: 0.492086\tBest loss: 0.492086\tAccuracy: 88.20%\n",
      "176\tValidation loss: 0.490802\tBest loss: 0.490802\tAccuracy: 88.70%\n",
      "177\tValidation loss: 0.490269\tBest loss: 0.490269\tAccuracy: 88.60%\n",
      "178\tValidation loss: 0.487311\tBest loss: 0.487311\tAccuracy: 88.80%\n",
      "179\tValidation loss: 0.488365\tBest loss: 0.487311\tAccuracy: 88.70%\n",
      "180\tValidation loss: 0.486857\tBest loss: 0.486857\tAccuracy: 88.40%\n",
      "181\tValidation loss: 0.486055\tBest loss: 0.486055\tAccuracy: 89.20%\n",
      "182\tValidation loss: 0.487349\tBest loss: 0.486055\tAccuracy: 88.90%\n",
      "183\tValidation loss: 0.485164\tBest loss: 0.485164\tAccuracy: 88.90%\n",
      "184\tValidation loss: 0.486127\tBest loss: 0.485164\tAccuracy: 88.90%\n",
      "185\tValidation loss: 0.483256\tBest loss: 0.483256\tAccuracy: 89.00%\n",
      "186\tValidation loss: 0.485211\tBest loss: 0.483256\tAccuracy: 88.70%\n",
      "187\tValidation loss: 0.481178\tBest loss: 0.481178\tAccuracy: 88.90%\n",
      "188\tValidation loss: 0.482775\tBest loss: 0.481178\tAccuracy: 88.90%\n",
      "189\tValidation loss: 0.481430\tBest loss: 0.481178\tAccuracy: 89.00%\n",
      "190\tValidation loss: 0.479603\tBest loss: 0.479603\tAccuracy: 89.20%\n",
      "191\tValidation loss: 0.479422\tBest loss: 0.479422\tAccuracy: 89.30%\n",
      "192\tValidation loss: 0.478142\tBest loss: 0.478142\tAccuracy: 89.40%\n",
      "193\tValidation loss: 0.480143\tBest loss: 0.478142\tAccuracy: 89.10%\n",
      "194\tValidation loss: 0.481164\tBest loss: 0.478142\tAccuracy: 88.70%\n",
      "195\tValidation loss: 0.477905\tBest loss: 0.477905\tAccuracy: 88.80%\n",
      "196\tValidation loss: 0.474845\tBest loss: 0.474845\tAccuracy: 89.40%\n",
      "197\tValidation loss: 0.475357\tBest loss: 0.474845\tAccuracy: 89.00%\n",
      "198\tValidation loss: 0.477570\tBest loss: 0.474845\tAccuracy: 89.00%\n",
      "199\tValidation loss: 0.476656\tBest loss: 0.474845\tAccuracy: 89.00%\n",
      "200\tValidation loss: 0.474045\tBest loss: 0.474045\tAccuracy: 89.50%\n",
      "201\tValidation loss: 0.475510\tBest loss: 0.474045\tAccuracy: 89.10%\n",
      "202\tValidation loss: 0.473531\tBest loss: 0.473531\tAccuracy: 89.30%\n",
      "203\tValidation loss: 0.473191\tBest loss: 0.473191\tAccuracy: 89.20%\n",
      "204\tValidation loss: 0.472770\tBest loss: 0.472770\tAccuracy: 89.10%\n",
      "205\tValidation loss: 0.470816\tBest loss: 0.470816\tAccuracy: 89.40%\n",
      "206\tValidation loss: 0.472425\tBest loss: 0.470816\tAccuracy: 89.00%\n",
      "207\tValidation loss: 0.470343\tBest loss: 0.470343\tAccuracy: 89.30%\n",
      "208\tValidation loss: 0.470363\tBest loss: 0.470343\tAccuracy: 89.20%\n",
      "209\tValidation loss: 0.471472\tBest loss: 0.470343\tAccuracy: 89.00%\n",
      "210\tValidation loss: 0.470527\tBest loss: 0.470343\tAccuracy: 89.30%\n",
      "211\tValidation loss: 0.467593\tBest loss: 0.467593\tAccuracy: 89.40%\n",
      "212\tValidation loss: 0.467862\tBest loss: 0.467593\tAccuracy: 89.50%\n",
      "213\tValidation loss: 0.469181\tBest loss: 0.467593\tAccuracy: 89.00%\n",
      "214\tValidation loss: 0.465968\tBest loss: 0.465968\tAccuracy: 89.40%\n",
      "215\tValidation loss: 0.468093\tBest loss: 0.465968\tAccuracy: 89.30%\n",
      "216\tValidation loss: 0.467655\tBest loss: 0.465968\tAccuracy: 89.30%\n",
      "217\tValidation loss: 0.466235\tBest loss: 0.465968\tAccuracy: 89.50%\n",
      "218\tValidation loss: 0.464550\tBest loss: 0.464550\tAccuracy: 89.50%\n",
      "219\tValidation loss: 0.466454\tBest loss: 0.464550\tAccuracy: 89.50%\n",
      "220\tValidation loss: 0.462302\tBest loss: 0.462302\tAccuracy: 89.60%\n",
      "221\tValidation loss: 0.464851\tBest loss: 0.462302\tAccuracy: 89.60%\n",
      "222\tValidation loss: 0.463515\tBest loss: 0.462302\tAccuracy: 89.50%\n",
      "223\tValidation loss: 0.463937\tBest loss: 0.462302\tAccuracy: 89.50%\n",
      "224\tValidation loss: 0.464630\tBest loss: 0.462302\tAccuracy: 89.60%\n",
      "225\tValidation loss: 0.462426\tBest loss: 0.462302\tAccuracy: 89.60%\n",
      "226\tValidation loss: 0.461688\tBest loss: 0.461688\tAccuracy: 89.70%\n",
      "227\tValidation loss: 0.458696\tBest loss: 0.458696\tAccuracy: 89.50%\n",
      "228\tValidation loss: 0.459152\tBest loss: 0.458696\tAccuracy: 89.50%\n",
      "229\tValidation loss: 0.460741\tBest loss: 0.458696\tAccuracy: 89.60%\n",
      "230\tValidation loss: 0.459042\tBest loss: 0.458696\tAccuracy: 89.60%\n",
      "231\tValidation loss: 0.458007\tBest loss: 0.458007\tAccuracy: 89.50%\n",
      "232\tValidation loss: 0.458790\tBest loss: 0.458007\tAccuracy: 89.90%\n",
      "233\tValidation loss: 0.457895\tBest loss: 0.457895\tAccuracy: 89.70%\n",
      "234\tValidation loss: 0.457446\tBest loss: 0.457446\tAccuracy: 89.80%\n",
      "235\tValidation loss: 0.458767\tBest loss: 0.457446\tAccuracy: 89.50%\n",
      "236\tValidation loss: 0.457099\tBest loss: 0.457099\tAccuracy: 89.70%\n",
      "237\tValidation loss: 0.456591\tBest loss: 0.456591\tAccuracy: 89.60%\n",
      "238\tValidation loss: 0.458039\tBest loss: 0.456591\tAccuracy: 89.40%\n",
      "239\tValidation loss: 0.456512\tBest loss: 0.456512\tAccuracy: 89.70%\n",
      "240\tValidation loss: 0.455552\tBest loss: 0.455552\tAccuracy: 89.60%\n",
      "241\tValidation loss: 0.455934\tBest loss: 0.455552\tAccuracy: 89.90%\n",
      "242\tValidation loss: 0.452761\tBest loss: 0.452761\tAccuracy: 89.80%\n",
      "243\tValidation loss: 0.452998\tBest loss: 0.452761\tAccuracy: 90.00%\n",
      "244\tValidation loss: 0.455087\tBest loss: 0.452761\tAccuracy: 89.80%\n",
      "245\tValidation loss: 0.453163\tBest loss: 0.452761\tAccuracy: 89.60%\n",
      "246\tValidation loss: 0.453426\tBest loss: 0.452761\tAccuracy: 89.90%\n",
      "247\tValidation loss: 0.451110\tBest loss: 0.451110\tAccuracy: 89.90%\n",
      "248\tValidation loss: 0.449646\tBest loss: 0.449646\tAccuracy: 89.80%\n",
      "249\tValidation loss: 0.450170\tBest loss: 0.449646\tAccuracy: 89.90%\n",
      "250\tValidation loss: 0.451038\tBest loss: 0.449646\tAccuracy: 90.20%\n",
      "251\tValidation loss: 0.450115\tBest loss: 0.449646\tAccuracy: 90.10%\n",
      "252\tValidation loss: 0.448548\tBest loss: 0.448548\tAccuracy: 89.70%\n",
      "253\tValidation loss: 0.449184\tBest loss: 0.448548\tAccuracy: 90.00%\n",
      "254\tValidation loss: 0.449128\tBest loss: 0.448548\tAccuracy: 90.00%\n",
      "255\tValidation loss: 0.450219\tBest loss: 0.448548\tAccuracy: 89.90%\n",
      "256\tValidation loss: 0.447677\tBest loss: 0.447677\tAccuracy: 89.90%\n",
      "257\tValidation loss: 0.450169\tBest loss: 0.447677\tAccuracy: 89.70%\n",
      "258\tValidation loss: 0.447489\tBest loss: 0.447489\tAccuracy: 89.80%\n",
      "259\tValidation loss: 0.449077\tBest loss: 0.447489\tAccuracy: 89.60%\n",
      "260\tValidation loss: 0.447195\tBest loss: 0.447195\tAccuracy: 89.70%\n",
      "261\tValidation loss: 0.446792\tBest loss: 0.446792\tAccuracy: 89.70%\n",
      "262\tValidation loss: 0.446820\tBest loss: 0.446792\tAccuracy: 90.00%\n",
      "263\tValidation loss: 0.445196\tBest loss: 0.445196\tAccuracy: 90.00%\n",
      "264\tValidation loss: 0.445903\tBest loss: 0.445196\tAccuracy: 89.90%\n",
      "265\tValidation loss: 0.444387\tBest loss: 0.444387\tAccuracy: 89.70%\n",
      "266\tValidation loss: 0.444147\tBest loss: 0.444147\tAccuracy: 89.80%\n",
      "267\tValidation loss: 0.443446\tBest loss: 0.443446\tAccuracy: 89.90%\n",
      "268\tValidation loss: 0.443476\tBest loss: 0.443446\tAccuracy: 90.20%\n",
      "269\tValidation loss: 0.442547\tBest loss: 0.442547\tAccuracy: 89.80%\n",
      "270\tValidation loss: 0.443830\tBest loss: 0.442547\tAccuracy: 89.80%\n",
      "271\tValidation loss: 0.442013\tBest loss: 0.442013\tAccuracy: 89.90%\n",
      "272\tValidation loss: 0.441141\tBest loss: 0.441141\tAccuracy: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\tValidation loss: 0.441997\tBest loss: 0.441141\tAccuracy: 90.10%\n",
      "274\tValidation loss: 0.440089\tBest loss: 0.440089\tAccuracy: 89.90%\n",
      "275\tValidation loss: 0.442867\tBest loss: 0.440089\tAccuracy: 89.70%\n",
      "276\tValidation loss: 0.443416\tBest loss: 0.440089\tAccuracy: 90.00%\n",
      "277\tValidation loss: 0.440833\tBest loss: 0.440089\tAccuracy: 89.90%\n",
      "278\tValidation loss: 0.439781\tBest loss: 0.439781\tAccuracy: 90.20%\n",
      "279\tValidation loss: 0.440325\tBest loss: 0.439781\tAccuracy: 90.00%\n",
      "280\tValidation loss: 0.439381\tBest loss: 0.439381\tAccuracy: 90.20%\n",
      "281\tValidation loss: 0.440222\tBest loss: 0.439381\tAccuracy: 89.90%\n",
      "282\tValidation loss: 0.438095\tBest loss: 0.438095\tAccuracy: 89.80%\n",
      "283\tValidation loss: 0.437586\tBest loss: 0.437586\tAccuracy: 90.10%\n",
      "284\tValidation loss: 0.437878\tBest loss: 0.437586\tAccuracy: 89.90%\n",
      "285\tValidation loss: 0.436257\tBest loss: 0.436257\tAccuracy: 90.10%\n",
      "286\tValidation loss: 0.437396\tBest loss: 0.436257\tAccuracy: 89.90%\n",
      "287\tValidation loss: 0.437453\tBest loss: 0.436257\tAccuracy: 89.70%\n",
      "288\tValidation loss: 0.434898\tBest loss: 0.434898\tAccuracy: 89.90%\n",
      "289\tValidation loss: 0.437128\tBest loss: 0.434898\tAccuracy: 90.20%\n",
      "290\tValidation loss: 0.435109\tBest loss: 0.434898\tAccuracy: 90.10%\n",
      "291\tValidation loss: 0.436742\tBest loss: 0.434898\tAccuracy: 90.50%\n",
      "292\tValidation loss: 0.436137\tBest loss: 0.434898\tAccuracy: 90.30%\n",
      "293\tValidation loss: 0.435983\tBest loss: 0.434898\tAccuracy: 90.30%\n",
      "294\tValidation loss: 0.435421\tBest loss: 0.434898\tAccuracy: 90.20%\n",
      "295\tValidation loss: 0.434767\tBest loss: 0.434767\tAccuracy: 90.30%\n",
      "296\tValidation loss: 0.435021\tBest loss: 0.434767\tAccuracy: 90.40%\n",
      "297\tValidation loss: 0.433588\tBest loss: 0.433588\tAccuracy: 90.10%\n",
      "298\tValidation loss: 0.433711\tBest loss: 0.433588\tAccuracy: 89.90%\n",
      "299\tValidation loss: 0.432946\tBest loss: 0.432946\tAccuracy: 90.30%\n",
      "300\tValidation loss: 0.433007\tBest loss: 0.432946\tAccuracy: 90.30%\n",
      "301\tValidation loss: 0.432448\tBest loss: 0.432448\tAccuracy: 90.00%\n",
      "302\tValidation loss: 0.434850\tBest loss: 0.432448\tAccuracy: 90.40%\n",
      "303\tValidation loss: 0.432691\tBest loss: 0.432448\tAccuracy: 90.00%\n",
      "304\tValidation loss: 0.431712\tBest loss: 0.431712\tAccuracy: 90.30%\n",
      "305\tValidation loss: 0.430543\tBest loss: 0.430543\tAccuracy: 89.90%\n",
      "306\tValidation loss: 0.429860\tBest loss: 0.429860\tAccuracy: 90.50%\n",
      "307\tValidation loss: 0.430172\tBest loss: 0.429860\tAccuracy: 90.00%\n",
      "308\tValidation loss: 0.430135\tBest loss: 0.429860\tAccuracy: 89.80%\n",
      "309\tValidation loss: 0.429476\tBest loss: 0.429476\tAccuracy: 90.30%\n",
      "310\tValidation loss: 0.428536\tBest loss: 0.428536\tAccuracy: 90.50%\n",
      "311\tValidation loss: 0.430782\tBest loss: 0.428536\tAccuracy: 90.40%\n",
      "312\tValidation loss: 0.428629\tBest loss: 0.428536\tAccuracy: 90.30%\n",
      "313\tValidation loss: 0.430053\tBest loss: 0.428536\tAccuracy: 90.00%\n",
      "314\tValidation loss: 0.427947\tBest loss: 0.427947\tAccuracy: 90.00%\n",
      "315\tValidation loss: 0.428639\tBest loss: 0.427947\tAccuracy: 90.30%\n",
      "316\tValidation loss: 0.428997\tBest loss: 0.427947\tAccuracy: 90.30%\n",
      "317\tValidation loss: 0.429774\tBest loss: 0.427947\tAccuracy: 90.60%\n",
      "318\tValidation loss: 0.427646\tBest loss: 0.427646\tAccuracy: 90.50%\n",
      "319\tValidation loss: 0.427151\tBest loss: 0.427151\tAccuracy: 90.20%\n",
      "320\tValidation loss: 0.426177\tBest loss: 0.426177\tAccuracy: 90.00%\n",
      "321\tValidation loss: 0.426334\tBest loss: 0.426177\tAccuracy: 90.80%\n",
      "322\tValidation loss: 0.426773\tBest loss: 0.426177\tAccuracy: 90.30%\n",
      "323\tValidation loss: 0.427637\tBest loss: 0.426177\tAccuracy: 90.70%\n",
      "324\tValidation loss: 0.426121\tBest loss: 0.426121\tAccuracy: 90.60%\n",
      "325\tValidation loss: 0.426874\tBest loss: 0.426121\tAccuracy: 90.50%\n",
      "326\tValidation loss: 0.424982\tBest loss: 0.424982\tAccuracy: 90.20%\n",
      "327\tValidation loss: 0.424508\tBest loss: 0.424508\tAccuracy: 90.40%\n",
      "328\tValidation loss: 0.424361\tBest loss: 0.424361\tAccuracy: 90.40%\n",
      "329\tValidation loss: 0.425464\tBest loss: 0.424361\tAccuracy: 90.40%\n",
      "330\tValidation loss: 0.423822\tBest loss: 0.423822\tAccuracy: 90.70%\n",
      "331\tValidation loss: 0.424277\tBest loss: 0.423822\tAccuracy: 90.40%\n",
      "332\tValidation loss: 0.422945\tBest loss: 0.422945\tAccuracy: 90.70%\n",
      "333\tValidation loss: 0.422862\tBest loss: 0.422862\tAccuracy: 90.50%\n",
      "334\tValidation loss: 0.423096\tBest loss: 0.422862\tAccuracy: 90.50%\n",
      "335\tValidation loss: 0.422103\tBest loss: 0.422103\tAccuracy: 90.40%\n",
      "336\tValidation loss: 0.421401\tBest loss: 0.421401\tAccuracy: 90.50%\n",
      "337\tValidation loss: 0.422184\tBest loss: 0.421401\tAccuracy: 91.00%\n",
      "338\tValidation loss: 0.420704\tBest loss: 0.420704\tAccuracy: 90.70%\n",
      "339\tValidation loss: 0.421291\tBest loss: 0.420704\tAccuracy: 90.60%\n",
      "340\tValidation loss: 0.422717\tBest loss: 0.420704\tAccuracy: 90.80%\n",
      "341\tValidation loss: 0.420128\tBest loss: 0.420128\tAccuracy: 90.90%\n",
      "342\tValidation loss: 0.419696\tBest loss: 0.419696\tAccuracy: 90.60%\n",
      "343\tValidation loss: 0.419603\tBest loss: 0.419603\tAccuracy: 90.90%\n",
      "344\tValidation loss: 0.420620\tBest loss: 0.419603\tAccuracy: 90.40%\n",
      "345\tValidation loss: 0.420631\tBest loss: 0.419603\tAccuracy: 90.70%\n",
      "346\tValidation loss: 0.419995\tBest loss: 0.419603\tAccuracy: 90.70%\n",
      "347\tValidation loss: 0.420978\tBest loss: 0.419603\tAccuracy: 90.60%\n",
      "348\tValidation loss: 0.420161\tBest loss: 0.419603\tAccuracy: 90.60%\n",
      "349\tValidation loss: 0.420605\tBest loss: 0.419603\tAccuracy: 90.80%\n",
      "350\tValidation loss: 0.419516\tBest loss: 0.419516\tAccuracy: 90.60%\n",
      "351\tValidation loss: 0.418429\tBest loss: 0.418429\tAccuracy: 90.80%\n",
      "352\tValidation loss: 0.418207\tBest loss: 0.418207\tAccuracy: 90.90%\n",
      "353\tValidation loss: 0.418668\tBest loss: 0.418207\tAccuracy: 90.80%\n",
      "354\tValidation loss: 0.418105\tBest loss: 0.418105\tAccuracy: 90.80%\n",
      "355\tValidation loss: 0.417630\tBest loss: 0.417630\tAccuracy: 90.30%\n",
      "356\tValidation loss: 0.416569\tBest loss: 0.416569\tAccuracy: 90.90%\n",
      "357\tValidation loss: 0.419225\tBest loss: 0.416569\tAccuracy: 90.60%\n",
      "358\tValidation loss: 0.416321\tBest loss: 0.416321\tAccuracy: 90.70%\n",
      "359\tValidation loss: 0.416199\tBest loss: 0.416199\tAccuracy: 90.90%\n",
      "360\tValidation loss: 0.415700\tBest loss: 0.415700\tAccuracy: 90.60%\n",
      "361\tValidation loss: 0.416672\tBest loss: 0.415700\tAccuracy: 90.80%\n",
      "362\tValidation loss: 0.417579\tBest loss: 0.415700\tAccuracy: 90.80%\n",
      "363\tValidation loss: 0.415706\tBest loss: 0.415700\tAccuracy: 90.90%\n",
      "364\tValidation loss: 0.416234\tBest loss: 0.415700\tAccuracy: 90.90%\n",
      "365\tValidation loss: 0.416810\tBest loss: 0.415700\tAccuracy: 90.90%\n",
      "366\tValidation loss: 0.415931\tBest loss: 0.415700\tAccuracy: 90.80%\n",
      "367\tValidation loss: 0.415179\tBest loss: 0.415179\tAccuracy: 90.80%\n",
      "368\tValidation loss: 0.416254\tBest loss: 0.415179\tAccuracy: 90.70%\n",
      "369\tValidation loss: 0.414346\tBest loss: 0.414346\tAccuracy: 90.80%\n",
      "370\tValidation loss: 0.413908\tBest loss: 0.413908\tAccuracy: 90.50%\n",
      "371\tValidation loss: 0.414386\tBest loss: 0.413908\tAccuracy: 90.90%\n",
      "372\tValidation loss: 0.414038\tBest loss: 0.413908\tAccuracy: 91.00%\n",
      "373\tValidation loss: 0.413347\tBest loss: 0.413347\tAccuracy: 90.70%\n",
      "374\tValidation loss: 0.415571\tBest loss: 0.413347\tAccuracy: 90.70%\n",
      "375\tValidation loss: 0.412963\tBest loss: 0.412963\tAccuracy: 90.80%\n",
      "376\tValidation loss: 0.412970\tBest loss: 0.412963\tAccuracy: 90.80%\n",
      "377\tValidation loss: 0.412427\tBest loss: 0.412427\tAccuracy: 90.80%\n",
      "378\tValidation loss: 0.412619\tBest loss: 0.412427\tAccuracy: 90.70%\n",
      "379\tValidation loss: 0.412709\tBest loss: 0.412427\tAccuracy: 90.90%\n",
      "380\tValidation loss: 0.413397\tBest loss: 0.412427\tAccuracy: 90.90%\n",
      "381\tValidation loss: 0.413054\tBest loss: 0.412427\tAccuracy: 90.90%\n",
      "382\tValidation loss: 0.411981\tBest loss: 0.411981\tAccuracy: 91.00%\n",
      "383\tValidation loss: 0.411888\tBest loss: 0.411888\tAccuracy: 90.70%\n",
      "384\tValidation loss: 0.411782\tBest loss: 0.411782\tAccuracy: 90.80%\n",
      "385\tValidation loss: 0.411786\tBest loss: 0.411782\tAccuracy: 90.80%\n",
      "386\tValidation loss: 0.411602\tBest loss: 0.411602\tAccuracy: 90.70%\n",
      "387\tValidation loss: 0.411112\tBest loss: 0.411112\tAccuracy: 91.10%\n",
      "388\tValidation loss: 0.409431\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "389\tValidation loss: 0.410366\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "390\tValidation loss: 0.411850\tBest loss: 0.409431\tAccuracy: 90.60%\n",
      "391\tValidation loss: 0.410790\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "392\tValidation loss: 0.410909\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "393\tValidation loss: 0.410019\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "394\tValidation loss: 0.409499\tBest loss: 0.409431\tAccuracy: 90.70%\n",
      "395\tValidation loss: 0.408309\tBest loss: 0.408309\tAccuracy: 90.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\tValidation loss: 0.409434\tBest loss: 0.408309\tAccuracy: 90.70%\n",
      "397\tValidation loss: 0.410029\tBest loss: 0.408309\tAccuracy: 90.60%\n",
      "398\tValidation loss: 0.408004\tBest loss: 0.408004\tAccuracy: 90.90%\n",
      "399\tValidation loss: 0.409606\tBest loss: 0.408004\tAccuracy: 90.80%\n",
      "400\tValidation loss: 0.408878\tBest loss: 0.408004\tAccuracy: 90.70%\n",
      "401\tValidation loss: 0.407821\tBest loss: 0.407821\tAccuracy: 90.90%\n",
      "402\tValidation loss: 0.406737\tBest loss: 0.406737\tAccuracy: 90.50%\n",
      "403\tValidation loss: 0.407524\tBest loss: 0.406737\tAccuracy: 90.60%\n",
      "404\tValidation loss: 0.408027\tBest loss: 0.406737\tAccuracy: 90.90%\n",
      "405\tValidation loss: 0.407141\tBest loss: 0.406737\tAccuracy: 90.90%\n",
      "406\tValidation loss: 0.407547\tBest loss: 0.406737\tAccuracy: 90.70%\n",
      "407\tValidation loss: 0.407930\tBest loss: 0.406737\tAccuracy: 90.70%\n",
      "408\tValidation loss: 0.406951\tBest loss: 0.406737\tAccuracy: 90.70%\n",
      "409\tValidation loss: 0.405763\tBest loss: 0.405763\tAccuracy: 90.60%\n",
      "410\tValidation loss: 0.406350\tBest loss: 0.405763\tAccuracy: 90.80%\n",
      "411\tValidation loss: 0.405772\tBest loss: 0.405763\tAccuracy: 90.80%\n",
      "412\tValidation loss: 0.405820\tBest loss: 0.405763\tAccuracy: 90.80%\n",
      "413\tValidation loss: 0.404671\tBest loss: 0.404671\tAccuracy: 91.10%\n",
      "414\tValidation loss: 0.404569\tBest loss: 0.404569\tAccuracy: 90.70%\n",
      "415\tValidation loss: 0.403688\tBest loss: 0.403688\tAccuracy: 90.90%\n",
      "416\tValidation loss: 0.403547\tBest loss: 0.403547\tAccuracy: 90.60%\n",
      "417\tValidation loss: 0.404767\tBest loss: 0.403547\tAccuracy: 91.10%\n",
      "418\tValidation loss: 0.405449\tBest loss: 0.403547\tAccuracy: 91.00%\n",
      "419\tValidation loss: 0.404570\tBest loss: 0.403547\tAccuracy: 91.10%\n",
      "420\tValidation loss: 0.403710\tBest loss: 0.403547\tAccuracy: 90.80%\n",
      "421\tValidation loss: 0.403169\tBest loss: 0.403169\tAccuracy: 90.70%\n",
      "422\tValidation loss: 0.403666\tBest loss: 0.403169\tAccuracy: 90.70%\n",
      "423\tValidation loss: 0.404289\tBest loss: 0.403169\tAccuracy: 90.90%\n",
      "424\tValidation loss: 0.402436\tBest loss: 0.402436\tAccuracy: 90.70%\n",
      "425\tValidation loss: 0.401998\tBest loss: 0.401998\tAccuracy: 90.80%\n",
      "426\tValidation loss: 0.403709\tBest loss: 0.401998\tAccuracy: 90.80%\n",
      "427\tValidation loss: 0.403739\tBest loss: 0.401998\tAccuracy: 91.00%\n",
      "428\tValidation loss: 0.401929\tBest loss: 0.401929\tAccuracy: 91.10%\n",
      "429\tValidation loss: 0.402940\tBest loss: 0.401929\tAccuracy: 91.00%\n",
      "430\tValidation loss: 0.402499\tBest loss: 0.401929\tAccuracy: 90.80%\n",
      "431\tValidation loss: 0.403023\tBest loss: 0.401929\tAccuracy: 90.80%\n",
      "432\tValidation loss: 0.402213\tBest loss: 0.401929\tAccuracy: 90.80%\n",
      "433\tValidation loss: 0.401729\tBest loss: 0.401729\tAccuracy: 91.10%\n",
      "434\tValidation loss: 0.403217\tBest loss: 0.401729\tAccuracy: 90.90%\n",
      "435\tValidation loss: 0.401696\tBest loss: 0.401696\tAccuracy: 91.00%\n",
      "436\tValidation loss: 0.402264\tBest loss: 0.401696\tAccuracy: 90.80%\n",
      "437\tValidation loss: 0.401982\tBest loss: 0.401696\tAccuracy: 90.80%\n",
      "438\tValidation loss: 0.401677\tBest loss: 0.401677\tAccuracy: 91.00%\n",
      "439\tValidation loss: 0.401591\tBest loss: 0.401591\tAccuracy: 91.10%\n",
      "440\tValidation loss: 0.401113\tBest loss: 0.401113\tAccuracy: 91.00%\n",
      "441\tValidation loss: 0.400677\tBest loss: 0.400677\tAccuracy: 91.00%\n",
      "442\tValidation loss: 0.401514\tBest loss: 0.400677\tAccuracy: 91.00%\n",
      "443\tValidation loss: 0.400016\tBest loss: 0.400016\tAccuracy: 91.00%\n",
      "444\tValidation loss: 0.400703\tBest loss: 0.400016\tAccuracy: 91.00%\n",
      "445\tValidation loss: 0.399991\tBest loss: 0.399991\tAccuracy: 90.90%\n",
      "446\tValidation loss: 0.399083\tBest loss: 0.399083\tAccuracy: 91.10%\n",
      "447\tValidation loss: 0.400012\tBest loss: 0.399083\tAccuracy: 91.10%\n",
      "448\tValidation loss: 0.399404\tBest loss: 0.399083\tAccuracy: 91.20%\n",
      "449\tValidation loss: 0.398501\tBest loss: 0.398501\tAccuracy: 91.10%\n",
      "450\tValidation loss: 0.398716\tBest loss: 0.398501\tAccuracy: 91.30%\n",
      "451\tValidation loss: 0.399148\tBest loss: 0.398501\tAccuracy: 91.20%\n",
      "452\tValidation loss: 0.400240\tBest loss: 0.398501\tAccuracy: 91.10%\n",
      "453\tValidation loss: 0.398201\tBest loss: 0.398201\tAccuracy: 91.10%\n",
      "454\tValidation loss: 0.399386\tBest loss: 0.398201\tAccuracy: 90.90%\n",
      "455\tValidation loss: 0.398780\tBest loss: 0.398201\tAccuracy: 91.10%\n",
      "456\tValidation loss: 0.398154\tBest loss: 0.398154\tAccuracy: 91.10%\n",
      "457\tValidation loss: 0.397810\tBest loss: 0.397810\tAccuracy: 91.10%\n",
      "458\tValidation loss: 0.397507\tBest loss: 0.397507\tAccuracy: 91.20%\n",
      "459\tValidation loss: 0.398020\tBest loss: 0.397507\tAccuracy: 91.20%\n",
      "460\tValidation loss: 0.397672\tBest loss: 0.397507\tAccuracy: 91.20%\n",
      "461\tValidation loss: 0.398175\tBest loss: 0.397507\tAccuracy: 91.10%\n",
      "462\tValidation loss: 0.398022\tBest loss: 0.397507\tAccuracy: 91.00%\n",
      "463\tValidation loss: 0.397997\tBest loss: 0.397507\tAccuracy: 91.20%\n",
      "464\tValidation loss: 0.396684\tBest loss: 0.396684\tAccuracy: 91.10%\n",
      "465\tValidation loss: 0.397212\tBest loss: 0.396684\tAccuracy: 91.10%\n",
      "466\tValidation loss: 0.396678\tBest loss: 0.396678\tAccuracy: 91.30%\n",
      "467\tValidation loss: 0.395158\tBest loss: 0.395158\tAccuracy: 91.10%\n",
      "468\tValidation loss: 0.397703\tBest loss: 0.395158\tAccuracy: 91.00%\n",
      "469\tValidation loss: 0.395505\tBest loss: 0.395158\tAccuracy: 91.20%\n",
      "470\tValidation loss: 0.396347\tBest loss: 0.395158\tAccuracy: 91.20%\n",
      "471\tValidation loss: 0.397742\tBest loss: 0.395158\tAccuracy: 91.10%\n",
      "472\tValidation loss: 0.396320\tBest loss: 0.395158\tAccuracy: 91.30%\n",
      "473\tValidation loss: 0.396467\tBest loss: 0.395158\tAccuracy: 91.20%\n",
      "474\tValidation loss: 0.397544\tBest loss: 0.395158\tAccuracy: 91.30%\n",
      "475\tValidation loss: 0.395242\tBest loss: 0.395158\tAccuracy: 91.10%\n",
      "476\tValidation loss: 0.395575\tBest loss: 0.395158\tAccuracy: 91.20%\n",
      "477\tValidation loss: 0.395835\tBest loss: 0.395158\tAccuracy: 91.10%\n",
      "478\tValidation loss: 0.395221\tBest loss: 0.395158\tAccuracy: 90.90%\n",
      "479\tValidation loss: 0.394958\tBest loss: 0.394958\tAccuracy: 91.10%\n",
      "480\tValidation loss: 0.395905\tBest loss: 0.394958\tAccuracy: 91.30%\n",
      "481\tValidation loss: 0.393868\tBest loss: 0.393868\tAccuracy: 91.50%\n",
      "482\tValidation loss: 0.393791\tBest loss: 0.393791\tAccuracy: 91.40%\n",
      "483\tValidation loss: 0.392978\tBest loss: 0.392978\tAccuracy: 91.30%\n",
      "484\tValidation loss: 0.393428\tBest loss: 0.392978\tAccuracy: 91.40%\n",
      "485\tValidation loss: 0.394359\tBest loss: 0.392978\tAccuracy: 91.10%\n",
      "486\tValidation loss: 0.394833\tBest loss: 0.392978\tAccuracy: 91.30%\n",
      "487\tValidation loss: 0.393150\tBest loss: 0.392978\tAccuracy: 91.30%\n",
      "488\tValidation loss: 0.394382\tBest loss: 0.392978\tAccuracy: 91.10%\n",
      "489\tValidation loss: 0.393836\tBest loss: 0.392978\tAccuracy: 91.30%\n",
      "490\tValidation loss: 0.393094\tBest loss: 0.392978\tAccuracy: 91.10%\n",
      "491\tValidation loss: 0.392599\tBest loss: 0.392599\tAccuracy: 91.40%\n",
      "492\tValidation loss: 0.392650\tBest loss: 0.392599\tAccuracy: 91.00%\n",
      "493\tValidation loss: 0.394129\tBest loss: 0.392599\tAccuracy: 91.30%\n",
      "494\tValidation loss: 0.392483\tBest loss: 0.392483\tAccuracy: 91.30%\n",
      "495\tValidation loss: 0.392987\tBest loss: 0.392483\tAccuracy: 91.40%\n",
      "496\tValidation loss: 0.391985\tBest loss: 0.391985\tAccuracy: 91.30%\n",
      "497\tValidation loss: 0.391883\tBest loss: 0.391883\tAccuracy: 91.30%\n",
      "498\tValidation loss: 0.392251\tBest loss: 0.391883\tAccuracy: 91.20%\n",
      "499\tValidation loss: 0.392198\tBest loss: 0.391883\tAccuracy: 91.30%\n",
      "500\tValidation loss: 0.392162\tBest loss: 0.391883\tAccuracy: 91.40%\n",
      "501\tValidation loss: 0.392117\tBest loss: 0.391883\tAccuracy: 91.20%\n",
      "502\tValidation loss: 0.391544\tBest loss: 0.391544\tAccuracy: 91.20%\n",
      "503\tValidation loss: 0.391074\tBest loss: 0.391074\tAccuracy: 91.30%\n",
      "504\tValidation loss: 0.391096\tBest loss: 0.391074\tAccuracy: 91.10%\n",
      "505\tValidation loss: 0.391194\tBest loss: 0.391074\tAccuracy: 91.40%\n",
      "506\tValidation loss: 0.391288\tBest loss: 0.391074\tAccuracy: 91.20%\n",
      "507\tValidation loss: 0.391188\tBest loss: 0.391074\tAccuracy: 91.10%\n",
      "508\tValidation loss: 0.390430\tBest loss: 0.390430\tAccuracy: 91.30%\n",
      "509\tValidation loss: 0.391764\tBest loss: 0.390430\tAccuracy: 91.40%\n",
      "510\tValidation loss: 0.390630\tBest loss: 0.390430\tAccuracy: 91.40%\n",
      "511\tValidation loss: 0.390300\tBest loss: 0.390300\tAccuracy: 91.20%\n",
      "512\tValidation loss: 0.390123\tBest loss: 0.390123\tAccuracy: 91.30%\n",
      "513\tValidation loss: 0.390590\tBest loss: 0.390123\tAccuracy: 91.40%\n",
      "514\tValidation loss: 0.389453\tBest loss: 0.389453\tAccuracy: 91.20%\n",
      "515\tValidation loss: 0.390127\tBest loss: 0.389453\tAccuracy: 91.40%\n",
      "516\tValidation loss: 0.389238\tBest loss: 0.389238\tAccuracy: 91.30%\n",
      "517\tValidation loss: 0.388315\tBest loss: 0.388315\tAccuracy: 91.20%\n",
      "518\tValidation loss: 0.390515\tBest loss: 0.388315\tAccuracy: 91.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\tValidation loss: 0.390013\tBest loss: 0.388315\tAccuracy: 91.30%\n",
      "520\tValidation loss: 0.389841\tBest loss: 0.388315\tAccuracy: 91.50%\n",
      "521\tValidation loss: 0.388963\tBest loss: 0.388315\tAccuracy: 91.40%\n",
      "522\tValidation loss: 0.389881\tBest loss: 0.388315\tAccuracy: 91.30%\n",
      "523\tValidation loss: 0.389303\tBest loss: 0.388315\tAccuracy: 91.30%\n",
      "524\tValidation loss: 0.388197\tBest loss: 0.388197\tAccuracy: 91.40%\n",
      "525\tValidation loss: 0.389182\tBest loss: 0.388197\tAccuracy: 91.40%\n",
      "526\tValidation loss: 0.388624\tBest loss: 0.388197\tAccuracy: 91.20%\n",
      "527\tValidation loss: 0.388114\tBest loss: 0.388114\tAccuracy: 91.40%\n",
      "528\tValidation loss: 0.387946\tBest loss: 0.387946\tAccuracy: 91.40%\n",
      "529\tValidation loss: 0.387646\tBest loss: 0.387646\tAccuracy: 91.40%\n",
      "530\tValidation loss: 0.387525\tBest loss: 0.387525\tAccuracy: 91.50%\n",
      "531\tValidation loss: 0.388023\tBest loss: 0.387525\tAccuracy: 91.50%\n",
      "532\tValidation loss: 0.388943\tBest loss: 0.387525\tAccuracy: 91.50%\n",
      "533\tValidation loss: 0.387844\tBest loss: 0.387525\tAccuracy: 91.50%\n",
      "534\tValidation loss: 0.387781\tBest loss: 0.387525\tAccuracy: 91.40%\n",
      "535\tValidation loss: 0.387586\tBest loss: 0.387525\tAccuracy: 91.30%\n",
      "536\tValidation loss: 0.387330\tBest loss: 0.387330\tAccuracy: 91.40%\n",
      "537\tValidation loss: 0.387565\tBest loss: 0.387330\tAccuracy: 91.50%\n",
      "538\tValidation loss: 0.388252\tBest loss: 0.387330\tAccuracy: 91.30%\n",
      "539\tValidation loss: 0.386827\tBest loss: 0.386827\tAccuracy: 91.50%\n",
      "540\tValidation loss: 0.385799\tBest loss: 0.385799\tAccuracy: 91.30%\n",
      "541\tValidation loss: 0.386984\tBest loss: 0.385799\tAccuracy: 91.30%\n",
      "542\tValidation loss: 0.387078\tBest loss: 0.385799\tAccuracy: 91.40%\n",
      "543\tValidation loss: 0.387406\tBest loss: 0.385799\tAccuracy: 91.40%\n",
      "544\tValidation loss: 0.386194\tBest loss: 0.385799\tAccuracy: 91.30%\n",
      "545\tValidation loss: 0.386300\tBest loss: 0.385799\tAccuracy: 91.30%\n",
      "546\tValidation loss: 0.386734\tBest loss: 0.385799\tAccuracy: 91.50%\n",
      "547\tValidation loss: 0.384945\tBest loss: 0.384945\tAccuracy: 91.40%\n",
      "548\tValidation loss: 0.386458\tBest loss: 0.384945\tAccuracy: 91.40%\n",
      "549\tValidation loss: 0.386703\tBest loss: 0.384945\tAccuracy: 91.50%\n",
      "550\tValidation loss: 0.385330\tBest loss: 0.384945\tAccuracy: 91.40%\n",
      "551\tValidation loss: 0.387408\tBest loss: 0.384945\tAccuracy: 91.60%\n",
      "552\tValidation loss: 0.384754\tBest loss: 0.384754\tAccuracy: 91.60%\n",
      "553\tValidation loss: 0.384423\tBest loss: 0.384423\tAccuracy: 91.60%\n",
      "554\tValidation loss: 0.385946\tBest loss: 0.384423\tAccuracy: 91.60%\n",
      "555\tValidation loss: 0.383858\tBest loss: 0.383858\tAccuracy: 91.70%\n",
      "556\tValidation loss: 0.385064\tBest loss: 0.383858\tAccuracy: 91.50%\n",
      "557\tValidation loss: 0.385016\tBest loss: 0.383858\tAccuracy: 91.50%\n",
      "558\tValidation loss: 0.385170\tBest loss: 0.383858\tAccuracy: 91.50%\n",
      "559\tValidation loss: 0.385354\tBest loss: 0.383858\tAccuracy: 91.50%\n",
      "560\tValidation loss: 0.385339\tBest loss: 0.383858\tAccuracy: 91.50%\n",
      "561\tValidation loss: 0.384560\tBest loss: 0.383858\tAccuracy: 91.40%\n",
      "562\tValidation loss: 0.384860\tBest loss: 0.383858\tAccuracy: 91.60%\n",
      "563\tValidation loss: 0.384510\tBest loss: 0.383858\tAccuracy: 91.60%\n",
      "564\tValidation loss: 0.383858\tBest loss: 0.383858\tAccuracy: 91.70%\n",
      "565\tValidation loss: 0.383192\tBest loss: 0.383192\tAccuracy: 91.50%\n",
      "566\tValidation loss: 0.384065\tBest loss: 0.383192\tAccuracy: 91.50%\n",
      "567\tValidation loss: 0.383146\tBest loss: 0.383146\tAccuracy: 91.70%\n",
      "568\tValidation loss: 0.382248\tBest loss: 0.382248\tAccuracy: 91.60%\n",
      "569\tValidation loss: 0.384096\tBest loss: 0.382248\tAccuracy: 91.60%\n",
      "570\tValidation loss: 0.383245\tBest loss: 0.382248\tAccuracy: 91.70%\n",
      "571\tValidation loss: 0.383471\tBest loss: 0.382248\tAccuracy: 91.50%\n",
      "572\tValidation loss: 0.382467\tBest loss: 0.382248\tAccuracy: 91.80%\n",
      "573\tValidation loss: 0.381785\tBest loss: 0.381785\tAccuracy: 91.70%\n",
      "574\tValidation loss: 0.382782\tBest loss: 0.381785\tAccuracy: 91.50%\n",
      "575\tValidation loss: 0.382440\tBest loss: 0.381785\tAccuracy: 91.70%\n",
      "576\tValidation loss: 0.382547\tBest loss: 0.381785\tAccuracy: 91.70%\n",
      "577\tValidation loss: 0.383031\tBest loss: 0.381785\tAccuracy: 91.60%\n",
      "578\tValidation loss: 0.382764\tBest loss: 0.381785\tAccuracy: 91.60%\n",
      "579\tValidation loss: 0.382177\tBest loss: 0.381785\tAccuracy: 91.60%\n",
      "580\tValidation loss: 0.381270\tBest loss: 0.381270\tAccuracy: 91.90%\n",
      "581\tValidation loss: 0.383173\tBest loss: 0.381270\tAccuracy: 91.60%\n",
      "582\tValidation loss: 0.382698\tBest loss: 0.381270\tAccuracy: 91.70%\n",
      "583\tValidation loss: 0.382020\tBest loss: 0.381270\tAccuracy: 91.70%\n",
      "584\tValidation loss: 0.382704\tBest loss: 0.381270\tAccuracy: 91.60%\n",
      "585\tValidation loss: 0.382871\tBest loss: 0.381270\tAccuracy: 91.60%\n",
      "586\tValidation loss: 0.381429\tBest loss: 0.381270\tAccuracy: 91.70%\n",
      "587\tValidation loss: 0.381583\tBest loss: 0.381270\tAccuracy: 91.60%\n",
      "588\tValidation loss: 0.382109\tBest loss: 0.381270\tAccuracy: 91.70%\n",
      "589\tValidation loss: 0.381378\tBest loss: 0.381270\tAccuracy: 91.70%\n",
      "590\tValidation loss: 0.380573\tBest loss: 0.380573\tAccuracy: 91.80%\n",
      "591\tValidation loss: 0.381219\tBest loss: 0.380573\tAccuracy: 91.70%\n",
      "592\tValidation loss: 0.380647\tBest loss: 0.380573\tAccuracy: 91.70%\n",
      "593\tValidation loss: 0.381478\tBest loss: 0.380573\tAccuracy: 91.70%\n",
      "594\tValidation loss: 0.380960\tBest loss: 0.380573\tAccuracy: 91.80%\n",
      "595\tValidation loss: 0.380794\tBest loss: 0.380573\tAccuracy: 91.80%\n",
      "596\tValidation loss: 0.380092\tBest loss: 0.380092\tAccuracy: 91.90%\n",
      "597\tValidation loss: 0.379678\tBest loss: 0.379678\tAccuracy: 91.90%\n",
      "598\tValidation loss: 0.380222\tBest loss: 0.379678\tAccuracy: 91.80%\n",
      "599\tValidation loss: 0.379636\tBest loss: 0.379636\tAccuracy: 91.80%\n",
      "600\tValidation loss: 0.381694\tBest loss: 0.379636\tAccuracy: 91.80%\n",
      "601\tValidation loss: 0.380918\tBest loss: 0.379636\tAccuracy: 91.70%\n",
      "602\tValidation loss: 0.381073\tBest loss: 0.379636\tAccuracy: 91.80%\n",
      "603\tValidation loss: 0.379684\tBest loss: 0.379636\tAccuracy: 91.80%\n",
      "604\tValidation loss: 0.380566\tBest loss: 0.379636\tAccuracy: 91.70%\n",
      "605\tValidation loss: 0.380801\tBest loss: 0.379636\tAccuracy: 91.80%\n",
      "606\tValidation loss: 0.379915\tBest loss: 0.379636\tAccuracy: 91.90%\n",
      "607\tValidation loss: 0.379350\tBest loss: 0.379350\tAccuracy: 91.90%\n",
      "608\tValidation loss: 0.380300\tBest loss: 0.379350\tAccuracy: 91.80%\n",
      "609\tValidation loss: 0.379298\tBest loss: 0.379298\tAccuracy: 91.80%\n",
      "610\tValidation loss: 0.378459\tBest loss: 0.378459\tAccuracy: 91.90%\n",
      "611\tValidation loss: 0.379446\tBest loss: 0.378459\tAccuracy: 91.80%\n",
      "612\tValidation loss: 0.378999\tBest loss: 0.378459\tAccuracy: 91.90%\n",
      "613\tValidation loss: 0.378709\tBest loss: 0.378459\tAccuracy: 91.80%\n",
      "614\tValidation loss: 0.380229\tBest loss: 0.378459\tAccuracy: 91.70%\n",
      "615\tValidation loss: 0.379174\tBest loss: 0.378459\tAccuracy: 91.90%\n",
      "616\tValidation loss: 0.379199\tBest loss: 0.378459\tAccuracy: 91.80%\n",
      "617\tValidation loss: 0.379500\tBest loss: 0.378459\tAccuracy: 91.80%\n",
      "618\tValidation loss: 0.378217\tBest loss: 0.378217\tAccuracy: 91.90%\n",
      "619\tValidation loss: 0.377945\tBest loss: 0.377945\tAccuracy: 91.80%\n",
      "620\tValidation loss: 0.378310\tBest loss: 0.377945\tAccuracy: 91.90%\n",
      "621\tValidation loss: 0.377874\tBest loss: 0.377874\tAccuracy: 91.70%\n",
      "622\tValidation loss: 0.378722\tBest loss: 0.377874\tAccuracy: 91.90%\n",
      "623\tValidation loss: 0.377527\tBest loss: 0.377527\tAccuracy: 91.90%\n",
      "624\tValidation loss: 0.378061\tBest loss: 0.377527\tAccuracy: 92.00%\n",
      "625\tValidation loss: 0.377883\tBest loss: 0.377527\tAccuracy: 91.90%\n",
      "626\tValidation loss: 0.377597\tBest loss: 0.377527\tAccuracy: 91.90%\n",
      "627\tValidation loss: 0.378236\tBest loss: 0.377527\tAccuracy: 92.00%\n",
      "628\tValidation loss: 0.377052\tBest loss: 0.377052\tAccuracy: 92.00%\n",
      "629\tValidation loss: 0.377236\tBest loss: 0.377052\tAccuracy: 91.90%\n",
      "630\tValidation loss: 0.377428\tBest loss: 0.377052\tAccuracy: 91.80%\n",
      "631\tValidation loss: 0.376754\tBest loss: 0.376754\tAccuracy: 91.90%\n",
      "632\tValidation loss: 0.378326\tBest loss: 0.376754\tAccuracy: 91.90%\n",
      "633\tValidation loss: 0.377703\tBest loss: 0.376754\tAccuracy: 92.10%\n",
      "634\tValidation loss: 0.377849\tBest loss: 0.376754\tAccuracy: 92.00%\n",
      "635\tValidation loss: 0.376342\tBest loss: 0.376342\tAccuracy: 91.90%\n",
      "636\tValidation loss: 0.376682\tBest loss: 0.376342\tAccuracy: 92.00%\n",
      "637\tValidation loss: 0.376741\tBest loss: 0.376342\tAccuracy: 91.90%\n",
      "638\tValidation loss: 0.375879\tBest loss: 0.375879\tAccuracy: 92.00%\n",
      "639\tValidation loss: 0.375989\tBest loss: 0.375879\tAccuracy: 91.90%\n",
      "640\tValidation loss: 0.376687\tBest loss: 0.375879\tAccuracy: 92.00%\n",
      "641\tValidation loss: 0.376859\tBest loss: 0.375879\tAccuracy: 91.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\tValidation loss: 0.377629\tBest loss: 0.375879\tAccuracy: 91.80%\n",
      "643\tValidation loss: 0.375754\tBest loss: 0.375754\tAccuracy: 91.70%\n",
      "644\tValidation loss: 0.375589\tBest loss: 0.375589\tAccuracy: 92.00%\n",
      "645\tValidation loss: 0.376250\tBest loss: 0.375589\tAccuracy: 91.90%\n",
      "646\tValidation loss: 0.376321\tBest loss: 0.375589\tAccuracy: 91.90%\n",
      "647\tValidation loss: 0.376395\tBest loss: 0.375589\tAccuracy: 91.80%\n",
      "648\tValidation loss: 0.375357\tBest loss: 0.375357\tAccuracy: 91.80%\n",
      "649\tValidation loss: 0.375361\tBest loss: 0.375357\tAccuracy: 91.90%\n",
      "650\tValidation loss: 0.375749\tBest loss: 0.375357\tAccuracy: 92.10%\n",
      "651\tValidation loss: 0.374513\tBest loss: 0.374513\tAccuracy: 91.90%\n",
      "652\tValidation loss: 0.375266\tBest loss: 0.374513\tAccuracy: 92.10%\n",
      "653\tValidation loss: 0.376038\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "654\tValidation loss: 0.375902\tBest loss: 0.374513\tAccuracy: 91.90%\n",
      "655\tValidation loss: 0.374521\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "656\tValidation loss: 0.375183\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "657\tValidation loss: 0.374901\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "658\tValidation loss: 0.375526\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "659\tValidation loss: 0.374835\tBest loss: 0.374513\tAccuracy: 92.10%\n",
      "660\tValidation loss: 0.376526\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "661\tValidation loss: 0.375058\tBest loss: 0.374513\tAccuracy: 92.00%\n",
      "662\tValidation loss: 0.374532\tBest loss: 0.374513\tAccuracy: 92.10%\n",
      "663\tValidation loss: 0.373591\tBest loss: 0.373591\tAccuracy: 91.80%\n",
      "664\tValidation loss: 0.374456\tBest loss: 0.373591\tAccuracy: 92.00%\n",
      "665\tValidation loss: 0.374882\tBest loss: 0.373591\tAccuracy: 92.00%\n",
      "666\tValidation loss: 0.374696\tBest loss: 0.373591\tAccuracy: 92.10%\n",
      "667\tValidation loss: 0.374694\tBest loss: 0.373591\tAccuracy: 92.10%\n",
      "668\tValidation loss: 0.374214\tBest loss: 0.373591\tAccuracy: 92.20%\n",
      "669\tValidation loss: 0.374721\tBest loss: 0.373591\tAccuracy: 92.10%\n",
      "670\tValidation loss: 0.375106\tBest loss: 0.373591\tAccuracy: 91.90%\n",
      "671\tValidation loss: 0.374070\tBest loss: 0.373591\tAccuracy: 92.20%\n",
      "672\tValidation loss: 0.372942\tBest loss: 0.372942\tAccuracy: 92.10%\n",
      "673\tValidation loss: 0.373584\tBest loss: 0.372942\tAccuracy: 91.70%\n",
      "674\tValidation loss: 0.374284\tBest loss: 0.372942\tAccuracy: 91.90%\n",
      "675\tValidation loss: 0.374165\tBest loss: 0.372942\tAccuracy: 92.10%\n",
      "676\tValidation loss: 0.373948\tBest loss: 0.372942\tAccuracy: 91.90%\n",
      "677\tValidation loss: 0.374392\tBest loss: 0.372942\tAccuracy: 92.00%\n",
      "678\tValidation loss: 0.373761\tBest loss: 0.372942\tAccuracy: 92.00%\n",
      "679\tValidation loss: 0.373852\tBest loss: 0.372942\tAccuracy: 92.00%\n",
      "680\tValidation loss: 0.373643\tBest loss: 0.372942\tAccuracy: 91.90%\n",
      "681\tValidation loss: 0.373206\tBest loss: 0.372942\tAccuracy: 92.10%\n",
      "682\tValidation loss: 0.371860\tBest loss: 0.371860\tAccuracy: 92.20%\n",
      "683\tValidation loss: 0.373080\tBest loss: 0.371860\tAccuracy: 91.90%\n",
      "684\tValidation loss: 0.372134\tBest loss: 0.371860\tAccuracy: 92.00%\n",
      "685\tValidation loss: 0.373300\tBest loss: 0.371860\tAccuracy: 92.00%\n",
      "686\tValidation loss: 0.372877\tBest loss: 0.371860\tAccuracy: 92.10%\n",
      "687\tValidation loss: 0.373159\tBest loss: 0.371860\tAccuracy: 92.00%\n",
      "688\tValidation loss: 0.373423\tBest loss: 0.371860\tAccuracy: 92.00%\n",
      "689\tValidation loss: 0.371840\tBest loss: 0.371840\tAccuracy: 92.10%\n",
      "690\tValidation loss: 0.373720\tBest loss: 0.371840\tAccuracy: 92.00%\n",
      "691\tValidation loss: 0.372166\tBest loss: 0.371840\tAccuracy: 92.30%\n",
      "692\tValidation loss: 0.372877\tBest loss: 0.371840\tAccuracy: 92.20%\n",
      "693\tValidation loss: 0.373087\tBest loss: 0.371840\tAccuracy: 92.00%\n",
      "694\tValidation loss: 0.372940\tBest loss: 0.371840\tAccuracy: 92.00%\n",
      "695\tValidation loss: 0.371689\tBest loss: 0.371689\tAccuracy: 92.30%\n",
      "696\tValidation loss: 0.372086\tBest loss: 0.371689\tAccuracy: 92.00%\n",
      "697\tValidation loss: 0.371650\tBest loss: 0.371650\tAccuracy: 92.20%\n",
      "698\tValidation loss: 0.370927\tBest loss: 0.370927\tAccuracy: 92.20%\n",
      "699\tValidation loss: 0.371653\tBest loss: 0.370927\tAccuracy: 92.20%\n",
      "700\tValidation loss: 0.371321\tBest loss: 0.370927\tAccuracy: 92.10%\n",
      "701\tValidation loss: 0.372142\tBest loss: 0.370927\tAccuracy: 92.10%\n",
      "702\tValidation loss: 0.371417\tBest loss: 0.370927\tAccuracy: 92.10%\n",
      "703\tValidation loss: 0.370335\tBest loss: 0.370335\tAccuracy: 92.00%\n",
      "704\tValidation loss: 0.371057\tBest loss: 0.370335\tAccuracy: 92.00%\n",
      "705\tValidation loss: 0.372025\tBest loss: 0.370335\tAccuracy: 92.10%\n",
      "706\tValidation loss: 0.371477\tBest loss: 0.370335\tAccuracy: 92.20%\n",
      "707\tValidation loss: 0.371811\tBest loss: 0.370335\tAccuracy: 92.20%\n",
      "708\tValidation loss: 0.371798\tBest loss: 0.370335\tAccuracy: 92.10%\n",
      "709\tValidation loss: 0.371880\tBest loss: 0.370335\tAccuracy: 92.10%\n",
      "710\tValidation loss: 0.371038\tBest loss: 0.370335\tAccuracy: 92.20%\n",
      "711\tValidation loss: 0.372589\tBest loss: 0.370335\tAccuracy: 92.00%\n",
      "712\tValidation loss: 0.371528\tBest loss: 0.370335\tAccuracy: 92.30%\n",
      "713\tValidation loss: 0.369854\tBest loss: 0.369854\tAccuracy: 92.10%\n",
      "714\tValidation loss: 0.369361\tBest loss: 0.369361\tAccuracy: 92.10%\n",
      "715\tValidation loss: 0.370713\tBest loss: 0.369361\tAccuracy: 92.10%\n",
      "716\tValidation loss: 0.370154\tBest loss: 0.369361\tAccuracy: 92.00%\n",
      "717\tValidation loss: 0.370338\tBest loss: 0.369361\tAccuracy: 92.20%\n",
      "718\tValidation loss: 0.370803\tBest loss: 0.369361\tAccuracy: 92.00%\n",
      "719\tValidation loss: 0.369530\tBest loss: 0.369361\tAccuracy: 92.40%\n",
      "720\tValidation loss: 0.370268\tBest loss: 0.369361\tAccuracy: 92.00%\n",
      "721\tValidation loss: 0.370674\tBest loss: 0.369361\tAccuracy: 92.10%\n",
      "722\tValidation loss: 0.370150\tBest loss: 0.369361\tAccuracy: 92.20%\n",
      "723\tValidation loss: 0.369959\tBest loss: 0.369361\tAccuracy: 92.00%\n",
      "724\tValidation loss: 0.370764\tBest loss: 0.369361\tAccuracy: 92.10%\n",
      "725\tValidation loss: 0.370326\tBest loss: 0.369361\tAccuracy: 91.90%\n",
      "726\tValidation loss: 0.369651\tBest loss: 0.369361\tAccuracy: 91.90%\n",
      "727\tValidation loss: 0.369198\tBest loss: 0.369198\tAccuracy: 91.90%\n",
      "728\tValidation loss: 0.369981\tBest loss: 0.369198\tAccuracy: 92.00%\n",
      "729\tValidation loss: 0.369285\tBest loss: 0.369198\tAccuracy: 92.00%\n",
      "730\tValidation loss: 0.370035\tBest loss: 0.369198\tAccuracy: 92.00%\n",
      "731\tValidation loss: 0.369849\tBest loss: 0.369198\tAccuracy: 92.00%\n",
      "732\tValidation loss: 0.369376\tBest loss: 0.369198\tAccuracy: 91.90%\n",
      "733\tValidation loss: 0.369802\tBest loss: 0.369198\tAccuracy: 92.10%\n",
      "734\tValidation loss: 0.369809\tBest loss: 0.369198\tAccuracy: 92.00%\n",
      "735\tValidation loss: 0.369332\tBest loss: 0.369198\tAccuracy: 91.90%\n",
      "736\tValidation loss: 0.369121\tBest loss: 0.369121\tAccuracy: 92.00%\n",
      "737\tValidation loss: 0.368987\tBest loss: 0.368987\tAccuracy: 91.90%\n",
      "738\tValidation loss: 0.370032\tBest loss: 0.368987\tAccuracy: 92.00%\n",
      "739\tValidation loss: 0.369432\tBest loss: 0.368987\tAccuracy: 92.20%\n",
      "740\tValidation loss: 0.369148\tBest loss: 0.368987\tAccuracy: 92.00%\n",
      "741\tValidation loss: 0.368731\tBest loss: 0.368731\tAccuracy: 92.10%\n",
      "742\tValidation loss: 0.369049\tBest loss: 0.368731\tAccuracy: 92.00%\n",
      "743\tValidation loss: 0.368657\tBest loss: 0.368657\tAccuracy: 92.00%\n",
      "744\tValidation loss: 0.368318\tBest loss: 0.368318\tAccuracy: 92.00%\n",
      "745\tValidation loss: 0.368587\tBest loss: 0.368318\tAccuracy: 92.00%\n",
      "746\tValidation loss: 0.368526\tBest loss: 0.368318\tAccuracy: 92.00%\n",
      "747\tValidation loss: 0.368648\tBest loss: 0.368318\tAccuracy: 92.00%\n",
      "748\tValidation loss: 0.368355\tBest loss: 0.368318\tAccuracy: 91.90%\n",
      "749\tValidation loss: 0.368008\tBest loss: 0.368008\tAccuracy: 91.80%\n",
      "750\tValidation loss: 0.368742\tBest loss: 0.368008\tAccuracy: 92.00%\n",
      "751\tValidation loss: 0.367408\tBest loss: 0.367408\tAccuracy: 92.10%\n",
      "752\tValidation loss: 0.367971\tBest loss: 0.367408\tAccuracy: 92.10%\n",
      "753\tValidation loss: 0.368521\tBest loss: 0.367408\tAccuracy: 92.00%\n",
      "754\tValidation loss: 0.367620\tBest loss: 0.367408\tAccuracy: 92.00%\n",
      "755\tValidation loss: 0.367880\tBest loss: 0.367408\tAccuracy: 92.10%\n",
      "756\tValidation loss: 0.368970\tBest loss: 0.367408\tAccuracy: 92.10%\n",
      "757\tValidation loss: 0.367555\tBest loss: 0.367408\tAccuracy: 92.10%\n",
      "758\tValidation loss: 0.368446\tBest loss: 0.367408\tAccuracy: 92.00%\n",
      "759\tValidation loss: 0.367360\tBest loss: 0.367360\tAccuracy: 92.00%\n",
      "760\tValidation loss: 0.368202\tBest loss: 0.367360\tAccuracy: 92.00%\n",
      "761\tValidation loss: 0.367929\tBest loss: 0.367360\tAccuracy: 92.10%\n",
      "762\tValidation loss: 0.367470\tBest loss: 0.367360\tAccuracy: 92.00%\n",
      "763\tValidation loss: 0.367534\tBest loss: 0.367360\tAccuracy: 92.10%\n",
      "764\tValidation loss: 0.367604\tBest loss: 0.367360\tAccuracy: 92.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\tValidation loss: 0.367483\tBest loss: 0.367360\tAccuracy: 92.00%\n",
      "766\tValidation loss: 0.368251\tBest loss: 0.367360\tAccuracy: 91.90%\n",
      "767\tValidation loss: 0.367468\tBest loss: 0.367360\tAccuracy: 92.00%\n",
      "768\tValidation loss: 0.366911\tBest loss: 0.366911\tAccuracy: 92.00%\n",
      "769\tValidation loss: 0.366734\tBest loss: 0.366734\tAccuracy: 92.00%\n",
      "770\tValidation loss: 0.366906\tBest loss: 0.366734\tAccuracy: 91.90%\n",
      "771\tValidation loss: 0.366937\tBest loss: 0.366734\tAccuracy: 92.10%\n",
      "772\tValidation loss: 0.367282\tBest loss: 0.366734\tAccuracy: 92.10%\n",
      "773\tValidation loss: 0.366721\tBest loss: 0.366721\tAccuracy: 92.00%\n",
      "774\tValidation loss: 0.367136\tBest loss: 0.366721\tAccuracy: 92.10%\n",
      "775\tValidation loss: 0.366610\tBest loss: 0.366610\tAccuracy: 92.00%\n",
      "776\tValidation loss: 0.367427\tBest loss: 0.366610\tAccuracy: 91.90%\n",
      "777\tValidation loss: 0.366847\tBest loss: 0.366610\tAccuracy: 91.90%\n",
      "778\tValidation loss: 0.367700\tBest loss: 0.366610\tAccuracy: 92.00%\n",
      "779\tValidation loss: 0.367079\tBest loss: 0.366610\tAccuracy: 91.90%\n",
      "780\tValidation loss: 0.365864\tBest loss: 0.365864\tAccuracy: 91.90%\n",
      "781\tValidation loss: 0.366520\tBest loss: 0.365864\tAccuracy: 91.90%\n",
      "782\tValidation loss: 0.367095\tBest loss: 0.365864\tAccuracy: 91.90%\n",
      "783\tValidation loss: 0.365171\tBest loss: 0.365171\tAccuracy: 92.00%\n",
      "784\tValidation loss: 0.366803\tBest loss: 0.365171\tAccuracy: 91.90%\n",
      "785\tValidation loss: 0.366718\tBest loss: 0.365171\tAccuracy: 92.10%\n",
      "786\tValidation loss: 0.365768\tBest loss: 0.365171\tAccuracy: 92.00%\n",
      "787\tValidation loss: 0.366541\tBest loss: 0.365171\tAccuracy: 92.10%\n",
      "788\tValidation loss: 0.366515\tBest loss: 0.365171\tAccuracy: 92.00%\n",
      "789\tValidation loss: 0.367093\tBest loss: 0.365171\tAccuracy: 92.00%\n",
      "790\tValidation loss: 0.365129\tBest loss: 0.365129\tAccuracy: 92.10%\n",
      "791\tValidation loss: 0.365413\tBest loss: 0.365129\tAccuracy: 92.10%\n",
      "792\tValidation loss: 0.365889\tBest loss: 0.365129\tAccuracy: 92.00%\n",
      "793\tValidation loss: 0.365290\tBest loss: 0.365129\tAccuracy: 92.00%\n",
      "794\tValidation loss: 0.367129\tBest loss: 0.365129\tAccuracy: 91.90%\n",
      "795\tValidation loss: 0.366095\tBest loss: 0.365129\tAccuracy: 92.00%\n",
      "796\tValidation loss: 0.365006\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "797\tValidation loss: 0.365695\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "798\tValidation loss: 0.365464\tBest loss: 0.365006\tAccuracy: 92.00%\n",
      "799\tValidation loss: 0.365380\tBest loss: 0.365006\tAccuracy: 91.90%\n",
      "800\tValidation loss: 0.365636\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "801\tValidation loss: 0.365347\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "802\tValidation loss: 0.365937\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "803\tValidation loss: 0.365336\tBest loss: 0.365006\tAccuracy: 92.00%\n",
      "804\tValidation loss: 0.365271\tBest loss: 0.365006\tAccuracy: 92.00%\n",
      "805\tValidation loss: 0.365317\tBest loss: 0.365006\tAccuracy: 92.00%\n",
      "806\tValidation loss: 0.365617\tBest loss: 0.365006\tAccuracy: 92.10%\n",
      "807\tValidation loss: 0.365304\tBest loss: 0.365006\tAccuracy: 92.00%\n",
      "808\tValidation loss: 0.364617\tBest loss: 0.364617\tAccuracy: 92.00%\n",
      "809\tValidation loss: 0.364548\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "810\tValidation loss: 0.364653\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "811\tValidation loss: 0.364711\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "812\tValidation loss: 0.365174\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "813\tValidation loss: 0.364847\tBest loss: 0.364548\tAccuracy: 92.00%\n",
      "814\tValidation loss: 0.365380\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "815\tValidation loss: 0.365045\tBest loss: 0.364548\tAccuracy: 92.00%\n",
      "816\tValidation loss: 0.365104\tBest loss: 0.364548\tAccuracy: 92.10%\n",
      "817\tValidation loss: 0.365761\tBest loss: 0.364548\tAccuracy: 92.00%\n",
      "818\tValidation loss: 0.364076\tBest loss: 0.364076\tAccuracy: 92.30%\n",
      "819\tValidation loss: 0.364688\tBest loss: 0.364076\tAccuracy: 92.00%\n",
      "820\tValidation loss: 0.363728\tBest loss: 0.363728\tAccuracy: 92.00%\n",
      "821\tValidation loss: 0.364951\tBest loss: 0.363728\tAccuracy: 91.80%\n",
      "822\tValidation loss: 0.364016\tBest loss: 0.363728\tAccuracy: 91.90%\n",
      "823\tValidation loss: 0.364547\tBest loss: 0.363728\tAccuracy: 91.90%\n",
      "824\tValidation loss: 0.364944\tBest loss: 0.363728\tAccuracy: 91.80%\n",
      "825\tValidation loss: 0.363936\tBest loss: 0.363728\tAccuracy: 91.90%\n",
      "826\tValidation loss: 0.364220\tBest loss: 0.363728\tAccuracy: 91.90%\n",
      "827\tValidation loss: 0.364511\tBest loss: 0.363728\tAccuracy: 91.90%\n",
      "828\tValidation loss: 0.363412\tBest loss: 0.363412\tAccuracy: 91.90%\n",
      "829\tValidation loss: 0.363889\tBest loss: 0.363412\tAccuracy: 91.90%\n",
      "830\tValidation loss: 0.364375\tBest loss: 0.363412\tAccuracy: 91.90%\n",
      "831\tValidation loss: 0.363024\tBest loss: 0.363024\tAccuracy: 91.80%\n",
      "832\tValidation loss: 0.364054\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "833\tValidation loss: 0.363839\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "834\tValidation loss: 0.363333\tBest loss: 0.363024\tAccuracy: 92.00%\n",
      "835\tValidation loss: 0.363130\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "836\tValidation loss: 0.363375\tBest loss: 0.363024\tAccuracy: 92.10%\n",
      "837\tValidation loss: 0.364019\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "838\tValidation loss: 0.363372\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "839\tValidation loss: 0.363133\tBest loss: 0.363024\tAccuracy: 92.00%\n",
      "840\tValidation loss: 0.363334\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "841\tValidation loss: 0.364090\tBest loss: 0.363024\tAccuracy: 91.90%\n",
      "842\tValidation loss: 0.363449\tBest loss: 0.363024\tAccuracy: 92.10%\n",
      "843\tValidation loss: 0.362218\tBest loss: 0.362218\tAccuracy: 92.20%\n",
      "844\tValidation loss: 0.363485\tBest loss: 0.362218\tAccuracy: 92.00%\n",
      "845\tValidation loss: 0.363333\tBest loss: 0.362218\tAccuracy: 91.80%\n",
      "846\tValidation loss: 0.362281\tBest loss: 0.362218\tAccuracy: 92.10%\n",
      "847\tValidation loss: 0.362825\tBest loss: 0.362218\tAccuracy: 92.00%\n",
      "848\tValidation loss: 0.361963\tBest loss: 0.361963\tAccuracy: 92.00%\n",
      "849\tValidation loss: 0.363171\tBest loss: 0.361963\tAccuracy: 91.80%\n",
      "850\tValidation loss: 0.363161\tBest loss: 0.361963\tAccuracy: 91.90%\n",
      "851\tValidation loss: 0.362741\tBest loss: 0.361963\tAccuracy: 92.00%\n",
      "852\tValidation loss: 0.363306\tBest loss: 0.361963\tAccuracy: 91.90%\n",
      "853\tValidation loss: 0.362652\tBest loss: 0.361963\tAccuracy: 91.90%\n",
      "854\tValidation loss: 0.363947\tBest loss: 0.361963\tAccuracy: 92.00%\n",
      "855\tValidation loss: 0.363217\tBest loss: 0.361963\tAccuracy: 92.00%\n",
      "856\tValidation loss: 0.361820\tBest loss: 0.361820\tAccuracy: 92.10%\n",
      "857\tValidation loss: 0.362320\tBest loss: 0.361820\tAccuracy: 92.20%\n",
      "858\tValidation loss: 0.363114\tBest loss: 0.361820\tAccuracy: 91.80%\n",
      "859\tValidation loss: 0.362460\tBest loss: 0.361820\tAccuracy: 92.10%\n",
      "860\tValidation loss: 0.362809\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "861\tValidation loss: 0.362720\tBest loss: 0.361820\tAccuracy: 91.90%\n",
      "862\tValidation loss: 0.362735\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "863\tValidation loss: 0.362489\tBest loss: 0.361820\tAccuracy: 91.90%\n",
      "864\tValidation loss: 0.362464\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "865\tValidation loss: 0.362395\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "866\tValidation loss: 0.362159\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "867\tValidation loss: 0.362284\tBest loss: 0.361820\tAccuracy: 92.10%\n",
      "868\tValidation loss: 0.362422\tBest loss: 0.361820\tAccuracy: 91.90%\n",
      "869\tValidation loss: 0.362422\tBest loss: 0.361820\tAccuracy: 92.00%\n",
      "870\tValidation loss: 0.361478\tBest loss: 0.361478\tAccuracy: 92.00%\n",
      "871\tValidation loss: 0.361647\tBest loss: 0.361478\tAccuracy: 91.90%\n",
      "872\tValidation loss: 0.362709\tBest loss: 0.361478\tAccuracy: 92.10%\n",
      "873\tValidation loss: 0.362331\tBest loss: 0.361478\tAccuracy: 91.90%\n",
      "874\tValidation loss: 0.361955\tBest loss: 0.361478\tAccuracy: 91.90%\n",
      "875\tValidation loss: 0.362146\tBest loss: 0.361478\tAccuracy: 91.90%\n",
      "876\tValidation loss: 0.361999\tBest loss: 0.361478\tAccuracy: 91.90%\n",
      "877\tValidation loss: 0.361229\tBest loss: 0.361229\tAccuracy: 92.10%\n",
      "878\tValidation loss: 0.361039\tBest loss: 0.361039\tAccuracy: 92.10%\n",
      "879\tValidation loss: 0.361404\tBest loss: 0.361039\tAccuracy: 91.90%\n",
      "880\tValidation loss: 0.361862\tBest loss: 0.361039\tAccuracy: 92.00%\n",
      "881\tValidation loss: 0.360697\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "882\tValidation loss: 0.361081\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "883\tValidation loss: 0.362080\tBest loss: 0.360697\tAccuracy: 92.00%\n",
      "884\tValidation loss: 0.362021\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "885\tValidation loss: 0.361528\tBest loss: 0.360697\tAccuracy: 92.00%\n",
      "886\tValidation loss: 0.361093\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "887\tValidation loss: 0.361570\tBest loss: 0.360697\tAccuracy: 92.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\tValidation loss: 0.360885\tBest loss: 0.360697\tAccuracy: 92.00%\n",
      "889\tValidation loss: 0.361105\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "890\tValidation loss: 0.361399\tBest loss: 0.360697\tAccuracy: 92.10%\n",
      "891\tValidation loss: 0.360512\tBest loss: 0.360512\tAccuracy: 92.10%\n",
      "892\tValidation loss: 0.361168\tBest loss: 0.360512\tAccuracy: 92.10%\n",
      "893\tValidation loss: 0.360430\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "894\tValidation loss: 0.360877\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "895\tValidation loss: 0.360844\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "896\tValidation loss: 0.360816\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "897\tValidation loss: 0.361333\tBest loss: 0.360430\tAccuracy: 92.00%\n",
      "898\tValidation loss: 0.360765\tBest loss: 0.360430\tAccuracy: 92.30%\n",
      "899\tValidation loss: 0.360875\tBest loss: 0.360430\tAccuracy: 92.00%\n",
      "900\tValidation loss: 0.360635\tBest loss: 0.360430\tAccuracy: 92.00%\n",
      "901\tValidation loss: 0.361624\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "902\tValidation loss: 0.360606\tBest loss: 0.360430\tAccuracy: 92.10%\n",
      "903\tValidation loss: 0.360268\tBest loss: 0.360268\tAccuracy: 92.10%\n",
      "904\tValidation loss: 0.361396\tBest loss: 0.360268\tAccuracy: 92.00%\n",
      "905\tValidation loss: 0.361275\tBest loss: 0.360268\tAccuracy: 92.10%\n",
      "906\tValidation loss: 0.360744\tBest loss: 0.360268\tAccuracy: 92.10%\n",
      "907\tValidation loss: 0.360333\tBest loss: 0.360268\tAccuracy: 92.10%\n",
      "908\tValidation loss: 0.360165\tBest loss: 0.360165\tAccuracy: 92.20%\n",
      "909\tValidation loss: 0.360748\tBest loss: 0.360165\tAccuracy: 92.20%\n",
      "910\tValidation loss: 0.360003\tBest loss: 0.360003\tAccuracy: 92.10%\n",
      "911\tValidation loss: 0.360155\tBest loss: 0.360003\tAccuracy: 92.20%\n",
      "912\tValidation loss: 0.360127\tBest loss: 0.360003\tAccuracy: 92.20%\n",
      "913\tValidation loss: 0.359674\tBest loss: 0.359674\tAccuracy: 92.20%\n",
      "914\tValidation loss: 0.360108\tBest loss: 0.359674\tAccuracy: 92.20%\n",
      "915\tValidation loss: 0.360239\tBest loss: 0.359674\tAccuracy: 92.20%\n",
      "916\tValidation loss: 0.360185\tBest loss: 0.359674\tAccuracy: 92.20%\n",
      "917\tValidation loss: 0.360572\tBest loss: 0.359674\tAccuracy: 92.20%\n",
      "918\tValidation loss: 0.359220\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "919\tValidation loss: 0.360258\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "920\tValidation loss: 0.360678\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "921\tValidation loss: 0.360062\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "922\tValidation loss: 0.360320\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "923\tValidation loss: 0.360592\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "924\tValidation loss: 0.359707\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "925\tValidation loss: 0.359974\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "926\tValidation loss: 0.359606\tBest loss: 0.359220\tAccuracy: 92.20%\n",
      "927\tValidation loss: 0.358647\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "928\tValidation loss: 0.359688\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "929\tValidation loss: 0.359974\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "930\tValidation loss: 0.359933\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "931\tValidation loss: 0.359281\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "932\tValidation loss: 0.359776\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "933\tValidation loss: 0.360025\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "934\tValidation loss: 0.359624\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "935\tValidation loss: 0.359498\tBest loss: 0.358647\tAccuracy: 92.10%\n",
      "936\tValidation loss: 0.359113\tBest loss: 0.358647\tAccuracy: 92.10%\n",
      "937\tValidation loss: 0.359882\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "938\tValidation loss: 0.359489\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "939\tValidation loss: 0.359151\tBest loss: 0.358647\tAccuracy: 92.30%\n",
      "940\tValidation loss: 0.359254\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "941\tValidation loss: 0.359302\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "942\tValidation loss: 0.359310\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "943\tValidation loss: 0.358804\tBest loss: 0.358647\tAccuracy: 92.20%\n",
      "944\tValidation loss: 0.358460\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "945\tValidation loss: 0.359426\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "946\tValidation loss: 0.359451\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "947\tValidation loss: 0.359124\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "948\tValidation loss: 0.359194\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "949\tValidation loss: 0.358897\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "950\tValidation loss: 0.359075\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "951\tValidation loss: 0.358863\tBest loss: 0.358460\tAccuracy: 92.20%\n",
      "952\tValidation loss: 0.358410\tBest loss: 0.358410\tAccuracy: 92.20%\n",
      "953\tValidation loss: 0.359168\tBest loss: 0.358410\tAccuracy: 92.30%\n",
      "954\tValidation loss: 0.359256\tBest loss: 0.358410\tAccuracy: 92.20%\n",
      "955\tValidation loss: 0.359090\tBest loss: 0.358410\tAccuracy: 92.20%\n",
      "956\tValidation loss: 0.358366\tBest loss: 0.358366\tAccuracy: 92.20%\n",
      "957\tValidation loss: 0.358661\tBest loss: 0.358366\tAccuracy: 92.30%\n",
      "958\tValidation loss: 0.358265\tBest loss: 0.358265\tAccuracy: 92.30%\n",
      "959\tValidation loss: 0.359293\tBest loss: 0.358265\tAccuracy: 92.20%\n",
      "960\tValidation loss: 0.358086\tBest loss: 0.358086\tAccuracy: 92.30%\n",
      "961\tValidation loss: 0.358358\tBest loss: 0.358086\tAccuracy: 92.20%\n",
      "962\tValidation loss: 0.358441\tBest loss: 0.358086\tAccuracy: 92.20%\n",
      "963\tValidation loss: 0.359282\tBest loss: 0.358086\tAccuracy: 92.20%\n",
      "964\tValidation loss: 0.357910\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "965\tValidation loss: 0.358916\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "966\tValidation loss: 0.358840\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "967\tValidation loss: 0.358050\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "968\tValidation loss: 0.358408\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "969\tValidation loss: 0.358054\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "970\tValidation loss: 0.358266\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "971\tValidation loss: 0.358709\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "972\tValidation loss: 0.358006\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "973\tValidation loss: 0.358300\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "974\tValidation loss: 0.358125\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "975\tValidation loss: 0.359016\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "976\tValidation loss: 0.358725\tBest loss: 0.357910\tAccuracy: 92.20%\n",
      "977\tValidation loss: 0.357955\tBest loss: 0.357910\tAccuracy: 92.30%\n",
      "978\tValidation loss: 0.358160\tBest loss: 0.357910\tAccuracy: 92.30%\n",
      "979\tValidation loss: 0.357498\tBest loss: 0.357498\tAccuracy: 92.30%\n",
      "980\tValidation loss: 0.357766\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "981\tValidation loss: 0.358122\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "982\tValidation loss: 0.357882\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "983\tValidation loss: 0.357516\tBest loss: 0.357498\tAccuracy: 92.40%\n",
      "984\tValidation loss: 0.357613\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "985\tValidation loss: 0.358097\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "986\tValidation loss: 0.358233\tBest loss: 0.357498\tAccuracy: 92.30%\n",
      "987\tValidation loss: 0.357789\tBest loss: 0.357498\tAccuracy: 92.20%\n",
      "988\tValidation loss: 0.357287\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "989\tValidation loss: 0.357374\tBest loss: 0.357287\tAccuracy: 92.20%\n",
      "990\tValidation loss: 0.357544\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "991\tValidation loss: 0.357348\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "992\tValidation loss: 0.357486\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "993\tValidation loss: 0.357712\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "994\tValidation loss: 0.357970\tBest loss: 0.357287\tAccuracy: 92.30%\n",
      "995\tValidation loss: 0.357083\tBest loss: 0.357083\tAccuracy: 92.20%\n",
      "996\tValidation loss: 0.357189\tBest loss: 0.357083\tAccuracy: 92.20%\n",
      "997\tValidation loss: 0.357155\tBest loss: 0.357083\tAccuracy: 92.30%\n",
      "998\tValidation loss: 0.356863\tBest loss: 0.356863\tAccuracy: 92.40%\n",
      "999\tValidation loss: 0.357468\tBest loss: 0.356863\tAccuracy: 92.30%\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.6min\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.828274\tBest loss: 5.828274\tAccuracy: 27.20%\n",
      "1\tValidation loss: 4.056475\tBest loss: 4.056475\tAccuracy: 46.40%\n",
      "2\tValidation loss: 3.764972\tBest loss: 3.764972\tAccuracy: 57.30%\n",
      "3\tValidation loss: 3.036978\tBest loss: 3.036978\tAccuracy: 61.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\tValidation loss: 4.017351\tBest loss: 3.036978\tAccuracy: 60.00%\n",
      "5\tValidation loss: 2.394557\tBest loss: 2.394557\tAccuracy: 67.50%\n",
      "6\tValidation loss: 1.398586\tBest loss: 1.398586\tAccuracy: 79.70%\n",
      "7\tValidation loss: 1.004399\tBest loss: 1.004399\tAccuracy: 80.60%\n",
      "8\tValidation loss: 1.862420\tBest loss: 1.004399\tAccuracy: 74.80%\n",
      "9\tValidation loss: 1.992621\tBest loss: 1.004399\tAccuracy: 74.00%\n",
      "10\tValidation loss: 1.090584\tBest loss: 1.004399\tAccuracy: 80.80%\n",
      "11\tValidation loss: 2.434435\tBest loss: 1.004399\tAccuracy: 74.40%\n",
      "12\tValidation loss: 2.347200\tBest loss: 1.004399\tAccuracy: 73.50%\n",
      "13\tValidation loss: 0.985045\tBest loss: 0.985045\tAccuracy: 85.00%\n",
      "14\tValidation loss: 1.307687\tBest loss: 0.985045\tAccuracy: 81.30%\n",
      "15\tValidation loss: 1.185129\tBest loss: 0.985045\tAccuracy: 81.80%\n",
      "16\tValidation loss: 1.469845\tBest loss: 0.985045\tAccuracy: 80.70%\n",
      "17\tValidation loss: 1.141316\tBest loss: 0.985045\tAccuracy: 85.40%\n",
      "18\tValidation loss: 0.841614\tBest loss: 0.841614\tAccuracy: 88.20%\n",
      "19\tValidation loss: 1.756731\tBest loss: 0.841614\tAccuracy: 77.00%\n",
      "20\tValidation loss: 0.825272\tBest loss: 0.825272\tAccuracy: 88.20%\n",
      "21\tValidation loss: 1.448687\tBest loss: 0.825272\tAccuracy: 81.90%\n",
      "22\tValidation loss: 1.421264\tBest loss: 0.825272\tAccuracy: 82.80%\n",
      "23\tValidation loss: 1.345675\tBest loss: 0.825272\tAccuracy: 83.20%\n",
      "24\tValidation loss: 1.159602\tBest loss: 0.825272\tAccuracy: 84.80%\n",
      "25\tValidation loss: 1.617007\tBest loss: 0.825272\tAccuracy: 80.30%\n",
      "26\tValidation loss: 1.410058\tBest loss: 0.825272\tAccuracy: 84.40%\n",
      "27\tValidation loss: 0.950802\tBest loss: 0.825272\tAccuracy: 87.20%\n",
      "28\tValidation loss: 1.079352\tBest loss: 0.825272\tAccuracy: 87.40%\n",
      "29\tValidation loss: 0.764159\tBest loss: 0.764159\tAccuracy: 89.80%\n",
      "30\tValidation loss: 1.000895\tBest loss: 0.764159\tAccuracy: 87.80%\n",
      "31\tValidation loss: 0.977585\tBest loss: 0.764159\tAccuracy: 88.50%\n",
      "32\tValidation loss: 1.174783\tBest loss: 0.764159\tAccuracy: 86.30%\n",
      "33\tValidation loss: 1.451035\tBest loss: 0.764159\tAccuracy: 81.90%\n",
      "34\tValidation loss: 1.217302\tBest loss: 0.764159\tAccuracy: 86.90%\n",
      "35\tValidation loss: 0.767385\tBest loss: 0.764159\tAccuracy: 90.70%\n",
      "36\tValidation loss: 1.187075\tBest loss: 0.764159\tAccuracy: 87.00%\n",
      "37\tValidation loss: 0.788037\tBest loss: 0.764159\tAccuracy: 89.30%\n",
      "38\tValidation loss: 1.037761\tBest loss: 0.764159\tAccuracy: 87.40%\n",
      "39\tValidation loss: 0.828312\tBest loss: 0.764159\tAccuracy: 91.20%\n",
      "40\tValidation loss: 0.819357\tBest loss: 0.764159\tAccuracy: 90.10%\n",
      "41\tValidation loss: 0.870460\tBest loss: 0.764159\tAccuracy: 90.50%\n",
      "42\tValidation loss: 0.948542\tBest loss: 0.764159\tAccuracy: 90.00%\n",
      "43\tValidation loss: 1.081076\tBest loss: 0.764159\tAccuracy: 89.80%\n",
      "44\tValidation loss: 0.892022\tBest loss: 0.764159\tAccuracy: 89.80%\n",
      "45\tValidation loss: 1.305972\tBest loss: 0.764159\tAccuracy: 85.70%\n",
      "46\tValidation loss: 1.211359\tBest loss: 0.764159\tAccuracy: 88.90%\n",
      "47\tValidation loss: 0.837941\tBest loss: 0.764159\tAccuracy: 91.40%\n",
      "48\tValidation loss: 0.945509\tBest loss: 0.764159\tAccuracy: 90.10%\n",
      "49\tValidation loss: 1.258278\tBest loss: 0.764159\tAccuracy: 88.90%\n",
      "50\tValidation loss: 0.937811\tBest loss: 0.764159\tAccuracy: 90.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   5.7s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.650133\tBest loss: 4.650133\tAccuracy: 27.50%\n",
      "1\tValidation loss: 4.026744\tBest loss: 4.026744\tAccuracy: 50.50%\n",
      "2\tValidation loss: 4.159717\tBest loss: 4.026744\tAccuracy: 55.10%\n",
      "3\tValidation loss: 2.305752\tBest loss: 2.305752\tAccuracy: 69.30%\n",
      "4\tValidation loss: 2.209744\tBest loss: 2.209744\tAccuracy: 69.60%\n",
      "5\tValidation loss: 1.991616\tBest loss: 1.991616\tAccuracy: 73.50%\n",
      "6\tValidation loss: 2.494896\tBest loss: 1.991616\tAccuracy: 67.60%\n",
      "7\tValidation loss: 1.601337\tBest loss: 1.601337\tAccuracy: 78.00%\n",
      "8\tValidation loss: 1.774603\tBest loss: 1.601337\tAccuracy: 78.10%\n",
      "9\tValidation loss: 1.737480\tBest loss: 1.601337\tAccuracy: 78.00%\n",
      "10\tValidation loss: 1.136549\tBest loss: 1.136549\tAccuracy: 84.20%\n",
      "11\tValidation loss: 1.436140\tBest loss: 1.136549\tAccuracy: 81.80%\n",
      "12\tValidation loss: 2.058086\tBest loss: 1.136549\tAccuracy: 76.10%\n",
      "13\tValidation loss: 1.142237\tBest loss: 1.136549\tAccuracy: 83.10%\n",
      "14\tValidation loss: 1.768682\tBest loss: 1.136549\tAccuracy: 76.10%\n",
      "15\tValidation loss: 1.835117\tBest loss: 1.136549\tAccuracy: 76.50%\n",
      "16\tValidation loss: 1.849745\tBest loss: 1.136549\tAccuracy: 78.40%\n",
      "17\tValidation loss: 0.880318\tBest loss: 0.880318\tAccuracy: 88.10%\n",
      "18\tValidation loss: 1.012829\tBest loss: 0.880318\tAccuracy: 85.00%\n",
      "19\tValidation loss: 2.440041\tBest loss: 0.880318\tAccuracy: 73.80%\n",
      "20\tValidation loss: 2.819285\tBest loss: 0.880318\tAccuracy: 76.10%\n",
      "21\tValidation loss: 0.852239\tBest loss: 0.852239\tAccuracy: 88.40%\n",
      "22\tValidation loss: 1.692496\tBest loss: 0.852239\tAccuracy: 82.50%\n",
      "23\tValidation loss: 1.820443\tBest loss: 0.852239\tAccuracy: 83.50%\n",
      "24\tValidation loss: 1.433716\tBest loss: 0.852239\tAccuracy: 85.20%\n",
      "25\tValidation loss: 0.922868\tBest loss: 0.852239\tAccuracy: 90.30%\n",
      "26\tValidation loss: 2.060728\tBest loss: 0.852239\tAccuracy: 77.90%\n",
      "27\tValidation loss: 2.080266\tBest loss: 0.852239\tAccuracy: 79.70%\n",
      "28\tValidation loss: 1.411429\tBest loss: 0.852239\tAccuracy: 85.20%\n",
      "29\tValidation loss: 0.943945\tBest loss: 0.852239\tAccuracy: 89.10%\n",
      "30\tValidation loss: 1.566890\tBest loss: 0.852239\tAccuracy: 85.90%\n",
      "31\tValidation loss: 1.841495\tBest loss: 0.852239\tAccuracy: 83.20%\n",
      "32\tValidation loss: 1.089682\tBest loss: 0.852239\tAccuracy: 88.80%\n",
      "33\tValidation loss: 1.041279\tBest loss: 0.852239\tAccuracy: 90.80%\n",
      "34\tValidation loss: 1.048726\tBest loss: 0.852239\tAccuracy: 90.50%\n",
      "35\tValidation loss: 1.814250\tBest loss: 0.852239\tAccuracy: 85.30%\n",
      "36\tValidation loss: 1.047097\tBest loss: 0.852239\tAccuracy: 90.30%\n",
      "37\tValidation loss: 1.191482\tBest loss: 0.852239\tAccuracy: 88.50%\n",
      "38\tValidation loss: 1.112462\tBest loss: 0.852239\tAccuracy: 89.10%\n",
      "39\tValidation loss: 0.956610\tBest loss: 0.852239\tAccuracy: 91.20%\n",
      "40\tValidation loss: 1.102773\tBest loss: 0.852239\tAccuracy: 90.30%\n",
      "41\tValidation loss: 1.036003\tBest loss: 0.852239\tAccuracy: 91.60%\n",
      "42\tValidation loss: 1.110467\tBest loss: 0.852239\tAccuracy: 89.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.8s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.424098\tBest loss: 4.424098\tAccuracy: 32.60%\n",
      "1\tValidation loss: 4.245400\tBest loss: 4.245400\tAccuracy: 49.20%\n",
      "2\tValidation loss: 3.368109\tBest loss: 3.368109\tAccuracy: 58.00%\n",
      "3\tValidation loss: 2.821598\tBest loss: 2.821598\tAccuracy: 64.40%\n",
      "4\tValidation loss: 2.203031\tBest loss: 2.203031\tAccuracy: 70.80%\n",
      "5\tValidation loss: 1.920678\tBest loss: 1.920678\tAccuracy: 72.20%\n",
      "6\tValidation loss: 1.654648\tBest loss: 1.654648\tAccuracy: 73.90%\n",
      "7\tValidation loss: 1.459072\tBest loss: 1.459072\tAccuracy: 76.60%\n",
      "8\tValidation loss: 1.757854\tBest loss: 1.459072\tAccuracy: 76.30%\n",
      "9\tValidation loss: 1.482958\tBest loss: 1.459072\tAccuracy: 79.30%\n",
      "10\tValidation loss: 1.733475\tBest loss: 1.459072\tAccuracy: 78.70%\n",
      "11\tValidation loss: 1.851734\tBest loss: 1.459072\tAccuracy: 79.50%\n",
      "12\tValidation loss: 1.532223\tBest loss: 1.459072\tAccuracy: 79.90%\n",
      "13\tValidation loss: 1.138401\tBest loss: 1.138401\tAccuracy: 81.10%\n",
      "14\tValidation loss: 1.310721\tBest loss: 1.138401\tAccuracy: 82.80%\n",
      "15\tValidation loss: 1.086232\tBest loss: 1.086232\tAccuracy: 86.40%\n",
      "16\tValidation loss: 1.851561\tBest loss: 1.086232\tAccuracy: 77.00%\n",
      "17\tValidation loss: 1.039123\tBest loss: 1.039123\tAccuracy: 85.40%\n",
      "18\tValidation loss: 1.282158\tBest loss: 1.039123\tAccuracy: 83.30%\n",
      "19\tValidation loss: 1.719504\tBest loss: 1.039123\tAccuracy: 83.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\tValidation loss: 1.275595\tBest loss: 1.039123\tAccuracy: 82.40%\n",
      "21\tValidation loss: 0.991773\tBest loss: 0.991773\tAccuracy: 86.60%\n",
      "22\tValidation loss: 1.183661\tBest loss: 0.991773\tAccuracy: 83.40%\n",
      "23\tValidation loss: 1.136432\tBest loss: 0.991773\tAccuracy: 86.60%\n",
      "24\tValidation loss: 1.106055\tBest loss: 0.991773\tAccuracy: 86.10%\n",
      "25\tValidation loss: 1.718281\tBest loss: 0.991773\tAccuracy: 81.80%\n",
      "26\tValidation loss: 1.299518\tBest loss: 0.991773\tAccuracy: 86.00%\n",
      "27\tValidation loss: 1.186206\tBest loss: 0.991773\tAccuracy: 87.30%\n",
      "28\tValidation loss: 1.087760\tBest loss: 0.991773\tAccuracy: 86.60%\n",
      "29\tValidation loss: 0.972786\tBest loss: 0.972786\tAccuracy: 87.30%\n",
      "30\tValidation loss: 0.741423\tBest loss: 0.741423\tAccuracy: 90.60%\n",
      "31\tValidation loss: 1.132284\tBest loss: 0.741423\tAccuracy: 87.10%\n",
      "32\tValidation loss: 1.549493\tBest loss: 0.741423\tAccuracy: 86.90%\n",
      "33\tValidation loss: 0.810918\tBest loss: 0.741423\tAccuracy: 88.80%\n",
      "34\tValidation loss: 1.095887\tBest loss: 0.741423\tAccuracy: 87.00%\n",
      "35\tValidation loss: 0.802582\tBest loss: 0.741423\tAccuracy: 89.50%\n",
      "36\tValidation loss: 1.276643\tBest loss: 0.741423\tAccuracy: 87.60%\n",
      "37\tValidation loss: 0.864646\tBest loss: 0.741423\tAccuracy: 89.70%\n",
      "38\tValidation loss: 1.445915\tBest loss: 0.741423\tAccuracy: 85.50%\n",
      "39\tValidation loss: 0.762057\tBest loss: 0.741423\tAccuracy: 90.60%\n",
      "40\tValidation loss: 1.286509\tBest loss: 0.741423\tAccuracy: 86.60%\n",
      "41\tValidation loss: 0.925028\tBest loss: 0.741423\tAccuracy: 90.40%\n",
      "42\tValidation loss: 1.028531\tBest loss: 0.741423\tAccuracy: 88.00%\n",
      "43\tValidation loss: 0.791721\tBest loss: 0.741423\tAccuracy: 91.70%\n",
      "44\tValidation loss: 1.267825\tBest loss: 0.741423\tAccuracy: 87.60%\n",
      "45\tValidation loss: 1.693200\tBest loss: 0.741423\tAccuracy: 85.70%\n",
      "46\tValidation loss: 1.589574\tBest loss: 0.741423\tAccuracy: 85.70%\n",
      "47\tValidation loss: 1.077948\tBest loss: 0.741423\tAccuracy: 90.60%\n",
      "48\tValidation loss: 1.586838\tBest loss: 0.741423\tAccuracy: 86.70%\n",
      "49\tValidation loss: 0.910687\tBest loss: 0.741423\tAccuracy: 90.40%\n",
      "50\tValidation loss: 1.779582\tBest loss: 0.741423\tAccuracy: 86.20%\n",
      "51\tValidation loss: 1.227087\tBest loss: 0.741423\tAccuracy: 88.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   5.7s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.476441\tBest loss: 1.476441\tAccuracy: 58.60%\n",
      "1\tValidation loss: 1.779868\tBest loss: 1.476441\tAccuracy: 57.70%\n",
      "2\tValidation loss: 0.822448\tBest loss: 0.822448\tAccuracy: 74.80%\n",
      "3\tValidation loss: 1.347634\tBest loss: 0.822448\tAccuracy: 69.40%\n",
      "4\tValidation loss: 1.559060\tBest loss: 0.822448\tAccuracy: 65.40%\n",
      "5\tValidation loss: 0.803687\tBest loss: 0.803687\tAccuracy: 80.30%\n",
      "6\tValidation loss: 0.820543\tBest loss: 0.803687\tAccuracy: 76.10%\n",
      "7\tValidation loss: 0.717924\tBest loss: 0.717924\tAccuracy: 82.10%\n",
      "8\tValidation loss: 0.828031\tBest loss: 0.717924\tAccuracy: 80.40%\n",
      "9\tValidation loss: 0.675373\tBest loss: 0.675373\tAccuracy: 81.60%\n",
      "10\tValidation loss: 0.617506\tBest loss: 0.617506\tAccuracy: 83.90%\n",
      "11\tValidation loss: 0.673935\tBest loss: 0.617506\tAccuracy: 85.10%\n",
      "12\tValidation loss: 0.712324\tBest loss: 0.617506\tAccuracy: 84.60%\n",
      "13\tValidation loss: 0.643418\tBest loss: 0.617506\tAccuracy: 85.50%\n",
      "14\tValidation loss: 0.549875\tBest loss: 0.549875\tAccuracy: 86.60%\n",
      "15\tValidation loss: 0.704803\tBest loss: 0.549875\tAccuracy: 83.90%\n",
      "16\tValidation loss: 0.584683\tBest loss: 0.549875\tAccuracy: 87.80%\n",
      "17\tValidation loss: 0.634695\tBest loss: 0.549875\tAccuracy: 87.10%\n",
      "18\tValidation loss: 0.451404\tBest loss: 0.451404\tAccuracy: 88.00%\n",
      "19\tValidation loss: 0.851152\tBest loss: 0.451404\tAccuracy: 87.00%\n",
      "20\tValidation loss: 0.723450\tBest loss: 0.451404\tAccuracy: 86.00%\n",
      "21\tValidation loss: 0.657320\tBest loss: 0.451404\tAccuracy: 87.00%\n",
      "22\tValidation loss: 0.797911\tBest loss: 0.451404\tAccuracy: 86.30%\n",
      "23\tValidation loss: 1.164312\tBest loss: 0.451404\tAccuracy: 84.70%\n",
      "24\tValidation loss: 1.209818\tBest loss: 0.451404\tAccuracy: 82.90%\n",
      "25\tValidation loss: 0.635889\tBest loss: 0.451404\tAccuracy: 88.00%\n",
      "26\tValidation loss: 0.983456\tBest loss: 0.451404\tAccuracy: 85.10%\n",
      "27\tValidation loss: 1.071411\tBest loss: 0.451404\tAccuracy: 82.40%\n",
      "28\tValidation loss: 0.914028\tBest loss: 0.451404\tAccuracy: 87.30%\n",
      "29\tValidation loss: 0.999373\tBest loss: 0.451404\tAccuracy: 85.50%\n",
      "30\tValidation loss: 0.976290\tBest loss: 0.451404\tAccuracy: 84.40%\n",
      "31\tValidation loss: 0.819212\tBest loss: 0.451404\tAccuracy: 86.80%\n",
      "32\tValidation loss: 1.539217\tBest loss: 0.451404\tAccuracy: 84.30%\n",
      "33\tValidation loss: 0.796501\tBest loss: 0.451404\tAccuracy: 87.90%\n",
      "34\tValidation loss: 1.260942\tBest loss: 0.451404\tAccuracy: 86.80%\n",
      "35\tValidation loss: 1.057911\tBest loss: 0.451404\tAccuracy: 87.20%\n",
      "36\tValidation loss: 0.711296\tBest loss: 0.451404\tAccuracy: 89.80%\n",
      "37\tValidation loss: 1.088189\tBest loss: 0.451404\tAccuracy: 86.20%\n",
      "38\tValidation loss: 1.577185\tBest loss: 0.451404\tAccuracy: 86.80%\n",
      "39\tValidation loss: 1.512563\tBest loss: 0.451404\tAccuracy: 86.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=  10.8s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.830348\tBest loss: 1.830348\tAccuracy: 47.80%\n",
      "1\tValidation loss: 1.305370\tBest loss: 1.305370\tAccuracy: 63.60%\n",
      "2\tValidation loss: 0.778177\tBest loss: 0.778177\tAccuracy: 76.60%\n",
      "3\tValidation loss: 0.801237\tBest loss: 0.778177\tAccuracy: 77.40%\n",
      "4\tValidation loss: 0.736284\tBest loss: 0.736284\tAccuracy: 78.80%\n",
      "5\tValidation loss: 0.853916\tBest loss: 0.736284\tAccuracy: 77.20%\n",
      "6\tValidation loss: 1.585999\tBest loss: 0.736284\tAccuracy: 76.90%\n",
      "7\tValidation loss: 0.698113\tBest loss: 0.698113\tAccuracy: 81.80%\n",
      "8\tValidation loss: 0.847845\tBest loss: 0.698113\tAccuracy: 82.40%\n",
      "9\tValidation loss: 0.900112\tBest loss: 0.698113\tAccuracy: 79.90%\n",
      "10\tValidation loss: 1.015896\tBest loss: 0.698113\tAccuracy: 80.40%\n",
      "11\tValidation loss: 1.116694\tBest loss: 0.698113\tAccuracy: 78.70%\n",
      "12\tValidation loss: 1.076708\tBest loss: 0.698113\tAccuracy: 80.30%\n",
      "13\tValidation loss: 0.708677\tBest loss: 0.698113\tAccuracy: 85.60%\n",
      "14\tValidation loss: 1.122232\tBest loss: 0.698113\tAccuracy: 81.80%\n",
      "15\tValidation loss: 0.729022\tBest loss: 0.698113\tAccuracy: 84.90%\n",
      "16\tValidation loss: 0.709051\tBest loss: 0.698113\tAccuracy: 86.00%\n",
      "17\tValidation loss: 1.147219\tBest loss: 0.698113\tAccuracy: 82.20%\n",
      "18\tValidation loss: 1.161668\tBest loss: 0.698113\tAccuracy: 82.90%\n",
      "19\tValidation loss: 0.982033\tBest loss: 0.698113\tAccuracy: 85.80%\n",
      "20\tValidation loss: 0.984582\tBest loss: 0.698113\tAccuracy: 86.30%\n",
      "21\tValidation loss: 0.955997\tBest loss: 0.698113\tAccuracy: 84.60%\n",
      "22\tValidation loss: 1.294195\tBest loss: 0.698113\tAccuracy: 85.50%\n",
      "23\tValidation loss: 0.999023\tBest loss: 0.698113\tAccuracy: 84.20%\n",
      "24\tValidation loss: 0.956397\tBest loss: 0.698113\tAccuracy: 86.60%\n",
      "25\tValidation loss: 1.549942\tBest loss: 0.698113\tAccuracy: 83.30%\n",
      "26\tValidation loss: 1.373509\tBest loss: 0.698113\tAccuracy: 86.20%\n",
      "27\tValidation loss: 0.872104\tBest loss: 0.698113\tAccuracy: 86.10%\n",
      "28\tValidation loss: 1.940006\tBest loss: 0.698113\tAccuracy: 84.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   7.9s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.170237\tBest loss: 3.170237\tAccuracy: 31.20%\n",
      "1\tValidation loss: 1.521089\tBest loss: 1.521089\tAccuracy: 58.40%\n",
      "2\tValidation loss: 0.844467\tBest loss: 0.844467\tAccuracy: 75.20%\n",
      "3\tValidation loss: 1.043912\tBest loss: 0.844467\tAccuracy: 72.00%\n",
      "4\tValidation loss: 0.607083\tBest loss: 0.607083\tAccuracy: 81.50%\n",
      "5\tValidation loss: 0.812683\tBest loss: 0.607083\tAccuracy: 78.10%\n",
      "6\tValidation loss: 1.037252\tBest loss: 0.607083\tAccuracy: 77.50%\n",
      "7\tValidation loss: 0.722354\tBest loss: 0.607083\tAccuracy: 82.30%\n",
      "8\tValidation loss: 0.763656\tBest loss: 0.607083\tAccuracy: 83.00%\n",
      "9\tValidation loss: 0.700508\tBest loss: 0.607083\tAccuracy: 82.70%\n",
      "10\tValidation loss: 0.599362\tBest loss: 0.599362\tAccuracy: 84.70%\n",
      "11\tValidation loss: 0.953537\tBest loss: 0.599362\tAccuracy: 82.20%\n",
      "12\tValidation loss: 0.666987\tBest loss: 0.599362\tAccuracy: 83.50%\n",
      "13\tValidation loss: 0.658239\tBest loss: 0.599362\tAccuracy: 85.90%\n",
      "14\tValidation loss: 0.915553\tBest loss: 0.599362\tAccuracy: 83.30%\n",
      "15\tValidation loss: 0.686979\tBest loss: 0.599362\tAccuracy: 84.50%\n",
      "16\tValidation loss: 1.003314\tBest loss: 0.599362\tAccuracy: 82.80%\n",
      "17\tValidation loss: 0.797999\tBest loss: 0.599362\tAccuracy: 86.50%\n",
      "18\tValidation loss: 0.870135\tBest loss: 0.599362\tAccuracy: 84.40%\n",
      "19\tValidation loss: 0.804679\tBest loss: 0.599362\tAccuracy: 86.30%\n",
      "20\tValidation loss: 0.894100\tBest loss: 0.599362\tAccuracy: 85.10%\n",
      "21\tValidation loss: 0.773450\tBest loss: 0.599362\tAccuracy: 86.90%\n",
      "22\tValidation loss: 0.843953\tBest loss: 0.599362\tAccuracy: 84.70%\n",
      "23\tValidation loss: 0.943175\tBest loss: 0.599362\tAccuracy: 85.70%\n",
      "24\tValidation loss: 0.949353\tBest loss: 0.599362\tAccuracy: 87.10%\n",
      "25\tValidation loss: 0.717643\tBest loss: 0.599362\tAccuracy: 87.10%\n",
      "26\tValidation loss: 1.102336\tBest loss: 0.599362\tAccuracy: 84.40%\n",
      "27\tValidation loss: 0.956461\tBest loss: 0.599362\tAccuracy: 86.20%\n",
      "28\tValidation loss: 0.723722\tBest loss: 0.599362\tAccuracy: 87.20%\n",
      "29\tValidation loss: 1.045219\tBest loss: 0.599362\tAccuracy: 87.50%\n",
      "30\tValidation loss: 1.104434\tBest loss: 0.599362\tAccuracy: 87.80%\n",
      "31\tValidation loss: 1.195918\tBest loss: 0.599362\tAccuracy: 85.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   8.6s\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.052491\tBest loss: 3.052491\tAccuracy: 23.00%\n",
      "1\tValidation loss: 2.532719\tBest loss: 2.532719\tAccuracy: 36.80%\n",
      "2\tValidation loss: 2.240878\tBest loss: 2.240878\tAccuracy: 46.90%\n",
      "3\tValidation loss: 2.054372\tBest loss: 2.054372\tAccuracy: 52.00%\n",
      "4\tValidation loss: 1.911981\tBest loss: 1.911981\tAccuracy: 57.10%\n",
      "5\tValidation loss: 1.804870\tBest loss: 1.804870\tAccuracy: 61.00%\n",
      "6\tValidation loss: 1.721326\tBest loss: 1.721326\tAccuracy: 62.70%\n",
      "7\tValidation loss: 1.650860\tBest loss: 1.650860\tAccuracy: 64.80%\n",
      "8\tValidation loss: 1.592687\tBest loss: 1.592687\tAccuracy: 66.20%\n",
      "9\tValidation loss: 1.539063\tBest loss: 1.539063\tAccuracy: 67.70%\n",
      "10\tValidation loss: 1.496847\tBest loss: 1.496847\tAccuracy: 68.30%\n",
      "11\tValidation loss: 1.456339\tBest loss: 1.456339\tAccuracy: 69.90%\n",
      "12\tValidation loss: 1.423967\tBest loss: 1.423967\tAccuracy: 70.50%\n",
      "13\tValidation loss: 1.392755\tBest loss: 1.392755\tAccuracy: 71.20%\n",
      "14\tValidation loss: 1.361868\tBest loss: 1.361868\tAccuracy: 72.00%\n",
      "15\tValidation loss: 1.334215\tBest loss: 1.334215\tAccuracy: 72.30%\n",
      "16\tValidation loss: 1.308086\tBest loss: 1.308086\tAccuracy: 73.10%\n",
      "17\tValidation loss: 1.287406\tBest loss: 1.287406\tAccuracy: 73.50%\n",
      "18\tValidation loss: 1.265810\tBest loss: 1.265810\tAccuracy: 73.40%\n",
      "19\tValidation loss: 1.246299\tBest loss: 1.246299\tAccuracy: 74.50%\n",
      "20\tValidation loss: 1.229208\tBest loss: 1.229208\tAccuracy: 74.50%\n",
      "21\tValidation loss: 1.210659\tBest loss: 1.210659\tAccuracy: 75.00%\n",
      "22\tValidation loss: 1.195542\tBest loss: 1.195542\tAccuracy: 75.60%\n",
      "23\tValidation loss: 1.180847\tBest loss: 1.180847\tAccuracy: 75.60%\n",
      "24\tValidation loss: 1.168655\tBest loss: 1.168655\tAccuracy: 76.40%\n",
      "25\tValidation loss: 1.153825\tBest loss: 1.153825\tAccuracy: 75.80%\n",
      "26\tValidation loss: 1.140512\tBest loss: 1.140512\tAccuracy: 76.70%\n",
      "27\tValidation loss: 1.129536\tBest loss: 1.129536\tAccuracy: 76.70%\n",
      "28\tValidation loss: 1.117056\tBest loss: 1.117056\tAccuracy: 77.20%\n",
      "29\tValidation loss: 1.107518\tBest loss: 1.107518\tAccuracy: 77.40%\n",
      "30\tValidation loss: 1.096747\tBest loss: 1.096747\tAccuracy: 77.70%\n",
      "31\tValidation loss: 1.084016\tBest loss: 1.084016\tAccuracy: 78.00%\n",
      "32\tValidation loss: 1.076516\tBest loss: 1.076516\tAccuracy: 78.50%\n",
      "33\tValidation loss: 1.066776\tBest loss: 1.066776\tAccuracy: 78.80%\n",
      "34\tValidation loss: 1.058488\tBest loss: 1.058488\tAccuracy: 78.80%\n",
      "35\tValidation loss: 1.049022\tBest loss: 1.049022\tAccuracy: 79.00%\n",
      "36\tValidation loss: 1.039774\tBest loss: 1.039774\tAccuracy: 79.40%\n",
      "37\tValidation loss: 1.034882\tBest loss: 1.034882\tAccuracy: 78.70%\n",
      "38\tValidation loss: 1.026108\tBest loss: 1.026108\tAccuracy: 80.10%\n",
      "39\tValidation loss: 1.016565\tBest loss: 1.016565\tAccuracy: 80.00%\n",
      "40\tValidation loss: 1.011603\tBest loss: 1.011603\tAccuracy: 80.00%\n",
      "41\tValidation loss: 1.005523\tBest loss: 1.005523\tAccuracy: 80.00%\n",
      "42\tValidation loss: 0.996674\tBest loss: 0.996674\tAccuracy: 80.90%\n",
      "43\tValidation loss: 0.990310\tBest loss: 0.990310\tAccuracy: 80.80%\n",
      "44\tValidation loss: 0.983526\tBest loss: 0.983526\tAccuracy: 80.80%\n",
      "45\tValidation loss: 0.978013\tBest loss: 0.978013\tAccuracy: 80.90%\n",
      "46\tValidation loss: 0.972383\tBest loss: 0.972383\tAccuracy: 81.20%\n",
      "47\tValidation loss: 0.966870\tBest loss: 0.966870\tAccuracy: 81.40%\n",
      "48\tValidation loss: 0.961695\tBest loss: 0.961695\tAccuracy: 81.10%\n",
      "49\tValidation loss: 0.956388\tBest loss: 0.956388\tAccuracy: 81.10%\n",
      "50\tValidation loss: 0.950128\tBest loss: 0.950128\tAccuracy: 81.50%\n",
      "51\tValidation loss: 0.945642\tBest loss: 0.945642\tAccuracy: 81.70%\n",
      "52\tValidation loss: 0.939935\tBest loss: 0.939935\tAccuracy: 81.40%\n",
      "53\tValidation loss: 0.935556\tBest loss: 0.935556\tAccuracy: 81.80%\n",
      "54\tValidation loss: 0.928531\tBest loss: 0.928531\tAccuracy: 81.80%\n",
      "55\tValidation loss: 0.926419\tBest loss: 0.926419\tAccuracy: 81.90%\n",
      "56\tValidation loss: 0.922287\tBest loss: 0.922287\tAccuracy: 81.60%\n",
      "57\tValidation loss: 0.917179\tBest loss: 0.917179\tAccuracy: 82.00%\n",
      "58\tValidation loss: 0.912402\tBest loss: 0.912402\tAccuracy: 82.00%\n",
      "59\tValidation loss: 0.908222\tBest loss: 0.908222\tAccuracy: 82.60%\n",
      "60\tValidation loss: 0.904060\tBest loss: 0.904060\tAccuracy: 82.40%\n",
      "61\tValidation loss: 0.900336\tBest loss: 0.900336\tAccuracy: 82.70%\n",
      "62\tValidation loss: 0.897350\tBest loss: 0.897350\tAccuracy: 82.30%\n",
      "63\tValidation loss: 0.892820\tBest loss: 0.892820\tAccuracy: 82.70%\n",
      "64\tValidation loss: 0.887504\tBest loss: 0.887504\tAccuracy: 82.70%\n",
      "65\tValidation loss: 0.884438\tBest loss: 0.884438\tAccuracy: 82.40%\n",
      "66\tValidation loss: 0.880737\tBest loss: 0.880737\tAccuracy: 82.70%\n",
      "67\tValidation loss: 0.876919\tBest loss: 0.876919\tAccuracy: 82.60%\n",
      "68\tValidation loss: 0.873590\tBest loss: 0.873590\tAccuracy: 82.70%\n",
      "69\tValidation loss: 0.870239\tBest loss: 0.870239\tAccuracy: 82.90%\n",
      "70\tValidation loss: 0.867903\tBest loss: 0.867903\tAccuracy: 82.90%\n",
      "71\tValidation loss: 0.863918\tBest loss: 0.863918\tAccuracy: 82.80%\n",
      "72\tValidation loss: 0.859961\tBest loss: 0.859961\tAccuracy: 83.00%\n",
      "73\tValidation loss: 0.856680\tBest loss: 0.856680\tAccuracy: 82.90%\n",
      "74\tValidation loss: 0.853884\tBest loss: 0.853884\tAccuracy: 83.00%\n",
      "75\tValidation loss: 0.851694\tBest loss: 0.851694\tAccuracy: 83.10%\n",
      "76\tValidation loss: 0.849282\tBest loss: 0.849282\tAccuracy: 83.00%\n",
      "77\tValidation loss: 0.845742\tBest loss: 0.845742\tAccuracy: 83.20%\n",
      "78\tValidation loss: 0.842553\tBest loss: 0.842553\tAccuracy: 82.90%\n",
      "79\tValidation loss: 0.839341\tBest loss: 0.839341\tAccuracy: 83.20%\n",
      "80\tValidation loss: 0.837614\tBest loss: 0.837614\tAccuracy: 83.10%\n",
      "81\tValidation loss: 0.834827\tBest loss: 0.834827\tAccuracy: 83.20%\n",
      "82\tValidation loss: 0.831287\tBest loss: 0.831287\tAccuracy: 83.20%\n",
      "83\tValidation loss: 0.828689\tBest loss: 0.828689\tAccuracy: 83.40%\n",
      "84\tValidation loss: 0.825366\tBest loss: 0.825366\tAccuracy: 83.30%\n",
      "85\tValidation loss: 0.822360\tBest loss: 0.822360\tAccuracy: 83.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\tValidation loss: 0.821198\tBest loss: 0.821198\tAccuracy: 83.70%\n",
      "87\tValidation loss: 0.818794\tBest loss: 0.818794\tAccuracy: 83.40%\n",
      "88\tValidation loss: 0.816010\tBest loss: 0.816010\tAccuracy: 83.50%\n",
      "89\tValidation loss: 0.813952\tBest loss: 0.813952\tAccuracy: 83.60%\n",
      "90\tValidation loss: 0.811988\tBest loss: 0.811988\tAccuracy: 83.30%\n",
      "91\tValidation loss: 0.807741\tBest loss: 0.807741\tAccuracy: 83.80%\n",
      "92\tValidation loss: 0.806107\tBest loss: 0.806107\tAccuracy: 83.90%\n",
      "93\tValidation loss: 0.804454\tBest loss: 0.804454\tAccuracy: 83.90%\n",
      "94\tValidation loss: 0.802264\tBest loss: 0.802264\tAccuracy: 83.60%\n",
      "95\tValidation loss: 0.799910\tBest loss: 0.799910\tAccuracy: 83.70%\n",
      "96\tValidation loss: 0.797815\tBest loss: 0.797815\tAccuracy: 84.00%\n",
      "97\tValidation loss: 0.795702\tBest loss: 0.795702\tAccuracy: 84.10%\n",
      "98\tValidation loss: 0.793026\tBest loss: 0.793026\tAccuracy: 83.80%\n",
      "99\tValidation loss: 0.790496\tBest loss: 0.790496\tAccuracy: 84.00%\n",
      "100\tValidation loss: 0.788778\tBest loss: 0.788778\tAccuracy: 84.10%\n",
      "101\tValidation loss: 0.786021\tBest loss: 0.786021\tAccuracy: 83.90%\n",
      "102\tValidation loss: 0.784196\tBest loss: 0.784196\tAccuracy: 84.10%\n",
      "103\tValidation loss: 0.782251\tBest loss: 0.782251\tAccuracy: 84.00%\n",
      "104\tValidation loss: 0.781389\tBest loss: 0.781389\tAccuracy: 84.40%\n",
      "105\tValidation loss: 0.779100\tBest loss: 0.779100\tAccuracy: 84.20%\n",
      "106\tValidation loss: 0.777163\tBest loss: 0.777163\tAccuracy: 84.20%\n",
      "107\tValidation loss: 0.775249\tBest loss: 0.775249\tAccuracy: 84.10%\n",
      "108\tValidation loss: 0.772898\tBest loss: 0.772898\tAccuracy: 84.20%\n",
      "109\tValidation loss: 0.771593\tBest loss: 0.771593\tAccuracy: 84.30%\n",
      "110\tValidation loss: 0.769416\tBest loss: 0.769416\tAccuracy: 84.40%\n",
      "111\tValidation loss: 0.767136\tBest loss: 0.767136\tAccuracy: 84.40%\n",
      "112\tValidation loss: 0.765541\tBest loss: 0.765541\tAccuracy: 84.60%\n",
      "113\tValidation loss: 0.763399\tBest loss: 0.763399\tAccuracy: 84.70%\n",
      "114\tValidation loss: 0.761818\tBest loss: 0.761818\tAccuracy: 84.60%\n",
      "115\tValidation loss: 0.761049\tBest loss: 0.761049\tAccuracy: 84.60%\n",
      "116\tValidation loss: 0.759077\tBest loss: 0.759077\tAccuracy: 84.70%\n",
      "117\tValidation loss: 0.756367\tBest loss: 0.756367\tAccuracy: 84.60%\n",
      "118\tValidation loss: 0.755257\tBest loss: 0.755257\tAccuracy: 85.00%\n",
      "119\tValidation loss: 0.753367\tBest loss: 0.753367\tAccuracy: 84.80%\n",
      "120\tValidation loss: 0.752068\tBest loss: 0.752068\tAccuracy: 84.80%\n",
      "121\tValidation loss: 0.751366\tBest loss: 0.751366\tAccuracy: 84.80%\n",
      "122\tValidation loss: 0.749427\tBest loss: 0.749427\tAccuracy: 84.80%\n",
      "123\tValidation loss: 0.747421\tBest loss: 0.747421\tAccuracy: 84.80%\n",
      "124\tValidation loss: 0.745922\tBest loss: 0.745922\tAccuracy: 84.60%\n",
      "125\tValidation loss: 0.744728\tBest loss: 0.744728\tAccuracy: 84.80%\n",
      "126\tValidation loss: 0.742562\tBest loss: 0.742562\tAccuracy: 84.90%\n",
      "127\tValidation loss: 0.741193\tBest loss: 0.741193\tAccuracy: 84.90%\n",
      "128\tValidation loss: 0.739202\tBest loss: 0.739202\tAccuracy: 84.90%\n",
      "129\tValidation loss: 0.738392\tBest loss: 0.738392\tAccuracy: 84.80%\n",
      "130\tValidation loss: 0.737188\tBest loss: 0.737188\tAccuracy: 84.90%\n",
      "131\tValidation loss: 0.735496\tBest loss: 0.735496\tAccuracy: 85.00%\n",
      "132\tValidation loss: 0.733930\tBest loss: 0.733930\tAccuracy: 85.10%\n",
      "133\tValidation loss: 0.732800\tBest loss: 0.732800\tAccuracy: 85.00%\n",
      "134\tValidation loss: 0.731160\tBest loss: 0.731160\tAccuracy: 85.10%\n",
      "135\tValidation loss: 0.730841\tBest loss: 0.730841\tAccuracy: 85.00%\n",
      "136\tValidation loss: 0.728108\tBest loss: 0.728108\tAccuracy: 85.00%\n",
      "137\tValidation loss: 0.726446\tBest loss: 0.726446\tAccuracy: 85.20%\n",
      "138\tValidation loss: 0.725362\tBest loss: 0.725362\tAccuracy: 85.20%\n",
      "139\tValidation loss: 0.724062\tBest loss: 0.724062\tAccuracy: 85.00%\n",
      "140\tValidation loss: 0.722346\tBest loss: 0.722346\tAccuracy: 85.20%\n",
      "141\tValidation loss: 0.721689\tBest loss: 0.721689\tAccuracy: 85.20%\n",
      "142\tValidation loss: 0.720504\tBest loss: 0.720504\tAccuracy: 85.30%\n",
      "143\tValidation loss: 0.718784\tBest loss: 0.718784\tAccuracy: 85.30%\n",
      "144\tValidation loss: 0.717312\tBest loss: 0.717312\tAccuracy: 85.20%\n",
      "145\tValidation loss: 0.716394\tBest loss: 0.716394\tAccuracy: 85.60%\n",
      "146\tValidation loss: 0.715222\tBest loss: 0.715222\tAccuracy: 85.20%\n",
      "147\tValidation loss: 0.713138\tBest loss: 0.713138\tAccuracy: 85.50%\n",
      "148\tValidation loss: 0.712390\tBest loss: 0.712390\tAccuracy: 85.40%\n",
      "149\tValidation loss: 0.711367\tBest loss: 0.711367\tAccuracy: 85.50%\n",
      "150\tValidation loss: 0.710658\tBest loss: 0.710658\tAccuracy: 85.30%\n",
      "151\tValidation loss: 0.709091\tBest loss: 0.709091\tAccuracy: 85.70%\n",
      "152\tValidation loss: 0.707888\tBest loss: 0.707888\tAccuracy: 85.50%\n",
      "153\tValidation loss: 0.706611\tBest loss: 0.706611\tAccuracy: 85.50%\n",
      "154\tValidation loss: 0.705390\tBest loss: 0.705390\tAccuracy: 85.40%\n",
      "155\tValidation loss: 0.704813\tBest loss: 0.704813\tAccuracy: 85.70%\n",
      "156\tValidation loss: 0.702944\tBest loss: 0.702944\tAccuracy: 85.60%\n",
      "157\tValidation loss: 0.702324\tBest loss: 0.702324\tAccuracy: 85.60%\n",
      "158\tValidation loss: 0.700750\tBest loss: 0.700750\tAccuracy: 85.60%\n",
      "159\tValidation loss: 0.699236\tBest loss: 0.699236\tAccuracy: 85.60%\n",
      "160\tValidation loss: 0.698774\tBest loss: 0.698774\tAccuracy: 85.60%\n",
      "161\tValidation loss: 0.697635\tBest loss: 0.697635\tAccuracy: 85.40%\n",
      "162\tValidation loss: 0.696545\tBest loss: 0.696545\tAccuracy: 85.60%\n",
      "163\tValidation loss: 0.695807\tBest loss: 0.695807\tAccuracy: 85.80%\n",
      "164\tValidation loss: 0.693752\tBest loss: 0.693752\tAccuracy: 85.70%\n",
      "165\tValidation loss: 0.693173\tBest loss: 0.693173\tAccuracy: 85.70%\n",
      "166\tValidation loss: 0.692298\tBest loss: 0.692298\tAccuracy: 85.90%\n",
      "167\tValidation loss: 0.691211\tBest loss: 0.691211\tAccuracy: 85.60%\n",
      "168\tValidation loss: 0.690478\tBest loss: 0.690478\tAccuracy: 85.90%\n",
      "169\tValidation loss: 0.689155\tBest loss: 0.689155\tAccuracy: 85.70%\n",
      "170\tValidation loss: 0.688281\tBest loss: 0.688281\tAccuracy: 85.90%\n",
      "171\tValidation loss: 0.687307\tBest loss: 0.687307\tAccuracy: 85.90%\n",
      "172\tValidation loss: 0.685749\tBest loss: 0.685749\tAccuracy: 85.70%\n",
      "173\tValidation loss: 0.685385\tBest loss: 0.685385\tAccuracy: 85.80%\n",
      "174\tValidation loss: 0.684035\tBest loss: 0.684035\tAccuracy: 86.00%\n",
      "175\tValidation loss: 0.682713\tBest loss: 0.682713\tAccuracy: 86.00%\n",
      "176\tValidation loss: 0.682173\tBest loss: 0.682173\tAccuracy: 86.00%\n",
      "177\tValidation loss: 0.680653\tBest loss: 0.680653\tAccuracy: 86.00%\n",
      "178\tValidation loss: 0.680018\tBest loss: 0.680018\tAccuracy: 86.30%\n",
      "179\tValidation loss: 0.678865\tBest loss: 0.678865\tAccuracy: 86.00%\n",
      "180\tValidation loss: 0.678030\tBest loss: 0.678030\tAccuracy: 86.20%\n",
      "181\tValidation loss: 0.677627\tBest loss: 0.677627\tAccuracy: 86.00%\n",
      "182\tValidation loss: 0.676709\tBest loss: 0.676709\tAccuracy: 86.10%\n",
      "183\tValidation loss: 0.675659\tBest loss: 0.675659\tAccuracy: 86.20%\n",
      "184\tValidation loss: 0.674573\tBest loss: 0.674573\tAccuracy: 86.40%\n",
      "185\tValidation loss: 0.673709\tBest loss: 0.673709\tAccuracy: 86.60%\n",
      "186\tValidation loss: 0.672807\tBest loss: 0.672807\tAccuracy: 86.40%\n",
      "187\tValidation loss: 0.671353\tBest loss: 0.671353\tAccuracy: 86.40%\n",
      "188\tValidation loss: 0.670737\tBest loss: 0.670737\tAccuracy: 86.50%\n",
      "189\tValidation loss: 0.669994\tBest loss: 0.669994\tAccuracy: 86.40%\n",
      "190\tValidation loss: 0.669232\tBest loss: 0.669232\tAccuracy: 86.40%\n",
      "191\tValidation loss: 0.667813\tBest loss: 0.667813\tAccuracy: 86.50%\n",
      "192\tValidation loss: 0.666617\tBest loss: 0.666617\tAccuracy: 86.40%\n",
      "193\tValidation loss: 0.665964\tBest loss: 0.665964\tAccuracy: 86.60%\n",
      "194\tValidation loss: 0.665324\tBest loss: 0.665324\tAccuracy: 86.60%\n",
      "195\tValidation loss: 0.664596\tBest loss: 0.664596\tAccuracy: 86.70%\n",
      "196\tValidation loss: 0.663615\tBest loss: 0.663615\tAccuracy: 86.50%\n",
      "197\tValidation loss: 0.662573\tBest loss: 0.662573\tAccuracy: 86.70%\n",
      "198\tValidation loss: 0.661664\tBest loss: 0.661664\tAccuracy: 86.80%\n",
      "199\tValidation loss: 0.661271\tBest loss: 0.661271\tAccuracy: 86.80%\n",
      "200\tValidation loss: 0.660920\tBest loss: 0.660920\tAccuracy: 86.50%\n",
      "201\tValidation loss: 0.659854\tBest loss: 0.659854\tAccuracy: 86.60%\n",
      "202\tValidation loss: 0.658876\tBest loss: 0.658876\tAccuracy: 86.70%\n",
      "203\tValidation loss: 0.658607\tBest loss: 0.658607\tAccuracy: 86.70%\n",
      "204\tValidation loss: 0.657854\tBest loss: 0.657854\tAccuracy: 86.80%\n",
      "205\tValidation loss: 0.656895\tBest loss: 0.656895\tAccuracy: 86.90%\n",
      "206\tValidation loss: 0.655652\tBest loss: 0.655652\tAccuracy: 86.70%\n",
      "207\tValidation loss: 0.655496\tBest loss: 0.655496\tAccuracy: 86.50%\n",
      "208\tValidation loss: 0.654562\tBest loss: 0.654562\tAccuracy: 86.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\tValidation loss: 0.653393\tBest loss: 0.653393\tAccuracy: 86.80%\n",
      "210\tValidation loss: 0.652400\tBest loss: 0.652400\tAccuracy: 86.90%\n",
      "211\tValidation loss: 0.651764\tBest loss: 0.651764\tAccuracy: 86.90%\n",
      "212\tValidation loss: 0.650955\tBest loss: 0.650955\tAccuracy: 86.80%\n",
      "213\tValidation loss: 0.649853\tBest loss: 0.649853\tAccuracy: 86.80%\n",
      "214\tValidation loss: 0.649063\tBest loss: 0.649063\tAccuracy: 86.80%\n",
      "215\tValidation loss: 0.648378\tBest loss: 0.648378\tAccuracy: 86.70%\n",
      "216\tValidation loss: 0.647680\tBest loss: 0.647680\tAccuracy: 86.70%\n",
      "217\tValidation loss: 0.647043\tBest loss: 0.647043\tAccuracy: 86.60%\n",
      "218\tValidation loss: 0.646688\tBest loss: 0.646688\tAccuracy: 86.70%\n",
      "219\tValidation loss: 0.645829\tBest loss: 0.645829\tAccuracy: 86.80%\n",
      "220\tValidation loss: 0.644733\tBest loss: 0.644733\tAccuracy: 86.80%\n",
      "221\tValidation loss: 0.644803\tBest loss: 0.644733\tAccuracy: 86.80%\n",
      "222\tValidation loss: 0.643808\tBest loss: 0.643808\tAccuracy: 86.70%\n",
      "223\tValidation loss: 0.643125\tBest loss: 0.643125\tAccuracy: 86.90%\n",
      "224\tValidation loss: 0.642270\tBest loss: 0.642270\tAccuracy: 87.00%\n",
      "225\tValidation loss: 0.641795\tBest loss: 0.641795\tAccuracy: 86.90%\n",
      "226\tValidation loss: 0.640737\tBest loss: 0.640737\tAccuracy: 86.60%\n",
      "227\tValidation loss: 0.639861\tBest loss: 0.639861\tAccuracy: 86.70%\n",
      "228\tValidation loss: 0.639272\tBest loss: 0.639272\tAccuracy: 86.80%\n",
      "229\tValidation loss: 0.638980\tBest loss: 0.638980\tAccuracy: 86.80%\n",
      "230\tValidation loss: 0.638407\tBest loss: 0.638407\tAccuracy: 86.70%\n",
      "231\tValidation loss: 0.637793\tBest loss: 0.637793\tAccuracy: 86.80%\n",
      "232\tValidation loss: 0.636852\tBest loss: 0.636852\tAccuracy: 86.60%\n",
      "233\tValidation loss: 0.636279\tBest loss: 0.636279\tAccuracy: 86.60%\n",
      "234\tValidation loss: 0.635360\tBest loss: 0.635360\tAccuracy: 86.80%\n",
      "235\tValidation loss: 0.634851\tBest loss: 0.634851\tAccuracy: 86.90%\n",
      "236\tValidation loss: 0.634752\tBest loss: 0.634752\tAccuracy: 86.80%\n",
      "237\tValidation loss: 0.633669\tBest loss: 0.633669\tAccuracy: 86.90%\n",
      "238\tValidation loss: 0.633037\tBest loss: 0.633037\tAccuracy: 86.90%\n",
      "239\tValidation loss: 0.632343\tBest loss: 0.632343\tAccuracy: 86.90%\n",
      "240\tValidation loss: 0.632000\tBest loss: 0.632000\tAccuracy: 86.90%\n",
      "241\tValidation loss: 0.631260\tBest loss: 0.631260\tAccuracy: 86.90%\n",
      "242\tValidation loss: 0.630223\tBest loss: 0.630223\tAccuracy: 86.90%\n",
      "243\tValidation loss: 0.629470\tBest loss: 0.629470\tAccuracy: 86.90%\n",
      "244\tValidation loss: 0.628986\tBest loss: 0.628986\tAccuracy: 87.00%\n",
      "245\tValidation loss: 0.628375\tBest loss: 0.628375\tAccuracy: 87.10%\n",
      "246\tValidation loss: 0.627529\tBest loss: 0.627529\tAccuracy: 86.90%\n",
      "247\tValidation loss: 0.627362\tBest loss: 0.627362\tAccuracy: 87.10%\n",
      "248\tValidation loss: 0.626597\tBest loss: 0.626597\tAccuracy: 87.20%\n",
      "249\tValidation loss: 0.625697\tBest loss: 0.625697\tAccuracy: 86.90%\n",
      "250\tValidation loss: 0.625175\tBest loss: 0.625175\tAccuracy: 86.90%\n",
      "251\tValidation loss: 0.624895\tBest loss: 0.624895\tAccuracy: 86.90%\n",
      "252\tValidation loss: 0.624235\tBest loss: 0.624235\tAccuracy: 87.10%\n",
      "253\tValidation loss: 0.623642\tBest loss: 0.623642\tAccuracy: 87.10%\n",
      "254\tValidation loss: 0.623085\tBest loss: 0.623085\tAccuracy: 86.90%\n",
      "255\tValidation loss: 0.622520\tBest loss: 0.622520\tAccuracy: 86.80%\n",
      "256\tValidation loss: 0.621866\tBest loss: 0.621866\tAccuracy: 86.80%\n",
      "257\tValidation loss: 0.621349\tBest loss: 0.621349\tAccuracy: 86.90%\n",
      "258\tValidation loss: 0.620710\tBest loss: 0.620710\tAccuracy: 87.00%\n",
      "259\tValidation loss: 0.619987\tBest loss: 0.619987\tAccuracy: 87.00%\n",
      "260\tValidation loss: 0.619389\tBest loss: 0.619389\tAccuracy: 87.10%\n",
      "261\tValidation loss: 0.618789\tBest loss: 0.618789\tAccuracy: 87.00%\n",
      "262\tValidation loss: 0.618590\tBest loss: 0.618590\tAccuracy: 87.10%\n",
      "263\tValidation loss: 0.618096\tBest loss: 0.618096\tAccuracy: 86.90%\n",
      "264\tValidation loss: 0.617644\tBest loss: 0.617644\tAccuracy: 87.00%\n",
      "265\tValidation loss: 0.617052\tBest loss: 0.617052\tAccuracy: 87.00%\n",
      "266\tValidation loss: 0.616516\tBest loss: 0.616516\tAccuracy: 87.20%\n",
      "267\tValidation loss: 0.616188\tBest loss: 0.616188\tAccuracy: 87.10%\n",
      "268\tValidation loss: 0.616012\tBest loss: 0.616012\tAccuracy: 87.10%\n",
      "269\tValidation loss: 0.615166\tBest loss: 0.615166\tAccuracy: 87.00%\n",
      "270\tValidation loss: 0.614423\tBest loss: 0.614423\tAccuracy: 87.00%\n",
      "271\tValidation loss: 0.613688\tBest loss: 0.613688\tAccuracy: 86.90%\n",
      "272\tValidation loss: 0.613013\tBest loss: 0.613013\tAccuracy: 87.10%\n",
      "273\tValidation loss: 0.612712\tBest loss: 0.612712\tAccuracy: 87.10%\n",
      "274\tValidation loss: 0.612231\tBest loss: 0.612231\tAccuracy: 87.10%\n",
      "275\tValidation loss: 0.611404\tBest loss: 0.611404\tAccuracy: 87.40%\n",
      "276\tValidation loss: 0.611026\tBest loss: 0.611026\tAccuracy: 87.50%\n",
      "277\tValidation loss: 0.610443\tBest loss: 0.610443\tAccuracy: 87.40%\n",
      "278\tValidation loss: 0.609779\tBest loss: 0.609779\tAccuracy: 87.10%\n",
      "279\tValidation loss: 0.608847\tBest loss: 0.608847\tAccuracy: 87.20%\n",
      "280\tValidation loss: 0.609047\tBest loss: 0.608847\tAccuracy: 87.10%\n",
      "281\tValidation loss: 0.608501\tBest loss: 0.608501\tAccuracy: 87.40%\n",
      "282\tValidation loss: 0.607843\tBest loss: 0.607843\tAccuracy: 87.40%\n",
      "283\tValidation loss: 0.607340\tBest loss: 0.607340\tAccuracy: 87.40%\n",
      "284\tValidation loss: 0.607072\tBest loss: 0.607072\tAccuracy: 87.40%\n",
      "285\tValidation loss: 0.606759\tBest loss: 0.606759\tAccuracy: 87.30%\n",
      "286\tValidation loss: 0.606229\tBest loss: 0.606229\tAccuracy: 87.50%\n",
      "287\tValidation loss: 0.605830\tBest loss: 0.605830\tAccuracy: 87.40%\n",
      "288\tValidation loss: 0.605189\tBest loss: 0.605189\tAccuracy: 87.50%\n",
      "289\tValidation loss: 0.604603\tBest loss: 0.604603\tAccuracy: 87.60%\n",
      "290\tValidation loss: 0.604032\tBest loss: 0.604032\tAccuracy: 87.60%\n",
      "291\tValidation loss: 0.603556\tBest loss: 0.603556\tAccuracy: 87.30%\n",
      "292\tValidation loss: 0.603050\tBest loss: 0.603050\tAccuracy: 87.50%\n",
      "293\tValidation loss: 0.602430\tBest loss: 0.602430\tAccuracy: 87.50%\n",
      "294\tValidation loss: 0.602206\tBest loss: 0.602206\tAccuracy: 87.50%\n",
      "295\tValidation loss: 0.601825\tBest loss: 0.601825\tAccuracy: 87.70%\n",
      "296\tValidation loss: 0.601119\tBest loss: 0.601119\tAccuracy: 87.60%\n",
      "297\tValidation loss: 0.600767\tBest loss: 0.600767\tAccuracy: 87.60%\n",
      "298\tValidation loss: 0.600453\tBest loss: 0.600453\tAccuracy: 87.70%\n",
      "299\tValidation loss: 0.599882\tBest loss: 0.599882\tAccuracy: 87.60%\n",
      "300\tValidation loss: 0.599679\tBest loss: 0.599679\tAccuracy: 87.50%\n",
      "301\tValidation loss: 0.599130\tBest loss: 0.599130\tAccuracy: 87.70%\n",
      "302\tValidation loss: 0.598443\tBest loss: 0.598443\tAccuracy: 87.70%\n",
      "303\tValidation loss: 0.597800\tBest loss: 0.597800\tAccuracy: 87.60%\n",
      "304\tValidation loss: 0.597806\tBest loss: 0.597800\tAccuracy: 87.60%\n",
      "305\tValidation loss: 0.596920\tBest loss: 0.596920\tAccuracy: 87.60%\n",
      "306\tValidation loss: 0.596703\tBest loss: 0.596703\tAccuracy: 87.70%\n",
      "307\tValidation loss: 0.596163\tBest loss: 0.596163\tAccuracy: 87.70%\n",
      "308\tValidation loss: 0.595521\tBest loss: 0.595521\tAccuracy: 87.90%\n",
      "309\tValidation loss: 0.595159\tBest loss: 0.595159\tAccuracy: 87.80%\n",
      "310\tValidation loss: 0.594710\tBest loss: 0.594710\tAccuracy: 87.90%\n",
      "311\tValidation loss: 0.594378\tBest loss: 0.594378\tAccuracy: 87.60%\n",
      "312\tValidation loss: 0.594062\tBest loss: 0.594062\tAccuracy: 87.70%\n",
      "313\tValidation loss: 0.593280\tBest loss: 0.593280\tAccuracy: 87.90%\n",
      "314\tValidation loss: 0.593188\tBest loss: 0.593188\tAccuracy: 87.70%\n",
      "315\tValidation loss: 0.592586\tBest loss: 0.592586\tAccuracy: 87.70%\n",
      "316\tValidation loss: 0.591851\tBest loss: 0.591851\tAccuracy: 87.70%\n",
      "317\tValidation loss: 0.591837\tBest loss: 0.591837\tAccuracy: 87.70%\n",
      "318\tValidation loss: 0.591384\tBest loss: 0.591384\tAccuracy: 87.70%\n",
      "319\tValidation loss: 0.591191\tBest loss: 0.591191\tAccuracy: 87.70%\n",
      "320\tValidation loss: 0.590680\tBest loss: 0.590680\tAccuracy: 87.80%\n",
      "321\tValidation loss: 0.589876\tBest loss: 0.589876\tAccuracy: 87.90%\n",
      "322\tValidation loss: 0.589293\tBest loss: 0.589293\tAccuracy: 88.00%\n",
      "323\tValidation loss: 0.588798\tBest loss: 0.588798\tAccuracy: 88.10%\n",
      "324\tValidation loss: 0.588117\tBest loss: 0.588117\tAccuracy: 88.00%\n",
      "325\tValidation loss: 0.587980\tBest loss: 0.587980\tAccuracy: 88.00%\n",
      "326\tValidation loss: 0.587970\tBest loss: 0.587970\tAccuracy: 87.90%\n",
      "327\tValidation loss: 0.587494\tBest loss: 0.587494\tAccuracy: 88.10%\n",
      "328\tValidation loss: 0.587339\tBest loss: 0.587339\tAccuracy: 87.90%\n",
      "329\tValidation loss: 0.586895\tBest loss: 0.586895\tAccuracy: 88.00%\n",
      "330\tValidation loss: 0.586500\tBest loss: 0.586500\tAccuracy: 87.90%\n",
      "331\tValidation loss: 0.586046\tBest loss: 0.586046\tAccuracy: 87.90%\n",
      "332\tValidation loss: 0.585669\tBest loss: 0.585669\tAccuracy: 88.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\tValidation loss: 0.585128\tBest loss: 0.585128\tAccuracy: 88.10%\n",
      "334\tValidation loss: 0.584916\tBest loss: 0.584916\tAccuracy: 87.80%\n",
      "335\tValidation loss: 0.584450\tBest loss: 0.584450\tAccuracy: 87.90%\n",
      "336\tValidation loss: 0.583715\tBest loss: 0.583715\tAccuracy: 88.00%\n",
      "337\tValidation loss: 0.583583\tBest loss: 0.583583\tAccuracy: 88.00%\n",
      "338\tValidation loss: 0.582999\tBest loss: 0.582999\tAccuracy: 88.10%\n",
      "339\tValidation loss: 0.582784\tBest loss: 0.582784\tAccuracy: 87.90%\n",
      "340\tValidation loss: 0.582240\tBest loss: 0.582240\tAccuracy: 88.20%\n",
      "341\tValidation loss: 0.582099\tBest loss: 0.582099\tAccuracy: 87.90%\n",
      "342\tValidation loss: 0.581445\tBest loss: 0.581445\tAccuracy: 88.20%\n",
      "343\tValidation loss: 0.581207\tBest loss: 0.581207\tAccuracy: 87.90%\n",
      "344\tValidation loss: 0.580952\tBest loss: 0.580952\tAccuracy: 88.10%\n",
      "345\tValidation loss: 0.580453\tBest loss: 0.580453\tAccuracy: 88.20%\n",
      "346\tValidation loss: 0.579923\tBest loss: 0.579923\tAccuracy: 88.20%\n",
      "347\tValidation loss: 0.579860\tBest loss: 0.579860\tAccuracy: 88.10%\n",
      "348\tValidation loss: 0.579665\tBest loss: 0.579665\tAccuracy: 88.20%\n",
      "349\tValidation loss: 0.579256\tBest loss: 0.579256\tAccuracy: 88.10%\n",
      "350\tValidation loss: 0.578559\tBest loss: 0.578559\tAccuracy: 88.10%\n",
      "351\tValidation loss: 0.578341\tBest loss: 0.578341\tAccuracy: 88.20%\n",
      "352\tValidation loss: 0.577878\tBest loss: 0.577878\tAccuracy: 88.10%\n",
      "353\tValidation loss: 0.577506\tBest loss: 0.577506\tAccuracy: 88.10%\n",
      "354\tValidation loss: 0.577277\tBest loss: 0.577277\tAccuracy: 88.00%\n",
      "355\tValidation loss: 0.576698\tBest loss: 0.576698\tAccuracy: 88.10%\n",
      "356\tValidation loss: 0.576510\tBest loss: 0.576510\tAccuracy: 88.10%\n",
      "357\tValidation loss: 0.575725\tBest loss: 0.575725\tAccuracy: 88.20%\n",
      "358\tValidation loss: 0.575683\tBest loss: 0.575683\tAccuracy: 88.30%\n",
      "359\tValidation loss: 0.575578\tBest loss: 0.575578\tAccuracy: 88.20%\n",
      "360\tValidation loss: 0.575206\tBest loss: 0.575206\tAccuracy: 88.10%\n",
      "361\tValidation loss: 0.574715\tBest loss: 0.574715\tAccuracy: 88.20%\n",
      "362\tValidation loss: 0.574197\tBest loss: 0.574197\tAccuracy: 88.20%\n",
      "363\tValidation loss: 0.573891\tBest loss: 0.573891\tAccuracy: 88.10%\n",
      "364\tValidation loss: 0.573617\tBest loss: 0.573617\tAccuracy: 88.10%\n",
      "365\tValidation loss: 0.573323\tBest loss: 0.573323\tAccuracy: 88.20%\n",
      "366\tValidation loss: 0.572646\tBest loss: 0.572646\tAccuracy: 88.30%\n",
      "367\tValidation loss: 0.572098\tBest loss: 0.572098\tAccuracy: 88.20%\n",
      "368\tValidation loss: 0.571997\tBest loss: 0.571997\tAccuracy: 88.20%\n",
      "369\tValidation loss: 0.571598\tBest loss: 0.571598\tAccuracy: 88.30%\n",
      "370\tValidation loss: 0.571310\tBest loss: 0.571310\tAccuracy: 88.20%\n",
      "371\tValidation loss: 0.570893\tBest loss: 0.570893\tAccuracy: 88.30%\n",
      "372\tValidation loss: 0.570531\tBest loss: 0.570531\tAccuracy: 88.30%\n",
      "373\tValidation loss: 0.570563\tBest loss: 0.570531\tAccuracy: 88.20%\n",
      "374\tValidation loss: 0.570065\tBest loss: 0.570065\tAccuracy: 88.20%\n",
      "375\tValidation loss: 0.569620\tBest loss: 0.569620\tAccuracy: 88.20%\n",
      "376\tValidation loss: 0.569444\tBest loss: 0.569444\tAccuracy: 88.30%\n",
      "377\tValidation loss: 0.569324\tBest loss: 0.569324\tAccuracy: 88.10%\n",
      "378\tValidation loss: 0.568759\tBest loss: 0.568759\tAccuracy: 88.20%\n",
      "379\tValidation loss: 0.568275\tBest loss: 0.568275\tAccuracy: 88.20%\n",
      "380\tValidation loss: 0.567944\tBest loss: 0.567944\tAccuracy: 88.20%\n",
      "381\tValidation loss: 0.567631\tBest loss: 0.567631\tAccuracy: 88.30%\n",
      "382\tValidation loss: 0.567406\tBest loss: 0.567406\tAccuracy: 88.20%\n",
      "383\tValidation loss: 0.566982\tBest loss: 0.566982\tAccuracy: 88.20%\n",
      "384\tValidation loss: 0.566817\tBest loss: 0.566817\tAccuracy: 88.20%\n",
      "385\tValidation loss: 0.566263\tBest loss: 0.566263\tAccuracy: 88.20%\n",
      "386\tValidation loss: 0.566116\tBest loss: 0.566116\tAccuracy: 88.30%\n",
      "387\tValidation loss: 0.565765\tBest loss: 0.565765\tAccuracy: 88.20%\n",
      "388\tValidation loss: 0.565270\tBest loss: 0.565270\tAccuracy: 88.20%\n",
      "389\tValidation loss: 0.565080\tBest loss: 0.565080\tAccuracy: 88.20%\n",
      "390\tValidation loss: 0.564651\tBest loss: 0.564651\tAccuracy: 88.20%\n",
      "391\tValidation loss: 0.564421\tBest loss: 0.564421\tAccuracy: 88.20%\n",
      "392\tValidation loss: 0.564038\tBest loss: 0.564038\tAccuracy: 88.20%\n",
      "393\tValidation loss: 0.563759\tBest loss: 0.563759\tAccuracy: 88.20%\n",
      "394\tValidation loss: 0.563379\tBest loss: 0.563379\tAccuracy: 88.20%\n",
      "395\tValidation loss: 0.563334\tBest loss: 0.563334\tAccuracy: 88.20%\n",
      "396\tValidation loss: 0.563049\tBest loss: 0.563049\tAccuracy: 88.20%\n",
      "397\tValidation loss: 0.562603\tBest loss: 0.562603\tAccuracy: 88.20%\n",
      "398\tValidation loss: 0.562257\tBest loss: 0.562257\tAccuracy: 88.20%\n",
      "399\tValidation loss: 0.561888\tBest loss: 0.561888\tAccuracy: 88.30%\n",
      "400\tValidation loss: 0.561676\tBest loss: 0.561676\tAccuracy: 88.20%\n",
      "401\tValidation loss: 0.561528\tBest loss: 0.561528\tAccuracy: 88.20%\n",
      "402\tValidation loss: 0.561105\tBest loss: 0.561105\tAccuracy: 88.20%\n",
      "403\tValidation loss: 0.560746\tBest loss: 0.560746\tAccuracy: 88.20%\n",
      "404\tValidation loss: 0.560476\tBest loss: 0.560476\tAccuracy: 88.30%\n",
      "405\tValidation loss: 0.560359\tBest loss: 0.560359\tAccuracy: 88.30%\n",
      "406\tValidation loss: 0.560091\tBest loss: 0.560091\tAccuracy: 88.30%\n",
      "407\tValidation loss: 0.559616\tBest loss: 0.559616\tAccuracy: 88.20%\n",
      "408\tValidation loss: 0.558963\tBest loss: 0.558963\tAccuracy: 88.30%\n",
      "409\tValidation loss: 0.558705\tBest loss: 0.558705\tAccuracy: 88.30%\n",
      "410\tValidation loss: 0.558498\tBest loss: 0.558498\tAccuracy: 88.30%\n",
      "411\tValidation loss: 0.558453\tBest loss: 0.558453\tAccuracy: 88.30%\n",
      "412\tValidation loss: 0.557941\tBest loss: 0.557941\tAccuracy: 88.30%\n",
      "413\tValidation loss: 0.557582\tBest loss: 0.557582\tAccuracy: 88.30%\n",
      "414\tValidation loss: 0.557406\tBest loss: 0.557406\tAccuracy: 88.30%\n",
      "415\tValidation loss: 0.557232\tBest loss: 0.557232\tAccuracy: 88.30%\n",
      "416\tValidation loss: 0.556939\tBest loss: 0.556939\tAccuracy: 88.30%\n",
      "417\tValidation loss: 0.556442\tBest loss: 0.556442\tAccuracy: 88.30%\n",
      "418\tValidation loss: 0.556105\tBest loss: 0.556105\tAccuracy: 88.30%\n",
      "419\tValidation loss: 0.555858\tBest loss: 0.555858\tAccuracy: 88.30%\n",
      "420\tValidation loss: 0.555765\tBest loss: 0.555765\tAccuracy: 88.30%\n",
      "421\tValidation loss: 0.555443\tBest loss: 0.555443\tAccuracy: 88.30%\n",
      "422\tValidation loss: 0.555206\tBest loss: 0.555206\tAccuracy: 88.30%\n",
      "423\tValidation loss: 0.555046\tBest loss: 0.555046\tAccuracy: 88.30%\n",
      "424\tValidation loss: 0.554679\tBest loss: 0.554679\tAccuracy: 88.30%\n",
      "425\tValidation loss: 0.554431\tBest loss: 0.554431\tAccuracy: 88.50%\n",
      "426\tValidation loss: 0.554122\tBest loss: 0.554122\tAccuracy: 88.30%\n",
      "427\tValidation loss: 0.553698\tBest loss: 0.553698\tAccuracy: 88.30%\n",
      "428\tValidation loss: 0.553236\tBest loss: 0.553236\tAccuracy: 88.30%\n",
      "429\tValidation loss: 0.553150\tBest loss: 0.553150\tAccuracy: 88.30%\n",
      "430\tValidation loss: 0.552700\tBest loss: 0.552700\tAccuracy: 88.30%\n",
      "431\tValidation loss: 0.552587\tBest loss: 0.552587\tAccuracy: 88.30%\n",
      "432\tValidation loss: 0.552385\tBest loss: 0.552385\tAccuracy: 88.30%\n",
      "433\tValidation loss: 0.552010\tBest loss: 0.552010\tAccuracy: 88.30%\n",
      "434\tValidation loss: 0.551764\tBest loss: 0.551764\tAccuracy: 88.30%\n",
      "435\tValidation loss: 0.551510\tBest loss: 0.551510\tAccuracy: 88.30%\n",
      "436\tValidation loss: 0.551522\tBest loss: 0.551510\tAccuracy: 88.30%\n",
      "437\tValidation loss: 0.551184\tBest loss: 0.551184\tAccuracy: 88.30%\n",
      "438\tValidation loss: 0.550672\tBest loss: 0.550672\tAccuracy: 88.40%\n",
      "439\tValidation loss: 0.550484\tBest loss: 0.550484\tAccuracy: 88.40%\n",
      "440\tValidation loss: 0.550186\tBest loss: 0.550186\tAccuracy: 88.30%\n",
      "441\tValidation loss: 0.549980\tBest loss: 0.549980\tAccuracy: 88.30%\n",
      "442\tValidation loss: 0.549755\tBest loss: 0.549755\tAccuracy: 88.40%\n",
      "443\tValidation loss: 0.549420\tBest loss: 0.549420\tAccuracy: 88.40%\n",
      "444\tValidation loss: 0.549157\tBest loss: 0.549157\tAccuracy: 88.40%\n",
      "445\tValidation loss: 0.548884\tBest loss: 0.548884\tAccuracy: 88.40%\n",
      "446\tValidation loss: 0.548733\tBest loss: 0.548733\tAccuracy: 88.40%\n",
      "447\tValidation loss: 0.548282\tBest loss: 0.548282\tAccuracy: 88.40%\n",
      "448\tValidation loss: 0.548188\tBest loss: 0.548188\tAccuracy: 88.40%\n",
      "449\tValidation loss: 0.547886\tBest loss: 0.547886\tAccuracy: 88.40%\n",
      "450\tValidation loss: 0.547505\tBest loss: 0.547505\tAccuracy: 88.40%\n",
      "451\tValidation loss: 0.547298\tBest loss: 0.547298\tAccuracy: 88.40%\n",
      "452\tValidation loss: 0.547068\tBest loss: 0.547068\tAccuracy: 88.40%\n",
      "453\tValidation loss: 0.546909\tBest loss: 0.546909\tAccuracy: 88.40%\n",
      "454\tValidation loss: 0.546586\tBest loss: 0.546586\tAccuracy: 88.40%\n",
      "455\tValidation loss: 0.546450\tBest loss: 0.546450\tAccuracy: 88.60%\n",
      "456\tValidation loss: 0.546040\tBest loss: 0.546040\tAccuracy: 88.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\tValidation loss: 0.545899\tBest loss: 0.545899\tAccuracy: 88.40%\n",
      "458\tValidation loss: 0.545825\tBest loss: 0.545825\tAccuracy: 88.60%\n",
      "459\tValidation loss: 0.545393\tBest loss: 0.545393\tAccuracy: 88.40%\n",
      "460\tValidation loss: 0.545036\tBest loss: 0.545036\tAccuracy: 88.60%\n",
      "461\tValidation loss: 0.544817\tBest loss: 0.544817\tAccuracy: 88.40%\n",
      "462\tValidation loss: 0.544513\tBest loss: 0.544513\tAccuracy: 88.60%\n",
      "463\tValidation loss: 0.544350\tBest loss: 0.544350\tAccuracy: 88.40%\n",
      "464\tValidation loss: 0.544055\tBest loss: 0.544055\tAccuracy: 88.60%\n",
      "465\tValidation loss: 0.543970\tBest loss: 0.543970\tAccuracy: 88.60%\n",
      "466\tValidation loss: 0.543553\tBest loss: 0.543553\tAccuracy: 88.60%\n",
      "467\tValidation loss: 0.543365\tBest loss: 0.543365\tAccuracy: 88.60%\n",
      "468\tValidation loss: 0.543174\tBest loss: 0.543174\tAccuracy: 88.60%\n",
      "469\tValidation loss: 0.542856\tBest loss: 0.542856\tAccuracy: 88.60%\n",
      "470\tValidation loss: 0.542730\tBest loss: 0.542730\tAccuracy: 88.60%\n",
      "471\tValidation loss: 0.542477\tBest loss: 0.542477\tAccuracy: 88.60%\n",
      "472\tValidation loss: 0.542083\tBest loss: 0.542083\tAccuracy: 88.60%\n",
      "473\tValidation loss: 0.541651\tBest loss: 0.541651\tAccuracy: 88.70%\n",
      "474\tValidation loss: 0.541495\tBest loss: 0.541495\tAccuracy: 88.70%\n",
      "475\tValidation loss: 0.541131\tBest loss: 0.541131\tAccuracy: 88.60%\n",
      "476\tValidation loss: 0.541083\tBest loss: 0.541083\tAccuracy: 88.70%\n",
      "477\tValidation loss: 0.540917\tBest loss: 0.540917\tAccuracy: 88.60%\n",
      "478\tValidation loss: 0.540501\tBest loss: 0.540501\tAccuracy: 88.60%\n",
      "479\tValidation loss: 0.540331\tBest loss: 0.540331\tAccuracy: 88.60%\n",
      "480\tValidation loss: 0.540104\tBest loss: 0.540104\tAccuracy: 88.40%\n",
      "481\tValidation loss: 0.539824\tBest loss: 0.539824\tAccuracy: 88.70%\n",
      "482\tValidation loss: 0.539678\tBest loss: 0.539678\tAccuracy: 88.70%\n",
      "483\tValidation loss: 0.539443\tBest loss: 0.539443\tAccuracy: 88.70%\n",
      "484\tValidation loss: 0.539216\tBest loss: 0.539216\tAccuracy: 88.70%\n",
      "485\tValidation loss: 0.539013\tBest loss: 0.539013\tAccuracy: 88.80%\n",
      "486\tValidation loss: 0.538553\tBest loss: 0.538553\tAccuracy: 88.80%\n",
      "487\tValidation loss: 0.538350\tBest loss: 0.538350\tAccuracy: 88.80%\n",
      "488\tValidation loss: 0.538260\tBest loss: 0.538260\tAccuracy: 88.80%\n",
      "489\tValidation loss: 0.538257\tBest loss: 0.538257\tAccuracy: 88.80%\n",
      "490\tValidation loss: 0.537976\tBest loss: 0.537976\tAccuracy: 88.70%\n",
      "491\tValidation loss: 0.537456\tBest loss: 0.537456\tAccuracy: 88.70%\n",
      "492\tValidation loss: 0.537267\tBest loss: 0.537267\tAccuracy: 88.70%\n",
      "493\tValidation loss: 0.537094\tBest loss: 0.537094\tAccuracy: 88.80%\n",
      "494\tValidation loss: 0.536781\tBest loss: 0.536781\tAccuracy: 88.80%\n",
      "495\tValidation loss: 0.536655\tBest loss: 0.536655\tAccuracy: 88.80%\n",
      "496\tValidation loss: 0.536252\tBest loss: 0.536252\tAccuracy: 88.80%\n",
      "497\tValidation loss: 0.536069\tBest loss: 0.536069\tAccuracy: 88.80%\n",
      "498\tValidation loss: 0.535881\tBest loss: 0.535881\tAccuracy: 88.80%\n",
      "499\tValidation loss: 0.535745\tBest loss: 0.535745\tAccuracy: 88.80%\n",
      "500\tValidation loss: 0.535626\tBest loss: 0.535626\tAccuracy: 88.70%\n",
      "501\tValidation loss: 0.535259\tBest loss: 0.535259\tAccuracy: 88.80%\n",
      "502\tValidation loss: 0.535055\tBest loss: 0.535055\tAccuracy: 88.80%\n",
      "503\tValidation loss: 0.534859\tBest loss: 0.534859\tAccuracy: 88.80%\n",
      "504\tValidation loss: 0.534543\tBest loss: 0.534543\tAccuracy: 88.80%\n",
      "505\tValidation loss: 0.534385\tBest loss: 0.534385\tAccuracy: 88.80%\n",
      "506\tValidation loss: 0.534083\tBest loss: 0.534083\tAccuracy: 88.80%\n",
      "507\tValidation loss: 0.534022\tBest loss: 0.534022\tAccuracy: 88.80%\n",
      "508\tValidation loss: 0.533595\tBest loss: 0.533595\tAccuracy: 88.80%\n",
      "509\tValidation loss: 0.533300\tBest loss: 0.533300\tAccuracy: 88.80%\n",
      "510\tValidation loss: 0.533203\tBest loss: 0.533203\tAccuracy: 88.80%\n",
      "511\tValidation loss: 0.533055\tBest loss: 0.533055\tAccuracy: 88.80%\n",
      "512\tValidation loss: 0.532846\tBest loss: 0.532846\tAccuracy: 88.80%\n",
      "513\tValidation loss: 0.532652\tBest loss: 0.532652\tAccuracy: 88.80%\n",
      "514\tValidation loss: 0.532382\tBest loss: 0.532382\tAccuracy: 88.80%\n",
      "515\tValidation loss: 0.532026\tBest loss: 0.532026\tAccuracy: 88.80%\n",
      "516\tValidation loss: 0.531866\tBest loss: 0.531866\tAccuracy: 88.80%\n",
      "517\tValidation loss: 0.531662\tBest loss: 0.531662\tAccuracy: 88.80%\n",
      "518\tValidation loss: 0.531589\tBest loss: 0.531589\tAccuracy: 88.80%\n",
      "519\tValidation loss: 0.531384\tBest loss: 0.531384\tAccuracy: 88.70%\n",
      "520\tValidation loss: 0.531191\tBest loss: 0.531191\tAccuracy: 88.70%\n",
      "521\tValidation loss: 0.530858\tBest loss: 0.530858\tAccuracy: 88.80%\n",
      "522\tValidation loss: 0.530737\tBest loss: 0.530737\tAccuracy: 88.80%\n",
      "523\tValidation loss: 0.530376\tBest loss: 0.530376\tAccuracy: 88.70%\n",
      "524\tValidation loss: 0.530307\tBest loss: 0.530307\tAccuracy: 88.70%\n",
      "525\tValidation loss: 0.530295\tBest loss: 0.530295\tAccuracy: 88.70%\n",
      "526\tValidation loss: 0.529826\tBest loss: 0.529826\tAccuracy: 88.70%\n",
      "527\tValidation loss: 0.529638\tBest loss: 0.529638\tAccuracy: 88.70%\n",
      "528\tValidation loss: 0.529469\tBest loss: 0.529469\tAccuracy: 88.70%\n",
      "529\tValidation loss: 0.529121\tBest loss: 0.529121\tAccuracy: 88.70%\n",
      "530\tValidation loss: 0.528878\tBest loss: 0.528878\tAccuracy: 88.80%\n",
      "531\tValidation loss: 0.528703\tBest loss: 0.528703\tAccuracy: 88.70%\n",
      "532\tValidation loss: 0.528532\tBest loss: 0.528532\tAccuracy: 88.70%\n",
      "533\tValidation loss: 0.528381\tBest loss: 0.528381\tAccuracy: 88.70%\n",
      "534\tValidation loss: 0.528181\tBest loss: 0.528181\tAccuracy: 88.70%\n",
      "535\tValidation loss: 0.527913\tBest loss: 0.527913\tAccuracy: 88.70%\n",
      "536\tValidation loss: 0.527585\tBest loss: 0.527585\tAccuracy: 88.80%\n",
      "537\tValidation loss: 0.527318\tBest loss: 0.527318\tAccuracy: 88.70%\n",
      "538\tValidation loss: 0.527146\tBest loss: 0.527146\tAccuracy: 88.70%\n",
      "539\tValidation loss: 0.527150\tBest loss: 0.527146\tAccuracy: 88.80%\n",
      "540\tValidation loss: 0.526816\tBest loss: 0.526816\tAccuracy: 88.80%\n",
      "541\tValidation loss: 0.526736\tBest loss: 0.526736\tAccuracy: 88.70%\n",
      "542\tValidation loss: 0.526662\tBest loss: 0.526662\tAccuracy: 88.70%\n",
      "543\tValidation loss: 0.526504\tBest loss: 0.526504\tAccuracy: 88.70%\n",
      "544\tValidation loss: 0.526224\tBest loss: 0.526224\tAccuracy: 88.70%\n",
      "545\tValidation loss: 0.526019\tBest loss: 0.526019\tAccuracy: 88.70%\n",
      "546\tValidation loss: 0.525730\tBest loss: 0.525730\tAccuracy: 88.70%\n",
      "547\tValidation loss: 0.525280\tBest loss: 0.525280\tAccuracy: 88.70%\n",
      "548\tValidation loss: 0.525025\tBest loss: 0.525025\tAccuracy: 88.70%\n",
      "549\tValidation loss: 0.525064\tBest loss: 0.525025\tAccuracy: 88.70%\n",
      "550\tValidation loss: 0.524852\tBest loss: 0.524852\tAccuracy: 88.70%\n",
      "551\tValidation loss: 0.524583\tBest loss: 0.524583\tAccuracy: 88.70%\n",
      "552\tValidation loss: 0.524555\tBest loss: 0.524555\tAccuracy: 88.70%\n",
      "553\tValidation loss: 0.524293\tBest loss: 0.524293\tAccuracy: 88.80%\n",
      "554\tValidation loss: 0.524256\tBest loss: 0.524256\tAccuracy: 88.70%\n",
      "555\tValidation loss: 0.523937\tBest loss: 0.523937\tAccuracy: 88.70%\n",
      "556\tValidation loss: 0.523664\tBest loss: 0.523664\tAccuracy: 88.70%\n",
      "557\tValidation loss: 0.523371\tBest loss: 0.523371\tAccuracy: 88.70%\n",
      "558\tValidation loss: 0.523364\tBest loss: 0.523364\tAccuracy: 88.70%\n",
      "559\tValidation loss: 0.523333\tBest loss: 0.523333\tAccuracy: 88.70%\n",
      "560\tValidation loss: 0.523015\tBest loss: 0.523015\tAccuracy: 88.70%\n",
      "561\tValidation loss: 0.522729\tBest loss: 0.522729\tAccuracy: 88.70%\n",
      "562\tValidation loss: 0.522391\tBest loss: 0.522391\tAccuracy: 88.70%\n",
      "563\tValidation loss: 0.522202\tBest loss: 0.522202\tAccuracy: 88.70%\n",
      "564\tValidation loss: 0.522199\tBest loss: 0.522199\tAccuracy: 88.70%\n",
      "565\tValidation loss: 0.521969\tBest loss: 0.521969\tAccuracy: 88.70%\n",
      "566\tValidation loss: 0.521771\tBest loss: 0.521771\tAccuracy: 88.70%\n",
      "567\tValidation loss: 0.521675\tBest loss: 0.521675\tAccuracy: 88.70%\n",
      "568\tValidation loss: 0.521285\tBest loss: 0.521285\tAccuracy: 88.80%\n",
      "569\tValidation loss: 0.521244\tBest loss: 0.521244\tAccuracy: 88.70%\n",
      "570\tValidation loss: 0.520899\tBest loss: 0.520899\tAccuracy: 88.80%\n",
      "571\tValidation loss: 0.520815\tBest loss: 0.520815\tAccuracy: 88.80%\n",
      "572\tValidation loss: 0.520558\tBest loss: 0.520558\tAccuracy: 88.80%\n",
      "573\tValidation loss: 0.520373\tBest loss: 0.520373\tAccuracy: 88.80%\n",
      "574\tValidation loss: 0.520269\tBest loss: 0.520269\tAccuracy: 88.70%\n",
      "575\tValidation loss: 0.520235\tBest loss: 0.520235\tAccuracy: 88.90%\n",
      "576\tValidation loss: 0.519973\tBest loss: 0.519973\tAccuracy: 88.70%\n",
      "577\tValidation loss: 0.519877\tBest loss: 0.519877\tAccuracy: 88.90%\n",
      "578\tValidation loss: 0.519705\tBest loss: 0.519705\tAccuracy: 88.80%\n",
      "579\tValidation loss: 0.519368\tBest loss: 0.519368\tAccuracy: 88.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\tValidation loss: 0.519234\tBest loss: 0.519234\tAccuracy: 88.90%\n",
      "581\tValidation loss: 0.519123\tBest loss: 0.519123\tAccuracy: 88.90%\n",
      "582\tValidation loss: 0.519043\tBest loss: 0.519043\tAccuracy: 88.80%\n",
      "583\tValidation loss: 0.518828\tBest loss: 0.518828\tAccuracy: 88.80%\n",
      "584\tValidation loss: 0.518565\tBest loss: 0.518565\tAccuracy: 88.80%\n",
      "585\tValidation loss: 0.518408\tBest loss: 0.518408\tAccuracy: 88.80%\n",
      "586\tValidation loss: 0.518238\tBest loss: 0.518238\tAccuracy: 88.90%\n",
      "587\tValidation loss: 0.517931\tBest loss: 0.517931\tAccuracy: 89.00%\n",
      "588\tValidation loss: 0.517750\tBest loss: 0.517750\tAccuracy: 88.80%\n",
      "589\tValidation loss: 0.517613\tBest loss: 0.517613\tAccuracy: 88.90%\n",
      "590\tValidation loss: 0.517399\tBest loss: 0.517399\tAccuracy: 88.90%\n",
      "591\tValidation loss: 0.517255\tBest loss: 0.517255\tAccuracy: 88.80%\n",
      "592\tValidation loss: 0.517184\tBest loss: 0.517184\tAccuracy: 88.90%\n",
      "593\tValidation loss: 0.516881\tBest loss: 0.516881\tAccuracy: 88.80%\n",
      "594\tValidation loss: 0.516588\tBest loss: 0.516588\tAccuracy: 88.80%\n",
      "595\tValidation loss: 0.516658\tBest loss: 0.516588\tAccuracy: 88.80%\n",
      "596\tValidation loss: 0.516528\tBest loss: 0.516528\tAccuracy: 88.80%\n",
      "597\tValidation loss: 0.516246\tBest loss: 0.516246\tAccuracy: 88.80%\n",
      "598\tValidation loss: 0.515941\tBest loss: 0.515941\tAccuracy: 88.80%\n",
      "599\tValidation loss: 0.515706\tBest loss: 0.515706\tAccuracy: 88.90%\n",
      "600\tValidation loss: 0.515755\tBest loss: 0.515706\tAccuracy: 88.90%\n",
      "601\tValidation loss: 0.515320\tBest loss: 0.515320\tAccuracy: 88.80%\n",
      "602\tValidation loss: 0.515464\tBest loss: 0.515320\tAccuracy: 88.90%\n",
      "603\tValidation loss: 0.515142\tBest loss: 0.515142\tAccuracy: 88.90%\n",
      "604\tValidation loss: 0.514893\tBest loss: 0.514893\tAccuracy: 88.90%\n",
      "605\tValidation loss: 0.514769\tBest loss: 0.514769\tAccuracy: 89.00%\n",
      "606\tValidation loss: 0.514579\tBest loss: 0.514579\tAccuracy: 88.90%\n",
      "607\tValidation loss: 0.514377\tBest loss: 0.514377\tAccuracy: 88.90%\n",
      "608\tValidation loss: 0.514161\tBest loss: 0.514161\tAccuracy: 88.90%\n",
      "609\tValidation loss: 0.513921\tBest loss: 0.513921\tAccuracy: 88.80%\n",
      "610\tValidation loss: 0.513938\tBest loss: 0.513921\tAccuracy: 88.80%\n",
      "611\tValidation loss: 0.513625\tBest loss: 0.513625\tAccuracy: 88.70%\n",
      "612\tValidation loss: 0.513532\tBest loss: 0.513532\tAccuracy: 88.70%\n",
      "613\tValidation loss: 0.513448\tBest loss: 0.513448\tAccuracy: 88.90%\n",
      "614\tValidation loss: 0.513277\tBest loss: 0.513277\tAccuracy: 88.90%\n",
      "615\tValidation loss: 0.513175\tBest loss: 0.513175\tAccuracy: 88.90%\n",
      "616\tValidation loss: 0.512835\tBest loss: 0.512835\tAccuracy: 88.90%\n",
      "617\tValidation loss: 0.512598\tBest loss: 0.512598\tAccuracy: 88.80%\n",
      "618\tValidation loss: 0.512568\tBest loss: 0.512568\tAccuracy: 88.80%\n",
      "619\tValidation loss: 0.512440\tBest loss: 0.512440\tAccuracy: 88.80%\n",
      "620\tValidation loss: 0.512069\tBest loss: 0.512069\tAccuracy: 88.90%\n",
      "621\tValidation loss: 0.511896\tBest loss: 0.511896\tAccuracy: 88.90%\n",
      "622\tValidation loss: 0.511871\tBest loss: 0.511871\tAccuracy: 88.80%\n",
      "623\tValidation loss: 0.511526\tBest loss: 0.511526\tAccuracy: 88.90%\n",
      "624\tValidation loss: 0.511556\tBest loss: 0.511526\tAccuracy: 88.80%\n",
      "625\tValidation loss: 0.511489\tBest loss: 0.511489\tAccuracy: 88.90%\n",
      "626\tValidation loss: 0.511374\tBest loss: 0.511374\tAccuracy: 88.90%\n",
      "627\tValidation loss: 0.510979\tBest loss: 0.510979\tAccuracy: 88.90%\n",
      "628\tValidation loss: 0.510917\tBest loss: 0.510917\tAccuracy: 88.90%\n",
      "629\tValidation loss: 0.510622\tBest loss: 0.510622\tAccuracy: 88.80%\n",
      "630\tValidation loss: 0.510539\tBest loss: 0.510539\tAccuracy: 88.90%\n",
      "631\tValidation loss: 0.510391\tBest loss: 0.510391\tAccuracy: 88.90%\n",
      "632\tValidation loss: 0.510266\tBest loss: 0.510266\tAccuracy: 88.90%\n",
      "633\tValidation loss: 0.510149\tBest loss: 0.510149\tAccuracy: 88.90%\n",
      "634\tValidation loss: 0.509826\tBest loss: 0.509826\tAccuracy: 89.00%\n",
      "635\tValidation loss: 0.509715\tBest loss: 0.509715\tAccuracy: 88.90%\n",
      "636\tValidation loss: 0.509504\tBest loss: 0.509504\tAccuracy: 89.00%\n",
      "637\tValidation loss: 0.509290\tBest loss: 0.509290\tAccuracy: 89.00%\n",
      "638\tValidation loss: 0.509113\tBest loss: 0.509113\tAccuracy: 89.00%\n",
      "639\tValidation loss: 0.509078\tBest loss: 0.509078\tAccuracy: 89.00%\n",
      "640\tValidation loss: 0.508811\tBest loss: 0.508811\tAccuracy: 89.00%\n",
      "641\tValidation loss: 0.508624\tBest loss: 0.508624\tAccuracy: 89.00%\n",
      "642\tValidation loss: 0.508458\tBest loss: 0.508458\tAccuracy: 89.00%\n",
      "643\tValidation loss: 0.508308\tBest loss: 0.508308\tAccuracy: 89.00%\n",
      "644\tValidation loss: 0.508238\tBest loss: 0.508238\tAccuracy: 89.00%\n",
      "645\tValidation loss: 0.508080\tBest loss: 0.508080\tAccuracy: 89.00%\n",
      "646\tValidation loss: 0.507928\tBest loss: 0.507928\tAccuracy: 89.00%\n",
      "647\tValidation loss: 0.507812\tBest loss: 0.507812\tAccuracy: 88.90%\n",
      "648\tValidation loss: 0.507518\tBest loss: 0.507518\tAccuracy: 88.90%\n",
      "649\tValidation loss: 0.507548\tBest loss: 0.507518\tAccuracy: 88.90%\n",
      "650\tValidation loss: 0.507429\tBest loss: 0.507429\tAccuracy: 89.00%\n",
      "651\tValidation loss: 0.507237\tBest loss: 0.507237\tAccuracy: 89.00%\n",
      "652\tValidation loss: 0.507006\tBest loss: 0.507006\tAccuracy: 89.00%\n",
      "653\tValidation loss: 0.506933\tBest loss: 0.506933\tAccuracy: 89.00%\n",
      "654\tValidation loss: 0.506777\tBest loss: 0.506777\tAccuracy: 89.00%\n",
      "655\tValidation loss: 0.506718\tBest loss: 0.506718\tAccuracy: 89.00%\n",
      "656\tValidation loss: 0.506587\tBest loss: 0.506587\tAccuracy: 89.00%\n",
      "657\tValidation loss: 0.506330\tBest loss: 0.506330\tAccuracy: 89.00%\n",
      "658\tValidation loss: 0.506292\tBest loss: 0.506292\tAccuracy: 89.00%\n",
      "659\tValidation loss: 0.506004\tBest loss: 0.506004\tAccuracy: 89.00%\n",
      "660\tValidation loss: 0.505929\tBest loss: 0.505929\tAccuracy: 89.00%\n",
      "661\tValidation loss: 0.505746\tBest loss: 0.505746\tAccuracy: 89.00%\n",
      "662\tValidation loss: 0.505403\tBest loss: 0.505403\tAccuracy: 89.00%\n",
      "663\tValidation loss: 0.505350\tBest loss: 0.505350\tAccuracy: 89.00%\n",
      "664\tValidation loss: 0.505360\tBest loss: 0.505350\tAccuracy: 88.90%\n",
      "665\tValidation loss: 0.505171\tBest loss: 0.505171\tAccuracy: 88.90%\n",
      "666\tValidation loss: 0.505027\tBest loss: 0.505027\tAccuracy: 88.90%\n",
      "667\tValidation loss: 0.504714\tBest loss: 0.504714\tAccuracy: 89.00%\n",
      "668\tValidation loss: 0.504581\tBest loss: 0.504581\tAccuracy: 89.00%\n",
      "669\tValidation loss: 0.504357\tBest loss: 0.504357\tAccuracy: 89.00%\n",
      "670\tValidation loss: 0.504392\tBest loss: 0.504357\tAccuracy: 88.90%\n",
      "671\tValidation loss: 0.504026\tBest loss: 0.504026\tAccuracy: 88.90%\n",
      "672\tValidation loss: 0.503866\tBest loss: 0.503866\tAccuracy: 88.90%\n",
      "673\tValidation loss: 0.503816\tBest loss: 0.503816\tAccuracy: 88.90%\n",
      "674\tValidation loss: 0.503468\tBest loss: 0.503468\tAccuracy: 88.90%\n",
      "675\tValidation loss: 0.503455\tBest loss: 0.503455\tAccuracy: 89.00%\n",
      "676\tValidation loss: 0.503230\tBest loss: 0.503230\tAccuracy: 88.90%\n",
      "677\tValidation loss: 0.503219\tBest loss: 0.503219\tAccuracy: 88.90%\n",
      "678\tValidation loss: 0.503015\tBest loss: 0.503015\tAccuracy: 88.90%\n",
      "679\tValidation loss: 0.503031\tBest loss: 0.503015\tAccuracy: 88.90%\n",
      "680\tValidation loss: 0.502773\tBest loss: 0.502773\tAccuracy: 88.90%\n",
      "681\tValidation loss: 0.502617\tBest loss: 0.502617\tAccuracy: 88.90%\n",
      "682\tValidation loss: 0.502408\tBest loss: 0.502408\tAccuracy: 88.90%\n",
      "683\tValidation loss: 0.502285\tBest loss: 0.502285\tAccuracy: 88.90%\n",
      "684\tValidation loss: 0.502181\tBest loss: 0.502181\tAccuracy: 88.90%\n",
      "685\tValidation loss: 0.502134\tBest loss: 0.502134\tAccuracy: 89.00%\n",
      "686\tValidation loss: 0.501763\tBest loss: 0.501763\tAccuracy: 88.90%\n",
      "687\tValidation loss: 0.501579\tBest loss: 0.501579\tAccuracy: 88.90%\n",
      "688\tValidation loss: 0.501528\tBest loss: 0.501528\tAccuracy: 88.90%\n",
      "689\tValidation loss: 0.501372\tBest loss: 0.501372\tAccuracy: 88.90%\n",
      "690\tValidation loss: 0.501193\tBest loss: 0.501193\tAccuracy: 88.90%\n",
      "691\tValidation loss: 0.501122\tBest loss: 0.501122\tAccuracy: 88.90%\n",
      "692\tValidation loss: 0.500876\tBest loss: 0.500876\tAccuracy: 88.90%\n",
      "693\tValidation loss: 0.500775\tBest loss: 0.500775\tAccuracy: 89.00%\n",
      "694\tValidation loss: 0.500753\tBest loss: 0.500753\tAccuracy: 88.90%\n",
      "695\tValidation loss: 0.500584\tBest loss: 0.500584\tAccuracy: 88.90%\n",
      "696\tValidation loss: 0.500450\tBest loss: 0.500450\tAccuracy: 88.90%\n",
      "697\tValidation loss: 0.500383\tBest loss: 0.500383\tAccuracy: 88.90%\n",
      "698\tValidation loss: 0.500206\tBest loss: 0.500206\tAccuracy: 88.90%\n",
      "699\tValidation loss: 0.500107\tBest loss: 0.500107\tAccuracy: 88.90%\n",
      "700\tValidation loss: 0.500118\tBest loss: 0.500107\tAccuracy: 88.90%\n",
      "701\tValidation loss: 0.499845\tBest loss: 0.499845\tAccuracy: 89.00%\n",
      "702\tValidation loss: 0.499536\tBest loss: 0.499536\tAccuracy: 89.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\tValidation loss: 0.499336\tBest loss: 0.499336\tAccuracy: 88.90%\n",
      "704\tValidation loss: 0.499276\tBest loss: 0.499276\tAccuracy: 89.00%\n",
      "705\tValidation loss: 0.499245\tBest loss: 0.499245\tAccuracy: 88.90%\n",
      "706\tValidation loss: 0.498853\tBest loss: 0.498853\tAccuracy: 89.10%\n",
      "707\tValidation loss: 0.498761\tBest loss: 0.498761\tAccuracy: 89.20%\n",
      "708\tValidation loss: 0.498589\tBest loss: 0.498589\tAccuracy: 89.00%\n",
      "709\tValidation loss: 0.498381\tBest loss: 0.498381\tAccuracy: 88.90%\n",
      "710\tValidation loss: 0.498383\tBest loss: 0.498381\tAccuracy: 88.90%\n",
      "711\tValidation loss: 0.498217\tBest loss: 0.498217\tAccuracy: 89.00%\n",
      "712\tValidation loss: 0.498090\tBest loss: 0.498090\tAccuracy: 89.00%\n",
      "713\tValidation loss: 0.498018\tBest loss: 0.498018\tAccuracy: 89.00%\n",
      "714\tValidation loss: 0.497928\tBest loss: 0.497928\tAccuracy: 88.90%\n",
      "715\tValidation loss: 0.497829\tBest loss: 0.497829\tAccuracy: 88.90%\n",
      "716\tValidation loss: 0.497665\tBest loss: 0.497665\tAccuracy: 88.90%\n",
      "717\tValidation loss: 0.497365\tBest loss: 0.497365\tAccuracy: 88.90%\n",
      "718\tValidation loss: 0.497284\tBest loss: 0.497284\tAccuracy: 88.90%\n",
      "719\tValidation loss: 0.497263\tBest loss: 0.497263\tAccuracy: 88.90%\n",
      "720\tValidation loss: 0.497060\tBest loss: 0.497060\tAccuracy: 89.00%\n",
      "721\tValidation loss: 0.497079\tBest loss: 0.497060\tAccuracy: 88.90%\n",
      "722\tValidation loss: 0.496982\tBest loss: 0.496982\tAccuracy: 89.00%\n",
      "723\tValidation loss: 0.496754\tBest loss: 0.496754\tAccuracy: 88.90%\n",
      "724\tValidation loss: 0.496707\tBest loss: 0.496707\tAccuracy: 89.00%\n",
      "725\tValidation loss: 0.496337\tBest loss: 0.496337\tAccuracy: 89.10%\n",
      "726\tValidation loss: 0.496286\tBest loss: 0.496286\tAccuracy: 89.00%\n",
      "727\tValidation loss: 0.496153\tBest loss: 0.496153\tAccuracy: 89.10%\n",
      "728\tValidation loss: 0.496089\tBest loss: 0.496089\tAccuracy: 89.10%\n",
      "729\tValidation loss: 0.495943\tBest loss: 0.495943\tAccuracy: 89.10%\n",
      "730\tValidation loss: 0.495714\tBest loss: 0.495714\tAccuracy: 89.10%\n",
      "731\tValidation loss: 0.495638\tBest loss: 0.495638\tAccuracy: 89.10%\n",
      "732\tValidation loss: 0.495523\tBest loss: 0.495523\tAccuracy: 89.20%\n",
      "733\tValidation loss: 0.495362\tBest loss: 0.495362\tAccuracy: 89.20%\n",
      "734\tValidation loss: 0.495050\tBest loss: 0.495050\tAccuracy: 89.20%\n",
      "735\tValidation loss: 0.494960\tBest loss: 0.494960\tAccuracy: 89.20%\n",
      "736\tValidation loss: 0.494807\tBest loss: 0.494807\tAccuracy: 89.20%\n",
      "737\tValidation loss: 0.494692\tBest loss: 0.494692\tAccuracy: 89.20%\n",
      "738\tValidation loss: 0.494723\tBest loss: 0.494692\tAccuracy: 89.10%\n",
      "739\tValidation loss: 0.494598\tBest loss: 0.494598\tAccuracy: 89.10%\n",
      "740\tValidation loss: 0.494455\tBest loss: 0.494455\tAccuracy: 89.00%\n",
      "741\tValidation loss: 0.494259\tBest loss: 0.494259\tAccuracy: 89.10%\n",
      "742\tValidation loss: 0.494090\tBest loss: 0.494090\tAccuracy: 89.10%\n",
      "743\tValidation loss: 0.493870\tBest loss: 0.493870\tAccuracy: 89.10%\n",
      "744\tValidation loss: 0.493811\tBest loss: 0.493811\tAccuracy: 89.20%\n",
      "745\tValidation loss: 0.493629\tBest loss: 0.493629\tAccuracy: 89.20%\n",
      "746\tValidation loss: 0.493483\tBest loss: 0.493483\tAccuracy: 89.20%\n",
      "747\tValidation loss: 0.493311\tBest loss: 0.493311\tAccuracy: 89.20%\n",
      "748\tValidation loss: 0.493213\tBest loss: 0.493213\tAccuracy: 89.10%\n",
      "749\tValidation loss: 0.493134\tBest loss: 0.493134\tAccuracy: 89.10%\n",
      "750\tValidation loss: 0.492906\tBest loss: 0.492906\tAccuracy: 89.20%\n",
      "751\tValidation loss: 0.492902\tBest loss: 0.492902\tAccuracy: 89.10%\n",
      "752\tValidation loss: 0.492749\tBest loss: 0.492749\tAccuracy: 89.20%\n",
      "753\tValidation loss: 0.492721\tBest loss: 0.492721\tAccuracy: 89.10%\n",
      "754\tValidation loss: 0.492668\tBest loss: 0.492668\tAccuracy: 89.20%\n",
      "755\tValidation loss: 0.492487\tBest loss: 0.492487\tAccuracy: 89.20%\n",
      "756\tValidation loss: 0.492475\tBest loss: 0.492475\tAccuracy: 89.20%\n",
      "757\tValidation loss: 0.492408\tBest loss: 0.492408\tAccuracy: 89.10%\n",
      "758\tValidation loss: 0.492199\tBest loss: 0.492199\tAccuracy: 89.10%\n",
      "759\tValidation loss: 0.492028\tBest loss: 0.492028\tAccuracy: 89.10%\n",
      "760\tValidation loss: 0.491992\tBest loss: 0.491992\tAccuracy: 89.20%\n",
      "761\tValidation loss: 0.491835\tBest loss: 0.491835\tAccuracy: 89.20%\n",
      "762\tValidation loss: 0.491632\tBest loss: 0.491632\tAccuracy: 89.10%\n",
      "763\tValidation loss: 0.491552\tBest loss: 0.491552\tAccuracy: 89.10%\n",
      "764\tValidation loss: 0.491255\tBest loss: 0.491255\tAccuracy: 89.20%\n",
      "765\tValidation loss: 0.491115\tBest loss: 0.491115\tAccuracy: 89.20%\n",
      "766\tValidation loss: 0.491019\tBest loss: 0.491019\tAccuracy: 89.20%\n",
      "767\tValidation loss: 0.490885\tBest loss: 0.490885\tAccuracy: 89.20%\n",
      "768\tValidation loss: 0.490730\tBest loss: 0.490730\tAccuracy: 89.20%\n",
      "769\tValidation loss: 0.490756\tBest loss: 0.490730\tAccuracy: 89.20%\n",
      "770\tValidation loss: 0.490608\tBest loss: 0.490608\tAccuracy: 89.10%\n",
      "771\tValidation loss: 0.490459\tBest loss: 0.490459\tAccuracy: 89.10%\n",
      "772\tValidation loss: 0.490369\tBest loss: 0.490369\tAccuracy: 89.20%\n",
      "773\tValidation loss: 0.490245\tBest loss: 0.490245\tAccuracy: 89.10%\n",
      "774\tValidation loss: 0.490083\tBest loss: 0.490083\tAccuracy: 89.20%\n",
      "775\tValidation loss: 0.489994\tBest loss: 0.489994\tAccuracy: 89.20%\n",
      "776\tValidation loss: 0.489850\tBest loss: 0.489850\tAccuracy: 89.20%\n",
      "777\tValidation loss: 0.489696\tBest loss: 0.489696\tAccuracy: 89.20%\n",
      "778\tValidation loss: 0.489481\tBest loss: 0.489481\tAccuracy: 89.20%\n",
      "779\tValidation loss: 0.489333\tBest loss: 0.489333\tAccuracy: 89.20%\n",
      "780\tValidation loss: 0.489381\tBest loss: 0.489333\tAccuracy: 89.20%\n",
      "781\tValidation loss: 0.489420\tBest loss: 0.489333\tAccuracy: 89.20%\n",
      "782\tValidation loss: 0.489201\tBest loss: 0.489201\tAccuracy: 89.20%\n",
      "783\tValidation loss: 0.489015\tBest loss: 0.489015\tAccuracy: 89.20%\n",
      "784\tValidation loss: 0.488782\tBest loss: 0.488782\tAccuracy: 89.20%\n",
      "785\tValidation loss: 0.488735\tBest loss: 0.488735\tAccuracy: 89.20%\n",
      "786\tValidation loss: 0.488482\tBest loss: 0.488482\tAccuracy: 89.20%\n",
      "787\tValidation loss: 0.488370\tBest loss: 0.488370\tAccuracy: 89.10%\n",
      "788\tValidation loss: 0.488419\tBest loss: 0.488370\tAccuracy: 89.00%\n",
      "789\tValidation loss: 0.488239\tBest loss: 0.488239\tAccuracy: 89.10%\n",
      "790\tValidation loss: 0.488110\tBest loss: 0.488110\tAccuracy: 89.20%\n",
      "791\tValidation loss: 0.487939\tBest loss: 0.487939\tAccuracy: 89.20%\n",
      "792\tValidation loss: 0.487815\tBest loss: 0.487815\tAccuracy: 89.20%\n",
      "793\tValidation loss: 0.487712\tBest loss: 0.487712\tAccuracy: 89.20%\n",
      "794\tValidation loss: 0.487689\tBest loss: 0.487689\tAccuracy: 89.20%\n",
      "795\tValidation loss: 0.487574\tBest loss: 0.487574\tAccuracy: 89.20%\n",
      "796\tValidation loss: 0.487524\tBest loss: 0.487524\tAccuracy: 89.20%\n",
      "797\tValidation loss: 0.487326\tBest loss: 0.487326\tAccuracy: 89.20%\n",
      "798\tValidation loss: 0.487262\tBest loss: 0.487262\tAccuracy: 89.20%\n",
      "799\tValidation loss: 0.487202\tBest loss: 0.487202\tAccuracy: 89.20%\n",
      "800\tValidation loss: 0.487042\tBest loss: 0.487042\tAccuracy: 89.20%\n",
      "801\tValidation loss: 0.486867\tBest loss: 0.486867\tAccuracy: 89.10%\n",
      "802\tValidation loss: 0.486709\tBest loss: 0.486709\tAccuracy: 89.10%\n",
      "803\tValidation loss: 0.486507\tBest loss: 0.486507\tAccuracy: 89.20%\n",
      "804\tValidation loss: 0.486485\tBest loss: 0.486485\tAccuracy: 89.00%\n",
      "805\tValidation loss: 0.486413\tBest loss: 0.486413\tAccuracy: 89.10%\n",
      "806\tValidation loss: 0.486224\tBest loss: 0.486224\tAccuracy: 89.10%\n",
      "807\tValidation loss: 0.486211\tBest loss: 0.486211\tAccuracy: 89.10%\n",
      "808\tValidation loss: 0.485994\tBest loss: 0.485994\tAccuracy: 89.00%\n",
      "809\tValidation loss: 0.485849\tBest loss: 0.485849\tAccuracy: 89.00%\n",
      "810\tValidation loss: 0.485731\tBest loss: 0.485731\tAccuracy: 89.10%\n",
      "811\tValidation loss: 0.485675\tBest loss: 0.485675\tAccuracy: 89.10%\n",
      "812\tValidation loss: 0.485534\tBest loss: 0.485534\tAccuracy: 89.10%\n",
      "813\tValidation loss: 0.485430\tBest loss: 0.485430\tAccuracy: 89.10%\n",
      "814\tValidation loss: 0.485366\tBest loss: 0.485366\tAccuracy: 89.10%\n",
      "815\tValidation loss: 0.485268\tBest loss: 0.485268\tAccuracy: 89.10%\n",
      "816\tValidation loss: 0.485108\tBest loss: 0.485108\tAccuracy: 89.10%\n",
      "817\tValidation loss: 0.485067\tBest loss: 0.485067\tAccuracy: 89.10%\n",
      "818\tValidation loss: 0.484963\tBest loss: 0.484963\tAccuracy: 89.10%\n",
      "819\tValidation loss: 0.484793\tBest loss: 0.484793\tAccuracy: 89.10%\n",
      "820\tValidation loss: 0.484665\tBest loss: 0.484665\tAccuracy: 89.10%\n",
      "821\tValidation loss: 0.484432\tBest loss: 0.484432\tAccuracy: 89.10%\n",
      "822\tValidation loss: 0.484328\tBest loss: 0.484328\tAccuracy: 89.10%\n",
      "823\tValidation loss: 0.484152\tBest loss: 0.484152\tAccuracy: 89.20%\n",
      "824\tValidation loss: 0.484209\tBest loss: 0.484152\tAccuracy: 89.20%\n",
      "825\tValidation loss: 0.484110\tBest loss: 0.484110\tAccuracy: 89.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\tValidation loss: 0.484015\tBest loss: 0.484015\tAccuracy: 89.20%\n",
      "827\tValidation loss: 0.483841\tBest loss: 0.483841\tAccuracy: 89.20%\n",
      "828\tValidation loss: 0.483704\tBest loss: 0.483704\tAccuracy: 89.20%\n",
      "829\tValidation loss: 0.483596\tBest loss: 0.483596\tAccuracy: 89.20%\n",
      "830\tValidation loss: 0.483521\tBest loss: 0.483521\tAccuracy: 89.20%\n",
      "831\tValidation loss: 0.483331\tBest loss: 0.483331\tAccuracy: 89.20%\n",
      "832\tValidation loss: 0.483227\tBest loss: 0.483227\tAccuracy: 89.20%\n",
      "833\tValidation loss: 0.483083\tBest loss: 0.483083\tAccuracy: 89.30%\n",
      "834\tValidation loss: 0.483057\tBest loss: 0.483057\tAccuracy: 89.30%\n",
      "835\tValidation loss: 0.482943\tBest loss: 0.482943\tAccuracy: 89.30%\n",
      "836\tValidation loss: 0.482818\tBest loss: 0.482818\tAccuracy: 89.30%\n",
      "837\tValidation loss: 0.482845\tBest loss: 0.482818\tAccuracy: 89.30%\n",
      "838\tValidation loss: 0.482662\tBest loss: 0.482662\tAccuracy: 89.30%\n",
      "839\tValidation loss: 0.482529\tBest loss: 0.482529\tAccuracy: 89.30%\n",
      "840\tValidation loss: 0.482412\tBest loss: 0.482412\tAccuracy: 89.30%\n",
      "841\tValidation loss: 0.482351\tBest loss: 0.482351\tAccuracy: 89.30%\n",
      "842\tValidation loss: 0.482240\tBest loss: 0.482240\tAccuracy: 89.30%\n",
      "843\tValidation loss: 0.482119\tBest loss: 0.482119\tAccuracy: 89.30%\n",
      "844\tValidation loss: 0.481970\tBest loss: 0.481970\tAccuracy: 89.30%\n",
      "845\tValidation loss: 0.481810\tBest loss: 0.481810\tAccuracy: 89.30%\n",
      "846\tValidation loss: 0.481739\tBest loss: 0.481739\tAccuracy: 89.30%\n",
      "847\tValidation loss: 0.481615\tBest loss: 0.481615\tAccuracy: 89.30%\n",
      "848\tValidation loss: 0.481517\tBest loss: 0.481517\tAccuracy: 89.30%\n",
      "849\tValidation loss: 0.481324\tBest loss: 0.481324\tAccuracy: 89.40%\n",
      "850\tValidation loss: 0.481326\tBest loss: 0.481324\tAccuracy: 89.40%\n",
      "851\tValidation loss: 0.481114\tBest loss: 0.481114\tAccuracy: 89.40%\n",
      "852\tValidation loss: 0.480998\tBest loss: 0.480998\tAccuracy: 89.30%\n",
      "853\tValidation loss: 0.480910\tBest loss: 0.480910\tAccuracy: 89.30%\n",
      "854\tValidation loss: 0.480794\tBest loss: 0.480794\tAccuracy: 89.40%\n",
      "855\tValidation loss: 0.480724\tBest loss: 0.480724\tAccuracy: 89.40%\n",
      "856\tValidation loss: 0.480706\tBest loss: 0.480706\tAccuracy: 89.30%\n",
      "857\tValidation loss: 0.480523\tBest loss: 0.480523\tAccuracy: 89.30%\n",
      "858\tValidation loss: 0.480437\tBest loss: 0.480437\tAccuracy: 89.30%\n",
      "859\tValidation loss: 0.480330\tBest loss: 0.480330\tAccuracy: 89.30%\n",
      "860\tValidation loss: 0.480224\tBest loss: 0.480224\tAccuracy: 89.40%\n",
      "861\tValidation loss: 0.480167\tBest loss: 0.480167\tAccuracy: 89.40%\n",
      "862\tValidation loss: 0.480081\tBest loss: 0.480081\tAccuracy: 89.40%\n",
      "863\tValidation loss: 0.479927\tBest loss: 0.479927\tAccuracy: 89.40%\n",
      "864\tValidation loss: 0.479680\tBest loss: 0.479680\tAccuracy: 89.40%\n",
      "865\tValidation loss: 0.479565\tBest loss: 0.479565\tAccuracy: 89.40%\n",
      "866\tValidation loss: 0.479430\tBest loss: 0.479430\tAccuracy: 89.40%\n",
      "867\tValidation loss: 0.479391\tBest loss: 0.479391\tAccuracy: 89.40%\n",
      "868\tValidation loss: 0.479178\tBest loss: 0.479178\tAccuracy: 89.40%\n",
      "869\tValidation loss: 0.479171\tBest loss: 0.479171\tAccuracy: 89.40%\n",
      "870\tValidation loss: 0.479142\tBest loss: 0.479142\tAccuracy: 89.40%\n",
      "871\tValidation loss: 0.479024\tBest loss: 0.479024\tAccuracy: 89.40%\n",
      "872\tValidation loss: 0.479010\tBest loss: 0.479010\tAccuracy: 89.40%\n",
      "873\tValidation loss: 0.478887\tBest loss: 0.478887\tAccuracy: 89.40%\n",
      "874\tValidation loss: 0.478815\tBest loss: 0.478815\tAccuracy: 89.40%\n",
      "875\tValidation loss: 0.478568\tBest loss: 0.478568\tAccuracy: 89.40%\n",
      "876\tValidation loss: 0.478557\tBest loss: 0.478557\tAccuracy: 89.40%\n",
      "877\tValidation loss: 0.478413\tBest loss: 0.478413\tAccuracy: 89.40%\n",
      "878\tValidation loss: 0.478250\tBest loss: 0.478250\tAccuracy: 89.40%\n",
      "879\tValidation loss: 0.478122\tBest loss: 0.478122\tAccuracy: 89.40%\n",
      "880\tValidation loss: 0.478016\tBest loss: 0.478016\tAccuracy: 89.40%\n",
      "881\tValidation loss: 0.477943\tBest loss: 0.477943\tAccuracy: 89.40%\n",
      "882\tValidation loss: 0.477830\tBest loss: 0.477830\tAccuracy: 89.40%\n",
      "883\tValidation loss: 0.477758\tBest loss: 0.477758\tAccuracy: 89.40%\n",
      "884\tValidation loss: 0.477610\tBest loss: 0.477610\tAccuracy: 89.40%\n",
      "885\tValidation loss: 0.477532\tBest loss: 0.477532\tAccuracy: 89.40%\n",
      "886\tValidation loss: 0.477512\tBest loss: 0.477512\tAccuracy: 89.40%\n",
      "887\tValidation loss: 0.477352\tBest loss: 0.477352\tAccuracy: 89.40%\n",
      "888\tValidation loss: 0.477270\tBest loss: 0.477270\tAccuracy: 89.40%\n",
      "889\tValidation loss: 0.477190\tBest loss: 0.477190\tAccuracy: 89.40%\n",
      "890\tValidation loss: 0.477075\tBest loss: 0.477075\tAccuracy: 89.40%\n",
      "891\tValidation loss: 0.477016\tBest loss: 0.477016\tAccuracy: 89.40%\n",
      "892\tValidation loss: 0.476993\tBest loss: 0.476993\tAccuracy: 89.40%\n",
      "893\tValidation loss: 0.476800\tBest loss: 0.476800\tAccuracy: 89.40%\n",
      "894\tValidation loss: 0.476696\tBest loss: 0.476696\tAccuracy: 89.40%\n",
      "895\tValidation loss: 0.476664\tBest loss: 0.476664\tAccuracy: 89.40%\n",
      "896\tValidation loss: 0.476598\tBest loss: 0.476598\tAccuracy: 89.40%\n",
      "897\tValidation loss: 0.476463\tBest loss: 0.476463\tAccuracy: 89.40%\n",
      "898\tValidation loss: 0.476375\tBest loss: 0.476375\tAccuracy: 89.40%\n",
      "899\tValidation loss: 0.476247\tBest loss: 0.476247\tAccuracy: 89.40%\n",
      "900\tValidation loss: 0.476122\tBest loss: 0.476122\tAccuracy: 89.40%\n",
      "901\tValidation loss: 0.475869\tBest loss: 0.475869\tAccuracy: 89.40%\n",
      "902\tValidation loss: 0.475794\tBest loss: 0.475794\tAccuracy: 89.40%\n",
      "903\tValidation loss: 0.475752\tBest loss: 0.475752\tAccuracy: 89.40%\n",
      "904\tValidation loss: 0.475634\tBest loss: 0.475634\tAccuracy: 89.40%\n",
      "905\tValidation loss: 0.475525\tBest loss: 0.475525\tAccuracy: 89.40%\n",
      "906\tValidation loss: 0.475473\tBest loss: 0.475473\tAccuracy: 89.40%\n",
      "907\tValidation loss: 0.475387\tBest loss: 0.475387\tAccuracy: 89.40%\n",
      "908\tValidation loss: 0.475264\tBest loss: 0.475264\tAccuracy: 89.40%\n",
      "909\tValidation loss: 0.475211\tBest loss: 0.475211\tAccuracy: 89.40%\n",
      "910\tValidation loss: 0.475118\tBest loss: 0.475118\tAccuracy: 89.40%\n",
      "911\tValidation loss: 0.474953\tBest loss: 0.474953\tAccuracy: 89.40%\n",
      "912\tValidation loss: 0.474894\tBest loss: 0.474894\tAccuracy: 89.40%\n",
      "913\tValidation loss: 0.474764\tBest loss: 0.474764\tAccuracy: 89.40%\n",
      "914\tValidation loss: 0.474701\tBest loss: 0.474701\tAccuracy: 89.40%\n",
      "915\tValidation loss: 0.474543\tBest loss: 0.474543\tAccuracy: 89.40%\n",
      "916\tValidation loss: 0.474548\tBest loss: 0.474543\tAccuracy: 89.40%\n",
      "917\tValidation loss: 0.474373\tBest loss: 0.474373\tAccuracy: 89.40%\n",
      "918\tValidation loss: 0.474196\tBest loss: 0.474196\tAccuracy: 89.40%\n",
      "919\tValidation loss: 0.474222\tBest loss: 0.474196\tAccuracy: 89.40%\n",
      "920\tValidation loss: 0.474208\tBest loss: 0.474196\tAccuracy: 89.40%\n",
      "921\tValidation loss: 0.474157\tBest loss: 0.474157\tAccuracy: 89.40%\n",
      "922\tValidation loss: 0.474077\tBest loss: 0.474077\tAccuracy: 89.40%\n",
      "923\tValidation loss: 0.473869\tBest loss: 0.473869\tAccuracy: 89.40%\n",
      "924\tValidation loss: 0.473631\tBest loss: 0.473631\tAccuracy: 89.40%\n",
      "925\tValidation loss: 0.473686\tBest loss: 0.473631\tAccuracy: 89.40%\n",
      "926\tValidation loss: 0.473645\tBest loss: 0.473631\tAccuracy: 89.40%\n",
      "927\tValidation loss: 0.473534\tBest loss: 0.473534\tAccuracy: 89.40%\n",
      "928\tValidation loss: 0.473388\tBest loss: 0.473388\tAccuracy: 89.40%\n",
      "929\tValidation loss: 0.473192\tBest loss: 0.473192\tAccuracy: 89.40%\n",
      "930\tValidation loss: 0.473173\tBest loss: 0.473173\tAccuracy: 89.40%\n",
      "931\tValidation loss: 0.473123\tBest loss: 0.473123\tAccuracy: 89.40%\n",
      "932\tValidation loss: 0.472951\tBest loss: 0.472951\tAccuracy: 89.40%\n",
      "933\tValidation loss: 0.472795\tBest loss: 0.472795\tAccuracy: 89.40%\n",
      "934\tValidation loss: 0.472676\tBest loss: 0.472676\tAccuracy: 89.40%\n",
      "935\tValidation loss: 0.472628\tBest loss: 0.472628\tAccuracy: 89.40%\n",
      "936\tValidation loss: 0.472542\tBest loss: 0.472542\tAccuracy: 89.40%\n",
      "937\tValidation loss: 0.472534\tBest loss: 0.472534\tAccuracy: 89.40%\n",
      "938\tValidation loss: 0.472419\tBest loss: 0.472419\tAccuracy: 89.40%\n",
      "939\tValidation loss: 0.472235\tBest loss: 0.472235\tAccuracy: 89.40%\n",
      "940\tValidation loss: 0.472055\tBest loss: 0.472055\tAccuracy: 89.40%\n",
      "941\tValidation loss: 0.471930\tBest loss: 0.471930\tAccuracy: 89.40%\n",
      "942\tValidation loss: 0.472012\tBest loss: 0.471930\tAccuracy: 89.40%\n",
      "943\tValidation loss: 0.471974\tBest loss: 0.471930\tAccuracy: 89.40%\n",
      "944\tValidation loss: 0.471783\tBest loss: 0.471783\tAccuracy: 89.40%\n",
      "945\tValidation loss: 0.471715\tBest loss: 0.471715\tAccuracy: 89.40%\n",
      "946\tValidation loss: 0.471736\tBest loss: 0.471715\tAccuracy: 89.40%\n",
      "947\tValidation loss: 0.471534\tBest loss: 0.471534\tAccuracy: 89.40%\n",
      "948\tValidation loss: 0.471478\tBest loss: 0.471478\tAccuracy: 89.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\tValidation loss: 0.471314\tBest loss: 0.471314\tAccuracy: 89.40%\n",
      "950\tValidation loss: 0.471111\tBest loss: 0.471111\tAccuracy: 89.40%\n",
      "951\tValidation loss: 0.471014\tBest loss: 0.471014\tAccuracy: 89.40%\n",
      "952\tValidation loss: 0.471012\tBest loss: 0.471012\tAccuracy: 89.40%\n",
      "953\tValidation loss: 0.470966\tBest loss: 0.470966\tAccuracy: 89.40%\n",
      "954\tValidation loss: 0.470939\tBest loss: 0.470939\tAccuracy: 89.40%\n",
      "955\tValidation loss: 0.470934\tBest loss: 0.470934\tAccuracy: 89.50%\n",
      "956\tValidation loss: 0.470697\tBest loss: 0.470697\tAccuracy: 89.40%\n",
      "957\tValidation loss: 0.470540\tBest loss: 0.470540\tAccuracy: 89.40%\n",
      "958\tValidation loss: 0.470538\tBest loss: 0.470538\tAccuracy: 89.40%\n",
      "959\tValidation loss: 0.470435\tBest loss: 0.470435\tAccuracy: 89.40%\n",
      "960\tValidation loss: 0.470295\tBest loss: 0.470295\tAccuracy: 89.40%\n",
      "961\tValidation loss: 0.470078\tBest loss: 0.470078\tAccuracy: 89.50%\n",
      "962\tValidation loss: 0.470050\tBest loss: 0.470050\tAccuracy: 89.50%\n",
      "963\tValidation loss: 0.469963\tBest loss: 0.469963\tAccuracy: 89.50%\n",
      "964\tValidation loss: 0.469923\tBest loss: 0.469923\tAccuracy: 89.40%\n",
      "965\tValidation loss: 0.469853\tBest loss: 0.469853\tAccuracy: 89.60%\n",
      "966\tValidation loss: 0.469750\tBest loss: 0.469750\tAccuracy: 89.50%\n",
      "967\tValidation loss: 0.469693\tBest loss: 0.469693\tAccuracy: 89.40%\n",
      "968\tValidation loss: 0.469564\tBest loss: 0.469564\tAccuracy: 89.40%\n",
      "969\tValidation loss: 0.469521\tBest loss: 0.469521\tAccuracy: 89.50%\n",
      "970\tValidation loss: 0.469255\tBest loss: 0.469255\tAccuracy: 89.50%\n",
      "971\tValidation loss: 0.469229\tBest loss: 0.469229\tAccuracy: 89.50%\n",
      "972\tValidation loss: 0.469092\tBest loss: 0.469092\tAccuracy: 89.50%\n",
      "973\tValidation loss: 0.469072\tBest loss: 0.469072\tAccuracy: 89.50%\n",
      "974\tValidation loss: 0.468981\tBest loss: 0.468981\tAccuracy: 89.40%\n",
      "975\tValidation loss: 0.468938\tBest loss: 0.468938\tAccuracy: 89.50%\n",
      "976\tValidation loss: 0.468812\tBest loss: 0.468812\tAccuracy: 89.60%\n",
      "977\tValidation loss: 0.468684\tBest loss: 0.468684\tAccuracy: 89.50%\n",
      "978\tValidation loss: 0.468638\tBest loss: 0.468638\tAccuracy: 89.60%\n",
      "979\tValidation loss: 0.468541\tBest loss: 0.468541\tAccuracy: 89.50%\n",
      "980\tValidation loss: 0.468326\tBest loss: 0.468326\tAccuracy: 89.60%\n",
      "981\tValidation loss: 0.468291\tBest loss: 0.468291\tAccuracy: 89.60%\n",
      "982\tValidation loss: 0.468281\tBest loss: 0.468281\tAccuracy: 89.50%\n",
      "983\tValidation loss: 0.468174\tBest loss: 0.468174\tAccuracy: 89.50%\n",
      "984\tValidation loss: 0.468105\tBest loss: 0.468105\tAccuracy: 89.50%\n",
      "985\tValidation loss: 0.468069\tBest loss: 0.468069\tAccuracy: 89.60%\n",
      "986\tValidation loss: 0.467926\tBest loss: 0.467926\tAccuracy: 89.60%\n",
      "987\tValidation loss: 0.467866\tBest loss: 0.467866\tAccuracy: 89.50%\n",
      "988\tValidation loss: 0.467859\tBest loss: 0.467859\tAccuracy: 89.60%\n",
      "989\tValidation loss: 0.467742\tBest loss: 0.467742\tAccuracy: 89.60%\n",
      "990\tValidation loss: 0.467583\tBest loss: 0.467583\tAccuracy: 89.60%\n",
      "991\tValidation loss: 0.467500\tBest loss: 0.467500\tAccuracy: 89.50%\n",
      "992\tValidation loss: 0.467475\tBest loss: 0.467475\tAccuracy: 89.60%\n",
      "993\tValidation loss: 0.467306\tBest loss: 0.467306\tAccuracy: 89.50%\n",
      "994\tValidation loss: 0.467145\tBest loss: 0.467145\tAccuracy: 89.60%\n",
      "995\tValidation loss: 0.467042\tBest loss: 0.467042\tAccuracy: 89.60%\n",
      "996\tValidation loss: 0.466974\tBest loss: 0.466974\tAccuracy: 89.50%\n",
      "997\tValidation loss: 0.466862\tBest loss: 0.466862\tAccuracy: 89.60%\n",
      "998\tValidation loss: 0.466852\tBest loss: 0.466852\tAccuracy: 89.70%\n",
      "999\tValidation loss: 0.466806\tBest loss: 0.466806\tAccuracy: 89.70%\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.8min\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.070784\tBest loss: 3.070784\tAccuracy: 22.20%\n",
      "1\tValidation loss: 2.532242\tBest loss: 2.532242\tAccuracy: 37.30%\n",
      "2\tValidation loss: 2.245597\tBest loss: 2.245597\tAccuracy: 48.30%\n",
      "3\tValidation loss: 2.051902\tBest loss: 2.051902\tAccuracy: 52.80%\n",
      "4\tValidation loss: 1.914364\tBest loss: 1.914364\tAccuracy: 58.40%\n",
      "5\tValidation loss: 1.811872\tBest loss: 1.811872\tAccuracy: 60.10%\n",
      "6\tValidation loss: 1.729216\tBest loss: 1.729216\tAccuracy: 63.10%\n",
      "7\tValidation loss: 1.653234\tBest loss: 1.653234\tAccuracy: 64.70%\n",
      "8\tValidation loss: 1.596775\tBest loss: 1.596775\tAccuracy: 66.70%\n",
      "9\tValidation loss: 1.550673\tBest loss: 1.550673\tAccuracy: 67.70%\n",
      "10\tValidation loss: 1.499340\tBest loss: 1.499340\tAccuracy: 68.30%\n",
      "11\tValidation loss: 1.461712\tBest loss: 1.461712\tAccuracy: 69.80%\n",
      "12\tValidation loss: 1.427128\tBest loss: 1.427128\tAccuracy: 70.10%\n",
      "13\tValidation loss: 1.398012\tBest loss: 1.398012\tAccuracy: 70.60%\n",
      "14\tValidation loss: 1.364330\tBest loss: 1.364330\tAccuracy: 71.70%\n",
      "15\tValidation loss: 1.339192\tBest loss: 1.339192\tAccuracy: 72.60%\n",
      "16\tValidation loss: 1.315801\tBest loss: 1.315801\tAccuracy: 72.40%\n",
      "17\tValidation loss: 1.294875\tBest loss: 1.294875\tAccuracy: 72.50%\n",
      "18\tValidation loss: 1.273917\tBest loss: 1.273917\tAccuracy: 73.40%\n",
      "19\tValidation loss: 1.256017\tBest loss: 1.256017\tAccuracy: 74.30%\n",
      "20\tValidation loss: 1.235742\tBest loss: 1.235742\tAccuracy: 74.80%\n",
      "21\tValidation loss: 1.217189\tBest loss: 1.217189\tAccuracy: 75.60%\n",
      "22\tValidation loss: 1.202278\tBest loss: 1.202278\tAccuracy: 75.50%\n",
      "23\tValidation loss: 1.188928\tBest loss: 1.188928\tAccuracy: 76.20%\n",
      "24\tValidation loss: 1.175676\tBest loss: 1.175676\tAccuracy: 76.20%\n",
      "25\tValidation loss: 1.160861\tBest loss: 1.160861\tAccuracy: 77.30%\n",
      "26\tValidation loss: 1.150153\tBest loss: 1.150153\tAccuracy: 76.50%\n",
      "27\tValidation loss: 1.134645\tBest loss: 1.134645\tAccuracy: 77.10%\n",
      "28\tValidation loss: 1.126033\tBest loss: 1.126033\tAccuracy: 77.60%\n",
      "29\tValidation loss: 1.113279\tBest loss: 1.113279\tAccuracy: 77.70%\n",
      "30\tValidation loss: 1.104500\tBest loss: 1.104500\tAccuracy: 77.40%\n",
      "31\tValidation loss: 1.091516\tBest loss: 1.091516\tAccuracy: 77.60%\n",
      "32\tValidation loss: 1.083682\tBest loss: 1.083682\tAccuracy: 78.40%\n",
      "33\tValidation loss: 1.074985\tBest loss: 1.074985\tAccuracy: 78.70%\n",
      "34\tValidation loss: 1.064902\tBest loss: 1.064902\tAccuracy: 78.70%\n",
      "35\tValidation loss: 1.057310\tBest loss: 1.057310\tAccuracy: 79.10%\n",
      "36\tValidation loss: 1.050013\tBest loss: 1.050013\tAccuracy: 79.00%\n",
      "37\tValidation loss: 1.039697\tBest loss: 1.039697\tAccuracy: 79.50%\n",
      "38\tValidation loss: 1.032523\tBest loss: 1.032523\tAccuracy: 79.30%\n",
      "39\tValidation loss: 1.025125\tBest loss: 1.025125\tAccuracy: 79.30%\n",
      "40\tValidation loss: 1.019491\tBest loss: 1.019491\tAccuracy: 80.40%\n",
      "41\tValidation loss: 1.012184\tBest loss: 1.012184\tAccuracy: 79.90%\n",
      "42\tValidation loss: 1.004862\tBest loss: 1.004862\tAccuracy: 80.00%\n",
      "43\tValidation loss: 0.997290\tBest loss: 0.997290\tAccuracy: 80.40%\n",
      "44\tValidation loss: 0.992096\tBest loss: 0.992096\tAccuracy: 80.10%\n",
      "45\tValidation loss: 0.987219\tBest loss: 0.987219\tAccuracy: 80.40%\n",
      "46\tValidation loss: 0.982121\tBest loss: 0.982121\tAccuracy: 80.50%\n",
      "47\tValidation loss: 0.973976\tBest loss: 0.973976\tAccuracy: 80.40%\n",
      "48\tValidation loss: 0.968809\tBest loss: 0.968809\tAccuracy: 80.70%\n",
      "49\tValidation loss: 0.964000\tBest loss: 0.964000\tAccuracy: 80.70%\n",
      "50\tValidation loss: 0.958864\tBest loss: 0.958864\tAccuracy: 80.90%\n",
      "51\tValidation loss: 0.951764\tBest loss: 0.951764\tAccuracy: 81.20%\n",
      "52\tValidation loss: 0.947422\tBest loss: 0.947422\tAccuracy: 81.20%\n",
      "53\tValidation loss: 0.941312\tBest loss: 0.941312\tAccuracy: 80.80%\n",
      "54\tValidation loss: 0.938157\tBest loss: 0.938157\tAccuracy: 81.40%\n",
      "55\tValidation loss: 0.933287\tBest loss: 0.933287\tAccuracy: 81.60%\n",
      "56\tValidation loss: 0.929072\tBest loss: 0.929072\tAccuracy: 81.40%\n",
      "57\tValidation loss: 0.924760\tBest loss: 0.924760\tAccuracy: 81.60%\n",
      "58\tValidation loss: 0.920808\tBest loss: 0.920808\tAccuracy: 81.50%\n",
      "59\tValidation loss: 0.916646\tBest loss: 0.916646\tAccuracy: 81.90%\n",
      "60\tValidation loss: 0.912612\tBest loss: 0.912612\tAccuracy: 82.00%\n",
      "61\tValidation loss: 0.907963\tBest loss: 0.907963\tAccuracy: 81.90%\n",
      "62\tValidation loss: 0.903503\tBest loss: 0.903503\tAccuracy: 82.40%\n",
      "63\tValidation loss: 0.899360\tBest loss: 0.899360\tAccuracy: 82.10%\n",
      "64\tValidation loss: 0.895811\tBest loss: 0.895811\tAccuracy: 82.10%\n",
      "65\tValidation loss: 0.891551\tBest loss: 0.891551\tAccuracy: 82.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\tValidation loss: 0.888581\tBest loss: 0.888581\tAccuracy: 82.40%\n",
      "67\tValidation loss: 0.885437\tBest loss: 0.885437\tAccuracy: 82.60%\n",
      "68\tValidation loss: 0.881465\tBest loss: 0.881465\tAccuracy: 82.40%\n",
      "69\tValidation loss: 0.878888\tBest loss: 0.878888\tAccuracy: 82.20%\n",
      "70\tValidation loss: 0.874674\tBest loss: 0.874674\tAccuracy: 82.40%\n",
      "71\tValidation loss: 0.871362\tBest loss: 0.871362\tAccuracy: 82.70%\n",
      "72\tValidation loss: 0.869751\tBest loss: 0.869751\tAccuracy: 82.20%\n",
      "73\tValidation loss: 0.865925\tBest loss: 0.865925\tAccuracy: 82.30%\n",
      "74\tValidation loss: 0.862118\tBest loss: 0.862118\tAccuracy: 82.20%\n",
      "75\tValidation loss: 0.859908\tBest loss: 0.859908\tAccuracy: 82.50%\n",
      "76\tValidation loss: 0.855871\tBest loss: 0.855871\tAccuracy: 82.80%\n",
      "77\tValidation loss: 0.853217\tBest loss: 0.853217\tAccuracy: 82.70%\n",
      "78\tValidation loss: 0.850369\tBest loss: 0.850369\tAccuracy: 82.50%\n",
      "79\tValidation loss: 0.847594\tBest loss: 0.847594\tAccuracy: 82.80%\n",
      "80\tValidation loss: 0.845288\tBest loss: 0.845288\tAccuracy: 82.80%\n",
      "81\tValidation loss: 0.843201\tBest loss: 0.843201\tAccuracy: 82.80%\n",
      "82\tValidation loss: 0.839606\tBest loss: 0.839606\tAccuracy: 83.10%\n",
      "83\tValidation loss: 0.837714\tBest loss: 0.837714\tAccuracy: 82.60%\n",
      "84\tValidation loss: 0.834135\tBest loss: 0.834135\tAccuracy: 82.80%\n",
      "85\tValidation loss: 0.830966\tBest loss: 0.830966\tAccuracy: 82.90%\n",
      "86\tValidation loss: 0.829139\tBest loss: 0.829139\tAccuracy: 83.00%\n",
      "87\tValidation loss: 0.825703\tBest loss: 0.825703\tAccuracy: 82.80%\n",
      "88\tValidation loss: 0.823630\tBest loss: 0.823630\tAccuracy: 82.80%\n",
      "89\tValidation loss: 0.821313\tBest loss: 0.821313\tAccuracy: 83.00%\n",
      "90\tValidation loss: 0.819238\tBest loss: 0.819238\tAccuracy: 83.00%\n",
      "91\tValidation loss: 0.816522\tBest loss: 0.816522\tAccuracy: 82.80%\n",
      "92\tValidation loss: 0.814855\tBest loss: 0.814855\tAccuracy: 82.90%\n",
      "93\tValidation loss: 0.811693\tBest loss: 0.811693\tAccuracy: 83.10%\n",
      "94\tValidation loss: 0.809312\tBest loss: 0.809312\tAccuracy: 82.90%\n",
      "95\tValidation loss: 0.807952\tBest loss: 0.807952\tAccuracy: 82.90%\n",
      "96\tValidation loss: 0.805673\tBest loss: 0.805673\tAccuracy: 82.90%\n",
      "97\tValidation loss: 0.803859\tBest loss: 0.803859\tAccuracy: 83.00%\n",
      "98\tValidation loss: 0.801741\tBest loss: 0.801741\tAccuracy: 83.00%\n",
      "99\tValidation loss: 0.799870\tBest loss: 0.799870\tAccuracy: 83.20%\n",
      "100\tValidation loss: 0.797573\tBest loss: 0.797573\tAccuracy: 83.30%\n",
      "101\tValidation loss: 0.795445\tBest loss: 0.795445\tAccuracy: 83.10%\n",
      "102\tValidation loss: 0.793491\tBest loss: 0.793491\tAccuracy: 83.20%\n",
      "103\tValidation loss: 0.791228\tBest loss: 0.791228\tAccuracy: 83.20%\n",
      "104\tValidation loss: 0.789923\tBest loss: 0.789923\tAccuracy: 82.80%\n",
      "105\tValidation loss: 0.787971\tBest loss: 0.787971\tAccuracy: 82.90%\n",
      "106\tValidation loss: 0.785528\tBest loss: 0.785528\tAccuracy: 83.40%\n",
      "107\tValidation loss: 0.784268\tBest loss: 0.784268\tAccuracy: 83.50%\n",
      "108\tValidation loss: 0.781811\tBest loss: 0.781811\tAccuracy: 83.60%\n",
      "109\tValidation loss: 0.780867\tBest loss: 0.780867\tAccuracy: 83.40%\n",
      "110\tValidation loss: 0.778588\tBest loss: 0.778588\tAccuracy: 83.30%\n",
      "111\tValidation loss: 0.776136\tBest loss: 0.776136\tAccuracy: 83.30%\n",
      "112\tValidation loss: 0.775338\tBest loss: 0.775338\tAccuracy: 83.40%\n",
      "113\tValidation loss: 0.773403\tBest loss: 0.773403\tAccuracy: 83.20%\n",
      "114\tValidation loss: 0.771200\tBest loss: 0.771200\tAccuracy: 83.60%\n",
      "115\tValidation loss: 0.769725\tBest loss: 0.769725\tAccuracy: 83.60%\n",
      "116\tValidation loss: 0.768216\tBest loss: 0.768216\tAccuracy: 83.50%\n",
      "117\tValidation loss: 0.766564\tBest loss: 0.766564\tAccuracy: 83.40%\n",
      "118\tValidation loss: 0.764241\tBest loss: 0.764241\tAccuracy: 83.80%\n",
      "119\tValidation loss: 0.763391\tBest loss: 0.763391\tAccuracy: 83.60%\n",
      "120\tValidation loss: 0.760950\tBest loss: 0.760950\tAccuracy: 83.60%\n",
      "121\tValidation loss: 0.759949\tBest loss: 0.759949\tAccuracy: 83.70%\n",
      "122\tValidation loss: 0.758197\tBest loss: 0.758197\tAccuracy: 83.70%\n",
      "123\tValidation loss: 0.756716\tBest loss: 0.756716\tAccuracy: 83.60%\n",
      "124\tValidation loss: 0.755476\tBest loss: 0.755476\tAccuracy: 83.70%\n",
      "125\tValidation loss: 0.753977\tBest loss: 0.753977\tAccuracy: 83.90%\n",
      "126\tValidation loss: 0.751989\tBest loss: 0.751989\tAccuracy: 83.90%\n",
      "127\tValidation loss: 0.750415\tBest loss: 0.750415\tAccuracy: 83.90%\n",
      "128\tValidation loss: 0.748922\tBest loss: 0.748922\tAccuracy: 83.80%\n",
      "129\tValidation loss: 0.747651\tBest loss: 0.747651\tAccuracy: 83.90%\n",
      "130\tValidation loss: 0.745364\tBest loss: 0.745364\tAccuracy: 83.90%\n",
      "131\tValidation loss: 0.744682\tBest loss: 0.744682\tAccuracy: 83.90%\n",
      "132\tValidation loss: 0.743436\tBest loss: 0.743436\tAccuracy: 84.00%\n",
      "133\tValidation loss: 0.742435\tBest loss: 0.742435\tAccuracy: 84.00%\n",
      "134\tValidation loss: 0.740641\tBest loss: 0.740641\tAccuracy: 84.10%\n",
      "135\tValidation loss: 0.740291\tBest loss: 0.740291\tAccuracy: 84.00%\n",
      "136\tValidation loss: 0.738768\tBest loss: 0.738768\tAccuracy: 84.30%\n",
      "137\tValidation loss: 0.737682\tBest loss: 0.737682\tAccuracy: 84.20%\n",
      "138\tValidation loss: 0.734959\tBest loss: 0.734959\tAccuracy: 84.40%\n",
      "139\tValidation loss: 0.734385\tBest loss: 0.734385\tAccuracy: 84.30%\n",
      "140\tValidation loss: 0.732940\tBest loss: 0.732940\tAccuracy: 84.50%\n",
      "141\tValidation loss: 0.732037\tBest loss: 0.732037\tAccuracy: 84.20%\n",
      "142\tValidation loss: 0.730655\tBest loss: 0.730655\tAccuracy: 84.30%\n",
      "143\tValidation loss: 0.728880\tBest loss: 0.728880\tAccuracy: 84.40%\n",
      "144\tValidation loss: 0.727649\tBest loss: 0.727649\tAccuracy: 84.40%\n",
      "145\tValidation loss: 0.726827\tBest loss: 0.726827\tAccuracy: 84.60%\n",
      "146\tValidation loss: 0.725695\tBest loss: 0.725695\tAccuracy: 84.50%\n",
      "147\tValidation loss: 0.723908\tBest loss: 0.723908\tAccuracy: 84.60%\n",
      "148\tValidation loss: 0.723000\tBest loss: 0.723000\tAccuracy: 84.40%\n",
      "149\tValidation loss: 0.721485\tBest loss: 0.721485\tAccuracy: 84.50%\n",
      "150\tValidation loss: 0.720644\tBest loss: 0.720644\tAccuracy: 84.70%\n",
      "151\tValidation loss: 0.718870\tBest loss: 0.718870\tAccuracy: 84.70%\n",
      "152\tValidation loss: 0.717731\tBest loss: 0.717731\tAccuracy: 84.70%\n",
      "153\tValidation loss: 0.717211\tBest loss: 0.717211\tAccuracy: 84.70%\n",
      "154\tValidation loss: 0.716016\tBest loss: 0.716016\tAccuracy: 84.60%\n",
      "155\tValidation loss: 0.714759\tBest loss: 0.714759\tAccuracy: 84.90%\n",
      "156\tValidation loss: 0.714068\tBest loss: 0.714068\tAccuracy: 85.30%\n",
      "157\tValidation loss: 0.712589\tBest loss: 0.712589\tAccuracy: 84.70%\n",
      "158\tValidation loss: 0.711240\tBest loss: 0.711240\tAccuracy: 84.80%\n",
      "159\tValidation loss: 0.710542\tBest loss: 0.710542\tAccuracy: 85.20%\n",
      "160\tValidation loss: 0.709486\tBest loss: 0.709486\tAccuracy: 85.00%\n",
      "161\tValidation loss: 0.708736\tBest loss: 0.708736\tAccuracy: 85.10%\n",
      "162\tValidation loss: 0.707463\tBest loss: 0.707463\tAccuracy: 84.90%\n",
      "163\tValidation loss: 0.706464\tBest loss: 0.706464\tAccuracy: 85.10%\n",
      "164\tValidation loss: 0.705050\tBest loss: 0.705050\tAccuracy: 85.10%\n",
      "165\tValidation loss: 0.704039\tBest loss: 0.704039\tAccuracy: 85.40%\n",
      "166\tValidation loss: 0.702773\tBest loss: 0.702773\tAccuracy: 85.40%\n",
      "167\tValidation loss: 0.701943\tBest loss: 0.701943\tAccuracy: 85.60%\n",
      "168\tValidation loss: 0.700924\tBest loss: 0.700924\tAccuracy: 85.70%\n",
      "169\tValidation loss: 0.700180\tBest loss: 0.700180\tAccuracy: 85.60%\n",
      "170\tValidation loss: 0.698731\tBest loss: 0.698731\tAccuracy: 85.40%\n",
      "171\tValidation loss: 0.698285\tBest loss: 0.698285\tAccuracy: 85.40%\n",
      "172\tValidation loss: 0.696924\tBest loss: 0.696924\tAccuracy: 85.30%\n",
      "173\tValidation loss: 0.696223\tBest loss: 0.696223\tAccuracy: 85.50%\n",
      "174\tValidation loss: 0.695302\tBest loss: 0.695302\tAccuracy: 85.50%\n",
      "175\tValidation loss: 0.694786\tBest loss: 0.694786\tAccuracy: 85.50%\n",
      "176\tValidation loss: 0.693610\tBest loss: 0.693610\tAccuracy: 85.50%\n",
      "177\tValidation loss: 0.692559\tBest loss: 0.692559\tAccuracy: 85.90%\n",
      "178\tValidation loss: 0.691565\tBest loss: 0.691565\tAccuracy: 85.50%\n",
      "179\tValidation loss: 0.690468\tBest loss: 0.690468\tAccuracy: 85.80%\n",
      "180\tValidation loss: 0.689736\tBest loss: 0.689736\tAccuracy: 86.00%\n",
      "181\tValidation loss: 0.688352\tBest loss: 0.688352\tAccuracy: 86.00%\n",
      "182\tValidation loss: 0.687490\tBest loss: 0.687490\tAccuracy: 85.80%\n",
      "183\tValidation loss: 0.686675\tBest loss: 0.686675\tAccuracy: 85.60%\n",
      "184\tValidation loss: 0.686199\tBest loss: 0.686199\tAccuracy: 85.70%\n",
      "185\tValidation loss: 0.684951\tBest loss: 0.684951\tAccuracy: 85.70%\n",
      "186\tValidation loss: 0.684663\tBest loss: 0.684663\tAccuracy: 85.70%\n",
      "187\tValidation loss: 0.683837\tBest loss: 0.683837\tAccuracy: 86.00%\n",
      "188\tValidation loss: 0.682653\tBest loss: 0.682653\tAccuracy: 86.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\tValidation loss: 0.681488\tBest loss: 0.681488\tAccuracy: 86.00%\n",
      "190\tValidation loss: 0.680607\tBest loss: 0.680607\tAccuracy: 86.10%\n",
      "191\tValidation loss: 0.679945\tBest loss: 0.679945\tAccuracy: 85.80%\n",
      "192\tValidation loss: 0.678991\tBest loss: 0.678991\tAccuracy: 85.90%\n",
      "193\tValidation loss: 0.678381\tBest loss: 0.678381\tAccuracy: 85.80%\n",
      "194\tValidation loss: 0.677527\tBest loss: 0.677527\tAccuracy: 85.60%\n",
      "195\tValidation loss: 0.676802\tBest loss: 0.676802\tAccuracy: 85.90%\n",
      "196\tValidation loss: 0.676086\tBest loss: 0.676086\tAccuracy: 85.90%\n",
      "197\tValidation loss: 0.675428\tBest loss: 0.675428\tAccuracy: 86.10%\n",
      "198\tValidation loss: 0.674390\tBest loss: 0.674390\tAccuracy: 85.80%\n",
      "199\tValidation loss: 0.673599\tBest loss: 0.673599\tAccuracy: 86.30%\n",
      "200\tValidation loss: 0.672733\tBest loss: 0.672733\tAccuracy: 86.30%\n",
      "201\tValidation loss: 0.671962\tBest loss: 0.671962\tAccuracy: 86.30%\n",
      "202\tValidation loss: 0.670659\tBest loss: 0.670659\tAccuracy: 86.10%\n",
      "203\tValidation loss: 0.670404\tBest loss: 0.670404\tAccuracy: 86.20%\n",
      "204\tValidation loss: 0.669689\tBest loss: 0.669689\tAccuracy: 86.10%\n",
      "205\tValidation loss: 0.668712\tBest loss: 0.668712\tAccuracy: 86.00%\n",
      "206\tValidation loss: 0.668416\tBest loss: 0.668416\tAccuracy: 86.20%\n",
      "207\tValidation loss: 0.667183\tBest loss: 0.667183\tAccuracy: 86.00%\n",
      "208\tValidation loss: 0.666792\tBest loss: 0.666792\tAccuracy: 86.20%\n",
      "209\tValidation loss: 0.665946\tBest loss: 0.665946\tAccuracy: 86.20%\n",
      "210\tValidation loss: 0.665566\tBest loss: 0.665566\tAccuracy: 86.00%\n",
      "211\tValidation loss: 0.664446\tBest loss: 0.664446\tAccuracy: 86.30%\n",
      "212\tValidation loss: 0.663729\tBest loss: 0.663729\tAccuracy: 86.20%\n",
      "213\tValidation loss: 0.662999\tBest loss: 0.662999\tAccuracy: 86.30%\n",
      "214\tValidation loss: 0.662326\tBest loss: 0.662326\tAccuracy: 86.60%\n",
      "215\tValidation loss: 0.661618\tBest loss: 0.661618\tAccuracy: 86.60%\n",
      "216\tValidation loss: 0.660798\tBest loss: 0.660798\tAccuracy: 86.70%\n",
      "217\tValidation loss: 0.659648\tBest loss: 0.659648\tAccuracy: 86.70%\n",
      "218\tValidation loss: 0.659216\tBest loss: 0.659216\tAccuracy: 86.50%\n",
      "219\tValidation loss: 0.658757\tBest loss: 0.658757\tAccuracy: 86.50%\n",
      "220\tValidation loss: 0.657720\tBest loss: 0.657720\tAccuracy: 86.40%\n",
      "221\tValidation loss: 0.657266\tBest loss: 0.657266\tAccuracy: 86.20%\n",
      "222\tValidation loss: 0.656900\tBest loss: 0.656900\tAccuracy: 86.50%\n",
      "223\tValidation loss: 0.655776\tBest loss: 0.655776\tAccuracy: 86.60%\n",
      "224\tValidation loss: 0.655063\tBest loss: 0.655063\tAccuracy: 86.60%\n",
      "225\tValidation loss: 0.654853\tBest loss: 0.654853\tAccuracy: 86.70%\n",
      "226\tValidation loss: 0.653497\tBest loss: 0.653497\tAccuracy: 86.70%\n",
      "227\tValidation loss: 0.652606\tBest loss: 0.652606\tAccuracy: 86.70%\n",
      "228\tValidation loss: 0.652352\tBest loss: 0.652352\tAccuracy: 86.60%\n",
      "229\tValidation loss: 0.651930\tBest loss: 0.651930\tAccuracy: 86.60%\n",
      "230\tValidation loss: 0.651209\tBest loss: 0.651209\tAccuracy: 86.70%\n",
      "231\tValidation loss: 0.650646\tBest loss: 0.650646\tAccuracy: 86.50%\n",
      "232\tValidation loss: 0.649898\tBest loss: 0.649898\tAccuracy: 86.50%\n",
      "233\tValidation loss: 0.648564\tBest loss: 0.648564\tAccuracy: 86.60%\n",
      "234\tValidation loss: 0.648406\tBest loss: 0.648406\tAccuracy: 86.70%\n",
      "235\tValidation loss: 0.647950\tBest loss: 0.647950\tAccuracy: 86.60%\n",
      "236\tValidation loss: 0.646847\tBest loss: 0.646847\tAccuracy: 86.70%\n",
      "237\tValidation loss: 0.646583\tBest loss: 0.646583\tAccuracy: 86.80%\n",
      "238\tValidation loss: 0.646278\tBest loss: 0.646278\tAccuracy: 86.40%\n",
      "239\tValidation loss: 0.646203\tBest loss: 0.646203\tAccuracy: 86.60%\n",
      "240\tValidation loss: 0.645189\tBest loss: 0.645189\tAccuracy: 86.70%\n",
      "241\tValidation loss: 0.644618\tBest loss: 0.644618\tAccuracy: 86.80%\n",
      "242\tValidation loss: 0.644217\tBest loss: 0.644217\tAccuracy: 86.80%\n",
      "243\tValidation loss: 0.643343\tBest loss: 0.643343\tAccuracy: 86.70%\n",
      "244\tValidation loss: 0.642656\tBest loss: 0.642656\tAccuracy: 86.60%\n",
      "245\tValidation loss: 0.641938\tBest loss: 0.641938\tAccuracy: 86.70%\n",
      "246\tValidation loss: 0.641716\tBest loss: 0.641716\tAccuracy: 86.80%\n",
      "247\tValidation loss: 0.641084\tBest loss: 0.641084\tAccuracy: 86.60%\n",
      "248\tValidation loss: 0.640620\tBest loss: 0.640620\tAccuracy: 86.50%\n",
      "249\tValidation loss: 0.639374\tBest loss: 0.639374\tAccuracy: 86.60%\n",
      "250\tValidation loss: 0.639169\tBest loss: 0.639169\tAccuracy: 86.60%\n",
      "251\tValidation loss: 0.638424\tBest loss: 0.638424\tAccuracy: 86.60%\n",
      "252\tValidation loss: 0.638102\tBest loss: 0.638102\tAccuracy: 86.60%\n",
      "253\tValidation loss: 0.637525\tBest loss: 0.637525\tAccuracy: 86.60%\n",
      "254\tValidation loss: 0.636842\tBest loss: 0.636842\tAccuracy: 86.60%\n",
      "255\tValidation loss: 0.636555\tBest loss: 0.636555\tAccuracy: 86.60%\n",
      "256\tValidation loss: 0.635921\tBest loss: 0.635921\tAccuracy: 86.60%\n",
      "257\tValidation loss: 0.635282\tBest loss: 0.635282\tAccuracy: 86.80%\n",
      "258\tValidation loss: 0.634882\tBest loss: 0.634882\tAccuracy: 86.70%\n",
      "259\tValidation loss: 0.634047\tBest loss: 0.634047\tAccuracy: 86.70%\n",
      "260\tValidation loss: 0.633625\tBest loss: 0.633625\tAccuracy: 86.70%\n",
      "261\tValidation loss: 0.632879\tBest loss: 0.632879\tAccuracy: 86.80%\n",
      "262\tValidation loss: 0.632291\tBest loss: 0.632291\tAccuracy: 86.80%\n",
      "263\tValidation loss: 0.631832\tBest loss: 0.631832\tAccuracy: 86.90%\n",
      "264\tValidation loss: 0.631633\tBest loss: 0.631633\tAccuracy: 86.90%\n",
      "265\tValidation loss: 0.631128\tBest loss: 0.631128\tAccuracy: 86.70%\n",
      "266\tValidation loss: 0.630142\tBest loss: 0.630142\tAccuracy: 86.80%\n",
      "267\tValidation loss: 0.629768\tBest loss: 0.629768\tAccuracy: 86.80%\n",
      "268\tValidation loss: 0.629382\tBest loss: 0.629382\tAccuracy: 86.90%\n",
      "269\tValidation loss: 0.628773\tBest loss: 0.628773\tAccuracy: 86.80%\n",
      "270\tValidation loss: 0.628452\tBest loss: 0.628452\tAccuracy: 86.70%\n",
      "271\tValidation loss: 0.627523\tBest loss: 0.627523\tAccuracy: 86.90%\n",
      "272\tValidation loss: 0.626831\tBest loss: 0.626831\tAccuracy: 87.10%\n",
      "273\tValidation loss: 0.626253\tBest loss: 0.626253\tAccuracy: 87.00%\n",
      "274\tValidation loss: 0.626118\tBest loss: 0.626118\tAccuracy: 86.90%\n",
      "275\tValidation loss: 0.625560\tBest loss: 0.625560\tAccuracy: 86.80%\n",
      "276\tValidation loss: 0.624859\tBest loss: 0.624859\tAccuracy: 87.10%\n",
      "277\tValidation loss: 0.624758\tBest loss: 0.624758\tAccuracy: 86.90%\n",
      "278\tValidation loss: 0.623898\tBest loss: 0.623898\tAccuracy: 87.00%\n",
      "279\tValidation loss: 0.623447\tBest loss: 0.623447\tAccuracy: 86.90%\n",
      "280\tValidation loss: 0.622758\tBest loss: 0.622758\tAccuracy: 86.80%\n",
      "281\tValidation loss: 0.622500\tBest loss: 0.622500\tAccuracy: 87.00%\n",
      "282\tValidation loss: 0.622292\tBest loss: 0.622292\tAccuracy: 86.90%\n",
      "283\tValidation loss: 0.621800\tBest loss: 0.621800\tAccuracy: 87.10%\n",
      "284\tValidation loss: 0.621020\tBest loss: 0.621020\tAccuracy: 87.20%\n",
      "285\tValidation loss: 0.620281\tBest loss: 0.620281\tAccuracy: 87.10%\n",
      "286\tValidation loss: 0.620367\tBest loss: 0.620281\tAccuracy: 86.80%\n",
      "287\tValidation loss: 0.619595\tBest loss: 0.619595\tAccuracy: 87.00%\n",
      "288\tValidation loss: 0.619128\tBest loss: 0.619128\tAccuracy: 87.20%\n",
      "289\tValidation loss: 0.618829\tBest loss: 0.618829\tAccuracy: 87.30%\n",
      "290\tValidation loss: 0.618161\tBest loss: 0.618161\tAccuracy: 87.20%\n",
      "291\tValidation loss: 0.617955\tBest loss: 0.617955\tAccuracy: 87.00%\n",
      "292\tValidation loss: 0.617753\tBest loss: 0.617753\tAccuracy: 86.90%\n",
      "293\tValidation loss: 0.617431\tBest loss: 0.617431\tAccuracy: 86.90%\n",
      "294\tValidation loss: 0.616319\tBest loss: 0.616319\tAccuracy: 86.80%\n",
      "295\tValidation loss: 0.615710\tBest loss: 0.615710\tAccuracy: 87.10%\n",
      "296\tValidation loss: 0.615484\tBest loss: 0.615484\tAccuracy: 87.10%\n",
      "297\tValidation loss: 0.615235\tBest loss: 0.615235\tAccuracy: 87.20%\n",
      "298\tValidation loss: 0.614483\tBest loss: 0.614483\tAccuracy: 87.20%\n",
      "299\tValidation loss: 0.614132\tBest loss: 0.614132\tAccuracy: 87.20%\n",
      "300\tValidation loss: 0.613612\tBest loss: 0.613612\tAccuracy: 87.00%\n",
      "301\tValidation loss: 0.613408\tBest loss: 0.613408\tAccuracy: 87.00%\n",
      "302\tValidation loss: 0.612923\tBest loss: 0.612923\tAccuracy: 87.20%\n",
      "303\tValidation loss: 0.612662\tBest loss: 0.612662\tAccuracy: 87.10%\n",
      "304\tValidation loss: 0.611839\tBest loss: 0.611839\tAccuracy: 87.00%\n",
      "305\tValidation loss: 0.611247\tBest loss: 0.611247\tAccuracy: 87.10%\n",
      "306\tValidation loss: 0.610928\tBest loss: 0.610928\tAccuracy: 87.20%\n",
      "307\tValidation loss: 0.610870\tBest loss: 0.610870\tAccuracy: 87.30%\n",
      "308\tValidation loss: 0.610245\tBest loss: 0.610245\tAccuracy: 87.30%\n",
      "309\tValidation loss: 0.609774\tBest loss: 0.609774\tAccuracy: 87.20%\n",
      "310\tValidation loss: 0.609239\tBest loss: 0.609239\tAccuracy: 87.20%\n",
      "311\tValidation loss: 0.608989\tBest loss: 0.608989\tAccuracy: 87.20%\n",
      "312\tValidation loss: 0.608720\tBest loss: 0.608720\tAccuracy: 87.20%\n",
      "313\tValidation loss: 0.608186\tBest loss: 0.608186\tAccuracy: 87.20%\n",
      "314\tValidation loss: 0.608095\tBest loss: 0.608095\tAccuracy: 87.10%\n",
      "315\tValidation loss: 0.607567\tBest loss: 0.607567\tAccuracy: 87.10%\n",
      "316\tValidation loss: 0.607015\tBest loss: 0.607015\tAccuracy: 87.10%\n",
      "317\tValidation loss: 0.606432\tBest loss: 0.606432\tAccuracy: 87.20%\n",
      "318\tValidation loss: 0.606061\tBest loss: 0.606061\tAccuracy: 87.10%\n",
      "319\tValidation loss: 0.605755\tBest loss: 0.605755\tAccuracy: 87.10%\n",
      "320\tValidation loss: 0.605142\tBest loss: 0.605142\tAccuracy: 87.10%\n",
      "321\tValidation loss: 0.604972\tBest loss: 0.604972\tAccuracy: 87.20%\n",
      "322\tValidation loss: 0.604517\tBest loss: 0.604517\tAccuracy: 87.10%\n",
      "323\tValidation loss: 0.604189\tBest loss: 0.604189\tAccuracy: 87.00%\n",
      "324\tValidation loss: 0.603746\tBest loss: 0.603746\tAccuracy: 87.10%\n",
      "325\tValidation loss: 0.603443\tBest loss: 0.603443\tAccuracy: 87.20%\n",
      "326\tValidation loss: 0.602794\tBest loss: 0.602794\tAccuracy: 87.20%\n",
      "327\tValidation loss: 0.602432\tBest loss: 0.602432\tAccuracy: 87.10%\n",
      "328\tValidation loss: 0.602068\tBest loss: 0.602068\tAccuracy: 87.10%\n",
      "329\tValidation loss: 0.601570\tBest loss: 0.601570\tAccuracy: 87.10%\n",
      "330\tValidation loss: 0.601238\tBest loss: 0.601238\tAccuracy: 87.10%\n",
      "331\tValidation loss: 0.600868\tBest loss: 0.600868\tAccuracy: 87.10%\n",
      "332\tValidation loss: 0.600336\tBest loss: 0.600336\tAccuracy: 87.00%\n",
      "333\tValidation loss: 0.600013\tBest loss: 0.600013\tAccuracy: 87.20%\n",
      "334\tValidation loss: 0.599579\tBest loss: 0.599579\tAccuracy: 87.10%\n",
      "335\tValidation loss: 0.599382\tBest loss: 0.599382\tAccuracy: 87.10%\n",
      "336\tValidation loss: 0.598995\tBest loss: 0.598995\tAccuracy: 87.10%\n",
      "337\tValidation loss: 0.598775\tBest loss: 0.598775\tAccuracy: 87.10%\n",
      "338\tValidation loss: 0.598168\tBest loss: 0.598168\tAccuracy: 87.10%\n",
      "339\tValidation loss: 0.597805\tBest loss: 0.597805\tAccuracy: 87.10%\n",
      "340\tValidation loss: 0.597378\tBest loss: 0.597378\tAccuracy: 87.00%\n",
      "341\tValidation loss: 0.596961\tBest loss: 0.596961\tAccuracy: 87.00%\n",
      "342\tValidation loss: 0.596397\tBest loss: 0.596397\tAccuracy: 87.20%\n",
      "343\tValidation loss: 0.596344\tBest loss: 0.596344\tAccuracy: 87.00%\n",
      "344\tValidation loss: 0.595849\tBest loss: 0.595849\tAccuracy: 87.10%\n",
      "345\tValidation loss: 0.595326\tBest loss: 0.595326\tAccuracy: 87.20%\n",
      "346\tValidation loss: 0.594915\tBest loss: 0.594915\tAccuracy: 87.10%\n",
      "347\tValidation loss: 0.594916\tBest loss: 0.594915\tAccuracy: 87.10%\n",
      "348\tValidation loss: 0.594492\tBest loss: 0.594492\tAccuracy: 87.20%\n",
      "349\tValidation loss: 0.594060\tBest loss: 0.594060\tAccuracy: 87.10%\n",
      "350\tValidation loss: 0.593821\tBest loss: 0.593821\tAccuracy: 87.10%\n",
      "351\tValidation loss: 0.593776\tBest loss: 0.593776\tAccuracy: 87.10%\n",
      "352\tValidation loss: 0.593100\tBest loss: 0.593100\tAccuracy: 87.00%\n",
      "353\tValidation loss: 0.592639\tBest loss: 0.592639\tAccuracy: 87.10%\n",
      "354\tValidation loss: 0.592392\tBest loss: 0.592392\tAccuracy: 87.10%\n",
      "355\tValidation loss: 0.591962\tBest loss: 0.591962\tAccuracy: 87.20%\n",
      "356\tValidation loss: 0.591392\tBest loss: 0.591392\tAccuracy: 87.20%\n",
      "357\tValidation loss: 0.591106\tBest loss: 0.591106\tAccuracy: 87.20%\n",
      "358\tValidation loss: 0.590807\tBest loss: 0.590807\tAccuracy: 87.20%\n",
      "359\tValidation loss: 0.590445\tBest loss: 0.590445\tAccuracy: 87.20%\n",
      "360\tValidation loss: 0.589994\tBest loss: 0.589994\tAccuracy: 87.10%\n",
      "361\tValidation loss: 0.589951\tBest loss: 0.589951\tAccuracy: 87.30%\n",
      "362\tValidation loss: 0.589516\tBest loss: 0.589516\tAccuracy: 87.20%\n",
      "363\tValidation loss: 0.589121\tBest loss: 0.589121\tAccuracy: 87.20%\n",
      "364\tValidation loss: 0.588664\tBest loss: 0.588664\tAccuracy: 87.10%\n",
      "365\tValidation loss: 0.588485\tBest loss: 0.588485\tAccuracy: 87.40%\n",
      "366\tValidation loss: 0.588051\tBest loss: 0.588051\tAccuracy: 87.30%\n",
      "367\tValidation loss: 0.587705\tBest loss: 0.587705\tAccuracy: 87.30%\n",
      "368\tValidation loss: 0.587405\tBest loss: 0.587405\tAccuracy: 87.30%\n",
      "369\tValidation loss: 0.587261\tBest loss: 0.587261\tAccuracy: 87.30%\n",
      "370\tValidation loss: 0.586750\tBest loss: 0.586750\tAccuracy: 87.40%\n",
      "371\tValidation loss: 0.586306\tBest loss: 0.586306\tAccuracy: 87.20%\n",
      "372\tValidation loss: 0.586247\tBest loss: 0.586247\tAccuracy: 87.20%\n",
      "373\tValidation loss: 0.585773\tBest loss: 0.585773\tAccuracy: 87.40%\n",
      "374\tValidation loss: 0.585441\tBest loss: 0.585441\tAccuracy: 87.40%\n",
      "375\tValidation loss: 0.585236\tBest loss: 0.585236\tAccuracy: 87.40%\n",
      "376\tValidation loss: 0.584875\tBest loss: 0.584875\tAccuracy: 87.40%\n",
      "377\tValidation loss: 0.584747\tBest loss: 0.584747\tAccuracy: 87.40%\n",
      "378\tValidation loss: 0.584266\tBest loss: 0.584266\tAccuracy: 87.40%\n",
      "379\tValidation loss: 0.583756\tBest loss: 0.583756\tAccuracy: 87.40%\n",
      "380\tValidation loss: 0.583432\tBest loss: 0.583432\tAccuracy: 87.40%\n",
      "381\tValidation loss: 0.583214\tBest loss: 0.583214\tAccuracy: 87.50%\n",
      "382\tValidation loss: 0.582911\tBest loss: 0.582911\tAccuracy: 87.50%\n",
      "383\tValidation loss: 0.582717\tBest loss: 0.582717\tAccuracy: 87.60%\n",
      "384\tValidation loss: 0.582053\tBest loss: 0.582053\tAccuracy: 87.50%\n",
      "385\tValidation loss: 0.582034\tBest loss: 0.582034\tAccuracy: 87.40%\n",
      "386\tValidation loss: 0.581558\tBest loss: 0.581558\tAccuracy: 87.40%\n",
      "387\tValidation loss: 0.581257\tBest loss: 0.581257\tAccuracy: 87.50%\n",
      "388\tValidation loss: 0.580827\tBest loss: 0.580827\tAccuracy: 87.50%\n",
      "389\tValidation loss: 0.580854\tBest loss: 0.580827\tAccuracy: 87.60%\n",
      "390\tValidation loss: 0.580449\tBest loss: 0.580449\tAccuracy: 87.60%\n",
      "391\tValidation loss: 0.580209\tBest loss: 0.580209\tAccuracy: 87.60%\n",
      "392\tValidation loss: 0.579749\tBest loss: 0.579749\tAccuracy: 87.50%\n",
      "393\tValidation loss: 0.579502\tBest loss: 0.579502\tAccuracy: 87.60%\n",
      "394\tValidation loss: 0.579306\tBest loss: 0.579306\tAccuracy: 87.50%\n",
      "395\tValidation loss: 0.578688\tBest loss: 0.578688\tAccuracy: 87.60%\n",
      "396\tValidation loss: 0.578722\tBest loss: 0.578688\tAccuracy: 87.60%\n",
      "397\tValidation loss: 0.578345\tBest loss: 0.578345\tAccuracy: 87.60%\n",
      "398\tValidation loss: 0.577712\tBest loss: 0.577712\tAccuracy: 87.50%\n",
      "399\tValidation loss: 0.577697\tBest loss: 0.577697\tAccuracy: 87.60%\n",
      "400\tValidation loss: 0.577423\tBest loss: 0.577423\tAccuracy: 87.50%\n",
      "401\tValidation loss: 0.576957\tBest loss: 0.576957\tAccuracy: 87.50%\n",
      "402\tValidation loss: 0.576543\tBest loss: 0.576543\tAccuracy: 87.50%\n",
      "403\tValidation loss: 0.576311\tBest loss: 0.576311\tAccuracy: 87.50%\n",
      "404\tValidation loss: 0.575865\tBest loss: 0.575865\tAccuracy: 87.60%\n",
      "405\tValidation loss: 0.575808\tBest loss: 0.575808\tAccuracy: 87.50%\n",
      "406\tValidation loss: 0.575395\tBest loss: 0.575395\tAccuracy: 87.50%\n",
      "407\tValidation loss: 0.575375\tBest loss: 0.575375\tAccuracy: 87.60%\n",
      "408\tValidation loss: 0.575067\tBest loss: 0.575067\tAccuracy: 87.60%\n",
      "409\tValidation loss: 0.574437\tBest loss: 0.574437\tAccuracy: 87.50%\n",
      "410\tValidation loss: 0.574471\tBest loss: 0.574437\tAccuracy: 87.70%\n",
      "411\tValidation loss: 0.574012\tBest loss: 0.574012\tAccuracy: 87.60%\n",
      "412\tValidation loss: 0.573936\tBest loss: 0.573936\tAccuracy: 87.60%\n",
      "413\tValidation loss: 0.573561\tBest loss: 0.573561\tAccuracy: 87.70%\n",
      "414\tValidation loss: 0.573113\tBest loss: 0.573113\tAccuracy: 87.70%\n",
      "415\tValidation loss: 0.572838\tBest loss: 0.572838\tAccuracy: 87.70%\n",
      "416\tValidation loss: 0.572463\tBest loss: 0.572463\tAccuracy: 87.70%\n",
      "417\tValidation loss: 0.572361\tBest loss: 0.572361\tAccuracy: 87.70%\n",
      "418\tValidation loss: 0.572080\tBest loss: 0.572080\tAccuracy: 87.70%\n",
      "419\tValidation loss: 0.571580\tBest loss: 0.571580\tAccuracy: 87.70%\n",
      "420\tValidation loss: 0.571578\tBest loss: 0.571578\tAccuracy: 87.70%\n",
      "421\tValidation loss: 0.571367\tBest loss: 0.571367\tAccuracy: 87.70%\n",
      "422\tValidation loss: 0.570955\tBest loss: 0.570955\tAccuracy: 87.70%\n",
      "423\tValidation loss: 0.570890\tBest loss: 0.570890\tAccuracy: 87.70%\n",
      "424\tValidation loss: 0.570431\tBest loss: 0.570431\tAccuracy: 87.70%\n",
      "425\tValidation loss: 0.570481\tBest loss: 0.570431\tAccuracy: 87.70%\n",
      "426\tValidation loss: 0.570067\tBest loss: 0.570067\tAccuracy: 87.70%\n",
      "427\tValidation loss: 0.569844\tBest loss: 0.569844\tAccuracy: 87.80%\n",
      "428\tValidation loss: 0.569355\tBest loss: 0.569355\tAccuracy: 87.70%\n",
      "429\tValidation loss: 0.569114\tBest loss: 0.569114\tAccuracy: 87.70%\n",
      "430\tValidation loss: 0.569045\tBest loss: 0.569045\tAccuracy: 87.70%\n",
      "431\tValidation loss: 0.568729\tBest loss: 0.568729\tAccuracy: 87.70%\n",
      "432\tValidation loss: 0.568375\tBest loss: 0.568375\tAccuracy: 87.70%\n",
      "433\tValidation loss: 0.567915\tBest loss: 0.567915\tAccuracy: 87.70%\n",
      "434\tValidation loss: 0.567785\tBest loss: 0.567785\tAccuracy: 87.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\tValidation loss: 0.567565\tBest loss: 0.567565\tAccuracy: 87.70%\n",
      "436\tValidation loss: 0.567335\tBest loss: 0.567335\tAccuracy: 87.70%\n",
      "437\tValidation loss: 0.567044\tBest loss: 0.567044\tAccuracy: 87.80%\n",
      "438\tValidation loss: 0.566701\tBest loss: 0.566701\tAccuracy: 87.80%\n",
      "439\tValidation loss: 0.566257\tBest loss: 0.566257\tAccuracy: 87.70%\n",
      "440\tValidation loss: 0.566213\tBest loss: 0.566213\tAccuracy: 87.70%\n",
      "441\tValidation loss: 0.566020\tBest loss: 0.566020\tAccuracy: 87.80%\n",
      "442\tValidation loss: 0.565783\tBest loss: 0.565783\tAccuracy: 87.80%\n",
      "443\tValidation loss: 0.565498\tBest loss: 0.565498\tAccuracy: 87.80%\n",
      "444\tValidation loss: 0.565060\tBest loss: 0.565060\tAccuracy: 87.80%\n",
      "445\tValidation loss: 0.564992\tBest loss: 0.564992\tAccuracy: 87.70%\n",
      "446\tValidation loss: 0.564627\tBest loss: 0.564627\tAccuracy: 87.80%\n",
      "447\tValidation loss: 0.564330\tBest loss: 0.564330\tAccuracy: 87.80%\n",
      "448\tValidation loss: 0.564171\tBest loss: 0.564171\tAccuracy: 87.80%\n",
      "449\tValidation loss: 0.563746\tBest loss: 0.563746\tAccuracy: 87.60%\n",
      "450\tValidation loss: 0.563548\tBest loss: 0.563548\tAccuracy: 87.80%\n",
      "451\tValidation loss: 0.563682\tBest loss: 0.563548\tAccuracy: 87.80%\n",
      "452\tValidation loss: 0.563319\tBest loss: 0.563319\tAccuracy: 87.80%\n",
      "453\tValidation loss: 0.563051\tBest loss: 0.563051\tAccuracy: 87.90%\n",
      "454\tValidation loss: 0.562727\tBest loss: 0.562727\tAccuracy: 87.80%\n",
      "455\tValidation loss: 0.562544\tBest loss: 0.562544\tAccuracy: 87.70%\n",
      "456\tValidation loss: 0.562208\tBest loss: 0.562208\tAccuracy: 87.80%\n",
      "457\tValidation loss: 0.561755\tBest loss: 0.561755\tAccuracy: 87.80%\n",
      "458\tValidation loss: 0.561614\tBest loss: 0.561614\tAccuracy: 87.80%\n",
      "459\tValidation loss: 0.561390\tBest loss: 0.561390\tAccuracy: 87.80%\n",
      "460\tValidation loss: 0.561281\tBest loss: 0.561281\tAccuracy: 87.80%\n",
      "461\tValidation loss: 0.561051\tBest loss: 0.561051\tAccuracy: 87.80%\n",
      "462\tValidation loss: 0.560748\tBest loss: 0.560748\tAccuracy: 87.80%\n",
      "463\tValidation loss: 0.560447\tBest loss: 0.560447\tAccuracy: 87.80%\n",
      "464\tValidation loss: 0.560056\tBest loss: 0.560056\tAccuracy: 87.70%\n",
      "465\tValidation loss: 0.559926\tBest loss: 0.559926\tAccuracy: 87.80%\n",
      "466\tValidation loss: 0.559574\tBest loss: 0.559574\tAccuracy: 87.80%\n",
      "467\tValidation loss: 0.559387\tBest loss: 0.559387\tAccuracy: 87.80%\n",
      "468\tValidation loss: 0.559139\tBest loss: 0.559139\tAccuracy: 87.80%\n",
      "469\tValidation loss: 0.559103\tBest loss: 0.559103\tAccuracy: 87.80%\n",
      "470\tValidation loss: 0.558742\tBest loss: 0.558742\tAccuracy: 87.80%\n",
      "471\tValidation loss: 0.558612\tBest loss: 0.558612\tAccuracy: 87.80%\n",
      "472\tValidation loss: 0.558359\tBest loss: 0.558359\tAccuracy: 87.80%\n",
      "473\tValidation loss: 0.558246\tBest loss: 0.558246\tAccuracy: 87.80%\n",
      "474\tValidation loss: 0.558020\tBest loss: 0.558020\tAccuracy: 87.80%\n",
      "475\tValidation loss: 0.557895\tBest loss: 0.557895\tAccuracy: 87.80%\n",
      "476\tValidation loss: 0.557736\tBest loss: 0.557736\tAccuracy: 87.70%\n",
      "477\tValidation loss: 0.557380\tBest loss: 0.557380\tAccuracy: 87.80%\n",
      "478\tValidation loss: 0.556977\tBest loss: 0.556977\tAccuracy: 87.90%\n",
      "479\tValidation loss: 0.556622\tBest loss: 0.556622\tAccuracy: 87.80%\n",
      "480\tValidation loss: 0.556614\tBest loss: 0.556614\tAccuracy: 87.80%\n",
      "481\tValidation loss: 0.556360\tBest loss: 0.556360\tAccuracy: 87.90%\n",
      "482\tValidation loss: 0.556087\tBest loss: 0.556087\tAccuracy: 88.00%\n",
      "483\tValidation loss: 0.555844\tBest loss: 0.555844\tAccuracy: 87.90%\n",
      "484\tValidation loss: 0.555464\tBest loss: 0.555464\tAccuracy: 87.90%\n",
      "485\tValidation loss: 0.555225\tBest loss: 0.555225\tAccuracy: 87.90%\n",
      "486\tValidation loss: 0.555027\tBest loss: 0.555027\tAccuracy: 88.00%\n",
      "487\tValidation loss: 0.554916\tBest loss: 0.554916\tAccuracy: 87.90%\n",
      "488\tValidation loss: 0.554754\tBest loss: 0.554754\tAccuracy: 87.80%\n",
      "489\tValidation loss: 0.554311\tBest loss: 0.554311\tAccuracy: 87.70%\n",
      "490\tValidation loss: 0.554164\tBest loss: 0.554164\tAccuracy: 87.80%\n",
      "491\tValidation loss: 0.553902\tBest loss: 0.553902\tAccuracy: 87.70%\n",
      "492\tValidation loss: 0.553620\tBest loss: 0.553620\tAccuracy: 87.70%\n",
      "493\tValidation loss: 0.553535\tBest loss: 0.553535\tAccuracy: 87.70%\n",
      "494\tValidation loss: 0.553265\tBest loss: 0.553265\tAccuracy: 87.80%\n",
      "495\tValidation loss: 0.553114\tBest loss: 0.553114\tAccuracy: 87.80%\n",
      "496\tValidation loss: 0.552786\tBest loss: 0.552786\tAccuracy: 87.90%\n",
      "497\tValidation loss: 0.552554\tBest loss: 0.552554\tAccuracy: 87.90%\n",
      "498\tValidation loss: 0.552334\tBest loss: 0.552334\tAccuracy: 88.00%\n",
      "499\tValidation loss: 0.552195\tBest loss: 0.552195\tAccuracy: 87.80%\n",
      "500\tValidation loss: 0.551993\tBest loss: 0.551993\tAccuracy: 87.90%\n",
      "501\tValidation loss: 0.551800\tBest loss: 0.551800\tAccuracy: 87.90%\n",
      "502\tValidation loss: 0.551536\tBest loss: 0.551536\tAccuracy: 87.80%\n",
      "503\tValidation loss: 0.551567\tBest loss: 0.551536\tAccuracy: 87.80%\n",
      "504\tValidation loss: 0.551309\tBest loss: 0.551309\tAccuracy: 88.10%\n",
      "505\tValidation loss: 0.551079\tBest loss: 0.551079\tAccuracy: 87.90%\n",
      "506\tValidation loss: 0.550736\tBest loss: 0.550736\tAccuracy: 88.00%\n",
      "507\tValidation loss: 0.550360\tBest loss: 0.550360\tAccuracy: 87.80%\n",
      "508\tValidation loss: 0.550265\tBest loss: 0.550265\tAccuracy: 87.80%\n",
      "509\tValidation loss: 0.550191\tBest loss: 0.550191\tAccuracy: 87.80%\n",
      "510\tValidation loss: 0.550067\tBest loss: 0.550067\tAccuracy: 88.00%\n",
      "511\tValidation loss: 0.549688\tBest loss: 0.549688\tAccuracy: 87.80%\n",
      "512\tValidation loss: 0.549491\tBest loss: 0.549491\tAccuracy: 87.80%\n",
      "513\tValidation loss: 0.549300\tBest loss: 0.549300\tAccuracy: 87.90%\n",
      "514\tValidation loss: 0.549145\tBest loss: 0.549145\tAccuracy: 87.90%\n",
      "515\tValidation loss: 0.548903\tBest loss: 0.548903\tAccuracy: 88.10%\n",
      "516\tValidation loss: 0.548735\tBest loss: 0.548735\tAccuracy: 87.90%\n",
      "517\tValidation loss: 0.548535\tBest loss: 0.548535\tAccuracy: 87.80%\n",
      "518\tValidation loss: 0.548538\tBest loss: 0.548535\tAccuracy: 88.00%\n",
      "519\tValidation loss: 0.548232\tBest loss: 0.548232\tAccuracy: 87.90%\n",
      "520\tValidation loss: 0.548086\tBest loss: 0.548086\tAccuracy: 88.00%\n",
      "521\tValidation loss: 0.547641\tBest loss: 0.547641\tAccuracy: 88.00%\n",
      "522\tValidation loss: 0.547417\tBest loss: 0.547417\tAccuracy: 88.00%\n",
      "523\tValidation loss: 0.547354\tBest loss: 0.547354\tAccuracy: 87.90%\n",
      "524\tValidation loss: 0.547061\tBest loss: 0.547061\tAccuracy: 87.80%\n",
      "525\tValidation loss: 0.546948\tBest loss: 0.546948\tAccuracy: 87.90%\n",
      "526\tValidation loss: 0.546766\tBest loss: 0.546766\tAccuracy: 88.00%\n",
      "527\tValidation loss: 0.546422\tBest loss: 0.546422\tAccuracy: 87.80%\n",
      "528\tValidation loss: 0.546359\tBest loss: 0.546359\tAccuracy: 88.00%\n",
      "529\tValidation loss: 0.546226\tBest loss: 0.546226\tAccuracy: 88.10%\n",
      "530\tValidation loss: 0.545970\tBest loss: 0.545970\tAccuracy: 88.10%\n",
      "531\tValidation loss: 0.545738\tBest loss: 0.545738\tAccuracy: 87.90%\n",
      "532\tValidation loss: 0.545581\tBest loss: 0.545581\tAccuracy: 88.00%\n",
      "533\tValidation loss: 0.545161\tBest loss: 0.545161\tAccuracy: 88.00%\n",
      "534\tValidation loss: 0.545010\tBest loss: 0.545010\tAccuracy: 88.10%\n",
      "535\tValidation loss: 0.544868\tBest loss: 0.544868\tAccuracy: 88.10%\n",
      "536\tValidation loss: 0.544565\tBest loss: 0.544565\tAccuracy: 88.00%\n",
      "537\tValidation loss: 0.544479\tBest loss: 0.544479\tAccuracy: 88.00%\n",
      "538\tValidation loss: 0.544333\tBest loss: 0.544333\tAccuracy: 87.90%\n",
      "539\tValidation loss: 0.544273\tBest loss: 0.544273\tAccuracy: 88.10%\n",
      "540\tValidation loss: 0.543869\tBest loss: 0.543869\tAccuracy: 88.10%\n",
      "541\tValidation loss: 0.543607\tBest loss: 0.543607\tAccuracy: 88.00%\n",
      "542\tValidation loss: 0.543490\tBest loss: 0.543490\tAccuracy: 88.00%\n",
      "543\tValidation loss: 0.543241\tBest loss: 0.543241\tAccuracy: 88.00%\n",
      "544\tValidation loss: 0.543068\tBest loss: 0.543068\tAccuracy: 88.10%\n",
      "545\tValidation loss: 0.542827\tBest loss: 0.542827\tAccuracy: 88.10%\n",
      "546\tValidation loss: 0.542675\tBest loss: 0.542675\tAccuracy: 88.10%\n",
      "547\tValidation loss: 0.542384\tBest loss: 0.542384\tAccuracy: 88.00%\n",
      "548\tValidation loss: 0.542134\tBest loss: 0.542134\tAccuracy: 88.10%\n",
      "549\tValidation loss: 0.541935\tBest loss: 0.541935\tAccuracy: 88.10%\n",
      "550\tValidation loss: 0.541799\tBest loss: 0.541799\tAccuracy: 88.10%\n",
      "551\tValidation loss: 0.541920\tBest loss: 0.541799\tAccuracy: 88.10%\n",
      "552\tValidation loss: 0.541641\tBest loss: 0.541641\tAccuracy: 88.00%\n",
      "553\tValidation loss: 0.541424\tBest loss: 0.541424\tAccuracy: 88.00%\n",
      "554\tValidation loss: 0.541285\tBest loss: 0.541285\tAccuracy: 88.10%\n",
      "555\tValidation loss: 0.541059\tBest loss: 0.541059\tAccuracy: 88.10%\n",
      "556\tValidation loss: 0.540902\tBest loss: 0.540902\tAccuracy: 88.00%\n",
      "557\tValidation loss: 0.540589\tBest loss: 0.540589\tAccuracy: 88.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\tValidation loss: 0.540416\tBest loss: 0.540416\tAccuracy: 88.00%\n",
      "559\tValidation loss: 0.540138\tBest loss: 0.540138\tAccuracy: 88.00%\n",
      "560\tValidation loss: 0.539929\tBest loss: 0.539929\tAccuracy: 88.10%\n",
      "561\tValidation loss: 0.539796\tBest loss: 0.539796\tAccuracy: 88.10%\n",
      "562\tValidation loss: 0.539756\tBest loss: 0.539756\tAccuracy: 88.10%\n",
      "563\tValidation loss: 0.539717\tBest loss: 0.539717\tAccuracy: 88.00%\n",
      "564\tValidation loss: 0.539305\tBest loss: 0.539305\tAccuracy: 88.10%\n",
      "565\tValidation loss: 0.538895\tBest loss: 0.538895\tAccuracy: 88.00%\n",
      "566\tValidation loss: 0.538909\tBest loss: 0.538895\tAccuracy: 88.00%\n",
      "567\tValidation loss: 0.538683\tBest loss: 0.538683\tAccuracy: 88.00%\n",
      "568\tValidation loss: 0.538492\tBest loss: 0.538492\tAccuracy: 88.00%\n",
      "569\tValidation loss: 0.538416\tBest loss: 0.538416\tAccuracy: 88.00%\n",
      "570\tValidation loss: 0.538294\tBest loss: 0.538294\tAccuracy: 88.00%\n",
      "571\tValidation loss: 0.537967\tBest loss: 0.537967\tAccuracy: 88.00%\n",
      "572\tValidation loss: 0.537729\tBest loss: 0.537729\tAccuracy: 88.00%\n",
      "573\tValidation loss: 0.537644\tBest loss: 0.537644\tAccuracy: 88.00%\n",
      "574\tValidation loss: 0.537352\tBest loss: 0.537352\tAccuracy: 88.00%\n",
      "575\tValidation loss: 0.537344\tBest loss: 0.537344\tAccuracy: 88.00%\n",
      "576\tValidation loss: 0.537367\tBest loss: 0.537344\tAccuracy: 88.00%\n",
      "577\tValidation loss: 0.537100\tBest loss: 0.537100\tAccuracy: 88.00%\n",
      "578\tValidation loss: 0.536932\tBest loss: 0.536932\tAccuracy: 88.00%\n",
      "579\tValidation loss: 0.536659\tBest loss: 0.536659\tAccuracy: 88.00%\n",
      "580\tValidation loss: 0.536358\tBest loss: 0.536358\tAccuracy: 88.10%\n",
      "581\tValidation loss: 0.536321\tBest loss: 0.536321\tAccuracy: 88.00%\n",
      "582\tValidation loss: 0.536077\tBest loss: 0.536077\tAccuracy: 88.10%\n",
      "583\tValidation loss: 0.535972\tBest loss: 0.535972\tAccuracy: 88.10%\n",
      "584\tValidation loss: 0.535715\tBest loss: 0.535715\tAccuracy: 88.10%\n",
      "585\tValidation loss: 0.535675\tBest loss: 0.535675\tAccuracy: 88.00%\n",
      "586\tValidation loss: 0.535367\tBest loss: 0.535367\tAccuracy: 88.00%\n",
      "587\tValidation loss: 0.535291\tBest loss: 0.535291\tAccuracy: 88.00%\n",
      "588\tValidation loss: 0.535043\tBest loss: 0.535043\tAccuracy: 88.10%\n",
      "589\tValidation loss: 0.534966\tBest loss: 0.534966\tAccuracy: 88.00%\n",
      "590\tValidation loss: 0.534727\tBest loss: 0.534727\tAccuracy: 88.00%\n",
      "591\tValidation loss: 0.534777\tBest loss: 0.534727\tAccuracy: 88.10%\n",
      "592\tValidation loss: 0.534307\tBest loss: 0.534307\tAccuracy: 88.00%\n",
      "593\tValidation loss: 0.534308\tBest loss: 0.534307\tAccuracy: 88.10%\n",
      "594\tValidation loss: 0.534112\tBest loss: 0.534112\tAccuracy: 88.10%\n",
      "595\tValidation loss: 0.533917\tBest loss: 0.533917\tAccuracy: 88.10%\n",
      "596\tValidation loss: 0.533535\tBest loss: 0.533535\tAccuracy: 88.20%\n",
      "597\tValidation loss: 0.533451\tBest loss: 0.533451\tAccuracy: 88.20%\n",
      "598\tValidation loss: 0.533342\tBest loss: 0.533342\tAccuracy: 88.10%\n",
      "599\tValidation loss: 0.533131\tBest loss: 0.533131\tAccuracy: 88.10%\n",
      "600\tValidation loss: 0.533198\tBest loss: 0.533131\tAccuracy: 88.00%\n",
      "601\tValidation loss: 0.532820\tBest loss: 0.532820\tAccuracy: 88.10%\n",
      "602\tValidation loss: 0.532708\tBest loss: 0.532708\tAccuracy: 88.10%\n",
      "603\tValidation loss: 0.532445\tBest loss: 0.532445\tAccuracy: 88.20%\n",
      "604\tValidation loss: 0.532317\tBest loss: 0.532317\tAccuracy: 88.20%\n",
      "605\tValidation loss: 0.532239\tBest loss: 0.532239\tAccuracy: 88.20%\n",
      "606\tValidation loss: 0.532080\tBest loss: 0.532080\tAccuracy: 88.20%\n",
      "607\tValidation loss: 0.531975\tBest loss: 0.531975\tAccuracy: 88.10%\n",
      "608\tValidation loss: 0.531881\tBest loss: 0.531881\tAccuracy: 88.10%\n",
      "609\tValidation loss: 0.531677\tBest loss: 0.531677\tAccuracy: 88.10%\n",
      "610\tValidation loss: 0.531579\tBest loss: 0.531579\tAccuracy: 88.20%\n",
      "611\tValidation loss: 0.531354\tBest loss: 0.531354\tAccuracy: 88.20%\n",
      "612\tValidation loss: 0.531013\tBest loss: 0.531013\tAccuracy: 88.30%\n",
      "613\tValidation loss: 0.530847\tBest loss: 0.530847\tAccuracy: 88.20%\n",
      "614\tValidation loss: 0.530742\tBest loss: 0.530742\tAccuracy: 88.20%\n",
      "615\tValidation loss: 0.530705\tBest loss: 0.530705\tAccuracy: 88.20%\n",
      "616\tValidation loss: 0.530491\tBest loss: 0.530491\tAccuracy: 88.30%\n",
      "617\tValidation loss: 0.530251\tBest loss: 0.530251\tAccuracy: 88.20%\n",
      "618\tValidation loss: 0.530126\tBest loss: 0.530126\tAccuracy: 88.30%\n",
      "619\tValidation loss: 0.529979\tBest loss: 0.529979\tAccuracy: 88.30%\n",
      "620\tValidation loss: 0.529751\tBest loss: 0.529751\tAccuracy: 88.30%\n",
      "621\tValidation loss: 0.529696\tBest loss: 0.529696\tAccuracy: 88.30%\n",
      "622\tValidation loss: 0.529741\tBest loss: 0.529696\tAccuracy: 88.20%\n",
      "623\tValidation loss: 0.529519\tBest loss: 0.529519\tAccuracy: 88.20%\n",
      "624\tValidation loss: 0.529245\tBest loss: 0.529245\tAccuracy: 88.40%\n",
      "625\tValidation loss: 0.528972\tBest loss: 0.528972\tAccuracy: 88.40%\n",
      "626\tValidation loss: 0.528911\tBest loss: 0.528911\tAccuracy: 88.40%\n",
      "627\tValidation loss: 0.528794\tBest loss: 0.528794\tAccuracy: 88.40%\n",
      "628\tValidation loss: 0.528444\tBest loss: 0.528444\tAccuracy: 88.30%\n",
      "629\tValidation loss: 0.528250\tBest loss: 0.528250\tAccuracy: 88.30%\n",
      "630\tValidation loss: 0.528136\tBest loss: 0.528136\tAccuracy: 88.30%\n",
      "631\tValidation loss: 0.528033\tBest loss: 0.528033\tAccuracy: 88.30%\n",
      "632\tValidation loss: 0.527872\tBest loss: 0.527872\tAccuracy: 88.30%\n",
      "633\tValidation loss: 0.527747\tBest loss: 0.527747\tAccuracy: 88.30%\n",
      "634\tValidation loss: 0.527623\tBest loss: 0.527623\tAccuracy: 88.30%\n",
      "635\tValidation loss: 0.527430\tBest loss: 0.527430\tAccuracy: 88.30%\n",
      "636\tValidation loss: 0.527267\tBest loss: 0.527267\tAccuracy: 88.30%\n",
      "637\tValidation loss: 0.527184\tBest loss: 0.527184\tAccuracy: 88.30%\n",
      "638\tValidation loss: 0.527065\tBest loss: 0.527065\tAccuracy: 88.30%\n",
      "639\tValidation loss: 0.526904\tBest loss: 0.526904\tAccuracy: 88.30%\n",
      "640\tValidation loss: 0.526737\tBest loss: 0.526737\tAccuracy: 88.30%\n",
      "641\tValidation loss: 0.526478\tBest loss: 0.526478\tAccuracy: 88.30%\n",
      "642\tValidation loss: 0.526370\tBest loss: 0.526370\tAccuracy: 88.40%\n",
      "643\tValidation loss: 0.526294\tBest loss: 0.526294\tAccuracy: 88.50%\n",
      "644\tValidation loss: 0.526080\tBest loss: 0.526080\tAccuracy: 88.50%\n",
      "645\tValidation loss: 0.525848\tBest loss: 0.525848\tAccuracy: 88.40%\n",
      "646\tValidation loss: 0.525811\tBest loss: 0.525811\tAccuracy: 88.40%\n",
      "647\tValidation loss: 0.525751\tBest loss: 0.525751\tAccuracy: 88.40%\n",
      "648\tValidation loss: 0.525510\tBest loss: 0.525510\tAccuracy: 88.50%\n",
      "649\tValidation loss: 0.525258\tBest loss: 0.525258\tAccuracy: 88.50%\n",
      "650\tValidation loss: 0.525091\tBest loss: 0.525091\tAccuracy: 88.50%\n",
      "651\tValidation loss: 0.524988\tBest loss: 0.524988\tAccuracy: 88.40%\n",
      "652\tValidation loss: 0.524864\tBest loss: 0.524864\tAccuracy: 88.50%\n",
      "653\tValidation loss: 0.524709\tBest loss: 0.524709\tAccuracy: 88.50%\n",
      "654\tValidation loss: 0.524716\tBest loss: 0.524709\tAccuracy: 88.40%\n",
      "655\tValidation loss: 0.524445\tBest loss: 0.524445\tAccuracy: 88.40%\n",
      "656\tValidation loss: 0.524272\tBest loss: 0.524272\tAccuracy: 88.40%\n",
      "657\tValidation loss: 0.524259\tBest loss: 0.524259\tAccuracy: 88.50%\n",
      "658\tValidation loss: 0.524053\tBest loss: 0.524053\tAccuracy: 88.40%\n",
      "659\tValidation loss: 0.523942\tBest loss: 0.523942\tAccuracy: 88.50%\n",
      "660\tValidation loss: 0.523901\tBest loss: 0.523901\tAccuracy: 88.50%\n",
      "661\tValidation loss: 0.523596\tBest loss: 0.523596\tAccuracy: 88.50%\n",
      "662\tValidation loss: 0.523543\tBest loss: 0.523543\tAccuracy: 88.50%\n",
      "663\tValidation loss: 0.523157\tBest loss: 0.523157\tAccuracy: 88.60%\n",
      "664\tValidation loss: 0.523064\tBest loss: 0.523064\tAccuracy: 88.60%\n",
      "665\tValidation loss: 0.523036\tBest loss: 0.523036\tAccuracy: 88.50%\n",
      "666\tValidation loss: 0.522930\tBest loss: 0.522930\tAccuracy: 88.40%\n",
      "667\tValidation loss: 0.522715\tBest loss: 0.522715\tAccuracy: 88.40%\n",
      "668\tValidation loss: 0.522632\tBest loss: 0.522632\tAccuracy: 88.50%\n",
      "669\tValidation loss: 0.522382\tBest loss: 0.522382\tAccuracy: 88.60%\n",
      "670\tValidation loss: 0.522256\tBest loss: 0.522256\tAccuracy: 88.70%\n",
      "671\tValidation loss: 0.522253\tBest loss: 0.522253\tAccuracy: 88.70%\n",
      "672\tValidation loss: 0.522178\tBest loss: 0.522178\tAccuracy: 88.60%\n",
      "673\tValidation loss: 0.521980\tBest loss: 0.521980\tAccuracy: 88.50%\n",
      "674\tValidation loss: 0.521776\tBest loss: 0.521776\tAccuracy: 88.60%\n",
      "675\tValidation loss: 0.521417\tBest loss: 0.521417\tAccuracy: 88.60%\n",
      "676\tValidation loss: 0.521529\tBest loss: 0.521417\tAccuracy: 88.50%\n",
      "677\tValidation loss: 0.521431\tBest loss: 0.521417\tAccuracy: 88.50%\n",
      "678\tValidation loss: 0.521215\tBest loss: 0.521215\tAccuracy: 88.60%\n",
      "679\tValidation loss: 0.521014\tBest loss: 0.521014\tAccuracy: 88.50%\n",
      "680\tValidation loss: 0.520999\tBest loss: 0.520999\tAccuracy: 88.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\tValidation loss: 0.520801\tBest loss: 0.520801\tAccuracy: 88.50%\n",
      "682\tValidation loss: 0.520655\tBest loss: 0.520655\tAccuracy: 88.60%\n",
      "683\tValidation loss: 0.520577\tBest loss: 0.520577\tAccuracy: 88.60%\n",
      "684\tValidation loss: 0.520477\tBest loss: 0.520477\tAccuracy: 88.70%\n",
      "685\tValidation loss: 0.520221\tBest loss: 0.520221\tAccuracy: 88.70%\n",
      "686\tValidation loss: 0.520030\tBest loss: 0.520030\tAccuracy: 88.70%\n",
      "687\tValidation loss: 0.519922\tBest loss: 0.519922\tAccuracy: 88.70%\n",
      "688\tValidation loss: 0.519856\tBest loss: 0.519856\tAccuracy: 88.70%\n",
      "689\tValidation loss: 0.519586\tBest loss: 0.519586\tAccuracy: 88.70%\n",
      "690\tValidation loss: 0.519434\tBest loss: 0.519434\tAccuracy: 88.70%\n",
      "691\tValidation loss: 0.519367\tBest loss: 0.519367\tAccuracy: 88.70%\n",
      "692\tValidation loss: 0.519226\tBest loss: 0.519226\tAccuracy: 88.80%\n",
      "693\tValidation loss: 0.519275\tBest loss: 0.519226\tAccuracy: 88.70%\n",
      "694\tValidation loss: 0.519114\tBest loss: 0.519114\tAccuracy: 88.80%\n",
      "695\tValidation loss: 0.518854\tBest loss: 0.518854\tAccuracy: 88.70%\n",
      "696\tValidation loss: 0.518820\tBest loss: 0.518820\tAccuracy: 88.70%\n",
      "697\tValidation loss: 0.518611\tBest loss: 0.518611\tAccuracy: 88.70%\n",
      "698\tValidation loss: 0.518391\tBest loss: 0.518391\tAccuracy: 88.70%\n",
      "699\tValidation loss: 0.518310\tBest loss: 0.518310\tAccuracy: 88.70%\n",
      "700\tValidation loss: 0.518223\tBest loss: 0.518223\tAccuracy: 88.80%\n",
      "701\tValidation loss: 0.517901\tBest loss: 0.517901\tAccuracy: 88.70%\n",
      "702\tValidation loss: 0.517854\tBest loss: 0.517854\tAccuracy: 88.80%\n",
      "703\tValidation loss: 0.517713\tBest loss: 0.517713\tAccuracy: 88.80%\n",
      "704\tValidation loss: 0.517519\tBest loss: 0.517519\tAccuracy: 88.80%\n",
      "705\tValidation loss: 0.517298\tBest loss: 0.517298\tAccuracy: 88.80%\n",
      "706\tValidation loss: 0.517278\tBest loss: 0.517278\tAccuracy: 88.70%\n",
      "707\tValidation loss: 0.517171\tBest loss: 0.517171\tAccuracy: 88.70%\n",
      "708\tValidation loss: 0.517195\tBest loss: 0.517171\tAccuracy: 88.70%\n",
      "709\tValidation loss: 0.517060\tBest loss: 0.517060\tAccuracy: 88.70%\n",
      "710\tValidation loss: 0.516993\tBest loss: 0.516993\tAccuracy: 88.70%\n",
      "711\tValidation loss: 0.516856\tBest loss: 0.516856\tAccuracy: 88.70%\n",
      "712\tValidation loss: 0.516745\tBest loss: 0.516745\tAccuracy: 88.70%\n",
      "713\tValidation loss: 0.516449\tBest loss: 0.516449\tAccuracy: 88.70%\n",
      "714\tValidation loss: 0.516300\tBest loss: 0.516300\tAccuracy: 88.80%\n",
      "715\tValidation loss: 0.516045\tBest loss: 0.516045\tAccuracy: 88.80%\n",
      "716\tValidation loss: 0.516008\tBest loss: 0.516008\tAccuracy: 88.70%\n",
      "717\tValidation loss: 0.515908\tBest loss: 0.515908\tAccuracy: 88.80%\n",
      "718\tValidation loss: 0.515774\tBest loss: 0.515774\tAccuracy: 88.80%\n",
      "719\tValidation loss: 0.515729\tBest loss: 0.515729\tAccuracy: 88.80%\n",
      "720\tValidation loss: 0.515385\tBest loss: 0.515385\tAccuracy: 88.70%\n",
      "721\tValidation loss: 0.515340\tBest loss: 0.515340\tAccuracy: 88.70%\n",
      "722\tValidation loss: 0.515266\tBest loss: 0.515266\tAccuracy: 88.70%\n",
      "723\tValidation loss: 0.515188\tBest loss: 0.515188\tAccuracy: 88.70%\n",
      "724\tValidation loss: 0.515162\tBest loss: 0.515162\tAccuracy: 88.80%\n",
      "725\tValidation loss: 0.515115\tBest loss: 0.515115\tAccuracy: 88.80%\n",
      "726\tValidation loss: 0.514889\tBest loss: 0.514889\tAccuracy: 88.80%\n",
      "727\tValidation loss: 0.514863\tBest loss: 0.514863\tAccuracy: 88.80%\n",
      "728\tValidation loss: 0.514585\tBest loss: 0.514585\tAccuracy: 88.70%\n",
      "729\tValidation loss: 0.514364\tBest loss: 0.514364\tAccuracy: 88.80%\n",
      "730\tValidation loss: 0.514310\tBest loss: 0.514310\tAccuracy: 88.80%\n",
      "731\tValidation loss: 0.513988\tBest loss: 0.513988\tAccuracy: 88.80%\n",
      "732\tValidation loss: 0.514055\tBest loss: 0.513988\tAccuracy: 88.80%\n",
      "733\tValidation loss: 0.513860\tBest loss: 0.513860\tAccuracy: 88.80%\n",
      "734\tValidation loss: 0.513783\tBest loss: 0.513783\tAccuracy: 88.80%\n",
      "735\tValidation loss: 0.513656\tBest loss: 0.513656\tAccuracy: 88.70%\n",
      "736\tValidation loss: 0.513443\tBest loss: 0.513443\tAccuracy: 88.60%\n",
      "737\tValidation loss: 0.513361\tBest loss: 0.513361\tAccuracy: 88.70%\n",
      "738\tValidation loss: 0.513252\tBest loss: 0.513252\tAccuracy: 88.80%\n",
      "739\tValidation loss: 0.513213\tBest loss: 0.513213\tAccuracy: 88.80%\n",
      "740\tValidation loss: 0.513143\tBest loss: 0.513143\tAccuracy: 88.80%\n",
      "741\tValidation loss: 0.512941\tBest loss: 0.512941\tAccuracy: 88.80%\n",
      "742\tValidation loss: 0.512855\tBest loss: 0.512855\tAccuracy: 88.80%\n",
      "743\tValidation loss: 0.512572\tBest loss: 0.512572\tAccuracy: 88.80%\n",
      "744\tValidation loss: 0.512529\tBest loss: 0.512529\tAccuracy: 88.80%\n",
      "745\tValidation loss: 0.512309\tBest loss: 0.512309\tAccuracy: 88.80%\n",
      "746\tValidation loss: 0.512183\tBest loss: 0.512183\tAccuracy: 88.80%\n",
      "747\tValidation loss: 0.512128\tBest loss: 0.512128\tAccuracy: 88.90%\n",
      "748\tValidation loss: 0.512056\tBest loss: 0.512056\tAccuracy: 88.90%\n",
      "749\tValidation loss: 0.511926\tBest loss: 0.511926\tAccuracy: 88.80%\n",
      "750\tValidation loss: 0.511854\tBest loss: 0.511854\tAccuracy: 88.80%\n",
      "751\tValidation loss: 0.511816\tBest loss: 0.511816\tAccuracy: 88.80%\n",
      "752\tValidation loss: 0.511751\tBest loss: 0.511751\tAccuracy: 88.90%\n",
      "753\tValidation loss: 0.511547\tBest loss: 0.511547\tAccuracy: 88.90%\n",
      "754\tValidation loss: 0.511419\tBest loss: 0.511419\tAccuracy: 88.90%\n",
      "755\tValidation loss: 0.511292\tBest loss: 0.511292\tAccuracy: 88.90%\n",
      "756\tValidation loss: 0.511180\tBest loss: 0.511180\tAccuracy: 88.90%\n",
      "757\tValidation loss: 0.511103\tBest loss: 0.511103\tAccuracy: 88.80%\n",
      "758\tValidation loss: 0.511004\tBest loss: 0.511004\tAccuracy: 88.90%\n",
      "759\tValidation loss: 0.510859\tBest loss: 0.510859\tAccuracy: 88.90%\n",
      "760\tValidation loss: 0.510681\tBest loss: 0.510681\tAccuracy: 88.90%\n",
      "761\tValidation loss: 0.510610\tBest loss: 0.510610\tAccuracy: 88.80%\n",
      "762\tValidation loss: 0.510578\tBest loss: 0.510578\tAccuracy: 88.80%\n",
      "763\tValidation loss: 0.510430\tBest loss: 0.510430\tAccuracy: 88.80%\n",
      "764\tValidation loss: 0.510358\tBest loss: 0.510358\tAccuracy: 88.80%\n",
      "765\tValidation loss: 0.510151\tBest loss: 0.510151\tAccuracy: 88.80%\n",
      "766\tValidation loss: 0.509981\tBest loss: 0.509981\tAccuracy: 88.80%\n",
      "767\tValidation loss: 0.509790\tBest loss: 0.509790\tAccuracy: 88.80%\n",
      "768\tValidation loss: 0.509800\tBest loss: 0.509790\tAccuracy: 88.90%\n",
      "769\tValidation loss: 0.509656\tBest loss: 0.509656\tAccuracy: 88.80%\n",
      "770\tValidation loss: 0.509470\tBest loss: 0.509470\tAccuracy: 88.80%\n",
      "771\tValidation loss: 0.509310\tBest loss: 0.509310\tAccuracy: 88.80%\n",
      "772\tValidation loss: 0.509211\tBest loss: 0.509211\tAccuracy: 88.80%\n",
      "773\tValidation loss: 0.509145\tBest loss: 0.509145\tAccuracy: 88.80%\n",
      "774\tValidation loss: 0.509019\tBest loss: 0.509019\tAccuracy: 88.80%\n",
      "775\tValidation loss: 0.508818\tBest loss: 0.508818\tAccuracy: 88.80%\n",
      "776\tValidation loss: 0.508769\tBest loss: 0.508769\tAccuracy: 88.80%\n",
      "777\tValidation loss: 0.508728\tBest loss: 0.508728\tAccuracy: 88.80%\n",
      "778\tValidation loss: 0.508670\tBest loss: 0.508670\tAccuracy: 88.80%\n",
      "779\tValidation loss: 0.508537\tBest loss: 0.508537\tAccuracy: 88.80%\n",
      "780\tValidation loss: 0.508412\tBest loss: 0.508412\tAccuracy: 88.80%\n",
      "781\tValidation loss: 0.508363\tBest loss: 0.508363\tAccuracy: 88.80%\n",
      "782\tValidation loss: 0.508231\tBest loss: 0.508231\tAccuracy: 88.80%\n",
      "783\tValidation loss: 0.508066\tBest loss: 0.508066\tAccuracy: 88.80%\n",
      "784\tValidation loss: 0.507871\tBest loss: 0.507871\tAccuracy: 88.80%\n",
      "785\tValidation loss: 0.507734\tBest loss: 0.507734\tAccuracy: 88.80%\n",
      "786\tValidation loss: 0.507629\tBest loss: 0.507629\tAccuracy: 88.80%\n",
      "787\tValidation loss: 0.507486\tBest loss: 0.507486\tAccuracy: 88.80%\n",
      "788\tValidation loss: 0.507418\tBest loss: 0.507418\tAccuracy: 88.80%\n",
      "789\tValidation loss: 0.507261\tBest loss: 0.507261\tAccuracy: 88.80%\n",
      "790\tValidation loss: 0.507159\tBest loss: 0.507159\tAccuracy: 88.80%\n",
      "791\tValidation loss: 0.507063\tBest loss: 0.507063\tAccuracy: 88.80%\n",
      "792\tValidation loss: 0.506999\tBest loss: 0.506999\tAccuracy: 88.80%\n",
      "793\tValidation loss: 0.506989\tBest loss: 0.506989\tAccuracy: 88.80%\n",
      "794\tValidation loss: 0.506719\tBest loss: 0.506719\tAccuracy: 88.80%\n",
      "795\tValidation loss: 0.506684\tBest loss: 0.506684\tAccuracy: 88.80%\n",
      "796\tValidation loss: 0.506562\tBest loss: 0.506562\tAccuracy: 88.80%\n",
      "797\tValidation loss: 0.506553\tBest loss: 0.506553\tAccuracy: 88.80%\n",
      "798\tValidation loss: 0.506415\tBest loss: 0.506415\tAccuracy: 88.80%\n",
      "799\tValidation loss: 0.506263\tBest loss: 0.506263\tAccuracy: 88.80%\n",
      "800\tValidation loss: 0.506226\tBest loss: 0.506226\tAccuracy: 88.80%\n",
      "801\tValidation loss: 0.506080\tBest loss: 0.506080\tAccuracy: 88.80%\n",
      "802\tValidation loss: 0.505897\tBest loss: 0.505897\tAccuracy: 88.80%\n",
      "803\tValidation loss: 0.505868\tBest loss: 0.505868\tAccuracy: 88.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804\tValidation loss: 0.505772\tBest loss: 0.505772\tAccuracy: 88.80%\n",
      "805\tValidation loss: 0.505689\tBest loss: 0.505689\tAccuracy: 88.80%\n",
      "806\tValidation loss: 0.505629\tBest loss: 0.505629\tAccuracy: 88.80%\n",
      "807\tValidation loss: 0.505401\tBest loss: 0.505401\tAccuracy: 88.80%\n",
      "808\tValidation loss: 0.505329\tBest loss: 0.505329\tAccuracy: 88.80%\n",
      "809\tValidation loss: 0.505219\tBest loss: 0.505219\tAccuracy: 88.80%\n",
      "810\tValidation loss: 0.505065\tBest loss: 0.505065\tAccuracy: 88.80%\n",
      "811\tValidation loss: 0.504888\tBest loss: 0.504888\tAccuracy: 89.00%\n",
      "812\tValidation loss: 0.504788\tBest loss: 0.504788\tAccuracy: 89.00%\n",
      "813\tValidation loss: 0.504704\tBest loss: 0.504704\tAccuracy: 89.00%\n",
      "814\tValidation loss: 0.504573\tBest loss: 0.504573\tAccuracy: 89.00%\n",
      "815\tValidation loss: 0.504456\tBest loss: 0.504456\tAccuracy: 88.90%\n",
      "816\tValidation loss: 0.504390\tBest loss: 0.504390\tAccuracy: 89.00%\n",
      "817\tValidation loss: 0.504248\tBest loss: 0.504248\tAccuracy: 89.00%\n",
      "818\tValidation loss: 0.504127\tBest loss: 0.504127\tAccuracy: 89.00%\n",
      "819\tValidation loss: 0.504031\tBest loss: 0.504031\tAccuracy: 89.00%\n",
      "820\tValidation loss: 0.503962\tBest loss: 0.503962\tAccuracy: 89.00%\n",
      "821\tValidation loss: 0.503825\tBest loss: 0.503825\tAccuracy: 89.00%\n",
      "822\tValidation loss: 0.503727\tBest loss: 0.503727\tAccuracy: 89.00%\n",
      "823\tValidation loss: 0.503627\tBest loss: 0.503627\tAccuracy: 89.00%\n",
      "824\tValidation loss: 0.503536\tBest loss: 0.503536\tAccuracy: 89.00%\n",
      "825\tValidation loss: 0.503437\tBest loss: 0.503437\tAccuracy: 88.90%\n",
      "826\tValidation loss: 0.503388\tBest loss: 0.503388\tAccuracy: 88.90%\n",
      "827\tValidation loss: 0.503205\tBest loss: 0.503205\tAccuracy: 89.00%\n",
      "828\tValidation loss: 0.503231\tBest loss: 0.503205\tAccuracy: 89.00%\n",
      "829\tValidation loss: 0.502991\tBest loss: 0.502991\tAccuracy: 89.00%\n",
      "830\tValidation loss: 0.502770\tBest loss: 0.502770\tAccuracy: 89.00%\n",
      "831\tValidation loss: 0.502692\tBest loss: 0.502692\tAccuracy: 89.00%\n",
      "832\tValidation loss: 0.502649\tBest loss: 0.502649\tAccuracy: 89.00%\n",
      "833\tValidation loss: 0.502671\tBest loss: 0.502649\tAccuracy: 89.00%\n",
      "834\tValidation loss: 0.502511\tBest loss: 0.502511\tAccuracy: 89.00%\n",
      "835\tValidation loss: 0.502443\tBest loss: 0.502443\tAccuracy: 89.00%\n",
      "836\tValidation loss: 0.502305\tBest loss: 0.502305\tAccuracy: 89.00%\n",
      "837\tValidation loss: 0.502166\tBest loss: 0.502166\tAccuracy: 89.00%\n",
      "838\tValidation loss: 0.502150\tBest loss: 0.502150\tAccuracy: 89.00%\n",
      "839\tValidation loss: 0.502039\tBest loss: 0.502039\tAccuracy: 89.10%\n",
      "840\tValidation loss: 0.501938\tBest loss: 0.501938\tAccuracy: 89.00%\n",
      "841\tValidation loss: 0.501925\tBest loss: 0.501925\tAccuracy: 89.00%\n",
      "842\tValidation loss: 0.501912\tBest loss: 0.501912\tAccuracy: 89.00%\n",
      "843\tValidation loss: 0.501738\tBest loss: 0.501738\tAccuracy: 89.00%\n",
      "844\tValidation loss: 0.501743\tBest loss: 0.501738\tAccuracy: 89.00%\n",
      "845\tValidation loss: 0.501508\tBest loss: 0.501508\tAccuracy: 89.00%\n",
      "846\tValidation loss: 0.501388\tBest loss: 0.501388\tAccuracy: 89.00%\n",
      "847\tValidation loss: 0.501289\tBest loss: 0.501289\tAccuracy: 89.00%\n",
      "848\tValidation loss: 0.501153\tBest loss: 0.501153\tAccuracy: 88.90%\n",
      "849\tValidation loss: 0.501018\tBest loss: 0.501018\tAccuracy: 89.00%\n",
      "850\tValidation loss: 0.501032\tBest loss: 0.501018\tAccuracy: 89.00%\n",
      "851\tValidation loss: 0.500761\tBest loss: 0.500761\tAccuracy: 89.00%\n",
      "852\tValidation loss: 0.500681\tBest loss: 0.500681\tAccuracy: 89.00%\n",
      "853\tValidation loss: 0.500613\tBest loss: 0.500613\tAccuracy: 89.00%\n",
      "854\tValidation loss: 0.500527\tBest loss: 0.500527\tAccuracy: 89.00%\n",
      "855\tValidation loss: 0.500469\tBest loss: 0.500469\tAccuracy: 89.00%\n",
      "856\tValidation loss: 0.500279\tBest loss: 0.500279\tAccuracy: 89.00%\n",
      "857\tValidation loss: 0.500087\tBest loss: 0.500087\tAccuracy: 89.10%\n",
      "858\tValidation loss: 0.500113\tBest loss: 0.500087\tAccuracy: 89.00%\n",
      "859\tValidation loss: 0.499960\tBest loss: 0.499960\tAccuracy: 89.10%\n",
      "860\tValidation loss: 0.499976\tBest loss: 0.499960\tAccuracy: 89.00%\n",
      "861\tValidation loss: 0.499921\tBest loss: 0.499921\tAccuracy: 89.00%\n",
      "862\tValidation loss: 0.499777\tBest loss: 0.499777\tAccuracy: 89.10%\n",
      "863\tValidation loss: 0.499669\tBest loss: 0.499669\tAccuracy: 89.10%\n",
      "864\tValidation loss: 0.499584\tBest loss: 0.499584\tAccuracy: 89.10%\n",
      "865\tValidation loss: 0.499485\tBest loss: 0.499485\tAccuracy: 89.10%\n",
      "866\tValidation loss: 0.499341\tBest loss: 0.499341\tAccuracy: 89.10%\n",
      "867\tValidation loss: 0.499231\tBest loss: 0.499231\tAccuracy: 89.10%\n",
      "868\tValidation loss: 0.499197\tBest loss: 0.499197\tAccuracy: 89.10%\n",
      "869\tValidation loss: 0.499119\tBest loss: 0.499119\tAccuracy: 89.10%\n",
      "870\tValidation loss: 0.499016\tBest loss: 0.499016\tAccuracy: 89.10%\n",
      "871\tValidation loss: 0.498874\tBest loss: 0.498874\tAccuracy: 89.10%\n",
      "872\tValidation loss: 0.498780\tBest loss: 0.498780\tAccuracy: 89.10%\n",
      "873\tValidation loss: 0.498731\tBest loss: 0.498731\tAccuracy: 89.10%\n",
      "874\tValidation loss: 0.498629\tBest loss: 0.498629\tAccuracy: 89.10%\n",
      "875\tValidation loss: 0.498648\tBest loss: 0.498629\tAccuracy: 89.00%\n",
      "876\tValidation loss: 0.498457\tBest loss: 0.498457\tAccuracy: 89.10%\n",
      "877\tValidation loss: 0.498253\tBest loss: 0.498253\tAccuracy: 89.10%\n",
      "878\tValidation loss: 0.498086\tBest loss: 0.498086\tAccuracy: 89.10%\n",
      "879\tValidation loss: 0.498104\tBest loss: 0.498086\tAccuracy: 89.10%\n",
      "880\tValidation loss: 0.498049\tBest loss: 0.498049\tAccuracy: 89.10%\n",
      "881\tValidation loss: 0.497932\tBest loss: 0.497932\tAccuracy: 89.10%\n",
      "882\tValidation loss: 0.497737\tBest loss: 0.497737\tAccuracy: 89.10%\n",
      "883\tValidation loss: 0.497770\tBest loss: 0.497737\tAccuracy: 89.10%\n",
      "884\tValidation loss: 0.497648\tBest loss: 0.497648\tAccuracy: 89.10%\n",
      "885\tValidation loss: 0.497560\tBest loss: 0.497560\tAccuracy: 89.10%\n",
      "886\tValidation loss: 0.497484\tBest loss: 0.497484\tAccuracy: 89.10%\n",
      "887\tValidation loss: 0.497294\tBest loss: 0.497294\tAccuracy: 89.10%\n",
      "888\tValidation loss: 0.497276\tBest loss: 0.497276\tAccuracy: 89.10%\n",
      "889\tValidation loss: 0.497136\tBest loss: 0.497136\tAccuracy: 89.10%\n",
      "890\tValidation loss: 0.497131\tBest loss: 0.497131\tAccuracy: 89.10%\n",
      "891\tValidation loss: 0.496910\tBest loss: 0.496910\tAccuracy: 89.10%\n",
      "892\tValidation loss: 0.496881\tBest loss: 0.496881\tAccuracy: 89.10%\n",
      "893\tValidation loss: 0.496681\tBest loss: 0.496681\tAccuracy: 89.10%\n",
      "894\tValidation loss: 0.496609\tBest loss: 0.496609\tAccuracy: 89.10%\n",
      "895\tValidation loss: 0.496549\tBest loss: 0.496549\tAccuracy: 89.10%\n",
      "896\tValidation loss: 0.496557\tBest loss: 0.496549\tAccuracy: 89.10%\n",
      "897\tValidation loss: 0.496490\tBest loss: 0.496490\tAccuracy: 89.10%\n",
      "898\tValidation loss: 0.496467\tBest loss: 0.496467\tAccuracy: 89.10%\n",
      "899\tValidation loss: 0.496415\tBest loss: 0.496415\tAccuracy: 89.10%\n",
      "900\tValidation loss: 0.496349\tBest loss: 0.496349\tAccuracy: 89.10%\n",
      "901\tValidation loss: 0.496149\tBest loss: 0.496149\tAccuracy: 89.10%\n",
      "902\tValidation loss: 0.495978\tBest loss: 0.495978\tAccuracy: 89.10%\n",
      "903\tValidation loss: 0.495932\tBest loss: 0.495932\tAccuracy: 89.10%\n",
      "904\tValidation loss: 0.495774\tBest loss: 0.495774\tAccuracy: 89.10%\n",
      "905\tValidation loss: 0.495741\tBest loss: 0.495741\tAccuracy: 89.10%\n",
      "906\tValidation loss: 0.495637\tBest loss: 0.495637\tAccuracy: 89.10%\n",
      "907\tValidation loss: 0.495600\tBest loss: 0.495600\tAccuracy: 89.10%\n",
      "908\tValidation loss: 0.495394\tBest loss: 0.495394\tAccuracy: 89.10%\n",
      "909\tValidation loss: 0.495386\tBest loss: 0.495386\tAccuracy: 89.10%\n",
      "910\tValidation loss: 0.495250\tBest loss: 0.495250\tAccuracy: 89.10%\n",
      "911\tValidation loss: 0.495159\tBest loss: 0.495159\tAccuracy: 89.10%\n",
      "912\tValidation loss: 0.495063\tBest loss: 0.495063\tAccuracy: 89.10%\n",
      "913\tValidation loss: 0.495023\tBest loss: 0.495023\tAccuracy: 89.10%\n",
      "914\tValidation loss: 0.494928\tBest loss: 0.494928\tAccuracy: 89.10%\n",
      "915\tValidation loss: 0.494717\tBest loss: 0.494717\tAccuracy: 89.00%\n",
      "916\tValidation loss: 0.494681\tBest loss: 0.494681\tAccuracy: 89.00%\n",
      "917\tValidation loss: 0.494621\tBest loss: 0.494621\tAccuracy: 89.10%\n",
      "918\tValidation loss: 0.494534\tBest loss: 0.494534\tAccuracy: 89.10%\n",
      "919\tValidation loss: 0.494429\tBest loss: 0.494429\tAccuracy: 89.10%\n",
      "920\tValidation loss: 0.494233\tBest loss: 0.494233\tAccuracy: 89.10%\n",
      "921\tValidation loss: 0.494238\tBest loss: 0.494233\tAccuracy: 89.10%\n",
      "922\tValidation loss: 0.494182\tBest loss: 0.494182\tAccuracy: 89.10%\n",
      "923\tValidation loss: 0.494056\tBest loss: 0.494056\tAccuracy: 89.10%\n",
      "924\tValidation loss: 0.493982\tBest loss: 0.493982\tAccuracy: 89.20%\n",
      "925\tValidation loss: 0.493900\tBest loss: 0.493900\tAccuracy: 89.10%\n",
      "926\tValidation loss: 0.493791\tBest loss: 0.493791\tAccuracy: 89.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\tValidation loss: 0.493701\tBest loss: 0.493701\tAccuracy: 89.30%\n",
      "928\tValidation loss: 0.493613\tBest loss: 0.493613\tAccuracy: 89.20%\n",
      "929\tValidation loss: 0.493650\tBest loss: 0.493613\tAccuracy: 89.30%\n",
      "930\tValidation loss: 0.493623\tBest loss: 0.493613\tAccuracy: 89.30%\n",
      "931\tValidation loss: 0.493503\tBest loss: 0.493503\tAccuracy: 89.30%\n",
      "932\tValidation loss: 0.493359\tBest loss: 0.493359\tAccuracy: 89.30%\n",
      "933\tValidation loss: 0.493245\tBest loss: 0.493245\tAccuracy: 89.30%\n",
      "934\tValidation loss: 0.493248\tBest loss: 0.493245\tAccuracy: 89.30%\n",
      "935\tValidation loss: 0.493081\tBest loss: 0.493081\tAccuracy: 89.30%\n",
      "936\tValidation loss: 0.492894\tBest loss: 0.492894\tAccuracy: 89.30%\n",
      "937\tValidation loss: 0.492823\tBest loss: 0.492823\tAccuracy: 89.30%\n",
      "938\tValidation loss: 0.492749\tBest loss: 0.492749\tAccuracy: 89.20%\n",
      "939\tValidation loss: 0.492636\tBest loss: 0.492636\tAccuracy: 89.30%\n",
      "940\tValidation loss: 0.492664\tBest loss: 0.492636\tAccuracy: 89.30%\n",
      "941\tValidation loss: 0.492448\tBest loss: 0.492448\tAccuracy: 89.30%\n",
      "942\tValidation loss: 0.492346\tBest loss: 0.492346\tAccuracy: 89.30%\n",
      "943\tValidation loss: 0.492209\tBest loss: 0.492209\tAccuracy: 89.30%\n",
      "944\tValidation loss: 0.492129\tBest loss: 0.492129\tAccuracy: 89.40%\n",
      "945\tValidation loss: 0.492041\tBest loss: 0.492041\tAccuracy: 89.40%\n",
      "946\tValidation loss: 0.491986\tBest loss: 0.491986\tAccuracy: 89.40%\n",
      "947\tValidation loss: 0.491867\tBest loss: 0.491867\tAccuracy: 89.40%\n",
      "948\tValidation loss: 0.491764\tBest loss: 0.491764\tAccuracy: 89.40%\n",
      "949\tValidation loss: 0.491683\tBest loss: 0.491683\tAccuracy: 89.30%\n",
      "950\tValidation loss: 0.491583\tBest loss: 0.491583\tAccuracy: 89.30%\n",
      "951\tValidation loss: 0.491541\tBest loss: 0.491541\tAccuracy: 89.30%\n",
      "952\tValidation loss: 0.491499\tBest loss: 0.491499\tAccuracy: 89.40%\n",
      "953\tValidation loss: 0.491414\tBest loss: 0.491414\tAccuracy: 89.30%\n",
      "954\tValidation loss: 0.491447\tBest loss: 0.491414\tAccuracy: 89.30%\n",
      "955\tValidation loss: 0.491303\tBest loss: 0.491303\tAccuracy: 89.20%\n",
      "956\tValidation loss: 0.491262\tBest loss: 0.491262\tAccuracy: 89.20%\n",
      "957\tValidation loss: 0.491089\tBest loss: 0.491089\tAccuracy: 89.30%\n",
      "958\tValidation loss: 0.491000\tBest loss: 0.491000\tAccuracy: 89.30%\n",
      "959\tValidation loss: 0.490945\tBest loss: 0.490945\tAccuracy: 89.40%\n",
      "960\tValidation loss: 0.490856\tBest loss: 0.490856\tAccuracy: 89.40%\n",
      "961\tValidation loss: 0.490763\tBest loss: 0.490763\tAccuracy: 89.40%\n",
      "962\tValidation loss: 0.490719\tBest loss: 0.490719\tAccuracy: 89.30%\n",
      "963\tValidation loss: 0.490515\tBest loss: 0.490515\tAccuracy: 89.30%\n",
      "964\tValidation loss: 0.490391\tBest loss: 0.490391\tAccuracy: 89.30%\n",
      "965\tValidation loss: 0.490365\tBest loss: 0.490365\tAccuracy: 89.30%\n",
      "966\tValidation loss: 0.490352\tBest loss: 0.490352\tAccuracy: 89.20%\n",
      "967\tValidation loss: 0.490301\tBest loss: 0.490301\tAccuracy: 89.40%\n",
      "968\tValidation loss: 0.490383\tBest loss: 0.490301\tAccuracy: 89.30%\n",
      "969\tValidation loss: 0.490338\tBest loss: 0.490301\tAccuracy: 89.30%\n",
      "970\tValidation loss: 0.490104\tBest loss: 0.490104\tAccuracy: 89.30%\n",
      "971\tValidation loss: 0.490035\tBest loss: 0.490035\tAccuracy: 89.30%\n",
      "972\tValidation loss: 0.489855\tBest loss: 0.489855\tAccuracy: 89.30%\n",
      "973\tValidation loss: 0.489829\tBest loss: 0.489829\tAccuracy: 89.30%\n",
      "974\tValidation loss: 0.489773\tBest loss: 0.489773\tAccuracy: 89.30%\n",
      "975\tValidation loss: 0.489633\tBest loss: 0.489633\tAccuracy: 89.40%\n",
      "976\tValidation loss: 0.489563\tBest loss: 0.489563\tAccuracy: 89.40%\n",
      "977\tValidation loss: 0.489536\tBest loss: 0.489536\tAccuracy: 89.40%\n",
      "978\tValidation loss: 0.489358\tBest loss: 0.489358\tAccuracy: 89.40%\n",
      "979\tValidation loss: 0.489168\tBest loss: 0.489168\tAccuracy: 89.30%\n",
      "980\tValidation loss: 0.489033\tBest loss: 0.489033\tAccuracy: 89.20%\n",
      "981\tValidation loss: 0.488931\tBest loss: 0.488931\tAccuracy: 89.30%\n",
      "982\tValidation loss: 0.488882\tBest loss: 0.488882\tAccuracy: 89.20%\n",
      "983\tValidation loss: 0.488932\tBest loss: 0.488882\tAccuracy: 89.20%\n",
      "984\tValidation loss: 0.488842\tBest loss: 0.488842\tAccuracy: 89.20%\n",
      "985\tValidation loss: 0.488811\tBest loss: 0.488811\tAccuracy: 89.40%\n",
      "986\tValidation loss: 0.488733\tBest loss: 0.488733\tAccuracy: 89.40%\n",
      "987\tValidation loss: 0.488700\tBest loss: 0.488700\tAccuracy: 89.60%\n",
      "988\tValidation loss: 0.488621\tBest loss: 0.488621\tAccuracy: 89.60%\n",
      "989\tValidation loss: 0.488452\tBest loss: 0.488452\tAccuracy: 89.60%\n",
      "990\tValidation loss: 0.488452\tBest loss: 0.488452\tAccuracy: 89.50%\n",
      "991\tValidation loss: 0.488304\tBest loss: 0.488304\tAccuracy: 89.40%\n",
      "992\tValidation loss: 0.488288\tBest loss: 0.488288\tAccuracy: 89.40%\n",
      "993\tValidation loss: 0.488230\tBest loss: 0.488230\tAccuracy: 89.50%\n",
      "994\tValidation loss: 0.488118\tBest loss: 0.488118\tAccuracy: 89.50%\n",
      "995\tValidation loss: 0.488090\tBest loss: 0.488090\tAccuracy: 89.60%\n",
      "996\tValidation loss: 0.487972\tBest loss: 0.487972\tAccuracy: 89.50%\n",
      "997\tValidation loss: 0.487837\tBest loss: 0.487837\tAccuracy: 89.50%\n",
      "998\tValidation loss: 0.487851\tBest loss: 0.487837\tAccuracy: 89.50%\n",
      "999\tValidation loss: 0.487713\tBest loss: 0.487713\tAccuracy: 89.70%\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.8min\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.065861\tBest loss: 3.065861\tAccuracy: 20.80%\n",
      "1\tValidation loss: 2.521807\tBest loss: 2.521807\tAccuracy: 39.30%\n",
      "2\tValidation loss: 2.244772\tBest loss: 2.244772\tAccuracy: 47.50%\n",
      "3\tValidation loss: 2.060830\tBest loss: 2.060830\tAccuracy: 51.90%\n",
      "4\tValidation loss: 1.913500\tBest loss: 1.913500\tAccuracy: 57.20%\n",
      "5\tValidation loss: 1.811183\tBest loss: 1.811183\tAccuracy: 60.10%\n",
      "6\tValidation loss: 1.726659\tBest loss: 1.726659\tAccuracy: 63.10%\n",
      "7\tValidation loss: 1.653176\tBest loss: 1.653176\tAccuracy: 64.80%\n",
      "8\tValidation loss: 1.598148\tBest loss: 1.598148\tAccuracy: 66.40%\n",
      "9\tValidation loss: 1.551401\tBest loss: 1.551401\tAccuracy: 67.50%\n",
      "10\tValidation loss: 1.500314\tBest loss: 1.500314\tAccuracy: 68.70%\n",
      "11\tValidation loss: 1.461794\tBest loss: 1.461794\tAccuracy: 68.60%\n",
      "12\tValidation loss: 1.427966\tBest loss: 1.427966\tAccuracy: 70.60%\n",
      "13\tValidation loss: 1.394820\tBest loss: 1.394820\tAccuracy: 71.00%\n",
      "14\tValidation loss: 1.366327\tBest loss: 1.366327\tAccuracy: 71.40%\n",
      "15\tValidation loss: 1.338860\tBest loss: 1.338860\tAccuracy: 72.90%\n",
      "16\tValidation loss: 1.318481\tBest loss: 1.318481\tAccuracy: 72.50%\n",
      "17\tValidation loss: 1.295212\tBest loss: 1.295212\tAccuracy: 73.90%\n",
      "18\tValidation loss: 1.273168\tBest loss: 1.273168\tAccuracy: 73.60%\n",
      "19\tValidation loss: 1.253976\tBest loss: 1.253976\tAccuracy: 74.40%\n",
      "20\tValidation loss: 1.236568\tBest loss: 1.236568\tAccuracy: 75.00%\n",
      "21\tValidation loss: 1.217774\tBest loss: 1.217774\tAccuracy: 75.60%\n",
      "22\tValidation loss: 1.202652\tBest loss: 1.202652\tAccuracy: 75.70%\n",
      "23\tValidation loss: 1.188257\tBest loss: 1.188257\tAccuracy: 76.00%\n",
      "24\tValidation loss: 1.174393\tBest loss: 1.174393\tAccuracy: 76.30%\n",
      "25\tValidation loss: 1.161463\tBest loss: 1.161463\tAccuracy: 75.90%\n",
      "26\tValidation loss: 1.148673\tBest loss: 1.148673\tAccuracy: 76.30%\n",
      "27\tValidation loss: 1.135123\tBest loss: 1.135123\tAccuracy: 77.00%\n",
      "28\tValidation loss: 1.123865\tBest loss: 1.123865\tAccuracy: 77.30%\n",
      "29\tValidation loss: 1.113444\tBest loss: 1.113444\tAccuracy: 77.00%\n",
      "30\tValidation loss: 1.102433\tBest loss: 1.102433\tAccuracy: 77.50%\n",
      "31\tValidation loss: 1.091812\tBest loss: 1.091812\tAccuracy: 77.50%\n",
      "32\tValidation loss: 1.082047\tBest loss: 1.082047\tAccuracy: 78.80%\n",
      "33\tValidation loss: 1.073911\tBest loss: 1.073911\tAccuracy: 78.40%\n",
      "34\tValidation loss: 1.065127\tBest loss: 1.065127\tAccuracy: 78.20%\n",
      "35\tValidation loss: 1.057207\tBest loss: 1.057207\tAccuracy: 78.50%\n",
      "36\tValidation loss: 1.051706\tBest loss: 1.051706\tAccuracy: 78.80%\n",
      "37\tValidation loss: 1.039549\tBest loss: 1.039549\tAccuracy: 78.90%\n",
      "38\tValidation loss: 1.030958\tBest loss: 1.030958\tAccuracy: 79.20%\n",
      "39\tValidation loss: 1.024669\tBest loss: 1.024669\tAccuracy: 79.30%\n",
      "40\tValidation loss: 1.018620\tBest loss: 1.018620\tAccuracy: 79.70%\n",
      "41\tValidation loss: 1.010386\tBest loss: 1.010386\tAccuracy: 79.40%\n",
      "42\tValidation loss: 1.004771\tBest loss: 1.004771\tAccuracy: 79.30%\n",
      "43\tValidation loss: 0.996690\tBest loss: 0.996690\tAccuracy: 79.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\tValidation loss: 0.991584\tBest loss: 0.991584\tAccuracy: 79.90%\n",
      "45\tValidation loss: 0.986215\tBest loss: 0.986215\tAccuracy: 79.50%\n",
      "46\tValidation loss: 0.979572\tBest loss: 0.979572\tAccuracy: 80.00%\n",
      "47\tValidation loss: 0.973472\tBest loss: 0.973472\tAccuracy: 79.80%\n",
      "48\tValidation loss: 0.968832\tBest loss: 0.968832\tAccuracy: 80.50%\n",
      "49\tValidation loss: 0.963484\tBest loss: 0.963484\tAccuracy: 80.20%\n",
      "50\tValidation loss: 0.958256\tBest loss: 0.958256\tAccuracy: 80.40%\n",
      "51\tValidation loss: 0.951563\tBest loss: 0.951563\tAccuracy: 80.50%\n",
      "52\tValidation loss: 0.947660\tBest loss: 0.947660\tAccuracy: 81.40%\n",
      "53\tValidation loss: 0.941381\tBest loss: 0.941381\tAccuracy: 81.30%\n",
      "54\tValidation loss: 0.936889\tBest loss: 0.936889\tAccuracy: 81.40%\n",
      "55\tValidation loss: 0.931636\tBest loss: 0.931636\tAccuracy: 80.80%\n",
      "56\tValidation loss: 0.929123\tBest loss: 0.929123\tAccuracy: 81.50%\n",
      "57\tValidation loss: 0.923567\tBest loss: 0.923567\tAccuracy: 81.80%\n",
      "58\tValidation loss: 0.919891\tBest loss: 0.919891\tAccuracy: 81.70%\n",
      "59\tValidation loss: 0.915173\tBest loss: 0.915173\tAccuracy: 81.70%\n",
      "60\tValidation loss: 0.911164\tBest loss: 0.911164\tAccuracy: 81.30%\n",
      "61\tValidation loss: 0.907325\tBest loss: 0.907325\tAccuracy: 81.70%\n",
      "62\tValidation loss: 0.902511\tBest loss: 0.902511\tAccuracy: 81.90%\n",
      "63\tValidation loss: 0.899610\tBest loss: 0.899610\tAccuracy: 81.50%\n",
      "64\tValidation loss: 0.895909\tBest loss: 0.895909\tAccuracy: 81.50%\n",
      "65\tValidation loss: 0.891880\tBest loss: 0.891880\tAccuracy: 81.80%\n",
      "66\tValidation loss: 0.888414\tBest loss: 0.888414\tAccuracy: 81.70%\n",
      "67\tValidation loss: 0.884456\tBest loss: 0.884456\tAccuracy: 81.40%\n",
      "68\tValidation loss: 0.880621\tBest loss: 0.880621\tAccuracy: 81.70%\n",
      "69\tValidation loss: 0.878218\tBest loss: 0.878218\tAccuracy: 82.00%\n",
      "70\tValidation loss: 0.874378\tBest loss: 0.874378\tAccuracy: 82.20%\n",
      "71\tValidation loss: 0.871059\tBest loss: 0.871059\tAccuracy: 82.30%\n",
      "72\tValidation loss: 0.868182\tBest loss: 0.868182\tAccuracy: 82.40%\n",
      "73\tValidation loss: 0.866023\tBest loss: 0.866023\tAccuracy: 82.60%\n",
      "74\tValidation loss: 0.862690\tBest loss: 0.862690\tAccuracy: 82.20%\n",
      "75\tValidation loss: 0.858400\tBest loss: 0.858400\tAccuracy: 82.00%\n",
      "76\tValidation loss: 0.857098\tBest loss: 0.857098\tAccuracy: 82.50%\n",
      "77\tValidation loss: 0.851735\tBest loss: 0.851735\tAccuracy: 82.80%\n",
      "78\tValidation loss: 0.848422\tBest loss: 0.848422\tAccuracy: 82.50%\n",
      "79\tValidation loss: 0.847179\tBest loss: 0.847179\tAccuracy: 82.70%\n",
      "80\tValidation loss: 0.843743\tBest loss: 0.843743\tAccuracy: 83.00%\n",
      "81\tValidation loss: 0.841807\tBest loss: 0.841807\tAccuracy: 82.40%\n",
      "82\tValidation loss: 0.839522\tBest loss: 0.839522\tAccuracy: 83.00%\n",
      "83\tValidation loss: 0.835729\tBest loss: 0.835729\tAccuracy: 82.80%\n",
      "84\tValidation loss: 0.833595\tBest loss: 0.833595\tAccuracy: 82.60%\n",
      "85\tValidation loss: 0.830067\tBest loss: 0.830067\tAccuracy: 83.00%\n",
      "86\tValidation loss: 0.827681\tBest loss: 0.827681\tAccuracy: 83.10%\n",
      "87\tValidation loss: 0.826240\tBest loss: 0.826240\tAccuracy: 83.00%\n",
      "88\tValidation loss: 0.823665\tBest loss: 0.823665\tAccuracy: 82.80%\n",
      "89\tValidation loss: 0.821652\tBest loss: 0.821652\tAccuracy: 83.30%\n",
      "90\tValidation loss: 0.818781\tBest loss: 0.818781\tAccuracy: 83.00%\n",
      "91\tValidation loss: 0.816116\tBest loss: 0.816116\tAccuracy: 83.10%\n",
      "92\tValidation loss: 0.814538\tBest loss: 0.814538\tAccuracy: 83.20%\n",
      "93\tValidation loss: 0.810817\tBest loss: 0.810817\tAccuracy: 83.40%\n",
      "94\tValidation loss: 0.809041\tBest loss: 0.809041\tAccuracy: 83.80%\n",
      "95\tValidation loss: 0.806820\tBest loss: 0.806820\tAccuracy: 83.90%\n",
      "96\tValidation loss: 0.803805\tBest loss: 0.803805\tAccuracy: 83.70%\n",
      "97\tValidation loss: 0.803381\tBest loss: 0.803381\tAccuracy: 83.20%\n",
      "98\tValidation loss: 0.800647\tBest loss: 0.800647\tAccuracy: 83.60%\n",
      "99\tValidation loss: 0.798914\tBest loss: 0.798914\tAccuracy: 83.50%\n",
      "100\tValidation loss: 0.796019\tBest loss: 0.796019\tAccuracy: 83.80%\n",
      "101\tValidation loss: 0.794459\tBest loss: 0.794459\tAccuracy: 83.80%\n",
      "102\tValidation loss: 0.792330\tBest loss: 0.792330\tAccuracy: 83.50%\n",
      "103\tValidation loss: 0.789482\tBest loss: 0.789482\tAccuracy: 83.90%\n",
      "104\tValidation loss: 0.788094\tBest loss: 0.788094\tAccuracy: 83.80%\n",
      "105\tValidation loss: 0.787619\tBest loss: 0.787619\tAccuracy: 83.60%\n",
      "106\tValidation loss: 0.784904\tBest loss: 0.784904\tAccuracy: 83.70%\n",
      "107\tValidation loss: 0.782761\tBest loss: 0.782761\tAccuracy: 83.80%\n",
      "108\tValidation loss: 0.780465\tBest loss: 0.780465\tAccuracy: 83.90%\n",
      "109\tValidation loss: 0.779003\tBest loss: 0.779003\tAccuracy: 83.70%\n",
      "110\tValidation loss: 0.776921\tBest loss: 0.776921\tAccuracy: 83.90%\n",
      "111\tValidation loss: 0.775307\tBest loss: 0.775307\tAccuracy: 83.80%\n",
      "112\tValidation loss: 0.773268\tBest loss: 0.773268\tAccuracy: 84.00%\n",
      "113\tValidation loss: 0.772329\tBest loss: 0.772329\tAccuracy: 83.80%\n",
      "114\tValidation loss: 0.771337\tBest loss: 0.771337\tAccuracy: 83.80%\n",
      "115\tValidation loss: 0.768671\tBest loss: 0.768671\tAccuracy: 84.00%\n",
      "116\tValidation loss: 0.767662\tBest loss: 0.767662\tAccuracy: 84.00%\n",
      "117\tValidation loss: 0.765332\tBest loss: 0.765332\tAccuracy: 83.90%\n",
      "118\tValidation loss: 0.763214\tBest loss: 0.763214\tAccuracy: 83.90%\n",
      "119\tValidation loss: 0.761688\tBest loss: 0.761688\tAccuracy: 84.00%\n",
      "120\tValidation loss: 0.760124\tBest loss: 0.760124\tAccuracy: 83.90%\n",
      "121\tValidation loss: 0.758487\tBest loss: 0.758487\tAccuracy: 83.90%\n",
      "122\tValidation loss: 0.757183\tBest loss: 0.757183\tAccuracy: 83.90%\n",
      "123\tValidation loss: 0.755919\tBest loss: 0.755919\tAccuracy: 84.00%\n",
      "124\tValidation loss: 0.754694\tBest loss: 0.754694\tAccuracy: 84.00%\n",
      "125\tValidation loss: 0.751960\tBest loss: 0.751960\tAccuracy: 84.20%\n",
      "126\tValidation loss: 0.750255\tBest loss: 0.750255\tAccuracy: 84.20%\n",
      "127\tValidation loss: 0.749151\tBest loss: 0.749151\tAccuracy: 84.30%\n",
      "128\tValidation loss: 0.747299\tBest loss: 0.747299\tAccuracy: 84.20%\n",
      "129\tValidation loss: 0.746193\tBest loss: 0.746193\tAccuracy: 84.20%\n",
      "130\tValidation loss: 0.744589\tBest loss: 0.744589\tAccuracy: 84.00%\n",
      "131\tValidation loss: 0.743774\tBest loss: 0.743774\tAccuracy: 84.40%\n",
      "132\tValidation loss: 0.741418\tBest loss: 0.741418\tAccuracy: 84.50%\n",
      "133\tValidation loss: 0.740746\tBest loss: 0.740746\tAccuracy: 84.50%\n",
      "134\tValidation loss: 0.739335\tBest loss: 0.739335\tAccuracy: 84.50%\n",
      "135\tValidation loss: 0.738155\tBest loss: 0.738155\tAccuracy: 84.30%\n",
      "136\tValidation loss: 0.736707\tBest loss: 0.736707\tAccuracy: 84.40%\n",
      "137\tValidation loss: 0.735712\tBest loss: 0.735712\tAccuracy: 84.50%\n",
      "138\tValidation loss: 0.733773\tBest loss: 0.733773\tAccuracy: 84.60%\n",
      "139\tValidation loss: 0.731991\tBest loss: 0.731991\tAccuracy: 84.50%\n",
      "140\tValidation loss: 0.731059\tBest loss: 0.731059\tAccuracy: 84.40%\n",
      "141\tValidation loss: 0.729442\tBest loss: 0.729442\tAccuracy: 84.40%\n",
      "142\tValidation loss: 0.728500\tBest loss: 0.728500\tAccuracy: 84.50%\n",
      "143\tValidation loss: 0.727147\tBest loss: 0.727147\tAccuracy: 84.20%\n",
      "144\tValidation loss: 0.726140\tBest loss: 0.726140\tAccuracy: 84.60%\n",
      "145\tValidation loss: 0.724642\tBest loss: 0.724642\tAccuracy: 84.80%\n",
      "146\tValidation loss: 0.723617\tBest loss: 0.723617\tAccuracy: 84.80%\n",
      "147\tValidation loss: 0.722017\tBest loss: 0.722017\tAccuracy: 84.70%\n",
      "148\tValidation loss: 0.721350\tBest loss: 0.721350\tAccuracy: 84.70%\n",
      "149\tValidation loss: 0.719979\tBest loss: 0.719979\tAccuracy: 84.80%\n",
      "150\tValidation loss: 0.718240\tBest loss: 0.718240\tAccuracy: 84.80%\n",
      "151\tValidation loss: 0.717127\tBest loss: 0.717127\tAccuracy: 85.00%\n",
      "152\tValidation loss: 0.715771\tBest loss: 0.715771\tAccuracy: 84.70%\n",
      "153\tValidation loss: 0.714431\tBest loss: 0.714431\tAccuracy: 85.00%\n",
      "154\tValidation loss: 0.713861\tBest loss: 0.713861\tAccuracy: 85.00%\n",
      "155\tValidation loss: 0.712837\tBest loss: 0.712837\tAccuracy: 85.10%\n",
      "156\tValidation loss: 0.712141\tBest loss: 0.712141\tAccuracy: 85.00%\n",
      "157\tValidation loss: 0.711078\tBest loss: 0.711078\tAccuracy: 85.30%\n",
      "158\tValidation loss: 0.709159\tBest loss: 0.709159\tAccuracy: 84.80%\n",
      "159\tValidation loss: 0.707496\tBest loss: 0.707496\tAccuracy: 84.80%\n",
      "160\tValidation loss: 0.707395\tBest loss: 0.707395\tAccuracy: 85.10%\n",
      "161\tValidation loss: 0.705843\tBest loss: 0.705843\tAccuracy: 85.20%\n",
      "162\tValidation loss: 0.704524\tBest loss: 0.704524\tAccuracy: 85.00%\n",
      "163\tValidation loss: 0.703393\tBest loss: 0.703393\tAccuracy: 85.20%\n",
      "164\tValidation loss: 0.702548\tBest loss: 0.702548\tAccuracy: 85.40%\n",
      "165\tValidation loss: 0.701529\tBest loss: 0.701529\tAccuracy: 85.30%\n",
      "166\tValidation loss: 0.700454\tBest loss: 0.700454\tAccuracy: 85.20%\n",
      "167\tValidation loss: 0.699646\tBest loss: 0.699646\tAccuracy: 85.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\tValidation loss: 0.698182\tBest loss: 0.698182\tAccuracy: 85.30%\n",
      "169\tValidation loss: 0.697699\tBest loss: 0.697699\tAccuracy: 84.90%\n",
      "170\tValidation loss: 0.696810\tBest loss: 0.696810\tAccuracy: 85.20%\n",
      "171\tValidation loss: 0.695307\tBest loss: 0.695307\tAccuracy: 85.30%\n",
      "172\tValidation loss: 0.694318\tBest loss: 0.694318\tAccuracy: 85.10%\n",
      "173\tValidation loss: 0.693257\tBest loss: 0.693257\tAccuracy: 85.70%\n",
      "174\tValidation loss: 0.692839\tBest loss: 0.692839\tAccuracy: 85.60%\n",
      "175\tValidation loss: 0.691893\tBest loss: 0.691893\tAccuracy: 85.30%\n",
      "176\tValidation loss: 0.691168\tBest loss: 0.691168\tAccuracy: 85.20%\n",
      "177\tValidation loss: 0.689966\tBest loss: 0.689966\tAccuracy: 85.40%\n",
      "178\tValidation loss: 0.688405\tBest loss: 0.688405\tAccuracy: 85.60%\n",
      "179\tValidation loss: 0.687808\tBest loss: 0.687808\tAccuracy: 85.60%\n",
      "180\tValidation loss: 0.686877\tBest loss: 0.686877\tAccuracy: 85.50%\n",
      "181\tValidation loss: 0.685285\tBest loss: 0.685285\tAccuracy: 85.80%\n",
      "182\tValidation loss: 0.684879\tBest loss: 0.684879\tAccuracy: 85.90%\n",
      "183\tValidation loss: 0.683749\tBest loss: 0.683749\tAccuracy: 85.80%\n",
      "184\tValidation loss: 0.683271\tBest loss: 0.683271\tAccuracy: 85.60%\n",
      "185\tValidation loss: 0.681254\tBest loss: 0.681254\tAccuracy: 85.60%\n",
      "186\tValidation loss: 0.681006\tBest loss: 0.681006\tAccuracy: 85.60%\n",
      "187\tValidation loss: 0.679892\tBest loss: 0.679892\tAccuracy: 85.80%\n",
      "188\tValidation loss: 0.679468\tBest loss: 0.679468\tAccuracy: 85.80%\n",
      "189\tValidation loss: 0.678537\tBest loss: 0.678537\tAccuracy: 85.80%\n",
      "190\tValidation loss: 0.677182\tBest loss: 0.677182\tAccuracy: 85.90%\n",
      "191\tValidation loss: 0.676296\tBest loss: 0.676296\tAccuracy: 86.00%\n",
      "192\tValidation loss: 0.675216\tBest loss: 0.675216\tAccuracy: 86.00%\n",
      "193\tValidation loss: 0.674771\tBest loss: 0.674771\tAccuracy: 86.10%\n",
      "194\tValidation loss: 0.674278\tBest loss: 0.674278\tAccuracy: 85.90%\n",
      "195\tValidation loss: 0.673665\tBest loss: 0.673665\tAccuracy: 85.90%\n",
      "196\tValidation loss: 0.672136\tBest loss: 0.672136\tAccuracy: 85.90%\n",
      "197\tValidation loss: 0.671028\tBest loss: 0.671028\tAccuracy: 86.30%\n",
      "198\tValidation loss: 0.670814\tBest loss: 0.670814\tAccuracy: 86.10%\n",
      "199\tValidation loss: 0.670227\tBest loss: 0.670227\tAccuracy: 86.00%\n",
      "200\tValidation loss: 0.669113\tBest loss: 0.669113\tAccuracy: 86.10%\n",
      "201\tValidation loss: 0.668559\tBest loss: 0.668559\tAccuracy: 86.20%\n",
      "202\tValidation loss: 0.667181\tBest loss: 0.667181\tAccuracy: 86.10%\n",
      "203\tValidation loss: 0.666265\tBest loss: 0.666265\tAccuracy: 86.20%\n",
      "204\tValidation loss: 0.665856\tBest loss: 0.665856\tAccuracy: 86.10%\n",
      "205\tValidation loss: 0.664809\tBest loss: 0.664809\tAccuracy: 86.30%\n",
      "206\tValidation loss: 0.664132\tBest loss: 0.664132\tAccuracy: 86.20%\n",
      "207\tValidation loss: 0.663597\tBest loss: 0.663597\tAccuracy: 86.40%\n",
      "208\tValidation loss: 0.662677\tBest loss: 0.662677\tAccuracy: 86.20%\n",
      "209\tValidation loss: 0.661907\tBest loss: 0.661907\tAccuracy: 86.20%\n",
      "210\tValidation loss: 0.661289\tBest loss: 0.661289\tAccuracy: 86.20%\n",
      "211\tValidation loss: 0.660124\tBest loss: 0.660124\tAccuracy: 86.30%\n",
      "212\tValidation loss: 0.659655\tBest loss: 0.659655\tAccuracy: 86.40%\n",
      "213\tValidation loss: 0.659354\tBest loss: 0.659354\tAccuracy: 86.30%\n",
      "214\tValidation loss: 0.657868\tBest loss: 0.657868\tAccuracy: 86.20%\n",
      "215\tValidation loss: 0.657350\tBest loss: 0.657350\tAccuracy: 86.20%\n",
      "216\tValidation loss: 0.656768\tBest loss: 0.656768\tAccuracy: 86.30%\n",
      "217\tValidation loss: 0.655773\tBest loss: 0.655773\tAccuracy: 86.10%\n",
      "218\tValidation loss: 0.654729\tBest loss: 0.654729\tAccuracy: 86.30%\n",
      "219\tValidation loss: 0.654225\tBest loss: 0.654225\tAccuracy: 86.30%\n",
      "220\tValidation loss: 0.653013\tBest loss: 0.653013\tAccuracy: 86.40%\n",
      "221\tValidation loss: 0.652822\tBest loss: 0.652822\tAccuracy: 86.40%\n",
      "222\tValidation loss: 0.652317\tBest loss: 0.652317\tAccuracy: 86.40%\n",
      "223\tValidation loss: 0.651657\tBest loss: 0.651657\tAccuracy: 86.50%\n",
      "224\tValidation loss: 0.650902\tBest loss: 0.650902\tAccuracy: 86.50%\n",
      "225\tValidation loss: 0.650360\tBest loss: 0.650360\tAccuracy: 86.60%\n",
      "226\tValidation loss: 0.649260\tBest loss: 0.649260\tAccuracy: 86.40%\n",
      "227\tValidation loss: 0.648275\tBest loss: 0.648275\tAccuracy: 86.60%\n",
      "228\tValidation loss: 0.647577\tBest loss: 0.647577\tAccuracy: 86.60%\n",
      "229\tValidation loss: 0.647412\tBest loss: 0.647412\tAccuracy: 86.30%\n",
      "230\tValidation loss: 0.646435\tBest loss: 0.646435\tAccuracy: 86.50%\n",
      "231\tValidation loss: 0.645788\tBest loss: 0.645788\tAccuracy: 86.60%\n",
      "232\tValidation loss: 0.644905\tBest loss: 0.644905\tAccuracy: 86.80%\n",
      "233\tValidation loss: 0.644764\tBest loss: 0.644764\tAccuracy: 86.60%\n",
      "234\tValidation loss: 0.644003\tBest loss: 0.644003\tAccuracy: 86.70%\n",
      "235\tValidation loss: 0.643478\tBest loss: 0.643478\tAccuracy: 86.50%\n",
      "236\tValidation loss: 0.642719\tBest loss: 0.642719\tAccuracy: 86.70%\n",
      "237\tValidation loss: 0.642414\tBest loss: 0.642414\tAccuracy: 86.70%\n",
      "238\tValidation loss: 0.641746\tBest loss: 0.641746\tAccuracy: 86.60%\n",
      "239\tValidation loss: 0.640803\tBest loss: 0.640803\tAccuracy: 86.70%\n",
      "240\tValidation loss: 0.640474\tBest loss: 0.640474\tAccuracy: 86.70%\n",
      "241\tValidation loss: 0.639744\tBest loss: 0.639744\tAccuracy: 86.80%\n",
      "242\tValidation loss: 0.638744\tBest loss: 0.638744\tAccuracy: 86.70%\n",
      "243\tValidation loss: 0.638108\tBest loss: 0.638108\tAccuracy: 86.60%\n",
      "244\tValidation loss: 0.637792\tBest loss: 0.637792\tAccuracy: 86.80%\n",
      "245\tValidation loss: 0.636833\tBest loss: 0.636833\tAccuracy: 86.60%\n",
      "246\tValidation loss: 0.636378\tBest loss: 0.636378\tAccuracy: 86.60%\n",
      "247\tValidation loss: 0.635679\tBest loss: 0.635679\tAccuracy: 86.80%\n",
      "248\tValidation loss: 0.634866\tBest loss: 0.634866\tAccuracy: 86.70%\n",
      "249\tValidation loss: 0.634398\tBest loss: 0.634398\tAccuracy: 86.90%\n",
      "250\tValidation loss: 0.633899\tBest loss: 0.633899\tAccuracy: 87.00%\n",
      "251\tValidation loss: 0.633247\tBest loss: 0.633247\tAccuracy: 86.90%\n",
      "252\tValidation loss: 0.632260\tBest loss: 0.632260\tAccuracy: 86.90%\n",
      "253\tValidation loss: 0.631924\tBest loss: 0.631924\tAccuracy: 86.90%\n",
      "254\tValidation loss: 0.631190\tBest loss: 0.631190\tAccuracy: 86.80%\n",
      "255\tValidation loss: 0.630790\tBest loss: 0.630790\tAccuracy: 86.80%\n",
      "256\tValidation loss: 0.630283\tBest loss: 0.630283\tAccuracy: 86.90%\n",
      "257\tValidation loss: 0.629920\tBest loss: 0.629920\tAccuracy: 86.80%\n",
      "258\tValidation loss: 0.629338\tBest loss: 0.629338\tAccuracy: 86.90%\n",
      "259\tValidation loss: 0.629110\tBest loss: 0.629110\tAccuracy: 87.00%\n",
      "260\tValidation loss: 0.627947\tBest loss: 0.627947\tAccuracy: 86.90%\n",
      "261\tValidation loss: 0.627448\tBest loss: 0.627448\tAccuracy: 86.90%\n",
      "262\tValidation loss: 0.627142\tBest loss: 0.627142\tAccuracy: 87.00%\n",
      "263\tValidation loss: 0.625953\tBest loss: 0.625953\tAccuracy: 86.80%\n",
      "264\tValidation loss: 0.625597\tBest loss: 0.625597\tAccuracy: 87.10%\n",
      "265\tValidation loss: 0.624959\tBest loss: 0.624959\tAccuracy: 87.00%\n",
      "266\tValidation loss: 0.624653\tBest loss: 0.624653\tAccuracy: 86.90%\n",
      "267\tValidation loss: 0.623867\tBest loss: 0.623867\tAccuracy: 87.00%\n",
      "268\tValidation loss: 0.623408\tBest loss: 0.623408\tAccuracy: 86.90%\n",
      "269\tValidation loss: 0.622677\tBest loss: 0.622677\tAccuracy: 86.90%\n",
      "270\tValidation loss: 0.622776\tBest loss: 0.622677\tAccuracy: 87.00%\n",
      "271\tValidation loss: 0.621858\tBest loss: 0.621858\tAccuracy: 87.00%\n",
      "272\tValidation loss: 0.620818\tBest loss: 0.620818\tAccuracy: 87.00%\n",
      "273\tValidation loss: 0.620736\tBest loss: 0.620736\tAccuracy: 87.00%\n",
      "274\tValidation loss: 0.620178\tBest loss: 0.620178\tAccuracy: 87.00%\n",
      "275\tValidation loss: 0.620011\tBest loss: 0.620011\tAccuracy: 87.00%\n",
      "276\tValidation loss: 0.619485\tBest loss: 0.619485\tAccuracy: 87.10%\n",
      "277\tValidation loss: 0.618462\tBest loss: 0.618462\tAccuracy: 87.00%\n",
      "278\tValidation loss: 0.618288\tBest loss: 0.618288\tAccuracy: 87.30%\n",
      "279\tValidation loss: 0.617995\tBest loss: 0.617995\tAccuracy: 87.10%\n",
      "280\tValidation loss: 0.617390\tBest loss: 0.617390\tAccuracy: 87.10%\n",
      "281\tValidation loss: 0.616835\tBest loss: 0.616835\tAccuracy: 87.10%\n",
      "282\tValidation loss: 0.616200\tBest loss: 0.616200\tAccuracy: 87.10%\n",
      "283\tValidation loss: 0.615592\tBest loss: 0.615592\tAccuracy: 87.30%\n",
      "284\tValidation loss: 0.615294\tBest loss: 0.615294\tAccuracy: 87.10%\n",
      "285\tValidation loss: 0.614387\tBest loss: 0.614387\tAccuracy: 87.10%\n",
      "286\tValidation loss: 0.614015\tBest loss: 0.614015\tAccuracy: 87.10%\n",
      "287\tValidation loss: 0.613737\tBest loss: 0.613737\tAccuracy: 87.50%\n",
      "288\tValidation loss: 0.612880\tBest loss: 0.612880\tAccuracy: 87.30%\n",
      "289\tValidation loss: 0.612673\tBest loss: 0.612673\tAccuracy: 87.40%\n",
      "290\tValidation loss: 0.611903\tBest loss: 0.611903\tAccuracy: 87.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\tValidation loss: 0.611526\tBest loss: 0.611526\tAccuracy: 87.50%\n",
      "292\tValidation loss: 0.611282\tBest loss: 0.611282\tAccuracy: 87.40%\n",
      "293\tValidation loss: 0.610857\tBest loss: 0.610857\tAccuracy: 87.40%\n",
      "294\tValidation loss: 0.610454\tBest loss: 0.610454\tAccuracy: 87.30%\n",
      "295\tValidation loss: 0.609677\tBest loss: 0.609677\tAccuracy: 87.40%\n",
      "296\tValidation loss: 0.609430\tBest loss: 0.609430\tAccuracy: 87.50%\n",
      "297\tValidation loss: 0.609043\tBest loss: 0.609043\tAccuracy: 87.40%\n",
      "298\tValidation loss: 0.608218\tBest loss: 0.608218\tAccuracy: 87.30%\n",
      "299\tValidation loss: 0.607488\tBest loss: 0.607488\tAccuracy: 87.40%\n",
      "300\tValidation loss: 0.607022\tBest loss: 0.607022\tAccuracy: 87.60%\n",
      "301\tValidation loss: 0.606744\tBest loss: 0.606744\tAccuracy: 87.50%\n",
      "302\tValidation loss: 0.606611\tBest loss: 0.606611\tAccuracy: 87.50%\n",
      "303\tValidation loss: 0.605967\tBest loss: 0.605967\tAccuracy: 87.60%\n",
      "304\tValidation loss: 0.605408\tBest loss: 0.605408\tAccuracy: 87.40%\n",
      "305\tValidation loss: 0.604681\tBest loss: 0.604681\tAccuracy: 87.60%\n",
      "306\tValidation loss: 0.604124\tBest loss: 0.604124\tAccuracy: 87.60%\n",
      "307\tValidation loss: 0.604012\tBest loss: 0.604012\tAccuracy: 87.60%\n",
      "308\tValidation loss: 0.603464\tBest loss: 0.603464\tAccuracy: 87.60%\n",
      "309\tValidation loss: 0.602847\tBest loss: 0.602847\tAccuracy: 87.40%\n",
      "310\tValidation loss: 0.602356\tBest loss: 0.602356\tAccuracy: 87.50%\n",
      "311\tValidation loss: 0.602439\tBest loss: 0.602356\tAccuracy: 87.60%\n",
      "312\tValidation loss: 0.601650\tBest loss: 0.601650\tAccuracy: 87.50%\n",
      "313\tValidation loss: 0.601402\tBest loss: 0.601402\tAccuracy: 87.60%\n",
      "314\tValidation loss: 0.600925\tBest loss: 0.600925\tAccuracy: 87.70%\n",
      "315\tValidation loss: 0.600563\tBest loss: 0.600563\tAccuracy: 87.70%\n",
      "316\tValidation loss: 0.600087\tBest loss: 0.600087\tAccuracy: 87.70%\n",
      "317\tValidation loss: 0.599934\tBest loss: 0.599934\tAccuracy: 87.60%\n",
      "318\tValidation loss: 0.598999\tBest loss: 0.598999\tAccuracy: 87.70%\n",
      "319\tValidation loss: 0.598578\tBest loss: 0.598578\tAccuracy: 87.60%\n",
      "320\tValidation loss: 0.598336\tBest loss: 0.598336\tAccuracy: 87.70%\n",
      "321\tValidation loss: 0.597944\tBest loss: 0.597944\tAccuracy: 87.50%\n",
      "322\tValidation loss: 0.597660\tBest loss: 0.597660\tAccuracy: 87.50%\n",
      "323\tValidation loss: 0.597375\tBest loss: 0.597375\tAccuracy: 87.70%\n",
      "324\tValidation loss: 0.596672\tBest loss: 0.596672\tAccuracy: 87.70%\n",
      "325\tValidation loss: 0.596290\tBest loss: 0.596290\tAccuracy: 87.70%\n",
      "326\tValidation loss: 0.595710\tBest loss: 0.595710\tAccuracy: 87.80%\n",
      "327\tValidation loss: 0.595201\tBest loss: 0.595201\tAccuracy: 87.60%\n",
      "328\tValidation loss: 0.594953\tBest loss: 0.594953\tAccuracy: 87.60%\n",
      "329\tValidation loss: 0.594598\tBest loss: 0.594598\tAccuracy: 87.60%\n",
      "330\tValidation loss: 0.593984\tBest loss: 0.593984\tAccuracy: 87.60%\n",
      "331\tValidation loss: 0.593717\tBest loss: 0.593717\tAccuracy: 87.70%\n",
      "332\tValidation loss: 0.593010\tBest loss: 0.593010\tAccuracy: 87.80%\n",
      "333\tValidation loss: 0.592647\tBest loss: 0.592647\tAccuracy: 87.70%\n",
      "334\tValidation loss: 0.592226\tBest loss: 0.592226\tAccuracy: 87.60%\n",
      "335\tValidation loss: 0.592186\tBest loss: 0.592186\tAccuracy: 87.70%\n",
      "336\tValidation loss: 0.591251\tBest loss: 0.591251\tAccuracy: 87.70%\n",
      "337\tValidation loss: 0.591265\tBest loss: 0.591251\tAccuracy: 87.70%\n",
      "338\tValidation loss: 0.590718\tBest loss: 0.590718\tAccuracy: 87.80%\n",
      "339\tValidation loss: 0.590363\tBest loss: 0.590363\tAccuracy: 87.90%\n",
      "340\tValidation loss: 0.590332\tBest loss: 0.590332\tAccuracy: 87.80%\n",
      "341\tValidation loss: 0.589665\tBest loss: 0.589665\tAccuracy: 87.60%\n",
      "342\tValidation loss: 0.589056\tBest loss: 0.589056\tAccuracy: 87.70%\n",
      "343\tValidation loss: 0.588419\tBest loss: 0.588419\tAccuracy: 87.80%\n",
      "344\tValidation loss: 0.588340\tBest loss: 0.588340\tAccuracy: 87.80%\n",
      "345\tValidation loss: 0.588057\tBest loss: 0.588057\tAccuracy: 87.80%\n",
      "346\tValidation loss: 0.587634\tBest loss: 0.587634\tAccuracy: 87.90%\n",
      "347\tValidation loss: 0.587412\tBest loss: 0.587412\tAccuracy: 87.90%\n",
      "348\tValidation loss: 0.587170\tBest loss: 0.587170\tAccuracy: 87.90%\n",
      "349\tValidation loss: 0.586837\tBest loss: 0.586837\tAccuracy: 87.90%\n",
      "350\tValidation loss: 0.586344\tBest loss: 0.586344\tAccuracy: 87.90%\n",
      "351\tValidation loss: 0.585999\tBest loss: 0.585999\tAccuracy: 87.80%\n",
      "352\tValidation loss: 0.585406\tBest loss: 0.585406\tAccuracy: 87.80%\n",
      "353\tValidation loss: 0.585235\tBest loss: 0.585235\tAccuracy: 87.80%\n",
      "354\tValidation loss: 0.584694\tBest loss: 0.584694\tAccuracy: 87.80%\n",
      "355\tValidation loss: 0.584420\tBest loss: 0.584420\tAccuracy: 87.80%\n",
      "356\tValidation loss: 0.583919\tBest loss: 0.583919\tAccuracy: 87.80%\n",
      "357\tValidation loss: 0.583775\tBest loss: 0.583775\tAccuracy: 87.90%\n",
      "358\tValidation loss: 0.583206\tBest loss: 0.583206\tAccuracy: 87.80%\n",
      "359\tValidation loss: 0.582906\tBest loss: 0.582906\tAccuracy: 87.80%\n",
      "360\tValidation loss: 0.582354\tBest loss: 0.582354\tAccuracy: 87.90%\n",
      "361\tValidation loss: 0.582202\tBest loss: 0.582202\tAccuracy: 88.00%\n",
      "362\tValidation loss: 0.581886\tBest loss: 0.581886\tAccuracy: 88.00%\n",
      "363\tValidation loss: 0.581573\tBest loss: 0.581573\tAccuracy: 87.90%\n",
      "364\tValidation loss: 0.581227\tBest loss: 0.581227\tAccuracy: 87.90%\n",
      "365\tValidation loss: 0.581075\tBest loss: 0.581075\tAccuracy: 88.10%\n",
      "366\tValidation loss: 0.580574\tBest loss: 0.580574\tAccuracy: 88.00%\n",
      "367\tValidation loss: 0.580148\tBest loss: 0.580148\tAccuracy: 88.00%\n",
      "368\tValidation loss: 0.580073\tBest loss: 0.580073\tAccuracy: 88.00%\n",
      "369\tValidation loss: 0.579167\tBest loss: 0.579167\tAccuracy: 88.00%\n",
      "370\tValidation loss: 0.578765\tBest loss: 0.578765\tAccuracy: 88.20%\n",
      "371\tValidation loss: 0.578526\tBest loss: 0.578526\tAccuracy: 88.00%\n",
      "372\tValidation loss: 0.578344\tBest loss: 0.578344\tAccuracy: 88.00%\n",
      "373\tValidation loss: 0.578119\tBest loss: 0.578119\tAccuracy: 88.00%\n",
      "374\tValidation loss: 0.577801\tBest loss: 0.577801\tAccuracy: 88.10%\n",
      "375\tValidation loss: 0.577400\tBest loss: 0.577400\tAccuracy: 88.20%\n",
      "376\tValidation loss: 0.576927\tBest loss: 0.576927\tAccuracy: 88.00%\n",
      "377\tValidation loss: 0.576694\tBest loss: 0.576694\tAccuracy: 88.10%\n",
      "378\tValidation loss: 0.576468\tBest loss: 0.576468\tAccuracy: 88.20%\n",
      "379\tValidation loss: 0.575905\tBest loss: 0.575905\tAccuracy: 88.10%\n",
      "380\tValidation loss: 0.575854\tBest loss: 0.575854\tAccuracy: 88.10%\n",
      "381\tValidation loss: 0.575403\tBest loss: 0.575403\tAccuracy: 88.10%\n",
      "382\tValidation loss: 0.575008\tBest loss: 0.575008\tAccuracy: 88.10%\n",
      "383\tValidation loss: 0.574602\tBest loss: 0.574602\tAccuracy: 88.20%\n",
      "384\tValidation loss: 0.574367\tBest loss: 0.574367\tAccuracy: 88.10%\n",
      "385\tValidation loss: 0.574135\tBest loss: 0.574135\tAccuracy: 88.10%\n",
      "386\tValidation loss: 0.573667\tBest loss: 0.573667\tAccuracy: 88.00%\n",
      "387\tValidation loss: 0.573500\tBest loss: 0.573500\tAccuracy: 88.00%\n",
      "388\tValidation loss: 0.572884\tBest loss: 0.572884\tAccuracy: 88.00%\n",
      "389\tValidation loss: 0.572820\tBest loss: 0.572820\tAccuracy: 88.20%\n",
      "390\tValidation loss: 0.572497\tBest loss: 0.572497\tAccuracy: 88.20%\n",
      "391\tValidation loss: 0.572299\tBest loss: 0.572299\tAccuracy: 88.20%\n",
      "392\tValidation loss: 0.572064\tBest loss: 0.572064\tAccuracy: 88.10%\n",
      "393\tValidation loss: 0.571382\tBest loss: 0.571382\tAccuracy: 88.20%\n",
      "394\tValidation loss: 0.571063\tBest loss: 0.571063\tAccuracy: 88.20%\n",
      "395\tValidation loss: 0.570562\tBest loss: 0.570562\tAccuracy: 88.10%\n",
      "396\tValidation loss: 0.570402\tBest loss: 0.570402\tAccuracy: 88.10%\n",
      "397\tValidation loss: 0.570273\tBest loss: 0.570273\tAccuracy: 88.20%\n",
      "398\tValidation loss: 0.569548\tBest loss: 0.569548\tAccuracy: 88.20%\n",
      "399\tValidation loss: 0.569643\tBest loss: 0.569548\tAccuracy: 88.10%\n",
      "400\tValidation loss: 0.569364\tBest loss: 0.569364\tAccuracy: 88.20%\n",
      "401\tValidation loss: 0.569054\tBest loss: 0.569054\tAccuracy: 88.20%\n",
      "402\tValidation loss: 0.568350\tBest loss: 0.568350\tAccuracy: 88.20%\n",
      "403\tValidation loss: 0.568239\tBest loss: 0.568239\tAccuracy: 88.20%\n",
      "404\tValidation loss: 0.567902\tBest loss: 0.567902\tAccuracy: 88.30%\n",
      "405\tValidation loss: 0.567472\tBest loss: 0.567472\tAccuracy: 88.30%\n",
      "406\tValidation loss: 0.567425\tBest loss: 0.567425\tAccuracy: 88.30%\n",
      "407\tValidation loss: 0.567276\tBest loss: 0.567276\tAccuracy: 88.30%\n",
      "408\tValidation loss: 0.566601\tBest loss: 0.566601\tAccuracy: 88.20%\n",
      "409\tValidation loss: 0.566184\tBest loss: 0.566184\tAccuracy: 88.30%\n",
      "410\tValidation loss: 0.566113\tBest loss: 0.566113\tAccuracy: 88.30%\n",
      "411\tValidation loss: 0.565766\tBest loss: 0.565766\tAccuracy: 88.20%\n",
      "412\tValidation loss: 0.565511\tBest loss: 0.565511\tAccuracy: 88.30%\n",
      "413\tValidation loss: 0.565149\tBest loss: 0.565149\tAccuracy: 88.30%\n",
      "414\tValidation loss: 0.564742\tBest loss: 0.564742\tAccuracy: 88.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\tValidation loss: 0.564197\tBest loss: 0.564197\tAccuracy: 88.30%\n",
      "416\tValidation loss: 0.563970\tBest loss: 0.563970\tAccuracy: 88.30%\n",
      "417\tValidation loss: 0.563849\tBest loss: 0.563849\tAccuracy: 88.30%\n",
      "418\tValidation loss: 0.563809\tBest loss: 0.563809\tAccuracy: 88.30%\n",
      "419\tValidation loss: 0.563322\tBest loss: 0.563322\tAccuracy: 88.20%\n",
      "420\tValidation loss: 0.562932\tBest loss: 0.562932\tAccuracy: 88.20%\n",
      "421\tValidation loss: 0.562493\tBest loss: 0.562493\tAccuracy: 88.30%\n",
      "422\tValidation loss: 0.562281\tBest loss: 0.562281\tAccuracy: 88.30%\n",
      "423\tValidation loss: 0.562368\tBest loss: 0.562281\tAccuracy: 88.30%\n",
      "424\tValidation loss: 0.561894\tBest loss: 0.561894\tAccuracy: 88.30%\n",
      "425\tValidation loss: 0.561520\tBest loss: 0.561520\tAccuracy: 88.30%\n",
      "426\tValidation loss: 0.561648\tBest loss: 0.561520\tAccuracy: 88.30%\n",
      "427\tValidation loss: 0.561282\tBest loss: 0.561282\tAccuracy: 88.30%\n",
      "428\tValidation loss: 0.560955\tBest loss: 0.560955\tAccuracy: 88.40%\n",
      "429\tValidation loss: 0.560622\tBest loss: 0.560622\tAccuracy: 88.30%\n",
      "430\tValidation loss: 0.560213\tBest loss: 0.560213\tAccuracy: 88.30%\n",
      "431\tValidation loss: 0.560128\tBest loss: 0.560128\tAccuracy: 88.30%\n",
      "432\tValidation loss: 0.559843\tBest loss: 0.559843\tAccuracy: 88.30%\n",
      "433\tValidation loss: 0.559374\tBest loss: 0.559374\tAccuracy: 88.30%\n",
      "434\tValidation loss: 0.559336\tBest loss: 0.559336\tAccuracy: 88.40%\n",
      "435\tValidation loss: 0.558918\tBest loss: 0.558918\tAccuracy: 88.30%\n",
      "436\tValidation loss: 0.558854\tBest loss: 0.558854\tAccuracy: 88.30%\n",
      "437\tValidation loss: 0.558324\tBest loss: 0.558324\tAccuracy: 88.40%\n",
      "438\tValidation loss: 0.558214\tBest loss: 0.558214\tAccuracy: 88.40%\n",
      "439\tValidation loss: 0.557802\tBest loss: 0.557802\tAccuracy: 88.30%\n",
      "440\tValidation loss: 0.557562\tBest loss: 0.557562\tAccuracy: 88.40%\n",
      "441\tValidation loss: 0.557205\tBest loss: 0.557205\tAccuracy: 88.40%\n",
      "442\tValidation loss: 0.557041\tBest loss: 0.557041\tAccuracy: 88.30%\n",
      "443\tValidation loss: 0.556812\tBest loss: 0.556812\tAccuracy: 88.40%\n",
      "444\tValidation loss: 0.556566\tBest loss: 0.556566\tAccuracy: 88.30%\n",
      "445\tValidation loss: 0.556211\tBest loss: 0.556211\tAccuracy: 88.40%\n",
      "446\tValidation loss: 0.555678\tBest loss: 0.555678\tAccuracy: 88.40%\n",
      "447\tValidation loss: 0.555581\tBest loss: 0.555581\tAccuracy: 88.40%\n",
      "448\tValidation loss: 0.555251\tBest loss: 0.555251\tAccuracy: 88.40%\n",
      "449\tValidation loss: 0.554804\tBest loss: 0.554804\tAccuracy: 88.40%\n",
      "450\tValidation loss: 0.554722\tBest loss: 0.554722\tAccuracy: 88.40%\n",
      "451\tValidation loss: 0.554651\tBest loss: 0.554651\tAccuracy: 88.40%\n",
      "452\tValidation loss: 0.554369\tBest loss: 0.554369\tAccuracy: 88.50%\n",
      "453\tValidation loss: 0.554081\tBest loss: 0.554081\tAccuracy: 88.50%\n",
      "454\tValidation loss: 0.553938\tBest loss: 0.553938\tAccuracy: 88.40%\n",
      "455\tValidation loss: 0.553427\tBest loss: 0.553427\tAccuracy: 88.40%\n",
      "456\tValidation loss: 0.553167\tBest loss: 0.553167\tAccuracy: 88.40%\n",
      "457\tValidation loss: 0.552981\tBest loss: 0.552981\tAccuracy: 88.30%\n",
      "458\tValidation loss: 0.552714\tBest loss: 0.552714\tAccuracy: 88.40%\n",
      "459\tValidation loss: 0.552525\tBest loss: 0.552525\tAccuracy: 88.40%\n",
      "460\tValidation loss: 0.552157\tBest loss: 0.552157\tAccuracy: 88.50%\n",
      "461\tValidation loss: 0.551912\tBest loss: 0.551912\tAccuracy: 88.60%\n",
      "462\tValidation loss: 0.551774\tBest loss: 0.551774\tAccuracy: 88.60%\n",
      "463\tValidation loss: 0.551487\tBest loss: 0.551487\tAccuracy: 88.60%\n",
      "464\tValidation loss: 0.551091\tBest loss: 0.551091\tAccuracy: 88.50%\n",
      "465\tValidation loss: 0.550812\tBest loss: 0.550812\tAccuracy: 88.60%\n",
      "466\tValidation loss: 0.550751\tBest loss: 0.550751\tAccuracy: 88.60%\n",
      "467\tValidation loss: 0.550104\tBest loss: 0.550104\tAccuracy: 88.50%\n",
      "468\tValidation loss: 0.550222\tBest loss: 0.550104\tAccuracy: 88.50%\n",
      "469\tValidation loss: 0.549750\tBest loss: 0.549750\tAccuracy: 88.50%\n",
      "470\tValidation loss: 0.549539\tBest loss: 0.549539\tAccuracy: 88.50%\n",
      "471\tValidation loss: 0.549492\tBest loss: 0.549492\tAccuracy: 88.50%\n",
      "472\tValidation loss: 0.549258\tBest loss: 0.549258\tAccuracy: 88.50%\n",
      "473\tValidation loss: 0.549131\tBest loss: 0.549131\tAccuracy: 88.50%\n",
      "474\tValidation loss: 0.548983\tBest loss: 0.548983\tAccuracy: 88.60%\n",
      "475\tValidation loss: 0.548575\tBest loss: 0.548575\tAccuracy: 88.50%\n",
      "476\tValidation loss: 0.548260\tBest loss: 0.548260\tAccuracy: 88.50%\n",
      "477\tValidation loss: 0.548196\tBest loss: 0.548196\tAccuracy: 88.50%\n",
      "478\tValidation loss: 0.547943\tBest loss: 0.547943\tAccuracy: 88.50%\n",
      "479\tValidation loss: 0.547559\tBest loss: 0.547559\tAccuracy: 88.50%\n",
      "480\tValidation loss: 0.547446\tBest loss: 0.547446\tAccuracy: 88.50%\n",
      "481\tValidation loss: 0.547048\tBest loss: 0.547048\tAccuracy: 88.50%\n",
      "482\tValidation loss: 0.546696\tBest loss: 0.546696\tAccuracy: 88.50%\n",
      "483\tValidation loss: 0.546265\tBest loss: 0.546265\tAccuracy: 88.50%\n",
      "484\tValidation loss: 0.546065\tBest loss: 0.546065\tAccuracy: 88.50%\n",
      "485\tValidation loss: 0.545949\tBest loss: 0.545949\tAccuracy: 88.60%\n",
      "486\tValidation loss: 0.545875\tBest loss: 0.545875\tAccuracy: 88.70%\n",
      "487\tValidation loss: 0.545490\tBest loss: 0.545490\tAccuracy: 88.60%\n",
      "488\tValidation loss: 0.545298\tBest loss: 0.545298\tAccuracy: 88.60%\n",
      "489\tValidation loss: 0.545079\tBest loss: 0.545079\tAccuracy: 88.50%\n",
      "490\tValidation loss: 0.544764\tBest loss: 0.544764\tAccuracy: 88.60%\n",
      "491\tValidation loss: 0.544478\tBest loss: 0.544478\tAccuracy: 88.50%\n",
      "492\tValidation loss: 0.544066\tBest loss: 0.544066\tAccuracy: 88.70%\n",
      "493\tValidation loss: 0.544050\tBest loss: 0.544050\tAccuracy: 88.70%\n",
      "494\tValidation loss: 0.543651\tBest loss: 0.543651\tAccuracy: 88.70%\n",
      "495\tValidation loss: 0.543516\tBest loss: 0.543516\tAccuracy: 88.70%\n",
      "496\tValidation loss: 0.543105\tBest loss: 0.543105\tAccuracy: 88.70%\n",
      "497\tValidation loss: 0.542976\tBest loss: 0.542976\tAccuracy: 88.70%\n",
      "498\tValidation loss: 0.542861\tBest loss: 0.542861\tAccuracy: 88.60%\n",
      "499\tValidation loss: 0.542642\tBest loss: 0.542642\tAccuracy: 88.70%\n",
      "500\tValidation loss: 0.542609\tBest loss: 0.542609\tAccuracy: 88.70%\n",
      "501\tValidation loss: 0.542301\tBest loss: 0.542301\tAccuracy: 88.70%\n",
      "502\tValidation loss: 0.542135\tBest loss: 0.542135\tAccuracy: 88.60%\n",
      "503\tValidation loss: 0.541768\tBest loss: 0.541768\tAccuracy: 88.70%\n",
      "504\tValidation loss: 0.541674\tBest loss: 0.541674\tAccuracy: 88.70%\n",
      "505\tValidation loss: 0.541365\tBest loss: 0.541365\tAccuracy: 88.70%\n",
      "506\tValidation loss: 0.541200\tBest loss: 0.541200\tAccuracy: 88.70%\n",
      "507\tValidation loss: 0.540946\tBest loss: 0.540946\tAccuracy: 88.70%\n",
      "508\tValidation loss: 0.540602\tBest loss: 0.540602\tAccuracy: 88.70%\n",
      "509\tValidation loss: 0.540534\tBest loss: 0.540534\tAccuracy: 88.70%\n",
      "510\tValidation loss: 0.540115\tBest loss: 0.540115\tAccuracy: 88.80%\n",
      "511\tValidation loss: 0.540022\tBest loss: 0.540022\tAccuracy: 88.80%\n",
      "512\tValidation loss: 0.539617\tBest loss: 0.539617\tAccuracy: 88.80%\n",
      "513\tValidation loss: 0.539539\tBest loss: 0.539539\tAccuracy: 88.80%\n",
      "514\tValidation loss: 0.539260\tBest loss: 0.539260\tAccuracy: 88.70%\n",
      "515\tValidation loss: 0.539104\tBest loss: 0.539104\tAccuracy: 88.80%\n",
      "516\tValidation loss: 0.538887\tBest loss: 0.538887\tAccuracy: 88.70%\n",
      "517\tValidation loss: 0.538509\tBest loss: 0.538509\tAccuracy: 88.80%\n",
      "518\tValidation loss: 0.538703\tBest loss: 0.538509\tAccuracy: 88.80%\n",
      "519\tValidation loss: 0.538259\tBest loss: 0.538259\tAccuracy: 88.80%\n",
      "520\tValidation loss: 0.538068\tBest loss: 0.538068\tAccuracy: 88.80%\n",
      "521\tValidation loss: 0.537923\tBest loss: 0.537923\tAccuracy: 88.70%\n",
      "522\tValidation loss: 0.537678\tBest loss: 0.537678\tAccuracy: 88.70%\n",
      "523\tValidation loss: 0.537283\tBest loss: 0.537283\tAccuracy: 88.70%\n",
      "524\tValidation loss: 0.536930\tBest loss: 0.536930\tAccuracy: 88.80%\n",
      "525\tValidation loss: 0.537064\tBest loss: 0.536930\tAccuracy: 88.80%\n",
      "526\tValidation loss: 0.536704\tBest loss: 0.536704\tAccuracy: 88.80%\n",
      "527\tValidation loss: 0.536324\tBest loss: 0.536324\tAccuracy: 88.80%\n",
      "528\tValidation loss: 0.536257\tBest loss: 0.536257\tAccuracy: 88.80%\n",
      "529\tValidation loss: 0.536056\tBest loss: 0.536056\tAccuracy: 88.80%\n",
      "530\tValidation loss: 0.535849\tBest loss: 0.535849\tAccuracy: 88.80%\n",
      "531\tValidation loss: 0.535687\tBest loss: 0.535687\tAccuracy: 88.80%\n",
      "532\tValidation loss: 0.535587\tBest loss: 0.535587\tAccuracy: 88.80%\n",
      "533\tValidation loss: 0.535451\tBest loss: 0.535451\tAccuracy: 88.80%\n",
      "534\tValidation loss: 0.534891\tBest loss: 0.534891\tAccuracy: 88.80%\n",
      "535\tValidation loss: 0.534664\tBest loss: 0.534664\tAccuracy: 88.70%\n",
      "536\tValidation loss: 0.534410\tBest loss: 0.534410\tAccuracy: 88.80%\n",
      "537\tValidation loss: 0.534243\tBest loss: 0.534243\tAccuracy: 88.70%\n",
      "538\tValidation loss: 0.534320\tBest loss: 0.534243\tAccuracy: 88.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\tValidation loss: 0.534022\tBest loss: 0.534022\tAccuracy: 88.70%\n",
      "540\tValidation loss: 0.533607\tBest loss: 0.533607\tAccuracy: 88.80%\n",
      "541\tValidation loss: 0.533538\tBest loss: 0.533538\tAccuracy: 88.80%\n",
      "542\tValidation loss: 0.533550\tBest loss: 0.533538\tAccuracy: 88.80%\n",
      "543\tValidation loss: 0.533394\tBest loss: 0.533394\tAccuracy: 88.70%\n",
      "544\tValidation loss: 0.533154\tBest loss: 0.533154\tAccuracy: 88.80%\n",
      "545\tValidation loss: 0.532855\tBest loss: 0.532855\tAccuracy: 88.70%\n",
      "546\tValidation loss: 0.532625\tBest loss: 0.532625\tAccuracy: 88.80%\n",
      "547\tValidation loss: 0.532310\tBest loss: 0.532310\tAccuracy: 88.70%\n",
      "548\tValidation loss: 0.532120\tBest loss: 0.532120\tAccuracy: 88.60%\n",
      "549\tValidation loss: 0.532033\tBest loss: 0.532033\tAccuracy: 88.60%\n",
      "550\tValidation loss: 0.531712\tBest loss: 0.531712\tAccuracy: 88.70%\n",
      "551\tValidation loss: 0.531785\tBest loss: 0.531712\tAccuracy: 88.60%\n",
      "552\tValidation loss: 0.531400\tBest loss: 0.531400\tAccuracy: 88.60%\n",
      "553\tValidation loss: 0.531006\tBest loss: 0.531006\tAccuracy: 88.70%\n",
      "554\tValidation loss: 0.530884\tBest loss: 0.530884\tAccuracy: 88.70%\n",
      "555\tValidation loss: 0.530535\tBest loss: 0.530535\tAccuracy: 88.70%\n",
      "556\tValidation loss: 0.530463\tBest loss: 0.530463\tAccuracy: 88.70%\n",
      "557\tValidation loss: 0.530234\tBest loss: 0.530234\tAccuracy: 88.70%\n",
      "558\tValidation loss: 0.530111\tBest loss: 0.530111\tAccuracy: 88.60%\n",
      "559\tValidation loss: 0.530081\tBest loss: 0.530081\tAccuracy: 88.70%\n",
      "560\tValidation loss: 0.529909\tBest loss: 0.529909\tAccuracy: 88.70%\n",
      "561\tValidation loss: 0.529651\tBest loss: 0.529651\tAccuracy: 88.70%\n",
      "562\tValidation loss: 0.529440\tBest loss: 0.529440\tAccuracy: 88.60%\n",
      "563\tValidation loss: 0.529407\tBest loss: 0.529407\tAccuracy: 88.60%\n",
      "564\tValidation loss: 0.528884\tBest loss: 0.528884\tAccuracy: 88.70%\n",
      "565\tValidation loss: 0.528690\tBest loss: 0.528690\tAccuracy: 88.70%\n",
      "566\tValidation loss: 0.528413\tBest loss: 0.528413\tAccuracy: 88.60%\n",
      "567\tValidation loss: 0.528148\tBest loss: 0.528148\tAccuracy: 88.70%\n",
      "568\tValidation loss: 0.527975\tBest loss: 0.527975\tAccuracy: 88.70%\n",
      "569\tValidation loss: 0.527982\tBest loss: 0.527975\tAccuracy: 88.70%\n",
      "570\tValidation loss: 0.527879\tBest loss: 0.527879\tAccuracy: 88.70%\n",
      "571\tValidation loss: 0.527701\tBest loss: 0.527701\tAccuracy: 88.60%\n",
      "572\tValidation loss: 0.527372\tBest loss: 0.527372\tAccuracy: 88.70%\n",
      "573\tValidation loss: 0.527138\tBest loss: 0.527138\tAccuracy: 88.70%\n",
      "574\tValidation loss: 0.526931\tBest loss: 0.526931\tAccuracy: 88.70%\n",
      "575\tValidation loss: 0.526734\tBest loss: 0.526734\tAccuracy: 88.70%\n",
      "576\tValidation loss: 0.526537\tBest loss: 0.526537\tAccuracy: 88.60%\n",
      "577\tValidation loss: 0.526494\tBest loss: 0.526494\tAccuracy: 88.60%\n",
      "578\tValidation loss: 0.526515\tBest loss: 0.526494\tAccuracy: 88.80%\n",
      "579\tValidation loss: 0.526229\tBest loss: 0.526229\tAccuracy: 88.80%\n",
      "580\tValidation loss: 0.525828\tBest loss: 0.525828\tAccuracy: 88.80%\n",
      "581\tValidation loss: 0.525732\tBest loss: 0.525732\tAccuracy: 88.80%\n",
      "582\tValidation loss: 0.525553\tBest loss: 0.525553\tAccuracy: 88.60%\n",
      "583\tValidation loss: 0.525263\tBest loss: 0.525263\tAccuracy: 88.70%\n",
      "584\tValidation loss: 0.525182\tBest loss: 0.525182\tAccuracy: 88.70%\n",
      "585\tValidation loss: 0.525102\tBest loss: 0.525102\tAccuracy: 88.60%\n",
      "586\tValidation loss: 0.524635\tBest loss: 0.524635\tAccuracy: 88.60%\n",
      "587\tValidation loss: 0.524615\tBest loss: 0.524615\tAccuracy: 88.60%\n",
      "588\tValidation loss: 0.524504\tBest loss: 0.524504\tAccuracy: 88.60%\n",
      "589\tValidation loss: 0.524335\tBest loss: 0.524335\tAccuracy: 88.70%\n",
      "590\tValidation loss: 0.523939\tBest loss: 0.523939\tAccuracy: 88.70%\n",
      "591\tValidation loss: 0.523939\tBest loss: 0.523939\tAccuracy: 88.70%\n",
      "592\tValidation loss: 0.523638\tBest loss: 0.523638\tAccuracy: 88.70%\n",
      "593\tValidation loss: 0.523425\tBest loss: 0.523425\tAccuracy: 88.70%\n",
      "594\tValidation loss: 0.523235\tBest loss: 0.523235\tAccuracy: 88.70%\n",
      "595\tValidation loss: 0.523036\tBest loss: 0.523036\tAccuracy: 88.70%\n",
      "596\tValidation loss: 0.523027\tBest loss: 0.523027\tAccuracy: 88.60%\n",
      "597\tValidation loss: 0.522644\tBest loss: 0.522644\tAccuracy: 88.70%\n",
      "598\tValidation loss: 0.522476\tBest loss: 0.522476\tAccuracy: 88.70%\n",
      "599\tValidation loss: 0.522380\tBest loss: 0.522380\tAccuracy: 88.70%\n",
      "600\tValidation loss: 0.522406\tBest loss: 0.522380\tAccuracy: 88.70%\n",
      "601\tValidation loss: 0.522270\tBest loss: 0.522270\tAccuracy: 88.70%\n",
      "602\tValidation loss: 0.521967\tBest loss: 0.521967\tAccuracy: 88.70%\n",
      "603\tValidation loss: 0.521658\tBest loss: 0.521658\tAccuracy: 88.70%\n",
      "604\tValidation loss: 0.521694\tBest loss: 0.521658\tAccuracy: 88.70%\n",
      "605\tValidation loss: 0.521603\tBest loss: 0.521603\tAccuracy: 88.60%\n",
      "606\tValidation loss: 0.521281\tBest loss: 0.521281\tAccuracy: 88.70%\n",
      "607\tValidation loss: 0.521017\tBest loss: 0.521017\tAccuracy: 88.60%\n",
      "608\tValidation loss: 0.520811\tBest loss: 0.520811\tAccuracy: 88.60%\n",
      "609\tValidation loss: 0.520608\tBest loss: 0.520608\tAccuracy: 88.60%\n",
      "610\tValidation loss: 0.520424\tBest loss: 0.520424\tAccuracy: 88.60%\n",
      "611\tValidation loss: 0.520356\tBest loss: 0.520356\tAccuracy: 88.60%\n",
      "612\tValidation loss: 0.520053\tBest loss: 0.520053\tAccuracy: 88.70%\n",
      "613\tValidation loss: 0.519770\tBest loss: 0.519770\tAccuracy: 88.60%\n",
      "614\tValidation loss: 0.519747\tBest loss: 0.519747\tAccuracy: 88.70%\n",
      "615\tValidation loss: 0.519700\tBest loss: 0.519700\tAccuracy: 88.70%\n",
      "616\tValidation loss: 0.519559\tBest loss: 0.519559\tAccuracy: 88.60%\n",
      "617\tValidation loss: 0.519464\tBest loss: 0.519464\tAccuracy: 88.70%\n",
      "618\tValidation loss: 0.519166\tBest loss: 0.519166\tAccuracy: 88.60%\n",
      "619\tValidation loss: 0.518789\tBest loss: 0.518789\tAccuracy: 88.60%\n",
      "620\tValidation loss: 0.518632\tBest loss: 0.518632\tAccuracy: 88.60%\n",
      "621\tValidation loss: 0.518569\tBest loss: 0.518569\tAccuracy: 88.60%\n",
      "622\tValidation loss: 0.518425\tBest loss: 0.518425\tAccuracy: 88.60%\n",
      "623\tValidation loss: 0.518076\tBest loss: 0.518076\tAccuracy: 88.60%\n",
      "624\tValidation loss: 0.518029\tBest loss: 0.518029\tAccuracy: 88.60%\n",
      "625\tValidation loss: 0.518040\tBest loss: 0.518029\tAccuracy: 88.70%\n",
      "626\tValidation loss: 0.517909\tBest loss: 0.517909\tAccuracy: 88.70%\n",
      "627\tValidation loss: 0.517700\tBest loss: 0.517700\tAccuracy: 88.60%\n",
      "628\tValidation loss: 0.517436\tBest loss: 0.517436\tAccuracy: 88.60%\n",
      "629\tValidation loss: 0.517219\tBest loss: 0.517219\tAccuracy: 88.60%\n",
      "630\tValidation loss: 0.517043\tBest loss: 0.517043\tAccuracy: 88.70%\n",
      "631\tValidation loss: 0.516900\tBest loss: 0.516900\tAccuracy: 88.60%\n",
      "632\tValidation loss: 0.516819\tBest loss: 0.516819\tAccuracy: 88.70%\n",
      "633\tValidation loss: 0.516585\tBest loss: 0.516585\tAccuracy: 88.70%\n",
      "634\tValidation loss: 0.516289\tBest loss: 0.516289\tAccuracy: 88.70%\n",
      "635\tValidation loss: 0.516222\tBest loss: 0.516222\tAccuracy: 88.70%\n",
      "636\tValidation loss: 0.515969\tBest loss: 0.515969\tAccuracy: 88.60%\n",
      "637\tValidation loss: 0.515851\tBest loss: 0.515851\tAccuracy: 88.60%\n",
      "638\tValidation loss: 0.515615\tBest loss: 0.515615\tAccuracy: 88.70%\n",
      "639\tValidation loss: 0.515473\tBest loss: 0.515473\tAccuracy: 88.70%\n",
      "640\tValidation loss: 0.515513\tBest loss: 0.515473\tAccuracy: 88.70%\n",
      "641\tValidation loss: 0.515295\tBest loss: 0.515295\tAccuracy: 88.70%\n",
      "642\tValidation loss: 0.515286\tBest loss: 0.515286\tAccuracy: 88.70%\n",
      "643\tValidation loss: 0.514957\tBest loss: 0.514957\tAccuracy: 88.70%\n",
      "644\tValidation loss: 0.514654\tBest loss: 0.514654\tAccuracy: 88.70%\n",
      "645\tValidation loss: 0.514482\tBest loss: 0.514482\tAccuracy: 88.70%\n",
      "646\tValidation loss: 0.514445\tBest loss: 0.514445\tAccuracy: 88.70%\n",
      "647\tValidation loss: 0.514326\tBest loss: 0.514326\tAccuracy: 88.70%\n",
      "648\tValidation loss: 0.514041\tBest loss: 0.514041\tAccuracy: 88.70%\n",
      "649\tValidation loss: 0.513968\tBest loss: 0.513968\tAccuracy: 88.70%\n",
      "650\tValidation loss: 0.513816\tBest loss: 0.513816\tAccuracy: 88.70%\n",
      "651\tValidation loss: 0.513632\tBest loss: 0.513632\tAccuracy: 88.70%\n",
      "652\tValidation loss: 0.513531\tBest loss: 0.513531\tAccuracy: 88.70%\n",
      "653\tValidation loss: 0.513356\tBest loss: 0.513356\tAccuracy: 88.70%\n",
      "654\tValidation loss: 0.513280\tBest loss: 0.513280\tAccuracy: 88.70%\n",
      "655\tValidation loss: 0.512910\tBest loss: 0.512910\tAccuracy: 88.70%\n",
      "656\tValidation loss: 0.512915\tBest loss: 0.512910\tAccuracy: 88.70%\n",
      "657\tValidation loss: 0.512840\tBest loss: 0.512840\tAccuracy: 88.60%\n",
      "658\tValidation loss: 0.512693\tBest loss: 0.512693\tAccuracy: 88.60%\n",
      "659\tValidation loss: 0.512461\tBest loss: 0.512461\tAccuracy: 88.60%\n",
      "660\tValidation loss: 0.512422\tBest loss: 0.512422\tAccuracy: 88.60%\n",
      "661\tValidation loss: 0.512083\tBest loss: 0.512083\tAccuracy: 88.60%\n",
      "662\tValidation loss: 0.511752\tBest loss: 0.511752\tAccuracy: 88.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\tValidation loss: 0.511528\tBest loss: 0.511528\tAccuracy: 88.70%\n",
      "664\tValidation loss: 0.511491\tBest loss: 0.511491\tAccuracy: 88.80%\n",
      "665\tValidation loss: 0.511331\tBest loss: 0.511331\tAccuracy: 88.80%\n",
      "666\tValidation loss: 0.511275\tBest loss: 0.511275\tAccuracy: 88.60%\n",
      "667\tValidation loss: 0.511229\tBest loss: 0.511229\tAccuracy: 88.80%\n",
      "668\tValidation loss: 0.510962\tBest loss: 0.510962\tAccuracy: 88.80%\n",
      "669\tValidation loss: 0.510920\tBest loss: 0.510920\tAccuracy: 88.80%\n",
      "670\tValidation loss: 0.510896\tBest loss: 0.510896\tAccuracy: 88.80%\n",
      "671\tValidation loss: 0.510661\tBest loss: 0.510661\tAccuracy: 88.90%\n",
      "672\tValidation loss: 0.510261\tBest loss: 0.510261\tAccuracy: 88.90%\n",
      "673\tValidation loss: 0.510226\tBest loss: 0.510226\tAccuracy: 88.90%\n",
      "674\tValidation loss: 0.510216\tBest loss: 0.510216\tAccuracy: 88.80%\n",
      "675\tValidation loss: 0.510030\tBest loss: 0.510030\tAccuracy: 88.90%\n",
      "676\tValidation loss: 0.509894\tBest loss: 0.509894\tAccuracy: 88.90%\n",
      "677\tValidation loss: 0.509715\tBest loss: 0.509715\tAccuracy: 89.00%\n",
      "678\tValidation loss: 0.509606\tBest loss: 0.509606\tAccuracy: 88.90%\n",
      "679\tValidation loss: 0.509453\tBest loss: 0.509453\tAccuracy: 89.00%\n",
      "680\tValidation loss: 0.509195\tBest loss: 0.509195\tAccuracy: 88.90%\n",
      "681\tValidation loss: 0.509042\tBest loss: 0.509042\tAccuracy: 88.90%\n",
      "682\tValidation loss: 0.508653\tBest loss: 0.508653\tAccuracy: 88.90%\n",
      "683\tValidation loss: 0.508641\tBest loss: 0.508641\tAccuracy: 88.90%\n",
      "684\tValidation loss: 0.508269\tBest loss: 0.508269\tAccuracy: 88.90%\n",
      "685\tValidation loss: 0.508307\tBest loss: 0.508269\tAccuracy: 88.80%\n",
      "686\tValidation loss: 0.508185\tBest loss: 0.508185\tAccuracy: 89.00%\n",
      "687\tValidation loss: 0.508120\tBest loss: 0.508120\tAccuracy: 89.00%\n",
      "688\tValidation loss: 0.508047\tBest loss: 0.508047\tAccuracy: 89.00%\n",
      "689\tValidation loss: 0.507878\tBest loss: 0.507878\tAccuracy: 89.00%\n",
      "690\tValidation loss: 0.507816\tBest loss: 0.507816\tAccuracy: 89.00%\n",
      "691\tValidation loss: 0.507519\tBest loss: 0.507519\tAccuracy: 88.90%\n",
      "692\tValidation loss: 0.507367\tBest loss: 0.507367\tAccuracy: 89.00%\n",
      "693\tValidation loss: 0.507272\tBest loss: 0.507272\tAccuracy: 88.90%\n",
      "694\tValidation loss: 0.507093\tBest loss: 0.507093\tAccuracy: 88.90%\n",
      "695\tValidation loss: 0.506928\tBest loss: 0.506928\tAccuracy: 88.80%\n",
      "696\tValidation loss: 0.506810\tBest loss: 0.506810\tAccuracy: 88.80%\n",
      "697\tValidation loss: 0.506609\tBest loss: 0.506609\tAccuracy: 88.80%\n",
      "698\tValidation loss: 0.506336\tBest loss: 0.506336\tAccuracy: 88.90%\n",
      "699\tValidation loss: 0.506311\tBest loss: 0.506311\tAccuracy: 88.80%\n",
      "700\tValidation loss: 0.506037\tBest loss: 0.506037\tAccuracy: 88.80%\n",
      "701\tValidation loss: 0.506125\tBest loss: 0.506037\tAccuracy: 89.00%\n",
      "702\tValidation loss: 0.505935\tBest loss: 0.505935\tAccuracy: 89.00%\n",
      "703\tValidation loss: 0.505678\tBest loss: 0.505678\tAccuracy: 89.00%\n",
      "704\tValidation loss: 0.505615\tBest loss: 0.505615\tAccuracy: 89.00%\n",
      "705\tValidation loss: 0.505616\tBest loss: 0.505615\tAccuracy: 88.80%\n",
      "706\tValidation loss: 0.505496\tBest loss: 0.505496\tAccuracy: 88.90%\n",
      "707\tValidation loss: 0.505323\tBest loss: 0.505323\tAccuracy: 89.00%\n",
      "708\tValidation loss: 0.505224\tBest loss: 0.505224\tAccuracy: 89.00%\n",
      "709\tValidation loss: 0.505258\tBest loss: 0.505224\tAccuracy: 89.00%\n",
      "710\tValidation loss: 0.505009\tBest loss: 0.505009\tAccuracy: 89.00%\n",
      "711\tValidation loss: 0.504986\tBest loss: 0.504986\tAccuracy: 89.00%\n",
      "712\tValidation loss: 0.504636\tBest loss: 0.504636\tAccuracy: 89.00%\n",
      "713\tValidation loss: 0.504367\tBest loss: 0.504367\tAccuracy: 88.90%\n",
      "714\tValidation loss: 0.504122\tBest loss: 0.504122\tAccuracy: 89.00%\n",
      "715\tValidation loss: 0.504034\tBest loss: 0.504034\tAccuracy: 89.00%\n",
      "716\tValidation loss: 0.503917\tBest loss: 0.503917\tAccuracy: 89.00%\n",
      "717\tValidation loss: 0.503750\tBest loss: 0.503750\tAccuracy: 89.00%\n",
      "718\tValidation loss: 0.503632\tBest loss: 0.503632\tAccuracy: 89.00%\n",
      "719\tValidation loss: 0.503470\tBest loss: 0.503470\tAccuracy: 88.90%\n",
      "720\tValidation loss: 0.503320\tBest loss: 0.503320\tAccuracy: 89.00%\n",
      "721\tValidation loss: 0.503332\tBest loss: 0.503320\tAccuracy: 89.00%\n",
      "722\tValidation loss: 0.503047\tBest loss: 0.503047\tAccuracy: 89.00%\n",
      "723\tValidation loss: 0.503074\tBest loss: 0.503047\tAccuracy: 89.00%\n",
      "724\tValidation loss: 0.502974\tBest loss: 0.502974\tAccuracy: 89.00%\n",
      "725\tValidation loss: 0.502767\tBest loss: 0.502767\tAccuracy: 89.00%\n",
      "726\tValidation loss: 0.502562\tBest loss: 0.502562\tAccuracy: 89.00%\n",
      "727\tValidation loss: 0.502358\tBest loss: 0.502358\tAccuracy: 89.00%\n",
      "728\tValidation loss: 0.502237\tBest loss: 0.502237\tAccuracy: 89.00%\n",
      "729\tValidation loss: 0.502226\tBest loss: 0.502226\tAccuracy: 89.00%\n",
      "730\tValidation loss: 0.502171\tBest loss: 0.502171\tAccuracy: 89.00%\n",
      "731\tValidation loss: 0.502002\tBest loss: 0.502002\tAccuracy: 89.00%\n",
      "732\tValidation loss: 0.501827\tBest loss: 0.501827\tAccuracy: 89.00%\n",
      "733\tValidation loss: 0.501754\tBest loss: 0.501754\tAccuracy: 88.90%\n",
      "734\tValidation loss: 0.501507\tBest loss: 0.501507\tAccuracy: 89.00%\n",
      "735\tValidation loss: 0.501421\tBest loss: 0.501421\tAccuracy: 88.90%\n",
      "736\tValidation loss: 0.501250\tBest loss: 0.501250\tAccuracy: 88.90%\n",
      "737\tValidation loss: 0.501031\tBest loss: 0.501031\tAccuracy: 89.00%\n",
      "738\tValidation loss: 0.501037\tBest loss: 0.501031\tAccuracy: 88.90%\n",
      "739\tValidation loss: 0.500828\tBest loss: 0.500828\tAccuracy: 88.90%\n",
      "740\tValidation loss: 0.500658\tBest loss: 0.500658\tAccuracy: 89.00%\n",
      "741\tValidation loss: 0.500508\tBest loss: 0.500508\tAccuracy: 89.00%\n",
      "742\tValidation loss: 0.500432\tBest loss: 0.500432\tAccuracy: 89.00%\n",
      "743\tValidation loss: 0.500218\tBest loss: 0.500218\tAccuracy: 88.90%\n",
      "744\tValidation loss: 0.499945\tBest loss: 0.499945\tAccuracy: 88.90%\n",
      "745\tValidation loss: 0.499844\tBest loss: 0.499844\tAccuracy: 88.90%\n",
      "746\tValidation loss: 0.499863\tBest loss: 0.499844\tAccuracy: 89.00%\n",
      "747\tValidation loss: 0.499700\tBest loss: 0.499700\tAccuracy: 89.00%\n",
      "748\tValidation loss: 0.499473\tBest loss: 0.499473\tAccuracy: 88.90%\n",
      "749\tValidation loss: 0.499437\tBest loss: 0.499437\tAccuracy: 88.80%\n",
      "750\tValidation loss: 0.499522\tBest loss: 0.499437\tAccuracy: 88.80%\n",
      "751\tValidation loss: 0.499250\tBest loss: 0.499250\tAccuracy: 88.90%\n",
      "752\tValidation loss: 0.499106\tBest loss: 0.499106\tAccuracy: 89.00%\n",
      "753\tValidation loss: 0.499102\tBest loss: 0.499102\tAccuracy: 88.90%\n",
      "754\tValidation loss: 0.498928\tBest loss: 0.498928\tAccuracy: 89.00%\n",
      "755\tValidation loss: 0.498866\tBest loss: 0.498866\tAccuracy: 89.00%\n",
      "756\tValidation loss: 0.498844\tBest loss: 0.498844\tAccuracy: 88.90%\n",
      "757\tValidation loss: 0.498448\tBest loss: 0.498448\tAccuracy: 88.90%\n",
      "758\tValidation loss: 0.498250\tBest loss: 0.498250\tAccuracy: 88.90%\n",
      "759\tValidation loss: 0.497992\tBest loss: 0.497992\tAccuracy: 88.90%\n",
      "760\tValidation loss: 0.498103\tBest loss: 0.497992\tAccuracy: 88.90%\n",
      "761\tValidation loss: 0.497909\tBest loss: 0.497909\tAccuracy: 88.90%\n",
      "762\tValidation loss: 0.497756\tBest loss: 0.497756\tAccuracy: 89.00%\n",
      "763\tValidation loss: 0.497613\tBest loss: 0.497613\tAccuracy: 89.00%\n",
      "764\tValidation loss: 0.497522\tBest loss: 0.497522\tAccuracy: 89.00%\n",
      "765\tValidation loss: 0.497430\tBest loss: 0.497430\tAccuracy: 89.00%\n",
      "766\tValidation loss: 0.497327\tBest loss: 0.497327\tAccuracy: 88.90%\n",
      "767\tValidation loss: 0.497225\tBest loss: 0.497225\tAccuracy: 88.90%\n",
      "768\tValidation loss: 0.497062\tBest loss: 0.497062\tAccuracy: 89.00%\n",
      "769\tValidation loss: 0.496846\tBest loss: 0.496846\tAccuracy: 88.90%\n",
      "770\tValidation loss: 0.496737\tBest loss: 0.496737\tAccuracy: 88.90%\n",
      "771\tValidation loss: 0.496672\tBest loss: 0.496672\tAccuracy: 89.00%\n",
      "772\tValidation loss: 0.496624\tBest loss: 0.496624\tAccuracy: 89.00%\n",
      "773\tValidation loss: 0.496521\tBest loss: 0.496521\tAccuracy: 89.00%\n",
      "774\tValidation loss: 0.496341\tBest loss: 0.496341\tAccuracy: 89.00%\n",
      "775\tValidation loss: 0.496256\tBest loss: 0.496256\tAccuracy: 89.00%\n",
      "776\tValidation loss: 0.496160\tBest loss: 0.496160\tAccuracy: 89.00%\n",
      "777\tValidation loss: 0.496008\tBest loss: 0.496008\tAccuracy: 89.00%\n",
      "778\tValidation loss: 0.495840\tBest loss: 0.495840\tAccuracy: 89.00%\n",
      "779\tValidation loss: 0.495629\tBest loss: 0.495629\tAccuracy: 89.00%\n",
      "780\tValidation loss: 0.495440\tBest loss: 0.495440\tAccuracy: 89.00%\n",
      "781\tValidation loss: 0.495207\tBest loss: 0.495207\tAccuracy: 89.00%\n",
      "782\tValidation loss: 0.495156\tBest loss: 0.495156\tAccuracy: 89.00%\n",
      "783\tValidation loss: 0.494950\tBest loss: 0.494950\tAccuracy: 89.00%\n",
      "784\tValidation loss: 0.494791\tBest loss: 0.494791\tAccuracy: 89.00%\n",
      "785\tValidation loss: 0.494895\tBest loss: 0.494791\tAccuracy: 89.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786\tValidation loss: 0.494758\tBest loss: 0.494758\tAccuracy: 89.00%\n",
      "787\tValidation loss: 0.494732\tBest loss: 0.494732\tAccuracy: 89.00%\n",
      "788\tValidation loss: 0.494585\tBest loss: 0.494585\tAccuracy: 89.00%\n",
      "789\tValidation loss: 0.494441\tBest loss: 0.494441\tAccuracy: 89.00%\n",
      "790\tValidation loss: 0.494314\tBest loss: 0.494314\tAccuracy: 89.10%\n",
      "791\tValidation loss: 0.494059\tBest loss: 0.494059\tAccuracy: 89.00%\n",
      "792\tValidation loss: 0.493996\tBest loss: 0.493996\tAccuracy: 89.10%\n",
      "793\tValidation loss: 0.493840\tBest loss: 0.493840\tAccuracy: 89.00%\n",
      "794\tValidation loss: 0.493890\tBest loss: 0.493840\tAccuracy: 89.00%\n",
      "795\tValidation loss: 0.493729\tBest loss: 0.493729\tAccuracy: 89.00%\n",
      "796\tValidation loss: 0.493639\tBest loss: 0.493639\tAccuracy: 89.10%\n",
      "797\tValidation loss: 0.493535\tBest loss: 0.493535\tAccuracy: 89.10%\n",
      "798\tValidation loss: 0.493406\tBest loss: 0.493406\tAccuracy: 89.10%\n",
      "799\tValidation loss: 0.493235\tBest loss: 0.493235\tAccuracy: 89.10%\n",
      "800\tValidation loss: 0.493134\tBest loss: 0.493134\tAccuracy: 89.10%\n",
      "801\tValidation loss: 0.492977\tBest loss: 0.492977\tAccuracy: 89.10%\n",
      "802\tValidation loss: 0.492954\tBest loss: 0.492954\tAccuracy: 89.10%\n",
      "803\tValidation loss: 0.492856\tBest loss: 0.492856\tAccuracy: 89.10%\n",
      "804\tValidation loss: 0.492750\tBest loss: 0.492750\tAccuracy: 89.10%\n",
      "805\tValidation loss: 0.492532\tBest loss: 0.492532\tAccuracy: 89.10%\n",
      "806\tValidation loss: 0.492462\tBest loss: 0.492462\tAccuracy: 89.10%\n",
      "807\tValidation loss: 0.492349\tBest loss: 0.492349\tAccuracy: 89.10%\n",
      "808\tValidation loss: 0.492128\tBest loss: 0.492128\tAccuracy: 89.10%\n",
      "809\tValidation loss: 0.491906\tBest loss: 0.491906\tAccuracy: 89.10%\n",
      "810\tValidation loss: 0.491868\tBest loss: 0.491868\tAccuracy: 89.20%\n",
      "811\tValidation loss: 0.491711\tBest loss: 0.491711\tAccuracy: 89.10%\n",
      "812\tValidation loss: 0.491610\tBest loss: 0.491610\tAccuracy: 89.10%\n",
      "813\tValidation loss: 0.491422\tBest loss: 0.491422\tAccuracy: 89.10%\n",
      "814\tValidation loss: 0.491412\tBest loss: 0.491412\tAccuracy: 89.10%\n",
      "815\tValidation loss: 0.491275\tBest loss: 0.491275\tAccuracy: 89.10%\n",
      "816\tValidation loss: 0.491209\tBest loss: 0.491209\tAccuracy: 89.10%\n",
      "817\tValidation loss: 0.491233\tBest loss: 0.491209\tAccuracy: 89.10%\n",
      "818\tValidation loss: 0.491103\tBest loss: 0.491103\tAccuracy: 89.10%\n",
      "819\tValidation loss: 0.491010\tBest loss: 0.491010\tAccuracy: 89.10%\n",
      "820\tValidation loss: 0.490786\tBest loss: 0.490786\tAccuracy: 89.10%\n",
      "821\tValidation loss: 0.490793\tBest loss: 0.490786\tAccuracy: 89.10%\n",
      "822\tValidation loss: 0.490678\tBest loss: 0.490678\tAccuracy: 89.20%\n",
      "823\tValidation loss: 0.490498\tBest loss: 0.490498\tAccuracy: 89.30%\n",
      "824\tValidation loss: 0.490317\tBest loss: 0.490317\tAccuracy: 89.40%\n",
      "825\tValidation loss: 0.490085\tBest loss: 0.490085\tAccuracy: 89.40%\n",
      "826\tValidation loss: 0.490000\tBest loss: 0.490000\tAccuracy: 89.40%\n",
      "827\tValidation loss: 0.490086\tBest loss: 0.490000\tAccuracy: 89.40%\n",
      "828\tValidation loss: 0.489848\tBest loss: 0.489848\tAccuracy: 89.40%\n",
      "829\tValidation loss: 0.489656\tBest loss: 0.489656\tAccuracy: 89.40%\n",
      "830\tValidation loss: 0.489718\tBest loss: 0.489656\tAccuracy: 89.30%\n",
      "831\tValidation loss: 0.489351\tBest loss: 0.489351\tAccuracy: 89.40%\n",
      "832\tValidation loss: 0.489377\tBest loss: 0.489351\tAccuracy: 89.40%\n",
      "833\tValidation loss: 0.489344\tBest loss: 0.489344\tAccuracy: 89.40%\n",
      "834\tValidation loss: 0.489166\tBest loss: 0.489166\tAccuracy: 89.30%\n",
      "835\tValidation loss: 0.488966\tBest loss: 0.488966\tAccuracy: 89.40%\n",
      "836\tValidation loss: 0.488860\tBest loss: 0.488860\tAccuracy: 89.40%\n",
      "837\tValidation loss: 0.488918\tBest loss: 0.488860\tAccuracy: 89.40%\n",
      "838\tValidation loss: 0.488739\tBest loss: 0.488739\tAccuracy: 89.40%\n",
      "839\tValidation loss: 0.488643\tBest loss: 0.488643\tAccuracy: 89.40%\n",
      "840\tValidation loss: 0.488513\tBest loss: 0.488513\tAccuracy: 89.40%\n",
      "841\tValidation loss: 0.488482\tBest loss: 0.488482\tAccuracy: 89.40%\n",
      "842\tValidation loss: 0.488308\tBest loss: 0.488308\tAccuracy: 89.40%\n",
      "843\tValidation loss: 0.488149\tBest loss: 0.488149\tAccuracy: 89.40%\n",
      "844\tValidation loss: 0.488073\tBest loss: 0.488073\tAccuracy: 89.40%\n",
      "845\tValidation loss: 0.487934\tBest loss: 0.487934\tAccuracy: 89.50%\n",
      "846\tValidation loss: 0.487803\tBest loss: 0.487803\tAccuracy: 89.50%\n",
      "847\tValidation loss: 0.487671\tBest loss: 0.487671\tAccuracy: 89.50%\n",
      "848\tValidation loss: 0.487421\tBest loss: 0.487421\tAccuracy: 89.50%\n",
      "849\tValidation loss: 0.487511\tBest loss: 0.487421\tAccuracy: 89.50%\n",
      "850\tValidation loss: 0.487491\tBest loss: 0.487421\tAccuracy: 89.50%\n",
      "851\tValidation loss: 0.487377\tBest loss: 0.487377\tAccuracy: 89.50%\n",
      "852\tValidation loss: 0.487198\tBest loss: 0.487198\tAccuracy: 89.50%\n",
      "853\tValidation loss: 0.487099\tBest loss: 0.487099\tAccuracy: 89.50%\n",
      "854\tValidation loss: 0.487110\tBest loss: 0.487099\tAccuracy: 89.50%\n",
      "855\tValidation loss: 0.486900\tBest loss: 0.486900\tAccuracy: 89.60%\n",
      "856\tValidation loss: 0.486689\tBest loss: 0.486689\tAccuracy: 89.50%\n",
      "857\tValidation loss: 0.486616\tBest loss: 0.486616\tAccuracy: 89.50%\n",
      "858\tValidation loss: 0.486564\tBest loss: 0.486564\tAccuracy: 89.50%\n",
      "859\tValidation loss: 0.486454\tBest loss: 0.486454\tAccuracy: 89.50%\n",
      "860\tValidation loss: 0.486303\tBest loss: 0.486303\tAccuracy: 89.50%\n",
      "861\tValidation loss: 0.486274\tBest loss: 0.486274\tAccuracy: 89.50%\n",
      "862\tValidation loss: 0.486223\tBest loss: 0.486223\tAccuracy: 89.50%\n",
      "863\tValidation loss: 0.486039\tBest loss: 0.486039\tAccuracy: 89.50%\n",
      "864\tValidation loss: 0.485910\tBest loss: 0.485910\tAccuracy: 89.50%\n",
      "865\tValidation loss: 0.485813\tBest loss: 0.485813\tAccuracy: 89.60%\n",
      "866\tValidation loss: 0.485692\tBest loss: 0.485692\tAccuracy: 89.50%\n",
      "867\tValidation loss: 0.485622\tBest loss: 0.485622\tAccuracy: 89.50%\n",
      "868\tValidation loss: 0.485535\tBest loss: 0.485535\tAccuracy: 89.50%\n",
      "869\tValidation loss: 0.485368\tBest loss: 0.485368\tAccuracy: 89.50%\n",
      "870\tValidation loss: 0.485236\tBest loss: 0.485236\tAccuracy: 89.50%\n",
      "871\tValidation loss: 0.485125\tBest loss: 0.485125\tAccuracy: 89.50%\n",
      "872\tValidation loss: 0.485073\tBest loss: 0.485073\tAccuracy: 89.50%\n",
      "873\tValidation loss: 0.485098\tBest loss: 0.485073\tAccuracy: 89.50%\n",
      "874\tValidation loss: 0.484928\tBest loss: 0.484928\tAccuracy: 89.60%\n",
      "875\tValidation loss: 0.484727\tBest loss: 0.484727\tAccuracy: 89.60%\n",
      "876\tValidation loss: 0.484728\tBest loss: 0.484727\tAccuracy: 89.50%\n",
      "877\tValidation loss: 0.484519\tBest loss: 0.484519\tAccuracy: 89.60%\n",
      "878\tValidation loss: 0.484244\tBest loss: 0.484244\tAccuracy: 89.60%\n",
      "879\tValidation loss: 0.484213\tBest loss: 0.484213\tAccuracy: 89.60%\n",
      "880\tValidation loss: 0.484135\tBest loss: 0.484135\tAccuracy: 89.60%\n",
      "881\tValidation loss: 0.483963\tBest loss: 0.483963\tAccuracy: 89.60%\n",
      "882\tValidation loss: 0.483950\tBest loss: 0.483950\tAccuracy: 89.60%\n",
      "883\tValidation loss: 0.483949\tBest loss: 0.483949\tAccuracy: 89.60%\n",
      "884\tValidation loss: 0.483833\tBest loss: 0.483833\tAccuracy: 89.60%\n",
      "885\tValidation loss: 0.483696\tBest loss: 0.483696\tAccuracy: 89.50%\n",
      "886\tValidation loss: 0.483568\tBest loss: 0.483568\tAccuracy: 89.60%\n",
      "887\tValidation loss: 0.483450\tBest loss: 0.483450\tAccuracy: 89.60%\n",
      "888\tValidation loss: 0.483379\tBest loss: 0.483379\tAccuracy: 89.60%\n",
      "889\tValidation loss: 0.483247\tBest loss: 0.483247\tAccuracy: 89.60%\n",
      "890\tValidation loss: 0.483191\tBest loss: 0.483191\tAccuracy: 89.50%\n",
      "891\tValidation loss: 0.483003\tBest loss: 0.483003\tAccuracy: 89.60%\n",
      "892\tValidation loss: 0.482879\tBest loss: 0.482879\tAccuracy: 89.60%\n",
      "893\tValidation loss: 0.482784\tBest loss: 0.482784\tAccuracy: 89.60%\n",
      "894\tValidation loss: 0.482711\tBest loss: 0.482711\tAccuracy: 89.60%\n",
      "895\tValidation loss: 0.482696\tBest loss: 0.482696\tAccuracy: 89.60%\n",
      "896\tValidation loss: 0.482572\tBest loss: 0.482572\tAccuracy: 89.60%\n",
      "897\tValidation loss: 0.482557\tBest loss: 0.482557\tAccuracy: 89.60%\n",
      "898\tValidation loss: 0.482276\tBest loss: 0.482276\tAccuracy: 89.60%\n",
      "899\tValidation loss: 0.482209\tBest loss: 0.482209\tAccuracy: 89.60%\n",
      "900\tValidation loss: 0.482011\tBest loss: 0.482011\tAccuracy: 89.60%\n",
      "901\tValidation loss: 0.482092\tBest loss: 0.482011\tAccuracy: 89.60%\n",
      "902\tValidation loss: 0.481983\tBest loss: 0.481983\tAccuracy: 89.60%\n",
      "903\tValidation loss: 0.481812\tBest loss: 0.481812\tAccuracy: 89.60%\n",
      "904\tValidation loss: 0.481855\tBest loss: 0.481812\tAccuracy: 89.60%\n",
      "905\tValidation loss: 0.481776\tBest loss: 0.481776\tAccuracy: 89.60%\n",
      "906\tValidation loss: 0.481608\tBest loss: 0.481608\tAccuracy: 89.60%\n",
      "907\tValidation loss: 0.481433\tBest loss: 0.481433\tAccuracy: 89.60%\n",
      "908\tValidation loss: 0.481227\tBest loss: 0.481227\tAccuracy: 89.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\tValidation loss: 0.481172\tBest loss: 0.481172\tAccuracy: 89.60%\n",
      "910\tValidation loss: 0.481059\tBest loss: 0.481059\tAccuracy: 89.60%\n",
      "911\tValidation loss: 0.481053\tBest loss: 0.481053\tAccuracy: 89.60%\n",
      "912\tValidation loss: 0.480970\tBest loss: 0.480970\tAccuracy: 89.60%\n",
      "913\tValidation loss: 0.480733\tBest loss: 0.480733\tAccuracy: 89.60%\n",
      "914\tValidation loss: 0.480679\tBest loss: 0.480679\tAccuracy: 89.60%\n",
      "915\tValidation loss: 0.480616\tBest loss: 0.480616\tAccuracy: 89.60%\n",
      "916\tValidation loss: 0.480514\tBest loss: 0.480514\tAccuracy: 89.60%\n",
      "917\tValidation loss: 0.480485\tBest loss: 0.480485\tAccuracy: 89.60%\n",
      "918\tValidation loss: 0.480358\tBest loss: 0.480358\tAccuracy: 89.60%\n",
      "919\tValidation loss: 0.480221\tBest loss: 0.480221\tAccuracy: 89.60%\n",
      "920\tValidation loss: 0.480101\tBest loss: 0.480101\tAccuracy: 89.60%\n",
      "921\tValidation loss: 0.480048\tBest loss: 0.480048\tAccuracy: 89.60%\n",
      "922\tValidation loss: 0.480070\tBest loss: 0.480048\tAccuracy: 89.60%\n",
      "923\tValidation loss: 0.479945\tBest loss: 0.479945\tAccuracy: 89.60%\n",
      "924\tValidation loss: 0.479789\tBest loss: 0.479789\tAccuracy: 89.60%\n",
      "925\tValidation loss: 0.479603\tBest loss: 0.479603\tAccuracy: 89.60%\n",
      "926\tValidation loss: 0.479543\tBest loss: 0.479543\tAccuracy: 89.60%\n",
      "927\tValidation loss: 0.479324\tBest loss: 0.479324\tAccuracy: 89.60%\n",
      "928\tValidation loss: 0.479316\tBest loss: 0.479316\tAccuracy: 89.60%\n",
      "929\tValidation loss: 0.479257\tBest loss: 0.479257\tAccuracy: 89.60%\n",
      "930\tValidation loss: 0.479133\tBest loss: 0.479133\tAccuracy: 89.60%\n",
      "931\tValidation loss: 0.479009\tBest loss: 0.479009\tAccuracy: 89.60%\n",
      "932\tValidation loss: 0.478914\tBest loss: 0.478914\tAccuracy: 89.60%\n",
      "933\tValidation loss: 0.478850\tBest loss: 0.478850\tAccuracy: 89.60%\n",
      "934\tValidation loss: 0.478761\tBest loss: 0.478761\tAccuracy: 89.60%\n",
      "935\tValidation loss: 0.478605\tBest loss: 0.478605\tAccuracy: 89.60%\n",
      "936\tValidation loss: 0.478513\tBest loss: 0.478513\tAccuracy: 89.60%\n",
      "937\tValidation loss: 0.478508\tBest loss: 0.478508\tAccuracy: 89.60%\n",
      "938\tValidation loss: 0.478455\tBest loss: 0.478455\tAccuracy: 89.60%\n",
      "939\tValidation loss: 0.478404\tBest loss: 0.478404\tAccuracy: 89.60%\n",
      "940\tValidation loss: 0.478298\tBest loss: 0.478298\tAccuracy: 89.60%\n",
      "941\tValidation loss: 0.478120\tBest loss: 0.478120\tAccuracy: 89.60%\n",
      "942\tValidation loss: 0.477987\tBest loss: 0.477987\tAccuracy: 89.60%\n",
      "943\tValidation loss: 0.477892\tBest loss: 0.477892\tAccuracy: 89.60%\n",
      "944\tValidation loss: 0.477782\tBest loss: 0.477782\tAccuracy: 89.60%\n",
      "945\tValidation loss: 0.477663\tBest loss: 0.477663\tAccuracy: 89.60%\n",
      "946\tValidation loss: 0.477649\tBest loss: 0.477649\tAccuracy: 89.60%\n",
      "947\tValidation loss: 0.477507\tBest loss: 0.477507\tAccuracy: 89.60%\n",
      "948\tValidation loss: 0.477333\tBest loss: 0.477333\tAccuracy: 89.60%\n",
      "949\tValidation loss: 0.477217\tBest loss: 0.477217\tAccuracy: 89.60%\n",
      "950\tValidation loss: 0.477148\tBest loss: 0.477148\tAccuracy: 89.60%\n",
      "951\tValidation loss: 0.477159\tBest loss: 0.477148\tAccuracy: 89.60%\n",
      "952\tValidation loss: 0.477035\tBest loss: 0.477035\tAccuracy: 89.60%\n",
      "953\tValidation loss: 0.477008\tBest loss: 0.477008\tAccuracy: 89.60%\n",
      "954\tValidation loss: 0.476924\tBest loss: 0.476924\tAccuracy: 89.60%\n",
      "955\tValidation loss: 0.476800\tBest loss: 0.476800\tAccuracy: 89.60%\n",
      "956\tValidation loss: 0.476733\tBest loss: 0.476733\tAccuracy: 89.60%\n",
      "957\tValidation loss: 0.476679\tBest loss: 0.476679\tAccuracy: 89.60%\n",
      "958\tValidation loss: 0.476515\tBest loss: 0.476515\tAccuracy: 89.60%\n",
      "959\tValidation loss: 0.476564\tBest loss: 0.476515\tAccuracy: 89.60%\n",
      "960\tValidation loss: 0.476436\tBest loss: 0.476436\tAccuracy: 89.60%\n",
      "961\tValidation loss: 0.476349\tBest loss: 0.476349\tAccuracy: 89.60%\n",
      "962\tValidation loss: 0.476213\tBest loss: 0.476213\tAccuracy: 89.60%\n",
      "963\tValidation loss: 0.476163\tBest loss: 0.476163\tAccuracy: 89.60%\n",
      "964\tValidation loss: 0.475934\tBest loss: 0.475934\tAccuracy: 89.60%\n",
      "965\tValidation loss: 0.475949\tBest loss: 0.475934\tAccuracy: 89.60%\n",
      "966\tValidation loss: 0.475864\tBest loss: 0.475864\tAccuracy: 89.60%\n",
      "967\tValidation loss: 0.475751\tBest loss: 0.475751\tAccuracy: 89.60%\n",
      "968\tValidation loss: 0.475641\tBest loss: 0.475641\tAccuracy: 89.60%\n",
      "969\tValidation loss: 0.475573\tBest loss: 0.475573\tAccuracy: 89.60%\n",
      "970\tValidation loss: 0.475519\tBest loss: 0.475519\tAccuracy: 89.60%\n",
      "971\tValidation loss: 0.475389\tBest loss: 0.475389\tAccuracy: 89.60%\n",
      "972\tValidation loss: 0.475262\tBest loss: 0.475262\tAccuracy: 89.60%\n",
      "973\tValidation loss: 0.475260\tBest loss: 0.475260\tAccuracy: 89.60%\n",
      "974\tValidation loss: 0.475073\tBest loss: 0.475073\tAccuracy: 89.60%\n",
      "975\tValidation loss: 0.475135\tBest loss: 0.475073\tAccuracy: 89.60%\n",
      "976\tValidation loss: 0.474977\tBest loss: 0.474977\tAccuracy: 89.60%\n",
      "977\tValidation loss: 0.474894\tBest loss: 0.474894\tAccuracy: 89.60%\n",
      "978\tValidation loss: 0.474629\tBest loss: 0.474629\tAccuracy: 89.70%\n",
      "979\tValidation loss: 0.474465\tBest loss: 0.474465\tAccuracy: 89.70%\n",
      "980\tValidation loss: 0.474478\tBest loss: 0.474465\tAccuracy: 89.60%\n",
      "981\tValidation loss: 0.474452\tBest loss: 0.474452\tAccuracy: 89.60%\n",
      "982\tValidation loss: 0.474321\tBest loss: 0.474321\tAccuracy: 89.70%\n",
      "983\tValidation loss: 0.474275\tBest loss: 0.474275\tAccuracy: 89.60%\n",
      "984\tValidation loss: 0.474118\tBest loss: 0.474118\tAccuracy: 89.60%\n",
      "985\tValidation loss: 0.474030\tBest loss: 0.474030\tAccuracy: 89.60%\n",
      "986\tValidation loss: 0.474082\tBest loss: 0.474030\tAccuracy: 89.60%\n",
      "987\tValidation loss: 0.474019\tBest loss: 0.474019\tAccuracy: 89.70%\n",
      "988\tValidation loss: 0.473877\tBest loss: 0.473877\tAccuracy: 89.70%\n",
      "989\tValidation loss: 0.473810\tBest loss: 0.473810\tAccuracy: 89.70%\n",
      "990\tValidation loss: 0.473681\tBest loss: 0.473681\tAccuracy: 89.80%\n",
      "991\tValidation loss: 0.473547\tBest loss: 0.473547\tAccuracy: 89.80%\n",
      "992\tValidation loss: 0.473421\tBest loss: 0.473421\tAccuracy: 89.80%\n",
      "993\tValidation loss: 0.473338\tBest loss: 0.473338\tAccuracy: 89.80%\n",
      "994\tValidation loss: 0.473356\tBest loss: 0.473338\tAccuracy: 89.80%\n",
      "995\tValidation loss: 0.473164\tBest loss: 0.473164\tAccuracy: 89.70%\n",
      "996\tValidation loss: 0.473070\tBest loss: 0.473070\tAccuracy: 89.80%\n",
      "997\tValidation loss: 0.472983\tBest loss: 0.472983\tAccuracy: 89.80%\n",
      "998\tValidation loss: 0.472833\tBest loss: 0.472833\tAccuracy: 89.80%\n",
      "999\tValidation loss: 0.472830\tBest loss: 0.472830\tAccuracy: 89.80%\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.8min\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 22.242313\tBest loss: 22.242313\tAccuracy: 14.40%\n",
      "1\tValidation loss: 16.040688\tBest loss: 16.040688\tAccuracy: 42.00%\n",
      "2\tValidation loss: 14.748841\tBest loss: 14.748841\tAccuracy: 50.80%\n",
      "3\tValidation loss: 13.922896\tBest loss: 13.922896\tAccuracy: 66.40%\n",
      "4\tValidation loss: 18.955868\tBest loss: 13.922896\tAccuracy: 62.50%\n",
      "5\tValidation loss: 17.357399\tBest loss: 13.922896\tAccuracy: 65.50%\n",
      "6\tValidation loss: 8.552032\tBest loss: 8.552032\tAccuracy: 74.20%\n",
      "7\tValidation loss: 11.069623\tBest loss: 8.552032\tAccuracy: 77.40%\n",
      "8\tValidation loss: 13.697499\tBest loss: 8.552032\tAccuracy: 75.70%\n",
      "9\tValidation loss: 17.106800\tBest loss: 8.552032\tAccuracy: 73.20%\n",
      "10\tValidation loss: 20.762314\tBest loss: 8.552032\tAccuracy: 75.30%\n",
      "11\tValidation loss: 13.885391\tBest loss: 8.552032\tAccuracy: 80.50%\n",
      "12\tValidation loss: 12.391284\tBest loss: 8.552032\tAccuracy: 82.20%\n",
      "13\tValidation loss: 10.595524\tBest loss: 8.552032\tAccuracy: 85.50%\n",
      "14\tValidation loss: 10.812474\tBest loss: 8.552032\tAccuracy: 86.10%\n",
      "15\tValidation loss: 20.384119\tBest loss: 8.552032\tAccuracy: 81.10%\n",
      "16\tValidation loss: 18.364460\tBest loss: 8.552032\tAccuracy: 81.70%\n",
      "17\tValidation loss: 14.158512\tBest loss: 8.552032\tAccuracy: 86.00%\n",
      "18\tValidation loss: 16.988380\tBest loss: 8.552032\tAccuracy: 87.60%\n",
      "19\tValidation loss: 27.529331\tBest loss: 8.552032\tAccuracy: 81.30%\n",
      "20\tValidation loss: 17.830210\tBest loss: 8.552032\tAccuracy: 86.60%\n",
      "21\tValidation loss: 26.379143\tBest loss: 8.552032\tAccuracy: 84.60%\n",
      "22\tValidation loss: 26.034636\tBest loss: 8.552032\tAccuracy: 85.50%\n",
      "23\tValidation loss: 25.054626\tBest loss: 8.552032\tAccuracy: 85.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\tValidation loss: 22.837490\tBest loss: 8.552032\tAccuracy: 86.30%\n",
      "25\tValidation loss: 21.949345\tBest loss: 8.552032\tAccuracy: 88.60%\n",
      "26\tValidation loss: 28.865406\tBest loss: 8.552032\tAccuracy: 85.50%\n",
      "27\tValidation loss: 26.173206\tBest loss: 8.552032\tAccuracy: 87.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   7.1s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 16.833588\tBest loss: 16.833588\tAccuracy: 12.50%\n",
      "1\tValidation loss: 10.547712\tBest loss: 10.547712\tAccuracy: 45.10%\n",
      "2\tValidation loss: 8.752656\tBest loss: 8.752656\tAccuracy: 61.40%\n",
      "3\tValidation loss: 9.489873\tBest loss: 8.752656\tAccuracy: 68.00%\n",
      "4\tValidation loss: 18.228775\tBest loss: 8.752656\tAccuracy: 61.70%\n",
      "5\tValidation loss: 14.864962\tBest loss: 8.752656\tAccuracy: 71.00%\n",
      "6\tValidation loss: 13.632956\tBest loss: 8.752656\tAccuracy: 71.10%\n",
      "7\tValidation loss: 24.064255\tBest loss: 8.752656\tAccuracy: 71.50%\n",
      "8\tValidation loss: 9.532914\tBest loss: 8.752656\tAccuracy: 79.30%\n",
      "9\tValidation loss: 10.035073\tBest loss: 8.752656\tAccuracy: 82.60%\n",
      "10\tValidation loss: 16.681696\tBest loss: 8.752656\tAccuracy: 78.10%\n",
      "11\tValidation loss: 15.196932\tBest loss: 8.752656\tAccuracy: 82.90%\n",
      "12\tValidation loss: 17.055059\tBest loss: 8.752656\tAccuracy: 80.70%\n",
      "13\tValidation loss: 22.959911\tBest loss: 8.752656\tAccuracy: 79.00%\n",
      "14\tValidation loss: 14.731875\tBest loss: 8.752656\tAccuracy: 83.60%\n",
      "15\tValidation loss: 20.592972\tBest loss: 8.752656\tAccuracy: 81.60%\n",
      "16\tValidation loss: 24.050247\tBest loss: 8.752656\tAccuracy: 82.90%\n",
      "17\tValidation loss: 23.778387\tBest loss: 8.752656\tAccuracy: 83.00%\n",
      "18\tValidation loss: 30.645004\tBest loss: 8.752656\tAccuracy: 81.10%\n",
      "19\tValidation loss: 21.403084\tBest loss: 8.752656\tAccuracy: 84.10%\n",
      "20\tValidation loss: 22.784849\tBest loss: 8.752656\tAccuracy: 86.50%\n",
      "21\tValidation loss: 29.206554\tBest loss: 8.752656\tAccuracy: 85.50%\n",
      "22\tValidation loss: 23.355991\tBest loss: 8.752656\tAccuracy: 86.40%\n",
      "23\tValidation loss: 23.729017\tBest loss: 8.752656\tAccuracy: 87.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   6.0s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 12.271743\tBest loss: 12.271743\tAccuracy: 19.00%\n",
      "1\tValidation loss: 18.906963\tBest loss: 12.271743\tAccuracy: 29.60%\n",
      "2\tValidation loss: 8.036425\tBest loss: 8.036425\tAccuracy: 62.50%\n",
      "3\tValidation loss: 8.616228\tBest loss: 8.036425\tAccuracy: 70.90%\n",
      "4\tValidation loss: 13.005112\tBest loss: 8.036425\tAccuracy: 67.10%\n",
      "5\tValidation loss: 13.694650\tBest loss: 8.036425\tAccuracy: 68.80%\n",
      "6\tValidation loss: 6.847612\tBest loss: 6.847612\tAccuracy: 79.50%\n",
      "7\tValidation loss: 10.495914\tBest loss: 6.847612\tAccuracy: 77.00%\n",
      "8\tValidation loss: 9.674923\tBest loss: 6.847612\tAccuracy: 79.50%\n",
      "9\tValidation loss: 13.055841\tBest loss: 6.847612\tAccuracy: 79.90%\n",
      "10\tValidation loss: 13.399969\tBest loss: 6.847612\tAccuracy: 79.80%\n",
      "11\tValidation loss: 12.587397\tBest loss: 6.847612\tAccuracy: 83.30%\n",
      "12\tValidation loss: 13.162643\tBest loss: 6.847612\tAccuracy: 82.90%\n",
      "13\tValidation loss: 15.226788\tBest loss: 6.847612\tAccuracy: 83.90%\n",
      "14\tValidation loss: 26.514961\tBest loss: 6.847612\tAccuracy: 79.10%\n",
      "15\tValidation loss: 16.240372\tBest loss: 6.847612\tAccuracy: 84.70%\n",
      "16\tValidation loss: 20.677652\tBest loss: 6.847612\tAccuracy: 84.20%\n",
      "17\tValidation loss: 25.614132\tBest loss: 6.847612\tAccuracy: 82.70%\n",
      "18\tValidation loss: 17.033512\tBest loss: 6.847612\tAccuracy: 86.10%\n",
      "19\tValidation loss: 22.422165\tBest loss: 6.847612\tAccuracy: 85.40%\n",
      "20\tValidation loss: 20.759890\tBest loss: 6.847612\tAccuracy: 86.40%\n",
      "21\tValidation loss: 22.356281\tBest loss: 6.847612\tAccuracy: 84.80%\n",
      "22\tValidation loss: 34.575832\tBest loss: 6.847612\tAccuracy: 83.70%\n",
      "23\tValidation loss: 20.946497\tBest loss: 6.847612\tAccuracy: 86.40%\n",
      "24\tValidation loss: 28.525249\tBest loss: 6.847612\tAccuracy: 86.10%\n",
      "25\tValidation loss: 23.907938\tBest loss: 6.847612\tAccuracy: 88.50%\n",
      "26\tValidation loss: 23.472582\tBest loss: 6.847612\tAccuracy: 88.10%\n",
      "27\tValidation loss: 34.005928\tBest loss: 6.847612\tAccuracy: 87.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   6.9s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.572845\tBest loss: 2.572845\tAccuracy: 30.50%\n",
      "1\tValidation loss: 1.303353\tBest loss: 1.303353\tAccuracy: 60.30%\n",
      "2\tValidation loss: 0.946578\tBest loss: 0.946578\tAccuracy: 72.40%\n",
      "3\tValidation loss: 0.794585\tBest loss: 0.794585\tAccuracy: 77.00%\n",
      "4\tValidation loss: 0.681669\tBest loss: 0.681669\tAccuracy: 79.70%\n",
      "5\tValidation loss: 0.649590\tBest loss: 0.649590\tAccuracy: 81.10%\n",
      "6\tValidation loss: 0.560584\tBest loss: 0.560584\tAccuracy: 84.00%\n",
      "7\tValidation loss: 0.560829\tBest loss: 0.560584\tAccuracy: 84.90%\n",
      "8\tValidation loss: 0.517949\tBest loss: 0.517949\tAccuracy: 84.50%\n",
      "9\tValidation loss: 0.516233\tBest loss: 0.516233\tAccuracy: 85.40%\n",
      "10\tValidation loss: 0.502316\tBest loss: 0.502316\tAccuracy: 85.60%\n",
      "11\tValidation loss: 0.437677\tBest loss: 0.437677\tAccuracy: 88.20%\n",
      "12\tValidation loss: 0.461010\tBest loss: 0.437677\tAccuracy: 88.70%\n",
      "13\tValidation loss: 0.454574\tBest loss: 0.437677\tAccuracy: 88.60%\n",
      "14\tValidation loss: 0.537391\tBest loss: 0.437677\tAccuracy: 86.60%\n",
      "15\tValidation loss: 0.521023\tBest loss: 0.437677\tAccuracy: 87.30%\n",
      "16\tValidation loss: 0.423057\tBest loss: 0.423057\tAccuracy: 89.00%\n",
      "17\tValidation loss: 0.442867\tBest loss: 0.423057\tAccuracy: 88.70%\n",
      "18\tValidation loss: 0.461544\tBest loss: 0.423057\tAccuracy: 89.90%\n",
      "19\tValidation loss: 0.487311\tBest loss: 0.423057\tAccuracy: 88.90%\n",
      "20\tValidation loss: 0.512958\tBest loss: 0.423057\tAccuracy: 86.60%\n",
      "21\tValidation loss: 0.479040\tBest loss: 0.423057\tAccuracy: 90.10%\n",
      "22\tValidation loss: 0.524597\tBest loss: 0.423057\tAccuracy: 88.90%\n",
      "23\tValidation loss: 0.579733\tBest loss: 0.423057\tAccuracy: 89.50%\n",
      "24\tValidation loss: 0.517435\tBest loss: 0.423057\tAccuracy: 89.60%\n",
      "25\tValidation loss: 0.629225\tBest loss: 0.423057\tAccuracy: 87.50%\n",
      "26\tValidation loss: 0.509815\tBest loss: 0.423057\tAccuracy: 90.00%\n",
      "27\tValidation loss: 0.526123\tBest loss: 0.423057\tAccuracy: 90.50%\n",
      "28\tValidation loss: 0.464075\tBest loss: 0.423057\tAccuracy: 91.70%\n",
      "29\tValidation loss: 0.677892\tBest loss: 0.423057\tAccuracy: 86.10%\n",
      "30\tValidation loss: 0.507810\tBest loss: 0.423057\tAccuracy: 89.00%\n",
      "31\tValidation loss: 0.579685\tBest loss: 0.423057\tAccuracy: 88.60%\n",
      "32\tValidation loss: 0.522183\tBest loss: 0.423057\tAccuracy: 89.70%\n",
      "33\tValidation loss: 0.632357\tBest loss: 0.423057\tAccuracy: 88.60%\n",
      "34\tValidation loss: 0.579473\tBest loss: 0.423057\tAccuracy: 90.20%\n",
      "35\tValidation loss: 0.558163\tBest loss: 0.423057\tAccuracy: 90.80%\n",
      "36\tValidation loss: 0.544744\tBest loss: 0.423057\tAccuracy: 90.70%\n",
      "37\tValidation loss: 0.583651\tBest loss: 0.423057\tAccuracy: 90.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.2s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.619138\tBest loss: 2.619138\tAccuracy: 30.80%\n",
      "1\tValidation loss: 1.257430\tBest loss: 1.257430\tAccuracy: 63.00%\n",
      "2\tValidation loss: 0.972699\tBest loss: 0.972699\tAccuracy: 72.50%\n",
      "3\tValidation loss: 0.754911\tBest loss: 0.754911\tAccuracy: 77.40%\n",
      "4\tValidation loss: 0.655395\tBest loss: 0.655395\tAccuracy: 81.60%\n",
      "5\tValidation loss: 0.677218\tBest loss: 0.655395\tAccuracy: 79.90%\n",
      "6\tValidation loss: 0.564103\tBest loss: 0.564103\tAccuracy: 83.40%\n",
      "7\tValidation loss: 0.685578\tBest loss: 0.564103\tAccuracy: 80.80%\n",
      "8\tValidation loss: 0.507443\tBest loss: 0.507443\tAccuracy: 85.30%\n",
      "9\tValidation loss: 0.539644\tBest loss: 0.507443\tAccuracy: 84.20%\n",
      "10\tValidation loss: 0.542449\tBest loss: 0.507443\tAccuracy: 86.70%\n",
      "11\tValidation loss: 0.629743\tBest loss: 0.507443\tAccuracy: 83.00%\n",
      "12\tValidation loss: 0.583241\tBest loss: 0.507443\tAccuracy: 85.30%\n",
      "13\tValidation loss: 0.541111\tBest loss: 0.507443\tAccuracy: 86.00%\n",
      "14\tValidation loss: 0.554423\tBest loss: 0.507443\tAccuracy: 86.40%\n",
      "15\tValidation loss: 0.456687\tBest loss: 0.456687\tAccuracy: 89.40%\n",
      "16\tValidation loss: 0.533356\tBest loss: 0.456687\tAccuracy: 86.00%\n",
      "17\tValidation loss: 0.473805\tBest loss: 0.456687\tAccuracy: 88.50%\n",
      "18\tValidation loss: 0.604535\tBest loss: 0.456687\tAccuracy: 85.60%\n",
      "19\tValidation loss: 0.588710\tBest loss: 0.456687\tAccuracy: 89.20%\n",
      "20\tValidation loss: 0.580448\tBest loss: 0.456687\tAccuracy: 85.10%\n",
      "21\tValidation loss: 0.534457\tBest loss: 0.456687\tAccuracy: 88.80%\n",
      "22\tValidation loss: 0.512206\tBest loss: 0.456687\tAccuracy: 86.40%\n",
      "23\tValidation loss: 0.648044\tBest loss: 0.456687\tAccuracy: 86.30%\n",
      "24\tValidation loss: 0.593687\tBest loss: 0.456687\tAccuracy: 86.20%\n",
      "25\tValidation loss: 0.530169\tBest loss: 0.456687\tAccuracy: 90.20%\n",
      "26\tValidation loss: 0.488179\tBest loss: 0.456687\tAccuracy: 89.50%\n",
      "27\tValidation loss: 0.539528\tBest loss: 0.456687\tAccuracy: 89.00%\n",
      "28\tValidation loss: 0.758781\tBest loss: 0.456687\tAccuracy: 85.30%\n",
      "29\tValidation loss: 0.640610\tBest loss: 0.456687\tAccuracy: 88.10%\n",
      "30\tValidation loss: 0.637312\tBest loss: 0.456687\tAccuracy: 86.60%\n",
      "31\tValidation loss: 0.594309\tBest loss: 0.456687\tAccuracy: 88.30%\n",
      "32\tValidation loss: 0.573763\tBest loss: 0.456687\tAccuracy: 87.90%\n",
      "33\tValidation loss: 0.516995\tBest loss: 0.456687\tAccuracy: 90.80%\n",
      "34\tValidation loss: 0.608282\tBest loss: 0.456687\tAccuracy: 90.50%\n",
      "35\tValidation loss: 0.561006\tBest loss: 0.456687\tAccuracy: 90.50%\n",
      "36\tValidation loss: 0.694796\tBest loss: 0.456687\tAccuracy: 88.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.0s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.715787\tBest loss: 2.715787\tAccuracy: 26.30%\n",
      "1\tValidation loss: 1.427635\tBest loss: 1.427635\tAccuracy: 57.80%\n",
      "2\tValidation loss: 0.945270\tBest loss: 0.945270\tAccuracy: 72.90%\n",
      "3\tValidation loss: 0.809797\tBest loss: 0.809797\tAccuracy: 77.50%\n",
      "4\tValidation loss: 0.682698\tBest loss: 0.682698\tAccuracy: 80.40%\n",
      "5\tValidation loss: 0.647562\tBest loss: 0.647562\tAccuracy: 82.10%\n",
      "6\tValidation loss: 0.576591\tBest loss: 0.576591\tAccuracy: 82.90%\n",
      "7\tValidation loss: 0.553214\tBest loss: 0.553214\tAccuracy: 85.30%\n",
      "8\tValidation loss: 0.540290\tBest loss: 0.540290\tAccuracy: 83.80%\n",
      "9\tValidation loss: 0.575824\tBest loss: 0.540290\tAccuracy: 83.30%\n",
      "10\tValidation loss: 0.511381\tBest loss: 0.511381\tAccuracy: 87.60%\n",
      "11\tValidation loss: 0.502646\tBest loss: 0.502646\tAccuracy: 86.50%\n",
      "12\tValidation loss: 0.502949\tBest loss: 0.502646\tAccuracy: 87.10%\n",
      "13\tValidation loss: 0.512356\tBest loss: 0.502646\tAccuracy: 86.20%\n",
      "14\tValidation loss: 0.469688\tBest loss: 0.469688\tAccuracy: 89.40%\n",
      "15\tValidation loss: 0.404329\tBest loss: 0.404329\tAccuracy: 90.50%\n",
      "16\tValidation loss: 0.369338\tBest loss: 0.369338\tAccuracy: 90.30%\n",
      "17\tValidation loss: 0.506557\tBest loss: 0.369338\tAccuracy: 88.20%\n",
      "18\tValidation loss: 0.448957\tBest loss: 0.369338\tAccuracy: 88.00%\n",
      "19\tValidation loss: 0.443061\tBest loss: 0.369338\tAccuracy: 89.70%\n",
      "20\tValidation loss: 0.514466\tBest loss: 0.369338\tAccuracy: 87.20%\n",
      "21\tValidation loss: 0.416992\tBest loss: 0.369338\tAccuracy: 90.20%\n",
      "22\tValidation loss: 0.517737\tBest loss: 0.369338\tAccuracy: 88.50%\n",
      "23\tValidation loss: 0.771053\tBest loss: 0.369338\tAccuracy: 86.40%\n",
      "24\tValidation loss: 0.599686\tBest loss: 0.369338\tAccuracy: 87.70%\n",
      "25\tValidation loss: 0.506826\tBest loss: 0.369338\tAccuracy: 89.40%\n",
      "26\tValidation loss: 0.660173\tBest loss: 0.369338\tAccuracy: 88.90%\n",
      "27\tValidation loss: 0.652919\tBest loss: 0.369338\tAccuracy: 85.90%\n",
      "28\tValidation loss: 0.543270\tBest loss: 0.369338\tAccuracy: 88.70%\n",
      "29\tValidation loss: 0.622389\tBest loss: 0.369338\tAccuracy: 88.60%\n",
      "30\tValidation loss: 0.537169\tBest loss: 0.369338\tAccuracy: 87.70%\n",
      "31\tValidation loss: 0.592860\tBest loss: 0.369338\tAccuracy: 90.50%\n",
      "32\tValidation loss: 0.627906\tBest loss: 0.369338\tAccuracy: 87.30%\n",
      "33\tValidation loss: 0.564768\tBest loss: 0.369338\tAccuracy: 88.80%\n",
      "34\tValidation loss: 0.564926\tBest loss: 0.369338\tAccuracy: 88.80%\n",
      "35\tValidation loss: 0.627423\tBest loss: 0.369338\tAccuracy: 88.80%\n",
      "36\tValidation loss: 0.659715\tBest loss: 0.369338\tAccuracy: 86.80%\n",
      "37\tValidation loss: 0.684746\tBest loss: 0.369338\tAccuracy: 88.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.4s\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.340376\tBest loss: 2.340376\tAccuracy: 40.80%\n",
      "1\tValidation loss: 1.856399\tBest loss: 1.856399\tAccuracy: 57.00%\n",
      "2\tValidation loss: 1.603286\tBest loss: 1.603286\tAccuracy: 62.00%\n",
      "3\tValidation loss: 1.451313\tBest loss: 1.451313\tAccuracy: 66.20%\n",
      "4\tValidation loss: 1.341859\tBest loss: 1.341859\tAccuracy: 70.00%\n",
      "5\tValidation loss: 1.244085\tBest loss: 1.244085\tAccuracy: 71.60%\n",
      "6\tValidation loss: 1.172731\tBest loss: 1.172731\tAccuracy: 73.20%\n",
      "7\tValidation loss: 1.118911\tBest loss: 1.118911\tAccuracy: 73.80%\n",
      "8\tValidation loss: 1.074707\tBest loss: 1.074707\tAccuracy: 74.80%\n",
      "9\tValidation loss: 1.031193\tBest loss: 1.031193\tAccuracy: 75.00%\n",
      "10\tValidation loss: 1.002213\tBest loss: 1.002213\tAccuracy: 76.30%\n",
      "11\tValidation loss: 0.962289\tBest loss: 0.962289\tAccuracy: 77.50%\n",
      "12\tValidation loss: 0.934060\tBest loss: 0.934060\tAccuracy: 77.60%\n",
      "13\tValidation loss: 0.909146\tBest loss: 0.909146\tAccuracy: 79.30%\n",
      "14\tValidation loss: 0.892518\tBest loss: 0.892518\tAccuracy: 78.70%\n",
      "15\tValidation loss: 0.871872\tBest loss: 0.871872\tAccuracy: 79.20%\n",
      "16\tValidation loss: 0.848700\tBest loss: 0.848700\tAccuracy: 80.00%\n",
      "17\tValidation loss: 0.829348\tBest loss: 0.829348\tAccuracy: 80.60%\n",
      "18\tValidation loss: 0.814051\tBest loss: 0.814051\tAccuracy: 80.70%\n",
      "19\tValidation loss: 0.791857\tBest loss: 0.791857\tAccuracy: 82.00%\n",
      "20\tValidation loss: 0.780636\tBest loss: 0.780636\tAccuracy: 82.60%\n",
      "21\tValidation loss: 0.768433\tBest loss: 0.768433\tAccuracy: 82.00%\n",
      "22\tValidation loss: 0.757112\tBest loss: 0.757112\tAccuracy: 82.90%\n",
      "23\tValidation loss: 0.745431\tBest loss: 0.745431\tAccuracy: 83.00%\n",
      "24\tValidation loss: 0.734259\tBest loss: 0.734259\tAccuracy: 83.50%\n",
      "25\tValidation loss: 0.726322\tBest loss: 0.726322\tAccuracy: 83.20%\n",
      "26\tValidation loss: 0.716879\tBest loss: 0.716879\tAccuracy: 82.90%\n",
      "27\tValidation loss: 0.712361\tBest loss: 0.712361\tAccuracy: 84.00%\n",
      "28\tValidation loss: 0.702932\tBest loss: 0.702932\tAccuracy: 83.70%\n",
      "29\tValidation loss: 0.694059\tBest loss: 0.694059\tAccuracy: 84.30%\n",
      "30\tValidation loss: 0.692438\tBest loss: 0.692438\tAccuracy: 84.20%\n",
      "31\tValidation loss: 0.672023\tBest loss: 0.672023\tAccuracy: 85.70%\n",
      "32\tValidation loss: 0.666283\tBest loss: 0.666283\tAccuracy: 83.50%\n",
      "33\tValidation loss: 0.664241\tBest loss: 0.664241\tAccuracy: 85.60%\n",
      "34\tValidation loss: 0.656956\tBest loss: 0.656956\tAccuracy: 85.50%\n",
      "35\tValidation loss: 0.649287\tBest loss: 0.649287\tAccuracy: 85.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\tValidation loss: 0.636883\tBest loss: 0.636883\tAccuracy: 86.20%\n",
      "37\tValidation loss: 0.639900\tBest loss: 0.636883\tAccuracy: 85.40%\n",
      "38\tValidation loss: 0.633666\tBest loss: 0.633666\tAccuracy: 85.60%\n",
      "39\tValidation loss: 0.627156\tBest loss: 0.627156\tAccuracy: 85.30%\n",
      "40\tValidation loss: 0.626643\tBest loss: 0.626643\tAccuracy: 85.90%\n",
      "41\tValidation loss: 0.621583\tBest loss: 0.621583\tAccuracy: 86.30%\n",
      "42\tValidation loss: 0.610145\tBest loss: 0.610145\tAccuracy: 86.00%\n",
      "43\tValidation loss: 0.605807\tBest loss: 0.605807\tAccuracy: 86.60%\n",
      "44\tValidation loss: 0.607958\tBest loss: 0.605807\tAccuracy: 85.60%\n",
      "45\tValidation loss: 0.590635\tBest loss: 0.590635\tAccuracy: 86.70%\n",
      "46\tValidation loss: 0.594473\tBest loss: 0.590635\tAccuracy: 85.90%\n",
      "47\tValidation loss: 0.589930\tBest loss: 0.589930\tAccuracy: 87.20%\n",
      "48\tValidation loss: 0.586393\tBest loss: 0.586393\tAccuracy: 87.10%\n",
      "49\tValidation loss: 0.587434\tBest loss: 0.586393\tAccuracy: 87.10%\n",
      "50\tValidation loss: 0.582681\tBest loss: 0.582681\tAccuracy: 87.50%\n",
      "51\tValidation loss: 0.583425\tBest loss: 0.582681\tAccuracy: 86.80%\n",
      "52\tValidation loss: 0.568082\tBest loss: 0.568082\tAccuracy: 88.10%\n",
      "53\tValidation loss: 0.575046\tBest loss: 0.568082\tAccuracy: 87.70%\n",
      "54\tValidation loss: 0.563623\tBest loss: 0.563623\tAccuracy: 87.10%\n",
      "55\tValidation loss: 0.560859\tBest loss: 0.560859\tAccuracy: 88.10%\n",
      "56\tValidation loss: 0.565813\tBest loss: 0.560859\tAccuracy: 86.80%\n",
      "57\tValidation loss: 0.559494\tBest loss: 0.559494\tAccuracy: 86.70%\n",
      "58\tValidation loss: 0.554373\tBest loss: 0.554373\tAccuracy: 87.60%\n",
      "59\tValidation loss: 0.552549\tBest loss: 0.552549\tAccuracy: 87.40%\n",
      "60\tValidation loss: 0.545948\tBest loss: 0.545948\tAccuracy: 87.90%\n",
      "61\tValidation loss: 0.546335\tBest loss: 0.545948\tAccuracy: 87.90%\n",
      "62\tValidation loss: 0.539001\tBest loss: 0.539001\tAccuracy: 87.90%\n",
      "63\tValidation loss: 0.535994\tBest loss: 0.535994\tAccuracy: 87.90%\n",
      "64\tValidation loss: 0.536766\tBest loss: 0.535994\tAccuracy: 88.10%\n",
      "65\tValidation loss: 0.533957\tBest loss: 0.533957\tAccuracy: 88.40%\n",
      "66\tValidation loss: 0.529608\tBest loss: 0.529608\tAccuracy: 88.40%\n",
      "67\tValidation loss: 0.532001\tBest loss: 0.529608\tAccuracy: 88.20%\n",
      "68\tValidation loss: 0.528263\tBest loss: 0.528263\tAccuracy: 87.60%\n",
      "69\tValidation loss: 0.523197\tBest loss: 0.523197\tAccuracy: 88.40%\n",
      "70\tValidation loss: 0.525629\tBest loss: 0.523197\tAccuracy: 88.00%\n",
      "71\tValidation loss: 0.520963\tBest loss: 0.520963\tAccuracy: 87.80%\n",
      "72\tValidation loss: 0.516265\tBest loss: 0.516265\tAccuracy: 88.70%\n",
      "73\tValidation loss: 0.516513\tBest loss: 0.516265\tAccuracy: 88.80%\n",
      "74\tValidation loss: 0.522042\tBest loss: 0.516265\tAccuracy: 88.00%\n",
      "75\tValidation loss: 0.512685\tBest loss: 0.512685\tAccuracy: 88.50%\n",
      "76\tValidation loss: 0.511539\tBest loss: 0.511539\tAccuracy: 88.20%\n",
      "77\tValidation loss: 0.510769\tBest loss: 0.510769\tAccuracy: 88.50%\n",
      "78\tValidation loss: 0.504990\tBest loss: 0.504990\tAccuracy: 88.60%\n",
      "79\tValidation loss: 0.499954\tBest loss: 0.499954\tAccuracy: 88.70%\n",
      "80\tValidation loss: 0.507822\tBest loss: 0.499954\tAccuracy: 88.20%\n",
      "81\tValidation loss: 0.500853\tBest loss: 0.499954\tAccuracy: 89.20%\n",
      "82\tValidation loss: 0.501953\tBest loss: 0.499954\tAccuracy: 88.70%\n",
      "83\tValidation loss: 0.493446\tBest loss: 0.493446\tAccuracy: 89.00%\n",
      "84\tValidation loss: 0.495503\tBest loss: 0.493446\tAccuracy: 89.00%\n",
      "85\tValidation loss: 0.489693\tBest loss: 0.489693\tAccuracy: 88.90%\n",
      "86\tValidation loss: 0.493065\tBest loss: 0.489693\tAccuracy: 88.70%\n",
      "87\tValidation loss: 0.491985\tBest loss: 0.489693\tAccuracy: 88.80%\n",
      "88\tValidation loss: 0.491603\tBest loss: 0.489693\tAccuracy: 88.70%\n",
      "89\tValidation loss: 0.491557\tBest loss: 0.489693\tAccuracy: 88.20%\n",
      "90\tValidation loss: 0.489267\tBest loss: 0.489267\tAccuracy: 88.80%\n",
      "91\tValidation loss: 0.480865\tBest loss: 0.480865\tAccuracy: 89.10%\n",
      "92\tValidation loss: 0.485197\tBest loss: 0.480865\tAccuracy: 88.70%\n",
      "93\tValidation loss: 0.480953\tBest loss: 0.480865\tAccuracy: 88.90%\n",
      "94\tValidation loss: 0.484120\tBest loss: 0.480865\tAccuracy: 89.00%\n",
      "95\tValidation loss: 0.480044\tBest loss: 0.480044\tAccuracy: 88.90%\n",
      "96\tValidation loss: 0.476568\tBest loss: 0.476568\tAccuracy: 89.00%\n",
      "97\tValidation loss: 0.477981\tBest loss: 0.476568\tAccuracy: 89.00%\n",
      "98\tValidation loss: 0.473990\tBest loss: 0.473990\tAccuracy: 89.20%\n",
      "99\tValidation loss: 0.474487\tBest loss: 0.473990\tAccuracy: 88.90%\n",
      "100\tValidation loss: 0.473530\tBest loss: 0.473530\tAccuracy: 88.80%\n",
      "101\tValidation loss: 0.466483\tBest loss: 0.466483\tAccuracy: 89.70%\n",
      "102\tValidation loss: 0.466957\tBest loss: 0.466483\tAccuracy: 89.10%\n",
      "103\tValidation loss: 0.468442\tBest loss: 0.466483\tAccuracy: 88.80%\n",
      "104\tValidation loss: 0.467598\tBest loss: 0.466483\tAccuracy: 89.70%\n",
      "105\tValidation loss: 0.464834\tBest loss: 0.464834\tAccuracy: 89.30%\n",
      "106\tValidation loss: 0.464232\tBest loss: 0.464232\tAccuracy: 89.20%\n",
      "107\tValidation loss: 0.464727\tBest loss: 0.464232\tAccuracy: 89.30%\n",
      "108\tValidation loss: 0.465552\tBest loss: 0.464232\tAccuracy: 89.10%\n",
      "109\tValidation loss: 0.461483\tBest loss: 0.461483\tAccuracy: 89.50%\n",
      "110\tValidation loss: 0.459904\tBest loss: 0.459904\tAccuracy: 89.20%\n",
      "111\tValidation loss: 0.458361\tBest loss: 0.458361\tAccuracy: 89.40%\n",
      "112\tValidation loss: 0.456840\tBest loss: 0.456840\tAccuracy: 89.50%\n",
      "113\tValidation loss: 0.453276\tBest loss: 0.453276\tAccuracy: 89.20%\n",
      "114\tValidation loss: 0.454677\tBest loss: 0.453276\tAccuracy: 89.60%\n",
      "115\tValidation loss: 0.456066\tBest loss: 0.453276\tAccuracy: 89.00%\n",
      "116\tValidation loss: 0.453782\tBest loss: 0.453276\tAccuracy: 89.60%\n",
      "117\tValidation loss: 0.448140\tBest loss: 0.448140\tAccuracy: 89.40%\n",
      "118\tValidation loss: 0.448965\tBest loss: 0.448140\tAccuracy: 89.40%\n",
      "119\tValidation loss: 0.449731\tBest loss: 0.448140\tAccuracy: 89.20%\n",
      "120\tValidation loss: 0.449931\tBest loss: 0.448140\tAccuracy: 89.00%\n",
      "121\tValidation loss: 0.449905\tBest loss: 0.448140\tAccuracy: 89.30%\n",
      "122\tValidation loss: 0.448090\tBest loss: 0.448090\tAccuracy: 89.20%\n",
      "123\tValidation loss: 0.446247\tBest loss: 0.446247\tAccuracy: 88.90%\n",
      "124\tValidation loss: 0.445469\tBest loss: 0.445469\tAccuracy: 89.70%\n",
      "125\tValidation loss: 0.443528\tBest loss: 0.443528\tAccuracy: 89.80%\n",
      "126\tValidation loss: 0.443189\tBest loss: 0.443189\tAccuracy: 89.40%\n",
      "127\tValidation loss: 0.445175\tBest loss: 0.443189\tAccuracy: 89.30%\n",
      "128\tValidation loss: 0.438029\tBest loss: 0.438029\tAccuracy: 89.90%\n",
      "129\tValidation loss: 0.442743\tBest loss: 0.438029\tAccuracy: 89.60%\n",
      "130\tValidation loss: 0.442670\tBest loss: 0.438029\tAccuracy: 89.70%\n",
      "131\tValidation loss: 0.438506\tBest loss: 0.438029\tAccuracy: 89.40%\n",
      "132\tValidation loss: 0.437767\tBest loss: 0.437767\tAccuracy: 89.90%\n",
      "133\tValidation loss: 0.439814\tBest loss: 0.437767\tAccuracy: 89.40%\n",
      "134\tValidation loss: 0.440705\tBest loss: 0.437767\tAccuracy: 89.50%\n",
      "135\tValidation loss: 0.437421\tBest loss: 0.437421\tAccuracy: 89.50%\n",
      "136\tValidation loss: 0.433220\tBest loss: 0.433220\tAccuracy: 89.70%\n",
      "137\tValidation loss: 0.432624\tBest loss: 0.432624\tAccuracy: 89.60%\n",
      "138\tValidation loss: 0.429754\tBest loss: 0.429754\tAccuracy: 89.60%\n",
      "139\tValidation loss: 0.429777\tBest loss: 0.429754\tAccuracy: 89.80%\n",
      "140\tValidation loss: 0.430390\tBest loss: 0.429754\tAccuracy: 89.70%\n",
      "141\tValidation loss: 0.431314\tBest loss: 0.429754\tAccuracy: 90.00%\n",
      "142\tValidation loss: 0.429759\tBest loss: 0.429754\tAccuracy: 90.00%\n",
      "143\tValidation loss: 0.424527\tBest loss: 0.424527\tAccuracy: 90.40%\n",
      "144\tValidation loss: 0.426451\tBest loss: 0.424527\tAccuracy: 90.10%\n",
      "145\tValidation loss: 0.425562\tBest loss: 0.424527\tAccuracy: 89.70%\n",
      "146\tValidation loss: 0.421546\tBest loss: 0.421546\tAccuracy: 90.10%\n",
      "147\tValidation loss: 0.423206\tBest loss: 0.421546\tAccuracy: 89.80%\n",
      "148\tValidation loss: 0.425700\tBest loss: 0.421546\tAccuracy: 90.00%\n",
      "149\tValidation loss: 0.423371\tBest loss: 0.421546\tAccuracy: 89.70%\n",
      "150\tValidation loss: 0.421854\tBest loss: 0.421546\tAccuracy: 89.80%\n",
      "151\tValidation loss: 0.422139\tBest loss: 0.421546\tAccuracy: 89.90%\n",
      "152\tValidation loss: 0.419436\tBest loss: 0.419436\tAccuracy: 89.90%\n",
      "153\tValidation loss: 0.416939\tBest loss: 0.416939\tAccuracy: 90.20%\n",
      "154\tValidation loss: 0.420642\tBest loss: 0.416939\tAccuracy: 89.90%\n",
      "155\tValidation loss: 0.418406\tBest loss: 0.416939\tAccuracy: 90.10%\n",
      "156\tValidation loss: 0.419673\tBest loss: 0.416939\tAccuracy: 90.00%\n",
      "157\tValidation loss: 0.422710\tBest loss: 0.416939\tAccuracy: 89.70%\n",
      "158\tValidation loss: 0.415339\tBest loss: 0.415339\tAccuracy: 89.70%\n",
      "159\tValidation loss: 0.414981\tBest loss: 0.414981\tAccuracy: 89.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\tValidation loss: 0.419087\tBest loss: 0.414981\tAccuracy: 90.10%\n",
      "161\tValidation loss: 0.418142\tBest loss: 0.414981\tAccuracy: 90.20%\n",
      "162\tValidation loss: 0.414308\tBest loss: 0.414308\tAccuracy: 89.90%\n",
      "163\tValidation loss: 0.413295\tBest loss: 0.413295\tAccuracy: 90.10%\n",
      "164\tValidation loss: 0.410488\tBest loss: 0.410488\tAccuracy: 90.00%\n",
      "165\tValidation loss: 0.412115\tBest loss: 0.410488\tAccuracy: 90.00%\n",
      "166\tValidation loss: 0.411902\tBest loss: 0.410488\tAccuracy: 90.00%\n",
      "167\tValidation loss: 0.408276\tBest loss: 0.408276\tAccuracy: 90.30%\n",
      "168\tValidation loss: 0.412218\tBest loss: 0.408276\tAccuracy: 90.20%\n",
      "169\tValidation loss: 0.407142\tBest loss: 0.407142\tAccuracy: 90.30%\n",
      "170\tValidation loss: 0.408389\tBest loss: 0.407142\tAccuracy: 90.20%\n",
      "171\tValidation loss: 0.407476\tBest loss: 0.407142\tAccuracy: 90.20%\n",
      "172\tValidation loss: 0.406422\tBest loss: 0.406422\tAccuracy: 90.40%\n",
      "173\tValidation loss: 0.411034\tBest loss: 0.406422\tAccuracy: 90.20%\n",
      "174\tValidation loss: 0.404925\tBest loss: 0.404925\tAccuracy: 90.20%\n",
      "175\tValidation loss: 0.403467\tBest loss: 0.403467\tAccuracy: 90.20%\n",
      "176\tValidation loss: 0.410168\tBest loss: 0.403467\tAccuracy: 90.10%\n",
      "177\tValidation loss: 0.404833\tBest loss: 0.403467\tAccuracy: 90.40%\n",
      "178\tValidation loss: 0.405031\tBest loss: 0.403467\tAccuracy: 90.30%\n",
      "179\tValidation loss: 0.403121\tBest loss: 0.403121\tAccuracy: 89.90%\n",
      "180\tValidation loss: 0.402722\tBest loss: 0.402722\tAccuracy: 90.30%\n",
      "181\tValidation loss: 0.401745\tBest loss: 0.401745\tAccuracy: 90.10%\n",
      "182\tValidation loss: 0.403834\tBest loss: 0.401745\tAccuracy: 90.80%\n",
      "183\tValidation loss: 0.402953\tBest loss: 0.401745\tAccuracy: 90.30%\n",
      "184\tValidation loss: 0.404124\tBest loss: 0.401745\tAccuracy: 90.50%\n",
      "185\tValidation loss: 0.401043\tBest loss: 0.401043\tAccuracy: 90.10%\n",
      "186\tValidation loss: 0.397773\tBest loss: 0.397773\tAccuracy: 90.50%\n",
      "187\tValidation loss: 0.398550\tBest loss: 0.397773\tAccuracy: 90.20%\n",
      "188\tValidation loss: 0.400090\tBest loss: 0.397773\tAccuracy: 90.30%\n",
      "189\tValidation loss: 0.399385\tBest loss: 0.397773\tAccuracy: 90.50%\n",
      "190\tValidation loss: 0.397300\tBest loss: 0.397300\tAccuracy: 90.40%\n",
      "191\tValidation loss: 0.395863\tBest loss: 0.395863\tAccuracy: 90.40%\n",
      "192\tValidation loss: 0.397398\tBest loss: 0.395863\tAccuracy: 90.60%\n",
      "193\tValidation loss: 0.395457\tBest loss: 0.395457\tAccuracy: 90.50%\n",
      "194\tValidation loss: 0.395259\tBest loss: 0.395259\tAccuracy: 90.40%\n",
      "195\tValidation loss: 0.393995\tBest loss: 0.393995\tAccuracy: 90.30%\n",
      "196\tValidation loss: 0.396638\tBest loss: 0.393995\tAccuracy: 90.70%\n",
      "197\tValidation loss: 0.392898\tBest loss: 0.392898\tAccuracy: 90.30%\n",
      "198\tValidation loss: 0.393761\tBest loss: 0.392898\tAccuracy: 90.20%\n",
      "199\tValidation loss: 0.393469\tBest loss: 0.392898\tAccuracy: 90.50%\n",
      "200\tValidation loss: 0.397384\tBest loss: 0.392898\tAccuracy: 90.70%\n",
      "201\tValidation loss: 0.394758\tBest loss: 0.392898\tAccuracy: 90.70%\n",
      "202\tValidation loss: 0.394170\tBest loss: 0.392898\tAccuracy: 90.20%\n",
      "203\tValidation loss: 0.394358\tBest loss: 0.392898\tAccuracy: 90.30%\n",
      "204\tValidation loss: 0.394760\tBest loss: 0.392898\tAccuracy: 90.30%\n",
      "205\tValidation loss: 0.391767\tBest loss: 0.391767\tAccuracy: 90.70%\n",
      "206\tValidation loss: 0.387392\tBest loss: 0.387392\tAccuracy: 90.50%\n",
      "207\tValidation loss: 0.391453\tBest loss: 0.387392\tAccuracy: 90.70%\n",
      "208\tValidation loss: 0.392538\tBest loss: 0.387392\tAccuracy: 90.40%\n",
      "209\tValidation loss: 0.385985\tBest loss: 0.385985\tAccuracy: 90.70%\n",
      "210\tValidation loss: 0.386033\tBest loss: 0.385985\tAccuracy: 90.40%\n",
      "211\tValidation loss: 0.387161\tBest loss: 0.385985\tAccuracy: 90.70%\n",
      "212\tValidation loss: 0.385592\tBest loss: 0.385592\tAccuracy: 91.20%\n",
      "213\tValidation loss: 0.386192\tBest loss: 0.385592\tAccuracy: 90.70%\n",
      "214\tValidation loss: 0.384777\tBest loss: 0.384777\tAccuracy: 90.90%\n",
      "215\tValidation loss: 0.385375\tBest loss: 0.384777\tAccuracy: 90.30%\n",
      "216\tValidation loss: 0.382423\tBest loss: 0.382423\tAccuracy: 90.80%\n",
      "217\tValidation loss: 0.383844\tBest loss: 0.382423\tAccuracy: 90.60%\n",
      "218\tValidation loss: 0.385301\tBest loss: 0.382423\tAccuracy: 90.90%\n",
      "219\tValidation loss: 0.385821\tBest loss: 0.382423\tAccuracy: 90.60%\n",
      "220\tValidation loss: 0.386272\tBest loss: 0.382423\tAccuracy: 90.60%\n",
      "221\tValidation loss: 0.385776\tBest loss: 0.382423\tAccuracy: 90.70%\n",
      "222\tValidation loss: 0.385121\tBest loss: 0.382423\tAccuracy: 90.60%\n",
      "223\tValidation loss: 0.385005\tBest loss: 0.382423\tAccuracy: 90.90%\n",
      "224\tValidation loss: 0.382294\tBest loss: 0.382294\tAccuracy: 90.90%\n",
      "225\tValidation loss: 0.381966\tBest loss: 0.381966\tAccuracy: 91.30%\n",
      "226\tValidation loss: 0.382040\tBest loss: 0.381966\tAccuracy: 90.90%\n",
      "227\tValidation loss: 0.378943\tBest loss: 0.378943\tAccuracy: 90.90%\n",
      "228\tValidation loss: 0.380558\tBest loss: 0.378943\tAccuracy: 90.80%\n",
      "229\tValidation loss: 0.384604\tBest loss: 0.378943\tAccuracy: 90.40%\n",
      "230\tValidation loss: 0.381607\tBest loss: 0.378943\tAccuracy: 90.30%\n",
      "231\tValidation loss: 0.382063\tBest loss: 0.378943\tAccuracy: 90.70%\n",
      "232\tValidation loss: 0.381607\tBest loss: 0.378943\tAccuracy: 90.50%\n",
      "233\tValidation loss: 0.380917\tBest loss: 0.378943\tAccuracy: 91.00%\n",
      "234\tValidation loss: 0.378755\tBest loss: 0.378755\tAccuracy: 91.00%\n",
      "235\tValidation loss: 0.376593\tBest loss: 0.376593\tAccuracy: 90.70%\n",
      "236\tValidation loss: 0.381675\tBest loss: 0.376593\tAccuracy: 90.90%\n",
      "237\tValidation loss: 0.377016\tBest loss: 0.376593\tAccuracy: 91.10%\n",
      "238\tValidation loss: 0.378613\tBest loss: 0.376593\tAccuracy: 90.80%\n",
      "239\tValidation loss: 0.376045\tBest loss: 0.376045\tAccuracy: 90.90%\n",
      "240\tValidation loss: 0.377814\tBest loss: 0.376045\tAccuracy: 91.10%\n",
      "241\tValidation loss: 0.376195\tBest loss: 0.376045\tAccuracy: 91.00%\n",
      "242\tValidation loss: 0.376110\tBest loss: 0.376045\tAccuracy: 90.90%\n",
      "243\tValidation loss: 0.374140\tBest loss: 0.374140\tAccuracy: 90.90%\n",
      "244\tValidation loss: 0.377058\tBest loss: 0.374140\tAccuracy: 91.30%\n",
      "245\tValidation loss: 0.375473\tBest loss: 0.374140\tAccuracy: 91.10%\n",
      "246\tValidation loss: 0.374115\tBest loss: 0.374115\tAccuracy: 90.90%\n",
      "247\tValidation loss: 0.373391\tBest loss: 0.373391\tAccuracy: 91.20%\n",
      "248\tValidation loss: 0.373014\tBest loss: 0.373014\tAccuracy: 91.30%\n",
      "249\tValidation loss: 0.372909\tBest loss: 0.372909\tAccuracy: 90.90%\n",
      "250\tValidation loss: 0.375366\tBest loss: 0.372909\tAccuracy: 90.90%\n",
      "251\tValidation loss: 0.372194\tBest loss: 0.372194\tAccuracy: 91.30%\n",
      "252\tValidation loss: 0.371519\tBest loss: 0.371519\tAccuracy: 91.10%\n",
      "253\tValidation loss: 0.374237\tBest loss: 0.371519\tAccuracy: 90.90%\n",
      "254\tValidation loss: 0.372994\tBest loss: 0.371519\tAccuracy: 91.30%\n",
      "255\tValidation loss: 0.372488\tBest loss: 0.371519\tAccuracy: 91.20%\n",
      "256\tValidation loss: 0.371885\tBest loss: 0.371519\tAccuracy: 91.40%\n",
      "257\tValidation loss: 0.373218\tBest loss: 0.371519\tAccuracy: 91.10%\n",
      "258\tValidation loss: 0.372305\tBest loss: 0.371519\tAccuracy: 91.00%\n",
      "259\tValidation loss: 0.366611\tBest loss: 0.366611\tAccuracy: 91.40%\n",
      "260\tValidation loss: 0.370152\tBest loss: 0.366611\tAccuracy: 90.90%\n",
      "261\tValidation loss: 0.367137\tBest loss: 0.366611\tAccuracy: 90.90%\n",
      "262\tValidation loss: 0.370635\tBest loss: 0.366611\tAccuracy: 91.00%\n",
      "263\tValidation loss: 0.370538\tBest loss: 0.366611\tAccuracy: 91.20%\n",
      "264\tValidation loss: 0.371087\tBest loss: 0.366611\tAccuracy: 91.10%\n",
      "265\tValidation loss: 0.368512\tBest loss: 0.366611\tAccuracy: 91.20%\n",
      "266\tValidation loss: 0.370884\tBest loss: 0.366611\tAccuracy: 91.20%\n",
      "267\tValidation loss: 0.368255\tBest loss: 0.366611\tAccuracy: 91.60%\n",
      "268\tValidation loss: 0.370301\tBest loss: 0.366611\tAccuracy: 91.20%\n",
      "269\tValidation loss: 0.366205\tBest loss: 0.366205\tAccuracy: 91.20%\n",
      "270\tValidation loss: 0.368770\tBest loss: 0.366205\tAccuracy: 91.00%\n",
      "271\tValidation loss: 0.366080\tBest loss: 0.366080\tAccuracy: 90.90%\n",
      "272\tValidation loss: 0.364915\tBest loss: 0.364915\tAccuracy: 91.40%\n",
      "273\tValidation loss: 0.368190\tBest loss: 0.364915\tAccuracy: 91.10%\n",
      "274\tValidation loss: 0.366624\tBest loss: 0.364915\tAccuracy: 91.10%\n",
      "275\tValidation loss: 0.364235\tBest loss: 0.364235\tAccuracy: 91.10%\n",
      "276\tValidation loss: 0.366551\tBest loss: 0.364235\tAccuracy: 90.70%\n",
      "277\tValidation loss: 0.364997\tBest loss: 0.364235\tAccuracy: 91.20%\n",
      "278\tValidation loss: 0.365407\tBest loss: 0.364235\tAccuracy: 91.20%\n",
      "279\tValidation loss: 0.365019\tBest loss: 0.364235\tAccuracy: 90.80%\n",
      "280\tValidation loss: 0.367653\tBest loss: 0.364235\tAccuracy: 91.00%\n",
      "281\tValidation loss: 0.366444\tBest loss: 0.364235\tAccuracy: 91.10%\n",
      "282\tValidation loss: 0.362109\tBest loss: 0.362109\tAccuracy: 91.20%\n",
      "283\tValidation loss: 0.361927\tBest loss: 0.361927\tAccuracy: 91.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\tValidation loss: 0.366556\tBest loss: 0.361927\tAccuracy: 91.10%\n",
      "285\tValidation loss: 0.364849\tBest loss: 0.361927\tAccuracy: 91.30%\n",
      "286\tValidation loss: 0.363386\tBest loss: 0.361927\tAccuracy: 91.30%\n",
      "287\tValidation loss: 0.363705\tBest loss: 0.361927\tAccuracy: 91.50%\n",
      "288\tValidation loss: 0.362154\tBest loss: 0.361927\tAccuracy: 91.10%\n",
      "289\tValidation loss: 0.361729\tBest loss: 0.361729\tAccuracy: 91.40%\n",
      "290\tValidation loss: 0.362888\tBest loss: 0.361729\tAccuracy: 91.60%\n",
      "291\tValidation loss: 0.360099\tBest loss: 0.360099\tAccuracy: 91.20%\n",
      "292\tValidation loss: 0.363409\tBest loss: 0.360099\tAccuracy: 91.20%\n",
      "293\tValidation loss: 0.363244\tBest loss: 0.360099\tAccuracy: 91.30%\n",
      "294\tValidation loss: 0.362172\tBest loss: 0.360099\tAccuracy: 91.50%\n",
      "295\tValidation loss: 0.360418\tBest loss: 0.360099\tAccuracy: 91.40%\n",
      "296\tValidation loss: 0.361001\tBest loss: 0.360099\tAccuracy: 91.60%\n",
      "297\tValidation loss: 0.362449\tBest loss: 0.360099\tAccuracy: 91.20%\n",
      "298\tValidation loss: 0.363961\tBest loss: 0.360099\tAccuracy: 91.50%\n",
      "299\tValidation loss: 0.360232\tBest loss: 0.360099\tAccuracy: 91.50%\n",
      "300\tValidation loss: 0.361048\tBest loss: 0.360099\tAccuracy: 91.50%\n",
      "301\tValidation loss: 0.359617\tBest loss: 0.359617\tAccuracy: 91.80%\n",
      "302\tValidation loss: 0.359720\tBest loss: 0.359617\tAccuracy: 91.50%\n",
      "303\tValidation loss: 0.358406\tBest loss: 0.358406\tAccuracy: 91.20%\n",
      "304\tValidation loss: 0.361922\tBest loss: 0.358406\tAccuracy: 91.50%\n",
      "305\tValidation loss: 0.359437\tBest loss: 0.358406\tAccuracy: 91.50%\n",
      "306\tValidation loss: 0.356923\tBest loss: 0.356923\tAccuracy: 91.40%\n",
      "307\tValidation loss: 0.357861\tBest loss: 0.356923\tAccuracy: 91.50%\n",
      "308\tValidation loss: 0.357433\tBest loss: 0.356923\tAccuracy: 91.40%\n",
      "309\tValidation loss: 0.358477\tBest loss: 0.356923\tAccuracy: 91.70%\n",
      "310\tValidation loss: 0.355270\tBest loss: 0.355270\tAccuracy: 91.80%\n",
      "311\tValidation loss: 0.356065\tBest loss: 0.355270\tAccuracy: 91.50%\n",
      "312\tValidation loss: 0.356377\tBest loss: 0.355270\tAccuracy: 91.50%\n",
      "313\tValidation loss: 0.354611\tBest loss: 0.354611\tAccuracy: 91.80%\n",
      "314\tValidation loss: 0.356471\tBest loss: 0.354611\tAccuracy: 91.40%\n",
      "315\tValidation loss: 0.354685\tBest loss: 0.354611\tAccuracy: 91.80%\n",
      "316\tValidation loss: 0.352662\tBest loss: 0.352662\tAccuracy: 91.60%\n",
      "317\tValidation loss: 0.356060\tBest loss: 0.352662\tAccuracy: 91.50%\n",
      "318\tValidation loss: 0.353749\tBest loss: 0.352662\tAccuracy: 91.50%\n",
      "319\tValidation loss: 0.353312\tBest loss: 0.352662\tAccuracy: 91.90%\n",
      "320\tValidation loss: 0.353278\tBest loss: 0.352662\tAccuracy: 91.60%\n",
      "321\tValidation loss: 0.353994\tBest loss: 0.352662\tAccuracy: 91.50%\n",
      "322\tValidation loss: 0.354001\tBest loss: 0.352662\tAccuracy: 91.80%\n",
      "323\tValidation loss: 0.351637\tBest loss: 0.351637\tAccuracy: 91.40%\n",
      "324\tValidation loss: 0.350797\tBest loss: 0.350797\tAccuracy: 91.60%\n",
      "325\tValidation loss: 0.352337\tBest loss: 0.350797\tAccuracy: 91.50%\n",
      "326\tValidation loss: 0.356211\tBest loss: 0.350797\tAccuracy: 91.50%\n",
      "327\tValidation loss: 0.353690\tBest loss: 0.350797\tAccuracy: 92.20%\n",
      "328\tValidation loss: 0.354596\tBest loss: 0.350797\tAccuracy: 91.80%\n",
      "329\tValidation loss: 0.352860\tBest loss: 0.350797\tAccuracy: 91.50%\n",
      "330\tValidation loss: 0.353707\tBest loss: 0.350797\tAccuracy: 91.70%\n",
      "331\tValidation loss: 0.353140\tBest loss: 0.350797\tAccuracy: 91.60%\n",
      "332\tValidation loss: 0.352326\tBest loss: 0.350797\tAccuracy: 91.90%\n",
      "333\tValidation loss: 0.350403\tBest loss: 0.350403\tAccuracy: 91.90%\n",
      "334\tValidation loss: 0.355045\tBest loss: 0.350403\tAccuracy: 91.80%\n",
      "335\tValidation loss: 0.350884\tBest loss: 0.350403\tAccuracy: 92.00%\n",
      "336\tValidation loss: 0.348995\tBest loss: 0.348995\tAccuracy: 91.70%\n",
      "337\tValidation loss: 0.350212\tBest loss: 0.348995\tAccuracy: 92.00%\n",
      "338\tValidation loss: 0.349761\tBest loss: 0.348995\tAccuracy: 91.50%\n",
      "339\tValidation loss: 0.350259\tBest loss: 0.348995\tAccuracy: 91.90%\n",
      "340\tValidation loss: 0.351744\tBest loss: 0.348995\tAccuracy: 91.90%\n",
      "341\tValidation loss: 0.350369\tBest loss: 0.348995\tAccuracy: 92.20%\n",
      "342\tValidation loss: 0.349500\tBest loss: 0.348995\tAccuracy: 92.20%\n",
      "343\tValidation loss: 0.346765\tBest loss: 0.346765\tAccuracy: 92.30%\n",
      "344\tValidation loss: 0.349385\tBest loss: 0.346765\tAccuracy: 92.40%\n",
      "345\tValidation loss: 0.348331\tBest loss: 0.346765\tAccuracy: 91.90%\n",
      "346\tValidation loss: 0.349503\tBest loss: 0.346765\tAccuracy: 91.90%\n",
      "347\tValidation loss: 0.349096\tBest loss: 0.346765\tAccuracy: 91.80%\n",
      "348\tValidation loss: 0.350286\tBest loss: 0.346765\tAccuracy: 92.30%\n",
      "349\tValidation loss: 0.349266\tBest loss: 0.346765\tAccuracy: 92.10%\n",
      "350\tValidation loss: 0.347207\tBest loss: 0.346765\tAccuracy: 91.70%\n",
      "351\tValidation loss: 0.349902\tBest loss: 0.346765\tAccuracy: 92.30%\n",
      "352\tValidation loss: 0.349089\tBest loss: 0.346765\tAccuracy: 92.10%\n",
      "353\tValidation loss: 0.346382\tBest loss: 0.346382\tAccuracy: 91.80%\n",
      "354\tValidation loss: 0.349195\tBest loss: 0.346382\tAccuracy: 92.10%\n",
      "355\tValidation loss: 0.346804\tBest loss: 0.346382\tAccuracy: 91.80%\n",
      "356\tValidation loss: 0.347527\tBest loss: 0.346382\tAccuracy: 91.90%\n",
      "357\tValidation loss: 0.345629\tBest loss: 0.345629\tAccuracy: 91.70%\n",
      "358\tValidation loss: 0.347983\tBest loss: 0.345629\tAccuracy: 92.30%\n",
      "359\tValidation loss: 0.347633\tBest loss: 0.345629\tAccuracy: 91.90%\n",
      "360\tValidation loss: 0.346062\tBest loss: 0.345629\tAccuracy: 91.90%\n",
      "361\tValidation loss: 0.346551\tBest loss: 0.345629\tAccuracy: 91.90%\n",
      "362\tValidation loss: 0.345210\tBest loss: 0.345210\tAccuracy: 92.00%\n",
      "363\tValidation loss: 0.346068\tBest loss: 0.345210\tAccuracy: 92.00%\n",
      "364\tValidation loss: 0.345889\tBest loss: 0.345210\tAccuracy: 92.10%\n",
      "365\tValidation loss: 0.348376\tBest loss: 0.345210\tAccuracy: 91.80%\n",
      "366\tValidation loss: 0.344975\tBest loss: 0.344975\tAccuracy: 92.00%\n",
      "367\tValidation loss: 0.343960\tBest loss: 0.343960\tAccuracy: 92.50%\n",
      "368\tValidation loss: 0.343550\tBest loss: 0.343550\tAccuracy: 92.40%\n",
      "369\tValidation loss: 0.343803\tBest loss: 0.343550\tAccuracy: 92.00%\n",
      "370\tValidation loss: 0.344390\tBest loss: 0.343550\tAccuracy: 92.00%\n",
      "371\tValidation loss: 0.343042\tBest loss: 0.343042\tAccuracy: 92.30%\n",
      "372\tValidation loss: 0.343733\tBest loss: 0.343042\tAccuracy: 92.30%\n",
      "373\tValidation loss: 0.344809\tBest loss: 0.343042\tAccuracy: 92.00%\n",
      "374\tValidation loss: 0.342408\tBest loss: 0.342408\tAccuracy: 92.00%\n",
      "375\tValidation loss: 0.342718\tBest loss: 0.342408\tAccuracy: 92.30%\n",
      "376\tValidation loss: 0.344769\tBest loss: 0.342408\tAccuracy: 92.50%\n",
      "377\tValidation loss: 0.344438\tBest loss: 0.342408\tAccuracy: 92.50%\n",
      "378\tValidation loss: 0.342028\tBest loss: 0.342028\tAccuracy: 92.10%\n",
      "379\tValidation loss: 0.343588\tBest loss: 0.342028\tAccuracy: 92.60%\n",
      "380\tValidation loss: 0.342041\tBest loss: 0.342028\tAccuracy: 92.30%\n",
      "381\tValidation loss: 0.342930\tBest loss: 0.342028\tAccuracy: 92.00%\n",
      "382\tValidation loss: 0.342127\tBest loss: 0.342028\tAccuracy: 92.10%\n",
      "383\tValidation loss: 0.341616\tBest loss: 0.341616\tAccuracy: 92.30%\n",
      "384\tValidation loss: 0.344363\tBest loss: 0.341616\tAccuracy: 92.40%\n",
      "385\tValidation loss: 0.340687\tBest loss: 0.340687\tAccuracy: 92.10%\n",
      "386\tValidation loss: 0.342625\tBest loss: 0.340687\tAccuracy: 92.60%\n",
      "387\tValidation loss: 0.341243\tBest loss: 0.340687\tAccuracy: 92.20%\n",
      "388\tValidation loss: 0.340166\tBest loss: 0.340166\tAccuracy: 92.20%\n",
      "389\tValidation loss: 0.342718\tBest loss: 0.340166\tAccuracy: 92.20%\n",
      "390\tValidation loss: 0.340445\tBest loss: 0.340166\tAccuracy: 92.40%\n",
      "391\tValidation loss: 0.338794\tBest loss: 0.338794\tAccuracy: 92.20%\n",
      "392\tValidation loss: 0.341561\tBest loss: 0.338794\tAccuracy: 92.10%\n",
      "393\tValidation loss: 0.340615\tBest loss: 0.338794\tAccuracy: 92.70%\n",
      "394\tValidation loss: 0.337156\tBest loss: 0.337156\tAccuracy: 92.60%\n",
      "395\tValidation loss: 0.341193\tBest loss: 0.337156\tAccuracy: 92.10%\n",
      "396\tValidation loss: 0.339341\tBest loss: 0.337156\tAccuracy: 92.50%\n",
      "397\tValidation loss: 0.338208\tBest loss: 0.337156\tAccuracy: 92.30%\n",
      "398\tValidation loss: 0.336494\tBest loss: 0.336494\tAccuracy: 92.40%\n",
      "399\tValidation loss: 0.338678\tBest loss: 0.336494\tAccuracy: 92.40%\n",
      "400\tValidation loss: 0.338411\tBest loss: 0.336494\tAccuracy: 92.50%\n",
      "401\tValidation loss: 0.340621\tBest loss: 0.336494\tAccuracy: 92.50%\n",
      "402\tValidation loss: 0.338966\tBest loss: 0.336494\tAccuracy: 92.50%\n",
      "403\tValidation loss: 0.339771\tBest loss: 0.336494\tAccuracy: 92.10%\n",
      "404\tValidation loss: 0.337714\tBest loss: 0.336494\tAccuracy: 92.40%\n",
      "405\tValidation loss: 0.339825\tBest loss: 0.336494\tAccuracy: 92.50%\n",
      "406\tValidation loss: 0.340138\tBest loss: 0.336494\tAccuracy: 92.70%\n",
      "407\tValidation loss: 0.336461\tBest loss: 0.336461\tAccuracy: 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\tValidation loss: 0.336052\tBest loss: 0.336052\tAccuracy: 92.80%\n",
      "409\tValidation loss: 0.337757\tBest loss: 0.336052\tAccuracy: 92.60%\n",
      "410\tValidation loss: 0.337383\tBest loss: 0.336052\tAccuracy: 92.70%\n",
      "411\tValidation loss: 0.337238\tBest loss: 0.336052\tAccuracy: 92.70%\n",
      "412\tValidation loss: 0.334516\tBest loss: 0.334516\tAccuracy: 92.50%\n",
      "413\tValidation loss: 0.339176\tBest loss: 0.334516\tAccuracy: 92.60%\n",
      "414\tValidation loss: 0.336172\tBest loss: 0.334516\tAccuracy: 92.40%\n",
      "415\tValidation loss: 0.336643\tBest loss: 0.334516\tAccuracy: 92.70%\n",
      "416\tValidation loss: 0.339265\tBest loss: 0.334516\tAccuracy: 92.60%\n",
      "417\tValidation loss: 0.335518\tBest loss: 0.334516\tAccuracy: 92.90%\n",
      "418\tValidation loss: 0.336479\tBest loss: 0.334516\tAccuracy: 92.40%\n",
      "419\tValidation loss: 0.335934\tBest loss: 0.334516\tAccuracy: 92.80%\n",
      "420\tValidation loss: 0.336178\tBest loss: 0.334516\tAccuracy: 92.70%\n",
      "421\tValidation loss: 0.334782\tBest loss: 0.334516\tAccuracy: 92.60%\n",
      "422\tValidation loss: 0.334694\tBest loss: 0.334516\tAccuracy: 92.70%\n",
      "423\tValidation loss: 0.335237\tBest loss: 0.334516\tAccuracy: 92.60%\n",
      "424\tValidation loss: 0.335455\tBest loss: 0.334516\tAccuracy: 92.70%\n",
      "425\tValidation loss: 0.337918\tBest loss: 0.334516\tAccuracy: 92.70%\n",
      "426\tValidation loss: 0.335485\tBest loss: 0.334516\tAccuracy: 92.40%\n",
      "427\tValidation loss: 0.333600\tBest loss: 0.333600\tAccuracy: 92.60%\n",
      "428\tValidation loss: 0.333788\tBest loss: 0.333600\tAccuracy: 92.60%\n",
      "429\tValidation loss: 0.335117\tBest loss: 0.333600\tAccuracy: 92.80%\n",
      "430\tValidation loss: 0.334336\tBest loss: 0.333600\tAccuracy: 92.70%\n",
      "431\tValidation loss: 0.336647\tBest loss: 0.333600\tAccuracy: 92.70%\n",
      "432\tValidation loss: 0.334332\tBest loss: 0.333600\tAccuracy: 92.50%\n",
      "433\tValidation loss: 0.334910\tBest loss: 0.333600\tAccuracy: 92.60%\n",
      "434\tValidation loss: 0.335985\tBest loss: 0.333600\tAccuracy: 92.80%\n",
      "435\tValidation loss: 0.334394\tBest loss: 0.333600\tAccuracy: 92.30%\n",
      "436\tValidation loss: 0.334877\tBest loss: 0.333600\tAccuracy: 92.60%\n",
      "437\tValidation loss: 0.335792\tBest loss: 0.333600\tAccuracy: 92.70%\n",
      "438\tValidation loss: 0.334130\tBest loss: 0.333600\tAccuracy: 92.60%\n",
      "439\tValidation loss: 0.334547\tBest loss: 0.333600\tAccuracy: 92.80%\n",
      "440\tValidation loss: 0.332943\tBest loss: 0.332943\tAccuracy: 93.00%\n",
      "441\tValidation loss: 0.333244\tBest loss: 0.332943\tAccuracy: 92.80%\n",
      "442\tValidation loss: 0.334547\tBest loss: 0.332943\tAccuracy: 92.60%\n",
      "443\tValidation loss: 0.333184\tBest loss: 0.332943\tAccuracy: 92.50%\n",
      "444\tValidation loss: 0.333606\tBest loss: 0.332943\tAccuracy: 92.60%\n",
      "445\tValidation loss: 0.333633\tBest loss: 0.332943\tAccuracy: 92.70%\n",
      "446\tValidation loss: 0.332791\tBest loss: 0.332791\tAccuracy: 92.90%\n",
      "447\tValidation loss: 0.331587\tBest loss: 0.331587\tAccuracy: 92.50%\n",
      "448\tValidation loss: 0.334352\tBest loss: 0.331587\tAccuracy: 92.50%\n",
      "449\tValidation loss: 0.331958\tBest loss: 0.331587\tAccuracy: 92.80%\n",
      "450\tValidation loss: 0.333867\tBest loss: 0.331587\tAccuracy: 92.60%\n",
      "451\tValidation loss: 0.330641\tBest loss: 0.330641\tAccuracy: 92.50%\n",
      "452\tValidation loss: 0.333349\tBest loss: 0.330641\tAccuracy: 92.80%\n",
      "453\tValidation loss: 0.333952\tBest loss: 0.330641\tAccuracy: 92.60%\n",
      "454\tValidation loss: 0.332175\tBest loss: 0.330641\tAccuracy: 92.70%\n",
      "455\tValidation loss: 0.332912\tBest loss: 0.330641\tAccuracy: 92.60%\n",
      "456\tValidation loss: 0.330239\tBest loss: 0.330239\tAccuracy: 92.90%\n",
      "457\tValidation loss: 0.332337\tBest loss: 0.330239\tAccuracy: 92.60%\n",
      "458\tValidation loss: 0.332873\tBest loss: 0.330239\tAccuracy: 92.60%\n",
      "459\tValidation loss: 0.332614\tBest loss: 0.330239\tAccuracy: 92.80%\n",
      "460\tValidation loss: 0.331640\tBest loss: 0.330239\tAccuracy: 92.60%\n",
      "461\tValidation loss: 0.331125\tBest loss: 0.330239\tAccuracy: 92.60%\n",
      "462\tValidation loss: 0.331983\tBest loss: 0.330239\tAccuracy: 92.90%\n",
      "463\tValidation loss: 0.331752\tBest loss: 0.330239\tAccuracy: 92.70%\n",
      "464\tValidation loss: 0.331986\tBest loss: 0.330239\tAccuracy: 92.60%\n",
      "465\tValidation loss: 0.334227\tBest loss: 0.330239\tAccuracy: 92.50%\n",
      "466\tValidation loss: 0.330797\tBest loss: 0.330239\tAccuracy: 92.80%\n",
      "467\tValidation loss: 0.330801\tBest loss: 0.330239\tAccuracy: 92.50%\n",
      "468\tValidation loss: 0.333132\tBest loss: 0.330239\tAccuracy: 92.90%\n",
      "469\tValidation loss: 0.330164\tBest loss: 0.330164\tAccuracy: 92.80%\n",
      "470\tValidation loss: 0.330115\tBest loss: 0.330115\tAccuracy: 92.90%\n",
      "471\tValidation loss: 0.329428\tBest loss: 0.329428\tAccuracy: 92.60%\n",
      "472\tValidation loss: 0.329808\tBest loss: 0.329428\tAccuracy: 92.90%\n",
      "473\tValidation loss: 0.330945\tBest loss: 0.329428\tAccuracy: 92.60%\n",
      "474\tValidation loss: 0.329491\tBest loss: 0.329428\tAccuracy: 92.90%\n",
      "475\tValidation loss: 0.328894\tBest loss: 0.328894\tAccuracy: 92.50%\n",
      "476\tValidation loss: 0.329720\tBest loss: 0.328894\tAccuracy: 92.50%\n",
      "477\tValidation loss: 0.329337\tBest loss: 0.328894\tAccuracy: 92.80%\n",
      "478\tValidation loss: 0.329748\tBest loss: 0.328894\tAccuracy: 92.80%\n",
      "479\tValidation loss: 0.330059\tBest loss: 0.328894\tAccuracy: 92.90%\n",
      "480\tValidation loss: 0.328378\tBest loss: 0.328378\tAccuracy: 92.90%\n",
      "481\tValidation loss: 0.328861\tBest loss: 0.328378\tAccuracy: 92.80%\n",
      "482\tValidation loss: 0.329031\tBest loss: 0.328378\tAccuracy: 92.80%\n",
      "483\tValidation loss: 0.328351\tBest loss: 0.328351\tAccuracy: 93.00%\n",
      "484\tValidation loss: 0.326849\tBest loss: 0.326849\tAccuracy: 92.90%\n",
      "485\tValidation loss: 0.328069\tBest loss: 0.326849\tAccuracy: 92.80%\n",
      "486\tValidation loss: 0.327271\tBest loss: 0.326849\tAccuracy: 92.60%\n",
      "487\tValidation loss: 0.327066\tBest loss: 0.326849\tAccuracy: 93.00%\n",
      "488\tValidation loss: 0.327952\tBest loss: 0.326849\tAccuracy: 92.80%\n",
      "489\tValidation loss: 0.329060\tBest loss: 0.326849\tAccuracy: 92.80%\n",
      "490\tValidation loss: 0.328130\tBest loss: 0.326849\tAccuracy: 92.70%\n",
      "491\tValidation loss: 0.326306\tBest loss: 0.326306\tAccuracy: 92.70%\n",
      "492\tValidation loss: 0.327799\tBest loss: 0.326306\tAccuracy: 92.80%\n",
      "493\tValidation loss: 0.327924\tBest loss: 0.326306\tAccuracy: 92.70%\n",
      "494\tValidation loss: 0.328278\tBest loss: 0.326306\tAccuracy: 92.70%\n",
      "495\tValidation loss: 0.326260\tBest loss: 0.326260\tAccuracy: 92.90%\n",
      "496\tValidation loss: 0.327072\tBest loss: 0.326260\tAccuracy: 92.80%\n",
      "497\tValidation loss: 0.326746\tBest loss: 0.326260\tAccuracy: 92.90%\n",
      "498\tValidation loss: 0.328019\tBest loss: 0.326260\tAccuracy: 92.60%\n",
      "499\tValidation loss: 0.327790\tBest loss: 0.326260\tAccuracy: 92.80%\n",
      "500\tValidation loss: 0.327234\tBest loss: 0.326260\tAccuracy: 92.50%\n",
      "501\tValidation loss: 0.326704\tBest loss: 0.326260\tAccuracy: 92.70%\n",
      "502\tValidation loss: 0.327355\tBest loss: 0.326260\tAccuracy: 92.80%\n",
      "503\tValidation loss: 0.326544\tBest loss: 0.326260\tAccuracy: 92.90%\n",
      "504\tValidation loss: 0.324774\tBest loss: 0.324774\tAccuracy: 93.00%\n",
      "505\tValidation loss: 0.325789\tBest loss: 0.324774\tAccuracy: 92.90%\n",
      "506\tValidation loss: 0.327112\tBest loss: 0.324774\tAccuracy: 92.80%\n",
      "507\tValidation loss: 0.326293\tBest loss: 0.324774\tAccuracy: 92.50%\n",
      "508\tValidation loss: 0.324810\tBest loss: 0.324774\tAccuracy: 92.80%\n",
      "509\tValidation loss: 0.324532\tBest loss: 0.324532\tAccuracy: 92.80%\n",
      "510\tValidation loss: 0.326229\tBest loss: 0.324532\tAccuracy: 92.70%\n",
      "511\tValidation loss: 0.325972\tBest loss: 0.324532\tAccuracy: 92.90%\n",
      "512\tValidation loss: 0.326494\tBest loss: 0.324532\tAccuracy: 92.90%\n",
      "513\tValidation loss: 0.325999\tBest loss: 0.324532\tAccuracy: 92.80%\n",
      "514\tValidation loss: 0.323969\tBest loss: 0.323969\tAccuracy: 92.90%\n",
      "515\tValidation loss: 0.324220\tBest loss: 0.323969\tAccuracy: 92.60%\n",
      "516\tValidation loss: 0.327124\tBest loss: 0.323969\tAccuracy: 92.80%\n",
      "517\tValidation loss: 0.324054\tBest loss: 0.323969\tAccuracy: 92.90%\n",
      "518\tValidation loss: 0.325821\tBest loss: 0.323969\tAccuracy: 93.00%\n",
      "519\tValidation loss: 0.324809\tBest loss: 0.323969\tAccuracy: 92.80%\n",
      "520\tValidation loss: 0.325664\tBest loss: 0.323969\tAccuracy: 92.80%\n",
      "521\tValidation loss: 0.324792\tBest loss: 0.323969\tAccuracy: 93.00%\n",
      "522\tValidation loss: 0.326832\tBest loss: 0.323969\tAccuracy: 92.80%\n",
      "523\tValidation loss: 0.324112\tBest loss: 0.323969\tAccuracy: 92.70%\n",
      "524\tValidation loss: 0.325525\tBest loss: 0.323969\tAccuracy: 92.90%\n",
      "525\tValidation loss: 0.325407\tBest loss: 0.323969\tAccuracy: 92.90%\n",
      "526\tValidation loss: 0.325505\tBest loss: 0.323969\tAccuracy: 92.70%\n",
      "527\tValidation loss: 0.323697\tBest loss: 0.323697\tAccuracy: 93.00%\n",
      "528\tValidation loss: 0.323425\tBest loss: 0.323425\tAccuracy: 93.00%\n",
      "529\tValidation loss: 0.322565\tBest loss: 0.322565\tAccuracy: 93.10%\n",
      "530\tValidation loss: 0.324006\tBest loss: 0.322565\tAccuracy: 92.90%\n",
      "531\tValidation loss: 0.322424\tBest loss: 0.322424\tAccuracy: 92.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\tValidation loss: 0.323478\tBest loss: 0.322424\tAccuracy: 92.90%\n",
      "533\tValidation loss: 0.323457\tBest loss: 0.322424\tAccuracy: 93.00%\n",
      "534\tValidation loss: 0.322897\tBest loss: 0.322424\tAccuracy: 93.00%\n",
      "535\tValidation loss: 0.321676\tBest loss: 0.321676\tAccuracy: 93.00%\n",
      "536\tValidation loss: 0.322413\tBest loss: 0.321676\tAccuracy: 93.00%\n",
      "537\tValidation loss: 0.322237\tBest loss: 0.321676\tAccuracy: 93.10%\n",
      "538\tValidation loss: 0.323300\tBest loss: 0.321676\tAccuracy: 92.90%\n",
      "539\tValidation loss: 0.324949\tBest loss: 0.321676\tAccuracy: 92.70%\n",
      "540\tValidation loss: 0.322629\tBest loss: 0.321676\tAccuracy: 92.90%\n",
      "541\tValidation loss: 0.323055\tBest loss: 0.321676\tAccuracy: 93.00%\n",
      "542\tValidation loss: 0.322626\tBest loss: 0.321676\tAccuracy: 92.80%\n",
      "543\tValidation loss: 0.322793\tBest loss: 0.321676\tAccuracy: 93.00%\n",
      "544\tValidation loss: 0.322566\tBest loss: 0.321676\tAccuracy: 92.90%\n",
      "545\tValidation loss: 0.323274\tBest loss: 0.321676\tAccuracy: 92.80%\n",
      "546\tValidation loss: 0.322553\tBest loss: 0.321676\tAccuracy: 93.00%\n",
      "547\tValidation loss: 0.321068\tBest loss: 0.321068\tAccuracy: 93.10%\n",
      "548\tValidation loss: 0.321647\tBest loss: 0.321068\tAccuracy: 93.00%\n",
      "549\tValidation loss: 0.322884\tBest loss: 0.321068\tAccuracy: 93.00%\n",
      "550\tValidation loss: 0.322857\tBest loss: 0.321068\tAccuracy: 92.90%\n",
      "551\tValidation loss: 0.321341\tBest loss: 0.321068\tAccuracy: 93.10%\n",
      "552\tValidation loss: 0.322736\tBest loss: 0.321068\tAccuracy: 92.80%\n",
      "553\tValidation loss: 0.322413\tBest loss: 0.321068\tAccuracy: 93.00%\n",
      "554\tValidation loss: 0.322385\tBest loss: 0.321068\tAccuracy: 93.00%\n",
      "555\tValidation loss: 0.323462\tBest loss: 0.321068\tAccuracy: 93.30%\n",
      "556\tValidation loss: 0.321047\tBest loss: 0.321047\tAccuracy: 92.80%\n",
      "557\tValidation loss: 0.321906\tBest loss: 0.321047\tAccuracy: 93.20%\n",
      "558\tValidation loss: 0.322642\tBest loss: 0.321047\tAccuracy: 93.00%\n",
      "559\tValidation loss: 0.321862\tBest loss: 0.321047\tAccuracy: 93.00%\n",
      "560\tValidation loss: 0.321602\tBest loss: 0.321047\tAccuracy: 93.10%\n",
      "561\tValidation loss: 0.319796\tBest loss: 0.319796\tAccuracy: 93.10%\n",
      "562\tValidation loss: 0.320727\tBest loss: 0.319796\tAccuracy: 93.00%\n",
      "563\tValidation loss: 0.320527\tBest loss: 0.319796\tAccuracy: 93.50%\n",
      "564\tValidation loss: 0.320830\tBest loss: 0.319796\tAccuracy: 93.10%\n",
      "565\tValidation loss: 0.321804\tBest loss: 0.319796\tAccuracy: 93.00%\n",
      "566\tValidation loss: 0.320440\tBest loss: 0.319796\tAccuracy: 93.10%\n",
      "567\tValidation loss: 0.321253\tBest loss: 0.319796\tAccuracy: 93.20%\n",
      "568\tValidation loss: 0.319696\tBest loss: 0.319696\tAccuracy: 92.90%\n",
      "569\tValidation loss: 0.321747\tBest loss: 0.319696\tAccuracy: 93.00%\n",
      "570\tValidation loss: 0.320151\tBest loss: 0.319696\tAccuracy: 92.90%\n",
      "571\tValidation loss: 0.321270\tBest loss: 0.319696\tAccuracy: 93.10%\n",
      "572\tValidation loss: 0.318957\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "573\tValidation loss: 0.319615\tBest loss: 0.318957\tAccuracy: 92.90%\n",
      "574\tValidation loss: 0.320274\tBest loss: 0.318957\tAccuracy: 93.20%\n",
      "575\tValidation loss: 0.321705\tBest loss: 0.318957\tAccuracy: 93.00%\n",
      "576\tValidation loss: 0.319863\tBest loss: 0.318957\tAccuracy: 93.20%\n",
      "577\tValidation loss: 0.321385\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "578\tValidation loss: 0.319617\tBest loss: 0.318957\tAccuracy: 93.20%\n",
      "579\tValidation loss: 0.319569\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "580\tValidation loss: 0.320673\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "581\tValidation loss: 0.321121\tBest loss: 0.318957\tAccuracy: 93.60%\n",
      "582\tValidation loss: 0.320722\tBest loss: 0.318957\tAccuracy: 93.00%\n",
      "583\tValidation loss: 0.319876\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "584\tValidation loss: 0.320250\tBest loss: 0.318957\tAccuracy: 93.20%\n",
      "585\tValidation loss: 0.320467\tBest loss: 0.318957\tAccuracy: 93.10%\n",
      "586\tValidation loss: 0.320003\tBest loss: 0.318957\tAccuracy: 93.50%\n",
      "587\tValidation loss: 0.319600\tBest loss: 0.318957\tAccuracy: 93.40%\n",
      "588\tValidation loss: 0.318845\tBest loss: 0.318845\tAccuracy: 93.20%\n",
      "589\tValidation loss: 0.319705\tBest loss: 0.318845\tAccuracy: 93.30%\n",
      "590\tValidation loss: 0.320198\tBest loss: 0.318845\tAccuracy: 93.10%\n",
      "591\tValidation loss: 0.318586\tBest loss: 0.318586\tAccuracy: 93.50%\n",
      "592\tValidation loss: 0.320131\tBest loss: 0.318586\tAccuracy: 93.40%\n",
      "593\tValidation loss: 0.318686\tBest loss: 0.318586\tAccuracy: 93.10%\n",
      "594\tValidation loss: 0.316890\tBest loss: 0.316890\tAccuracy: 93.50%\n",
      "595\tValidation loss: 0.319773\tBest loss: 0.316890\tAccuracy: 93.60%\n",
      "596\tValidation loss: 0.319881\tBest loss: 0.316890\tAccuracy: 93.40%\n",
      "597\tValidation loss: 0.319868\tBest loss: 0.316890\tAccuracy: 93.20%\n",
      "598\tValidation loss: 0.318659\tBest loss: 0.316890\tAccuracy: 93.20%\n",
      "599\tValidation loss: 0.318521\tBest loss: 0.316890\tAccuracy: 93.10%\n",
      "600\tValidation loss: 0.319829\tBest loss: 0.316890\tAccuracy: 93.30%\n",
      "601\tValidation loss: 0.316630\tBest loss: 0.316630\tAccuracy: 93.30%\n",
      "602\tValidation loss: 0.319547\tBest loss: 0.316630\tAccuracy: 93.40%\n",
      "603\tValidation loss: 0.318488\tBest loss: 0.316630\tAccuracy: 93.30%\n",
      "604\tValidation loss: 0.318671\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "605\tValidation loss: 0.319668\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "606\tValidation loss: 0.319408\tBest loss: 0.316630\tAccuracy: 93.10%\n",
      "607\tValidation loss: 0.317587\tBest loss: 0.316630\tAccuracy: 93.30%\n",
      "608\tValidation loss: 0.318233\tBest loss: 0.316630\tAccuracy: 93.10%\n",
      "609\tValidation loss: 0.317105\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "610\tValidation loss: 0.317971\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "611\tValidation loss: 0.317093\tBest loss: 0.316630\tAccuracy: 93.50%\n",
      "612\tValidation loss: 0.319076\tBest loss: 0.316630\tAccuracy: 93.40%\n",
      "613\tValidation loss: 0.318506\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "614\tValidation loss: 0.317770\tBest loss: 0.316630\tAccuracy: 93.30%\n",
      "615\tValidation loss: 0.318414\tBest loss: 0.316630\tAccuracy: 93.30%\n",
      "616\tValidation loss: 0.318732\tBest loss: 0.316630\tAccuracy: 93.40%\n",
      "617\tValidation loss: 0.318949\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "618\tValidation loss: 0.318298\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "619\tValidation loss: 0.317802\tBest loss: 0.316630\tAccuracy: 93.20%\n",
      "620\tValidation loss: 0.315937\tBest loss: 0.315937\tAccuracy: 93.20%\n",
      "621\tValidation loss: 0.316945\tBest loss: 0.315937\tAccuracy: 93.10%\n",
      "622\tValidation loss: 0.318146\tBest loss: 0.315937\tAccuracy: 93.40%\n",
      "623\tValidation loss: 0.316970\tBest loss: 0.315937\tAccuracy: 93.50%\n",
      "624\tValidation loss: 0.317438\tBest loss: 0.315937\tAccuracy: 93.50%\n",
      "625\tValidation loss: 0.317280\tBest loss: 0.315937\tAccuracy: 93.30%\n",
      "626\tValidation loss: 0.317127\tBest loss: 0.315937\tAccuracy: 93.10%\n",
      "627\tValidation loss: 0.317471\tBest loss: 0.315937\tAccuracy: 93.30%\n",
      "628\tValidation loss: 0.319380\tBest loss: 0.315937\tAccuracy: 93.20%\n",
      "629\tValidation loss: 0.316899\tBest loss: 0.315937\tAccuracy: 93.50%\n",
      "630\tValidation loss: 0.317597\tBest loss: 0.315937\tAccuracy: 93.50%\n",
      "631\tValidation loss: 0.315768\tBest loss: 0.315768\tAccuracy: 93.40%\n",
      "632\tValidation loss: 0.317066\tBest loss: 0.315768\tAccuracy: 93.30%\n",
      "633\tValidation loss: 0.316824\tBest loss: 0.315768\tAccuracy: 93.20%\n",
      "634\tValidation loss: 0.316463\tBest loss: 0.315768\tAccuracy: 93.50%\n",
      "635\tValidation loss: 0.314960\tBest loss: 0.314960\tAccuracy: 93.50%\n",
      "636\tValidation loss: 0.315587\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "637\tValidation loss: 0.315841\tBest loss: 0.314960\tAccuracy: 93.50%\n",
      "638\tValidation loss: 0.316460\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "639\tValidation loss: 0.317387\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "640\tValidation loss: 0.316103\tBest loss: 0.314960\tAccuracy: 93.50%\n",
      "641\tValidation loss: 0.315922\tBest loss: 0.314960\tAccuracy: 93.20%\n",
      "642\tValidation loss: 0.317035\tBest loss: 0.314960\tAccuracy: 93.50%\n",
      "643\tValidation loss: 0.317335\tBest loss: 0.314960\tAccuracy: 93.50%\n",
      "644\tValidation loss: 0.318146\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "645\tValidation loss: 0.316597\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "646\tValidation loss: 0.315977\tBest loss: 0.314960\tAccuracy: 93.60%\n",
      "647\tValidation loss: 0.317296\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "648\tValidation loss: 0.316844\tBest loss: 0.314960\tAccuracy: 93.10%\n",
      "649\tValidation loss: 0.317316\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "650\tValidation loss: 0.316353\tBest loss: 0.314960\tAccuracy: 93.30%\n",
      "651\tValidation loss: 0.316377\tBest loss: 0.314960\tAccuracy: 93.30%\n",
      "652\tValidation loss: 0.317348\tBest loss: 0.314960\tAccuracy: 93.30%\n",
      "653\tValidation loss: 0.315003\tBest loss: 0.314960\tAccuracy: 93.60%\n",
      "654\tValidation loss: 0.315888\tBest loss: 0.314960\tAccuracy: 93.40%\n",
      "655\tValidation loss: 0.316109\tBest loss: 0.314960\tAccuracy: 93.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\tValidation loss: 0.316103\tBest loss: 0.314960\tAccuracy: 93.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.4min\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.364252\tBest loss: 2.364252\tAccuracy: 39.70%\n",
      "1\tValidation loss: 1.846744\tBest loss: 1.846744\tAccuracy: 56.80%\n",
      "2\tValidation loss: 1.608011\tBest loss: 1.608011\tAccuracy: 64.40%\n",
      "3\tValidation loss: 1.441477\tBest loss: 1.441477\tAccuracy: 65.90%\n",
      "4\tValidation loss: 1.349611\tBest loss: 1.349611\tAccuracy: 68.10%\n",
      "5\tValidation loss: 1.244775\tBest loss: 1.244775\tAccuracy: 70.20%\n",
      "6\tValidation loss: 1.187254\tBest loss: 1.187254\tAccuracy: 71.90%\n",
      "7\tValidation loss: 1.127816\tBest loss: 1.127816\tAccuracy: 73.50%\n",
      "8\tValidation loss: 1.076347\tBest loss: 1.076347\tAccuracy: 74.30%\n",
      "9\tValidation loss: 1.044693\tBest loss: 1.044693\tAccuracy: 75.40%\n",
      "10\tValidation loss: 0.995255\tBest loss: 0.995255\tAccuracy: 77.90%\n",
      "11\tValidation loss: 0.970298\tBest loss: 0.970298\tAccuracy: 77.80%\n",
      "12\tValidation loss: 0.942257\tBest loss: 0.942257\tAccuracy: 77.70%\n",
      "13\tValidation loss: 0.907721\tBest loss: 0.907721\tAccuracy: 79.30%\n",
      "14\tValidation loss: 0.887176\tBest loss: 0.887176\tAccuracy: 79.40%\n",
      "15\tValidation loss: 0.876251\tBest loss: 0.876251\tAccuracy: 79.70%\n",
      "16\tValidation loss: 0.845189\tBest loss: 0.845189\tAccuracy: 80.10%\n",
      "17\tValidation loss: 0.828770\tBest loss: 0.828770\tAccuracy: 80.70%\n",
      "18\tValidation loss: 0.818772\tBest loss: 0.818772\tAccuracy: 80.60%\n",
      "19\tValidation loss: 0.807768\tBest loss: 0.807768\tAccuracy: 81.90%\n",
      "20\tValidation loss: 0.791711\tBest loss: 0.791711\tAccuracy: 81.70%\n",
      "21\tValidation loss: 0.776700\tBest loss: 0.776700\tAccuracy: 82.30%\n",
      "22\tValidation loss: 0.761401\tBest loss: 0.761401\tAccuracy: 82.20%\n",
      "23\tValidation loss: 0.751839\tBest loss: 0.751839\tAccuracy: 83.00%\n",
      "24\tValidation loss: 0.742552\tBest loss: 0.742552\tAccuracy: 82.50%\n",
      "25\tValidation loss: 0.733250\tBest loss: 0.733250\tAccuracy: 83.20%\n",
      "26\tValidation loss: 0.732415\tBest loss: 0.732415\tAccuracy: 83.00%\n",
      "27\tValidation loss: 0.717476\tBest loss: 0.717476\tAccuracy: 84.60%\n",
      "28\tValidation loss: 0.706680\tBest loss: 0.706680\tAccuracy: 84.40%\n",
      "29\tValidation loss: 0.702201\tBest loss: 0.702201\tAccuracy: 83.30%\n",
      "30\tValidation loss: 0.689998\tBest loss: 0.689998\tAccuracy: 83.80%\n",
      "31\tValidation loss: 0.681964\tBest loss: 0.681964\tAccuracy: 84.50%\n",
      "32\tValidation loss: 0.676295\tBest loss: 0.676295\tAccuracy: 84.40%\n",
      "33\tValidation loss: 0.667621\tBest loss: 0.667621\tAccuracy: 84.40%\n",
      "34\tValidation loss: 0.667309\tBest loss: 0.667309\tAccuracy: 84.20%\n",
      "35\tValidation loss: 0.657995\tBest loss: 0.657995\tAccuracy: 84.70%\n",
      "36\tValidation loss: 0.653503\tBest loss: 0.653503\tAccuracy: 84.70%\n",
      "37\tValidation loss: 0.643846\tBest loss: 0.643846\tAccuracy: 85.60%\n",
      "38\tValidation loss: 0.643174\tBest loss: 0.643174\tAccuracy: 85.80%\n",
      "39\tValidation loss: 0.637948\tBest loss: 0.637948\tAccuracy: 86.00%\n",
      "40\tValidation loss: 0.629692\tBest loss: 0.629692\tAccuracy: 86.20%\n",
      "41\tValidation loss: 0.625232\tBest loss: 0.625232\tAccuracy: 85.90%\n",
      "42\tValidation loss: 0.619468\tBest loss: 0.619468\tAccuracy: 85.20%\n",
      "43\tValidation loss: 0.608391\tBest loss: 0.608391\tAccuracy: 86.10%\n",
      "44\tValidation loss: 0.608838\tBest loss: 0.608391\tAccuracy: 86.00%\n",
      "45\tValidation loss: 0.607943\tBest loss: 0.607943\tAccuracy: 85.70%\n",
      "46\tValidation loss: 0.605830\tBest loss: 0.605830\tAccuracy: 86.00%\n",
      "47\tValidation loss: 0.601511\tBest loss: 0.601511\tAccuracy: 85.40%\n",
      "48\tValidation loss: 0.596669\tBest loss: 0.596669\tAccuracy: 86.50%\n",
      "49\tValidation loss: 0.594800\tBest loss: 0.594800\tAccuracy: 86.00%\n",
      "50\tValidation loss: 0.589114\tBest loss: 0.589114\tAccuracy: 86.20%\n",
      "51\tValidation loss: 0.584667\tBest loss: 0.584667\tAccuracy: 86.20%\n",
      "52\tValidation loss: 0.580643\tBest loss: 0.580643\tAccuracy: 87.10%\n",
      "53\tValidation loss: 0.573117\tBest loss: 0.573117\tAccuracy: 86.80%\n",
      "54\tValidation loss: 0.571438\tBest loss: 0.571438\tAccuracy: 86.90%\n",
      "55\tValidation loss: 0.566445\tBest loss: 0.566445\tAccuracy: 87.40%\n",
      "56\tValidation loss: 0.571054\tBest loss: 0.566445\tAccuracy: 85.90%\n",
      "57\tValidation loss: 0.560274\tBest loss: 0.560274\tAccuracy: 86.80%\n",
      "58\tValidation loss: 0.562913\tBest loss: 0.560274\tAccuracy: 86.10%\n",
      "59\tValidation loss: 0.559071\tBest loss: 0.559071\tAccuracy: 86.80%\n",
      "60\tValidation loss: 0.555983\tBest loss: 0.555983\tAccuracy: 87.10%\n",
      "61\tValidation loss: 0.554581\tBest loss: 0.554581\tAccuracy: 87.20%\n",
      "62\tValidation loss: 0.553400\tBest loss: 0.553400\tAccuracy: 86.80%\n",
      "63\tValidation loss: 0.544795\tBest loss: 0.544795\tAccuracy: 87.40%\n",
      "64\tValidation loss: 0.538440\tBest loss: 0.538440\tAccuracy: 87.70%\n",
      "65\tValidation loss: 0.537127\tBest loss: 0.537127\tAccuracy: 88.50%\n",
      "66\tValidation loss: 0.542105\tBest loss: 0.537127\tAccuracy: 86.90%\n",
      "67\tValidation loss: 0.541180\tBest loss: 0.537127\tAccuracy: 87.40%\n",
      "68\tValidation loss: 0.533544\tBest loss: 0.533544\tAccuracy: 87.50%\n",
      "69\tValidation loss: 0.537303\tBest loss: 0.533544\tAccuracy: 87.30%\n",
      "70\tValidation loss: 0.531088\tBest loss: 0.531088\tAccuracy: 87.10%\n",
      "71\tValidation loss: 0.526773\tBest loss: 0.526773\tAccuracy: 87.00%\n",
      "72\tValidation loss: 0.536222\tBest loss: 0.526773\tAccuracy: 86.80%\n",
      "73\tValidation loss: 0.521227\tBest loss: 0.521227\tAccuracy: 87.20%\n",
      "74\tValidation loss: 0.522585\tBest loss: 0.521227\tAccuracy: 87.80%\n",
      "75\tValidation loss: 0.520179\tBest loss: 0.520179\tAccuracy: 87.70%\n",
      "76\tValidation loss: 0.511561\tBest loss: 0.511561\tAccuracy: 88.00%\n",
      "77\tValidation loss: 0.517530\tBest loss: 0.511561\tAccuracy: 87.20%\n",
      "78\tValidation loss: 0.507898\tBest loss: 0.507898\tAccuracy: 88.10%\n",
      "79\tValidation loss: 0.508548\tBest loss: 0.507898\tAccuracy: 87.90%\n",
      "80\tValidation loss: 0.509392\tBest loss: 0.507898\tAccuracy: 87.90%\n",
      "81\tValidation loss: 0.511356\tBest loss: 0.507898\tAccuracy: 88.00%\n",
      "82\tValidation loss: 0.500868\tBest loss: 0.500868\tAccuracy: 88.00%\n",
      "83\tValidation loss: 0.507927\tBest loss: 0.500868\tAccuracy: 87.70%\n",
      "84\tValidation loss: 0.501354\tBest loss: 0.500868\tAccuracy: 88.30%\n",
      "85\tValidation loss: 0.498654\tBest loss: 0.498654\tAccuracy: 88.30%\n",
      "86\tValidation loss: 0.498141\tBest loss: 0.498141\tAccuracy: 88.30%\n",
      "87\tValidation loss: 0.495114\tBest loss: 0.495114\tAccuracy: 88.00%\n",
      "88\tValidation loss: 0.495388\tBest loss: 0.495114\tAccuracy: 88.50%\n",
      "89\tValidation loss: 0.495841\tBest loss: 0.495114\tAccuracy: 88.40%\n",
      "90\tValidation loss: 0.490458\tBest loss: 0.490458\tAccuracy: 88.50%\n",
      "91\tValidation loss: 0.488569\tBest loss: 0.488569\tAccuracy: 88.00%\n",
      "92\tValidation loss: 0.492189\tBest loss: 0.488569\tAccuracy: 88.50%\n",
      "93\tValidation loss: 0.485829\tBest loss: 0.485829\tAccuracy: 88.70%\n",
      "94\tValidation loss: 0.484742\tBest loss: 0.484742\tAccuracy: 88.10%\n",
      "95\tValidation loss: 0.482472\tBest loss: 0.482472\tAccuracy: 88.70%\n",
      "96\tValidation loss: 0.481988\tBest loss: 0.481988\tAccuracy: 88.60%\n",
      "97\tValidation loss: 0.480440\tBest loss: 0.480440\tAccuracy: 88.50%\n",
      "98\tValidation loss: 0.479473\tBest loss: 0.479473\tAccuracy: 88.70%\n",
      "99\tValidation loss: 0.483552\tBest loss: 0.479473\tAccuracy: 88.50%\n",
      "100\tValidation loss: 0.478206\tBest loss: 0.478206\tAccuracy: 88.80%\n",
      "101\tValidation loss: 0.477067\tBest loss: 0.477067\tAccuracy: 89.20%\n",
      "102\tValidation loss: 0.475280\tBest loss: 0.475280\tAccuracy: 88.20%\n",
      "103\tValidation loss: 0.471455\tBest loss: 0.471455\tAccuracy: 88.60%\n",
      "104\tValidation loss: 0.474577\tBest loss: 0.471455\tAccuracy: 88.60%\n",
      "105\tValidation loss: 0.472414\tBest loss: 0.471455\tAccuracy: 88.80%\n",
      "106\tValidation loss: 0.466594\tBest loss: 0.466594\tAccuracy: 89.10%\n",
      "107\tValidation loss: 0.470060\tBest loss: 0.466594\tAccuracy: 88.90%\n",
      "108\tValidation loss: 0.474943\tBest loss: 0.466594\tAccuracy: 88.60%\n",
      "109\tValidation loss: 0.469253\tBest loss: 0.466594\tAccuracy: 88.20%\n",
      "110\tValidation loss: 0.470292\tBest loss: 0.466594\tAccuracy: 88.90%\n",
      "111\tValidation loss: 0.463829\tBest loss: 0.463829\tAccuracy: 88.20%\n",
      "112\tValidation loss: 0.466060\tBest loss: 0.463829\tAccuracy: 88.60%\n",
      "113\tValidation loss: 0.461190\tBest loss: 0.461190\tAccuracy: 88.70%\n",
      "114\tValidation loss: 0.460199\tBest loss: 0.460199\tAccuracy: 89.20%\n",
      "115\tValidation loss: 0.465548\tBest loss: 0.460199\tAccuracy: 88.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\tValidation loss: 0.462706\tBest loss: 0.460199\tAccuracy: 89.50%\n",
      "117\tValidation loss: 0.458231\tBest loss: 0.458231\tAccuracy: 89.10%\n",
      "118\tValidation loss: 0.458673\tBest loss: 0.458231\tAccuracy: 89.30%\n",
      "119\tValidation loss: 0.458443\tBest loss: 0.458231\tAccuracy: 89.30%\n",
      "120\tValidation loss: 0.456247\tBest loss: 0.456247\tAccuracy: 88.90%\n",
      "121\tValidation loss: 0.458687\tBest loss: 0.456247\tAccuracy: 89.10%\n",
      "122\tValidation loss: 0.452425\tBest loss: 0.452425\tAccuracy: 88.80%\n",
      "123\tValidation loss: 0.450894\tBest loss: 0.450894\tAccuracy: 89.60%\n",
      "124\tValidation loss: 0.452929\tBest loss: 0.450894\tAccuracy: 89.50%\n",
      "125\tValidation loss: 0.450227\tBest loss: 0.450227\tAccuracy: 89.20%\n",
      "126\tValidation loss: 0.451892\tBest loss: 0.450227\tAccuracy: 89.50%\n",
      "127\tValidation loss: 0.451390\tBest loss: 0.450227\tAccuracy: 89.60%\n",
      "128\tValidation loss: 0.448721\tBest loss: 0.448721\tAccuracy: 89.80%\n",
      "129\tValidation loss: 0.445975\tBest loss: 0.445975\tAccuracy: 89.40%\n",
      "130\tValidation loss: 0.443391\tBest loss: 0.443391\tAccuracy: 89.30%\n",
      "131\tValidation loss: 0.443473\tBest loss: 0.443391\tAccuracy: 89.50%\n",
      "132\tValidation loss: 0.443562\tBest loss: 0.443391\tAccuracy: 89.60%\n",
      "133\tValidation loss: 0.448199\tBest loss: 0.443391\tAccuracy: 89.50%\n",
      "134\tValidation loss: 0.445184\tBest loss: 0.443391\tAccuracy: 89.20%\n",
      "135\tValidation loss: 0.445903\tBest loss: 0.443391\tAccuracy: 89.80%\n",
      "136\tValidation loss: 0.442821\tBest loss: 0.442821\tAccuracy: 89.40%\n",
      "137\tValidation loss: 0.444042\tBest loss: 0.442821\tAccuracy: 89.80%\n",
      "138\tValidation loss: 0.439241\tBest loss: 0.439241\tAccuracy: 89.50%\n",
      "139\tValidation loss: 0.440222\tBest loss: 0.439241\tAccuracy: 89.60%\n",
      "140\tValidation loss: 0.442731\tBest loss: 0.439241\tAccuracy: 89.20%\n",
      "141\tValidation loss: 0.441728\tBest loss: 0.439241\tAccuracy: 89.40%\n",
      "142\tValidation loss: 0.438301\tBest loss: 0.438301\tAccuracy: 89.70%\n",
      "143\tValidation loss: 0.437494\tBest loss: 0.437494\tAccuracy: 89.80%\n",
      "144\tValidation loss: 0.435164\tBest loss: 0.435164\tAccuracy: 89.60%\n",
      "145\tValidation loss: 0.436508\tBest loss: 0.435164\tAccuracy: 89.80%\n",
      "146\tValidation loss: 0.434447\tBest loss: 0.434447\tAccuracy: 89.90%\n",
      "147\tValidation loss: 0.432437\tBest loss: 0.432437\tAccuracy: 89.70%\n",
      "148\tValidation loss: 0.434075\tBest loss: 0.432437\tAccuracy: 89.80%\n",
      "149\tValidation loss: 0.433771\tBest loss: 0.432437\tAccuracy: 90.00%\n",
      "150\tValidation loss: 0.431936\tBest loss: 0.431936\tAccuracy: 90.00%\n",
      "151\tValidation loss: 0.433213\tBest loss: 0.431936\tAccuracy: 90.10%\n",
      "152\tValidation loss: 0.429314\tBest loss: 0.429314\tAccuracy: 90.40%\n",
      "153\tValidation loss: 0.434176\tBest loss: 0.429314\tAccuracy: 89.70%\n",
      "154\tValidation loss: 0.431596\tBest loss: 0.429314\tAccuracy: 90.10%\n",
      "155\tValidation loss: 0.431724\tBest loss: 0.429314\tAccuracy: 89.80%\n",
      "156\tValidation loss: 0.428835\tBest loss: 0.428835\tAccuracy: 89.80%\n",
      "157\tValidation loss: 0.426060\tBest loss: 0.426060\tAccuracy: 90.00%\n",
      "158\tValidation loss: 0.426337\tBest loss: 0.426060\tAccuracy: 90.00%\n",
      "159\tValidation loss: 0.426635\tBest loss: 0.426060\tAccuracy: 90.00%\n",
      "160\tValidation loss: 0.426802\tBest loss: 0.426060\tAccuracy: 90.10%\n",
      "161\tValidation loss: 0.431750\tBest loss: 0.426060\tAccuracy: 89.70%\n",
      "162\tValidation loss: 0.427696\tBest loss: 0.426060\tAccuracy: 90.00%\n",
      "163\tValidation loss: 0.430519\tBest loss: 0.426060\tAccuracy: 89.90%\n",
      "164\tValidation loss: 0.422983\tBest loss: 0.422983\tAccuracy: 90.20%\n",
      "165\tValidation loss: 0.425320\tBest loss: 0.422983\tAccuracy: 89.80%\n",
      "166\tValidation loss: 0.421242\tBest loss: 0.421242\tAccuracy: 90.00%\n",
      "167\tValidation loss: 0.423398\tBest loss: 0.421242\tAccuracy: 90.30%\n",
      "168\tValidation loss: 0.418824\tBest loss: 0.418824\tAccuracy: 90.20%\n",
      "169\tValidation loss: 0.422221\tBest loss: 0.418824\tAccuracy: 90.00%\n",
      "170\tValidation loss: 0.418587\tBest loss: 0.418587\tAccuracy: 90.00%\n",
      "171\tValidation loss: 0.420351\tBest loss: 0.418587\tAccuracy: 90.40%\n",
      "172\tValidation loss: 0.419699\tBest loss: 0.418587\tAccuracy: 90.20%\n",
      "173\tValidation loss: 0.423334\tBest loss: 0.418587\tAccuracy: 90.10%\n",
      "174\tValidation loss: 0.416023\tBest loss: 0.416023\tAccuracy: 90.40%\n",
      "175\tValidation loss: 0.418748\tBest loss: 0.416023\tAccuracy: 90.20%\n",
      "176\tValidation loss: 0.418095\tBest loss: 0.416023\tAccuracy: 90.30%\n",
      "177\tValidation loss: 0.420012\tBest loss: 0.416023\tAccuracy: 90.20%\n",
      "178\tValidation loss: 0.420349\tBest loss: 0.416023\tAccuracy: 90.00%\n",
      "179\tValidation loss: 0.420197\tBest loss: 0.416023\tAccuracy: 90.10%\n",
      "180\tValidation loss: 0.417323\tBest loss: 0.416023\tAccuracy: 90.00%\n",
      "181\tValidation loss: 0.414425\tBest loss: 0.414425\tAccuracy: 90.50%\n",
      "182\tValidation loss: 0.411658\tBest loss: 0.411658\tAccuracy: 90.60%\n",
      "183\tValidation loss: 0.415907\tBest loss: 0.411658\tAccuracy: 90.00%\n",
      "184\tValidation loss: 0.415826\tBest loss: 0.411658\tAccuracy: 90.30%\n",
      "185\tValidation loss: 0.412367\tBest loss: 0.411658\tAccuracy: 90.80%\n",
      "186\tValidation loss: 0.414720\tBest loss: 0.411658\tAccuracy: 90.20%\n",
      "187\tValidation loss: 0.413042\tBest loss: 0.411658\tAccuracy: 90.30%\n",
      "188\tValidation loss: 0.411767\tBest loss: 0.411658\tAccuracy: 90.10%\n",
      "189\tValidation loss: 0.412165\tBest loss: 0.411658\tAccuracy: 90.30%\n",
      "190\tValidation loss: 0.409801\tBest loss: 0.409801\tAccuracy: 90.40%\n",
      "191\tValidation loss: 0.411048\tBest loss: 0.409801\tAccuracy: 90.40%\n",
      "192\tValidation loss: 0.412943\tBest loss: 0.409801\tAccuracy: 90.20%\n",
      "193\tValidation loss: 0.407821\tBest loss: 0.407821\tAccuracy: 90.40%\n",
      "194\tValidation loss: 0.407872\tBest loss: 0.407821\tAccuracy: 90.70%\n",
      "195\tValidation loss: 0.408940\tBest loss: 0.407821\tAccuracy: 90.60%\n",
      "196\tValidation loss: 0.406596\tBest loss: 0.406596\tAccuracy: 90.40%\n",
      "197\tValidation loss: 0.412320\tBest loss: 0.406596\tAccuracy: 90.50%\n",
      "198\tValidation loss: 0.407178\tBest loss: 0.406596\tAccuracy: 90.60%\n",
      "199\tValidation loss: 0.408728\tBest loss: 0.406596\tAccuracy: 90.40%\n",
      "200\tValidation loss: 0.405259\tBest loss: 0.405259\tAccuracy: 90.70%\n",
      "201\tValidation loss: 0.409617\tBest loss: 0.405259\tAccuracy: 90.50%\n",
      "202\tValidation loss: 0.403064\tBest loss: 0.403064\tAccuracy: 91.00%\n",
      "203\tValidation loss: 0.407902\tBest loss: 0.403064\tAccuracy: 90.30%\n",
      "204\tValidation loss: 0.404076\tBest loss: 0.403064\tAccuracy: 90.60%\n",
      "205\tValidation loss: 0.404666\tBest loss: 0.403064\tAccuracy: 90.70%\n",
      "206\tValidation loss: 0.408740\tBest loss: 0.403064\tAccuracy: 90.60%\n",
      "207\tValidation loss: 0.402348\tBest loss: 0.402348\tAccuracy: 90.30%\n",
      "208\tValidation loss: 0.404061\tBest loss: 0.402348\tAccuracy: 90.50%\n",
      "209\tValidation loss: 0.403562\tBest loss: 0.402348\tAccuracy: 91.00%\n",
      "210\tValidation loss: 0.404196\tBest loss: 0.402348\tAccuracy: 90.60%\n",
      "211\tValidation loss: 0.403898\tBest loss: 0.402348\tAccuracy: 90.90%\n",
      "212\tValidation loss: 0.401862\tBest loss: 0.401862\tAccuracy: 90.90%\n",
      "213\tValidation loss: 0.403806\tBest loss: 0.401862\tAccuracy: 90.70%\n",
      "214\tValidation loss: 0.402538\tBest loss: 0.401862\tAccuracy: 90.80%\n",
      "215\tValidation loss: 0.404507\tBest loss: 0.401862\tAccuracy: 90.40%\n",
      "216\tValidation loss: 0.402218\tBest loss: 0.401862\tAccuracy: 90.90%\n",
      "217\tValidation loss: 0.401453\tBest loss: 0.401453\tAccuracy: 90.60%\n",
      "218\tValidation loss: 0.403810\tBest loss: 0.401453\tAccuracy: 90.80%\n",
      "219\tValidation loss: 0.401616\tBest loss: 0.401453\tAccuracy: 90.80%\n",
      "220\tValidation loss: 0.398587\tBest loss: 0.398587\tAccuracy: 90.90%\n",
      "221\tValidation loss: 0.401559\tBest loss: 0.398587\tAccuracy: 90.50%\n",
      "222\tValidation loss: 0.403229\tBest loss: 0.398587\tAccuracy: 90.70%\n",
      "223\tValidation loss: 0.399741\tBest loss: 0.398587\tAccuracy: 91.10%\n",
      "224\tValidation loss: 0.397142\tBest loss: 0.397142\tAccuracy: 91.00%\n",
      "225\tValidation loss: 0.401740\tBest loss: 0.397142\tAccuracy: 90.80%\n",
      "226\tValidation loss: 0.396562\tBest loss: 0.396562\tAccuracy: 90.90%\n",
      "227\tValidation loss: 0.396462\tBest loss: 0.396462\tAccuracy: 90.80%\n",
      "228\tValidation loss: 0.398098\tBest loss: 0.396462\tAccuracy: 90.90%\n",
      "229\tValidation loss: 0.398752\tBest loss: 0.396462\tAccuracy: 90.40%\n",
      "230\tValidation loss: 0.394436\tBest loss: 0.394436\tAccuracy: 90.90%\n",
      "231\tValidation loss: 0.396890\tBest loss: 0.394436\tAccuracy: 91.00%\n",
      "232\tValidation loss: 0.396688\tBest loss: 0.394436\tAccuracy: 91.00%\n",
      "233\tValidation loss: 0.396747\tBest loss: 0.394436\tAccuracy: 91.00%\n",
      "234\tValidation loss: 0.394722\tBest loss: 0.394436\tAccuracy: 91.00%\n",
      "235\tValidation loss: 0.398714\tBest loss: 0.394436\tAccuracy: 91.10%\n",
      "236\tValidation loss: 0.393464\tBest loss: 0.393464\tAccuracy: 91.20%\n",
      "237\tValidation loss: 0.396267\tBest loss: 0.393464\tAccuracy: 91.10%\n",
      "238\tValidation loss: 0.397330\tBest loss: 0.393464\tAccuracy: 91.20%\n",
      "239\tValidation loss: 0.398387\tBest loss: 0.393464\tAccuracy: 91.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\tValidation loss: 0.394834\tBest loss: 0.393464\tAccuracy: 91.30%\n",
      "241\tValidation loss: 0.397633\tBest loss: 0.393464\tAccuracy: 91.00%\n",
      "242\tValidation loss: 0.400029\tBest loss: 0.393464\tAccuracy: 91.30%\n",
      "243\tValidation loss: 0.391805\tBest loss: 0.391805\tAccuracy: 91.20%\n",
      "244\tValidation loss: 0.394225\tBest loss: 0.391805\tAccuracy: 91.30%\n",
      "245\tValidation loss: 0.391139\tBest loss: 0.391139\tAccuracy: 91.30%\n",
      "246\tValidation loss: 0.394344\tBest loss: 0.391139\tAccuracy: 91.00%\n",
      "247\tValidation loss: 0.392104\tBest loss: 0.391139\tAccuracy: 91.30%\n",
      "248\tValidation loss: 0.393436\tBest loss: 0.391139\tAccuracy: 91.30%\n",
      "249\tValidation loss: 0.391531\tBest loss: 0.391139\tAccuracy: 91.40%\n",
      "250\tValidation loss: 0.393011\tBest loss: 0.391139\tAccuracy: 91.10%\n",
      "251\tValidation loss: 0.390388\tBest loss: 0.390388\tAccuracy: 91.20%\n",
      "252\tValidation loss: 0.392784\tBest loss: 0.390388\tAccuracy: 91.50%\n",
      "253\tValidation loss: 0.389905\tBest loss: 0.389905\tAccuracy: 91.30%\n",
      "254\tValidation loss: 0.392355\tBest loss: 0.389905\tAccuracy: 91.20%\n",
      "255\tValidation loss: 0.393830\tBest loss: 0.389905\tAccuracy: 91.30%\n",
      "256\tValidation loss: 0.390323\tBest loss: 0.389905\tAccuracy: 91.30%\n",
      "257\tValidation loss: 0.392809\tBest loss: 0.389905\tAccuracy: 91.50%\n",
      "258\tValidation loss: 0.389346\tBest loss: 0.389346\tAccuracy: 91.30%\n",
      "259\tValidation loss: 0.387982\tBest loss: 0.387982\tAccuracy: 91.70%\n",
      "260\tValidation loss: 0.392044\tBest loss: 0.387982\tAccuracy: 91.10%\n",
      "261\tValidation loss: 0.389471\tBest loss: 0.387982\tAccuracy: 91.40%\n",
      "262\tValidation loss: 0.389117\tBest loss: 0.387982\tAccuracy: 91.60%\n",
      "263\tValidation loss: 0.388658\tBest loss: 0.387982\tAccuracy: 91.50%\n",
      "264\tValidation loss: 0.392342\tBest loss: 0.387982\tAccuracy: 91.50%\n",
      "265\tValidation loss: 0.386616\tBest loss: 0.386616\tAccuracy: 91.50%\n",
      "266\tValidation loss: 0.389111\tBest loss: 0.386616\tAccuracy: 91.60%\n",
      "267\tValidation loss: 0.390943\tBest loss: 0.386616\tAccuracy: 91.60%\n",
      "268\tValidation loss: 0.386862\tBest loss: 0.386616\tAccuracy: 91.70%\n",
      "269\tValidation loss: 0.389375\tBest loss: 0.386616\tAccuracy: 91.60%\n",
      "270\tValidation loss: 0.384733\tBest loss: 0.384733\tAccuracy: 91.50%\n",
      "271\tValidation loss: 0.384715\tBest loss: 0.384715\tAccuracy: 91.90%\n",
      "272\tValidation loss: 0.386204\tBest loss: 0.384715\tAccuracy: 91.80%\n",
      "273\tValidation loss: 0.386021\tBest loss: 0.384715\tAccuracy: 91.70%\n",
      "274\tValidation loss: 0.387107\tBest loss: 0.384715\tAccuracy: 91.70%\n",
      "275\tValidation loss: 0.382956\tBest loss: 0.382956\tAccuracy: 91.80%\n",
      "276\tValidation loss: 0.387571\tBest loss: 0.382956\tAccuracy: 91.30%\n",
      "277\tValidation loss: 0.388128\tBest loss: 0.382956\tAccuracy: 91.70%\n",
      "278\tValidation loss: 0.384492\tBest loss: 0.382956\tAccuracy: 91.70%\n",
      "279\tValidation loss: 0.386382\tBest loss: 0.382956\tAccuracy: 91.70%\n",
      "280\tValidation loss: 0.381792\tBest loss: 0.381792\tAccuracy: 91.70%\n",
      "281\tValidation loss: 0.384973\tBest loss: 0.381792\tAccuracy: 91.60%\n",
      "282\tValidation loss: 0.385461\tBest loss: 0.381792\tAccuracy: 91.60%\n",
      "283\tValidation loss: 0.386896\tBest loss: 0.381792\tAccuracy: 91.40%\n",
      "284\tValidation loss: 0.383354\tBest loss: 0.381792\tAccuracy: 91.70%\n",
      "285\tValidation loss: 0.383699\tBest loss: 0.381792\tAccuracy: 91.80%\n",
      "286\tValidation loss: 0.383012\tBest loss: 0.381792\tAccuracy: 91.90%\n",
      "287\tValidation loss: 0.384883\tBest loss: 0.381792\tAccuracy: 91.80%\n",
      "288\tValidation loss: 0.382295\tBest loss: 0.381792\tAccuracy: 91.70%\n",
      "289\tValidation loss: 0.381016\tBest loss: 0.381016\tAccuracy: 91.80%\n",
      "290\tValidation loss: 0.381098\tBest loss: 0.381016\tAccuracy: 91.70%\n",
      "291\tValidation loss: 0.382010\tBest loss: 0.381016\tAccuracy: 91.70%\n",
      "292\tValidation loss: 0.385951\tBest loss: 0.381016\tAccuracy: 91.80%\n",
      "293\tValidation loss: 0.380999\tBest loss: 0.380999\tAccuracy: 91.80%\n",
      "294\tValidation loss: 0.379033\tBest loss: 0.379033\tAccuracy: 91.90%\n",
      "295\tValidation loss: 0.381980\tBest loss: 0.379033\tAccuracy: 91.70%\n",
      "296\tValidation loss: 0.382905\tBest loss: 0.379033\tAccuracy: 91.60%\n",
      "297\tValidation loss: 0.379497\tBest loss: 0.379033\tAccuracy: 91.80%\n",
      "298\tValidation loss: 0.383252\tBest loss: 0.379033\tAccuracy: 91.70%\n",
      "299\tValidation loss: 0.380364\tBest loss: 0.379033\tAccuracy: 91.80%\n",
      "300\tValidation loss: 0.382982\tBest loss: 0.379033\tAccuracy: 91.70%\n",
      "301\tValidation loss: 0.381177\tBest loss: 0.379033\tAccuracy: 91.70%\n",
      "302\tValidation loss: 0.378824\tBest loss: 0.378824\tAccuracy: 91.80%\n",
      "303\tValidation loss: 0.380595\tBest loss: 0.378824\tAccuracy: 91.60%\n",
      "304\tValidation loss: 0.378078\tBest loss: 0.378078\tAccuracy: 91.70%\n",
      "305\tValidation loss: 0.377915\tBest loss: 0.377915\tAccuracy: 91.60%\n",
      "306\tValidation loss: 0.381077\tBest loss: 0.377915\tAccuracy: 91.80%\n",
      "307\tValidation loss: 0.381654\tBest loss: 0.377915\tAccuracy: 91.60%\n",
      "308\tValidation loss: 0.379892\tBest loss: 0.377915\tAccuracy: 91.80%\n",
      "309\tValidation loss: 0.381989\tBest loss: 0.377915\tAccuracy: 91.90%\n",
      "310\tValidation loss: 0.379153\tBest loss: 0.377915\tAccuracy: 91.80%\n",
      "311\tValidation loss: 0.379630\tBest loss: 0.377915\tAccuracy: 91.90%\n",
      "312\tValidation loss: 0.382020\tBest loss: 0.377915\tAccuracy: 91.60%\n",
      "313\tValidation loss: 0.381110\tBest loss: 0.377915\tAccuracy: 91.90%\n",
      "314\tValidation loss: 0.381168\tBest loss: 0.377915\tAccuracy: 91.60%\n",
      "315\tValidation loss: 0.377849\tBest loss: 0.377849\tAccuracy: 91.80%\n",
      "316\tValidation loss: 0.381056\tBest loss: 0.377849\tAccuracy: 91.60%\n",
      "317\tValidation loss: 0.378616\tBest loss: 0.377849\tAccuracy: 91.80%\n",
      "318\tValidation loss: 0.378226\tBest loss: 0.377849\tAccuracy: 92.10%\n",
      "319\tValidation loss: 0.379269\tBest loss: 0.377849\tAccuracy: 92.00%\n",
      "320\tValidation loss: 0.378282\tBest loss: 0.377849\tAccuracy: 91.70%\n",
      "321\tValidation loss: 0.378911\tBest loss: 0.377849\tAccuracy: 91.60%\n",
      "322\tValidation loss: 0.379676\tBest loss: 0.377849\tAccuracy: 91.70%\n",
      "323\tValidation loss: 0.378488\tBest loss: 0.377849\tAccuracy: 91.70%\n",
      "324\tValidation loss: 0.379126\tBest loss: 0.377849\tAccuracy: 92.00%\n",
      "325\tValidation loss: 0.379674\tBest loss: 0.377849\tAccuracy: 92.00%\n",
      "326\tValidation loss: 0.378086\tBest loss: 0.377849\tAccuracy: 91.70%\n",
      "327\tValidation loss: 0.377006\tBest loss: 0.377006\tAccuracy: 91.90%\n",
      "328\tValidation loss: 0.378733\tBest loss: 0.377006\tAccuracy: 92.00%\n",
      "329\tValidation loss: 0.377120\tBest loss: 0.377006\tAccuracy: 91.90%\n",
      "330\tValidation loss: 0.379001\tBest loss: 0.377006\tAccuracy: 92.00%\n",
      "331\tValidation loss: 0.376613\tBest loss: 0.376613\tAccuracy: 91.70%\n",
      "332\tValidation loss: 0.378033\tBest loss: 0.376613\tAccuracy: 91.80%\n",
      "333\tValidation loss: 0.374338\tBest loss: 0.374338\tAccuracy: 91.70%\n",
      "334\tValidation loss: 0.375686\tBest loss: 0.374338\tAccuracy: 91.90%\n",
      "335\tValidation loss: 0.376767\tBest loss: 0.374338\tAccuracy: 91.90%\n",
      "336\tValidation loss: 0.376248\tBest loss: 0.374338\tAccuracy: 91.80%\n",
      "337\tValidation loss: 0.377887\tBest loss: 0.374338\tAccuracy: 91.80%\n",
      "338\tValidation loss: 0.376434\tBest loss: 0.374338\tAccuracy: 91.80%\n",
      "339\tValidation loss: 0.373838\tBest loss: 0.373838\tAccuracy: 92.00%\n",
      "340\tValidation loss: 0.375756\tBest loss: 0.373838\tAccuracy: 91.90%\n",
      "341\tValidation loss: 0.376289\tBest loss: 0.373838\tAccuracy: 91.90%\n",
      "342\tValidation loss: 0.375153\tBest loss: 0.373838\tAccuracy: 91.70%\n",
      "343\tValidation loss: 0.378797\tBest loss: 0.373838\tAccuracy: 92.00%\n",
      "344\tValidation loss: 0.374182\tBest loss: 0.373838\tAccuracy: 91.80%\n",
      "345\tValidation loss: 0.373772\tBest loss: 0.373772\tAccuracy: 91.80%\n",
      "346\tValidation loss: 0.372433\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "347\tValidation loss: 0.375990\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "348\tValidation loss: 0.374493\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "349\tValidation loss: 0.375592\tBest loss: 0.372433\tAccuracy: 92.10%\n",
      "350\tValidation loss: 0.373840\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "351\tValidation loss: 0.379613\tBest loss: 0.372433\tAccuracy: 91.90%\n",
      "352\tValidation loss: 0.373191\tBest loss: 0.372433\tAccuracy: 91.80%\n",
      "353\tValidation loss: 0.374687\tBest loss: 0.372433\tAccuracy: 92.10%\n",
      "354\tValidation loss: 0.376989\tBest loss: 0.372433\tAccuracy: 91.90%\n",
      "355\tValidation loss: 0.376191\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "356\tValidation loss: 0.374520\tBest loss: 0.372433\tAccuracy: 91.80%\n",
      "357\tValidation loss: 0.373588\tBest loss: 0.372433\tAccuracy: 92.00%\n",
      "358\tValidation loss: 0.376819\tBest loss: 0.372433\tAccuracy: 92.10%\n",
      "359\tValidation loss: 0.371658\tBest loss: 0.371658\tAccuracy: 91.90%\n",
      "360\tValidation loss: 0.371600\tBest loss: 0.371600\tAccuracy: 92.00%\n",
      "361\tValidation loss: 0.373962\tBest loss: 0.371600\tAccuracy: 92.10%\n",
      "362\tValidation loss: 0.374384\tBest loss: 0.371600\tAccuracy: 92.10%\n",
      "363\tValidation loss: 0.374607\tBest loss: 0.371600\tAccuracy: 92.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\tValidation loss: 0.374438\tBest loss: 0.371600\tAccuracy: 92.10%\n",
      "365\tValidation loss: 0.375628\tBest loss: 0.371600\tAccuracy: 92.00%\n",
      "366\tValidation loss: 0.372976\tBest loss: 0.371600\tAccuracy: 91.90%\n",
      "367\tValidation loss: 0.374673\tBest loss: 0.371600\tAccuracy: 91.80%\n",
      "368\tValidation loss: 0.371639\tBest loss: 0.371600\tAccuracy: 92.00%\n",
      "369\tValidation loss: 0.376862\tBest loss: 0.371600\tAccuracy: 92.20%\n",
      "370\tValidation loss: 0.372450\tBest loss: 0.371600\tAccuracy: 92.20%\n",
      "371\tValidation loss: 0.372108\tBest loss: 0.371600\tAccuracy: 92.30%\n",
      "372\tValidation loss: 0.374319\tBest loss: 0.371600\tAccuracy: 92.10%\n",
      "373\tValidation loss: 0.373731\tBest loss: 0.371600\tAccuracy: 92.20%\n",
      "374\tValidation loss: 0.369212\tBest loss: 0.369212\tAccuracy: 92.00%\n",
      "375\tValidation loss: 0.372476\tBest loss: 0.369212\tAccuracy: 92.30%\n",
      "376\tValidation loss: 0.372815\tBest loss: 0.369212\tAccuracy: 92.10%\n",
      "377\tValidation loss: 0.375153\tBest loss: 0.369212\tAccuracy: 92.20%\n",
      "378\tValidation loss: 0.370517\tBest loss: 0.369212\tAccuracy: 92.30%\n",
      "379\tValidation loss: 0.373420\tBest loss: 0.369212\tAccuracy: 92.20%\n",
      "380\tValidation loss: 0.370054\tBest loss: 0.369212\tAccuracy: 92.20%\n",
      "381\tValidation loss: 0.374131\tBest loss: 0.369212\tAccuracy: 91.90%\n",
      "382\tValidation loss: 0.373610\tBest loss: 0.369212\tAccuracy: 92.20%\n",
      "383\tValidation loss: 0.372492\tBest loss: 0.369212\tAccuracy: 92.30%\n",
      "384\tValidation loss: 0.373357\tBest loss: 0.369212\tAccuracy: 92.00%\n",
      "385\tValidation loss: 0.373332\tBest loss: 0.369212\tAccuracy: 92.30%\n",
      "386\tValidation loss: 0.370221\tBest loss: 0.369212\tAccuracy: 91.90%\n",
      "387\tValidation loss: 0.370916\tBest loss: 0.369212\tAccuracy: 92.10%\n",
      "388\tValidation loss: 0.370165\tBest loss: 0.369212\tAccuracy: 92.00%\n",
      "389\tValidation loss: 0.372145\tBest loss: 0.369212\tAccuracy: 91.90%\n",
      "390\tValidation loss: 0.369623\tBest loss: 0.369212\tAccuracy: 92.00%\n",
      "391\tValidation loss: 0.370453\tBest loss: 0.369212\tAccuracy: 92.30%\n",
      "392\tValidation loss: 0.371294\tBest loss: 0.369212\tAccuracy: 92.50%\n",
      "393\tValidation loss: 0.371942\tBest loss: 0.369212\tAccuracy: 92.20%\n",
      "394\tValidation loss: 0.368620\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "395\tValidation loss: 0.371047\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "396\tValidation loss: 0.371260\tBest loss: 0.368620\tAccuracy: 92.10%\n",
      "397\tValidation loss: 0.371481\tBest loss: 0.368620\tAccuracy: 92.40%\n",
      "398\tValidation loss: 0.371690\tBest loss: 0.368620\tAccuracy: 92.20%\n",
      "399\tValidation loss: 0.374929\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "400\tValidation loss: 0.371730\tBest loss: 0.368620\tAccuracy: 92.80%\n",
      "401\tValidation loss: 0.371749\tBest loss: 0.368620\tAccuracy: 92.40%\n",
      "402\tValidation loss: 0.369709\tBest loss: 0.368620\tAccuracy: 92.40%\n",
      "403\tValidation loss: 0.368678\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "404\tValidation loss: 0.370627\tBest loss: 0.368620\tAccuracy: 92.10%\n",
      "405\tValidation loss: 0.371880\tBest loss: 0.368620\tAccuracy: 92.60%\n",
      "406\tValidation loss: 0.370906\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "407\tValidation loss: 0.372876\tBest loss: 0.368620\tAccuracy: 92.40%\n",
      "408\tValidation loss: 0.370666\tBest loss: 0.368620\tAccuracy: 92.30%\n",
      "409\tValidation loss: 0.367430\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "410\tValidation loss: 0.370274\tBest loss: 0.367430\tAccuracy: 92.40%\n",
      "411\tValidation loss: 0.369332\tBest loss: 0.367430\tAccuracy: 92.40%\n",
      "412\tValidation loss: 0.371995\tBest loss: 0.367430\tAccuracy: 92.40%\n",
      "413\tValidation loss: 0.371398\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "414\tValidation loss: 0.371187\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "415\tValidation loss: 0.369848\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "416\tValidation loss: 0.368703\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "417\tValidation loss: 0.370840\tBest loss: 0.367430\tAccuracy: 92.70%\n",
      "418\tValidation loss: 0.370200\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "419\tValidation loss: 0.368214\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "420\tValidation loss: 0.373166\tBest loss: 0.367430\tAccuracy: 92.20%\n",
      "421\tValidation loss: 0.370111\tBest loss: 0.367430\tAccuracy: 92.60%\n",
      "422\tValidation loss: 0.368179\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "423\tValidation loss: 0.369986\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "424\tValidation loss: 0.369366\tBest loss: 0.367430\tAccuracy: 92.30%\n",
      "425\tValidation loss: 0.372199\tBest loss: 0.367430\tAccuracy: 92.40%\n",
      "426\tValidation loss: 0.368687\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "427\tValidation loss: 0.370802\tBest loss: 0.367430\tAccuracy: 92.40%\n",
      "428\tValidation loss: 0.369074\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "429\tValidation loss: 0.369507\tBest loss: 0.367430\tAccuracy: 92.60%\n",
      "430\tValidation loss: 0.368603\tBest loss: 0.367430\tAccuracy: 92.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  57.0s\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.343303\tBest loss: 2.343303\tAccuracy: 41.60%\n",
      "1\tValidation loss: 1.846035\tBest loss: 1.846035\tAccuracy: 56.50%\n",
      "2\tValidation loss: 1.607660\tBest loss: 1.607660\tAccuracy: 60.80%\n",
      "3\tValidation loss: 1.469301\tBest loss: 1.469301\tAccuracy: 64.60%\n",
      "4\tValidation loss: 1.331237\tBest loss: 1.331237\tAccuracy: 69.30%\n",
      "5\tValidation loss: 1.246432\tBest loss: 1.246432\tAccuracy: 70.70%\n",
      "6\tValidation loss: 1.175807\tBest loss: 1.175807\tAccuracy: 72.00%\n",
      "7\tValidation loss: 1.116189\tBest loss: 1.116189\tAccuracy: 73.90%\n",
      "8\tValidation loss: 1.078276\tBest loss: 1.078276\tAccuracy: 74.30%\n",
      "9\tValidation loss: 1.050127\tBest loss: 1.050127\tAccuracy: 73.80%\n",
      "10\tValidation loss: 1.002750\tBest loss: 1.002750\tAccuracy: 74.90%\n",
      "11\tValidation loss: 0.971743\tBest loss: 0.971743\tAccuracy: 76.10%\n",
      "12\tValidation loss: 0.937042\tBest loss: 0.937042\tAccuracy: 78.40%\n",
      "13\tValidation loss: 0.912909\tBest loss: 0.912909\tAccuracy: 78.50%\n",
      "14\tValidation loss: 0.889552\tBest loss: 0.889552\tAccuracy: 78.40%\n",
      "15\tValidation loss: 0.870402\tBest loss: 0.870402\tAccuracy: 80.00%\n",
      "16\tValidation loss: 0.855261\tBest loss: 0.855261\tAccuracy: 79.60%\n",
      "17\tValidation loss: 0.828201\tBest loss: 0.828201\tAccuracy: 80.50%\n",
      "18\tValidation loss: 0.818923\tBest loss: 0.818923\tAccuracy: 81.30%\n",
      "19\tValidation loss: 0.801741\tBest loss: 0.801741\tAccuracy: 81.30%\n",
      "20\tValidation loss: 0.798850\tBest loss: 0.798850\tAccuracy: 80.40%\n",
      "21\tValidation loss: 0.778019\tBest loss: 0.778019\tAccuracy: 82.40%\n",
      "22\tValidation loss: 0.763125\tBest loss: 0.763125\tAccuracy: 82.30%\n",
      "23\tValidation loss: 0.755247\tBest loss: 0.755247\tAccuracy: 83.60%\n",
      "24\tValidation loss: 0.750199\tBest loss: 0.750199\tAccuracy: 81.60%\n",
      "25\tValidation loss: 0.737591\tBest loss: 0.737591\tAccuracy: 83.50%\n",
      "26\tValidation loss: 0.727770\tBest loss: 0.727770\tAccuracy: 83.40%\n",
      "27\tValidation loss: 0.711396\tBest loss: 0.711396\tAccuracy: 83.00%\n",
      "28\tValidation loss: 0.707793\tBest loss: 0.707793\tAccuracy: 83.60%\n",
      "29\tValidation loss: 0.699157\tBest loss: 0.699157\tAccuracy: 84.20%\n",
      "30\tValidation loss: 0.692896\tBest loss: 0.692896\tAccuracy: 84.20%\n",
      "31\tValidation loss: 0.686912\tBest loss: 0.686912\tAccuracy: 84.40%\n",
      "32\tValidation loss: 0.676755\tBest loss: 0.676755\tAccuracy: 85.00%\n",
      "33\tValidation loss: 0.672773\tBest loss: 0.672773\tAccuracy: 84.90%\n",
      "34\tValidation loss: 0.665440\tBest loss: 0.665440\tAccuracy: 85.30%\n",
      "35\tValidation loss: 0.661088\tBest loss: 0.661088\tAccuracy: 85.20%\n",
      "36\tValidation loss: 0.658886\tBest loss: 0.658886\tAccuracy: 85.80%\n",
      "37\tValidation loss: 0.644241\tBest loss: 0.644241\tAccuracy: 84.90%\n",
      "38\tValidation loss: 0.637446\tBest loss: 0.637446\tAccuracy: 86.50%\n",
      "39\tValidation loss: 0.633508\tBest loss: 0.633508\tAccuracy: 85.40%\n",
      "40\tValidation loss: 0.627086\tBest loss: 0.627086\tAccuracy: 86.40%\n",
      "41\tValidation loss: 0.620709\tBest loss: 0.620709\tAccuracy: 86.40%\n",
      "42\tValidation loss: 0.623243\tBest loss: 0.620709\tAccuracy: 86.90%\n",
      "43\tValidation loss: 0.613468\tBest loss: 0.613468\tAccuracy: 86.50%\n",
      "44\tValidation loss: 0.605211\tBest loss: 0.605211\tAccuracy: 86.70%\n",
      "45\tValidation loss: 0.612910\tBest loss: 0.605211\tAccuracy: 86.00%\n",
      "46\tValidation loss: 0.606859\tBest loss: 0.605211\tAccuracy: 87.00%\n",
      "47\tValidation loss: 0.597638\tBest loss: 0.597638\tAccuracy: 86.70%\n",
      "48\tValidation loss: 0.591658\tBest loss: 0.591658\tAccuracy: 87.70%\n",
      "49\tValidation loss: 0.589535\tBest loss: 0.589535\tAccuracy: 86.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\tValidation loss: 0.588047\tBest loss: 0.588047\tAccuracy: 87.30%\n",
      "51\tValidation loss: 0.580184\tBest loss: 0.580184\tAccuracy: 87.90%\n",
      "52\tValidation loss: 0.581471\tBest loss: 0.580184\tAccuracy: 87.40%\n",
      "53\tValidation loss: 0.575012\tBest loss: 0.575012\tAccuracy: 88.00%\n",
      "54\tValidation loss: 0.570427\tBest loss: 0.570427\tAccuracy: 87.80%\n",
      "55\tValidation loss: 0.570616\tBest loss: 0.570427\tAccuracy: 87.70%\n",
      "56\tValidation loss: 0.568477\tBest loss: 0.568477\tAccuracy: 87.70%\n",
      "57\tValidation loss: 0.558741\tBest loss: 0.558741\tAccuracy: 88.30%\n",
      "58\tValidation loss: 0.558298\tBest loss: 0.558298\tAccuracy: 87.90%\n",
      "59\tValidation loss: 0.555160\tBest loss: 0.555160\tAccuracy: 88.20%\n",
      "60\tValidation loss: 0.554350\tBest loss: 0.554350\tAccuracy: 87.70%\n",
      "61\tValidation loss: 0.557548\tBest loss: 0.554350\tAccuracy: 88.00%\n",
      "62\tValidation loss: 0.547462\tBest loss: 0.547462\tAccuracy: 87.40%\n",
      "63\tValidation loss: 0.541595\tBest loss: 0.541595\tAccuracy: 88.20%\n",
      "64\tValidation loss: 0.539918\tBest loss: 0.539918\tAccuracy: 88.00%\n",
      "65\tValidation loss: 0.541410\tBest loss: 0.539918\tAccuracy: 88.10%\n",
      "66\tValidation loss: 0.535544\tBest loss: 0.535544\tAccuracy: 88.40%\n",
      "67\tValidation loss: 0.536290\tBest loss: 0.535544\tAccuracy: 88.20%\n",
      "68\tValidation loss: 0.529238\tBest loss: 0.529238\tAccuracy: 88.30%\n",
      "69\tValidation loss: 0.531976\tBest loss: 0.529238\tAccuracy: 88.10%\n",
      "70\tValidation loss: 0.526609\tBest loss: 0.526609\tAccuracy: 88.40%\n",
      "71\tValidation loss: 0.528170\tBest loss: 0.526609\tAccuracy: 88.30%\n",
      "72\tValidation loss: 0.522207\tBest loss: 0.522207\tAccuracy: 88.70%\n",
      "73\tValidation loss: 0.519121\tBest loss: 0.519121\tAccuracy: 88.90%\n",
      "74\tValidation loss: 0.518353\tBest loss: 0.518353\tAccuracy: 88.30%\n",
      "75\tValidation loss: 0.517514\tBest loss: 0.517514\tAccuracy: 88.60%\n",
      "76\tValidation loss: 0.519803\tBest loss: 0.517514\tAccuracy: 88.50%\n",
      "77\tValidation loss: 0.515137\tBest loss: 0.515137\tAccuracy: 88.60%\n",
      "78\tValidation loss: 0.505516\tBest loss: 0.505516\tAccuracy: 89.40%\n",
      "79\tValidation loss: 0.515265\tBest loss: 0.505516\tAccuracy: 88.60%\n",
      "80\tValidation loss: 0.504957\tBest loss: 0.504957\tAccuracy: 88.70%\n",
      "81\tValidation loss: 0.504896\tBest loss: 0.504896\tAccuracy: 88.80%\n",
      "82\tValidation loss: 0.500819\tBest loss: 0.500819\tAccuracy: 88.70%\n",
      "83\tValidation loss: 0.499884\tBest loss: 0.499884\tAccuracy: 88.50%\n",
      "84\tValidation loss: 0.498727\tBest loss: 0.498727\tAccuracy: 88.80%\n",
      "85\tValidation loss: 0.493573\tBest loss: 0.493573\tAccuracy: 89.10%\n",
      "86\tValidation loss: 0.493299\tBest loss: 0.493299\tAccuracy: 89.00%\n",
      "87\tValidation loss: 0.496583\tBest loss: 0.493299\tAccuracy: 88.50%\n",
      "88\tValidation loss: 0.488694\tBest loss: 0.488694\tAccuracy: 89.00%\n",
      "89\tValidation loss: 0.487418\tBest loss: 0.487418\tAccuracy: 89.20%\n",
      "90\tValidation loss: 0.487681\tBest loss: 0.487418\tAccuracy: 89.30%\n",
      "91\tValidation loss: 0.484894\tBest loss: 0.484894\tAccuracy: 89.60%\n",
      "92\tValidation loss: 0.490401\tBest loss: 0.484894\tAccuracy: 88.90%\n",
      "93\tValidation loss: 0.481648\tBest loss: 0.481648\tAccuracy: 89.30%\n",
      "94\tValidation loss: 0.481146\tBest loss: 0.481146\tAccuracy: 89.10%\n",
      "95\tValidation loss: 0.475546\tBest loss: 0.475546\tAccuracy: 89.20%\n",
      "96\tValidation loss: 0.474637\tBest loss: 0.474637\tAccuracy: 89.30%\n",
      "97\tValidation loss: 0.482437\tBest loss: 0.474637\tAccuracy: 89.10%\n",
      "98\tValidation loss: 0.473841\tBest loss: 0.473841\tAccuracy: 89.20%\n",
      "99\tValidation loss: 0.474869\tBest loss: 0.473841\tAccuracy: 89.40%\n",
      "100\tValidation loss: 0.476681\tBest loss: 0.473841\tAccuracy: 89.20%\n",
      "101\tValidation loss: 0.471606\tBest loss: 0.471606\tAccuracy: 89.20%\n",
      "102\tValidation loss: 0.465742\tBest loss: 0.465742\tAccuracy: 89.50%\n",
      "103\tValidation loss: 0.466953\tBest loss: 0.465742\tAccuracy: 89.10%\n",
      "104\tValidation loss: 0.468353\tBest loss: 0.465742\tAccuracy: 89.10%\n",
      "105\tValidation loss: 0.472868\tBest loss: 0.465742\tAccuracy: 89.20%\n",
      "106\tValidation loss: 0.463991\tBest loss: 0.463991\tAccuracy: 89.10%\n",
      "107\tValidation loss: 0.466212\tBest loss: 0.463991\tAccuracy: 89.00%\n",
      "108\tValidation loss: 0.466381\tBest loss: 0.463991\tAccuracy: 89.10%\n",
      "109\tValidation loss: 0.460660\tBest loss: 0.460660\tAccuracy: 89.30%\n",
      "110\tValidation loss: 0.459504\tBest loss: 0.459504\tAccuracy: 89.30%\n",
      "111\tValidation loss: 0.464052\tBest loss: 0.459504\tAccuracy: 89.20%\n",
      "112\tValidation loss: 0.457397\tBest loss: 0.457397\tAccuracy: 89.60%\n",
      "113\tValidation loss: 0.455840\tBest loss: 0.455840\tAccuracy: 89.30%\n",
      "114\tValidation loss: 0.461479\tBest loss: 0.455840\tAccuracy: 89.50%\n",
      "115\tValidation loss: 0.452667\tBest loss: 0.452667\tAccuracy: 89.70%\n",
      "116\tValidation loss: 0.453410\tBest loss: 0.452667\tAccuracy: 89.50%\n",
      "117\tValidation loss: 0.453860\tBest loss: 0.452667\tAccuracy: 89.00%\n",
      "118\tValidation loss: 0.444970\tBest loss: 0.444970\tAccuracy: 90.20%\n",
      "119\tValidation loss: 0.446766\tBest loss: 0.444970\tAccuracy: 89.60%\n",
      "120\tValidation loss: 0.444727\tBest loss: 0.444727\tAccuracy: 90.40%\n",
      "121\tValidation loss: 0.447589\tBest loss: 0.444727\tAccuracy: 89.50%\n",
      "122\tValidation loss: 0.448058\tBest loss: 0.444727\tAccuracy: 89.50%\n",
      "123\tValidation loss: 0.445548\tBest loss: 0.444727\tAccuracy: 90.00%\n",
      "124\tValidation loss: 0.445152\tBest loss: 0.444727\tAccuracy: 89.60%\n",
      "125\tValidation loss: 0.441176\tBest loss: 0.441176\tAccuracy: 90.30%\n",
      "126\tValidation loss: 0.441531\tBest loss: 0.441176\tAccuracy: 89.90%\n",
      "127\tValidation loss: 0.441053\tBest loss: 0.441053\tAccuracy: 89.60%\n",
      "128\tValidation loss: 0.437488\tBest loss: 0.437488\tAccuracy: 89.90%\n",
      "129\tValidation loss: 0.435002\tBest loss: 0.435002\tAccuracy: 90.40%\n",
      "130\tValidation loss: 0.434690\tBest loss: 0.434690\tAccuracy: 90.30%\n",
      "131\tValidation loss: 0.437877\tBest loss: 0.434690\tAccuracy: 90.10%\n",
      "132\tValidation loss: 0.434071\tBest loss: 0.434071\tAccuracy: 90.10%\n",
      "133\tValidation loss: 0.440638\tBest loss: 0.434071\tAccuracy: 90.10%\n",
      "134\tValidation loss: 0.434179\tBest loss: 0.434071\tAccuracy: 90.10%\n",
      "135\tValidation loss: 0.435771\tBest loss: 0.434071\tAccuracy: 89.90%\n",
      "136\tValidation loss: 0.430570\tBest loss: 0.430570\tAccuracy: 90.40%\n",
      "137\tValidation loss: 0.430329\tBest loss: 0.430329\tAccuracy: 90.40%\n",
      "138\tValidation loss: 0.430883\tBest loss: 0.430329\tAccuracy: 90.00%\n",
      "139\tValidation loss: 0.426962\tBest loss: 0.426962\tAccuracy: 90.40%\n",
      "140\tValidation loss: 0.427470\tBest loss: 0.426962\tAccuracy: 90.20%\n",
      "141\tValidation loss: 0.426386\tBest loss: 0.426386\tAccuracy: 90.20%\n",
      "142\tValidation loss: 0.423955\tBest loss: 0.423955\tAccuracy: 90.20%\n",
      "143\tValidation loss: 0.424747\tBest loss: 0.423955\tAccuracy: 90.50%\n",
      "144\tValidation loss: 0.423815\tBest loss: 0.423815\tAccuracy: 90.70%\n",
      "145\tValidation loss: 0.422706\tBest loss: 0.422706\tAccuracy: 91.10%\n",
      "146\tValidation loss: 0.424347\tBest loss: 0.422706\tAccuracy: 90.10%\n",
      "147\tValidation loss: 0.425231\tBest loss: 0.422706\tAccuracy: 90.50%\n",
      "148\tValidation loss: 0.422517\tBest loss: 0.422517\tAccuracy: 90.80%\n",
      "149\tValidation loss: 0.419666\tBest loss: 0.419666\tAccuracy: 90.60%\n",
      "150\tValidation loss: 0.422353\tBest loss: 0.419666\tAccuracy: 90.80%\n",
      "151\tValidation loss: 0.416884\tBest loss: 0.416884\tAccuracy: 90.90%\n",
      "152\tValidation loss: 0.416265\tBest loss: 0.416265\tAccuracy: 90.80%\n",
      "153\tValidation loss: 0.417528\tBest loss: 0.416265\tAccuracy: 91.00%\n",
      "154\tValidation loss: 0.418106\tBest loss: 0.416265\tAccuracy: 90.70%\n",
      "155\tValidation loss: 0.416969\tBest loss: 0.416265\tAccuracy: 90.60%\n",
      "156\tValidation loss: 0.414581\tBest loss: 0.414581\tAccuracy: 90.90%\n",
      "157\tValidation loss: 0.416687\tBest loss: 0.414581\tAccuracy: 90.90%\n",
      "158\tValidation loss: 0.411105\tBest loss: 0.411105\tAccuracy: 91.00%\n",
      "159\tValidation loss: 0.409827\tBest loss: 0.409827\tAccuracy: 90.70%\n",
      "160\tValidation loss: 0.417316\tBest loss: 0.409827\tAccuracy: 90.80%\n",
      "161\tValidation loss: 0.408379\tBest loss: 0.408379\tAccuracy: 91.00%\n",
      "162\tValidation loss: 0.407895\tBest loss: 0.407895\tAccuracy: 91.10%\n",
      "163\tValidation loss: 0.407694\tBest loss: 0.407694\tAccuracy: 91.00%\n",
      "164\tValidation loss: 0.411044\tBest loss: 0.407694\tAccuracy: 90.90%\n",
      "165\tValidation loss: 0.408212\tBest loss: 0.407694\tAccuracy: 90.90%\n",
      "166\tValidation loss: 0.407439\tBest loss: 0.407439\tAccuracy: 90.90%\n",
      "167\tValidation loss: 0.402059\tBest loss: 0.402059\tAccuracy: 90.80%\n",
      "168\tValidation loss: 0.403666\tBest loss: 0.402059\tAccuracy: 90.80%\n",
      "169\tValidation loss: 0.405305\tBest loss: 0.402059\tAccuracy: 90.80%\n",
      "170\tValidation loss: 0.407274\tBest loss: 0.402059\tAccuracy: 90.60%\n",
      "171\tValidation loss: 0.403629\tBest loss: 0.402059\tAccuracy: 91.00%\n",
      "172\tValidation loss: 0.402045\tBest loss: 0.402045\tAccuracy: 91.00%\n",
      "173\tValidation loss: 0.401018\tBest loss: 0.401018\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\tValidation loss: 0.401036\tBest loss: 0.401018\tAccuracy: 91.00%\n",
      "175\tValidation loss: 0.401237\tBest loss: 0.401018\tAccuracy: 91.10%\n",
      "176\tValidation loss: 0.399019\tBest loss: 0.399019\tAccuracy: 90.80%\n",
      "177\tValidation loss: 0.398585\tBest loss: 0.398585\tAccuracy: 91.20%\n",
      "178\tValidation loss: 0.397438\tBest loss: 0.397438\tAccuracy: 90.90%\n",
      "179\tValidation loss: 0.398619\tBest loss: 0.397438\tAccuracy: 91.50%\n",
      "180\tValidation loss: 0.396564\tBest loss: 0.396564\tAccuracy: 91.00%\n",
      "181\tValidation loss: 0.396907\tBest loss: 0.396564\tAccuracy: 91.10%\n",
      "182\tValidation loss: 0.398642\tBest loss: 0.396564\tAccuracy: 91.00%\n",
      "183\tValidation loss: 0.396078\tBest loss: 0.396078\tAccuracy: 91.10%\n",
      "184\tValidation loss: 0.398122\tBest loss: 0.396078\tAccuracy: 90.90%\n",
      "185\tValidation loss: 0.393214\tBest loss: 0.393214\tAccuracy: 90.90%\n",
      "186\tValidation loss: 0.393917\tBest loss: 0.393214\tAccuracy: 91.00%\n",
      "187\tValidation loss: 0.391143\tBest loss: 0.391143\tAccuracy: 91.30%\n",
      "188\tValidation loss: 0.393488\tBest loss: 0.391143\tAccuracy: 91.10%\n",
      "189\tValidation loss: 0.392651\tBest loss: 0.391143\tAccuracy: 91.00%\n",
      "190\tValidation loss: 0.391005\tBest loss: 0.391005\tAccuracy: 91.10%\n",
      "191\tValidation loss: 0.389438\tBest loss: 0.389438\tAccuracy: 91.10%\n",
      "192\tValidation loss: 0.388591\tBest loss: 0.388591\tAccuracy: 90.90%\n",
      "193\tValidation loss: 0.390742\tBest loss: 0.388591\tAccuracy: 91.20%\n",
      "194\tValidation loss: 0.392699\tBest loss: 0.388591\tAccuracy: 91.20%\n",
      "195\tValidation loss: 0.389681\tBest loss: 0.388591\tAccuracy: 91.10%\n",
      "196\tValidation loss: 0.384931\tBest loss: 0.384931\tAccuracy: 91.20%\n",
      "197\tValidation loss: 0.389199\tBest loss: 0.384931\tAccuracy: 91.30%\n",
      "198\tValidation loss: 0.389610\tBest loss: 0.384931\tAccuracy: 91.40%\n",
      "199\tValidation loss: 0.388964\tBest loss: 0.384931\tAccuracy: 91.40%\n",
      "200\tValidation loss: 0.386668\tBest loss: 0.384931\tAccuracy: 91.20%\n",
      "201\tValidation loss: 0.385383\tBest loss: 0.384931\tAccuracy: 91.10%\n",
      "202\tValidation loss: 0.382215\tBest loss: 0.382215\tAccuracy: 91.30%\n",
      "203\tValidation loss: 0.384531\tBest loss: 0.382215\tAccuracy: 91.00%\n",
      "204\tValidation loss: 0.383447\tBest loss: 0.382215\tAccuracy: 91.10%\n",
      "205\tValidation loss: 0.384298\tBest loss: 0.382215\tAccuracy: 91.00%\n",
      "206\tValidation loss: 0.381793\tBest loss: 0.381793\tAccuracy: 91.30%\n",
      "207\tValidation loss: 0.383104\tBest loss: 0.381793\tAccuracy: 91.20%\n",
      "208\tValidation loss: 0.383289\tBest loss: 0.381793\tAccuracy: 91.30%\n",
      "209\tValidation loss: 0.382491\tBest loss: 0.381793\tAccuracy: 91.50%\n",
      "210\tValidation loss: 0.384660\tBest loss: 0.381793\tAccuracy: 91.20%\n",
      "211\tValidation loss: 0.380784\tBest loss: 0.380784\tAccuracy: 91.40%\n",
      "212\tValidation loss: 0.380504\tBest loss: 0.380504\tAccuracy: 91.30%\n",
      "213\tValidation loss: 0.381796\tBest loss: 0.380504\tAccuracy: 91.50%\n",
      "214\tValidation loss: 0.379148\tBest loss: 0.379148\tAccuracy: 91.50%\n",
      "215\tValidation loss: 0.380896\tBest loss: 0.379148\tAccuracy: 91.00%\n",
      "216\tValidation loss: 0.378853\tBest loss: 0.378853\tAccuracy: 91.20%\n",
      "217\tValidation loss: 0.378240\tBest loss: 0.378240\tAccuracy: 91.20%\n",
      "218\tValidation loss: 0.377938\tBest loss: 0.377938\tAccuracy: 91.00%\n",
      "219\tValidation loss: 0.379787\tBest loss: 0.377938\tAccuracy: 91.60%\n",
      "220\tValidation loss: 0.376867\tBest loss: 0.376867\tAccuracy: 91.30%\n",
      "221\tValidation loss: 0.378557\tBest loss: 0.376867\tAccuracy: 91.30%\n",
      "222\tValidation loss: 0.378295\tBest loss: 0.376867\tAccuracy: 91.60%\n",
      "223\tValidation loss: 0.376189\tBest loss: 0.376189\tAccuracy: 91.30%\n",
      "224\tValidation loss: 0.376603\tBest loss: 0.376189\tAccuracy: 91.30%\n",
      "225\tValidation loss: 0.375318\tBest loss: 0.375318\tAccuracy: 91.40%\n",
      "226\tValidation loss: 0.376995\tBest loss: 0.375318\tAccuracy: 91.30%\n",
      "227\tValidation loss: 0.373172\tBest loss: 0.373172\tAccuracy: 91.30%\n",
      "228\tValidation loss: 0.370937\tBest loss: 0.370937\tAccuracy: 91.50%\n",
      "229\tValidation loss: 0.375101\tBest loss: 0.370937\tAccuracy: 91.20%\n",
      "230\tValidation loss: 0.372783\tBest loss: 0.370937\tAccuracy: 91.90%\n",
      "231\tValidation loss: 0.370525\tBest loss: 0.370525\tAccuracy: 91.40%\n",
      "232\tValidation loss: 0.371230\tBest loss: 0.370525\tAccuracy: 91.40%\n",
      "233\tValidation loss: 0.369421\tBest loss: 0.369421\tAccuracy: 91.90%\n",
      "234\tValidation loss: 0.371370\tBest loss: 0.369421\tAccuracy: 91.50%\n",
      "235\tValidation loss: 0.375470\tBest loss: 0.369421\tAccuracy: 91.50%\n",
      "236\tValidation loss: 0.370484\tBest loss: 0.369421\tAccuracy: 91.40%\n",
      "237\tValidation loss: 0.371874\tBest loss: 0.369421\tAccuracy: 91.90%\n",
      "238\tValidation loss: 0.373177\tBest loss: 0.369421\tAccuracy: 91.50%\n",
      "239\tValidation loss: 0.369846\tBest loss: 0.369421\tAccuracy: 91.80%\n",
      "240\tValidation loss: 0.369834\tBest loss: 0.369421\tAccuracy: 91.80%\n",
      "241\tValidation loss: 0.370992\tBest loss: 0.369421\tAccuracy: 92.00%\n",
      "242\tValidation loss: 0.368481\tBest loss: 0.368481\tAccuracy: 91.50%\n",
      "243\tValidation loss: 0.366640\tBest loss: 0.366640\tAccuracy: 91.60%\n",
      "244\tValidation loss: 0.369922\tBest loss: 0.366640\tAccuracy: 91.70%\n",
      "245\tValidation loss: 0.368873\tBest loss: 0.366640\tAccuracy: 91.60%\n",
      "246\tValidation loss: 0.370910\tBest loss: 0.366640\tAccuracy: 92.10%\n",
      "247\tValidation loss: 0.363133\tBest loss: 0.363133\tAccuracy: 91.60%\n",
      "248\tValidation loss: 0.365731\tBest loss: 0.363133\tAccuracy: 91.40%\n",
      "249\tValidation loss: 0.364960\tBest loss: 0.363133\tAccuracy: 91.70%\n",
      "250\tValidation loss: 0.364242\tBest loss: 0.363133\tAccuracy: 91.90%\n",
      "251\tValidation loss: 0.365683\tBest loss: 0.363133\tAccuracy: 91.90%\n",
      "252\tValidation loss: 0.362967\tBest loss: 0.362967\tAccuracy: 91.70%\n",
      "253\tValidation loss: 0.363140\tBest loss: 0.362967\tAccuracy: 92.10%\n",
      "254\tValidation loss: 0.363524\tBest loss: 0.362967\tAccuracy: 91.30%\n",
      "255\tValidation loss: 0.364415\tBest loss: 0.362967\tAccuracy: 91.80%\n",
      "256\tValidation loss: 0.361899\tBest loss: 0.361899\tAccuracy: 91.80%\n",
      "257\tValidation loss: 0.368394\tBest loss: 0.361899\tAccuracy: 91.90%\n",
      "258\tValidation loss: 0.363752\tBest loss: 0.361899\tAccuracy: 91.50%\n",
      "259\tValidation loss: 0.365366\tBest loss: 0.361899\tAccuracy: 92.00%\n",
      "260\tValidation loss: 0.363114\tBest loss: 0.361899\tAccuracy: 91.60%\n",
      "261\tValidation loss: 0.362845\tBest loss: 0.361899\tAccuracy: 91.70%\n",
      "262\tValidation loss: 0.361276\tBest loss: 0.361276\tAccuracy: 91.70%\n",
      "263\tValidation loss: 0.359787\tBest loss: 0.359787\tAccuracy: 91.50%\n",
      "264\tValidation loss: 0.358868\tBest loss: 0.358868\tAccuracy: 91.60%\n",
      "265\tValidation loss: 0.360325\tBest loss: 0.358868\tAccuracy: 91.90%\n",
      "266\tValidation loss: 0.360623\tBest loss: 0.358868\tAccuracy: 92.00%\n",
      "267\tValidation loss: 0.357969\tBest loss: 0.357969\tAccuracy: 91.60%\n",
      "268\tValidation loss: 0.360011\tBest loss: 0.357969\tAccuracy: 91.90%\n",
      "269\tValidation loss: 0.358399\tBest loss: 0.357969\tAccuracy: 92.00%\n",
      "270\tValidation loss: 0.360384\tBest loss: 0.357969\tAccuracy: 92.00%\n",
      "271\tValidation loss: 0.358085\tBest loss: 0.357969\tAccuracy: 91.50%\n",
      "272\tValidation loss: 0.356322\tBest loss: 0.356322\tAccuracy: 92.10%\n",
      "273\tValidation loss: 0.357968\tBest loss: 0.356322\tAccuracy: 91.70%\n",
      "274\tValidation loss: 0.355445\tBest loss: 0.355445\tAccuracy: 91.70%\n",
      "275\tValidation loss: 0.360005\tBest loss: 0.355445\tAccuracy: 91.80%\n",
      "276\tValidation loss: 0.357817\tBest loss: 0.355445\tAccuracy: 91.90%\n",
      "277\tValidation loss: 0.357982\tBest loss: 0.355445\tAccuracy: 92.00%\n",
      "278\tValidation loss: 0.355336\tBest loss: 0.355336\tAccuracy: 92.00%\n",
      "279\tValidation loss: 0.357426\tBest loss: 0.355336\tAccuracy: 91.80%\n",
      "280\tValidation loss: 0.353118\tBest loss: 0.353118\tAccuracy: 91.70%\n",
      "281\tValidation loss: 0.356947\tBest loss: 0.353118\tAccuracy: 92.00%\n",
      "282\tValidation loss: 0.356654\tBest loss: 0.353118\tAccuracy: 91.70%\n",
      "283\tValidation loss: 0.353132\tBest loss: 0.353118\tAccuracy: 91.70%\n",
      "284\tValidation loss: 0.356516\tBest loss: 0.353118\tAccuracy: 92.10%\n",
      "285\tValidation loss: 0.353531\tBest loss: 0.353118\tAccuracy: 92.10%\n",
      "286\tValidation loss: 0.353894\tBest loss: 0.353118\tAccuracy: 92.00%\n",
      "287\tValidation loss: 0.354877\tBest loss: 0.353118\tAccuracy: 92.00%\n",
      "288\tValidation loss: 0.352326\tBest loss: 0.352326\tAccuracy: 91.80%\n",
      "289\tValidation loss: 0.354333\tBest loss: 0.352326\tAccuracy: 91.80%\n",
      "290\tValidation loss: 0.351369\tBest loss: 0.351369\tAccuracy: 92.00%\n",
      "291\tValidation loss: 0.351903\tBest loss: 0.351369\tAccuracy: 91.80%\n",
      "292\tValidation loss: 0.353721\tBest loss: 0.351369\tAccuracy: 92.00%\n",
      "293\tValidation loss: 0.353734\tBest loss: 0.351369\tAccuracy: 92.10%\n",
      "294\tValidation loss: 0.351283\tBest loss: 0.351283\tAccuracy: 91.80%\n",
      "295\tValidation loss: 0.352808\tBest loss: 0.351283\tAccuracy: 92.10%\n",
      "296\tValidation loss: 0.352260\tBest loss: 0.351283\tAccuracy: 92.10%\n",
      "297\tValidation loss: 0.351003\tBest loss: 0.351003\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\tValidation loss: 0.351568\tBest loss: 0.351003\tAccuracy: 91.80%\n",
      "299\tValidation loss: 0.350824\tBest loss: 0.350824\tAccuracy: 91.90%\n",
      "300\tValidation loss: 0.349438\tBest loss: 0.349438\tAccuracy: 91.80%\n",
      "301\tValidation loss: 0.349419\tBest loss: 0.349419\tAccuracy: 92.20%\n",
      "302\tValidation loss: 0.353718\tBest loss: 0.349419\tAccuracy: 92.10%\n",
      "303\tValidation loss: 0.352238\tBest loss: 0.349419\tAccuracy: 92.00%\n",
      "304\tValidation loss: 0.349039\tBest loss: 0.349039\tAccuracy: 91.70%\n",
      "305\tValidation loss: 0.347859\tBest loss: 0.347859\tAccuracy: 92.00%\n",
      "306\tValidation loss: 0.349274\tBest loss: 0.347859\tAccuracy: 92.00%\n",
      "307\tValidation loss: 0.349576\tBest loss: 0.347859\tAccuracy: 92.00%\n",
      "308\tValidation loss: 0.348792\tBest loss: 0.347859\tAccuracy: 92.10%\n",
      "309\tValidation loss: 0.348549\tBest loss: 0.347859\tAccuracy: 91.80%\n",
      "310\tValidation loss: 0.346289\tBest loss: 0.346289\tAccuracy: 91.80%\n",
      "311\tValidation loss: 0.347816\tBest loss: 0.346289\tAccuracy: 92.00%\n",
      "312\tValidation loss: 0.346173\tBest loss: 0.346173\tAccuracy: 91.80%\n",
      "313\tValidation loss: 0.349870\tBest loss: 0.346173\tAccuracy: 91.90%\n",
      "314\tValidation loss: 0.346304\tBest loss: 0.346173\tAccuracy: 92.10%\n",
      "315\tValidation loss: 0.347357\tBest loss: 0.346173\tAccuracy: 91.90%\n",
      "316\tValidation loss: 0.349634\tBest loss: 0.346173\tAccuracy: 91.70%\n",
      "317\tValidation loss: 0.348150\tBest loss: 0.346173\tAccuracy: 91.80%\n",
      "318\tValidation loss: 0.346779\tBest loss: 0.346173\tAccuracy: 91.90%\n",
      "319\tValidation loss: 0.347371\tBest loss: 0.346173\tAccuracy: 91.90%\n",
      "320\tValidation loss: 0.342837\tBest loss: 0.342837\tAccuracy: 91.80%\n",
      "321\tValidation loss: 0.344996\tBest loss: 0.342837\tAccuracy: 92.10%\n",
      "322\tValidation loss: 0.344089\tBest loss: 0.342837\tAccuracy: 92.20%\n",
      "323\tValidation loss: 0.347958\tBest loss: 0.342837\tAccuracy: 92.10%\n",
      "324\tValidation loss: 0.345873\tBest loss: 0.342837\tAccuracy: 92.00%\n",
      "325\tValidation loss: 0.346632\tBest loss: 0.342837\tAccuracy: 91.80%\n",
      "326\tValidation loss: 0.344011\tBest loss: 0.342837\tAccuracy: 92.20%\n",
      "327\tValidation loss: 0.345247\tBest loss: 0.342837\tAccuracy: 91.80%\n",
      "328\tValidation loss: 0.345075\tBest loss: 0.342837\tAccuracy: 92.20%\n",
      "329\tValidation loss: 0.346294\tBest loss: 0.342837\tAccuracy: 91.90%\n",
      "330\tValidation loss: 0.343877\tBest loss: 0.342837\tAccuracy: 91.90%\n",
      "331\tValidation loss: 0.343335\tBest loss: 0.342837\tAccuracy: 92.10%\n",
      "332\tValidation loss: 0.343717\tBest loss: 0.342837\tAccuracy: 92.00%\n",
      "333\tValidation loss: 0.343800\tBest loss: 0.342837\tAccuracy: 92.20%\n",
      "334\tValidation loss: 0.344865\tBest loss: 0.342837\tAccuracy: 92.30%\n",
      "335\tValidation loss: 0.340824\tBest loss: 0.340824\tAccuracy: 91.90%\n",
      "336\tValidation loss: 0.339421\tBest loss: 0.339421\tAccuracy: 92.10%\n",
      "337\tValidation loss: 0.342046\tBest loss: 0.339421\tAccuracy: 91.90%\n",
      "338\tValidation loss: 0.341976\tBest loss: 0.339421\tAccuracy: 92.30%\n",
      "339\tValidation loss: 0.342387\tBest loss: 0.339421\tAccuracy: 92.30%\n",
      "340\tValidation loss: 0.343016\tBest loss: 0.339421\tAccuracy: 92.50%\n",
      "341\tValidation loss: 0.340193\tBest loss: 0.339421\tAccuracy: 92.40%\n",
      "342\tValidation loss: 0.341436\tBest loss: 0.339421\tAccuracy: 92.20%\n",
      "343\tValidation loss: 0.340240\tBest loss: 0.339421\tAccuracy: 92.10%\n",
      "344\tValidation loss: 0.340268\tBest loss: 0.339421\tAccuracy: 92.50%\n",
      "345\tValidation loss: 0.341208\tBest loss: 0.339421\tAccuracy: 91.90%\n",
      "346\tValidation loss: 0.339724\tBest loss: 0.339421\tAccuracy: 92.10%\n",
      "347\tValidation loss: 0.342749\tBest loss: 0.339421\tAccuracy: 92.20%\n",
      "348\tValidation loss: 0.339249\tBest loss: 0.339249\tAccuracy: 92.20%\n",
      "349\tValidation loss: 0.341862\tBest loss: 0.339249\tAccuracy: 92.30%\n",
      "350\tValidation loss: 0.341988\tBest loss: 0.339249\tAccuracy: 92.20%\n",
      "351\tValidation loss: 0.338950\tBest loss: 0.338950\tAccuracy: 92.30%\n",
      "352\tValidation loss: 0.338455\tBest loss: 0.338455\tAccuracy: 92.20%\n",
      "353\tValidation loss: 0.340641\tBest loss: 0.338455\tAccuracy: 92.10%\n",
      "354\tValidation loss: 0.341539\tBest loss: 0.338455\tAccuracy: 92.20%\n",
      "355\tValidation loss: 0.340053\tBest loss: 0.338455\tAccuracy: 92.20%\n",
      "356\tValidation loss: 0.337753\tBest loss: 0.337753\tAccuracy: 92.00%\n",
      "357\tValidation loss: 0.340678\tBest loss: 0.337753\tAccuracy: 92.30%\n",
      "358\tValidation loss: 0.337800\tBest loss: 0.337753\tAccuracy: 92.20%\n",
      "359\tValidation loss: 0.337797\tBest loss: 0.337753\tAccuracy: 92.10%\n",
      "360\tValidation loss: 0.339217\tBest loss: 0.337753\tAccuracy: 92.20%\n",
      "361\tValidation loss: 0.339524\tBest loss: 0.337753\tAccuracy: 92.00%\n",
      "362\tValidation loss: 0.338769\tBest loss: 0.337753\tAccuracy: 91.90%\n",
      "363\tValidation loss: 0.338443\tBest loss: 0.337753\tAccuracy: 92.10%\n",
      "364\tValidation loss: 0.337100\tBest loss: 0.337100\tAccuracy: 92.20%\n",
      "365\tValidation loss: 0.337730\tBest loss: 0.337100\tAccuracy: 92.30%\n",
      "366\tValidation loss: 0.337311\tBest loss: 0.337100\tAccuracy: 92.10%\n",
      "367\tValidation loss: 0.336936\tBest loss: 0.336936\tAccuracy: 92.10%\n",
      "368\tValidation loss: 0.335904\tBest loss: 0.335904\tAccuracy: 92.30%\n",
      "369\tValidation loss: 0.336560\tBest loss: 0.335904\tAccuracy: 92.30%\n",
      "370\tValidation loss: 0.336038\tBest loss: 0.335904\tAccuracy: 92.30%\n",
      "371\tValidation loss: 0.335238\tBest loss: 0.335238\tAccuracy: 92.30%\n",
      "372\tValidation loss: 0.335730\tBest loss: 0.335238\tAccuracy: 92.30%\n",
      "373\tValidation loss: 0.335533\tBest loss: 0.335238\tAccuracy: 92.30%\n",
      "374\tValidation loss: 0.337671\tBest loss: 0.335238\tAccuracy: 92.20%\n",
      "375\tValidation loss: 0.335399\tBest loss: 0.335238\tAccuracy: 92.40%\n",
      "376\tValidation loss: 0.335773\tBest loss: 0.335238\tAccuracy: 92.30%\n",
      "377\tValidation loss: 0.333850\tBest loss: 0.333850\tAccuracy: 92.40%\n",
      "378\tValidation loss: 0.334215\tBest loss: 0.333850\tAccuracy: 92.30%\n",
      "379\tValidation loss: 0.335361\tBest loss: 0.333850\tAccuracy: 92.30%\n",
      "380\tValidation loss: 0.334676\tBest loss: 0.333850\tAccuracy: 92.30%\n",
      "381\tValidation loss: 0.336329\tBest loss: 0.333850\tAccuracy: 92.20%\n",
      "382\tValidation loss: 0.334144\tBest loss: 0.333850\tAccuracy: 92.30%\n",
      "383\tValidation loss: 0.334516\tBest loss: 0.333850\tAccuracy: 92.50%\n",
      "384\tValidation loss: 0.331929\tBest loss: 0.331929\tAccuracy: 92.30%\n",
      "385\tValidation loss: 0.334914\tBest loss: 0.331929\tAccuracy: 92.10%\n",
      "386\tValidation loss: 0.334888\tBest loss: 0.331929\tAccuracy: 92.30%\n",
      "387\tValidation loss: 0.333044\tBest loss: 0.331929\tAccuracy: 92.10%\n",
      "388\tValidation loss: 0.332292\tBest loss: 0.331929\tAccuracy: 92.30%\n",
      "389\tValidation loss: 0.333982\tBest loss: 0.331929\tAccuracy: 92.40%\n",
      "390\tValidation loss: 0.335994\tBest loss: 0.331929\tAccuracy: 92.30%\n",
      "391\tValidation loss: 0.331632\tBest loss: 0.331632\tAccuracy: 92.40%\n",
      "392\tValidation loss: 0.333428\tBest loss: 0.331632\tAccuracy: 92.40%\n",
      "393\tValidation loss: 0.334192\tBest loss: 0.331632\tAccuracy: 92.50%\n",
      "394\tValidation loss: 0.332994\tBest loss: 0.331632\tAccuracy: 92.30%\n",
      "395\tValidation loss: 0.331523\tBest loss: 0.331523\tAccuracy: 92.30%\n",
      "396\tValidation loss: 0.333916\tBest loss: 0.331523\tAccuracy: 92.20%\n",
      "397\tValidation loss: 0.332752\tBest loss: 0.331523\tAccuracy: 92.50%\n",
      "398\tValidation loss: 0.331025\tBest loss: 0.331025\tAccuracy: 92.20%\n",
      "399\tValidation loss: 0.332466\tBest loss: 0.331025\tAccuracy: 92.20%\n",
      "400\tValidation loss: 0.331848\tBest loss: 0.331025\tAccuracy: 92.40%\n",
      "401\tValidation loss: 0.330041\tBest loss: 0.330041\tAccuracy: 92.20%\n",
      "402\tValidation loss: 0.331236\tBest loss: 0.330041\tAccuracy: 92.30%\n",
      "403\tValidation loss: 0.331428\tBest loss: 0.330041\tAccuracy: 92.50%\n",
      "404\tValidation loss: 0.331701\tBest loss: 0.330041\tAccuracy: 92.50%\n",
      "405\tValidation loss: 0.328703\tBest loss: 0.328703\tAccuracy: 92.50%\n",
      "406\tValidation loss: 0.330927\tBest loss: 0.328703\tAccuracy: 92.30%\n",
      "407\tValidation loss: 0.331087\tBest loss: 0.328703\tAccuracy: 92.50%\n",
      "408\tValidation loss: 0.331478\tBest loss: 0.328703\tAccuracy: 92.40%\n",
      "409\tValidation loss: 0.328228\tBest loss: 0.328228\tAccuracy: 92.30%\n",
      "410\tValidation loss: 0.329367\tBest loss: 0.328228\tAccuracy: 92.40%\n",
      "411\tValidation loss: 0.329338\tBest loss: 0.328228\tAccuracy: 92.40%\n",
      "412\tValidation loss: 0.329422\tBest loss: 0.328228\tAccuracy: 92.40%\n",
      "413\tValidation loss: 0.328288\tBest loss: 0.328228\tAccuracy: 92.40%\n",
      "414\tValidation loss: 0.329449\tBest loss: 0.328228\tAccuracy: 92.50%\n",
      "415\tValidation loss: 0.328662\tBest loss: 0.328228\tAccuracy: 92.30%\n",
      "416\tValidation loss: 0.328109\tBest loss: 0.328109\tAccuracy: 92.20%\n",
      "417\tValidation loss: 0.328266\tBest loss: 0.328109\tAccuracy: 92.60%\n",
      "418\tValidation loss: 0.329312\tBest loss: 0.328109\tAccuracy: 92.50%\n",
      "419\tValidation loss: 0.327777\tBest loss: 0.327777\tAccuracy: 92.40%\n",
      "420\tValidation loss: 0.328512\tBest loss: 0.327777\tAccuracy: 92.30%\n",
      "421\tValidation loss: 0.327718\tBest loss: 0.327718\tAccuracy: 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\tValidation loss: 0.330059\tBest loss: 0.327718\tAccuracy: 92.50%\n",
      "423\tValidation loss: 0.327552\tBest loss: 0.327552\tAccuracy: 92.40%\n",
      "424\tValidation loss: 0.327543\tBest loss: 0.327543\tAccuracy: 92.50%\n",
      "425\tValidation loss: 0.326299\tBest loss: 0.326299\tAccuracy: 92.50%\n",
      "426\tValidation loss: 0.328130\tBest loss: 0.326299\tAccuracy: 92.40%\n",
      "427\tValidation loss: 0.328820\tBest loss: 0.326299\tAccuracy: 92.20%\n",
      "428\tValidation loss: 0.326388\tBest loss: 0.326299\tAccuracy: 92.30%\n",
      "429\tValidation loss: 0.327896\tBest loss: 0.326299\tAccuracy: 92.50%\n",
      "430\tValidation loss: 0.328800\tBest loss: 0.326299\tAccuracy: 92.30%\n",
      "431\tValidation loss: 0.328540\tBest loss: 0.326299\tAccuracy: 92.50%\n",
      "432\tValidation loss: 0.327069\tBest loss: 0.326299\tAccuracy: 92.30%\n",
      "433\tValidation loss: 0.328234\tBest loss: 0.326299\tAccuracy: 92.50%\n",
      "434\tValidation loss: 0.328765\tBest loss: 0.326299\tAccuracy: 92.60%\n",
      "435\tValidation loss: 0.325761\tBest loss: 0.325761\tAccuracy: 92.60%\n",
      "436\tValidation loss: 0.326915\tBest loss: 0.325761\tAccuracy: 92.40%\n",
      "437\tValidation loss: 0.325074\tBest loss: 0.325074\tAccuracy: 92.70%\n",
      "438\tValidation loss: 0.326951\tBest loss: 0.325074\tAccuracy: 92.40%\n",
      "439\tValidation loss: 0.327385\tBest loss: 0.325074\tAccuracy: 92.60%\n",
      "440\tValidation loss: 0.325536\tBest loss: 0.325074\tAccuracy: 92.50%\n",
      "441\tValidation loss: 0.327016\tBest loss: 0.325074\tAccuracy: 92.30%\n",
      "442\tValidation loss: 0.326866\tBest loss: 0.325074\tAccuracy: 92.40%\n",
      "443\tValidation loss: 0.326271\tBest loss: 0.325074\tAccuracy: 92.30%\n",
      "444\tValidation loss: 0.325162\tBest loss: 0.325074\tAccuracy: 92.30%\n",
      "445\tValidation loss: 0.324235\tBest loss: 0.324235\tAccuracy: 92.70%\n",
      "446\tValidation loss: 0.326056\tBest loss: 0.324235\tAccuracy: 92.50%\n",
      "447\tValidation loss: 0.328928\tBest loss: 0.324235\tAccuracy: 92.60%\n",
      "448\tValidation loss: 0.325114\tBest loss: 0.324235\tAccuracy: 92.60%\n",
      "449\tValidation loss: 0.324320\tBest loss: 0.324235\tAccuracy: 92.50%\n",
      "450\tValidation loss: 0.324770\tBest loss: 0.324235\tAccuracy: 92.70%\n",
      "451\tValidation loss: 0.324381\tBest loss: 0.324235\tAccuracy: 92.70%\n",
      "452\tValidation loss: 0.326247\tBest loss: 0.324235\tAccuracy: 92.70%\n",
      "453\tValidation loss: 0.323715\tBest loss: 0.323715\tAccuracy: 92.60%\n",
      "454\tValidation loss: 0.325404\tBest loss: 0.323715\tAccuracy: 92.60%\n",
      "455\tValidation loss: 0.325064\tBest loss: 0.323715\tAccuracy: 92.60%\n",
      "456\tValidation loss: 0.323855\tBest loss: 0.323715\tAccuracy: 92.80%\n",
      "457\tValidation loss: 0.322992\tBest loss: 0.322992\tAccuracy: 92.80%\n",
      "458\tValidation loss: 0.323110\tBest loss: 0.322992\tAccuracy: 92.70%\n",
      "459\tValidation loss: 0.322957\tBest loss: 0.322957\tAccuracy: 92.70%\n",
      "460\tValidation loss: 0.324511\tBest loss: 0.322957\tAccuracy: 92.60%\n",
      "461\tValidation loss: 0.324846\tBest loss: 0.322957\tAccuracy: 92.70%\n",
      "462\tValidation loss: 0.323786\tBest loss: 0.322957\tAccuracy: 92.70%\n",
      "463\tValidation loss: 0.324274\tBest loss: 0.322957\tAccuracy: 92.70%\n",
      "464\tValidation loss: 0.323128\tBest loss: 0.322957\tAccuracy: 92.50%\n",
      "465\tValidation loss: 0.323481\tBest loss: 0.322957\tAccuracy: 92.60%\n",
      "466\tValidation loss: 0.323439\tBest loss: 0.322957\tAccuracy: 92.70%\n",
      "467\tValidation loss: 0.321048\tBest loss: 0.321048\tAccuracy: 92.80%\n",
      "468\tValidation loss: 0.323051\tBest loss: 0.321048\tAccuracy: 92.80%\n",
      "469\tValidation loss: 0.322471\tBest loss: 0.321048\tAccuracy: 92.80%\n",
      "470\tValidation loss: 0.323682\tBest loss: 0.321048\tAccuracy: 92.60%\n",
      "471\tValidation loss: 0.325203\tBest loss: 0.321048\tAccuracy: 92.80%\n",
      "472\tValidation loss: 0.324028\tBest loss: 0.321048\tAccuracy: 92.60%\n",
      "473\tValidation loss: 0.322897\tBest loss: 0.321048\tAccuracy: 92.70%\n",
      "474\tValidation loss: 0.324886\tBest loss: 0.321048\tAccuracy: 92.50%\n",
      "475\tValidation loss: 0.323310\tBest loss: 0.321048\tAccuracy: 92.60%\n",
      "476\tValidation loss: 0.323223\tBest loss: 0.321048\tAccuracy: 92.60%\n",
      "477\tValidation loss: 0.325015\tBest loss: 0.321048\tAccuracy: 92.60%\n",
      "478\tValidation loss: 0.322021\tBest loss: 0.321048\tAccuracy: 93.00%\n",
      "479\tValidation loss: 0.322216\tBest loss: 0.321048\tAccuracy: 92.80%\n",
      "480\tValidation loss: 0.323763\tBest loss: 0.321048\tAccuracy: 92.90%\n",
      "481\tValidation loss: 0.322189\tBest loss: 0.321048\tAccuracy: 92.70%\n",
      "482\tValidation loss: 0.322108\tBest loss: 0.321048\tAccuracy: 92.70%\n",
      "483\tValidation loss: 0.319501\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "484\tValidation loss: 0.320559\tBest loss: 0.319501\tAccuracy: 93.00%\n",
      "485\tValidation loss: 0.321852\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "486\tValidation loss: 0.321846\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "487\tValidation loss: 0.320965\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "488\tValidation loss: 0.321962\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "489\tValidation loss: 0.322341\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "490\tValidation loss: 0.323557\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "491\tValidation loss: 0.320280\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "492\tValidation loss: 0.320305\tBest loss: 0.319501\tAccuracy: 92.80%\n",
      "493\tValidation loss: 0.322059\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "494\tValidation loss: 0.320670\tBest loss: 0.319501\tAccuracy: 92.80%\n",
      "495\tValidation loss: 0.322016\tBest loss: 0.319501\tAccuracy: 92.50%\n",
      "496\tValidation loss: 0.320790\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "497\tValidation loss: 0.320523\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "498\tValidation loss: 0.322014\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "499\tValidation loss: 0.322065\tBest loss: 0.319501\tAccuracy: 92.80%\n",
      "500\tValidation loss: 0.321316\tBest loss: 0.319501\tAccuracy: 92.80%\n",
      "501\tValidation loss: 0.321576\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "502\tValidation loss: 0.319866\tBest loss: 0.319501\tAccuracy: 92.60%\n",
      "503\tValidation loss: 0.320069\tBest loss: 0.319501\tAccuracy: 92.70%\n",
      "504\tValidation loss: 0.318980\tBest loss: 0.318980\tAccuracy: 92.90%\n",
      "505\tValidation loss: 0.321018\tBest loss: 0.318980\tAccuracy: 92.60%\n",
      "506\tValidation loss: 0.319235\tBest loss: 0.318980\tAccuracy: 92.90%\n",
      "507\tValidation loss: 0.320751\tBest loss: 0.318980\tAccuracy: 92.90%\n",
      "508\tValidation loss: 0.320070\tBest loss: 0.318980\tAccuracy: 92.80%\n",
      "509\tValidation loss: 0.321332\tBest loss: 0.318980\tAccuracy: 92.70%\n",
      "510\tValidation loss: 0.319032\tBest loss: 0.318980\tAccuracy: 92.80%\n",
      "511\tValidation loss: 0.319273\tBest loss: 0.318980\tAccuracy: 92.90%\n",
      "512\tValidation loss: 0.319398\tBest loss: 0.318980\tAccuracy: 93.00%\n",
      "513\tValidation loss: 0.320018\tBest loss: 0.318980\tAccuracy: 92.70%\n",
      "514\tValidation loss: 0.319627\tBest loss: 0.318980\tAccuracy: 92.80%\n",
      "515\tValidation loss: 0.319685\tBest loss: 0.318980\tAccuracy: 92.90%\n",
      "516\tValidation loss: 0.318084\tBest loss: 0.318084\tAccuracy: 92.90%\n",
      "517\tValidation loss: 0.317486\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "518\tValidation loss: 0.319921\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "519\tValidation loss: 0.319595\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "520\tValidation loss: 0.320508\tBest loss: 0.317486\tAccuracy: 92.80%\n",
      "521\tValidation loss: 0.319442\tBest loss: 0.317486\tAccuracy: 92.80%\n",
      "522\tValidation loss: 0.319538\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "523\tValidation loss: 0.319376\tBest loss: 0.317486\tAccuracy: 92.80%\n",
      "524\tValidation loss: 0.318678\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "525\tValidation loss: 0.320625\tBest loss: 0.317486\tAccuracy: 92.60%\n",
      "526\tValidation loss: 0.318382\tBest loss: 0.317486\tAccuracy: 92.80%\n",
      "527\tValidation loss: 0.318244\tBest loss: 0.317486\tAccuracy: 92.80%\n",
      "528\tValidation loss: 0.318235\tBest loss: 0.317486\tAccuracy: 92.90%\n",
      "529\tValidation loss: 0.317246\tBest loss: 0.317246\tAccuracy: 92.70%\n",
      "530\tValidation loss: 0.319949\tBest loss: 0.317246\tAccuracy: 92.90%\n",
      "531\tValidation loss: 0.318711\tBest loss: 0.317246\tAccuracy: 93.10%\n",
      "532\tValidation loss: 0.318954\tBest loss: 0.317246\tAccuracy: 92.70%\n",
      "533\tValidation loss: 0.318063\tBest loss: 0.317246\tAccuracy: 92.90%\n",
      "534\tValidation loss: 0.318056\tBest loss: 0.317246\tAccuracy: 92.90%\n",
      "535\tValidation loss: 0.316983\tBest loss: 0.316983\tAccuracy: 93.00%\n",
      "536\tValidation loss: 0.317483\tBest loss: 0.316983\tAccuracy: 92.70%\n",
      "537\tValidation loss: 0.319458\tBest loss: 0.316983\tAccuracy: 92.70%\n",
      "538\tValidation loss: 0.318496\tBest loss: 0.316983\tAccuracy: 92.80%\n",
      "539\tValidation loss: 0.317340\tBest loss: 0.316983\tAccuracy: 93.00%\n",
      "540\tValidation loss: 0.315947\tBest loss: 0.315947\tAccuracy: 92.90%\n",
      "541\tValidation loss: 0.318217\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "542\tValidation loss: 0.319242\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "543\tValidation loss: 0.318482\tBest loss: 0.315947\tAccuracy: 92.70%\n",
      "544\tValidation loss: 0.318208\tBest loss: 0.315947\tAccuracy: 92.90%\n",
      "545\tValidation loss: 0.316476\tBest loss: 0.315947\tAccuracy: 92.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\tValidation loss: 0.317869\tBest loss: 0.315947\tAccuracy: 93.00%\n",
      "547\tValidation loss: 0.316882\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "548\tValidation loss: 0.317886\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "549\tValidation loss: 0.318050\tBest loss: 0.315947\tAccuracy: 92.90%\n",
      "550\tValidation loss: 0.316234\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "551\tValidation loss: 0.319751\tBest loss: 0.315947\tAccuracy: 92.80%\n",
      "552\tValidation loss: 0.317509\tBest loss: 0.315947\tAccuracy: 93.10%\n",
      "553\tValidation loss: 0.315347\tBest loss: 0.315347\tAccuracy: 92.80%\n",
      "554\tValidation loss: 0.318037\tBest loss: 0.315347\tAccuracy: 92.90%\n",
      "555\tValidation loss: 0.315729\tBest loss: 0.315347\tAccuracy: 93.10%\n",
      "556\tValidation loss: 0.316927\tBest loss: 0.315347\tAccuracy: 93.00%\n",
      "557\tValidation loss: 0.317614\tBest loss: 0.315347\tAccuracy: 93.20%\n",
      "558\tValidation loss: 0.317321\tBest loss: 0.315347\tAccuracy: 93.30%\n",
      "559\tValidation loss: 0.318790\tBest loss: 0.315347\tAccuracy: 92.90%\n",
      "560\tValidation loss: 0.318311\tBest loss: 0.315347\tAccuracy: 92.90%\n",
      "561\tValidation loss: 0.316522\tBest loss: 0.315347\tAccuracy: 93.10%\n",
      "562\tValidation loss: 0.316066\tBest loss: 0.315347\tAccuracy: 92.90%\n",
      "563\tValidation loss: 0.315123\tBest loss: 0.315123\tAccuracy: 92.90%\n",
      "564\tValidation loss: 0.315178\tBest loss: 0.315123\tAccuracy: 93.10%\n",
      "565\tValidation loss: 0.315770\tBest loss: 0.315123\tAccuracy: 93.10%\n",
      "566\tValidation loss: 0.316930\tBest loss: 0.315123\tAccuracy: 92.90%\n",
      "567\tValidation loss: 0.317525\tBest loss: 0.315123\tAccuracy: 93.10%\n",
      "568\tValidation loss: 0.315767\tBest loss: 0.315123\tAccuracy: 93.10%\n",
      "569\tValidation loss: 0.317804\tBest loss: 0.315123\tAccuracy: 93.00%\n",
      "570\tValidation loss: 0.315519\tBest loss: 0.315123\tAccuracy: 93.00%\n",
      "571\tValidation loss: 0.316291\tBest loss: 0.315123\tAccuracy: 92.90%\n",
      "572\tValidation loss: 0.315956\tBest loss: 0.315123\tAccuracy: 92.90%\n",
      "573\tValidation loss: 0.315568\tBest loss: 0.315123\tAccuracy: 93.10%\n",
      "574\tValidation loss: 0.317646\tBest loss: 0.315123\tAccuracy: 93.00%\n",
      "575\tValidation loss: 0.317385\tBest loss: 0.315123\tAccuracy: 93.00%\n",
      "576\tValidation loss: 0.315953\tBest loss: 0.315123\tAccuracy: 93.20%\n",
      "577\tValidation loss: 0.315656\tBest loss: 0.315123\tAccuracy: 93.00%\n",
      "578\tValidation loss: 0.317026\tBest loss: 0.315123\tAccuracy: 92.90%\n",
      "579\tValidation loss: 0.316828\tBest loss: 0.315123\tAccuracy: 93.20%\n",
      "580\tValidation loss: 0.314331\tBest loss: 0.314331\tAccuracy: 93.10%\n",
      "581\tValidation loss: 0.316308\tBest loss: 0.314331\tAccuracy: 93.10%\n",
      "582\tValidation loss: 0.317348\tBest loss: 0.314331\tAccuracy: 93.20%\n",
      "583\tValidation loss: 0.315194\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "584\tValidation loss: 0.316520\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "585\tValidation loss: 0.317186\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "586\tValidation loss: 0.316365\tBest loss: 0.314331\tAccuracy: 93.20%\n",
      "587\tValidation loss: 0.316001\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "588\tValidation loss: 0.316499\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "589\tValidation loss: 0.315789\tBest loss: 0.314331\tAccuracy: 93.00%\n",
      "590\tValidation loss: 0.314185\tBest loss: 0.314185\tAccuracy: 93.20%\n",
      "591\tValidation loss: 0.315776\tBest loss: 0.314185\tAccuracy: 93.40%\n",
      "592\tValidation loss: 0.315139\tBest loss: 0.314185\tAccuracy: 93.20%\n",
      "593\tValidation loss: 0.316414\tBest loss: 0.314185\tAccuracy: 93.10%\n",
      "594\tValidation loss: 0.315185\tBest loss: 0.314185\tAccuracy: 93.00%\n",
      "595\tValidation loss: 0.314611\tBest loss: 0.314185\tAccuracy: 93.20%\n",
      "596\tValidation loss: 0.314617\tBest loss: 0.314185\tAccuracy: 93.00%\n",
      "597\tValidation loss: 0.314794\tBest loss: 0.314185\tAccuracy: 93.10%\n",
      "598\tValidation loss: 0.314532\tBest loss: 0.314185\tAccuracy: 93.20%\n",
      "599\tValidation loss: 0.314036\tBest loss: 0.314036\tAccuracy: 93.20%\n",
      "600\tValidation loss: 0.315562\tBest loss: 0.314036\tAccuracy: 93.10%\n",
      "601\tValidation loss: 0.316827\tBest loss: 0.314036\tAccuracy: 92.90%\n",
      "602\tValidation loss: 0.315728\tBest loss: 0.314036\tAccuracy: 93.10%\n",
      "603\tValidation loss: 0.313978\tBest loss: 0.313978\tAccuracy: 93.00%\n",
      "604\tValidation loss: 0.315901\tBest loss: 0.313978\tAccuracy: 93.00%\n",
      "605\tValidation loss: 0.316997\tBest loss: 0.313978\tAccuracy: 93.30%\n",
      "606\tValidation loss: 0.315025\tBest loss: 0.313978\tAccuracy: 93.10%\n",
      "607\tValidation loss: 0.315347\tBest loss: 0.313978\tAccuracy: 93.10%\n",
      "608\tValidation loss: 0.315500\tBest loss: 0.313978\tAccuracy: 93.20%\n",
      "609\tValidation loss: 0.314003\tBest loss: 0.313978\tAccuracy: 92.90%\n",
      "610\tValidation loss: 0.314206\tBest loss: 0.313978\tAccuracy: 93.20%\n",
      "611\tValidation loss: 0.314905\tBest loss: 0.313978\tAccuracy: 93.20%\n",
      "612\tValidation loss: 0.315363\tBest loss: 0.313978\tAccuracy: 93.10%\n",
      "613\tValidation loss: 0.315904\tBest loss: 0.313978\tAccuracy: 93.10%\n",
      "614\tValidation loss: 0.316653\tBest loss: 0.313978\tAccuracy: 93.20%\n",
      "615\tValidation loss: 0.314145\tBest loss: 0.313978\tAccuracy: 93.00%\n",
      "616\tValidation loss: 0.316066\tBest loss: 0.313978\tAccuracy: 93.10%\n",
      "617\tValidation loss: 0.315164\tBest loss: 0.313978\tAccuracy: 93.20%\n",
      "618\tValidation loss: 0.313010\tBest loss: 0.313010\tAccuracy: 93.00%\n",
      "619\tValidation loss: 0.313576\tBest loss: 0.313010\tAccuracy: 93.20%\n",
      "620\tValidation loss: 0.313419\tBest loss: 0.313010\tAccuracy: 93.00%\n",
      "621\tValidation loss: 0.313249\tBest loss: 0.313010\tAccuracy: 93.20%\n",
      "622\tValidation loss: 0.314027\tBest loss: 0.313010\tAccuracy: 93.10%\n",
      "623\tValidation loss: 0.313656\tBest loss: 0.313010\tAccuracy: 93.00%\n",
      "624\tValidation loss: 0.315896\tBest loss: 0.313010\tAccuracy: 93.00%\n",
      "625\tValidation loss: 0.314251\tBest loss: 0.313010\tAccuracy: 93.10%\n",
      "626\tValidation loss: 0.314337\tBest loss: 0.313010\tAccuracy: 93.10%\n",
      "627\tValidation loss: 0.315100\tBest loss: 0.313010\tAccuracy: 93.10%\n",
      "628\tValidation loss: 0.313489\tBest loss: 0.313010\tAccuracy: 93.10%\n",
      "629\tValidation loss: 0.312837\tBest loss: 0.312837\tAccuracy: 93.20%\n",
      "630\tValidation loss: 0.312956\tBest loss: 0.312837\tAccuracy: 93.20%\n",
      "631\tValidation loss: 0.312792\tBest loss: 0.312792\tAccuracy: 93.30%\n",
      "632\tValidation loss: 0.315064\tBest loss: 0.312792\tAccuracy: 93.10%\n",
      "633\tValidation loss: 0.314538\tBest loss: 0.312792\tAccuracy: 93.10%\n",
      "634\tValidation loss: 0.314392\tBest loss: 0.312792\tAccuracy: 93.00%\n",
      "635\tValidation loss: 0.312421\tBest loss: 0.312421\tAccuracy: 93.20%\n",
      "636\tValidation loss: 0.314166\tBest loss: 0.312421\tAccuracy: 93.10%\n",
      "637\tValidation loss: 0.313536\tBest loss: 0.312421\tAccuracy: 93.10%\n",
      "638\tValidation loss: 0.312210\tBest loss: 0.312210\tAccuracy: 93.20%\n",
      "639\tValidation loss: 0.314595\tBest loss: 0.312210\tAccuracy: 93.00%\n",
      "640\tValidation loss: 0.314848\tBest loss: 0.312210\tAccuracy: 93.30%\n",
      "641\tValidation loss: 0.314985\tBest loss: 0.312210\tAccuracy: 93.20%\n",
      "642\tValidation loss: 0.314666\tBest loss: 0.312210\tAccuracy: 93.10%\n",
      "643\tValidation loss: 0.313196\tBest loss: 0.312210\tAccuracy: 92.90%\n",
      "644\tValidation loss: 0.313416\tBest loss: 0.312210\tAccuracy: 93.10%\n",
      "645\tValidation loss: 0.313517\tBest loss: 0.312210\tAccuracy: 93.00%\n",
      "646\tValidation loss: 0.313859\tBest loss: 0.312210\tAccuracy: 93.00%\n",
      "647\tValidation loss: 0.313942\tBest loss: 0.312210\tAccuracy: 93.20%\n",
      "648\tValidation loss: 0.312501\tBest loss: 0.312210\tAccuracy: 93.20%\n",
      "649\tValidation loss: 0.312158\tBest loss: 0.312158\tAccuracy: 93.10%\n",
      "650\tValidation loss: 0.312288\tBest loss: 0.312158\tAccuracy: 93.00%\n",
      "651\tValidation loss: 0.312225\tBest loss: 0.312158\tAccuracy: 93.30%\n",
      "652\tValidation loss: 0.313283\tBest loss: 0.312158\tAccuracy: 93.00%\n",
      "653\tValidation loss: 0.313184\tBest loss: 0.312158\tAccuracy: 93.10%\n",
      "654\tValidation loss: 0.314606\tBest loss: 0.312158\tAccuracy: 93.20%\n",
      "655\tValidation loss: 0.311901\tBest loss: 0.311901\tAccuracy: 93.30%\n",
      "656\tValidation loss: 0.312796\tBest loss: 0.311901\tAccuracy: 93.20%\n",
      "657\tValidation loss: 0.313229\tBest loss: 0.311901\tAccuracy: 93.10%\n",
      "658\tValidation loss: 0.313870\tBest loss: 0.311901\tAccuracy: 93.20%\n",
      "659\tValidation loss: 0.312817\tBest loss: 0.311901\tAccuracy: 93.20%\n",
      "660\tValidation loss: 0.313866\tBest loss: 0.311901\tAccuracy: 93.20%\n",
      "661\tValidation loss: 0.313074\tBest loss: 0.311901\tAccuracy: 93.30%\n",
      "662\tValidation loss: 0.313052\tBest loss: 0.311901\tAccuracy: 93.30%\n",
      "663\tValidation loss: 0.311415\tBest loss: 0.311415\tAccuracy: 93.20%\n",
      "664\tValidation loss: 0.312228\tBest loss: 0.311415\tAccuracy: 93.40%\n",
      "665\tValidation loss: 0.314328\tBest loss: 0.311415\tAccuracy: 93.10%\n",
      "666\tValidation loss: 0.314157\tBest loss: 0.311415\tAccuracy: 93.20%\n",
      "667\tValidation loss: 0.314125\tBest loss: 0.311415\tAccuracy: 93.10%\n",
      "668\tValidation loss: 0.312722\tBest loss: 0.311415\tAccuracy: 93.10%\n",
      "669\tValidation loss: 0.314351\tBest loss: 0.311415\tAccuracy: 93.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\tValidation loss: 0.314090\tBest loss: 0.311415\tAccuracy: 93.20%\n",
      "671\tValidation loss: 0.313013\tBest loss: 0.311415\tAccuracy: 93.10%\n",
      "672\tValidation loss: 0.311359\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "673\tValidation loss: 0.313960\tBest loss: 0.311359\tAccuracy: 93.30%\n",
      "674\tValidation loss: 0.313411\tBest loss: 0.311359\tAccuracy: 93.40%\n",
      "675\tValidation loss: 0.313039\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "676\tValidation loss: 0.313002\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "677\tValidation loss: 0.313597\tBest loss: 0.311359\tAccuracy: 93.30%\n",
      "678\tValidation loss: 0.312925\tBest loss: 0.311359\tAccuracy: 93.30%\n",
      "679\tValidation loss: 0.312469\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "680\tValidation loss: 0.311845\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "681\tValidation loss: 0.312671\tBest loss: 0.311359\tAccuracy: 93.10%\n",
      "682\tValidation loss: 0.311395\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "683\tValidation loss: 0.312785\tBest loss: 0.311359\tAccuracy: 93.10%\n",
      "684\tValidation loss: 0.311997\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "685\tValidation loss: 0.313627\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "686\tValidation loss: 0.312847\tBest loss: 0.311359\tAccuracy: 93.40%\n",
      "687\tValidation loss: 0.312237\tBest loss: 0.311359\tAccuracy: 93.40%\n",
      "688\tValidation loss: 0.312624\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "689\tValidation loss: 0.311624\tBest loss: 0.311359\tAccuracy: 93.40%\n",
      "690\tValidation loss: 0.313610\tBest loss: 0.311359\tAccuracy: 93.10%\n",
      "691\tValidation loss: 0.311888\tBest loss: 0.311359\tAccuracy: 93.40%\n",
      "692\tValidation loss: 0.313062\tBest loss: 0.311359\tAccuracy: 93.20%\n",
      "693\tValidation loss: 0.313101\tBest loss: 0.311359\tAccuracy: 93.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.5min\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.307008\tBest loss: 1.307008\tAccuracy: 61.00%\n",
      "1\tValidation loss: 0.979664\tBest loss: 0.979664\tAccuracy: 73.90%\n",
      "2\tValidation loss: 0.866476\tBest loss: 0.866476\tAccuracy: 77.20%\n",
      "3\tValidation loss: 0.729323\tBest loss: 0.729323\tAccuracy: 77.80%\n",
      "4\tValidation loss: 0.695330\tBest loss: 0.695330\tAccuracy: 80.80%\n",
      "5\tValidation loss: 0.768602\tBest loss: 0.695330\tAccuracy: 78.50%\n",
      "6\tValidation loss: 0.684378\tBest loss: 0.684378\tAccuracy: 80.30%\n",
      "7\tValidation loss: 0.965664\tBest loss: 0.684378\tAccuracy: 76.60%\n",
      "8\tValidation loss: 0.755805\tBest loss: 0.684378\tAccuracy: 79.90%\n",
      "9\tValidation loss: 0.797884\tBest loss: 0.684378\tAccuracy: 79.50%\n",
      "10\tValidation loss: 0.704015\tBest loss: 0.684378\tAccuracy: 83.80%\n",
      "11\tValidation loss: 0.740870\tBest loss: 0.684378\tAccuracy: 82.20%\n",
      "12\tValidation loss: 0.668492\tBest loss: 0.668492\tAccuracy: 80.70%\n",
      "13\tValidation loss: 0.804780\tBest loss: 0.668492\tAccuracy: 80.50%\n",
      "14\tValidation loss: 0.821262\tBest loss: 0.668492\tAccuracy: 81.00%\n",
      "15\tValidation loss: 0.652838\tBest loss: 0.652838\tAccuracy: 85.00%\n",
      "16\tValidation loss: 0.943953\tBest loss: 0.652838\tAccuracy: 79.10%\n",
      "17\tValidation loss: 0.862501\tBest loss: 0.652838\tAccuracy: 78.50%\n",
      "18\tValidation loss: 0.892828\tBest loss: 0.652838\tAccuracy: 79.40%\n",
      "19\tValidation loss: 0.806532\tBest loss: 0.652838\tAccuracy: 82.40%\n",
      "20\tValidation loss: 1.469126\tBest loss: 0.652838\tAccuracy: 75.10%\n",
      "21\tValidation loss: 0.736244\tBest loss: 0.652838\tAccuracy: 83.20%\n",
      "22\tValidation loss: 0.851633\tBest loss: 0.652838\tAccuracy: 83.90%\n",
      "23\tValidation loss: 1.464212\tBest loss: 0.652838\tAccuracy: 74.20%\n",
      "24\tValidation loss: 1.284622\tBest loss: 0.652838\tAccuracy: 78.00%\n",
      "25\tValidation loss: 1.110623\tBest loss: 0.652838\tAccuracy: 80.30%\n",
      "26\tValidation loss: 0.956974\tBest loss: 0.652838\tAccuracy: 82.40%\n",
      "27\tValidation loss: 1.381376\tBest loss: 0.652838\tAccuracy: 76.00%\n",
      "28\tValidation loss: 0.836851\tBest loss: 0.652838\tAccuracy: 82.50%\n",
      "29\tValidation loss: 1.241141\tBest loss: 0.652838\tAccuracy: 82.30%\n",
      "30\tValidation loss: 1.940903\tBest loss: 0.652838\tAccuracy: 77.30%\n",
      "31\tValidation loss: 1.560012\tBest loss: 0.652838\tAccuracy: 80.00%\n",
      "32\tValidation loss: 1.431729\tBest loss: 0.652838\tAccuracy: 81.60%\n",
      "33\tValidation loss: 1.129043\tBest loss: 0.652838\tAccuracy: 80.70%\n",
      "34\tValidation loss: 1.734626\tBest loss: 0.652838\tAccuracy: 74.80%\n",
      "35\tValidation loss: 2.473196\tBest loss: 0.652838\tAccuracy: 70.80%\n",
      "36\tValidation loss: 1.027866\tBest loss: 0.652838\tAccuracy: 83.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=  14.0s\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.494144\tBest loss: 1.494144\tAccuracy: 55.80%\n",
      "1\tValidation loss: 0.947157\tBest loss: 0.947157\tAccuracy: 70.70%\n",
      "2\tValidation loss: 0.853839\tBest loss: 0.853839\tAccuracy: 74.30%\n",
      "3\tValidation loss: 0.767714\tBest loss: 0.767714\tAccuracy: 77.10%\n",
      "4\tValidation loss: 0.829404\tBest loss: 0.767714\tAccuracy: 74.70%\n",
      "5\tValidation loss: 0.776878\tBest loss: 0.767714\tAccuracy: 76.80%\n",
      "6\tValidation loss: 0.828600\tBest loss: 0.767714\tAccuracy: 78.60%\n",
      "7\tValidation loss: 0.918460\tBest loss: 0.767714\tAccuracy: 76.60%\n",
      "8\tValidation loss: 0.757777\tBest loss: 0.757777\tAccuracy: 79.60%\n",
      "9\tValidation loss: 0.848858\tBest loss: 0.757777\tAccuracy: 79.30%\n",
      "10\tValidation loss: 0.797109\tBest loss: 0.757777\tAccuracy: 80.10%\n",
      "11\tValidation loss: 0.676929\tBest loss: 0.676929\tAccuracy: 83.30%\n",
      "12\tValidation loss: 0.991477\tBest loss: 0.676929\tAccuracy: 78.60%\n",
      "13\tValidation loss: 1.028057\tBest loss: 0.676929\tAccuracy: 76.90%\n",
      "14\tValidation loss: 1.031433\tBest loss: 0.676929\tAccuracy: 80.00%\n",
      "15\tValidation loss: 0.842176\tBest loss: 0.676929\tAccuracy: 83.70%\n",
      "16\tValidation loss: 1.065929\tBest loss: 0.676929\tAccuracy: 78.80%\n",
      "17\tValidation loss: 1.064259\tBest loss: 0.676929\tAccuracy: 79.40%\n",
      "18\tValidation loss: 1.074920\tBest loss: 0.676929\tAccuracy: 77.90%\n",
      "19\tValidation loss: 1.317703\tBest loss: 0.676929\tAccuracy: 75.70%\n",
      "20\tValidation loss: 1.083322\tBest loss: 0.676929\tAccuracy: 79.10%\n",
      "21\tValidation loss: 0.962695\tBest loss: 0.676929\tAccuracy: 80.90%\n",
      "22\tValidation loss: 0.976439\tBest loss: 0.676929\tAccuracy: 82.10%\n",
      "23\tValidation loss: 0.891473\tBest loss: 0.676929\tAccuracy: 83.50%\n",
      "24\tValidation loss: 2.168499\tBest loss: 0.676929\tAccuracy: 71.30%\n",
      "25\tValidation loss: 1.248605\tBest loss: 0.676929\tAccuracy: 77.30%\n",
      "26\tValidation loss: 1.062385\tBest loss: 0.676929\tAccuracy: 79.60%\n",
      "27\tValidation loss: 0.861798\tBest loss: 0.676929\tAccuracy: 84.10%\n",
      "28\tValidation loss: 1.039861\tBest loss: 0.676929\tAccuracy: 81.40%\n",
      "29\tValidation loss: 1.927081\tBest loss: 0.676929\tAccuracy: 76.90%\n",
      "30\tValidation loss: 1.627354\tBest loss: 0.676929\tAccuracy: 74.90%\n",
      "31\tValidation loss: 0.953207\tBest loss: 0.676929\tAccuracy: 83.30%\n",
      "32\tValidation loss: 0.752306\tBest loss: 0.676929\tAccuracy: 86.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=  12.5s\n",
      "[CV] batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.309452\tBest loss: 1.309452\tAccuracy: 61.40%\n",
      "1\tValidation loss: 1.067725\tBest loss: 1.067725\tAccuracy: 69.50%\n",
      "2\tValidation loss: 0.973536\tBest loss: 0.973536\tAccuracy: 72.90%\n",
      "3\tValidation loss: 1.039473\tBest loss: 0.973536\tAccuracy: 73.60%\n",
      "4\tValidation loss: 0.822475\tBest loss: 0.822475\tAccuracy: 77.10%\n",
      "5\tValidation loss: 0.738732\tBest loss: 0.738732\tAccuracy: 80.20%\n",
      "6\tValidation loss: 0.644390\tBest loss: 0.644390\tAccuracy: 83.00%\n",
      "7\tValidation loss: 0.906398\tBest loss: 0.644390\tAccuracy: 79.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\tValidation loss: 0.928182\tBest loss: 0.644390\tAccuracy: 76.00%\n",
      "9\tValidation loss: 0.889795\tBest loss: 0.644390\tAccuracy: 79.90%\n",
      "10\tValidation loss: 1.019754\tBest loss: 0.644390\tAccuracy: 75.80%\n",
      "11\tValidation loss: 0.856349\tBest loss: 0.644390\tAccuracy: 79.80%\n",
      "12\tValidation loss: 0.976426\tBest loss: 0.644390\tAccuracy: 77.80%\n",
      "13\tValidation loss: 0.649950\tBest loss: 0.644390\tAccuracy: 84.50%\n",
      "14\tValidation loss: 0.941694\tBest loss: 0.644390\tAccuracy: 80.20%\n",
      "15\tValidation loss: 0.900512\tBest loss: 0.644390\tAccuracy: 81.30%\n",
      "16\tValidation loss: 0.948099\tBest loss: 0.644390\tAccuracy: 81.00%\n",
      "17\tValidation loss: 1.460012\tBest loss: 0.644390\tAccuracy: 77.40%\n",
      "18\tValidation loss: 0.819239\tBest loss: 0.644390\tAccuracy: 82.10%\n",
      "19\tValidation loss: 0.907184\tBest loss: 0.644390\tAccuracy: 86.10%\n",
      "20\tValidation loss: 1.063059\tBest loss: 0.644390\tAccuracy: 83.30%\n",
      "21\tValidation loss: 0.777340\tBest loss: 0.644390\tAccuracy: 84.30%\n",
      "22\tValidation loss: 0.947032\tBest loss: 0.644390\tAccuracy: 83.80%\n",
      "23\tValidation loss: 1.242045\tBest loss: 0.644390\tAccuracy: 79.30%\n",
      "24\tValidation loss: 1.353077\tBest loss: 0.644390\tAccuracy: 78.60%\n",
      "25\tValidation loss: 1.007381\tBest loss: 0.644390\tAccuracy: 77.90%\n",
      "26\tValidation loss: 1.841781\tBest loss: 0.644390\tAccuracy: 81.40%\n",
      "27\tValidation loss: 1.111706\tBest loss: 0.644390\tAccuracy: 80.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=  10.4s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.299143\tBest loss: 2.299143\tAccuracy: 42.40%\n",
      "1\tValidation loss: 1.233034\tBest loss: 1.233034\tAccuracy: 63.90%\n",
      "2\tValidation loss: 1.167487\tBest loss: 1.167487\tAccuracy: 67.50%\n",
      "3\tValidation loss: 0.819656\tBest loss: 0.819656\tAccuracy: 76.10%\n",
      "4\tValidation loss: 0.891801\tBest loss: 0.819656\tAccuracy: 77.50%\n",
      "5\tValidation loss: 0.773243\tBest loss: 0.773243\tAccuracy: 80.80%\n",
      "6\tValidation loss: 0.744838\tBest loss: 0.744838\tAccuracy: 80.00%\n",
      "7\tValidation loss: 0.949090\tBest loss: 0.744838\tAccuracy: 80.30%\n",
      "8\tValidation loss: 1.036746\tBest loss: 0.744838\tAccuracy: 80.70%\n",
      "9\tValidation loss: 1.115552\tBest loss: 0.744838\tAccuracy: 78.90%\n",
      "10\tValidation loss: 1.105695\tBest loss: 0.744838\tAccuracy: 80.20%\n",
      "11\tValidation loss: 0.815382\tBest loss: 0.744838\tAccuracy: 84.00%\n",
      "12\tValidation loss: 0.703466\tBest loss: 0.703466\tAccuracy: 87.00%\n",
      "13\tValidation loss: 0.789349\tBest loss: 0.703466\tAccuracy: 86.00%\n",
      "14\tValidation loss: 0.734982\tBest loss: 0.703466\tAccuracy: 84.70%\n",
      "15\tValidation loss: 1.769490\tBest loss: 0.703466\tAccuracy: 81.30%\n",
      "16\tValidation loss: 0.683261\tBest loss: 0.683261\tAccuracy: 88.10%\n",
      "17\tValidation loss: 0.956764\tBest loss: 0.683261\tAccuracy: 85.30%\n",
      "18\tValidation loss: 1.482756\tBest loss: 0.683261\tAccuracy: 86.00%\n",
      "19\tValidation loss: 0.949524\tBest loss: 0.683261\tAccuracy: 85.30%\n",
      "20\tValidation loss: 1.214941\tBest loss: 0.683261\tAccuracy: 85.30%\n",
      "21\tValidation loss: 1.757486\tBest loss: 0.683261\tAccuracy: 83.00%\n",
      "22\tValidation loss: 0.884703\tBest loss: 0.683261\tAccuracy: 86.30%\n",
      "23\tValidation loss: 1.252816\tBest loss: 0.683261\tAccuracy: 87.10%\n",
      "24\tValidation loss: 1.495974\tBest loss: 0.683261\tAccuracy: 85.30%\n",
      "25\tValidation loss: 1.209837\tBest loss: 0.683261\tAccuracy: 86.00%\n",
      "26\tValidation loss: 2.495144\tBest loss: 0.683261\tAccuracy: 81.80%\n",
      "27\tValidation loss: 1.038436\tBest loss: 0.683261\tAccuracy: 86.50%\n",
      "28\tValidation loss: 1.449097\tBest loss: 0.683261\tAccuracy: 84.80%\n",
      "29\tValidation loss: 2.721950\tBest loss: 0.683261\tAccuracy: 81.00%\n",
      "30\tValidation loss: 0.987922\tBest loss: 0.683261\tAccuracy: 87.40%\n",
      "31\tValidation loss: 1.035394\tBest loss: 0.683261\tAccuracy: 89.10%\n",
      "32\tValidation loss: 1.688880\tBest loss: 0.683261\tAccuracy: 83.90%\n",
      "33\tValidation loss: 1.756384\tBest loss: 0.683261\tAccuracy: 87.80%\n",
      "34\tValidation loss: 1.827872\tBest loss: 0.683261\tAccuracy: 88.70%\n",
      "35\tValidation loss: 1.725213\tBest loss: 0.683261\tAccuracy: 86.60%\n",
      "36\tValidation loss: 1.669562\tBest loss: 0.683261\tAccuracy: 87.50%\n",
      "37\tValidation loss: 2.541526\tBest loss: 0.683261\tAccuracy: 85.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=  11.0s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.372156\tBest loss: 2.372156\tAccuracy: 41.50%\n",
      "1\tValidation loss: 1.305228\tBest loss: 1.305228\tAccuracy: 67.30%\n",
      "2\tValidation loss: 2.048104\tBest loss: 1.305228\tAccuracy: 59.20%\n",
      "3\tValidation loss: 1.191095\tBest loss: 1.191095\tAccuracy: 69.80%\n",
      "4\tValidation loss: 1.499747\tBest loss: 1.191095\tAccuracy: 70.00%\n",
      "5\tValidation loss: 0.727242\tBest loss: 0.727242\tAccuracy: 82.30%\n",
      "6\tValidation loss: 1.455806\tBest loss: 0.727242\tAccuracy: 71.30%\n",
      "7\tValidation loss: 0.981821\tBest loss: 0.727242\tAccuracy: 79.90%\n",
      "8\tValidation loss: 0.891993\tBest loss: 0.727242\tAccuracy: 81.00%\n",
      "9\tValidation loss: 2.991033\tBest loss: 0.727242\tAccuracy: 76.10%\n",
      "10\tValidation loss: 0.762001\tBest loss: 0.727242\tAccuracy: 83.90%\n",
      "11\tValidation loss: 1.262432\tBest loss: 0.727242\tAccuracy: 81.00%\n",
      "12\tValidation loss: 1.052594\tBest loss: 0.727242\tAccuracy: 83.50%\n",
      "13\tValidation loss: 0.719989\tBest loss: 0.719989\tAccuracy: 84.10%\n",
      "14\tValidation loss: 1.435490\tBest loss: 0.719989\tAccuracy: 81.30%\n",
      "15\tValidation loss: 1.520632\tBest loss: 0.719989\tAccuracy: 81.80%\n",
      "16\tValidation loss: 1.182228\tBest loss: 0.719989\tAccuracy: 84.90%\n",
      "17\tValidation loss: 1.754739\tBest loss: 0.719989\tAccuracy: 83.40%\n",
      "18\tValidation loss: 1.422925\tBest loss: 0.719989\tAccuracy: 81.70%\n",
      "19\tValidation loss: 1.634938\tBest loss: 0.719989\tAccuracy: 84.50%\n",
      "20\tValidation loss: 1.146152\tBest loss: 0.719989\tAccuracy: 87.50%\n",
      "21\tValidation loss: 2.155529\tBest loss: 0.719989\tAccuracy: 82.40%\n",
      "22\tValidation loss: 1.460640\tBest loss: 0.719989\tAccuracy: 83.30%\n",
      "23\tValidation loss: 1.343696\tBest loss: 0.719989\tAccuracy: 86.50%\n",
      "24\tValidation loss: 1.365232\tBest loss: 0.719989\tAccuracy: 84.90%\n",
      "25\tValidation loss: 1.942064\tBest loss: 0.719989\tAccuracy: 83.40%\n",
      "26\tValidation loss: 3.739454\tBest loss: 0.719989\tAccuracy: 81.90%\n",
      "27\tValidation loss: 1.224662\tBest loss: 0.719989\tAccuracy: 86.30%\n",
      "28\tValidation loss: 1.254289\tBest loss: 0.719989\tAccuracy: 87.10%\n",
      "29\tValidation loss: 1.806125\tBest loss: 0.719989\tAccuracy: 84.90%\n",
      "30\tValidation loss: 2.790505\tBest loss: 0.719989\tAccuracy: 85.80%\n",
      "31\tValidation loss: 1.948571\tBest loss: 0.719989\tAccuracy: 85.40%\n",
      "32\tValidation loss: 1.699150\tBest loss: 0.719989\tAccuracy: 86.90%\n",
      "33\tValidation loss: 2.230326\tBest loss: 0.719989\tAccuracy: 83.50%\n",
      "34\tValidation loss: 1.955367\tBest loss: 0.719989\tAccuracy: 88.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   9.7s\n",
      "[CV] batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.945091\tBest loss: 1.945091\tAccuracy: 44.40%\n",
      "1\tValidation loss: 1.557905\tBest loss: 1.557905\tAccuracy: 62.00%\n",
      "2\tValidation loss: 0.921905\tBest loss: 0.921905\tAccuracy: 74.10%\n",
      "3\tValidation loss: 1.024560\tBest loss: 0.921905\tAccuracy: 74.60%\n",
      "4\tValidation loss: 0.852121\tBest loss: 0.852121\tAccuracy: 78.50%\n",
      "5\tValidation loss: 0.766588\tBest loss: 0.766588\tAccuracy: 80.40%\n",
      "6\tValidation loss: 1.263883\tBest loss: 0.766588\tAccuracy: 76.30%\n",
      "7\tValidation loss: 0.905392\tBest loss: 0.766588\tAccuracy: 81.30%\n",
      "8\tValidation loss: 0.930322\tBest loss: 0.766588\tAccuracy: 82.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 0.932319\tBest loss: 0.766588\tAccuracy: 84.10%\n",
      "10\tValidation loss: 0.854833\tBest loss: 0.766588\tAccuracy: 82.10%\n",
      "11\tValidation loss: 0.864145\tBest loss: 0.766588\tAccuracy: 81.70%\n",
      "12\tValidation loss: 1.115892\tBest loss: 0.766588\tAccuracy: 84.40%\n",
      "13\tValidation loss: 1.427143\tBest loss: 0.766588\tAccuracy: 84.50%\n",
      "14\tValidation loss: 1.094851\tBest loss: 0.766588\tAccuracy: 85.30%\n",
      "15\tValidation loss: 1.529423\tBest loss: 0.766588\tAccuracy: 83.80%\n",
      "16\tValidation loss: 0.849219\tBest loss: 0.766588\tAccuracy: 86.40%\n",
      "17\tValidation loss: 1.468795\tBest loss: 0.766588\tAccuracy: 82.70%\n",
      "18\tValidation loss: 1.480123\tBest loss: 0.766588\tAccuracy: 83.80%\n",
      "19\tValidation loss: 1.225886\tBest loss: 0.766588\tAccuracy: 85.80%\n",
      "20\tValidation loss: 1.976053\tBest loss: 0.766588\tAccuracy: 84.00%\n",
      "21\tValidation loss: 1.856239\tBest loss: 0.766588\tAccuracy: 83.00%\n",
      "22\tValidation loss: 1.515156\tBest loss: 0.766588\tAccuracy: 87.10%\n",
      "23\tValidation loss: 0.733969\tBest loss: 0.733969\tAccuracy: 88.60%\n",
      "24\tValidation loss: 1.530444\tBest loss: 0.733969\tAccuracy: 82.70%\n",
      "25\tValidation loss: 1.664111\tBest loss: 0.733969\tAccuracy: 84.70%\n",
      "26\tValidation loss: 1.903849\tBest loss: 0.733969\tAccuracy: 85.60%\n",
      "27\tValidation loss: 0.813067\tBest loss: 0.733969\tAccuracy: 88.70%\n",
      "28\tValidation loss: 1.674153\tBest loss: 0.733969\tAccuracy: 86.50%\n",
      "29\tValidation loss: 1.383056\tBest loss: 0.733969\tAccuracy: 86.50%\n",
      "30\tValidation loss: 1.546261\tBest loss: 0.733969\tAccuracy: 88.00%\n",
      "31\tValidation loss: 2.113546\tBest loss: 0.733969\tAccuracy: 86.90%\n",
      "32\tValidation loss: 2.135007\tBest loss: 0.733969\tAccuracy: 87.90%\n",
      "33\tValidation loss: 1.442162\tBest loss: 0.733969\tAccuracy: 85.60%\n",
      "34\tValidation loss: 1.450814\tBest loss: 0.733969\tAccuracy: 87.70%\n",
      "35\tValidation loss: 2.667537\tBest loss: 0.733969\tAccuracy: 83.70%\n",
      "36\tValidation loss: 3.920418\tBest loss: 0.733969\tAccuracy: 84.50%\n",
      "37\tValidation loss: 2.095923\tBest loss: 0.733969\tAccuracy: 89.20%\n",
      "38\tValidation loss: 2.114888\tBest loss: 0.733969\tAccuracy: 86.80%\n",
      "39\tValidation loss: 2.662969\tBest loss: 0.733969\tAccuracy: 87.30%\n",
      "40\tValidation loss: 2.640245\tBest loss: 0.733969\tAccuracy: 88.90%\n",
      "41\tValidation loss: 2.716517\tBest loss: 0.733969\tAccuracy: 87.60%\n",
      "42\tValidation loss: 2.687269\tBest loss: 0.733969\tAccuracy: 87.70%\n",
      "43\tValidation loss: 4.804862\tBest loss: 0.733969\tAccuracy: 84.50%\n",
      "44\tValidation loss: 5.699444\tBest loss: 0.733969\tAccuracy: 84.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=250, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=  12.8s\n",
      "[CV] batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.295824\tBest loss: 2.295824\tAccuracy: 43.50%\n",
      "1\tValidation loss: 1.837005\tBest loss: 1.837005\tAccuracy: 53.90%\n",
      "2\tValidation loss: 1.494088\tBest loss: 1.494088\tAccuracy: 64.60%\n",
      "3\tValidation loss: 1.393192\tBest loss: 1.393192\tAccuracy: 65.80%\n",
      "4\tValidation loss: 1.228181\tBest loss: 1.228181\tAccuracy: 70.30%\n",
      "5\tValidation loss: 1.119245\tBest loss: 1.119245\tAccuracy: 72.70%\n",
      "6\tValidation loss: 1.033249\tBest loss: 1.033249\tAccuracy: 75.50%\n",
      "7\tValidation loss: 0.984066\tBest loss: 0.984066\tAccuracy: 75.30%\n",
      "8\tValidation loss: 0.953069\tBest loss: 0.953069\tAccuracy: 75.90%\n",
      "9\tValidation loss: 0.898839\tBest loss: 0.898839\tAccuracy: 78.60%\n",
      "10\tValidation loss: 0.856097\tBest loss: 0.856097\tAccuracy: 78.30%\n",
      "11\tValidation loss: 0.813331\tBest loss: 0.813331\tAccuracy: 81.20%\n",
      "12\tValidation loss: 0.799742\tBest loss: 0.799742\tAccuracy: 81.40%\n",
      "13\tValidation loss: 0.764984\tBest loss: 0.764984\tAccuracy: 81.50%\n",
      "14\tValidation loss: 0.761529\tBest loss: 0.761529\tAccuracy: 81.90%\n",
      "15\tValidation loss: 0.735402\tBest loss: 0.735402\tAccuracy: 82.90%\n",
      "16\tValidation loss: 0.704948\tBest loss: 0.704948\tAccuracy: 82.90%\n",
      "17\tValidation loss: 0.690958\tBest loss: 0.690958\tAccuracy: 84.70%\n",
      "18\tValidation loss: 0.682331\tBest loss: 0.682331\tAccuracy: 84.00%\n",
      "19\tValidation loss: 0.663218\tBest loss: 0.663218\tAccuracy: 83.70%\n",
      "20\tValidation loss: 0.647506\tBest loss: 0.647506\tAccuracy: 85.10%\n",
      "21\tValidation loss: 0.628303\tBest loss: 0.628303\tAccuracy: 85.80%\n",
      "22\tValidation loss: 0.639024\tBest loss: 0.628303\tAccuracy: 85.00%\n",
      "23\tValidation loss: 0.621361\tBest loss: 0.621361\tAccuracy: 85.00%\n",
      "24\tValidation loss: 0.611899\tBest loss: 0.611899\tAccuracy: 86.00%\n",
      "25\tValidation loss: 0.596274\tBest loss: 0.596274\tAccuracy: 86.50%\n",
      "26\tValidation loss: 0.595615\tBest loss: 0.595615\tAccuracy: 85.90%\n",
      "27\tValidation loss: 0.593621\tBest loss: 0.593621\tAccuracy: 86.40%\n",
      "28\tValidation loss: 0.576991\tBest loss: 0.576991\tAccuracy: 86.30%\n",
      "29\tValidation loss: 0.577326\tBest loss: 0.576991\tAccuracy: 86.50%\n",
      "30\tValidation loss: 0.578315\tBest loss: 0.576991\tAccuracy: 87.20%\n",
      "31\tValidation loss: 0.555141\tBest loss: 0.555141\tAccuracy: 87.20%\n",
      "32\tValidation loss: 0.547809\tBest loss: 0.547809\tAccuracy: 87.10%\n",
      "33\tValidation loss: 0.542244\tBest loss: 0.542244\tAccuracy: 88.00%\n",
      "34\tValidation loss: 0.543233\tBest loss: 0.542244\tAccuracy: 87.10%\n",
      "35\tValidation loss: 0.540501\tBest loss: 0.540501\tAccuracy: 86.40%\n",
      "36\tValidation loss: 0.529870\tBest loss: 0.529870\tAccuracy: 87.50%\n",
      "37\tValidation loss: 0.531962\tBest loss: 0.529870\tAccuracy: 88.50%\n",
      "38\tValidation loss: 0.525188\tBest loss: 0.525188\tAccuracy: 88.00%\n",
      "39\tValidation loss: 0.513618\tBest loss: 0.513618\tAccuracy: 87.90%\n",
      "40\tValidation loss: 0.533226\tBest loss: 0.513618\tAccuracy: 87.60%\n",
      "41\tValidation loss: 0.515473\tBest loss: 0.513618\tAccuracy: 88.40%\n",
      "42\tValidation loss: 0.507556\tBest loss: 0.507556\tAccuracy: 87.30%\n",
      "43\tValidation loss: 0.492307\tBest loss: 0.492307\tAccuracy: 89.00%\n",
      "44\tValidation loss: 0.506756\tBest loss: 0.492307\tAccuracy: 87.70%\n",
      "45\tValidation loss: 0.480845\tBest loss: 0.480845\tAccuracy: 89.40%\n",
      "46\tValidation loss: 0.488936\tBest loss: 0.480845\tAccuracy: 88.60%\n",
      "47\tValidation loss: 0.481407\tBest loss: 0.480845\tAccuracy: 88.50%\n",
      "48\tValidation loss: 0.483414\tBest loss: 0.480845\tAccuracy: 88.90%\n",
      "49\tValidation loss: 0.489960\tBest loss: 0.480845\tAccuracy: 88.80%\n",
      "50\tValidation loss: 0.485688\tBest loss: 0.480845\tAccuracy: 87.80%\n",
      "51\tValidation loss: 0.485166\tBest loss: 0.480845\tAccuracy: 89.00%\n",
      "52\tValidation loss: 0.473359\tBest loss: 0.473359\tAccuracy: 88.50%\n",
      "53\tValidation loss: 0.473057\tBest loss: 0.473057\tAccuracy: 90.00%\n",
      "54\tValidation loss: 0.458258\tBest loss: 0.458258\tAccuracy: 89.00%\n",
      "55\tValidation loss: 0.459027\tBest loss: 0.458258\tAccuracy: 89.60%\n",
      "56\tValidation loss: 0.467848\tBest loss: 0.458258\tAccuracy: 89.60%\n",
      "57\tValidation loss: 0.456830\tBest loss: 0.456830\tAccuracy: 89.70%\n",
      "58\tValidation loss: 0.462554\tBest loss: 0.456830\tAccuracy: 88.30%\n",
      "59\tValidation loss: 0.455211\tBest loss: 0.455211\tAccuracy: 89.80%\n",
      "60\tValidation loss: 0.450395\tBest loss: 0.450395\tAccuracy: 89.70%\n",
      "61\tValidation loss: 0.454905\tBest loss: 0.450395\tAccuracy: 89.50%\n",
      "62\tValidation loss: 0.442009\tBest loss: 0.442009\tAccuracy: 89.30%\n",
      "63\tValidation loss: 0.443616\tBest loss: 0.442009\tAccuracy: 89.70%\n",
      "64\tValidation loss: 0.439156\tBest loss: 0.439156\tAccuracy: 89.40%\n",
      "65\tValidation loss: 0.438006\tBest loss: 0.438006\tAccuracy: 89.90%\n",
      "66\tValidation loss: 0.434343\tBest loss: 0.434343\tAccuracy: 89.60%\n",
      "67\tValidation loss: 0.438273\tBest loss: 0.434343\tAccuracy: 89.40%\n",
      "68\tValidation loss: 0.436634\tBest loss: 0.434343\tAccuracy: 88.90%\n",
      "69\tValidation loss: 0.427082\tBest loss: 0.427082\tAccuracy: 89.80%\n",
      "70\tValidation loss: 0.432495\tBest loss: 0.427082\tAccuracy: 90.00%\n",
      "71\tValidation loss: 0.430130\tBest loss: 0.427082\tAccuracy: 89.80%\n",
      "72\tValidation loss: 0.424756\tBest loss: 0.424756\tAccuracy: 89.90%\n",
      "73\tValidation loss: 0.419374\tBest loss: 0.419374\tAccuracy: 90.10%\n",
      "74\tValidation loss: 0.439149\tBest loss: 0.419374\tAccuracy: 89.30%\n",
      "75\tValidation loss: 0.420705\tBest loss: 0.419374\tAccuracy: 89.70%\n",
      "76\tValidation loss: 0.419663\tBest loss: 0.419374\tAccuracy: 90.00%\n",
      "77\tValidation loss: 0.432089\tBest loss: 0.419374\tAccuracy: 89.50%\n",
      "78\tValidation loss: 0.413664\tBest loss: 0.413664\tAccuracy: 89.60%\n",
      "79\tValidation loss: 0.420169\tBest loss: 0.413664\tAccuracy: 89.90%\n",
      "80\tValidation loss: 0.421002\tBest loss: 0.413664\tAccuracy: 90.00%\n",
      "81\tValidation loss: 0.411569\tBest loss: 0.411569\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\tValidation loss: 0.423369\tBest loss: 0.411569\tAccuracy: 90.60%\n",
      "83\tValidation loss: 0.400687\tBest loss: 0.400687\tAccuracy: 90.20%\n",
      "84\tValidation loss: 0.405971\tBest loss: 0.400687\tAccuracy: 90.60%\n",
      "85\tValidation loss: 0.401615\tBest loss: 0.400687\tAccuracy: 90.90%\n",
      "86\tValidation loss: 0.403759\tBest loss: 0.400687\tAccuracy: 90.60%\n",
      "87\tValidation loss: 0.406872\tBest loss: 0.400687\tAccuracy: 90.30%\n",
      "88\tValidation loss: 0.404180\tBest loss: 0.400687\tAccuracy: 90.40%\n",
      "89\tValidation loss: 0.409905\tBest loss: 0.400687\tAccuracy: 90.60%\n",
      "90\tValidation loss: 0.404395\tBest loss: 0.400687\tAccuracy: 90.40%\n",
      "91\tValidation loss: 0.394978\tBest loss: 0.394978\tAccuracy: 91.00%\n",
      "92\tValidation loss: 0.404681\tBest loss: 0.394978\tAccuracy: 90.40%\n",
      "93\tValidation loss: 0.395443\tBest loss: 0.394978\tAccuracy: 90.70%\n",
      "94\tValidation loss: 0.420231\tBest loss: 0.394978\tAccuracy: 90.60%\n",
      "95\tValidation loss: 0.393330\tBest loss: 0.393330\tAccuracy: 90.90%\n",
      "96\tValidation loss: 0.389060\tBest loss: 0.389060\tAccuracy: 90.80%\n",
      "97\tValidation loss: 0.398064\tBest loss: 0.389060\tAccuracy: 90.70%\n",
      "98\tValidation loss: 0.391219\tBest loss: 0.389060\tAccuracy: 91.10%\n",
      "99\tValidation loss: 0.390965\tBest loss: 0.389060\tAccuracy: 91.00%\n",
      "100\tValidation loss: 0.391892\tBest loss: 0.389060\tAccuracy: 90.90%\n",
      "101\tValidation loss: 0.384491\tBest loss: 0.384491\tAccuracy: 91.60%\n",
      "102\tValidation loss: 0.385246\tBest loss: 0.384491\tAccuracy: 90.90%\n",
      "103\tValidation loss: 0.392027\tBest loss: 0.384491\tAccuracy: 90.90%\n",
      "104\tValidation loss: 0.389251\tBest loss: 0.384491\tAccuracy: 91.00%\n",
      "105\tValidation loss: 0.390316\tBest loss: 0.384491\tAccuracy: 91.00%\n",
      "106\tValidation loss: 0.385323\tBest loss: 0.384491\tAccuracy: 91.00%\n",
      "107\tValidation loss: 0.390644\tBest loss: 0.384491\tAccuracy: 90.80%\n",
      "108\tValidation loss: 0.394835\tBest loss: 0.384491\tAccuracy: 90.60%\n",
      "109\tValidation loss: 0.380382\tBest loss: 0.380382\tAccuracy: 91.00%\n",
      "110\tValidation loss: 0.392377\tBest loss: 0.380382\tAccuracy: 91.10%\n",
      "111\tValidation loss: 0.386129\tBest loss: 0.380382\tAccuracy: 90.80%\n",
      "112\tValidation loss: 0.383021\tBest loss: 0.380382\tAccuracy: 90.70%\n",
      "113\tValidation loss: 0.379251\tBest loss: 0.379251\tAccuracy: 90.70%\n",
      "114\tValidation loss: 0.383754\tBest loss: 0.379251\tAccuracy: 91.00%\n",
      "115\tValidation loss: 0.386315\tBest loss: 0.379251\tAccuracy: 90.40%\n",
      "116\tValidation loss: 0.383177\tBest loss: 0.379251\tAccuracy: 91.10%\n",
      "117\tValidation loss: 0.377310\tBest loss: 0.377310\tAccuracy: 91.30%\n",
      "118\tValidation loss: 0.378667\tBest loss: 0.377310\tAccuracy: 91.30%\n",
      "119\tValidation loss: 0.377394\tBest loss: 0.377310\tAccuracy: 91.00%\n",
      "120\tValidation loss: 0.377496\tBest loss: 0.377310\tAccuracy: 91.30%\n",
      "121\tValidation loss: 0.382698\tBest loss: 0.377310\tAccuracy: 91.00%\n",
      "122\tValidation loss: 0.378447\tBest loss: 0.377310\tAccuracy: 91.60%\n",
      "123\tValidation loss: 0.381591\tBest loss: 0.377310\tAccuracy: 91.30%\n",
      "124\tValidation loss: 0.374296\tBest loss: 0.374296\tAccuracy: 90.80%\n",
      "125\tValidation loss: 0.375682\tBest loss: 0.374296\tAccuracy: 91.60%\n",
      "126\tValidation loss: 0.377274\tBest loss: 0.374296\tAccuracy: 91.20%\n",
      "127\tValidation loss: 0.383222\tBest loss: 0.374296\tAccuracy: 91.30%\n",
      "128\tValidation loss: 0.367810\tBest loss: 0.367810\tAccuracy: 91.60%\n",
      "129\tValidation loss: 0.372219\tBest loss: 0.367810\tAccuracy: 91.30%\n",
      "130\tValidation loss: 0.374426\tBest loss: 0.367810\tAccuracy: 91.30%\n",
      "131\tValidation loss: 0.370240\tBest loss: 0.367810\tAccuracy: 91.40%\n",
      "132\tValidation loss: 0.370782\tBest loss: 0.367810\tAccuracy: 91.30%\n",
      "133\tValidation loss: 0.370308\tBest loss: 0.367810\tAccuracy: 92.10%\n",
      "134\tValidation loss: 0.374133\tBest loss: 0.367810\tAccuracy: 91.30%\n",
      "135\tValidation loss: 0.370973\tBest loss: 0.367810\tAccuracy: 91.50%\n",
      "136\tValidation loss: 0.364983\tBest loss: 0.364983\tAccuracy: 92.00%\n",
      "137\tValidation loss: 0.370965\tBest loss: 0.364983\tAccuracy: 91.90%\n",
      "138\tValidation loss: 0.364299\tBest loss: 0.364299\tAccuracy: 91.30%\n",
      "139\tValidation loss: 0.363517\tBest loss: 0.363517\tAccuracy: 91.50%\n",
      "140\tValidation loss: 0.366016\tBest loss: 0.363517\tAccuracy: 91.50%\n",
      "141\tValidation loss: 0.373561\tBest loss: 0.363517\tAccuracy: 91.40%\n",
      "142\tValidation loss: 0.364313\tBest loss: 0.363517\tAccuracy: 91.60%\n",
      "143\tValidation loss: 0.358203\tBest loss: 0.358203\tAccuracy: 92.00%\n",
      "144\tValidation loss: 0.363670\tBest loss: 0.358203\tAccuracy: 91.40%\n",
      "145\tValidation loss: 0.364002\tBest loss: 0.358203\tAccuracy: 91.30%\n",
      "146\tValidation loss: 0.354333\tBest loss: 0.354333\tAccuracy: 92.30%\n",
      "147\tValidation loss: 0.360630\tBest loss: 0.354333\tAccuracy: 91.80%\n",
      "148\tValidation loss: 0.366266\tBest loss: 0.354333\tAccuracy: 91.30%\n",
      "149\tValidation loss: 0.360655\tBest loss: 0.354333\tAccuracy: 91.50%\n",
      "150\tValidation loss: 0.359726\tBest loss: 0.354333\tAccuracy: 91.90%\n",
      "151\tValidation loss: 0.362214\tBest loss: 0.354333\tAccuracy: 91.40%\n",
      "152\tValidation loss: 0.360726\tBest loss: 0.354333\tAccuracy: 92.00%\n",
      "153\tValidation loss: 0.355931\tBest loss: 0.354333\tAccuracy: 91.30%\n",
      "154\tValidation loss: 0.363582\tBest loss: 0.354333\tAccuracy: 91.30%\n",
      "155\tValidation loss: 0.357637\tBest loss: 0.354333\tAccuracy: 91.90%\n",
      "156\tValidation loss: 0.363440\tBest loss: 0.354333\tAccuracy: 91.60%\n",
      "157\tValidation loss: 0.368206\tBest loss: 0.354333\tAccuracy: 91.50%\n",
      "158\tValidation loss: 0.361243\tBest loss: 0.354333\tAccuracy: 91.60%\n",
      "159\tValidation loss: 0.361099\tBest loss: 0.354333\tAccuracy: 92.20%\n",
      "160\tValidation loss: 0.367016\tBest loss: 0.354333\tAccuracy: 91.60%\n",
      "161\tValidation loss: 0.362162\tBest loss: 0.354333\tAccuracy: 91.90%\n",
      "162\tValidation loss: 0.356132\tBest loss: 0.354333\tAccuracy: 91.50%\n",
      "163\tValidation loss: 0.354934\tBest loss: 0.354333\tAccuracy: 92.00%\n",
      "164\tValidation loss: 0.353393\tBest loss: 0.353393\tAccuracy: 92.00%\n",
      "165\tValidation loss: 0.356698\tBest loss: 0.353393\tAccuracy: 91.70%\n",
      "166\tValidation loss: 0.355897\tBest loss: 0.353393\tAccuracy: 92.10%\n",
      "167\tValidation loss: 0.352397\tBest loss: 0.352397\tAccuracy: 92.20%\n",
      "168\tValidation loss: 0.356340\tBest loss: 0.352397\tAccuracy: 91.80%\n",
      "169\tValidation loss: 0.355383\tBest loss: 0.352397\tAccuracy: 92.00%\n",
      "170\tValidation loss: 0.351921\tBest loss: 0.351921\tAccuracy: 91.70%\n",
      "171\tValidation loss: 0.351083\tBest loss: 0.351083\tAccuracy: 92.10%\n",
      "172\tValidation loss: 0.345868\tBest loss: 0.345868\tAccuracy: 92.60%\n",
      "173\tValidation loss: 0.359429\tBest loss: 0.345868\tAccuracy: 91.80%\n",
      "174\tValidation loss: 0.351746\tBest loss: 0.345868\tAccuracy: 92.10%\n",
      "175\tValidation loss: 0.348628\tBest loss: 0.345868\tAccuracy: 92.00%\n",
      "176\tValidation loss: 0.360413\tBest loss: 0.345868\tAccuracy: 92.20%\n",
      "177\tValidation loss: 0.350650\tBest loss: 0.345868\tAccuracy: 92.70%\n",
      "178\tValidation loss: 0.348942\tBest loss: 0.345868\tAccuracy: 92.30%\n",
      "179\tValidation loss: 0.351253\tBest loss: 0.345868\tAccuracy: 92.50%\n",
      "180\tValidation loss: 0.349469\tBest loss: 0.345868\tAccuracy: 92.50%\n",
      "181\tValidation loss: 0.348665\tBest loss: 0.345868\tAccuracy: 91.90%\n",
      "182\tValidation loss: 0.349871\tBest loss: 0.345868\tAccuracy: 92.40%\n",
      "183\tValidation loss: 0.348508\tBest loss: 0.345868\tAccuracy: 92.10%\n",
      "184\tValidation loss: 0.350997\tBest loss: 0.345868\tAccuracy: 92.30%\n",
      "185\tValidation loss: 0.349177\tBest loss: 0.345868\tAccuracy: 91.90%\n",
      "186\tValidation loss: 0.341512\tBest loss: 0.341512\tAccuracy: 92.40%\n",
      "187\tValidation loss: 0.349341\tBest loss: 0.341512\tAccuracy: 92.00%\n",
      "188\tValidation loss: 0.349170\tBest loss: 0.341512\tAccuracy: 92.30%\n",
      "189\tValidation loss: 0.350087\tBest loss: 0.341512\tAccuracy: 92.30%\n",
      "190\tValidation loss: 0.349198\tBest loss: 0.341512\tAccuracy: 92.20%\n",
      "191\tValidation loss: 0.345678\tBest loss: 0.341512\tAccuracy: 92.60%\n",
      "192\tValidation loss: 0.351220\tBest loss: 0.341512\tAccuracy: 92.10%\n",
      "193\tValidation loss: 0.341941\tBest loss: 0.341512\tAccuracy: 92.60%\n",
      "194\tValidation loss: 0.346080\tBest loss: 0.341512\tAccuracy: 92.00%\n",
      "195\tValidation loss: 0.341151\tBest loss: 0.341151\tAccuracy: 92.50%\n",
      "196\tValidation loss: 0.344493\tBest loss: 0.341151\tAccuracy: 92.50%\n",
      "197\tValidation loss: 0.343173\tBest loss: 0.341151\tAccuracy: 92.70%\n",
      "198\tValidation loss: 0.345394\tBest loss: 0.341151\tAccuracy: 92.40%\n",
      "199\tValidation loss: 0.343157\tBest loss: 0.341151\tAccuracy: 92.40%\n",
      "200\tValidation loss: 0.354507\tBest loss: 0.341151\tAccuracy: 92.10%\n",
      "201\tValidation loss: 0.346964\tBest loss: 0.341151\tAccuracy: 92.60%\n",
      "202\tValidation loss: 0.347491\tBest loss: 0.341151\tAccuracy: 92.20%\n",
      "203\tValidation loss: 0.345447\tBest loss: 0.341151\tAccuracy: 92.50%\n",
      "204\tValidation loss: 0.348624\tBest loss: 0.341151\tAccuracy: 92.00%\n",
      "205\tValidation loss: 0.344660\tBest loss: 0.341151\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\tValidation loss: 0.337081\tBest loss: 0.337081\tAccuracy: 92.70%\n",
      "207\tValidation loss: 0.346801\tBest loss: 0.337081\tAccuracy: 93.00%\n",
      "208\tValidation loss: 0.345191\tBest loss: 0.337081\tAccuracy: 92.80%\n",
      "209\tValidation loss: 0.338737\tBest loss: 0.337081\tAccuracy: 93.00%\n",
      "210\tValidation loss: 0.337766\tBest loss: 0.337081\tAccuracy: 92.80%\n",
      "211\tValidation loss: 0.339190\tBest loss: 0.337081\tAccuracy: 92.80%\n",
      "212\tValidation loss: 0.341788\tBest loss: 0.337081\tAccuracy: 92.60%\n",
      "213\tValidation loss: 0.340336\tBest loss: 0.337081\tAccuracy: 92.80%\n",
      "214\tValidation loss: 0.339345\tBest loss: 0.337081\tAccuracy: 92.70%\n",
      "215\tValidation loss: 0.340039\tBest loss: 0.337081\tAccuracy: 92.30%\n",
      "216\tValidation loss: 0.339820\tBest loss: 0.337081\tAccuracy: 92.30%\n",
      "217\tValidation loss: 0.333847\tBest loss: 0.333847\tAccuracy: 92.80%\n",
      "218\tValidation loss: 0.340108\tBest loss: 0.333847\tAccuracy: 92.50%\n",
      "219\tValidation loss: 0.339737\tBest loss: 0.333847\tAccuracy: 92.60%\n",
      "220\tValidation loss: 0.343859\tBest loss: 0.333847\tAccuracy: 92.30%\n",
      "221\tValidation loss: 0.342009\tBest loss: 0.333847\tAccuracy: 92.50%\n",
      "222\tValidation loss: 0.341180\tBest loss: 0.333847\tAccuracy: 92.60%\n",
      "223\tValidation loss: 0.342633\tBest loss: 0.333847\tAccuracy: 92.60%\n",
      "224\tValidation loss: 0.335883\tBest loss: 0.333847\tAccuracy: 93.00%\n",
      "225\tValidation loss: 0.337339\tBest loss: 0.333847\tAccuracy: 93.00%\n",
      "226\tValidation loss: 0.339750\tBest loss: 0.333847\tAccuracy: 92.80%\n",
      "227\tValidation loss: 0.336878\tBest loss: 0.333847\tAccuracy: 92.50%\n",
      "228\tValidation loss: 0.335959\tBest loss: 0.333847\tAccuracy: 92.50%\n",
      "229\tValidation loss: 0.340635\tBest loss: 0.333847\tAccuracy: 92.80%\n",
      "230\tValidation loss: 0.341544\tBest loss: 0.333847\tAccuracy: 92.30%\n",
      "231\tValidation loss: 0.340527\tBest loss: 0.333847\tAccuracy: 92.60%\n",
      "232\tValidation loss: 0.335699\tBest loss: 0.333847\tAccuracy: 92.90%\n",
      "233\tValidation loss: 0.341289\tBest loss: 0.333847\tAccuracy: 92.30%\n",
      "234\tValidation loss: 0.337966\tBest loss: 0.333847\tAccuracy: 92.90%\n",
      "235\tValidation loss: 0.337712\tBest loss: 0.333847\tAccuracy: 92.50%\n",
      "236\tValidation loss: 0.341690\tBest loss: 0.333847\tAccuracy: 92.30%\n",
      "237\tValidation loss: 0.339191\tBest loss: 0.333847\tAccuracy: 92.60%\n",
      "238\tValidation loss: 0.340934\tBest loss: 0.333847\tAccuracy: 92.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  35.5s\n",
      "[CV] batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.309799\tBest loss: 2.309799\tAccuracy: 41.80%\n",
      "1\tValidation loss: 1.770775\tBest loss: 1.770775\tAccuracy: 57.30%\n",
      "2\tValidation loss: 1.544516\tBest loss: 1.544516\tAccuracy: 62.50%\n",
      "3\tValidation loss: 1.363784\tBest loss: 1.363784\tAccuracy: 66.10%\n",
      "4\tValidation loss: 1.227742\tBest loss: 1.227742\tAccuracy: 71.30%\n",
      "5\tValidation loss: 1.117861\tBest loss: 1.117861\tAccuracy: 73.20%\n",
      "6\tValidation loss: 1.046375\tBest loss: 1.046375\tAccuracy: 76.10%\n",
      "7\tValidation loss: 0.980843\tBest loss: 0.980843\tAccuracy: 76.20%\n",
      "8\tValidation loss: 0.945853\tBest loss: 0.945853\tAccuracy: 77.40%\n",
      "9\tValidation loss: 0.906838\tBest loss: 0.906838\tAccuracy: 78.30%\n",
      "10\tValidation loss: 0.872585\tBest loss: 0.872585\tAccuracy: 79.00%\n",
      "11\tValidation loss: 0.863105\tBest loss: 0.863105\tAccuracy: 79.30%\n",
      "12\tValidation loss: 0.816993\tBest loss: 0.816993\tAccuracy: 80.20%\n",
      "13\tValidation loss: 0.784890\tBest loss: 0.784890\tAccuracy: 81.60%\n",
      "14\tValidation loss: 0.747420\tBest loss: 0.747420\tAccuracy: 82.70%\n",
      "15\tValidation loss: 0.732230\tBest loss: 0.732230\tAccuracy: 82.80%\n",
      "16\tValidation loss: 0.707583\tBest loss: 0.707583\tAccuracy: 83.30%\n",
      "17\tValidation loss: 0.704534\tBest loss: 0.704534\tAccuracy: 83.40%\n",
      "18\tValidation loss: 0.692845\tBest loss: 0.692845\tAccuracy: 83.00%\n",
      "19\tValidation loss: 0.677262\tBest loss: 0.677262\tAccuracy: 84.20%\n",
      "20\tValidation loss: 0.663554\tBest loss: 0.663554\tAccuracy: 84.40%\n",
      "21\tValidation loss: 0.655147\tBest loss: 0.655147\tAccuracy: 84.80%\n",
      "22\tValidation loss: 0.632961\tBest loss: 0.632961\tAccuracy: 84.10%\n",
      "23\tValidation loss: 0.631270\tBest loss: 0.631270\tAccuracy: 84.90%\n",
      "24\tValidation loss: 0.617246\tBest loss: 0.617246\tAccuracy: 86.00%\n",
      "25\tValidation loss: 0.617279\tBest loss: 0.617246\tAccuracy: 84.90%\n",
      "26\tValidation loss: 0.611279\tBest loss: 0.611279\tAccuracy: 85.90%\n",
      "27\tValidation loss: 0.594479\tBest loss: 0.594479\tAccuracy: 85.80%\n",
      "28\tValidation loss: 0.591113\tBest loss: 0.591113\tAccuracy: 87.30%\n",
      "29\tValidation loss: 0.580340\tBest loss: 0.580340\tAccuracy: 85.90%\n",
      "30\tValidation loss: 0.562908\tBest loss: 0.562908\tAccuracy: 87.10%\n",
      "31\tValidation loss: 0.563374\tBest loss: 0.562908\tAccuracy: 86.80%\n",
      "32\tValidation loss: 0.560925\tBest loss: 0.560925\tAccuracy: 87.20%\n",
      "33\tValidation loss: 0.551396\tBest loss: 0.551396\tAccuracy: 87.60%\n",
      "34\tValidation loss: 0.555349\tBest loss: 0.551396\tAccuracy: 87.50%\n",
      "35\tValidation loss: 0.542608\tBest loss: 0.542608\tAccuracy: 87.50%\n",
      "36\tValidation loss: 0.543218\tBest loss: 0.542608\tAccuracy: 87.90%\n",
      "37\tValidation loss: 0.525620\tBest loss: 0.525620\tAccuracy: 88.90%\n",
      "38\tValidation loss: 0.529278\tBest loss: 0.525620\tAccuracy: 88.70%\n",
      "39\tValidation loss: 0.526364\tBest loss: 0.525620\tAccuracy: 87.60%\n",
      "40\tValidation loss: 0.523228\tBest loss: 0.523228\tAccuracy: 88.50%\n",
      "41\tValidation loss: 0.509327\tBest loss: 0.509327\tAccuracy: 89.20%\n",
      "42\tValidation loss: 0.506578\tBest loss: 0.506578\tAccuracy: 88.40%\n",
      "43\tValidation loss: 0.493444\tBest loss: 0.493444\tAccuracy: 88.90%\n",
      "44\tValidation loss: 0.498925\tBest loss: 0.493444\tAccuracy: 89.10%\n",
      "45\tValidation loss: 0.496321\tBest loss: 0.493444\tAccuracy: 88.60%\n",
      "46\tValidation loss: 0.499699\tBest loss: 0.493444\tAccuracy: 88.50%\n",
      "47\tValidation loss: 0.502786\tBest loss: 0.493444\tAccuracy: 88.40%\n",
      "48\tValidation loss: 0.494974\tBest loss: 0.493444\tAccuracy: 89.70%\n",
      "49\tValidation loss: 0.478530\tBest loss: 0.478530\tAccuracy: 89.60%\n",
      "50\tValidation loss: 0.477141\tBest loss: 0.477141\tAccuracy: 89.80%\n",
      "51\tValidation loss: 0.477729\tBest loss: 0.477141\tAccuracy: 89.30%\n",
      "52\tValidation loss: 0.474322\tBest loss: 0.474322\tAccuracy: 89.60%\n",
      "53\tValidation loss: 0.470207\tBest loss: 0.470207\tAccuracy: 89.80%\n",
      "54\tValidation loss: 0.466460\tBest loss: 0.466460\tAccuracy: 89.90%\n",
      "55\tValidation loss: 0.461305\tBest loss: 0.461305\tAccuracy: 89.90%\n",
      "56\tValidation loss: 0.468339\tBest loss: 0.461305\tAccuracy: 89.10%\n",
      "57\tValidation loss: 0.459215\tBest loss: 0.459215\tAccuracy: 89.50%\n",
      "58\tValidation loss: 0.464262\tBest loss: 0.459215\tAccuracy: 89.10%\n",
      "59\tValidation loss: 0.458703\tBest loss: 0.458703\tAccuracy: 89.50%\n",
      "60\tValidation loss: 0.459415\tBest loss: 0.458703\tAccuracy: 89.60%\n",
      "61\tValidation loss: 0.463523\tBest loss: 0.458703\tAccuracy: 89.00%\n",
      "62\tValidation loss: 0.458092\tBest loss: 0.458092\tAccuracy: 89.50%\n",
      "63\tValidation loss: 0.445131\tBest loss: 0.445131\tAccuracy: 90.00%\n",
      "64\tValidation loss: 0.439070\tBest loss: 0.439070\tAccuracy: 90.00%\n",
      "65\tValidation loss: 0.436967\tBest loss: 0.436967\tAccuracy: 89.60%\n",
      "66\tValidation loss: 0.444472\tBest loss: 0.436967\tAccuracy: 88.90%\n",
      "67\tValidation loss: 0.442322\tBest loss: 0.436967\tAccuracy: 90.30%\n",
      "68\tValidation loss: 0.439133\tBest loss: 0.436967\tAccuracy: 90.20%\n",
      "69\tValidation loss: 0.437654\tBest loss: 0.436967\tAccuracy: 89.70%\n",
      "70\tValidation loss: 0.438729\tBest loss: 0.436967\tAccuracy: 89.70%\n",
      "71\tValidation loss: 0.444108\tBest loss: 0.436967\tAccuracy: 89.80%\n",
      "72\tValidation loss: 0.449127\tBest loss: 0.436967\tAccuracy: 89.30%\n",
      "73\tValidation loss: 0.433528\tBest loss: 0.433528\tAccuracy: 90.00%\n",
      "74\tValidation loss: 0.438991\tBest loss: 0.433528\tAccuracy: 89.80%\n",
      "75\tValidation loss: 0.431420\tBest loss: 0.431420\tAccuracy: 90.00%\n",
      "76\tValidation loss: 0.421429\tBest loss: 0.421429\tAccuracy: 90.00%\n",
      "77\tValidation loss: 0.433989\tBest loss: 0.421429\tAccuracy: 89.50%\n",
      "78\tValidation loss: 0.415384\tBest loss: 0.415384\tAccuracy: 90.30%\n",
      "79\tValidation loss: 0.424467\tBest loss: 0.415384\tAccuracy: 90.40%\n",
      "80\tValidation loss: 0.417076\tBest loss: 0.415384\tAccuracy: 90.80%\n",
      "81\tValidation loss: 0.421524\tBest loss: 0.415384\tAccuracy: 90.50%\n",
      "82\tValidation loss: 0.410711\tBest loss: 0.410711\tAccuracy: 90.80%\n",
      "83\tValidation loss: 0.425167\tBest loss: 0.410711\tAccuracy: 90.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\tValidation loss: 0.417807\tBest loss: 0.410711\tAccuracy: 90.40%\n",
      "85\tValidation loss: 0.420042\tBest loss: 0.410711\tAccuracy: 90.00%\n",
      "86\tValidation loss: 0.413128\tBest loss: 0.410711\tAccuracy: 90.30%\n",
      "87\tValidation loss: 0.416743\tBest loss: 0.410711\tAccuracy: 90.40%\n",
      "88\tValidation loss: 0.413949\tBest loss: 0.410711\tAccuracy: 90.50%\n",
      "89\tValidation loss: 0.419317\tBest loss: 0.410711\tAccuracy: 90.70%\n",
      "90\tValidation loss: 0.412894\tBest loss: 0.410711\tAccuracy: 90.20%\n",
      "91\tValidation loss: 0.414407\tBest loss: 0.410711\tAccuracy: 90.40%\n",
      "92\tValidation loss: 0.428034\tBest loss: 0.410711\tAccuracy: 89.70%\n",
      "93\tValidation loss: 0.406608\tBest loss: 0.406608\tAccuracy: 90.70%\n",
      "94\tValidation loss: 0.404275\tBest loss: 0.404275\tAccuracy: 90.90%\n",
      "95\tValidation loss: 0.402839\tBest loss: 0.402839\tAccuracy: 91.30%\n",
      "96\tValidation loss: 0.407718\tBest loss: 0.402839\tAccuracy: 90.80%\n",
      "97\tValidation loss: 0.403205\tBest loss: 0.402839\tAccuracy: 90.90%\n",
      "98\tValidation loss: 0.404428\tBest loss: 0.402839\tAccuracy: 90.50%\n",
      "99\tValidation loss: 0.408992\tBest loss: 0.402839\tAccuracy: 90.80%\n",
      "100\tValidation loss: 0.400861\tBest loss: 0.400861\tAccuracy: 91.00%\n",
      "101\tValidation loss: 0.400475\tBest loss: 0.400475\tAccuracy: 91.20%\n",
      "102\tValidation loss: 0.403094\tBest loss: 0.400475\tAccuracy: 90.30%\n",
      "103\tValidation loss: 0.393799\tBest loss: 0.393799\tAccuracy: 91.20%\n",
      "104\tValidation loss: 0.394078\tBest loss: 0.393799\tAccuracy: 91.20%\n",
      "105\tValidation loss: 0.395514\tBest loss: 0.393799\tAccuracy: 90.90%\n",
      "106\tValidation loss: 0.397667\tBest loss: 0.393799\tAccuracy: 91.10%\n",
      "107\tValidation loss: 0.395086\tBest loss: 0.393799\tAccuracy: 90.60%\n",
      "108\tValidation loss: 0.406945\tBest loss: 0.393799\tAccuracy: 90.80%\n",
      "109\tValidation loss: 0.402763\tBest loss: 0.393799\tAccuracy: 90.50%\n",
      "110\tValidation loss: 0.403887\tBest loss: 0.393799\tAccuracy: 90.80%\n",
      "111\tValidation loss: 0.394561\tBest loss: 0.393799\tAccuracy: 90.80%\n",
      "112\tValidation loss: 0.391691\tBest loss: 0.391691\tAccuracy: 90.10%\n",
      "113\tValidation loss: 0.392104\tBest loss: 0.391691\tAccuracy: 91.00%\n",
      "114\tValidation loss: 0.387967\tBest loss: 0.387967\tAccuracy: 90.90%\n",
      "115\tValidation loss: 0.398944\tBest loss: 0.387967\tAccuracy: 90.90%\n",
      "116\tValidation loss: 0.390360\tBest loss: 0.387967\tAccuracy: 90.80%\n",
      "117\tValidation loss: 0.389170\tBest loss: 0.387967\tAccuracy: 91.40%\n",
      "118\tValidation loss: 0.387321\tBest loss: 0.387321\tAccuracy: 91.40%\n",
      "119\tValidation loss: 0.395542\tBest loss: 0.387321\tAccuracy: 90.90%\n",
      "120\tValidation loss: 0.390304\tBest loss: 0.387321\tAccuracy: 91.10%\n",
      "121\tValidation loss: 0.390810\tBest loss: 0.387321\tAccuracy: 90.90%\n",
      "122\tValidation loss: 0.380617\tBest loss: 0.380617\tAccuracy: 91.00%\n",
      "123\tValidation loss: 0.383263\tBest loss: 0.380617\tAccuracy: 91.10%\n",
      "124\tValidation loss: 0.393156\tBest loss: 0.380617\tAccuracy: 91.10%\n",
      "125\tValidation loss: 0.386115\tBest loss: 0.380617\tAccuracy: 91.40%\n",
      "126\tValidation loss: 0.391806\tBest loss: 0.380617\tAccuracy: 90.50%\n",
      "127\tValidation loss: 0.384254\tBest loss: 0.380617\tAccuracy: 91.00%\n",
      "128\tValidation loss: 0.384530\tBest loss: 0.380617\tAccuracy: 91.40%\n",
      "129\tValidation loss: 0.385773\tBest loss: 0.380617\tAccuracy: 91.40%\n",
      "130\tValidation loss: 0.375432\tBest loss: 0.375432\tAccuracy: 91.30%\n",
      "131\tValidation loss: 0.381475\tBest loss: 0.375432\tAccuracy: 91.20%\n",
      "132\tValidation loss: 0.378061\tBest loss: 0.375432\tAccuracy: 91.90%\n",
      "133\tValidation loss: 0.382298\tBest loss: 0.375432\tAccuracy: 90.80%\n",
      "134\tValidation loss: 0.377755\tBest loss: 0.375432\tAccuracy: 90.90%\n",
      "135\tValidation loss: 0.382005\tBest loss: 0.375432\tAccuracy: 91.30%\n",
      "136\tValidation loss: 0.380204\tBest loss: 0.375432\tAccuracy: 91.00%\n",
      "137\tValidation loss: 0.377402\tBest loss: 0.375432\tAccuracy: 91.00%\n",
      "138\tValidation loss: 0.376583\tBest loss: 0.375432\tAccuracy: 90.90%\n",
      "139\tValidation loss: 0.377984\tBest loss: 0.375432\tAccuracy: 91.20%\n",
      "140\tValidation loss: 0.382580\tBest loss: 0.375432\tAccuracy: 91.40%\n",
      "141\tValidation loss: 0.376886\tBest loss: 0.375432\tAccuracy: 91.20%\n",
      "142\tValidation loss: 0.378516\tBest loss: 0.375432\tAccuracy: 91.50%\n",
      "143\tValidation loss: 0.377043\tBest loss: 0.375432\tAccuracy: 91.90%\n",
      "144\tValidation loss: 0.377938\tBest loss: 0.375432\tAccuracy: 91.20%\n",
      "145\tValidation loss: 0.375516\tBest loss: 0.375432\tAccuracy: 91.50%\n",
      "146\tValidation loss: 0.374231\tBest loss: 0.374231\tAccuracy: 91.10%\n",
      "147\tValidation loss: 0.373098\tBest loss: 0.373098\tAccuracy: 91.30%\n",
      "148\tValidation loss: 0.379872\tBest loss: 0.373098\tAccuracy: 91.10%\n",
      "149\tValidation loss: 0.375300\tBest loss: 0.373098\tAccuracy: 91.40%\n",
      "150\tValidation loss: 0.371758\tBest loss: 0.371758\tAccuracy: 91.60%\n",
      "151\tValidation loss: 0.373657\tBest loss: 0.371758\tAccuracy: 91.60%\n",
      "152\tValidation loss: 0.377912\tBest loss: 0.371758\tAccuracy: 91.40%\n",
      "153\tValidation loss: 0.375102\tBest loss: 0.371758\tAccuracy: 91.40%\n",
      "154\tValidation loss: 0.376249\tBest loss: 0.371758\tAccuracy: 91.50%\n",
      "155\tValidation loss: 0.379431\tBest loss: 0.371758\tAccuracy: 91.30%\n",
      "156\tValidation loss: 0.368950\tBest loss: 0.368950\tAccuracy: 91.40%\n",
      "157\tValidation loss: 0.368868\tBest loss: 0.368868\tAccuracy: 91.30%\n",
      "158\tValidation loss: 0.372129\tBest loss: 0.368868\tAccuracy: 91.60%\n",
      "159\tValidation loss: 0.373387\tBest loss: 0.368868\tAccuracy: 91.60%\n",
      "160\tValidation loss: 0.371425\tBest loss: 0.368868\tAccuracy: 91.40%\n",
      "161\tValidation loss: 0.378287\tBest loss: 0.368868\tAccuracy: 92.10%\n",
      "162\tValidation loss: 0.376145\tBest loss: 0.368868\tAccuracy: 91.40%\n",
      "163\tValidation loss: 0.379852\tBest loss: 0.368868\tAccuracy: 91.90%\n",
      "164\tValidation loss: 0.365150\tBest loss: 0.365150\tAccuracy: 91.40%\n",
      "165\tValidation loss: 0.377093\tBest loss: 0.365150\tAccuracy: 91.50%\n",
      "166\tValidation loss: 0.371354\tBest loss: 0.365150\tAccuracy: 91.40%\n",
      "167\tValidation loss: 0.371166\tBest loss: 0.365150\tAccuracy: 91.60%\n",
      "168\tValidation loss: 0.364692\tBest loss: 0.364692\tAccuracy: 91.40%\n",
      "169\tValidation loss: 0.370402\tBest loss: 0.364692\tAccuracy: 91.40%\n",
      "170\tValidation loss: 0.363868\tBest loss: 0.363868\tAccuracy: 91.60%\n",
      "171\tValidation loss: 0.365993\tBest loss: 0.363868\tAccuracy: 91.80%\n",
      "172\tValidation loss: 0.368899\tBest loss: 0.363868\tAccuracy: 91.50%\n",
      "173\tValidation loss: 0.371300\tBest loss: 0.363868\tAccuracy: 91.20%\n",
      "174\tValidation loss: 0.369308\tBest loss: 0.363868\tAccuracy: 91.40%\n",
      "175\tValidation loss: 0.368917\tBest loss: 0.363868\tAccuracy: 91.30%\n",
      "176\tValidation loss: 0.365303\tBest loss: 0.363868\tAccuracy: 91.40%\n",
      "177\tValidation loss: 0.376226\tBest loss: 0.363868\tAccuracy: 91.80%\n",
      "178\tValidation loss: 0.376168\tBest loss: 0.363868\tAccuracy: 91.60%\n",
      "179\tValidation loss: 0.371565\tBest loss: 0.363868\tAccuracy: 91.50%\n",
      "180\tValidation loss: 0.369571\tBest loss: 0.363868\tAccuracy: 91.80%\n",
      "181\tValidation loss: 0.366534\tBest loss: 0.363868\tAccuracy: 92.20%\n",
      "182\tValidation loss: 0.360336\tBest loss: 0.360336\tAccuracy: 91.80%\n",
      "183\tValidation loss: 0.364565\tBest loss: 0.360336\tAccuracy: 92.30%\n",
      "184\tValidation loss: 0.368868\tBest loss: 0.360336\tAccuracy: 91.50%\n",
      "185\tValidation loss: 0.364379\tBest loss: 0.360336\tAccuracy: 91.90%\n",
      "186\tValidation loss: 0.368790\tBest loss: 0.360336\tAccuracy: 91.80%\n",
      "187\tValidation loss: 0.362718\tBest loss: 0.360336\tAccuracy: 92.20%\n",
      "188\tValidation loss: 0.364375\tBest loss: 0.360336\tAccuracy: 92.00%\n",
      "189\tValidation loss: 0.365918\tBest loss: 0.360336\tAccuracy: 91.70%\n",
      "190\tValidation loss: 0.365539\tBest loss: 0.360336\tAccuracy: 91.40%\n",
      "191\tValidation loss: 0.365805\tBest loss: 0.360336\tAccuracy: 91.90%\n",
      "192\tValidation loss: 0.366032\tBest loss: 0.360336\tAccuracy: 92.40%\n",
      "193\tValidation loss: 0.355307\tBest loss: 0.355307\tAccuracy: 91.70%\n",
      "194\tValidation loss: 0.363101\tBest loss: 0.355307\tAccuracy: 92.00%\n",
      "195\tValidation loss: 0.364353\tBest loss: 0.355307\tAccuracy: 92.00%\n",
      "196\tValidation loss: 0.359580\tBest loss: 0.355307\tAccuracy: 92.20%\n",
      "197\tValidation loss: 0.367691\tBest loss: 0.355307\tAccuracy: 92.20%\n",
      "198\tValidation loss: 0.363703\tBest loss: 0.355307\tAccuracy: 91.80%\n",
      "199\tValidation loss: 0.367614\tBest loss: 0.355307\tAccuracy: 92.20%\n",
      "200\tValidation loss: 0.358458\tBest loss: 0.355307\tAccuracy: 91.80%\n",
      "201\tValidation loss: 0.366368\tBest loss: 0.355307\tAccuracy: 92.20%\n",
      "202\tValidation loss: 0.358327\tBest loss: 0.355307\tAccuracy: 92.50%\n",
      "203\tValidation loss: 0.366004\tBest loss: 0.355307\tAccuracy: 92.20%\n",
      "204\tValidation loss: 0.357850\tBest loss: 0.355307\tAccuracy: 92.40%\n",
      "205\tValidation loss: 0.357557\tBest loss: 0.355307\tAccuracy: 92.60%\n",
      "206\tValidation loss: 0.366988\tBest loss: 0.355307\tAccuracy: 92.40%\n",
      "207\tValidation loss: 0.359610\tBest loss: 0.355307\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\tValidation loss: 0.358408\tBest loss: 0.355307\tAccuracy: 92.50%\n",
      "209\tValidation loss: 0.362784\tBest loss: 0.355307\tAccuracy: 92.10%\n",
      "210\tValidation loss: 0.362308\tBest loss: 0.355307\tAccuracy: 92.40%\n",
      "211\tValidation loss: 0.359469\tBest loss: 0.355307\tAccuracy: 92.50%\n",
      "212\tValidation loss: 0.360648\tBest loss: 0.355307\tAccuracy: 92.40%\n",
      "213\tValidation loss: 0.363889\tBest loss: 0.355307\tAccuracy: 92.50%\n",
      "214\tValidation loss: 0.360822\tBest loss: 0.355307\tAccuracy: 92.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  32.8s\n",
      "[CV] batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.316061\tBest loss: 2.316061\tAccuracy: 42.90%\n",
      "1\tValidation loss: 1.857041\tBest loss: 1.857041\tAccuracy: 56.80%\n",
      "2\tValidation loss: 1.574809\tBest loss: 1.574809\tAccuracy: 61.10%\n",
      "3\tValidation loss: 1.369894\tBest loss: 1.369894\tAccuracy: 66.80%\n",
      "4\tValidation loss: 1.230475\tBest loss: 1.230475\tAccuracy: 69.20%\n",
      "5\tValidation loss: 1.157863\tBest loss: 1.157863\tAccuracy: 71.80%\n",
      "6\tValidation loss: 1.129352\tBest loss: 1.129352\tAccuracy: 70.90%\n",
      "7\tValidation loss: 0.995536\tBest loss: 0.995536\tAccuracy: 75.70%\n",
      "8\tValidation loss: 0.957033\tBest loss: 0.957033\tAccuracy: 76.00%\n",
      "9\tValidation loss: 0.912807\tBest loss: 0.912807\tAccuracy: 77.20%\n",
      "10\tValidation loss: 0.904227\tBest loss: 0.904227\tAccuracy: 76.80%\n",
      "11\tValidation loss: 0.849771\tBest loss: 0.849771\tAccuracy: 78.00%\n",
      "12\tValidation loss: 0.831338\tBest loss: 0.831338\tAccuracy: 78.60%\n",
      "13\tValidation loss: 0.781382\tBest loss: 0.781382\tAccuracy: 81.00%\n",
      "14\tValidation loss: 0.792082\tBest loss: 0.781382\tAccuracy: 79.60%\n",
      "15\tValidation loss: 0.744079\tBest loss: 0.744079\tAccuracy: 83.30%\n",
      "16\tValidation loss: 0.742470\tBest loss: 0.742470\tAccuracy: 82.40%\n",
      "17\tValidation loss: 0.718599\tBest loss: 0.718599\tAccuracy: 82.60%\n",
      "18\tValidation loss: 0.702572\tBest loss: 0.702572\tAccuracy: 84.10%\n",
      "19\tValidation loss: 0.684997\tBest loss: 0.684997\tAccuracy: 84.40%\n",
      "20\tValidation loss: 0.672360\tBest loss: 0.672360\tAccuracy: 83.70%\n",
      "21\tValidation loss: 0.659433\tBest loss: 0.659433\tAccuracy: 84.20%\n",
      "22\tValidation loss: 0.643230\tBest loss: 0.643230\tAccuracy: 85.90%\n",
      "23\tValidation loss: 0.641585\tBest loss: 0.641585\tAccuracy: 85.30%\n",
      "24\tValidation loss: 0.641811\tBest loss: 0.641585\tAccuracy: 85.50%\n",
      "25\tValidation loss: 0.626411\tBest loss: 0.626411\tAccuracy: 84.90%\n",
      "26\tValidation loss: 0.609365\tBest loss: 0.609365\tAccuracy: 86.60%\n",
      "27\tValidation loss: 0.596623\tBest loss: 0.596623\tAccuracy: 86.50%\n",
      "28\tValidation loss: 0.596781\tBest loss: 0.596623\tAccuracy: 85.50%\n",
      "29\tValidation loss: 0.591525\tBest loss: 0.591525\tAccuracy: 85.50%\n",
      "30\tValidation loss: 0.571624\tBest loss: 0.571624\tAccuracy: 86.80%\n",
      "31\tValidation loss: 0.588428\tBest loss: 0.571624\tAccuracy: 85.90%\n",
      "32\tValidation loss: 0.575140\tBest loss: 0.571624\tAccuracy: 87.00%\n",
      "33\tValidation loss: 0.564931\tBest loss: 0.564931\tAccuracy: 86.60%\n",
      "34\tValidation loss: 0.562934\tBest loss: 0.562934\tAccuracy: 86.80%\n",
      "35\tValidation loss: 0.551965\tBest loss: 0.551965\tAccuracy: 87.20%\n",
      "36\tValidation loss: 0.554027\tBest loss: 0.551965\tAccuracy: 87.60%\n",
      "37\tValidation loss: 0.533277\tBest loss: 0.533277\tAccuracy: 88.10%\n",
      "38\tValidation loss: 0.532864\tBest loss: 0.532864\tAccuracy: 87.40%\n",
      "39\tValidation loss: 0.522440\tBest loss: 0.522440\tAccuracy: 88.30%\n",
      "40\tValidation loss: 0.525226\tBest loss: 0.522440\tAccuracy: 88.40%\n",
      "41\tValidation loss: 0.511155\tBest loss: 0.511155\tAccuracy: 88.80%\n",
      "42\tValidation loss: 0.517536\tBest loss: 0.511155\tAccuracy: 88.80%\n",
      "43\tValidation loss: 0.510965\tBest loss: 0.510965\tAccuracy: 88.60%\n",
      "44\tValidation loss: 0.508424\tBest loss: 0.508424\tAccuracy: 88.20%\n",
      "45\tValidation loss: 0.502065\tBest loss: 0.502065\tAccuracy: 88.60%\n",
      "46\tValidation loss: 0.513854\tBest loss: 0.502065\tAccuracy: 88.50%\n",
      "47\tValidation loss: 0.493069\tBest loss: 0.493069\tAccuracy: 89.00%\n",
      "48\tValidation loss: 0.489798\tBest loss: 0.489798\tAccuracy: 88.90%\n",
      "49\tValidation loss: 0.487799\tBest loss: 0.487799\tAccuracy: 88.80%\n",
      "50\tValidation loss: 0.495156\tBest loss: 0.487799\tAccuracy: 88.30%\n",
      "51\tValidation loss: 0.482153\tBest loss: 0.482153\tAccuracy: 89.40%\n",
      "52\tValidation loss: 0.479043\tBest loss: 0.479043\tAccuracy: 89.30%\n",
      "53\tValidation loss: 0.483605\tBest loss: 0.479043\tAccuracy: 88.80%\n",
      "54\tValidation loss: 0.470937\tBest loss: 0.470937\tAccuracy: 89.60%\n",
      "55\tValidation loss: 0.476476\tBest loss: 0.470937\tAccuracy: 89.70%\n",
      "56\tValidation loss: 0.470151\tBest loss: 0.470151\tAccuracy: 89.00%\n",
      "57\tValidation loss: 0.468865\tBest loss: 0.468865\tAccuracy: 89.60%\n",
      "58\tValidation loss: 0.460787\tBest loss: 0.460787\tAccuracy: 89.70%\n",
      "59\tValidation loss: 0.460421\tBest loss: 0.460421\tAccuracy: 89.40%\n",
      "60\tValidation loss: 0.460551\tBest loss: 0.460421\tAccuracy: 89.20%\n",
      "61\tValidation loss: 0.463770\tBest loss: 0.460421\tAccuracy: 89.20%\n",
      "62\tValidation loss: 0.463677\tBest loss: 0.460421\tAccuracy: 88.90%\n",
      "63\tValidation loss: 0.440391\tBest loss: 0.440391\tAccuracy: 89.70%\n",
      "64\tValidation loss: 0.444254\tBest loss: 0.440391\tAccuracy: 89.60%\n",
      "65\tValidation loss: 0.448259\tBest loss: 0.440391\tAccuracy: 89.60%\n",
      "66\tValidation loss: 0.439079\tBest loss: 0.439079\tAccuracy: 90.20%\n",
      "67\tValidation loss: 0.446567\tBest loss: 0.439079\tAccuracy: 89.90%\n",
      "68\tValidation loss: 0.432301\tBest loss: 0.432301\tAccuracy: 90.50%\n",
      "69\tValidation loss: 0.437828\tBest loss: 0.432301\tAccuracy: 90.50%\n",
      "70\tValidation loss: 0.437103\tBest loss: 0.432301\tAccuracy: 89.80%\n",
      "71\tValidation loss: 0.438104\tBest loss: 0.432301\tAccuracy: 89.50%\n",
      "72\tValidation loss: 0.425957\tBest loss: 0.425957\tAccuracy: 90.30%\n",
      "73\tValidation loss: 0.430450\tBest loss: 0.425957\tAccuracy: 89.80%\n",
      "74\tValidation loss: 0.430084\tBest loss: 0.425957\tAccuracy: 90.20%\n",
      "75\tValidation loss: 0.432433\tBest loss: 0.425957\tAccuracy: 89.80%\n",
      "76\tValidation loss: 0.425807\tBest loss: 0.425807\tAccuracy: 90.30%\n",
      "77\tValidation loss: 0.429943\tBest loss: 0.425807\tAccuracy: 89.90%\n",
      "78\tValidation loss: 0.419314\tBest loss: 0.419314\tAccuracy: 89.70%\n",
      "79\tValidation loss: 0.423774\tBest loss: 0.419314\tAccuracy: 89.70%\n",
      "80\tValidation loss: 0.418506\tBest loss: 0.418506\tAccuracy: 90.00%\n",
      "81\tValidation loss: 0.416334\tBest loss: 0.416334\tAccuracy: 90.80%\n",
      "82\tValidation loss: 0.414108\tBest loss: 0.414108\tAccuracy: 90.50%\n",
      "83\tValidation loss: 0.419275\tBest loss: 0.414108\tAccuracy: 90.30%\n",
      "84\tValidation loss: 0.412086\tBest loss: 0.412086\tAccuracy: 90.00%\n",
      "85\tValidation loss: 0.418415\tBest loss: 0.412086\tAccuracy: 90.70%\n",
      "86\tValidation loss: 0.411712\tBest loss: 0.411712\tAccuracy: 90.60%\n",
      "87\tValidation loss: 0.412458\tBest loss: 0.411712\tAccuracy: 90.30%\n",
      "88\tValidation loss: 0.398302\tBest loss: 0.398302\tAccuracy: 91.20%\n",
      "89\tValidation loss: 0.405454\tBest loss: 0.398302\tAccuracy: 91.10%\n",
      "90\tValidation loss: 0.399251\tBest loss: 0.398302\tAccuracy: 90.60%\n",
      "91\tValidation loss: 0.403788\tBest loss: 0.398302\tAccuracy: 90.60%\n",
      "92\tValidation loss: 0.412752\tBest loss: 0.398302\tAccuracy: 90.40%\n",
      "93\tValidation loss: 0.403571\tBest loss: 0.398302\tAccuracy: 91.10%\n",
      "94\tValidation loss: 0.402435\tBest loss: 0.398302\tAccuracy: 90.80%\n",
      "95\tValidation loss: 0.386422\tBest loss: 0.386422\tAccuracy: 91.30%\n",
      "96\tValidation loss: 0.394724\tBest loss: 0.386422\tAccuracy: 90.10%\n",
      "97\tValidation loss: 0.403148\tBest loss: 0.386422\tAccuracy: 90.40%\n",
      "98\tValidation loss: 0.395244\tBest loss: 0.386422\tAccuracy: 91.00%\n",
      "99\tValidation loss: 0.391263\tBest loss: 0.386422\tAccuracy: 90.70%\n",
      "100\tValidation loss: 0.400324\tBest loss: 0.386422\tAccuracy: 90.70%\n",
      "101\tValidation loss: 0.392342\tBest loss: 0.386422\tAccuracy: 90.90%\n",
      "102\tValidation loss: 0.389031\tBest loss: 0.386422\tAccuracy: 91.00%\n",
      "103\tValidation loss: 0.391347\tBest loss: 0.386422\tAccuracy: 91.30%\n",
      "104\tValidation loss: 0.391890\tBest loss: 0.386422\tAccuracy: 90.40%\n",
      "105\tValidation loss: 0.394827\tBest loss: 0.386422\tAccuracy: 90.70%\n",
      "106\tValidation loss: 0.388331\tBest loss: 0.386422\tAccuracy: 91.00%\n",
      "107\tValidation loss: 0.394368\tBest loss: 0.386422\tAccuracy: 90.70%\n",
      "108\tValidation loss: 0.393705\tBest loss: 0.386422\tAccuracy: 90.90%\n",
      "109\tValidation loss: 0.387252\tBest loss: 0.386422\tAccuracy: 90.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\tValidation loss: 0.385634\tBest loss: 0.385634\tAccuracy: 90.80%\n",
      "111\tValidation loss: 0.394390\tBest loss: 0.385634\tAccuracy: 90.60%\n",
      "112\tValidation loss: 0.383792\tBest loss: 0.383792\tAccuracy: 90.60%\n",
      "113\tValidation loss: 0.383040\tBest loss: 0.383040\tAccuracy: 90.80%\n",
      "114\tValidation loss: 0.394262\tBest loss: 0.383040\tAccuracy: 90.80%\n",
      "115\tValidation loss: 0.379492\tBest loss: 0.379492\tAccuracy: 91.20%\n",
      "116\tValidation loss: 0.385332\tBest loss: 0.379492\tAccuracy: 90.90%\n",
      "117\tValidation loss: 0.383225\tBest loss: 0.379492\tAccuracy: 90.50%\n",
      "118\tValidation loss: 0.370677\tBest loss: 0.370677\tAccuracy: 91.40%\n",
      "119\tValidation loss: 0.377549\tBest loss: 0.370677\tAccuracy: 91.20%\n",
      "120\tValidation loss: 0.374958\tBest loss: 0.370677\tAccuracy: 91.00%\n",
      "121\tValidation loss: 0.376493\tBest loss: 0.370677\tAccuracy: 91.50%\n",
      "122\tValidation loss: 0.374876\tBest loss: 0.370677\tAccuracy: 91.00%\n",
      "123\tValidation loss: 0.379791\tBest loss: 0.370677\tAccuracy: 91.20%\n",
      "124\tValidation loss: 0.372973\tBest loss: 0.370677\tAccuracy: 91.20%\n",
      "125\tValidation loss: 0.374995\tBest loss: 0.370677\tAccuracy: 91.20%\n",
      "126\tValidation loss: 0.373070\tBest loss: 0.370677\tAccuracy: 91.20%\n",
      "127\tValidation loss: 0.380686\tBest loss: 0.370677\tAccuracy: 90.50%\n",
      "128\tValidation loss: 0.373183\tBest loss: 0.370677\tAccuracy: 91.10%\n",
      "129\tValidation loss: 0.371994\tBest loss: 0.370677\tAccuracy: 90.90%\n",
      "130\tValidation loss: 0.367469\tBest loss: 0.367469\tAccuracy: 91.50%\n",
      "131\tValidation loss: 0.370532\tBest loss: 0.367469\tAccuracy: 91.40%\n",
      "132\tValidation loss: 0.366759\tBest loss: 0.366759\tAccuracy: 91.50%\n",
      "133\tValidation loss: 0.379890\tBest loss: 0.366759\tAccuracy: 91.10%\n",
      "134\tValidation loss: 0.364407\tBest loss: 0.364407\tAccuracy: 91.60%\n",
      "135\tValidation loss: 0.372544\tBest loss: 0.364407\tAccuracy: 91.30%\n",
      "136\tValidation loss: 0.369351\tBest loss: 0.364407\tAccuracy: 91.10%\n",
      "137\tValidation loss: 0.366635\tBest loss: 0.364407\tAccuracy: 91.40%\n",
      "138\tValidation loss: 0.366470\tBest loss: 0.364407\tAccuracy: 91.20%\n",
      "139\tValidation loss: 0.361885\tBest loss: 0.361885\tAccuracy: 91.70%\n",
      "140\tValidation loss: 0.369910\tBest loss: 0.361885\tAccuracy: 91.30%\n",
      "141\tValidation loss: 0.364542\tBest loss: 0.361885\tAccuracy: 91.40%\n",
      "142\tValidation loss: 0.357592\tBest loss: 0.357592\tAccuracy: 91.80%\n",
      "143\tValidation loss: 0.365900\tBest loss: 0.357592\tAccuracy: 91.40%\n",
      "144\tValidation loss: 0.362039\tBest loss: 0.357592\tAccuracy: 92.10%\n",
      "145\tValidation loss: 0.367197\tBest loss: 0.357592\tAccuracy: 91.40%\n",
      "146\tValidation loss: 0.366052\tBest loss: 0.357592\tAccuracy: 91.40%\n",
      "147\tValidation loss: 0.370772\tBest loss: 0.357592\tAccuracy: 91.20%\n",
      "148\tValidation loss: 0.359678\tBest loss: 0.357592\tAccuracy: 91.30%\n",
      "149\tValidation loss: 0.358019\tBest loss: 0.357592\tAccuracy: 91.10%\n",
      "150\tValidation loss: 0.361996\tBest loss: 0.357592\tAccuracy: 91.60%\n",
      "151\tValidation loss: 0.357198\tBest loss: 0.357198\tAccuracy: 92.00%\n",
      "152\tValidation loss: 0.356664\tBest loss: 0.356664\tAccuracy: 91.50%\n",
      "153\tValidation loss: 0.360578\tBest loss: 0.356664\tAccuracy: 91.80%\n",
      "154\tValidation loss: 0.363007\tBest loss: 0.356664\tAccuracy: 91.90%\n",
      "155\tValidation loss: 0.358010\tBest loss: 0.356664\tAccuracy: 91.60%\n",
      "156\tValidation loss: 0.356262\tBest loss: 0.356262\tAccuracy: 91.80%\n",
      "157\tValidation loss: 0.361748\tBest loss: 0.356262\tAccuracy: 91.40%\n",
      "158\tValidation loss: 0.353143\tBest loss: 0.353143\tAccuracy: 92.10%\n",
      "159\tValidation loss: 0.356044\tBest loss: 0.353143\tAccuracy: 91.70%\n",
      "160\tValidation loss: 0.363101\tBest loss: 0.353143\tAccuracy: 91.90%\n",
      "161\tValidation loss: 0.353992\tBest loss: 0.353143\tAccuracy: 92.10%\n",
      "162\tValidation loss: 0.354899\tBest loss: 0.353143\tAccuracy: 91.80%\n",
      "163\tValidation loss: 0.352261\tBest loss: 0.352261\tAccuracy: 91.60%\n",
      "164\tValidation loss: 0.356112\tBest loss: 0.352261\tAccuracy: 91.90%\n",
      "165\tValidation loss: 0.351558\tBest loss: 0.351558\tAccuracy: 91.80%\n",
      "166\tValidation loss: 0.358673\tBest loss: 0.351558\tAccuracy: 91.90%\n",
      "167\tValidation loss: 0.349761\tBest loss: 0.349761\tAccuracy: 91.90%\n",
      "168\tValidation loss: 0.355890\tBest loss: 0.349761\tAccuracy: 92.20%\n",
      "169\tValidation loss: 0.350913\tBest loss: 0.349761\tAccuracy: 91.90%\n",
      "170\tValidation loss: 0.358593\tBest loss: 0.349761\tAccuracy: 91.70%\n",
      "171\tValidation loss: 0.354346\tBest loss: 0.349761\tAccuracy: 91.80%\n",
      "172\tValidation loss: 0.348979\tBest loss: 0.348979\tAccuracy: 91.80%\n",
      "173\tValidation loss: 0.348884\tBest loss: 0.348884\tAccuracy: 92.30%\n",
      "174\tValidation loss: 0.356204\tBest loss: 0.348884\tAccuracy: 91.90%\n",
      "175\tValidation loss: 0.352284\tBest loss: 0.348884\tAccuracy: 92.10%\n",
      "176\tValidation loss: 0.345504\tBest loss: 0.345504\tAccuracy: 92.20%\n",
      "177\tValidation loss: 0.349008\tBest loss: 0.345504\tAccuracy: 92.00%\n",
      "178\tValidation loss: 0.354798\tBest loss: 0.345504\tAccuracy: 92.10%\n",
      "179\tValidation loss: 0.348413\tBest loss: 0.345504\tAccuracy: 92.20%\n",
      "180\tValidation loss: 0.348165\tBest loss: 0.345504\tAccuracy: 92.00%\n",
      "181\tValidation loss: 0.349508\tBest loss: 0.345504\tAccuracy: 92.30%\n",
      "182\tValidation loss: 0.350079\tBest loss: 0.345504\tAccuracy: 92.10%\n",
      "183\tValidation loss: 0.346906\tBest loss: 0.345504\tAccuracy: 92.30%\n",
      "184\tValidation loss: 0.352662\tBest loss: 0.345504\tAccuracy: 91.90%\n",
      "185\tValidation loss: 0.350795\tBest loss: 0.345504\tAccuracy: 91.70%\n",
      "186\tValidation loss: 0.345273\tBest loss: 0.345273\tAccuracy: 92.10%\n",
      "187\tValidation loss: 0.346352\tBest loss: 0.345273\tAccuracy: 92.00%\n",
      "188\tValidation loss: 0.343172\tBest loss: 0.343172\tAccuracy: 92.30%\n",
      "189\tValidation loss: 0.347180\tBest loss: 0.343172\tAccuracy: 91.90%\n",
      "190\tValidation loss: 0.346051\tBest loss: 0.343172\tAccuracy: 91.90%\n",
      "191\tValidation loss: 0.346466\tBest loss: 0.343172\tAccuracy: 92.30%\n",
      "192\tValidation loss: 0.340415\tBest loss: 0.340415\tAccuracy: 92.30%\n",
      "193\tValidation loss: 0.342946\tBest loss: 0.340415\tAccuracy: 92.30%\n",
      "194\tValidation loss: 0.347861\tBest loss: 0.340415\tAccuracy: 92.30%\n",
      "195\tValidation loss: 0.348368\tBest loss: 0.340415\tAccuracy: 91.70%\n",
      "196\tValidation loss: 0.341366\tBest loss: 0.340415\tAccuracy: 92.20%\n",
      "197\tValidation loss: 0.349126\tBest loss: 0.340415\tAccuracy: 92.00%\n",
      "198\tValidation loss: 0.353486\tBest loss: 0.340415\tAccuracy: 92.20%\n",
      "199\tValidation loss: 0.344118\tBest loss: 0.340415\tAccuracy: 92.20%\n",
      "200\tValidation loss: 0.344183\tBest loss: 0.340415\tAccuracy: 92.60%\n",
      "201\tValidation loss: 0.339740\tBest loss: 0.339740\tAccuracy: 92.50%\n",
      "202\tValidation loss: 0.340015\tBest loss: 0.339740\tAccuracy: 92.70%\n",
      "203\tValidation loss: 0.344259\tBest loss: 0.339740\tAccuracy: 92.10%\n",
      "204\tValidation loss: 0.341063\tBest loss: 0.339740\tAccuracy: 92.30%\n",
      "205\tValidation loss: 0.346360\tBest loss: 0.339740\tAccuracy: 91.90%\n",
      "206\tValidation loss: 0.341033\tBest loss: 0.339740\tAccuracy: 92.20%\n",
      "207\tValidation loss: 0.346113\tBest loss: 0.339740\tAccuracy: 92.50%\n",
      "208\tValidation loss: 0.346978\tBest loss: 0.339740\tAccuracy: 92.30%\n",
      "209\tValidation loss: 0.344038\tBest loss: 0.339740\tAccuracy: 92.30%\n",
      "210\tValidation loss: 0.345072\tBest loss: 0.339740\tAccuracy: 92.00%\n",
      "211\tValidation loss: 0.341053\tBest loss: 0.339740\tAccuracy: 92.10%\n",
      "212\tValidation loss: 0.342004\tBest loss: 0.339740\tAccuracy: 92.30%\n",
      "213\tValidation loss: 0.339551\tBest loss: 0.339551\tAccuracy: 92.30%\n",
      "214\tValidation loss: 0.340255\tBest loss: 0.339551\tAccuracy: 92.30%\n",
      "215\tValidation loss: 0.344268\tBest loss: 0.339551\tAccuracy: 92.20%\n",
      "216\tValidation loss: 0.335778\tBest loss: 0.335778\tAccuracy: 92.80%\n",
      "217\tValidation loss: 0.337824\tBest loss: 0.335778\tAccuracy: 91.90%\n",
      "218\tValidation loss: 0.341264\tBest loss: 0.335778\tAccuracy: 92.30%\n",
      "219\tValidation loss: 0.341611\tBest loss: 0.335778\tAccuracy: 92.30%\n",
      "220\tValidation loss: 0.337687\tBest loss: 0.335778\tAccuracy: 92.20%\n",
      "221\tValidation loss: 0.342553\tBest loss: 0.335778\tAccuracy: 92.30%\n",
      "222\tValidation loss: 0.341975\tBest loss: 0.335778\tAccuracy: 92.40%\n",
      "223\tValidation loss: 0.338818\tBest loss: 0.335778\tAccuracy: 92.30%\n",
      "224\tValidation loss: 0.341215\tBest loss: 0.335778\tAccuracy: 92.50%\n",
      "225\tValidation loss: 0.341913\tBest loss: 0.335778\tAccuracy: 92.40%\n",
      "226\tValidation loss: 0.337947\tBest loss: 0.335778\tAccuracy: 92.40%\n",
      "227\tValidation loss: 0.335532\tBest loss: 0.335532\tAccuracy: 92.20%\n",
      "228\tValidation loss: 0.337069\tBest loss: 0.335532\tAccuracy: 92.80%\n",
      "229\tValidation loss: 0.338047\tBest loss: 0.335532\tAccuracy: 92.60%\n",
      "230\tValidation loss: 0.340883\tBest loss: 0.335532\tAccuracy: 92.30%\n",
      "231\tValidation loss: 0.334168\tBest loss: 0.334168\tAccuracy: 92.90%\n",
      "232\tValidation loss: 0.336372\tBest loss: 0.334168\tAccuracy: 92.40%\n",
      "233\tValidation loss: 0.335595\tBest loss: 0.334168\tAccuracy: 92.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\tValidation loss: 0.340100\tBest loss: 0.334168\tAccuracy: 92.50%\n",
      "235\tValidation loss: 0.343077\tBest loss: 0.334168\tAccuracy: 92.20%\n",
      "236\tValidation loss: 0.336080\tBest loss: 0.334168\tAccuracy: 92.40%\n",
      "237\tValidation loss: 0.338149\tBest loss: 0.334168\tAccuracy: 92.50%\n",
      "238\tValidation loss: 0.337535\tBest loss: 0.334168\tAccuracy: 92.60%\n",
      "239\tValidation loss: 0.335925\tBest loss: 0.334168\tAccuracy: 92.60%\n",
      "240\tValidation loss: 0.337168\tBest loss: 0.334168\tAccuracy: 92.10%\n",
      "241\tValidation loss: 0.339140\tBest loss: 0.334168\tAccuracy: 92.40%\n",
      "242\tValidation loss: 0.340845\tBest loss: 0.334168\tAccuracy: 92.30%\n",
      "243\tValidation loss: 0.339051\tBest loss: 0.334168\tAccuracy: 92.70%\n",
      "244\tValidation loss: 0.341295\tBest loss: 0.334168\tAccuracy: 92.60%\n",
      "245\tValidation loss: 0.341703\tBest loss: 0.334168\tAccuracy: 92.50%\n",
      "246\tValidation loss: 0.343369\tBest loss: 0.334168\tAccuracy: 92.60%\n",
      "247\tValidation loss: 0.332772\tBest loss: 0.332772\tAccuracy: 92.80%\n",
      "248\tValidation loss: 0.334683\tBest loss: 0.332772\tAccuracy: 93.00%\n",
      "249\tValidation loss: 0.334096\tBest loss: 0.332772\tAccuracy: 92.60%\n",
      "250\tValidation loss: 0.332717\tBest loss: 0.332717\tAccuracy: 92.60%\n",
      "251\tValidation loss: 0.333429\tBest loss: 0.332717\tAccuracy: 92.60%\n",
      "252\tValidation loss: 0.331501\tBest loss: 0.331501\tAccuracy: 92.80%\n",
      "253\tValidation loss: 0.338738\tBest loss: 0.331501\tAccuracy: 92.60%\n",
      "254\tValidation loss: 0.335946\tBest loss: 0.331501\tAccuracy: 92.80%\n",
      "255\tValidation loss: 0.338521\tBest loss: 0.331501\tAccuracy: 92.90%\n",
      "256\tValidation loss: 0.329589\tBest loss: 0.329589\tAccuracy: 92.80%\n",
      "257\tValidation loss: 0.343307\tBest loss: 0.329589\tAccuracy: 92.20%\n",
      "258\tValidation loss: 0.336621\tBest loss: 0.329589\tAccuracy: 92.70%\n",
      "259\tValidation loss: 0.338034\tBest loss: 0.329589\tAccuracy: 92.50%\n",
      "260\tValidation loss: 0.336776\tBest loss: 0.329589\tAccuracy: 92.40%\n",
      "261\tValidation loss: 0.335303\tBest loss: 0.329589\tAccuracy: 92.70%\n",
      "262\tValidation loss: 0.336627\tBest loss: 0.329589\tAccuracy: 92.20%\n",
      "263\tValidation loss: 0.332034\tBest loss: 0.329589\tAccuracy: 93.00%\n",
      "264\tValidation loss: 0.330458\tBest loss: 0.329589\tAccuracy: 93.00%\n",
      "265\tValidation loss: 0.334719\tBest loss: 0.329589\tAccuracy: 92.60%\n",
      "266\tValidation loss: 0.338114\tBest loss: 0.329589\tAccuracy: 92.50%\n",
      "267\tValidation loss: 0.330549\tBest loss: 0.329589\tAccuracy: 92.60%\n",
      "268\tValidation loss: 0.337281\tBest loss: 0.329589\tAccuracy: 92.70%\n",
      "269\tValidation loss: 0.332431\tBest loss: 0.329589\tAccuracy: 92.80%\n",
      "270\tValidation loss: 0.338552\tBest loss: 0.329589\tAccuracy: 92.80%\n",
      "271\tValidation loss: 0.329851\tBest loss: 0.329589\tAccuracy: 92.60%\n",
      "272\tValidation loss: 0.330662\tBest loss: 0.329589\tAccuracy: 92.70%\n",
      "273\tValidation loss: 0.335342\tBest loss: 0.329589\tAccuracy: 92.90%\n",
      "274\tValidation loss: 0.333342\tBest loss: 0.329589\tAccuracy: 92.80%\n",
      "275\tValidation loss: 0.337079\tBest loss: 0.329589\tAccuracy: 92.40%\n",
      "276\tValidation loss: 0.335577\tBest loss: 0.329589\tAccuracy: 93.20%\n",
      "277\tValidation loss: 0.332803\tBest loss: 0.329589\tAccuracy: 92.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=700, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  41.2s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.187964\tBest loss: 4.187964\tAccuracy: 7.40%\n",
      "1\tValidation loss: 15.185635\tBest loss: 4.187964\tAccuracy: 9.50%\n",
      "2\tValidation loss: 8.052714\tBest loss: 4.187964\tAccuracy: 20.60%\n",
      "3\tValidation loss: 11.045601\tBest loss: 4.187964\tAccuracy: 31.00%\n",
      "4\tValidation loss: 5.159352\tBest loss: 4.187964\tAccuracy: 50.90%\n",
      "5\tValidation loss: 8.385424\tBest loss: 4.187964\tAccuracy: 50.00%\n",
      "6\tValidation loss: 44.679668\tBest loss: 4.187964\tAccuracy: 32.20%\n",
      "7\tValidation loss: 2.396338\tBest loss: 2.396338\tAccuracy: 74.10%\n",
      "8\tValidation loss: 5.780647\tBest loss: 2.396338\tAccuracy: 65.70%\n",
      "9\tValidation loss: 13.604178\tBest loss: 2.396338\tAccuracy: 56.60%\n",
      "10\tValidation loss: 24.928181\tBest loss: 2.396338\tAccuracy: 52.50%\n",
      "11\tValidation loss: 12.838181\tBest loss: 2.396338\tAccuracy: 59.30%\n",
      "12\tValidation loss: 13.110853\tBest loss: 2.396338\tAccuracy: 67.10%\n",
      "13\tValidation loss: 4.103381\tBest loss: 2.396338\tAccuracy: 78.50%\n",
      "14\tValidation loss: 9.221582\tBest loss: 2.396338\tAccuracy: 68.10%\n",
      "15\tValidation loss: 8.084255\tBest loss: 2.396338\tAccuracy: 73.00%\n",
      "16\tValidation loss: 4.834909\tBest loss: 2.396338\tAccuracy: 77.70%\n",
      "17\tValidation loss: 3.530120\tBest loss: 2.396338\tAccuracy: 84.00%\n",
      "18\tValidation loss: 8.667038\tBest loss: 2.396338\tAccuracy: 76.00%\n",
      "19\tValidation loss: 3.121441\tBest loss: 2.396338\tAccuracy: 86.00%\n",
      "20\tValidation loss: 6.708883\tBest loss: 2.396338\tAccuracy: 81.40%\n",
      "21\tValidation loss: 4.241263\tBest loss: 2.396338\tAccuracy: 86.20%\n",
      "22\tValidation loss: 6.093452\tBest loss: 2.396338\tAccuracy: 83.40%\n",
      "23\tValidation loss: 5.970113\tBest loss: 2.396338\tAccuracy: 84.20%\n",
      "24\tValidation loss: 8.829748\tBest loss: 2.396338\tAccuracy: 83.60%\n",
      "25\tValidation loss: 3.914033\tBest loss: 2.396338\tAccuracy: 89.40%\n",
      "26\tValidation loss: 4.914263\tBest loss: 2.396338\tAccuracy: 87.00%\n",
      "27\tValidation loss: 5.155623\tBest loss: 2.396338\tAccuracy: 87.60%\n",
      "28\tValidation loss: 6.929249\tBest loss: 2.396338\tAccuracy: 84.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.0s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 6.622978\tBest loss: 6.622978\tAccuracy: 6.80%\n",
      "1\tValidation loss: 6.676571\tBest loss: 6.622978\tAccuracy: 10.40%\n",
      "2\tValidation loss: 13.656725\tBest loss: 6.622978\tAccuracy: 14.60%\n",
      "3\tValidation loss: 15.568680\tBest loss: 6.622978\tAccuracy: 20.00%\n",
      "4\tValidation loss: 12.984701\tBest loss: 6.622978\tAccuracy: 32.30%\n",
      "5\tValidation loss: 11.940299\tBest loss: 6.622978\tAccuracy: 36.60%\n",
      "6\tValidation loss: 5.560163\tBest loss: 5.560163\tAccuracy: 56.70%\n",
      "7\tValidation loss: 21.357561\tBest loss: 5.560163\tAccuracy: 46.90%\n",
      "8\tValidation loss: 12.143194\tBest loss: 5.560163\tAccuracy: 52.00%\n",
      "9\tValidation loss: 5.421223\tBest loss: 5.421223\tAccuracy: 74.00%\n",
      "10\tValidation loss: 10.970413\tBest loss: 5.421223\tAccuracy: 61.20%\n",
      "11\tValidation loss: 4.498408\tBest loss: 4.498408\tAccuracy: 75.10%\n",
      "12\tValidation loss: 4.750786\tBest loss: 4.498408\tAccuracy: 76.10%\n",
      "13\tValidation loss: 3.348557\tBest loss: 3.348557\tAccuracy: 78.80%\n",
      "14\tValidation loss: 13.158540\tBest loss: 3.348557\tAccuracy: 65.80%\n",
      "15\tValidation loss: 2.955225\tBest loss: 2.955225\tAccuracy: 81.30%\n",
      "16\tValidation loss: 5.960156\tBest loss: 2.955225\tAccuracy: 76.20%\n",
      "17\tValidation loss: 6.153840\tBest loss: 2.955225\tAccuracy: 77.80%\n",
      "18\tValidation loss: 8.575047\tBest loss: 2.955225\tAccuracy: 75.90%\n",
      "19\tValidation loss: 3.999129\tBest loss: 2.955225\tAccuracy: 86.00%\n",
      "20\tValidation loss: 6.861756\tBest loss: 2.955225\tAccuracy: 80.40%\n",
      "21\tValidation loss: 6.232603\tBest loss: 2.955225\tAccuracy: 82.20%\n",
      "22\tValidation loss: 16.325918\tBest loss: 2.955225\tAccuracy: 69.10%\n",
      "23\tValidation loss: 6.832651\tBest loss: 2.955225\tAccuracy: 84.50%\n",
      "24\tValidation loss: 8.250599\tBest loss: 2.955225\tAccuracy: 81.40%\n",
      "25\tValidation loss: 7.388214\tBest loss: 2.955225\tAccuracy: 84.90%\n",
      "26\tValidation loss: 8.245102\tBest loss: 2.955225\tAccuracy: 84.60%\n",
      "27\tValidation loss: 10.417103\tBest loss: 2.955225\tAccuracy: 82.00%\n",
      "28\tValidation loss: 9.880414\tBest loss: 2.955225\tAccuracy: 81.70%\n",
      "29\tValidation loss: 6.282064\tBest loss: 2.955225\tAccuracy: 85.50%\n",
      "30\tValidation loss: 7.305283\tBest loss: 2.955225\tAccuracy: 83.30%\n",
      "31\tValidation loss: 9.094321\tBest loss: 2.955225\tAccuracy: 84.30%\n",
      "32\tValidation loss: 5.284858\tBest loss: 2.955225\tAccuracy: 88.30%\n",
      "33\tValidation loss: 7.109110\tBest loss: 2.955225\tAccuracy: 88.70%\n",
      "34\tValidation loss: 9.952554\tBest loss: 2.955225\tAccuracy: 85.10%\n",
      "35\tValidation loss: 5.987275\tBest loss: 2.955225\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\tValidation loss: 12.908136\tBest loss: 2.955225\tAccuracy: 83.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.9s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.371195\tBest loss: 5.371195\tAccuracy: 11.00%\n",
      "1\tValidation loss: 7.515520\tBest loss: 5.371195\tAccuracy: 6.50%\n",
      "2\tValidation loss: 8.071149\tBest loss: 5.371195\tAccuracy: 21.90%\n",
      "3\tValidation loss: 29.085209\tBest loss: 5.371195\tAccuracy: 17.80%\n",
      "4\tValidation loss: 2.966209\tBest loss: 2.966209\tAccuracy: 56.70%\n",
      "5\tValidation loss: 5.752024\tBest loss: 2.966209\tAccuracy: 55.30%\n",
      "6\tValidation loss: 4.761713\tBest loss: 2.966209\tAccuracy: 59.10%\n",
      "7\tValidation loss: 10.363197\tBest loss: 2.966209\tAccuracy: 50.50%\n",
      "8\tValidation loss: 3.086626\tBest loss: 2.966209\tAccuracy: 71.60%\n",
      "9\tValidation loss: 4.854104\tBest loss: 2.966209\tAccuracy: 72.30%\n",
      "10\tValidation loss: 3.175681\tBest loss: 2.966209\tAccuracy: 76.00%\n",
      "11\tValidation loss: 3.906777\tBest loss: 2.966209\tAccuracy: 76.80%\n",
      "12\tValidation loss: 6.675536\tBest loss: 2.966209\tAccuracy: 69.20%\n",
      "13\tValidation loss: 9.993235\tBest loss: 2.966209\tAccuracy: 67.70%\n",
      "14\tValidation loss: 3.380455\tBest loss: 2.966209\tAccuracy: 80.20%\n",
      "15\tValidation loss: 20.073606\tBest loss: 2.966209\tAccuracy: 59.90%\n",
      "16\tValidation loss: 3.388555\tBest loss: 2.966209\tAccuracy: 83.70%\n",
      "17\tValidation loss: 3.148135\tBest loss: 2.966209\tAccuracy: 83.40%\n",
      "18\tValidation loss: 4.757019\tBest loss: 2.966209\tAccuracy: 82.10%\n",
      "19\tValidation loss: 7.973946\tBest loss: 2.966209\tAccuracy: 75.90%\n",
      "20\tValidation loss: 2.751063\tBest loss: 2.751063\tAccuracy: 86.00%\n",
      "21\tValidation loss: 8.416082\tBest loss: 2.751063\tAccuracy: 78.30%\n",
      "22\tValidation loss: 4.903893\tBest loss: 2.751063\tAccuracy: 84.50%\n",
      "23\tValidation loss: 4.843922\tBest loss: 2.751063\tAccuracy: 84.50%\n",
      "24\tValidation loss: 5.956282\tBest loss: 2.751063\tAccuracy: 82.20%\n",
      "25\tValidation loss: 13.855841\tBest loss: 2.751063\tAccuracy: 78.40%\n",
      "26\tValidation loss: 3.916583\tBest loss: 2.751063\tAccuracy: 88.40%\n",
      "27\tValidation loss: 11.503770\tBest loss: 2.751063\tAccuracy: 79.10%\n",
      "28\tValidation loss: 8.304289\tBest loss: 2.751063\tAccuracy: 83.20%\n",
      "29\tValidation loss: 5.844334\tBest loss: 2.751063\tAccuracy: 88.20%\n",
      "30\tValidation loss: 5.547679\tBest loss: 2.751063\tAccuracy: 86.20%\n",
      "31\tValidation loss: 11.244419\tBest loss: 2.751063\tAccuracy: 82.70%\n",
      "32\tValidation loss: 6.202929\tBest loss: 2.751063\tAccuracy: 86.40%\n",
      "33\tValidation loss: 3.896756\tBest loss: 2.751063\tAccuracy: 90.10%\n",
      "34\tValidation loss: 5.799248\tBest loss: 2.751063\tAccuracy: 87.10%\n",
      "35\tValidation loss: 8.234026\tBest loss: 2.751063\tAccuracy: 85.60%\n",
      "36\tValidation loss: 3.900330\tBest loss: 2.751063\tAccuracy: 91.40%\n",
      "37\tValidation loss: 5.755587\tBest loss: 2.751063\tAccuracy: 88.50%\n",
      "38\tValidation loss: 5.098182\tBest loss: 2.751063\tAccuracy: 90.10%\n",
      "39\tValidation loss: 8.280446\tBest loss: 2.751063\tAccuracy: 87.50%\n",
      "40\tValidation loss: 7.110328\tBest loss: 2.751063\tAccuracy: 88.80%\n",
      "41\tValidation loss: 8.196454\tBest loss: 2.751063\tAccuracy: 88.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   5.5s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.234129\tBest loss: 3.234129\tAccuracy: 20.80%\n",
      "1\tValidation loss: 2.760618\tBest loss: 2.760618\tAccuracy: 35.50%\n",
      "2\tValidation loss: 2.447614\tBest loss: 2.447614\tAccuracy: 42.80%\n",
      "3\tValidation loss: 2.218738\tBest loss: 2.218738\tAccuracy: 48.20%\n",
      "4\tValidation loss: 2.041507\tBest loss: 2.041507\tAccuracy: 51.90%\n",
      "5\tValidation loss: 1.894471\tBest loss: 1.894471\tAccuracy: 55.00%\n",
      "6\tValidation loss: 1.773328\tBest loss: 1.773328\tAccuracy: 59.10%\n",
      "7\tValidation loss: 1.677525\tBest loss: 1.677525\tAccuracy: 60.90%\n",
      "8\tValidation loss: 1.595229\tBest loss: 1.595229\tAccuracy: 62.80%\n",
      "9\tValidation loss: 1.519701\tBest loss: 1.519701\tAccuracy: 64.40%\n",
      "10\tValidation loss: 1.464463\tBest loss: 1.464463\tAccuracy: 66.00%\n",
      "11\tValidation loss: 1.404015\tBest loss: 1.404015\tAccuracy: 68.20%\n",
      "12\tValidation loss: 1.361962\tBest loss: 1.361962\tAccuracy: 68.20%\n",
      "13\tValidation loss: 1.315915\tBest loss: 1.315915\tAccuracy: 69.80%\n",
      "14\tValidation loss: 1.275990\tBest loss: 1.275990\tAccuracy: 70.40%\n",
      "15\tValidation loss: 1.236963\tBest loss: 1.236963\tAccuracy: 70.70%\n",
      "16\tValidation loss: 1.201039\tBest loss: 1.201039\tAccuracy: 72.40%\n",
      "17\tValidation loss: 1.172814\tBest loss: 1.172814\tAccuracy: 73.10%\n",
      "18\tValidation loss: 1.145525\tBest loss: 1.145525\tAccuracy: 74.20%\n",
      "19\tValidation loss: 1.120174\tBest loss: 1.120174\tAccuracy: 74.70%\n",
      "20\tValidation loss: 1.098801\tBest loss: 1.098801\tAccuracy: 74.60%\n",
      "21\tValidation loss: 1.073858\tBest loss: 1.073858\tAccuracy: 76.20%\n",
      "22\tValidation loss: 1.057210\tBest loss: 1.057210\tAccuracy: 76.00%\n",
      "23\tValidation loss: 1.041387\tBest loss: 1.041387\tAccuracy: 76.40%\n",
      "24\tValidation loss: 1.026771\tBest loss: 1.026771\tAccuracy: 76.30%\n",
      "25\tValidation loss: 1.006188\tBest loss: 1.006188\tAccuracy: 76.50%\n",
      "26\tValidation loss: 0.991034\tBest loss: 0.991034\tAccuracy: 76.90%\n",
      "27\tValidation loss: 0.980951\tBest loss: 0.980951\tAccuracy: 77.80%\n",
      "28\tValidation loss: 0.963407\tBest loss: 0.963407\tAccuracy: 77.70%\n",
      "29\tValidation loss: 0.950702\tBest loss: 0.950702\tAccuracy: 78.40%\n",
      "30\tValidation loss: 0.940651\tBest loss: 0.940651\tAccuracy: 78.40%\n",
      "31\tValidation loss: 0.922265\tBest loss: 0.922265\tAccuracy: 79.20%\n",
      "32\tValidation loss: 0.915795\tBest loss: 0.915795\tAccuracy: 78.50%\n",
      "33\tValidation loss: 0.904335\tBest loss: 0.904335\tAccuracy: 79.40%\n",
      "34\tValidation loss: 0.893727\tBest loss: 0.893727\tAccuracy: 79.80%\n",
      "35\tValidation loss: 0.884600\tBest loss: 0.884600\tAccuracy: 79.20%\n",
      "36\tValidation loss: 0.869509\tBest loss: 0.869509\tAccuracy: 79.90%\n",
      "37\tValidation loss: 0.868499\tBest loss: 0.868499\tAccuracy: 80.00%\n",
      "38\tValidation loss: 0.859720\tBest loss: 0.859720\tAccuracy: 80.10%\n",
      "39\tValidation loss: 0.848578\tBest loss: 0.848578\tAccuracy: 79.80%\n",
      "40\tValidation loss: 0.844830\tBest loss: 0.844830\tAccuracy: 80.70%\n",
      "41\tValidation loss: 0.839493\tBest loss: 0.839493\tAccuracy: 80.80%\n",
      "42\tValidation loss: 0.826566\tBest loss: 0.826566\tAccuracy: 80.30%\n",
      "43\tValidation loss: 0.819194\tBest loss: 0.819194\tAccuracy: 81.10%\n",
      "44\tValidation loss: 0.812880\tBest loss: 0.812880\tAccuracy: 81.10%\n",
      "45\tValidation loss: 0.805959\tBest loss: 0.805959\tAccuracy: 81.20%\n",
      "46\tValidation loss: 0.799360\tBest loss: 0.799360\tAccuracy: 81.10%\n",
      "47\tValidation loss: 0.793695\tBest loss: 0.793695\tAccuracy: 81.50%\n",
      "48\tValidation loss: 0.790072\tBest loss: 0.790072\tAccuracy: 81.40%\n",
      "49\tValidation loss: 0.785263\tBest loss: 0.785263\tAccuracy: 81.40%\n",
      "50\tValidation loss: 0.776493\tBest loss: 0.776493\tAccuracy: 81.40%\n",
      "51\tValidation loss: 0.772770\tBest loss: 0.772770\tAccuracy: 81.90%\n",
      "52\tValidation loss: 0.764816\tBest loss: 0.764816\tAccuracy: 82.30%\n",
      "53\tValidation loss: 0.761792\tBest loss: 0.761792\tAccuracy: 82.20%\n",
      "54\tValidation loss: 0.753447\tBest loss: 0.753447\tAccuracy: 82.00%\n",
      "55\tValidation loss: 0.751310\tBest loss: 0.751310\tAccuracy: 82.30%\n",
      "56\tValidation loss: 0.749627\tBest loss: 0.749627\tAccuracy: 82.30%\n",
      "57\tValidation loss: 0.743017\tBest loss: 0.743017\tAccuracy: 82.30%\n",
      "58\tValidation loss: 0.739550\tBest loss: 0.739550\tAccuracy: 82.90%\n",
      "59\tValidation loss: 0.734584\tBest loss: 0.734584\tAccuracy: 82.60%\n",
      "60\tValidation loss: 0.730018\tBest loss: 0.730018\tAccuracy: 83.10%\n",
      "61\tValidation loss: 0.725860\tBest loss: 0.725860\tAccuracy: 83.00%\n",
      "62\tValidation loss: 0.722216\tBest loss: 0.722216\tAccuracy: 83.20%\n",
      "63\tValidation loss: 0.717826\tBest loss: 0.717826\tAccuracy: 82.70%\n",
      "64\tValidation loss: 0.711758\tBest loss: 0.711758\tAccuracy: 82.80%\n",
      "65\tValidation loss: 0.709705\tBest loss: 0.709705\tAccuracy: 82.90%\n",
      "66\tValidation loss: 0.708842\tBest loss: 0.708842\tAccuracy: 83.30%\n",
      "67\tValidation loss: 0.702895\tBest loss: 0.702895\tAccuracy: 82.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\tValidation loss: 0.698927\tBest loss: 0.698927\tAccuracy: 83.10%\n",
      "69\tValidation loss: 0.696141\tBest loss: 0.696141\tAccuracy: 82.80%\n",
      "70\tValidation loss: 0.694887\tBest loss: 0.694887\tAccuracy: 83.50%\n",
      "71\tValidation loss: 0.691768\tBest loss: 0.691768\tAccuracy: 82.90%\n",
      "72\tValidation loss: 0.684433\tBest loss: 0.684433\tAccuracy: 83.20%\n",
      "73\tValidation loss: 0.683460\tBest loss: 0.683460\tAccuracy: 83.10%\n",
      "74\tValidation loss: 0.682326\tBest loss: 0.682326\tAccuracy: 83.30%\n",
      "75\tValidation loss: 0.678502\tBest loss: 0.678502\tAccuracy: 83.20%\n",
      "76\tValidation loss: 0.677935\tBest loss: 0.677935\tAccuracy: 83.40%\n",
      "77\tValidation loss: 0.673021\tBest loss: 0.673021\tAccuracy: 83.50%\n",
      "78\tValidation loss: 0.669347\tBest loss: 0.669347\tAccuracy: 83.50%\n",
      "79\tValidation loss: 0.666039\tBest loss: 0.666039\tAccuracy: 83.90%\n",
      "80\tValidation loss: 0.665358\tBest loss: 0.665358\tAccuracy: 84.20%\n",
      "81\tValidation loss: 0.664922\tBest loss: 0.664922\tAccuracy: 84.30%\n",
      "82\tValidation loss: 0.660930\tBest loss: 0.660930\tAccuracy: 84.20%\n",
      "83\tValidation loss: 0.656044\tBest loss: 0.656044\tAccuracy: 84.30%\n",
      "84\tValidation loss: 0.654336\tBest loss: 0.654336\tAccuracy: 84.60%\n",
      "85\tValidation loss: 0.649423\tBest loss: 0.649423\tAccuracy: 84.20%\n",
      "86\tValidation loss: 0.650051\tBest loss: 0.649423\tAccuracy: 84.30%\n",
      "87\tValidation loss: 0.648510\tBest loss: 0.648510\tAccuracy: 84.90%\n",
      "88\tValidation loss: 0.645478\tBest loss: 0.645478\tAccuracy: 84.70%\n",
      "89\tValidation loss: 0.643713\tBest loss: 0.643713\tAccuracy: 84.80%\n",
      "90\tValidation loss: 0.642556\tBest loss: 0.642556\tAccuracy: 84.80%\n",
      "91\tValidation loss: 0.635395\tBest loss: 0.635395\tAccuracy: 85.30%\n",
      "92\tValidation loss: 0.633828\tBest loss: 0.633828\tAccuracy: 84.80%\n",
      "93\tValidation loss: 0.633704\tBest loss: 0.633704\tAccuracy: 84.80%\n",
      "94\tValidation loss: 0.631037\tBest loss: 0.631037\tAccuracy: 84.80%\n",
      "95\tValidation loss: 0.629520\tBest loss: 0.629520\tAccuracy: 85.00%\n",
      "96\tValidation loss: 0.627319\tBest loss: 0.627319\tAccuracy: 85.00%\n",
      "97\tValidation loss: 0.626063\tBest loss: 0.626063\tAccuracy: 85.10%\n",
      "98\tValidation loss: 0.622883\tBest loss: 0.622883\tAccuracy: 85.10%\n",
      "99\tValidation loss: 0.621538\tBest loss: 0.621538\tAccuracy: 85.60%\n",
      "100\tValidation loss: 0.620799\tBest loss: 0.620799\tAccuracy: 85.10%\n",
      "101\tValidation loss: 0.615234\tBest loss: 0.615234\tAccuracy: 85.40%\n",
      "102\tValidation loss: 0.613706\tBest loss: 0.613706\tAccuracy: 85.70%\n",
      "103\tValidation loss: 0.612732\tBest loss: 0.612732\tAccuracy: 85.30%\n",
      "104\tValidation loss: 0.612248\tBest loss: 0.612248\tAccuracy: 85.30%\n",
      "105\tValidation loss: 0.608195\tBest loss: 0.608195\tAccuracy: 85.40%\n",
      "106\tValidation loss: 0.606987\tBest loss: 0.606987\tAccuracy: 85.30%\n",
      "107\tValidation loss: 0.607400\tBest loss: 0.606987\tAccuracy: 85.20%\n",
      "108\tValidation loss: 0.606130\tBest loss: 0.606130\tAccuracy: 85.60%\n",
      "109\tValidation loss: 0.603707\tBest loss: 0.603707\tAccuracy: 85.60%\n",
      "110\tValidation loss: 0.601721\tBest loss: 0.601721\tAccuracy: 85.80%\n",
      "111\tValidation loss: 0.598660\tBest loss: 0.598660\tAccuracy: 85.70%\n",
      "112\tValidation loss: 0.598642\tBest loss: 0.598642\tAccuracy: 85.80%\n",
      "113\tValidation loss: 0.594316\tBest loss: 0.594316\tAccuracy: 85.70%\n",
      "114\tValidation loss: 0.592801\tBest loss: 0.592801\tAccuracy: 86.20%\n",
      "115\tValidation loss: 0.594960\tBest loss: 0.592801\tAccuracy: 85.70%\n",
      "116\tValidation loss: 0.592027\tBest loss: 0.592027\tAccuracy: 85.70%\n",
      "117\tValidation loss: 0.588219\tBest loss: 0.588219\tAccuracy: 86.30%\n",
      "118\tValidation loss: 0.587579\tBest loss: 0.587579\tAccuracy: 86.00%\n",
      "119\tValidation loss: 0.585751\tBest loss: 0.585751\tAccuracy: 85.80%\n",
      "120\tValidation loss: 0.585541\tBest loss: 0.585541\tAccuracy: 86.20%\n",
      "121\tValidation loss: 0.585327\tBest loss: 0.585327\tAccuracy: 86.20%\n",
      "122\tValidation loss: 0.583356\tBest loss: 0.583356\tAccuracy: 86.20%\n",
      "123\tValidation loss: 0.580665\tBest loss: 0.580665\tAccuracy: 86.10%\n",
      "124\tValidation loss: 0.580408\tBest loss: 0.580408\tAccuracy: 86.40%\n",
      "125\tValidation loss: 0.578879\tBest loss: 0.578879\tAccuracy: 86.40%\n",
      "126\tValidation loss: 0.576342\tBest loss: 0.576342\tAccuracy: 86.50%\n",
      "127\tValidation loss: 0.576838\tBest loss: 0.576342\tAccuracy: 86.20%\n",
      "128\tValidation loss: 0.572199\tBest loss: 0.572199\tAccuracy: 86.40%\n",
      "129\tValidation loss: 0.573102\tBest loss: 0.572199\tAccuracy: 85.90%\n",
      "130\tValidation loss: 0.574553\tBest loss: 0.572199\tAccuracy: 86.00%\n",
      "131\tValidation loss: 0.570709\tBest loss: 0.570709\tAccuracy: 86.30%\n",
      "132\tValidation loss: 0.568757\tBest loss: 0.568757\tAccuracy: 86.30%\n",
      "133\tValidation loss: 0.569125\tBest loss: 0.568757\tAccuracy: 86.60%\n",
      "134\tValidation loss: 0.568243\tBest loss: 0.568243\tAccuracy: 86.60%\n",
      "135\tValidation loss: 0.566573\tBest loss: 0.566573\tAccuracy: 85.80%\n",
      "136\tValidation loss: 0.563661\tBest loss: 0.563661\tAccuracy: 86.00%\n",
      "137\tValidation loss: 0.562200\tBest loss: 0.562200\tAccuracy: 86.50%\n",
      "138\tValidation loss: 0.562109\tBest loss: 0.562109\tAccuracy: 86.70%\n",
      "139\tValidation loss: 0.560516\tBest loss: 0.560516\tAccuracy: 86.30%\n",
      "140\tValidation loss: 0.557325\tBest loss: 0.557325\tAccuracy: 86.50%\n",
      "141\tValidation loss: 0.557331\tBest loss: 0.557325\tAccuracy: 86.60%\n",
      "142\tValidation loss: 0.557106\tBest loss: 0.557106\tAccuracy: 86.80%\n",
      "143\tValidation loss: 0.554455\tBest loss: 0.554455\tAccuracy: 86.60%\n",
      "144\tValidation loss: 0.553352\tBest loss: 0.553352\tAccuracy: 86.70%\n",
      "145\tValidation loss: 0.552404\tBest loss: 0.552404\tAccuracy: 86.20%\n",
      "146\tValidation loss: 0.551145\tBest loss: 0.551145\tAccuracy: 86.40%\n",
      "147\tValidation loss: 0.549721\tBest loss: 0.549721\tAccuracy: 87.30%\n",
      "148\tValidation loss: 0.549319\tBest loss: 0.549319\tAccuracy: 86.60%\n",
      "149\tValidation loss: 0.548946\tBest loss: 0.548946\tAccuracy: 86.90%\n",
      "150\tValidation loss: 0.547986\tBest loss: 0.547986\tAccuracy: 86.40%\n",
      "151\tValidation loss: 0.547749\tBest loss: 0.547749\tAccuracy: 86.90%\n",
      "152\tValidation loss: 0.544650\tBest loss: 0.544650\tAccuracy: 87.10%\n",
      "153\tValidation loss: 0.544450\tBest loss: 0.544450\tAccuracy: 86.60%\n",
      "154\tValidation loss: 0.543566\tBest loss: 0.543566\tAccuracy: 87.00%\n",
      "155\tValidation loss: 0.543396\tBest loss: 0.543396\tAccuracy: 86.90%\n",
      "156\tValidation loss: 0.542662\tBest loss: 0.542662\tAccuracy: 87.00%\n",
      "157\tValidation loss: 0.541539\tBest loss: 0.541539\tAccuracy: 86.90%\n",
      "158\tValidation loss: 0.539254\tBest loss: 0.539254\tAccuracy: 86.50%\n",
      "159\tValidation loss: 0.536168\tBest loss: 0.536168\tAccuracy: 87.20%\n",
      "160\tValidation loss: 0.539919\tBest loss: 0.536168\tAccuracy: 87.30%\n",
      "161\tValidation loss: 0.538044\tBest loss: 0.536168\tAccuracy: 86.50%\n",
      "162\tValidation loss: 0.536200\tBest loss: 0.536168\tAccuracy: 86.80%\n",
      "163\tValidation loss: 0.536365\tBest loss: 0.536168\tAccuracy: 86.90%\n",
      "164\tValidation loss: 0.531899\tBest loss: 0.531899\tAccuracy: 87.50%\n",
      "165\tValidation loss: 0.532045\tBest loss: 0.531899\tAccuracy: 86.80%\n",
      "166\tValidation loss: 0.531209\tBest loss: 0.531209\tAccuracy: 87.30%\n",
      "167\tValidation loss: 0.530120\tBest loss: 0.530120\tAccuracy: 87.60%\n",
      "168\tValidation loss: 0.531795\tBest loss: 0.530120\tAccuracy: 86.80%\n",
      "169\tValidation loss: 0.527836\tBest loss: 0.527836\tAccuracy: 87.20%\n",
      "170\tValidation loss: 0.528741\tBest loss: 0.527836\tAccuracy: 87.60%\n",
      "171\tValidation loss: 0.527446\tBest loss: 0.527446\tAccuracy: 87.30%\n",
      "172\tValidation loss: 0.525965\tBest loss: 0.525965\tAccuracy: 87.60%\n",
      "173\tValidation loss: 0.527206\tBest loss: 0.525965\tAccuracy: 87.10%\n",
      "174\tValidation loss: 0.524385\tBest loss: 0.524385\tAccuracy: 87.30%\n",
      "175\tValidation loss: 0.523310\tBest loss: 0.523310\tAccuracy: 87.40%\n",
      "176\tValidation loss: 0.524927\tBest loss: 0.523310\tAccuracy: 87.50%\n",
      "177\tValidation loss: 0.522378\tBest loss: 0.522378\tAccuracy: 87.50%\n",
      "178\tValidation loss: 0.522508\tBest loss: 0.522378\tAccuracy: 87.60%\n",
      "179\tValidation loss: 0.520491\tBest loss: 0.520491\tAccuracy: 87.80%\n",
      "180\tValidation loss: 0.518599\tBest loss: 0.518599\tAccuracy: 87.60%\n",
      "181\tValidation loss: 0.519814\tBest loss: 0.518599\tAccuracy: 87.20%\n",
      "182\tValidation loss: 0.519398\tBest loss: 0.518599\tAccuracy: 87.80%\n",
      "183\tValidation loss: 0.518044\tBest loss: 0.518044\tAccuracy: 87.90%\n",
      "184\tValidation loss: 0.517321\tBest loss: 0.517321\tAccuracy: 87.80%\n",
      "185\tValidation loss: 0.517462\tBest loss: 0.517321\tAccuracy: 87.70%\n",
      "186\tValidation loss: 0.515371\tBest loss: 0.515371\tAccuracy: 87.70%\n",
      "187\tValidation loss: 0.513550\tBest loss: 0.513550\tAccuracy: 88.00%\n",
      "188\tValidation loss: 0.514547\tBest loss: 0.513550\tAccuracy: 87.60%\n",
      "189\tValidation loss: 0.513405\tBest loss: 0.513405\tAccuracy: 88.00%\n",
      "190\tValidation loss: 0.512795\tBest loss: 0.512795\tAccuracy: 87.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\tValidation loss: 0.511921\tBest loss: 0.511921\tAccuracy: 87.60%\n",
      "192\tValidation loss: 0.510968\tBest loss: 0.510968\tAccuracy: 87.80%\n",
      "193\tValidation loss: 0.510152\tBest loss: 0.510152\tAccuracy: 88.00%\n",
      "194\tValidation loss: 0.510976\tBest loss: 0.510152\tAccuracy: 88.20%\n",
      "195\tValidation loss: 0.508884\tBest loss: 0.508884\tAccuracy: 88.00%\n",
      "196\tValidation loss: 0.507761\tBest loss: 0.507761\tAccuracy: 88.00%\n",
      "197\tValidation loss: 0.506367\tBest loss: 0.506367\tAccuracy: 88.00%\n",
      "198\tValidation loss: 0.507216\tBest loss: 0.506367\tAccuracy: 88.10%\n",
      "199\tValidation loss: 0.506295\tBest loss: 0.506295\tAccuracy: 87.90%\n",
      "200\tValidation loss: 0.506595\tBest loss: 0.506295\tAccuracy: 87.80%\n",
      "201\tValidation loss: 0.505723\tBest loss: 0.505723\tAccuracy: 88.20%\n",
      "202\tValidation loss: 0.504731\tBest loss: 0.504731\tAccuracy: 87.90%\n",
      "203\tValidation loss: 0.505686\tBest loss: 0.504731\tAccuracy: 87.80%\n",
      "204\tValidation loss: 0.504860\tBest loss: 0.504731\tAccuracy: 88.00%\n",
      "205\tValidation loss: 0.502419\tBest loss: 0.502419\tAccuracy: 88.10%\n",
      "206\tValidation loss: 0.500847\tBest loss: 0.500847\tAccuracy: 88.10%\n",
      "207\tValidation loss: 0.503106\tBest loss: 0.500847\tAccuracy: 87.90%\n",
      "208\tValidation loss: 0.502897\tBest loss: 0.500847\tAccuracy: 87.90%\n",
      "209\tValidation loss: 0.497777\tBest loss: 0.497777\tAccuracy: 88.30%\n",
      "210\tValidation loss: 0.498449\tBest loss: 0.497777\tAccuracy: 88.10%\n",
      "211\tValidation loss: 0.499249\tBest loss: 0.497777\tAccuracy: 88.40%\n",
      "212\tValidation loss: 0.495873\tBest loss: 0.495873\tAccuracy: 88.30%\n",
      "213\tValidation loss: 0.497482\tBest loss: 0.495873\tAccuracy: 88.20%\n",
      "214\tValidation loss: 0.496167\tBest loss: 0.495873\tAccuracy: 88.40%\n",
      "215\tValidation loss: 0.495999\tBest loss: 0.495873\tAccuracy: 88.50%\n",
      "216\tValidation loss: 0.494420\tBest loss: 0.494420\tAccuracy: 88.70%\n",
      "217\tValidation loss: 0.494419\tBest loss: 0.494419\tAccuracy: 88.30%\n",
      "218\tValidation loss: 0.495056\tBest loss: 0.494419\tAccuracy: 88.10%\n",
      "219\tValidation loss: 0.493358\tBest loss: 0.493358\tAccuracy: 88.30%\n",
      "220\tValidation loss: 0.493292\tBest loss: 0.493292\tAccuracy: 88.40%\n",
      "221\tValidation loss: 0.494729\tBest loss: 0.493292\tAccuracy: 88.50%\n",
      "222\tValidation loss: 0.493459\tBest loss: 0.493292\tAccuracy: 88.60%\n",
      "223\tValidation loss: 0.492013\tBest loss: 0.492013\tAccuracy: 88.30%\n",
      "224\tValidation loss: 0.491433\tBest loss: 0.491433\tAccuracy: 88.70%\n",
      "225\tValidation loss: 0.490683\tBest loss: 0.490683\tAccuracy: 88.40%\n",
      "226\tValidation loss: 0.489492\tBest loss: 0.489492\tAccuracy: 88.80%\n",
      "227\tValidation loss: 0.488219\tBest loss: 0.488219\tAccuracy: 88.40%\n",
      "228\tValidation loss: 0.488337\tBest loss: 0.488219\tAccuracy: 88.70%\n",
      "229\tValidation loss: 0.489749\tBest loss: 0.488219\tAccuracy: 88.60%\n",
      "230\tValidation loss: 0.489110\tBest loss: 0.488219\tAccuracy: 88.50%\n",
      "231\tValidation loss: 0.487974\tBest loss: 0.487974\tAccuracy: 88.50%\n",
      "232\tValidation loss: 0.487791\tBest loss: 0.487791\tAccuracy: 88.70%\n",
      "233\tValidation loss: 0.486988\tBest loss: 0.486988\tAccuracy: 88.10%\n",
      "234\tValidation loss: 0.485189\tBest loss: 0.485189\tAccuracy: 88.40%\n",
      "235\tValidation loss: 0.485579\tBest loss: 0.485189\tAccuracy: 88.40%\n",
      "236\tValidation loss: 0.486625\tBest loss: 0.485189\tAccuracy: 88.50%\n",
      "237\tValidation loss: 0.484086\tBest loss: 0.484086\tAccuracy: 88.70%\n",
      "238\tValidation loss: 0.483887\tBest loss: 0.483887\tAccuracy: 88.50%\n",
      "239\tValidation loss: 0.482966\tBest loss: 0.482966\tAccuracy: 88.30%\n",
      "240\tValidation loss: 0.484664\tBest loss: 0.482966\tAccuracy: 88.70%\n",
      "241\tValidation loss: 0.482936\tBest loss: 0.482936\tAccuracy: 88.40%\n",
      "242\tValidation loss: 0.481910\tBest loss: 0.481910\tAccuracy: 88.30%\n",
      "243\tValidation loss: 0.481512\tBest loss: 0.481512\tAccuracy: 88.80%\n",
      "244\tValidation loss: 0.481129\tBest loss: 0.481129\tAccuracy: 88.60%\n",
      "245\tValidation loss: 0.481298\tBest loss: 0.481129\tAccuracy: 88.70%\n",
      "246\tValidation loss: 0.480738\tBest loss: 0.480738\tAccuracy: 88.70%\n",
      "247\tValidation loss: 0.479683\tBest loss: 0.479683\tAccuracy: 88.80%\n",
      "248\tValidation loss: 0.479200\tBest loss: 0.479200\tAccuracy: 88.70%\n",
      "249\tValidation loss: 0.477854\tBest loss: 0.477854\tAccuracy: 88.60%\n",
      "250\tValidation loss: 0.479352\tBest loss: 0.477854\tAccuracy: 88.40%\n",
      "251\tValidation loss: 0.478678\tBest loss: 0.477854\tAccuracy: 88.80%\n",
      "252\tValidation loss: 0.476921\tBest loss: 0.476921\tAccuracy: 88.90%\n",
      "253\tValidation loss: 0.478381\tBest loss: 0.476921\tAccuracy: 88.80%\n",
      "254\tValidation loss: 0.477667\tBest loss: 0.476921\tAccuracy: 88.50%\n",
      "255\tValidation loss: 0.477268\tBest loss: 0.476921\tAccuracy: 88.80%\n",
      "256\tValidation loss: 0.476356\tBest loss: 0.476356\tAccuracy: 88.50%\n",
      "257\tValidation loss: 0.477409\tBest loss: 0.476356\tAccuracy: 88.40%\n",
      "258\tValidation loss: 0.475892\tBest loss: 0.475892\tAccuracy: 88.60%\n",
      "259\tValidation loss: 0.473783\tBest loss: 0.473783\tAccuracy: 88.50%\n",
      "260\tValidation loss: 0.474698\tBest loss: 0.473783\tAccuracy: 88.80%\n",
      "261\tValidation loss: 0.473466\tBest loss: 0.473466\tAccuracy: 88.60%\n",
      "262\tValidation loss: 0.475727\tBest loss: 0.473466\tAccuracy: 88.70%\n",
      "263\tValidation loss: 0.474785\tBest loss: 0.473466\tAccuracy: 88.70%\n",
      "264\tValidation loss: 0.474544\tBest loss: 0.473466\tAccuracy: 89.10%\n",
      "265\tValidation loss: 0.473199\tBest loss: 0.473199\tAccuracy: 88.80%\n",
      "266\tValidation loss: 0.473032\tBest loss: 0.473032\tAccuracy: 88.40%\n",
      "267\tValidation loss: 0.473241\tBest loss: 0.473032\tAccuracy: 88.90%\n",
      "268\tValidation loss: 0.473882\tBest loss: 0.473032\tAccuracy: 88.80%\n",
      "269\tValidation loss: 0.471454\tBest loss: 0.471454\tAccuracy: 88.80%\n",
      "270\tValidation loss: 0.472312\tBest loss: 0.471454\tAccuracy: 88.70%\n",
      "271\tValidation loss: 0.470533\tBest loss: 0.470533\tAccuracy: 88.90%\n",
      "272\tValidation loss: 0.469345\tBest loss: 0.469345\tAccuracy: 88.90%\n",
      "273\tValidation loss: 0.471632\tBest loss: 0.469345\tAccuracy: 88.90%\n",
      "274\tValidation loss: 0.470813\tBest loss: 0.469345\tAccuracy: 88.80%\n",
      "275\tValidation loss: 0.468535\tBest loss: 0.468535\tAccuracy: 89.00%\n",
      "276\tValidation loss: 0.468547\tBest loss: 0.468535\tAccuracy: 89.00%\n",
      "277\tValidation loss: 0.468709\tBest loss: 0.468535\tAccuracy: 89.10%\n",
      "278\tValidation loss: 0.467827\tBest loss: 0.467827\tAccuracy: 89.00%\n",
      "279\tValidation loss: 0.466939\tBest loss: 0.466939\tAccuracy: 89.20%\n",
      "280\tValidation loss: 0.469079\tBest loss: 0.466939\tAccuracy: 88.60%\n",
      "281\tValidation loss: 0.469196\tBest loss: 0.466939\tAccuracy: 88.60%\n",
      "282\tValidation loss: 0.466522\tBest loss: 0.466522\tAccuracy: 88.80%\n",
      "283\tValidation loss: 0.466201\tBest loss: 0.466201\tAccuracy: 89.10%\n",
      "284\tValidation loss: 0.466979\tBest loss: 0.466201\tAccuracy: 89.10%\n",
      "285\tValidation loss: 0.466116\tBest loss: 0.466116\tAccuracy: 89.00%\n",
      "286\tValidation loss: 0.465337\tBest loss: 0.465337\tAccuracy: 89.10%\n",
      "287\tValidation loss: 0.465875\tBest loss: 0.465337\tAccuracy: 88.90%\n",
      "288\tValidation loss: 0.464514\tBest loss: 0.464514\tAccuracy: 89.10%\n",
      "289\tValidation loss: 0.463964\tBest loss: 0.463964\tAccuracy: 89.00%\n",
      "290\tValidation loss: 0.463428\tBest loss: 0.463428\tAccuracy: 89.10%\n",
      "291\tValidation loss: 0.463501\tBest loss: 0.463428\tAccuracy: 89.00%\n",
      "292\tValidation loss: 0.463498\tBest loss: 0.463428\tAccuracy: 89.10%\n",
      "293\tValidation loss: 0.462932\tBest loss: 0.462932\tAccuracy: 89.00%\n",
      "294\tValidation loss: 0.463403\tBest loss: 0.462932\tAccuracy: 89.00%\n",
      "295\tValidation loss: 0.463217\tBest loss: 0.462932\tAccuracy: 88.90%\n",
      "296\tValidation loss: 0.461882\tBest loss: 0.461882\tAccuracy: 89.00%\n",
      "297\tValidation loss: 0.463193\tBest loss: 0.461882\tAccuracy: 88.80%\n",
      "298\tValidation loss: 0.463456\tBest loss: 0.461882\tAccuracy: 89.00%\n",
      "299\tValidation loss: 0.461419\tBest loss: 0.461419\tAccuracy: 89.20%\n",
      "300\tValidation loss: 0.460911\tBest loss: 0.460911\tAccuracy: 88.90%\n",
      "301\tValidation loss: 0.460900\tBest loss: 0.460900\tAccuracy: 88.80%\n",
      "302\tValidation loss: 0.460647\tBest loss: 0.460647\tAccuracy: 89.00%\n",
      "303\tValidation loss: 0.460769\tBest loss: 0.460647\tAccuracy: 89.10%\n",
      "304\tValidation loss: 0.460850\tBest loss: 0.460647\tAccuracy: 89.10%\n",
      "305\tValidation loss: 0.459122\tBest loss: 0.459122\tAccuracy: 89.00%\n",
      "306\tValidation loss: 0.459616\tBest loss: 0.459122\tAccuracy: 89.00%\n",
      "307\tValidation loss: 0.459456\tBest loss: 0.459122\tAccuracy: 89.00%\n",
      "308\tValidation loss: 0.459170\tBest loss: 0.459122\tAccuracy: 89.10%\n",
      "309\tValidation loss: 0.458158\tBest loss: 0.458158\tAccuracy: 89.10%\n",
      "310\tValidation loss: 0.457274\tBest loss: 0.457274\tAccuracy: 89.10%\n",
      "311\tValidation loss: 0.458239\tBest loss: 0.457274\tAccuracy: 89.00%\n",
      "312\tValidation loss: 0.457718\tBest loss: 0.457274\tAccuracy: 89.10%\n",
      "313\tValidation loss: 0.455439\tBest loss: 0.455439\tAccuracy: 89.00%\n",
      "314\tValidation loss: 0.457309\tBest loss: 0.455439\tAccuracy: 89.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\tValidation loss: 0.455480\tBest loss: 0.455439\tAccuracy: 89.10%\n",
      "316\tValidation loss: 0.454476\tBest loss: 0.454476\tAccuracy: 89.20%\n",
      "317\tValidation loss: 0.455741\tBest loss: 0.454476\tAccuracy: 89.10%\n",
      "318\tValidation loss: 0.454765\tBest loss: 0.454476\tAccuracy: 89.10%\n",
      "319\tValidation loss: 0.455066\tBest loss: 0.454476\tAccuracy: 89.10%\n",
      "320\tValidation loss: 0.454548\tBest loss: 0.454476\tAccuracy: 89.00%\n",
      "321\tValidation loss: 0.454594\tBest loss: 0.454476\tAccuracy: 89.10%\n",
      "322\tValidation loss: 0.453232\tBest loss: 0.453232\tAccuracy: 89.00%\n",
      "323\tValidation loss: 0.453852\tBest loss: 0.453232\tAccuracy: 89.10%\n",
      "324\tValidation loss: 0.452736\tBest loss: 0.452736\tAccuracy: 89.20%\n",
      "325\tValidation loss: 0.453195\tBest loss: 0.452736\tAccuracy: 89.00%\n",
      "326\tValidation loss: 0.454062\tBest loss: 0.452736\tAccuracy: 88.90%\n",
      "327\tValidation loss: 0.452670\tBest loss: 0.452670\tAccuracy: 89.10%\n",
      "328\tValidation loss: 0.452907\tBest loss: 0.452670\tAccuracy: 89.00%\n",
      "329\tValidation loss: 0.453584\tBest loss: 0.452670\tAccuracy: 89.20%\n",
      "330\tValidation loss: 0.453420\tBest loss: 0.452670\tAccuracy: 89.10%\n",
      "331\tValidation loss: 0.451954\tBest loss: 0.451954\tAccuracy: 89.20%\n",
      "332\tValidation loss: 0.451950\tBest loss: 0.451950\tAccuracy: 89.10%\n",
      "333\tValidation loss: 0.451368\tBest loss: 0.451368\tAccuracy: 89.00%\n",
      "334\tValidation loss: 0.453086\tBest loss: 0.451368\tAccuracy: 88.90%\n",
      "335\tValidation loss: 0.450921\tBest loss: 0.450921\tAccuracy: 89.30%\n",
      "336\tValidation loss: 0.449914\tBest loss: 0.449914\tAccuracy: 89.10%\n",
      "337\tValidation loss: 0.450768\tBest loss: 0.449914\tAccuracy: 89.20%\n",
      "338\tValidation loss: 0.449712\tBest loss: 0.449712\tAccuracy: 89.30%\n",
      "339\tValidation loss: 0.450039\tBest loss: 0.449712\tAccuracy: 89.20%\n",
      "340\tValidation loss: 0.449488\tBest loss: 0.449488\tAccuracy: 89.20%\n",
      "341\tValidation loss: 0.449480\tBest loss: 0.449480\tAccuracy: 88.90%\n",
      "342\tValidation loss: 0.448422\tBest loss: 0.448422\tAccuracy: 89.10%\n",
      "343\tValidation loss: 0.447575\tBest loss: 0.447575\tAccuracy: 89.00%\n",
      "344\tValidation loss: 0.449077\tBest loss: 0.447575\tAccuracy: 89.10%\n",
      "345\tValidation loss: 0.449472\tBest loss: 0.447575\tAccuracy: 89.10%\n",
      "346\tValidation loss: 0.447493\tBest loss: 0.447493\tAccuracy: 89.20%\n",
      "347\tValidation loss: 0.448931\tBest loss: 0.447493\tAccuracy: 89.10%\n",
      "348\tValidation loss: 0.448866\tBest loss: 0.447493\tAccuracy: 89.00%\n",
      "349\tValidation loss: 0.447183\tBest loss: 0.447183\tAccuracy: 89.20%\n",
      "350\tValidation loss: 0.446948\tBest loss: 0.446948\tAccuracy: 89.30%\n",
      "351\tValidation loss: 0.448346\tBest loss: 0.446948\tAccuracy: 88.90%\n",
      "352\tValidation loss: 0.446839\tBest loss: 0.446839\tAccuracy: 89.30%\n",
      "353\tValidation loss: 0.445924\tBest loss: 0.445924\tAccuracy: 89.20%\n",
      "354\tValidation loss: 0.446409\tBest loss: 0.445924\tAccuracy: 89.00%\n",
      "355\tValidation loss: 0.445800\tBest loss: 0.445800\tAccuracy: 89.30%\n",
      "356\tValidation loss: 0.445865\tBest loss: 0.445800\tAccuracy: 89.20%\n",
      "357\tValidation loss: 0.445296\tBest loss: 0.445296\tAccuracy: 89.30%\n",
      "358\tValidation loss: 0.445558\tBest loss: 0.445296\tAccuracy: 89.20%\n",
      "359\tValidation loss: 0.446022\tBest loss: 0.445296\tAccuracy: 89.10%\n",
      "360\tValidation loss: 0.445258\tBest loss: 0.445258\tAccuracy: 89.20%\n",
      "361\tValidation loss: 0.444535\tBest loss: 0.444535\tAccuracy: 89.00%\n",
      "362\tValidation loss: 0.443839\tBest loss: 0.443839\tAccuracy: 89.20%\n",
      "363\tValidation loss: 0.444315\tBest loss: 0.443839\tAccuracy: 89.20%\n",
      "364\tValidation loss: 0.444129\tBest loss: 0.443839\tAccuracy: 89.10%\n",
      "365\tValidation loss: 0.444810\tBest loss: 0.443839\tAccuracy: 89.00%\n",
      "366\tValidation loss: 0.443138\tBest loss: 0.443138\tAccuracy: 89.10%\n",
      "367\tValidation loss: 0.441759\tBest loss: 0.441759\tAccuracy: 89.40%\n",
      "368\tValidation loss: 0.441916\tBest loss: 0.441759\tAccuracy: 89.40%\n",
      "369\tValidation loss: 0.442100\tBest loss: 0.441759\tAccuracy: 89.20%\n",
      "370\tValidation loss: 0.441941\tBest loss: 0.441759\tAccuracy: 89.40%\n",
      "371\tValidation loss: 0.441600\tBest loss: 0.441600\tAccuracy: 89.40%\n",
      "372\tValidation loss: 0.442535\tBest loss: 0.441600\tAccuracy: 89.40%\n",
      "373\tValidation loss: 0.441870\tBest loss: 0.441600\tAccuracy: 89.20%\n",
      "374\tValidation loss: 0.441891\tBest loss: 0.441600\tAccuracy: 89.30%\n",
      "375\tValidation loss: 0.440737\tBest loss: 0.440737\tAccuracy: 89.40%\n",
      "376\tValidation loss: 0.441745\tBest loss: 0.440737\tAccuracy: 89.20%\n",
      "377\tValidation loss: 0.440957\tBest loss: 0.440737\tAccuracy: 89.20%\n",
      "378\tValidation loss: 0.439972\tBest loss: 0.439972\tAccuracy: 89.20%\n",
      "379\tValidation loss: 0.440157\tBest loss: 0.439972\tAccuracy: 89.40%\n",
      "380\tValidation loss: 0.440660\tBest loss: 0.439972\tAccuracy: 89.10%\n",
      "381\tValidation loss: 0.439921\tBest loss: 0.439921\tAccuracy: 89.20%\n",
      "382\tValidation loss: 0.440158\tBest loss: 0.439921\tAccuracy: 89.30%\n",
      "383\tValidation loss: 0.438571\tBest loss: 0.438571\tAccuracy: 89.50%\n",
      "384\tValidation loss: 0.440000\tBest loss: 0.438571\tAccuracy: 89.40%\n",
      "385\tValidation loss: 0.438417\tBest loss: 0.438417\tAccuracy: 89.30%\n",
      "386\tValidation loss: 0.440711\tBest loss: 0.438417\tAccuracy: 89.00%\n",
      "387\tValidation loss: 0.438548\tBest loss: 0.438417\tAccuracy: 89.40%\n",
      "388\tValidation loss: 0.437592\tBest loss: 0.437592\tAccuracy: 89.30%\n",
      "389\tValidation loss: 0.439700\tBest loss: 0.437592\tAccuracy: 89.30%\n",
      "390\tValidation loss: 0.437651\tBest loss: 0.437592\tAccuracy: 89.40%\n",
      "391\tValidation loss: 0.437175\tBest loss: 0.437175\tAccuracy: 89.10%\n",
      "392\tValidation loss: 0.437061\tBest loss: 0.437061\tAccuracy: 89.40%\n",
      "393\tValidation loss: 0.437288\tBest loss: 0.437061\tAccuracy: 89.40%\n",
      "394\tValidation loss: 0.436254\tBest loss: 0.436254\tAccuracy: 89.60%\n",
      "395\tValidation loss: 0.438043\tBest loss: 0.436254\tAccuracy: 89.20%\n",
      "396\tValidation loss: 0.437237\tBest loss: 0.436254\tAccuracy: 89.50%\n",
      "397\tValidation loss: 0.436044\tBest loss: 0.436044\tAccuracy: 89.40%\n",
      "398\tValidation loss: 0.435956\tBest loss: 0.435956\tAccuracy: 89.70%\n",
      "399\tValidation loss: 0.436527\tBest loss: 0.435956\tAccuracy: 89.30%\n",
      "400\tValidation loss: 0.435412\tBest loss: 0.435412\tAccuracy: 89.50%\n",
      "401\tValidation loss: 0.436316\tBest loss: 0.435412\tAccuracy: 89.40%\n",
      "402\tValidation loss: 0.434793\tBest loss: 0.434793\tAccuracy: 89.40%\n",
      "403\tValidation loss: 0.435734\tBest loss: 0.434793\tAccuracy: 89.30%\n",
      "404\tValidation loss: 0.434495\tBest loss: 0.434495\tAccuracy: 89.30%\n",
      "405\tValidation loss: 0.436221\tBest loss: 0.434495\tAccuracy: 89.40%\n",
      "406\tValidation loss: 0.436031\tBest loss: 0.434495\tAccuracy: 89.20%\n",
      "407\tValidation loss: 0.434275\tBest loss: 0.434275\tAccuracy: 89.20%\n",
      "408\tValidation loss: 0.433101\tBest loss: 0.433101\tAccuracy: 89.40%\n",
      "409\tValidation loss: 0.434323\tBest loss: 0.433101\tAccuracy: 89.30%\n",
      "410\tValidation loss: 0.434315\tBest loss: 0.433101\tAccuracy: 89.50%\n",
      "411\tValidation loss: 0.434320\tBest loss: 0.433101\tAccuracy: 89.70%\n",
      "412\tValidation loss: 0.433592\tBest loss: 0.433101\tAccuracy: 89.40%\n",
      "413\tValidation loss: 0.433292\tBest loss: 0.433101\tAccuracy: 89.50%\n",
      "414\tValidation loss: 0.433107\tBest loss: 0.433101\tAccuracy: 89.50%\n",
      "415\tValidation loss: 0.433717\tBest loss: 0.433101\tAccuracy: 89.70%\n",
      "416\tValidation loss: 0.433323\tBest loss: 0.433101\tAccuracy: 89.30%\n",
      "417\tValidation loss: 0.432369\tBest loss: 0.432369\tAccuracy: 89.70%\n",
      "418\tValidation loss: 0.433111\tBest loss: 0.432369\tAccuracy: 89.60%\n",
      "419\tValidation loss: 0.432452\tBest loss: 0.432369\tAccuracy: 89.50%\n",
      "420\tValidation loss: 0.432908\tBest loss: 0.432369\tAccuracy: 89.50%\n",
      "421\tValidation loss: 0.431953\tBest loss: 0.431953\tAccuracy: 89.40%\n",
      "422\tValidation loss: 0.432000\tBest loss: 0.431953\tAccuracy: 89.50%\n",
      "423\tValidation loss: 0.432547\tBest loss: 0.431953\tAccuracy: 89.70%\n",
      "424\tValidation loss: 0.431636\tBest loss: 0.431636\tAccuracy: 89.40%\n",
      "425\tValidation loss: 0.432261\tBest loss: 0.431636\tAccuracy: 89.60%\n",
      "426\tValidation loss: 0.431667\tBest loss: 0.431636\tAccuracy: 89.50%\n",
      "427\tValidation loss: 0.430221\tBest loss: 0.430221\tAccuracy: 89.70%\n",
      "428\tValidation loss: 0.431629\tBest loss: 0.430221\tAccuracy: 89.50%\n",
      "429\tValidation loss: 0.430813\tBest loss: 0.430221\tAccuracy: 89.40%\n",
      "430\tValidation loss: 0.430922\tBest loss: 0.430221\tAccuracy: 89.60%\n",
      "431\tValidation loss: 0.431144\tBest loss: 0.430221\tAccuracy: 89.70%\n",
      "432\tValidation loss: 0.430875\tBest loss: 0.430221\tAccuracy: 89.40%\n",
      "433\tValidation loss: 0.430422\tBest loss: 0.430221\tAccuracy: 89.50%\n",
      "434\tValidation loss: 0.430127\tBest loss: 0.430127\tAccuracy: 89.50%\n",
      "435\tValidation loss: 0.429479\tBest loss: 0.429479\tAccuracy: 89.80%\n",
      "436\tValidation loss: 0.430270\tBest loss: 0.429479\tAccuracy: 89.80%\n",
      "437\tValidation loss: 0.429597\tBest loss: 0.429479\tAccuracy: 89.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\tValidation loss: 0.428950\tBest loss: 0.428950\tAccuracy: 89.70%\n",
      "439\tValidation loss: 0.430274\tBest loss: 0.428950\tAccuracy: 89.50%\n",
      "440\tValidation loss: 0.428791\tBest loss: 0.428791\tAccuracy: 89.60%\n",
      "441\tValidation loss: 0.429186\tBest loss: 0.428791\tAccuracy: 89.70%\n",
      "442\tValidation loss: 0.429724\tBest loss: 0.428791\tAccuracy: 89.60%\n",
      "443\tValidation loss: 0.428382\tBest loss: 0.428382\tAccuracy: 89.60%\n",
      "444\tValidation loss: 0.428784\tBest loss: 0.428382\tAccuracy: 89.60%\n",
      "445\tValidation loss: 0.428503\tBest loss: 0.428382\tAccuracy: 89.70%\n",
      "446\tValidation loss: 0.428176\tBest loss: 0.428176\tAccuracy: 89.80%\n",
      "447\tValidation loss: 0.427712\tBest loss: 0.427712\tAccuracy: 89.60%\n",
      "448\tValidation loss: 0.428038\tBest loss: 0.427712\tAccuracy: 89.80%\n",
      "449\tValidation loss: 0.427607\tBest loss: 0.427607\tAccuracy: 89.80%\n",
      "450\tValidation loss: 0.427657\tBest loss: 0.427607\tAccuracy: 89.60%\n",
      "451\tValidation loss: 0.426095\tBest loss: 0.426095\tAccuracy: 89.70%\n",
      "452\tValidation loss: 0.426487\tBest loss: 0.426095\tAccuracy: 89.60%\n",
      "453\tValidation loss: 0.427545\tBest loss: 0.426095\tAccuracy: 89.80%\n",
      "454\tValidation loss: 0.426933\tBest loss: 0.426095\tAccuracy: 89.60%\n",
      "455\tValidation loss: 0.427479\tBest loss: 0.426095\tAccuracy: 89.60%\n",
      "456\tValidation loss: 0.426058\tBest loss: 0.426058\tAccuracy: 89.80%\n",
      "457\tValidation loss: 0.426805\tBest loss: 0.426058\tAccuracy: 89.60%\n",
      "458\tValidation loss: 0.427178\tBest loss: 0.426058\tAccuracy: 89.50%\n",
      "459\tValidation loss: 0.426003\tBest loss: 0.426003\tAccuracy: 89.70%\n",
      "460\tValidation loss: 0.426069\tBest loss: 0.426003\tAccuracy: 89.70%\n",
      "461\tValidation loss: 0.426440\tBest loss: 0.426003\tAccuracy: 89.70%\n",
      "462\tValidation loss: 0.426060\tBest loss: 0.426003\tAccuracy: 89.80%\n",
      "463\tValidation loss: 0.426307\tBest loss: 0.426003\tAccuracy: 90.00%\n",
      "464\tValidation loss: 0.425328\tBest loss: 0.425328\tAccuracy: 89.80%\n",
      "465\tValidation loss: 0.425228\tBest loss: 0.425228\tAccuracy: 89.60%\n",
      "466\tValidation loss: 0.425720\tBest loss: 0.425228\tAccuracy: 89.70%\n",
      "467\tValidation loss: 0.425549\tBest loss: 0.425228\tAccuracy: 89.70%\n",
      "468\tValidation loss: 0.425941\tBest loss: 0.425228\tAccuracy: 89.90%\n",
      "469\tValidation loss: 0.424734\tBest loss: 0.424734\tAccuracy: 89.90%\n",
      "470\tValidation loss: 0.425155\tBest loss: 0.424734\tAccuracy: 90.00%\n",
      "471\tValidation loss: 0.424667\tBest loss: 0.424667\tAccuracy: 89.80%\n",
      "472\tValidation loss: 0.423828\tBest loss: 0.423828\tAccuracy: 89.90%\n",
      "473\tValidation loss: 0.424324\tBest loss: 0.423828\tAccuracy: 89.90%\n",
      "474\tValidation loss: 0.423649\tBest loss: 0.423649\tAccuracy: 90.00%\n",
      "475\tValidation loss: 0.423407\tBest loss: 0.423407\tAccuracy: 89.80%\n",
      "476\tValidation loss: 0.424405\tBest loss: 0.423407\tAccuracy: 89.60%\n",
      "477\tValidation loss: 0.423830\tBest loss: 0.423407\tAccuracy: 89.80%\n",
      "478\tValidation loss: 0.423207\tBest loss: 0.423207\tAccuracy: 89.90%\n",
      "479\tValidation loss: 0.423680\tBest loss: 0.423207\tAccuracy: 90.00%\n",
      "480\tValidation loss: 0.422072\tBest loss: 0.422072\tAccuracy: 90.00%\n",
      "481\tValidation loss: 0.421947\tBest loss: 0.421947\tAccuracy: 89.70%\n",
      "482\tValidation loss: 0.422855\tBest loss: 0.421947\tAccuracy: 89.90%\n",
      "483\tValidation loss: 0.422461\tBest loss: 0.421947\tAccuracy: 90.00%\n",
      "484\tValidation loss: 0.421889\tBest loss: 0.421889\tAccuracy: 89.80%\n",
      "485\tValidation loss: 0.421970\tBest loss: 0.421889\tAccuracy: 90.10%\n",
      "486\tValidation loss: 0.421702\tBest loss: 0.421702\tAccuracy: 89.90%\n",
      "487\tValidation loss: 0.420417\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "488\tValidation loss: 0.421853\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "489\tValidation loss: 0.421942\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "490\tValidation loss: 0.421990\tBest loss: 0.420417\tAccuracy: 89.80%\n",
      "491\tValidation loss: 0.421027\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "492\tValidation loss: 0.421052\tBest loss: 0.420417\tAccuracy: 90.20%\n",
      "493\tValidation loss: 0.421054\tBest loss: 0.420417\tAccuracy: 90.20%\n",
      "494\tValidation loss: 0.420795\tBest loss: 0.420417\tAccuracy: 89.80%\n",
      "495\tValidation loss: 0.420847\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "496\tValidation loss: 0.420927\tBest loss: 0.420417\tAccuracy: 89.90%\n",
      "497\tValidation loss: 0.421087\tBest loss: 0.420417\tAccuracy: 90.10%\n",
      "498\tValidation loss: 0.421113\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "499\tValidation loss: 0.420616\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "500\tValidation loss: 0.420457\tBest loss: 0.420417\tAccuracy: 90.00%\n",
      "501\tValidation loss: 0.420524\tBest loss: 0.420417\tAccuracy: 89.90%\n",
      "502\tValidation loss: 0.421245\tBest loss: 0.420417\tAccuracy: 89.80%\n",
      "503\tValidation loss: 0.419800\tBest loss: 0.419800\tAccuracy: 90.00%\n",
      "504\tValidation loss: 0.419104\tBest loss: 0.419104\tAccuracy: 89.70%\n",
      "505\tValidation loss: 0.419625\tBest loss: 0.419104\tAccuracy: 90.10%\n",
      "506\tValidation loss: 0.420390\tBest loss: 0.419104\tAccuracy: 89.80%\n",
      "507\tValidation loss: 0.420630\tBest loss: 0.419104\tAccuracy: 90.10%\n",
      "508\tValidation loss: 0.418932\tBest loss: 0.418932\tAccuracy: 90.00%\n",
      "509\tValidation loss: 0.418390\tBest loss: 0.418390\tAccuracy: 89.90%\n",
      "510\tValidation loss: 0.419130\tBest loss: 0.418390\tAccuracy: 90.00%\n",
      "511\tValidation loss: 0.419655\tBest loss: 0.418390\tAccuracy: 89.80%\n",
      "512\tValidation loss: 0.419740\tBest loss: 0.418390\tAccuracy: 90.00%\n",
      "513\tValidation loss: 0.418863\tBest loss: 0.418390\tAccuracy: 89.70%\n",
      "514\tValidation loss: 0.417694\tBest loss: 0.417694\tAccuracy: 89.80%\n",
      "515\tValidation loss: 0.417432\tBest loss: 0.417432\tAccuracy: 90.00%\n",
      "516\tValidation loss: 0.418766\tBest loss: 0.417432\tAccuracy: 89.80%\n",
      "517\tValidation loss: 0.417798\tBest loss: 0.417432\tAccuracy: 90.00%\n",
      "518\tValidation loss: 0.417888\tBest loss: 0.417432\tAccuracy: 90.00%\n",
      "519\tValidation loss: 0.418033\tBest loss: 0.417432\tAccuracy: 90.10%\n",
      "520\tValidation loss: 0.418216\tBest loss: 0.417432\tAccuracy: 90.10%\n",
      "521\tValidation loss: 0.417370\tBest loss: 0.417370\tAccuracy: 90.20%\n",
      "522\tValidation loss: 0.418666\tBest loss: 0.417370\tAccuracy: 90.20%\n",
      "523\tValidation loss: 0.417585\tBest loss: 0.417370\tAccuracy: 90.10%\n",
      "524\tValidation loss: 0.418086\tBest loss: 0.417370\tAccuracy: 90.20%\n",
      "525\tValidation loss: 0.417657\tBest loss: 0.417370\tAccuracy: 90.10%\n",
      "526\tValidation loss: 0.417443\tBest loss: 0.417370\tAccuracy: 90.10%\n",
      "527\tValidation loss: 0.417335\tBest loss: 0.417335\tAccuracy: 90.20%\n",
      "528\tValidation loss: 0.417080\tBest loss: 0.417080\tAccuracy: 90.30%\n",
      "529\tValidation loss: 0.416784\tBest loss: 0.416784\tAccuracy: 90.30%\n",
      "530\tValidation loss: 0.416578\tBest loss: 0.416578\tAccuracy: 90.10%\n",
      "531\tValidation loss: 0.416028\tBest loss: 0.416028\tAccuracy: 90.30%\n",
      "532\tValidation loss: 0.416571\tBest loss: 0.416028\tAccuracy: 90.30%\n",
      "533\tValidation loss: 0.416455\tBest loss: 0.416028\tAccuracy: 90.00%\n",
      "534\tValidation loss: 0.415907\tBest loss: 0.415907\tAccuracy: 90.10%\n",
      "535\tValidation loss: 0.415204\tBest loss: 0.415204\tAccuracy: 90.40%\n",
      "536\tValidation loss: 0.415278\tBest loss: 0.415204\tAccuracy: 90.00%\n",
      "537\tValidation loss: 0.415128\tBest loss: 0.415128\tAccuracy: 90.00%\n",
      "538\tValidation loss: 0.416059\tBest loss: 0.415128\tAccuracy: 89.90%\n",
      "539\tValidation loss: 0.415818\tBest loss: 0.415128\tAccuracy: 90.10%\n",
      "540\tValidation loss: 0.415430\tBest loss: 0.415128\tAccuracy: 90.10%\n",
      "541\tValidation loss: 0.416179\tBest loss: 0.415128\tAccuracy: 89.90%\n",
      "542\tValidation loss: 0.415117\tBest loss: 0.415117\tAccuracy: 90.40%\n",
      "543\tValidation loss: 0.415432\tBest loss: 0.415117\tAccuracy: 90.30%\n",
      "544\tValidation loss: 0.415201\tBest loss: 0.415117\tAccuracy: 90.20%\n",
      "545\tValidation loss: 0.415265\tBest loss: 0.415117\tAccuracy: 90.00%\n",
      "546\tValidation loss: 0.414525\tBest loss: 0.414525\tAccuracy: 90.20%\n",
      "547\tValidation loss: 0.414355\tBest loss: 0.414355\tAccuracy: 90.40%\n",
      "548\tValidation loss: 0.413779\tBest loss: 0.413779\tAccuracy: 90.10%\n",
      "549\tValidation loss: 0.414433\tBest loss: 0.413779\tAccuracy: 90.00%\n",
      "550\tValidation loss: 0.414527\tBest loss: 0.413779\tAccuracy: 90.10%\n",
      "551\tValidation loss: 0.413588\tBest loss: 0.413588\tAccuracy: 90.40%\n",
      "552\tValidation loss: 0.414139\tBest loss: 0.413588\tAccuracy: 90.00%\n",
      "553\tValidation loss: 0.413726\tBest loss: 0.413588\tAccuracy: 90.00%\n",
      "554\tValidation loss: 0.415278\tBest loss: 0.413588\tAccuracy: 90.40%\n",
      "555\tValidation loss: 0.415414\tBest loss: 0.413588\tAccuracy: 90.30%\n",
      "556\tValidation loss: 0.413128\tBest loss: 0.413128\tAccuracy: 90.10%\n",
      "557\tValidation loss: 0.413477\tBest loss: 0.413128\tAccuracy: 90.20%\n",
      "558\tValidation loss: 0.413835\tBest loss: 0.413128\tAccuracy: 90.20%\n",
      "559\tValidation loss: 0.413784\tBest loss: 0.413128\tAccuracy: 90.30%\n",
      "560\tValidation loss: 0.413396\tBest loss: 0.413128\tAccuracy: 90.00%\n",
      "561\tValidation loss: 0.412641\tBest loss: 0.412641\tAccuracy: 90.20%\n",
      "562\tValidation loss: 0.412744\tBest loss: 0.412641\tAccuracy: 90.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\tValidation loss: 0.412566\tBest loss: 0.412566\tAccuracy: 90.50%\n",
      "564\tValidation loss: 0.412826\tBest loss: 0.412566\tAccuracy: 90.40%\n",
      "565\tValidation loss: 0.412572\tBest loss: 0.412566\tAccuracy: 90.00%\n",
      "566\tValidation loss: 0.411889\tBest loss: 0.411889\tAccuracy: 90.20%\n",
      "567\tValidation loss: 0.412662\tBest loss: 0.411889\tAccuracy: 90.50%\n",
      "568\tValidation loss: 0.411364\tBest loss: 0.411364\tAccuracy: 90.10%\n",
      "569\tValidation loss: 0.412434\tBest loss: 0.411364\tAccuracy: 90.40%\n",
      "570\tValidation loss: 0.411537\tBest loss: 0.411364\tAccuracy: 90.20%\n",
      "571\tValidation loss: 0.412433\tBest loss: 0.411364\tAccuracy: 90.00%\n",
      "572\tValidation loss: 0.411697\tBest loss: 0.411364\tAccuracy: 90.30%\n",
      "573\tValidation loss: 0.411633\tBest loss: 0.411364\tAccuracy: 90.30%\n",
      "574\tValidation loss: 0.412113\tBest loss: 0.411364\tAccuracy: 90.20%\n",
      "575\tValidation loss: 0.412742\tBest loss: 0.411364\tAccuracy: 90.00%\n",
      "576\tValidation loss: 0.412257\tBest loss: 0.411364\tAccuracy: 90.00%\n",
      "577\tValidation loss: 0.412094\tBest loss: 0.411364\tAccuracy: 90.40%\n",
      "578\tValidation loss: 0.411553\tBest loss: 0.411364\tAccuracy: 90.40%\n",
      "579\tValidation loss: 0.411295\tBest loss: 0.411295\tAccuracy: 90.30%\n",
      "580\tValidation loss: 0.411306\tBest loss: 0.411295\tAccuracy: 90.10%\n",
      "581\tValidation loss: 0.411771\tBest loss: 0.411295\tAccuracy: 90.40%\n",
      "582\tValidation loss: 0.411601\tBest loss: 0.411295\tAccuracy: 90.40%\n",
      "583\tValidation loss: 0.410443\tBest loss: 0.410443\tAccuracy: 90.00%\n",
      "584\tValidation loss: 0.410275\tBest loss: 0.410275\tAccuracy: 90.40%\n",
      "585\tValidation loss: 0.411093\tBest loss: 0.410275\tAccuracy: 90.50%\n",
      "586\tValidation loss: 0.410792\tBest loss: 0.410275\tAccuracy: 90.30%\n",
      "587\tValidation loss: 0.410273\tBest loss: 0.410273\tAccuracy: 90.40%\n",
      "588\tValidation loss: 0.410671\tBest loss: 0.410273\tAccuracy: 90.20%\n",
      "589\tValidation loss: 0.410754\tBest loss: 0.410273\tAccuracy: 90.50%\n",
      "590\tValidation loss: 0.410851\tBest loss: 0.410273\tAccuracy: 90.30%\n",
      "591\tValidation loss: 0.409758\tBest loss: 0.409758\tAccuracy: 90.20%\n",
      "592\tValidation loss: 0.410256\tBest loss: 0.409758\tAccuracy: 90.40%\n",
      "593\tValidation loss: 0.409427\tBest loss: 0.409427\tAccuracy: 90.30%\n",
      "594\tValidation loss: 0.408974\tBest loss: 0.408974\tAccuracy: 90.60%\n",
      "595\tValidation loss: 0.410169\tBest loss: 0.408974\tAccuracy: 90.50%\n",
      "596\tValidation loss: 0.410153\tBest loss: 0.408974\tAccuracy: 90.70%\n",
      "597\tValidation loss: 0.410267\tBest loss: 0.408974\tAccuracy: 90.20%\n",
      "598\tValidation loss: 0.410196\tBest loss: 0.408974\tAccuracy: 90.40%\n",
      "599\tValidation loss: 0.409435\tBest loss: 0.408974\tAccuracy: 90.40%\n",
      "600\tValidation loss: 0.409486\tBest loss: 0.408974\tAccuracy: 90.40%\n",
      "601\tValidation loss: 0.408381\tBest loss: 0.408381\tAccuracy: 90.30%\n",
      "602\tValidation loss: 0.410643\tBest loss: 0.408381\tAccuracy: 90.50%\n",
      "603\tValidation loss: 0.408259\tBest loss: 0.408259\tAccuracy: 90.50%\n",
      "604\tValidation loss: 0.409104\tBest loss: 0.408259\tAccuracy: 90.30%\n",
      "605\tValidation loss: 0.410001\tBest loss: 0.408259\tAccuracy: 90.40%\n",
      "606\tValidation loss: 0.409228\tBest loss: 0.408259\tAccuracy: 90.40%\n",
      "607\tValidation loss: 0.408572\tBest loss: 0.408259\tAccuracy: 90.30%\n",
      "608\tValidation loss: 0.407918\tBest loss: 0.407918\tAccuracy: 90.40%\n",
      "609\tValidation loss: 0.407917\tBest loss: 0.407917\tAccuracy: 90.30%\n",
      "610\tValidation loss: 0.408323\tBest loss: 0.407917\tAccuracy: 90.70%\n",
      "611\tValidation loss: 0.406443\tBest loss: 0.406443\tAccuracy: 90.30%\n",
      "612\tValidation loss: 0.408468\tBest loss: 0.406443\tAccuracy: 90.30%\n",
      "613\tValidation loss: 0.408038\tBest loss: 0.406443\tAccuracy: 90.40%\n",
      "614\tValidation loss: 0.407602\tBest loss: 0.406443\tAccuracy: 90.40%\n",
      "615\tValidation loss: 0.407553\tBest loss: 0.406443\tAccuracy: 90.70%\n",
      "616\tValidation loss: 0.407503\tBest loss: 0.406443\tAccuracy: 90.50%\n",
      "617\tValidation loss: 0.407618\tBest loss: 0.406443\tAccuracy: 90.40%\n",
      "618\tValidation loss: 0.407844\tBest loss: 0.406443\tAccuracy: 90.60%\n",
      "619\tValidation loss: 0.407174\tBest loss: 0.406443\tAccuracy: 90.60%\n",
      "620\tValidation loss: 0.406667\tBest loss: 0.406443\tAccuracy: 90.60%\n",
      "621\tValidation loss: 0.407238\tBest loss: 0.406443\tAccuracy: 90.60%\n",
      "622\tValidation loss: 0.407474\tBest loss: 0.406443\tAccuracy: 90.60%\n",
      "623\tValidation loss: 0.405908\tBest loss: 0.405908\tAccuracy: 90.60%\n",
      "624\tValidation loss: 0.407445\tBest loss: 0.405908\tAccuracy: 90.30%\n",
      "625\tValidation loss: 0.406341\tBest loss: 0.405908\tAccuracy: 90.70%\n",
      "626\tValidation loss: 0.407340\tBest loss: 0.405908\tAccuracy: 90.60%\n",
      "627\tValidation loss: 0.406682\tBest loss: 0.405908\tAccuracy: 90.70%\n",
      "628\tValidation loss: 0.407435\tBest loss: 0.405908\tAccuracy: 90.70%\n",
      "629\tValidation loss: 0.406671\tBest loss: 0.405908\tAccuracy: 90.40%\n",
      "630\tValidation loss: 0.406850\tBest loss: 0.405908\tAccuracy: 90.50%\n",
      "631\tValidation loss: 0.406329\tBest loss: 0.405908\tAccuracy: 90.80%\n",
      "632\tValidation loss: 0.406037\tBest loss: 0.405908\tAccuracy: 90.50%\n",
      "633\tValidation loss: 0.406444\tBest loss: 0.405908\tAccuracy: 90.70%\n",
      "634\tValidation loss: 0.405630\tBest loss: 0.405630\tAccuracy: 90.80%\n",
      "635\tValidation loss: 0.406005\tBest loss: 0.405630\tAccuracy: 90.80%\n",
      "636\tValidation loss: 0.405494\tBest loss: 0.405494\tAccuracy: 90.60%\n",
      "637\tValidation loss: 0.405113\tBest loss: 0.405113\tAccuracy: 90.60%\n",
      "638\tValidation loss: 0.405334\tBest loss: 0.405113\tAccuracy: 90.70%\n",
      "639\tValidation loss: 0.405678\tBest loss: 0.405113\tAccuracy: 90.50%\n",
      "640\tValidation loss: 0.405085\tBest loss: 0.405085\tAccuracy: 90.70%\n",
      "641\tValidation loss: 0.404835\tBest loss: 0.404835\tAccuracy: 90.50%\n",
      "642\tValidation loss: 0.405595\tBest loss: 0.404835\tAccuracy: 90.50%\n",
      "643\tValidation loss: 0.404825\tBest loss: 0.404825\tAccuracy: 90.70%\n",
      "644\tValidation loss: 0.405629\tBest loss: 0.404825\tAccuracy: 90.60%\n",
      "645\tValidation loss: 0.405499\tBest loss: 0.404825\tAccuracy: 90.50%\n",
      "646\tValidation loss: 0.405431\tBest loss: 0.404825\tAccuracy: 90.60%\n",
      "647\tValidation loss: 0.405605\tBest loss: 0.404825\tAccuracy: 90.60%\n",
      "648\tValidation loss: 0.404964\tBest loss: 0.404825\tAccuracy: 90.60%\n",
      "649\tValidation loss: 0.405881\tBest loss: 0.404825\tAccuracy: 90.50%\n",
      "650\tValidation loss: 0.404815\tBest loss: 0.404815\tAccuracy: 90.60%\n",
      "651\tValidation loss: 0.404947\tBest loss: 0.404815\tAccuracy: 90.50%\n",
      "652\tValidation loss: 0.404439\tBest loss: 0.404439\tAccuracy: 90.50%\n",
      "653\tValidation loss: 0.404796\tBest loss: 0.404439\tAccuracy: 90.60%\n",
      "654\tValidation loss: 0.404717\tBest loss: 0.404439\tAccuracy: 90.50%\n",
      "655\tValidation loss: 0.404831\tBest loss: 0.404439\tAccuracy: 90.60%\n",
      "656\tValidation loss: 0.404375\tBest loss: 0.404375\tAccuracy: 90.80%\n",
      "657\tValidation loss: 0.404437\tBest loss: 0.404375\tAccuracy: 90.50%\n",
      "658\tValidation loss: 0.404377\tBest loss: 0.404375\tAccuracy: 90.60%\n",
      "659\tValidation loss: 0.403536\tBest loss: 0.403536\tAccuracy: 90.60%\n",
      "660\tValidation loss: 0.404029\tBest loss: 0.403536\tAccuracy: 90.40%\n",
      "661\tValidation loss: 0.403884\tBest loss: 0.403536\tAccuracy: 90.60%\n",
      "662\tValidation loss: 0.403091\tBest loss: 0.403091\tAccuracy: 90.50%\n",
      "663\tValidation loss: 0.403780\tBest loss: 0.403091\tAccuracy: 90.80%\n",
      "664\tValidation loss: 0.403925\tBest loss: 0.403091\tAccuracy: 90.70%\n",
      "665\tValidation loss: 0.404545\tBest loss: 0.403091\tAccuracy: 90.60%\n",
      "666\tValidation loss: 0.404122\tBest loss: 0.403091\tAccuracy: 90.60%\n",
      "667\tValidation loss: 0.402586\tBest loss: 0.402586\tAccuracy: 90.50%\n",
      "668\tValidation loss: 0.403419\tBest loss: 0.402586\tAccuracy: 90.60%\n",
      "669\tValidation loss: 0.402903\tBest loss: 0.402586\tAccuracy: 90.50%\n",
      "670\tValidation loss: 0.403400\tBest loss: 0.402586\tAccuracy: 90.60%\n",
      "671\tValidation loss: 0.403131\tBest loss: 0.402586\tAccuracy: 90.50%\n",
      "672\tValidation loss: 0.403084\tBest loss: 0.402586\tAccuracy: 90.50%\n",
      "673\tValidation loss: 0.403780\tBest loss: 0.402586\tAccuracy: 90.70%\n",
      "674\tValidation loss: 0.401808\tBest loss: 0.401808\tAccuracy: 90.50%\n",
      "675\tValidation loss: 0.401892\tBest loss: 0.401808\tAccuracy: 90.70%\n",
      "676\tValidation loss: 0.402592\tBest loss: 0.401808\tAccuracy: 90.60%\n",
      "677\tValidation loss: 0.402375\tBest loss: 0.401808\tAccuracy: 90.70%\n",
      "678\tValidation loss: 0.402278\tBest loss: 0.401808\tAccuracy: 90.80%\n",
      "679\tValidation loss: 0.402763\tBest loss: 0.401808\tAccuracy: 90.60%\n",
      "680\tValidation loss: 0.401165\tBest loss: 0.401165\tAccuracy: 90.60%\n",
      "681\tValidation loss: 0.401460\tBest loss: 0.401165\tAccuracy: 90.40%\n",
      "682\tValidation loss: 0.401723\tBest loss: 0.401165\tAccuracy: 90.60%\n",
      "683\tValidation loss: 0.402356\tBest loss: 0.401165\tAccuracy: 90.50%\n",
      "684\tValidation loss: 0.401830\tBest loss: 0.401165\tAccuracy: 90.50%\n",
      "685\tValidation loss: 0.401776\tBest loss: 0.401165\tAccuracy: 90.70%\n",
      "686\tValidation loss: 0.400852\tBest loss: 0.400852\tAccuracy: 90.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\tValidation loss: 0.401243\tBest loss: 0.400852\tAccuracy: 90.60%\n",
      "688\tValidation loss: 0.402415\tBest loss: 0.400852\tAccuracy: 90.40%\n",
      "689\tValidation loss: 0.401474\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "690\tValidation loss: 0.401269\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "691\tValidation loss: 0.401790\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "692\tValidation loss: 0.401399\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "693\tValidation loss: 0.401409\tBest loss: 0.400852\tAccuracy: 90.40%\n",
      "694\tValidation loss: 0.401569\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "695\tValidation loss: 0.401375\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "696\tValidation loss: 0.401558\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "697\tValidation loss: 0.401280\tBest loss: 0.400852\tAccuracy: 90.50%\n",
      "698\tValidation loss: 0.400781\tBest loss: 0.400781\tAccuracy: 90.50%\n",
      "699\tValidation loss: 0.401537\tBest loss: 0.400781\tAccuracy: 90.60%\n",
      "700\tValidation loss: 0.401867\tBest loss: 0.400781\tAccuracy: 90.60%\n",
      "701\tValidation loss: 0.400819\tBest loss: 0.400781\tAccuracy: 90.50%\n",
      "702\tValidation loss: 0.401588\tBest loss: 0.400781\tAccuracy: 90.60%\n",
      "703\tValidation loss: 0.400179\tBest loss: 0.400179\tAccuracy: 90.60%\n",
      "704\tValidation loss: 0.400780\tBest loss: 0.400179\tAccuracy: 90.60%\n",
      "705\tValidation loss: 0.401178\tBest loss: 0.400179\tAccuracy: 90.60%\n",
      "706\tValidation loss: 0.399696\tBest loss: 0.399696\tAccuracy: 90.60%\n",
      "707\tValidation loss: 0.399722\tBest loss: 0.399696\tAccuracy: 90.50%\n",
      "708\tValidation loss: 0.399322\tBest loss: 0.399322\tAccuracy: 90.70%\n",
      "709\tValidation loss: 0.399928\tBest loss: 0.399322\tAccuracy: 90.60%\n",
      "710\tValidation loss: 0.400524\tBest loss: 0.399322\tAccuracy: 90.50%\n",
      "711\tValidation loss: 0.399606\tBest loss: 0.399322\tAccuracy: 90.60%\n",
      "712\tValidation loss: 0.400547\tBest loss: 0.399322\tAccuracy: 90.60%\n",
      "713\tValidation loss: 0.400546\tBest loss: 0.399322\tAccuracy: 90.60%\n",
      "714\tValidation loss: 0.399716\tBest loss: 0.399322\tAccuracy: 90.70%\n",
      "715\tValidation loss: 0.399683\tBest loss: 0.399322\tAccuracy: 90.50%\n",
      "716\tValidation loss: 0.400184\tBest loss: 0.399322\tAccuracy: 90.70%\n",
      "717\tValidation loss: 0.398362\tBest loss: 0.398362\tAccuracy: 90.60%\n",
      "718\tValidation loss: 0.398970\tBest loss: 0.398362\tAccuracy: 90.60%\n",
      "719\tValidation loss: 0.399841\tBest loss: 0.398362\tAccuracy: 90.60%\n",
      "720\tValidation loss: 0.399023\tBest loss: 0.398362\tAccuracy: 90.70%\n",
      "721\tValidation loss: 0.399732\tBest loss: 0.398362\tAccuracy: 90.70%\n",
      "722\tValidation loss: 0.399384\tBest loss: 0.398362\tAccuracy: 90.60%\n",
      "723\tValidation loss: 0.398890\tBest loss: 0.398362\tAccuracy: 90.80%\n",
      "724\tValidation loss: 0.399222\tBest loss: 0.398362\tAccuracy: 90.60%\n",
      "725\tValidation loss: 0.398233\tBest loss: 0.398233\tAccuracy: 90.70%\n",
      "726\tValidation loss: 0.398104\tBest loss: 0.398104\tAccuracy: 90.70%\n",
      "727\tValidation loss: 0.399107\tBest loss: 0.398104\tAccuracy: 90.70%\n",
      "728\tValidation loss: 0.399439\tBest loss: 0.398104\tAccuracy: 90.50%\n",
      "729\tValidation loss: 0.399375\tBest loss: 0.398104\tAccuracy: 90.70%\n",
      "730\tValidation loss: 0.397940\tBest loss: 0.397940\tAccuracy: 90.70%\n",
      "731\tValidation loss: 0.399249\tBest loss: 0.397940\tAccuracy: 90.70%\n",
      "732\tValidation loss: 0.399314\tBest loss: 0.397940\tAccuracy: 90.60%\n",
      "733\tValidation loss: 0.398298\tBest loss: 0.397940\tAccuracy: 90.50%\n",
      "734\tValidation loss: 0.397260\tBest loss: 0.397260\tAccuracy: 90.90%\n",
      "735\tValidation loss: 0.398947\tBest loss: 0.397260\tAccuracy: 90.70%\n",
      "736\tValidation loss: 0.398071\tBest loss: 0.397260\tAccuracy: 90.60%\n",
      "737\tValidation loss: 0.397169\tBest loss: 0.397169\tAccuracy: 90.50%\n",
      "738\tValidation loss: 0.398201\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "739\tValidation loss: 0.398638\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "740\tValidation loss: 0.399164\tBest loss: 0.397169\tAccuracy: 90.80%\n",
      "741\tValidation loss: 0.397804\tBest loss: 0.397169\tAccuracy: 90.80%\n",
      "742\tValidation loss: 0.397908\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "743\tValidation loss: 0.397227\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "744\tValidation loss: 0.398170\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "745\tValidation loss: 0.397392\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "746\tValidation loss: 0.397972\tBest loss: 0.397169\tAccuracy: 90.70%\n",
      "747\tValidation loss: 0.396874\tBest loss: 0.396874\tAccuracy: 90.90%\n",
      "748\tValidation loss: 0.396214\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "749\tValidation loss: 0.396907\tBest loss: 0.396214\tAccuracy: 90.70%\n",
      "750\tValidation loss: 0.396640\tBest loss: 0.396214\tAccuracy: 90.60%\n",
      "751\tValidation loss: 0.397009\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "752\tValidation loss: 0.397163\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "753\tValidation loss: 0.396971\tBest loss: 0.396214\tAccuracy: 90.90%\n",
      "754\tValidation loss: 0.397819\tBest loss: 0.396214\tAccuracy: 90.90%\n",
      "755\tValidation loss: 0.396349\tBest loss: 0.396214\tAccuracy: 90.70%\n",
      "756\tValidation loss: 0.398184\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "757\tValidation loss: 0.396801\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "758\tValidation loss: 0.397272\tBest loss: 0.396214\tAccuracy: 90.90%\n",
      "759\tValidation loss: 0.396812\tBest loss: 0.396214\tAccuracy: 90.70%\n",
      "760\tValidation loss: 0.397310\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "761\tValidation loss: 0.396752\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "762\tValidation loss: 0.397106\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "763\tValidation loss: 0.396871\tBest loss: 0.396214\tAccuracy: 90.90%\n",
      "764\tValidation loss: 0.396317\tBest loss: 0.396214\tAccuracy: 90.60%\n",
      "765\tValidation loss: 0.396724\tBest loss: 0.396214\tAccuracy: 91.00%\n",
      "766\tValidation loss: 0.396997\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "767\tValidation loss: 0.396528\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "768\tValidation loss: 0.396277\tBest loss: 0.396214\tAccuracy: 90.80%\n",
      "769\tValidation loss: 0.396547\tBest loss: 0.396214\tAccuracy: 91.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.3min\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.249303\tBest loss: 3.249303\tAccuracy: 20.90%\n",
      "1\tValidation loss: 2.771648\tBest loss: 2.771648\tAccuracy: 34.70%\n",
      "2\tValidation loss: 2.448037\tBest loss: 2.448037\tAccuracy: 43.40%\n",
      "3\tValidation loss: 2.225106\tBest loss: 2.225106\tAccuracy: 48.20%\n",
      "4\tValidation loss: 2.041783\tBest loss: 2.041783\tAccuracy: 52.10%\n",
      "5\tValidation loss: 1.903350\tBest loss: 1.903350\tAccuracy: 55.10%\n",
      "6\tValidation loss: 1.783698\tBest loss: 1.783698\tAccuracy: 58.80%\n",
      "7\tValidation loss: 1.677562\tBest loss: 1.677562\tAccuracy: 60.60%\n",
      "8\tValidation loss: 1.599929\tBest loss: 1.599929\tAccuracy: 63.00%\n",
      "9\tValidation loss: 1.531398\tBest loss: 1.531398\tAccuracy: 65.20%\n",
      "10\tValidation loss: 1.461371\tBest loss: 1.461371\tAccuracy: 66.30%\n",
      "11\tValidation loss: 1.404020\tBest loss: 1.404020\tAccuracy: 68.00%\n",
      "12\tValidation loss: 1.364827\tBest loss: 1.364827\tAccuracy: 67.60%\n",
      "13\tValidation loss: 1.319871\tBest loss: 1.319871\tAccuracy: 70.00%\n",
      "14\tValidation loss: 1.272298\tBest loss: 1.272298\tAccuracy: 70.90%\n",
      "15\tValidation loss: 1.238135\tBest loss: 1.238135\tAccuracy: 72.10%\n",
      "16\tValidation loss: 1.201259\tBest loss: 1.201259\tAccuracy: 72.40%\n",
      "17\tValidation loss: 1.175026\tBest loss: 1.175026\tAccuracy: 72.40%\n",
      "18\tValidation loss: 1.150584\tBest loss: 1.150584\tAccuracy: 74.10%\n",
      "19\tValidation loss: 1.122678\tBest loss: 1.122678\tAccuracy: 74.70%\n",
      "20\tValidation loss: 1.100428\tBest loss: 1.100428\tAccuracy: 74.90%\n",
      "21\tValidation loss: 1.076271\tBest loss: 1.076271\tAccuracy: 75.60%\n",
      "22\tValidation loss: 1.059202\tBest loss: 1.059202\tAccuracy: 76.20%\n",
      "23\tValidation loss: 1.038113\tBest loss: 1.038113\tAccuracy: 75.70%\n",
      "24\tValidation loss: 1.026008\tBest loss: 1.026008\tAccuracy: 77.00%\n",
      "25\tValidation loss: 1.008290\tBest loss: 1.008290\tAccuracy: 77.10%\n",
      "26\tValidation loss: 0.999282\tBest loss: 0.999282\tAccuracy: 77.50%\n",
      "27\tValidation loss: 0.976542\tBest loss: 0.976542\tAccuracy: 77.80%\n",
      "28\tValidation loss: 0.963563\tBest loss: 0.963563\tAccuracy: 78.30%\n",
      "29\tValidation loss: 0.951364\tBest loss: 0.951364\tAccuracy: 78.50%\n",
      "30\tValidation loss: 0.942284\tBest loss: 0.942284\tAccuracy: 78.70%\n",
      "31\tValidation loss: 0.926333\tBest loss: 0.926333\tAccuracy: 79.00%\n",
      "32\tValidation loss: 0.916210\tBest loss: 0.916210\tAccuracy: 79.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\tValidation loss: 0.904872\tBest loss: 0.904872\tAccuracy: 79.20%\n",
      "34\tValidation loss: 0.898807\tBest loss: 0.898807\tAccuracy: 79.20%\n",
      "35\tValidation loss: 0.886936\tBest loss: 0.886936\tAccuracy: 78.90%\n",
      "36\tValidation loss: 0.878618\tBest loss: 0.878618\tAccuracy: 79.80%\n",
      "37\tValidation loss: 0.866692\tBest loss: 0.866692\tAccuracy: 80.30%\n",
      "38\tValidation loss: 0.860438\tBest loss: 0.860438\tAccuracy: 80.70%\n",
      "39\tValidation loss: 0.852324\tBest loss: 0.852324\tAccuracy: 80.70%\n",
      "40\tValidation loss: 0.846077\tBest loss: 0.846077\tAccuracy: 80.60%\n",
      "41\tValidation loss: 0.835742\tBest loss: 0.835742\tAccuracy: 81.00%\n",
      "42\tValidation loss: 0.830014\tBest loss: 0.830014\tAccuracy: 80.90%\n",
      "43\tValidation loss: 0.818932\tBest loss: 0.818932\tAccuracy: 80.70%\n",
      "44\tValidation loss: 0.818007\tBest loss: 0.818007\tAccuracy: 80.90%\n",
      "45\tValidation loss: 0.811809\tBest loss: 0.811809\tAccuracy: 81.20%\n",
      "46\tValidation loss: 0.810086\tBest loss: 0.810086\tAccuracy: 81.30%\n",
      "47\tValidation loss: 0.798722\tBest loss: 0.798722\tAccuracy: 81.60%\n",
      "48\tValidation loss: 0.791927\tBest loss: 0.791927\tAccuracy: 81.10%\n",
      "49\tValidation loss: 0.787082\tBest loss: 0.787082\tAccuracy: 81.90%\n",
      "50\tValidation loss: 0.781930\tBest loss: 0.781930\tAccuracy: 82.00%\n",
      "51\tValidation loss: 0.773766\tBest loss: 0.773766\tAccuracy: 82.20%\n",
      "52\tValidation loss: 0.767034\tBest loss: 0.767034\tAccuracy: 82.40%\n",
      "53\tValidation loss: 0.759064\tBest loss: 0.759064\tAccuracy: 82.50%\n",
      "54\tValidation loss: 0.757851\tBest loss: 0.757851\tAccuracy: 82.30%\n",
      "55\tValidation loss: 0.753543\tBest loss: 0.753543\tAccuracy: 82.40%\n",
      "56\tValidation loss: 0.751084\tBest loss: 0.751084\tAccuracy: 82.50%\n",
      "57\tValidation loss: 0.743102\tBest loss: 0.743102\tAccuracy: 82.60%\n",
      "58\tValidation loss: 0.742682\tBest loss: 0.742682\tAccuracy: 83.10%\n",
      "59\tValidation loss: 0.737236\tBest loss: 0.737236\tAccuracy: 83.40%\n",
      "60\tValidation loss: 0.734074\tBest loss: 0.734074\tAccuracy: 83.20%\n",
      "61\tValidation loss: 0.728937\tBest loss: 0.728937\tAccuracy: 83.10%\n",
      "62\tValidation loss: 0.721893\tBest loss: 0.721893\tAccuracy: 84.00%\n",
      "63\tValidation loss: 0.715422\tBest loss: 0.715422\tAccuracy: 83.70%\n",
      "64\tValidation loss: 0.712923\tBest loss: 0.712923\tAccuracy: 83.40%\n",
      "65\tValidation loss: 0.706987\tBest loss: 0.706987\tAccuracy: 84.10%\n",
      "66\tValidation loss: 0.706279\tBest loss: 0.706279\tAccuracy: 83.50%\n",
      "67\tValidation loss: 0.708074\tBest loss: 0.706279\tAccuracy: 83.60%\n",
      "68\tValidation loss: 0.698198\tBest loss: 0.698198\tAccuracy: 83.50%\n",
      "69\tValidation loss: 0.697409\tBest loss: 0.697409\tAccuracy: 83.30%\n",
      "70\tValidation loss: 0.692557\tBest loss: 0.692557\tAccuracy: 83.30%\n",
      "71\tValidation loss: 0.689218\tBest loss: 0.689218\tAccuracy: 83.90%\n",
      "72\tValidation loss: 0.690993\tBest loss: 0.689218\tAccuracy: 83.90%\n",
      "73\tValidation loss: 0.682953\tBest loss: 0.682953\tAccuracy: 83.80%\n",
      "74\tValidation loss: 0.678533\tBest loss: 0.678533\tAccuracy: 83.90%\n",
      "75\tValidation loss: 0.678070\tBest loss: 0.678070\tAccuracy: 83.60%\n",
      "76\tValidation loss: 0.670115\tBest loss: 0.670115\tAccuracy: 84.60%\n",
      "77\tValidation loss: 0.670062\tBest loss: 0.670062\tAccuracy: 84.80%\n",
      "78\tValidation loss: 0.664963\tBest loss: 0.664963\tAccuracy: 85.30%\n",
      "79\tValidation loss: 0.665228\tBest loss: 0.664963\tAccuracy: 84.30%\n",
      "80\tValidation loss: 0.661307\tBest loss: 0.661307\tAccuracy: 84.80%\n",
      "81\tValidation loss: 0.660122\tBest loss: 0.660122\tAccuracy: 84.50%\n",
      "82\tValidation loss: 0.653594\tBest loss: 0.653594\tAccuracy: 84.60%\n",
      "83\tValidation loss: 0.658117\tBest loss: 0.653594\tAccuracy: 84.20%\n",
      "84\tValidation loss: 0.649762\tBest loss: 0.649762\tAccuracy: 84.80%\n",
      "85\tValidation loss: 0.646477\tBest loss: 0.646477\tAccuracy: 85.00%\n",
      "86\tValidation loss: 0.647237\tBest loss: 0.646477\tAccuracy: 85.00%\n",
      "87\tValidation loss: 0.641750\tBest loss: 0.641750\tAccuracy: 85.00%\n",
      "88\tValidation loss: 0.641480\tBest loss: 0.641480\tAccuracy: 85.00%\n",
      "89\tValidation loss: 0.637455\tBest loss: 0.637455\tAccuracy: 84.80%\n",
      "90\tValidation loss: 0.635912\tBest loss: 0.635912\tAccuracy: 85.00%\n",
      "91\tValidation loss: 0.632577\tBest loss: 0.632577\tAccuracy: 84.60%\n",
      "92\tValidation loss: 0.632880\tBest loss: 0.632577\tAccuracy: 84.80%\n",
      "93\tValidation loss: 0.626911\tBest loss: 0.626911\tAccuracy: 85.20%\n",
      "94\tValidation loss: 0.626102\tBest loss: 0.626102\tAccuracy: 85.30%\n",
      "95\tValidation loss: 0.621663\tBest loss: 0.621663\tAccuracy: 85.50%\n",
      "96\tValidation loss: 0.621884\tBest loss: 0.621663\tAccuracy: 84.90%\n",
      "97\tValidation loss: 0.619593\tBest loss: 0.619593\tAccuracy: 85.20%\n",
      "98\tValidation loss: 0.620193\tBest loss: 0.619593\tAccuracy: 85.20%\n",
      "99\tValidation loss: 0.617858\tBest loss: 0.617858\tAccuracy: 85.50%\n",
      "100\tValidation loss: 0.615895\tBest loss: 0.615895\tAccuracy: 85.30%\n",
      "101\tValidation loss: 0.611546\tBest loss: 0.611546\tAccuracy: 85.80%\n",
      "102\tValidation loss: 0.608650\tBest loss: 0.608650\tAccuracy: 85.40%\n",
      "103\tValidation loss: 0.607553\tBest loss: 0.607553\tAccuracy: 85.60%\n",
      "104\tValidation loss: 0.608571\tBest loss: 0.607553\tAccuracy: 85.50%\n",
      "105\tValidation loss: 0.605259\tBest loss: 0.605259\tAccuracy: 85.10%\n",
      "106\tValidation loss: 0.602198\tBest loss: 0.602198\tAccuracy: 85.40%\n",
      "107\tValidation loss: 0.601629\tBest loss: 0.601629\tAccuracy: 85.20%\n",
      "108\tValidation loss: 0.599589\tBest loss: 0.599589\tAccuracy: 85.60%\n",
      "109\tValidation loss: 0.600431\tBest loss: 0.599589\tAccuracy: 85.20%\n",
      "110\tValidation loss: 0.596636\tBest loss: 0.596636\tAccuracy: 85.40%\n",
      "111\tValidation loss: 0.593782\tBest loss: 0.593782\tAccuracy: 85.60%\n",
      "112\tValidation loss: 0.595882\tBest loss: 0.593782\tAccuracy: 85.10%\n",
      "113\tValidation loss: 0.591842\tBest loss: 0.591842\tAccuracy: 85.60%\n",
      "114\tValidation loss: 0.588878\tBest loss: 0.588878\tAccuracy: 85.80%\n",
      "115\tValidation loss: 0.588880\tBest loss: 0.588878\tAccuracy: 85.40%\n",
      "116\tValidation loss: 0.588684\tBest loss: 0.588684\tAccuracy: 85.50%\n",
      "117\tValidation loss: 0.584069\tBest loss: 0.584069\tAccuracy: 85.90%\n",
      "118\tValidation loss: 0.582132\tBest loss: 0.582132\tAccuracy: 86.10%\n",
      "119\tValidation loss: 0.581986\tBest loss: 0.581986\tAccuracy: 85.70%\n",
      "120\tValidation loss: 0.580738\tBest loss: 0.580738\tAccuracy: 86.00%\n",
      "121\tValidation loss: 0.579366\tBest loss: 0.579366\tAccuracy: 85.90%\n",
      "122\tValidation loss: 0.577495\tBest loss: 0.577495\tAccuracy: 85.70%\n",
      "123\tValidation loss: 0.574701\tBest loss: 0.574701\tAccuracy: 86.30%\n",
      "124\tValidation loss: 0.575645\tBest loss: 0.574701\tAccuracy: 86.10%\n",
      "125\tValidation loss: 0.573410\tBest loss: 0.573410\tAccuracy: 85.90%\n",
      "126\tValidation loss: 0.571521\tBest loss: 0.571521\tAccuracy: 86.10%\n",
      "127\tValidation loss: 0.571151\tBest loss: 0.571151\tAccuracy: 86.10%\n",
      "128\tValidation loss: 0.570123\tBest loss: 0.570123\tAccuracy: 85.90%\n",
      "129\tValidation loss: 0.566470\tBest loss: 0.566470\tAccuracy: 86.30%\n",
      "130\tValidation loss: 0.564010\tBest loss: 0.564010\tAccuracy: 86.40%\n",
      "131\tValidation loss: 0.563998\tBest loss: 0.563998\tAccuracy: 86.00%\n",
      "132\tValidation loss: 0.563716\tBest loss: 0.563716\tAccuracy: 86.20%\n",
      "133\tValidation loss: 0.564180\tBest loss: 0.563716\tAccuracy: 86.10%\n",
      "134\tValidation loss: 0.561345\tBest loss: 0.561345\tAccuracy: 86.90%\n",
      "135\tValidation loss: 0.564145\tBest loss: 0.561345\tAccuracy: 85.70%\n",
      "136\tValidation loss: 0.561800\tBest loss: 0.561345\tAccuracy: 85.80%\n",
      "137\tValidation loss: 0.560729\tBest loss: 0.560729\tAccuracy: 86.30%\n",
      "138\tValidation loss: 0.556276\tBest loss: 0.556276\tAccuracy: 85.90%\n",
      "139\tValidation loss: 0.556531\tBest loss: 0.556276\tAccuracy: 86.20%\n",
      "140\tValidation loss: 0.556622\tBest loss: 0.556276\tAccuracy: 86.20%\n",
      "141\tValidation loss: 0.556871\tBest loss: 0.556276\tAccuracy: 86.00%\n",
      "142\tValidation loss: 0.552270\tBest loss: 0.552270\tAccuracy: 86.50%\n",
      "143\tValidation loss: 0.552374\tBest loss: 0.552270\tAccuracy: 86.30%\n",
      "144\tValidation loss: 0.549727\tBest loss: 0.549727\tAccuracy: 86.90%\n",
      "145\tValidation loss: 0.550656\tBest loss: 0.549727\tAccuracy: 86.10%\n",
      "146\tValidation loss: 0.549978\tBest loss: 0.549727\tAccuracy: 86.50%\n",
      "147\tValidation loss: 0.546971\tBest loss: 0.546971\tAccuracy: 86.70%\n",
      "148\tValidation loss: 0.547271\tBest loss: 0.546971\tAccuracy: 86.30%\n",
      "149\tValidation loss: 0.546051\tBest loss: 0.546051\tAccuracy: 86.50%\n",
      "150\tValidation loss: 0.544165\tBest loss: 0.544165\tAccuracy: 86.70%\n",
      "151\tValidation loss: 0.542525\tBest loss: 0.542525\tAccuracy: 86.90%\n",
      "152\tValidation loss: 0.541483\tBest loss: 0.541483\tAccuracy: 86.80%\n",
      "153\tValidation loss: 0.542694\tBest loss: 0.541483\tAccuracy: 86.30%\n",
      "154\tValidation loss: 0.541200\tBest loss: 0.541200\tAccuracy: 86.80%\n",
      "155\tValidation loss: 0.540220\tBest loss: 0.540220\tAccuracy: 86.50%\n",
      "156\tValidation loss: 0.538476\tBest loss: 0.538476\tAccuracy: 86.80%\n",
      "157\tValidation loss: 0.536545\tBest loss: 0.536545\tAccuracy: 86.80%\n",
      "158\tValidation loss: 0.537199\tBest loss: 0.536545\tAccuracy: 87.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\tValidation loss: 0.537956\tBest loss: 0.536545\tAccuracy: 86.80%\n",
      "160\tValidation loss: 0.534698\tBest loss: 0.534698\tAccuracy: 87.00%\n",
      "161\tValidation loss: 0.536789\tBest loss: 0.534698\tAccuracy: 86.40%\n",
      "162\tValidation loss: 0.534981\tBest loss: 0.534698\tAccuracy: 86.70%\n",
      "163\tValidation loss: 0.535537\tBest loss: 0.534698\tAccuracy: 86.60%\n",
      "164\tValidation loss: 0.531535\tBest loss: 0.531535\tAccuracy: 87.10%\n",
      "165\tValidation loss: 0.531778\tBest loss: 0.531535\tAccuracy: 87.10%\n",
      "166\tValidation loss: 0.528871\tBest loss: 0.528871\tAccuracy: 87.20%\n",
      "167\tValidation loss: 0.529022\tBest loss: 0.528871\tAccuracy: 87.00%\n",
      "168\tValidation loss: 0.527271\tBest loss: 0.527271\tAccuracy: 86.50%\n",
      "169\tValidation loss: 0.528383\tBest loss: 0.527271\tAccuracy: 87.00%\n",
      "170\tValidation loss: 0.524603\tBest loss: 0.524603\tAccuracy: 87.10%\n",
      "171\tValidation loss: 0.526243\tBest loss: 0.524603\tAccuracy: 86.70%\n",
      "172\tValidation loss: 0.524335\tBest loss: 0.524335\tAccuracy: 86.80%\n",
      "173\tValidation loss: 0.524062\tBest loss: 0.524062\tAccuracy: 87.00%\n",
      "174\tValidation loss: 0.522145\tBest loss: 0.522145\tAccuracy: 87.50%\n",
      "175\tValidation loss: 0.523261\tBest loss: 0.522145\tAccuracy: 87.20%\n",
      "176\tValidation loss: 0.522911\tBest loss: 0.522145\tAccuracy: 87.00%\n",
      "177\tValidation loss: 0.522671\tBest loss: 0.522145\tAccuracy: 87.10%\n",
      "178\tValidation loss: 0.522346\tBest loss: 0.522145\tAccuracy: 86.80%\n",
      "179\tValidation loss: 0.520321\tBest loss: 0.520321\tAccuracy: 87.00%\n",
      "180\tValidation loss: 0.520709\tBest loss: 0.520321\tAccuracy: 87.10%\n",
      "181\tValidation loss: 0.517668\tBest loss: 0.517668\tAccuracy: 87.10%\n",
      "182\tValidation loss: 0.515953\tBest loss: 0.515953\tAccuracy: 87.40%\n",
      "183\tValidation loss: 0.517393\tBest loss: 0.515953\tAccuracy: 87.00%\n",
      "184\tValidation loss: 0.518269\tBest loss: 0.515953\tAccuracy: 86.80%\n",
      "185\tValidation loss: 0.515463\tBest loss: 0.515463\tAccuracy: 87.00%\n",
      "186\tValidation loss: 0.516107\tBest loss: 0.515463\tAccuracy: 87.20%\n",
      "187\tValidation loss: 0.514637\tBest loss: 0.514637\tAccuracy: 87.30%\n",
      "188\tValidation loss: 0.513632\tBest loss: 0.513632\tAccuracy: 87.00%\n",
      "189\tValidation loss: 0.513045\tBest loss: 0.513045\tAccuracy: 87.00%\n",
      "190\tValidation loss: 0.512616\tBest loss: 0.512616\tAccuracy: 87.60%\n",
      "191\tValidation loss: 0.511470\tBest loss: 0.511470\tAccuracy: 87.00%\n",
      "192\tValidation loss: 0.510703\tBest loss: 0.510703\tAccuracy: 87.20%\n",
      "193\tValidation loss: 0.510028\tBest loss: 0.510028\tAccuracy: 87.00%\n",
      "194\tValidation loss: 0.509298\tBest loss: 0.509298\tAccuracy: 87.40%\n",
      "195\tValidation loss: 0.509610\tBest loss: 0.509298\tAccuracy: 87.10%\n",
      "196\tValidation loss: 0.506677\tBest loss: 0.506677\tAccuracy: 87.20%\n",
      "197\tValidation loss: 0.510134\tBest loss: 0.506677\tAccuracy: 86.80%\n",
      "198\tValidation loss: 0.507277\tBest loss: 0.506677\tAccuracy: 87.50%\n",
      "199\tValidation loss: 0.506189\tBest loss: 0.506189\tAccuracy: 87.20%\n",
      "200\tValidation loss: 0.505726\tBest loss: 0.505726\tAccuracy: 87.50%\n",
      "201\tValidation loss: 0.506124\tBest loss: 0.505726\tAccuracy: 87.20%\n",
      "202\tValidation loss: 0.502873\tBest loss: 0.502873\tAccuracy: 87.30%\n",
      "203\tValidation loss: 0.504349\tBest loss: 0.502873\tAccuracy: 87.30%\n",
      "204\tValidation loss: 0.502598\tBest loss: 0.502598\tAccuracy: 87.20%\n",
      "205\tValidation loss: 0.502087\tBest loss: 0.502087\tAccuracy: 87.60%\n",
      "206\tValidation loss: 0.504420\tBest loss: 0.502087\tAccuracy: 87.10%\n",
      "207\tValidation loss: 0.500504\tBest loss: 0.500504\tAccuracy: 87.30%\n",
      "208\tValidation loss: 0.500588\tBest loss: 0.500504\tAccuracy: 87.60%\n",
      "209\tValidation loss: 0.501155\tBest loss: 0.500504\tAccuracy: 87.40%\n",
      "210\tValidation loss: 0.501833\tBest loss: 0.500504\tAccuracy: 87.50%\n",
      "211\tValidation loss: 0.499821\tBest loss: 0.499821\tAccuracy: 87.50%\n",
      "212\tValidation loss: 0.498655\tBest loss: 0.498655\tAccuracy: 87.50%\n",
      "213\tValidation loss: 0.499783\tBest loss: 0.498655\tAccuracy: 87.30%\n",
      "214\tValidation loss: 0.498051\tBest loss: 0.498051\tAccuracy: 87.60%\n",
      "215\tValidation loss: 0.498720\tBest loss: 0.498051\tAccuracy: 87.30%\n",
      "216\tValidation loss: 0.498282\tBest loss: 0.498051\tAccuracy: 87.40%\n",
      "217\tValidation loss: 0.495636\tBest loss: 0.495636\tAccuracy: 87.70%\n",
      "218\tValidation loss: 0.497492\tBest loss: 0.495636\tAccuracy: 87.20%\n",
      "219\tValidation loss: 0.496393\tBest loss: 0.495636\tAccuracy: 87.70%\n",
      "220\tValidation loss: 0.493875\tBest loss: 0.493875\tAccuracy: 87.60%\n",
      "221\tValidation loss: 0.496102\tBest loss: 0.493875\tAccuracy: 87.30%\n",
      "222\tValidation loss: 0.495946\tBest loss: 0.493875\tAccuracy: 87.50%\n",
      "223\tValidation loss: 0.493256\tBest loss: 0.493256\tAccuracy: 87.90%\n",
      "224\tValidation loss: 0.492550\tBest loss: 0.492550\tAccuracy: 87.30%\n",
      "225\tValidation loss: 0.494834\tBest loss: 0.492550\tAccuracy: 87.50%\n",
      "226\tValidation loss: 0.491267\tBest loss: 0.491267\tAccuracy: 87.50%\n",
      "227\tValidation loss: 0.490517\tBest loss: 0.490517\tAccuracy: 87.90%\n",
      "228\tValidation loss: 0.490521\tBest loss: 0.490517\tAccuracy: 88.10%\n",
      "229\tValidation loss: 0.491406\tBest loss: 0.490517\tAccuracy: 87.80%\n",
      "230\tValidation loss: 0.489712\tBest loss: 0.489712\tAccuracy: 87.90%\n",
      "231\tValidation loss: 0.490776\tBest loss: 0.489712\tAccuracy: 87.60%\n",
      "232\tValidation loss: 0.489801\tBest loss: 0.489712\tAccuracy: 87.50%\n",
      "233\tValidation loss: 0.488418\tBest loss: 0.488418\tAccuracy: 88.10%\n",
      "234\tValidation loss: 0.487936\tBest loss: 0.487936\tAccuracy: 87.90%\n",
      "235\tValidation loss: 0.489406\tBest loss: 0.487936\tAccuracy: 87.60%\n",
      "236\tValidation loss: 0.486041\tBest loss: 0.486041\tAccuracy: 87.60%\n",
      "237\tValidation loss: 0.486611\tBest loss: 0.486041\tAccuracy: 87.60%\n",
      "238\tValidation loss: 0.488978\tBest loss: 0.486041\tAccuracy: 87.70%\n",
      "239\tValidation loss: 0.489603\tBest loss: 0.486041\tAccuracy: 87.60%\n",
      "240\tValidation loss: 0.486696\tBest loss: 0.486041\tAccuracy: 87.90%\n",
      "241\tValidation loss: 0.486832\tBest loss: 0.486041\tAccuracy: 87.60%\n",
      "242\tValidation loss: 0.487615\tBest loss: 0.486041\tAccuracy: 88.00%\n",
      "243\tValidation loss: 0.484921\tBest loss: 0.484921\tAccuracy: 87.80%\n",
      "244\tValidation loss: 0.484268\tBest loss: 0.484268\tAccuracy: 87.80%\n",
      "245\tValidation loss: 0.482559\tBest loss: 0.482559\tAccuracy: 88.30%\n",
      "246\tValidation loss: 0.484575\tBest loss: 0.482559\tAccuracy: 87.90%\n",
      "247\tValidation loss: 0.483986\tBest loss: 0.482559\tAccuracy: 88.00%\n",
      "248\tValidation loss: 0.483895\tBest loss: 0.482559\tAccuracy: 87.80%\n",
      "249\tValidation loss: 0.482456\tBest loss: 0.482456\tAccuracy: 88.00%\n",
      "250\tValidation loss: 0.483118\tBest loss: 0.482456\tAccuracy: 87.90%\n",
      "251\tValidation loss: 0.480578\tBest loss: 0.480578\tAccuracy: 88.30%\n",
      "252\tValidation loss: 0.483293\tBest loss: 0.480578\tAccuracy: 87.80%\n",
      "253\tValidation loss: 0.481532\tBest loss: 0.480578\tAccuracy: 88.00%\n",
      "254\tValidation loss: 0.481277\tBest loss: 0.480578\tAccuracy: 88.10%\n",
      "255\tValidation loss: 0.481953\tBest loss: 0.480578\tAccuracy: 88.10%\n",
      "256\tValidation loss: 0.480389\tBest loss: 0.480389\tAccuracy: 88.20%\n",
      "257\tValidation loss: 0.482148\tBest loss: 0.480389\tAccuracy: 88.10%\n",
      "258\tValidation loss: 0.479252\tBest loss: 0.479252\tAccuracy: 88.20%\n",
      "259\tValidation loss: 0.478068\tBest loss: 0.478068\tAccuracy: 87.80%\n",
      "260\tValidation loss: 0.479312\tBest loss: 0.478068\tAccuracy: 87.90%\n",
      "261\tValidation loss: 0.478284\tBest loss: 0.478068\tAccuracy: 88.20%\n",
      "262\tValidation loss: 0.476796\tBest loss: 0.476796\tAccuracy: 88.10%\n",
      "263\tValidation loss: 0.477708\tBest loss: 0.476796\tAccuracy: 88.20%\n",
      "264\tValidation loss: 0.478675\tBest loss: 0.476796\tAccuracy: 88.00%\n",
      "265\tValidation loss: 0.477936\tBest loss: 0.476796\tAccuracy: 87.90%\n",
      "266\tValidation loss: 0.476503\tBest loss: 0.476503\tAccuracy: 87.90%\n",
      "267\tValidation loss: 0.477126\tBest loss: 0.476503\tAccuracy: 87.90%\n",
      "268\tValidation loss: 0.476533\tBest loss: 0.476503\tAccuracy: 88.40%\n",
      "269\tValidation loss: 0.475036\tBest loss: 0.475036\tAccuracy: 88.30%\n",
      "270\tValidation loss: 0.474521\tBest loss: 0.474521\tAccuracy: 88.20%\n",
      "271\tValidation loss: 0.473013\tBest loss: 0.473013\tAccuracy: 88.40%\n",
      "272\tValidation loss: 0.474170\tBest loss: 0.473013\tAccuracy: 88.40%\n",
      "273\tValidation loss: 0.473571\tBest loss: 0.473013\tAccuracy: 88.20%\n",
      "274\tValidation loss: 0.474250\tBest loss: 0.473013\tAccuracy: 88.10%\n",
      "275\tValidation loss: 0.472099\tBest loss: 0.472099\tAccuracy: 88.30%\n",
      "276\tValidation loss: 0.471785\tBest loss: 0.471785\tAccuracy: 88.50%\n",
      "277\tValidation loss: 0.474415\tBest loss: 0.471785\tAccuracy: 88.20%\n",
      "278\tValidation loss: 0.470919\tBest loss: 0.470919\tAccuracy: 88.20%\n",
      "279\tValidation loss: 0.472388\tBest loss: 0.470919\tAccuracy: 88.10%\n",
      "280\tValidation loss: 0.470897\tBest loss: 0.470897\tAccuracy: 88.40%\n",
      "281\tValidation loss: 0.471180\tBest loss: 0.470897\tAccuracy: 88.00%\n",
      "282\tValidation loss: 0.472318\tBest loss: 0.470897\tAccuracy: 88.10%\n",
      "283\tValidation loss: 0.472327\tBest loss: 0.470897\tAccuracy: 88.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\tValidation loss: 0.469120\tBest loss: 0.469120\tAccuracy: 88.70%\n",
      "285\tValidation loss: 0.469706\tBest loss: 0.469120\tAccuracy: 88.20%\n",
      "286\tValidation loss: 0.470300\tBest loss: 0.469120\tAccuracy: 88.30%\n",
      "287\tValidation loss: 0.471067\tBest loss: 0.469120\tAccuracy: 88.40%\n",
      "288\tValidation loss: 0.468425\tBest loss: 0.468425\tAccuracy: 88.10%\n",
      "289\tValidation loss: 0.469391\tBest loss: 0.468425\tAccuracy: 88.40%\n",
      "290\tValidation loss: 0.469500\tBest loss: 0.468425\tAccuracy: 88.00%\n",
      "291\tValidation loss: 0.468709\tBest loss: 0.468425\tAccuracy: 88.00%\n",
      "292\tValidation loss: 0.470955\tBest loss: 0.468425\tAccuracy: 88.10%\n",
      "293\tValidation loss: 0.469239\tBest loss: 0.468425\tAccuracy: 88.00%\n",
      "294\tValidation loss: 0.465734\tBest loss: 0.465734\tAccuracy: 88.40%\n",
      "295\tValidation loss: 0.466614\tBest loss: 0.465734\tAccuracy: 88.60%\n",
      "296\tValidation loss: 0.468471\tBest loss: 0.465734\tAccuracy: 88.10%\n",
      "297\tValidation loss: 0.467662\tBest loss: 0.465734\tAccuracy: 88.60%\n",
      "298\tValidation loss: 0.466662\tBest loss: 0.465734\tAccuracy: 88.50%\n",
      "299\tValidation loss: 0.466216\tBest loss: 0.465734\tAccuracy: 88.10%\n",
      "300\tValidation loss: 0.465874\tBest loss: 0.465734\tAccuracy: 88.40%\n",
      "301\tValidation loss: 0.466229\tBest loss: 0.465734\tAccuracy: 88.30%\n",
      "302\tValidation loss: 0.465160\tBest loss: 0.465160\tAccuracy: 88.30%\n",
      "303\tValidation loss: 0.465592\tBest loss: 0.465160\tAccuracy: 88.30%\n",
      "304\tValidation loss: 0.463733\tBest loss: 0.463733\tAccuracy: 88.60%\n",
      "305\tValidation loss: 0.462751\tBest loss: 0.462751\tAccuracy: 88.40%\n",
      "306\tValidation loss: 0.464850\tBest loss: 0.462751\tAccuracy: 88.60%\n",
      "307\tValidation loss: 0.466318\tBest loss: 0.462751\tAccuracy: 88.50%\n",
      "308\tValidation loss: 0.464397\tBest loss: 0.462751\tAccuracy: 88.70%\n",
      "309\tValidation loss: 0.464325\tBest loss: 0.462751\tAccuracy: 88.80%\n",
      "310\tValidation loss: 0.463157\tBest loss: 0.462751\tAccuracy: 88.40%\n",
      "311\tValidation loss: 0.462695\tBest loss: 0.462695\tAccuracy: 88.40%\n",
      "312\tValidation loss: 0.464167\tBest loss: 0.462695\tAccuracy: 88.80%\n",
      "313\tValidation loss: 0.464301\tBest loss: 0.462695\tAccuracy: 88.50%\n",
      "314\tValidation loss: 0.464460\tBest loss: 0.462695\tAccuracy: 88.40%\n",
      "315\tValidation loss: 0.462172\tBest loss: 0.462172\tAccuracy: 88.20%\n",
      "316\tValidation loss: 0.463613\tBest loss: 0.462172\tAccuracy: 88.70%\n",
      "317\tValidation loss: 0.461428\tBest loss: 0.461428\tAccuracy: 88.70%\n",
      "318\tValidation loss: 0.461977\tBest loss: 0.461428\tAccuracy: 88.50%\n",
      "319\tValidation loss: 0.461794\tBest loss: 0.461428\tAccuracy: 88.60%\n",
      "320\tValidation loss: 0.460256\tBest loss: 0.460256\tAccuracy: 88.80%\n",
      "321\tValidation loss: 0.462200\tBest loss: 0.460256\tAccuracy: 88.40%\n",
      "322\tValidation loss: 0.461634\tBest loss: 0.460256\tAccuracy: 88.50%\n",
      "323\tValidation loss: 0.461145\tBest loss: 0.460256\tAccuracy: 88.50%\n",
      "324\tValidation loss: 0.461727\tBest loss: 0.460256\tAccuracy: 88.70%\n",
      "325\tValidation loss: 0.461649\tBest loss: 0.460256\tAccuracy: 88.80%\n",
      "326\tValidation loss: 0.459549\tBest loss: 0.459549\tAccuracy: 88.60%\n",
      "327\tValidation loss: 0.459687\tBest loss: 0.459549\tAccuracy: 88.70%\n",
      "328\tValidation loss: 0.460407\tBest loss: 0.459549\tAccuracy: 88.90%\n",
      "329\tValidation loss: 0.458528\tBest loss: 0.458528\tAccuracy: 88.60%\n",
      "330\tValidation loss: 0.459366\tBest loss: 0.458528\tAccuracy: 88.70%\n",
      "331\tValidation loss: 0.458998\tBest loss: 0.458528\tAccuracy: 89.00%\n",
      "332\tValidation loss: 0.458535\tBest loss: 0.458528\tAccuracy: 89.10%\n",
      "333\tValidation loss: 0.457734\tBest loss: 0.457734\tAccuracy: 88.80%\n",
      "334\tValidation loss: 0.457957\tBest loss: 0.457734\tAccuracy: 88.70%\n",
      "335\tValidation loss: 0.458844\tBest loss: 0.457734\tAccuracy: 88.90%\n",
      "336\tValidation loss: 0.458236\tBest loss: 0.457734\tAccuracy: 88.60%\n",
      "337\tValidation loss: 0.458535\tBest loss: 0.457734\tAccuracy: 88.90%\n",
      "338\tValidation loss: 0.457061\tBest loss: 0.457061\tAccuracy: 88.80%\n",
      "339\tValidation loss: 0.456691\tBest loss: 0.456691\tAccuracy: 89.00%\n",
      "340\tValidation loss: 0.456015\tBest loss: 0.456015\tAccuracy: 88.90%\n",
      "341\tValidation loss: 0.456200\tBest loss: 0.456015\tAccuracy: 88.70%\n",
      "342\tValidation loss: 0.455299\tBest loss: 0.455299\tAccuracy: 89.00%\n",
      "343\tValidation loss: 0.457360\tBest loss: 0.455299\tAccuracy: 88.80%\n",
      "344\tValidation loss: 0.455606\tBest loss: 0.455299\tAccuracy: 88.50%\n",
      "345\tValidation loss: 0.455302\tBest loss: 0.455299\tAccuracy: 89.00%\n",
      "346\tValidation loss: 0.454837\tBest loss: 0.454837\tAccuracy: 88.80%\n",
      "347\tValidation loss: 0.456973\tBest loss: 0.454837\tAccuracy: 88.60%\n",
      "348\tValidation loss: 0.455099\tBest loss: 0.454837\tAccuracy: 88.90%\n",
      "349\tValidation loss: 0.454669\tBest loss: 0.454669\tAccuracy: 89.00%\n",
      "350\tValidation loss: 0.454723\tBest loss: 0.454669\tAccuracy: 89.00%\n",
      "351\tValidation loss: 0.456732\tBest loss: 0.454669\tAccuracy: 88.60%\n",
      "352\tValidation loss: 0.453862\tBest loss: 0.453862\tAccuracy: 89.10%\n",
      "353\tValidation loss: 0.454549\tBest loss: 0.453862\tAccuracy: 88.90%\n",
      "354\tValidation loss: 0.454875\tBest loss: 0.453862\tAccuracy: 88.80%\n",
      "355\tValidation loss: 0.454819\tBest loss: 0.453862\tAccuracy: 89.10%\n",
      "356\tValidation loss: 0.452447\tBest loss: 0.452447\tAccuracy: 88.90%\n",
      "357\tValidation loss: 0.451999\tBest loss: 0.451999\tAccuracy: 88.80%\n",
      "358\tValidation loss: 0.453283\tBest loss: 0.451999\tAccuracy: 88.90%\n",
      "359\tValidation loss: 0.452260\tBest loss: 0.451999\tAccuracy: 89.10%\n",
      "360\tValidation loss: 0.451042\tBest loss: 0.451042\tAccuracy: 88.90%\n",
      "361\tValidation loss: 0.452902\tBest loss: 0.451042\tAccuracy: 89.10%\n",
      "362\tValidation loss: 0.451993\tBest loss: 0.451042\tAccuracy: 89.00%\n",
      "363\tValidation loss: 0.452720\tBest loss: 0.451042\tAccuracy: 89.00%\n",
      "364\tValidation loss: 0.452302\tBest loss: 0.451042\tAccuracy: 89.10%\n",
      "365\tValidation loss: 0.452448\tBest loss: 0.451042\tAccuracy: 88.90%\n",
      "366\tValidation loss: 0.451134\tBest loss: 0.451042\tAccuracy: 89.10%\n",
      "367\tValidation loss: 0.450681\tBest loss: 0.450681\tAccuracy: 88.90%\n",
      "368\tValidation loss: 0.450558\tBest loss: 0.450558\tAccuracy: 89.00%\n",
      "369\tValidation loss: 0.452724\tBest loss: 0.450558\tAccuracy: 88.70%\n",
      "370\tValidation loss: 0.450450\tBest loss: 0.450450\tAccuracy: 89.20%\n",
      "371\tValidation loss: 0.449657\tBest loss: 0.449657\tAccuracy: 89.00%\n",
      "372\tValidation loss: 0.451456\tBest loss: 0.449657\tAccuracy: 89.00%\n",
      "373\tValidation loss: 0.450392\tBest loss: 0.449657\tAccuracy: 88.70%\n",
      "374\tValidation loss: 0.448977\tBest loss: 0.448977\tAccuracy: 89.20%\n",
      "375\tValidation loss: 0.450355\tBest loss: 0.448977\tAccuracy: 88.80%\n",
      "376\tValidation loss: 0.449347\tBest loss: 0.448977\tAccuracy: 89.00%\n",
      "377\tValidation loss: 0.450262\tBest loss: 0.448977\tAccuracy: 89.10%\n",
      "378\tValidation loss: 0.449172\tBest loss: 0.448977\tAccuracy: 88.90%\n",
      "379\tValidation loss: 0.449722\tBest loss: 0.448977\tAccuracy: 89.00%\n",
      "380\tValidation loss: 0.448364\tBest loss: 0.448364\tAccuracy: 89.20%\n",
      "381\tValidation loss: 0.448540\tBest loss: 0.448364\tAccuracy: 88.90%\n",
      "382\tValidation loss: 0.450198\tBest loss: 0.448364\tAccuracy: 89.10%\n",
      "383\tValidation loss: 0.449026\tBest loss: 0.448364\tAccuracy: 89.10%\n",
      "384\tValidation loss: 0.447774\tBest loss: 0.447774\tAccuracy: 89.20%\n",
      "385\tValidation loss: 0.448852\tBest loss: 0.447774\tAccuracy: 89.00%\n",
      "386\tValidation loss: 0.446854\tBest loss: 0.446854\tAccuracy: 89.20%\n",
      "387\tValidation loss: 0.446877\tBest loss: 0.446854\tAccuracy: 89.30%\n",
      "388\tValidation loss: 0.446283\tBest loss: 0.446283\tAccuracy: 89.20%\n",
      "389\tValidation loss: 0.449077\tBest loss: 0.446283\tAccuracy: 88.90%\n",
      "390\tValidation loss: 0.447295\tBest loss: 0.446283\tAccuracy: 89.10%\n",
      "391\tValidation loss: 0.446508\tBest loss: 0.446283\tAccuracy: 89.30%\n",
      "392\tValidation loss: 0.446422\tBest loss: 0.446283\tAccuracy: 89.30%\n",
      "393\tValidation loss: 0.446780\tBest loss: 0.446283\tAccuracy: 88.80%\n",
      "394\tValidation loss: 0.445836\tBest loss: 0.445836\tAccuracy: 89.20%\n",
      "395\tValidation loss: 0.446283\tBest loss: 0.445836\tAccuracy: 89.20%\n",
      "396\tValidation loss: 0.447182\tBest loss: 0.445836\tAccuracy: 89.10%\n",
      "397\tValidation loss: 0.447509\tBest loss: 0.445836\tAccuracy: 89.20%\n",
      "398\tValidation loss: 0.444197\tBest loss: 0.444197\tAccuracy: 89.30%\n",
      "399\tValidation loss: 0.447650\tBest loss: 0.444197\tAccuracy: 89.10%\n",
      "400\tValidation loss: 0.446857\tBest loss: 0.444197\tAccuracy: 89.40%\n",
      "401\tValidation loss: 0.444920\tBest loss: 0.444197\tAccuracy: 89.50%\n",
      "402\tValidation loss: 0.444114\tBest loss: 0.444114\tAccuracy: 89.30%\n",
      "403\tValidation loss: 0.443395\tBest loss: 0.443395\tAccuracy: 89.60%\n",
      "404\tValidation loss: 0.443839\tBest loss: 0.443395\tAccuracy: 89.20%\n",
      "405\tValidation loss: 0.444771\tBest loss: 0.443395\tAccuracy: 89.60%\n",
      "406\tValidation loss: 0.443745\tBest loss: 0.443395\tAccuracy: 89.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\tValidation loss: 0.445380\tBest loss: 0.443395\tAccuracy: 89.30%\n",
      "408\tValidation loss: 0.444765\tBest loss: 0.443395\tAccuracy: 89.10%\n",
      "409\tValidation loss: 0.442847\tBest loss: 0.442847\tAccuracy: 89.30%\n",
      "410\tValidation loss: 0.444619\tBest loss: 0.442847\tAccuracy: 89.20%\n",
      "411\tValidation loss: 0.443728\tBest loss: 0.442847\tAccuracy: 89.20%\n",
      "412\tValidation loss: 0.444242\tBest loss: 0.442847\tAccuracy: 89.40%\n",
      "413\tValidation loss: 0.444048\tBest loss: 0.442847\tAccuracy: 89.40%\n",
      "414\tValidation loss: 0.442381\tBest loss: 0.442381\tAccuracy: 89.30%\n",
      "415\tValidation loss: 0.443381\tBest loss: 0.442381\tAccuracy: 89.10%\n",
      "416\tValidation loss: 0.442851\tBest loss: 0.442381\tAccuracy: 89.30%\n",
      "417\tValidation loss: 0.442591\tBest loss: 0.442381\tAccuracy: 89.60%\n",
      "418\tValidation loss: 0.442789\tBest loss: 0.442381\tAccuracy: 89.30%\n",
      "419\tValidation loss: 0.441130\tBest loss: 0.441130\tAccuracy: 89.40%\n",
      "420\tValidation loss: 0.443940\tBest loss: 0.441130\tAccuracy: 89.40%\n",
      "421\tValidation loss: 0.442507\tBest loss: 0.441130\tAccuracy: 89.40%\n",
      "422\tValidation loss: 0.441427\tBest loss: 0.441130\tAccuracy: 89.30%\n",
      "423\tValidation loss: 0.442815\tBest loss: 0.441130\tAccuracy: 89.60%\n",
      "424\tValidation loss: 0.440822\tBest loss: 0.440822\tAccuracy: 90.00%\n",
      "425\tValidation loss: 0.443401\tBest loss: 0.440822\tAccuracy: 89.50%\n",
      "426\tValidation loss: 0.441717\tBest loss: 0.440822\tAccuracy: 89.60%\n",
      "427\tValidation loss: 0.441798\tBest loss: 0.440822\tAccuracy: 89.50%\n",
      "428\tValidation loss: 0.441128\tBest loss: 0.440822\tAccuracy: 89.70%\n",
      "429\tValidation loss: 0.441230\tBest loss: 0.440822\tAccuracy: 89.40%\n",
      "430\tValidation loss: 0.441257\tBest loss: 0.440822\tAccuracy: 89.30%\n",
      "431\tValidation loss: 0.442297\tBest loss: 0.440822\tAccuracy: 89.50%\n",
      "432\tValidation loss: 0.440513\tBest loss: 0.440513\tAccuracy: 89.60%\n",
      "433\tValidation loss: 0.440931\tBest loss: 0.440513\tAccuracy: 89.50%\n",
      "434\tValidation loss: 0.440614\tBest loss: 0.440513\tAccuracy: 89.10%\n",
      "435\tValidation loss: 0.441433\tBest loss: 0.440513\tAccuracy: 89.60%\n",
      "436\tValidation loss: 0.440099\tBest loss: 0.440099\tAccuracy: 89.90%\n",
      "437\tValidation loss: 0.440403\tBest loss: 0.440099\tAccuracy: 89.60%\n",
      "438\tValidation loss: 0.438523\tBest loss: 0.438523\tAccuracy: 89.70%\n",
      "439\tValidation loss: 0.439928\tBest loss: 0.438523\tAccuracy: 89.70%\n",
      "440\tValidation loss: 0.439317\tBest loss: 0.438523\tAccuracy: 89.70%\n",
      "441\tValidation loss: 0.439188\tBest loss: 0.438523\tAccuracy: 89.80%\n",
      "442\tValidation loss: 0.439488\tBest loss: 0.438523\tAccuracy: 89.50%\n",
      "443\tValidation loss: 0.439057\tBest loss: 0.438523\tAccuracy: 89.50%\n",
      "444\tValidation loss: 0.438223\tBest loss: 0.438223\tAccuracy: 89.70%\n",
      "445\tValidation loss: 0.440007\tBest loss: 0.438223\tAccuracy: 89.50%\n",
      "446\tValidation loss: 0.438935\tBest loss: 0.438223\tAccuracy: 89.70%\n",
      "447\tValidation loss: 0.438387\tBest loss: 0.438223\tAccuracy: 89.70%\n",
      "448\tValidation loss: 0.438633\tBest loss: 0.438223\tAccuracy: 89.60%\n",
      "449\tValidation loss: 0.437405\tBest loss: 0.437405\tAccuracy: 89.60%\n",
      "450\tValidation loss: 0.438255\tBest loss: 0.437405\tAccuracy: 90.00%\n",
      "451\tValidation loss: 0.439131\tBest loss: 0.437405\tAccuracy: 89.70%\n",
      "452\tValidation loss: 0.438607\tBest loss: 0.437405\tAccuracy: 89.70%\n",
      "453\tValidation loss: 0.438516\tBest loss: 0.437405\tAccuracy: 89.60%\n",
      "454\tValidation loss: 0.437634\tBest loss: 0.437405\tAccuracy: 89.80%\n",
      "455\tValidation loss: 0.438693\tBest loss: 0.437405\tAccuracy: 89.90%\n",
      "456\tValidation loss: 0.436350\tBest loss: 0.436350\tAccuracy: 89.90%\n",
      "457\tValidation loss: 0.436463\tBest loss: 0.436350\tAccuracy: 89.90%\n",
      "458\tValidation loss: 0.437086\tBest loss: 0.436350\tAccuracy: 89.70%\n",
      "459\tValidation loss: 0.437489\tBest loss: 0.436350\tAccuracy: 89.80%\n",
      "460\tValidation loss: 0.436647\tBest loss: 0.436350\tAccuracy: 89.70%\n",
      "461\tValidation loss: 0.437691\tBest loss: 0.436350\tAccuracy: 90.00%\n",
      "462\tValidation loss: 0.436686\tBest loss: 0.436350\tAccuracy: 90.10%\n",
      "463\tValidation loss: 0.436122\tBest loss: 0.436122\tAccuracy: 89.80%\n",
      "464\tValidation loss: 0.435777\tBest loss: 0.435777\tAccuracy: 89.90%\n",
      "465\tValidation loss: 0.437162\tBest loss: 0.435777\tAccuracy: 89.80%\n",
      "466\tValidation loss: 0.436114\tBest loss: 0.435777\tAccuracy: 89.80%\n",
      "467\tValidation loss: 0.435765\tBest loss: 0.435765\tAccuracy: 90.00%\n",
      "468\tValidation loss: 0.437819\tBest loss: 0.435765\tAccuracy: 89.80%\n",
      "469\tValidation loss: 0.436331\tBest loss: 0.435765\tAccuracy: 89.90%\n",
      "470\tValidation loss: 0.435822\tBest loss: 0.435765\tAccuracy: 90.00%\n",
      "471\tValidation loss: 0.437000\tBest loss: 0.435765\tAccuracy: 89.70%\n",
      "472\tValidation loss: 0.435476\tBest loss: 0.435476\tAccuracy: 89.80%\n",
      "473\tValidation loss: 0.436667\tBest loss: 0.435476\tAccuracy: 89.40%\n",
      "474\tValidation loss: 0.435815\tBest loss: 0.435476\tAccuracy: 89.80%\n",
      "475\tValidation loss: 0.435422\tBest loss: 0.435422\tAccuracy: 89.80%\n",
      "476\tValidation loss: 0.435747\tBest loss: 0.435422\tAccuracy: 90.00%\n",
      "477\tValidation loss: 0.434669\tBest loss: 0.434669\tAccuracy: 89.80%\n",
      "478\tValidation loss: 0.434605\tBest loss: 0.434605\tAccuracy: 90.10%\n",
      "479\tValidation loss: 0.434754\tBest loss: 0.434605\tAccuracy: 90.00%\n",
      "480\tValidation loss: 0.435629\tBest loss: 0.434605\tAccuracy: 89.80%\n",
      "481\tValidation loss: 0.435156\tBest loss: 0.434605\tAccuracy: 90.10%\n",
      "482\tValidation loss: 0.433872\tBest loss: 0.433872\tAccuracy: 90.00%\n",
      "483\tValidation loss: 0.433638\tBest loss: 0.433638\tAccuracy: 90.10%\n",
      "484\tValidation loss: 0.434429\tBest loss: 0.433638\tAccuracy: 90.20%\n",
      "485\tValidation loss: 0.433153\tBest loss: 0.433153\tAccuracy: 90.10%\n",
      "486\tValidation loss: 0.434340\tBest loss: 0.433153\tAccuracy: 90.10%\n",
      "487\tValidation loss: 0.433916\tBest loss: 0.433153\tAccuracy: 90.00%\n",
      "488\tValidation loss: 0.434937\tBest loss: 0.433153\tAccuracy: 90.00%\n",
      "489\tValidation loss: 0.433196\tBest loss: 0.433153\tAccuracy: 90.00%\n",
      "490\tValidation loss: 0.432136\tBest loss: 0.432136\tAccuracy: 90.00%\n",
      "491\tValidation loss: 0.433462\tBest loss: 0.432136\tAccuracy: 89.80%\n",
      "492\tValidation loss: 0.433258\tBest loss: 0.432136\tAccuracy: 89.80%\n",
      "493\tValidation loss: 0.433262\tBest loss: 0.432136\tAccuracy: 90.00%\n",
      "494\tValidation loss: 0.433735\tBest loss: 0.432136\tAccuracy: 89.90%\n",
      "495\tValidation loss: 0.433091\tBest loss: 0.432136\tAccuracy: 90.20%\n",
      "496\tValidation loss: 0.431413\tBest loss: 0.431413\tAccuracy: 90.00%\n",
      "497\tValidation loss: 0.432156\tBest loss: 0.431413\tAccuracy: 90.20%\n",
      "498\tValidation loss: 0.431894\tBest loss: 0.431413\tAccuracy: 90.20%\n",
      "499\tValidation loss: 0.430923\tBest loss: 0.430923\tAccuracy: 90.20%\n",
      "500\tValidation loss: 0.433058\tBest loss: 0.430923\tAccuracy: 89.90%\n",
      "501\tValidation loss: 0.432519\tBest loss: 0.430923\tAccuracy: 89.90%\n",
      "502\tValidation loss: 0.431305\tBest loss: 0.430923\tAccuracy: 89.90%\n",
      "503\tValidation loss: 0.432009\tBest loss: 0.430923\tAccuracy: 89.90%\n",
      "504\tValidation loss: 0.432104\tBest loss: 0.430923\tAccuracy: 90.10%\n",
      "505\tValidation loss: 0.431695\tBest loss: 0.430923\tAccuracy: 89.90%\n",
      "506\tValidation loss: 0.430638\tBest loss: 0.430638\tAccuracy: 90.20%\n",
      "507\tValidation loss: 0.431477\tBest loss: 0.430638\tAccuracy: 90.00%\n",
      "508\tValidation loss: 0.431887\tBest loss: 0.430638\tAccuracy: 90.20%\n",
      "509\tValidation loss: 0.431356\tBest loss: 0.430638\tAccuracy: 89.90%\n",
      "510\tValidation loss: 0.433314\tBest loss: 0.430638\tAccuracy: 90.00%\n",
      "511\tValidation loss: 0.430667\tBest loss: 0.430638\tAccuracy: 90.20%\n",
      "512\tValidation loss: 0.431105\tBest loss: 0.430638\tAccuracy: 90.00%\n",
      "513\tValidation loss: 0.431018\tBest loss: 0.430638\tAccuracy: 90.00%\n",
      "514\tValidation loss: 0.431128\tBest loss: 0.430638\tAccuracy: 90.20%\n",
      "515\tValidation loss: 0.430386\tBest loss: 0.430386\tAccuracy: 90.10%\n",
      "516\tValidation loss: 0.430868\tBest loss: 0.430386\tAccuracy: 90.10%\n",
      "517\tValidation loss: 0.431677\tBest loss: 0.430386\tAccuracy: 90.20%\n",
      "518\tValidation loss: 0.432106\tBest loss: 0.430386\tAccuracy: 90.20%\n",
      "519\tValidation loss: 0.431355\tBest loss: 0.430386\tAccuracy: 90.10%\n",
      "520\tValidation loss: 0.431255\tBest loss: 0.430386\tAccuracy: 90.20%\n",
      "521\tValidation loss: 0.429664\tBest loss: 0.429664\tAccuracy: 90.10%\n",
      "522\tValidation loss: 0.430295\tBest loss: 0.429664\tAccuracy: 90.00%\n",
      "523\tValidation loss: 0.430008\tBest loss: 0.429664\tAccuracy: 90.00%\n",
      "524\tValidation loss: 0.429766\tBest loss: 0.429664\tAccuracy: 90.00%\n",
      "525\tValidation loss: 0.429920\tBest loss: 0.429664\tAccuracy: 90.20%\n",
      "526\tValidation loss: 0.430192\tBest loss: 0.429664\tAccuracy: 90.10%\n",
      "527\tValidation loss: 0.430277\tBest loss: 0.429664\tAccuracy: 90.10%\n",
      "528\tValidation loss: 0.429195\tBest loss: 0.429195\tAccuracy: 90.30%\n",
      "529\tValidation loss: 0.429936\tBest loss: 0.429195\tAccuracy: 90.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\tValidation loss: 0.429677\tBest loss: 0.429195\tAccuracy: 90.30%\n",
      "531\tValidation loss: 0.429322\tBest loss: 0.429195\tAccuracy: 90.20%\n",
      "532\tValidation loss: 0.429879\tBest loss: 0.429195\tAccuracy: 90.20%\n",
      "533\tValidation loss: 0.428484\tBest loss: 0.428484\tAccuracy: 90.10%\n",
      "534\tValidation loss: 0.429011\tBest loss: 0.428484\tAccuracy: 90.20%\n",
      "535\tValidation loss: 0.428996\tBest loss: 0.428484\tAccuracy: 90.20%\n",
      "536\tValidation loss: 0.427788\tBest loss: 0.427788\tAccuracy: 90.20%\n",
      "537\tValidation loss: 0.429318\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "538\tValidation loss: 0.429952\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "539\tValidation loss: 0.430006\tBest loss: 0.427788\tAccuracy: 90.20%\n",
      "540\tValidation loss: 0.428236\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "541\tValidation loss: 0.428269\tBest loss: 0.427788\tAccuracy: 90.20%\n",
      "542\tValidation loss: 0.428369\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "543\tValidation loss: 0.428560\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "544\tValidation loss: 0.428439\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "545\tValidation loss: 0.428326\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "546\tValidation loss: 0.428215\tBest loss: 0.427788\tAccuracy: 90.10%\n",
      "547\tValidation loss: 0.427731\tBest loss: 0.427731\tAccuracy: 90.30%\n",
      "548\tValidation loss: 0.426625\tBest loss: 0.426625\tAccuracy: 90.20%\n",
      "549\tValidation loss: 0.427270\tBest loss: 0.426625\tAccuracy: 90.30%\n",
      "550\tValidation loss: 0.427819\tBest loss: 0.426625\tAccuracy: 90.30%\n",
      "551\tValidation loss: 0.429669\tBest loss: 0.426625\tAccuracy: 90.40%\n",
      "552\tValidation loss: 0.427529\tBest loss: 0.426625\tAccuracy: 90.30%\n",
      "553\tValidation loss: 0.427573\tBest loss: 0.426625\tAccuracy: 90.40%\n",
      "554\tValidation loss: 0.427452\tBest loss: 0.426625\tAccuracy: 90.30%\n",
      "555\tValidation loss: 0.426376\tBest loss: 0.426376\tAccuracy: 90.20%\n",
      "556\tValidation loss: 0.427331\tBest loss: 0.426376\tAccuracy: 90.40%\n",
      "557\tValidation loss: 0.426248\tBest loss: 0.426248\tAccuracy: 90.30%\n",
      "558\tValidation loss: 0.427257\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "559\tValidation loss: 0.426624\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "560\tValidation loss: 0.427207\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "561\tValidation loss: 0.426422\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "562\tValidation loss: 0.426792\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "563\tValidation loss: 0.426701\tBest loss: 0.426248\tAccuracy: 90.40%\n",
      "564\tValidation loss: 0.425771\tBest loss: 0.425771\tAccuracy: 90.40%\n",
      "565\tValidation loss: 0.425306\tBest loss: 0.425306\tAccuracy: 90.40%\n",
      "566\tValidation loss: 0.426735\tBest loss: 0.425306\tAccuracy: 90.50%\n",
      "567\tValidation loss: 0.426020\tBest loss: 0.425306\tAccuracy: 90.40%\n",
      "568\tValidation loss: 0.424811\tBest loss: 0.424811\tAccuracy: 90.40%\n",
      "569\tValidation loss: 0.426507\tBest loss: 0.424811\tAccuracy: 90.30%\n",
      "570\tValidation loss: 0.427392\tBest loss: 0.424811\tAccuracy: 90.40%\n",
      "571\tValidation loss: 0.425731\tBest loss: 0.424811\tAccuracy: 90.30%\n",
      "572\tValidation loss: 0.426130\tBest loss: 0.424811\tAccuracy: 90.40%\n",
      "573\tValidation loss: 0.425839\tBest loss: 0.424811\tAccuracy: 90.30%\n",
      "574\tValidation loss: 0.425411\tBest loss: 0.424811\tAccuracy: 90.40%\n",
      "575\tValidation loss: 0.426716\tBest loss: 0.424811\tAccuracy: 90.30%\n",
      "576\tValidation loss: 0.427201\tBest loss: 0.424811\tAccuracy: 90.60%\n",
      "577\tValidation loss: 0.425731\tBest loss: 0.424811\tAccuracy: 90.40%\n",
      "578\tValidation loss: 0.426556\tBest loss: 0.424811\tAccuracy: 90.50%\n",
      "579\tValidation loss: 0.424762\tBest loss: 0.424762\tAccuracy: 90.40%\n",
      "580\tValidation loss: 0.424853\tBest loss: 0.424762\tAccuracy: 90.50%\n",
      "581\tValidation loss: 0.425488\tBest loss: 0.424762\tAccuracy: 90.30%\n",
      "582\tValidation loss: 0.425123\tBest loss: 0.424762\tAccuracy: 90.40%\n",
      "583\tValidation loss: 0.425405\tBest loss: 0.424762\tAccuracy: 90.50%\n",
      "584\tValidation loss: 0.425686\tBest loss: 0.424762\tAccuracy: 90.50%\n",
      "585\tValidation loss: 0.425974\tBest loss: 0.424762\tAccuracy: 90.50%\n",
      "586\tValidation loss: 0.425056\tBest loss: 0.424762\tAccuracy: 90.40%\n",
      "587\tValidation loss: 0.424943\tBest loss: 0.424762\tAccuracy: 90.40%\n",
      "588\tValidation loss: 0.425235\tBest loss: 0.424762\tAccuracy: 90.60%\n",
      "589\tValidation loss: 0.425046\tBest loss: 0.424762\tAccuracy: 90.50%\n",
      "590\tValidation loss: 0.424230\tBest loss: 0.424230\tAccuracy: 90.60%\n",
      "591\tValidation loss: 0.424969\tBest loss: 0.424230\tAccuracy: 90.50%\n",
      "592\tValidation loss: 0.423027\tBest loss: 0.423027\tAccuracy: 90.70%\n",
      "593\tValidation loss: 0.425473\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "594\tValidation loss: 0.425087\tBest loss: 0.423027\tAccuracy: 90.40%\n",
      "595\tValidation loss: 0.423900\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "596\tValidation loss: 0.423048\tBest loss: 0.423027\tAccuracy: 90.50%\n",
      "597\tValidation loss: 0.424048\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "598\tValidation loss: 0.424235\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "599\tValidation loss: 0.423492\tBest loss: 0.423027\tAccuracy: 90.50%\n",
      "600\tValidation loss: 0.424810\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "601\tValidation loss: 0.423085\tBest loss: 0.423027\tAccuracy: 90.50%\n",
      "602\tValidation loss: 0.423749\tBest loss: 0.423027\tAccuracy: 90.40%\n",
      "603\tValidation loss: 0.423816\tBest loss: 0.423027\tAccuracy: 90.40%\n",
      "604\tValidation loss: 0.423371\tBest loss: 0.423027\tAccuracy: 90.50%\n",
      "605\tValidation loss: 0.424157\tBest loss: 0.423027\tAccuracy: 90.50%\n",
      "606\tValidation loss: 0.424060\tBest loss: 0.423027\tAccuracy: 90.70%\n",
      "607\tValidation loss: 0.423534\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "608\tValidation loss: 0.424704\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "609\tValidation loss: 0.423493\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "610\tValidation loss: 0.425103\tBest loss: 0.423027\tAccuracy: 90.60%\n",
      "611\tValidation loss: 0.423178\tBest loss: 0.423027\tAccuracy: 90.40%\n",
      "612\tValidation loss: 0.422397\tBest loss: 0.422397\tAccuracy: 90.60%\n",
      "613\tValidation loss: 0.423059\tBest loss: 0.422397\tAccuracy: 90.60%\n",
      "614\tValidation loss: 0.422781\tBest loss: 0.422397\tAccuracy: 90.60%\n",
      "615\tValidation loss: 0.423565\tBest loss: 0.422397\tAccuracy: 90.50%\n",
      "616\tValidation loss: 0.422785\tBest loss: 0.422397\tAccuracy: 90.60%\n",
      "617\tValidation loss: 0.422316\tBest loss: 0.422316\tAccuracy: 90.40%\n",
      "618\tValidation loss: 0.423617\tBest loss: 0.422316\tAccuracy: 90.60%\n",
      "619\tValidation loss: 0.422654\tBest loss: 0.422316\tAccuracy: 90.60%\n",
      "620\tValidation loss: 0.422696\tBest loss: 0.422316\tAccuracy: 90.80%\n",
      "621\tValidation loss: 0.423037\tBest loss: 0.422316\tAccuracy: 90.50%\n",
      "622\tValidation loss: 0.423357\tBest loss: 0.422316\tAccuracy: 90.60%\n",
      "623\tValidation loss: 0.423546\tBest loss: 0.422316\tAccuracy: 90.70%\n",
      "624\tValidation loss: 0.422514\tBest loss: 0.422316\tAccuracy: 90.70%\n",
      "625\tValidation loss: 0.422438\tBest loss: 0.422316\tAccuracy: 90.60%\n",
      "626\tValidation loss: 0.422202\tBest loss: 0.422202\tAccuracy: 90.80%\n",
      "627\tValidation loss: 0.422980\tBest loss: 0.422202\tAccuracy: 90.90%\n",
      "628\tValidation loss: 0.421992\tBest loss: 0.421992\tAccuracy: 90.60%\n",
      "629\tValidation loss: 0.421101\tBest loss: 0.421101\tAccuracy: 90.50%\n",
      "630\tValidation loss: 0.421272\tBest loss: 0.421101\tAccuracy: 90.70%\n",
      "631\tValidation loss: 0.422334\tBest loss: 0.421101\tAccuracy: 90.80%\n",
      "632\tValidation loss: 0.422325\tBest loss: 0.421101\tAccuracy: 90.80%\n",
      "633\tValidation loss: 0.422135\tBest loss: 0.421101\tAccuracy: 90.90%\n",
      "634\tValidation loss: 0.421535\tBest loss: 0.421101\tAccuracy: 90.70%\n",
      "635\tValidation loss: 0.422490\tBest loss: 0.421101\tAccuracy: 90.80%\n",
      "636\tValidation loss: 0.421615\tBest loss: 0.421101\tAccuracy: 90.70%\n",
      "637\tValidation loss: 0.422105\tBest loss: 0.421101\tAccuracy: 90.80%\n",
      "638\tValidation loss: 0.422514\tBest loss: 0.421101\tAccuracy: 90.90%\n",
      "639\tValidation loss: 0.421125\tBest loss: 0.421101\tAccuracy: 90.90%\n",
      "640\tValidation loss: 0.421610\tBest loss: 0.421101\tAccuracy: 90.60%\n",
      "641\tValidation loss: 0.420917\tBest loss: 0.420917\tAccuracy: 90.60%\n",
      "642\tValidation loss: 0.421335\tBest loss: 0.420917\tAccuracy: 90.80%\n",
      "643\tValidation loss: 0.422308\tBest loss: 0.420917\tAccuracy: 91.00%\n",
      "644\tValidation loss: 0.421336\tBest loss: 0.420917\tAccuracy: 90.90%\n",
      "645\tValidation loss: 0.421055\tBest loss: 0.420917\tAccuracy: 91.10%\n",
      "646\tValidation loss: 0.421256\tBest loss: 0.420917\tAccuracy: 91.00%\n",
      "647\tValidation loss: 0.421624\tBest loss: 0.420917\tAccuracy: 91.00%\n",
      "648\tValidation loss: 0.420358\tBest loss: 0.420358\tAccuracy: 90.90%\n",
      "649\tValidation loss: 0.420880\tBest loss: 0.420358\tAccuracy: 91.00%\n",
      "650\tValidation loss: 0.421321\tBest loss: 0.420358\tAccuracy: 90.90%\n",
      "651\tValidation loss: 0.421246\tBest loss: 0.420358\tAccuracy: 90.90%\n",
      "652\tValidation loss: 0.420386\tBest loss: 0.420358\tAccuracy: 91.10%\n",
      "653\tValidation loss: 0.421148\tBest loss: 0.420358\tAccuracy: 91.00%\n",
      "654\tValidation loss: 0.422691\tBest loss: 0.420358\tAccuracy: 91.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655\tValidation loss: 0.421048\tBest loss: 0.420358\tAccuracy: 91.10%\n",
      "656\tValidation loss: 0.421397\tBest loss: 0.420358\tAccuracy: 91.30%\n",
      "657\tValidation loss: 0.421894\tBest loss: 0.420358\tAccuracy: 91.00%\n",
      "658\tValidation loss: 0.420498\tBest loss: 0.420358\tAccuracy: 90.90%\n",
      "659\tValidation loss: 0.421449\tBest loss: 0.420358\tAccuracy: 91.00%\n",
      "660\tValidation loss: 0.421798\tBest loss: 0.420358\tAccuracy: 91.20%\n",
      "661\tValidation loss: 0.420291\tBest loss: 0.420291\tAccuracy: 90.90%\n",
      "662\tValidation loss: 0.421594\tBest loss: 0.420291\tAccuracy: 91.10%\n",
      "663\tValidation loss: 0.420460\tBest loss: 0.420291\tAccuracy: 91.20%\n",
      "664\tValidation loss: 0.421068\tBest loss: 0.420291\tAccuracy: 91.20%\n",
      "665\tValidation loss: 0.420899\tBest loss: 0.420291\tAccuracy: 91.20%\n",
      "666\tValidation loss: 0.420312\tBest loss: 0.420291\tAccuracy: 91.00%\n",
      "667\tValidation loss: 0.420460\tBest loss: 0.420291\tAccuracy: 91.10%\n",
      "668\tValidation loss: 0.420998\tBest loss: 0.420291\tAccuracy: 91.20%\n",
      "669\tValidation loss: 0.420141\tBest loss: 0.420141\tAccuracy: 91.20%\n",
      "670\tValidation loss: 0.420528\tBest loss: 0.420141\tAccuracy: 91.10%\n",
      "671\tValidation loss: 0.421006\tBest loss: 0.420141\tAccuracy: 91.00%\n",
      "672\tValidation loss: 0.420242\tBest loss: 0.420141\tAccuracy: 91.20%\n",
      "673\tValidation loss: 0.419533\tBest loss: 0.419533\tAccuracy: 91.20%\n",
      "674\tValidation loss: 0.420628\tBest loss: 0.419533\tAccuracy: 91.20%\n",
      "675\tValidation loss: 0.419900\tBest loss: 0.419533\tAccuracy: 91.20%\n",
      "676\tValidation loss: 0.420664\tBest loss: 0.419533\tAccuracy: 91.10%\n",
      "677\tValidation loss: 0.419531\tBest loss: 0.419531\tAccuracy: 91.30%\n",
      "678\tValidation loss: 0.420400\tBest loss: 0.419531\tAccuracy: 91.20%\n",
      "679\tValidation loss: 0.418900\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "680\tValidation loss: 0.420696\tBest loss: 0.418900\tAccuracy: 91.30%\n",
      "681\tValidation loss: 0.419968\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "682\tValidation loss: 0.419563\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "683\tValidation loss: 0.419134\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "684\tValidation loss: 0.420266\tBest loss: 0.418900\tAccuracy: 91.10%\n",
      "685\tValidation loss: 0.419995\tBest loss: 0.418900\tAccuracy: 91.10%\n",
      "686\tValidation loss: 0.420333\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "687\tValidation loss: 0.419302\tBest loss: 0.418900\tAccuracy: 91.10%\n",
      "688\tValidation loss: 0.419842\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "689\tValidation loss: 0.419342\tBest loss: 0.418900\tAccuracy: 91.30%\n",
      "690\tValidation loss: 0.419238\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "691\tValidation loss: 0.420316\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "692\tValidation loss: 0.420169\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "693\tValidation loss: 0.420716\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "694\tValidation loss: 0.419845\tBest loss: 0.418900\tAccuracy: 91.30%\n",
      "695\tValidation loss: 0.419383\tBest loss: 0.418900\tAccuracy: 91.40%\n",
      "696\tValidation loss: 0.419004\tBest loss: 0.418900\tAccuracy: 91.20%\n",
      "697\tValidation loss: 0.419134\tBest loss: 0.418900\tAccuracy: 91.30%\n",
      "698\tValidation loss: 0.419123\tBest loss: 0.418900\tAccuracy: 91.40%\n",
      "699\tValidation loss: 0.418838\tBest loss: 0.418838\tAccuracy: 91.40%\n",
      "700\tValidation loss: 0.419696\tBest loss: 0.418838\tAccuracy: 91.10%\n",
      "701\tValidation loss: 0.418638\tBest loss: 0.418638\tAccuracy: 91.20%\n",
      "702\tValidation loss: 0.418429\tBest loss: 0.418429\tAccuracy: 91.30%\n",
      "703\tValidation loss: 0.419366\tBest loss: 0.418429\tAccuracy: 91.30%\n",
      "704\tValidation loss: 0.419001\tBest loss: 0.418429\tAccuracy: 91.30%\n",
      "705\tValidation loss: 0.418085\tBest loss: 0.418085\tAccuracy: 91.40%\n",
      "706\tValidation loss: 0.418647\tBest loss: 0.418085\tAccuracy: 91.20%\n",
      "707\tValidation loss: 0.418638\tBest loss: 0.418085\tAccuracy: 91.30%\n",
      "708\tValidation loss: 0.419233\tBest loss: 0.418085\tAccuracy: 91.10%\n",
      "709\tValidation loss: 0.419559\tBest loss: 0.418085\tAccuracy: 91.10%\n",
      "710\tValidation loss: 0.419049\tBest loss: 0.418085\tAccuracy: 91.30%\n",
      "711\tValidation loss: 0.419030\tBest loss: 0.418085\tAccuracy: 91.30%\n",
      "712\tValidation loss: 0.418536\tBest loss: 0.418085\tAccuracy: 91.40%\n",
      "713\tValidation loss: 0.418364\tBest loss: 0.418085\tAccuracy: 91.30%\n",
      "714\tValidation loss: 0.418608\tBest loss: 0.418085\tAccuracy: 91.40%\n",
      "715\tValidation loss: 0.417615\tBest loss: 0.417615\tAccuracy: 91.30%\n",
      "716\tValidation loss: 0.418978\tBest loss: 0.417615\tAccuracy: 91.20%\n",
      "717\tValidation loss: 0.418249\tBest loss: 0.417615\tAccuracy: 91.10%\n",
      "718\tValidation loss: 0.418877\tBest loss: 0.417615\tAccuracy: 91.40%\n",
      "719\tValidation loss: 0.418899\tBest loss: 0.417615\tAccuracy: 91.40%\n",
      "720\tValidation loss: 0.417248\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "721\tValidation loss: 0.417827\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "722\tValidation loss: 0.418552\tBest loss: 0.417248\tAccuracy: 91.50%\n",
      "723\tValidation loss: 0.417738\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "724\tValidation loss: 0.418857\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "725\tValidation loss: 0.418679\tBest loss: 0.417248\tAccuracy: 91.10%\n",
      "726\tValidation loss: 0.418541\tBest loss: 0.417248\tAccuracy: 91.50%\n",
      "727\tValidation loss: 0.419389\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "728\tValidation loss: 0.419426\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "729\tValidation loss: 0.417938\tBest loss: 0.417248\tAccuracy: 91.30%\n",
      "730\tValidation loss: 0.417292\tBest loss: 0.417248\tAccuracy: 91.50%\n",
      "731\tValidation loss: 0.416992\tBest loss: 0.416992\tAccuracy: 91.30%\n",
      "732\tValidation loss: 0.419171\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "733\tValidation loss: 0.418497\tBest loss: 0.416992\tAccuracy: 91.40%\n",
      "734\tValidation loss: 0.419167\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "735\tValidation loss: 0.418557\tBest loss: 0.416992\tAccuracy: 91.40%\n",
      "736\tValidation loss: 0.418020\tBest loss: 0.416992\tAccuracy: 91.40%\n",
      "737\tValidation loss: 0.418334\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "738\tValidation loss: 0.418128\tBest loss: 0.416992\tAccuracy: 91.40%\n",
      "739\tValidation loss: 0.419136\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "740\tValidation loss: 0.417994\tBest loss: 0.416992\tAccuracy: 91.30%\n",
      "741\tValidation loss: 0.417581\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "742\tValidation loss: 0.417805\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "743\tValidation loss: 0.417133\tBest loss: 0.416992\tAccuracy: 91.50%\n",
      "744\tValidation loss: 0.418436\tBest loss: 0.416992\tAccuracy: 91.40%\n",
      "745\tValidation loss: 0.416319\tBest loss: 0.416319\tAccuracy: 91.40%\n",
      "746\tValidation loss: 0.416794\tBest loss: 0.416319\tAccuracy: 91.40%\n",
      "747\tValidation loss: 0.417804\tBest loss: 0.416319\tAccuracy: 91.30%\n",
      "748\tValidation loss: 0.418288\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "749\tValidation loss: 0.417291\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "750\tValidation loss: 0.417382\tBest loss: 0.416319\tAccuracy: 91.60%\n",
      "751\tValidation loss: 0.418815\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "752\tValidation loss: 0.418459\tBest loss: 0.416319\tAccuracy: 91.40%\n",
      "753\tValidation loss: 0.416888\tBest loss: 0.416319\tAccuracy: 91.60%\n",
      "754\tValidation loss: 0.417736\tBest loss: 0.416319\tAccuracy: 91.60%\n",
      "755\tValidation loss: 0.418135\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "756\tValidation loss: 0.418966\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "757\tValidation loss: 0.418103\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "758\tValidation loss: 0.417787\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "759\tValidation loss: 0.417674\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "760\tValidation loss: 0.417479\tBest loss: 0.416319\tAccuracy: 91.30%\n",
      "761\tValidation loss: 0.417077\tBest loss: 0.416319\tAccuracy: 91.40%\n",
      "762\tValidation loss: 0.418010\tBest loss: 0.416319\tAccuracy: 91.60%\n",
      "763\tValidation loss: 0.417508\tBest loss: 0.416319\tAccuracy: 91.70%\n",
      "764\tValidation loss: 0.418629\tBest loss: 0.416319\tAccuracy: 91.60%\n",
      "765\tValidation loss: 0.417258\tBest loss: 0.416319\tAccuracy: 91.50%\n",
      "766\tValidation loss: 0.417225\tBest loss: 0.416319\tAccuracy: 91.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.3min\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.237456\tBest loss: 3.237456\tAccuracy: 21.60%\n",
      "1\tValidation loss: 2.760708\tBest loss: 2.760708\tAccuracy: 34.60%\n",
      "2\tValidation loss: 2.439166\tBest loss: 2.439166\tAccuracy: 42.90%\n",
      "3\tValidation loss: 2.212356\tBest loss: 2.212356\tAccuracy: 46.70%\n",
      "4\tValidation loss: 2.025427\tBest loss: 2.025427\tAccuracy: 52.70%\n",
      "5\tValidation loss: 1.880238\tBest loss: 1.880238\tAccuracy: 56.40%\n",
      "6\tValidation loss: 1.766090\tBest loss: 1.766090\tAccuracy: 59.10%\n",
      "7\tValidation loss: 1.658295\tBest loss: 1.658295\tAccuracy: 61.40%\n",
      "8\tValidation loss: 1.585929\tBest loss: 1.585929\tAccuracy: 63.10%\n",
      "9\tValidation loss: 1.517313\tBest loss: 1.517313\tAccuracy: 65.50%\n",
      "10\tValidation loss: 1.445448\tBest loss: 1.445448\tAccuracy: 67.00%\n",
      "11\tValidation loss: 1.391872\tBest loss: 1.391872\tAccuracy: 68.00%\n",
      "12\tValidation loss: 1.347448\tBest loss: 1.347448\tAccuracy: 68.50%\n",
      "13\tValidation loss: 1.305982\tBest loss: 1.305982\tAccuracy: 69.40%\n",
      "14\tValidation loss: 1.261470\tBest loss: 1.261470\tAccuracy: 70.90%\n",
      "15\tValidation loss: 1.227043\tBest loss: 1.227043\tAccuracy: 72.70%\n",
      "16\tValidation loss: 1.200593\tBest loss: 1.200593\tAccuracy: 73.00%\n",
      "17\tValidation loss: 1.171223\tBest loss: 1.171223\tAccuracy: 72.60%\n",
      "18\tValidation loss: 1.141845\tBest loss: 1.141845\tAccuracy: 74.60%\n",
      "19\tValidation loss: 1.118530\tBest loss: 1.118530\tAccuracy: 74.00%\n",
      "20\tValidation loss: 1.100731\tBest loss: 1.100731\tAccuracy: 74.60%\n",
      "21\tValidation loss: 1.075561\tBest loss: 1.075561\tAccuracy: 75.00%\n",
      "22\tValidation loss: 1.056319\tBest loss: 1.056319\tAccuracy: 76.20%\n",
      "23\tValidation loss: 1.038036\tBest loss: 1.038036\tAccuracy: 75.90%\n",
      "24\tValidation loss: 1.025705\tBest loss: 1.025705\tAccuracy: 76.20%\n",
      "25\tValidation loss: 1.011720\tBest loss: 1.011720\tAccuracy: 76.10%\n",
      "26\tValidation loss: 0.993121\tBest loss: 0.993121\tAccuracy: 77.30%\n",
      "27\tValidation loss: 0.975140\tBest loss: 0.975140\tAccuracy: 77.20%\n",
      "28\tValidation loss: 0.965820\tBest loss: 0.965820\tAccuracy: 77.10%\n",
      "29\tValidation loss: 0.952919\tBest loss: 0.952919\tAccuracy: 77.60%\n",
      "30\tValidation loss: 0.940362\tBest loss: 0.940362\tAccuracy: 77.60%\n",
      "31\tValidation loss: 0.926479\tBest loss: 0.926479\tAccuracy: 77.70%\n",
      "32\tValidation loss: 0.913850\tBest loss: 0.913850\tAccuracy: 78.10%\n",
      "33\tValidation loss: 0.907593\tBest loss: 0.907593\tAccuracy: 78.40%\n",
      "34\tValidation loss: 0.898590\tBest loss: 0.898590\tAccuracy: 78.50%\n",
      "35\tValidation loss: 0.889922\tBest loss: 0.889922\tAccuracy: 79.00%\n",
      "36\tValidation loss: 0.884592\tBest loss: 0.884592\tAccuracy: 79.80%\n",
      "37\tValidation loss: 0.867215\tBest loss: 0.867215\tAccuracy: 79.40%\n",
      "38\tValidation loss: 0.858324\tBest loss: 0.858324\tAccuracy: 79.60%\n",
      "39\tValidation loss: 0.854478\tBest loss: 0.854478\tAccuracy: 79.60%\n",
      "40\tValidation loss: 0.845068\tBest loss: 0.845068\tAccuracy: 80.20%\n",
      "41\tValidation loss: 0.834718\tBest loss: 0.834718\tAccuracy: 80.20%\n",
      "42\tValidation loss: 0.830218\tBest loss: 0.830218\tAccuracy: 80.00%\n",
      "43\tValidation loss: 0.821150\tBest loss: 0.821150\tAccuracy: 80.50%\n",
      "44\tValidation loss: 0.815657\tBest loss: 0.815657\tAccuracy: 80.80%\n",
      "45\tValidation loss: 0.811571\tBest loss: 0.811571\tAccuracy: 81.00%\n",
      "46\tValidation loss: 0.805663\tBest loss: 0.805663\tAccuracy: 81.10%\n",
      "47\tValidation loss: 0.797840\tBest loss: 0.797840\tAccuracy: 81.20%\n",
      "48\tValidation loss: 0.790856\tBest loss: 0.790856\tAccuracy: 81.70%\n",
      "49\tValidation loss: 0.785863\tBest loss: 0.785863\tAccuracy: 81.80%\n",
      "50\tValidation loss: 0.784403\tBest loss: 0.784403\tAccuracy: 81.50%\n",
      "51\tValidation loss: 0.773593\tBest loss: 0.773593\tAccuracy: 81.50%\n",
      "52\tValidation loss: 0.770067\tBest loss: 0.770067\tAccuracy: 82.00%\n",
      "53\tValidation loss: 0.764349\tBest loss: 0.764349\tAccuracy: 82.10%\n",
      "54\tValidation loss: 0.758356\tBest loss: 0.758356\tAccuracy: 82.30%\n",
      "55\tValidation loss: 0.752613\tBest loss: 0.752613\tAccuracy: 82.40%\n",
      "56\tValidation loss: 0.751078\tBest loss: 0.751078\tAccuracy: 82.80%\n",
      "57\tValidation loss: 0.743671\tBest loss: 0.743671\tAccuracy: 82.70%\n",
      "58\tValidation loss: 0.742768\tBest loss: 0.742768\tAccuracy: 82.40%\n",
      "59\tValidation loss: 0.735279\tBest loss: 0.735279\tAccuracy: 83.00%\n",
      "60\tValidation loss: 0.733133\tBest loss: 0.733133\tAccuracy: 82.50%\n",
      "61\tValidation loss: 0.731487\tBest loss: 0.731487\tAccuracy: 83.20%\n",
      "62\tValidation loss: 0.726952\tBest loss: 0.726952\tAccuracy: 83.10%\n",
      "63\tValidation loss: 0.721164\tBest loss: 0.721164\tAccuracy: 83.40%\n",
      "64\tValidation loss: 0.717242\tBest loss: 0.717242\tAccuracy: 83.50%\n",
      "65\tValidation loss: 0.714575\tBest loss: 0.714575\tAccuracy: 83.80%\n",
      "66\tValidation loss: 0.707445\tBest loss: 0.707445\tAccuracy: 83.70%\n",
      "67\tValidation loss: 0.707642\tBest loss: 0.707445\tAccuracy: 83.70%\n",
      "68\tValidation loss: 0.700915\tBest loss: 0.700915\tAccuracy: 83.20%\n",
      "69\tValidation loss: 0.700731\tBest loss: 0.700731\tAccuracy: 84.00%\n",
      "70\tValidation loss: 0.694348\tBest loss: 0.694348\tAccuracy: 84.30%\n",
      "71\tValidation loss: 0.693003\tBest loss: 0.693003\tAccuracy: 83.90%\n",
      "72\tValidation loss: 0.690317\tBest loss: 0.690317\tAccuracy: 83.90%\n",
      "73\tValidation loss: 0.687381\tBest loss: 0.687381\tAccuracy: 83.90%\n",
      "74\tValidation loss: 0.684607\tBest loss: 0.684607\tAccuracy: 84.00%\n",
      "75\tValidation loss: 0.680145\tBest loss: 0.680145\tAccuracy: 84.10%\n",
      "76\tValidation loss: 0.681636\tBest loss: 0.680145\tAccuracy: 84.40%\n",
      "77\tValidation loss: 0.671688\tBest loss: 0.671688\tAccuracy: 84.40%\n",
      "78\tValidation loss: 0.667296\tBest loss: 0.667296\tAccuracy: 84.70%\n",
      "79\tValidation loss: 0.670879\tBest loss: 0.667296\tAccuracy: 84.00%\n",
      "80\tValidation loss: 0.663605\tBest loss: 0.663605\tAccuracy: 84.50%\n",
      "81\tValidation loss: 0.664207\tBest loss: 0.663605\tAccuracy: 83.90%\n",
      "82\tValidation loss: 0.659776\tBest loss: 0.659776\tAccuracy: 84.30%\n",
      "83\tValidation loss: 0.656444\tBest loss: 0.656444\tAccuracy: 84.60%\n",
      "84\tValidation loss: 0.656244\tBest loss: 0.656244\tAccuracy: 84.60%\n",
      "85\tValidation loss: 0.649666\tBest loss: 0.649666\tAccuracy: 84.40%\n",
      "86\tValidation loss: 0.648870\tBest loss: 0.648870\tAccuracy: 84.30%\n",
      "87\tValidation loss: 0.648681\tBest loss: 0.648681\tAccuracy: 85.10%\n",
      "88\tValidation loss: 0.645449\tBest loss: 0.645449\tAccuracy: 84.70%\n",
      "89\tValidation loss: 0.643208\tBest loss: 0.643208\tAccuracy: 84.70%\n",
      "90\tValidation loss: 0.640275\tBest loss: 0.640275\tAccuracy: 84.80%\n",
      "91\tValidation loss: 0.635687\tBest loss: 0.635687\tAccuracy: 84.70%\n",
      "92\tValidation loss: 0.639883\tBest loss: 0.635687\tAccuracy: 84.40%\n",
      "93\tValidation loss: 0.631371\tBest loss: 0.631371\tAccuracy: 84.70%\n",
      "94\tValidation loss: 0.629477\tBest loss: 0.629477\tAccuracy: 85.10%\n",
      "95\tValidation loss: 0.627283\tBest loss: 0.627283\tAccuracy: 85.30%\n",
      "96\tValidation loss: 0.624390\tBest loss: 0.624390\tAccuracy: 84.90%\n",
      "97\tValidation loss: 0.628030\tBest loss: 0.624390\tAccuracy: 84.80%\n",
      "98\tValidation loss: 0.622720\tBest loss: 0.622720\tAccuracy: 85.20%\n",
      "99\tValidation loss: 0.620022\tBest loss: 0.620022\tAccuracy: 85.20%\n",
      "100\tValidation loss: 0.618790\tBest loss: 0.618790\tAccuracy: 85.00%\n",
      "101\tValidation loss: 0.617308\tBest loss: 0.617308\tAccuracy: 85.00%\n",
      "102\tValidation loss: 0.613464\tBest loss: 0.613464\tAccuracy: 85.00%\n",
      "103\tValidation loss: 0.611097\tBest loss: 0.611097\tAccuracy: 85.30%\n",
      "104\tValidation loss: 0.613305\tBest loss: 0.611097\tAccuracy: 85.00%\n",
      "105\tValidation loss: 0.614570\tBest loss: 0.611097\tAccuracy: 84.90%\n",
      "106\tValidation loss: 0.607747\tBest loss: 0.607747\tAccuracy: 85.10%\n",
      "107\tValidation loss: 0.605250\tBest loss: 0.605250\tAccuracy: 85.20%\n",
      "108\tValidation loss: 0.605073\tBest loss: 0.605073\tAccuracy: 85.20%\n",
      "109\tValidation loss: 0.602453\tBest loss: 0.602453\tAccuracy: 85.20%\n",
      "110\tValidation loss: 0.599310\tBest loss: 0.599310\tAccuracy: 85.10%\n",
      "111\tValidation loss: 0.601834\tBest loss: 0.599310\tAccuracy: 85.20%\n",
      "112\tValidation loss: 0.597345\tBest loss: 0.597345\tAccuracy: 85.10%\n",
      "113\tValidation loss: 0.596895\tBest loss: 0.596895\tAccuracy: 85.10%\n",
      "114\tValidation loss: 0.596994\tBest loss: 0.596895\tAccuracy: 84.80%\n",
      "115\tValidation loss: 0.591352\tBest loss: 0.591352\tAccuracy: 85.20%\n",
      "116\tValidation loss: 0.594479\tBest loss: 0.591352\tAccuracy: 84.70%\n",
      "117\tValidation loss: 0.592485\tBest loss: 0.591352\tAccuracy: 85.00%\n",
      "118\tValidation loss: 0.585200\tBest loss: 0.585200\tAccuracy: 85.30%\n",
      "119\tValidation loss: 0.585998\tBest loss: 0.585200\tAccuracy: 84.80%\n",
      "120\tValidation loss: 0.583904\tBest loss: 0.583904\tAccuracy: 85.10%\n",
      "121\tValidation loss: 0.582993\tBest loss: 0.582993\tAccuracy: 85.30%\n",
      "122\tValidation loss: 0.584196\tBest loss: 0.582993\tAccuracy: 85.50%\n",
      "123\tValidation loss: 0.580551\tBest loss: 0.580551\tAccuracy: 86.00%\n",
      "124\tValidation loss: 0.582753\tBest loss: 0.580551\tAccuracy: 85.20%\n",
      "125\tValidation loss: 0.576421\tBest loss: 0.576421\tAccuracy: 85.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 0.575714\tBest loss: 0.575714\tAccuracy: 85.60%\n",
      "127\tValidation loss: 0.577337\tBest loss: 0.575714\tAccuracy: 85.50%\n",
      "128\tValidation loss: 0.572021\tBest loss: 0.572021\tAccuracy: 86.40%\n",
      "129\tValidation loss: 0.570600\tBest loss: 0.570600\tAccuracy: 85.50%\n",
      "130\tValidation loss: 0.569573\tBest loss: 0.569573\tAccuracy: 85.90%\n",
      "131\tValidation loss: 0.569735\tBest loss: 0.569573\tAccuracy: 85.70%\n",
      "132\tValidation loss: 0.566823\tBest loss: 0.566823\tAccuracy: 85.70%\n",
      "133\tValidation loss: 0.567460\tBest loss: 0.566823\tAccuracy: 86.00%\n",
      "134\tValidation loss: 0.565475\tBest loss: 0.565475\tAccuracy: 86.40%\n",
      "135\tValidation loss: 0.566312\tBest loss: 0.565475\tAccuracy: 85.80%\n",
      "136\tValidation loss: 0.564255\tBest loss: 0.564255\tAccuracy: 85.90%\n",
      "137\tValidation loss: 0.562457\tBest loss: 0.562457\tAccuracy: 85.90%\n",
      "138\tValidation loss: 0.561867\tBest loss: 0.561867\tAccuracy: 85.80%\n",
      "139\tValidation loss: 0.559519\tBest loss: 0.559519\tAccuracy: 86.10%\n",
      "140\tValidation loss: 0.558277\tBest loss: 0.558277\tAccuracy: 85.80%\n",
      "141\tValidation loss: 0.557910\tBest loss: 0.557910\tAccuracy: 86.40%\n",
      "142\tValidation loss: 0.555860\tBest loss: 0.555860\tAccuracy: 86.70%\n",
      "143\tValidation loss: 0.555957\tBest loss: 0.555860\tAccuracy: 86.40%\n",
      "144\tValidation loss: 0.554264\tBest loss: 0.554264\tAccuracy: 86.40%\n",
      "145\tValidation loss: 0.550862\tBest loss: 0.550862\tAccuracy: 86.60%\n",
      "146\tValidation loss: 0.552974\tBest loss: 0.550862\tAccuracy: 86.50%\n",
      "147\tValidation loss: 0.552464\tBest loss: 0.550862\tAccuracy: 86.30%\n",
      "148\tValidation loss: 0.551151\tBest loss: 0.550862\tAccuracy: 86.50%\n",
      "149\tValidation loss: 0.548892\tBest loss: 0.548892\tAccuracy: 86.90%\n",
      "150\tValidation loss: 0.548200\tBest loss: 0.548200\tAccuracy: 86.60%\n",
      "151\tValidation loss: 0.545935\tBest loss: 0.545935\tAccuracy: 86.90%\n",
      "152\tValidation loss: 0.545411\tBest loss: 0.545411\tAccuracy: 86.40%\n",
      "153\tValidation loss: 0.542827\tBest loss: 0.542827\tAccuracy: 86.70%\n",
      "154\tValidation loss: 0.543277\tBest loss: 0.542827\tAccuracy: 87.00%\n",
      "155\tValidation loss: 0.542005\tBest loss: 0.542005\tAccuracy: 86.90%\n",
      "156\tValidation loss: 0.542193\tBest loss: 0.542005\tAccuracy: 86.80%\n",
      "157\tValidation loss: 0.541528\tBest loss: 0.541528\tAccuracy: 86.40%\n",
      "158\tValidation loss: 0.536941\tBest loss: 0.536941\tAccuracy: 87.30%\n",
      "159\tValidation loss: 0.536714\tBest loss: 0.536714\tAccuracy: 87.30%\n",
      "160\tValidation loss: 0.539503\tBest loss: 0.536714\tAccuracy: 86.50%\n",
      "161\tValidation loss: 0.534657\tBest loss: 0.534657\tAccuracy: 87.40%\n",
      "162\tValidation loss: 0.533973\tBest loss: 0.533973\tAccuracy: 87.10%\n",
      "163\tValidation loss: 0.533351\tBest loss: 0.533351\tAccuracy: 87.20%\n",
      "164\tValidation loss: 0.533461\tBest loss: 0.533351\tAccuracy: 86.90%\n",
      "165\tValidation loss: 0.532602\tBest loss: 0.532602\tAccuracy: 87.10%\n",
      "166\tValidation loss: 0.532885\tBest loss: 0.532602\tAccuracy: 87.00%\n",
      "167\tValidation loss: 0.529757\tBest loss: 0.529757\tAccuracy: 87.30%\n",
      "168\tValidation loss: 0.528380\tBest loss: 0.528380\tAccuracy: 87.10%\n",
      "169\tValidation loss: 0.530166\tBest loss: 0.528380\tAccuracy: 87.10%\n",
      "170\tValidation loss: 0.529613\tBest loss: 0.528380\tAccuracy: 87.00%\n",
      "171\tValidation loss: 0.527802\tBest loss: 0.527802\tAccuracy: 87.00%\n",
      "172\tValidation loss: 0.526000\tBest loss: 0.526000\tAccuracy: 87.00%\n",
      "173\tValidation loss: 0.525937\tBest loss: 0.525937\tAccuracy: 87.20%\n",
      "174\tValidation loss: 0.525318\tBest loss: 0.525318\tAccuracy: 87.00%\n",
      "175\tValidation loss: 0.524505\tBest loss: 0.524505\tAccuracy: 87.20%\n",
      "176\tValidation loss: 0.523964\tBest loss: 0.523964\tAccuracy: 87.10%\n",
      "177\tValidation loss: 0.521831\tBest loss: 0.521831\tAccuracy: 87.20%\n",
      "178\tValidation loss: 0.520627\tBest loss: 0.520627\tAccuracy: 87.20%\n",
      "179\tValidation loss: 0.519036\tBest loss: 0.519036\tAccuracy: 87.50%\n",
      "180\tValidation loss: 0.519252\tBest loss: 0.519036\tAccuracy: 87.10%\n",
      "181\tValidation loss: 0.517827\tBest loss: 0.517827\tAccuracy: 87.40%\n",
      "182\tValidation loss: 0.519513\tBest loss: 0.517827\tAccuracy: 87.10%\n",
      "183\tValidation loss: 0.516284\tBest loss: 0.516284\tAccuracy: 87.50%\n",
      "184\tValidation loss: 0.516489\tBest loss: 0.516284\tAccuracy: 87.20%\n",
      "185\tValidation loss: 0.514799\tBest loss: 0.514799\tAccuracy: 87.30%\n",
      "186\tValidation loss: 0.514677\tBest loss: 0.514677\tAccuracy: 87.30%\n",
      "187\tValidation loss: 0.512135\tBest loss: 0.512135\tAccuracy: 87.50%\n",
      "188\tValidation loss: 0.513940\tBest loss: 0.512135\tAccuracy: 87.10%\n",
      "189\tValidation loss: 0.513223\tBest loss: 0.512135\tAccuracy: 87.50%\n",
      "190\tValidation loss: 0.511566\tBest loss: 0.511566\tAccuracy: 87.30%\n",
      "191\tValidation loss: 0.509558\tBest loss: 0.509558\tAccuracy: 87.40%\n",
      "192\tValidation loss: 0.508842\tBest loss: 0.508842\tAccuracy: 87.30%\n",
      "193\tValidation loss: 0.510043\tBest loss: 0.508842\tAccuracy: 87.40%\n",
      "194\tValidation loss: 0.512366\tBest loss: 0.508842\tAccuracy: 87.50%\n",
      "195\tValidation loss: 0.508862\tBest loss: 0.508842\tAccuracy: 87.40%\n",
      "196\tValidation loss: 0.506039\tBest loss: 0.506039\tAccuracy: 87.40%\n",
      "197\tValidation loss: 0.505991\tBest loss: 0.505991\tAccuracy: 87.80%\n",
      "198\tValidation loss: 0.507198\tBest loss: 0.505991\tAccuracy: 87.80%\n",
      "199\tValidation loss: 0.507702\tBest loss: 0.505991\tAccuracy: 87.30%\n",
      "200\tValidation loss: 0.504797\tBest loss: 0.504797\tAccuracy: 87.60%\n",
      "201\tValidation loss: 0.504758\tBest loss: 0.504758\tAccuracy: 87.10%\n",
      "202\tValidation loss: 0.503187\tBest loss: 0.503187\tAccuracy: 87.30%\n",
      "203\tValidation loss: 0.503093\tBest loss: 0.503093\tAccuracy: 87.60%\n",
      "204\tValidation loss: 0.502690\tBest loss: 0.502690\tAccuracy: 87.60%\n",
      "205\tValidation loss: 0.501687\tBest loss: 0.501687\tAccuracy: 87.70%\n",
      "206\tValidation loss: 0.501982\tBest loss: 0.501687\tAccuracy: 87.30%\n",
      "207\tValidation loss: 0.499139\tBest loss: 0.499139\tAccuracy: 87.70%\n",
      "208\tValidation loss: 0.500006\tBest loss: 0.499139\tAccuracy: 87.70%\n",
      "209\tValidation loss: 0.499589\tBest loss: 0.499139\tAccuracy: 87.60%\n",
      "210\tValidation loss: 0.498971\tBest loss: 0.498971\tAccuracy: 88.20%\n",
      "211\tValidation loss: 0.497306\tBest loss: 0.497306\tAccuracy: 87.90%\n",
      "212\tValidation loss: 0.497264\tBest loss: 0.497264\tAccuracy: 88.10%\n",
      "213\tValidation loss: 0.497532\tBest loss: 0.497264\tAccuracy: 87.70%\n",
      "214\tValidation loss: 0.494859\tBest loss: 0.494859\tAccuracy: 87.80%\n",
      "215\tValidation loss: 0.495307\tBest loss: 0.494859\tAccuracy: 87.90%\n",
      "216\tValidation loss: 0.496670\tBest loss: 0.494859\tAccuracy: 87.50%\n",
      "217\tValidation loss: 0.494707\tBest loss: 0.494707\tAccuracy: 88.10%\n",
      "218\tValidation loss: 0.493338\tBest loss: 0.493338\tAccuracy: 88.20%\n",
      "219\tValidation loss: 0.493845\tBest loss: 0.493338\tAccuracy: 87.90%\n",
      "220\tValidation loss: 0.491582\tBest loss: 0.491582\tAccuracy: 88.00%\n",
      "221\tValidation loss: 0.492671\tBest loss: 0.491582\tAccuracy: 87.70%\n",
      "222\tValidation loss: 0.492136\tBest loss: 0.491582\tAccuracy: 87.90%\n",
      "223\tValidation loss: 0.491388\tBest loss: 0.491388\tAccuracy: 88.10%\n",
      "224\tValidation loss: 0.491047\tBest loss: 0.491047\tAccuracy: 88.10%\n",
      "225\tValidation loss: 0.490060\tBest loss: 0.490060\tAccuracy: 88.30%\n",
      "226\tValidation loss: 0.490553\tBest loss: 0.490060\tAccuracy: 88.20%\n",
      "227\tValidation loss: 0.486159\tBest loss: 0.486159\tAccuracy: 88.30%\n",
      "228\tValidation loss: 0.487180\tBest loss: 0.486159\tAccuracy: 88.00%\n",
      "229\tValidation loss: 0.489349\tBest loss: 0.486159\tAccuracy: 88.20%\n",
      "230\tValidation loss: 0.485802\tBest loss: 0.485802\tAccuracy: 88.20%\n",
      "231\tValidation loss: 0.486275\tBest loss: 0.485802\tAccuracy: 88.00%\n",
      "232\tValidation loss: 0.484930\tBest loss: 0.484930\tAccuracy: 88.40%\n",
      "233\tValidation loss: 0.485164\tBest loss: 0.484930\tAccuracy: 88.10%\n",
      "234\tValidation loss: 0.484504\tBest loss: 0.484504\tAccuracy: 88.30%\n",
      "235\tValidation loss: 0.486142\tBest loss: 0.484504\tAccuracy: 88.20%\n",
      "236\tValidation loss: 0.484312\tBest loss: 0.484312\tAccuracy: 88.20%\n",
      "237\tValidation loss: 0.484068\tBest loss: 0.484068\tAccuracy: 88.20%\n",
      "238\tValidation loss: 0.484482\tBest loss: 0.484068\tAccuracy: 88.30%\n",
      "239\tValidation loss: 0.482394\tBest loss: 0.482394\tAccuracy: 88.50%\n",
      "240\tValidation loss: 0.482465\tBest loss: 0.482394\tAccuracy: 88.30%\n",
      "241\tValidation loss: 0.481868\tBest loss: 0.481868\tAccuracy: 88.30%\n",
      "242\tValidation loss: 0.480877\tBest loss: 0.480877\tAccuracy: 88.40%\n",
      "243\tValidation loss: 0.480362\tBest loss: 0.480362\tAccuracy: 88.30%\n",
      "244\tValidation loss: 0.480738\tBest loss: 0.480362\tAccuracy: 88.60%\n",
      "245\tValidation loss: 0.480521\tBest loss: 0.480362\tAccuracy: 88.40%\n",
      "246\tValidation loss: 0.479941\tBest loss: 0.479941\tAccuracy: 88.60%\n",
      "247\tValidation loss: 0.478459\tBest loss: 0.478459\tAccuracy: 88.00%\n",
      "248\tValidation loss: 0.477603\tBest loss: 0.477603\tAccuracy: 88.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\tValidation loss: 0.476457\tBest loss: 0.476457\tAccuracy: 88.40%\n",
      "250\tValidation loss: 0.477296\tBest loss: 0.476457\tAccuracy: 88.30%\n",
      "251\tValidation loss: 0.475603\tBest loss: 0.475603\tAccuracy: 88.60%\n",
      "252\tValidation loss: 0.474399\tBest loss: 0.474399\tAccuracy: 88.70%\n",
      "253\tValidation loss: 0.474471\tBest loss: 0.474399\tAccuracy: 88.60%\n",
      "254\tValidation loss: 0.474596\tBest loss: 0.474399\tAccuracy: 88.30%\n",
      "255\tValidation loss: 0.475903\tBest loss: 0.474399\tAccuracy: 88.50%\n",
      "256\tValidation loss: 0.473440\tBest loss: 0.473440\tAccuracy: 88.50%\n",
      "257\tValidation loss: 0.475943\tBest loss: 0.473440\tAccuracy: 88.40%\n",
      "258\tValidation loss: 0.474102\tBest loss: 0.473440\tAccuracy: 88.70%\n",
      "259\tValidation loss: 0.475105\tBest loss: 0.473440\tAccuracy: 88.60%\n",
      "260\tValidation loss: 0.472606\tBest loss: 0.472606\tAccuracy: 88.50%\n",
      "261\tValidation loss: 0.474170\tBest loss: 0.472606\tAccuracy: 88.60%\n",
      "262\tValidation loss: 0.473423\tBest loss: 0.472606\tAccuracy: 88.60%\n",
      "263\tValidation loss: 0.470042\tBest loss: 0.470042\tAccuracy: 88.60%\n",
      "264\tValidation loss: 0.470613\tBest loss: 0.470042\tAccuracy: 88.70%\n",
      "265\tValidation loss: 0.468957\tBest loss: 0.468957\tAccuracy: 88.80%\n",
      "266\tValidation loss: 0.471012\tBest loss: 0.468957\tAccuracy: 88.70%\n",
      "267\tValidation loss: 0.469127\tBest loss: 0.468957\tAccuracy: 88.60%\n",
      "268\tValidation loss: 0.467830\tBest loss: 0.467830\tAccuracy: 88.70%\n",
      "269\tValidation loss: 0.468119\tBest loss: 0.467830\tAccuracy: 88.60%\n",
      "270\tValidation loss: 0.469856\tBest loss: 0.467830\tAccuracy: 88.80%\n",
      "271\tValidation loss: 0.467617\tBest loss: 0.467617\tAccuracy: 88.60%\n",
      "272\tValidation loss: 0.465071\tBest loss: 0.465071\tAccuracy: 88.80%\n",
      "273\tValidation loss: 0.467099\tBest loss: 0.465071\tAccuracy: 88.70%\n",
      "274\tValidation loss: 0.465901\tBest loss: 0.465071\tAccuracy: 88.70%\n",
      "275\tValidation loss: 0.468215\tBest loss: 0.465071\tAccuracy: 88.60%\n",
      "276\tValidation loss: 0.466260\tBest loss: 0.465071\tAccuracy: 88.70%\n",
      "277\tValidation loss: 0.466606\tBest loss: 0.465071\tAccuracy: 88.80%\n",
      "278\tValidation loss: 0.464060\tBest loss: 0.464060\tAccuracy: 88.90%\n",
      "279\tValidation loss: 0.464977\tBest loss: 0.464060\tAccuracy: 88.90%\n",
      "280\tValidation loss: 0.464198\tBest loss: 0.464060\tAccuracy: 88.90%\n",
      "281\tValidation loss: 0.465019\tBest loss: 0.464060\tAccuracy: 89.00%\n",
      "282\tValidation loss: 0.463198\tBest loss: 0.463198\tAccuracy: 89.00%\n",
      "283\tValidation loss: 0.461831\tBest loss: 0.461831\tAccuracy: 89.20%\n",
      "284\tValidation loss: 0.462455\tBest loss: 0.461831\tAccuracy: 89.00%\n",
      "285\tValidation loss: 0.461945\tBest loss: 0.461831\tAccuracy: 89.00%\n",
      "286\tValidation loss: 0.462776\tBest loss: 0.461831\tAccuracy: 89.00%\n",
      "287\tValidation loss: 0.461945\tBest loss: 0.461831\tAccuracy: 88.90%\n",
      "288\tValidation loss: 0.459743\tBest loss: 0.459743\tAccuracy: 88.80%\n",
      "289\tValidation loss: 0.460713\tBest loss: 0.459743\tAccuracy: 89.00%\n",
      "290\tValidation loss: 0.459099\tBest loss: 0.459099\tAccuracy: 89.10%\n",
      "291\tValidation loss: 0.459716\tBest loss: 0.459099\tAccuracy: 89.00%\n",
      "292\tValidation loss: 0.460472\tBest loss: 0.459099\tAccuracy: 88.90%\n",
      "293\tValidation loss: 0.459767\tBest loss: 0.459099\tAccuracy: 89.00%\n",
      "294\tValidation loss: 0.459216\tBest loss: 0.459099\tAccuracy: 89.10%\n",
      "295\tValidation loss: 0.458095\tBest loss: 0.458095\tAccuracy: 89.00%\n",
      "296\tValidation loss: 0.458701\tBest loss: 0.458095\tAccuracy: 88.90%\n",
      "297\tValidation loss: 0.458440\tBest loss: 0.458095\tAccuracy: 89.00%\n",
      "298\tValidation loss: 0.457120\tBest loss: 0.457120\tAccuracy: 89.00%\n",
      "299\tValidation loss: 0.457214\tBest loss: 0.457120\tAccuracy: 88.90%\n",
      "300\tValidation loss: 0.456093\tBest loss: 0.456093\tAccuracy: 89.10%\n",
      "301\tValidation loss: 0.455772\tBest loss: 0.455772\tAccuracy: 89.00%\n",
      "302\tValidation loss: 0.457689\tBest loss: 0.455772\tAccuracy: 88.90%\n",
      "303\tValidation loss: 0.455569\tBest loss: 0.455569\tAccuracy: 89.20%\n",
      "304\tValidation loss: 0.456073\tBest loss: 0.455569\tAccuracy: 89.20%\n",
      "305\tValidation loss: 0.453671\tBest loss: 0.453671\tAccuracy: 89.00%\n",
      "306\tValidation loss: 0.452787\tBest loss: 0.452787\tAccuracy: 89.00%\n",
      "307\tValidation loss: 0.454755\tBest loss: 0.452787\tAccuracy: 89.30%\n",
      "308\tValidation loss: 0.454678\tBest loss: 0.452787\tAccuracy: 89.10%\n",
      "309\tValidation loss: 0.454103\tBest loss: 0.452787\tAccuracy: 89.10%\n",
      "310\tValidation loss: 0.452542\tBest loss: 0.452542\tAccuracy: 89.00%\n",
      "311\tValidation loss: 0.452864\tBest loss: 0.452542\tAccuracy: 89.10%\n",
      "312\tValidation loss: 0.450980\tBest loss: 0.450980\tAccuracy: 89.10%\n",
      "313\tValidation loss: 0.452281\tBest loss: 0.450980\tAccuracy: 89.20%\n",
      "314\tValidation loss: 0.451059\tBest loss: 0.450980\tAccuracy: 89.40%\n",
      "315\tValidation loss: 0.451265\tBest loss: 0.450980\tAccuracy: 89.30%\n",
      "316\tValidation loss: 0.451007\tBest loss: 0.450980\tAccuracy: 89.30%\n",
      "317\tValidation loss: 0.451655\tBest loss: 0.450980\tAccuracy: 89.00%\n",
      "318\tValidation loss: 0.450724\tBest loss: 0.450724\tAccuracy: 89.30%\n",
      "319\tValidation loss: 0.450503\tBest loss: 0.450503\tAccuracy: 89.00%\n",
      "320\tValidation loss: 0.448650\tBest loss: 0.448650\tAccuracy: 89.10%\n",
      "321\tValidation loss: 0.448199\tBest loss: 0.448199\tAccuracy: 89.00%\n",
      "322\tValidation loss: 0.448876\tBest loss: 0.448199\tAccuracy: 89.10%\n",
      "323\tValidation loss: 0.448963\tBest loss: 0.448199\tAccuracy: 89.00%\n",
      "324\tValidation loss: 0.446915\tBest loss: 0.446915\tAccuracy: 89.10%\n",
      "325\tValidation loss: 0.448608\tBest loss: 0.446915\tAccuracy: 89.00%\n",
      "326\tValidation loss: 0.446456\tBest loss: 0.446456\tAccuracy: 89.30%\n",
      "327\tValidation loss: 0.447018\tBest loss: 0.446456\tAccuracy: 89.30%\n",
      "328\tValidation loss: 0.446405\tBest loss: 0.446405\tAccuracy: 89.00%\n",
      "329\tValidation loss: 0.446538\tBest loss: 0.446405\tAccuracy: 89.10%\n",
      "330\tValidation loss: 0.445961\tBest loss: 0.445961\tAccuracy: 89.50%\n",
      "331\tValidation loss: 0.446179\tBest loss: 0.445961\tAccuracy: 89.20%\n",
      "332\tValidation loss: 0.445932\tBest loss: 0.445932\tAccuracy: 89.20%\n",
      "333\tValidation loss: 0.446078\tBest loss: 0.445932\tAccuracy: 89.20%\n",
      "334\tValidation loss: 0.444713\tBest loss: 0.444713\tAccuracy: 89.30%\n",
      "335\tValidation loss: 0.444207\tBest loss: 0.444207\tAccuracy: 89.10%\n",
      "336\tValidation loss: 0.442732\tBest loss: 0.442732\tAccuracy: 89.30%\n",
      "337\tValidation loss: 0.444164\tBest loss: 0.442732\tAccuracy: 89.30%\n",
      "338\tValidation loss: 0.443036\tBest loss: 0.442732\tAccuracy: 89.50%\n",
      "339\tValidation loss: 0.443770\tBest loss: 0.442732\tAccuracy: 89.40%\n",
      "340\tValidation loss: 0.442705\tBest loss: 0.442705\tAccuracy: 89.10%\n",
      "341\tValidation loss: 0.441345\tBest loss: 0.441345\tAccuracy: 89.20%\n",
      "342\tValidation loss: 0.442131\tBest loss: 0.441345\tAccuracy: 89.20%\n",
      "343\tValidation loss: 0.441221\tBest loss: 0.441221\tAccuracy: 89.30%\n",
      "344\tValidation loss: 0.440319\tBest loss: 0.440319\tAccuracy: 89.20%\n",
      "345\tValidation loss: 0.441685\tBest loss: 0.440319\tAccuracy: 89.10%\n",
      "346\tValidation loss: 0.440561\tBest loss: 0.440319\tAccuracy: 89.50%\n",
      "347\tValidation loss: 0.441948\tBest loss: 0.440319\tAccuracy: 89.20%\n",
      "348\tValidation loss: 0.439857\tBest loss: 0.439857\tAccuracy: 89.50%\n",
      "349\tValidation loss: 0.441827\tBest loss: 0.439857\tAccuracy: 89.20%\n",
      "350\tValidation loss: 0.439189\tBest loss: 0.439189\tAccuracy: 89.40%\n",
      "351\tValidation loss: 0.438992\tBest loss: 0.438992\tAccuracy: 89.30%\n",
      "352\tValidation loss: 0.438068\tBest loss: 0.438068\tAccuracy: 89.40%\n",
      "353\tValidation loss: 0.438772\tBest loss: 0.438068\tAccuracy: 89.20%\n",
      "354\tValidation loss: 0.438218\tBest loss: 0.438068\tAccuracy: 89.50%\n",
      "355\tValidation loss: 0.439110\tBest loss: 0.438068\tAccuracy: 89.50%\n",
      "356\tValidation loss: 0.437091\tBest loss: 0.437091\tAccuracy: 89.30%\n",
      "357\tValidation loss: 0.439322\tBest loss: 0.437091\tAccuracy: 89.40%\n",
      "358\tValidation loss: 0.436381\tBest loss: 0.436381\tAccuracy: 89.30%\n",
      "359\tValidation loss: 0.438282\tBest loss: 0.436381\tAccuracy: 89.40%\n",
      "360\tValidation loss: 0.437030\tBest loss: 0.436381\tAccuracy: 89.60%\n",
      "361\tValidation loss: 0.436825\tBest loss: 0.436381\tAccuracy: 89.50%\n",
      "362\tValidation loss: 0.436926\tBest loss: 0.436381\tAccuracy: 89.40%\n",
      "363\tValidation loss: 0.434976\tBest loss: 0.434976\tAccuracy: 89.40%\n",
      "364\tValidation loss: 0.435058\tBest loss: 0.434976\tAccuracy: 89.30%\n",
      "365\tValidation loss: 0.436470\tBest loss: 0.434976\tAccuracy: 89.50%\n",
      "366\tValidation loss: 0.435074\tBest loss: 0.434976\tAccuracy: 89.40%\n",
      "367\tValidation loss: 0.435276\tBest loss: 0.434976\tAccuracy: 89.30%\n",
      "368\tValidation loss: 0.434508\tBest loss: 0.434508\tAccuracy: 89.30%\n",
      "369\tValidation loss: 0.433961\tBest loss: 0.433961\tAccuracy: 89.40%\n",
      "370\tValidation loss: 0.433877\tBest loss: 0.433877\tAccuracy: 89.80%\n",
      "371\tValidation loss: 0.434114\tBest loss: 0.433877\tAccuracy: 89.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\tValidation loss: 0.432985\tBest loss: 0.432985\tAccuracy: 89.40%\n",
      "373\tValidation loss: 0.433596\tBest loss: 0.432985\tAccuracy: 89.30%\n",
      "374\tValidation loss: 0.434543\tBest loss: 0.432985\tAccuracy: 89.40%\n",
      "375\tValidation loss: 0.432419\tBest loss: 0.432419\tAccuracy: 89.40%\n",
      "376\tValidation loss: 0.431326\tBest loss: 0.431326\tAccuracy: 89.30%\n",
      "377\tValidation loss: 0.431875\tBest loss: 0.431326\tAccuracy: 89.40%\n",
      "378\tValidation loss: 0.432105\tBest loss: 0.431326\tAccuracy: 89.80%\n",
      "379\tValidation loss: 0.432163\tBest loss: 0.431326\tAccuracy: 89.40%\n",
      "380\tValidation loss: 0.431831\tBest loss: 0.431326\tAccuracy: 89.70%\n",
      "381\tValidation loss: 0.431988\tBest loss: 0.431326\tAccuracy: 89.40%\n",
      "382\tValidation loss: 0.430260\tBest loss: 0.430260\tAccuracy: 89.40%\n",
      "383\tValidation loss: 0.430904\tBest loss: 0.430260\tAccuracy: 89.30%\n",
      "384\tValidation loss: 0.429557\tBest loss: 0.429557\tAccuracy: 89.70%\n",
      "385\tValidation loss: 0.430630\tBest loss: 0.429557\tAccuracy: 89.90%\n",
      "386\tValidation loss: 0.430023\tBest loss: 0.429557\tAccuracy: 89.50%\n",
      "387\tValidation loss: 0.429843\tBest loss: 0.429557\tAccuracy: 89.60%\n",
      "388\tValidation loss: 0.427754\tBest loss: 0.427754\tAccuracy: 89.50%\n",
      "389\tValidation loss: 0.430145\tBest loss: 0.427754\tAccuracy: 89.30%\n",
      "390\tValidation loss: 0.429739\tBest loss: 0.427754\tAccuracy: 89.70%\n",
      "391\tValidation loss: 0.428474\tBest loss: 0.427754\tAccuracy: 89.60%\n",
      "392\tValidation loss: 0.429307\tBest loss: 0.427754\tAccuracy: 89.70%\n",
      "393\tValidation loss: 0.427381\tBest loss: 0.427381\tAccuracy: 89.80%\n",
      "394\tValidation loss: 0.427905\tBest loss: 0.427381\tAccuracy: 89.70%\n",
      "395\tValidation loss: 0.426933\tBest loss: 0.426933\tAccuracy: 89.60%\n",
      "396\tValidation loss: 0.428002\tBest loss: 0.426933\tAccuracy: 89.80%\n",
      "397\tValidation loss: 0.428201\tBest loss: 0.426933\tAccuracy: 89.90%\n",
      "398\tValidation loss: 0.426458\tBest loss: 0.426458\tAccuracy: 90.10%\n",
      "399\tValidation loss: 0.426600\tBest loss: 0.426458\tAccuracy: 89.80%\n",
      "400\tValidation loss: 0.427383\tBest loss: 0.426458\tAccuracy: 89.50%\n",
      "401\tValidation loss: 0.426526\tBest loss: 0.426458\tAccuracy: 90.00%\n",
      "402\tValidation loss: 0.425433\tBest loss: 0.425433\tAccuracy: 90.00%\n",
      "403\tValidation loss: 0.425692\tBest loss: 0.425433\tAccuracy: 89.80%\n",
      "404\tValidation loss: 0.425030\tBest loss: 0.425030\tAccuracy: 89.80%\n",
      "405\tValidation loss: 0.425241\tBest loss: 0.425030\tAccuracy: 89.80%\n",
      "406\tValidation loss: 0.425997\tBest loss: 0.425030\tAccuracy: 89.50%\n",
      "407\tValidation loss: 0.425797\tBest loss: 0.425030\tAccuracy: 89.80%\n",
      "408\tValidation loss: 0.424603\tBest loss: 0.424603\tAccuracy: 89.30%\n",
      "409\tValidation loss: 0.423090\tBest loss: 0.423090\tAccuracy: 89.90%\n",
      "410\tValidation loss: 0.423371\tBest loss: 0.423090\tAccuracy: 89.80%\n",
      "411\tValidation loss: 0.423488\tBest loss: 0.423090\tAccuracy: 90.10%\n",
      "412\tValidation loss: 0.424321\tBest loss: 0.423090\tAccuracy: 89.50%\n",
      "413\tValidation loss: 0.421932\tBest loss: 0.421932\tAccuracy: 89.40%\n",
      "414\tValidation loss: 0.422759\tBest loss: 0.421932\tAccuracy: 89.90%\n",
      "415\tValidation loss: 0.421339\tBest loss: 0.421339\tAccuracy: 89.90%\n",
      "416\tValidation loss: 0.422529\tBest loss: 0.421339\tAccuracy: 90.00%\n",
      "417\tValidation loss: 0.421770\tBest loss: 0.421339\tAccuracy: 89.70%\n",
      "418\tValidation loss: 0.422660\tBest loss: 0.421339\tAccuracy: 89.60%\n",
      "419\tValidation loss: 0.420899\tBest loss: 0.420899\tAccuracy: 89.60%\n",
      "420\tValidation loss: 0.421210\tBest loss: 0.420899\tAccuracy: 89.80%\n",
      "421\tValidation loss: 0.421340\tBest loss: 0.420899\tAccuracy: 90.00%\n",
      "422\tValidation loss: 0.421236\tBest loss: 0.420899\tAccuracy: 89.70%\n",
      "423\tValidation loss: 0.420973\tBest loss: 0.420899\tAccuracy: 89.60%\n",
      "424\tValidation loss: 0.419824\tBest loss: 0.419824\tAccuracy: 90.00%\n",
      "425\tValidation loss: 0.419500\tBest loss: 0.419500\tAccuracy: 89.80%\n",
      "426\tValidation loss: 0.420414\tBest loss: 0.419500\tAccuracy: 89.80%\n",
      "427\tValidation loss: 0.420652\tBest loss: 0.419500\tAccuracy: 90.00%\n",
      "428\tValidation loss: 0.419147\tBest loss: 0.419147\tAccuracy: 89.90%\n",
      "429\tValidation loss: 0.420799\tBest loss: 0.419147\tAccuracy: 90.10%\n",
      "430\tValidation loss: 0.420180\tBest loss: 0.419147\tAccuracy: 89.90%\n",
      "431\tValidation loss: 0.420451\tBest loss: 0.419147\tAccuracy: 89.90%\n",
      "432\tValidation loss: 0.420100\tBest loss: 0.419147\tAccuracy: 90.10%\n",
      "433\tValidation loss: 0.418954\tBest loss: 0.418954\tAccuracy: 90.00%\n",
      "434\tValidation loss: 0.419817\tBest loss: 0.418954\tAccuracy: 89.90%\n",
      "435\tValidation loss: 0.418000\tBest loss: 0.418000\tAccuracy: 89.90%\n",
      "436\tValidation loss: 0.418511\tBest loss: 0.418000\tAccuracy: 90.00%\n",
      "437\tValidation loss: 0.417659\tBest loss: 0.417659\tAccuracy: 89.90%\n",
      "438\tValidation loss: 0.417995\tBest loss: 0.417659\tAccuracy: 90.00%\n",
      "439\tValidation loss: 0.418054\tBest loss: 0.417659\tAccuracy: 89.90%\n",
      "440\tValidation loss: 0.417824\tBest loss: 0.417659\tAccuracy: 90.00%\n",
      "441\tValidation loss: 0.417026\tBest loss: 0.417026\tAccuracy: 90.00%\n",
      "442\tValidation loss: 0.417366\tBest loss: 0.417026\tAccuracy: 89.50%\n",
      "443\tValidation loss: 0.417245\tBest loss: 0.417026\tAccuracy: 90.10%\n",
      "444\tValidation loss: 0.417105\tBest loss: 0.417026\tAccuracy: 89.80%\n",
      "445\tValidation loss: 0.416801\tBest loss: 0.416801\tAccuracy: 89.90%\n",
      "446\tValidation loss: 0.415639\tBest loss: 0.415639\tAccuracy: 90.00%\n",
      "447\tValidation loss: 0.417322\tBest loss: 0.415639\tAccuracy: 90.10%\n",
      "448\tValidation loss: 0.416289\tBest loss: 0.415639\tAccuracy: 89.90%\n",
      "449\tValidation loss: 0.415066\tBest loss: 0.415066\tAccuracy: 90.10%\n",
      "450\tValidation loss: 0.415685\tBest loss: 0.415066\tAccuracy: 90.00%\n",
      "451\tValidation loss: 0.415141\tBest loss: 0.415066\tAccuracy: 89.90%\n",
      "452\tValidation loss: 0.415182\tBest loss: 0.415066\tAccuracy: 90.00%\n",
      "453\tValidation loss: 0.414942\tBest loss: 0.414942\tAccuracy: 90.10%\n",
      "454\tValidation loss: 0.415130\tBest loss: 0.414942\tAccuracy: 89.90%\n",
      "455\tValidation loss: 0.414506\tBest loss: 0.414506\tAccuracy: 90.00%\n",
      "456\tValidation loss: 0.413709\tBest loss: 0.413709\tAccuracy: 89.90%\n",
      "457\tValidation loss: 0.413320\tBest loss: 0.413320\tAccuracy: 89.80%\n",
      "458\tValidation loss: 0.412623\tBest loss: 0.412623\tAccuracy: 90.00%\n",
      "459\tValidation loss: 0.413191\tBest loss: 0.412623\tAccuracy: 90.10%\n",
      "460\tValidation loss: 0.413103\tBest loss: 0.412623\tAccuracy: 90.00%\n",
      "461\tValidation loss: 0.413498\tBest loss: 0.412623\tAccuracy: 90.30%\n",
      "462\tValidation loss: 0.413162\tBest loss: 0.412623\tAccuracy: 90.10%\n",
      "463\tValidation loss: 0.413129\tBest loss: 0.412623\tAccuracy: 90.20%\n",
      "464\tValidation loss: 0.412228\tBest loss: 0.412228\tAccuracy: 90.20%\n",
      "465\tValidation loss: 0.412227\tBest loss: 0.412227\tAccuracy: 90.10%\n",
      "466\tValidation loss: 0.412601\tBest loss: 0.412227\tAccuracy: 90.20%\n",
      "467\tValidation loss: 0.410920\tBest loss: 0.410920\tAccuracy: 90.20%\n",
      "468\tValidation loss: 0.411827\tBest loss: 0.410920\tAccuracy: 90.10%\n",
      "469\tValidation loss: 0.410916\tBest loss: 0.410916\tAccuracy: 90.10%\n",
      "470\tValidation loss: 0.411208\tBest loss: 0.410916\tAccuracy: 90.10%\n",
      "471\tValidation loss: 0.412700\tBest loss: 0.410916\tAccuracy: 90.00%\n",
      "472\tValidation loss: 0.411785\tBest loss: 0.410916\tAccuracy: 90.10%\n",
      "473\tValidation loss: 0.411053\tBest loss: 0.410916\tAccuracy: 90.10%\n",
      "474\tValidation loss: 0.412092\tBest loss: 0.410916\tAccuracy: 90.30%\n",
      "475\tValidation loss: 0.410657\tBest loss: 0.410657\tAccuracy: 90.20%\n",
      "476\tValidation loss: 0.410887\tBest loss: 0.410657\tAccuracy: 90.10%\n",
      "477\tValidation loss: 0.410859\tBest loss: 0.410657\tAccuracy: 90.20%\n",
      "478\tValidation loss: 0.411432\tBest loss: 0.410657\tAccuracy: 90.20%\n",
      "479\tValidation loss: 0.409900\tBest loss: 0.409900\tAccuracy: 90.20%\n",
      "480\tValidation loss: 0.411106\tBest loss: 0.409900\tAccuracy: 90.30%\n",
      "481\tValidation loss: 0.410124\tBest loss: 0.409900\tAccuracy: 90.30%\n",
      "482\tValidation loss: 0.409833\tBest loss: 0.409833\tAccuracy: 90.30%\n",
      "483\tValidation loss: 0.409112\tBest loss: 0.409112\tAccuracy: 90.30%\n",
      "484\tValidation loss: 0.408412\tBest loss: 0.408412\tAccuracy: 90.20%\n",
      "485\tValidation loss: 0.408512\tBest loss: 0.408412\tAccuracy: 90.30%\n",
      "486\tValidation loss: 0.408985\tBest loss: 0.408412\tAccuracy: 90.30%\n",
      "487\tValidation loss: 0.407810\tBest loss: 0.407810\tAccuracy: 90.30%\n",
      "488\tValidation loss: 0.409118\tBest loss: 0.407810\tAccuracy: 90.30%\n",
      "489\tValidation loss: 0.408399\tBest loss: 0.407810\tAccuracy: 90.30%\n",
      "490\tValidation loss: 0.408743\tBest loss: 0.407810\tAccuracy: 90.20%\n",
      "491\tValidation loss: 0.407038\tBest loss: 0.407038\tAccuracy: 90.30%\n",
      "492\tValidation loss: 0.406028\tBest loss: 0.406028\tAccuracy: 90.40%\n",
      "493\tValidation loss: 0.407993\tBest loss: 0.406028\tAccuracy: 90.10%\n",
      "494\tValidation loss: 0.407210\tBest loss: 0.406028\tAccuracy: 90.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\tValidation loss: 0.407004\tBest loss: 0.406028\tAccuracy: 90.30%\n",
      "496\tValidation loss: 0.407092\tBest loss: 0.406028\tAccuracy: 90.30%\n",
      "497\tValidation loss: 0.405958\tBest loss: 0.405958\tAccuracy: 90.30%\n",
      "498\tValidation loss: 0.407422\tBest loss: 0.405958\tAccuracy: 90.40%\n",
      "499\tValidation loss: 0.407009\tBest loss: 0.405958\tAccuracy: 90.40%\n",
      "500\tValidation loss: 0.406226\tBest loss: 0.405958\tAccuracy: 90.40%\n",
      "501\tValidation loss: 0.406557\tBest loss: 0.405958\tAccuracy: 90.30%\n",
      "502\tValidation loss: 0.406230\tBest loss: 0.405958\tAccuracy: 90.50%\n",
      "503\tValidation loss: 0.405268\tBest loss: 0.405268\tAccuracy: 90.40%\n",
      "504\tValidation loss: 0.405010\tBest loss: 0.405010\tAccuracy: 90.40%\n",
      "505\tValidation loss: 0.405149\tBest loss: 0.405010\tAccuracy: 90.50%\n",
      "506\tValidation loss: 0.405244\tBest loss: 0.405010\tAccuracy: 90.40%\n",
      "507\tValidation loss: 0.404554\tBest loss: 0.404554\tAccuracy: 90.40%\n",
      "508\tValidation loss: 0.405254\tBest loss: 0.404554\tAccuracy: 90.30%\n",
      "509\tValidation loss: 0.404522\tBest loss: 0.404522\tAccuracy: 90.40%\n",
      "510\tValidation loss: 0.403807\tBest loss: 0.403807\tAccuracy: 90.40%\n",
      "511\tValidation loss: 0.404563\tBest loss: 0.403807\tAccuracy: 90.40%\n",
      "512\tValidation loss: 0.403257\tBest loss: 0.403257\tAccuracy: 90.40%\n",
      "513\tValidation loss: 0.403799\tBest loss: 0.403257\tAccuracy: 90.30%\n",
      "514\tValidation loss: 0.403776\tBest loss: 0.403257\tAccuracy: 90.30%\n",
      "515\tValidation loss: 0.403897\tBest loss: 0.403257\tAccuracy: 90.30%\n",
      "516\tValidation loss: 0.401807\tBest loss: 0.401807\tAccuracy: 90.60%\n",
      "517\tValidation loss: 0.402210\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "518\tValidation loss: 0.403724\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "519\tValidation loss: 0.403125\tBest loss: 0.401807\tAccuracy: 90.30%\n",
      "520\tValidation loss: 0.403815\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "521\tValidation loss: 0.402460\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "522\tValidation loss: 0.402143\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "523\tValidation loss: 0.402803\tBest loss: 0.401807\tAccuracy: 90.40%\n",
      "524\tValidation loss: 0.402428\tBest loss: 0.401807\tAccuracy: 90.60%\n",
      "525\tValidation loss: 0.402279\tBest loss: 0.401807\tAccuracy: 90.50%\n",
      "526\tValidation loss: 0.401812\tBest loss: 0.401807\tAccuracy: 90.40%\n",
      "527\tValidation loss: 0.401726\tBest loss: 0.401726\tAccuracy: 90.50%\n",
      "528\tValidation loss: 0.401590\tBest loss: 0.401590\tAccuracy: 90.50%\n",
      "529\tValidation loss: 0.400585\tBest loss: 0.400585\tAccuracy: 90.70%\n",
      "530\tValidation loss: 0.401581\tBest loss: 0.400585\tAccuracy: 90.40%\n",
      "531\tValidation loss: 0.401443\tBest loss: 0.400585\tAccuracy: 90.30%\n",
      "532\tValidation loss: 0.401377\tBest loss: 0.400585\tAccuracy: 90.70%\n",
      "533\tValidation loss: 0.400115\tBest loss: 0.400115\tAccuracy: 90.50%\n",
      "534\tValidation loss: 0.400075\tBest loss: 0.400075\tAccuracy: 90.50%\n",
      "535\tValidation loss: 0.400381\tBest loss: 0.400075\tAccuracy: 90.50%\n",
      "536\tValidation loss: 0.399963\tBest loss: 0.399963\tAccuracy: 90.50%\n",
      "537\tValidation loss: 0.400904\tBest loss: 0.399963\tAccuracy: 90.60%\n",
      "538\tValidation loss: 0.399766\tBest loss: 0.399766\tAccuracy: 90.50%\n",
      "539\tValidation loss: 0.399906\tBest loss: 0.399766\tAccuracy: 90.80%\n",
      "540\tValidation loss: 0.398768\tBest loss: 0.398768\tAccuracy: 90.60%\n",
      "541\tValidation loss: 0.399356\tBest loss: 0.398768\tAccuracy: 90.50%\n",
      "542\tValidation loss: 0.400081\tBest loss: 0.398768\tAccuracy: 90.40%\n",
      "543\tValidation loss: 0.399678\tBest loss: 0.398768\tAccuracy: 90.70%\n",
      "544\tValidation loss: 0.399714\tBest loss: 0.398768\tAccuracy: 90.60%\n",
      "545\tValidation loss: 0.397411\tBest loss: 0.397411\tAccuracy: 90.70%\n",
      "546\tValidation loss: 0.399500\tBest loss: 0.397411\tAccuracy: 90.50%\n",
      "547\tValidation loss: 0.397821\tBest loss: 0.397411\tAccuracy: 90.80%\n",
      "548\tValidation loss: 0.399184\tBest loss: 0.397411\tAccuracy: 90.60%\n",
      "549\tValidation loss: 0.400380\tBest loss: 0.397411\tAccuracy: 90.70%\n",
      "550\tValidation loss: 0.397219\tBest loss: 0.397219\tAccuracy: 90.70%\n",
      "551\tValidation loss: 0.399107\tBest loss: 0.397219\tAccuracy: 90.80%\n",
      "552\tValidation loss: 0.397665\tBest loss: 0.397219\tAccuracy: 90.60%\n",
      "553\tValidation loss: 0.396357\tBest loss: 0.396357\tAccuracy: 90.90%\n",
      "554\tValidation loss: 0.397750\tBest loss: 0.396357\tAccuracy: 90.60%\n",
      "555\tValidation loss: 0.397019\tBest loss: 0.396357\tAccuracy: 90.60%\n",
      "556\tValidation loss: 0.397404\tBest loss: 0.396357\tAccuracy: 90.50%\n",
      "557\tValidation loss: 0.397800\tBest loss: 0.396357\tAccuracy: 90.60%\n",
      "558\tValidation loss: 0.397323\tBest loss: 0.396357\tAccuracy: 90.60%\n",
      "559\tValidation loss: 0.397474\tBest loss: 0.396357\tAccuracy: 90.80%\n",
      "560\tValidation loss: 0.397466\tBest loss: 0.396357\tAccuracy: 90.70%\n",
      "561\tValidation loss: 0.396512\tBest loss: 0.396357\tAccuracy: 90.60%\n",
      "562\tValidation loss: 0.396204\tBest loss: 0.396204\tAccuracy: 90.80%\n",
      "563\tValidation loss: 0.396356\tBest loss: 0.396204\tAccuracy: 90.80%\n",
      "564\tValidation loss: 0.396368\tBest loss: 0.396204\tAccuracy: 90.60%\n",
      "565\tValidation loss: 0.396210\tBest loss: 0.396204\tAccuracy: 90.50%\n",
      "566\tValidation loss: 0.395832\tBest loss: 0.395832\tAccuracy: 90.80%\n",
      "567\tValidation loss: 0.395146\tBest loss: 0.395146\tAccuracy: 90.80%\n",
      "568\tValidation loss: 0.395553\tBest loss: 0.395146\tAccuracy: 90.50%\n",
      "569\tValidation loss: 0.396154\tBest loss: 0.395146\tAccuracy: 90.50%\n",
      "570\tValidation loss: 0.395036\tBest loss: 0.395036\tAccuracy: 90.70%\n",
      "571\tValidation loss: 0.394417\tBest loss: 0.394417\tAccuracy: 91.00%\n",
      "572\tValidation loss: 0.394232\tBest loss: 0.394232\tAccuracy: 90.80%\n",
      "573\tValidation loss: 0.393977\tBest loss: 0.393977\tAccuracy: 90.80%\n",
      "574\tValidation loss: 0.395928\tBest loss: 0.393977\tAccuracy: 90.60%\n",
      "575\tValidation loss: 0.395371\tBest loss: 0.393977\tAccuracy: 90.60%\n",
      "576\tValidation loss: 0.393756\tBest loss: 0.393756\tAccuracy: 90.80%\n",
      "577\tValidation loss: 0.393662\tBest loss: 0.393662\tAccuracy: 90.90%\n",
      "578\tValidation loss: 0.393956\tBest loss: 0.393662\tAccuracy: 91.00%\n",
      "579\tValidation loss: 0.393396\tBest loss: 0.393396\tAccuracy: 90.80%\n",
      "580\tValidation loss: 0.393265\tBest loss: 0.393265\tAccuracy: 90.90%\n",
      "581\tValidation loss: 0.393918\tBest loss: 0.393265\tAccuracy: 91.00%\n",
      "582\tValidation loss: 0.394685\tBest loss: 0.393265\tAccuracy: 90.90%\n",
      "583\tValidation loss: 0.392525\tBest loss: 0.392525\tAccuracy: 91.20%\n",
      "584\tValidation loss: 0.394063\tBest loss: 0.392525\tAccuracy: 90.80%\n",
      "585\tValidation loss: 0.393356\tBest loss: 0.392525\tAccuracy: 90.90%\n",
      "586\tValidation loss: 0.393960\tBest loss: 0.392525\tAccuracy: 91.00%\n",
      "587\tValidation loss: 0.393106\tBest loss: 0.392525\tAccuracy: 90.90%\n",
      "588\tValidation loss: 0.394029\tBest loss: 0.392525\tAccuracy: 90.90%\n",
      "589\tValidation loss: 0.392917\tBest loss: 0.392525\tAccuracy: 90.80%\n",
      "590\tValidation loss: 0.392486\tBest loss: 0.392486\tAccuracy: 90.80%\n",
      "591\tValidation loss: 0.392094\tBest loss: 0.392094\tAccuracy: 91.20%\n",
      "592\tValidation loss: 0.392405\tBest loss: 0.392094\tAccuracy: 90.90%\n",
      "593\tValidation loss: 0.393138\tBest loss: 0.392094\tAccuracy: 91.00%\n",
      "594\tValidation loss: 0.391800\tBest loss: 0.391800\tAccuracy: 90.90%\n",
      "595\tValidation loss: 0.392000\tBest loss: 0.391800\tAccuracy: 90.80%\n",
      "596\tValidation loss: 0.391310\tBest loss: 0.391310\tAccuracy: 91.00%\n",
      "597\tValidation loss: 0.391052\tBest loss: 0.391052\tAccuracy: 91.00%\n",
      "598\tValidation loss: 0.391181\tBest loss: 0.391052\tAccuracy: 90.80%\n",
      "599\tValidation loss: 0.390884\tBest loss: 0.390884\tAccuracy: 90.90%\n",
      "600\tValidation loss: 0.391473\tBest loss: 0.390884\tAccuracy: 91.20%\n",
      "601\tValidation loss: 0.391175\tBest loss: 0.390884\tAccuracy: 91.20%\n",
      "602\tValidation loss: 0.391438\tBest loss: 0.390884\tAccuracy: 91.00%\n",
      "603\tValidation loss: 0.390046\tBest loss: 0.390046\tAccuracy: 91.00%\n",
      "604\tValidation loss: 0.391570\tBest loss: 0.390046\tAccuracy: 91.20%\n",
      "605\tValidation loss: 0.391944\tBest loss: 0.390046\tAccuracy: 91.00%\n",
      "606\tValidation loss: 0.390827\tBest loss: 0.390046\tAccuracy: 91.20%\n",
      "607\tValidation loss: 0.391141\tBest loss: 0.390046\tAccuracy: 91.10%\n",
      "608\tValidation loss: 0.390858\tBest loss: 0.390046\tAccuracy: 91.00%\n",
      "609\tValidation loss: 0.390486\tBest loss: 0.390046\tAccuracy: 90.80%\n",
      "610\tValidation loss: 0.389750\tBest loss: 0.389750\tAccuracy: 91.10%\n",
      "611\tValidation loss: 0.390407\tBest loss: 0.389750\tAccuracy: 91.20%\n",
      "612\tValidation loss: 0.390395\tBest loss: 0.389750\tAccuracy: 91.00%\n",
      "613\tValidation loss: 0.389909\tBest loss: 0.389750\tAccuracy: 91.10%\n",
      "614\tValidation loss: 0.389580\tBest loss: 0.389580\tAccuracy: 91.10%\n",
      "615\tValidation loss: 0.389098\tBest loss: 0.389098\tAccuracy: 91.20%\n",
      "616\tValidation loss: 0.390310\tBest loss: 0.389098\tAccuracy: 91.30%\n",
      "617\tValidation loss: 0.390263\tBest loss: 0.389098\tAccuracy: 91.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618\tValidation loss: 0.388542\tBest loss: 0.388542\tAccuracy: 91.10%\n",
      "619\tValidation loss: 0.388545\tBest loss: 0.388542\tAccuracy: 91.00%\n",
      "620\tValidation loss: 0.388585\tBest loss: 0.388542\tAccuracy: 91.10%\n",
      "621\tValidation loss: 0.387692\tBest loss: 0.387692\tAccuracy: 91.10%\n",
      "622\tValidation loss: 0.389100\tBest loss: 0.387692\tAccuracy: 91.00%\n",
      "623\tValidation loss: 0.387582\tBest loss: 0.387582\tAccuracy: 91.10%\n",
      "624\tValidation loss: 0.389017\tBest loss: 0.387582\tAccuracy: 91.10%\n",
      "625\tValidation loss: 0.388180\tBest loss: 0.387582\tAccuracy: 91.30%\n",
      "626\tValidation loss: 0.387383\tBest loss: 0.387383\tAccuracy: 91.30%\n",
      "627\tValidation loss: 0.387822\tBest loss: 0.387383\tAccuracy: 91.10%\n",
      "628\tValidation loss: 0.387488\tBest loss: 0.387383\tAccuracy: 91.30%\n",
      "629\tValidation loss: 0.387052\tBest loss: 0.387052\tAccuracy: 91.10%\n",
      "630\tValidation loss: 0.386059\tBest loss: 0.386059\tAccuracy: 91.40%\n",
      "631\tValidation loss: 0.387234\tBest loss: 0.386059\tAccuracy: 91.20%\n",
      "632\tValidation loss: 0.387004\tBest loss: 0.386059\tAccuracy: 91.50%\n",
      "633\tValidation loss: 0.387532\tBest loss: 0.386059\tAccuracy: 91.30%\n",
      "634\tValidation loss: 0.387072\tBest loss: 0.386059\tAccuracy: 91.30%\n",
      "635\tValidation loss: 0.387318\tBest loss: 0.386059\tAccuracy: 91.50%\n",
      "636\tValidation loss: 0.386253\tBest loss: 0.386059\tAccuracy: 91.30%\n",
      "637\tValidation loss: 0.386679\tBest loss: 0.386059\tAccuracy: 91.20%\n",
      "638\tValidation loss: 0.386072\tBest loss: 0.386059\tAccuracy: 91.40%\n",
      "639\tValidation loss: 0.386181\tBest loss: 0.386059\tAccuracy: 91.20%\n",
      "640\tValidation loss: 0.385333\tBest loss: 0.385333\tAccuracy: 91.50%\n",
      "641\tValidation loss: 0.386282\tBest loss: 0.385333\tAccuracy: 91.30%\n",
      "642\tValidation loss: 0.386259\tBest loss: 0.385333\tAccuracy: 91.20%\n",
      "643\tValidation loss: 0.384339\tBest loss: 0.384339\tAccuracy: 91.30%\n",
      "644\tValidation loss: 0.385354\tBest loss: 0.384339\tAccuracy: 91.30%\n",
      "645\tValidation loss: 0.385586\tBest loss: 0.384339\tAccuracy: 91.40%\n",
      "646\tValidation loss: 0.385471\tBest loss: 0.384339\tAccuracy: 91.40%\n",
      "647\tValidation loss: 0.384601\tBest loss: 0.384339\tAccuracy: 91.40%\n",
      "648\tValidation loss: 0.385226\tBest loss: 0.384339\tAccuracy: 91.20%\n",
      "649\tValidation loss: 0.384542\tBest loss: 0.384339\tAccuracy: 91.20%\n",
      "650\tValidation loss: 0.384396\tBest loss: 0.384339\tAccuracy: 91.30%\n",
      "651\tValidation loss: 0.383902\tBest loss: 0.383902\tAccuracy: 91.60%\n",
      "652\tValidation loss: 0.384704\tBest loss: 0.383902\tAccuracy: 91.30%\n",
      "653\tValidation loss: 0.384906\tBest loss: 0.383902\tAccuracy: 91.40%\n",
      "654\tValidation loss: 0.385668\tBest loss: 0.383902\tAccuracy: 91.40%\n",
      "655\tValidation loss: 0.382978\tBest loss: 0.382978\tAccuracy: 91.50%\n",
      "656\tValidation loss: 0.384132\tBest loss: 0.382978\tAccuracy: 91.50%\n",
      "657\tValidation loss: 0.384248\tBest loss: 0.382978\tAccuracy: 91.20%\n",
      "658\tValidation loss: 0.384381\tBest loss: 0.382978\tAccuracy: 91.40%\n",
      "659\tValidation loss: 0.384151\tBest loss: 0.382978\tAccuracy: 91.30%\n",
      "660\tValidation loss: 0.384357\tBest loss: 0.382978\tAccuracy: 91.50%\n",
      "661\tValidation loss: 0.383153\tBest loss: 0.382978\tAccuracy: 91.50%\n",
      "662\tValidation loss: 0.382784\tBest loss: 0.382784\tAccuracy: 91.70%\n",
      "663\tValidation loss: 0.382679\tBest loss: 0.382679\tAccuracy: 91.30%\n",
      "664\tValidation loss: 0.382285\tBest loss: 0.382285\tAccuracy: 91.80%\n",
      "665\tValidation loss: 0.383120\tBest loss: 0.382285\tAccuracy: 91.50%\n",
      "666\tValidation loss: 0.383339\tBest loss: 0.382285\tAccuracy: 91.40%\n",
      "667\tValidation loss: 0.384012\tBest loss: 0.382285\tAccuracy: 91.60%\n",
      "668\tValidation loss: 0.382792\tBest loss: 0.382285\tAccuracy: 91.70%\n",
      "669\tValidation loss: 0.382604\tBest loss: 0.382285\tAccuracy: 91.40%\n",
      "670\tValidation loss: 0.382525\tBest loss: 0.382285\tAccuracy: 91.60%\n",
      "671\tValidation loss: 0.382805\tBest loss: 0.382285\tAccuracy: 91.50%\n",
      "672\tValidation loss: 0.381654\tBest loss: 0.381654\tAccuracy: 91.40%\n",
      "673\tValidation loss: 0.382194\tBest loss: 0.381654\tAccuracy: 91.50%\n",
      "674\tValidation loss: 0.382136\tBest loss: 0.381654\tAccuracy: 91.70%\n",
      "675\tValidation loss: 0.381455\tBest loss: 0.381455\tAccuracy: 91.80%\n",
      "676\tValidation loss: 0.382487\tBest loss: 0.381455\tAccuracy: 91.50%\n",
      "677\tValidation loss: 0.382261\tBest loss: 0.381455\tAccuracy: 91.70%\n",
      "678\tValidation loss: 0.382041\tBest loss: 0.381455\tAccuracy: 91.80%\n",
      "679\tValidation loss: 0.381811\tBest loss: 0.381455\tAccuracy: 91.70%\n",
      "680\tValidation loss: 0.381399\tBest loss: 0.381399\tAccuracy: 91.60%\n",
      "681\tValidation loss: 0.381552\tBest loss: 0.381399\tAccuracy: 91.30%\n",
      "682\tValidation loss: 0.381004\tBest loss: 0.381004\tAccuracy: 91.50%\n",
      "683\tValidation loss: 0.380775\tBest loss: 0.380775\tAccuracy: 91.60%\n",
      "684\tValidation loss: 0.380642\tBest loss: 0.380642\tAccuracy: 91.40%\n",
      "685\tValidation loss: 0.381477\tBest loss: 0.380642\tAccuracy: 91.50%\n",
      "686\tValidation loss: 0.380507\tBest loss: 0.380507\tAccuracy: 91.60%\n",
      "687\tValidation loss: 0.380492\tBest loss: 0.380492\tAccuracy: 91.60%\n",
      "688\tValidation loss: 0.380538\tBest loss: 0.380492\tAccuracy: 91.80%\n",
      "689\tValidation loss: 0.379805\tBest loss: 0.379805\tAccuracy: 91.70%\n",
      "690\tValidation loss: 0.380874\tBest loss: 0.379805\tAccuracy: 91.60%\n",
      "691\tValidation loss: 0.379774\tBest loss: 0.379774\tAccuracy: 91.70%\n",
      "692\tValidation loss: 0.380254\tBest loss: 0.379774\tAccuracy: 91.60%\n",
      "693\tValidation loss: 0.380249\tBest loss: 0.379774\tAccuracy: 91.60%\n",
      "694\tValidation loss: 0.380023\tBest loss: 0.379774\tAccuracy: 91.50%\n",
      "695\tValidation loss: 0.379373\tBest loss: 0.379373\tAccuracy: 91.60%\n",
      "696\tValidation loss: 0.379836\tBest loss: 0.379373\tAccuracy: 91.50%\n",
      "697\tValidation loss: 0.378913\tBest loss: 0.378913\tAccuracy: 91.70%\n",
      "698\tValidation loss: 0.378892\tBest loss: 0.378892\tAccuracy: 91.70%\n",
      "699\tValidation loss: 0.378214\tBest loss: 0.378214\tAccuracy: 91.60%\n",
      "700\tValidation loss: 0.378861\tBest loss: 0.378214\tAccuracy: 91.60%\n",
      "701\tValidation loss: 0.379012\tBest loss: 0.378214\tAccuracy: 91.40%\n",
      "702\tValidation loss: 0.379550\tBest loss: 0.378214\tAccuracy: 91.50%\n",
      "703\tValidation loss: 0.378131\tBest loss: 0.378131\tAccuracy: 91.80%\n",
      "704\tValidation loss: 0.378399\tBest loss: 0.378131\tAccuracy: 91.70%\n",
      "705\tValidation loss: 0.378814\tBest loss: 0.378131\tAccuracy: 91.60%\n",
      "706\tValidation loss: 0.378208\tBest loss: 0.378131\tAccuracy: 91.60%\n",
      "707\tValidation loss: 0.378723\tBest loss: 0.378131\tAccuracy: 91.80%\n",
      "708\tValidation loss: 0.378623\tBest loss: 0.378131\tAccuracy: 91.60%\n",
      "709\tValidation loss: 0.378119\tBest loss: 0.378119\tAccuracy: 91.80%\n",
      "710\tValidation loss: 0.378262\tBest loss: 0.378119\tAccuracy: 91.60%\n",
      "711\tValidation loss: 0.378289\tBest loss: 0.378119\tAccuracy: 91.90%\n",
      "712\tValidation loss: 0.377960\tBest loss: 0.377960\tAccuracy: 91.70%\n",
      "713\tValidation loss: 0.376846\tBest loss: 0.376846\tAccuracy: 91.80%\n",
      "714\tValidation loss: 0.376556\tBest loss: 0.376556\tAccuracy: 91.80%\n",
      "715\tValidation loss: 0.377651\tBest loss: 0.376556\tAccuracy: 91.80%\n",
      "716\tValidation loss: 0.376951\tBest loss: 0.376556\tAccuracy: 91.90%\n",
      "717\tValidation loss: 0.377931\tBest loss: 0.376556\tAccuracy: 91.60%\n",
      "718\tValidation loss: 0.376878\tBest loss: 0.376556\tAccuracy: 91.90%\n",
      "719\tValidation loss: 0.376385\tBest loss: 0.376385\tAccuracy: 91.70%\n",
      "720\tValidation loss: 0.377148\tBest loss: 0.376385\tAccuracy: 91.80%\n",
      "721\tValidation loss: 0.377134\tBest loss: 0.376385\tAccuracy: 91.80%\n",
      "722\tValidation loss: 0.376516\tBest loss: 0.376385\tAccuracy: 91.70%\n",
      "723\tValidation loss: 0.376867\tBest loss: 0.376385\tAccuracy: 91.80%\n",
      "724\tValidation loss: 0.376541\tBest loss: 0.376385\tAccuracy: 91.80%\n",
      "725\tValidation loss: 0.375357\tBest loss: 0.375357\tAccuracy: 91.80%\n",
      "726\tValidation loss: 0.376090\tBest loss: 0.375357\tAccuracy: 91.80%\n",
      "727\tValidation loss: 0.376284\tBest loss: 0.375357\tAccuracy: 91.80%\n",
      "728\tValidation loss: 0.376167\tBest loss: 0.375357\tAccuracy: 91.90%\n",
      "729\tValidation loss: 0.375335\tBest loss: 0.375335\tAccuracy: 91.90%\n",
      "730\tValidation loss: 0.376296\tBest loss: 0.375335\tAccuracy: 91.80%\n",
      "731\tValidation loss: 0.376264\tBest loss: 0.375335\tAccuracy: 91.90%\n",
      "732\tValidation loss: 0.375953\tBest loss: 0.375335\tAccuracy: 91.60%\n",
      "733\tValidation loss: 0.376403\tBest loss: 0.375335\tAccuracy: 91.60%\n",
      "734\tValidation loss: 0.374971\tBest loss: 0.374971\tAccuracy: 92.00%\n",
      "735\tValidation loss: 0.374538\tBest loss: 0.374538\tAccuracy: 91.90%\n",
      "736\tValidation loss: 0.375342\tBest loss: 0.374538\tAccuracy: 91.80%\n",
      "737\tValidation loss: 0.375079\tBest loss: 0.374538\tAccuracy: 91.70%\n",
      "738\tValidation loss: 0.375780\tBest loss: 0.374538\tAccuracy: 91.70%\n",
      "739\tValidation loss: 0.374129\tBest loss: 0.374129\tAccuracy: 91.90%\n",
      "740\tValidation loss: 0.374919\tBest loss: 0.374129\tAccuracy: 91.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\tValidation loss: 0.374821\tBest loss: 0.374129\tAccuracy: 91.90%\n",
      "742\tValidation loss: 0.374562\tBest loss: 0.374129\tAccuracy: 91.80%\n",
      "743\tValidation loss: 0.374185\tBest loss: 0.374129\tAccuracy: 91.80%\n",
      "744\tValidation loss: 0.374164\tBest loss: 0.374129\tAccuracy: 91.80%\n",
      "745\tValidation loss: 0.374171\tBest loss: 0.374129\tAccuracy: 91.90%\n",
      "746\tValidation loss: 0.374043\tBest loss: 0.374043\tAccuracy: 92.10%\n",
      "747\tValidation loss: 0.374714\tBest loss: 0.374043\tAccuracy: 91.80%\n",
      "748\tValidation loss: 0.373500\tBest loss: 0.373500\tAccuracy: 91.80%\n",
      "749\tValidation loss: 0.373289\tBest loss: 0.373289\tAccuracy: 91.70%\n",
      "750\tValidation loss: 0.373458\tBest loss: 0.373289\tAccuracy: 91.90%\n",
      "751\tValidation loss: 0.373178\tBest loss: 0.373178\tAccuracy: 91.90%\n",
      "752\tValidation loss: 0.373036\tBest loss: 0.373036\tAccuracy: 91.90%\n",
      "753\tValidation loss: 0.373448\tBest loss: 0.373036\tAccuracy: 91.70%\n",
      "754\tValidation loss: 0.373732\tBest loss: 0.373036\tAccuracy: 91.80%\n",
      "755\tValidation loss: 0.373318\tBest loss: 0.373036\tAccuracy: 91.80%\n",
      "756\tValidation loss: 0.374733\tBest loss: 0.373036\tAccuracy: 91.90%\n",
      "757\tValidation loss: 0.373263\tBest loss: 0.373036\tAccuracy: 91.80%\n",
      "758\tValidation loss: 0.373102\tBest loss: 0.373036\tAccuracy: 92.10%\n",
      "759\tValidation loss: 0.372836\tBest loss: 0.372836\tAccuracy: 91.80%\n",
      "760\tValidation loss: 0.372871\tBest loss: 0.372836\tAccuracy: 91.80%\n",
      "761\tValidation loss: 0.372959\tBest loss: 0.372836\tAccuracy: 91.90%\n",
      "762\tValidation loss: 0.372210\tBest loss: 0.372210\tAccuracy: 92.00%\n",
      "763\tValidation loss: 0.371688\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "764\tValidation loss: 0.372848\tBest loss: 0.371688\tAccuracy: 91.90%\n",
      "765\tValidation loss: 0.372299\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "766\tValidation loss: 0.373334\tBest loss: 0.371688\tAccuracy: 91.70%\n",
      "767\tValidation loss: 0.372147\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "768\tValidation loss: 0.372358\tBest loss: 0.371688\tAccuracy: 91.90%\n",
      "769\tValidation loss: 0.371943\tBest loss: 0.371688\tAccuracy: 91.80%\n",
      "770\tValidation loss: 0.372056\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "771\tValidation loss: 0.372119\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "772\tValidation loss: 0.372441\tBest loss: 0.371688\tAccuracy: 92.00%\n",
      "773\tValidation loss: 0.371775\tBest loss: 0.371688\tAccuracy: 91.90%\n",
      "774\tValidation loss: 0.371175\tBest loss: 0.371175\tAccuracy: 91.90%\n",
      "775\tValidation loss: 0.371384\tBest loss: 0.371175\tAccuracy: 91.90%\n",
      "776\tValidation loss: 0.371583\tBest loss: 0.371175\tAccuracy: 92.00%\n",
      "777\tValidation loss: 0.370674\tBest loss: 0.370674\tAccuracy: 92.20%\n",
      "778\tValidation loss: 0.371169\tBest loss: 0.370674\tAccuracy: 92.00%\n",
      "779\tValidation loss: 0.371595\tBest loss: 0.370674\tAccuracy: 92.00%\n",
      "780\tValidation loss: 0.370971\tBest loss: 0.370674\tAccuracy: 92.00%\n",
      "781\tValidation loss: 0.370355\tBest loss: 0.370355\tAccuracy: 91.90%\n",
      "782\tValidation loss: 0.370018\tBest loss: 0.370018\tAccuracy: 92.00%\n",
      "783\tValidation loss: 0.369818\tBest loss: 0.369818\tAccuracy: 92.00%\n",
      "784\tValidation loss: 0.369807\tBest loss: 0.369807\tAccuracy: 92.00%\n",
      "785\tValidation loss: 0.370478\tBest loss: 0.369807\tAccuracy: 92.00%\n",
      "786\tValidation loss: 0.369321\tBest loss: 0.369321\tAccuracy: 91.90%\n",
      "787\tValidation loss: 0.369977\tBest loss: 0.369321\tAccuracy: 92.10%\n",
      "788\tValidation loss: 0.369925\tBest loss: 0.369321\tAccuracy: 92.10%\n",
      "789\tValidation loss: 0.370205\tBest loss: 0.369321\tAccuracy: 92.10%\n",
      "790\tValidation loss: 0.369703\tBest loss: 0.369321\tAccuracy: 92.00%\n",
      "791\tValidation loss: 0.369377\tBest loss: 0.369321\tAccuracy: 92.00%\n",
      "792\tValidation loss: 0.369621\tBest loss: 0.369321\tAccuracy: 92.10%\n",
      "793\tValidation loss: 0.369577\tBest loss: 0.369321\tAccuracy: 91.90%\n",
      "794\tValidation loss: 0.371132\tBest loss: 0.369321\tAccuracy: 92.00%\n",
      "795\tValidation loss: 0.369888\tBest loss: 0.369321\tAccuracy: 91.80%\n",
      "796\tValidation loss: 0.368906\tBest loss: 0.368906\tAccuracy: 91.90%\n",
      "797\tValidation loss: 0.369285\tBest loss: 0.368906\tAccuracy: 91.90%\n",
      "798\tValidation loss: 0.369003\tBest loss: 0.368906\tAccuracy: 92.20%\n",
      "799\tValidation loss: 0.369725\tBest loss: 0.368906\tAccuracy: 91.80%\n",
      "800\tValidation loss: 0.369114\tBest loss: 0.368906\tAccuracy: 92.10%\n",
      "801\tValidation loss: 0.368640\tBest loss: 0.368640\tAccuracy: 91.80%\n",
      "802\tValidation loss: 0.368666\tBest loss: 0.368640\tAccuracy: 92.10%\n",
      "803\tValidation loss: 0.367894\tBest loss: 0.367894\tAccuracy: 92.00%\n",
      "804\tValidation loss: 0.368905\tBest loss: 0.367894\tAccuracy: 92.00%\n",
      "805\tValidation loss: 0.367779\tBest loss: 0.367779\tAccuracy: 92.10%\n",
      "806\tValidation loss: 0.368986\tBest loss: 0.367779\tAccuracy: 91.90%\n",
      "807\tValidation loss: 0.369244\tBest loss: 0.367779\tAccuracy: 91.80%\n",
      "808\tValidation loss: 0.368214\tBest loss: 0.367779\tAccuracy: 91.90%\n",
      "809\tValidation loss: 0.368159\tBest loss: 0.367779\tAccuracy: 92.10%\n",
      "810\tValidation loss: 0.368304\tBest loss: 0.367779\tAccuracy: 92.10%\n",
      "811\tValidation loss: 0.367898\tBest loss: 0.367779\tAccuracy: 92.10%\n",
      "812\tValidation loss: 0.367764\tBest loss: 0.367764\tAccuracy: 91.90%\n",
      "813\tValidation loss: 0.368011\tBest loss: 0.367764\tAccuracy: 92.10%\n",
      "814\tValidation loss: 0.368501\tBest loss: 0.367764\tAccuracy: 92.00%\n",
      "815\tValidation loss: 0.367832\tBest loss: 0.367764\tAccuracy: 92.00%\n",
      "816\tValidation loss: 0.367828\tBest loss: 0.367764\tAccuracy: 92.20%\n",
      "817\tValidation loss: 0.368657\tBest loss: 0.367764\tAccuracy: 92.10%\n",
      "818\tValidation loss: 0.367304\tBest loss: 0.367304\tAccuracy: 92.20%\n",
      "819\tValidation loss: 0.367336\tBest loss: 0.367304\tAccuracy: 92.20%\n",
      "820\tValidation loss: 0.366965\tBest loss: 0.366965\tAccuracy: 92.20%\n",
      "821\tValidation loss: 0.367404\tBest loss: 0.366965\tAccuracy: 92.20%\n",
      "822\tValidation loss: 0.366828\tBest loss: 0.366828\tAccuracy: 92.20%\n",
      "823\tValidation loss: 0.366602\tBest loss: 0.366602\tAccuracy: 92.20%\n",
      "824\tValidation loss: 0.367049\tBest loss: 0.366602\tAccuracy: 92.20%\n",
      "825\tValidation loss: 0.367003\tBest loss: 0.366602\tAccuracy: 92.10%\n",
      "826\tValidation loss: 0.366248\tBest loss: 0.366248\tAccuracy: 92.20%\n",
      "827\tValidation loss: 0.366812\tBest loss: 0.366248\tAccuracy: 92.20%\n",
      "828\tValidation loss: 0.366806\tBest loss: 0.366248\tAccuracy: 92.10%\n",
      "829\tValidation loss: 0.366131\tBest loss: 0.366131\tAccuracy: 92.10%\n",
      "830\tValidation loss: 0.367027\tBest loss: 0.366131\tAccuracy: 92.10%\n",
      "831\tValidation loss: 0.365983\tBest loss: 0.365983\tAccuracy: 92.10%\n",
      "832\tValidation loss: 0.365832\tBest loss: 0.365832\tAccuracy: 92.20%\n",
      "833\tValidation loss: 0.366155\tBest loss: 0.365832\tAccuracy: 92.10%\n",
      "834\tValidation loss: 0.366193\tBest loss: 0.365832\tAccuracy: 92.10%\n",
      "835\tValidation loss: 0.365593\tBest loss: 0.365593\tAccuracy: 92.20%\n",
      "836\tValidation loss: 0.365314\tBest loss: 0.365314\tAccuracy: 92.10%\n",
      "837\tValidation loss: 0.365672\tBest loss: 0.365314\tAccuracy: 92.10%\n",
      "838\tValidation loss: 0.365887\tBest loss: 0.365314\tAccuracy: 92.10%\n",
      "839\tValidation loss: 0.365419\tBest loss: 0.365314\tAccuracy: 92.20%\n",
      "840\tValidation loss: 0.365399\tBest loss: 0.365314\tAccuracy: 92.10%\n",
      "841\tValidation loss: 0.366252\tBest loss: 0.365314\tAccuracy: 92.20%\n",
      "842\tValidation loss: 0.365815\tBest loss: 0.365314\tAccuracy: 92.10%\n",
      "843\tValidation loss: 0.365223\tBest loss: 0.365223\tAccuracy: 92.20%\n",
      "844\tValidation loss: 0.366419\tBest loss: 0.365223\tAccuracy: 92.00%\n",
      "845\tValidation loss: 0.365673\tBest loss: 0.365223\tAccuracy: 92.20%\n",
      "846\tValidation loss: 0.364706\tBest loss: 0.364706\tAccuracy: 92.10%\n",
      "847\tValidation loss: 0.364972\tBest loss: 0.364706\tAccuracy: 92.10%\n",
      "848\tValidation loss: 0.364464\tBest loss: 0.364464\tAccuracy: 92.20%\n",
      "849\tValidation loss: 0.364397\tBest loss: 0.364397\tAccuracy: 92.20%\n",
      "850\tValidation loss: 0.364344\tBest loss: 0.364344\tAccuracy: 92.20%\n",
      "851\tValidation loss: 0.364765\tBest loss: 0.364344\tAccuracy: 92.20%\n",
      "852\tValidation loss: 0.365144\tBest loss: 0.364344\tAccuracy: 92.10%\n",
      "853\tValidation loss: 0.364460\tBest loss: 0.364344\tAccuracy: 92.20%\n",
      "854\tValidation loss: 0.365086\tBest loss: 0.364344\tAccuracy: 92.30%\n",
      "855\tValidation loss: 0.364572\tBest loss: 0.364344\tAccuracy: 92.20%\n",
      "856\tValidation loss: 0.364163\tBest loss: 0.364163\tAccuracy: 92.10%\n",
      "857\tValidation loss: 0.364291\tBest loss: 0.364163\tAccuracy: 92.10%\n",
      "858\tValidation loss: 0.364672\tBest loss: 0.364163\tAccuracy: 92.10%\n",
      "859\tValidation loss: 0.363944\tBest loss: 0.363944\tAccuracy: 92.10%\n",
      "860\tValidation loss: 0.364841\tBest loss: 0.363944\tAccuracy: 92.10%\n",
      "861\tValidation loss: 0.363916\tBest loss: 0.363916\tAccuracy: 92.10%\n",
      "862\tValidation loss: 0.363481\tBest loss: 0.363481\tAccuracy: 92.10%\n",
      "863\tValidation loss: 0.363233\tBest loss: 0.363233\tAccuracy: 92.10%\n",
      "864\tValidation loss: 0.364229\tBest loss: 0.363233\tAccuracy: 92.10%\n",
      "865\tValidation loss: 0.364277\tBest loss: 0.363233\tAccuracy: 92.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\tValidation loss: 0.363273\tBest loss: 0.363233\tAccuracy: 92.10%\n",
      "867\tValidation loss: 0.364265\tBest loss: 0.363233\tAccuracy: 92.00%\n",
      "868\tValidation loss: 0.363724\tBest loss: 0.363233\tAccuracy: 91.90%\n",
      "869\tValidation loss: 0.363351\tBest loss: 0.363233\tAccuracy: 92.10%\n",
      "870\tValidation loss: 0.362393\tBest loss: 0.362393\tAccuracy: 92.30%\n",
      "871\tValidation loss: 0.363134\tBest loss: 0.362393\tAccuracy: 92.10%\n",
      "872\tValidation loss: 0.362646\tBest loss: 0.362393\tAccuracy: 92.20%\n",
      "873\tValidation loss: 0.363788\tBest loss: 0.362393\tAccuracy: 91.90%\n",
      "874\tValidation loss: 0.362924\tBest loss: 0.362393\tAccuracy: 92.10%\n",
      "875\tValidation loss: 0.362754\tBest loss: 0.362393\tAccuracy: 92.00%\n",
      "876\tValidation loss: 0.363383\tBest loss: 0.362393\tAccuracy: 92.10%\n",
      "877\tValidation loss: 0.362489\tBest loss: 0.362393\tAccuracy: 92.30%\n",
      "878\tValidation loss: 0.361811\tBest loss: 0.361811\tAccuracy: 92.10%\n",
      "879\tValidation loss: 0.361714\tBest loss: 0.361714\tAccuracy: 92.30%\n",
      "880\tValidation loss: 0.362243\tBest loss: 0.361714\tAccuracy: 92.30%\n",
      "881\tValidation loss: 0.362470\tBest loss: 0.361714\tAccuracy: 92.00%\n",
      "882\tValidation loss: 0.362444\tBest loss: 0.361714\tAccuracy: 92.10%\n",
      "883\tValidation loss: 0.362545\tBest loss: 0.361714\tAccuracy: 92.20%\n",
      "884\tValidation loss: 0.361988\tBest loss: 0.361714\tAccuracy: 92.20%\n",
      "885\tValidation loss: 0.362002\tBest loss: 0.361714\tAccuracy: 92.20%\n",
      "886\tValidation loss: 0.361498\tBest loss: 0.361498\tAccuracy: 92.20%\n",
      "887\tValidation loss: 0.361826\tBest loss: 0.361498\tAccuracy: 92.10%\n",
      "888\tValidation loss: 0.361129\tBest loss: 0.361129\tAccuracy: 92.20%\n",
      "889\tValidation loss: 0.360870\tBest loss: 0.360870\tAccuracy: 92.30%\n",
      "890\tValidation loss: 0.361297\tBest loss: 0.360870\tAccuracy: 92.20%\n",
      "891\tValidation loss: 0.360963\tBest loss: 0.360870\tAccuracy: 92.20%\n",
      "892\tValidation loss: 0.361862\tBest loss: 0.360870\tAccuracy: 92.20%\n",
      "893\tValidation loss: 0.361715\tBest loss: 0.360870\tAccuracy: 92.20%\n",
      "894\tValidation loss: 0.360418\tBest loss: 0.360418\tAccuracy: 92.40%\n",
      "895\tValidation loss: 0.361968\tBest loss: 0.360418\tAccuracy: 92.20%\n",
      "896\tValidation loss: 0.360993\tBest loss: 0.360418\tAccuracy: 92.10%\n",
      "897\tValidation loss: 0.361377\tBest loss: 0.360418\tAccuracy: 92.10%\n",
      "898\tValidation loss: 0.360292\tBest loss: 0.360292\tAccuracy: 92.30%\n",
      "899\tValidation loss: 0.361061\tBest loss: 0.360292\tAccuracy: 92.00%\n",
      "900\tValidation loss: 0.360452\tBest loss: 0.360292\tAccuracy: 92.20%\n",
      "901\tValidation loss: 0.361105\tBest loss: 0.360292\tAccuracy: 92.20%\n",
      "902\tValidation loss: 0.360719\tBest loss: 0.360292\tAccuracy: 92.20%\n",
      "903\tValidation loss: 0.360531\tBest loss: 0.360292\tAccuracy: 92.30%\n",
      "904\tValidation loss: 0.360905\tBest loss: 0.360292\tAccuracy: 92.10%\n",
      "905\tValidation loss: 0.360532\tBest loss: 0.360292\tAccuracy: 92.30%\n",
      "906\tValidation loss: 0.360728\tBest loss: 0.360292\tAccuracy: 92.10%\n",
      "907\tValidation loss: 0.360208\tBest loss: 0.360208\tAccuracy: 92.40%\n",
      "908\tValidation loss: 0.360865\tBest loss: 0.360208\tAccuracy: 92.20%\n",
      "909\tValidation loss: 0.360193\tBest loss: 0.360193\tAccuracy: 92.20%\n",
      "910\tValidation loss: 0.359637\tBest loss: 0.359637\tAccuracy: 92.50%\n",
      "911\tValidation loss: 0.360318\tBest loss: 0.359637\tAccuracy: 92.40%\n",
      "912\tValidation loss: 0.360012\tBest loss: 0.359637\tAccuracy: 92.30%\n",
      "913\tValidation loss: 0.359896\tBest loss: 0.359637\tAccuracy: 92.20%\n",
      "914\tValidation loss: 0.360189\tBest loss: 0.359637\tAccuracy: 92.20%\n",
      "915\tValidation loss: 0.360433\tBest loss: 0.359637\tAccuracy: 92.10%\n",
      "916\tValidation loss: 0.359814\tBest loss: 0.359637\tAccuracy: 92.40%\n",
      "917\tValidation loss: 0.360691\tBest loss: 0.359637\tAccuracy: 92.20%\n",
      "918\tValidation loss: 0.358938\tBest loss: 0.358938\tAccuracy: 92.30%\n",
      "919\tValidation loss: 0.359068\tBest loss: 0.358938\tAccuracy: 92.30%\n",
      "920\tValidation loss: 0.359087\tBest loss: 0.358938\tAccuracy: 92.30%\n",
      "921\tValidation loss: 0.359176\tBest loss: 0.358938\tAccuracy: 92.40%\n",
      "922\tValidation loss: 0.358838\tBest loss: 0.358838\tAccuracy: 92.40%\n",
      "923\tValidation loss: 0.359920\tBest loss: 0.358838\tAccuracy: 92.40%\n",
      "924\tValidation loss: 0.359417\tBest loss: 0.358838\tAccuracy: 92.20%\n",
      "925\tValidation loss: 0.359351\tBest loss: 0.358838\tAccuracy: 92.30%\n",
      "926\tValidation loss: 0.358861\tBest loss: 0.358838\tAccuracy: 92.40%\n",
      "927\tValidation loss: 0.358669\tBest loss: 0.358669\tAccuracy: 92.30%\n",
      "928\tValidation loss: 0.359355\tBest loss: 0.358669\tAccuracy: 92.20%\n",
      "929\tValidation loss: 0.358999\tBest loss: 0.358669\tAccuracy: 92.30%\n",
      "930\tValidation loss: 0.358951\tBest loss: 0.358669\tAccuracy: 92.30%\n",
      "931\tValidation loss: 0.359207\tBest loss: 0.358669\tAccuracy: 92.30%\n",
      "932\tValidation loss: 0.358711\tBest loss: 0.358669\tAccuracy: 92.20%\n",
      "933\tValidation loss: 0.358038\tBest loss: 0.358038\tAccuracy: 92.40%\n",
      "934\tValidation loss: 0.358751\tBest loss: 0.358038\tAccuracy: 92.30%\n",
      "935\tValidation loss: 0.357927\tBest loss: 0.357927\tAccuracy: 92.40%\n",
      "936\tValidation loss: 0.357587\tBest loss: 0.357587\tAccuracy: 92.40%\n",
      "937\tValidation loss: 0.358482\tBest loss: 0.357587\tAccuracy: 92.40%\n",
      "938\tValidation loss: 0.358266\tBest loss: 0.357587\tAccuracy: 92.40%\n",
      "939\tValidation loss: 0.357796\tBest loss: 0.357587\tAccuracy: 92.40%\n",
      "940\tValidation loss: 0.358524\tBest loss: 0.357587\tAccuracy: 92.20%\n",
      "941\tValidation loss: 0.358189\tBest loss: 0.357587\tAccuracy: 92.30%\n",
      "942\tValidation loss: 0.357942\tBest loss: 0.357587\tAccuracy: 92.30%\n",
      "943\tValidation loss: 0.357428\tBest loss: 0.357428\tAccuracy: 92.20%\n",
      "944\tValidation loss: 0.356827\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "945\tValidation loss: 0.357351\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "946\tValidation loss: 0.357381\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "947\tValidation loss: 0.357608\tBest loss: 0.356827\tAccuracy: 92.30%\n",
      "948\tValidation loss: 0.356881\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "949\tValidation loss: 0.357173\tBest loss: 0.356827\tAccuracy: 92.30%\n",
      "950\tValidation loss: 0.357635\tBest loss: 0.356827\tAccuracy: 92.20%\n",
      "951\tValidation loss: 0.357182\tBest loss: 0.356827\tAccuracy: 92.60%\n",
      "952\tValidation loss: 0.356950\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "953\tValidation loss: 0.357272\tBest loss: 0.356827\tAccuracy: 92.30%\n",
      "954\tValidation loss: 0.357093\tBest loss: 0.356827\tAccuracy: 92.30%\n",
      "955\tValidation loss: 0.357447\tBest loss: 0.356827\tAccuracy: 92.40%\n",
      "956\tValidation loss: 0.357016\tBest loss: 0.356827\tAccuracy: 92.30%\n",
      "957\tValidation loss: 0.356648\tBest loss: 0.356648\tAccuracy: 92.20%\n",
      "958\tValidation loss: 0.356442\tBest loss: 0.356442\tAccuracy: 92.30%\n",
      "959\tValidation loss: 0.356863\tBest loss: 0.356442\tAccuracy: 92.30%\n",
      "960\tValidation loss: 0.356630\tBest loss: 0.356442\tAccuracy: 92.20%\n",
      "961\tValidation loss: 0.356471\tBest loss: 0.356442\tAccuracy: 92.30%\n",
      "962\tValidation loss: 0.356598\tBest loss: 0.356442\tAccuracy: 92.10%\n",
      "963\tValidation loss: 0.357039\tBest loss: 0.356442\tAccuracy: 92.10%\n",
      "964\tValidation loss: 0.356032\tBest loss: 0.356032\tAccuracy: 92.10%\n",
      "965\tValidation loss: 0.356367\tBest loss: 0.356032\tAccuracy: 92.40%\n",
      "966\tValidation loss: 0.355919\tBest loss: 0.355919\tAccuracy: 92.40%\n",
      "967\tValidation loss: 0.355797\tBest loss: 0.355797\tAccuracy: 92.30%\n",
      "968\tValidation loss: 0.355974\tBest loss: 0.355797\tAccuracy: 92.20%\n",
      "969\tValidation loss: 0.355867\tBest loss: 0.355797\tAccuracy: 92.20%\n",
      "970\tValidation loss: 0.356385\tBest loss: 0.355797\tAccuracy: 92.30%\n",
      "971\tValidation loss: 0.356417\tBest loss: 0.355797\tAccuracy: 92.30%\n",
      "972\tValidation loss: 0.356515\tBest loss: 0.355797\tAccuracy: 92.30%\n",
      "973\tValidation loss: 0.355912\tBest loss: 0.355797\tAccuracy: 92.30%\n",
      "974\tValidation loss: 0.355056\tBest loss: 0.355056\tAccuracy: 92.40%\n",
      "975\tValidation loss: 0.355416\tBest loss: 0.355056\tAccuracy: 92.40%\n",
      "976\tValidation loss: 0.355810\tBest loss: 0.355056\tAccuracy: 92.30%\n",
      "977\tValidation loss: 0.355464\tBest loss: 0.355056\tAccuracy: 92.20%\n",
      "978\tValidation loss: 0.356356\tBest loss: 0.355056\tAccuracy: 92.20%\n",
      "979\tValidation loss: 0.355382\tBest loss: 0.355056\tAccuracy: 92.10%\n",
      "980\tValidation loss: 0.355105\tBest loss: 0.355056\tAccuracy: 92.20%\n",
      "981\tValidation loss: 0.355100\tBest loss: 0.355056\tAccuracy: 92.40%\n",
      "982\tValidation loss: 0.355430\tBest loss: 0.355056\tAccuracy: 92.40%\n",
      "983\tValidation loss: 0.354329\tBest loss: 0.354329\tAccuracy: 92.50%\n",
      "984\tValidation loss: 0.354570\tBest loss: 0.354329\tAccuracy: 92.50%\n",
      "985\tValidation loss: 0.354892\tBest loss: 0.354329\tAccuracy: 92.30%\n",
      "986\tValidation loss: 0.355202\tBest loss: 0.354329\tAccuracy: 92.40%\n",
      "987\tValidation loss: 0.354596\tBest loss: 0.354329\tAccuracy: 92.30%\n",
      "988\tValidation loss: 0.354419\tBest loss: 0.354329\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989\tValidation loss: 0.354688\tBest loss: 0.354329\tAccuracy: 92.20%\n",
      "990\tValidation loss: 0.354680\tBest loss: 0.354329\tAccuracy: 92.20%\n",
      "991\tValidation loss: 0.354534\tBest loss: 0.354329\tAccuracy: 92.40%\n",
      "992\tValidation loss: 0.354617\tBest loss: 0.354329\tAccuracy: 92.30%\n",
      "993\tValidation loss: 0.354330\tBest loss: 0.354329\tAccuracy: 92.40%\n",
      "994\tValidation loss: 0.354710\tBest loss: 0.354329\tAccuracy: 92.30%\n",
      "995\tValidation loss: 0.355108\tBest loss: 0.354329\tAccuracy: 92.20%\n",
      "996\tValidation loss: 0.354499\tBest loss: 0.354329\tAccuracy: 92.30%\n",
      "997\tValidation loss: 0.353923\tBest loss: 0.353923\tAccuracy: 92.30%\n",
      "998\tValidation loss: 0.354362\tBest loss: 0.353923\tAccuracy: 92.30%\n",
      "999\tValidation loss: 0.354483\tBest loss: 0.353923\tAccuracy: 92.30%\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.7min\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.114470\tBest loss: 2.114470\tAccuracy: 43.40%\n",
      "1\tValidation loss: 1.172462\tBest loss: 1.172462\tAccuracy: 67.80%\n",
      "2\tValidation loss: 0.963822\tBest loss: 0.963822\tAccuracy: 70.40%\n",
      "3\tValidation loss: 0.728813\tBest loss: 0.728813\tAccuracy: 80.40%\n",
      "4\tValidation loss: 0.662272\tBest loss: 0.662272\tAccuracy: 81.50%\n",
      "5\tValidation loss: 0.644618\tBest loss: 0.644618\tAccuracy: 82.80%\n",
      "6\tValidation loss: 0.575845\tBest loss: 0.575845\tAccuracy: 85.20%\n",
      "7\tValidation loss: 0.550531\tBest loss: 0.550531\tAccuracy: 84.50%\n",
      "8\tValidation loss: 0.510698\tBest loss: 0.510698\tAccuracy: 86.10%\n",
      "9\tValidation loss: 0.501840\tBest loss: 0.501840\tAccuracy: 86.10%\n",
      "10\tValidation loss: 0.494603\tBest loss: 0.494603\tAccuracy: 86.10%\n",
      "11\tValidation loss: 0.501806\tBest loss: 0.494603\tAccuracy: 85.60%\n",
      "12\tValidation loss: 0.464608\tBest loss: 0.464608\tAccuracy: 87.40%\n",
      "13\tValidation loss: 0.417959\tBest loss: 0.417959\tAccuracy: 89.60%\n",
      "14\tValidation loss: 0.433311\tBest loss: 0.417959\tAccuracy: 88.30%\n",
      "15\tValidation loss: 0.400673\tBest loss: 0.400673\tAccuracy: 89.50%\n",
      "16\tValidation loss: 0.447997\tBest loss: 0.400673\tAccuracy: 88.90%\n",
      "17\tValidation loss: 0.392980\tBest loss: 0.392980\tAccuracy: 89.80%\n",
      "18\tValidation loss: 0.389412\tBest loss: 0.389412\tAccuracy: 89.80%\n",
      "19\tValidation loss: 0.385270\tBest loss: 0.385270\tAccuracy: 89.50%\n",
      "20\tValidation loss: 0.363060\tBest loss: 0.363060\tAccuracy: 90.00%\n",
      "21\tValidation loss: 0.370916\tBest loss: 0.363060\tAccuracy: 90.10%\n",
      "22\tValidation loss: 0.363891\tBest loss: 0.363060\tAccuracy: 90.20%\n",
      "23\tValidation loss: 0.364586\tBest loss: 0.363060\tAccuracy: 89.80%\n",
      "24\tValidation loss: 0.349208\tBest loss: 0.349208\tAccuracy: 90.50%\n",
      "25\tValidation loss: 0.349228\tBest loss: 0.349208\tAccuracy: 90.60%\n",
      "26\tValidation loss: 0.347926\tBest loss: 0.347926\tAccuracy: 90.80%\n",
      "27\tValidation loss: 0.330137\tBest loss: 0.330137\tAccuracy: 91.10%\n",
      "28\tValidation loss: 0.333801\tBest loss: 0.330137\tAccuracy: 91.40%\n",
      "29\tValidation loss: 0.328162\tBest loss: 0.328162\tAccuracy: 91.30%\n",
      "30\tValidation loss: 0.325206\tBest loss: 0.325206\tAccuracy: 92.20%\n",
      "31\tValidation loss: 0.314058\tBest loss: 0.314058\tAccuracy: 92.00%\n",
      "32\tValidation loss: 0.326165\tBest loss: 0.314058\tAccuracy: 91.00%\n",
      "33\tValidation loss: 0.322704\tBest loss: 0.314058\tAccuracy: 91.90%\n",
      "34\tValidation loss: 0.318203\tBest loss: 0.314058\tAccuracy: 92.00%\n",
      "35\tValidation loss: 0.308262\tBest loss: 0.308262\tAccuracy: 92.10%\n",
      "36\tValidation loss: 0.309334\tBest loss: 0.308262\tAccuracy: 92.00%\n",
      "37\tValidation loss: 0.312870\tBest loss: 0.308262\tAccuracy: 91.90%\n",
      "38\tValidation loss: 0.316655\tBest loss: 0.308262\tAccuracy: 91.70%\n",
      "39\tValidation loss: 0.311416\tBest loss: 0.308262\tAccuracy: 92.50%\n",
      "40\tValidation loss: 0.312429\tBest loss: 0.308262\tAccuracy: 92.00%\n",
      "41\tValidation loss: 0.302583\tBest loss: 0.302583\tAccuracy: 92.30%\n",
      "42\tValidation loss: 0.296946\tBest loss: 0.296946\tAccuracy: 92.60%\n",
      "43\tValidation loss: 0.286154\tBest loss: 0.286154\tAccuracy: 92.70%\n",
      "44\tValidation loss: 0.293296\tBest loss: 0.286154\tAccuracy: 93.00%\n",
      "45\tValidation loss: 0.288684\tBest loss: 0.286154\tAccuracy: 92.90%\n",
      "46\tValidation loss: 0.301642\tBest loss: 0.286154\tAccuracy: 92.60%\n",
      "47\tValidation loss: 0.288673\tBest loss: 0.286154\tAccuracy: 92.70%\n",
      "48\tValidation loss: 0.296915\tBest loss: 0.286154\tAccuracy: 92.70%\n",
      "49\tValidation loss: 0.293080\tBest loss: 0.286154\tAccuracy: 92.90%\n",
      "50\tValidation loss: 0.293266\tBest loss: 0.286154\tAccuracy: 92.70%\n",
      "51\tValidation loss: 0.284629\tBest loss: 0.284629\tAccuracy: 92.80%\n",
      "52\tValidation loss: 0.276413\tBest loss: 0.276413\tAccuracy: 93.40%\n",
      "53\tValidation loss: 0.292447\tBest loss: 0.276413\tAccuracy: 92.70%\n",
      "54\tValidation loss: 0.282789\tBest loss: 0.276413\tAccuracy: 93.00%\n",
      "55\tValidation loss: 0.277581\tBest loss: 0.276413\tAccuracy: 93.70%\n",
      "56\tValidation loss: 0.290327\tBest loss: 0.276413\tAccuracy: 92.90%\n",
      "57\tValidation loss: 0.287876\tBest loss: 0.276413\tAccuracy: 93.30%\n",
      "58\tValidation loss: 0.276966\tBest loss: 0.276413\tAccuracy: 93.70%\n",
      "59\tValidation loss: 0.274158\tBest loss: 0.274158\tAccuracy: 93.40%\n",
      "60\tValidation loss: 0.280916\tBest loss: 0.274158\tAccuracy: 93.70%\n",
      "61\tValidation loss: 0.286276\tBest loss: 0.274158\tAccuracy: 93.40%\n",
      "62\tValidation loss: 0.280029\tBest loss: 0.274158\tAccuracy: 93.60%\n",
      "63\tValidation loss: 0.281685\tBest loss: 0.274158\tAccuracy: 93.90%\n",
      "64\tValidation loss: 0.277071\tBest loss: 0.274158\tAccuracy: 93.60%\n",
      "65\tValidation loss: 0.281744\tBest loss: 0.274158\tAccuracy: 93.40%\n",
      "66\tValidation loss: 0.277442\tBest loss: 0.274158\tAccuracy: 94.20%\n",
      "67\tValidation loss: 0.282735\tBest loss: 0.274158\tAccuracy: 93.30%\n",
      "68\tValidation loss: 0.288559\tBest loss: 0.274158\tAccuracy: 93.40%\n",
      "69\tValidation loss: 0.276069\tBest loss: 0.274158\tAccuracy: 94.10%\n",
      "70\tValidation loss: 0.278624\tBest loss: 0.274158\tAccuracy: 93.60%\n",
      "71\tValidation loss: 0.290755\tBest loss: 0.274158\tAccuracy: 93.40%\n",
      "72\tValidation loss: 0.287445\tBest loss: 0.274158\tAccuracy: 93.50%\n",
      "73\tValidation loss: 0.282550\tBest loss: 0.274158\tAccuracy: 93.90%\n",
      "74\tValidation loss: 0.279804\tBest loss: 0.274158\tAccuracy: 93.80%\n",
      "75\tValidation loss: 0.279251\tBest loss: 0.274158\tAccuracy: 93.80%\n",
      "76\tValidation loss: 0.277565\tBest loss: 0.274158\tAccuracy: 94.00%\n",
      "77\tValidation loss: 0.281797\tBest loss: 0.274158\tAccuracy: 94.20%\n",
      "78\tValidation loss: 0.275824\tBest loss: 0.274158\tAccuracy: 94.00%\n",
      "79\tValidation loss: 0.280504\tBest loss: 0.274158\tAccuracy: 94.10%\n",
      "80\tValidation loss: 0.282897\tBest loss: 0.274158\tAccuracy: 94.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  10.7s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.023701\tBest loss: 2.023701\tAccuracy: 42.20%\n",
      "1\tValidation loss: 1.122880\tBest loss: 1.122880\tAccuracy: 68.80%\n",
      "2\tValidation loss: 0.829549\tBest loss: 0.829549\tAccuracy: 77.90%\n",
      "3\tValidation loss: 0.706856\tBest loss: 0.706856\tAccuracy: 81.90%\n",
      "4\tValidation loss: 0.714468\tBest loss: 0.706856\tAccuracy: 79.20%\n",
      "5\tValidation loss: 0.618719\tBest loss: 0.618719\tAccuracy: 83.30%\n",
      "6\tValidation loss: 0.571699\tBest loss: 0.571699\tAccuracy: 83.40%\n",
      "7\tValidation loss: 0.524529\tBest loss: 0.524529\tAccuracy: 86.40%\n",
      "8\tValidation loss: 0.517726\tBest loss: 0.517726\tAccuracy: 85.80%\n",
      "9\tValidation loss: 0.482662\tBest loss: 0.482662\tAccuracy: 86.30%\n",
      "10\tValidation loss: 0.472127\tBest loss: 0.472127\tAccuracy: 86.90%\n",
      "11\tValidation loss: 0.441741\tBest loss: 0.441741\tAccuracy: 87.60%\n",
      "12\tValidation loss: 0.465374\tBest loss: 0.441741\tAccuracy: 86.20%\n",
      "13\tValidation loss: 0.446621\tBest loss: 0.441741\tAccuracy: 86.80%\n",
      "14\tValidation loss: 0.392027\tBest loss: 0.392027\tAccuracy: 88.90%\n",
      "15\tValidation loss: 0.400330\tBest loss: 0.392027\tAccuracy: 88.90%\n",
      "16\tValidation loss: 0.377979\tBest loss: 0.377979\tAccuracy: 89.70%\n",
      "17\tValidation loss: 0.411254\tBest loss: 0.377979\tAccuracy: 88.60%\n",
      "18\tValidation loss: 0.367786\tBest loss: 0.367786\tAccuracy: 90.10%\n",
      "19\tValidation loss: 0.366179\tBest loss: 0.366179\tAccuracy: 90.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\tValidation loss: 0.358111\tBest loss: 0.358111\tAccuracy: 90.30%\n",
      "21\tValidation loss: 0.352818\tBest loss: 0.352818\tAccuracy: 90.10%\n",
      "22\tValidation loss: 0.354809\tBest loss: 0.352818\tAccuracy: 90.40%\n",
      "23\tValidation loss: 0.360754\tBest loss: 0.352818\tAccuracy: 89.90%\n",
      "24\tValidation loss: 0.339240\tBest loss: 0.339240\tAccuracy: 91.00%\n",
      "25\tValidation loss: 0.340030\tBest loss: 0.339240\tAccuracy: 90.40%\n",
      "26\tValidation loss: 0.342390\tBest loss: 0.339240\tAccuracy: 91.10%\n",
      "27\tValidation loss: 0.330847\tBest loss: 0.330847\tAccuracy: 91.30%\n",
      "28\tValidation loss: 0.334894\tBest loss: 0.330847\tAccuracy: 91.40%\n",
      "29\tValidation loss: 0.333778\tBest loss: 0.330847\tAccuracy: 91.30%\n",
      "30\tValidation loss: 0.325188\tBest loss: 0.325188\tAccuracy: 91.30%\n",
      "31\tValidation loss: 0.324101\tBest loss: 0.324101\tAccuracy: 91.30%\n",
      "32\tValidation loss: 0.343617\tBest loss: 0.324101\tAccuracy: 90.20%\n",
      "33\tValidation loss: 0.321325\tBest loss: 0.321325\tAccuracy: 91.60%\n",
      "34\tValidation loss: 0.324459\tBest loss: 0.321325\tAccuracy: 91.10%\n",
      "35\tValidation loss: 0.314420\tBest loss: 0.314420\tAccuracy: 91.80%\n",
      "36\tValidation loss: 0.319239\tBest loss: 0.314420\tAccuracy: 91.80%\n",
      "37\tValidation loss: 0.320269\tBest loss: 0.314420\tAccuracy: 92.10%\n",
      "38\tValidation loss: 0.325430\tBest loss: 0.314420\tAccuracy: 91.70%\n",
      "39\tValidation loss: 0.313217\tBest loss: 0.313217\tAccuracy: 92.20%\n",
      "40\tValidation loss: 0.329607\tBest loss: 0.313217\tAccuracy: 91.50%\n",
      "41\tValidation loss: 0.308562\tBest loss: 0.308562\tAccuracy: 92.20%\n",
      "42\tValidation loss: 0.312688\tBest loss: 0.308562\tAccuracy: 92.30%\n",
      "43\tValidation loss: 0.299654\tBest loss: 0.299654\tAccuracy: 92.40%\n",
      "44\tValidation loss: 0.298970\tBest loss: 0.298970\tAccuracy: 93.00%\n",
      "45\tValidation loss: 0.301329\tBest loss: 0.298970\tAccuracy: 92.50%\n",
      "46\tValidation loss: 0.308858\tBest loss: 0.298970\tAccuracy: 92.40%\n",
      "47\tValidation loss: 0.319937\tBest loss: 0.298970\tAccuracy: 93.00%\n",
      "48\tValidation loss: 0.308352\tBest loss: 0.298970\tAccuracy: 92.80%\n",
      "49\tValidation loss: 0.304576\tBest loss: 0.298970\tAccuracy: 93.00%\n",
      "50\tValidation loss: 0.306110\tBest loss: 0.298970\tAccuracy: 92.90%\n",
      "51\tValidation loss: 0.316935\tBest loss: 0.298970\tAccuracy: 92.60%\n",
      "52\tValidation loss: 0.307405\tBest loss: 0.298970\tAccuracy: 93.10%\n",
      "53\tValidation loss: 0.309845\tBest loss: 0.298970\tAccuracy: 92.90%\n",
      "54\tValidation loss: 0.293889\tBest loss: 0.293889\tAccuracy: 93.10%\n",
      "55\tValidation loss: 0.309041\tBest loss: 0.293889\tAccuracy: 92.70%\n",
      "56\tValidation loss: 0.309069\tBest loss: 0.293889\tAccuracy: 92.80%\n",
      "57\tValidation loss: 0.304756\tBest loss: 0.293889\tAccuracy: 93.10%\n",
      "58\tValidation loss: 0.303746\tBest loss: 0.293889\tAccuracy: 93.60%\n",
      "59\tValidation loss: 0.301682\tBest loss: 0.293889\tAccuracy: 93.40%\n",
      "60\tValidation loss: 0.327633\tBest loss: 0.293889\tAccuracy: 92.80%\n",
      "61\tValidation loss: 0.309807\tBest loss: 0.293889\tAccuracy: 93.10%\n",
      "62\tValidation loss: 0.309572\tBest loss: 0.293889\tAccuracy: 93.10%\n",
      "63\tValidation loss: 0.308596\tBest loss: 0.293889\tAccuracy: 93.20%\n",
      "64\tValidation loss: 0.301681\tBest loss: 0.293889\tAccuracy: 93.20%\n",
      "65\tValidation loss: 0.311977\tBest loss: 0.293889\tAccuracy: 93.00%\n",
      "66\tValidation loss: 0.302200\tBest loss: 0.293889\tAccuracy: 93.60%\n",
      "67\tValidation loss: 0.303400\tBest loss: 0.293889\tAccuracy: 93.50%\n",
      "68\tValidation loss: 0.307248\tBest loss: 0.293889\tAccuracy: 93.90%\n",
      "69\tValidation loss: 0.304322\tBest loss: 0.293889\tAccuracy: 93.50%\n",
      "70\tValidation loss: 0.311902\tBest loss: 0.293889\tAccuracy: 93.70%\n",
      "71\tValidation loss: 0.318781\tBest loss: 0.293889\tAccuracy: 93.10%\n",
      "72\tValidation loss: 0.316938\tBest loss: 0.293889\tAccuracy: 93.20%\n",
      "73\tValidation loss: 0.323301\tBest loss: 0.293889\tAccuracy: 93.30%\n",
      "74\tValidation loss: 0.319913\tBest loss: 0.293889\tAccuracy: 93.40%\n",
      "75\tValidation loss: 0.322207\tBest loss: 0.293889\tAccuracy: 93.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  10.4s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 2.028305\tBest loss: 2.028305\tAccuracy: 41.10%\n",
      "1\tValidation loss: 1.153909\tBest loss: 1.153909\tAccuracy: 68.30%\n",
      "2\tValidation loss: 0.861371\tBest loss: 0.861371\tAccuracy: 75.80%\n",
      "3\tValidation loss: 0.765587\tBest loss: 0.765587\tAccuracy: 78.70%\n",
      "4\tValidation loss: 0.672689\tBest loss: 0.672689\tAccuracy: 81.50%\n",
      "5\tValidation loss: 0.606656\tBest loss: 0.606656\tAccuracy: 83.10%\n",
      "6\tValidation loss: 0.572887\tBest loss: 0.572887\tAccuracy: 84.40%\n",
      "7\tValidation loss: 0.544481\tBest loss: 0.544481\tAccuracy: 85.30%\n",
      "8\tValidation loss: 0.539587\tBest loss: 0.539587\tAccuracy: 86.30%\n",
      "9\tValidation loss: 0.511856\tBest loss: 0.511856\tAccuracy: 85.90%\n",
      "10\tValidation loss: 0.527931\tBest loss: 0.511856\tAccuracy: 85.70%\n",
      "11\tValidation loss: 0.462032\tBest loss: 0.462032\tAccuracy: 88.10%\n",
      "12\tValidation loss: 0.456347\tBest loss: 0.456347\tAccuracy: 87.60%\n",
      "13\tValidation loss: 0.426924\tBest loss: 0.426924\tAccuracy: 88.40%\n",
      "14\tValidation loss: 0.423243\tBest loss: 0.423243\tAccuracy: 88.50%\n",
      "15\tValidation loss: 0.419485\tBest loss: 0.419485\tAccuracy: 89.10%\n",
      "16\tValidation loss: 0.436288\tBest loss: 0.419485\tAccuracy: 87.70%\n",
      "17\tValidation loss: 0.411894\tBest loss: 0.411894\tAccuracy: 88.90%\n",
      "18\tValidation loss: 0.377382\tBest loss: 0.377382\tAccuracy: 90.20%\n",
      "19\tValidation loss: 0.385146\tBest loss: 0.377382\tAccuracy: 89.60%\n",
      "20\tValidation loss: 0.385520\tBest loss: 0.377382\tAccuracy: 89.50%\n",
      "21\tValidation loss: 0.368626\tBest loss: 0.368626\tAccuracy: 90.10%\n",
      "22\tValidation loss: 0.358204\tBest loss: 0.358204\tAccuracy: 91.10%\n",
      "23\tValidation loss: 0.356886\tBest loss: 0.356886\tAccuracy: 91.10%\n",
      "24\tValidation loss: 0.359303\tBest loss: 0.356886\tAccuracy: 90.50%\n",
      "25\tValidation loss: 0.352642\tBest loss: 0.352642\tAccuracy: 90.80%\n",
      "26\tValidation loss: 0.343003\tBest loss: 0.343003\tAccuracy: 91.60%\n",
      "27\tValidation loss: 0.342695\tBest loss: 0.342695\tAccuracy: 91.20%\n",
      "28\tValidation loss: 0.336692\tBest loss: 0.336692\tAccuracy: 92.00%\n",
      "29\tValidation loss: 0.334867\tBest loss: 0.334867\tAccuracy: 91.50%\n",
      "30\tValidation loss: 0.318915\tBest loss: 0.318915\tAccuracy: 92.20%\n",
      "31\tValidation loss: 0.336112\tBest loss: 0.318915\tAccuracy: 91.40%\n",
      "32\tValidation loss: 0.324685\tBest loss: 0.318915\tAccuracy: 91.90%\n",
      "33\tValidation loss: 0.317896\tBest loss: 0.317896\tAccuracy: 91.60%\n",
      "34\tValidation loss: 0.312055\tBest loss: 0.312055\tAccuracy: 91.90%\n",
      "35\tValidation loss: 0.318762\tBest loss: 0.312055\tAccuracy: 92.10%\n",
      "36\tValidation loss: 0.317475\tBest loss: 0.312055\tAccuracy: 91.50%\n",
      "37\tValidation loss: 0.296241\tBest loss: 0.296241\tAccuracy: 92.70%\n",
      "38\tValidation loss: 0.305808\tBest loss: 0.296241\tAccuracy: 92.60%\n",
      "39\tValidation loss: 0.297053\tBest loss: 0.296241\tAccuracy: 92.40%\n",
      "40\tValidation loss: 0.296077\tBest loss: 0.296077\tAccuracy: 92.60%\n",
      "41\tValidation loss: 0.290582\tBest loss: 0.290582\tAccuracy: 93.40%\n",
      "42\tValidation loss: 0.297466\tBest loss: 0.290582\tAccuracy: 92.20%\n",
      "43\tValidation loss: 0.301610\tBest loss: 0.290582\tAccuracy: 92.10%\n",
      "44\tValidation loss: 0.291502\tBest loss: 0.290582\tAccuracy: 93.10%\n",
      "45\tValidation loss: 0.289667\tBest loss: 0.289667\tAccuracy: 92.80%\n",
      "46\tValidation loss: 0.295283\tBest loss: 0.289667\tAccuracy: 92.90%\n",
      "47\tValidation loss: 0.296549\tBest loss: 0.289667\tAccuracy: 91.90%\n",
      "48\tValidation loss: 0.278481\tBest loss: 0.278481\tAccuracy: 93.20%\n",
      "49\tValidation loss: 0.283686\tBest loss: 0.278481\tAccuracy: 92.90%\n",
      "50\tValidation loss: 0.292871\tBest loss: 0.278481\tAccuracy: 92.10%\n",
      "51\tValidation loss: 0.285604\tBest loss: 0.278481\tAccuracy: 92.90%\n",
      "52\tValidation loss: 0.284277\tBest loss: 0.278481\tAccuracy: 93.20%\n",
      "53\tValidation loss: 0.278190\tBest loss: 0.278190\tAccuracy: 93.40%\n",
      "54\tValidation loss: 0.280603\tBest loss: 0.278190\tAccuracy: 93.10%\n",
      "55\tValidation loss: 0.276229\tBest loss: 0.276229\tAccuracy: 93.50%\n",
      "56\tValidation loss: 0.275456\tBest loss: 0.275456\tAccuracy: 93.70%\n",
      "57\tValidation loss: 0.290020\tBest loss: 0.275456\tAccuracy: 92.70%\n",
      "58\tValidation loss: 0.269481\tBest loss: 0.269481\tAccuracy: 93.30%\n",
      "59\tValidation loss: 0.281789\tBest loss: 0.269481\tAccuracy: 93.20%\n",
      "60\tValidation loss: 0.281087\tBest loss: 0.269481\tAccuracy: 93.30%\n",
      "61\tValidation loss: 0.280786\tBest loss: 0.269481\tAccuracy: 93.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\tValidation loss: 0.274641\tBest loss: 0.269481\tAccuracy: 93.90%\n",
      "63\tValidation loss: 0.275362\tBest loss: 0.269481\tAccuracy: 93.80%\n",
      "64\tValidation loss: 0.270859\tBest loss: 0.269481\tAccuracy: 94.10%\n",
      "65\tValidation loss: 0.276428\tBest loss: 0.269481\tAccuracy: 93.90%\n",
      "66\tValidation loss: 0.280639\tBest loss: 0.269481\tAccuracy: 93.60%\n",
      "67\tValidation loss: 0.276743\tBest loss: 0.269481\tAccuracy: 93.80%\n",
      "68\tValidation loss: 0.270891\tBest loss: 0.269481\tAccuracy: 93.50%\n",
      "69\tValidation loss: 0.273514\tBest loss: 0.269481\tAccuracy: 93.80%\n",
      "70\tValidation loss: 0.278285\tBest loss: 0.269481\tAccuracy: 93.30%\n",
      "71\tValidation loss: 0.278363\tBest loss: 0.269481\tAccuracy: 93.60%\n",
      "72\tValidation loss: 0.277316\tBest loss: 0.269481\tAccuracy: 93.40%\n",
      "73\tValidation loss: 0.283473\tBest loss: 0.269481\tAccuracy: 93.50%\n",
      "74\tValidation loss: 0.272779\tBest loss: 0.269481\tAccuracy: 93.90%\n",
      "75\tValidation loss: 0.274039\tBest loss: 0.269481\tAccuracy: 93.50%\n",
      "76\tValidation loss: 0.275383\tBest loss: 0.269481\tAccuracy: 94.00%\n",
      "77\tValidation loss: 0.278386\tBest loss: 0.269481\tAccuracy: 93.90%\n",
      "78\tValidation loss: 0.277275\tBest loss: 0.269481\tAccuracy: 94.20%\n",
      "79\tValidation loss: 0.271965\tBest loss: 0.269481\tAccuracy: 93.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.05, total=  11.0s\n",
      "[CV] batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.731176\tBest loss: 2.731176\tAccuracy: 33.20%\n",
      "1\tValidation loss: 2.159164\tBest loss: 2.159164\tAccuracy: 46.20%\n",
      "2\tValidation loss: 1.763851\tBest loss: 1.763851\tAccuracy: 55.60%\n",
      "3\tValidation loss: 1.526570\tBest loss: 1.526570\tAccuracy: 61.20%\n",
      "4\tValidation loss: 1.346768\tBest loss: 1.346768\tAccuracy: 67.40%\n",
      "5\tValidation loss: 1.230486\tBest loss: 1.230486\tAccuracy: 70.20%\n",
      "6\tValidation loss: 1.138083\tBest loss: 1.138083\tAccuracy: 72.30%\n",
      "7\tValidation loss: 1.067299\tBest loss: 1.067299\tAccuracy: 72.50%\n",
      "8\tValidation loss: 1.007908\tBest loss: 1.007908\tAccuracy: 74.40%\n",
      "9\tValidation loss: 0.948790\tBest loss: 0.948790\tAccuracy: 76.10%\n",
      "10\tValidation loss: 0.913247\tBest loss: 0.913247\tAccuracy: 77.40%\n",
      "11\tValidation loss: 0.877406\tBest loss: 0.877406\tAccuracy: 78.20%\n",
      "12\tValidation loss: 0.847300\tBest loss: 0.847300\tAccuracy: 78.50%\n",
      "13\tValidation loss: 0.815130\tBest loss: 0.815130\tAccuracy: 79.00%\n",
      "14\tValidation loss: 0.794015\tBest loss: 0.794015\tAccuracy: 79.50%\n",
      "15\tValidation loss: 0.773499\tBest loss: 0.773499\tAccuracy: 80.10%\n",
      "16\tValidation loss: 0.761288\tBest loss: 0.761288\tAccuracy: 80.90%\n",
      "17\tValidation loss: 0.737014\tBest loss: 0.737014\tAccuracy: 81.30%\n",
      "18\tValidation loss: 0.722918\tBest loss: 0.722918\tAccuracy: 81.40%\n",
      "19\tValidation loss: 0.701241\tBest loss: 0.701241\tAccuracy: 83.30%\n",
      "20\tValidation loss: 0.690591\tBest loss: 0.690591\tAccuracy: 82.90%\n",
      "21\tValidation loss: 0.680596\tBest loss: 0.680596\tAccuracy: 82.70%\n",
      "22\tValidation loss: 0.672099\tBest loss: 0.672099\tAccuracy: 83.00%\n",
      "23\tValidation loss: 0.662660\tBest loss: 0.662660\tAccuracy: 83.70%\n",
      "24\tValidation loss: 0.650509\tBest loss: 0.650509\tAccuracy: 84.40%\n",
      "25\tValidation loss: 0.644143\tBest loss: 0.644143\tAccuracy: 83.60%\n",
      "26\tValidation loss: 0.640535\tBest loss: 0.640535\tAccuracy: 83.50%\n",
      "27\tValidation loss: 0.628872\tBest loss: 0.628872\tAccuracy: 84.50%\n",
      "28\tValidation loss: 0.622986\tBest loss: 0.622986\tAccuracy: 85.20%\n",
      "29\tValidation loss: 0.619013\tBest loss: 0.619013\tAccuracy: 85.40%\n",
      "30\tValidation loss: 0.612506\tBest loss: 0.612506\tAccuracy: 84.30%\n",
      "31\tValidation loss: 0.597687\tBest loss: 0.597687\tAccuracy: 85.60%\n",
      "32\tValidation loss: 0.594870\tBest loss: 0.594870\tAccuracy: 85.20%\n",
      "33\tValidation loss: 0.590549\tBest loss: 0.590549\tAccuracy: 85.80%\n",
      "34\tValidation loss: 0.588220\tBest loss: 0.588220\tAccuracy: 85.40%\n",
      "35\tValidation loss: 0.582101\tBest loss: 0.582101\tAccuracy: 86.00%\n",
      "36\tValidation loss: 0.566091\tBest loss: 0.566091\tAccuracy: 86.10%\n",
      "37\tValidation loss: 0.569361\tBest loss: 0.566091\tAccuracy: 85.80%\n",
      "38\tValidation loss: 0.568447\tBest loss: 0.566091\tAccuracy: 86.00%\n",
      "39\tValidation loss: 0.562410\tBest loss: 0.562410\tAccuracy: 85.80%\n",
      "40\tValidation loss: 0.564435\tBest loss: 0.562410\tAccuracy: 85.80%\n",
      "41\tValidation loss: 0.554146\tBest loss: 0.554146\tAccuracy: 86.60%\n",
      "42\tValidation loss: 0.549421\tBest loss: 0.549421\tAccuracy: 86.80%\n",
      "43\tValidation loss: 0.544144\tBest loss: 0.544144\tAccuracy: 86.70%\n",
      "44\tValidation loss: 0.540561\tBest loss: 0.540561\tAccuracy: 86.50%\n",
      "45\tValidation loss: 0.532343\tBest loss: 0.532343\tAccuracy: 86.30%\n",
      "46\tValidation loss: 0.537502\tBest loss: 0.532343\tAccuracy: 86.60%\n",
      "47\tValidation loss: 0.528888\tBest loss: 0.528888\tAccuracy: 87.00%\n",
      "48\tValidation loss: 0.532955\tBest loss: 0.528888\tAccuracy: 87.00%\n",
      "49\tValidation loss: 0.531126\tBest loss: 0.528888\tAccuracy: 87.20%\n",
      "50\tValidation loss: 0.527205\tBest loss: 0.527205\tAccuracy: 87.00%\n",
      "51\tValidation loss: 0.525042\tBest loss: 0.525042\tAccuracy: 87.10%\n",
      "52\tValidation loss: 0.516751\tBest loss: 0.516751\tAccuracy: 87.00%\n",
      "53\tValidation loss: 0.518521\tBest loss: 0.516751\tAccuracy: 87.60%\n",
      "54\tValidation loss: 0.506803\tBest loss: 0.506803\tAccuracy: 87.10%\n",
      "55\tValidation loss: 0.509444\tBest loss: 0.506803\tAccuracy: 87.70%\n",
      "56\tValidation loss: 0.511870\tBest loss: 0.506803\tAccuracy: 87.50%\n",
      "57\tValidation loss: 0.507026\tBest loss: 0.506803\tAccuracy: 87.30%\n",
      "58\tValidation loss: 0.504791\tBest loss: 0.504791\tAccuracy: 87.30%\n",
      "59\tValidation loss: 0.503370\tBest loss: 0.503370\tAccuracy: 87.40%\n",
      "60\tValidation loss: 0.497245\tBest loss: 0.497245\tAccuracy: 87.80%\n",
      "61\tValidation loss: 0.496460\tBest loss: 0.496460\tAccuracy: 87.60%\n",
      "62\tValidation loss: 0.491277\tBest loss: 0.491277\tAccuracy: 87.70%\n",
      "63\tValidation loss: 0.491848\tBest loss: 0.491277\tAccuracy: 87.90%\n",
      "64\tValidation loss: 0.492110\tBest loss: 0.491277\tAccuracy: 87.60%\n",
      "65\tValidation loss: 0.486157\tBest loss: 0.486157\tAccuracy: 88.10%\n",
      "66\tValidation loss: 0.482837\tBest loss: 0.482837\tAccuracy: 87.90%\n",
      "67\tValidation loss: 0.485525\tBest loss: 0.482837\tAccuracy: 88.30%\n",
      "68\tValidation loss: 0.487209\tBest loss: 0.482837\tAccuracy: 87.60%\n",
      "69\tValidation loss: 0.474721\tBest loss: 0.474721\tAccuracy: 88.40%\n",
      "70\tValidation loss: 0.485011\tBest loss: 0.474721\tAccuracy: 88.10%\n",
      "71\tValidation loss: 0.480173\tBest loss: 0.474721\tAccuracy: 88.30%\n",
      "72\tValidation loss: 0.474521\tBest loss: 0.474521\tAccuracy: 88.40%\n",
      "73\tValidation loss: 0.480325\tBest loss: 0.474521\tAccuracy: 88.20%\n",
      "74\tValidation loss: 0.488457\tBest loss: 0.474521\tAccuracy: 87.70%\n",
      "75\tValidation loss: 0.471701\tBest loss: 0.471701\tAccuracy: 88.30%\n",
      "76\tValidation loss: 0.471655\tBest loss: 0.471655\tAccuracy: 88.20%\n",
      "77\tValidation loss: 0.471007\tBest loss: 0.471007\tAccuracy: 88.00%\n",
      "78\tValidation loss: 0.466757\tBest loss: 0.466757\tAccuracy: 87.90%\n",
      "79\tValidation loss: 0.462162\tBest loss: 0.462162\tAccuracy: 88.50%\n",
      "80\tValidation loss: 0.470591\tBest loss: 0.462162\tAccuracy: 88.60%\n",
      "81\tValidation loss: 0.469250\tBest loss: 0.462162\tAccuracy: 88.40%\n",
      "82\tValidation loss: 0.467867\tBest loss: 0.462162\tAccuracy: 88.20%\n",
      "83\tValidation loss: 0.455939\tBest loss: 0.455939\tAccuracy: 88.70%\n",
      "84\tValidation loss: 0.461158\tBest loss: 0.455939\tAccuracy: 88.70%\n",
      "85\tValidation loss: 0.457585\tBest loss: 0.455939\tAccuracy: 88.60%\n",
      "86\tValidation loss: 0.456173\tBest loss: 0.455939\tAccuracy: 88.50%\n",
      "87\tValidation loss: 0.456958\tBest loss: 0.455939\tAccuracy: 89.10%\n",
      "88\tValidation loss: 0.458629\tBest loss: 0.455939\tAccuracy: 88.80%\n",
      "89\tValidation loss: 0.459164\tBest loss: 0.455939\tAccuracy: 88.60%\n",
      "90\tValidation loss: 0.456011\tBest loss: 0.455939\tAccuracy: 89.00%\n",
      "91\tValidation loss: 0.449854\tBest loss: 0.449854\tAccuracy: 89.00%\n",
      "92\tValidation loss: 0.452421\tBest loss: 0.449854\tAccuracy: 89.10%\n",
      "93\tValidation loss: 0.448184\tBest loss: 0.448184\tAccuracy: 89.10%\n",
      "94\tValidation loss: 0.451336\tBest loss: 0.448184\tAccuracy: 88.70%\n",
      "95\tValidation loss: 0.451783\tBest loss: 0.448184\tAccuracy: 89.30%\n",
      "96\tValidation loss: 0.444556\tBest loss: 0.444556\tAccuracy: 88.80%\n",
      "97\tValidation loss: 0.445404\tBest loss: 0.444556\tAccuracy: 89.30%\n",
      "98\tValidation loss: 0.443530\tBest loss: 0.443530\tAccuracy: 88.80%\n",
      "99\tValidation loss: 0.442724\tBest loss: 0.442724\tAccuracy: 88.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\tValidation loss: 0.444452\tBest loss: 0.442724\tAccuracy: 89.30%\n",
      "101\tValidation loss: 0.437050\tBest loss: 0.437050\tAccuracy: 88.80%\n",
      "102\tValidation loss: 0.437395\tBest loss: 0.437050\tAccuracy: 89.00%\n",
      "103\tValidation loss: 0.442035\tBest loss: 0.437050\tAccuracy: 89.40%\n",
      "104\tValidation loss: 0.436677\tBest loss: 0.436677\tAccuracy: 89.40%\n",
      "105\tValidation loss: 0.437135\tBest loss: 0.436677\tAccuracy: 89.60%\n",
      "106\tValidation loss: 0.436806\tBest loss: 0.436677\tAccuracy: 89.10%\n",
      "107\tValidation loss: 0.436445\tBest loss: 0.436445\tAccuracy: 89.30%\n",
      "108\tValidation loss: 0.436630\tBest loss: 0.436445\tAccuracy: 89.40%\n",
      "109\tValidation loss: 0.433431\tBest loss: 0.433431\tAccuracy: 89.30%\n",
      "110\tValidation loss: 0.438393\tBest loss: 0.433431\tAccuracy: 89.00%\n",
      "111\tValidation loss: 0.432081\tBest loss: 0.432081\tAccuracy: 89.40%\n",
      "112\tValidation loss: 0.432284\tBest loss: 0.432081\tAccuracy: 89.50%\n",
      "113\tValidation loss: 0.427152\tBest loss: 0.427152\tAccuracy: 89.30%\n",
      "114\tValidation loss: 0.428340\tBest loss: 0.427152\tAccuracy: 89.60%\n",
      "115\tValidation loss: 0.429148\tBest loss: 0.427152\tAccuracy: 89.40%\n",
      "116\tValidation loss: 0.428255\tBest loss: 0.427152\tAccuracy: 89.60%\n",
      "117\tValidation loss: 0.424956\tBest loss: 0.424956\tAccuracy: 89.90%\n",
      "118\tValidation loss: 0.425177\tBest loss: 0.424956\tAccuracy: 89.80%\n",
      "119\tValidation loss: 0.427376\tBest loss: 0.424956\tAccuracy: 89.10%\n",
      "120\tValidation loss: 0.422707\tBest loss: 0.422707\tAccuracy: 89.50%\n",
      "121\tValidation loss: 0.427597\tBest loss: 0.422707\tAccuracy: 89.80%\n",
      "122\tValidation loss: 0.427701\tBest loss: 0.422707\tAccuracy: 90.00%\n",
      "123\tValidation loss: 0.422279\tBest loss: 0.422279\tAccuracy: 89.60%\n",
      "124\tValidation loss: 0.420385\tBest loss: 0.420385\tAccuracy: 89.70%\n",
      "125\tValidation loss: 0.420215\tBest loss: 0.420215\tAccuracy: 89.90%\n",
      "126\tValidation loss: 0.423192\tBest loss: 0.420215\tAccuracy: 89.80%\n",
      "127\tValidation loss: 0.424011\tBest loss: 0.420215\tAccuracy: 90.00%\n",
      "128\tValidation loss: 0.415710\tBest loss: 0.415710\tAccuracy: 89.50%\n",
      "129\tValidation loss: 0.416948\tBest loss: 0.415710\tAccuracy: 89.40%\n",
      "130\tValidation loss: 0.419637\tBest loss: 0.415710\tAccuracy: 89.70%\n",
      "131\tValidation loss: 0.414961\tBest loss: 0.414961\tAccuracy: 89.70%\n",
      "132\tValidation loss: 0.415574\tBest loss: 0.414961\tAccuracy: 89.70%\n",
      "133\tValidation loss: 0.415647\tBest loss: 0.414961\tAccuracy: 89.80%\n",
      "134\tValidation loss: 0.419294\tBest loss: 0.414961\tAccuracy: 89.80%\n",
      "135\tValidation loss: 0.415016\tBest loss: 0.414961\tAccuracy: 89.80%\n",
      "136\tValidation loss: 0.413722\tBest loss: 0.413722\tAccuracy: 90.30%\n",
      "137\tValidation loss: 0.410423\tBest loss: 0.410423\tAccuracy: 89.60%\n",
      "138\tValidation loss: 0.407580\tBest loss: 0.407580\tAccuracy: 90.00%\n",
      "139\tValidation loss: 0.408729\tBest loss: 0.407580\tAccuracy: 90.60%\n",
      "140\tValidation loss: 0.408020\tBest loss: 0.407580\tAccuracy: 90.40%\n",
      "141\tValidation loss: 0.410093\tBest loss: 0.407580\tAccuracy: 90.40%\n",
      "142\tValidation loss: 0.408044\tBest loss: 0.407580\tAccuracy: 90.20%\n",
      "143\tValidation loss: 0.405274\tBest loss: 0.405274\tAccuracy: 90.00%\n",
      "144\tValidation loss: 0.406039\tBest loss: 0.405274\tAccuracy: 90.40%\n",
      "145\tValidation loss: 0.405614\tBest loss: 0.405274\tAccuracy: 90.40%\n",
      "146\tValidation loss: 0.401585\tBest loss: 0.401585\tAccuracy: 90.40%\n",
      "147\tValidation loss: 0.402258\tBest loss: 0.401585\tAccuracy: 90.60%\n",
      "148\tValidation loss: 0.406020\tBest loss: 0.401585\tAccuracy: 90.40%\n",
      "149\tValidation loss: 0.405228\tBest loss: 0.401585\tAccuracy: 90.40%\n",
      "150\tValidation loss: 0.403570\tBest loss: 0.401585\tAccuracy: 90.50%\n",
      "151\tValidation loss: 0.401197\tBest loss: 0.401197\tAccuracy: 90.20%\n",
      "152\tValidation loss: 0.399132\tBest loss: 0.399132\tAccuracy: 90.60%\n",
      "153\tValidation loss: 0.395267\tBest loss: 0.395267\tAccuracy: 90.40%\n",
      "154\tValidation loss: 0.400296\tBest loss: 0.395267\tAccuracy: 90.60%\n",
      "155\tValidation loss: 0.398187\tBest loss: 0.395267\tAccuracy: 90.70%\n",
      "156\tValidation loss: 0.401090\tBest loss: 0.395267\tAccuracy: 91.00%\n",
      "157\tValidation loss: 0.405930\tBest loss: 0.395267\tAccuracy: 90.90%\n",
      "158\tValidation loss: 0.396136\tBest loss: 0.395267\tAccuracy: 90.70%\n",
      "159\tValidation loss: 0.398110\tBest loss: 0.395267\tAccuracy: 90.60%\n",
      "160\tValidation loss: 0.398873\tBest loss: 0.395267\tAccuracy: 90.50%\n",
      "161\tValidation loss: 0.398272\tBest loss: 0.395267\tAccuracy: 90.60%\n",
      "162\tValidation loss: 0.396275\tBest loss: 0.395267\tAccuracy: 90.60%\n",
      "163\tValidation loss: 0.396574\tBest loss: 0.395267\tAccuracy: 90.70%\n",
      "164\tValidation loss: 0.392885\tBest loss: 0.392885\tAccuracy: 90.90%\n",
      "165\tValidation loss: 0.393790\tBest loss: 0.392885\tAccuracy: 90.70%\n",
      "166\tValidation loss: 0.395942\tBest loss: 0.392885\tAccuracy: 91.00%\n",
      "167\tValidation loss: 0.388599\tBest loss: 0.388599\tAccuracy: 90.70%\n",
      "168\tValidation loss: 0.392768\tBest loss: 0.388599\tAccuracy: 90.90%\n",
      "169\tValidation loss: 0.387450\tBest loss: 0.387450\tAccuracy: 90.60%\n",
      "170\tValidation loss: 0.392087\tBest loss: 0.387450\tAccuracy: 90.70%\n",
      "171\tValidation loss: 0.387207\tBest loss: 0.387207\tAccuracy: 90.90%\n",
      "172\tValidation loss: 0.388974\tBest loss: 0.387207\tAccuracy: 91.20%\n",
      "173\tValidation loss: 0.394613\tBest loss: 0.387207\tAccuracy: 91.00%\n",
      "174\tValidation loss: 0.389988\tBest loss: 0.387207\tAccuracy: 91.00%\n",
      "175\tValidation loss: 0.385967\tBest loss: 0.385967\tAccuracy: 90.70%\n",
      "176\tValidation loss: 0.394599\tBest loss: 0.385967\tAccuracy: 91.20%\n",
      "177\tValidation loss: 0.387309\tBest loss: 0.385967\tAccuracy: 91.00%\n",
      "178\tValidation loss: 0.387080\tBest loss: 0.385967\tAccuracy: 90.80%\n",
      "179\tValidation loss: 0.385812\tBest loss: 0.385812\tAccuracy: 91.40%\n",
      "180\tValidation loss: 0.385864\tBest loss: 0.385812\tAccuracy: 90.90%\n",
      "181\tValidation loss: 0.383339\tBest loss: 0.383339\tAccuracy: 90.90%\n",
      "182\tValidation loss: 0.386655\tBest loss: 0.383339\tAccuracy: 91.10%\n",
      "183\tValidation loss: 0.387824\tBest loss: 0.383339\tAccuracy: 91.00%\n",
      "184\tValidation loss: 0.387964\tBest loss: 0.383339\tAccuracy: 91.10%\n",
      "185\tValidation loss: 0.383113\tBest loss: 0.383113\tAccuracy: 91.30%\n",
      "186\tValidation loss: 0.380147\tBest loss: 0.380147\tAccuracy: 91.30%\n",
      "187\tValidation loss: 0.379881\tBest loss: 0.379881\tAccuracy: 91.30%\n",
      "188\tValidation loss: 0.381858\tBest loss: 0.379881\tAccuracy: 90.80%\n",
      "189\tValidation loss: 0.383039\tBest loss: 0.379881\tAccuracy: 91.20%\n",
      "190\tValidation loss: 0.380516\tBest loss: 0.379881\tAccuracy: 91.00%\n",
      "191\tValidation loss: 0.381403\tBest loss: 0.379881\tAccuracy: 91.30%\n",
      "192\tValidation loss: 0.382501\tBest loss: 0.379881\tAccuracy: 91.10%\n",
      "193\tValidation loss: 0.378426\tBest loss: 0.378426\tAccuracy: 91.40%\n",
      "194\tValidation loss: 0.378123\tBest loss: 0.378123\tAccuracy: 90.90%\n",
      "195\tValidation loss: 0.375969\tBest loss: 0.375969\tAccuracy: 91.50%\n",
      "196\tValidation loss: 0.381790\tBest loss: 0.375969\tAccuracy: 91.30%\n",
      "197\tValidation loss: 0.376787\tBest loss: 0.375969\tAccuracy: 90.90%\n",
      "198\tValidation loss: 0.377997\tBest loss: 0.375969\tAccuracy: 91.20%\n",
      "199\tValidation loss: 0.375905\tBest loss: 0.375905\tAccuracy: 91.30%\n",
      "200\tValidation loss: 0.381548\tBest loss: 0.375905\tAccuracy: 91.10%\n",
      "201\tValidation loss: 0.378945\tBest loss: 0.375905\tAccuracy: 91.10%\n",
      "202\tValidation loss: 0.379594\tBest loss: 0.375905\tAccuracy: 91.30%\n",
      "203\tValidation loss: 0.375193\tBest loss: 0.375193\tAccuracy: 91.50%\n",
      "204\tValidation loss: 0.377690\tBest loss: 0.375193\tAccuracy: 91.30%\n",
      "205\tValidation loss: 0.375009\tBest loss: 0.375009\tAccuracy: 91.20%\n",
      "206\tValidation loss: 0.372724\tBest loss: 0.372724\tAccuracy: 91.20%\n",
      "207\tValidation loss: 0.375387\tBest loss: 0.372724\tAccuracy: 91.40%\n",
      "208\tValidation loss: 0.374729\tBest loss: 0.372724\tAccuracy: 91.60%\n",
      "209\tValidation loss: 0.369404\tBest loss: 0.369404\tAccuracy: 91.70%\n",
      "210\tValidation loss: 0.369562\tBest loss: 0.369404\tAccuracy: 91.20%\n",
      "211\tValidation loss: 0.370373\tBest loss: 0.369404\tAccuracy: 91.20%\n",
      "212\tValidation loss: 0.368962\tBest loss: 0.368962\tAccuracy: 91.60%\n",
      "213\tValidation loss: 0.373582\tBest loss: 0.368962\tAccuracy: 91.40%\n",
      "214\tValidation loss: 0.368191\tBest loss: 0.368191\tAccuracy: 91.80%\n",
      "215\tValidation loss: 0.369722\tBest loss: 0.368191\tAccuracy: 91.20%\n",
      "216\tValidation loss: 0.368614\tBest loss: 0.368191\tAccuracy: 91.30%\n",
      "217\tValidation loss: 0.369043\tBest loss: 0.368191\tAccuracy: 91.80%\n",
      "218\tValidation loss: 0.372178\tBest loss: 0.368191\tAccuracy: 91.30%\n",
      "219\tValidation loss: 0.371777\tBest loss: 0.368191\tAccuracy: 91.90%\n",
      "220\tValidation loss: 0.370357\tBest loss: 0.368191\tAccuracy: 91.60%\n",
      "221\tValidation loss: 0.370020\tBest loss: 0.368191\tAccuracy: 91.70%\n",
      "222\tValidation loss: 0.368099\tBest loss: 0.368099\tAccuracy: 91.70%\n",
      "223\tValidation loss: 0.369298\tBest loss: 0.368099\tAccuracy: 91.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\tValidation loss: 0.367037\tBest loss: 0.367037\tAccuracy: 92.00%\n",
      "225\tValidation loss: 0.365122\tBest loss: 0.365122\tAccuracy: 91.60%\n",
      "226\tValidation loss: 0.367097\tBest loss: 0.365122\tAccuracy: 91.90%\n",
      "227\tValidation loss: 0.363154\tBest loss: 0.363154\tAccuracy: 91.80%\n",
      "228\tValidation loss: 0.365685\tBest loss: 0.363154\tAccuracy: 91.90%\n",
      "229\tValidation loss: 0.367409\tBest loss: 0.363154\tAccuracy: 91.90%\n",
      "230\tValidation loss: 0.365474\tBest loss: 0.363154\tAccuracy: 91.70%\n",
      "231\tValidation loss: 0.366823\tBest loss: 0.363154\tAccuracy: 91.90%\n",
      "232\tValidation loss: 0.369199\tBest loss: 0.363154\tAccuracy: 91.60%\n",
      "233\tValidation loss: 0.365690\tBest loss: 0.363154\tAccuracy: 91.80%\n",
      "234\tValidation loss: 0.365774\tBest loss: 0.363154\tAccuracy: 91.60%\n",
      "235\tValidation loss: 0.360897\tBest loss: 0.360897\tAccuracy: 92.40%\n",
      "236\tValidation loss: 0.366793\tBest loss: 0.360897\tAccuracy: 92.00%\n",
      "237\tValidation loss: 0.362934\tBest loss: 0.360897\tAccuracy: 91.80%\n",
      "238\tValidation loss: 0.363975\tBest loss: 0.360897\tAccuracy: 92.50%\n",
      "239\tValidation loss: 0.360327\tBest loss: 0.360327\tAccuracy: 92.00%\n",
      "240\tValidation loss: 0.362535\tBest loss: 0.360327\tAccuracy: 91.80%\n",
      "241\tValidation loss: 0.360505\tBest loss: 0.360327\tAccuracy: 92.10%\n",
      "242\tValidation loss: 0.360811\tBest loss: 0.360327\tAccuracy: 91.90%\n",
      "243\tValidation loss: 0.361020\tBest loss: 0.360327\tAccuracy: 91.80%\n",
      "244\tValidation loss: 0.361086\tBest loss: 0.360327\tAccuracy: 91.90%\n",
      "245\tValidation loss: 0.363449\tBest loss: 0.360327\tAccuracy: 92.30%\n",
      "246\tValidation loss: 0.362144\tBest loss: 0.360327\tAccuracy: 92.00%\n",
      "247\tValidation loss: 0.357965\tBest loss: 0.357965\tAccuracy: 91.90%\n",
      "248\tValidation loss: 0.359455\tBest loss: 0.357965\tAccuracy: 92.20%\n",
      "249\tValidation loss: 0.359056\tBest loss: 0.357965\tAccuracy: 92.00%\n",
      "250\tValidation loss: 0.362016\tBest loss: 0.357965\tAccuracy: 92.40%\n",
      "251\tValidation loss: 0.357753\tBest loss: 0.357753\tAccuracy: 92.00%\n",
      "252\tValidation loss: 0.360626\tBest loss: 0.357753\tAccuracy: 92.20%\n",
      "253\tValidation loss: 0.358952\tBest loss: 0.357753\tAccuracy: 92.20%\n",
      "254\tValidation loss: 0.360215\tBest loss: 0.357753\tAccuracy: 92.40%\n",
      "255\tValidation loss: 0.357894\tBest loss: 0.357753\tAccuracy: 92.10%\n",
      "256\tValidation loss: 0.356300\tBest loss: 0.356300\tAccuracy: 92.40%\n",
      "257\tValidation loss: 0.359434\tBest loss: 0.356300\tAccuracy: 92.30%\n",
      "258\tValidation loss: 0.359499\tBest loss: 0.356300\tAccuracy: 92.10%\n",
      "259\tValidation loss: 0.353556\tBest loss: 0.353556\tAccuracy: 92.60%\n",
      "260\tValidation loss: 0.357000\tBest loss: 0.353556\tAccuracy: 92.40%\n",
      "261\tValidation loss: 0.351948\tBest loss: 0.351948\tAccuracy: 92.20%\n",
      "262\tValidation loss: 0.358715\tBest loss: 0.351948\tAccuracy: 92.30%\n",
      "263\tValidation loss: 0.358895\tBest loss: 0.351948\tAccuracy: 92.10%\n",
      "264\tValidation loss: 0.357871\tBest loss: 0.351948\tAccuracy: 92.50%\n",
      "265\tValidation loss: 0.356856\tBest loss: 0.351948\tAccuracy: 92.30%\n",
      "266\tValidation loss: 0.357498\tBest loss: 0.351948\tAccuracy: 92.40%\n",
      "267\tValidation loss: 0.355055\tBest loss: 0.351948\tAccuracy: 92.60%\n",
      "268\tValidation loss: 0.356152\tBest loss: 0.351948\tAccuracy: 92.30%\n",
      "269\tValidation loss: 0.353975\tBest loss: 0.351948\tAccuracy: 92.40%\n",
      "270\tValidation loss: 0.354553\tBest loss: 0.351948\tAccuracy: 92.60%\n",
      "271\tValidation loss: 0.352582\tBest loss: 0.351948\tAccuracy: 92.20%\n",
      "272\tValidation loss: 0.352101\tBest loss: 0.351948\tAccuracy: 92.60%\n",
      "273\tValidation loss: 0.354674\tBest loss: 0.351948\tAccuracy: 92.70%\n",
      "274\tValidation loss: 0.354807\tBest loss: 0.351948\tAccuracy: 92.40%\n",
      "275\tValidation loss: 0.353658\tBest loss: 0.351948\tAccuracy: 92.40%\n",
      "276\tValidation loss: 0.356220\tBest loss: 0.351948\tAccuracy: 92.30%\n",
      "277\tValidation loss: 0.353640\tBest loss: 0.351948\tAccuracy: 92.70%\n",
      "278\tValidation loss: 0.353056\tBest loss: 0.351948\tAccuracy: 92.40%\n",
      "279\tValidation loss: 0.354344\tBest loss: 0.351948\tAccuracy: 92.50%\n",
      "280\tValidation loss: 0.354637\tBest loss: 0.351948\tAccuracy: 92.50%\n",
      "281\tValidation loss: 0.352136\tBest loss: 0.351948\tAccuracy: 92.90%\n",
      "282\tValidation loss: 0.352432\tBest loss: 0.351948\tAccuracy: 92.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  32.7s\n",
      "[CV] batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.735945\tBest loss: 2.735945\tAccuracy: 32.30%\n",
      "1\tValidation loss: 2.144732\tBest loss: 2.144732\tAccuracy: 46.30%\n",
      "2\tValidation loss: 1.754656\tBest loss: 1.754656\tAccuracy: 56.50%\n",
      "3\tValidation loss: 1.506318\tBest loss: 1.506318\tAccuracy: 61.90%\n",
      "4\tValidation loss: 1.340346\tBest loss: 1.340346\tAccuracy: 67.30%\n",
      "5\tValidation loss: 1.231119\tBest loss: 1.231119\tAccuracy: 68.80%\n",
      "6\tValidation loss: 1.130785\tBest loss: 1.130785\tAccuracy: 71.80%\n",
      "7\tValidation loss: 1.058796\tBest loss: 1.058796\tAccuracy: 71.90%\n",
      "8\tValidation loss: 1.003986\tBest loss: 1.003986\tAccuracy: 74.10%\n",
      "9\tValidation loss: 0.959566\tBest loss: 0.959566\tAccuracy: 74.90%\n",
      "10\tValidation loss: 0.908684\tBest loss: 0.908684\tAccuracy: 77.00%\n",
      "11\tValidation loss: 0.876337\tBest loss: 0.876337\tAccuracy: 77.30%\n",
      "12\tValidation loss: 0.851435\tBest loss: 0.851435\tAccuracy: 76.70%\n",
      "13\tValidation loss: 0.822038\tBest loss: 0.822038\tAccuracy: 79.00%\n",
      "14\tValidation loss: 0.790655\tBest loss: 0.790655\tAccuracy: 80.20%\n",
      "15\tValidation loss: 0.771890\tBest loss: 0.771890\tAccuracy: 80.80%\n",
      "16\tValidation loss: 0.749618\tBest loss: 0.749618\tAccuracy: 80.20%\n",
      "17\tValidation loss: 0.732490\tBest loss: 0.732490\tAccuracy: 81.80%\n",
      "18\tValidation loss: 0.720767\tBest loss: 0.720767\tAccuracy: 81.90%\n",
      "19\tValidation loss: 0.709233\tBest loss: 0.709233\tAccuracy: 82.50%\n",
      "20\tValidation loss: 0.688495\tBest loss: 0.688495\tAccuracy: 82.90%\n",
      "21\tValidation loss: 0.678869\tBest loss: 0.678869\tAccuracy: 82.70%\n",
      "22\tValidation loss: 0.671513\tBest loss: 0.671513\tAccuracy: 83.40%\n",
      "23\tValidation loss: 0.664183\tBest loss: 0.664183\tAccuracy: 82.70%\n",
      "24\tValidation loss: 0.646461\tBest loss: 0.646461\tAccuracy: 83.40%\n",
      "25\tValidation loss: 0.644481\tBest loss: 0.644481\tAccuracy: 84.50%\n",
      "26\tValidation loss: 0.633788\tBest loss: 0.633788\tAccuracy: 84.30%\n",
      "27\tValidation loss: 0.624274\tBest loss: 0.624274\tAccuracy: 85.00%\n",
      "28\tValidation loss: 0.616010\tBest loss: 0.616010\tAccuracy: 84.60%\n",
      "29\tValidation loss: 0.612846\tBest loss: 0.612846\tAccuracy: 84.30%\n",
      "30\tValidation loss: 0.603093\tBest loss: 0.603093\tAccuracy: 85.40%\n",
      "31\tValidation loss: 0.597372\tBest loss: 0.597372\tAccuracy: 85.00%\n",
      "32\tValidation loss: 0.595255\tBest loss: 0.595255\tAccuracy: 85.20%\n",
      "33\tValidation loss: 0.586133\tBest loss: 0.586133\tAccuracy: 84.70%\n",
      "34\tValidation loss: 0.588284\tBest loss: 0.586133\tAccuracy: 84.90%\n",
      "35\tValidation loss: 0.578133\tBest loss: 0.578133\tAccuracy: 85.40%\n",
      "36\tValidation loss: 0.576591\tBest loss: 0.576591\tAccuracy: 86.40%\n",
      "37\tValidation loss: 0.567135\tBest loss: 0.567135\tAccuracy: 86.10%\n",
      "38\tValidation loss: 0.563162\tBest loss: 0.563162\tAccuracy: 86.30%\n",
      "39\tValidation loss: 0.566268\tBest loss: 0.563162\tAccuracy: 85.80%\n",
      "40\tValidation loss: 0.554812\tBest loss: 0.554812\tAccuracy: 86.10%\n",
      "41\tValidation loss: 0.555611\tBest loss: 0.554812\tAccuracy: 85.70%\n",
      "42\tValidation loss: 0.548150\tBest loss: 0.548150\tAccuracy: 86.40%\n",
      "43\tValidation loss: 0.539968\tBest loss: 0.539968\tAccuracy: 86.40%\n",
      "44\tValidation loss: 0.543755\tBest loss: 0.539968\tAccuracy: 86.50%\n",
      "45\tValidation loss: 0.539696\tBest loss: 0.539696\tAccuracy: 86.20%\n",
      "46\tValidation loss: 0.541384\tBest loss: 0.539696\tAccuracy: 85.80%\n",
      "47\tValidation loss: 0.538183\tBest loss: 0.538183\tAccuracy: 85.90%\n",
      "48\tValidation loss: 0.535014\tBest loss: 0.535014\tAccuracy: 86.60%\n",
      "49\tValidation loss: 0.530179\tBest loss: 0.530179\tAccuracy: 86.30%\n",
      "50\tValidation loss: 0.526906\tBest loss: 0.526906\tAccuracy: 86.40%\n",
      "51\tValidation loss: 0.519925\tBest loss: 0.519925\tAccuracy: 87.10%\n",
      "52\tValidation loss: 0.519034\tBest loss: 0.519034\tAccuracy: 87.80%\n",
      "53\tValidation loss: 0.512464\tBest loss: 0.512464\tAccuracy: 87.50%\n",
      "54\tValidation loss: 0.514604\tBest loss: 0.512464\tAccuracy: 87.30%\n",
      "55\tValidation loss: 0.506737\tBest loss: 0.506737\tAccuracy: 87.50%\n",
      "56\tValidation loss: 0.507068\tBest loss: 0.506737\tAccuracy: 87.10%\n",
      "57\tValidation loss: 0.508052\tBest loss: 0.506737\tAccuracy: 86.80%\n",
      "58\tValidation loss: 0.508848\tBest loss: 0.506737\tAccuracy: 86.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\tValidation loss: 0.502396\tBest loss: 0.502396\tAccuracy: 87.30%\n",
      "60\tValidation loss: 0.504867\tBest loss: 0.502396\tAccuracy: 86.90%\n",
      "61\tValidation loss: 0.501084\tBest loss: 0.501084\tAccuracy: 87.40%\n",
      "62\tValidation loss: 0.504939\tBest loss: 0.501084\tAccuracy: 87.60%\n",
      "63\tValidation loss: 0.490930\tBest loss: 0.490930\tAccuracy: 87.80%\n",
      "64\tValidation loss: 0.490665\tBest loss: 0.490665\tAccuracy: 87.90%\n",
      "65\tValidation loss: 0.492125\tBest loss: 0.490665\tAccuracy: 88.00%\n",
      "66\tValidation loss: 0.491918\tBest loss: 0.490665\tAccuracy: 87.90%\n",
      "67\tValidation loss: 0.494334\tBest loss: 0.490665\tAccuracy: 87.30%\n",
      "68\tValidation loss: 0.486126\tBest loss: 0.486126\tAccuracy: 87.70%\n",
      "69\tValidation loss: 0.489037\tBest loss: 0.486126\tAccuracy: 87.80%\n",
      "70\tValidation loss: 0.487629\tBest loss: 0.486126\tAccuracy: 87.40%\n",
      "71\tValidation loss: 0.485726\tBest loss: 0.485726\tAccuracy: 87.50%\n",
      "72\tValidation loss: 0.494593\tBest loss: 0.485726\tAccuracy: 87.50%\n",
      "73\tValidation loss: 0.480364\tBest loss: 0.480364\tAccuracy: 87.40%\n",
      "74\tValidation loss: 0.484380\tBest loss: 0.480364\tAccuracy: 87.30%\n",
      "75\tValidation loss: 0.483138\tBest loss: 0.480364\tAccuracy: 87.60%\n",
      "76\tValidation loss: 0.473754\tBest loss: 0.473754\tAccuracy: 88.30%\n",
      "77\tValidation loss: 0.477545\tBest loss: 0.473754\tAccuracy: 88.20%\n",
      "78\tValidation loss: 0.471209\tBest loss: 0.471209\tAccuracy: 88.30%\n",
      "79\tValidation loss: 0.473865\tBest loss: 0.471209\tAccuracy: 88.30%\n",
      "80\tValidation loss: 0.470471\tBest loss: 0.470471\tAccuracy: 87.80%\n",
      "81\tValidation loss: 0.474212\tBest loss: 0.470471\tAccuracy: 88.10%\n",
      "82\tValidation loss: 0.467808\tBest loss: 0.467808\tAccuracy: 88.10%\n",
      "83\tValidation loss: 0.471517\tBest loss: 0.467808\tAccuracy: 88.20%\n",
      "84\tValidation loss: 0.468678\tBest loss: 0.467808\tAccuracy: 88.60%\n",
      "85\tValidation loss: 0.463907\tBest loss: 0.463907\tAccuracy: 88.60%\n",
      "86\tValidation loss: 0.465695\tBest loss: 0.463907\tAccuracy: 88.80%\n",
      "87\tValidation loss: 0.467215\tBest loss: 0.463907\tAccuracy: 88.20%\n",
      "88\tValidation loss: 0.462687\tBest loss: 0.462687\tAccuracy: 88.30%\n",
      "89\tValidation loss: 0.470104\tBest loss: 0.462687\tAccuracy: 88.10%\n",
      "90\tValidation loss: 0.462986\tBest loss: 0.462687\tAccuracy: 88.20%\n",
      "91\tValidation loss: 0.462334\tBest loss: 0.462334\tAccuracy: 88.00%\n",
      "92\tValidation loss: 0.470585\tBest loss: 0.462334\tAccuracy: 89.10%\n",
      "93\tValidation loss: 0.459664\tBest loss: 0.459664\tAccuracy: 88.60%\n",
      "94\tValidation loss: 0.459205\tBest loss: 0.459205\tAccuracy: 88.90%\n",
      "95\tValidation loss: 0.457124\tBest loss: 0.457124\tAccuracy: 88.20%\n",
      "96\tValidation loss: 0.456784\tBest loss: 0.456784\tAccuracy: 88.90%\n",
      "97\tValidation loss: 0.459403\tBest loss: 0.456784\tAccuracy: 88.60%\n",
      "98\tValidation loss: 0.459692\tBest loss: 0.456784\tAccuracy: 88.10%\n",
      "99\tValidation loss: 0.460130\tBest loss: 0.456784\tAccuracy: 88.60%\n",
      "100\tValidation loss: 0.459024\tBest loss: 0.456784\tAccuracy: 89.20%\n",
      "101\tValidation loss: 0.457664\tBest loss: 0.456784\tAccuracy: 89.10%\n",
      "102\tValidation loss: 0.454315\tBest loss: 0.454315\tAccuracy: 88.80%\n",
      "103\tValidation loss: 0.452372\tBest loss: 0.452372\tAccuracy: 89.50%\n",
      "104\tValidation loss: 0.452092\tBest loss: 0.452092\tAccuracy: 89.30%\n",
      "105\tValidation loss: 0.453240\tBest loss: 0.452092\tAccuracy: 89.80%\n",
      "106\tValidation loss: 0.451879\tBest loss: 0.451879\tAccuracy: 89.40%\n",
      "107\tValidation loss: 0.453052\tBest loss: 0.451879\tAccuracy: 89.20%\n",
      "108\tValidation loss: 0.460049\tBest loss: 0.451879\tAccuracy: 88.90%\n",
      "109\tValidation loss: 0.456529\tBest loss: 0.451879\tAccuracy: 89.40%\n",
      "110\tValidation loss: 0.456061\tBest loss: 0.451879\tAccuracy: 89.60%\n",
      "111\tValidation loss: 0.453664\tBest loss: 0.451879\tAccuracy: 89.60%\n",
      "112\tValidation loss: 0.454653\tBest loss: 0.451879\tAccuracy: 89.50%\n",
      "113\tValidation loss: 0.448834\tBest loss: 0.448834\tAccuracy: 89.80%\n",
      "114\tValidation loss: 0.449062\tBest loss: 0.448834\tAccuracy: 89.50%\n",
      "115\tValidation loss: 0.453885\tBest loss: 0.448834\tAccuracy: 89.50%\n",
      "116\tValidation loss: 0.453216\tBest loss: 0.448834\tAccuracy: 89.80%\n",
      "117\tValidation loss: 0.447097\tBest loss: 0.447097\tAccuracy: 89.80%\n",
      "118\tValidation loss: 0.451188\tBest loss: 0.447097\tAccuracy: 89.90%\n",
      "119\tValidation loss: 0.453038\tBest loss: 0.447097\tAccuracy: 89.80%\n",
      "120\tValidation loss: 0.445648\tBest loss: 0.445648\tAccuracy: 89.90%\n",
      "121\tValidation loss: 0.448775\tBest loss: 0.445648\tAccuracy: 89.90%\n",
      "122\tValidation loss: 0.443161\tBest loss: 0.443161\tAccuracy: 90.30%\n",
      "123\tValidation loss: 0.444688\tBest loss: 0.443161\tAccuracy: 89.90%\n",
      "124\tValidation loss: 0.446586\tBest loss: 0.443161\tAccuracy: 89.90%\n",
      "125\tValidation loss: 0.444941\tBest loss: 0.443161\tAccuracy: 89.80%\n",
      "126\tValidation loss: 0.447503\tBest loss: 0.443161\tAccuracy: 90.10%\n",
      "127\tValidation loss: 0.447105\tBest loss: 0.443161\tAccuracy: 90.20%\n",
      "128\tValidation loss: 0.444561\tBest loss: 0.443161\tAccuracy: 90.20%\n",
      "129\tValidation loss: 0.442981\tBest loss: 0.442981\tAccuracy: 90.20%\n",
      "130\tValidation loss: 0.438647\tBest loss: 0.438647\tAccuracy: 90.30%\n",
      "131\tValidation loss: 0.437912\tBest loss: 0.437912\tAccuracy: 90.10%\n",
      "132\tValidation loss: 0.442166\tBest loss: 0.437912\tAccuracy: 89.90%\n",
      "133\tValidation loss: 0.444387\tBest loss: 0.437912\tAccuracy: 90.40%\n",
      "134\tValidation loss: 0.441713\tBest loss: 0.437912\tAccuracy: 89.90%\n",
      "135\tValidation loss: 0.445976\tBest loss: 0.437912\tAccuracy: 90.30%\n",
      "136\tValidation loss: 0.439382\tBest loss: 0.437912\tAccuracy: 90.30%\n",
      "137\tValidation loss: 0.441872\tBest loss: 0.437912\tAccuracy: 90.30%\n",
      "138\tValidation loss: 0.439778\tBest loss: 0.437912\tAccuracy: 90.50%\n",
      "139\tValidation loss: 0.441657\tBest loss: 0.437912\tAccuracy: 90.40%\n",
      "140\tValidation loss: 0.441846\tBest loss: 0.437912\tAccuracy: 90.40%\n",
      "141\tValidation loss: 0.440359\tBest loss: 0.437912\tAccuracy: 91.10%\n",
      "142\tValidation loss: 0.439080\tBest loss: 0.437912\tAccuracy: 90.40%\n",
      "143\tValidation loss: 0.439025\tBest loss: 0.437912\tAccuracy: 90.20%\n",
      "144\tValidation loss: 0.437318\tBest loss: 0.437318\tAccuracy: 90.80%\n",
      "145\tValidation loss: 0.440350\tBest loss: 0.437318\tAccuracy: 90.50%\n",
      "146\tValidation loss: 0.439108\tBest loss: 0.437318\tAccuracy: 90.40%\n",
      "147\tValidation loss: 0.436466\tBest loss: 0.436466\tAccuracy: 90.80%\n",
      "148\tValidation loss: 0.439065\tBest loss: 0.436466\tAccuracy: 90.70%\n",
      "149\tValidation loss: 0.436970\tBest loss: 0.436466\tAccuracy: 90.20%\n",
      "150\tValidation loss: 0.437757\tBest loss: 0.436466\tAccuracy: 90.90%\n",
      "151\tValidation loss: 0.438561\tBest loss: 0.436466\tAccuracy: 90.50%\n",
      "152\tValidation loss: 0.436837\tBest loss: 0.436466\tAccuracy: 90.50%\n",
      "153\tValidation loss: 0.441649\tBest loss: 0.436466\tAccuracy: 90.50%\n",
      "154\tValidation loss: 0.440229\tBest loss: 0.436466\tAccuracy: 90.60%\n",
      "155\tValidation loss: 0.439943\tBest loss: 0.436466\tAccuracy: 90.90%\n",
      "156\tValidation loss: 0.435037\tBest loss: 0.435037\tAccuracy: 91.20%\n",
      "157\tValidation loss: 0.432331\tBest loss: 0.432331\tAccuracy: 90.90%\n",
      "158\tValidation loss: 0.436190\tBest loss: 0.432331\tAccuracy: 90.80%\n",
      "159\tValidation loss: 0.439568\tBest loss: 0.432331\tAccuracy: 90.60%\n",
      "160\tValidation loss: 0.437880\tBest loss: 0.432331\tAccuracy: 90.80%\n",
      "161\tValidation loss: 0.441383\tBest loss: 0.432331\tAccuracy: 90.70%\n",
      "162\tValidation loss: 0.438133\tBest loss: 0.432331\tAccuracy: 90.60%\n",
      "163\tValidation loss: 0.442193\tBest loss: 0.432331\tAccuracy: 90.70%\n",
      "164\tValidation loss: 0.432427\tBest loss: 0.432331\tAccuracy: 90.70%\n",
      "165\tValidation loss: 0.436414\tBest loss: 0.432331\tAccuracy: 90.80%\n",
      "166\tValidation loss: 0.431533\tBest loss: 0.431533\tAccuracy: 91.20%\n",
      "167\tValidation loss: 0.434720\tBest loss: 0.431533\tAccuracy: 91.10%\n",
      "168\tValidation loss: 0.433425\tBest loss: 0.431533\tAccuracy: 91.40%\n",
      "169\tValidation loss: 0.436573\tBest loss: 0.431533\tAccuracy: 90.80%\n",
      "170\tValidation loss: 0.428480\tBest loss: 0.428480\tAccuracy: 90.70%\n",
      "171\tValidation loss: 0.433939\tBest loss: 0.428480\tAccuracy: 91.00%\n",
      "172\tValidation loss: 0.433892\tBest loss: 0.428480\tAccuracy: 90.70%\n",
      "173\tValidation loss: 0.434280\tBest loss: 0.428480\tAccuracy: 90.90%\n",
      "174\tValidation loss: 0.428886\tBest loss: 0.428480\tAccuracy: 91.00%\n",
      "175\tValidation loss: 0.435513\tBest loss: 0.428480\tAccuracy: 90.90%\n",
      "176\tValidation loss: 0.436360\tBest loss: 0.428480\tAccuracy: 91.20%\n",
      "177\tValidation loss: 0.436634\tBest loss: 0.428480\tAccuracy: 91.00%\n",
      "178\tValidation loss: 0.435607\tBest loss: 0.428480\tAccuracy: 91.00%\n",
      "179\tValidation loss: 0.435447\tBest loss: 0.428480\tAccuracy: 91.30%\n",
      "180\tValidation loss: 0.432605\tBest loss: 0.428480\tAccuracy: 91.10%\n",
      "181\tValidation loss: 0.433028\tBest loss: 0.428480\tAccuracy: 90.70%\n",
      "182\tValidation loss: 0.430206\tBest loss: 0.428480\tAccuracy: 91.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\tValidation loss: 0.432192\tBest loss: 0.428480\tAccuracy: 91.30%\n",
      "184\tValidation loss: 0.434820\tBest loss: 0.428480\tAccuracy: 91.20%\n",
      "185\tValidation loss: 0.432338\tBest loss: 0.428480\tAccuracy: 91.10%\n",
      "186\tValidation loss: 0.433219\tBest loss: 0.428480\tAccuracy: 91.20%\n",
      "187\tValidation loss: 0.432232\tBest loss: 0.428480\tAccuracy: 90.80%\n",
      "188\tValidation loss: 0.429408\tBest loss: 0.428480\tAccuracy: 91.30%\n",
      "189\tValidation loss: 0.432721\tBest loss: 0.428480\tAccuracy: 91.00%\n",
      "190\tValidation loss: 0.429295\tBest loss: 0.428480\tAccuracy: 91.10%\n",
      "191\tValidation loss: 0.432707\tBest loss: 0.428480\tAccuracy: 91.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  21.9s\n",
      "[CV] batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.721998\tBest loss: 2.721998\tAccuracy: 32.40%\n",
      "1\tValidation loss: 2.128473\tBest loss: 2.128473\tAccuracy: 46.70%\n",
      "2\tValidation loss: 1.763321\tBest loss: 1.763321\tAccuracy: 55.80%\n",
      "3\tValidation loss: 1.517915\tBest loss: 1.517915\tAccuracy: 60.50%\n",
      "4\tValidation loss: 1.347132\tBest loss: 1.347132\tAccuracy: 66.30%\n",
      "5\tValidation loss: 1.230378\tBest loss: 1.230378\tAccuracy: 69.30%\n",
      "6\tValidation loss: 1.136748\tBest loss: 1.136748\tAccuracy: 71.30%\n",
      "7\tValidation loss: 1.060864\tBest loss: 1.060864\tAccuracy: 72.50%\n",
      "8\tValidation loss: 1.003434\tBest loss: 1.003434\tAccuracy: 73.90%\n",
      "9\tValidation loss: 0.965506\tBest loss: 0.965506\tAccuracy: 74.30%\n",
      "10\tValidation loss: 0.921295\tBest loss: 0.921295\tAccuracy: 76.50%\n",
      "11\tValidation loss: 0.876413\tBest loss: 0.876413\tAccuracy: 77.70%\n",
      "12\tValidation loss: 0.851789\tBest loss: 0.851789\tAccuracy: 77.90%\n",
      "13\tValidation loss: 0.813909\tBest loss: 0.813909\tAccuracy: 79.40%\n",
      "14\tValidation loss: 0.799409\tBest loss: 0.799409\tAccuracy: 79.50%\n",
      "15\tValidation loss: 0.776994\tBest loss: 0.776994\tAccuracy: 80.60%\n",
      "16\tValidation loss: 0.764395\tBest loss: 0.764395\tAccuracy: 80.50%\n",
      "17\tValidation loss: 0.737466\tBest loss: 0.737466\tAccuracy: 81.90%\n",
      "18\tValidation loss: 0.724909\tBest loss: 0.724909\tAccuracy: 82.20%\n",
      "19\tValidation loss: 0.708803\tBest loss: 0.708803\tAccuracy: 82.30%\n",
      "20\tValidation loss: 0.702128\tBest loss: 0.702128\tAccuracy: 83.20%\n",
      "21\tValidation loss: 0.685988\tBest loss: 0.685988\tAccuracy: 82.30%\n",
      "22\tValidation loss: 0.661769\tBest loss: 0.661769\tAccuracy: 83.60%\n",
      "23\tValidation loss: 0.662566\tBest loss: 0.661769\tAccuracy: 83.70%\n",
      "24\tValidation loss: 0.657160\tBest loss: 0.657160\tAccuracy: 83.50%\n",
      "25\tValidation loss: 0.643821\tBest loss: 0.643821\tAccuracy: 84.00%\n",
      "26\tValidation loss: 0.632327\tBest loss: 0.632327\tAccuracy: 84.10%\n",
      "27\tValidation loss: 0.624562\tBest loss: 0.624562\tAccuracy: 84.50%\n",
      "28\tValidation loss: 0.622775\tBest loss: 0.622775\tAccuracy: 83.40%\n",
      "29\tValidation loss: 0.613120\tBest loss: 0.613120\tAccuracy: 84.50%\n",
      "30\tValidation loss: 0.604709\tBest loss: 0.604709\tAccuracy: 84.80%\n",
      "31\tValidation loss: 0.598852\tBest loss: 0.598852\tAccuracy: 85.40%\n",
      "32\tValidation loss: 0.597889\tBest loss: 0.597889\tAccuracy: 85.00%\n",
      "33\tValidation loss: 0.592816\tBest loss: 0.592816\tAccuracy: 84.70%\n",
      "34\tValidation loss: 0.582213\tBest loss: 0.582213\tAccuracy: 85.20%\n",
      "35\tValidation loss: 0.578318\tBest loss: 0.578318\tAccuracy: 85.60%\n",
      "36\tValidation loss: 0.576743\tBest loss: 0.576743\tAccuracy: 85.60%\n",
      "37\tValidation loss: 0.560527\tBest loss: 0.560527\tAccuracy: 85.80%\n",
      "38\tValidation loss: 0.564057\tBest loss: 0.560527\tAccuracy: 85.80%\n",
      "39\tValidation loss: 0.557298\tBest loss: 0.557298\tAccuracy: 85.60%\n",
      "40\tValidation loss: 0.550802\tBest loss: 0.550802\tAccuracy: 86.40%\n",
      "41\tValidation loss: 0.545808\tBest loss: 0.545808\tAccuracy: 86.10%\n",
      "42\tValidation loss: 0.545474\tBest loss: 0.545474\tAccuracy: 85.80%\n",
      "43\tValidation loss: 0.538028\tBest loss: 0.538028\tAccuracy: 86.80%\n",
      "44\tValidation loss: 0.531407\tBest loss: 0.531407\tAccuracy: 86.80%\n",
      "45\tValidation loss: 0.538067\tBest loss: 0.531407\tAccuracy: 86.40%\n",
      "46\tValidation loss: 0.532874\tBest loss: 0.531407\tAccuracy: 86.60%\n",
      "47\tValidation loss: 0.526135\tBest loss: 0.526135\tAccuracy: 87.10%\n",
      "48\tValidation loss: 0.522168\tBest loss: 0.522168\tAccuracy: 86.60%\n",
      "49\tValidation loss: 0.522651\tBest loss: 0.522168\tAccuracy: 87.20%\n",
      "50\tValidation loss: 0.519782\tBest loss: 0.519782\tAccuracy: 87.00%\n",
      "51\tValidation loss: 0.514334\tBest loss: 0.514334\tAccuracy: 87.40%\n",
      "52\tValidation loss: 0.513840\tBest loss: 0.513840\tAccuracy: 87.30%\n",
      "53\tValidation loss: 0.510341\tBest loss: 0.510341\tAccuracy: 87.30%\n",
      "54\tValidation loss: 0.505328\tBest loss: 0.505328\tAccuracy: 87.60%\n",
      "55\tValidation loss: 0.505415\tBest loss: 0.505328\tAccuracy: 87.70%\n",
      "56\tValidation loss: 0.503606\tBest loss: 0.503606\tAccuracy: 87.70%\n",
      "57\tValidation loss: 0.494207\tBest loss: 0.494207\tAccuracy: 87.90%\n",
      "58\tValidation loss: 0.493731\tBest loss: 0.493731\tAccuracy: 87.80%\n",
      "59\tValidation loss: 0.492914\tBest loss: 0.492914\tAccuracy: 88.20%\n",
      "60\tValidation loss: 0.495677\tBest loss: 0.492914\tAccuracy: 87.80%\n",
      "61\tValidation loss: 0.496535\tBest loss: 0.492914\tAccuracy: 87.30%\n",
      "62\tValidation loss: 0.491601\tBest loss: 0.491601\tAccuracy: 87.90%\n",
      "63\tValidation loss: 0.478115\tBest loss: 0.478115\tAccuracy: 88.00%\n",
      "64\tValidation loss: 0.483989\tBest loss: 0.478115\tAccuracy: 88.10%\n",
      "65\tValidation loss: 0.482918\tBest loss: 0.478115\tAccuracy: 87.50%\n",
      "66\tValidation loss: 0.476834\tBest loss: 0.476834\tAccuracy: 88.50%\n",
      "67\tValidation loss: 0.482619\tBest loss: 0.476834\tAccuracy: 88.50%\n",
      "68\tValidation loss: 0.471322\tBest loss: 0.471322\tAccuracy: 88.30%\n",
      "69\tValidation loss: 0.475118\tBest loss: 0.471322\tAccuracy: 88.30%\n",
      "70\tValidation loss: 0.472573\tBest loss: 0.471322\tAccuracy: 88.30%\n",
      "71\tValidation loss: 0.471334\tBest loss: 0.471322\tAccuracy: 89.10%\n",
      "72\tValidation loss: 0.466551\tBest loss: 0.466551\tAccuracy: 88.60%\n",
      "73\tValidation loss: 0.468312\tBest loss: 0.466551\tAccuracy: 88.20%\n",
      "74\tValidation loss: 0.464819\tBest loss: 0.464819\tAccuracy: 88.50%\n",
      "75\tValidation loss: 0.463782\tBest loss: 0.463782\tAccuracy: 89.00%\n",
      "76\tValidation loss: 0.464442\tBest loss: 0.463782\tAccuracy: 87.90%\n",
      "77\tValidation loss: 0.462202\tBest loss: 0.462202\tAccuracy: 88.80%\n",
      "78\tValidation loss: 0.457175\tBest loss: 0.457175\tAccuracy: 88.90%\n",
      "79\tValidation loss: 0.459824\tBest loss: 0.457175\tAccuracy: 88.50%\n",
      "80\tValidation loss: 0.453496\tBest loss: 0.453496\tAccuracy: 89.00%\n",
      "81\tValidation loss: 0.455688\tBest loss: 0.453496\tAccuracy: 89.30%\n",
      "82\tValidation loss: 0.450546\tBest loss: 0.450546\tAccuracy: 89.30%\n",
      "83\tValidation loss: 0.451210\tBest loss: 0.450546\tAccuracy: 89.10%\n",
      "84\tValidation loss: 0.450697\tBest loss: 0.450546\tAccuracy: 89.30%\n",
      "85\tValidation loss: 0.447744\tBest loss: 0.447744\tAccuracy: 89.50%\n",
      "86\tValidation loss: 0.444098\tBest loss: 0.444098\tAccuracy: 89.10%\n",
      "87\tValidation loss: 0.445899\tBest loss: 0.444098\tAccuracy: 88.70%\n",
      "88\tValidation loss: 0.439913\tBest loss: 0.439913\tAccuracy: 89.70%\n",
      "89\tValidation loss: 0.444021\tBest loss: 0.439913\tAccuracy: 89.40%\n",
      "90\tValidation loss: 0.438030\tBest loss: 0.438030\tAccuracy: 89.60%\n",
      "91\tValidation loss: 0.436030\tBest loss: 0.436030\tAccuracy: 89.30%\n",
      "92\tValidation loss: 0.444436\tBest loss: 0.436030\tAccuracy: 88.80%\n",
      "93\tValidation loss: 0.437519\tBest loss: 0.436030\tAccuracy: 89.10%\n",
      "94\tValidation loss: 0.439403\tBest loss: 0.436030\tAccuracy: 89.30%\n",
      "95\tValidation loss: 0.432532\tBest loss: 0.432532\tAccuracy: 89.40%\n",
      "96\tValidation loss: 0.431718\tBest loss: 0.431718\tAccuracy: 89.60%\n",
      "97\tValidation loss: 0.437279\tBest loss: 0.431718\tAccuracy: 89.20%\n",
      "98\tValidation loss: 0.429098\tBest loss: 0.429098\tAccuracy: 89.10%\n",
      "99\tValidation loss: 0.426965\tBest loss: 0.426965\tAccuracy: 89.50%\n",
      "100\tValidation loss: 0.429869\tBest loss: 0.426965\tAccuracy: 89.40%\n",
      "101\tValidation loss: 0.427034\tBest loss: 0.426965\tAccuracy: 89.40%\n",
      "102\tValidation loss: 0.426115\tBest loss: 0.426115\tAccuracy: 89.30%\n",
      "103\tValidation loss: 0.424780\tBest loss: 0.424780\tAccuracy: 89.60%\n",
      "104\tValidation loss: 0.427540\tBest loss: 0.424780\tAccuracy: 89.50%\n",
      "105\tValidation loss: 0.431954\tBest loss: 0.424780\tAccuracy: 88.60%\n",
      "106\tValidation loss: 0.421307\tBest loss: 0.421307\tAccuracy: 89.50%\n",
      "107\tValidation loss: 0.424240\tBest loss: 0.421307\tAccuracy: 89.40%\n",
      "108\tValidation loss: 0.423254\tBest loss: 0.421307\tAccuracy: 89.50%\n",
      "109\tValidation loss: 0.420946\tBest loss: 0.420946\tAccuracy: 89.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\tValidation loss: 0.420425\tBest loss: 0.420425\tAccuracy: 89.60%\n",
      "111\tValidation loss: 0.426223\tBest loss: 0.420425\tAccuracy: 89.30%\n",
      "112\tValidation loss: 0.418842\tBest loss: 0.418842\tAccuracy: 89.60%\n",
      "113\tValidation loss: 0.421791\tBest loss: 0.418842\tAccuracy: 89.40%\n",
      "114\tValidation loss: 0.422634\tBest loss: 0.418842\tAccuracy: 89.50%\n",
      "115\tValidation loss: 0.415849\tBest loss: 0.415849\tAccuracy: 90.20%\n",
      "116\tValidation loss: 0.420905\tBest loss: 0.415849\tAccuracy: 89.30%\n",
      "117\tValidation loss: 0.415507\tBest loss: 0.415507\tAccuracy: 89.60%\n",
      "118\tValidation loss: 0.408152\tBest loss: 0.408152\tAccuracy: 89.70%\n",
      "119\tValidation loss: 0.410965\tBest loss: 0.408152\tAccuracy: 89.60%\n",
      "120\tValidation loss: 0.409931\tBest loss: 0.408152\tAccuracy: 89.60%\n",
      "121\tValidation loss: 0.410557\tBest loss: 0.408152\tAccuracy: 89.70%\n",
      "122\tValidation loss: 0.414631\tBest loss: 0.408152\tAccuracy: 89.30%\n",
      "123\tValidation loss: 0.409563\tBest loss: 0.408152\tAccuracy: 89.70%\n",
      "124\tValidation loss: 0.409938\tBest loss: 0.408152\tAccuracy: 90.20%\n",
      "125\tValidation loss: 0.408673\tBest loss: 0.408152\tAccuracy: 89.70%\n",
      "126\tValidation loss: 0.406692\tBest loss: 0.406692\tAccuracy: 90.00%\n",
      "127\tValidation loss: 0.410986\tBest loss: 0.406692\tAccuracy: 89.80%\n",
      "128\tValidation loss: 0.405539\tBest loss: 0.405539\tAccuracy: 90.30%\n",
      "129\tValidation loss: 0.402559\tBest loss: 0.402559\tAccuracy: 90.10%\n",
      "130\tValidation loss: 0.402935\tBest loss: 0.402559\tAccuracy: 90.30%\n",
      "131\tValidation loss: 0.405344\tBest loss: 0.402559\tAccuracy: 90.10%\n",
      "132\tValidation loss: 0.405093\tBest loss: 0.402559\tAccuracy: 90.20%\n",
      "133\tValidation loss: 0.407605\tBest loss: 0.402559\tAccuracy: 90.00%\n",
      "134\tValidation loss: 0.402343\tBest loss: 0.402343\tAccuracy: 90.90%\n",
      "135\tValidation loss: 0.403124\tBest loss: 0.402343\tAccuracy: 89.80%\n",
      "136\tValidation loss: 0.403158\tBest loss: 0.402343\tAccuracy: 90.40%\n",
      "137\tValidation loss: 0.399458\tBest loss: 0.399458\tAccuracy: 90.00%\n",
      "138\tValidation loss: 0.402242\tBest loss: 0.399458\tAccuracy: 90.00%\n",
      "139\tValidation loss: 0.397900\tBest loss: 0.397900\tAccuracy: 90.40%\n",
      "140\tValidation loss: 0.400930\tBest loss: 0.397900\tAccuracy: 90.20%\n",
      "141\tValidation loss: 0.399071\tBest loss: 0.397900\tAccuracy: 90.70%\n",
      "142\tValidation loss: 0.394985\tBest loss: 0.394985\tAccuracy: 91.00%\n",
      "143\tValidation loss: 0.401485\tBest loss: 0.394985\tAccuracy: 90.20%\n",
      "144\tValidation loss: 0.397360\tBest loss: 0.394985\tAccuracy: 90.70%\n",
      "145\tValidation loss: 0.397804\tBest loss: 0.394985\tAccuracy: 90.20%\n",
      "146\tValidation loss: 0.400922\tBest loss: 0.394985\tAccuracy: 89.90%\n",
      "147\tValidation loss: 0.398906\tBest loss: 0.394985\tAccuracy: 90.30%\n",
      "148\tValidation loss: 0.395893\tBest loss: 0.394985\tAccuracy: 90.80%\n",
      "149\tValidation loss: 0.395976\tBest loss: 0.394985\tAccuracy: 90.30%\n",
      "150\tValidation loss: 0.398649\tBest loss: 0.394985\tAccuracy: 90.30%\n",
      "151\tValidation loss: 0.391736\tBest loss: 0.391736\tAccuracy: 90.30%\n",
      "152\tValidation loss: 0.392600\tBest loss: 0.391736\tAccuracy: 90.70%\n",
      "153\tValidation loss: 0.388619\tBest loss: 0.388619\tAccuracy: 90.80%\n",
      "154\tValidation loss: 0.391760\tBest loss: 0.388619\tAccuracy: 90.90%\n",
      "155\tValidation loss: 0.391174\tBest loss: 0.388619\tAccuracy: 90.80%\n",
      "156\tValidation loss: 0.390784\tBest loss: 0.388619\tAccuracy: 90.90%\n",
      "157\tValidation loss: 0.394173\tBest loss: 0.388619\tAccuracy: 90.70%\n",
      "158\tValidation loss: 0.390957\tBest loss: 0.388619\tAccuracy: 91.00%\n",
      "159\tValidation loss: 0.391384\tBest loss: 0.388619\tAccuracy: 90.90%\n",
      "160\tValidation loss: 0.392362\tBest loss: 0.388619\tAccuracy: 90.90%\n",
      "161\tValidation loss: 0.384094\tBest loss: 0.384094\tAccuracy: 91.00%\n",
      "162\tValidation loss: 0.386963\tBest loss: 0.384094\tAccuracy: 90.70%\n",
      "163\tValidation loss: 0.386683\tBest loss: 0.384094\tAccuracy: 90.80%\n",
      "164\tValidation loss: 0.388757\tBest loss: 0.384094\tAccuracy: 90.70%\n",
      "165\tValidation loss: 0.385389\tBest loss: 0.384094\tAccuracy: 91.40%\n",
      "166\tValidation loss: 0.385602\tBest loss: 0.384094\tAccuracy: 91.10%\n",
      "167\tValidation loss: 0.385458\tBest loss: 0.384094\tAccuracy: 91.20%\n",
      "168\tValidation loss: 0.384876\tBest loss: 0.384094\tAccuracy: 91.40%\n",
      "169\tValidation loss: 0.387152\tBest loss: 0.384094\tAccuracy: 91.00%\n",
      "170\tValidation loss: 0.388811\tBest loss: 0.384094\tAccuracy: 90.70%\n",
      "171\tValidation loss: 0.384264\tBest loss: 0.384094\tAccuracy: 91.10%\n",
      "172\tValidation loss: 0.382298\tBest loss: 0.382298\tAccuracy: 91.20%\n",
      "173\tValidation loss: 0.382598\tBest loss: 0.382298\tAccuracy: 91.10%\n",
      "174\tValidation loss: 0.384043\tBest loss: 0.382298\tAccuracy: 91.20%\n",
      "175\tValidation loss: 0.383905\tBest loss: 0.382298\tAccuracy: 90.90%\n",
      "176\tValidation loss: 0.383281\tBest loss: 0.382298\tAccuracy: 91.30%\n",
      "177\tValidation loss: 0.381493\tBest loss: 0.381493\tAccuracy: 91.30%\n",
      "178\tValidation loss: 0.380025\tBest loss: 0.380025\tAccuracy: 91.20%\n",
      "179\tValidation loss: 0.383152\tBest loss: 0.380025\tAccuracy: 90.90%\n",
      "180\tValidation loss: 0.379901\tBest loss: 0.379901\tAccuracy: 91.40%\n",
      "181\tValidation loss: 0.381157\tBest loss: 0.379901\tAccuracy: 91.00%\n",
      "182\tValidation loss: 0.381760\tBest loss: 0.379901\tAccuracy: 91.00%\n",
      "183\tValidation loss: 0.381224\tBest loss: 0.379901\tAccuracy: 91.10%\n",
      "184\tValidation loss: 0.380473\tBest loss: 0.379901\tAccuracy: 91.10%\n",
      "185\tValidation loss: 0.378552\tBest loss: 0.378552\tAccuracy: 91.10%\n",
      "186\tValidation loss: 0.378116\tBest loss: 0.378116\tAccuracy: 90.90%\n",
      "187\tValidation loss: 0.375385\tBest loss: 0.375385\tAccuracy: 91.40%\n",
      "188\tValidation loss: 0.378018\tBest loss: 0.375385\tAccuracy: 90.90%\n",
      "189\tValidation loss: 0.379032\tBest loss: 0.375385\tAccuracy: 91.70%\n",
      "190\tValidation loss: 0.380742\tBest loss: 0.375385\tAccuracy: 91.40%\n",
      "191\tValidation loss: 0.378808\tBest loss: 0.375385\tAccuracy: 91.50%\n",
      "192\tValidation loss: 0.375053\tBest loss: 0.375053\tAccuracy: 91.20%\n",
      "193\tValidation loss: 0.377187\tBest loss: 0.375053\tAccuracy: 91.50%\n",
      "194\tValidation loss: 0.377270\tBest loss: 0.375053\tAccuracy: 91.30%\n",
      "195\tValidation loss: 0.376281\tBest loss: 0.375053\tAccuracy: 91.20%\n",
      "196\tValidation loss: 0.370220\tBest loss: 0.370220\tAccuracy: 91.70%\n",
      "197\tValidation loss: 0.377017\tBest loss: 0.370220\tAccuracy: 90.90%\n",
      "198\tValidation loss: 0.377698\tBest loss: 0.370220\tAccuracy: 91.30%\n",
      "199\tValidation loss: 0.378316\tBest loss: 0.370220\tAccuracy: 91.30%\n",
      "200\tValidation loss: 0.373610\tBest loss: 0.370220\tAccuracy: 91.10%\n",
      "201\tValidation loss: 0.373927\tBest loss: 0.370220\tAccuracy: 91.50%\n",
      "202\tValidation loss: 0.367881\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "203\tValidation loss: 0.372574\tBest loss: 0.367881\tAccuracy: 91.60%\n",
      "204\tValidation loss: 0.375425\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "205\tValidation loss: 0.374892\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "206\tValidation loss: 0.371424\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "207\tValidation loss: 0.372345\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "208\tValidation loss: 0.373851\tBest loss: 0.367881\tAccuracy: 91.20%\n",
      "209\tValidation loss: 0.374783\tBest loss: 0.367881\tAccuracy: 91.40%\n",
      "210\tValidation loss: 0.375375\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "211\tValidation loss: 0.372520\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "212\tValidation loss: 0.371430\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "213\tValidation loss: 0.372775\tBest loss: 0.367881\tAccuracy: 91.60%\n",
      "214\tValidation loss: 0.370413\tBest loss: 0.367881\tAccuracy: 91.60%\n",
      "215\tValidation loss: 0.373670\tBest loss: 0.367881\tAccuracy: 91.40%\n",
      "216\tValidation loss: 0.370409\tBest loss: 0.367881\tAccuracy: 91.80%\n",
      "217\tValidation loss: 0.372073\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "218\tValidation loss: 0.369800\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "219\tValidation loss: 0.371664\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "220\tValidation loss: 0.369395\tBest loss: 0.367881\tAccuracy: 91.40%\n",
      "221\tValidation loss: 0.372563\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "222\tValidation loss: 0.372750\tBest loss: 0.367881\tAccuracy: 91.30%\n",
      "223\tValidation loss: 0.370252\tBest loss: 0.367881\tAccuracy: 91.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  26.4s\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.266060\tBest loss: 2.266060\tAccuracy: 40.10%\n",
      "1\tValidation loss: 1.739380\tBest loss: 1.739380\tAccuracy: 57.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\tValidation loss: 1.486145\tBest loss: 1.486145\tAccuracy: 65.40%\n",
      "3\tValidation loss: 1.333085\tBest loss: 1.333085\tAccuracy: 69.90%\n",
      "4\tValidation loss: 1.224179\tBest loss: 1.224179\tAccuracy: 70.90%\n",
      "5\tValidation loss: 1.135338\tBest loss: 1.135338\tAccuracy: 73.40%\n",
      "6\tValidation loss: 1.070690\tBest loss: 1.070690\tAccuracy: 75.60%\n",
      "7\tValidation loss: 1.017295\tBest loss: 1.017295\tAccuracy: 75.00%\n",
      "8\tValidation loss: 0.980369\tBest loss: 0.980369\tAccuracy: 76.60%\n",
      "9\tValidation loss: 0.937949\tBest loss: 0.937949\tAccuracy: 76.80%\n",
      "10\tValidation loss: 0.910221\tBest loss: 0.910221\tAccuracy: 78.40%\n",
      "11\tValidation loss: 0.875643\tBest loss: 0.875643\tAccuracy: 79.00%\n",
      "12\tValidation loss: 0.855935\tBest loss: 0.855935\tAccuracy: 79.60%\n",
      "13\tValidation loss: 0.828519\tBest loss: 0.828519\tAccuracy: 80.20%\n",
      "14\tValidation loss: 0.815469\tBest loss: 0.815469\tAccuracy: 80.20%\n",
      "15\tValidation loss: 0.793182\tBest loss: 0.793182\tAccuracy: 80.50%\n",
      "16\tValidation loss: 0.776370\tBest loss: 0.776370\tAccuracy: 81.00%\n",
      "17\tValidation loss: 0.759308\tBest loss: 0.759308\tAccuracy: 81.40%\n",
      "18\tValidation loss: 0.746595\tBest loss: 0.746595\tAccuracy: 82.00%\n",
      "19\tValidation loss: 0.724693\tBest loss: 0.724693\tAccuracy: 82.10%\n",
      "20\tValidation loss: 0.712541\tBest loss: 0.712541\tAccuracy: 82.50%\n",
      "21\tValidation loss: 0.703246\tBest loss: 0.703246\tAccuracy: 82.50%\n",
      "22\tValidation loss: 0.695408\tBest loss: 0.695408\tAccuracy: 82.90%\n",
      "23\tValidation loss: 0.684254\tBest loss: 0.684254\tAccuracy: 83.60%\n",
      "24\tValidation loss: 0.677034\tBest loss: 0.677034\tAccuracy: 83.50%\n",
      "25\tValidation loss: 0.669897\tBest loss: 0.669897\tAccuracy: 83.50%\n",
      "26\tValidation loss: 0.662160\tBest loss: 0.662160\tAccuracy: 83.80%\n",
      "27\tValidation loss: 0.655297\tBest loss: 0.655297\tAccuracy: 83.70%\n",
      "28\tValidation loss: 0.650260\tBest loss: 0.650260\tAccuracy: 83.60%\n",
      "29\tValidation loss: 0.641053\tBest loss: 0.641053\tAccuracy: 84.80%\n",
      "30\tValidation loss: 0.639101\tBest loss: 0.639101\tAccuracy: 84.50%\n",
      "31\tValidation loss: 0.618573\tBest loss: 0.618573\tAccuracy: 84.30%\n",
      "32\tValidation loss: 0.616747\tBest loss: 0.616747\tAccuracy: 84.10%\n",
      "33\tValidation loss: 0.616296\tBest loss: 0.616296\tAccuracy: 85.50%\n",
      "34\tValidation loss: 0.608175\tBest loss: 0.608175\tAccuracy: 85.30%\n",
      "35\tValidation loss: 0.601341\tBest loss: 0.601341\tAccuracy: 85.50%\n",
      "36\tValidation loss: 0.591427\tBest loss: 0.591427\tAccuracy: 86.00%\n",
      "37\tValidation loss: 0.593799\tBest loss: 0.591427\tAccuracy: 85.80%\n",
      "38\tValidation loss: 0.590131\tBest loss: 0.590131\tAccuracy: 84.90%\n",
      "39\tValidation loss: 0.583629\tBest loss: 0.583629\tAccuracy: 84.90%\n",
      "40\tValidation loss: 0.584028\tBest loss: 0.583629\tAccuracy: 85.60%\n",
      "41\tValidation loss: 0.579926\tBest loss: 0.579926\tAccuracy: 84.90%\n",
      "42\tValidation loss: 0.570206\tBest loss: 0.570206\tAccuracy: 85.80%\n",
      "43\tValidation loss: 0.564200\tBest loss: 0.564200\tAccuracy: 85.90%\n",
      "44\tValidation loss: 0.565895\tBest loss: 0.564200\tAccuracy: 85.50%\n",
      "45\tValidation loss: 0.551414\tBest loss: 0.551414\tAccuracy: 86.00%\n",
      "46\tValidation loss: 0.556364\tBest loss: 0.551414\tAccuracy: 86.20%\n",
      "47\tValidation loss: 0.552629\tBest loss: 0.551414\tAccuracy: 86.10%\n",
      "48\tValidation loss: 0.548098\tBest loss: 0.548098\tAccuracy: 86.20%\n",
      "49\tValidation loss: 0.550719\tBest loss: 0.548098\tAccuracy: 86.30%\n",
      "50\tValidation loss: 0.545952\tBest loss: 0.545952\tAccuracy: 86.50%\n",
      "51\tValidation loss: 0.543354\tBest loss: 0.543354\tAccuracy: 86.20%\n",
      "52\tValidation loss: 0.533281\tBest loss: 0.533281\tAccuracy: 86.60%\n",
      "53\tValidation loss: 0.538972\tBest loss: 0.533281\tAccuracy: 86.50%\n",
      "54\tValidation loss: 0.527587\tBest loss: 0.527587\tAccuracy: 87.10%\n",
      "55\tValidation loss: 0.529351\tBest loss: 0.527587\tAccuracy: 86.60%\n",
      "56\tValidation loss: 0.530957\tBest loss: 0.527587\tAccuracy: 87.20%\n",
      "57\tValidation loss: 0.523635\tBest loss: 0.523635\tAccuracy: 86.90%\n",
      "58\tValidation loss: 0.524436\tBest loss: 0.523635\tAccuracy: 86.90%\n",
      "59\tValidation loss: 0.519741\tBest loss: 0.519741\tAccuracy: 86.80%\n",
      "60\tValidation loss: 0.515898\tBest loss: 0.515898\tAccuracy: 87.20%\n",
      "61\tValidation loss: 0.512668\tBest loss: 0.512668\tAccuracy: 87.80%\n",
      "62\tValidation loss: 0.508499\tBest loss: 0.508499\tAccuracy: 87.90%\n",
      "63\tValidation loss: 0.506730\tBest loss: 0.506730\tAccuracy: 87.90%\n",
      "64\tValidation loss: 0.505717\tBest loss: 0.505717\tAccuracy: 87.60%\n",
      "65\tValidation loss: 0.504321\tBest loss: 0.504321\tAccuracy: 88.30%\n",
      "66\tValidation loss: 0.502097\tBest loss: 0.502097\tAccuracy: 87.60%\n",
      "67\tValidation loss: 0.500465\tBest loss: 0.500465\tAccuracy: 87.50%\n",
      "68\tValidation loss: 0.498977\tBest loss: 0.498977\tAccuracy: 87.70%\n",
      "69\tValidation loss: 0.492762\tBest loss: 0.492762\tAccuracy: 88.20%\n",
      "70\tValidation loss: 0.499329\tBest loss: 0.492762\tAccuracy: 87.70%\n",
      "71\tValidation loss: 0.493463\tBest loss: 0.492762\tAccuracy: 88.30%\n",
      "72\tValidation loss: 0.488006\tBest loss: 0.488006\tAccuracy: 88.20%\n",
      "73\tValidation loss: 0.492255\tBest loss: 0.488006\tAccuracy: 88.00%\n",
      "74\tValidation loss: 0.493572\tBest loss: 0.488006\tAccuracy: 87.40%\n",
      "75\tValidation loss: 0.487016\tBest loss: 0.487016\tAccuracy: 87.80%\n",
      "76\tValidation loss: 0.485667\tBest loss: 0.485667\tAccuracy: 88.00%\n",
      "77\tValidation loss: 0.486045\tBest loss: 0.485667\tAccuracy: 88.10%\n",
      "78\tValidation loss: 0.478112\tBest loss: 0.478112\tAccuracy: 88.30%\n",
      "79\tValidation loss: 0.474241\tBest loss: 0.474241\tAccuracy: 89.00%\n",
      "80\tValidation loss: 0.482090\tBest loss: 0.474241\tAccuracy: 88.50%\n",
      "81\tValidation loss: 0.476525\tBest loss: 0.474241\tAccuracy: 88.50%\n",
      "82\tValidation loss: 0.478083\tBest loss: 0.474241\tAccuracy: 88.00%\n",
      "83\tValidation loss: 0.469264\tBest loss: 0.469264\tAccuracy: 88.60%\n",
      "84\tValidation loss: 0.472446\tBest loss: 0.469264\tAccuracy: 88.70%\n",
      "85\tValidation loss: 0.466575\tBest loss: 0.466575\tAccuracy: 88.70%\n",
      "86\tValidation loss: 0.471537\tBest loss: 0.466575\tAccuracy: 88.60%\n",
      "87\tValidation loss: 0.469342\tBest loss: 0.466575\tAccuracy: 88.60%\n",
      "88\tValidation loss: 0.468187\tBest loss: 0.466575\tAccuracy: 88.40%\n",
      "89\tValidation loss: 0.468825\tBest loss: 0.466575\tAccuracy: 88.60%\n",
      "90\tValidation loss: 0.464988\tBest loss: 0.464988\tAccuracy: 88.80%\n",
      "91\tValidation loss: 0.459473\tBest loss: 0.459473\tAccuracy: 88.70%\n",
      "92\tValidation loss: 0.462271\tBest loss: 0.459473\tAccuracy: 88.40%\n",
      "93\tValidation loss: 0.459838\tBest loss: 0.459473\tAccuracy: 88.40%\n",
      "94\tValidation loss: 0.461311\tBest loss: 0.459473\tAccuracy: 88.90%\n",
      "95\tValidation loss: 0.456054\tBest loss: 0.456054\tAccuracy: 88.70%\n",
      "96\tValidation loss: 0.454593\tBest loss: 0.454593\tAccuracy: 88.80%\n",
      "97\tValidation loss: 0.455096\tBest loss: 0.454593\tAccuracy: 88.80%\n",
      "98\tValidation loss: 0.453123\tBest loss: 0.453123\tAccuracy: 88.40%\n",
      "99\tValidation loss: 0.454283\tBest loss: 0.453123\tAccuracy: 88.90%\n",
      "100\tValidation loss: 0.453489\tBest loss: 0.453123\tAccuracy: 89.10%\n",
      "101\tValidation loss: 0.446724\tBest loss: 0.446724\tAccuracy: 89.20%\n",
      "102\tValidation loss: 0.446784\tBest loss: 0.446724\tAccuracy: 89.00%\n",
      "103\tValidation loss: 0.447188\tBest loss: 0.446724\tAccuracy: 89.00%\n",
      "104\tValidation loss: 0.446741\tBest loss: 0.446724\tAccuracy: 89.00%\n",
      "105\tValidation loss: 0.443711\tBest loss: 0.443711\tAccuracy: 89.30%\n",
      "106\tValidation loss: 0.444836\tBest loss: 0.443711\tAccuracy: 88.60%\n",
      "107\tValidation loss: 0.443463\tBest loss: 0.443463\tAccuracy: 89.50%\n",
      "108\tValidation loss: 0.444766\tBest loss: 0.443463\tAccuracy: 88.90%\n",
      "109\tValidation loss: 0.441319\tBest loss: 0.441319\tAccuracy: 88.90%\n",
      "110\tValidation loss: 0.440703\tBest loss: 0.440703\tAccuracy: 89.30%\n",
      "111\tValidation loss: 0.438956\tBest loss: 0.438956\tAccuracy: 88.80%\n",
      "112\tValidation loss: 0.437932\tBest loss: 0.437932\tAccuracy: 89.10%\n",
      "113\tValidation loss: 0.434002\tBest loss: 0.434002\tAccuracy: 89.20%\n",
      "114\tValidation loss: 0.435013\tBest loss: 0.434002\tAccuracy: 89.10%\n",
      "115\tValidation loss: 0.437369\tBest loss: 0.434002\tAccuracy: 89.20%\n",
      "116\tValidation loss: 0.434861\tBest loss: 0.434002\tAccuracy: 89.50%\n",
      "117\tValidation loss: 0.428750\tBest loss: 0.428750\tAccuracy: 89.30%\n",
      "118\tValidation loss: 0.429810\tBest loss: 0.428750\tAccuracy: 89.30%\n",
      "119\tValidation loss: 0.430874\tBest loss: 0.428750\tAccuracy: 88.70%\n",
      "120\tValidation loss: 0.431044\tBest loss: 0.428750\tAccuracy: 89.10%\n",
      "121\tValidation loss: 0.431093\tBest loss: 0.428750\tAccuracy: 89.00%\n",
      "122\tValidation loss: 0.428696\tBest loss: 0.428696\tAccuracy: 89.50%\n",
      "123\tValidation loss: 0.429767\tBest loss: 0.428696\tAccuracy: 89.10%\n",
      "124\tValidation loss: 0.428104\tBest loss: 0.428104\tAccuracy: 89.20%\n",
      "125\tValidation loss: 0.425018\tBest loss: 0.425018\tAccuracy: 89.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 0.425344\tBest loss: 0.425018\tAccuracy: 89.30%\n",
      "127\tValidation loss: 0.427313\tBest loss: 0.425018\tAccuracy: 89.50%\n",
      "128\tValidation loss: 0.421624\tBest loss: 0.421624\tAccuracy: 89.60%\n",
      "129\tValidation loss: 0.424362\tBest loss: 0.421624\tAccuracy: 89.40%\n",
      "130\tValidation loss: 0.426114\tBest loss: 0.421624\tAccuracy: 89.30%\n",
      "131\tValidation loss: 0.420671\tBest loss: 0.420671\tAccuracy: 89.70%\n",
      "132\tValidation loss: 0.422145\tBest loss: 0.420671\tAccuracy: 89.40%\n",
      "133\tValidation loss: 0.423339\tBest loss: 0.420671\tAccuracy: 89.40%\n",
      "134\tValidation loss: 0.423589\tBest loss: 0.420671\tAccuracy: 89.40%\n",
      "135\tValidation loss: 0.421164\tBest loss: 0.420671\tAccuracy: 89.90%\n",
      "136\tValidation loss: 0.416127\tBest loss: 0.416127\tAccuracy: 90.10%\n",
      "137\tValidation loss: 0.416287\tBest loss: 0.416127\tAccuracy: 89.30%\n",
      "138\tValidation loss: 0.413514\tBest loss: 0.413514\tAccuracy: 89.90%\n",
      "139\tValidation loss: 0.415018\tBest loss: 0.413514\tAccuracy: 89.60%\n",
      "140\tValidation loss: 0.414247\tBest loss: 0.413514\tAccuracy: 89.90%\n",
      "141\tValidation loss: 0.414960\tBest loss: 0.413514\tAccuracy: 89.60%\n",
      "142\tValidation loss: 0.414624\tBest loss: 0.413514\tAccuracy: 89.90%\n",
      "143\tValidation loss: 0.409500\tBest loss: 0.409500\tAccuracy: 89.70%\n",
      "144\tValidation loss: 0.410369\tBest loss: 0.409500\tAccuracy: 89.60%\n",
      "145\tValidation loss: 0.411130\tBest loss: 0.409500\tAccuracy: 90.00%\n",
      "146\tValidation loss: 0.406784\tBest loss: 0.406784\tAccuracy: 90.30%\n",
      "147\tValidation loss: 0.409085\tBest loss: 0.406784\tAccuracy: 89.80%\n",
      "148\tValidation loss: 0.409864\tBest loss: 0.406784\tAccuracy: 89.90%\n",
      "149\tValidation loss: 0.409036\tBest loss: 0.406784\tAccuracy: 90.00%\n",
      "150\tValidation loss: 0.407952\tBest loss: 0.406784\tAccuracy: 90.20%\n",
      "151\tValidation loss: 0.407602\tBest loss: 0.406784\tAccuracy: 90.30%\n",
      "152\tValidation loss: 0.405439\tBest loss: 0.405439\tAccuracy: 90.10%\n",
      "153\tValidation loss: 0.402863\tBest loss: 0.402863\tAccuracy: 90.00%\n",
      "154\tValidation loss: 0.405251\tBest loss: 0.402863\tAccuracy: 90.20%\n",
      "155\tValidation loss: 0.404841\tBest loss: 0.402863\tAccuracy: 89.60%\n",
      "156\tValidation loss: 0.404783\tBest loss: 0.402863\tAccuracy: 90.10%\n",
      "157\tValidation loss: 0.408863\tBest loss: 0.402863\tAccuracy: 90.00%\n",
      "158\tValidation loss: 0.402709\tBest loss: 0.402709\tAccuracy: 90.10%\n",
      "159\tValidation loss: 0.402312\tBest loss: 0.402312\tAccuracy: 90.10%\n",
      "160\tValidation loss: 0.406119\tBest loss: 0.402312\tAccuracy: 89.90%\n",
      "161\tValidation loss: 0.403989\tBest loss: 0.402312\tAccuracy: 90.00%\n",
      "162\tValidation loss: 0.401987\tBest loss: 0.401987\tAccuracy: 90.00%\n",
      "163\tValidation loss: 0.400802\tBest loss: 0.400802\tAccuracy: 90.00%\n",
      "164\tValidation loss: 0.397783\tBest loss: 0.397783\tAccuracy: 90.00%\n",
      "165\tValidation loss: 0.398321\tBest loss: 0.397783\tAccuracy: 90.20%\n",
      "166\tValidation loss: 0.399815\tBest loss: 0.397783\tAccuracy: 89.80%\n",
      "167\tValidation loss: 0.395532\tBest loss: 0.395532\tAccuracy: 90.10%\n",
      "168\tValidation loss: 0.399894\tBest loss: 0.395532\tAccuracy: 90.10%\n",
      "169\tValidation loss: 0.394713\tBest loss: 0.394713\tAccuracy: 90.00%\n",
      "170\tValidation loss: 0.396006\tBest loss: 0.394713\tAccuracy: 90.50%\n",
      "171\tValidation loss: 0.395197\tBest loss: 0.394713\tAccuracy: 90.10%\n",
      "172\tValidation loss: 0.394916\tBest loss: 0.394713\tAccuracy: 90.10%\n",
      "173\tValidation loss: 0.397768\tBest loss: 0.394713\tAccuracy: 89.90%\n",
      "174\tValidation loss: 0.392915\tBest loss: 0.392915\tAccuracy: 90.30%\n",
      "175\tValidation loss: 0.392280\tBest loss: 0.392280\tAccuracy: 90.10%\n",
      "176\tValidation loss: 0.398335\tBest loss: 0.392280\tAccuracy: 90.10%\n",
      "177\tValidation loss: 0.393637\tBest loss: 0.392280\tAccuracy: 90.10%\n",
      "178\tValidation loss: 0.393082\tBest loss: 0.392280\tAccuracy: 90.40%\n",
      "179\tValidation loss: 0.392781\tBest loss: 0.392280\tAccuracy: 89.90%\n",
      "180\tValidation loss: 0.391497\tBest loss: 0.391497\tAccuracy: 90.50%\n",
      "181\tValidation loss: 0.389586\tBest loss: 0.389586\tAccuracy: 90.00%\n",
      "182\tValidation loss: 0.391812\tBest loss: 0.389586\tAccuracy: 90.40%\n",
      "183\tValidation loss: 0.392133\tBest loss: 0.389586\tAccuracy: 90.10%\n",
      "184\tValidation loss: 0.392376\tBest loss: 0.389586\tAccuracy: 90.20%\n",
      "185\tValidation loss: 0.390517\tBest loss: 0.389586\tAccuracy: 90.00%\n",
      "186\tValidation loss: 0.388393\tBest loss: 0.388393\tAccuracy: 90.20%\n",
      "187\tValidation loss: 0.387211\tBest loss: 0.387211\tAccuracy: 90.10%\n",
      "188\tValidation loss: 0.388558\tBest loss: 0.387211\tAccuracy: 89.90%\n",
      "189\tValidation loss: 0.388014\tBest loss: 0.387211\tAccuracy: 90.00%\n",
      "190\tValidation loss: 0.386417\tBest loss: 0.386417\tAccuracy: 90.00%\n",
      "191\tValidation loss: 0.385394\tBest loss: 0.385394\tAccuracy: 90.30%\n",
      "192\tValidation loss: 0.385752\tBest loss: 0.385394\tAccuracy: 89.90%\n",
      "193\tValidation loss: 0.385299\tBest loss: 0.385299\tAccuracy: 90.20%\n",
      "194\tValidation loss: 0.385045\tBest loss: 0.385045\tAccuracy: 90.10%\n",
      "195\tValidation loss: 0.383097\tBest loss: 0.383097\tAccuracy: 90.00%\n",
      "196\tValidation loss: 0.385826\tBest loss: 0.383097\tAccuracy: 90.20%\n",
      "197\tValidation loss: 0.382983\tBest loss: 0.382983\tAccuracy: 89.90%\n",
      "198\tValidation loss: 0.382370\tBest loss: 0.382370\tAccuracy: 90.20%\n",
      "199\tValidation loss: 0.382948\tBest loss: 0.382370\tAccuracy: 90.40%\n",
      "200\tValidation loss: 0.385895\tBest loss: 0.382370\tAccuracy: 90.30%\n",
      "201\tValidation loss: 0.383762\tBest loss: 0.382370\tAccuracy: 90.50%\n",
      "202\tValidation loss: 0.382788\tBest loss: 0.382370\tAccuracy: 90.30%\n",
      "203\tValidation loss: 0.382268\tBest loss: 0.382268\tAccuracy: 90.20%\n",
      "204\tValidation loss: 0.385216\tBest loss: 0.382268\tAccuracy: 90.00%\n",
      "205\tValidation loss: 0.381159\tBest loss: 0.381159\tAccuracy: 90.30%\n",
      "206\tValidation loss: 0.378713\tBest loss: 0.378713\tAccuracy: 90.40%\n",
      "207\tValidation loss: 0.381356\tBest loss: 0.378713\tAccuracy: 90.40%\n",
      "208\tValidation loss: 0.382444\tBest loss: 0.378713\tAccuracy: 90.20%\n",
      "209\tValidation loss: 0.376460\tBest loss: 0.376460\tAccuracy: 90.40%\n",
      "210\tValidation loss: 0.376652\tBest loss: 0.376460\tAccuracy: 90.10%\n",
      "211\tValidation loss: 0.378256\tBest loss: 0.376460\tAccuracy: 90.20%\n",
      "212\tValidation loss: 0.376383\tBest loss: 0.376383\tAccuracy: 90.70%\n",
      "213\tValidation loss: 0.377121\tBest loss: 0.376383\tAccuracy: 90.50%\n",
      "214\tValidation loss: 0.375011\tBest loss: 0.375011\tAccuracy: 90.20%\n",
      "215\tValidation loss: 0.376183\tBest loss: 0.375011\tAccuracy: 90.30%\n",
      "216\tValidation loss: 0.373537\tBest loss: 0.373537\tAccuracy: 90.50%\n",
      "217\tValidation loss: 0.374505\tBest loss: 0.373537\tAccuracy: 90.70%\n",
      "218\tValidation loss: 0.375410\tBest loss: 0.373537\tAccuracy: 90.40%\n",
      "219\tValidation loss: 0.375871\tBest loss: 0.373537\tAccuracy: 90.30%\n",
      "220\tValidation loss: 0.376988\tBest loss: 0.373537\tAccuracy: 90.20%\n",
      "221\tValidation loss: 0.376560\tBest loss: 0.373537\tAccuracy: 90.50%\n",
      "222\tValidation loss: 0.376114\tBest loss: 0.373537\tAccuracy: 90.70%\n",
      "223\tValidation loss: 0.374637\tBest loss: 0.373537\tAccuracy: 90.50%\n",
      "224\tValidation loss: 0.372855\tBest loss: 0.372855\tAccuracy: 91.00%\n",
      "225\tValidation loss: 0.373280\tBest loss: 0.372855\tAccuracy: 90.50%\n",
      "226\tValidation loss: 0.372504\tBest loss: 0.372504\tAccuracy: 90.60%\n",
      "227\tValidation loss: 0.370384\tBest loss: 0.370384\tAccuracy: 90.30%\n",
      "228\tValidation loss: 0.371522\tBest loss: 0.370384\tAccuracy: 90.70%\n",
      "229\tValidation loss: 0.373629\tBest loss: 0.370384\tAccuracy: 90.40%\n",
      "230\tValidation loss: 0.372321\tBest loss: 0.370384\tAccuracy: 90.60%\n",
      "231\tValidation loss: 0.372090\tBest loss: 0.370384\tAccuracy: 90.70%\n",
      "232\tValidation loss: 0.373241\tBest loss: 0.370384\tAccuracy: 90.50%\n",
      "233\tValidation loss: 0.371275\tBest loss: 0.370384\tAccuracy: 90.70%\n",
      "234\tValidation loss: 0.369656\tBest loss: 0.369656\tAccuracy: 90.70%\n",
      "235\tValidation loss: 0.368296\tBest loss: 0.368296\tAccuracy: 90.40%\n",
      "236\tValidation loss: 0.371308\tBest loss: 0.368296\tAccuracy: 90.20%\n",
      "237\tValidation loss: 0.368711\tBest loss: 0.368296\tAccuracy: 90.80%\n",
      "238\tValidation loss: 0.369451\tBest loss: 0.368296\tAccuracy: 91.20%\n",
      "239\tValidation loss: 0.366710\tBest loss: 0.366710\tAccuracy: 90.50%\n",
      "240\tValidation loss: 0.369009\tBest loss: 0.366710\tAccuracy: 90.70%\n",
      "241\tValidation loss: 0.367973\tBest loss: 0.366710\tAccuracy: 90.80%\n",
      "242\tValidation loss: 0.367480\tBest loss: 0.366710\tAccuracy: 90.80%\n",
      "243\tValidation loss: 0.366263\tBest loss: 0.366263\tAccuracy: 91.10%\n",
      "244\tValidation loss: 0.368777\tBest loss: 0.366263\tAccuracy: 91.10%\n",
      "245\tValidation loss: 0.366883\tBest loss: 0.366263\tAccuracy: 91.00%\n",
      "246\tValidation loss: 0.367015\tBest loss: 0.366263\tAccuracy: 90.70%\n",
      "247\tValidation loss: 0.364955\tBest loss: 0.364955\tAccuracy: 91.10%\n",
      "248\tValidation loss: 0.365737\tBest loss: 0.364955\tAccuracy: 91.20%\n",
      "249\tValidation loss: 0.364198\tBest loss: 0.364198\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 0.367998\tBest loss: 0.364198\tAccuracy: 90.80%\n",
      "251\tValidation loss: 0.365330\tBest loss: 0.364198\tAccuracy: 90.80%\n",
      "252\tValidation loss: 0.365109\tBest loss: 0.364198\tAccuracy: 91.20%\n",
      "253\tValidation loss: 0.365317\tBest loss: 0.364198\tAccuracy: 91.40%\n",
      "254\tValidation loss: 0.364867\tBest loss: 0.364198\tAccuracy: 91.30%\n",
      "255\tValidation loss: 0.364567\tBest loss: 0.364198\tAccuracy: 91.20%\n",
      "256\tValidation loss: 0.364143\tBest loss: 0.364143\tAccuracy: 90.90%\n",
      "257\tValidation loss: 0.365499\tBest loss: 0.364143\tAccuracy: 91.10%\n",
      "258\tValidation loss: 0.364963\tBest loss: 0.364143\tAccuracy: 91.30%\n",
      "259\tValidation loss: 0.360092\tBest loss: 0.360092\tAccuracy: 91.20%\n",
      "260\tValidation loss: 0.362221\tBest loss: 0.360092\tAccuracy: 91.00%\n",
      "261\tValidation loss: 0.359897\tBest loss: 0.359897\tAccuracy: 90.80%\n",
      "262\tValidation loss: 0.363059\tBest loss: 0.359897\tAccuracy: 91.10%\n",
      "263\tValidation loss: 0.362735\tBest loss: 0.359897\tAccuracy: 91.20%\n",
      "264\tValidation loss: 0.362937\tBest loss: 0.359897\tAccuracy: 91.10%\n",
      "265\tValidation loss: 0.361982\tBest loss: 0.359897\tAccuracy: 91.00%\n",
      "266\tValidation loss: 0.363337\tBest loss: 0.359897\tAccuracy: 91.40%\n",
      "267\tValidation loss: 0.360957\tBest loss: 0.359897\tAccuracy: 91.20%\n",
      "268\tValidation loss: 0.362288\tBest loss: 0.359897\tAccuracy: 91.30%\n",
      "269\tValidation loss: 0.359854\tBest loss: 0.359854\tAccuracy: 90.90%\n",
      "270\tValidation loss: 0.361206\tBest loss: 0.359854\tAccuracy: 90.70%\n",
      "271\tValidation loss: 0.358144\tBest loss: 0.358144\tAccuracy: 91.30%\n",
      "272\tValidation loss: 0.357789\tBest loss: 0.357789\tAccuracy: 91.30%\n",
      "273\tValidation loss: 0.360380\tBest loss: 0.357789\tAccuracy: 91.60%\n",
      "274\tValidation loss: 0.359624\tBest loss: 0.357789\tAccuracy: 91.50%\n",
      "275\tValidation loss: 0.357427\tBest loss: 0.357427\tAccuracy: 91.20%\n",
      "276\tValidation loss: 0.359464\tBest loss: 0.357427\tAccuracy: 90.80%\n",
      "277\tValidation loss: 0.358550\tBest loss: 0.357427\tAccuracy: 91.40%\n",
      "278\tValidation loss: 0.358570\tBest loss: 0.357427\tAccuracy: 91.30%\n",
      "279\tValidation loss: 0.357886\tBest loss: 0.357427\tAccuracy: 90.90%\n",
      "280\tValidation loss: 0.360116\tBest loss: 0.357427\tAccuracy: 91.10%\n",
      "281\tValidation loss: 0.359401\tBest loss: 0.357427\tAccuracy: 91.30%\n",
      "282\tValidation loss: 0.356447\tBest loss: 0.356447\tAccuracy: 91.50%\n",
      "283\tValidation loss: 0.356401\tBest loss: 0.356401\tAccuracy: 91.30%\n",
      "284\tValidation loss: 0.359130\tBest loss: 0.356401\tAccuracy: 91.20%\n",
      "285\tValidation loss: 0.357652\tBest loss: 0.356401\tAccuracy: 91.40%\n",
      "286\tValidation loss: 0.357039\tBest loss: 0.356401\tAccuracy: 91.30%\n",
      "287\tValidation loss: 0.356435\tBest loss: 0.356401\tAccuracy: 91.10%\n",
      "288\tValidation loss: 0.356009\tBest loss: 0.356009\tAccuracy: 91.50%\n",
      "289\tValidation loss: 0.355616\tBest loss: 0.355616\tAccuracy: 91.10%\n",
      "290\tValidation loss: 0.355481\tBest loss: 0.355481\tAccuracy: 91.50%\n",
      "291\tValidation loss: 0.353880\tBest loss: 0.353880\tAccuracy: 91.30%\n",
      "292\tValidation loss: 0.356552\tBest loss: 0.353880\tAccuracy: 91.80%\n",
      "293\tValidation loss: 0.356344\tBest loss: 0.353880\tAccuracy: 91.40%\n",
      "294\tValidation loss: 0.354854\tBest loss: 0.353880\tAccuracy: 91.70%\n",
      "295\tValidation loss: 0.354216\tBest loss: 0.353880\tAccuracy: 91.50%\n",
      "296\tValidation loss: 0.355107\tBest loss: 0.353880\tAccuracy: 91.40%\n",
      "297\tValidation loss: 0.356284\tBest loss: 0.353880\tAccuracy: 91.40%\n",
      "298\tValidation loss: 0.357285\tBest loss: 0.353880\tAccuracy: 91.30%\n",
      "299\tValidation loss: 0.354113\tBest loss: 0.353880\tAccuracy: 91.40%\n",
      "300\tValidation loss: 0.354438\tBest loss: 0.353880\tAccuracy: 91.40%\n",
      "301\tValidation loss: 0.354104\tBest loss: 0.353880\tAccuracy: 91.50%\n",
      "302\tValidation loss: 0.353656\tBest loss: 0.353656\tAccuracy: 91.40%\n",
      "303\tValidation loss: 0.353240\tBest loss: 0.353240\tAccuracy: 91.40%\n",
      "304\tValidation loss: 0.354768\tBest loss: 0.353240\tAccuracy: 91.60%\n",
      "305\tValidation loss: 0.353103\tBest loss: 0.353103\tAccuracy: 91.60%\n",
      "306\tValidation loss: 0.350384\tBest loss: 0.350384\tAccuracy: 91.30%\n",
      "307\tValidation loss: 0.351733\tBest loss: 0.350384\tAccuracy: 91.40%\n",
      "308\tValidation loss: 0.352031\tBest loss: 0.350384\tAccuracy: 91.50%\n",
      "309\tValidation loss: 0.352010\tBest loss: 0.350384\tAccuracy: 91.60%\n",
      "310\tValidation loss: 0.349561\tBest loss: 0.349561\tAccuracy: 91.60%\n",
      "311\tValidation loss: 0.350997\tBest loss: 0.349561\tAccuracy: 91.80%\n",
      "312\tValidation loss: 0.349974\tBest loss: 0.349561\tAccuracy: 91.40%\n",
      "313\tValidation loss: 0.349328\tBest loss: 0.349328\tAccuracy: 91.60%\n",
      "314\tValidation loss: 0.350855\tBest loss: 0.349328\tAccuracy: 91.50%\n",
      "315\tValidation loss: 0.349418\tBest loss: 0.349328\tAccuracy: 91.60%\n",
      "316\tValidation loss: 0.348685\tBest loss: 0.348685\tAccuracy: 91.60%\n",
      "317\tValidation loss: 0.350083\tBest loss: 0.348685\tAccuracy: 91.50%\n",
      "318\tValidation loss: 0.348294\tBest loss: 0.348294\tAccuracy: 91.50%\n",
      "319\tValidation loss: 0.348900\tBest loss: 0.348294\tAccuracy: 91.50%\n",
      "320\tValidation loss: 0.348057\tBest loss: 0.348057\tAccuracy: 91.60%\n",
      "321\tValidation loss: 0.348376\tBest loss: 0.348057\tAccuracy: 91.60%\n",
      "322\tValidation loss: 0.349754\tBest loss: 0.348057\tAccuracy: 91.60%\n",
      "323\tValidation loss: 0.347467\tBest loss: 0.347467\tAccuracy: 91.60%\n",
      "324\tValidation loss: 0.346893\tBest loss: 0.346893\tAccuracy: 91.40%\n",
      "325\tValidation loss: 0.348309\tBest loss: 0.346893\tAccuracy: 91.60%\n",
      "326\tValidation loss: 0.349853\tBest loss: 0.346893\tAccuracy: 91.40%\n",
      "327\tValidation loss: 0.347987\tBest loss: 0.346893\tAccuracy: 91.80%\n",
      "328\tValidation loss: 0.349975\tBest loss: 0.346893\tAccuracy: 91.60%\n",
      "329\tValidation loss: 0.347141\tBest loss: 0.346893\tAccuracy: 91.50%\n",
      "330\tValidation loss: 0.348199\tBest loss: 0.346893\tAccuracy: 91.50%\n",
      "331\tValidation loss: 0.346951\tBest loss: 0.346893\tAccuracy: 91.70%\n",
      "332\tValidation loss: 0.346627\tBest loss: 0.346627\tAccuracy: 91.80%\n",
      "333\tValidation loss: 0.346216\tBest loss: 0.346216\tAccuracy: 91.60%\n",
      "334\tValidation loss: 0.349573\tBest loss: 0.346216\tAccuracy: 91.40%\n",
      "335\tValidation loss: 0.346150\tBest loss: 0.346150\tAccuracy: 91.90%\n",
      "336\tValidation loss: 0.344959\tBest loss: 0.344959\tAccuracy: 91.50%\n",
      "337\tValidation loss: 0.346189\tBest loss: 0.344959\tAccuracy: 91.60%\n",
      "338\tValidation loss: 0.345282\tBest loss: 0.344959\tAccuracy: 91.70%\n",
      "339\tValidation loss: 0.344882\tBest loss: 0.344882\tAccuracy: 91.60%\n",
      "340\tValidation loss: 0.346709\tBest loss: 0.344882\tAccuracy: 91.60%\n",
      "341\tValidation loss: 0.345088\tBest loss: 0.344882\tAccuracy: 91.80%\n",
      "342\tValidation loss: 0.345312\tBest loss: 0.344882\tAccuracy: 91.70%\n",
      "343\tValidation loss: 0.343902\tBest loss: 0.343902\tAccuracy: 91.80%\n",
      "344\tValidation loss: 0.344907\tBest loss: 0.343902\tAccuracy: 91.50%\n",
      "345\tValidation loss: 0.344678\tBest loss: 0.343902\tAccuracy: 91.50%\n",
      "346\tValidation loss: 0.344748\tBest loss: 0.343902\tAccuracy: 91.60%\n",
      "347\tValidation loss: 0.344463\tBest loss: 0.343902\tAccuracy: 91.60%\n",
      "348\tValidation loss: 0.345606\tBest loss: 0.343902\tAccuracy: 91.50%\n",
      "349\tValidation loss: 0.344862\tBest loss: 0.343902\tAccuracy: 91.40%\n",
      "350\tValidation loss: 0.343078\tBest loss: 0.343078\tAccuracy: 91.70%\n",
      "351\tValidation loss: 0.345414\tBest loss: 0.343078\tAccuracy: 91.70%\n",
      "352\tValidation loss: 0.344893\tBest loss: 0.343078\tAccuracy: 91.60%\n",
      "353\tValidation loss: 0.342851\tBest loss: 0.342851\tAccuracy: 91.70%\n",
      "354\tValidation loss: 0.343586\tBest loss: 0.342851\tAccuracy: 91.80%\n",
      "355\tValidation loss: 0.343616\tBest loss: 0.342851\tAccuracy: 91.60%\n",
      "356\tValidation loss: 0.343666\tBest loss: 0.342851\tAccuracy: 91.80%\n",
      "357\tValidation loss: 0.340848\tBest loss: 0.340848\tAccuracy: 91.60%\n",
      "358\tValidation loss: 0.344893\tBest loss: 0.340848\tAccuracy: 91.70%\n",
      "359\tValidation loss: 0.344678\tBest loss: 0.340848\tAccuracy: 91.60%\n",
      "360\tValidation loss: 0.342713\tBest loss: 0.340848\tAccuracy: 91.60%\n",
      "361\tValidation loss: 0.342524\tBest loss: 0.340848\tAccuracy: 91.80%\n",
      "362\tValidation loss: 0.342121\tBest loss: 0.340848\tAccuracy: 91.70%\n",
      "363\tValidation loss: 0.342430\tBest loss: 0.340848\tAccuracy: 91.50%\n",
      "364\tValidation loss: 0.342528\tBest loss: 0.340848\tAccuracy: 91.80%\n",
      "365\tValidation loss: 0.343769\tBest loss: 0.340848\tAccuracy: 91.50%\n",
      "366\tValidation loss: 0.342355\tBest loss: 0.340848\tAccuracy: 91.60%\n",
      "367\tValidation loss: 0.340855\tBest loss: 0.340848\tAccuracy: 91.80%\n",
      "368\tValidation loss: 0.340256\tBest loss: 0.340256\tAccuracy: 91.70%\n",
      "369\tValidation loss: 0.340002\tBest loss: 0.340002\tAccuracy: 91.70%\n",
      "370\tValidation loss: 0.340261\tBest loss: 0.340002\tAccuracy: 91.70%\n",
      "371\tValidation loss: 0.340109\tBest loss: 0.340002\tAccuracy: 91.80%\n",
      "372\tValidation loss: 0.340937\tBest loss: 0.340002\tAccuracy: 91.70%\n",
      "373\tValidation loss: 0.341887\tBest loss: 0.340002\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\tValidation loss: 0.340782\tBest loss: 0.340002\tAccuracy: 91.80%\n",
      "375\tValidation loss: 0.339482\tBest loss: 0.339482\tAccuracy: 91.80%\n",
      "376\tValidation loss: 0.341241\tBest loss: 0.339482\tAccuracy: 91.50%\n",
      "377\tValidation loss: 0.340309\tBest loss: 0.339482\tAccuracy: 91.70%\n",
      "378\tValidation loss: 0.338461\tBest loss: 0.338461\tAccuracy: 91.70%\n",
      "379\tValidation loss: 0.340903\tBest loss: 0.338461\tAccuracy: 91.70%\n",
      "380\tValidation loss: 0.339733\tBest loss: 0.338461\tAccuracy: 91.70%\n",
      "381\tValidation loss: 0.339867\tBest loss: 0.338461\tAccuracy: 91.70%\n",
      "382\tValidation loss: 0.340239\tBest loss: 0.338461\tAccuracy: 91.70%\n",
      "383\tValidation loss: 0.339076\tBest loss: 0.338461\tAccuracy: 92.00%\n",
      "384\tValidation loss: 0.340941\tBest loss: 0.338461\tAccuracy: 91.50%\n",
      "385\tValidation loss: 0.337698\tBest loss: 0.337698\tAccuracy: 91.60%\n",
      "386\tValidation loss: 0.340055\tBest loss: 0.337698\tAccuracy: 91.80%\n",
      "387\tValidation loss: 0.339339\tBest loss: 0.337698\tAccuracy: 91.90%\n",
      "388\tValidation loss: 0.337819\tBest loss: 0.337698\tAccuracy: 91.70%\n",
      "389\tValidation loss: 0.338846\tBest loss: 0.337698\tAccuracy: 91.80%\n",
      "390\tValidation loss: 0.337299\tBest loss: 0.337299\tAccuracy: 91.60%\n",
      "391\tValidation loss: 0.336888\tBest loss: 0.336888\tAccuracy: 91.90%\n",
      "392\tValidation loss: 0.337942\tBest loss: 0.336888\tAccuracy: 91.60%\n",
      "393\tValidation loss: 0.337732\tBest loss: 0.336888\tAccuracy: 91.70%\n",
      "394\tValidation loss: 0.335260\tBest loss: 0.335260\tAccuracy: 91.70%\n",
      "395\tValidation loss: 0.337652\tBest loss: 0.335260\tAccuracy: 91.50%\n",
      "396\tValidation loss: 0.336432\tBest loss: 0.335260\tAccuracy: 91.80%\n",
      "397\tValidation loss: 0.335158\tBest loss: 0.335158\tAccuracy: 91.70%\n",
      "398\tValidation loss: 0.334233\tBest loss: 0.334233\tAccuracy: 91.70%\n",
      "399\tValidation loss: 0.336630\tBest loss: 0.334233\tAccuracy: 91.90%\n",
      "400\tValidation loss: 0.335264\tBest loss: 0.334233\tAccuracy: 91.80%\n",
      "401\tValidation loss: 0.337413\tBest loss: 0.334233\tAccuracy: 91.60%\n",
      "402\tValidation loss: 0.336238\tBest loss: 0.334233\tAccuracy: 91.60%\n",
      "403\tValidation loss: 0.337045\tBest loss: 0.334233\tAccuracy: 92.00%\n",
      "404\tValidation loss: 0.335061\tBest loss: 0.334233\tAccuracy: 91.70%\n",
      "405\tValidation loss: 0.337174\tBest loss: 0.334233\tAccuracy: 91.80%\n",
      "406\tValidation loss: 0.337636\tBest loss: 0.334233\tAccuracy: 91.70%\n",
      "407\tValidation loss: 0.333923\tBest loss: 0.333923\tAccuracy: 91.70%\n",
      "408\tValidation loss: 0.333997\tBest loss: 0.333923\tAccuracy: 91.70%\n",
      "409\tValidation loss: 0.335107\tBest loss: 0.333923\tAccuracy: 91.70%\n",
      "410\tValidation loss: 0.335382\tBest loss: 0.333923\tAccuracy: 91.60%\n",
      "411\tValidation loss: 0.334740\tBest loss: 0.333923\tAccuracy: 91.90%\n",
      "412\tValidation loss: 0.332632\tBest loss: 0.332632\tAccuracy: 91.90%\n",
      "413\tValidation loss: 0.336705\tBest loss: 0.332632\tAccuracy: 91.60%\n",
      "414\tValidation loss: 0.335032\tBest loss: 0.332632\tAccuracy: 91.80%\n",
      "415\tValidation loss: 0.334683\tBest loss: 0.332632\tAccuracy: 91.60%\n",
      "416\tValidation loss: 0.336154\tBest loss: 0.332632\tAccuracy: 91.70%\n",
      "417\tValidation loss: 0.333829\tBest loss: 0.332632\tAccuracy: 91.70%\n",
      "418\tValidation loss: 0.334763\tBest loss: 0.332632\tAccuracy: 91.80%\n",
      "419\tValidation loss: 0.334878\tBest loss: 0.332632\tAccuracy: 91.60%\n",
      "420\tValidation loss: 0.334206\tBest loss: 0.332632\tAccuracy: 91.60%\n",
      "421\tValidation loss: 0.333873\tBest loss: 0.332632\tAccuracy: 91.70%\n",
      "422\tValidation loss: 0.332783\tBest loss: 0.332632\tAccuracy: 92.00%\n",
      "423\tValidation loss: 0.333244\tBest loss: 0.332632\tAccuracy: 91.60%\n",
      "424\tValidation loss: 0.333311\tBest loss: 0.332632\tAccuracy: 91.80%\n",
      "425\tValidation loss: 0.335567\tBest loss: 0.332632\tAccuracy: 91.80%\n",
      "426\tValidation loss: 0.333627\tBest loss: 0.332632\tAccuracy: 91.70%\n",
      "427\tValidation loss: 0.332049\tBest loss: 0.332049\tAccuracy: 91.90%\n",
      "428\tValidation loss: 0.332301\tBest loss: 0.332049\tAccuracy: 91.70%\n",
      "429\tValidation loss: 0.333200\tBest loss: 0.332049\tAccuracy: 92.00%\n",
      "430\tValidation loss: 0.331513\tBest loss: 0.331513\tAccuracy: 91.60%\n",
      "431\tValidation loss: 0.334831\tBest loss: 0.331513\tAccuracy: 91.50%\n",
      "432\tValidation loss: 0.333737\tBest loss: 0.331513\tAccuracy: 91.60%\n",
      "433\tValidation loss: 0.334332\tBest loss: 0.331513\tAccuracy: 91.70%\n",
      "434\tValidation loss: 0.334262\tBest loss: 0.331513\tAccuracy: 91.70%\n",
      "435\tValidation loss: 0.332722\tBest loss: 0.331513\tAccuracy: 91.70%\n",
      "436\tValidation loss: 0.333063\tBest loss: 0.331513\tAccuracy: 91.80%\n",
      "437\tValidation loss: 0.331890\tBest loss: 0.331513\tAccuracy: 91.70%\n",
      "438\tValidation loss: 0.332223\tBest loss: 0.331513\tAccuracy: 91.70%\n",
      "439\tValidation loss: 0.332502\tBest loss: 0.331513\tAccuracy: 92.20%\n",
      "440\tValidation loss: 0.330463\tBest loss: 0.330463\tAccuracy: 91.70%\n",
      "441\tValidation loss: 0.331015\tBest loss: 0.330463\tAccuracy: 91.80%\n",
      "442\tValidation loss: 0.333889\tBest loss: 0.330463\tAccuracy: 91.60%\n",
      "443\tValidation loss: 0.331754\tBest loss: 0.330463\tAccuracy: 91.90%\n",
      "444\tValidation loss: 0.332095\tBest loss: 0.330463\tAccuracy: 91.70%\n",
      "445\tValidation loss: 0.331983\tBest loss: 0.330463\tAccuracy: 91.80%\n",
      "446\tValidation loss: 0.331118\tBest loss: 0.330463\tAccuracy: 91.90%\n",
      "447\tValidation loss: 0.330444\tBest loss: 0.330444\tAccuracy: 92.10%\n",
      "448\tValidation loss: 0.332149\tBest loss: 0.330444\tAccuracy: 92.50%\n",
      "449\tValidation loss: 0.330859\tBest loss: 0.330444\tAccuracy: 92.00%\n",
      "450\tValidation loss: 0.332290\tBest loss: 0.330444\tAccuracy: 92.00%\n",
      "451\tValidation loss: 0.329524\tBest loss: 0.329524\tAccuracy: 92.20%\n",
      "452\tValidation loss: 0.331698\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "453\tValidation loss: 0.333456\tBest loss: 0.329524\tAccuracy: 91.90%\n",
      "454\tValidation loss: 0.331299\tBest loss: 0.329524\tAccuracy: 91.70%\n",
      "455\tValidation loss: 0.332308\tBest loss: 0.329524\tAccuracy: 92.20%\n",
      "456\tValidation loss: 0.330002\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "457\tValidation loss: 0.330424\tBest loss: 0.329524\tAccuracy: 92.10%\n",
      "458\tValidation loss: 0.332291\tBest loss: 0.329524\tAccuracy: 92.10%\n",
      "459\tValidation loss: 0.330898\tBest loss: 0.329524\tAccuracy: 91.80%\n",
      "460\tValidation loss: 0.331557\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "461\tValidation loss: 0.330756\tBest loss: 0.329524\tAccuracy: 91.90%\n",
      "462\tValidation loss: 0.331419\tBest loss: 0.329524\tAccuracy: 91.90%\n",
      "463\tValidation loss: 0.331210\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "464\tValidation loss: 0.330765\tBest loss: 0.329524\tAccuracy: 92.10%\n",
      "465\tValidation loss: 0.331682\tBest loss: 0.329524\tAccuracy: 92.30%\n",
      "466\tValidation loss: 0.329808\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "467\tValidation loss: 0.329648\tBest loss: 0.329524\tAccuracy: 92.00%\n",
      "468\tValidation loss: 0.331623\tBest loss: 0.329524\tAccuracy: 92.10%\n",
      "469\tValidation loss: 0.328702\tBest loss: 0.328702\tAccuracy: 92.10%\n",
      "470\tValidation loss: 0.329633\tBest loss: 0.328702\tAccuracy: 92.00%\n",
      "471\tValidation loss: 0.329798\tBest loss: 0.328702\tAccuracy: 92.10%\n",
      "472\tValidation loss: 0.329317\tBest loss: 0.328702\tAccuracy: 92.20%\n",
      "473\tValidation loss: 0.330943\tBest loss: 0.328702\tAccuracy: 92.20%\n",
      "474\tValidation loss: 0.329615\tBest loss: 0.328702\tAccuracy: 92.10%\n",
      "475\tValidation loss: 0.329447\tBest loss: 0.328702\tAccuracy: 92.20%\n",
      "476\tValidation loss: 0.329824\tBest loss: 0.328702\tAccuracy: 91.70%\n",
      "477\tValidation loss: 0.329222\tBest loss: 0.328702\tAccuracy: 92.00%\n",
      "478\tValidation loss: 0.329327\tBest loss: 0.328702\tAccuracy: 92.00%\n",
      "479\tValidation loss: 0.330192\tBest loss: 0.328702\tAccuracy: 91.90%\n",
      "480\tValidation loss: 0.328525\tBest loss: 0.328525\tAccuracy: 92.10%\n",
      "481\tValidation loss: 0.328976\tBest loss: 0.328525\tAccuracy: 92.10%\n",
      "482\tValidation loss: 0.328554\tBest loss: 0.328525\tAccuracy: 92.20%\n",
      "483\tValidation loss: 0.328644\tBest loss: 0.328525\tAccuracy: 92.40%\n",
      "484\tValidation loss: 0.327202\tBest loss: 0.327202\tAccuracy: 92.20%\n",
      "485\tValidation loss: 0.328320\tBest loss: 0.327202\tAccuracy: 92.30%\n",
      "486\tValidation loss: 0.328081\tBest loss: 0.327202\tAccuracy: 92.00%\n",
      "487\tValidation loss: 0.327174\tBest loss: 0.327174\tAccuracy: 92.40%\n",
      "488\tValidation loss: 0.327659\tBest loss: 0.327174\tAccuracy: 92.20%\n",
      "489\tValidation loss: 0.328647\tBest loss: 0.327174\tAccuracy: 92.20%\n",
      "490\tValidation loss: 0.328445\tBest loss: 0.327174\tAccuracy: 92.30%\n",
      "491\tValidation loss: 0.327480\tBest loss: 0.327174\tAccuracy: 92.20%\n",
      "492\tValidation loss: 0.329020\tBest loss: 0.327174\tAccuracy: 92.30%\n",
      "493\tValidation loss: 0.328171\tBest loss: 0.327174\tAccuracy: 92.20%\n",
      "494\tValidation loss: 0.328866\tBest loss: 0.327174\tAccuracy: 92.30%\n",
      "495\tValidation loss: 0.327201\tBest loss: 0.327174\tAccuracy: 92.10%\n",
      "496\tValidation loss: 0.327973\tBest loss: 0.327174\tAccuracy: 92.40%\n",
      "497\tValidation loss: 0.327167\tBest loss: 0.327167\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\tValidation loss: 0.328713\tBest loss: 0.327167\tAccuracy: 92.10%\n",
      "499\tValidation loss: 0.328721\tBest loss: 0.327167\tAccuracy: 92.20%\n",
      "500\tValidation loss: 0.327941\tBest loss: 0.327167\tAccuracy: 92.30%\n",
      "501\tValidation loss: 0.328141\tBest loss: 0.327167\tAccuracy: 92.20%\n",
      "502\tValidation loss: 0.327202\tBest loss: 0.327167\tAccuracy: 92.50%\n",
      "503\tValidation loss: 0.326668\tBest loss: 0.326668\tAccuracy: 92.30%\n",
      "504\tValidation loss: 0.325037\tBest loss: 0.325037\tAccuracy: 92.30%\n",
      "505\tValidation loss: 0.326358\tBest loss: 0.325037\tAccuracy: 92.40%\n",
      "506\tValidation loss: 0.327807\tBest loss: 0.325037\tAccuracy: 92.30%\n",
      "507\tValidation loss: 0.327560\tBest loss: 0.325037\tAccuracy: 92.20%\n",
      "508\tValidation loss: 0.325798\tBest loss: 0.325037\tAccuracy: 92.20%\n",
      "509\tValidation loss: 0.324745\tBest loss: 0.324745\tAccuracy: 92.50%\n",
      "510\tValidation loss: 0.326623\tBest loss: 0.324745\tAccuracy: 92.50%\n",
      "511\tValidation loss: 0.327172\tBest loss: 0.324745\tAccuracy: 92.40%\n",
      "512\tValidation loss: 0.326554\tBest loss: 0.324745\tAccuracy: 92.40%\n",
      "513\tValidation loss: 0.326692\tBest loss: 0.324745\tAccuracy: 92.20%\n",
      "514\tValidation loss: 0.324134\tBest loss: 0.324134\tAccuracy: 92.30%\n",
      "515\tValidation loss: 0.325464\tBest loss: 0.324134\tAccuracy: 92.20%\n",
      "516\tValidation loss: 0.326849\tBest loss: 0.324134\tAccuracy: 92.50%\n",
      "517\tValidation loss: 0.324911\tBest loss: 0.324134\tAccuracy: 92.40%\n",
      "518\tValidation loss: 0.325530\tBest loss: 0.324134\tAccuracy: 92.50%\n",
      "519\tValidation loss: 0.326151\tBest loss: 0.324134\tAccuracy: 92.10%\n",
      "520\tValidation loss: 0.325969\tBest loss: 0.324134\tAccuracy: 92.60%\n",
      "521\tValidation loss: 0.326083\tBest loss: 0.324134\tAccuracy: 92.50%\n",
      "522\tValidation loss: 0.327508\tBest loss: 0.324134\tAccuracy: 92.00%\n",
      "523\tValidation loss: 0.324786\tBest loss: 0.324134\tAccuracy: 92.40%\n",
      "524\tValidation loss: 0.325966\tBest loss: 0.324134\tAccuracy: 92.40%\n",
      "525\tValidation loss: 0.326793\tBest loss: 0.324134\tAccuracy: 92.30%\n",
      "526\tValidation loss: 0.325622\tBest loss: 0.324134\tAccuracy: 92.50%\n",
      "527\tValidation loss: 0.324885\tBest loss: 0.324134\tAccuracy: 92.40%\n",
      "528\tValidation loss: 0.325571\tBest loss: 0.324134\tAccuracy: 92.20%\n",
      "529\tValidation loss: 0.324027\tBest loss: 0.324027\tAccuracy: 92.50%\n",
      "530\tValidation loss: 0.324975\tBest loss: 0.324027\tAccuracy: 92.40%\n",
      "531\tValidation loss: 0.324814\tBest loss: 0.324027\tAccuracy: 92.50%\n",
      "532\tValidation loss: 0.324911\tBest loss: 0.324027\tAccuracy: 92.60%\n",
      "533\tValidation loss: 0.325084\tBest loss: 0.324027\tAccuracy: 92.30%\n",
      "534\tValidation loss: 0.324612\tBest loss: 0.324027\tAccuracy: 92.30%\n",
      "535\tValidation loss: 0.322898\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "536\tValidation loss: 0.324079\tBest loss: 0.322898\tAccuracy: 92.30%\n",
      "537\tValidation loss: 0.323777\tBest loss: 0.322898\tAccuracy: 92.70%\n",
      "538\tValidation loss: 0.324554\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "539\tValidation loss: 0.325906\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "540\tValidation loss: 0.324131\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "541\tValidation loss: 0.325737\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "542\tValidation loss: 0.323710\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "543\tValidation loss: 0.324448\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "544\tValidation loss: 0.324707\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "545\tValidation loss: 0.324696\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "546\tValidation loss: 0.325127\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "547\tValidation loss: 0.323906\tBest loss: 0.322898\tAccuracy: 92.30%\n",
      "548\tValidation loss: 0.323588\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "549\tValidation loss: 0.324331\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "550\tValidation loss: 0.324344\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "551\tValidation loss: 0.323940\tBest loss: 0.322898\tAccuracy: 92.30%\n",
      "552\tValidation loss: 0.324338\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "553\tValidation loss: 0.324508\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "554\tValidation loss: 0.324624\tBest loss: 0.322898\tAccuracy: 92.40%\n",
      "555\tValidation loss: 0.326029\tBest loss: 0.322898\tAccuracy: 92.50%\n",
      "556\tValidation loss: 0.323746\tBest loss: 0.322898\tAccuracy: 92.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.1min\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.294169\tBest loss: 2.294169\tAccuracy: 39.80%\n",
      "1\tValidation loss: 1.734997\tBest loss: 1.734997\tAccuracy: 58.40%\n",
      "2\tValidation loss: 1.503927\tBest loss: 1.503927\tAccuracy: 63.10%\n",
      "3\tValidation loss: 1.324638\tBest loss: 1.324638\tAccuracy: 68.50%\n",
      "4\tValidation loss: 1.222987\tBest loss: 1.222987\tAccuracy: 70.90%\n",
      "5\tValidation loss: 1.138700\tBest loss: 1.138700\tAccuracy: 72.60%\n",
      "6\tValidation loss: 1.087479\tBest loss: 1.087479\tAccuracy: 74.20%\n",
      "7\tValidation loss: 1.031636\tBest loss: 1.031636\tAccuracy: 74.80%\n",
      "8\tValidation loss: 0.981884\tBest loss: 0.981884\tAccuracy: 75.70%\n",
      "9\tValidation loss: 0.954895\tBest loss: 0.954895\tAccuracy: 76.80%\n",
      "10\tValidation loss: 0.912528\tBest loss: 0.912528\tAccuracy: 79.20%\n",
      "11\tValidation loss: 0.889068\tBest loss: 0.889068\tAccuracy: 78.20%\n",
      "12\tValidation loss: 0.865537\tBest loss: 0.865537\tAccuracy: 78.60%\n",
      "13\tValidation loss: 0.836695\tBest loss: 0.836695\tAccuracy: 79.60%\n",
      "14\tValidation loss: 0.813810\tBest loss: 0.813810\tAccuracy: 80.30%\n",
      "15\tValidation loss: 0.801275\tBest loss: 0.801275\tAccuracy: 80.30%\n",
      "16\tValidation loss: 0.781937\tBest loss: 0.781937\tAccuracy: 80.30%\n",
      "17\tValidation loss: 0.764068\tBest loss: 0.764068\tAccuracy: 81.50%\n",
      "18\tValidation loss: 0.754948\tBest loss: 0.754948\tAccuracy: 81.80%\n",
      "19\tValidation loss: 0.740335\tBest loss: 0.740335\tAccuracy: 81.80%\n",
      "20\tValidation loss: 0.723887\tBest loss: 0.723887\tAccuracy: 82.30%\n",
      "21\tValidation loss: 0.713835\tBest loss: 0.713835\tAccuracy: 83.20%\n",
      "22\tValidation loss: 0.700875\tBest loss: 0.700875\tAccuracy: 83.30%\n",
      "23\tValidation loss: 0.697511\tBest loss: 0.697511\tAccuracy: 83.20%\n",
      "24\tValidation loss: 0.684563\tBest loss: 0.684563\tAccuracy: 83.40%\n",
      "25\tValidation loss: 0.679180\tBest loss: 0.679180\tAccuracy: 83.60%\n",
      "26\tValidation loss: 0.675000\tBest loss: 0.675000\tAccuracy: 84.30%\n",
      "27\tValidation loss: 0.662729\tBest loss: 0.662729\tAccuracy: 84.50%\n",
      "28\tValidation loss: 0.656241\tBest loss: 0.656241\tAccuracy: 83.80%\n",
      "29\tValidation loss: 0.652418\tBest loss: 0.652418\tAccuracy: 84.10%\n",
      "30\tValidation loss: 0.639534\tBest loss: 0.639534\tAccuracy: 84.60%\n",
      "31\tValidation loss: 0.632366\tBest loss: 0.632366\tAccuracy: 84.80%\n",
      "32\tValidation loss: 0.630882\tBest loss: 0.630882\tAccuracy: 84.40%\n",
      "33\tValidation loss: 0.622481\tBest loss: 0.622481\tAccuracy: 84.60%\n",
      "34\tValidation loss: 0.620040\tBest loss: 0.620040\tAccuracy: 84.80%\n",
      "35\tValidation loss: 0.614639\tBest loss: 0.614639\tAccuracy: 84.80%\n",
      "36\tValidation loss: 0.609476\tBest loss: 0.609476\tAccuracy: 84.60%\n",
      "37\tValidation loss: 0.599733\tBest loss: 0.599733\tAccuracy: 85.20%\n",
      "38\tValidation loss: 0.597973\tBest loss: 0.597973\tAccuracy: 85.60%\n",
      "39\tValidation loss: 0.596291\tBest loss: 0.596291\tAccuracy: 85.10%\n",
      "40\tValidation loss: 0.591184\tBest loss: 0.591184\tAccuracy: 85.50%\n",
      "41\tValidation loss: 0.583946\tBest loss: 0.583946\tAccuracy: 85.90%\n",
      "42\tValidation loss: 0.580508\tBest loss: 0.580508\tAccuracy: 85.80%\n",
      "43\tValidation loss: 0.568685\tBest loss: 0.568685\tAccuracy: 86.00%\n",
      "44\tValidation loss: 0.569231\tBest loss: 0.568685\tAccuracy: 85.70%\n",
      "45\tValidation loss: 0.568960\tBest loss: 0.568685\tAccuracy: 86.40%\n",
      "46\tValidation loss: 0.569571\tBest loss: 0.568685\tAccuracy: 85.20%\n",
      "47\tValidation loss: 0.564843\tBest loss: 0.564843\tAccuracy: 85.80%\n",
      "48\tValidation loss: 0.560247\tBest loss: 0.560247\tAccuracy: 86.10%\n",
      "49\tValidation loss: 0.556264\tBest loss: 0.556264\tAccuracy: 86.10%\n",
      "50\tValidation loss: 0.552939\tBest loss: 0.552939\tAccuracy: 86.20%\n",
      "51\tValidation loss: 0.549906\tBest loss: 0.549906\tAccuracy: 86.00%\n",
      "52\tValidation loss: 0.544575\tBest loss: 0.544575\tAccuracy: 86.90%\n",
      "53\tValidation loss: 0.539947\tBest loss: 0.539947\tAccuracy: 86.50%\n",
      "54\tValidation loss: 0.539449\tBest loss: 0.539449\tAccuracy: 86.80%\n",
      "55\tValidation loss: 0.535566\tBest loss: 0.535566\tAccuracy: 86.60%\n",
      "56\tValidation loss: 0.537368\tBest loss: 0.535566\tAccuracy: 86.40%\n",
      "57\tValidation loss: 0.530199\tBest loss: 0.530199\tAccuracy: 86.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\tValidation loss: 0.532879\tBest loss: 0.530199\tAccuracy: 86.70%\n",
      "59\tValidation loss: 0.529261\tBest loss: 0.529261\tAccuracy: 86.40%\n",
      "60\tValidation loss: 0.529629\tBest loss: 0.529261\tAccuracy: 86.60%\n",
      "61\tValidation loss: 0.526049\tBest loss: 0.526049\tAccuracy: 87.00%\n",
      "62\tValidation loss: 0.523433\tBest loss: 0.523433\tAccuracy: 86.90%\n",
      "63\tValidation loss: 0.516242\tBest loss: 0.516242\tAccuracy: 87.10%\n",
      "64\tValidation loss: 0.511980\tBest loss: 0.511980\tAccuracy: 87.30%\n",
      "65\tValidation loss: 0.510509\tBest loss: 0.510509\tAccuracy: 87.10%\n",
      "66\tValidation loss: 0.513394\tBest loss: 0.510509\tAccuracy: 87.10%\n",
      "67\tValidation loss: 0.514992\tBest loss: 0.510509\tAccuracy: 87.00%\n",
      "68\tValidation loss: 0.507226\tBest loss: 0.507226\tAccuracy: 87.60%\n",
      "69\tValidation loss: 0.511952\tBest loss: 0.507226\tAccuracy: 87.30%\n",
      "70\tValidation loss: 0.507591\tBest loss: 0.507226\tAccuracy: 87.00%\n",
      "71\tValidation loss: 0.502077\tBest loss: 0.502077\tAccuracy: 87.10%\n",
      "72\tValidation loss: 0.510005\tBest loss: 0.502077\tAccuracy: 87.60%\n",
      "73\tValidation loss: 0.500128\tBest loss: 0.500128\tAccuracy: 87.00%\n",
      "74\tValidation loss: 0.499816\tBest loss: 0.499816\tAccuracy: 88.00%\n",
      "75\tValidation loss: 0.498342\tBest loss: 0.498342\tAccuracy: 87.50%\n",
      "76\tValidation loss: 0.489380\tBest loss: 0.489380\tAccuracy: 87.50%\n",
      "77\tValidation loss: 0.495565\tBest loss: 0.489380\tAccuracy: 88.10%\n",
      "78\tValidation loss: 0.486811\tBest loss: 0.486811\tAccuracy: 88.30%\n",
      "79\tValidation loss: 0.488728\tBest loss: 0.486811\tAccuracy: 87.70%\n",
      "80\tValidation loss: 0.487332\tBest loss: 0.486811\tAccuracy: 87.60%\n",
      "81\tValidation loss: 0.491677\tBest loss: 0.486811\tAccuracy: 87.80%\n",
      "82\tValidation loss: 0.482847\tBest loss: 0.482847\tAccuracy: 88.20%\n",
      "83\tValidation loss: 0.489699\tBest loss: 0.482847\tAccuracy: 88.10%\n",
      "84\tValidation loss: 0.482018\tBest loss: 0.482018\tAccuracy: 88.00%\n",
      "85\tValidation loss: 0.480784\tBest loss: 0.480784\tAccuracy: 88.40%\n",
      "86\tValidation loss: 0.478813\tBest loss: 0.478813\tAccuracy: 87.90%\n",
      "87\tValidation loss: 0.477783\tBest loss: 0.477783\tAccuracy: 88.40%\n",
      "88\tValidation loss: 0.476569\tBest loss: 0.476569\tAccuracy: 88.60%\n",
      "89\tValidation loss: 0.479749\tBest loss: 0.476569\tAccuracy: 88.40%\n",
      "90\tValidation loss: 0.474263\tBest loss: 0.474263\tAccuracy: 88.20%\n",
      "91\tValidation loss: 0.472486\tBest loss: 0.472486\tAccuracy: 88.70%\n",
      "92\tValidation loss: 0.476063\tBest loss: 0.472486\tAccuracy: 88.60%\n",
      "93\tValidation loss: 0.470205\tBest loss: 0.470205\tAccuracy: 88.20%\n",
      "94\tValidation loss: 0.470107\tBest loss: 0.470107\tAccuracy: 89.30%\n",
      "95\tValidation loss: 0.466956\tBest loss: 0.466956\tAccuracy: 88.80%\n",
      "96\tValidation loss: 0.467127\tBest loss: 0.466956\tAccuracy: 88.30%\n",
      "97\tValidation loss: 0.464694\tBest loss: 0.464694\tAccuracy: 89.10%\n",
      "98\tValidation loss: 0.466023\tBest loss: 0.464694\tAccuracy: 89.00%\n",
      "99\tValidation loss: 0.468536\tBest loss: 0.464694\tAccuracy: 88.80%\n",
      "100\tValidation loss: 0.464264\tBest loss: 0.464264\tAccuracy: 89.30%\n",
      "101\tValidation loss: 0.461960\tBest loss: 0.461960\tAccuracy: 88.60%\n",
      "102\tValidation loss: 0.461911\tBest loss: 0.461911\tAccuracy: 88.80%\n",
      "103\tValidation loss: 0.459422\tBest loss: 0.459422\tAccuracy: 88.50%\n",
      "104\tValidation loss: 0.460868\tBest loss: 0.459422\tAccuracy: 89.10%\n",
      "105\tValidation loss: 0.458511\tBest loss: 0.458511\tAccuracy: 88.70%\n",
      "106\tValidation loss: 0.455138\tBest loss: 0.455138\tAccuracy: 89.10%\n",
      "107\tValidation loss: 0.457683\tBest loss: 0.455138\tAccuracy: 89.10%\n",
      "108\tValidation loss: 0.461911\tBest loss: 0.455138\tAccuracy: 89.30%\n",
      "109\tValidation loss: 0.457687\tBest loss: 0.455138\tAccuracy: 88.80%\n",
      "110\tValidation loss: 0.457510\tBest loss: 0.455138\tAccuracy: 88.70%\n",
      "111\tValidation loss: 0.455752\tBest loss: 0.455138\tAccuracy: 89.20%\n",
      "112\tValidation loss: 0.456140\tBest loss: 0.455138\tAccuracy: 89.10%\n",
      "113\tValidation loss: 0.450079\tBest loss: 0.450079\tAccuracy: 89.20%\n",
      "114\tValidation loss: 0.451213\tBest loss: 0.450079\tAccuracy: 89.30%\n",
      "115\tValidation loss: 0.454915\tBest loss: 0.450079\tAccuracy: 89.20%\n",
      "116\tValidation loss: 0.453857\tBest loss: 0.450079\tAccuracy: 89.30%\n",
      "117\tValidation loss: 0.449207\tBest loss: 0.449207\tAccuracy: 89.80%\n",
      "118\tValidation loss: 0.448635\tBest loss: 0.448635\tAccuracy: 89.50%\n",
      "119\tValidation loss: 0.448641\tBest loss: 0.448635\tAccuracy: 89.40%\n",
      "120\tValidation loss: 0.447715\tBest loss: 0.447715\tAccuracy: 89.30%\n",
      "121\tValidation loss: 0.448447\tBest loss: 0.447715\tAccuracy: 89.40%\n",
      "122\tValidation loss: 0.444039\tBest loss: 0.444039\tAccuracy: 89.20%\n",
      "123\tValidation loss: 0.442892\tBest loss: 0.442892\tAccuracy: 89.60%\n",
      "124\tValidation loss: 0.444964\tBest loss: 0.442892\tAccuracy: 89.10%\n",
      "125\tValidation loss: 0.444359\tBest loss: 0.442892\tAccuracy: 89.50%\n",
      "126\tValidation loss: 0.444042\tBest loss: 0.442892\tAccuracy: 89.80%\n",
      "127\tValidation loss: 0.443352\tBest loss: 0.442892\tAccuracy: 90.00%\n",
      "128\tValidation loss: 0.442334\tBest loss: 0.442334\tAccuracy: 89.60%\n",
      "129\tValidation loss: 0.438929\tBest loss: 0.438929\tAccuracy: 89.60%\n",
      "130\tValidation loss: 0.437437\tBest loss: 0.437437\tAccuracy: 89.70%\n",
      "131\tValidation loss: 0.436814\tBest loss: 0.436814\tAccuracy: 90.10%\n",
      "132\tValidation loss: 0.437158\tBest loss: 0.436814\tAccuracy: 89.80%\n",
      "133\tValidation loss: 0.440231\tBest loss: 0.436814\tAccuracy: 90.10%\n",
      "134\tValidation loss: 0.439051\tBest loss: 0.436814\tAccuracy: 89.90%\n",
      "135\tValidation loss: 0.438653\tBest loss: 0.436814\tAccuracy: 89.70%\n",
      "136\tValidation loss: 0.436274\tBest loss: 0.436274\tAccuracy: 89.80%\n",
      "137\tValidation loss: 0.438719\tBest loss: 0.436274\tAccuracy: 90.00%\n",
      "138\tValidation loss: 0.433284\tBest loss: 0.433284\tAccuracy: 89.80%\n",
      "139\tValidation loss: 0.434964\tBest loss: 0.433284\tAccuracy: 89.60%\n",
      "140\tValidation loss: 0.437770\tBest loss: 0.433284\tAccuracy: 90.00%\n",
      "141\tValidation loss: 0.436455\tBest loss: 0.433284\tAccuracy: 89.70%\n",
      "142\tValidation loss: 0.433502\tBest loss: 0.433284\tAccuracy: 90.00%\n",
      "143\tValidation loss: 0.433393\tBest loss: 0.433284\tAccuracy: 90.30%\n",
      "144\tValidation loss: 0.431712\tBest loss: 0.431712\tAccuracy: 90.20%\n",
      "145\tValidation loss: 0.430619\tBest loss: 0.430619\tAccuracy: 89.80%\n",
      "146\tValidation loss: 0.431560\tBest loss: 0.430619\tAccuracy: 89.40%\n",
      "147\tValidation loss: 0.428352\tBest loss: 0.428352\tAccuracy: 89.90%\n",
      "148\tValidation loss: 0.430166\tBest loss: 0.428352\tAccuracy: 89.80%\n",
      "149\tValidation loss: 0.429750\tBest loss: 0.428352\tAccuracy: 89.90%\n",
      "150\tValidation loss: 0.428177\tBest loss: 0.428177\tAccuracy: 90.20%\n",
      "151\tValidation loss: 0.429120\tBest loss: 0.428177\tAccuracy: 90.30%\n",
      "152\tValidation loss: 0.426735\tBest loss: 0.426735\tAccuracy: 90.10%\n",
      "153\tValidation loss: 0.429806\tBest loss: 0.426735\tAccuracy: 89.90%\n",
      "154\tValidation loss: 0.428665\tBest loss: 0.426735\tAccuracy: 89.90%\n",
      "155\tValidation loss: 0.428463\tBest loss: 0.426735\tAccuracy: 89.90%\n",
      "156\tValidation loss: 0.426496\tBest loss: 0.426496\tAccuracy: 89.90%\n",
      "157\tValidation loss: 0.424602\tBest loss: 0.424602\tAccuracy: 90.20%\n",
      "158\tValidation loss: 0.424305\tBest loss: 0.424305\tAccuracy: 90.00%\n",
      "159\tValidation loss: 0.425067\tBest loss: 0.424305\tAccuracy: 90.20%\n",
      "160\tValidation loss: 0.423372\tBest loss: 0.423372\tAccuracy: 90.50%\n",
      "161\tValidation loss: 0.428129\tBest loss: 0.423372\tAccuracy: 90.10%\n",
      "162\tValidation loss: 0.425226\tBest loss: 0.423372\tAccuracy: 89.80%\n",
      "163\tValidation loss: 0.428424\tBest loss: 0.423372\tAccuracy: 89.90%\n",
      "164\tValidation loss: 0.420473\tBest loss: 0.420473\tAccuracy: 90.10%\n",
      "165\tValidation loss: 0.423255\tBest loss: 0.420473\tAccuracy: 90.00%\n",
      "166\tValidation loss: 0.419886\tBest loss: 0.419886\tAccuracy: 90.40%\n",
      "167\tValidation loss: 0.421356\tBest loss: 0.419886\tAccuracy: 90.20%\n",
      "168\tValidation loss: 0.417902\tBest loss: 0.417902\tAccuracy: 89.90%\n",
      "169\tValidation loss: 0.420278\tBest loss: 0.417902\tAccuracy: 89.90%\n",
      "170\tValidation loss: 0.418087\tBest loss: 0.417902\tAccuracy: 89.80%\n",
      "171\tValidation loss: 0.419822\tBest loss: 0.417902\tAccuracy: 89.90%\n",
      "172\tValidation loss: 0.418417\tBest loss: 0.417902\tAccuracy: 89.90%\n",
      "173\tValidation loss: 0.420978\tBest loss: 0.417902\tAccuracy: 90.70%\n",
      "174\tValidation loss: 0.416151\tBest loss: 0.416151\tAccuracy: 90.60%\n",
      "175\tValidation loss: 0.417178\tBest loss: 0.416151\tAccuracy: 90.00%\n",
      "176\tValidation loss: 0.417214\tBest loss: 0.416151\tAccuracy: 90.00%\n",
      "177\tValidation loss: 0.419302\tBest loss: 0.416151\tAccuracy: 90.30%\n",
      "178\tValidation loss: 0.418351\tBest loss: 0.416151\tAccuracy: 90.10%\n",
      "179\tValidation loss: 0.418053\tBest loss: 0.416151\tAccuracy: 90.20%\n",
      "180\tValidation loss: 0.415377\tBest loss: 0.415377\tAccuracy: 90.10%\n",
      "181\tValidation loss: 0.414994\tBest loss: 0.414994\tAccuracy: 91.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\tValidation loss: 0.411560\tBest loss: 0.411560\tAccuracy: 90.50%\n",
      "183\tValidation loss: 0.415914\tBest loss: 0.411560\tAccuracy: 90.40%\n",
      "184\tValidation loss: 0.414804\tBest loss: 0.411560\tAccuracy: 90.10%\n",
      "185\tValidation loss: 0.413660\tBest loss: 0.411560\tAccuracy: 90.50%\n",
      "186\tValidation loss: 0.413985\tBest loss: 0.411560\tAccuracy: 90.20%\n",
      "187\tValidation loss: 0.412566\tBest loss: 0.411560\tAccuracy: 90.20%\n",
      "188\tValidation loss: 0.410932\tBest loss: 0.410932\tAccuracy: 89.70%\n",
      "189\tValidation loss: 0.411812\tBest loss: 0.410932\tAccuracy: 90.30%\n",
      "190\tValidation loss: 0.410999\tBest loss: 0.410932\tAccuracy: 90.50%\n",
      "191\tValidation loss: 0.411248\tBest loss: 0.410932\tAccuracy: 90.60%\n",
      "192\tValidation loss: 0.412599\tBest loss: 0.410932\tAccuracy: 90.40%\n",
      "193\tValidation loss: 0.409602\tBest loss: 0.409602\tAccuracy: 91.00%\n",
      "194\tValidation loss: 0.409949\tBest loss: 0.409602\tAccuracy: 90.70%\n",
      "195\tValidation loss: 0.409034\tBest loss: 0.409034\tAccuracy: 90.40%\n",
      "196\tValidation loss: 0.407816\tBest loss: 0.407816\tAccuracy: 91.00%\n",
      "197\tValidation loss: 0.413327\tBest loss: 0.407816\tAccuracy: 90.70%\n",
      "198\tValidation loss: 0.409380\tBest loss: 0.407816\tAccuracy: 90.30%\n",
      "199\tValidation loss: 0.410636\tBest loss: 0.407816\tAccuracy: 90.50%\n",
      "200\tValidation loss: 0.407499\tBest loss: 0.407499\tAccuracy: 90.10%\n",
      "201\tValidation loss: 0.410103\tBest loss: 0.407499\tAccuracy: 90.60%\n",
      "202\tValidation loss: 0.405055\tBest loss: 0.405055\tAccuracy: 90.60%\n",
      "203\tValidation loss: 0.409113\tBest loss: 0.405055\tAccuracy: 90.50%\n",
      "204\tValidation loss: 0.406639\tBest loss: 0.405055\tAccuracy: 90.70%\n",
      "205\tValidation loss: 0.406572\tBest loss: 0.405055\tAccuracy: 90.70%\n",
      "206\tValidation loss: 0.410858\tBest loss: 0.405055\tAccuracy: 90.60%\n",
      "207\tValidation loss: 0.404417\tBest loss: 0.404417\tAccuracy: 90.40%\n",
      "208\tValidation loss: 0.406716\tBest loss: 0.404417\tAccuracy: 90.90%\n",
      "209\tValidation loss: 0.406067\tBest loss: 0.404417\tAccuracy: 90.70%\n",
      "210\tValidation loss: 0.407081\tBest loss: 0.404417\tAccuracy: 90.80%\n",
      "211\tValidation loss: 0.405331\tBest loss: 0.404417\tAccuracy: 90.90%\n",
      "212\tValidation loss: 0.404744\tBest loss: 0.404417\tAccuracy: 90.90%\n",
      "213\tValidation loss: 0.405363\tBest loss: 0.404417\tAccuracy: 90.60%\n",
      "214\tValidation loss: 0.405074\tBest loss: 0.404417\tAccuracy: 90.70%\n",
      "215\tValidation loss: 0.407740\tBest loss: 0.404417\tAccuracy: 90.80%\n",
      "216\tValidation loss: 0.405543\tBest loss: 0.404417\tAccuracy: 90.50%\n",
      "217\tValidation loss: 0.403715\tBest loss: 0.403715\tAccuracy: 90.60%\n",
      "218\tValidation loss: 0.406232\tBest loss: 0.403715\tAccuracy: 90.70%\n",
      "219\tValidation loss: 0.404450\tBest loss: 0.403715\tAccuracy: 90.70%\n",
      "220\tValidation loss: 0.401592\tBest loss: 0.401592\tAccuracy: 91.00%\n",
      "221\tValidation loss: 0.403998\tBest loss: 0.401592\tAccuracy: 90.80%\n",
      "222\tValidation loss: 0.405005\tBest loss: 0.401592\tAccuracy: 91.10%\n",
      "223\tValidation loss: 0.403586\tBest loss: 0.401592\tAccuracy: 90.70%\n",
      "224\tValidation loss: 0.401268\tBest loss: 0.401268\tAccuracy: 91.20%\n",
      "225\tValidation loss: 0.404599\tBest loss: 0.401268\tAccuracy: 90.70%\n",
      "226\tValidation loss: 0.400413\tBest loss: 0.400413\tAccuracy: 91.20%\n",
      "227\tValidation loss: 0.400536\tBest loss: 0.400413\tAccuracy: 90.70%\n",
      "228\tValidation loss: 0.401434\tBest loss: 0.400413\tAccuracy: 91.40%\n",
      "229\tValidation loss: 0.401669\tBest loss: 0.400413\tAccuracy: 90.70%\n",
      "230\tValidation loss: 0.399557\tBest loss: 0.399557\tAccuracy: 91.30%\n",
      "231\tValidation loss: 0.401025\tBest loss: 0.399557\tAccuracy: 90.80%\n",
      "232\tValidation loss: 0.400796\tBest loss: 0.399557\tAccuracy: 90.90%\n",
      "233\tValidation loss: 0.400224\tBest loss: 0.399557\tAccuracy: 91.10%\n",
      "234\tValidation loss: 0.398502\tBest loss: 0.398502\tAccuracy: 91.00%\n",
      "235\tValidation loss: 0.401790\tBest loss: 0.398502\tAccuracy: 91.10%\n",
      "236\tValidation loss: 0.398380\tBest loss: 0.398380\tAccuracy: 91.30%\n",
      "237\tValidation loss: 0.399955\tBest loss: 0.398380\tAccuracy: 90.80%\n",
      "238\tValidation loss: 0.401097\tBest loss: 0.398380\tAccuracy: 91.00%\n",
      "239\tValidation loss: 0.402231\tBest loss: 0.398380\tAccuracy: 91.20%\n",
      "240\tValidation loss: 0.399309\tBest loss: 0.398380\tAccuracy: 91.00%\n",
      "241\tValidation loss: 0.401124\tBest loss: 0.398380\tAccuracy: 91.20%\n",
      "242\tValidation loss: 0.403263\tBest loss: 0.398380\tAccuracy: 91.00%\n",
      "243\tValidation loss: 0.397963\tBest loss: 0.397963\tAccuracy: 91.30%\n",
      "244\tValidation loss: 0.399194\tBest loss: 0.397963\tAccuracy: 91.10%\n",
      "245\tValidation loss: 0.396562\tBest loss: 0.396562\tAccuracy: 91.20%\n",
      "246\tValidation loss: 0.398468\tBest loss: 0.396562\tAccuracy: 91.00%\n",
      "247\tValidation loss: 0.398201\tBest loss: 0.396562\tAccuracy: 91.10%\n",
      "248\tValidation loss: 0.398547\tBest loss: 0.396562\tAccuracy: 91.10%\n",
      "249\tValidation loss: 0.397214\tBest loss: 0.396562\tAccuracy: 91.00%\n",
      "250\tValidation loss: 0.398534\tBest loss: 0.396562\tAccuracy: 91.10%\n",
      "251\tValidation loss: 0.396151\tBest loss: 0.396151\tAccuracy: 91.50%\n",
      "252\tValidation loss: 0.398875\tBest loss: 0.396151\tAccuracy: 91.20%\n",
      "253\tValidation loss: 0.395689\tBest loss: 0.395689\tAccuracy: 91.10%\n",
      "254\tValidation loss: 0.397230\tBest loss: 0.395689\tAccuracy: 91.10%\n",
      "255\tValidation loss: 0.398413\tBest loss: 0.395689\tAccuracy: 91.00%\n",
      "256\tValidation loss: 0.395598\tBest loss: 0.395598\tAccuracy: 91.40%\n",
      "257\tValidation loss: 0.398326\tBest loss: 0.395598\tAccuracy: 91.20%\n",
      "258\tValidation loss: 0.395672\tBest loss: 0.395598\tAccuracy: 91.20%\n",
      "259\tValidation loss: 0.395036\tBest loss: 0.395036\tAccuracy: 91.30%\n",
      "260\tValidation loss: 0.397723\tBest loss: 0.395036\tAccuracy: 91.00%\n",
      "261\tValidation loss: 0.396498\tBest loss: 0.395036\tAccuracy: 91.50%\n",
      "262\tValidation loss: 0.396360\tBest loss: 0.395036\tAccuracy: 91.50%\n",
      "263\tValidation loss: 0.394899\tBest loss: 0.394899\tAccuracy: 91.20%\n",
      "264\tValidation loss: 0.397449\tBest loss: 0.394899\tAccuracy: 91.30%\n",
      "265\tValidation loss: 0.394746\tBest loss: 0.394746\tAccuracy: 91.10%\n",
      "266\tValidation loss: 0.395867\tBest loss: 0.394746\tAccuracy: 91.30%\n",
      "267\tValidation loss: 0.397411\tBest loss: 0.394746\tAccuracy: 91.30%\n",
      "268\tValidation loss: 0.394748\tBest loss: 0.394746\tAccuracy: 91.30%\n",
      "269\tValidation loss: 0.395871\tBest loss: 0.394746\tAccuracy: 91.10%\n",
      "270\tValidation loss: 0.391830\tBest loss: 0.391830\tAccuracy: 91.50%\n",
      "271\tValidation loss: 0.393515\tBest loss: 0.391830\tAccuracy: 91.20%\n",
      "272\tValidation loss: 0.393193\tBest loss: 0.391830\tAccuracy: 91.50%\n",
      "273\tValidation loss: 0.392676\tBest loss: 0.391830\tAccuracy: 91.20%\n",
      "274\tValidation loss: 0.394384\tBest loss: 0.391830\tAccuracy: 91.20%\n",
      "275\tValidation loss: 0.390825\tBest loss: 0.390825\tAccuracy: 91.60%\n",
      "276\tValidation loss: 0.393821\tBest loss: 0.390825\tAccuracy: 91.40%\n",
      "277\tValidation loss: 0.395347\tBest loss: 0.390825\tAccuracy: 91.70%\n",
      "278\tValidation loss: 0.392476\tBest loss: 0.390825\tAccuracy: 91.60%\n",
      "279\tValidation loss: 0.393480\tBest loss: 0.390825\tAccuracy: 91.50%\n",
      "280\tValidation loss: 0.390314\tBest loss: 0.390314\tAccuracy: 91.80%\n",
      "281\tValidation loss: 0.391653\tBest loss: 0.390314\tAccuracy: 91.70%\n",
      "282\tValidation loss: 0.393827\tBest loss: 0.390314\tAccuracy: 91.50%\n",
      "283\tValidation loss: 0.394284\tBest loss: 0.390314\tAccuracy: 91.30%\n",
      "284\tValidation loss: 0.391533\tBest loss: 0.390314\tAccuracy: 91.60%\n",
      "285\tValidation loss: 0.391749\tBest loss: 0.390314\tAccuracy: 91.60%\n",
      "286\tValidation loss: 0.391660\tBest loss: 0.390314\tAccuracy: 91.50%\n",
      "287\tValidation loss: 0.392554\tBest loss: 0.390314\tAccuracy: 91.50%\n",
      "288\tValidation loss: 0.390962\tBest loss: 0.390314\tAccuracy: 91.70%\n",
      "289\tValidation loss: 0.389452\tBest loss: 0.389452\tAccuracy: 91.10%\n",
      "290\tValidation loss: 0.390131\tBest loss: 0.389452\tAccuracy: 91.40%\n",
      "291\tValidation loss: 0.390374\tBest loss: 0.389452\tAccuracy: 91.60%\n",
      "292\tValidation loss: 0.393900\tBest loss: 0.389452\tAccuracy: 91.40%\n",
      "293\tValidation loss: 0.389653\tBest loss: 0.389452\tAccuracy: 91.70%\n",
      "294\tValidation loss: 0.388472\tBest loss: 0.388472\tAccuracy: 92.00%\n",
      "295\tValidation loss: 0.391353\tBest loss: 0.388472\tAccuracy: 91.60%\n",
      "296\tValidation loss: 0.392089\tBest loss: 0.388472\tAccuracy: 91.50%\n",
      "297\tValidation loss: 0.389020\tBest loss: 0.388472\tAccuracy: 91.50%\n",
      "298\tValidation loss: 0.391127\tBest loss: 0.388472\tAccuracy: 91.40%\n",
      "299\tValidation loss: 0.389872\tBest loss: 0.388472\tAccuracy: 91.30%\n",
      "300\tValidation loss: 0.392257\tBest loss: 0.388472\tAccuracy: 91.50%\n",
      "301\tValidation loss: 0.390521\tBest loss: 0.388472\tAccuracy: 91.50%\n",
      "302\tValidation loss: 0.388823\tBest loss: 0.388472\tAccuracy: 91.70%\n",
      "303\tValidation loss: 0.389688\tBest loss: 0.388472\tAccuracy: 91.80%\n",
      "304\tValidation loss: 0.388222\tBest loss: 0.388222\tAccuracy: 91.60%\n",
      "305\tValidation loss: 0.387885\tBest loss: 0.387885\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\tValidation loss: 0.389868\tBest loss: 0.387885\tAccuracy: 91.80%\n",
      "307\tValidation loss: 0.391314\tBest loss: 0.387885\tAccuracy: 91.60%\n",
      "308\tValidation loss: 0.389536\tBest loss: 0.387885\tAccuracy: 91.60%\n",
      "309\tValidation loss: 0.390985\tBest loss: 0.387885\tAccuracy: 91.50%\n",
      "310\tValidation loss: 0.388276\tBest loss: 0.387885\tAccuracy: 91.80%\n",
      "311\tValidation loss: 0.389532\tBest loss: 0.387885\tAccuracy: 91.80%\n",
      "312\tValidation loss: 0.390998\tBest loss: 0.387885\tAccuracy: 91.60%\n",
      "313\tValidation loss: 0.390099\tBest loss: 0.387885\tAccuracy: 91.80%\n",
      "314\tValidation loss: 0.390750\tBest loss: 0.387885\tAccuracy: 92.00%\n",
      "315\tValidation loss: 0.388609\tBest loss: 0.387885\tAccuracy: 91.90%\n",
      "316\tValidation loss: 0.390937\tBest loss: 0.387885\tAccuracy: 91.80%\n",
      "317\tValidation loss: 0.388790\tBest loss: 0.387885\tAccuracy: 91.40%\n",
      "318\tValidation loss: 0.387819\tBest loss: 0.387819\tAccuracy: 91.70%\n",
      "319\tValidation loss: 0.390097\tBest loss: 0.387819\tAccuracy: 91.50%\n",
      "320\tValidation loss: 0.388267\tBest loss: 0.387819\tAccuracy: 91.70%\n",
      "321\tValidation loss: 0.389455\tBest loss: 0.387819\tAccuracy: 91.60%\n",
      "322\tValidation loss: 0.390688\tBest loss: 0.387819\tAccuracy: 91.60%\n",
      "323\tValidation loss: 0.389039\tBest loss: 0.387819\tAccuracy: 91.90%\n",
      "324\tValidation loss: 0.389522\tBest loss: 0.387819\tAccuracy: 91.70%\n",
      "325\tValidation loss: 0.389901\tBest loss: 0.387819\tAccuracy: 91.60%\n",
      "326\tValidation loss: 0.388482\tBest loss: 0.387819\tAccuracy: 91.90%\n",
      "327\tValidation loss: 0.388321\tBest loss: 0.387819\tAccuracy: 92.00%\n",
      "328\tValidation loss: 0.388767\tBest loss: 0.387819\tAccuracy: 91.80%\n",
      "329\tValidation loss: 0.387211\tBest loss: 0.387211\tAccuracy: 92.20%\n",
      "330\tValidation loss: 0.389644\tBest loss: 0.387211\tAccuracy: 91.70%\n",
      "331\tValidation loss: 0.386940\tBest loss: 0.386940\tAccuracy: 91.90%\n",
      "332\tValidation loss: 0.387896\tBest loss: 0.386940\tAccuracy: 91.60%\n",
      "333\tValidation loss: 0.384727\tBest loss: 0.384727\tAccuracy: 91.90%\n",
      "334\tValidation loss: 0.386860\tBest loss: 0.384727\tAccuracy: 92.00%\n",
      "335\tValidation loss: 0.387607\tBest loss: 0.384727\tAccuracy: 91.60%\n",
      "336\tValidation loss: 0.386710\tBest loss: 0.384727\tAccuracy: 91.90%\n",
      "337\tValidation loss: 0.388217\tBest loss: 0.384727\tAccuracy: 91.60%\n",
      "338\tValidation loss: 0.386835\tBest loss: 0.384727\tAccuracy: 91.90%\n",
      "339\tValidation loss: 0.385631\tBest loss: 0.384727\tAccuracy: 92.00%\n",
      "340\tValidation loss: 0.386196\tBest loss: 0.384727\tAccuracy: 91.80%\n",
      "341\tValidation loss: 0.387715\tBest loss: 0.384727\tAccuracy: 92.00%\n",
      "342\tValidation loss: 0.385803\tBest loss: 0.384727\tAccuracy: 91.90%\n",
      "343\tValidation loss: 0.389750\tBest loss: 0.384727\tAccuracy: 91.50%\n",
      "344\tValidation loss: 0.385538\tBest loss: 0.384727\tAccuracy: 91.90%\n",
      "345\tValidation loss: 0.385456\tBest loss: 0.384727\tAccuracy: 92.00%\n",
      "346\tValidation loss: 0.383540\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "347\tValidation loss: 0.387558\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "348\tValidation loss: 0.386425\tBest loss: 0.383540\tAccuracy: 91.60%\n",
      "349\tValidation loss: 0.387163\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "350\tValidation loss: 0.386169\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "351\tValidation loss: 0.390494\tBest loss: 0.383540\tAccuracy: 91.70%\n",
      "352\tValidation loss: 0.384615\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "353\tValidation loss: 0.386024\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "354\tValidation loss: 0.388956\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "355\tValidation loss: 0.387230\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "356\tValidation loss: 0.386280\tBest loss: 0.383540\tAccuracy: 91.60%\n",
      "357\tValidation loss: 0.385913\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "358\tValidation loss: 0.388003\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "359\tValidation loss: 0.383705\tBest loss: 0.383540\tAccuracy: 92.10%\n",
      "360\tValidation loss: 0.384231\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "361\tValidation loss: 0.387502\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "362\tValidation loss: 0.386937\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "363\tValidation loss: 0.387247\tBest loss: 0.383540\tAccuracy: 91.80%\n",
      "364\tValidation loss: 0.386891\tBest loss: 0.383540\tAccuracy: 92.10%\n",
      "365\tValidation loss: 0.387438\tBest loss: 0.383540\tAccuracy: 91.90%\n",
      "366\tValidation loss: 0.385312\tBest loss: 0.383540\tAccuracy: 91.70%\n",
      "367\tValidation loss: 0.386866\tBest loss: 0.383540\tAccuracy: 92.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  46.1s\n",
      "[CV] batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.268734\tBest loss: 2.268734\tAccuracy: 40.10%\n",
      "1\tValidation loss: 1.738014\tBest loss: 1.738014\tAccuracy: 58.30%\n",
      "2\tValidation loss: 1.488816\tBest loss: 1.488816\tAccuracy: 63.70%\n",
      "3\tValidation loss: 1.342185\tBest loss: 1.342185\tAccuracy: 68.50%\n",
      "4\tValidation loss: 1.218204\tBest loss: 1.218204\tAccuracy: 71.30%\n",
      "5\tValidation loss: 1.136832\tBest loss: 1.136832\tAccuracy: 73.10%\n",
      "6\tValidation loss: 1.073178\tBest loss: 1.073178\tAccuracy: 74.10%\n",
      "7\tValidation loss: 1.023736\tBest loss: 1.023736\tAccuracy: 74.80%\n",
      "8\tValidation loss: 0.986857\tBest loss: 0.986857\tAccuracy: 75.60%\n",
      "9\tValidation loss: 0.952940\tBest loss: 0.952940\tAccuracy: 76.00%\n",
      "10\tValidation loss: 0.912258\tBest loss: 0.912258\tAccuracy: 77.10%\n",
      "11\tValidation loss: 0.884864\tBest loss: 0.884864\tAccuracy: 78.10%\n",
      "12\tValidation loss: 0.858161\tBest loss: 0.858161\tAccuracy: 79.30%\n",
      "13\tValidation loss: 0.835238\tBest loss: 0.835238\tAccuracy: 78.90%\n",
      "14\tValidation loss: 0.814485\tBest loss: 0.814485\tAccuracy: 80.40%\n",
      "15\tValidation loss: 0.795825\tBest loss: 0.795825\tAccuracy: 80.30%\n",
      "16\tValidation loss: 0.790293\tBest loss: 0.790293\tAccuracy: 80.50%\n",
      "17\tValidation loss: 0.760016\tBest loss: 0.760016\tAccuracy: 81.70%\n",
      "18\tValidation loss: 0.757607\tBest loss: 0.757607\tAccuracy: 81.00%\n",
      "19\tValidation loss: 0.736929\tBest loss: 0.736929\tAccuracy: 82.00%\n",
      "20\tValidation loss: 0.730661\tBest loss: 0.730661\tAccuracy: 81.60%\n",
      "21\tValidation loss: 0.720891\tBest loss: 0.720891\tAccuracy: 82.30%\n",
      "22\tValidation loss: 0.702441\tBest loss: 0.702441\tAccuracy: 83.10%\n",
      "23\tValidation loss: 0.697257\tBest loss: 0.697257\tAccuracy: 82.40%\n",
      "24\tValidation loss: 0.691714\tBest loss: 0.691714\tAccuracy: 83.20%\n",
      "25\tValidation loss: 0.681164\tBest loss: 0.681164\tAccuracy: 84.00%\n",
      "26\tValidation loss: 0.672323\tBest loss: 0.672323\tAccuracy: 83.90%\n",
      "27\tValidation loss: 0.659428\tBest loss: 0.659428\tAccuracy: 83.90%\n",
      "28\tValidation loss: 0.657143\tBest loss: 0.657143\tAccuracy: 83.80%\n",
      "29\tValidation loss: 0.649834\tBest loss: 0.649834\tAccuracy: 83.50%\n",
      "30\tValidation loss: 0.640854\tBest loss: 0.640854\tAccuracy: 84.00%\n",
      "31\tValidation loss: 0.639498\tBest loss: 0.639498\tAccuracy: 84.90%\n",
      "32\tValidation loss: 0.631926\tBest loss: 0.631926\tAccuracy: 85.10%\n",
      "33\tValidation loss: 0.625115\tBest loss: 0.625115\tAccuracy: 85.00%\n",
      "34\tValidation loss: 0.619446\tBest loss: 0.619446\tAccuracy: 84.10%\n",
      "35\tValidation loss: 0.615500\tBest loss: 0.615500\tAccuracy: 85.80%\n",
      "36\tValidation loss: 0.615013\tBest loss: 0.615013\tAccuracy: 85.40%\n",
      "37\tValidation loss: 0.600850\tBest loss: 0.600850\tAccuracy: 85.70%\n",
      "38\tValidation loss: 0.593661\tBest loss: 0.593661\tAccuracy: 85.40%\n",
      "39\tValidation loss: 0.588767\tBest loss: 0.588767\tAccuracy: 85.70%\n",
      "40\tValidation loss: 0.587985\tBest loss: 0.587985\tAccuracy: 86.30%\n",
      "41\tValidation loss: 0.581063\tBest loss: 0.581063\tAccuracy: 85.80%\n",
      "42\tValidation loss: 0.580488\tBest loss: 0.580488\tAccuracy: 85.80%\n",
      "43\tValidation loss: 0.572577\tBest loss: 0.572577\tAccuracy: 86.70%\n",
      "44\tValidation loss: 0.566868\tBest loss: 0.566868\tAccuracy: 86.30%\n",
      "45\tValidation loss: 0.570793\tBest loss: 0.566868\tAccuracy: 86.30%\n",
      "46\tValidation loss: 0.566924\tBest loss: 0.566868\tAccuracy: 86.50%\n",
      "47\tValidation loss: 0.560087\tBest loss: 0.560087\tAccuracy: 86.60%\n",
      "48\tValidation loss: 0.554832\tBest loss: 0.554832\tAccuracy: 86.70%\n",
      "49\tValidation loss: 0.552256\tBest loss: 0.552256\tAccuracy: 87.00%\n",
      "50\tValidation loss: 0.550582\tBest loss: 0.550582\tAccuracy: 86.80%\n",
      "51\tValidation loss: 0.545760\tBest loss: 0.545760\tAccuracy: 86.40%\n",
      "52\tValidation loss: 0.544513\tBest loss: 0.544513\tAccuracy: 87.10%\n",
      "53\tValidation loss: 0.539504\tBest loss: 0.539504\tAccuracy: 87.20%\n",
      "54\tValidation loss: 0.534847\tBest loss: 0.534847\tAccuracy: 87.50%\n",
      "55\tValidation loss: 0.534231\tBest loss: 0.534231\tAccuracy: 86.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\tValidation loss: 0.533933\tBest loss: 0.533933\tAccuracy: 87.10%\n",
      "57\tValidation loss: 0.524281\tBest loss: 0.524281\tAccuracy: 88.10%\n",
      "58\tValidation loss: 0.524449\tBest loss: 0.524281\tAccuracy: 88.10%\n",
      "59\tValidation loss: 0.523035\tBest loss: 0.523035\tAccuracy: 87.90%\n",
      "60\tValidation loss: 0.522805\tBest loss: 0.522805\tAccuracy: 87.50%\n",
      "61\tValidation loss: 0.523932\tBest loss: 0.522805\tAccuracy: 87.50%\n",
      "62\tValidation loss: 0.519056\tBest loss: 0.519056\tAccuracy: 87.60%\n",
      "63\tValidation loss: 0.511946\tBest loss: 0.511946\tAccuracy: 87.50%\n",
      "64\tValidation loss: 0.509309\tBest loss: 0.509309\tAccuracy: 87.60%\n",
      "65\tValidation loss: 0.511014\tBest loss: 0.509309\tAccuracy: 88.00%\n",
      "66\tValidation loss: 0.504527\tBest loss: 0.504527\tAccuracy: 88.30%\n",
      "67\tValidation loss: 0.506683\tBest loss: 0.504527\tAccuracy: 88.20%\n",
      "68\tValidation loss: 0.498550\tBest loss: 0.498550\tAccuracy: 87.90%\n",
      "69\tValidation loss: 0.503575\tBest loss: 0.498550\tAccuracy: 88.40%\n",
      "70\tValidation loss: 0.498586\tBest loss: 0.498550\tAccuracy: 88.60%\n",
      "71\tValidation loss: 0.498503\tBest loss: 0.498503\tAccuracy: 88.50%\n",
      "72\tValidation loss: 0.496206\tBest loss: 0.496206\tAccuracy: 88.20%\n",
      "73\tValidation loss: 0.492034\tBest loss: 0.492034\tAccuracy: 88.70%\n",
      "74\tValidation loss: 0.492581\tBest loss: 0.492034\tAccuracy: 88.60%\n",
      "75\tValidation loss: 0.491148\tBest loss: 0.491148\tAccuracy: 88.20%\n",
      "76\tValidation loss: 0.492957\tBest loss: 0.491148\tAccuracy: 88.40%\n",
      "77\tValidation loss: 0.487522\tBest loss: 0.487522\tAccuracy: 88.50%\n",
      "78\tValidation loss: 0.480918\tBest loss: 0.480918\tAccuracy: 89.60%\n",
      "79\tValidation loss: 0.488201\tBest loss: 0.480918\tAccuracy: 88.60%\n",
      "80\tValidation loss: 0.478080\tBest loss: 0.478080\tAccuracy: 89.10%\n",
      "81\tValidation loss: 0.480957\tBest loss: 0.478080\tAccuracy: 88.80%\n",
      "82\tValidation loss: 0.476434\tBest loss: 0.476434\tAccuracy: 89.10%\n",
      "83\tValidation loss: 0.474800\tBest loss: 0.474800\tAccuracy: 89.70%\n",
      "84\tValidation loss: 0.473823\tBest loss: 0.473823\tAccuracy: 88.80%\n",
      "85\tValidation loss: 0.471205\tBest loss: 0.471205\tAccuracy: 89.60%\n",
      "86\tValidation loss: 0.469373\tBest loss: 0.469373\tAccuracy: 89.10%\n",
      "87\tValidation loss: 0.470540\tBest loss: 0.469373\tAccuracy: 89.60%\n",
      "88\tValidation loss: 0.464773\tBest loss: 0.464773\tAccuracy: 89.10%\n",
      "89\tValidation loss: 0.465618\tBest loss: 0.464773\tAccuracy: 89.80%\n",
      "90\tValidation loss: 0.462858\tBest loss: 0.462858\tAccuracy: 89.90%\n",
      "91\tValidation loss: 0.460358\tBest loss: 0.460358\tAccuracy: 89.50%\n",
      "92\tValidation loss: 0.466046\tBest loss: 0.460358\tAccuracy: 89.40%\n",
      "93\tValidation loss: 0.457512\tBest loss: 0.457512\tAccuracy: 90.00%\n",
      "94\tValidation loss: 0.458591\tBest loss: 0.457512\tAccuracy: 89.90%\n",
      "95\tValidation loss: 0.453084\tBest loss: 0.453084\tAccuracy: 90.10%\n",
      "96\tValidation loss: 0.453215\tBest loss: 0.453084\tAccuracy: 90.40%\n",
      "97\tValidation loss: 0.458035\tBest loss: 0.453084\tAccuracy: 89.80%\n",
      "98\tValidation loss: 0.452076\tBest loss: 0.452076\tAccuracy: 90.10%\n",
      "99\tValidation loss: 0.450585\tBest loss: 0.450585\tAccuracy: 89.40%\n",
      "100\tValidation loss: 0.451408\tBest loss: 0.450585\tAccuracy: 90.10%\n",
      "101\tValidation loss: 0.450408\tBest loss: 0.450408\tAccuracy: 89.60%\n",
      "102\tValidation loss: 0.444900\tBest loss: 0.444900\tAccuracy: 89.90%\n",
      "103\tValidation loss: 0.445131\tBest loss: 0.444900\tAccuracy: 90.10%\n",
      "104\tValidation loss: 0.445874\tBest loss: 0.444900\tAccuracy: 89.80%\n",
      "105\tValidation loss: 0.450348\tBest loss: 0.444900\tAccuracy: 90.00%\n",
      "106\tValidation loss: 0.442490\tBest loss: 0.442490\tAccuracy: 90.10%\n",
      "107\tValidation loss: 0.442807\tBest loss: 0.442490\tAccuracy: 90.20%\n",
      "108\tValidation loss: 0.443262\tBest loss: 0.442490\tAccuracy: 89.90%\n",
      "109\tValidation loss: 0.438869\tBest loss: 0.438869\tAccuracy: 90.00%\n",
      "110\tValidation loss: 0.439442\tBest loss: 0.438869\tAccuracy: 90.30%\n",
      "111\tValidation loss: 0.440446\tBest loss: 0.438869\tAccuracy: 90.50%\n",
      "112\tValidation loss: 0.436705\tBest loss: 0.436705\tAccuracy: 89.90%\n",
      "113\tValidation loss: 0.436357\tBest loss: 0.436357\tAccuracy: 90.10%\n",
      "114\tValidation loss: 0.439309\tBest loss: 0.436357\tAccuracy: 90.00%\n",
      "115\tValidation loss: 0.432102\tBest loss: 0.432102\tAccuracy: 90.10%\n",
      "116\tValidation loss: 0.434010\tBest loss: 0.432102\tAccuracy: 90.20%\n",
      "117\tValidation loss: 0.433450\tBest loss: 0.432102\tAccuracy: 89.90%\n",
      "118\tValidation loss: 0.427078\tBest loss: 0.427078\tAccuracy: 90.30%\n",
      "119\tValidation loss: 0.427644\tBest loss: 0.427078\tAccuracy: 90.40%\n",
      "120\tValidation loss: 0.425022\tBest loss: 0.425022\tAccuracy: 90.20%\n",
      "121\tValidation loss: 0.426320\tBest loss: 0.425022\tAccuracy: 90.30%\n",
      "122\tValidation loss: 0.428381\tBest loss: 0.425022\tAccuracy: 90.00%\n",
      "123\tValidation loss: 0.427686\tBest loss: 0.425022\tAccuracy: 90.60%\n",
      "124\tValidation loss: 0.425630\tBest loss: 0.425022\tAccuracy: 90.00%\n",
      "125\tValidation loss: 0.424172\tBest loss: 0.424172\tAccuracy: 90.40%\n",
      "126\tValidation loss: 0.424431\tBest loss: 0.424172\tAccuracy: 90.50%\n",
      "127\tValidation loss: 0.421401\tBest loss: 0.421401\tAccuracy: 90.30%\n",
      "128\tValidation loss: 0.420156\tBest loss: 0.420156\tAccuracy: 90.50%\n",
      "129\tValidation loss: 0.418299\tBest loss: 0.418299\tAccuracy: 89.80%\n",
      "130\tValidation loss: 0.417825\tBest loss: 0.417825\tAccuracy: 90.50%\n",
      "131\tValidation loss: 0.419040\tBest loss: 0.417825\tAccuracy: 90.90%\n",
      "132\tValidation loss: 0.416498\tBest loss: 0.416498\tAccuracy: 90.40%\n",
      "133\tValidation loss: 0.421478\tBest loss: 0.416498\tAccuracy: 90.60%\n",
      "134\tValidation loss: 0.415978\tBest loss: 0.415978\tAccuracy: 90.80%\n",
      "135\tValidation loss: 0.416385\tBest loss: 0.415978\tAccuracy: 90.60%\n",
      "136\tValidation loss: 0.413542\tBest loss: 0.413542\tAccuracy: 90.50%\n",
      "137\tValidation loss: 0.412171\tBest loss: 0.412171\tAccuracy: 90.70%\n",
      "138\tValidation loss: 0.414662\tBest loss: 0.412171\tAccuracy: 90.50%\n",
      "139\tValidation loss: 0.409870\tBest loss: 0.409870\tAccuracy: 91.00%\n",
      "140\tValidation loss: 0.410660\tBest loss: 0.409870\tAccuracy: 90.30%\n",
      "141\tValidation loss: 0.407991\tBest loss: 0.407991\tAccuracy: 90.20%\n",
      "142\tValidation loss: 0.408409\tBest loss: 0.407991\tAccuracy: 91.00%\n",
      "143\tValidation loss: 0.409642\tBest loss: 0.407991\tAccuracy: 90.60%\n",
      "144\tValidation loss: 0.408261\tBest loss: 0.407991\tAccuracy: 91.20%\n",
      "145\tValidation loss: 0.405684\tBest loss: 0.405684\tAccuracy: 90.80%\n",
      "146\tValidation loss: 0.407488\tBest loss: 0.405684\tAccuracy: 90.40%\n",
      "147\tValidation loss: 0.408731\tBest loss: 0.405684\tAccuracy: 90.70%\n",
      "148\tValidation loss: 0.404549\tBest loss: 0.404549\tAccuracy: 91.10%\n",
      "149\tValidation loss: 0.403903\tBest loss: 0.403903\tAccuracy: 91.00%\n",
      "150\tValidation loss: 0.406824\tBest loss: 0.403903\tAccuracy: 90.40%\n",
      "151\tValidation loss: 0.400738\tBest loss: 0.400738\tAccuracy: 90.60%\n",
      "152\tValidation loss: 0.401688\tBest loss: 0.400738\tAccuracy: 91.10%\n",
      "153\tValidation loss: 0.400758\tBest loss: 0.400738\tAccuracy: 90.90%\n",
      "154\tValidation loss: 0.401766\tBest loss: 0.400738\tAccuracy: 90.70%\n",
      "155\tValidation loss: 0.402459\tBest loss: 0.400738\tAccuracy: 91.20%\n",
      "156\tValidation loss: 0.402077\tBest loss: 0.400738\tAccuracy: 91.20%\n",
      "157\tValidation loss: 0.401800\tBest loss: 0.400738\tAccuracy: 91.20%\n",
      "158\tValidation loss: 0.397989\tBest loss: 0.397989\tAccuracy: 91.10%\n",
      "159\tValidation loss: 0.395179\tBest loss: 0.395179\tAccuracy: 90.90%\n",
      "160\tValidation loss: 0.401191\tBest loss: 0.395179\tAccuracy: 91.10%\n",
      "161\tValidation loss: 0.395341\tBest loss: 0.395179\tAccuracy: 91.50%\n",
      "162\tValidation loss: 0.394310\tBest loss: 0.394310\tAccuracy: 91.20%\n",
      "163\tValidation loss: 0.393851\tBest loss: 0.393851\tAccuracy: 91.20%\n",
      "164\tValidation loss: 0.396772\tBest loss: 0.393851\tAccuracy: 91.10%\n",
      "165\tValidation loss: 0.394605\tBest loss: 0.393851\tAccuracy: 91.40%\n",
      "166\tValidation loss: 0.395674\tBest loss: 0.393851\tAccuracy: 90.80%\n",
      "167\tValidation loss: 0.390228\tBest loss: 0.390228\tAccuracy: 91.00%\n",
      "168\tValidation loss: 0.391943\tBest loss: 0.390228\tAccuracy: 91.20%\n",
      "169\tValidation loss: 0.392287\tBest loss: 0.390228\tAccuracy: 91.10%\n",
      "170\tValidation loss: 0.391987\tBest loss: 0.390228\tAccuracy: 91.00%\n",
      "171\tValidation loss: 0.391502\tBest loss: 0.390228\tAccuracy: 91.50%\n",
      "172\tValidation loss: 0.390653\tBest loss: 0.390228\tAccuracy: 91.20%\n",
      "173\tValidation loss: 0.388481\tBest loss: 0.388481\tAccuracy: 91.20%\n",
      "174\tValidation loss: 0.389172\tBest loss: 0.388481\tAccuracy: 91.10%\n",
      "175\tValidation loss: 0.387859\tBest loss: 0.387859\tAccuracy: 91.30%\n",
      "176\tValidation loss: 0.386713\tBest loss: 0.386713\tAccuracy: 91.10%\n",
      "177\tValidation loss: 0.386983\tBest loss: 0.386713\tAccuracy: 91.40%\n",
      "178\tValidation loss: 0.385320\tBest loss: 0.385320\tAccuracy: 91.10%\n",
      "179\tValidation loss: 0.387256\tBest loss: 0.385320\tAccuracy: 91.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\tValidation loss: 0.385526\tBest loss: 0.385320\tAccuracy: 91.20%\n",
      "181\tValidation loss: 0.384537\tBest loss: 0.384537\tAccuracy: 91.50%\n",
      "182\tValidation loss: 0.385325\tBest loss: 0.384537\tAccuracy: 91.30%\n",
      "183\tValidation loss: 0.383362\tBest loss: 0.383362\tAccuracy: 91.60%\n",
      "184\tValidation loss: 0.385467\tBest loss: 0.383362\tAccuracy: 91.90%\n",
      "185\tValidation loss: 0.382470\tBest loss: 0.382470\tAccuracy: 91.30%\n",
      "186\tValidation loss: 0.383617\tBest loss: 0.382470\tAccuracy: 91.30%\n",
      "187\tValidation loss: 0.379773\tBest loss: 0.379773\tAccuracy: 91.80%\n",
      "188\tValidation loss: 0.381356\tBest loss: 0.379773\tAccuracy: 91.50%\n",
      "189\tValidation loss: 0.381574\tBest loss: 0.379773\tAccuracy: 91.60%\n",
      "190\tValidation loss: 0.380178\tBest loss: 0.379773\tAccuracy: 91.50%\n",
      "191\tValidation loss: 0.378736\tBest loss: 0.378736\tAccuracy: 91.70%\n",
      "192\tValidation loss: 0.377388\tBest loss: 0.377388\tAccuracy: 91.50%\n",
      "193\tValidation loss: 0.379723\tBest loss: 0.377388\tAccuracy: 91.60%\n",
      "194\tValidation loss: 0.379988\tBest loss: 0.377388\tAccuracy: 91.40%\n",
      "195\tValidation loss: 0.378668\tBest loss: 0.377388\tAccuracy: 91.80%\n",
      "196\tValidation loss: 0.375133\tBest loss: 0.375133\tAccuracy: 91.40%\n",
      "197\tValidation loss: 0.375858\tBest loss: 0.375133\tAccuracy: 91.30%\n",
      "198\tValidation loss: 0.378923\tBest loss: 0.375133\tAccuracy: 91.70%\n",
      "199\tValidation loss: 0.377682\tBest loss: 0.375133\tAccuracy: 91.50%\n",
      "200\tValidation loss: 0.375021\tBest loss: 0.375021\tAccuracy: 91.90%\n",
      "201\tValidation loss: 0.376183\tBest loss: 0.375021\tAccuracy: 91.80%\n",
      "202\tValidation loss: 0.373630\tBest loss: 0.373630\tAccuracy: 92.20%\n",
      "203\tValidation loss: 0.373428\tBest loss: 0.373428\tAccuracy: 91.50%\n",
      "204\tValidation loss: 0.373731\tBest loss: 0.373428\tAccuracy: 91.70%\n",
      "205\tValidation loss: 0.372901\tBest loss: 0.372901\tAccuracy: 91.50%\n",
      "206\tValidation loss: 0.372399\tBest loss: 0.372399\tAccuracy: 91.80%\n",
      "207\tValidation loss: 0.374307\tBest loss: 0.372399\tAccuracy: 91.90%\n",
      "208\tValidation loss: 0.371883\tBest loss: 0.371883\tAccuracy: 91.80%\n",
      "209\tValidation loss: 0.372558\tBest loss: 0.371883\tAccuracy: 91.90%\n",
      "210\tValidation loss: 0.373936\tBest loss: 0.371883\tAccuracy: 91.80%\n",
      "211\tValidation loss: 0.370385\tBest loss: 0.370385\tAccuracy: 91.70%\n",
      "212\tValidation loss: 0.371058\tBest loss: 0.370385\tAccuracy: 91.90%\n",
      "213\tValidation loss: 0.371251\tBest loss: 0.370385\tAccuracy: 92.00%\n",
      "214\tValidation loss: 0.369120\tBest loss: 0.369120\tAccuracy: 91.60%\n",
      "215\tValidation loss: 0.371273\tBest loss: 0.369120\tAccuracy: 91.80%\n",
      "216\tValidation loss: 0.368783\tBest loss: 0.368783\tAccuracy: 91.90%\n",
      "217\tValidation loss: 0.369184\tBest loss: 0.368783\tAccuracy: 92.10%\n",
      "218\tValidation loss: 0.367092\tBest loss: 0.367092\tAccuracy: 91.80%\n",
      "219\tValidation loss: 0.369240\tBest loss: 0.367092\tAccuracy: 91.90%\n",
      "220\tValidation loss: 0.366387\tBest loss: 0.366387\tAccuracy: 91.90%\n",
      "221\tValidation loss: 0.369229\tBest loss: 0.366387\tAccuracy: 92.10%\n",
      "222\tValidation loss: 0.369224\tBest loss: 0.366387\tAccuracy: 92.00%\n",
      "223\tValidation loss: 0.367208\tBest loss: 0.366387\tAccuracy: 91.70%\n",
      "224\tValidation loss: 0.367866\tBest loss: 0.366387\tAccuracy: 92.10%\n",
      "225\tValidation loss: 0.366343\tBest loss: 0.366343\tAccuracy: 92.00%\n",
      "226\tValidation loss: 0.364933\tBest loss: 0.364933\tAccuracy: 91.80%\n",
      "227\tValidation loss: 0.363517\tBest loss: 0.363517\tAccuracy: 92.20%\n",
      "228\tValidation loss: 0.362840\tBest loss: 0.362840\tAccuracy: 92.00%\n",
      "229\tValidation loss: 0.364209\tBest loss: 0.362840\tAccuracy: 91.70%\n",
      "230\tValidation loss: 0.363448\tBest loss: 0.362840\tAccuracy: 91.90%\n",
      "231\tValidation loss: 0.362154\tBest loss: 0.362154\tAccuracy: 92.00%\n",
      "232\tValidation loss: 0.362792\tBest loss: 0.362154\tAccuracy: 92.20%\n",
      "233\tValidation loss: 0.361042\tBest loss: 0.361042\tAccuracy: 92.10%\n",
      "234\tValidation loss: 0.364067\tBest loss: 0.361042\tAccuracy: 92.10%\n",
      "235\tValidation loss: 0.363851\tBest loss: 0.361042\tAccuracy: 91.80%\n",
      "236\tValidation loss: 0.362461\tBest loss: 0.361042\tAccuracy: 92.20%\n",
      "237\tValidation loss: 0.363255\tBest loss: 0.361042\tAccuracy: 92.30%\n",
      "238\tValidation loss: 0.362749\tBest loss: 0.361042\tAccuracy: 92.10%\n",
      "239\tValidation loss: 0.360955\tBest loss: 0.360955\tAccuracy: 92.10%\n",
      "240\tValidation loss: 0.360855\tBest loss: 0.360855\tAccuracy: 92.20%\n",
      "241\tValidation loss: 0.362914\tBest loss: 0.360855\tAccuracy: 92.00%\n",
      "242\tValidation loss: 0.359190\tBest loss: 0.359190\tAccuracy: 92.10%\n",
      "243\tValidation loss: 0.358915\tBest loss: 0.358915\tAccuracy: 92.40%\n",
      "244\tValidation loss: 0.361286\tBest loss: 0.358915\tAccuracy: 92.20%\n",
      "245\tValidation loss: 0.359448\tBest loss: 0.358915\tAccuracy: 92.10%\n",
      "246\tValidation loss: 0.360775\tBest loss: 0.358915\tAccuracy: 92.40%\n",
      "247\tValidation loss: 0.356928\tBest loss: 0.356928\tAccuracy: 92.30%\n",
      "248\tValidation loss: 0.357162\tBest loss: 0.356928\tAccuracy: 92.00%\n",
      "249\tValidation loss: 0.357264\tBest loss: 0.356928\tAccuracy: 92.30%\n",
      "250\tValidation loss: 0.357057\tBest loss: 0.356928\tAccuracy: 92.40%\n",
      "251\tValidation loss: 0.357654\tBest loss: 0.356928\tAccuracy: 92.10%\n",
      "252\tValidation loss: 0.355827\tBest loss: 0.355827\tAccuracy: 92.30%\n",
      "253\tValidation loss: 0.355772\tBest loss: 0.355772\tAccuracy: 92.30%\n",
      "254\tValidation loss: 0.355951\tBest loss: 0.355772\tAccuracy: 92.40%\n",
      "255\tValidation loss: 0.356668\tBest loss: 0.355772\tAccuracy: 92.10%\n",
      "256\tValidation loss: 0.354130\tBest loss: 0.354130\tAccuracy: 92.40%\n",
      "257\tValidation loss: 0.358505\tBest loss: 0.354130\tAccuracy: 91.90%\n",
      "258\tValidation loss: 0.355918\tBest loss: 0.354130\tAccuracy: 92.40%\n",
      "259\tValidation loss: 0.358010\tBest loss: 0.354130\tAccuracy: 92.40%\n",
      "260\tValidation loss: 0.354132\tBest loss: 0.354130\tAccuracy: 92.30%\n",
      "261\tValidation loss: 0.354287\tBest loss: 0.354130\tAccuracy: 92.40%\n",
      "262\tValidation loss: 0.354549\tBest loss: 0.354130\tAccuracy: 92.30%\n",
      "263\tValidation loss: 0.351502\tBest loss: 0.351502\tAccuracy: 92.30%\n",
      "264\tValidation loss: 0.352943\tBest loss: 0.351502\tAccuracy: 92.50%\n",
      "265\tValidation loss: 0.352426\tBest loss: 0.351502\tAccuracy: 92.30%\n",
      "266\tValidation loss: 0.351570\tBest loss: 0.351502\tAccuracy: 92.20%\n",
      "267\tValidation loss: 0.351403\tBest loss: 0.351403\tAccuracy: 92.50%\n",
      "268\tValidation loss: 0.352891\tBest loss: 0.351403\tAccuracy: 92.40%\n",
      "269\tValidation loss: 0.351228\tBest loss: 0.351228\tAccuracy: 92.40%\n",
      "270\tValidation loss: 0.352603\tBest loss: 0.351228\tAccuracy: 92.20%\n",
      "271\tValidation loss: 0.351298\tBest loss: 0.351228\tAccuracy: 92.40%\n",
      "272\tValidation loss: 0.350400\tBest loss: 0.350400\tAccuracy: 92.50%\n",
      "273\tValidation loss: 0.351516\tBest loss: 0.350400\tAccuracy: 92.40%\n",
      "274\tValidation loss: 0.349730\tBest loss: 0.349730\tAccuracy: 92.40%\n",
      "275\tValidation loss: 0.351312\tBest loss: 0.349730\tAccuracy: 92.00%\n",
      "276\tValidation loss: 0.352151\tBest loss: 0.349730\tAccuracy: 92.40%\n",
      "277\tValidation loss: 0.349886\tBest loss: 0.349730\tAccuracy: 92.40%\n",
      "278\tValidation loss: 0.349930\tBest loss: 0.349730\tAccuracy: 92.60%\n",
      "279\tValidation loss: 0.350613\tBest loss: 0.349730\tAccuracy: 92.20%\n",
      "280\tValidation loss: 0.348961\tBest loss: 0.348961\tAccuracy: 92.50%\n",
      "281\tValidation loss: 0.349796\tBest loss: 0.348961\tAccuracy: 92.20%\n",
      "282\tValidation loss: 0.349457\tBest loss: 0.348961\tAccuracy: 92.20%\n",
      "283\tValidation loss: 0.347954\tBest loss: 0.347954\tAccuracy: 92.50%\n",
      "284\tValidation loss: 0.348186\tBest loss: 0.347954\tAccuracy: 92.40%\n",
      "285\tValidation loss: 0.347307\tBest loss: 0.347307\tAccuracy: 92.30%\n",
      "286\tValidation loss: 0.346649\tBest loss: 0.346649\tAccuracy: 92.20%\n",
      "287\tValidation loss: 0.347732\tBest loss: 0.346649\tAccuracy: 92.40%\n",
      "288\tValidation loss: 0.345993\tBest loss: 0.345993\tAccuracy: 92.60%\n",
      "289\tValidation loss: 0.347792\tBest loss: 0.345993\tAccuracy: 92.30%\n",
      "290\tValidation loss: 0.345691\tBest loss: 0.345691\tAccuracy: 92.50%\n",
      "291\tValidation loss: 0.346863\tBest loss: 0.345691\tAccuracy: 92.60%\n",
      "292\tValidation loss: 0.346459\tBest loss: 0.345691\tAccuracy: 92.60%\n",
      "293\tValidation loss: 0.347222\tBest loss: 0.345691\tAccuracy: 92.50%\n",
      "294\tValidation loss: 0.345965\tBest loss: 0.345691\tAccuracy: 92.50%\n",
      "295\tValidation loss: 0.346549\tBest loss: 0.345691\tAccuracy: 92.40%\n",
      "296\tValidation loss: 0.345667\tBest loss: 0.345667\tAccuracy: 92.40%\n",
      "297\tValidation loss: 0.344194\tBest loss: 0.344194\tAccuracy: 92.60%\n",
      "298\tValidation loss: 0.345908\tBest loss: 0.344194\tAccuracy: 92.30%\n",
      "299\tValidation loss: 0.345563\tBest loss: 0.344194\tAccuracy: 92.60%\n",
      "300\tValidation loss: 0.344345\tBest loss: 0.344194\tAccuracy: 92.50%\n",
      "301\tValidation loss: 0.343025\tBest loss: 0.343025\tAccuracy: 92.60%\n",
      "302\tValidation loss: 0.347237\tBest loss: 0.343025\tAccuracy: 92.40%\n",
      "303\tValidation loss: 0.345859\tBest loss: 0.343025\tAccuracy: 92.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\tValidation loss: 0.342965\tBest loss: 0.342965\tAccuracy: 92.50%\n",
      "305\tValidation loss: 0.342318\tBest loss: 0.342318\tAccuracy: 92.60%\n",
      "306\tValidation loss: 0.344487\tBest loss: 0.342318\tAccuracy: 92.70%\n",
      "307\tValidation loss: 0.342034\tBest loss: 0.342034\tAccuracy: 92.70%\n",
      "308\tValidation loss: 0.342693\tBest loss: 0.342034\tAccuracy: 92.60%\n",
      "309\tValidation loss: 0.341283\tBest loss: 0.341283\tAccuracy: 92.80%\n",
      "310\tValidation loss: 0.341368\tBest loss: 0.341283\tAccuracy: 92.70%\n",
      "311\tValidation loss: 0.343452\tBest loss: 0.341283\tAccuracy: 92.70%\n",
      "312\tValidation loss: 0.342168\tBest loss: 0.341283\tAccuracy: 92.90%\n",
      "313\tValidation loss: 0.343278\tBest loss: 0.341283\tAccuracy: 92.80%\n",
      "314\tValidation loss: 0.340718\tBest loss: 0.340718\tAccuracy: 92.70%\n",
      "315\tValidation loss: 0.342481\tBest loss: 0.340718\tAccuracy: 92.70%\n",
      "316\tValidation loss: 0.343662\tBest loss: 0.340718\tAccuracy: 92.70%\n",
      "317\tValidation loss: 0.342630\tBest loss: 0.340718\tAccuracy: 92.50%\n",
      "318\tValidation loss: 0.340821\tBest loss: 0.340718\tAccuracy: 92.80%\n",
      "319\tValidation loss: 0.340638\tBest loss: 0.340638\tAccuracy: 92.80%\n",
      "320\tValidation loss: 0.338820\tBest loss: 0.338820\tAccuracy: 92.70%\n",
      "321\tValidation loss: 0.340001\tBest loss: 0.338820\tAccuracy: 92.80%\n",
      "322\tValidation loss: 0.340008\tBest loss: 0.338820\tAccuracy: 92.80%\n",
      "323\tValidation loss: 0.341394\tBest loss: 0.338820\tAccuracy: 92.80%\n",
      "324\tValidation loss: 0.339756\tBest loss: 0.338820\tAccuracy: 92.90%\n",
      "325\tValidation loss: 0.341116\tBest loss: 0.338820\tAccuracy: 92.80%\n",
      "326\tValidation loss: 0.339449\tBest loss: 0.338820\tAccuracy: 92.90%\n",
      "327\tValidation loss: 0.339277\tBest loss: 0.338820\tAccuracy: 92.80%\n",
      "328\tValidation loss: 0.339047\tBest loss: 0.338820\tAccuracy: 92.90%\n",
      "329\tValidation loss: 0.341431\tBest loss: 0.338820\tAccuracy: 93.00%\n",
      "330\tValidation loss: 0.339100\tBest loss: 0.338820\tAccuracy: 92.90%\n",
      "331\tValidation loss: 0.338961\tBest loss: 0.338820\tAccuracy: 92.90%\n",
      "332\tValidation loss: 0.338470\tBest loss: 0.338470\tAccuracy: 93.10%\n",
      "333\tValidation loss: 0.337413\tBest loss: 0.337413\tAccuracy: 92.90%\n",
      "334\tValidation loss: 0.339110\tBest loss: 0.337413\tAccuracy: 92.70%\n",
      "335\tValidation loss: 0.337145\tBest loss: 0.337145\tAccuracy: 92.80%\n",
      "336\tValidation loss: 0.335527\tBest loss: 0.335527\tAccuracy: 92.80%\n",
      "337\tValidation loss: 0.337735\tBest loss: 0.335527\tAccuracy: 92.70%\n",
      "338\tValidation loss: 0.335612\tBest loss: 0.335527\tAccuracy: 93.00%\n",
      "339\tValidation loss: 0.337391\tBest loss: 0.335527\tAccuracy: 92.90%\n",
      "340\tValidation loss: 0.338571\tBest loss: 0.335527\tAccuracy: 93.00%\n",
      "341\tValidation loss: 0.336320\tBest loss: 0.335527\tAccuracy: 92.90%\n",
      "342\tValidation loss: 0.336825\tBest loss: 0.335527\tAccuracy: 93.10%\n",
      "343\tValidation loss: 0.334058\tBest loss: 0.334058\tAccuracy: 92.80%\n",
      "344\tValidation loss: 0.336012\tBest loss: 0.334058\tAccuracy: 93.00%\n",
      "345\tValidation loss: 0.337195\tBest loss: 0.334058\tAccuracy: 93.10%\n",
      "346\tValidation loss: 0.336399\tBest loss: 0.334058\tAccuracy: 92.90%\n",
      "347\tValidation loss: 0.336969\tBest loss: 0.334058\tAccuracy: 93.10%\n",
      "348\tValidation loss: 0.335252\tBest loss: 0.334058\tAccuracy: 93.10%\n",
      "349\tValidation loss: 0.336503\tBest loss: 0.334058\tAccuracy: 92.90%\n",
      "350\tValidation loss: 0.336980\tBest loss: 0.334058\tAccuracy: 93.00%\n",
      "351\tValidation loss: 0.334589\tBest loss: 0.334058\tAccuracy: 93.10%\n",
      "352\tValidation loss: 0.334768\tBest loss: 0.334058\tAccuracy: 92.90%\n",
      "353\tValidation loss: 0.336466\tBest loss: 0.334058\tAccuracy: 92.80%\n",
      "354\tValidation loss: 0.335893\tBest loss: 0.334058\tAccuracy: 92.80%\n",
      "355\tValidation loss: 0.332669\tBest loss: 0.332669\tAccuracy: 92.70%\n",
      "356\tValidation loss: 0.334348\tBest loss: 0.332669\tAccuracy: 92.80%\n",
      "357\tValidation loss: 0.334612\tBest loss: 0.332669\tAccuracy: 92.90%\n",
      "358\tValidation loss: 0.333880\tBest loss: 0.332669\tAccuracy: 92.80%\n",
      "359\tValidation loss: 0.332705\tBest loss: 0.332669\tAccuracy: 93.00%\n",
      "360\tValidation loss: 0.333711\tBest loss: 0.332669\tAccuracy: 93.10%\n",
      "361\tValidation loss: 0.334318\tBest loss: 0.332669\tAccuracy: 92.90%\n",
      "362\tValidation loss: 0.334765\tBest loss: 0.332669\tAccuracy: 92.70%\n",
      "363\tValidation loss: 0.333218\tBest loss: 0.332669\tAccuracy: 93.00%\n",
      "364\tValidation loss: 0.332973\tBest loss: 0.332669\tAccuracy: 93.00%\n",
      "365\tValidation loss: 0.333806\tBest loss: 0.332669\tAccuracy: 93.20%\n",
      "366\tValidation loss: 0.333248\tBest loss: 0.332669\tAccuracy: 92.80%\n",
      "367\tValidation loss: 0.332761\tBest loss: 0.332669\tAccuracy: 92.90%\n",
      "368\tValidation loss: 0.332783\tBest loss: 0.332669\tAccuracy: 92.90%\n",
      "369\tValidation loss: 0.331412\tBest loss: 0.331412\tAccuracy: 92.90%\n",
      "370\tValidation loss: 0.332409\tBest loss: 0.331412\tAccuracy: 93.00%\n",
      "371\tValidation loss: 0.333870\tBest loss: 0.331412\tAccuracy: 92.90%\n",
      "372\tValidation loss: 0.331998\tBest loss: 0.331412\tAccuracy: 93.00%\n",
      "373\tValidation loss: 0.332110\tBest loss: 0.331412\tAccuracy: 92.90%\n",
      "374\tValidation loss: 0.333100\tBest loss: 0.331412\tAccuracy: 92.90%\n",
      "375\tValidation loss: 0.331897\tBest loss: 0.331412\tAccuracy: 93.00%\n",
      "376\tValidation loss: 0.330962\tBest loss: 0.330962\tAccuracy: 93.00%\n",
      "377\tValidation loss: 0.330391\tBest loss: 0.330391\tAccuracy: 92.90%\n",
      "378\tValidation loss: 0.330475\tBest loss: 0.330391\tAccuracy: 93.10%\n",
      "379\tValidation loss: 0.331656\tBest loss: 0.330391\tAccuracy: 92.80%\n",
      "380\tValidation loss: 0.331941\tBest loss: 0.330391\tAccuracy: 93.10%\n",
      "381\tValidation loss: 0.331159\tBest loss: 0.330391\tAccuracy: 93.20%\n",
      "382\tValidation loss: 0.331193\tBest loss: 0.330391\tAccuracy: 92.90%\n",
      "383\tValidation loss: 0.330103\tBest loss: 0.330103\tAccuracy: 93.20%\n",
      "384\tValidation loss: 0.330359\tBest loss: 0.330103\tAccuracy: 93.00%\n",
      "385\tValidation loss: 0.330673\tBest loss: 0.330103\tAccuracy: 92.90%\n",
      "386\tValidation loss: 0.330399\tBest loss: 0.330103\tAccuracy: 92.90%\n",
      "387\tValidation loss: 0.329303\tBest loss: 0.329303\tAccuracy: 92.90%\n",
      "388\tValidation loss: 0.328002\tBest loss: 0.328002\tAccuracy: 92.90%\n",
      "389\tValidation loss: 0.329802\tBest loss: 0.328002\tAccuracy: 93.20%\n",
      "390\tValidation loss: 0.331539\tBest loss: 0.328002\tAccuracy: 92.90%\n",
      "391\tValidation loss: 0.329627\tBest loss: 0.328002\tAccuracy: 93.10%\n",
      "392\tValidation loss: 0.329168\tBest loss: 0.328002\tAccuracy: 92.90%\n",
      "393\tValidation loss: 0.330848\tBest loss: 0.328002\tAccuracy: 92.90%\n",
      "394\tValidation loss: 0.329288\tBest loss: 0.328002\tAccuracy: 93.10%\n",
      "395\tValidation loss: 0.327754\tBest loss: 0.327754\tAccuracy: 93.00%\n",
      "396\tValidation loss: 0.330198\tBest loss: 0.327754\tAccuracy: 93.10%\n",
      "397\tValidation loss: 0.329716\tBest loss: 0.327754\tAccuracy: 93.00%\n",
      "398\tValidation loss: 0.327736\tBest loss: 0.327736\tAccuracy: 93.30%\n",
      "399\tValidation loss: 0.328644\tBest loss: 0.327736\tAccuracy: 92.90%\n",
      "400\tValidation loss: 0.329145\tBest loss: 0.327736\tAccuracy: 93.00%\n",
      "401\tValidation loss: 0.327810\tBest loss: 0.327736\tAccuracy: 93.20%\n",
      "402\tValidation loss: 0.326548\tBest loss: 0.326548\tAccuracy: 93.20%\n",
      "403\tValidation loss: 0.328405\tBest loss: 0.326548\tAccuracy: 93.00%\n",
      "404\tValidation loss: 0.328236\tBest loss: 0.326548\tAccuracy: 93.00%\n",
      "405\tValidation loss: 0.326225\tBest loss: 0.326225\tAccuracy: 93.10%\n",
      "406\tValidation loss: 0.327699\tBest loss: 0.326225\tAccuracy: 93.10%\n",
      "407\tValidation loss: 0.327707\tBest loss: 0.326225\tAccuracy: 92.90%\n",
      "408\tValidation loss: 0.328254\tBest loss: 0.326225\tAccuracy: 93.10%\n",
      "409\tValidation loss: 0.325695\tBest loss: 0.325695\tAccuracy: 93.20%\n",
      "410\tValidation loss: 0.328191\tBest loss: 0.325695\tAccuracy: 92.90%\n",
      "411\tValidation loss: 0.325637\tBest loss: 0.325637\tAccuracy: 93.30%\n",
      "412\tValidation loss: 0.325474\tBest loss: 0.325474\tAccuracy: 93.00%\n",
      "413\tValidation loss: 0.326860\tBest loss: 0.325474\tAccuracy: 93.20%\n",
      "414\tValidation loss: 0.325740\tBest loss: 0.325474\tAccuracy: 93.30%\n",
      "415\tValidation loss: 0.325347\tBest loss: 0.325347\tAccuracy: 93.30%\n",
      "416\tValidation loss: 0.323524\tBest loss: 0.323524\tAccuracy: 93.10%\n",
      "417\tValidation loss: 0.326193\tBest loss: 0.323524\tAccuracy: 93.10%\n",
      "418\tValidation loss: 0.326614\tBest loss: 0.323524\tAccuracy: 93.00%\n",
      "419\tValidation loss: 0.326279\tBest loss: 0.323524\tAccuracy: 93.00%\n",
      "420\tValidation loss: 0.324569\tBest loss: 0.323524\tAccuracy: 93.10%\n",
      "421\tValidation loss: 0.325023\tBest loss: 0.323524\tAccuracy: 93.10%\n",
      "422\tValidation loss: 0.327005\tBest loss: 0.323524\tAccuracy: 93.00%\n",
      "423\tValidation loss: 0.325491\tBest loss: 0.323524\tAccuracy: 93.10%\n",
      "424\tValidation loss: 0.324159\tBest loss: 0.323524\tAccuracy: 93.30%\n",
      "425\tValidation loss: 0.324674\tBest loss: 0.323524\tAccuracy: 93.20%\n",
      "426\tValidation loss: 0.324702\tBest loss: 0.323524\tAccuracy: 93.40%\n",
      "427\tValidation loss: 0.326163\tBest loss: 0.323524\tAccuracy: 93.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\tValidation loss: 0.323726\tBest loss: 0.323524\tAccuracy: 93.20%\n",
      "429\tValidation loss: 0.325124\tBest loss: 0.323524\tAccuracy: 93.30%\n",
      "430\tValidation loss: 0.324531\tBest loss: 0.323524\tAccuracy: 93.40%\n",
      "431\tValidation loss: 0.325454\tBest loss: 0.323524\tAccuracy: 92.90%\n",
      "432\tValidation loss: 0.323866\tBest loss: 0.323524\tAccuracy: 93.40%\n",
      "433\tValidation loss: 0.324705\tBest loss: 0.323524\tAccuracy: 93.20%\n",
      "434\tValidation loss: 0.326635\tBest loss: 0.323524\tAccuracy: 93.30%\n",
      "435\tValidation loss: 0.323983\tBest loss: 0.323524\tAccuracy: 93.30%\n",
      "436\tValidation loss: 0.325322\tBest loss: 0.323524\tAccuracy: 93.20%\n",
      "437\tValidation loss: 0.324221\tBest loss: 0.323524\tAccuracy: 93.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=500, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  54.6s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 11.151111\tBest loss: 11.151111\tAccuracy: 11.80%\n",
      "1\tValidation loss: 14.820499\tBest loss: 11.151111\tAccuracy: 16.70%\n",
      "2\tValidation loss: 11.942443\tBest loss: 11.151111\tAccuracy: 35.10%\n",
      "3\tValidation loss: 5.771304\tBest loss: 5.771304\tAccuracy: 40.50%\n",
      "4\tValidation loss: 2.916956\tBest loss: 2.916956\tAccuracy: 65.70%\n",
      "5\tValidation loss: 7.827814\tBest loss: 2.916956\tAccuracy: 51.50%\n",
      "6\tValidation loss: 2.163239\tBest loss: 2.163239\tAccuracy: 71.90%\n",
      "7\tValidation loss: 5.821061\tBest loss: 2.163239\tAccuracy: 66.60%\n",
      "8\tValidation loss: 4.012374\tBest loss: 2.163239\tAccuracy: 68.90%\n",
      "9\tValidation loss: 4.753797\tBest loss: 2.163239\tAccuracy: 67.10%\n",
      "10\tValidation loss: 7.173876\tBest loss: 2.163239\tAccuracy: 68.30%\n",
      "11\tValidation loss: 2.722398\tBest loss: 2.163239\tAccuracy: 78.00%\n",
      "12\tValidation loss: 3.352150\tBest loss: 2.163239\tAccuracy: 77.70%\n",
      "13\tValidation loss: 1.873723\tBest loss: 1.873723\tAccuracy: 82.90%\n",
      "14\tValidation loss: 5.126959\tBest loss: 1.873723\tAccuracy: 75.30%\n",
      "15\tValidation loss: 4.323185\tBest loss: 1.873723\tAccuracy: 79.00%\n",
      "16\tValidation loss: 6.252764\tBest loss: 1.873723\tAccuracy: 75.40%\n",
      "17\tValidation loss: 3.130200\tBest loss: 1.873723\tAccuracy: 84.40%\n",
      "18\tValidation loss: 4.952086\tBest loss: 1.873723\tAccuracy: 82.40%\n",
      "19\tValidation loss: 4.008797\tBest loss: 1.873723\tAccuracy: 81.80%\n",
      "20\tValidation loss: 4.975924\tBest loss: 1.873723\tAccuracy: 80.10%\n",
      "21\tValidation loss: 4.451381\tBest loss: 1.873723\tAccuracy: 84.60%\n",
      "22\tValidation loss: 4.014992\tBest loss: 1.873723\tAccuracy: 83.60%\n",
      "23\tValidation loss: 2.650978\tBest loss: 1.873723\tAccuracy: 88.50%\n",
      "24\tValidation loss: 4.766715\tBest loss: 1.873723\tAccuracy: 85.80%\n",
      "25\tValidation loss: 4.675779\tBest loss: 1.873723\tAccuracy: 87.80%\n",
      "26\tValidation loss: 3.642314\tBest loss: 1.873723\tAccuracy: 88.30%\n",
      "27\tValidation loss: 3.537961\tBest loss: 1.873723\tAccuracy: 87.60%\n",
      "28\tValidation loss: 8.206467\tBest loss: 1.873723\tAccuracy: 85.40%\n",
      "29\tValidation loss: 5.124519\tBest loss: 1.873723\tAccuracy: 88.90%\n",
      "30\tValidation loss: 6.765536\tBest loss: 1.873723\tAccuracy: 85.40%\n",
      "31\tValidation loss: 4.369626\tBest loss: 1.873723\tAccuracy: 90.10%\n",
      "32\tValidation loss: 5.642417\tBest loss: 1.873723\tAccuracy: 88.80%\n",
      "33\tValidation loss: 6.249058\tBest loss: 1.873723\tAccuracy: 88.70%\n",
      "34\tValidation loss: 5.510966\tBest loss: 1.873723\tAccuracy: 89.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   6.7s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 9.174221\tBest loss: 9.174221\tAccuracy: 16.30%\n",
      "1\tValidation loss: 21.001963\tBest loss: 9.174221\tAccuracy: 12.50%\n",
      "2\tValidation loss: 15.377251\tBest loss: 9.174221\tAccuracy: 29.40%\n",
      "3\tValidation loss: 4.712029\tBest loss: 4.712029\tAccuracy: 50.50%\n",
      "4\tValidation loss: 3.852627\tBest loss: 3.852627\tAccuracy: 60.30%\n",
      "5\tValidation loss: 5.891132\tBest loss: 3.852627\tAccuracy: 61.30%\n",
      "6\tValidation loss: 4.477231\tBest loss: 3.852627\tAccuracy: 59.90%\n",
      "7\tValidation loss: 3.168852\tBest loss: 3.168852\tAccuracy: 68.10%\n",
      "8\tValidation loss: 3.456755\tBest loss: 3.168852\tAccuracy: 72.80%\n",
      "9\tValidation loss: 3.323443\tBest loss: 3.168852\tAccuracy: 73.40%\n",
      "10\tValidation loss: 2.991022\tBest loss: 2.991022\tAccuracy: 75.00%\n",
      "11\tValidation loss: 6.695876\tBest loss: 2.991022\tAccuracy: 69.80%\n",
      "12\tValidation loss: 2.972172\tBest loss: 2.972172\tAccuracy: 78.40%\n",
      "13\tValidation loss: 2.533252\tBest loss: 2.533252\tAccuracy: 83.70%\n",
      "14\tValidation loss: 5.053062\tBest loss: 2.533252\tAccuracy: 76.60%\n",
      "15\tValidation loss: 3.534184\tBest loss: 2.533252\tAccuracy: 78.90%\n",
      "16\tValidation loss: 3.230085\tBest loss: 2.533252\tAccuracy: 82.20%\n",
      "17\tValidation loss: 2.226659\tBest loss: 2.226659\tAccuracy: 86.90%\n",
      "18\tValidation loss: 2.822978\tBest loss: 2.226659\tAccuracy: 85.00%\n",
      "19\tValidation loss: 6.350484\tBest loss: 2.226659\tAccuracy: 80.20%\n",
      "20\tValidation loss: 3.448396\tBest loss: 2.226659\tAccuracy: 86.10%\n",
      "21\tValidation loss: 3.986253\tBest loss: 2.226659\tAccuracy: 84.60%\n",
      "22\tValidation loss: 3.222798\tBest loss: 2.226659\tAccuracy: 85.20%\n",
      "23\tValidation loss: 3.517379\tBest loss: 2.226659\tAccuracy: 86.00%\n",
      "24\tValidation loss: 4.140733\tBest loss: 2.226659\tAccuracy: 85.50%\n",
      "25\tValidation loss: 4.030959\tBest loss: 2.226659\tAccuracy: 86.20%\n",
      "26\tValidation loss: 7.215974\tBest loss: 2.226659\tAccuracy: 83.10%\n",
      "27\tValidation loss: 3.416953\tBest loss: 2.226659\tAccuracy: 89.50%\n",
      "28\tValidation loss: 9.681528\tBest loss: 2.226659\tAccuracy: 82.90%\n",
      "29\tValidation loss: 8.688221\tBest loss: 2.226659\tAccuracy: 83.90%\n",
      "30\tValidation loss: 6.806784\tBest loss: 2.226659\tAccuracy: 86.70%\n",
      "31\tValidation loss: 7.566253\tBest loss: 2.226659\tAccuracy: 84.40%\n",
      "32\tValidation loss: 6.203012\tBest loss: 2.226659\tAccuracy: 86.10%\n",
      "33\tValidation loss: 6.714805\tBest loss: 2.226659\tAccuracy: 88.40%\n",
      "34\tValidation loss: 7.920116\tBest loss: 2.226659\tAccuracy: 85.70%\n",
      "35\tValidation loss: 5.776344\tBest loss: 2.226659\tAccuracy: 88.90%\n",
      "36\tValidation loss: 9.956103\tBest loss: 2.226659\tAccuracy: 87.70%\n",
      "37\tValidation loss: 8.408981\tBest loss: 2.226659\tAccuracy: 88.20%\n",
      "38\tValidation loss: 7.604355\tBest loss: 2.226659\tAccuracy: 88.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   7.5s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 21.574171\tBest loss: 21.574171\tAccuracy: 9.20%\n",
      "1\tValidation loss: 12.538074\tBest loss: 12.538074\tAccuracy: 19.50%\n",
      "2\tValidation loss: 5.056708\tBest loss: 5.056708\tAccuracy: 42.80%\n",
      "3\tValidation loss: 4.832099\tBest loss: 4.832099\tAccuracy: 48.40%\n",
      "4\tValidation loss: 2.839494\tBest loss: 2.839494\tAccuracy: 64.10%\n",
      "5\tValidation loss: 3.271296\tBest loss: 2.839494\tAccuracy: 64.40%\n",
      "6\tValidation loss: 3.026337\tBest loss: 2.839494\tAccuracy: 70.50%\n",
      "7\tValidation loss: 3.881825\tBest loss: 2.839494\tAccuracy: 71.30%\n",
      "8\tValidation loss: 5.833570\tBest loss: 2.839494\tAccuracy: 66.70%\n",
      "9\tValidation loss: 5.019077\tBest loss: 2.839494\tAccuracy: 69.20%\n",
      "10\tValidation loss: 2.516496\tBest loss: 2.516496\tAccuracy: 79.00%\n",
      "11\tValidation loss: 4.110356\tBest loss: 2.516496\tAccuracy: 73.40%\n",
      "12\tValidation loss: 4.573723\tBest loss: 2.516496\tAccuracy: 76.70%\n",
      "13\tValidation loss: 2.684655\tBest loss: 2.516496\tAccuracy: 79.80%\n",
      "14\tValidation loss: 9.538584\tBest loss: 2.516496\tAccuracy: 71.70%\n",
      "15\tValidation loss: 4.557968\tBest loss: 2.516496\tAccuracy: 81.00%\n",
      "16\tValidation loss: 4.257035\tBest loss: 2.516496\tAccuracy: 80.40%\n",
      "17\tValidation loss: 7.598599\tBest loss: 2.516496\tAccuracy: 78.70%\n",
      "18\tValidation loss: 3.101363\tBest loss: 2.516496\tAccuracy: 83.20%\n",
      "19\tValidation loss: 9.430314\tBest loss: 2.516496\tAccuracy: 80.60%\n",
      "20\tValidation loss: 3.040083\tBest loss: 2.516496\tAccuracy: 84.60%\n",
      "21\tValidation loss: 4.204137\tBest loss: 2.516496\tAccuracy: 82.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tValidation loss: 3.683973\tBest loss: 2.516496\tAccuracy: 86.40%\n",
      "23\tValidation loss: 3.284904\tBest loss: 2.516496\tAccuracy: 87.20%\n",
      "24\tValidation loss: 3.005316\tBest loss: 2.516496\tAccuracy: 87.60%\n",
      "25\tValidation loss: 4.498080\tBest loss: 2.516496\tAccuracy: 84.80%\n",
      "26\tValidation loss: 4.392350\tBest loss: 2.516496\tAccuracy: 85.80%\n",
      "27\tValidation loss: 7.926300\tBest loss: 2.516496\tAccuracy: 85.90%\n",
      "28\tValidation loss: 4.689589\tBest loss: 2.516496\tAccuracy: 86.00%\n",
      "29\tValidation loss: 8.241378\tBest loss: 2.516496\tAccuracy: 83.20%\n",
      "30\tValidation loss: 9.150047\tBest loss: 2.516496\tAccuracy: 85.50%\n",
      "31\tValidation loss: 5.300123\tBest loss: 2.516496\tAccuracy: 89.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   6.1s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 62.993778\tBest loss: 62.993778\tAccuracy: 5.50%\n",
      "1\tValidation loss: 27.799049\tBest loss: 27.799049\tAccuracy: 22.10%\n",
      "2\tValidation loss: 10.855145\tBest loss: 10.855145\tAccuracy: 45.70%\n",
      "3\tValidation loss: 10.620149\tBest loss: 10.620149\tAccuracy: 48.90%\n",
      "4\tValidation loss: 7.782955\tBest loss: 7.782955\tAccuracy: 64.70%\n",
      "5\tValidation loss: 11.899562\tBest loss: 7.782955\tAccuracy: 60.90%\n",
      "6\tValidation loss: 5.024022\tBest loss: 5.024022\tAccuracy: 74.10%\n",
      "7\tValidation loss: 4.479489\tBest loss: 4.479489\tAccuracy: 76.80%\n",
      "8\tValidation loss: 9.838714\tBest loss: 4.479489\tAccuracy: 72.80%\n",
      "9\tValidation loss: 6.004326\tBest loss: 4.479489\tAccuracy: 79.20%\n",
      "10\tValidation loss: 16.599497\tBest loss: 4.479489\tAccuracy: 69.40%\n",
      "11\tValidation loss: 6.253269\tBest loss: 4.479489\tAccuracy: 80.20%\n",
      "12\tValidation loss: 9.218848\tBest loss: 4.479489\tAccuracy: 78.00%\n",
      "13\tValidation loss: 5.435054\tBest loss: 4.479489\tAccuracy: 82.40%\n",
      "14\tValidation loss: 7.411561\tBest loss: 4.479489\tAccuracy: 81.90%\n",
      "15\tValidation loss: 8.206755\tBest loss: 4.479489\tAccuracy: 80.60%\n",
      "16\tValidation loss: 6.080768\tBest loss: 4.479489\tAccuracy: 85.00%\n",
      "17\tValidation loss: 6.118667\tBest loss: 4.479489\tAccuracy: 85.90%\n",
      "18\tValidation loss: 5.180475\tBest loss: 4.479489\tAccuracy: 87.60%\n",
      "19\tValidation loss: 8.325068\tBest loss: 4.479489\tAccuracy: 84.00%\n",
      "20\tValidation loss: 6.902452\tBest loss: 4.479489\tAccuracy: 85.50%\n",
      "21\tValidation loss: 9.067422\tBest loss: 4.479489\tAccuracy: 83.80%\n",
      "22\tValidation loss: 11.810318\tBest loss: 4.479489\tAccuracy: 83.70%\n",
      "23\tValidation loss: 8.462383\tBest loss: 4.479489\tAccuracy: 85.70%\n",
      "24\tValidation loss: 10.614770\tBest loss: 4.479489\tAccuracy: 87.60%\n",
      "25\tValidation loss: 11.082175\tBest loss: 4.479489\tAccuracy: 88.20%\n",
      "26\tValidation loss: 9.897396\tBest loss: 4.479489\tAccuracy: 85.70%\n",
      "27\tValidation loss: 8.920997\tBest loss: 4.479489\tAccuracy: 88.50%\n",
      "28\tValidation loss: 7.258076\tBest loss: 4.479489\tAccuracy: 90.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.0s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 43.165134\tBest loss: 43.165134\tAccuracy: 7.10%\n",
      "1\tValidation loss: 28.073364\tBest loss: 28.073364\tAccuracy: 22.60%\n",
      "2\tValidation loss: 16.691767\tBest loss: 16.691767\tAccuracy: 43.40%\n",
      "3\tValidation loss: 5.377419\tBest loss: 5.377419\tAccuracy: 67.00%\n",
      "4\tValidation loss: 10.323149\tBest loss: 5.377419\tAccuracy: 62.60%\n",
      "5\tValidation loss: 7.208560\tBest loss: 5.377419\tAccuracy: 71.70%\n",
      "6\tValidation loss: 11.167800\tBest loss: 5.377419\tAccuracy: 68.10%\n",
      "7\tValidation loss: 4.451628\tBest loss: 4.451628\tAccuracy: 78.60%\n",
      "8\tValidation loss: 11.957429\tBest loss: 4.451628\tAccuracy: 69.30%\n",
      "9\tValidation loss: 8.772270\tBest loss: 4.451628\tAccuracy: 73.90%\n",
      "10\tValidation loss: 9.360897\tBest loss: 4.451628\tAccuracy: 75.60%\n",
      "11\tValidation loss: 5.840170\tBest loss: 4.451628\tAccuracy: 82.40%\n",
      "12\tValidation loss: 5.984562\tBest loss: 4.451628\tAccuracy: 83.60%\n",
      "13\tValidation loss: 6.784640\tBest loss: 4.451628\tAccuracy: 82.50%\n",
      "14\tValidation loss: 8.381700\tBest loss: 4.451628\tAccuracy: 81.00%\n",
      "15\tValidation loss: 8.721023\tBest loss: 4.451628\tAccuracy: 81.50%\n",
      "16\tValidation loss: 10.536684\tBest loss: 4.451628\tAccuracy: 80.00%\n",
      "17\tValidation loss: 8.800303\tBest loss: 4.451628\tAccuracy: 85.00%\n",
      "18\tValidation loss: 9.728945\tBest loss: 4.451628\tAccuracy: 85.30%\n",
      "19\tValidation loss: 12.269345\tBest loss: 4.451628\tAccuracy: 82.70%\n",
      "20\tValidation loss: 8.020411\tBest loss: 4.451628\tAccuracy: 87.60%\n",
      "21\tValidation loss: 10.646088\tBest loss: 4.451628\tAccuracy: 84.20%\n",
      "22\tValidation loss: 12.440552\tBest loss: 4.451628\tAccuracy: 86.30%\n",
      "23\tValidation loss: 8.775057\tBest loss: 4.451628\tAccuracy: 89.20%\n",
      "24\tValidation loss: 12.959213\tBest loss: 4.451628\tAccuracy: 86.10%\n",
      "25\tValidation loss: 9.565941\tBest loss: 4.451628\tAccuracy: 89.80%\n",
      "26\tValidation loss: 10.938643\tBest loss: 4.451628\tAccuracy: 88.80%\n",
      "27\tValidation loss: 12.155196\tBest loss: 4.451628\tAccuracy: 87.40%\n",
      "28\tValidation loss: 12.975958\tBest loss: 4.451628\tAccuracy: 87.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.1s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 31.957556\tBest loss: 31.957556\tAccuracy: 7.50%\n",
      "1\tValidation loss: 33.054901\tBest loss: 31.957556\tAccuracy: 16.70%\n",
      "2\tValidation loss: 10.845181\tBest loss: 10.845181\tAccuracy: 46.10%\n",
      "3\tValidation loss: 10.266504\tBest loss: 10.266504\tAccuracy: 52.50%\n",
      "4\tValidation loss: 9.930658\tBest loss: 9.930658\tAccuracy: 59.10%\n",
      "5\tValidation loss: 6.273181\tBest loss: 6.273181\tAccuracy: 69.70%\n",
      "6\tValidation loss: 9.884391\tBest loss: 6.273181\tAccuracy: 68.50%\n",
      "7\tValidation loss: 9.642792\tBest loss: 6.273181\tAccuracy: 70.80%\n",
      "8\tValidation loss: 6.746163\tBest loss: 6.273181\tAccuracy: 75.10%\n",
      "9\tValidation loss: 4.886823\tBest loss: 4.886823\tAccuracy: 78.60%\n",
      "10\tValidation loss: 6.502298\tBest loss: 4.886823\tAccuracy: 77.00%\n",
      "11\tValidation loss: 7.550509\tBest loss: 4.886823\tAccuracy: 76.00%\n",
      "12\tValidation loss: 6.079980\tBest loss: 4.886823\tAccuracy: 80.10%\n",
      "13\tValidation loss: 7.294780\tBest loss: 4.886823\tAccuracy: 81.10%\n",
      "14\tValidation loss: 6.650265\tBest loss: 4.886823\tAccuracy: 80.70%\n",
      "15\tValidation loss: 5.528968\tBest loss: 4.886823\tAccuracy: 84.00%\n",
      "16\tValidation loss: 8.026831\tBest loss: 4.886823\tAccuracy: 81.70%\n",
      "17\tValidation loss: 6.947652\tBest loss: 4.886823\tAccuracy: 85.50%\n",
      "18\tValidation loss: 11.342435\tBest loss: 4.886823\tAccuracy: 82.60%\n",
      "19\tValidation loss: 7.041784\tBest loss: 4.886823\tAccuracy: 83.70%\n",
      "20\tValidation loss: 9.624071\tBest loss: 4.886823\tAccuracy: 84.40%\n",
      "21\tValidation loss: 12.114589\tBest loss: 4.886823\tAccuracy: 83.60%\n",
      "22\tValidation loss: 9.947192\tBest loss: 4.886823\tAccuracy: 85.40%\n",
      "23\tValidation loss: 7.128815\tBest loss: 4.886823\tAccuracy: 88.20%\n",
      "24\tValidation loss: 6.736398\tBest loss: 4.886823\tAccuracy: 88.10%\n",
      "25\tValidation loss: 9.581785\tBest loss: 4.886823\tAccuracy: 87.20%\n",
      "26\tValidation loss: 11.825675\tBest loss: 4.886823\tAccuracy: 86.90%\n",
      "27\tValidation loss: 7.535937\tBest loss: 4.886823\tAccuracy: 88.70%\n",
      "28\tValidation loss: 11.995358\tBest loss: 4.886823\tAccuracy: 88.10%\n",
      "29\tValidation loss: 14.965256\tBest loss: 4.886823\tAccuracy: 83.90%\n",
      "30\tValidation loss: 12.518298\tBest loss: 4.886823\tAccuracy: 88.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.1s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.516299\tBest loss: 3.516299\tAccuracy: 12.40%\n",
      "1\tValidation loss: 3.066411\tBest loss: 3.066411\tAccuracy: 21.40%\n",
      "2\tValidation loss: 3.042876\tBest loss: 3.042876\tAccuracy: 23.30%\n",
      "3\tValidation loss: 2.928472\tBest loss: 2.928472\tAccuracy: 23.20%\n",
      "4\tValidation loss: 2.731528\tBest loss: 2.731528\tAccuracy: 25.00%\n",
      "5\tValidation loss: 2.914213\tBest loss: 2.731528\tAccuracy: 26.20%\n",
      "6\tValidation loss: 2.861699\tBest loss: 2.731528\tAccuracy: 26.20%\n",
      "7\tValidation loss: 2.909288\tBest loss: 2.731528\tAccuracy: 26.30%\n",
      "8\tValidation loss: 2.677138\tBest loss: 2.677138\tAccuracy: 30.90%\n",
      "9\tValidation loss: 2.514190\tBest loss: 2.514190\tAccuracy: 29.90%\n",
      "10\tValidation loss: 2.852658\tBest loss: 2.514190\tAccuracy: 29.40%\n",
      "11\tValidation loss: 2.844556\tBest loss: 2.514190\tAccuracy: 31.10%\n",
      "12\tValidation loss: 2.618314\tBest loss: 2.514190\tAccuracy: 29.80%\n",
      "13\tValidation loss: 2.549283\tBest loss: 2.514190\tAccuracy: 32.10%\n",
      "14\tValidation loss: 3.208757\tBest loss: 2.514190\tAccuracy: 24.00%\n",
      "15\tValidation loss: 2.854681\tBest loss: 2.514190\tAccuracy: 30.20%\n",
      "16\tValidation loss: 2.647086\tBest loss: 2.514190\tAccuracy: 32.00%\n",
      "17\tValidation loss: 2.873033\tBest loss: 2.514190\tAccuracy: 29.50%\n",
      "18\tValidation loss: 2.464148\tBest loss: 2.464148\tAccuracy: 35.00%\n",
      "19\tValidation loss: 2.952500\tBest loss: 2.464148\tAccuracy: 27.90%\n",
      "20\tValidation loss: 2.716788\tBest loss: 2.464148\tAccuracy: 32.10%\n",
      "21\tValidation loss: 3.002828\tBest loss: 2.464148\tAccuracy: 27.70%\n",
      "22\tValidation loss: 2.411388\tBest loss: 2.411388\tAccuracy: 30.40%\n",
      "23\tValidation loss: 3.042316\tBest loss: 2.411388\tAccuracy: 31.80%\n",
      "24\tValidation loss: 2.957557\tBest loss: 2.411388\tAccuracy: 29.20%\n",
      "25\tValidation loss: 3.065703\tBest loss: 2.411388\tAccuracy: 29.30%\n",
      "26\tValidation loss: 2.400952\tBest loss: 2.400952\tAccuracy: 35.20%\n",
      "27\tValidation loss: 2.656809\tBest loss: 2.400952\tAccuracy: 32.50%\n",
      "28\tValidation loss: 2.733863\tBest loss: 2.400952\tAccuracy: 36.40%\n",
      "29\tValidation loss: 2.762895\tBest loss: 2.400952\tAccuracy: 35.10%\n",
      "30\tValidation loss: 3.018656\tBest loss: 2.400952\tAccuracy: 29.60%\n",
      "31\tValidation loss: 2.522945\tBest loss: 2.400952\tAccuracy: 35.00%\n",
      "32\tValidation loss: 2.811824\tBest loss: 2.400952\tAccuracy: 34.00%\n",
      "33\tValidation loss: 2.835393\tBest loss: 2.400952\tAccuracy: 28.90%\n",
      "34\tValidation loss: 2.941775\tBest loss: 2.400952\tAccuracy: 31.90%\n",
      "35\tValidation loss: 2.703629\tBest loss: 2.400952\tAccuracy: 30.30%\n",
      "36\tValidation loss: 2.854136\tBest loss: 2.400952\tAccuracy: 32.40%\n",
      "37\tValidation loss: 2.786184\tBest loss: 2.400952\tAccuracy: 31.40%\n",
      "38\tValidation loss: 2.707687\tBest loss: 2.400952\tAccuracy: 37.00%\n",
      "39\tValidation loss: 2.639878\tBest loss: 2.400952\tAccuracy: 35.60%\n",
      "40\tValidation loss: 2.790620\tBest loss: 2.400952\tAccuracy: 33.50%\n",
      "41\tValidation loss: 2.677242\tBest loss: 2.400952\tAccuracy: 35.90%\n",
      "42\tValidation loss: 2.959617\tBest loss: 2.400952\tAccuracy: 30.60%\n",
      "43\tValidation loss: 3.030940\tBest loss: 2.400952\tAccuracy: 32.30%\n",
      "44\tValidation loss: 2.700100\tBest loss: 2.400952\tAccuracy: 31.60%\n",
      "45\tValidation loss: 2.937069\tBest loss: 2.400952\tAccuracy: 36.30%\n",
      "46\tValidation loss: 2.747013\tBest loss: 2.400952\tAccuracy: 34.80%\n",
      "47\tValidation loss: 2.504310\tBest loss: 2.400952\tAccuracy: 36.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=  11.6s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 3.475072\tBest loss: 3.475072\tAccuracy: 11.80%\n",
      "1\tValidation loss: 2.519769\tBest loss: 2.519769\tAccuracy: 31.70%\n",
      "2\tValidation loss: 2.661122\tBest loss: 2.519769\tAccuracy: 32.10%\n",
      "3\tValidation loss: 2.643508\tBest loss: 2.519769\tAccuracy: 29.90%\n",
      "4\tValidation loss: 2.446188\tBest loss: 2.446188\tAccuracy: 32.80%\n",
      "5\tValidation loss: 2.753469\tBest loss: 2.446188\tAccuracy: 33.60%\n",
      "6\tValidation loss: 2.756135\tBest loss: 2.446188\tAccuracy: 30.60%\n",
      "7\tValidation loss: 2.719306\tBest loss: 2.446188\tAccuracy: 32.00%\n",
      "8\tValidation loss: 2.807046\tBest loss: 2.446188\tAccuracy: 31.20%\n",
      "9\tValidation loss: 3.128503\tBest loss: 2.446188\tAccuracy: 31.90%\n",
      "10\tValidation loss: 2.840573\tBest loss: 2.446188\tAccuracy: 29.90%\n",
      "11\tValidation loss: 2.324976\tBest loss: 2.324976\tAccuracy: 36.00%\n",
      "12\tValidation loss: 4.360887\tBest loss: 2.324976\tAccuracy: 22.30%\n",
      "13\tValidation loss: 2.621071\tBest loss: 2.324976\tAccuracy: 29.40%\n",
      "14\tValidation loss: 2.403855\tBest loss: 2.324976\tAccuracy: 37.10%\n",
      "15\tValidation loss: 2.885647\tBest loss: 2.324976\tAccuracy: 31.50%\n",
      "16\tValidation loss: 2.621527\tBest loss: 2.324976\tAccuracy: 36.10%\n",
      "17\tValidation loss: 2.889416\tBest loss: 2.324976\tAccuracy: 32.30%\n",
      "18\tValidation loss: 2.918942\tBest loss: 2.324976\tAccuracy: 29.80%\n",
      "19\tValidation loss: 2.518146\tBest loss: 2.324976\tAccuracy: 35.90%\n",
      "20\tValidation loss: 2.521530\tBest loss: 2.324976\tAccuracy: 32.40%\n",
      "21\tValidation loss: 2.620041\tBest loss: 2.324976\tAccuracy: 36.20%\n",
      "22\tValidation loss: 2.423779\tBest loss: 2.324976\tAccuracy: 32.90%\n",
      "23\tValidation loss: 2.574872\tBest loss: 2.324976\tAccuracy: 36.00%\n",
      "24\tValidation loss: 3.274920\tBest loss: 2.324976\tAccuracy: 27.30%\n",
      "25\tValidation loss: 2.510038\tBest loss: 2.324976\tAccuracy: 33.90%\n",
      "26\tValidation loss: 2.584360\tBest loss: 2.324976\tAccuracy: 35.50%\n",
      "27\tValidation loss: 2.309541\tBest loss: 2.309541\tAccuracy: 35.20%\n",
      "28\tValidation loss: 2.567228\tBest loss: 2.309541\tAccuracy: 35.30%\n",
      "29\tValidation loss: 2.757153\tBest loss: 2.309541\tAccuracy: 32.70%\n",
      "30\tValidation loss: 2.592665\tBest loss: 2.309541\tAccuracy: 33.60%\n",
      "31\tValidation loss: 2.687043\tBest loss: 2.309541\tAccuracy: 36.50%\n",
      "32\tValidation loss: 2.670615\tBest loss: 2.309541\tAccuracy: 33.00%\n",
      "33\tValidation loss: 2.776550\tBest loss: 2.309541\tAccuracy: 34.40%\n",
      "34\tValidation loss: 2.817644\tBest loss: 2.309541\tAccuracy: 32.30%\n",
      "35\tValidation loss: 2.531275\tBest loss: 2.309541\tAccuracy: 35.90%\n",
      "36\tValidation loss: 2.636156\tBest loss: 2.309541\tAccuracy: 36.90%\n",
      "37\tValidation loss: 2.701427\tBest loss: 2.309541\tAccuracy: 34.20%\n",
      "38\tValidation loss: 2.571277\tBest loss: 2.309541\tAccuracy: 38.40%\n",
      "39\tValidation loss: 2.661433\tBest loss: 2.309541\tAccuracy: 32.10%\n",
      "40\tValidation loss: 2.707058\tBest loss: 2.309541\tAccuracy: 37.30%\n",
      "41\tValidation loss: 2.611709\tBest loss: 2.309541\tAccuracy: 37.70%\n",
      "42\tValidation loss: 2.633023\tBest loss: 2.309541\tAccuracy: 31.00%\n",
      "43\tValidation loss: 2.618845\tBest loss: 2.309541\tAccuracy: 36.10%\n",
      "44\tValidation loss: 3.063828\tBest loss: 2.309541\tAccuracy: 34.70%\n",
      "45\tValidation loss: 2.512794\tBest loss: 2.309541\tAccuracy: 34.60%\n",
      "46\tValidation loss: 3.087228\tBest loss: 2.309541\tAccuracy: 35.00%\n",
      "47\tValidation loss: 2.983430\tBest loss: 2.309541\tAccuracy: 33.90%\n",
      "48\tValidation loss: 2.636766\tBest loss: 2.309541\tAccuracy: 33.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=  11.8s\n",
      "[CV] batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 3.627329\tBest loss: 3.627329\tAccuracy: 9.10%\n",
      "1\tValidation loss: 3.463708\tBest loss: 3.463708\tAccuracy: 9.40%\n",
      "2\tValidation loss: 3.292643\tBest loss: 3.292643\tAccuracy: 10.70%\n",
      "3\tValidation loss: 3.587668\tBest loss: 3.292643\tAccuracy: 11.10%\n",
      "4\tValidation loss: 3.282371\tBest loss: 3.282371\tAccuracy: 14.90%\n",
      "5\tValidation loss: 3.197059\tBest loss: 3.197059\tAccuracy: 15.10%\n",
      "6\tValidation loss: 3.214695\tBest loss: 3.197059\tAccuracy: 19.40%\n",
      "7\tValidation loss: 2.800959\tBest loss: 2.800959\tAccuracy: 20.10%\n",
      "8\tValidation loss: 2.853900\tBest loss: 2.800959\tAccuracy: 25.10%\n",
      "9\tValidation loss: 3.179888\tBest loss: 2.800959\tAccuracy: 22.90%\n",
      "10\tValidation loss: 2.895236\tBest loss: 2.800959\tAccuracy: 23.50%\n",
      "11\tValidation loss: 2.774745\tBest loss: 2.774745\tAccuracy: 25.40%\n",
      "12\tValidation loss: 2.996174\tBest loss: 2.774745\tAccuracy: 23.60%\n",
      "13\tValidation loss: 2.615660\tBest loss: 2.615660\tAccuracy: 25.70%\n",
      "14\tValidation loss: 3.177128\tBest loss: 2.615660\tAccuracy: 26.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tValidation loss: 5.433272\tBest loss: 2.615660\tAccuracy: 27.70%\n",
      "16\tValidation loss: 2.637692\tBest loss: 2.615660\tAccuracy: 27.80%\n",
      "17\tValidation loss: 2.620603\tBest loss: 2.615660\tAccuracy: 30.70%\n",
      "18\tValidation loss: 2.452717\tBest loss: 2.452717\tAccuracy: 30.50%\n",
      "19\tValidation loss: 2.891619\tBest loss: 2.452717\tAccuracy: 27.20%\n",
      "20\tValidation loss: 2.971370\tBest loss: 2.452717\tAccuracy: 28.80%\n",
      "21\tValidation loss: 2.742326\tBest loss: 2.452717\tAccuracy: 31.60%\n",
      "22\tValidation loss: 3.128552\tBest loss: 2.452717\tAccuracy: 20.60%\n",
      "23\tValidation loss: 2.788918\tBest loss: 2.452717\tAccuracy: 30.60%\n",
      "24\tValidation loss: 2.919951\tBest loss: 2.452717\tAccuracy: 27.50%\n",
      "25\tValidation loss: 3.111803\tBest loss: 2.452717\tAccuracy: 26.60%\n",
      "26\tValidation loss: 3.220237\tBest loss: 2.452717\tAccuracy: 31.80%\n",
      "27\tValidation loss: 2.622696\tBest loss: 2.452717\tAccuracy: 30.80%\n",
      "28\tValidation loss: 2.995166\tBest loss: 2.452717\tAccuracy: 27.10%\n",
      "29\tValidation loss: 2.509686\tBest loss: 2.452717\tAccuracy: 30.80%\n",
      "30\tValidation loss: 2.846179\tBest loss: 2.452717\tAccuracy: 29.40%\n",
      "31\tValidation loss: 2.844543\tBest loss: 2.452717\tAccuracy: 26.30%\n",
      "32\tValidation loss: 4.306868\tBest loss: 2.452717\tAccuracy: 25.80%\n",
      "33\tValidation loss: 3.131728\tBest loss: 2.452717\tAccuracy: 24.60%\n",
      "34\tValidation loss: 3.555654\tBest loss: 2.452717\tAccuracy: 20.40%\n",
      "35\tValidation loss: 2.835556\tBest loss: 2.452717\tAccuracy: 29.60%\n",
      "36\tValidation loss: 3.159842\tBest loss: 2.452717\tAccuracy: 25.90%\n",
      "37\tValidation loss: 2.841782\tBest loss: 2.452717\tAccuracy: 28.70%\n",
      "38\tValidation loss: 2.862093\tBest loss: 2.452717\tAccuracy: 32.10%\n",
      "39\tValidation loss: 2.842513\tBest loss: 2.452717\tAccuracy: 29.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=100, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   9.8s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 18.810482\tBest loss: 18.810482\tAccuracy: 2.20%\n",
      "1\tValidation loss: 16.417358\tBest loss: 16.417358\tAccuracy: 1.70%\n",
      "2\tValidation loss: 16.893528\tBest loss: 16.417358\tAccuracy: 3.70%\n",
      "3\tValidation loss: 14.387062\tBest loss: 14.387062\tAccuracy: 2.40%\n",
      "4\tValidation loss: 6.266918\tBest loss: 6.266918\tAccuracy: 2.40%\n",
      "5\tValidation loss: 4.412317\tBest loss: 4.412317\tAccuracy: 5.10%\n",
      "6\tValidation loss: 3.643563\tBest loss: 3.643563\tAccuracy: 7.00%\n",
      "7\tValidation loss: 3.716042\tBest loss: 3.643563\tAccuracy: 5.90%\n",
      "8\tValidation loss: 3.468755\tBest loss: 3.468755\tAccuracy: 9.60%\n",
      "9\tValidation loss: 3.129874\tBest loss: 3.129874\tAccuracy: 14.90%\n",
      "10\tValidation loss: 2.910122\tBest loss: 2.910122\tAccuracy: 16.70%\n",
      "11\tValidation loss: 2.840550\tBest loss: 2.840550\tAccuracy: 18.80%\n",
      "12\tValidation loss: 2.641288\tBest loss: 2.641288\tAccuracy: 22.50%\n",
      "13\tValidation loss: 2.462130\tBest loss: 2.462130\tAccuracy: 25.70%\n",
      "14\tValidation loss: 2.341048\tBest loss: 2.341048\tAccuracy: 29.30%\n",
      "15\tValidation loss: 2.300096\tBest loss: 2.300096\tAccuracy: 28.00%\n",
      "16\tValidation loss: 2.158629\tBest loss: 2.158629\tAccuracy: 32.60%\n",
      "17\tValidation loss: 2.208288\tBest loss: 2.158629\tAccuracy: 32.40%\n",
      "18\tValidation loss: 2.690274\tBest loss: 2.158629\tAccuracy: 27.80%\n",
      "19\tValidation loss: 2.208452\tBest loss: 2.158629\tAccuracy: 32.60%\n",
      "20\tValidation loss: 2.228761\tBest loss: 2.158629\tAccuracy: 31.80%\n",
      "21\tValidation loss: 2.050021\tBest loss: 2.050021\tAccuracy: 37.30%\n",
      "22\tValidation loss: 1.986752\tBest loss: 1.986752\tAccuracy: 39.30%\n",
      "23\tValidation loss: 1.831302\tBest loss: 1.831302\tAccuracy: 42.00%\n",
      "24\tValidation loss: 1.877475\tBest loss: 1.831302\tAccuracy: 41.40%\n",
      "25\tValidation loss: 1.838646\tBest loss: 1.831302\tAccuracy: 41.50%\n",
      "26\tValidation loss: 1.689753\tBest loss: 1.689753\tAccuracy: 46.80%\n",
      "27\tValidation loss: 1.778278\tBest loss: 1.689753\tAccuracy: 42.20%\n",
      "28\tValidation loss: 1.784306\tBest loss: 1.689753\tAccuracy: 46.50%\n",
      "29\tValidation loss: 1.584985\tBest loss: 1.584985\tAccuracy: 51.80%\n",
      "30\tValidation loss: 1.967146\tBest loss: 1.584985\tAccuracy: 40.40%\n",
      "31\tValidation loss: 1.640744\tBest loss: 1.584985\tAccuracy: 49.80%\n",
      "32\tValidation loss: 1.564845\tBest loss: 1.564845\tAccuracy: 51.90%\n",
      "33\tValidation loss: 1.643532\tBest loss: 1.564845\tAccuracy: 49.80%\n",
      "34\tValidation loss: 1.613488\tBest loss: 1.564845\tAccuracy: 48.30%\n",
      "35\tValidation loss: 1.633299\tBest loss: 1.564845\tAccuracy: 51.00%\n",
      "36\tValidation loss: 1.501713\tBest loss: 1.501713\tAccuracy: 55.90%\n",
      "37\tValidation loss: 1.663470\tBest loss: 1.501713\tAccuracy: 50.20%\n",
      "38\tValidation loss: 1.401557\tBest loss: 1.401557\tAccuracy: 55.80%\n",
      "39\tValidation loss: 1.476564\tBest loss: 1.401557\tAccuracy: 54.10%\n",
      "40\tValidation loss: 1.417964\tBest loss: 1.401557\tAccuracy: 58.60%\n",
      "41\tValidation loss: 1.292692\tBest loss: 1.292692\tAccuracy: 62.00%\n",
      "42\tValidation loss: 1.374279\tBest loss: 1.292692\tAccuracy: 59.20%\n",
      "43\tValidation loss: 1.357186\tBest loss: 1.292692\tAccuracy: 59.60%\n",
      "44\tValidation loss: 1.776803\tBest loss: 1.292692\tAccuracy: 50.10%\n",
      "45\tValidation loss: 1.339013\tBest loss: 1.292692\tAccuracy: 59.40%\n",
      "46\tValidation loss: 1.266450\tBest loss: 1.266450\tAccuracy: 60.70%\n",
      "47\tValidation loss: 1.227273\tBest loss: 1.227273\tAccuracy: 64.30%\n",
      "48\tValidation loss: 1.470766\tBest loss: 1.227273\tAccuracy: 58.80%\n",
      "49\tValidation loss: 14.907812\tBest loss: 1.227273\tAccuracy: 2.90%\n",
      "50\tValidation loss: 27.554108\tBest loss: 1.227273\tAccuracy: 1.50%\n",
      "51\tValidation loss: 21.080803\tBest loss: 1.227273\tAccuracy: 2.30%\n",
      "52\tValidation loss: 13.745811\tBest loss: 1.227273\tAccuracy: 3.10%\n",
      "53\tValidation loss: 10.860893\tBest loss: 1.227273\tAccuracy: 3.50%\n",
      "54\tValidation loss: 8.140546\tBest loss: 1.227273\tAccuracy: 3.90%\n",
      "55\tValidation loss: 5.089078\tBest loss: 1.227273\tAccuracy: 1.30%\n",
      "56\tValidation loss: 4.813338\tBest loss: 1.227273\tAccuracy: 1.10%\n",
      "57\tValidation loss: 4.041519\tBest loss: 1.227273\tAccuracy: 1.50%\n",
      "58\tValidation loss: 3.924956\tBest loss: 1.227273\tAccuracy: 3.80%\n",
      "59\tValidation loss: 4.030926\tBest loss: 1.227273\tAccuracy: 3.80%\n",
      "60\tValidation loss: 3.979558\tBest loss: 1.227273\tAccuracy: 3.00%\n",
      "61\tValidation loss: 3.879557\tBest loss: 1.227273\tAccuracy: 3.50%\n",
      "62\tValidation loss: 3.920812\tBest loss: 1.227273\tAccuracy: 2.90%\n",
      "63\tValidation loss: 3.933534\tBest loss: 1.227273\tAccuracy: 3.40%\n",
      "64\tValidation loss: 3.983871\tBest loss: 1.227273\tAccuracy: 3.40%\n",
      "65\tValidation loss: 4.004012\tBest loss: 1.227273\tAccuracy: 3.80%\n",
      "66\tValidation loss: 3.942910\tBest loss: 1.227273\tAccuracy: 3.10%\n",
      "67\tValidation loss: 4.045042\tBest loss: 1.227273\tAccuracy: 3.50%\n",
      "68\tValidation loss: 4.060183\tBest loss: 1.227273\tAccuracy: 2.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   8.9s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 22.558348\tBest loss: 22.558348\tAccuracy: 4.30%\n",
      "1\tValidation loss: 10.586164\tBest loss: 10.586164\tAccuracy: 2.60%\n",
      "2\tValidation loss: 9.257037\tBest loss: 9.257037\tAccuracy: 3.20%\n",
      "3\tValidation loss: 4.840729\tBest loss: 4.840729\tAccuracy: 3.70%\n",
      "4\tValidation loss: 4.256068\tBest loss: 4.256068\tAccuracy: 2.50%\n",
      "5\tValidation loss: 3.660939\tBest loss: 3.660939\tAccuracy: 6.60%\n",
      "6\tValidation loss: 3.540421\tBest loss: 3.540421\tAccuracy: 9.90%\n",
      "7\tValidation loss: 3.329100\tBest loss: 3.329100\tAccuracy: 12.60%\n",
      "8\tValidation loss: 3.182360\tBest loss: 3.182360\tAccuracy: 14.50%\n",
      "9\tValidation loss: 2.941281\tBest loss: 2.941281\tAccuracy: 18.40%\n",
      "10\tValidation loss: 3.256115\tBest loss: 2.941281\tAccuracy: 17.90%\n",
      "11\tValidation loss: 2.972966\tBest loss: 2.941281\tAccuracy: 20.70%\n",
      "12\tValidation loss: 2.729205\tBest loss: 2.729205\tAccuracy: 21.30%\n",
      "13\tValidation loss: 2.473094\tBest loss: 2.473094\tAccuracy: 25.90%\n",
      "14\tValidation loss: 2.395791\tBest loss: 2.395791\tAccuracy: 24.50%\n",
      "15\tValidation loss: 2.156682\tBest loss: 2.156682\tAccuracy: 32.40%\n",
      "16\tValidation loss: 2.225513\tBest loss: 2.156682\tAccuracy: 33.60%\n",
      "17\tValidation loss: 2.209783\tBest loss: 2.156682\tAccuracy: 34.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 2.127009\tBest loss: 2.127009\tAccuracy: 35.30%\n",
      "19\tValidation loss: 2.190184\tBest loss: 2.127009\tAccuracy: 36.20%\n",
      "20\tValidation loss: 1.886873\tBest loss: 1.886873\tAccuracy: 40.00%\n",
      "21\tValidation loss: 2.095607\tBest loss: 1.886873\tAccuracy: 36.10%\n",
      "22\tValidation loss: 1.778163\tBest loss: 1.778163\tAccuracy: 44.20%\n",
      "23\tValidation loss: 1.869780\tBest loss: 1.778163\tAccuracy: 41.20%\n",
      "24\tValidation loss: 1.724269\tBest loss: 1.724269\tAccuracy: 45.40%\n",
      "25\tValidation loss: 1.953456\tBest loss: 1.724269\tAccuracy: 42.50%\n",
      "26\tValidation loss: 1.696342\tBest loss: 1.696342\tAccuracy: 46.40%\n",
      "27\tValidation loss: 2.038754\tBest loss: 1.696342\tAccuracy: 42.30%\n",
      "28\tValidation loss: 1.581002\tBest loss: 1.581002\tAccuracy: 51.30%\n",
      "29\tValidation loss: 1.778729\tBest loss: 1.581002\tAccuracy: 44.20%\n",
      "30\tValidation loss: 1.568684\tBest loss: 1.568684\tAccuracy: 53.30%\n",
      "31\tValidation loss: 1.673142\tBest loss: 1.568684\tAccuracy: 49.40%\n",
      "32\tValidation loss: 1.439386\tBest loss: 1.439386\tAccuracy: 54.80%\n",
      "33\tValidation loss: 1.715045\tBest loss: 1.439386\tAccuracy: 49.90%\n",
      "34\tValidation loss: 1.548499\tBest loss: 1.439386\tAccuracy: 51.70%\n",
      "35\tValidation loss: 1.459289\tBest loss: 1.439386\tAccuracy: 56.00%\n",
      "36\tValidation loss: 1.554855\tBest loss: 1.439386\tAccuracy: 51.80%\n",
      "37\tValidation loss: 1.498455\tBest loss: 1.439386\tAccuracy: 56.20%\n",
      "38\tValidation loss: 1.565455\tBest loss: 1.439386\tAccuracy: 52.50%\n",
      "39\tValidation loss: 1.642908\tBest loss: 1.439386\tAccuracy: 50.10%\n",
      "40\tValidation loss: 1.462387\tBest loss: 1.439386\tAccuracy: 54.50%\n",
      "41\tValidation loss: 1.548821\tBest loss: 1.439386\tAccuracy: 55.40%\n",
      "42\tValidation loss: 1.335624\tBest loss: 1.335624\tAccuracy: 61.30%\n",
      "43\tValidation loss: 1.549352\tBest loss: 1.335624\tAccuracy: 56.10%\n",
      "44\tValidation loss: 1.562731\tBest loss: 1.335624\tAccuracy: 56.60%\n",
      "45\tValidation loss: 1.616558\tBest loss: 1.335624\tAccuracy: 54.90%\n",
      "46\tValidation loss: 1.434561\tBest loss: 1.335624\tAccuracy: 60.70%\n",
      "47\tValidation loss: 1.373954\tBest loss: 1.335624\tAccuracy: 60.90%\n",
      "48\tValidation loss: 1.333874\tBest loss: 1.333874\tAccuracy: 61.60%\n",
      "49\tValidation loss: 1.440532\tBest loss: 1.333874\tAccuracy: 60.70%\n",
      "50\tValidation loss: 1.362503\tBest loss: 1.333874\tAccuracy: 62.40%\n",
      "51\tValidation loss: 1.456142\tBest loss: 1.333874\tAccuracy: 59.20%\n",
      "52\tValidation loss: 1.479801\tBest loss: 1.333874\tAccuracy: 60.50%\n",
      "53\tValidation loss: 1.413354\tBest loss: 1.333874\tAccuracy: 61.90%\n",
      "54\tValidation loss: 1.326163\tBest loss: 1.326163\tAccuracy: 62.70%\n",
      "55\tValidation loss: 1.361074\tBest loss: 1.326163\tAccuracy: 62.50%\n",
      "56\tValidation loss: 1.274734\tBest loss: 1.274734\tAccuracy: 64.70%\n",
      "57\tValidation loss: 1.503985\tBest loss: 1.274734\tAccuracy: 61.00%\n",
      "58\tValidation loss: 1.331135\tBest loss: 1.274734\tAccuracy: 63.40%\n",
      "59\tValidation loss: 1.417066\tBest loss: 1.274734\tAccuracy: 61.70%\n",
      "60\tValidation loss: 1.323092\tBest loss: 1.274734\tAccuracy: 66.10%\n",
      "61\tValidation loss: 1.275638\tBest loss: 1.274734\tAccuracy: 65.20%\n",
      "62\tValidation loss: 1.431610\tBest loss: 1.274734\tAccuracy: 64.20%\n",
      "63\tValidation loss: 1.256565\tBest loss: 1.256565\tAccuracy: 65.70%\n",
      "64\tValidation loss: 1.276837\tBest loss: 1.256565\tAccuracy: 67.00%\n",
      "65\tValidation loss: 1.434362\tBest loss: 1.256565\tAccuracy: 64.00%\n",
      "66\tValidation loss: 1.296988\tBest loss: 1.256565\tAccuracy: 65.30%\n",
      "67\tValidation loss: 1.227486\tBest loss: 1.227486\tAccuracy: 68.40%\n",
      "68\tValidation loss: 1.403887\tBest loss: 1.227486\tAccuracy: 64.70%\n",
      "69\tValidation loss: 1.682948\tBest loss: 1.227486\tAccuracy: 60.70%\n",
      "70\tValidation loss: 1.262321\tBest loss: 1.227486\tAccuracy: 66.90%\n",
      "71\tValidation loss: 1.334980\tBest loss: 1.227486\tAccuracy: 65.90%\n",
      "72\tValidation loss: 1.637768\tBest loss: 1.227486\tAccuracy: 61.20%\n",
      "73\tValidation loss: 1.484886\tBest loss: 1.227486\tAccuracy: 62.50%\n",
      "74\tValidation loss: 1.474937\tBest loss: 1.227486\tAccuracy: 66.60%\n",
      "75\tValidation loss: 1.239182\tBest loss: 1.227486\tAccuracy: 69.20%\n",
      "76\tValidation loss: 1.430350\tBest loss: 1.227486\tAccuracy: 64.10%\n",
      "77\tValidation loss: 1.375039\tBest loss: 1.227486\tAccuracy: 66.00%\n",
      "78\tValidation loss: 2.095864\tBest loss: 1.227486\tAccuracy: 55.80%\n",
      "79\tValidation loss: 1.454091\tBest loss: 1.227486\tAccuracy: 64.40%\n",
      "80\tValidation loss: 1.297965\tBest loss: 1.227486\tAccuracy: 68.50%\n",
      "81\tValidation loss: 1.716164\tBest loss: 1.227486\tAccuracy: 58.50%\n",
      "82\tValidation loss: 1.572660\tBest loss: 1.227486\tAccuracy: 65.20%\n",
      "83\tValidation loss: 1.197193\tBest loss: 1.197193\tAccuracy: 71.70%\n",
      "84\tValidation loss: 1.363998\tBest loss: 1.197193\tAccuracy: 68.60%\n",
      "85\tValidation loss: 1.471539\tBest loss: 1.197193\tAccuracy: 64.30%\n",
      "86\tValidation loss: 1.397040\tBest loss: 1.197193\tAccuracy: 68.80%\n",
      "87\tValidation loss: 1.298003\tBest loss: 1.197193\tAccuracy: 69.20%\n",
      "88\tValidation loss: 1.691782\tBest loss: 1.197193\tAccuracy: 62.60%\n",
      "89\tValidation loss: 1.369534\tBest loss: 1.197193\tAccuracy: 68.60%\n",
      "90\tValidation loss: 1.247385\tBest loss: 1.197193\tAccuracy: 70.10%\n",
      "91\tValidation loss: 1.333499\tBest loss: 1.197193\tAccuracy: 67.20%\n",
      "92\tValidation loss: 1.287842\tBest loss: 1.197193\tAccuracy: 69.40%\n",
      "93\tValidation loss: 1.167734\tBest loss: 1.167734\tAccuracy: 71.30%\n",
      "94\tValidation loss: 3.506526\tBest loss: 1.167734\tAccuracy: 38.70%\n",
      "95\tValidation loss: 4.848341\tBest loss: 1.167734\tAccuracy: 29.60%\n",
      "96\tValidation loss: 2.752908\tBest loss: 1.167734\tAccuracy: 35.70%\n",
      "97\tValidation loss: 2.544609\tBest loss: 1.167734\tAccuracy: 46.70%\n",
      "98\tValidation loss: 1.857409\tBest loss: 1.167734\tAccuracy: 51.60%\n",
      "99\tValidation loss: 137.702484\tBest loss: 1.167734\tAccuracy: 1.50%\n",
      "100\tValidation loss: 2485.830566\tBest loss: 1.167734\tAccuracy: 1.90%\n",
      "101\tValidation loss: 111.176254\tBest loss: 1.167734\tAccuracy: 0.60%\n",
      "102\tValidation loss: 75.811096\tBest loss: 1.167734\tAccuracy: 1.10%\n",
      "103\tValidation loss: 49.325897\tBest loss: 1.167734\tAccuracy: 3.00%\n",
      "104\tValidation loss: 39.490749\tBest loss: 1.167734\tAccuracy: 2.60%\n",
      "105\tValidation loss: 30.690151\tBest loss: 1.167734\tAccuracy: 1.40%\n",
      "106\tValidation loss: 23.100807\tBest loss: 1.167734\tAccuracy: 0.90%\n",
      "107\tValidation loss: 14.931506\tBest loss: 1.167734\tAccuracy: 2.00%\n",
      "108\tValidation loss: 10.523314\tBest loss: 1.167734\tAccuracy: 2.90%\n",
      "109\tValidation loss: 7.355694\tBest loss: 1.167734\tAccuracy: 3.60%\n",
      "110\tValidation loss: 4.689664\tBest loss: 1.167734\tAccuracy: 3.40%\n",
      "111\tValidation loss: 3.975193\tBest loss: 1.167734\tAccuracy: 3.50%\n",
      "112\tValidation loss: 3.940135\tBest loss: 1.167734\tAccuracy: 3.10%\n",
      "113\tValidation loss: 3.895849\tBest loss: 1.167734\tAccuracy: 2.60%\n",
      "114\tValidation loss: 3.918668\tBest loss: 1.167734\tAccuracy: 2.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=  14.0s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 23.928314\tBest loss: 23.928314\tAccuracy: 3.80%\n",
      "1\tValidation loss: 20.278378\tBest loss: 20.278378\tAccuracy: 1.40%\n",
      "2\tValidation loss: 15.066815\tBest loss: 15.066815\tAccuracy: 1.40%\n",
      "3\tValidation loss: 8.258536\tBest loss: 8.258536\tAccuracy: 1.60%\n",
      "4\tValidation loss: 8.266498\tBest loss: 8.258536\tAccuracy: 3.60%\n",
      "5\tValidation loss: 5.880426\tBest loss: 5.880426\tAccuracy: 3.70%\n",
      "6\tValidation loss: 4.591793\tBest loss: 4.591793\tAccuracy: 1.30%\n",
      "7\tValidation loss: 3.917247\tBest loss: 3.917247\tAccuracy: 5.30%\n",
      "8\tValidation loss: 3.503088\tBest loss: 3.503088\tAccuracy: 9.20%\n",
      "9\tValidation loss: 3.312516\tBest loss: 3.312516\tAccuracy: 9.70%\n",
      "10\tValidation loss: 3.136772\tBest loss: 3.136772\tAccuracy: 11.90%\n",
      "11\tValidation loss: 2.850164\tBest loss: 2.850164\tAccuracy: 19.30%\n",
      "12\tValidation loss: 2.807402\tBest loss: 2.807402\tAccuracy: 20.80%\n",
      "13\tValidation loss: 2.762329\tBest loss: 2.762329\tAccuracy: 20.10%\n",
      "14\tValidation loss: 2.563607\tBest loss: 2.563607\tAccuracy: 28.40%\n",
      "15\tValidation loss: 2.547805\tBest loss: 2.547805\tAccuracy: 24.90%\n",
      "16\tValidation loss: 2.572164\tBest loss: 2.547805\tAccuracy: 29.60%\n",
      "17\tValidation loss: 2.589155\tBest loss: 2.547805\tAccuracy: 29.10%\n",
      "18\tValidation loss: 1.924218\tBest loss: 1.924218\tAccuracy: 40.30%\n",
      "19\tValidation loss: 1.840555\tBest loss: 1.840555\tAccuracy: 44.30%\n",
      "20\tValidation loss: 1.752725\tBest loss: 1.752725\tAccuracy: 46.00%\n",
      "21\tValidation loss: 1.906008\tBest loss: 1.752725\tAccuracy: 45.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tValidation loss: 1.652904\tBest loss: 1.652904\tAccuracy: 47.80%\n",
      "23\tValidation loss: 1.936110\tBest loss: 1.652904\tAccuracy: 47.00%\n",
      "24\tValidation loss: 1.635295\tBest loss: 1.635295\tAccuracy: 50.80%\n",
      "25\tValidation loss: 2.086938\tBest loss: 1.635295\tAccuracy: 43.60%\n",
      "26\tValidation loss: 1.625526\tBest loss: 1.625526\tAccuracy: 50.80%\n",
      "27\tValidation loss: 1.550551\tBest loss: 1.550551\tAccuracy: 52.30%\n",
      "28\tValidation loss: 1.443614\tBest loss: 1.443614\tAccuracy: 57.70%\n",
      "29\tValidation loss: 1.558143\tBest loss: 1.443614\tAccuracy: 52.20%\n",
      "30\tValidation loss: 1.687589\tBest loss: 1.443614\tAccuracy: 51.00%\n",
      "31\tValidation loss: 2.042988\tBest loss: 1.443614\tAccuracy: 44.90%\n",
      "32\tValidation loss: 1.334083\tBest loss: 1.334083\tAccuracy: 60.70%\n",
      "33\tValidation loss: 1.379074\tBest loss: 1.334083\tAccuracy: 58.70%\n",
      "34\tValidation loss: 1.494326\tBest loss: 1.334083\tAccuracy: 56.90%\n",
      "35\tValidation loss: 1.430293\tBest loss: 1.334083\tAccuracy: 60.20%\n",
      "36\tValidation loss: 1.321628\tBest loss: 1.321628\tAccuracy: 61.20%\n",
      "37\tValidation loss: 1.352058\tBest loss: 1.321628\tAccuracy: 60.80%\n",
      "38\tValidation loss: 1.290135\tBest loss: 1.290135\tAccuracy: 62.80%\n",
      "39\tValidation loss: 1.402194\tBest loss: 1.290135\tAccuracy: 61.60%\n",
      "40\tValidation loss: 1.957351\tBest loss: 1.290135\tAccuracy: 50.90%\n",
      "41\tValidation loss: 1.774921\tBest loss: 1.290135\tAccuracy: 55.00%\n",
      "42\tValidation loss: 1.511292\tBest loss: 1.290135\tAccuracy: 60.10%\n",
      "43\tValidation loss: 1.449370\tBest loss: 1.290135\tAccuracy: 60.50%\n",
      "44\tValidation loss: 1.384756\tBest loss: 1.290135\tAccuracy: 61.20%\n",
      "45\tValidation loss: 1.363281\tBest loss: 1.290135\tAccuracy: 63.20%\n",
      "46\tValidation loss: 1.377661\tBest loss: 1.290135\tAccuracy: 64.60%\n",
      "47\tValidation loss: 1.313049\tBest loss: 1.290135\tAccuracy: 65.50%\n",
      "48\tValidation loss: 1.380546\tBest loss: 1.290135\tAccuracy: 64.20%\n",
      "49\tValidation loss: 0.999923\tBest loss: 0.999923\tAccuracy: 70.70%\n",
      "50\tValidation loss: 1.152502\tBest loss: 0.999923\tAccuracy: 69.00%\n",
      "51\tValidation loss: 1.193254\tBest loss: 0.999923\tAccuracy: 69.00%\n",
      "52\tValidation loss: 1.139724\tBest loss: 0.999923\tAccuracy: 70.30%\n",
      "53\tValidation loss: 1.108555\tBest loss: 0.999923\tAccuracy: 69.60%\n",
      "54\tValidation loss: 1.185428\tBest loss: 0.999923\tAccuracy: 70.50%\n",
      "55\tValidation loss: 1.194172\tBest loss: 0.999923\tAccuracy: 69.40%\n",
      "56\tValidation loss: 1.278142\tBest loss: 0.999923\tAccuracy: 67.40%\n",
      "57\tValidation loss: 1.136987\tBest loss: 0.999923\tAccuracy: 72.20%\n",
      "58\tValidation loss: 1.109523\tBest loss: 0.999923\tAccuracy: 70.90%\n",
      "59\tValidation loss: 1.136941\tBest loss: 0.999923\tAccuracy: 71.70%\n",
      "60\tValidation loss: 1.278597\tBest loss: 0.999923\tAccuracy: 69.30%\n",
      "61\tValidation loss: 1.107559\tBest loss: 0.999923\tAccuracy: 70.30%\n",
      "62\tValidation loss: 1.233924\tBest loss: 0.999923\tAccuracy: 69.90%\n",
      "63\tValidation loss: 1.161916\tBest loss: 0.999923\tAccuracy: 71.10%\n",
      "64\tValidation loss: 0.964807\tBest loss: 0.964807\tAccuracy: 74.90%\n",
      "65\tValidation loss: 1.026689\tBest loss: 0.964807\tAccuracy: 72.90%\n",
      "66\tValidation loss: 1.026148\tBest loss: 0.964807\tAccuracy: 73.30%\n",
      "67\tValidation loss: 1.151075\tBest loss: 0.964807\tAccuracy: 72.30%\n",
      "68\tValidation loss: 1.348471\tBest loss: 0.964807\tAccuracy: 68.10%\n",
      "69\tValidation loss: 1.119220\tBest loss: 0.964807\tAccuracy: 73.00%\n",
      "70\tValidation loss: 1.310127\tBest loss: 0.964807\tAccuracy: 71.10%\n",
      "71\tValidation loss: 1.002797\tBest loss: 0.964807\tAccuracy: 74.20%\n",
      "72\tValidation loss: 1.116057\tBest loss: 0.964807\tAccuracy: 74.80%\n",
      "73\tValidation loss: 1.030616\tBest loss: 0.964807\tAccuracy: 75.60%\n",
      "74\tValidation loss: 1.510315\tBest loss: 0.964807\tAccuracy: 68.60%\n",
      "75\tValidation loss: 1.151192\tBest loss: 0.964807\tAccuracy: 74.50%\n",
      "76\tValidation loss: 1.316140\tBest loss: 0.964807\tAccuracy: 74.20%\n",
      "77\tValidation loss: 1.274275\tBest loss: 0.964807\tAccuracy: 71.50%\n",
      "78\tValidation loss: 1.318000\tBest loss: 0.964807\tAccuracy: 68.60%\n",
      "79\tValidation loss: 1.526769\tBest loss: 0.964807\tAccuracy: 68.10%\n",
      "80\tValidation loss: 1.381351\tBest loss: 0.964807\tAccuracy: 71.00%\n",
      "81\tValidation loss: 1.220982\tBest loss: 0.964807\tAccuracy: 74.30%\n",
      "82\tValidation loss: 1.132004\tBest loss: 0.964807\tAccuracy: 74.20%\n",
      "83\tValidation loss: 1.234669\tBest loss: 0.964807\tAccuracy: 73.20%\n",
      "84\tValidation loss: 1.373753\tBest loss: 0.964807\tAccuracy: 72.10%\n",
      "85\tValidation loss: 1.066996\tBest loss: 0.964807\tAccuracy: 76.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=  11.1s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.820193\tBest loss: 2.820193\tAccuracy: 32.80%\n",
      "1\tValidation loss: 2.244951\tBest loss: 2.244951\tAccuracy: 43.20%\n",
      "2\tValidation loss: 1.873390\tBest loss: 1.873390\tAccuracy: 54.60%\n",
      "3\tValidation loss: 1.613046\tBest loss: 1.613046\tAccuracy: 60.60%\n",
      "4\tValidation loss: 1.423871\tBest loss: 1.423871\tAccuracy: 65.30%\n",
      "5\tValidation loss: 1.294831\tBest loss: 1.294831\tAccuracy: 66.70%\n",
      "6\tValidation loss: 1.170049\tBest loss: 1.170049\tAccuracy: 72.50%\n",
      "7\tValidation loss: 1.109241\tBest loss: 1.109241\tAccuracy: 69.80%\n",
      "8\tValidation loss: 1.016324\tBest loss: 1.016324\tAccuracy: 73.60%\n",
      "9\tValidation loss: 0.983606\tBest loss: 0.983606\tAccuracy: 75.30%\n",
      "10\tValidation loss: 0.958032\tBest loss: 0.958032\tAccuracy: 74.80%\n",
      "11\tValidation loss: 0.871118\tBest loss: 0.871118\tAccuracy: 78.40%\n",
      "12\tValidation loss: 0.872003\tBest loss: 0.871118\tAccuracy: 77.00%\n",
      "13\tValidation loss: 0.804081\tBest loss: 0.804081\tAccuracy: 79.60%\n",
      "14\tValidation loss: 0.805466\tBest loss: 0.804081\tAccuracy: 80.40%\n",
      "15\tValidation loss: 0.777251\tBest loss: 0.777251\tAccuracy: 80.80%\n",
      "16\tValidation loss: 0.756465\tBest loss: 0.756465\tAccuracy: 80.50%\n",
      "17\tValidation loss: 0.736857\tBest loss: 0.736857\tAccuracy: 81.90%\n",
      "18\tValidation loss: 0.711348\tBest loss: 0.711348\tAccuracy: 81.10%\n",
      "19\tValidation loss: 0.692519\tBest loss: 0.692519\tAccuracy: 83.20%\n",
      "20\tValidation loss: 0.676909\tBest loss: 0.676909\tAccuracy: 82.50%\n",
      "21\tValidation loss: 0.650392\tBest loss: 0.650392\tAccuracy: 83.40%\n",
      "22\tValidation loss: 0.666506\tBest loss: 0.650392\tAccuracy: 82.80%\n",
      "23\tValidation loss: 0.640728\tBest loss: 0.640728\tAccuracy: 83.70%\n",
      "24\tValidation loss: 0.630643\tBest loss: 0.630643\tAccuracy: 85.80%\n",
      "25\tValidation loss: 0.622190\tBest loss: 0.622190\tAccuracy: 84.70%\n",
      "26\tValidation loss: 0.609177\tBest loss: 0.609177\tAccuracy: 85.10%\n",
      "27\tValidation loss: 0.620857\tBest loss: 0.609177\tAccuracy: 84.60%\n",
      "28\tValidation loss: 0.598531\tBest loss: 0.598531\tAccuracy: 84.50%\n",
      "29\tValidation loss: 0.595408\tBest loss: 0.595408\tAccuracy: 84.90%\n",
      "30\tValidation loss: 0.598222\tBest loss: 0.595408\tAccuracy: 84.80%\n",
      "31\tValidation loss: 0.567492\tBest loss: 0.567492\tAccuracy: 87.30%\n",
      "32\tValidation loss: 0.559334\tBest loss: 0.559334\tAccuracy: 86.20%\n",
      "33\tValidation loss: 0.553507\tBest loss: 0.553507\tAccuracy: 88.00%\n",
      "34\tValidation loss: 0.552789\tBest loss: 0.552789\tAccuracy: 86.50%\n",
      "35\tValidation loss: 0.549088\tBest loss: 0.549088\tAccuracy: 86.60%\n",
      "36\tValidation loss: 0.542411\tBest loss: 0.542411\tAccuracy: 87.10%\n",
      "37\tValidation loss: 0.540488\tBest loss: 0.540488\tAccuracy: 86.70%\n",
      "38\tValidation loss: 0.533103\tBest loss: 0.533103\tAccuracy: 86.70%\n",
      "39\tValidation loss: 0.518010\tBest loss: 0.518010\tAccuracy: 86.90%\n",
      "40\tValidation loss: 0.555101\tBest loss: 0.518010\tAccuracy: 86.70%\n",
      "41\tValidation loss: 0.534651\tBest loss: 0.518010\tAccuracy: 87.40%\n",
      "42\tValidation loss: 0.526871\tBest loss: 0.518010\tAccuracy: 85.90%\n",
      "43\tValidation loss: 0.504184\tBest loss: 0.504184\tAccuracy: 87.90%\n",
      "44\tValidation loss: 0.504807\tBest loss: 0.504184\tAccuracy: 87.60%\n",
      "45\tValidation loss: 0.484554\tBest loss: 0.484554\tAccuracy: 89.40%\n",
      "46\tValidation loss: 0.504245\tBest loss: 0.484554\tAccuracy: 87.30%\n",
      "47\tValidation loss: 0.480934\tBest loss: 0.480934\tAccuracy: 88.20%\n",
      "48\tValidation loss: 0.481853\tBest loss: 0.480934\tAccuracy: 87.50%\n",
      "49\tValidation loss: 0.486797\tBest loss: 0.480934\tAccuracy: 88.30%\n",
      "50\tValidation loss: 0.490102\tBest loss: 0.480934\tAccuracy: 87.00%\n",
      "51\tValidation loss: 0.479840\tBest loss: 0.479840\tAccuracy: 87.90%\n",
      "52\tValidation loss: 0.471677\tBest loss: 0.471677\tAccuracy: 87.60%\n",
      "53\tValidation loss: 0.468261\tBest loss: 0.468261\tAccuracy: 88.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\tValidation loss: 0.455630\tBest loss: 0.455630\tAccuracy: 89.40%\n",
      "55\tValidation loss: 0.455368\tBest loss: 0.455368\tAccuracy: 88.80%\n",
      "56\tValidation loss: 0.464004\tBest loss: 0.455368\tAccuracy: 89.40%\n",
      "57\tValidation loss: 0.451014\tBest loss: 0.451014\tAccuracy: 89.20%\n",
      "58\tValidation loss: 0.464182\tBest loss: 0.451014\tAccuracy: 88.00%\n",
      "59\tValidation loss: 0.454345\tBest loss: 0.451014\tAccuracy: 88.70%\n",
      "60\tValidation loss: 0.450631\tBest loss: 0.450631\tAccuracy: 89.40%\n",
      "61\tValidation loss: 0.451131\tBest loss: 0.450631\tAccuracy: 89.20%\n",
      "62\tValidation loss: 0.436938\tBest loss: 0.436938\tAccuracy: 89.50%\n",
      "63\tValidation loss: 0.438923\tBest loss: 0.436938\tAccuracy: 88.90%\n",
      "64\tValidation loss: 0.446384\tBest loss: 0.436938\tAccuracy: 89.20%\n",
      "65\tValidation loss: 0.433764\tBest loss: 0.433764\tAccuracy: 89.70%\n",
      "66\tValidation loss: 0.429789\tBest loss: 0.429789\tAccuracy: 89.50%\n",
      "67\tValidation loss: 0.446005\tBest loss: 0.429789\tAccuracy: 89.60%\n",
      "68\tValidation loss: 0.429450\tBest loss: 0.429450\tAccuracy: 89.30%\n",
      "69\tValidation loss: 0.423381\tBest loss: 0.423381\tAccuracy: 89.60%\n",
      "70\tValidation loss: 0.424336\tBest loss: 0.423381\tAccuracy: 89.70%\n",
      "71\tValidation loss: 0.421187\tBest loss: 0.421187\tAccuracy: 89.70%\n",
      "72\tValidation loss: 0.417615\tBest loss: 0.417615\tAccuracy: 90.10%\n",
      "73\tValidation loss: 0.419747\tBest loss: 0.417615\tAccuracy: 90.50%\n",
      "74\tValidation loss: 0.430877\tBest loss: 0.417615\tAccuracy: 89.40%\n",
      "75\tValidation loss: 0.416027\tBest loss: 0.416027\tAccuracy: 90.00%\n",
      "76\tValidation loss: 0.412290\tBest loss: 0.412290\tAccuracy: 90.80%\n",
      "77\tValidation loss: 0.417799\tBest loss: 0.412290\tAccuracy: 89.90%\n",
      "78\tValidation loss: 0.406972\tBest loss: 0.406972\tAccuracy: 89.70%\n",
      "79\tValidation loss: 0.401845\tBest loss: 0.401845\tAccuracy: 90.80%\n",
      "80\tValidation loss: 0.409201\tBest loss: 0.401845\tAccuracy: 90.30%\n",
      "81\tValidation loss: 0.406221\tBest loss: 0.401845\tAccuracy: 90.90%\n",
      "82\tValidation loss: 0.413684\tBest loss: 0.401845\tAccuracy: 89.90%\n",
      "83\tValidation loss: 0.394539\tBest loss: 0.394539\tAccuracy: 91.10%\n",
      "84\tValidation loss: 0.396392\tBest loss: 0.394539\tAccuracy: 90.60%\n",
      "85\tValidation loss: 0.393801\tBest loss: 0.393801\tAccuracy: 90.70%\n",
      "86\tValidation loss: 0.396037\tBest loss: 0.393801\tAccuracy: 90.80%\n",
      "87\tValidation loss: 0.398794\tBest loss: 0.393801\tAccuracy: 91.00%\n",
      "88\tValidation loss: 0.395419\tBest loss: 0.393801\tAccuracy: 90.80%\n",
      "89\tValidation loss: 0.401491\tBest loss: 0.393801\tAccuracy: 90.40%\n",
      "90\tValidation loss: 0.396040\tBest loss: 0.393801\tAccuracy: 91.00%\n",
      "91\tValidation loss: 0.388707\tBest loss: 0.388707\tAccuracy: 91.40%\n",
      "92\tValidation loss: 0.390088\tBest loss: 0.388707\tAccuracy: 91.20%\n",
      "93\tValidation loss: 0.385478\tBest loss: 0.385478\tAccuracy: 91.40%\n",
      "94\tValidation loss: 0.415112\tBest loss: 0.385478\tAccuracy: 89.80%\n",
      "95\tValidation loss: 0.380773\tBest loss: 0.380773\tAccuracy: 91.40%\n",
      "96\tValidation loss: 0.379921\tBest loss: 0.379921\tAccuracy: 91.40%\n",
      "97\tValidation loss: 0.389991\tBest loss: 0.379921\tAccuracy: 91.00%\n",
      "98\tValidation loss: 0.379580\tBest loss: 0.379580\tAccuracy: 91.00%\n",
      "99\tValidation loss: 0.377210\tBest loss: 0.377210\tAccuracy: 91.30%\n",
      "100\tValidation loss: 0.379687\tBest loss: 0.377210\tAccuracy: 91.60%\n",
      "101\tValidation loss: 0.377869\tBest loss: 0.377210\tAccuracy: 91.40%\n",
      "102\tValidation loss: 0.370530\tBest loss: 0.370530\tAccuracy: 91.80%\n",
      "103\tValidation loss: 0.382684\tBest loss: 0.370530\tAccuracy: 91.50%\n",
      "104\tValidation loss: 0.370719\tBest loss: 0.370530\tAccuracy: 91.90%\n",
      "105\tValidation loss: 0.372863\tBest loss: 0.370530\tAccuracy: 91.50%\n",
      "106\tValidation loss: 0.370256\tBest loss: 0.370256\tAccuracy: 90.90%\n",
      "107\tValidation loss: 0.376201\tBest loss: 0.370256\tAccuracy: 91.70%\n",
      "108\tValidation loss: 0.377432\tBest loss: 0.370256\tAccuracy: 91.20%\n",
      "109\tValidation loss: 0.367096\tBest loss: 0.367096\tAccuracy: 91.30%\n",
      "110\tValidation loss: 0.374654\tBest loss: 0.367096\tAccuracy: 91.80%\n",
      "111\tValidation loss: 0.374571\tBest loss: 0.367096\tAccuracy: 91.70%\n",
      "112\tValidation loss: 0.372551\tBest loss: 0.367096\tAccuracy: 91.70%\n",
      "113\tValidation loss: 0.362073\tBest loss: 0.362073\tAccuracy: 91.20%\n",
      "114\tValidation loss: 0.364399\tBest loss: 0.362073\tAccuracy: 92.20%\n",
      "115\tValidation loss: 0.367586\tBest loss: 0.362073\tAccuracy: 91.50%\n",
      "116\tValidation loss: 0.367454\tBest loss: 0.362073\tAccuracy: 91.50%\n",
      "117\tValidation loss: 0.361515\tBest loss: 0.361515\tAccuracy: 92.00%\n",
      "118\tValidation loss: 0.357474\tBest loss: 0.357474\tAccuracy: 91.90%\n",
      "119\tValidation loss: 0.364585\tBest loss: 0.357474\tAccuracy: 91.80%\n",
      "120\tValidation loss: 0.362762\tBest loss: 0.357474\tAccuracy: 92.10%\n",
      "121\tValidation loss: 0.363160\tBest loss: 0.357474\tAccuracy: 92.00%\n",
      "122\tValidation loss: 0.359105\tBest loss: 0.357474\tAccuracy: 92.60%\n",
      "123\tValidation loss: 0.357673\tBest loss: 0.357474\tAccuracy: 91.80%\n",
      "124\tValidation loss: 0.354765\tBest loss: 0.354765\tAccuracy: 91.90%\n",
      "125\tValidation loss: 0.355421\tBest loss: 0.354765\tAccuracy: 92.30%\n",
      "126\tValidation loss: 0.357920\tBest loss: 0.354765\tAccuracy: 92.20%\n",
      "127\tValidation loss: 0.361935\tBest loss: 0.354765\tAccuracy: 92.10%\n",
      "128\tValidation loss: 0.349436\tBest loss: 0.349436\tAccuracy: 92.40%\n",
      "129\tValidation loss: 0.356620\tBest loss: 0.349436\tAccuracy: 92.30%\n",
      "130\tValidation loss: 0.357239\tBest loss: 0.349436\tAccuracy: 91.50%\n",
      "131\tValidation loss: 0.353773\tBest loss: 0.349436\tAccuracy: 92.00%\n",
      "132\tValidation loss: 0.349847\tBest loss: 0.349436\tAccuracy: 91.90%\n",
      "133\tValidation loss: 0.353088\tBest loss: 0.349436\tAccuracy: 92.30%\n",
      "134\tValidation loss: 0.352624\tBest loss: 0.349436\tAccuracy: 92.30%\n",
      "135\tValidation loss: 0.352637\tBest loss: 0.349436\tAccuracy: 92.10%\n",
      "136\tValidation loss: 0.345937\tBest loss: 0.345937\tAccuracy: 92.80%\n",
      "137\tValidation loss: 0.353714\tBest loss: 0.345937\tAccuracy: 92.80%\n",
      "138\tValidation loss: 0.346819\tBest loss: 0.345937\tAccuracy: 92.30%\n",
      "139\tValidation loss: 0.342672\tBest loss: 0.342672\tAccuracy: 92.50%\n",
      "140\tValidation loss: 0.342148\tBest loss: 0.342148\tAccuracy: 92.80%\n",
      "141\tValidation loss: 0.350895\tBest loss: 0.342148\tAccuracy: 92.00%\n",
      "142\tValidation loss: 0.345472\tBest loss: 0.342148\tAccuracy: 92.50%\n",
      "143\tValidation loss: 0.339532\tBest loss: 0.339532\tAccuracy: 92.90%\n",
      "144\tValidation loss: 0.343457\tBest loss: 0.339532\tAccuracy: 92.70%\n",
      "145\tValidation loss: 0.343537\tBest loss: 0.339532\tAccuracy: 92.60%\n",
      "146\tValidation loss: 0.334902\tBest loss: 0.334902\tAccuracy: 93.10%\n",
      "147\tValidation loss: 0.339930\tBest loss: 0.334902\tAccuracy: 92.60%\n",
      "148\tValidation loss: 0.339760\tBest loss: 0.334902\tAccuracy: 92.70%\n",
      "149\tValidation loss: 0.339243\tBest loss: 0.334902\tAccuracy: 92.60%\n",
      "150\tValidation loss: 0.339550\tBest loss: 0.334902\tAccuracy: 92.80%\n",
      "151\tValidation loss: 0.341411\tBest loss: 0.334902\tAccuracy: 92.80%\n",
      "152\tValidation loss: 0.337141\tBest loss: 0.334902\tAccuracy: 93.00%\n",
      "153\tValidation loss: 0.333923\tBest loss: 0.333923\tAccuracy: 93.00%\n",
      "154\tValidation loss: 0.339519\tBest loss: 0.333923\tAccuracy: 92.90%\n",
      "155\tValidation loss: 0.337304\tBest loss: 0.333923\tAccuracy: 92.90%\n",
      "156\tValidation loss: 0.336566\tBest loss: 0.333923\tAccuracy: 92.60%\n",
      "157\tValidation loss: 0.341349\tBest loss: 0.333923\tAccuracy: 92.60%\n",
      "158\tValidation loss: 0.335457\tBest loss: 0.333923\tAccuracy: 92.90%\n",
      "159\tValidation loss: 0.337546\tBest loss: 0.333923\tAccuracy: 92.60%\n",
      "160\tValidation loss: 0.336071\tBest loss: 0.333923\tAccuracy: 93.00%\n",
      "161\tValidation loss: 0.338461\tBest loss: 0.333923\tAccuracy: 92.60%\n",
      "162\tValidation loss: 0.329063\tBest loss: 0.329063\tAccuracy: 92.80%\n",
      "163\tValidation loss: 0.330207\tBest loss: 0.329063\tAccuracy: 92.70%\n",
      "164\tValidation loss: 0.332137\tBest loss: 0.329063\tAccuracy: 92.70%\n",
      "165\tValidation loss: 0.329228\tBest loss: 0.329063\tAccuracy: 93.00%\n",
      "166\tValidation loss: 0.332198\tBest loss: 0.329063\tAccuracy: 93.30%\n",
      "167\tValidation loss: 0.327304\tBest loss: 0.327304\tAccuracy: 93.20%\n",
      "168\tValidation loss: 0.334580\tBest loss: 0.327304\tAccuracy: 93.20%\n",
      "169\tValidation loss: 0.331094\tBest loss: 0.327304\tAccuracy: 93.30%\n",
      "170\tValidation loss: 0.329995\tBest loss: 0.327304\tAccuracy: 92.90%\n",
      "171\tValidation loss: 0.326116\tBest loss: 0.326116\tAccuracy: 92.90%\n",
      "172\tValidation loss: 0.326235\tBest loss: 0.326116\tAccuracy: 93.30%\n",
      "173\tValidation loss: 0.332235\tBest loss: 0.326116\tAccuracy: 93.00%\n",
      "174\tValidation loss: 0.326247\tBest loss: 0.326116\tAccuracy: 92.80%\n",
      "175\tValidation loss: 0.325758\tBest loss: 0.325758\tAccuracy: 92.70%\n",
      "176\tValidation loss: 0.331806\tBest loss: 0.325758\tAccuracy: 92.60%\n",
      "177\tValidation loss: 0.324103\tBest loss: 0.324103\tAccuracy: 93.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\tValidation loss: 0.325803\tBest loss: 0.324103\tAccuracy: 92.70%\n",
      "179\tValidation loss: 0.325650\tBest loss: 0.324103\tAccuracy: 93.20%\n",
      "180\tValidation loss: 0.324760\tBest loss: 0.324103\tAccuracy: 93.20%\n",
      "181\tValidation loss: 0.320750\tBest loss: 0.320750\tAccuracy: 93.10%\n",
      "182\tValidation loss: 0.322329\tBest loss: 0.320750\tAccuracy: 93.50%\n",
      "183\tValidation loss: 0.323509\tBest loss: 0.320750\tAccuracy: 92.80%\n",
      "184\tValidation loss: 0.324896\tBest loss: 0.320750\tAccuracy: 93.10%\n",
      "185\tValidation loss: 0.327095\tBest loss: 0.320750\tAccuracy: 92.50%\n",
      "186\tValidation loss: 0.319985\tBest loss: 0.319985\tAccuracy: 93.30%\n",
      "187\tValidation loss: 0.323752\tBest loss: 0.319985\tAccuracy: 92.60%\n",
      "188\tValidation loss: 0.323387\tBest loss: 0.319985\tAccuracy: 93.80%\n",
      "189\tValidation loss: 0.320909\tBest loss: 0.319985\tAccuracy: 93.40%\n",
      "190\tValidation loss: 0.324000\tBest loss: 0.319985\tAccuracy: 92.90%\n",
      "191\tValidation loss: 0.322727\tBest loss: 0.319985\tAccuracy: 93.40%\n",
      "192\tValidation loss: 0.327770\tBest loss: 0.319985\tAccuracy: 93.30%\n",
      "193\tValidation loss: 0.326099\tBest loss: 0.319985\tAccuracy: 92.90%\n",
      "194\tValidation loss: 0.318632\tBest loss: 0.318632\tAccuracy: 93.20%\n",
      "195\tValidation loss: 0.313424\tBest loss: 0.313424\tAccuracy: 93.30%\n",
      "196\tValidation loss: 0.325630\tBest loss: 0.313424\tAccuracy: 93.60%\n",
      "197\tValidation loss: 0.318165\tBest loss: 0.313424\tAccuracy: 93.50%\n",
      "198\tValidation loss: 0.321485\tBest loss: 0.313424\tAccuracy: 92.90%\n",
      "199\tValidation loss: 0.317987\tBest loss: 0.313424\tAccuracy: 93.50%\n",
      "200\tValidation loss: 0.326118\tBest loss: 0.313424\tAccuracy: 93.30%\n",
      "201\tValidation loss: 0.322494\tBest loss: 0.313424\tAccuracy: 93.50%\n",
      "202\tValidation loss: 0.319203\tBest loss: 0.313424\tAccuracy: 93.30%\n",
      "203\tValidation loss: 0.319530\tBest loss: 0.313424\tAccuracy: 93.20%\n",
      "204\tValidation loss: 0.319611\tBest loss: 0.313424\tAccuracy: 93.10%\n",
      "205\tValidation loss: 0.317533\tBest loss: 0.313424\tAccuracy: 93.10%\n",
      "206\tValidation loss: 0.316284\tBest loss: 0.313424\tAccuracy: 93.40%\n",
      "207\tValidation loss: 0.316111\tBest loss: 0.313424\tAccuracy: 93.60%\n",
      "208\tValidation loss: 0.318608\tBest loss: 0.313424\tAccuracy: 93.90%\n",
      "209\tValidation loss: 0.313262\tBest loss: 0.313262\tAccuracy: 93.40%\n",
      "210\tValidation loss: 0.309593\tBest loss: 0.309593\tAccuracy: 93.70%\n",
      "211\tValidation loss: 0.313857\tBest loss: 0.309593\tAccuracy: 94.10%\n",
      "212\tValidation loss: 0.312500\tBest loss: 0.309593\tAccuracy: 93.30%\n",
      "213\tValidation loss: 0.314038\tBest loss: 0.309593\tAccuracy: 93.70%\n",
      "214\tValidation loss: 0.311590\tBest loss: 0.309593\tAccuracy: 93.80%\n",
      "215\tValidation loss: 0.312291\tBest loss: 0.309593\tAccuracy: 93.70%\n",
      "216\tValidation loss: 0.315041\tBest loss: 0.309593\tAccuracy: 93.40%\n",
      "217\tValidation loss: 0.312596\tBest loss: 0.309593\tAccuracy: 93.90%\n",
      "218\tValidation loss: 0.314352\tBest loss: 0.309593\tAccuracy: 93.80%\n",
      "219\tValidation loss: 0.312757\tBest loss: 0.309593\tAccuracy: 94.00%\n",
      "220\tValidation loss: 0.316483\tBest loss: 0.309593\tAccuracy: 93.40%\n",
      "221\tValidation loss: 0.312518\tBest loss: 0.309593\tAccuracy: 93.80%\n",
      "222\tValidation loss: 0.315600\tBest loss: 0.309593\tAccuracy: 93.70%\n",
      "223\tValidation loss: 0.316238\tBest loss: 0.309593\tAccuracy: 93.80%\n",
      "224\tValidation loss: 0.312220\tBest loss: 0.309593\tAccuracy: 93.80%\n",
      "225\tValidation loss: 0.310037\tBest loss: 0.309593\tAccuracy: 94.00%\n",
      "226\tValidation loss: 0.310354\tBest loss: 0.309593\tAccuracy: 93.30%\n",
      "227\tValidation loss: 0.309110\tBest loss: 0.309110\tAccuracy: 93.50%\n",
      "228\tValidation loss: 0.310587\tBest loss: 0.309110\tAccuracy: 94.20%\n",
      "229\tValidation loss: 0.315470\tBest loss: 0.309110\tAccuracy: 93.80%\n",
      "230\tValidation loss: 0.312168\tBest loss: 0.309110\tAccuracy: 93.40%\n",
      "231\tValidation loss: 0.311423\tBest loss: 0.309110\tAccuracy: 93.60%\n",
      "232\tValidation loss: 0.309082\tBest loss: 0.309082\tAccuracy: 93.80%\n",
      "233\tValidation loss: 0.312808\tBest loss: 0.309082\tAccuracy: 94.10%\n",
      "234\tValidation loss: 0.311456\tBest loss: 0.309082\tAccuracy: 94.20%\n",
      "235\tValidation loss: 0.308868\tBest loss: 0.308868\tAccuracy: 93.80%\n",
      "236\tValidation loss: 0.311029\tBest loss: 0.308868\tAccuracy: 93.50%\n",
      "237\tValidation loss: 0.308062\tBest loss: 0.308062\tAccuracy: 94.30%\n",
      "238\tValidation loss: 0.313473\tBest loss: 0.308062\tAccuracy: 93.80%\n",
      "239\tValidation loss: 0.308787\tBest loss: 0.308062\tAccuracy: 93.90%\n",
      "240\tValidation loss: 0.311062\tBest loss: 0.308062\tAccuracy: 93.90%\n",
      "241\tValidation loss: 0.311273\tBest loss: 0.308062\tAccuracy: 94.20%\n",
      "242\tValidation loss: 0.307555\tBest loss: 0.307555\tAccuracy: 93.60%\n",
      "243\tValidation loss: 0.307662\tBest loss: 0.307555\tAccuracy: 93.80%\n",
      "244\tValidation loss: 0.312275\tBest loss: 0.307555\tAccuracy: 94.50%\n",
      "245\tValidation loss: 0.310356\tBest loss: 0.307555\tAccuracy: 93.70%\n",
      "246\tValidation loss: 0.308539\tBest loss: 0.307555\tAccuracy: 94.30%\n",
      "247\tValidation loss: 0.306218\tBest loss: 0.306218\tAccuracy: 94.20%\n",
      "248\tValidation loss: 0.310677\tBest loss: 0.306218\tAccuracy: 94.10%\n",
      "249\tValidation loss: 0.308822\tBest loss: 0.306218\tAccuracy: 93.90%\n",
      "250\tValidation loss: 0.310268\tBest loss: 0.306218\tAccuracy: 93.50%\n",
      "251\tValidation loss: 0.307836\tBest loss: 0.306218\tAccuracy: 94.10%\n",
      "252\tValidation loss: 0.306366\tBest loss: 0.306218\tAccuracy: 94.60%\n",
      "253\tValidation loss: 0.309038\tBest loss: 0.306218\tAccuracy: 93.80%\n",
      "254\tValidation loss: 0.308786\tBest loss: 0.306218\tAccuracy: 94.30%\n",
      "255\tValidation loss: 0.307368\tBest loss: 0.306218\tAccuracy: 94.10%\n",
      "256\tValidation loss: 0.309929\tBest loss: 0.306218\tAccuracy: 93.80%\n",
      "257\tValidation loss: 0.311986\tBest loss: 0.306218\tAccuracy: 93.60%\n",
      "258\tValidation loss: 0.308109\tBest loss: 0.306218\tAccuracy: 94.10%\n",
      "259\tValidation loss: 0.306494\tBest loss: 0.306218\tAccuracy: 93.90%\n",
      "260\tValidation loss: 0.305841\tBest loss: 0.305841\tAccuracy: 94.50%\n",
      "261\tValidation loss: 0.304614\tBest loss: 0.304614\tAccuracy: 94.10%\n",
      "262\tValidation loss: 0.309253\tBest loss: 0.304614\tAccuracy: 93.80%\n",
      "263\tValidation loss: 0.311159\tBest loss: 0.304614\tAccuracy: 94.30%\n",
      "264\tValidation loss: 0.311524\tBest loss: 0.304614\tAccuracy: 93.90%\n",
      "265\tValidation loss: 0.309758\tBest loss: 0.304614\tAccuracy: 93.90%\n",
      "266\tValidation loss: 0.310038\tBest loss: 0.304614\tAccuracy: 93.80%\n",
      "267\tValidation loss: 0.306988\tBest loss: 0.304614\tAccuracy: 93.90%\n",
      "268\tValidation loss: 0.309712\tBest loss: 0.304614\tAccuracy: 94.00%\n",
      "269\tValidation loss: 0.307883\tBest loss: 0.304614\tAccuracy: 94.30%\n",
      "270\tValidation loss: 0.310577\tBest loss: 0.304614\tAccuracy: 94.30%\n",
      "271\tValidation loss: 0.304807\tBest loss: 0.304614\tAccuracy: 94.10%\n",
      "272\tValidation loss: 0.307367\tBest loss: 0.304614\tAccuracy: 94.00%\n",
      "273\tValidation loss: 0.305818\tBest loss: 0.304614\tAccuracy: 94.40%\n",
      "274\tValidation loss: 0.308276\tBest loss: 0.304614\tAccuracy: 94.40%\n",
      "275\tValidation loss: 0.302985\tBest loss: 0.302985\tAccuracy: 94.50%\n",
      "276\tValidation loss: 0.309408\tBest loss: 0.302985\tAccuracy: 93.90%\n",
      "277\tValidation loss: 0.304457\tBest loss: 0.302985\tAccuracy: 94.10%\n",
      "278\tValidation loss: 0.306018\tBest loss: 0.302985\tAccuracy: 94.10%\n",
      "279\tValidation loss: 0.310881\tBest loss: 0.302985\tAccuracy: 94.10%\n",
      "280\tValidation loss: 0.307930\tBest loss: 0.302985\tAccuracy: 94.40%\n",
      "281\tValidation loss: 0.305497\tBest loss: 0.302985\tAccuracy: 93.80%\n",
      "282\tValidation loss: 0.303112\tBest loss: 0.302985\tAccuracy: 94.00%\n",
      "283\tValidation loss: 0.306386\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "284\tValidation loss: 0.310737\tBest loss: 0.302985\tAccuracy: 94.30%\n",
      "285\tValidation loss: 0.308257\tBest loss: 0.302985\tAccuracy: 94.30%\n",
      "286\tValidation loss: 0.306481\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "287\tValidation loss: 0.305922\tBest loss: 0.302985\tAccuracy: 94.30%\n",
      "288\tValidation loss: 0.308463\tBest loss: 0.302985\tAccuracy: 94.40%\n",
      "289\tValidation loss: 0.303742\tBest loss: 0.302985\tAccuracy: 94.30%\n",
      "290\tValidation loss: 0.307351\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "291\tValidation loss: 0.304713\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "292\tValidation loss: 0.308635\tBest loss: 0.302985\tAccuracy: 94.50%\n",
      "293\tValidation loss: 0.309209\tBest loss: 0.302985\tAccuracy: 94.50%\n",
      "294\tValidation loss: 0.308635\tBest loss: 0.302985\tAccuracy: 94.80%\n",
      "295\tValidation loss: 0.309147\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "296\tValidation loss: 0.308360\tBest loss: 0.302985\tAccuracy: 94.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  37.1s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.812396\tBest loss: 2.812396\tAccuracy: 30.70%\n",
      "1\tValidation loss: 2.231282\tBest loss: 2.231282\tAccuracy: 46.40%\n",
      "2\tValidation loss: 1.841755\tBest loss: 1.841755\tAccuracy: 56.40%\n",
      "3\tValidation loss: 1.622993\tBest loss: 1.622993\tAccuracy: 59.50%\n",
      "4\tValidation loss: 1.401456\tBest loss: 1.401456\tAccuracy: 65.70%\n",
      "5\tValidation loss: 1.300698\tBest loss: 1.300698\tAccuracy: 67.10%\n",
      "6\tValidation loss: 1.175341\tBest loss: 1.175341\tAccuracy: 70.90%\n",
      "7\tValidation loss: 1.084538\tBest loss: 1.084538\tAccuracy: 71.50%\n",
      "8\tValidation loss: 1.081418\tBest loss: 1.081418\tAccuracy: 73.10%\n",
      "9\tValidation loss: 0.990971\tBest loss: 0.990971\tAccuracy: 75.60%\n",
      "10\tValidation loss: 0.918422\tBest loss: 0.918422\tAccuracy: 76.80%\n",
      "11\tValidation loss: 0.969147\tBest loss: 0.918422\tAccuracy: 76.10%\n",
      "12\tValidation loss: 0.889602\tBest loss: 0.889602\tAccuracy: 77.30%\n",
      "13\tValidation loss: 0.846182\tBest loss: 0.846182\tAccuracy: 79.90%\n",
      "14\tValidation loss: 0.793375\tBest loss: 0.793375\tAccuracy: 81.70%\n",
      "15\tValidation loss: 0.758715\tBest loss: 0.758715\tAccuracy: 81.30%\n",
      "16\tValidation loss: 0.740039\tBest loss: 0.740039\tAccuracy: 81.70%\n",
      "17\tValidation loss: 0.723052\tBest loss: 0.723052\tAccuracy: 82.20%\n",
      "18\tValidation loss: 0.711666\tBest loss: 0.711666\tAccuracy: 82.50%\n",
      "19\tValidation loss: 0.709430\tBest loss: 0.709430\tAccuracy: 83.50%\n",
      "20\tValidation loss: 0.691534\tBest loss: 0.691534\tAccuracy: 82.80%\n",
      "21\tValidation loss: 0.684076\tBest loss: 0.684076\tAccuracy: 82.70%\n",
      "22\tValidation loss: 0.671533\tBest loss: 0.671533\tAccuracy: 83.20%\n",
      "23\tValidation loss: 0.645002\tBest loss: 0.645002\tAccuracy: 83.80%\n",
      "24\tValidation loss: 0.631797\tBest loss: 0.631797\tAccuracy: 84.60%\n",
      "25\tValidation loss: 0.643581\tBest loss: 0.631797\tAccuracy: 83.20%\n",
      "26\tValidation loss: 0.632398\tBest loss: 0.631797\tAccuracy: 84.50%\n",
      "27\tValidation loss: 0.614039\tBest loss: 0.614039\tAccuracy: 85.70%\n",
      "28\tValidation loss: 0.604512\tBest loss: 0.604512\tAccuracy: 86.00%\n",
      "29\tValidation loss: 0.601030\tBest loss: 0.601030\tAccuracy: 84.60%\n",
      "30\tValidation loss: 0.575630\tBest loss: 0.575630\tAccuracy: 85.60%\n",
      "31\tValidation loss: 0.572969\tBest loss: 0.572969\tAccuracy: 85.00%\n",
      "32\tValidation loss: 0.578052\tBest loss: 0.572969\tAccuracy: 85.30%\n",
      "33\tValidation loss: 0.565687\tBest loss: 0.565687\tAccuracy: 86.20%\n",
      "34\tValidation loss: 0.568028\tBest loss: 0.565687\tAccuracy: 86.00%\n",
      "35\tValidation loss: 0.548429\tBest loss: 0.548429\tAccuracy: 86.50%\n",
      "36\tValidation loss: 0.543301\tBest loss: 0.543301\tAccuracy: 87.30%\n",
      "37\tValidation loss: 0.546826\tBest loss: 0.543301\tAccuracy: 86.70%\n",
      "38\tValidation loss: 0.537346\tBest loss: 0.537346\tAccuracy: 86.90%\n",
      "39\tValidation loss: 0.528794\tBest loss: 0.528794\tAccuracy: 86.60%\n",
      "40\tValidation loss: 0.524284\tBest loss: 0.524284\tAccuracy: 86.60%\n",
      "41\tValidation loss: 0.517168\tBest loss: 0.517168\tAccuracy: 87.20%\n",
      "42\tValidation loss: 0.506550\tBest loss: 0.506550\tAccuracy: 87.40%\n",
      "43\tValidation loss: 0.494718\tBest loss: 0.494718\tAccuracy: 88.40%\n",
      "44\tValidation loss: 0.504468\tBest loss: 0.494718\tAccuracy: 87.70%\n",
      "45\tValidation loss: 0.497228\tBest loss: 0.494718\tAccuracy: 87.70%\n",
      "46\tValidation loss: 0.506345\tBest loss: 0.494718\tAccuracy: 87.70%\n",
      "47\tValidation loss: 0.505837\tBest loss: 0.494718\tAccuracy: 87.80%\n",
      "48\tValidation loss: 0.493843\tBest loss: 0.493843\tAccuracy: 87.90%\n",
      "49\tValidation loss: 0.492795\tBest loss: 0.492795\tAccuracy: 87.60%\n",
      "50\tValidation loss: 0.484358\tBest loss: 0.484358\tAccuracy: 88.40%\n",
      "51\tValidation loss: 0.494503\tBest loss: 0.484358\tAccuracy: 88.70%\n",
      "52\tValidation loss: 0.474829\tBest loss: 0.474829\tAccuracy: 89.00%\n",
      "53\tValidation loss: 0.475007\tBest loss: 0.474829\tAccuracy: 88.60%\n",
      "54\tValidation loss: 0.475816\tBest loss: 0.474829\tAccuracy: 89.10%\n",
      "55\tValidation loss: 0.470619\tBest loss: 0.470619\tAccuracy: 89.10%\n",
      "56\tValidation loss: 0.471410\tBest loss: 0.470619\tAccuracy: 88.80%\n",
      "57\tValidation loss: 0.462780\tBest loss: 0.462780\tAccuracy: 89.30%\n",
      "58\tValidation loss: 0.467611\tBest loss: 0.462780\tAccuracy: 89.00%\n",
      "59\tValidation loss: 0.461773\tBest loss: 0.461773\tAccuracy: 88.80%\n",
      "60\tValidation loss: 0.472178\tBest loss: 0.461773\tAccuracy: 88.60%\n",
      "61\tValidation loss: 0.470015\tBest loss: 0.461773\tAccuracy: 88.90%\n",
      "62\tValidation loss: 0.468598\tBest loss: 0.461773\tAccuracy: 88.40%\n",
      "63\tValidation loss: 0.451404\tBest loss: 0.451404\tAccuracy: 90.00%\n",
      "64\tValidation loss: 0.445275\tBest loss: 0.445275\tAccuracy: 89.40%\n",
      "65\tValidation loss: 0.444727\tBest loss: 0.444727\tAccuracy: 89.60%\n",
      "66\tValidation loss: 0.452427\tBest loss: 0.444727\tAccuracy: 89.30%\n",
      "67\tValidation loss: 0.455381\tBest loss: 0.444727\tAccuracy: 89.30%\n",
      "68\tValidation loss: 0.444533\tBest loss: 0.444533\tAccuracy: 89.50%\n",
      "69\tValidation loss: 0.445565\tBest loss: 0.444533\tAccuracy: 90.10%\n",
      "70\tValidation loss: 0.444206\tBest loss: 0.444206\tAccuracy: 89.70%\n",
      "71\tValidation loss: 0.440085\tBest loss: 0.440085\tAccuracy: 89.60%\n",
      "72\tValidation loss: 0.451150\tBest loss: 0.440085\tAccuracy: 89.10%\n",
      "73\tValidation loss: 0.440772\tBest loss: 0.440085\tAccuracy: 89.70%\n",
      "74\tValidation loss: 0.445787\tBest loss: 0.440085\tAccuracy: 89.80%\n",
      "75\tValidation loss: 0.436052\tBest loss: 0.436052\tAccuracy: 90.30%\n",
      "76\tValidation loss: 0.432023\tBest loss: 0.432023\tAccuracy: 89.60%\n",
      "77\tValidation loss: 0.436714\tBest loss: 0.432023\tAccuracy: 89.60%\n",
      "78\tValidation loss: 0.423332\tBest loss: 0.423332\tAccuracy: 89.40%\n",
      "79\tValidation loss: 0.425765\tBest loss: 0.423332\tAccuracy: 90.30%\n",
      "80\tValidation loss: 0.432442\tBest loss: 0.423332\tAccuracy: 89.70%\n",
      "81\tValidation loss: 0.428931\tBest loss: 0.423332\tAccuracy: 89.90%\n",
      "82\tValidation loss: 0.420403\tBest loss: 0.420403\tAccuracy: 90.30%\n",
      "83\tValidation loss: 0.426452\tBest loss: 0.420403\tAccuracy: 90.50%\n",
      "84\tValidation loss: 0.419150\tBest loss: 0.419150\tAccuracy: 90.60%\n",
      "85\tValidation loss: 0.428808\tBest loss: 0.419150\tAccuracy: 90.50%\n",
      "86\tValidation loss: 0.418601\tBest loss: 0.418601\tAccuracy: 90.30%\n",
      "87\tValidation loss: 0.425678\tBest loss: 0.418601\tAccuracy: 90.50%\n",
      "88\tValidation loss: 0.420926\tBest loss: 0.418601\tAccuracy: 90.50%\n",
      "89\tValidation loss: 0.424631\tBest loss: 0.418601\tAccuracy: 90.70%\n",
      "90\tValidation loss: 0.415335\tBest loss: 0.415335\tAccuracy: 90.50%\n",
      "91\tValidation loss: 0.430117\tBest loss: 0.415335\tAccuracy: 89.70%\n",
      "92\tValidation loss: 0.428481\tBest loss: 0.415335\tAccuracy: 90.40%\n",
      "93\tValidation loss: 0.414673\tBest loss: 0.414673\tAccuracy: 91.00%\n",
      "94\tValidation loss: 0.410471\tBest loss: 0.410471\tAccuracy: 90.70%\n",
      "95\tValidation loss: 0.409472\tBest loss: 0.409472\tAccuracy: 91.00%\n",
      "96\tValidation loss: 0.412921\tBest loss: 0.409472\tAccuracy: 90.40%\n",
      "97\tValidation loss: 0.411549\tBest loss: 0.409472\tAccuracy: 90.90%\n",
      "98\tValidation loss: 0.415760\tBest loss: 0.409472\tAccuracy: 90.60%\n",
      "99\tValidation loss: 0.425749\tBest loss: 0.409472\tAccuracy: 91.30%\n",
      "100\tValidation loss: 0.413621\tBest loss: 0.409472\tAccuracy: 90.80%\n",
      "101\tValidation loss: 0.412052\tBest loss: 0.409472\tAccuracy: 90.90%\n",
      "102\tValidation loss: 0.417952\tBest loss: 0.409472\tAccuracy: 91.10%\n",
      "103\tValidation loss: 0.408871\tBest loss: 0.408871\tAccuracy: 90.60%\n",
      "104\tValidation loss: 0.407422\tBest loss: 0.407422\tAccuracy: 90.90%\n",
      "105\tValidation loss: 0.410019\tBest loss: 0.407422\tAccuracy: 91.20%\n",
      "106\tValidation loss: 0.412712\tBest loss: 0.407422\tAccuracy: 91.30%\n",
      "107\tValidation loss: 0.412379\tBest loss: 0.407422\tAccuracy: 90.90%\n",
      "108\tValidation loss: 0.422979\tBest loss: 0.407422\tAccuracy: 91.00%\n",
      "109\tValidation loss: 0.407694\tBest loss: 0.407422\tAccuracy: 91.50%\n",
      "110\tValidation loss: 0.415138\tBest loss: 0.407422\tAccuracy: 90.80%\n",
      "111\tValidation loss: 0.399802\tBest loss: 0.399802\tAccuracy: 91.00%\n",
      "112\tValidation loss: 0.415370\tBest loss: 0.399802\tAccuracy: 90.70%\n",
      "113\tValidation loss: 0.402299\tBest loss: 0.399802\tAccuracy: 90.80%\n",
      "114\tValidation loss: 0.401894\tBest loss: 0.399802\tAccuracy: 90.50%\n",
      "115\tValidation loss: 0.409866\tBest loss: 0.399802\tAccuracy: 91.20%\n",
      "116\tValidation loss: 0.407257\tBest loss: 0.399802\tAccuracy: 90.70%\n",
      "117\tValidation loss: 0.407710\tBest loss: 0.399802\tAccuracy: 90.60%\n",
      "118\tValidation loss: 0.403669\tBest loss: 0.399802\tAccuracy: 90.90%\n",
      "119\tValidation loss: 0.408405\tBest loss: 0.399802\tAccuracy: 91.50%\n",
      "120\tValidation loss: 0.409012\tBest loss: 0.399802\tAccuracy: 90.90%\n",
      "121\tValidation loss: 0.413387\tBest loss: 0.399802\tAccuracy: 90.80%\n",
      "122\tValidation loss: 0.404422\tBest loss: 0.399802\tAccuracy: 91.20%\n",
      "123\tValidation loss: 0.404898\tBest loss: 0.399802\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 0.412262\tBest loss: 0.399802\tAccuracy: 91.50%\n",
      "125\tValidation loss: 0.402445\tBest loss: 0.399802\tAccuracy: 91.40%\n",
      "126\tValidation loss: 0.408585\tBest loss: 0.399802\tAccuracy: 91.50%\n",
      "127\tValidation loss: 0.406426\tBest loss: 0.399802\tAccuracy: 91.30%\n",
      "128\tValidation loss: 0.403882\tBest loss: 0.399802\tAccuracy: 91.20%\n",
      "129\tValidation loss: 0.404252\tBest loss: 0.399802\tAccuracy: 90.90%\n",
      "130\tValidation loss: 0.399141\tBest loss: 0.399141\tAccuracy: 91.00%\n",
      "131\tValidation loss: 0.396588\tBest loss: 0.396588\tAccuracy: 91.60%\n",
      "132\tValidation loss: 0.395756\tBest loss: 0.395756\tAccuracy: 91.40%\n",
      "133\tValidation loss: 0.398151\tBest loss: 0.395756\tAccuracy: 91.00%\n",
      "134\tValidation loss: 0.402121\tBest loss: 0.395756\tAccuracy: 91.10%\n",
      "135\tValidation loss: 0.404243\tBest loss: 0.395756\tAccuracy: 91.70%\n",
      "136\tValidation loss: 0.403032\tBest loss: 0.395756\tAccuracy: 91.60%\n",
      "137\tValidation loss: 0.407460\tBest loss: 0.395756\tAccuracy: 91.10%\n",
      "138\tValidation loss: 0.399899\tBest loss: 0.395756\tAccuracy: 91.40%\n",
      "139\tValidation loss: 0.407946\tBest loss: 0.395756\tAccuracy: 91.60%\n",
      "140\tValidation loss: 0.405815\tBest loss: 0.395756\tAccuracy: 91.60%\n",
      "141\tValidation loss: 0.404223\tBest loss: 0.395756\tAccuracy: 91.30%\n",
      "142\tValidation loss: 0.408540\tBest loss: 0.395756\tAccuracy: 91.90%\n",
      "143\tValidation loss: 0.403159\tBest loss: 0.395756\tAccuracy: 91.40%\n",
      "144\tValidation loss: 0.399961\tBest loss: 0.395756\tAccuracy: 91.10%\n",
      "145\tValidation loss: 0.401471\tBest loss: 0.395756\tAccuracy: 91.20%\n",
      "146\tValidation loss: 0.399817\tBest loss: 0.395756\tAccuracy: 91.70%\n",
      "147\tValidation loss: 0.402850\tBest loss: 0.395756\tAccuracy: 91.30%\n",
      "148\tValidation loss: 0.401402\tBest loss: 0.395756\tAccuracy: 91.20%\n",
      "149\tValidation loss: 0.399338\tBest loss: 0.395756\tAccuracy: 91.30%\n",
      "150\tValidation loss: 0.400468\tBest loss: 0.395756\tAccuracy: 91.60%\n",
      "151\tValidation loss: 0.401789\tBest loss: 0.395756\tAccuracy: 91.50%\n",
      "152\tValidation loss: 0.403708\tBest loss: 0.395756\tAccuracy: 91.70%\n",
      "153\tValidation loss: 0.408771\tBest loss: 0.395756\tAccuracy: 91.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  19.2s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.838642\tBest loss: 2.838642\tAccuracy: 31.90%\n",
      "1\tValidation loss: 2.275697\tBest loss: 2.275697\tAccuracy: 46.90%\n",
      "2\tValidation loss: 1.953149\tBest loss: 1.953149\tAccuracy: 49.40%\n",
      "3\tValidation loss: 1.624952\tBest loss: 1.624952\tAccuracy: 60.10%\n",
      "4\tValidation loss: 1.406670\tBest loss: 1.406670\tAccuracy: 65.00%\n",
      "5\tValidation loss: 1.304441\tBest loss: 1.304441\tAccuracy: 67.80%\n",
      "6\tValidation loss: 1.173406\tBest loss: 1.173406\tAccuracy: 70.00%\n",
      "7\tValidation loss: 1.093182\tBest loss: 1.093182\tAccuracy: 72.50%\n",
      "8\tValidation loss: 1.035699\tBest loss: 1.035699\tAccuracy: 73.20%\n",
      "9\tValidation loss: 0.982589\tBest loss: 0.982589\tAccuracy: 75.30%\n",
      "10\tValidation loss: 0.923645\tBest loss: 0.923645\tAccuracy: 78.10%\n",
      "11\tValidation loss: 0.917831\tBest loss: 0.917831\tAccuracy: 77.90%\n",
      "12\tValidation loss: 0.859914\tBest loss: 0.859914\tAccuracy: 78.20%\n",
      "13\tValidation loss: 0.831017\tBest loss: 0.831017\tAccuracy: 79.90%\n",
      "14\tValidation loss: 0.813777\tBest loss: 0.813777\tAccuracy: 80.80%\n",
      "15\tValidation loss: 0.784013\tBest loss: 0.784013\tAccuracy: 81.60%\n",
      "16\tValidation loss: 0.781579\tBest loss: 0.781579\tAccuracy: 80.30%\n",
      "17\tValidation loss: 0.738304\tBest loss: 0.738304\tAccuracy: 81.00%\n",
      "18\tValidation loss: 0.718928\tBest loss: 0.718928\tAccuracy: 82.90%\n",
      "19\tValidation loss: 0.702591\tBest loss: 0.702591\tAccuracy: 83.10%\n",
      "20\tValidation loss: 0.699108\tBest loss: 0.699108\tAccuracy: 82.60%\n",
      "21\tValidation loss: 0.683537\tBest loss: 0.683537\tAccuracy: 83.10%\n",
      "22\tValidation loss: 0.670005\tBest loss: 0.670005\tAccuracy: 84.80%\n",
      "23\tValidation loss: 0.656321\tBest loss: 0.656321\tAccuracy: 84.40%\n",
      "24\tValidation loss: 0.649428\tBest loss: 0.649428\tAccuracy: 85.40%\n",
      "25\tValidation loss: 0.648312\tBest loss: 0.648312\tAccuracy: 83.40%\n",
      "26\tValidation loss: 0.623301\tBest loss: 0.623301\tAccuracy: 85.10%\n",
      "27\tValidation loss: 0.617141\tBest loss: 0.617141\tAccuracy: 84.40%\n",
      "28\tValidation loss: 0.614991\tBest loss: 0.614991\tAccuracy: 85.20%\n",
      "29\tValidation loss: 0.616048\tBest loss: 0.614991\tAccuracy: 83.90%\n",
      "30\tValidation loss: 0.590263\tBest loss: 0.590263\tAccuracy: 85.50%\n",
      "31\tValidation loss: 0.598821\tBest loss: 0.590263\tAccuracy: 85.60%\n",
      "32\tValidation loss: 0.587237\tBest loss: 0.587237\tAccuracy: 86.10%\n",
      "33\tValidation loss: 0.575442\tBest loss: 0.575442\tAccuracy: 85.90%\n",
      "34\tValidation loss: 0.568821\tBest loss: 0.568821\tAccuracy: 86.00%\n",
      "35\tValidation loss: 0.567552\tBest loss: 0.567552\tAccuracy: 86.50%\n",
      "36\tValidation loss: 0.569291\tBest loss: 0.567552\tAccuracy: 86.40%\n",
      "37\tValidation loss: 0.544279\tBest loss: 0.544279\tAccuracy: 87.00%\n",
      "38\tValidation loss: 0.544184\tBest loss: 0.544184\tAccuracy: 87.20%\n",
      "39\tValidation loss: 0.534158\tBest loss: 0.534158\tAccuracy: 87.50%\n",
      "40\tValidation loss: 0.537926\tBest loss: 0.534158\tAccuracy: 87.10%\n",
      "41\tValidation loss: 0.518070\tBest loss: 0.518070\tAccuracy: 87.10%\n",
      "42\tValidation loss: 0.530883\tBest loss: 0.518070\tAccuracy: 87.50%\n",
      "43\tValidation loss: 0.514632\tBest loss: 0.514632\tAccuracy: 87.80%\n",
      "44\tValidation loss: 0.521179\tBest loss: 0.514632\tAccuracy: 86.10%\n",
      "45\tValidation loss: 0.515871\tBest loss: 0.514632\tAccuracy: 87.50%\n",
      "46\tValidation loss: 0.518816\tBest loss: 0.514632\tAccuracy: 87.50%\n",
      "47\tValidation loss: 0.499288\tBest loss: 0.499288\tAccuracy: 87.50%\n",
      "48\tValidation loss: 0.494362\tBest loss: 0.494362\tAccuracy: 87.80%\n",
      "49\tValidation loss: 0.496537\tBest loss: 0.494362\tAccuracy: 87.60%\n",
      "50\tValidation loss: 0.496581\tBest loss: 0.494362\tAccuracy: 87.50%\n",
      "51\tValidation loss: 0.494223\tBest loss: 0.494223\tAccuracy: 88.00%\n",
      "52\tValidation loss: 0.487048\tBest loss: 0.487048\tAccuracy: 87.90%\n",
      "53\tValidation loss: 0.486978\tBest loss: 0.486978\tAccuracy: 88.40%\n",
      "54\tValidation loss: 0.478662\tBest loss: 0.478662\tAccuracy: 88.70%\n",
      "55\tValidation loss: 0.485809\tBest loss: 0.478662\tAccuracy: 88.00%\n",
      "56\tValidation loss: 0.478007\tBest loss: 0.478007\tAccuracy: 88.20%\n",
      "57\tValidation loss: 0.471901\tBest loss: 0.471901\tAccuracy: 88.40%\n",
      "58\tValidation loss: 0.473311\tBest loss: 0.471901\tAccuracy: 88.50%\n",
      "59\tValidation loss: 0.472904\tBest loss: 0.471901\tAccuracy: 87.90%\n",
      "60\tValidation loss: 0.465250\tBest loss: 0.465250\tAccuracy: 88.00%\n",
      "61\tValidation loss: 0.469938\tBest loss: 0.465250\tAccuracy: 88.20%\n",
      "62\tValidation loss: 0.466990\tBest loss: 0.465250\tAccuracy: 89.50%\n",
      "63\tValidation loss: 0.457405\tBest loss: 0.457405\tAccuracy: 88.60%\n",
      "64\tValidation loss: 0.448921\tBest loss: 0.448921\tAccuracy: 88.50%\n",
      "65\tValidation loss: 0.457196\tBest loss: 0.448921\tAccuracy: 89.10%\n",
      "66\tValidation loss: 0.449808\tBest loss: 0.448921\tAccuracy: 89.00%\n",
      "67\tValidation loss: 0.453603\tBest loss: 0.448921\tAccuracy: 89.40%\n",
      "68\tValidation loss: 0.447243\tBest loss: 0.447243\tAccuracy: 89.40%\n",
      "69\tValidation loss: 0.443272\tBest loss: 0.443272\tAccuracy: 89.20%\n",
      "70\tValidation loss: 0.451412\tBest loss: 0.443272\tAccuracy: 89.00%\n",
      "71\tValidation loss: 0.446238\tBest loss: 0.443272\tAccuracy: 89.30%\n",
      "72\tValidation loss: 0.434976\tBest loss: 0.434976\tAccuracy: 88.90%\n",
      "73\tValidation loss: 0.439310\tBest loss: 0.434976\tAccuracy: 89.70%\n",
      "74\tValidation loss: 0.441794\tBest loss: 0.434976\tAccuracy: 89.30%\n",
      "75\tValidation loss: 0.442695\tBest loss: 0.434976\tAccuracy: 89.20%\n",
      "76\tValidation loss: 0.432976\tBest loss: 0.432976\tAccuracy: 89.50%\n",
      "77\tValidation loss: 0.439197\tBest loss: 0.432976\tAccuracy: 89.00%\n",
      "78\tValidation loss: 0.431292\tBest loss: 0.431292\tAccuracy: 89.90%\n",
      "79\tValidation loss: 0.436491\tBest loss: 0.431292\tAccuracy: 89.60%\n",
      "80\tValidation loss: 0.434610\tBest loss: 0.431292\tAccuracy: 89.20%\n",
      "81\tValidation loss: 0.428087\tBest loss: 0.428087\tAccuracy: 89.40%\n",
      "82\tValidation loss: 0.426537\tBest loss: 0.426537\tAccuracy: 89.40%\n",
      "83\tValidation loss: 0.432054\tBest loss: 0.426537\tAccuracy: 89.90%\n",
      "84\tValidation loss: 0.423987\tBest loss: 0.423987\tAccuracy: 90.10%\n",
      "85\tValidation loss: 0.427762\tBest loss: 0.423987\tAccuracy: 89.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\tValidation loss: 0.424804\tBest loss: 0.423987\tAccuracy: 89.90%\n",
      "87\tValidation loss: 0.426919\tBest loss: 0.423987\tAccuracy: 89.60%\n",
      "88\tValidation loss: 0.412260\tBest loss: 0.412260\tAccuracy: 90.00%\n",
      "89\tValidation loss: 0.415797\tBest loss: 0.412260\tAccuracy: 90.40%\n",
      "90\tValidation loss: 0.406129\tBest loss: 0.406129\tAccuracy: 90.30%\n",
      "91\tValidation loss: 0.418957\tBest loss: 0.406129\tAccuracy: 90.00%\n",
      "92\tValidation loss: 0.422091\tBest loss: 0.406129\tAccuracy: 89.40%\n",
      "93\tValidation loss: 0.409238\tBest loss: 0.406129\tAccuracy: 90.40%\n",
      "94\tValidation loss: 0.415507\tBest loss: 0.406129\tAccuracy: 90.00%\n",
      "95\tValidation loss: 0.400393\tBest loss: 0.400393\tAccuracy: 90.10%\n",
      "96\tValidation loss: 0.405779\tBest loss: 0.400393\tAccuracy: 90.30%\n",
      "97\tValidation loss: 0.412394\tBest loss: 0.400393\tAccuracy: 90.50%\n",
      "98\tValidation loss: 0.405298\tBest loss: 0.400393\tAccuracy: 90.00%\n",
      "99\tValidation loss: 0.401482\tBest loss: 0.400393\tAccuracy: 90.10%\n",
      "100\tValidation loss: 0.417011\tBest loss: 0.400393\tAccuracy: 90.20%\n",
      "101\tValidation loss: 0.400731\tBest loss: 0.400393\tAccuracy: 90.20%\n",
      "102\tValidation loss: 0.398409\tBest loss: 0.398409\tAccuracy: 90.60%\n",
      "103\tValidation loss: 0.398079\tBest loss: 0.398079\tAccuracy: 90.70%\n",
      "104\tValidation loss: 0.407949\tBest loss: 0.398079\tAccuracy: 90.40%\n",
      "105\tValidation loss: 0.410635\tBest loss: 0.398079\tAccuracy: 89.90%\n",
      "106\tValidation loss: 0.396418\tBest loss: 0.396418\tAccuracy: 90.00%\n",
      "107\tValidation loss: 0.403080\tBest loss: 0.396418\tAccuracy: 90.10%\n",
      "108\tValidation loss: 0.403254\tBest loss: 0.396418\tAccuracy: 90.60%\n",
      "109\tValidation loss: 0.395171\tBest loss: 0.395171\tAccuracy: 90.70%\n",
      "110\tValidation loss: 0.400775\tBest loss: 0.395171\tAccuracy: 90.50%\n",
      "111\tValidation loss: 0.408895\tBest loss: 0.395171\tAccuracy: 90.60%\n",
      "112\tValidation loss: 0.400824\tBest loss: 0.395171\tAccuracy: 90.50%\n",
      "113\tValidation loss: 0.393091\tBest loss: 0.393091\tAccuracy: 90.20%\n",
      "114\tValidation loss: 0.408154\tBest loss: 0.393091\tAccuracy: 90.60%\n",
      "115\tValidation loss: 0.390351\tBest loss: 0.390351\tAccuracy: 90.90%\n",
      "116\tValidation loss: 0.399870\tBest loss: 0.390351\tAccuracy: 90.50%\n",
      "117\tValidation loss: 0.388693\tBest loss: 0.388693\tAccuracy: 91.00%\n",
      "118\tValidation loss: 0.382626\tBest loss: 0.382626\tAccuracy: 90.90%\n",
      "119\tValidation loss: 0.395222\tBest loss: 0.382626\tAccuracy: 90.80%\n",
      "120\tValidation loss: 0.386241\tBest loss: 0.382626\tAccuracy: 91.10%\n",
      "121\tValidation loss: 0.387482\tBest loss: 0.382626\tAccuracy: 91.10%\n",
      "122\tValidation loss: 0.392276\tBest loss: 0.382626\tAccuracy: 90.80%\n",
      "123\tValidation loss: 0.392050\tBest loss: 0.382626\tAccuracy: 91.10%\n",
      "124\tValidation loss: 0.388378\tBest loss: 0.382626\tAccuracy: 91.40%\n",
      "125\tValidation loss: 0.391411\tBest loss: 0.382626\tAccuracy: 90.90%\n",
      "126\tValidation loss: 0.392514\tBest loss: 0.382626\tAccuracy: 90.60%\n",
      "127\tValidation loss: 0.401912\tBest loss: 0.382626\tAccuracy: 91.20%\n",
      "128\tValidation loss: 0.383407\tBest loss: 0.382626\tAccuracy: 91.10%\n",
      "129\tValidation loss: 0.384626\tBest loss: 0.382626\tAccuracy: 91.00%\n",
      "130\tValidation loss: 0.379079\tBest loss: 0.379079\tAccuracy: 91.00%\n",
      "131\tValidation loss: 0.387224\tBest loss: 0.379079\tAccuracy: 91.50%\n",
      "132\tValidation loss: 0.382328\tBest loss: 0.379079\tAccuracy: 91.20%\n",
      "133\tValidation loss: 0.388722\tBest loss: 0.379079\tAccuracy: 90.60%\n",
      "134\tValidation loss: 0.382074\tBest loss: 0.379079\tAccuracy: 91.00%\n",
      "135\tValidation loss: 0.386228\tBest loss: 0.379079\tAccuracy: 91.00%\n",
      "136\tValidation loss: 0.382392\tBest loss: 0.379079\tAccuracy: 91.00%\n",
      "137\tValidation loss: 0.394716\tBest loss: 0.379079\tAccuracy: 91.10%\n",
      "138\tValidation loss: 0.386248\tBest loss: 0.379079\tAccuracy: 91.40%\n",
      "139\tValidation loss: 0.375085\tBest loss: 0.375085\tAccuracy: 91.30%\n",
      "140\tValidation loss: 0.389040\tBest loss: 0.375085\tAccuracy: 91.00%\n",
      "141\tValidation loss: 0.380423\tBest loss: 0.375085\tAccuracy: 91.70%\n",
      "142\tValidation loss: 0.365686\tBest loss: 0.365686\tAccuracy: 91.70%\n",
      "143\tValidation loss: 0.380293\tBest loss: 0.365686\tAccuracy: 91.30%\n",
      "144\tValidation loss: 0.374116\tBest loss: 0.365686\tAccuracy: 91.90%\n",
      "145\tValidation loss: 0.378074\tBest loss: 0.365686\tAccuracy: 91.70%\n",
      "146\tValidation loss: 0.380715\tBest loss: 0.365686\tAccuracy: 91.60%\n",
      "147\tValidation loss: 0.386022\tBest loss: 0.365686\tAccuracy: 91.10%\n",
      "148\tValidation loss: 0.375481\tBest loss: 0.365686\tAccuracy: 91.20%\n",
      "149\tValidation loss: 0.381340\tBest loss: 0.365686\tAccuracy: 91.10%\n",
      "150\tValidation loss: 0.376312\tBest loss: 0.365686\tAccuracy: 92.20%\n",
      "151\tValidation loss: 0.367915\tBest loss: 0.365686\tAccuracy: 91.70%\n",
      "152\tValidation loss: 0.378101\tBest loss: 0.365686\tAccuracy: 91.60%\n",
      "153\tValidation loss: 0.375509\tBest loss: 0.365686\tAccuracy: 91.60%\n",
      "154\tValidation loss: 0.379945\tBest loss: 0.365686\tAccuracy: 91.10%\n",
      "155\tValidation loss: 0.373640\tBest loss: 0.365686\tAccuracy: 91.80%\n",
      "156\tValidation loss: 0.373546\tBest loss: 0.365686\tAccuracy: 91.30%\n",
      "157\tValidation loss: 0.372501\tBest loss: 0.365686\tAccuracy: 91.60%\n",
      "158\tValidation loss: 0.372988\tBest loss: 0.365686\tAccuracy: 91.70%\n",
      "159\tValidation loss: 0.376289\tBest loss: 0.365686\tAccuracy: 91.70%\n",
      "160\tValidation loss: 0.372498\tBest loss: 0.365686\tAccuracy: 91.90%\n",
      "161\tValidation loss: 0.368824\tBest loss: 0.365686\tAccuracy: 91.60%\n",
      "162\tValidation loss: 0.372879\tBest loss: 0.365686\tAccuracy: 91.40%\n",
      "163\tValidation loss: 0.369740\tBest loss: 0.365686\tAccuracy: 92.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  21.2s\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.050834\tBest loss: 2.050834\tAccuracy: 48.50%\n",
      "1\tValidation loss: 1.608720\tBest loss: 1.608720\tAccuracy: 61.40%\n",
      "2\tValidation loss: 1.392314\tBest loss: 1.392314\tAccuracy: 67.10%\n",
      "3\tValidation loss: 1.245005\tBest loss: 1.245005\tAccuracy: 69.90%\n",
      "4\tValidation loss: 1.136688\tBest loss: 1.136688\tAccuracy: 73.30%\n",
      "5\tValidation loss: 1.057835\tBest loss: 1.057835\tAccuracy: 75.00%\n",
      "6\tValidation loss: 0.998160\tBest loss: 0.998160\tAccuracy: 76.70%\n",
      "7\tValidation loss: 0.952550\tBest loss: 0.952550\tAccuracy: 77.40%\n",
      "8\tValidation loss: 0.919819\tBest loss: 0.919819\tAccuracy: 78.50%\n",
      "9\tValidation loss: 0.883766\tBest loss: 0.883766\tAccuracy: 79.40%\n",
      "10\tValidation loss: 0.856683\tBest loss: 0.856683\tAccuracy: 80.80%\n",
      "11\tValidation loss: 0.828133\tBest loss: 0.828133\tAccuracy: 81.40%\n",
      "12\tValidation loss: 0.805014\tBest loss: 0.805014\tAccuracy: 81.10%\n",
      "13\tValidation loss: 0.779511\tBest loss: 0.779511\tAccuracy: 81.90%\n",
      "14\tValidation loss: 0.773128\tBest loss: 0.773128\tAccuracy: 82.10%\n",
      "15\tValidation loss: 0.750461\tBest loss: 0.750461\tAccuracy: 82.80%\n",
      "16\tValidation loss: 0.735127\tBest loss: 0.735127\tAccuracy: 83.10%\n",
      "17\tValidation loss: 0.721929\tBest loss: 0.721929\tAccuracy: 82.80%\n",
      "18\tValidation loss: 0.710713\tBest loss: 0.710713\tAccuracy: 84.20%\n",
      "19\tValidation loss: 0.690211\tBest loss: 0.690211\tAccuracy: 84.50%\n",
      "20\tValidation loss: 0.679770\tBest loss: 0.679770\tAccuracy: 84.10%\n",
      "21\tValidation loss: 0.672709\tBest loss: 0.672709\tAccuracy: 84.30%\n",
      "22\tValidation loss: 0.661787\tBest loss: 0.661787\tAccuracy: 85.00%\n",
      "23\tValidation loss: 0.651934\tBest loss: 0.651934\tAccuracy: 85.40%\n",
      "24\tValidation loss: 0.648074\tBest loss: 0.648074\tAccuracy: 85.40%\n",
      "25\tValidation loss: 0.640743\tBest loss: 0.640743\tAccuracy: 85.20%\n",
      "26\tValidation loss: 0.636118\tBest loss: 0.636118\tAccuracy: 84.90%\n",
      "27\tValidation loss: 0.628954\tBest loss: 0.628954\tAccuracy: 85.80%\n",
      "28\tValidation loss: 0.621956\tBest loss: 0.621956\tAccuracy: 85.70%\n",
      "29\tValidation loss: 0.619086\tBest loss: 0.619086\tAccuracy: 85.90%\n",
      "30\tValidation loss: 0.610570\tBest loss: 0.610570\tAccuracy: 86.40%\n",
      "31\tValidation loss: 0.596481\tBest loss: 0.596481\tAccuracy: 86.00%\n",
      "32\tValidation loss: 0.591651\tBest loss: 0.591651\tAccuracy: 85.50%\n",
      "33\tValidation loss: 0.591054\tBest loss: 0.591054\tAccuracy: 86.00%\n",
      "34\tValidation loss: 0.584681\tBest loss: 0.584681\tAccuracy: 86.30%\n",
      "35\tValidation loss: 0.576934\tBest loss: 0.576934\tAccuracy: 86.60%\n",
      "36\tValidation loss: 0.569614\tBest loss: 0.569614\tAccuracy: 87.10%\n",
      "37\tValidation loss: 0.571293\tBest loss: 0.569614\tAccuracy: 86.00%\n",
      "38\tValidation loss: 0.567952\tBest loss: 0.567952\tAccuracy: 86.70%\n",
      "39\tValidation loss: 0.562945\tBest loss: 0.562945\tAccuracy: 86.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\tValidation loss: 0.560090\tBest loss: 0.560090\tAccuracy: 87.30%\n",
      "41\tValidation loss: 0.557146\tBest loss: 0.557146\tAccuracy: 87.00%\n",
      "42\tValidation loss: 0.549209\tBest loss: 0.549209\tAccuracy: 86.60%\n",
      "43\tValidation loss: 0.543955\tBest loss: 0.543955\tAccuracy: 87.00%\n",
      "44\tValidation loss: 0.545854\tBest loss: 0.543955\tAccuracy: 86.70%\n",
      "45\tValidation loss: 0.530905\tBest loss: 0.530905\tAccuracy: 87.60%\n",
      "46\tValidation loss: 0.534541\tBest loss: 0.530905\tAccuracy: 87.20%\n",
      "47\tValidation loss: 0.532177\tBest loss: 0.530905\tAccuracy: 87.50%\n",
      "48\tValidation loss: 0.527878\tBest loss: 0.527878\tAccuracy: 87.60%\n",
      "49\tValidation loss: 0.534213\tBest loss: 0.527878\tAccuracy: 87.60%\n",
      "50\tValidation loss: 0.527097\tBest loss: 0.527097\tAccuracy: 88.10%\n",
      "51\tValidation loss: 0.526512\tBest loss: 0.526512\tAccuracy: 87.50%\n",
      "52\tValidation loss: 0.514987\tBest loss: 0.514987\tAccuracy: 87.90%\n",
      "53\tValidation loss: 0.520897\tBest loss: 0.514987\tAccuracy: 88.00%\n",
      "54\tValidation loss: 0.509965\tBest loss: 0.509965\tAccuracy: 87.70%\n",
      "55\tValidation loss: 0.510129\tBest loss: 0.509965\tAccuracy: 87.90%\n",
      "56\tValidation loss: 0.515016\tBest loss: 0.509965\tAccuracy: 87.70%\n",
      "57\tValidation loss: 0.507080\tBest loss: 0.507080\tAccuracy: 88.00%\n",
      "58\tValidation loss: 0.506242\tBest loss: 0.506242\tAccuracy: 88.20%\n",
      "59\tValidation loss: 0.502448\tBest loss: 0.502448\tAccuracy: 88.00%\n",
      "60\tValidation loss: 0.495570\tBest loss: 0.495570\tAccuracy: 88.20%\n",
      "61\tValidation loss: 0.495466\tBest loss: 0.495466\tAccuracy: 88.10%\n",
      "62\tValidation loss: 0.492015\tBest loss: 0.492015\tAccuracy: 88.50%\n",
      "63\tValidation loss: 0.490256\tBest loss: 0.490256\tAccuracy: 87.50%\n",
      "64\tValidation loss: 0.489043\tBest loss: 0.489043\tAccuracy: 87.80%\n",
      "65\tValidation loss: 0.487633\tBest loss: 0.487633\tAccuracy: 88.80%\n",
      "66\tValidation loss: 0.485429\tBest loss: 0.485429\tAccuracy: 88.10%\n",
      "67\tValidation loss: 0.484044\tBest loss: 0.484044\tAccuracy: 88.20%\n",
      "68\tValidation loss: 0.483611\tBest loss: 0.483611\tAccuracy: 87.70%\n",
      "69\tValidation loss: 0.477956\tBest loss: 0.477956\tAccuracy: 88.20%\n",
      "70\tValidation loss: 0.483833\tBest loss: 0.477956\tAccuracy: 88.10%\n",
      "71\tValidation loss: 0.477677\tBest loss: 0.477677\tAccuracy: 88.30%\n",
      "72\tValidation loss: 0.472813\tBest loss: 0.472813\tAccuracy: 88.20%\n",
      "73\tValidation loss: 0.473744\tBest loss: 0.472813\tAccuracy: 88.10%\n",
      "74\tValidation loss: 0.478217\tBest loss: 0.472813\tAccuracy: 87.50%\n",
      "75\tValidation loss: 0.470978\tBest loss: 0.470978\tAccuracy: 88.40%\n",
      "76\tValidation loss: 0.470605\tBest loss: 0.470605\tAccuracy: 88.20%\n",
      "77\tValidation loss: 0.470353\tBest loss: 0.470353\tAccuracy: 87.60%\n",
      "78\tValidation loss: 0.464002\tBest loss: 0.464002\tAccuracy: 88.10%\n",
      "79\tValidation loss: 0.460080\tBest loss: 0.460080\tAccuracy: 88.20%\n",
      "80\tValidation loss: 0.467731\tBest loss: 0.460080\tAccuracy: 88.40%\n",
      "81\tValidation loss: 0.458874\tBest loss: 0.458874\tAccuracy: 89.30%\n",
      "82\tValidation loss: 0.463673\tBest loss: 0.458874\tAccuracy: 88.80%\n",
      "83\tValidation loss: 0.454091\tBest loss: 0.454091\tAccuracy: 88.80%\n",
      "84\tValidation loss: 0.456903\tBest loss: 0.454091\tAccuracy: 89.00%\n",
      "85\tValidation loss: 0.451801\tBest loss: 0.451801\tAccuracy: 89.10%\n",
      "86\tValidation loss: 0.454716\tBest loss: 0.451801\tAccuracy: 88.60%\n",
      "87\tValidation loss: 0.454252\tBest loss: 0.451801\tAccuracy: 88.30%\n",
      "88\tValidation loss: 0.452470\tBest loss: 0.451801\tAccuracy: 88.90%\n",
      "89\tValidation loss: 0.453009\tBest loss: 0.451801\tAccuracy: 88.40%\n",
      "90\tValidation loss: 0.451413\tBest loss: 0.451413\tAccuracy: 88.40%\n",
      "91\tValidation loss: 0.445283\tBest loss: 0.445283\tAccuracy: 88.90%\n",
      "92\tValidation loss: 0.449750\tBest loss: 0.445283\tAccuracy: 89.00%\n",
      "93\tValidation loss: 0.445647\tBest loss: 0.445283\tAccuracy: 88.40%\n",
      "94\tValidation loss: 0.447596\tBest loss: 0.445283\tAccuracy: 89.00%\n",
      "95\tValidation loss: 0.441058\tBest loss: 0.441058\tAccuracy: 89.20%\n",
      "96\tValidation loss: 0.441047\tBest loss: 0.441047\tAccuracy: 88.40%\n",
      "97\tValidation loss: 0.441188\tBest loss: 0.441047\tAccuracy: 89.70%\n",
      "98\tValidation loss: 0.440042\tBest loss: 0.440042\tAccuracy: 88.80%\n",
      "99\tValidation loss: 0.440190\tBest loss: 0.440042\tAccuracy: 89.30%\n",
      "100\tValidation loss: 0.438826\tBest loss: 0.438826\tAccuracy: 89.50%\n",
      "101\tValidation loss: 0.431951\tBest loss: 0.431951\tAccuracy: 89.00%\n",
      "102\tValidation loss: 0.432623\tBest loss: 0.431951\tAccuracy: 89.40%\n",
      "103\tValidation loss: 0.434165\tBest loss: 0.431951\tAccuracy: 88.90%\n",
      "104\tValidation loss: 0.434018\tBest loss: 0.431951\tAccuracy: 89.80%\n",
      "105\tValidation loss: 0.432106\tBest loss: 0.431951\tAccuracy: 89.50%\n",
      "106\tValidation loss: 0.432001\tBest loss: 0.431951\tAccuracy: 89.00%\n",
      "107\tValidation loss: 0.431531\tBest loss: 0.431531\tAccuracy: 89.70%\n",
      "108\tValidation loss: 0.431837\tBest loss: 0.431531\tAccuracy: 88.80%\n",
      "109\tValidation loss: 0.428800\tBest loss: 0.428800\tAccuracy: 89.20%\n",
      "110\tValidation loss: 0.427666\tBest loss: 0.427666\tAccuracy: 89.40%\n",
      "111\tValidation loss: 0.426373\tBest loss: 0.426373\tAccuracy: 89.50%\n",
      "112\tValidation loss: 0.425062\tBest loss: 0.425062\tAccuracy: 89.60%\n",
      "113\tValidation loss: 0.420580\tBest loss: 0.420580\tAccuracy: 89.30%\n",
      "114\tValidation loss: 0.423213\tBest loss: 0.420580\tAccuracy: 89.40%\n",
      "115\tValidation loss: 0.425602\tBest loss: 0.420580\tAccuracy: 89.10%\n",
      "116\tValidation loss: 0.421089\tBest loss: 0.420580\tAccuracy: 89.30%\n",
      "117\tValidation loss: 0.418650\tBest loss: 0.418650\tAccuracy: 89.80%\n",
      "118\tValidation loss: 0.419371\tBest loss: 0.418650\tAccuracy: 89.50%\n",
      "119\tValidation loss: 0.420609\tBest loss: 0.418650\tAccuracy: 89.00%\n",
      "120\tValidation loss: 0.418757\tBest loss: 0.418650\tAccuracy: 89.70%\n",
      "121\tValidation loss: 0.420789\tBest loss: 0.418650\tAccuracy: 89.00%\n",
      "122\tValidation loss: 0.419188\tBest loss: 0.418650\tAccuracy: 89.90%\n",
      "123\tValidation loss: 0.418965\tBest loss: 0.418650\tAccuracy: 89.40%\n",
      "124\tValidation loss: 0.416788\tBest loss: 0.416788\tAccuracy: 90.00%\n",
      "125\tValidation loss: 0.414614\tBest loss: 0.414614\tAccuracy: 90.60%\n",
      "126\tValidation loss: 0.414794\tBest loss: 0.414614\tAccuracy: 90.00%\n",
      "127\tValidation loss: 0.416785\tBest loss: 0.414614\tAccuracy: 90.20%\n",
      "128\tValidation loss: 0.409667\tBest loss: 0.409667\tAccuracy: 89.60%\n",
      "129\tValidation loss: 0.412076\tBest loss: 0.409667\tAccuracy: 89.60%\n",
      "130\tValidation loss: 0.415584\tBest loss: 0.409667\tAccuracy: 89.70%\n",
      "131\tValidation loss: 0.409943\tBest loss: 0.409667\tAccuracy: 90.00%\n",
      "132\tValidation loss: 0.411637\tBest loss: 0.409667\tAccuracy: 89.70%\n",
      "133\tValidation loss: 0.412840\tBest loss: 0.409667\tAccuracy: 89.60%\n",
      "134\tValidation loss: 0.412214\tBest loss: 0.409667\tAccuracy: 90.00%\n",
      "135\tValidation loss: 0.409973\tBest loss: 0.409667\tAccuracy: 89.70%\n",
      "136\tValidation loss: 0.406045\tBest loss: 0.406045\tAccuracy: 90.10%\n",
      "137\tValidation loss: 0.406457\tBest loss: 0.406045\tAccuracy: 89.60%\n",
      "138\tValidation loss: 0.402766\tBest loss: 0.402766\tAccuracy: 90.20%\n",
      "139\tValidation loss: 0.402673\tBest loss: 0.402673\tAccuracy: 90.30%\n",
      "140\tValidation loss: 0.405349\tBest loss: 0.402673\tAccuracy: 90.20%\n",
      "141\tValidation loss: 0.405800\tBest loss: 0.402673\tAccuracy: 90.20%\n",
      "142\tValidation loss: 0.405552\tBest loss: 0.402673\tAccuracy: 90.10%\n",
      "143\tValidation loss: 0.399374\tBest loss: 0.399374\tAccuracy: 90.60%\n",
      "144\tValidation loss: 0.400599\tBest loss: 0.399374\tAccuracy: 90.40%\n",
      "145\tValidation loss: 0.400631\tBest loss: 0.399374\tAccuracy: 90.20%\n",
      "146\tValidation loss: 0.397629\tBest loss: 0.397629\tAccuracy: 90.40%\n",
      "147\tValidation loss: 0.400007\tBest loss: 0.397629\tAccuracy: 90.30%\n",
      "148\tValidation loss: 0.401287\tBest loss: 0.397629\tAccuracy: 90.40%\n",
      "149\tValidation loss: 0.398090\tBest loss: 0.397629\tAccuracy: 90.60%\n",
      "150\tValidation loss: 0.398441\tBest loss: 0.397629\tAccuracy: 90.20%\n",
      "151\tValidation loss: 0.400061\tBest loss: 0.397629\tAccuracy: 89.90%\n",
      "152\tValidation loss: 0.396270\tBest loss: 0.396270\tAccuracy: 90.40%\n",
      "153\tValidation loss: 0.395236\tBest loss: 0.395236\tAccuracy: 90.60%\n",
      "154\tValidation loss: 0.397378\tBest loss: 0.395236\tAccuracy: 90.50%\n",
      "155\tValidation loss: 0.394109\tBest loss: 0.394109\tAccuracy: 90.30%\n",
      "156\tValidation loss: 0.397150\tBest loss: 0.394109\tAccuracy: 90.30%\n",
      "157\tValidation loss: 0.400841\tBest loss: 0.394109\tAccuracy: 90.20%\n",
      "158\tValidation loss: 0.393576\tBest loss: 0.393576\tAccuracy: 90.10%\n",
      "159\tValidation loss: 0.393311\tBest loss: 0.393311\tAccuracy: 90.80%\n",
      "160\tValidation loss: 0.397720\tBest loss: 0.393311\tAccuracy: 90.10%\n",
      "161\tValidation loss: 0.396524\tBest loss: 0.393311\tAccuracy: 90.20%\n",
      "162\tValidation loss: 0.392850\tBest loss: 0.392850\tAccuracy: 90.20%\n",
      "163\tValidation loss: 0.390786\tBest loss: 0.390786\tAccuracy: 90.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\tValidation loss: 0.388667\tBest loss: 0.388667\tAccuracy: 90.60%\n",
      "165\tValidation loss: 0.391304\tBest loss: 0.388667\tAccuracy: 90.20%\n",
      "166\tValidation loss: 0.390661\tBest loss: 0.388667\tAccuracy: 90.40%\n",
      "167\tValidation loss: 0.388441\tBest loss: 0.388441\tAccuracy: 90.70%\n",
      "168\tValidation loss: 0.390557\tBest loss: 0.388441\tAccuracy: 90.60%\n",
      "169\tValidation loss: 0.387453\tBest loss: 0.387453\tAccuracy: 90.80%\n",
      "170\tValidation loss: 0.388127\tBest loss: 0.387453\tAccuracy: 90.80%\n",
      "171\tValidation loss: 0.387594\tBest loss: 0.387453\tAccuracy: 90.70%\n",
      "172\tValidation loss: 0.386187\tBest loss: 0.386187\tAccuracy: 90.50%\n",
      "173\tValidation loss: 0.389499\tBest loss: 0.386187\tAccuracy: 90.60%\n",
      "174\tValidation loss: 0.384926\tBest loss: 0.384926\tAccuracy: 90.40%\n",
      "175\tValidation loss: 0.384756\tBest loss: 0.384756\tAccuracy: 90.80%\n",
      "176\tValidation loss: 0.390077\tBest loss: 0.384756\tAccuracy: 90.40%\n",
      "177\tValidation loss: 0.386548\tBest loss: 0.384756\tAccuracy: 90.50%\n",
      "178\tValidation loss: 0.385279\tBest loss: 0.384756\tAccuracy: 90.70%\n",
      "179\tValidation loss: 0.385068\tBest loss: 0.384756\tAccuracy: 90.70%\n",
      "180\tValidation loss: 0.384389\tBest loss: 0.384389\tAccuracy: 90.80%\n",
      "181\tValidation loss: 0.381938\tBest loss: 0.381938\tAccuracy: 90.40%\n",
      "182\tValidation loss: 0.384505\tBest loss: 0.381938\tAccuracy: 91.20%\n",
      "183\tValidation loss: 0.384625\tBest loss: 0.381938\tAccuracy: 90.80%\n",
      "184\tValidation loss: 0.385648\tBest loss: 0.381938\tAccuracy: 90.40%\n",
      "185\tValidation loss: 0.382797\tBest loss: 0.381938\tAccuracy: 90.60%\n",
      "186\tValidation loss: 0.380525\tBest loss: 0.380525\tAccuracy: 90.90%\n",
      "187\tValidation loss: 0.379800\tBest loss: 0.379800\tAccuracy: 90.90%\n",
      "188\tValidation loss: 0.380342\tBest loss: 0.379800\tAccuracy: 91.00%\n",
      "189\tValidation loss: 0.381441\tBest loss: 0.379800\tAccuracy: 90.90%\n",
      "190\tValidation loss: 0.379906\tBest loss: 0.379800\tAccuracy: 90.80%\n",
      "191\tValidation loss: 0.377834\tBest loss: 0.377834\tAccuracy: 90.90%\n",
      "192\tValidation loss: 0.378295\tBest loss: 0.377834\tAccuracy: 90.60%\n",
      "193\tValidation loss: 0.377795\tBest loss: 0.377795\tAccuracy: 90.80%\n",
      "194\tValidation loss: 0.378191\tBest loss: 0.377795\tAccuracy: 90.70%\n",
      "195\tValidation loss: 0.376790\tBest loss: 0.376790\tAccuracy: 90.70%\n",
      "196\tValidation loss: 0.379934\tBest loss: 0.376790\tAccuracy: 91.20%\n",
      "197\tValidation loss: 0.375971\tBest loss: 0.375971\tAccuracy: 90.60%\n",
      "198\tValidation loss: 0.377161\tBest loss: 0.375971\tAccuracy: 90.80%\n",
      "199\tValidation loss: 0.375986\tBest loss: 0.375971\tAccuracy: 91.10%\n",
      "200\tValidation loss: 0.380001\tBest loss: 0.375971\tAccuracy: 90.80%\n",
      "201\tValidation loss: 0.377501\tBest loss: 0.375971\tAccuracy: 91.00%\n",
      "202\tValidation loss: 0.376193\tBest loss: 0.375971\tAccuracy: 91.00%\n",
      "203\tValidation loss: 0.375222\tBest loss: 0.375222\tAccuracy: 90.90%\n",
      "204\tValidation loss: 0.377229\tBest loss: 0.375222\tAccuracy: 90.60%\n",
      "205\tValidation loss: 0.373861\tBest loss: 0.373861\tAccuracy: 91.10%\n",
      "206\tValidation loss: 0.371032\tBest loss: 0.371032\tAccuracy: 91.00%\n",
      "207\tValidation loss: 0.375416\tBest loss: 0.371032\tAccuracy: 91.20%\n",
      "208\tValidation loss: 0.374619\tBest loss: 0.371032\tAccuracy: 90.80%\n",
      "209\tValidation loss: 0.369629\tBest loss: 0.369629\tAccuracy: 91.00%\n",
      "210\tValidation loss: 0.369732\tBest loss: 0.369629\tAccuracy: 90.80%\n",
      "211\tValidation loss: 0.371822\tBest loss: 0.369629\tAccuracy: 91.30%\n",
      "212\tValidation loss: 0.371145\tBest loss: 0.369629\tAccuracy: 91.50%\n",
      "213\tValidation loss: 0.370616\tBest loss: 0.369629\tAccuracy: 91.40%\n",
      "214\tValidation loss: 0.368938\tBest loss: 0.368938\tAccuracy: 91.20%\n",
      "215\tValidation loss: 0.369697\tBest loss: 0.368938\tAccuracy: 90.90%\n",
      "216\tValidation loss: 0.366837\tBest loss: 0.366837\tAccuracy: 91.00%\n",
      "217\tValidation loss: 0.367716\tBest loss: 0.366837\tAccuracy: 91.40%\n",
      "218\tValidation loss: 0.368185\tBest loss: 0.366837\tAccuracy: 91.10%\n",
      "219\tValidation loss: 0.369181\tBest loss: 0.366837\tAccuracy: 91.20%\n",
      "220\tValidation loss: 0.370698\tBest loss: 0.366837\tAccuracy: 91.20%\n",
      "221\tValidation loss: 0.370603\tBest loss: 0.366837\tAccuracy: 91.20%\n",
      "222\tValidation loss: 0.369096\tBest loss: 0.366837\tAccuracy: 91.00%\n",
      "223\tValidation loss: 0.368232\tBest loss: 0.366837\tAccuracy: 91.30%\n",
      "224\tValidation loss: 0.366714\tBest loss: 0.366714\tAccuracy: 91.40%\n",
      "225\tValidation loss: 0.366060\tBest loss: 0.366060\tAccuracy: 91.60%\n",
      "226\tValidation loss: 0.366311\tBest loss: 0.366060\tAccuracy: 91.70%\n",
      "227\tValidation loss: 0.364493\tBest loss: 0.364493\tAccuracy: 91.20%\n",
      "228\tValidation loss: 0.365118\tBest loss: 0.364493\tAccuracy: 91.50%\n",
      "229\tValidation loss: 0.368156\tBest loss: 0.364493\tAccuracy: 91.40%\n",
      "230\tValidation loss: 0.365425\tBest loss: 0.364493\tAccuracy: 91.20%\n",
      "231\tValidation loss: 0.366282\tBest loss: 0.364493\tAccuracy: 91.10%\n",
      "232\tValidation loss: 0.367012\tBest loss: 0.364493\tAccuracy: 90.90%\n",
      "233\tValidation loss: 0.366162\tBest loss: 0.364493\tAccuracy: 91.30%\n",
      "234\tValidation loss: 0.363370\tBest loss: 0.363370\tAccuracy: 91.40%\n",
      "235\tValidation loss: 0.362369\tBest loss: 0.362369\tAccuracy: 91.70%\n",
      "236\tValidation loss: 0.365905\tBest loss: 0.362369\tAccuracy: 91.40%\n",
      "237\tValidation loss: 0.362190\tBest loss: 0.362190\tAccuracy: 91.30%\n",
      "238\tValidation loss: 0.363603\tBest loss: 0.362190\tAccuracy: 91.40%\n",
      "239\tValidation loss: 0.360943\tBest loss: 0.360943\tAccuracy: 91.20%\n",
      "240\tValidation loss: 0.362030\tBest loss: 0.360943\tAccuracy: 91.40%\n",
      "241\tValidation loss: 0.361154\tBest loss: 0.360943\tAccuracy: 91.70%\n",
      "242\tValidation loss: 0.360696\tBest loss: 0.360696\tAccuracy: 91.30%\n",
      "243\tValidation loss: 0.360324\tBest loss: 0.360324\tAccuracy: 91.70%\n",
      "244\tValidation loss: 0.363131\tBest loss: 0.360324\tAccuracy: 91.30%\n",
      "245\tValidation loss: 0.362421\tBest loss: 0.360324\tAccuracy: 91.30%\n",
      "246\tValidation loss: 0.361130\tBest loss: 0.360324\tAccuracy: 91.40%\n",
      "247\tValidation loss: 0.358568\tBest loss: 0.358568\tAccuracy: 91.70%\n",
      "248\tValidation loss: 0.359759\tBest loss: 0.358568\tAccuracy: 91.60%\n",
      "249\tValidation loss: 0.358233\tBest loss: 0.358233\tAccuracy: 91.60%\n",
      "250\tValidation loss: 0.361781\tBest loss: 0.358233\tAccuracy: 91.50%\n",
      "251\tValidation loss: 0.359337\tBest loss: 0.358233\tAccuracy: 91.50%\n",
      "252\tValidation loss: 0.359357\tBest loss: 0.358233\tAccuracy: 92.00%\n",
      "253\tValidation loss: 0.360905\tBest loss: 0.358233\tAccuracy: 91.50%\n",
      "254\tValidation loss: 0.359993\tBest loss: 0.358233\tAccuracy: 91.70%\n",
      "255\tValidation loss: 0.359044\tBest loss: 0.358233\tAccuracy: 91.70%\n",
      "256\tValidation loss: 0.358534\tBest loss: 0.358233\tAccuracy: 91.50%\n",
      "257\tValidation loss: 0.358949\tBest loss: 0.358233\tAccuracy: 91.60%\n",
      "258\tValidation loss: 0.359347\tBest loss: 0.358233\tAccuracy: 91.50%\n",
      "259\tValidation loss: 0.354529\tBest loss: 0.354529\tAccuracy: 91.80%\n",
      "260\tValidation loss: 0.358317\tBest loss: 0.354529\tAccuracy: 91.60%\n",
      "261\tValidation loss: 0.354681\tBest loss: 0.354529\tAccuracy: 91.50%\n",
      "262\tValidation loss: 0.357396\tBest loss: 0.354529\tAccuracy: 91.60%\n",
      "263\tValidation loss: 0.356696\tBest loss: 0.354529\tAccuracy: 91.80%\n",
      "264\tValidation loss: 0.356268\tBest loss: 0.354529\tAccuracy: 91.40%\n",
      "265\tValidation loss: 0.356656\tBest loss: 0.354529\tAccuracy: 91.40%\n",
      "266\tValidation loss: 0.357297\tBest loss: 0.354529\tAccuracy: 91.70%\n",
      "267\tValidation loss: 0.355711\tBest loss: 0.354529\tAccuracy: 91.60%\n",
      "268\tValidation loss: 0.357067\tBest loss: 0.354529\tAccuracy: 91.40%\n",
      "269\tValidation loss: 0.353898\tBest loss: 0.353898\tAccuracy: 91.70%\n",
      "270\tValidation loss: 0.355506\tBest loss: 0.353898\tAccuracy: 91.70%\n",
      "271\tValidation loss: 0.353132\tBest loss: 0.353132\tAccuracy: 91.70%\n",
      "272\tValidation loss: 0.352894\tBest loss: 0.352894\tAccuracy: 91.60%\n",
      "273\tValidation loss: 0.354670\tBest loss: 0.352894\tAccuracy: 91.70%\n",
      "274\tValidation loss: 0.354335\tBest loss: 0.352894\tAccuracy: 91.50%\n",
      "275\tValidation loss: 0.352245\tBest loss: 0.352245\tAccuracy: 91.90%\n",
      "276\tValidation loss: 0.353741\tBest loss: 0.352245\tAccuracy: 91.70%\n",
      "277\tValidation loss: 0.353138\tBest loss: 0.352245\tAccuracy: 91.50%\n",
      "278\tValidation loss: 0.352679\tBest loss: 0.352245\tAccuracy: 92.00%\n",
      "279\tValidation loss: 0.352616\tBest loss: 0.352245\tAccuracy: 91.60%\n",
      "280\tValidation loss: 0.355002\tBest loss: 0.352245\tAccuracy: 91.70%\n",
      "281\tValidation loss: 0.353963\tBest loss: 0.352245\tAccuracy: 91.60%\n",
      "282\tValidation loss: 0.351225\tBest loss: 0.351225\tAccuracy: 92.00%\n",
      "283\tValidation loss: 0.350325\tBest loss: 0.350325\tAccuracy: 91.70%\n",
      "284\tValidation loss: 0.354763\tBest loss: 0.350325\tAccuracy: 91.50%\n",
      "285\tValidation loss: 0.353301\tBest loss: 0.350325\tAccuracy: 91.60%\n",
      "286\tValidation loss: 0.352565\tBest loss: 0.350325\tAccuracy: 91.60%\n",
      "287\tValidation loss: 0.350572\tBest loss: 0.350325\tAccuracy: 91.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\tValidation loss: 0.351256\tBest loss: 0.350325\tAccuracy: 91.60%\n",
      "289\tValidation loss: 0.351543\tBest loss: 0.350325\tAccuracy: 91.80%\n",
      "290\tValidation loss: 0.351743\tBest loss: 0.350325\tAccuracy: 91.70%\n",
      "291\tValidation loss: 0.349462\tBest loss: 0.349462\tAccuracy: 91.90%\n",
      "292\tValidation loss: 0.351198\tBest loss: 0.349462\tAccuracy: 91.70%\n",
      "293\tValidation loss: 0.351446\tBest loss: 0.349462\tAccuracy: 91.80%\n",
      "294\tValidation loss: 0.350468\tBest loss: 0.349462\tAccuracy: 91.80%\n",
      "295\tValidation loss: 0.349156\tBest loss: 0.349156\tAccuracy: 91.80%\n",
      "296\tValidation loss: 0.350801\tBest loss: 0.349156\tAccuracy: 91.70%\n",
      "297\tValidation loss: 0.349726\tBest loss: 0.349156\tAccuracy: 91.90%\n",
      "298\tValidation loss: 0.352295\tBest loss: 0.349156\tAccuracy: 91.60%\n",
      "299\tValidation loss: 0.349983\tBest loss: 0.349156\tAccuracy: 91.80%\n",
      "300\tValidation loss: 0.350226\tBest loss: 0.349156\tAccuracy: 91.70%\n",
      "301\tValidation loss: 0.348700\tBest loss: 0.348700\tAccuracy: 91.50%\n",
      "302\tValidation loss: 0.348116\tBest loss: 0.348116\tAccuracy: 91.70%\n",
      "303\tValidation loss: 0.348629\tBest loss: 0.348116\tAccuracy: 91.60%\n",
      "304\tValidation loss: 0.350103\tBest loss: 0.348116\tAccuracy: 91.40%\n",
      "305\tValidation loss: 0.348665\tBest loss: 0.348116\tAccuracy: 91.80%\n",
      "306\tValidation loss: 0.345353\tBest loss: 0.345353\tAccuracy: 91.80%\n",
      "307\tValidation loss: 0.347149\tBest loss: 0.345353\tAccuracy: 91.90%\n",
      "308\tValidation loss: 0.346853\tBest loss: 0.345353\tAccuracy: 91.70%\n",
      "309\tValidation loss: 0.346852\tBest loss: 0.345353\tAccuracy: 91.70%\n",
      "310\tValidation loss: 0.345293\tBest loss: 0.345293\tAccuracy: 91.90%\n",
      "311\tValidation loss: 0.346224\tBest loss: 0.345293\tAccuracy: 91.80%\n",
      "312\tValidation loss: 0.345034\tBest loss: 0.345034\tAccuracy: 91.90%\n",
      "313\tValidation loss: 0.345049\tBest loss: 0.345034\tAccuracy: 92.10%\n",
      "314\tValidation loss: 0.345826\tBest loss: 0.345034\tAccuracy: 91.80%\n",
      "315\tValidation loss: 0.344505\tBest loss: 0.344505\tAccuracy: 91.90%\n",
      "316\tValidation loss: 0.344058\tBest loss: 0.344058\tAccuracy: 92.10%\n",
      "317\tValidation loss: 0.345979\tBest loss: 0.344058\tAccuracy: 91.90%\n",
      "318\tValidation loss: 0.343192\tBest loss: 0.343192\tAccuracy: 92.00%\n",
      "319\tValidation loss: 0.343764\tBest loss: 0.343192\tAccuracy: 91.90%\n",
      "320\tValidation loss: 0.343650\tBest loss: 0.343192\tAccuracy: 91.80%\n",
      "321\tValidation loss: 0.343778\tBest loss: 0.343192\tAccuracy: 91.90%\n",
      "322\tValidation loss: 0.345167\tBest loss: 0.343192\tAccuracy: 92.00%\n",
      "323\tValidation loss: 0.343206\tBest loss: 0.343192\tAccuracy: 91.90%\n",
      "324\tValidation loss: 0.342385\tBest loss: 0.342385\tAccuracy: 92.00%\n",
      "325\tValidation loss: 0.343411\tBest loss: 0.342385\tAccuracy: 92.00%\n",
      "326\tValidation loss: 0.345102\tBest loss: 0.342385\tAccuracy: 92.00%\n",
      "327\tValidation loss: 0.342381\tBest loss: 0.342381\tAccuracy: 92.20%\n",
      "328\tValidation loss: 0.345520\tBest loss: 0.342381\tAccuracy: 92.20%\n",
      "329\tValidation loss: 0.342563\tBest loss: 0.342381\tAccuracy: 91.80%\n",
      "330\tValidation loss: 0.343327\tBest loss: 0.342381\tAccuracy: 91.60%\n",
      "331\tValidation loss: 0.343358\tBest loss: 0.342381\tAccuracy: 92.00%\n",
      "332\tValidation loss: 0.342064\tBest loss: 0.342064\tAccuracy: 91.90%\n",
      "333\tValidation loss: 0.340740\tBest loss: 0.340740\tAccuracy: 91.90%\n",
      "334\tValidation loss: 0.345149\tBest loss: 0.340740\tAccuracy: 91.90%\n",
      "335\tValidation loss: 0.341471\tBest loss: 0.340740\tAccuracy: 92.10%\n",
      "336\tValidation loss: 0.340852\tBest loss: 0.340740\tAccuracy: 92.00%\n",
      "337\tValidation loss: 0.340827\tBest loss: 0.340740\tAccuracy: 92.10%\n",
      "338\tValidation loss: 0.340160\tBest loss: 0.340160\tAccuracy: 92.10%\n",
      "339\tValidation loss: 0.340340\tBest loss: 0.340160\tAccuracy: 92.10%\n",
      "340\tValidation loss: 0.342527\tBest loss: 0.340160\tAccuracy: 92.10%\n",
      "341\tValidation loss: 0.341050\tBest loss: 0.340160\tAccuracy: 92.10%\n",
      "342\tValidation loss: 0.340862\tBest loss: 0.340160\tAccuracy: 92.20%\n",
      "343\tValidation loss: 0.338973\tBest loss: 0.338973\tAccuracy: 92.00%\n",
      "344\tValidation loss: 0.340694\tBest loss: 0.338973\tAccuracy: 92.10%\n",
      "345\tValidation loss: 0.339838\tBest loss: 0.338973\tAccuracy: 92.10%\n",
      "346\tValidation loss: 0.339342\tBest loss: 0.338973\tAccuracy: 92.20%\n",
      "347\tValidation loss: 0.340339\tBest loss: 0.338973\tAccuracy: 92.00%\n",
      "348\tValidation loss: 0.341616\tBest loss: 0.338973\tAccuracy: 92.20%\n",
      "349\tValidation loss: 0.340274\tBest loss: 0.338973\tAccuracy: 92.30%\n",
      "350\tValidation loss: 0.338633\tBest loss: 0.338633\tAccuracy: 92.30%\n",
      "351\tValidation loss: 0.340842\tBest loss: 0.338633\tAccuracy: 92.30%\n",
      "352\tValidation loss: 0.340730\tBest loss: 0.338633\tAccuracy: 92.30%\n",
      "353\tValidation loss: 0.338772\tBest loss: 0.338633\tAccuracy: 91.90%\n",
      "354\tValidation loss: 0.338796\tBest loss: 0.338633\tAccuracy: 92.40%\n",
      "355\tValidation loss: 0.339035\tBest loss: 0.338633\tAccuracy: 91.70%\n",
      "356\tValidation loss: 0.338811\tBest loss: 0.338633\tAccuracy: 92.10%\n",
      "357\tValidation loss: 0.336524\tBest loss: 0.336524\tAccuracy: 91.90%\n",
      "358\tValidation loss: 0.339936\tBest loss: 0.336524\tAccuracy: 92.10%\n",
      "359\tValidation loss: 0.340466\tBest loss: 0.336524\tAccuracy: 91.80%\n",
      "360\tValidation loss: 0.338230\tBest loss: 0.336524\tAccuracy: 92.40%\n",
      "361\tValidation loss: 0.337926\tBest loss: 0.336524\tAccuracy: 92.00%\n",
      "362\tValidation loss: 0.337852\tBest loss: 0.336524\tAccuracy: 92.30%\n",
      "363\tValidation loss: 0.338137\tBest loss: 0.336524\tAccuracy: 92.30%\n",
      "364\tValidation loss: 0.338104\tBest loss: 0.336524\tAccuracy: 92.20%\n",
      "365\tValidation loss: 0.340360\tBest loss: 0.336524\tAccuracy: 92.00%\n",
      "366\tValidation loss: 0.337403\tBest loss: 0.336524\tAccuracy: 92.10%\n",
      "367\tValidation loss: 0.336700\tBest loss: 0.336524\tAccuracy: 92.40%\n",
      "368\tValidation loss: 0.335772\tBest loss: 0.335772\tAccuracy: 92.40%\n",
      "369\tValidation loss: 0.335332\tBest loss: 0.335332\tAccuracy: 92.10%\n",
      "370\tValidation loss: 0.336486\tBest loss: 0.335332\tAccuracy: 92.60%\n",
      "371\tValidation loss: 0.335961\tBest loss: 0.335332\tAccuracy: 92.10%\n",
      "372\tValidation loss: 0.337005\tBest loss: 0.335332\tAccuracy: 92.20%\n",
      "373\tValidation loss: 0.337330\tBest loss: 0.335332\tAccuracy: 92.40%\n",
      "374\tValidation loss: 0.336116\tBest loss: 0.335332\tAccuracy: 92.40%\n",
      "375\tValidation loss: 0.335137\tBest loss: 0.335137\tAccuracy: 92.20%\n",
      "376\tValidation loss: 0.337736\tBest loss: 0.335137\tAccuracy: 92.20%\n",
      "377\tValidation loss: 0.336763\tBest loss: 0.335137\tAccuracy: 92.60%\n",
      "378\tValidation loss: 0.334754\tBest loss: 0.334754\tAccuracy: 92.30%\n",
      "379\tValidation loss: 0.335884\tBest loss: 0.334754\tAccuracy: 92.50%\n",
      "380\tValidation loss: 0.334803\tBest loss: 0.334754\tAccuracy: 92.40%\n",
      "381\tValidation loss: 0.335481\tBest loss: 0.334754\tAccuracy: 92.20%\n",
      "382\tValidation loss: 0.335013\tBest loss: 0.334754\tAccuracy: 92.50%\n",
      "383\tValidation loss: 0.335615\tBest loss: 0.334754\tAccuracy: 92.40%\n",
      "384\tValidation loss: 0.336500\tBest loss: 0.334754\tAccuracy: 92.30%\n",
      "385\tValidation loss: 0.333148\tBest loss: 0.333148\tAccuracy: 92.20%\n",
      "386\tValidation loss: 0.335557\tBest loss: 0.333148\tAccuracy: 92.60%\n",
      "387\tValidation loss: 0.334713\tBest loss: 0.333148\tAccuracy: 92.50%\n",
      "388\tValidation loss: 0.333345\tBest loss: 0.333148\tAccuracy: 92.00%\n",
      "389\tValidation loss: 0.334693\tBest loss: 0.333148\tAccuracy: 92.70%\n",
      "390\tValidation loss: 0.332475\tBest loss: 0.332475\tAccuracy: 92.30%\n",
      "391\tValidation loss: 0.332369\tBest loss: 0.332369\tAccuracy: 92.40%\n",
      "392\tValidation loss: 0.333774\tBest loss: 0.332369\tAccuracy: 92.50%\n",
      "393\tValidation loss: 0.332735\tBest loss: 0.332369\tAccuracy: 92.80%\n",
      "394\tValidation loss: 0.330590\tBest loss: 0.330590\tAccuracy: 92.50%\n",
      "395\tValidation loss: 0.334307\tBest loss: 0.330590\tAccuracy: 92.40%\n",
      "396\tValidation loss: 0.332533\tBest loss: 0.330590\tAccuracy: 92.50%\n",
      "397\tValidation loss: 0.331559\tBest loss: 0.330590\tAccuracy: 92.80%\n",
      "398\tValidation loss: 0.330300\tBest loss: 0.330300\tAccuracy: 92.30%\n",
      "399\tValidation loss: 0.333019\tBest loss: 0.330300\tAccuracy: 92.60%\n",
      "400\tValidation loss: 0.330916\tBest loss: 0.330300\tAccuracy: 92.70%\n",
      "401\tValidation loss: 0.333512\tBest loss: 0.330300\tAccuracy: 92.70%\n",
      "402\tValidation loss: 0.333096\tBest loss: 0.330300\tAccuracy: 92.30%\n",
      "403\tValidation loss: 0.333052\tBest loss: 0.330300\tAccuracy: 92.60%\n",
      "404\tValidation loss: 0.331432\tBest loss: 0.330300\tAccuracy: 92.20%\n",
      "405\tValidation loss: 0.333317\tBest loss: 0.330300\tAccuracy: 92.50%\n",
      "406\tValidation loss: 0.333441\tBest loss: 0.330300\tAccuracy: 92.60%\n",
      "407\tValidation loss: 0.331056\tBest loss: 0.330300\tAccuracy: 92.50%\n",
      "408\tValidation loss: 0.330378\tBest loss: 0.330300\tAccuracy: 92.60%\n",
      "409\tValidation loss: 0.331387\tBest loss: 0.330300\tAccuracy: 92.80%\n",
      "410\tValidation loss: 0.331558\tBest loss: 0.330300\tAccuracy: 92.60%\n",
      "411\tValidation loss: 0.331240\tBest loss: 0.330300\tAccuracy: 92.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\tValidation loss: 0.328356\tBest loss: 0.328356\tAccuracy: 92.60%\n",
      "413\tValidation loss: 0.332148\tBest loss: 0.328356\tAccuracy: 92.80%\n",
      "414\tValidation loss: 0.330392\tBest loss: 0.328356\tAccuracy: 92.40%\n",
      "415\tValidation loss: 0.331329\tBest loss: 0.328356\tAccuracy: 92.60%\n",
      "416\tValidation loss: 0.332811\tBest loss: 0.328356\tAccuracy: 92.40%\n",
      "417\tValidation loss: 0.329701\tBest loss: 0.328356\tAccuracy: 92.70%\n",
      "418\tValidation loss: 0.330908\tBest loss: 0.328356\tAccuracy: 92.70%\n",
      "419\tValidation loss: 0.330114\tBest loss: 0.328356\tAccuracy: 92.60%\n",
      "420\tValidation loss: 0.330101\tBest loss: 0.328356\tAccuracy: 92.90%\n",
      "421\tValidation loss: 0.329311\tBest loss: 0.328356\tAccuracy: 92.60%\n",
      "422\tValidation loss: 0.329536\tBest loss: 0.328356\tAccuracy: 92.70%\n",
      "423\tValidation loss: 0.329802\tBest loss: 0.328356\tAccuracy: 92.80%\n",
      "424\tValidation loss: 0.329782\tBest loss: 0.328356\tAccuracy: 92.50%\n",
      "425\tValidation loss: 0.331742\tBest loss: 0.328356\tAccuracy: 92.70%\n",
      "426\tValidation loss: 0.330146\tBest loss: 0.328356\tAccuracy: 92.40%\n",
      "427\tValidation loss: 0.327774\tBest loss: 0.327774\tAccuracy: 92.90%\n",
      "428\tValidation loss: 0.328145\tBest loss: 0.327774\tAccuracy: 92.70%\n",
      "429\tValidation loss: 0.329915\tBest loss: 0.327774\tAccuracy: 92.70%\n",
      "430\tValidation loss: 0.327560\tBest loss: 0.327560\tAccuracy: 92.60%\n",
      "431\tValidation loss: 0.330660\tBest loss: 0.327560\tAccuracy: 92.50%\n",
      "432\tValidation loss: 0.329175\tBest loss: 0.327560\tAccuracy: 92.70%\n",
      "433\tValidation loss: 0.330348\tBest loss: 0.327560\tAccuracy: 92.70%\n",
      "434\tValidation loss: 0.330017\tBest loss: 0.327560\tAccuracy: 92.70%\n",
      "435\tValidation loss: 0.329792\tBest loss: 0.327560\tAccuracy: 92.60%\n",
      "436\tValidation loss: 0.328710\tBest loss: 0.327560\tAccuracy: 92.60%\n",
      "437\tValidation loss: 0.328750\tBest loss: 0.327560\tAccuracy: 92.60%\n",
      "438\tValidation loss: 0.328038\tBest loss: 0.327560\tAccuracy: 92.40%\n",
      "439\tValidation loss: 0.328824\tBest loss: 0.327560\tAccuracy: 92.80%\n",
      "440\tValidation loss: 0.326619\tBest loss: 0.326619\tAccuracy: 92.70%\n",
      "441\tValidation loss: 0.328171\tBest loss: 0.326619\tAccuracy: 92.60%\n",
      "442\tValidation loss: 0.329372\tBest loss: 0.326619\tAccuracy: 92.50%\n",
      "443\tValidation loss: 0.327839\tBest loss: 0.326619\tAccuracy: 92.40%\n",
      "444\tValidation loss: 0.327827\tBest loss: 0.326619\tAccuracy: 92.80%\n",
      "445\tValidation loss: 0.328770\tBest loss: 0.326619\tAccuracy: 92.70%\n",
      "446\tValidation loss: 0.327432\tBest loss: 0.326619\tAccuracy: 92.70%\n",
      "447\tValidation loss: 0.326436\tBest loss: 0.326436\tAccuracy: 92.80%\n",
      "448\tValidation loss: 0.328290\tBest loss: 0.326436\tAccuracy: 92.70%\n",
      "449\tValidation loss: 0.327373\tBest loss: 0.326436\tAccuracy: 92.70%\n",
      "450\tValidation loss: 0.329059\tBest loss: 0.326436\tAccuracy: 92.70%\n",
      "451\tValidation loss: 0.326176\tBest loss: 0.326176\tAccuracy: 92.60%\n",
      "452\tValidation loss: 0.328846\tBest loss: 0.326176\tAccuracy: 92.70%\n",
      "453\tValidation loss: 0.329284\tBest loss: 0.326176\tAccuracy: 92.50%\n",
      "454\tValidation loss: 0.327710\tBest loss: 0.326176\tAccuracy: 92.50%\n",
      "455\tValidation loss: 0.328763\tBest loss: 0.326176\tAccuracy: 92.60%\n",
      "456\tValidation loss: 0.327303\tBest loss: 0.326176\tAccuracy: 92.80%\n",
      "457\tValidation loss: 0.326558\tBest loss: 0.326176\tAccuracy: 92.60%\n",
      "458\tValidation loss: 0.328603\tBest loss: 0.326176\tAccuracy: 92.90%\n",
      "459\tValidation loss: 0.327485\tBest loss: 0.326176\tAccuracy: 92.50%\n",
      "460\tValidation loss: 0.327745\tBest loss: 0.326176\tAccuracy: 92.50%\n",
      "461\tValidation loss: 0.326907\tBest loss: 0.326176\tAccuracy: 92.50%\n",
      "462\tValidation loss: 0.327021\tBest loss: 0.326176\tAccuracy: 92.60%\n",
      "463\tValidation loss: 0.328138\tBest loss: 0.326176\tAccuracy: 92.70%\n",
      "464\tValidation loss: 0.327935\tBest loss: 0.326176\tAccuracy: 92.40%\n",
      "465\tValidation loss: 0.328856\tBest loss: 0.326176\tAccuracy: 92.60%\n",
      "466\tValidation loss: 0.326605\tBest loss: 0.326176\tAccuracy: 92.70%\n",
      "467\tValidation loss: 0.325848\tBest loss: 0.325848\tAccuracy: 92.60%\n",
      "468\tValidation loss: 0.328643\tBest loss: 0.325848\tAccuracy: 92.70%\n",
      "469\tValidation loss: 0.325877\tBest loss: 0.325848\tAccuracy: 92.60%\n",
      "470\tValidation loss: 0.325475\tBest loss: 0.325475\tAccuracy: 92.80%\n",
      "471\tValidation loss: 0.325747\tBest loss: 0.325475\tAccuracy: 92.50%\n",
      "472\tValidation loss: 0.325543\tBest loss: 0.325475\tAccuracy: 92.80%\n",
      "473\tValidation loss: 0.327471\tBest loss: 0.325475\tAccuracy: 92.40%\n",
      "474\tValidation loss: 0.326156\tBest loss: 0.325475\tAccuracy: 92.50%\n",
      "475\tValidation loss: 0.326018\tBest loss: 0.325475\tAccuracy: 92.80%\n",
      "476\tValidation loss: 0.325773\tBest loss: 0.325475\tAccuracy: 92.60%\n",
      "477\tValidation loss: 0.325608\tBest loss: 0.325475\tAccuracy: 92.70%\n",
      "478\tValidation loss: 0.326835\tBest loss: 0.325475\tAccuracy: 92.70%\n",
      "479\tValidation loss: 0.327943\tBest loss: 0.325475\tAccuracy: 92.50%\n",
      "480\tValidation loss: 0.325642\tBest loss: 0.325475\tAccuracy: 92.80%\n",
      "481\tValidation loss: 0.325346\tBest loss: 0.325346\tAccuracy: 92.60%\n",
      "482\tValidation loss: 0.325257\tBest loss: 0.325257\tAccuracy: 92.60%\n",
      "483\tValidation loss: 0.325037\tBest loss: 0.325037\tAccuracy: 92.80%\n",
      "484\tValidation loss: 0.323935\tBest loss: 0.323935\tAccuracy: 92.70%\n",
      "485\tValidation loss: 0.324716\tBest loss: 0.323935\tAccuracy: 93.10%\n",
      "486\tValidation loss: 0.324602\tBest loss: 0.323935\tAccuracy: 92.90%\n",
      "487\tValidation loss: 0.323762\tBest loss: 0.323762\tAccuracy: 92.80%\n",
      "488\tValidation loss: 0.324798\tBest loss: 0.323762\tAccuracy: 92.50%\n",
      "489\tValidation loss: 0.326112\tBest loss: 0.323762\tAccuracy: 92.70%\n",
      "490\tValidation loss: 0.325245\tBest loss: 0.323762\tAccuracy: 92.70%\n",
      "491\tValidation loss: 0.324152\tBest loss: 0.323762\tAccuracy: 92.80%\n",
      "492\tValidation loss: 0.325141\tBest loss: 0.323762\tAccuracy: 92.80%\n",
      "493\tValidation loss: 0.323722\tBest loss: 0.323722\tAccuracy: 92.90%\n",
      "494\tValidation loss: 0.325356\tBest loss: 0.323722\tAccuracy: 93.00%\n",
      "495\tValidation loss: 0.323719\tBest loss: 0.323719\tAccuracy: 92.80%\n",
      "496\tValidation loss: 0.324486\tBest loss: 0.323719\tAccuracy: 92.70%\n",
      "497\tValidation loss: 0.323965\tBest loss: 0.323719\tAccuracy: 92.90%\n",
      "498\tValidation loss: 0.325347\tBest loss: 0.323719\tAccuracy: 92.60%\n",
      "499\tValidation loss: 0.326467\tBest loss: 0.323719\tAccuracy: 92.70%\n",
      "500\tValidation loss: 0.325334\tBest loss: 0.323719\tAccuracy: 92.90%\n",
      "501\tValidation loss: 0.325449\tBest loss: 0.323719\tAccuracy: 92.70%\n",
      "502\tValidation loss: 0.324206\tBest loss: 0.323719\tAccuracy: 92.80%\n",
      "503\tValidation loss: 0.324113\tBest loss: 0.323719\tAccuracy: 92.70%\n",
      "504\tValidation loss: 0.322862\tBest loss: 0.322862\tAccuracy: 92.80%\n",
      "505\tValidation loss: 0.323872\tBest loss: 0.322862\tAccuracy: 92.90%\n",
      "506\tValidation loss: 0.325358\tBest loss: 0.322862\tAccuracy: 92.90%\n",
      "507\tValidation loss: 0.323950\tBest loss: 0.322862\tAccuracy: 93.00%\n",
      "508\tValidation loss: 0.322948\tBest loss: 0.322862\tAccuracy: 92.80%\n",
      "509\tValidation loss: 0.322792\tBest loss: 0.322792\tAccuracy: 92.80%\n",
      "510\tValidation loss: 0.323337\tBest loss: 0.322792\tAccuracy: 92.90%\n",
      "511\tValidation loss: 0.324999\tBest loss: 0.322792\tAccuracy: 93.00%\n",
      "512\tValidation loss: 0.324175\tBest loss: 0.322792\tAccuracy: 93.10%\n",
      "513\tValidation loss: 0.324582\tBest loss: 0.322792\tAccuracy: 92.80%\n",
      "514\tValidation loss: 0.321489\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "515\tValidation loss: 0.323538\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "516\tValidation loss: 0.324816\tBest loss: 0.321489\tAccuracy: 92.50%\n",
      "517\tValidation loss: 0.323196\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "518\tValidation loss: 0.322807\tBest loss: 0.321489\tAccuracy: 92.80%\n",
      "519\tValidation loss: 0.323221\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "520\tValidation loss: 0.323685\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "521\tValidation loss: 0.323614\tBest loss: 0.321489\tAccuracy: 93.00%\n",
      "522\tValidation loss: 0.324763\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "523\tValidation loss: 0.322822\tBest loss: 0.321489\tAccuracy: 92.80%\n",
      "524\tValidation loss: 0.323888\tBest loss: 0.321489\tAccuracy: 93.00%\n",
      "525\tValidation loss: 0.324323\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "526\tValidation loss: 0.323162\tBest loss: 0.321489\tAccuracy: 92.80%\n",
      "527\tValidation loss: 0.322680\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "528\tValidation loss: 0.322397\tBest loss: 0.321489\tAccuracy: 92.90%\n",
      "529\tValidation loss: 0.321622\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "530\tValidation loss: 0.322321\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "531\tValidation loss: 0.321837\tBest loss: 0.321489\tAccuracy: 93.20%\n",
      "532\tValidation loss: 0.322422\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "533\tValidation loss: 0.322256\tBest loss: 0.321489\tAccuracy: 93.20%\n",
      "534\tValidation loss: 0.322096\tBest loss: 0.321489\tAccuracy: 93.10%\n",
      "535\tValidation loss: 0.321095\tBest loss: 0.321095\tAccuracy: 93.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\tValidation loss: 0.321614\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "537\tValidation loss: 0.321885\tBest loss: 0.321095\tAccuracy: 92.80%\n",
      "538\tValidation loss: 0.321838\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "539\tValidation loss: 0.323558\tBest loss: 0.321095\tAccuracy: 93.20%\n",
      "540\tValidation loss: 0.321282\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "541\tValidation loss: 0.323711\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "542\tValidation loss: 0.322039\tBest loss: 0.321095\tAccuracy: 93.10%\n",
      "543\tValidation loss: 0.321980\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "544\tValidation loss: 0.322141\tBest loss: 0.321095\tAccuracy: 92.80%\n",
      "545\tValidation loss: 0.322990\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "546\tValidation loss: 0.322077\tBest loss: 0.321095\tAccuracy: 93.00%\n",
      "547\tValidation loss: 0.320683\tBest loss: 0.320683\tAccuracy: 93.10%\n",
      "548\tValidation loss: 0.321626\tBest loss: 0.320683\tAccuracy: 93.10%\n",
      "549\tValidation loss: 0.322767\tBest loss: 0.320683\tAccuracy: 93.10%\n",
      "550\tValidation loss: 0.321341\tBest loss: 0.320683\tAccuracy: 93.00%\n",
      "551\tValidation loss: 0.320813\tBest loss: 0.320683\tAccuracy: 92.90%\n",
      "552\tValidation loss: 0.321814\tBest loss: 0.320683\tAccuracy: 93.10%\n",
      "553\tValidation loss: 0.321885\tBest loss: 0.320683\tAccuracy: 93.00%\n",
      "554\tValidation loss: 0.322219\tBest loss: 0.320683\tAccuracy: 93.30%\n",
      "555\tValidation loss: 0.322809\tBest loss: 0.320683\tAccuracy: 93.30%\n",
      "556\tValidation loss: 0.321413\tBest loss: 0.320683\tAccuracy: 93.00%\n",
      "557\tValidation loss: 0.321404\tBest loss: 0.320683\tAccuracy: 93.20%\n",
      "558\tValidation loss: 0.322487\tBest loss: 0.320683\tAccuracy: 93.00%\n",
      "559\tValidation loss: 0.321400\tBest loss: 0.320683\tAccuracy: 93.00%\n",
      "560\tValidation loss: 0.322103\tBest loss: 0.320683\tAccuracy: 92.90%\n",
      "561\tValidation loss: 0.320305\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "562\tValidation loss: 0.321601\tBest loss: 0.320305\tAccuracy: 92.90%\n",
      "563\tValidation loss: 0.320602\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "564\tValidation loss: 0.320503\tBest loss: 0.320305\tAccuracy: 93.20%\n",
      "565\tValidation loss: 0.322681\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "566\tValidation loss: 0.321004\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "567\tValidation loss: 0.321820\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "568\tValidation loss: 0.320702\tBest loss: 0.320305\tAccuracy: 93.10%\n",
      "569\tValidation loss: 0.321806\tBest loss: 0.320305\tAccuracy: 93.00%\n",
      "570\tValidation loss: 0.320020\tBest loss: 0.320020\tAccuracy: 93.20%\n",
      "571\tValidation loss: 0.321198\tBest loss: 0.320020\tAccuracy: 92.90%\n",
      "572\tValidation loss: 0.320110\tBest loss: 0.320020\tAccuracy: 93.20%\n",
      "573\tValidation loss: 0.320760\tBest loss: 0.320020\tAccuracy: 93.40%\n",
      "574\tValidation loss: 0.320652\tBest loss: 0.320020\tAccuracy: 92.90%\n",
      "575\tValidation loss: 0.322411\tBest loss: 0.320020\tAccuracy: 93.30%\n",
      "576\tValidation loss: 0.320575\tBest loss: 0.320020\tAccuracy: 93.00%\n",
      "577\tValidation loss: 0.321997\tBest loss: 0.320020\tAccuracy: 93.20%\n",
      "578\tValidation loss: 0.320492\tBest loss: 0.320020\tAccuracy: 93.00%\n",
      "579\tValidation loss: 0.320350\tBest loss: 0.320020\tAccuracy: 93.10%\n",
      "580\tValidation loss: 0.321365\tBest loss: 0.320020\tAccuracy: 93.30%\n",
      "581\tValidation loss: 0.321004\tBest loss: 0.320020\tAccuracy: 93.20%\n",
      "582\tValidation loss: 0.321087\tBest loss: 0.320020\tAccuracy: 93.10%\n",
      "583\tValidation loss: 0.320091\tBest loss: 0.320020\tAccuracy: 92.80%\n",
      "584\tValidation loss: 0.320954\tBest loss: 0.320020\tAccuracy: 93.10%\n",
      "585\tValidation loss: 0.320580\tBest loss: 0.320020\tAccuracy: 93.00%\n",
      "586\tValidation loss: 0.321097\tBest loss: 0.320020\tAccuracy: 93.10%\n",
      "587\tValidation loss: 0.320601\tBest loss: 0.320020\tAccuracy: 93.30%\n",
      "588\tValidation loss: 0.320477\tBest loss: 0.320020\tAccuracy: 93.00%\n",
      "589\tValidation loss: 0.320753\tBest loss: 0.320020\tAccuracy: 93.20%\n",
      "590\tValidation loss: 0.320535\tBest loss: 0.320020\tAccuracy: 93.30%\n",
      "591\tValidation loss: 0.320573\tBest loss: 0.320020\tAccuracy: 92.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.3min\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.105709\tBest loss: 2.105709\tAccuracy: 45.40%\n",
      "1\tValidation loss: 1.604764\tBest loss: 1.604764\tAccuracy: 62.10%\n",
      "2\tValidation loss: 1.386983\tBest loss: 1.386983\tAccuracy: 67.60%\n",
      "3\tValidation loss: 1.232408\tBest loss: 1.232408\tAccuracy: 70.60%\n",
      "4\tValidation loss: 1.145273\tBest loss: 1.145273\tAccuracy: 72.40%\n",
      "5\tValidation loss: 1.070952\tBest loss: 1.070952\tAccuracy: 75.30%\n",
      "6\tValidation loss: 1.023335\tBest loss: 1.023335\tAccuracy: 75.50%\n",
      "7\tValidation loss: 0.975042\tBest loss: 0.975042\tAccuracy: 76.20%\n",
      "8\tValidation loss: 0.926974\tBest loss: 0.926974\tAccuracy: 78.20%\n",
      "9\tValidation loss: 0.904264\tBest loss: 0.904264\tAccuracy: 78.00%\n",
      "10\tValidation loss: 0.863651\tBest loss: 0.863651\tAccuracy: 80.00%\n",
      "11\tValidation loss: 0.843104\tBest loss: 0.843104\tAccuracy: 80.60%\n",
      "12\tValidation loss: 0.822793\tBest loss: 0.822793\tAccuracy: 80.40%\n",
      "13\tValidation loss: 0.793949\tBest loss: 0.793949\tAccuracy: 81.50%\n",
      "14\tValidation loss: 0.772748\tBest loss: 0.772748\tAccuracy: 82.00%\n",
      "15\tValidation loss: 0.761924\tBest loss: 0.761924\tAccuracy: 83.10%\n",
      "16\tValidation loss: 0.741524\tBest loss: 0.741524\tAccuracy: 82.50%\n",
      "17\tValidation loss: 0.728064\tBest loss: 0.728064\tAccuracy: 83.50%\n",
      "18\tValidation loss: 0.717641\tBest loss: 0.717641\tAccuracy: 83.20%\n",
      "19\tValidation loss: 0.708022\tBest loss: 0.708022\tAccuracy: 83.60%\n",
      "20\tValidation loss: 0.693851\tBest loss: 0.693851\tAccuracy: 84.10%\n",
      "21\tValidation loss: 0.679295\tBest loss: 0.679295\tAccuracy: 84.70%\n",
      "22\tValidation loss: 0.669989\tBest loss: 0.669989\tAccuracy: 84.60%\n",
      "23\tValidation loss: 0.667557\tBest loss: 0.667557\tAccuracy: 84.60%\n",
      "24\tValidation loss: 0.655595\tBest loss: 0.655595\tAccuracy: 85.10%\n",
      "25\tValidation loss: 0.649776\tBest loss: 0.649776\tAccuracy: 85.00%\n",
      "26\tValidation loss: 0.647788\tBest loss: 0.647788\tAccuracy: 85.30%\n",
      "27\tValidation loss: 0.635654\tBest loss: 0.635654\tAccuracy: 86.00%\n",
      "28\tValidation loss: 0.626135\tBest loss: 0.626135\tAccuracy: 86.50%\n",
      "29\tValidation loss: 0.626398\tBest loss: 0.626135\tAccuracy: 85.40%\n",
      "30\tValidation loss: 0.611761\tBest loss: 0.611761\tAccuracy: 85.80%\n",
      "31\tValidation loss: 0.607136\tBest loss: 0.607136\tAccuracy: 86.20%\n",
      "32\tValidation loss: 0.605900\tBest loss: 0.605900\tAccuracy: 85.70%\n",
      "33\tValidation loss: 0.596530\tBest loss: 0.596530\tAccuracy: 85.80%\n",
      "34\tValidation loss: 0.595805\tBest loss: 0.595805\tAccuracy: 86.40%\n",
      "35\tValidation loss: 0.589663\tBest loss: 0.589663\tAccuracy: 86.60%\n",
      "36\tValidation loss: 0.584038\tBest loss: 0.584038\tAccuracy: 86.50%\n",
      "37\tValidation loss: 0.575930\tBest loss: 0.575930\tAccuracy: 87.60%\n",
      "38\tValidation loss: 0.575785\tBest loss: 0.575785\tAccuracy: 87.70%\n",
      "39\tValidation loss: 0.573372\tBest loss: 0.573372\tAccuracy: 87.00%\n",
      "40\tValidation loss: 0.568415\tBest loss: 0.568415\tAccuracy: 86.90%\n",
      "41\tValidation loss: 0.560930\tBest loss: 0.560930\tAccuracy: 87.80%\n",
      "42\tValidation loss: 0.560108\tBest loss: 0.560108\tAccuracy: 87.20%\n",
      "43\tValidation loss: 0.546420\tBest loss: 0.546420\tAccuracy: 87.70%\n",
      "44\tValidation loss: 0.548808\tBest loss: 0.546420\tAccuracy: 87.70%\n",
      "45\tValidation loss: 0.548537\tBest loss: 0.546420\tAccuracy: 87.60%\n",
      "46\tValidation loss: 0.546832\tBest loss: 0.546420\tAccuracy: 87.00%\n",
      "47\tValidation loss: 0.544373\tBest loss: 0.544373\tAccuracy: 87.30%\n",
      "48\tValidation loss: 0.538768\tBest loss: 0.538768\tAccuracy: 88.00%\n",
      "49\tValidation loss: 0.536218\tBest loss: 0.536218\tAccuracy: 87.90%\n",
      "50\tValidation loss: 0.532384\tBest loss: 0.532384\tAccuracy: 88.30%\n",
      "51\tValidation loss: 0.528292\tBest loss: 0.528292\tAccuracy: 87.60%\n",
      "52\tValidation loss: 0.524195\tBest loss: 0.524195\tAccuracy: 88.20%\n",
      "53\tValidation loss: 0.521122\tBest loss: 0.521122\tAccuracy: 88.10%\n",
      "54\tValidation loss: 0.519602\tBest loss: 0.519602\tAccuracy: 88.20%\n",
      "55\tValidation loss: 0.515314\tBest loss: 0.515314\tAccuracy: 88.60%\n",
      "56\tValidation loss: 0.517216\tBest loss: 0.515314\tAccuracy: 88.20%\n",
      "57\tValidation loss: 0.511283\tBest loss: 0.511283\tAccuracy: 88.70%\n",
      "58\tValidation loss: 0.514179\tBest loss: 0.511283\tAccuracy: 87.60%\n",
      "59\tValidation loss: 0.508693\tBest loss: 0.508693\tAccuracy: 88.60%\n",
      "60\tValidation loss: 0.509898\tBest loss: 0.508693\tAccuracy: 87.50%\n",
      "61\tValidation loss: 0.506105\tBest loss: 0.506105\tAccuracy: 88.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\tValidation loss: 0.507407\tBest loss: 0.506105\tAccuracy: 87.90%\n",
      "63\tValidation loss: 0.499039\tBest loss: 0.499039\tAccuracy: 88.40%\n",
      "64\tValidation loss: 0.493496\tBest loss: 0.493496\tAccuracy: 88.40%\n",
      "65\tValidation loss: 0.493327\tBest loss: 0.493327\tAccuracy: 88.70%\n",
      "66\tValidation loss: 0.494182\tBest loss: 0.493327\tAccuracy: 88.80%\n",
      "67\tValidation loss: 0.496294\tBest loss: 0.493327\tAccuracy: 88.80%\n",
      "68\tValidation loss: 0.488713\tBest loss: 0.488713\tAccuracy: 88.80%\n",
      "69\tValidation loss: 0.492123\tBest loss: 0.488713\tAccuracy: 88.50%\n",
      "70\tValidation loss: 0.488569\tBest loss: 0.488569\tAccuracy: 88.50%\n",
      "71\tValidation loss: 0.484693\tBest loss: 0.484693\tAccuracy: 88.60%\n",
      "72\tValidation loss: 0.491715\tBest loss: 0.484693\tAccuracy: 88.80%\n",
      "73\tValidation loss: 0.481870\tBest loss: 0.481870\tAccuracy: 88.80%\n",
      "74\tValidation loss: 0.481323\tBest loss: 0.481323\tAccuracy: 89.20%\n",
      "75\tValidation loss: 0.479591\tBest loss: 0.479591\tAccuracy: 88.90%\n",
      "76\tValidation loss: 0.472958\tBest loss: 0.472958\tAccuracy: 88.80%\n",
      "77\tValidation loss: 0.478414\tBest loss: 0.472958\tAccuracy: 88.70%\n",
      "78\tValidation loss: 0.469255\tBest loss: 0.469255\tAccuracy: 89.70%\n",
      "79\tValidation loss: 0.472425\tBest loss: 0.469255\tAccuracy: 89.20%\n",
      "80\tValidation loss: 0.470230\tBest loss: 0.469255\tAccuracy: 89.40%\n",
      "81\tValidation loss: 0.474236\tBest loss: 0.469255\tAccuracy: 88.70%\n",
      "82\tValidation loss: 0.465137\tBest loss: 0.465137\tAccuracy: 89.20%\n",
      "83\tValidation loss: 0.472983\tBest loss: 0.465137\tAccuracy: 88.20%\n",
      "84\tValidation loss: 0.465888\tBest loss: 0.465137\tAccuracy: 89.20%\n",
      "85\tValidation loss: 0.464815\tBest loss: 0.464815\tAccuracy: 89.60%\n",
      "86\tValidation loss: 0.461863\tBest loss: 0.461863\tAccuracy: 89.40%\n",
      "87\tValidation loss: 0.462144\tBest loss: 0.461863\tAccuracy: 89.40%\n",
      "88\tValidation loss: 0.460387\tBest loss: 0.460387\tAccuracy: 89.10%\n",
      "89\tValidation loss: 0.463482\tBest loss: 0.460387\tAccuracy: 89.40%\n",
      "90\tValidation loss: 0.457388\tBest loss: 0.457388\tAccuracy: 89.10%\n",
      "91\tValidation loss: 0.456397\tBest loss: 0.456397\tAccuracy: 88.90%\n",
      "92\tValidation loss: 0.459914\tBest loss: 0.456397\tAccuracy: 89.40%\n",
      "93\tValidation loss: 0.454986\tBest loss: 0.454986\tAccuracy: 88.70%\n",
      "94\tValidation loss: 0.454753\tBest loss: 0.454753\tAccuracy: 89.80%\n",
      "95\tValidation loss: 0.450879\tBest loss: 0.450879\tAccuracy: 89.50%\n",
      "96\tValidation loss: 0.450281\tBest loss: 0.450281\tAccuracy: 89.30%\n",
      "97\tValidation loss: 0.449642\tBest loss: 0.449642\tAccuracy: 89.80%\n",
      "98\tValidation loss: 0.449914\tBest loss: 0.449642\tAccuracy: 90.10%\n",
      "99\tValidation loss: 0.452703\tBest loss: 0.449642\tAccuracy: 89.50%\n",
      "100\tValidation loss: 0.447489\tBest loss: 0.447489\tAccuracy: 90.50%\n",
      "101\tValidation loss: 0.447321\tBest loss: 0.447321\tAccuracy: 89.80%\n",
      "102\tValidation loss: 0.445319\tBest loss: 0.445319\tAccuracy: 89.70%\n",
      "103\tValidation loss: 0.443308\tBest loss: 0.443308\tAccuracy: 89.40%\n",
      "104\tValidation loss: 0.443500\tBest loss: 0.443308\tAccuracy: 89.70%\n",
      "105\tValidation loss: 0.443137\tBest loss: 0.443137\tAccuracy: 89.70%\n",
      "106\tValidation loss: 0.438789\tBest loss: 0.438789\tAccuracy: 90.10%\n",
      "107\tValidation loss: 0.440250\tBest loss: 0.438789\tAccuracy: 90.10%\n",
      "108\tValidation loss: 0.445788\tBest loss: 0.438789\tAccuracy: 89.70%\n",
      "109\tValidation loss: 0.441517\tBest loss: 0.438789\tAccuracy: 89.80%\n",
      "110\tValidation loss: 0.442330\tBest loss: 0.438789\tAccuracy: 89.80%\n",
      "111\tValidation loss: 0.439206\tBest loss: 0.438789\tAccuracy: 89.60%\n",
      "112\tValidation loss: 0.438304\tBest loss: 0.438304\tAccuracy: 89.70%\n",
      "113\tValidation loss: 0.435411\tBest loss: 0.435411\tAccuracy: 89.80%\n",
      "114\tValidation loss: 0.435087\tBest loss: 0.435087\tAccuracy: 89.80%\n",
      "115\tValidation loss: 0.437593\tBest loss: 0.435087\tAccuracy: 90.10%\n",
      "116\tValidation loss: 0.437597\tBest loss: 0.435087\tAccuracy: 89.50%\n",
      "117\tValidation loss: 0.433336\tBest loss: 0.433336\tAccuracy: 89.70%\n",
      "118\tValidation loss: 0.433198\tBest loss: 0.433198\tAccuracy: 90.40%\n",
      "119\tValidation loss: 0.433739\tBest loss: 0.433198\tAccuracy: 90.20%\n",
      "120\tValidation loss: 0.430733\tBest loss: 0.430733\tAccuracy: 90.20%\n",
      "121\tValidation loss: 0.431975\tBest loss: 0.430733\tAccuracy: 90.00%\n",
      "122\tValidation loss: 0.427799\tBest loss: 0.427799\tAccuracy: 90.40%\n",
      "123\tValidation loss: 0.427178\tBest loss: 0.427178\tAccuracy: 90.30%\n",
      "124\tValidation loss: 0.428034\tBest loss: 0.427178\tAccuracy: 89.70%\n",
      "125\tValidation loss: 0.427743\tBest loss: 0.427178\tAccuracy: 90.60%\n",
      "126\tValidation loss: 0.428736\tBest loss: 0.427178\tAccuracy: 90.40%\n",
      "127\tValidation loss: 0.426946\tBest loss: 0.426946\tAccuracy: 90.70%\n",
      "128\tValidation loss: 0.425811\tBest loss: 0.425811\tAccuracy: 90.10%\n",
      "129\tValidation loss: 0.422838\tBest loss: 0.422838\tAccuracy: 89.90%\n",
      "130\tValidation loss: 0.420198\tBest loss: 0.420198\tAccuracy: 90.60%\n",
      "131\tValidation loss: 0.420969\tBest loss: 0.420198\tAccuracy: 90.50%\n",
      "132\tValidation loss: 0.421931\tBest loss: 0.420198\tAccuracy: 90.30%\n",
      "133\tValidation loss: 0.423638\tBest loss: 0.420198\tAccuracy: 90.80%\n",
      "134\tValidation loss: 0.422283\tBest loss: 0.420198\tAccuracy: 90.40%\n",
      "135\tValidation loss: 0.421669\tBest loss: 0.420198\tAccuracy: 90.40%\n",
      "136\tValidation loss: 0.420015\tBest loss: 0.420015\tAccuracy: 90.70%\n",
      "137\tValidation loss: 0.420596\tBest loss: 0.420015\tAccuracy: 90.70%\n",
      "138\tValidation loss: 0.417372\tBest loss: 0.417372\tAccuracy: 90.50%\n",
      "139\tValidation loss: 0.419376\tBest loss: 0.417372\tAccuracy: 90.60%\n",
      "140\tValidation loss: 0.420297\tBest loss: 0.417372\tAccuracy: 90.50%\n",
      "141\tValidation loss: 0.418839\tBest loss: 0.417372\tAccuracy: 90.60%\n",
      "142\tValidation loss: 0.417131\tBest loss: 0.417131\tAccuracy: 90.70%\n",
      "143\tValidation loss: 0.417949\tBest loss: 0.417131\tAccuracy: 90.30%\n",
      "144\tValidation loss: 0.415341\tBest loss: 0.415341\tAccuracy: 90.80%\n",
      "145\tValidation loss: 0.414452\tBest loss: 0.414452\tAccuracy: 90.50%\n",
      "146\tValidation loss: 0.414032\tBest loss: 0.414032\tAccuracy: 89.90%\n",
      "147\tValidation loss: 0.412882\tBest loss: 0.412882\tAccuracy: 90.90%\n",
      "148\tValidation loss: 0.414317\tBest loss: 0.412882\tAccuracy: 90.60%\n",
      "149\tValidation loss: 0.413370\tBest loss: 0.412882\tAccuracy: 90.80%\n",
      "150\tValidation loss: 0.410898\tBest loss: 0.410898\tAccuracy: 91.00%\n",
      "151\tValidation loss: 0.413459\tBest loss: 0.410898\tAccuracy: 90.70%\n",
      "152\tValidation loss: 0.409535\tBest loss: 0.409535\tAccuracy: 90.70%\n",
      "153\tValidation loss: 0.413742\tBest loss: 0.409535\tAccuracy: 90.60%\n",
      "154\tValidation loss: 0.412262\tBest loss: 0.409535\tAccuracy: 90.40%\n",
      "155\tValidation loss: 0.413581\tBest loss: 0.409535\tAccuracy: 90.60%\n",
      "156\tValidation loss: 0.409891\tBest loss: 0.409535\tAccuracy: 90.50%\n",
      "157\tValidation loss: 0.408566\tBest loss: 0.408566\tAccuracy: 90.50%\n",
      "158\tValidation loss: 0.407470\tBest loss: 0.407470\tAccuracy: 90.80%\n",
      "159\tValidation loss: 0.409006\tBest loss: 0.407470\tAccuracy: 90.70%\n",
      "160\tValidation loss: 0.407675\tBest loss: 0.407470\tAccuracy: 90.70%\n",
      "161\tValidation loss: 0.411371\tBest loss: 0.407470\tAccuracy: 90.70%\n",
      "162\tValidation loss: 0.410007\tBest loss: 0.407470\tAccuracy: 90.30%\n",
      "163\tValidation loss: 0.411580\tBest loss: 0.407470\tAccuracy: 90.70%\n",
      "164\tValidation loss: 0.404602\tBest loss: 0.404602\tAccuracy: 90.90%\n",
      "165\tValidation loss: 0.407721\tBest loss: 0.404602\tAccuracy: 90.70%\n",
      "166\tValidation loss: 0.403833\tBest loss: 0.403833\tAccuracy: 91.10%\n",
      "167\tValidation loss: 0.404991\tBest loss: 0.403833\tAccuracy: 90.80%\n",
      "168\tValidation loss: 0.401971\tBest loss: 0.401971\tAccuracy: 91.20%\n",
      "169\tValidation loss: 0.404655\tBest loss: 0.401971\tAccuracy: 90.80%\n",
      "170\tValidation loss: 0.401705\tBest loss: 0.401705\tAccuracy: 91.10%\n",
      "171\tValidation loss: 0.403504\tBest loss: 0.401705\tAccuracy: 90.70%\n",
      "172\tValidation loss: 0.401998\tBest loss: 0.401705\tAccuracy: 91.10%\n",
      "173\tValidation loss: 0.404368\tBest loss: 0.401705\tAccuracy: 90.60%\n",
      "174\tValidation loss: 0.399441\tBest loss: 0.399441\tAccuracy: 91.00%\n",
      "175\tValidation loss: 0.400583\tBest loss: 0.399441\tAccuracy: 90.80%\n",
      "176\tValidation loss: 0.399972\tBest loss: 0.399441\tAccuracy: 91.10%\n",
      "177\tValidation loss: 0.403404\tBest loss: 0.399441\tAccuracy: 90.90%\n",
      "178\tValidation loss: 0.402131\tBest loss: 0.399441\tAccuracy: 91.20%\n",
      "179\tValidation loss: 0.401532\tBest loss: 0.399441\tAccuracy: 90.80%\n",
      "180\tValidation loss: 0.400321\tBest loss: 0.399441\tAccuracy: 91.00%\n",
      "181\tValidation loss: 0.398214\tBest loss: 0.398214\tAccuracy: 91.00%\n",
      "182\tValidation loss: 0.395618\tBest loss: 0.395618\tAccuracy: 91.00%\n",
      "183\tValidation loss: 0.398995\tBest loss: 0.395618\tAccuracy: 91.00%\n",
      "184\tValidation loss: 0.398641\tBest loss: 0.395618\tAccuracy: 91.20%\n",
      "185\tValidation loss: 0.397200\tBest loss: 0.395618\tAccuracy: 91.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\tValidation loss: 0.398116\tBest loss: 0.395618\tAccuracy: 90.80%\n",
      "187\tValidation loss: 0.395547\tBest loss: 0.395547\tAccuracy: 91.20%\n",
      "188\tValidation loss: 0.394409\tBest loss: 0.394409\tAccuracy: 91.40%\n",
      "189\tValidation loss: 0.396671\tBest loss: 0.394409\tAccuracy: 91.30%\n",
      "190\tValidation loss: 0.394690\tBest loss: 0.394409\tAccuracy: 91.10%\n",
      "191\tValidation loss: 0.396252\tBest loss: 0.394409\tAccuracy: 91.40%\n",
      "192\tValidation loss: 0.397229\tBest loss: 0.394409\tAccuracy: 91.30%\n",
      "193\tValidation loss: 0.392345\tBest loss: 0.392345\tAccuracy: 91.10%\n",
      "194\tValidation loss: 0.393815\tBest loss: 0.392345\tAccuracy: 91.60%\n",
      "195\tValidation loss: 0.393145\tBest loss: 0.392345\tAccuracy: 91.10%\n",
      "196\tValidation loss: 0.391344\tBest loss: 0.391344\tAccuracy: 91.30%\n",
      "197\tValidation loss: 0.396656\tBest loss: 0.391344\tAccuracy: 91.10%\n",
      "198\tValidation loss: 0.393219\tBest loss: 0.391344\tAccuracy: 91.20%\n",
      "199\tValidation loss: 0.394642\tBest loss: 0.391344\tAccuracy: 90.90%\n",
      "200\tValidation loss: 0.390494\tBest loss: 0.390494\tAccuracy: 91.40%\n",
      "201\tValidation loss: 0.393912\tBest loss: 0.390494\tAccuracy: 91.40%\n",
      "202\tValidation loss: 0.388389\tBest loss: 0.388389\tAccuracy: 91.70%\n",
      "203\tValidation loss: 0.393520\tBest loss: 0.388389\tAccuracy: 90.80%\n",
      "204\tValidation loss: 0.390323\tBest loss: 0.388389\tAccuracy: 91.70%\n",
      "205\tValidation loss: 0.389878\tBest loss: 0.388389\tAccuracy: 91.60%\n",
      "206\tValidation loss: 0.394073\tBest loss: 0.388389\tAccuracy: 91.40%\n",
      "207\tValidation loss: 0.388220\tBest loss: 0.388220\tAccuracy: 91.40%\n",
      "208\tValidation loss: 0.390237\tBest loss: 0.388220\tAccuracy: 91.50%\n",
      "209\tValidation loss: 0.389959\tBest loss: 0.388220\tAccuracy: 91.50%\n",
      "210\tValidation loss: 0.390677\tBest loss: 0.388220\tAccuracy: 91.20%\n",
      "211\tValidation loss: 0.388872\tBest loss: 0.388220\tAccuracy: 91.50%\n",
      "212\tValidation loss: 0.387410\tBest loss: 0.387410\tAccuracy: 91.80%\n",
      "213\tValidation loss: 0.389041\tBest loss: 0.387410\tAccuracy: 91.80%\n",
      "214\tValidation loss: 0.388672\tBest loss: 0.387410\tAccuracy: 91.40%\n",
      "215\tValidation loss: 0.391158\tBest loss: 0.387410\tAccuracy: 91.30%\n",
      "216\tValidation loss: 0.389720\tBest loss: 0.387410\tAccuracy: 91.40%\n",
      "217\tValidation loss: 0.387977\tBest loss: 0.387410\tAccuracy: 91.50%\n",
      "218\tValidation loss: 0.389149\tBest loss: 0.387410\tAccuracy: 91.70%\n",
      "219\tValidation loss: 0.388958\tBest loss: 0.387410\tAccuracy: 91.30%\n",
      "220\tValidation loss: 0.385287\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "221\tValidation loss: 0.388125\tBest loss: 0.385287\tAccuracy: 91.40%\n",
      "222\tValidation loss: 0.389338\tBest loss: 0.385287\tAccuracy: 91.50%\n",
      "223\tValidation loss: 0.387496\tBest loss: 0.385287\tAccuracy: 91.60%\n",
      "224\tValidation loss: 0.385416\tBest loss: 0.385287\tAccuracy: 92.10%\n",
      "225\tValidation loss: 0.387450\tBest loss: 0.385287\tAccuracy: 91.70%\n",
      "226\tValidation loss: 0.383721\tBest loss: 0.383721\tAccuracy: 92.00%\n",
      "227\tValidation loss: 0.384801\tBest loss: 0.383721\tAccuracy: 91.70%\n",
      "228\tValidation loss: 0.385347\tBest loss: 0.383721\tAccuracy: 91.70%\n",
      "229\tValidation loss: 0.385739\tBest loss: 0.383721\tAccuracy: 91.50%\n",
      "230\tValidation loss: 0.383516\tBest loss: 0.383516\tAccuracy: 91.50%\n",
      "231\tValidation loss: 0.384790\tBest loss: 0.383516\tAccuracy: 91.70%\n",
      "232\tValidation loss: 0.384251\tBest loss: 0.383516\tAccuracy: 91.40%\n",
      "233\tValidation loss: 0.384660\tBest loss: 0.383516\tAccuracy: 91.70%\n",
      "234\tValidation loss: 0.381724\tBest loss: 0.381724\tAccuracy: 91.90%\n",
      "235\tValidation loss: 0.385757\tBest loss: 0.381724\tAccuracy: 91.70%\n",
      "236\tValidation loss: 0.382128\tBest loss: 0.381724\tAccuracy: 91.70%\n",
      "237\tValidation loss: 0.383957\tBest loss: 0.381724\tAccuracy: 91.50%\n",
      "238\tValidation loss: 0.384193\tBest loss: 0.381724\tAccuracy: 91.90%\n",
      "239\tValidation loss: 0.385861\tBest loss: 0.381724\tAccuracy: 91.30%\n",
      "240\tValidation loss: 0.384212\tBest loss: 0.381724\tAccuracy: 91.70%\n",
      "241\tValidation loss: 0.385416\tBest loss: 0.381724\tAccuracy: 91.80%\n",
      "242\tValidation loss: 0.387645\tBest loss: 0.381724\tAccuracy: 91.50%\n",
      "243\tValidation loss: 0.381482\tBest loss: 0.381482\tAccuracy: 91.90%\n",
      "244\tValidation loss: 0.382767\tBest loss: 0.381482\tAccuracy: 92.10%\n",
      "245\tValidation loss: 0.379951\tBest loss: 0.379951\tAccuracy: 92.30%\n",
      "246\tValidation loss: 0.382623\tBest loss: 0.379951\tAccuracy: 91.50%\n",
      "247\tValidation loss: 0.381826\tBest loss: 0.379951\tAccuracy: 91.80%\n",
      "248\tValidation loss: 0.382023\tBest loss: 0.379951\tAccuracy: 92.10%\n",
      "249\tValidation loss: 0.381085\tBest loss: 0.379951\tAccuracy: 91.70%\n",
      "250\tValidation loss: 0.382396\tBest loss: 0.379951\tAccuracy: 91.50%\n",
      "251\tValidation loss: 0.379587\tBest loss: 0.379587\tAccuracy: 91.80%\n",
      "252\tValidation loss: 0.383073\tBest loss: 0.379587\tAccuracy: 92.00%\n",
      "253\tValidation loss: 0.379187\tBest loss: 0.379187\tAccuracy: 92.00%\n",
      "254\tValidation loss: 0.380864\tBest loss: 0.379187\tAccuracy: 91.80%\n",
      "255\tValidation loss: 0.382723\tBest loss: 0.379187\tAccuracy: 91.60%\n",
      "256\tValidation loss: 0.379635\tBest loss: 0.379187\tAccuracy: 92.20%\n",
      "257\tValidation loss: 0.382491\tBest loss: 0.379187\tAccuracy: 91.70%\n",
      "258\tValidation loss: 0.378190\tBest loss: 0.378190\tAccuracy: 92.00%\n",
      "259\tValidation loss: 0.377920\tBest loss: 0.377920\tAccuracy: 92.00%\n",
      "260\tValidation loss: 0.380630\tBest loss: 0.377920\tAccuracy: 92.10%\n",
      "261\tValidation loss: 0.379577\tBest loss: 0.377920\tAccuracy: 92.00%\n",
      "262\tValidation loss: 0.379575\tBest loss: 0.377920\tAccuracy: 91.90%\n",
      "263\tValidation loss: 0.379110\tBest loss: 0.377920\tAccuracy: 92.10%\n",
      "264\tValidation loss: 0.381590\tBest loss: 0.377920\tAccuracy: 91.70%\n",
      "265\tValidation loss: 0.378664\tBest loss: 0.377920\tAccuracy: 91.80%\n",
      "266\tValidation loss: 0.379352\tBest loss: 0.377920\tAccuracy: 92.20%\n",
      "267\tValidation loss: 0.380714\tBest loss: 0.377920\tAccuracy: 92.00%\n",
      "268\tValidation loss: 0.378589\tBest loss: 0.377920\tAccuracy: 91.90%\n",
      "269\tValidation loss: 0.379270\tBest loss: 0.377920\tAccuracy: 91.80%\n",
      "270\tValidation loss: 0.375396\tBest loss: 0.375396\tAccuracy: 92.00%\n",
      "271\tValidation loss: 0.376339\tBest loss: 0.375396\tAccuracy: 92.10%\n",
      "272\tValidation loss: 0.376792\tBest loss: 0.375396\tAccuracy: 92.00%\n",
      "273\tValidation loss: 0.376238\tBest loss: 0.375396\tAccuracy: 92.10%\n",
      "274\tValidation loss: 0.377940\tBest loss: 0.375396\tAccuracy: 91.90%\n",
      "275\tValidation loss: 0.374399\tBest loss: 0.374399\tAccuracy: 92.40%\n",
      "276\tValidation loss: 0.378007\tBest loss: 0.374399\tAccuracy: 91.90%\n",
      "277\tValidation loss: 0.378237\tBest loss: 0.374399\tAccuracy: 91.90%\n",
      "278\tValidation loss: 0.375688\tBest loss: 0.374399\tAccuracy: 92.40%\n",
      "279\tValidation loss: 0.376658\tBest loss: 0.374399\tAccuracy: 91.70%\n",
      "280\tValidation loss: 0.374462\tBest loss: 0.374399\tAccuracy: 92.20%\n",
      "281\tValidation loss: 0.374871\tBest loss: 0.374399\tAccuracy: 92.30%\n",
      "282\tValidation loss: 0.376832\tBest loss: 0.374399\tAccuracy: 92.00%\n",
      "283\tValidation loss: 0.377389\tBest loss: 0.374399\tAccuracy: 92.30%\n",
      "284\tValidation loss: 0.375388\tBest loss: 0.374399\tAccuracy: 92.20%\n",
      "285\tValidation loss: 0.374501\tBest loss: 0.374399\tAccuracy: 92.20%\n",
      "286\tValidation loss: 0.375075\tBest loss: 0.374399\tAccuracy: 91.90%\n",
      "287\tValidation loss: 0.376401\tBest loss: 0.374399\tAccuracy: 91.80%\n",
      "288\tValidation loss: 0.374146\tBest loss: 0.374146\tAccuracy: 92.30%\n",
      "289\tValidation loss: 0.373196\tBest loss: 0.373196\tAccuracy: 92.00%\n",
      "290\tValidation loss: 0.373688\tBest loss: 0.373196\tAccuracy: 91.90%\n",
      "291\tValidation loss: 0.374787\tBest loss: 0.373196\tAccuracy: 92.00%\n",
      "292\tValidation loss: 0.377834\tBest loss: 0.373196\tAccuracy: 91.90%\n",
      "293\tValidation loss: 0.373387\tBest loss: 0.373196\tAccuracy: 92.10%\n",
      "294\tValidation loss: 0.372245\tBest loss: 0.372245\tAccuracy: 92.10%\n",
      "295\tValidation loss: 0.375657\tBest loss: 0.372245\tAccuracy: 91.60%\n",
      "296\tValidation loss: 0.375114\tBest loss: 0.372245\tAccuracy: 92.10%\n",
      "297\tValidation loss: 0.372616\tBest loss: 0.372245\tAccuracy: 91.90%\n",
      "298\tValidation loss: 0.374654\tBest loss: 0.372245\tAccuracy: 92.20%\n",
      "299\tValidation loss: 0.373603\tBest loss: 0.372245\tAccuracy: 91.90%\n",
      "300\tValidation loss: 0.376121\tBest loss: 0.372245\tAccuracy: 91.90%\n",
      "301\tValidation loss: 0.374455\tBest loss: 0.372245\tAccuracy: 91.80%\n",
      "302\tValidation loss: 0.372191\tBest loss: 0.372191\tAccuracy: 92.20%\n",
      "303\tValidation loss: 0.372065\tBest loss: 0.372065\tAccuracy: 92.50%\n",
      "304\tValidation loss: 0.371893\tBest loss: 0.371893\tAccuracy: 92.00%\n",
      "305\tValidation loss: 0.370395\tBest loss: 0.370395\tAccuracy: 92.50%\n",
      "306\tValidation loss: 0.373411\tBest loss: 0.370395\tAccuracy: 92.00%\n",
      "307\tValidation loss: 0.374307\tBest loss: 0.370395\tAccuracy: 92.00%\n",
      "308\tValidation loss: 0.373131\tBest loss: 0.370395\tAccuracy: 91.90%\n",
      "309\tValidation loss: 0.374837\tBest loss: 0.370395\tAccuracy: 91.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\tValidation loss: 0.372241\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "311\tValidation loss: 0.372734\tBest loss: 0.370395\tAccuracy: 92.00%\n",
      "312\tValidation loss: 0.374272\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "313\tValidation loss: 0.373778\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "314\tValidation loss: 0.375023\tBest loss: 0.370395\tAccuracy: 92.10%\n",
      "315\tValidation loss: 0.371446\tBest loss: 0.370395\tAccuracy: 92.40%\n",
      "316\tValidation loss: 0.374333\tBest loss: 0.370395\tAccuracy: 92.00%\n",
      "317\tValidation loss: 0.372461\tBest loss: 0.370395\tAccuracy: 92.10%\n",
      "318\tValidation loss: 0.371573\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "319\tValidation loss: 0.374423\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "320\tValidation loss: 0.370839\tBest loss: 0.370395\tAccuracy: 91.90%\n",
      "321\tValidation loss: 0.372713\tBest loss: 0.370395\tAccuracy: 92.40%\n",
      "322\tValidation loss: 0.374743\tBest loss: 0.370395\tAccuracy: 92.20%\n",
      "323\tValidation loss: 0.372892\tBest loss: 0.370395\tAccuracy: 92.10%\n",
      "324\tValidation loss: 0.373027\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "325\tValidation loss: 0.373546\tBest loss: 0.370395\tAccuracy: 92.20%\n",
      "326\tValidation loss: 0.372157\tBest loss: 0.370395\tAccuracy: 92.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  42.7s\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.087695\tBest loss: 2.087695\tAccuracy: 46.50%\n",
      "1\tValidation loss: 1.609134\tBest loss: 1.609134\tAccuracy: 61.20%\n",
      "2\tValidation loss: 1.382045\tBest loss: 1.382045\tAccuracy: 67.60%\n",
      "3\tValidation loss: 1.253841\tBest loss: 1.253841\tAccuracy: 70.70%\n",
      "4\tValidation loss: 1.137270\tBest loss: 1.137270\tAccuracy: 73.70%\n",
      "5\tValidation loss: 1.069041\tBest loss: 1.069041\tAccuracy: 74.70%\n",
      "6\tValidation loss: 1.006152\tBest loss: 1.006152\tAccuracy: 75.80%\n",
      "7\tValidation loss: 0.959773\tBest loss: 0.959773\tAccuracy: 76.70%\n",
      "8\tValidation loss: 0.928638\tBest loss: 0.928638\tAccuracy: 76.90%\n",
      "9\tValidation loss: 0.896090\tBest loss: 0.896090\tAccuracy: 77.10%\n",
      "10\tValidation loss: 0.867303\tBest loss: 0.867303\tAccuracy: 78.20%\n",
      "11\tValidation loss: 0.837366\tBest loss: 0.837366\tAccuracy: 79.40%\n",
      "12\tValidation loss: 0.813557\tBest loss: 0.813557\tAccuracy: 81.00%\n",
      "13\tValidation loss: 0.789255\tBest loss: 0.789255\tAccuracy: 81.60%\n",
      "14\tValidation loss: 0.770522\tBest loss: 0.770522\tAccuracy: 81.30%\n",
      "15\tValidation loss: 0.751987\tBest loss: 0.751987\tAccuracy: 82.60%\n",
      "16\tValidation loss: 0.747287\tBest loss: 0.747287\tAccuracy: 82.00%\n",
      "17\tValidation loss: 0.718109\tBest loss: 0.718109\tAccuracy: 83.50%\n",
      "18\tValidation loss: 0.718467\tBest loss: 0.718109\tAccuracy: 83.80%\n",
      "19\tValidation loss: 0.699309\tBest loss: 0.699309\tAccuracy: 83.70%\n",
      "20\tValidation loss: 0.694493\tBest loss: 0.694493\tAccuracy: 83.10%\n",
      "21\tValidation loss: 0.681599\tBest loss: 0.681599\tAccuracy: 84.80%\n",
      "22\tValidation loss: 0.664175\tBest loss: 0.664175\tAccuracy: 84.70%\n",
      "23\tValidation loss: 0.664690\tBest loss: 0.664175\tAccuracy: 84.10%\n",
      "24\tValidation loss: 0.658514\tBest loss: 0.658514\tAccuracy: 85.40%\n",
      "25\tValidation loss: 0.649549\tBest loss: 0.649549\tAccuracy: 85.80%\n",
      "26\tValidation loss: 0.641358\tBest loss: 0.641358\tAccuracy: 85.70%\n",
      "27\tValidation loss: 0.626933\tBest loss: 0.626933\tAccuracy: 85.80%\n",
      "28\tValidation loss: 0.624408\tBest loss: 0.624408\tAccuracy: 85.80%\n",
      "29\tValidation loss: 0.618608\tBest loss: 0.618608\tAccuracy: 85.90%\n",
      "30\tValidation loss: 0.609741\tBest loss: 0.609741\tAccuracy: 85.90%\n",
      "31\tValidation loss: 0.610573\tBest loss: 0.609741\tAccuracy: 85.80%\n",
      "32\tValidation loss: 0.601958\tBest loss: 0.601958\tAccuracy: 86.60%\n",
      "33\tValidation loss: 0.595516\tBest loss: 0.595516\tAccuracy: 86.90%\n",
      "34\tValidation loss: 0.590160\tBest loss: 0.590160\tAccuracy: 86.90%\n",
      "35\tValidation loss: 0.587013\tBest loss: 0.587013\tAccuracy: 87.00%\n",
      "36\tValidation loss: 0.587131\tBest loss: 0.587013\tAccuracy: 86.70%\n",
      "37\tValidation loss: 0.576084\tBest loss: 0.576084\tAccuracy: 87.10%\n",
      "38\tValidation loss: 0.567380\tBest loss: 0.567380\tAccuracy: 86.90%\n",
      "39\tValidation loss: 0.562722\tBest loss: 0.562722\tAccuracy: 87.30%\n",
      "40\tValidation loss: 0.560463\tBest loss: 0.560463\tAccuracy: 87.50%\n",
      "41\tValidation loss: 0.554299\tBest loss: 0.554299\tAccuracy: 87.90%\n",
      "42\tValidation loss: 0.553939\tBest loss: 0.553939\tAccuracy: 87.70%\n",
      "43\tValidation loss: 0.547002\tBest loss: 0.547002\tAccuracy: 87.70%\n",
      "44\tValidation loss: 0.542443\tBest loss: 0.542443\tAccuracy: 87.40%\n",
      "45\tValidation loss: 0.547555\tBest loss: 0.542443\tAccuracy: 87.00%\n",
      "46\tValidation loss: 0.543192\tBest loss: 0.542443\tAccuracy: 88.20%\n",
      "47\tValidation loss: 0.535395\tBest loss: 0.535395\tAccuracy: 87.70%\n",
      "48\tValidation loss: 0.530656\tBest loss: 0.530656\tAccuracy: 87.60%\n",
      "49\tValidation loss: 0.527660\tBest loss: 0.527660\tAccuracy: 88.10%\n",
      "50\tValidation loss: 0.525375\tBest loss: 0.525375\tAccuracy: 87.70%\n",
      "51\tValidation loss: 0.520761\tBest loss: 0.520761\tAccuracy: 88.00%\n",
      "52\tValidation loss: 0.520331\tBest loss: 0.520331\tAccuracy: 88.10%\n",
      "53\tValidation loss: 0.517184\tBest loss: 0.517184\tAccuracy: 88.40%\n",
      "54\tValidation loss: 0.512132\tBest loss: 0.512132\tAccuracy: 88.60%\n",
      "55\tValidation loss: 0.510680\tBest loss: 0.510680\tAccuracy: 88.20%\n",
      "56\tValidation loss: 0.508677\tBest loss: 0.508677\tAccuracy: 88.00%\n",
      "57\tValidation loss: 0.502211\tBest loss: 0.502211\tAccuracy: 89.40%\n",
      "58\tValidation loss: 0.501403\tBest loss: 0.501403\tAccuracy: 88.70%\n",
      "59\tValidation loss: 0.501646\tBest loss: 0.501403\tAccuracy: 88.70%\n",
      "60\tValidation loss: 0.500445\tBest loss: 0.500445\tAccuracy: 87.90%\n",
      "61\tValidation loss: 0.502756\tBest loss: 0.500445\tAccuracy: 89.00%\n",
      "62\tValidation loss: 0.496577\tBest loss: 0.496577\tAccuracy: 88.40%\n",
      "63\tValidation loss: 0.489340\tBest loss: 0.489340\tAccuracy: 88.70%\n",
      "64\tValidation loss: 0.488194\tBest loss: 0.488194\tAccuracy: 88.60%\n",
      "65\tValidation loss: 0.488984\tBest loss: 0.488194\tAccuracy: 88.60%\n",
      "66\tValidation loss: 0.483512\tBest loss: 0.483512\tAccuracy: 89.40%\n",
      "67\tValidation loss: 0.485134\tBest loss: 0.483512\tAccuracy: 88.90%\n",
      "68\tValidation loss: 0.475650\tBest loss: 0.475650\tAccuracy: 89.10%\n",
      "69\tValidation loss: 0.480933\tBest loss: 0.475650\tAccuracy: 88.80%\n",
      "70\tValidation loss: 0.475791\tBest loss: 0.475650\tAccuracy: 88.90%\n",
      "71\tValidation loss: 0.476626\tBest loss: 0.475650\tAccuracy: 89.20%\n",
      "72\tValidation loss: 0.474479\tBest loss: 0.474479\tAccuracy: 89.10%\n",
      "73\tValidation loss: 0.471632\tBest loss: 0.471632\tAccuracy: 89.40%\n",
      "74\tValidation loss: 0.472572\tBest loss: 0.471632\tAccuracy: 89.60%\n",
      "75\tValidation loss: 0.468319\tBest loss: 0.468319\tAccuracy: 89.00%\n",
      "76\tValidation loss: 0.471410\tBest loss: 0.468319\tAccuracy: 88.90%\n",
      "77\tValidation loss: 0.467338\tBest loss: 0.467338\tAccuracy: 89.10%\n",
      "78\tValidation loss: 0.460421\tBest loss: 0.460421\tAccuracy: 89.20%\n",
      "79\tValidation loss: 0.468639\tBest loss: 0.460421\tAccuracy: 88.90%\n",
      "80\tValidation loss: 0.457575\tBest loss: 0.457575\tAccuracy: 89.40%\n",
      "81\tValidation loss: 0.460480\tBest loss: 0.457575\tAccuracy: 89.70%\n",
      "82\tValidation loss: 0.455796\tBest loss: 0.455796\tAccuracy: 89.70%\n",
      "83\tValidation loss: 0.454425\tBest loss: 0.454425\tAccuracy: 89.10%\n",
      "84\tValidation loss: 0.451451\tBest loss: 0.451451\tAccuracy: 89.20%\n",
      "85\tValidation loss: 0.449321\tBest loss: 0.449321\tAccuracy: 89.80%\n",
      "86\tValidation loss: 0.447964\tBest loss: 0.447964\tAccuracy: 89.50%\n",
      "87\tValidation loss: 0.452208\tBest loss: 0.447964\tAccuracy: 88.90%\n",
      "88\tValidation loss: 0.444652\tBest loss: 0.444652\tAccuracy: 89.30%\n",
      "89\tValidation loss: 0.445204\tBest loss: 0.444652\tAccuracy: 89.80%\n",
      "90\tValidation loss: 0.442158\tBest loss: 0.442158\tAccuracy: 90.10%\n",
      "91\tValidation loss: 0.440085\tBest loss: 0.440085\tAccuracy: 89.30%\n",
      "92\tValidation loss: 0.445801\tBest loss: 0.440085\tAccuracy: 89.20%\n",
      "93\tValidation loss: 0.437637\tBest loss: 0.437637\tAccuracy: 89.60%\n",
      "94\tValidation loss: 0.439168\tBest loss: 0.437637\tAccuracy: 89.80%\n",
      "95\tValidation loss: 0.433690\tBest loss: 0.433690\tAccuracy: 90.30%\n",
      "96\tValidation loss: 0.432910\tBest loss: 0.432910\tAccuracy: 90.00%\n",
      "97\tValidation loss: 0.437402\tBest loss: 0.432910\tAccuracy: 89.70%\n",
      "98\tValidation loss: 0.432223\tBest loss: 0.432223\tAccuracy: 90.20%\n",
      "99\tValidation loss: 0.430699\tBest loss: 0.430699\tAccuracy: 89.80%\n",
      "100\tValidation loss: 0.432934\tBest loss: 0.430699\tAccuracy: 89.70%\n",
      "101\tValidation loss: 0.431026\tBest loss: 0.430699\tAccuracy: 89.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\tValidation loss: 0.425019\tBest loss: 0.425019\tAccuracy: 90.10%\n",
      "103\tValidation loss: 0.425289\tBest loss: 0.425019\tAccuracy: 90.20%\n",
      "104\tValidation loss: 0.425525\tBest loss: 0.425019\tAccuracy: 89.90%\n",
      "105\tValidation loss: 0.430050\tBest loss: 0.425019\tAccuracy: 89.90%\n",
      "106\tValidation loss: 0.423021\tBest loss: 0.423021\tAccuracy: 90.40%\n",
      "107\tValidation loss: 0.423819\tBest loss: 0.423021\tAccuracy: 90.70%\n",
      "108\tValidation loss: 0.424825\tBest loss: 0.423021\tAccuracy: 90.20%\n",
      "109\tValidation loss: 0.420597\tBest loss: 0.420597\tAccuracy: 90.30%\n",
      "110\tValidation loss: 0.419523\tBest loss: 0.419523\tAccuracy: 89.70%\n",
      "111\tValidation loss: 0.422274\tBest loss: 0.419523\tAccuracy: 90.30%\n",
      "112\tValidation loss: 0.418319\tBest loss: 0.418319\tAccuracy: 90.40%\n",
      "113\tValidation loss: 0.416511\tBest loss: 0.416511\tAccuracy: 90.20%\n",
      "114\tValidation loss: 0.420240\tBest loss: 0.416511\tAccuracy: 90.00%\n",
      "115\tValidation loss: 0.414089\tBest loss: 0.414089\tAccuracy: 90.70%\n",
      "116\tValidation loss: 0.414097\tBest loss: 0.414089\tAccuracy: 90.20%\n",
      "117\tValidation loss: 0.414558\tBest loss: 0.414089\tAccuracy: 89.80%\n",
      "118\tValidation loss: 0.407857\tBest loss: 0.407857\tAccuracy: 90.60%\n",
      "119\tValidation loss: 0.408869\tBest loss: 0.407857\tAccuracy: 90.70%\n",
      "120\tValidation loss: 0.406375\tBest loss: 0.406375\tAccuracy: 90.50%\n",
      "121\tValidation loss: 0.407967\tBest loss: 0.406375\tAccuracy: 90.50%\n",
      "122\tValidation loss: 0.410242\tBest loss: 0.406375\tAccuracy: 89.90%\n",
      "123\tValidation loss: 0.410479\tBest loss: 0.406375\tAccuracy: 90.50%\n",
      "124\tValidation loss: 0.406345\tBest loss: 0.406345\tAccuracy: 90.30%\n",
      "125\tValidation loss: 0.405961\tBest loss: 0.405961\tAccuracy: 90.20%\n",
      "126\tValidation loss: 0.407769\tBest loss: 0.405961\tAccuracy: 90.50%\n",
      "127\tValidation loss: 0.403710\tBest loss: 0.403710\tAccuracy: 90.60%\n",
      "128\tValidation loss: 0.404003\tBest loss: 0.403710\tAccuracy: 90.50%\n",
      "129\tValidation loss: 0.400494\tBest loss: 0.400494\tAccuracy: 90.50%\n",
      "130\tValidation loss: 0.400880\tBest loss: 0.400494\tAccuracy: 90.50%\n",
      "131\tValidation loss: 0.401661\tBest loss: 0.400494\tAccuracy: 90.70%\n",
      "132\tValidation loss: 0.398493\tBest loss: 0.398493\tAccuracy: 90.80%\n",
      "133\tValidation loss: 0.406687\tBest loss: 0.398493\tAccuracy: 91.20%\n",
      "134\tValidation loss: 0.399298\tBest loss: 0.398493\tAccuracy: 91.30%\n",
      "135\tValidation loss: 0.399618\tBest loss: 0.398493\tAccuracy: 90.90%\n",
      "136\tValidation loss: 0.396632\tBest loss: 0.396632\tAccuracy: 90.90%\n",
      "137\tValidation loss: 0.394971\tBest loss: 0.394971\tAccuracy: 90.80%\n",
      "138\tValidation loss: 0.396815\tBest loss: 0.394971\tAccuracy: 90.60%\n",
      "139\tValidation loss: 0.392363\tBest loss: 0.392363\tAccuracy: 90.90%\n",
      "140\tValidation loss: 0.393800\tBest loss: 0.392363\tAccuracy: 90.60%\n",
      "141\tValidation loss: 0.390137\tBest loss: 0.390137\tAccuracy: 91.00%\n",
      "142\tValidation loss: 0.391163\tBest loss: 0.390137\tAccuracy: 91.20%\n",
      "143\tValidation loss: 0.392822\tBest loss: 0.390137\tAccuracy: 90.80%\n",
      "144\tValidation loss: 0.391074\tBest loss: 0.390137\tAccuracy: 90.80%\n",
      "145\tValidation loss: 0.389947\tBest loss: 0.389947\tAccuracy: 91.20%\n",
      "146\tValidation loss: 0.390797\tBest loss: 0.389947\tAccuracy: 90.90%\n",
      "147\tValidation loss: 0.392819\tBest loss: 0.389947\tAccuracy: 90.80%\n",
      "148\tValidation loss: 0.389401\tBest loss: 0.389401\tAccuracy: 90.90%\n",
      "149\tValidation loss: 0.388008\tBest loss: 0.388008\tAccuracy: 91.00%\n",
      "150\tValidation loss: 0.389444\tBest loss: 0.388008\tAccuracy: 91.20%\n",
      "151\tValidation loss: 0.385554\tBest loss: 0.385554\tAccuracy: 91.00%\n",
      "152\tValidation loss: 0.384248\tBest loss: 0.384248\tAccuracy: 90.90%\n",
      "153\tValidation loss: 0.385426\tBest loss: 0.384248\tAccuracy: 91.50%\n",
      "154\tValidation loss: 0.386500\tBest loss: 0.384248\tAccuracy: 91.30%\n",
      "155\tValidation loss: 0.386321\tBest loss: 0.384248\tAccuracy: 91.20%\n",
      "156\tValidation loss: 0.386133\tBest loss: 0.384248\tAccuracy: 91.50%\n",
      "157\tValidation loss: 0.386601\tBest loss: 0.384248\tAccuracy: 91.50%\n",
      "158\tValidation loss: 0.382006\tBest loss: 0.382006\tAccuracy: 91.50%\n",
      "159\tValidation loss: 0.378672\tBest loss: 0.378672\tAccuracy: 91.00%\n",
      "160\tValidation loss: 0.387258\tBest loss: 0.378672\tAccuracy: 91.30%\n",
      "161\tValidation loss: 0.380379\tBest loss: 0.378672\tAccuracy: 91.50%\n",
      "162\tValidation loss: 0.379315\tBest loss: 0.378672\tAccuracy: 91.40%\n",
      "163\tValidation loss: 0.378946\tBest loss: 0.378672\tAccuracy: 91.50%\n",
      "164\tValidation loss: 0.381816\tBest loss: 0.378672\tAccuracy: 91.70%\n",
      "165\tValidation loss: 0.379415\tBest loss: 0.378672\tAccuracy: 91.70%\n",
      "166\tValidation loss: 0.379890\tBest loss: 0.378672\tAccuracy: 91.60%\n",
      "167\tValidation loss: 0.373972\tBest loss: 0.373972\tAccuracy: 91.40%\n",
      "168\tValidation loss: 0.375887\tBest loss: 0.373972\tAccuracy: 91.80%\n",
      "169\tValidation loss: 0.378403\tBest loss: 0.373972\tAccuracy: 91.30%\n",
      "170\tValidation loss: 0.378111\tBest loss: 0.373972\tAccuracy: 91.50%\n",
      "171\tValidation loss: 0.376558\tBest loss: 0.373972\tAccuracy: 91.90%\n",
      "172\tValidation loss: 0.377050\tBest loss: 0.373972\tAccuracy: 91.70%\n",
      "173\tValidation loss: 0.372403\tBest loss: 0.372403\tAccuracy: 91.90%\n",
      "174\tValidation loss: 0.374320\tBest loss: 0.372403\tAccuracy: 91.50%\n",
      "175\tValidation loss: 0.373483\tBest loss: 0.372403\tAccuracy: 91.90%\n",
      "176\tValidation loss: 0.372296\tBest loss: 0.372296\tAccuracy: 91.70%\n",
      "177\tValidation loss: 0.372247\tBest loss: 0.372247\tAccuracy: 91.90%\n",
      "178\tValidation loss: 0.370934\tBest loss: 0.370934\tAccuracy: 91.90%\n",
      "179\tValidation loss: 0.373149\tBest loss: 0.370934\tAccuracy: 91.90%\n",
      "180\tValidation loss: 0.369806\tBest loss: 0.369806\tAccuracy: 91.80%\n",
      "181\tValidation loss: 0.370288\tBest loss: 0.369806\tAccuracy: 92.10%\n",
      "182\tValidation loss: 0.370751\tBest loss: 0.369806\tAccuracy: 91.70%\n",
      "183\tValidation loss: 0.368291\tBest loss: 0.368291\tAccuracy: 92.10%\n",
      "184\tValidation loss: 0.371889\tBest loss: 0.368291\tAccuracy: 91.80%\n",
      "185\tValidation loss: 0.367063\tBest loss: 0.367063\tAccuracy: 92.00%\n",
      "186\tValidation loss: 0.369805\tBest loss: 0.367063\tAccuracy: 92.00%\n",
      "187\tValidation loss: 0.365018\tBest loss: 0.365018\tAccuracy: 92.20%\n",
      "188\tValidation loss: 0.367544\tBest loss: 0.365018\tAccuracy: 92.00%\n",
      "189\tValidation loss: 0.367860\tBest loss: 0.365018\tAccuracy: 92.00%\n",
      "190\tValidation loss: 0.366882\tBest loss: 0.365018\tAccuracy: 92.00%\n",
      "191\tValidation loss: 0.364579\tBest loss: 0.364579\tAccuracy: 91.90%\n",
      "192\tValidation loss: 0.363037\tBest loss: 0.363037\tAccuracy: 92.20%\n",
      "193\tValidation loss: 0.365443\tBest loss: 0.363037\tAccuracy: 92.40%\n",
      "194\tValidation loss: 0.366851\tBest loss: 0.363037\tAccuracy: 91.70%\n",
      "195\tValidation loss: 0.366145\tBest loss: 0.363037\tAccuracy: 91.90%\n",
      "196\tValidation loss: 0.361278\tBest loss: 0.361278\tAccuracy: 92.00%\n",
      "197\tValidation loss: 0.361660\tBest loss: 0.361278\tAccuracy: 92.60%\n",
      "198\tValidation loss: 0.364934\tBest loss: 0.361278\tAccuracy: 92.40%\n",
      "199\tValidation loss: 0.364374\tBest loss: 0.361278\tAccuracy: 92.10%\n",
      "200\tValidation loss: 0.360485\tBest loss: 0.360485\tAccuracy: 92.00%\n",
      "201\tValidation loss: 0.362183\tBest loss: 0.360485\tAccuracy: 91.60%\n",
      "202\tValidation loss: 0.359568\tBest loss: 0.359568\tAccuracy: 92.40%\n",
      "203\tValidation loss: 0.360374\tBest loss: 0.359568\tAccuracy: 92.20%\n",
      "204\tValidation loss: 0.360394\tBest loss: 0.359568\tAccuracy: 92.10%\n",
      "205\tValidation loss: 0.358295\tBest loss: 0.358295\tAccuracy: 92.30%\n",
      "206\tValidation loss: 0.358368\tBest loss: 0.358295\tAccuracy: 92.40%\n",
      "207\tValidation loss: 0.360634\tBest loss: 0.358295\tAccuracy: 92.20%\n",
      "208\tValidation loss: 0.359109\tBest loss: 0.358295\tAccuracy: 92.10%\n",
      "209\tValidation loss: 0.360183\tBest loss: 0.358295\tAccuracy: 92.00%\n",
      "210\tValidation loss: 0.361569\tBest loss: 0.358295\tAccuracy: 92.10%\n",
      "211\tValidation loss: 0.357804\tBest loss: 0.357804\tAccuracy: 92.00%\n",
      "212\tValidation loss: 0.357714\tBest loss: 0.357714\tAccuracy: 92.20%\n",
      "213\tValidation loss: 0.358921\tBest loss: 0.357714\tAccuracy: 92.10%\n",
      "214\tValidation loss: 0.355950\tBest loss: 0.355950\tAccuracy: 92.30%\n",
      "215\tValidation loss: 0.358697\tBest loss: 0.355950\tAccuracy: 92.20%\n",
      "216\tValidation loss: 0.355392\tBest loss: 0.355392\tAccuracy: 92.20%\n",
      "217\tValidation loss: 0.356703\tBest loss: 0.355392\tAccuracy: 92.10%\n",
      "218\tValidation loss: 0.354049\tBest loss: 0.354049\tAccuracy: 92.10%\n",
      "219\tValidation loss: 0.356439\tBest loss: 0.354049\tAccuracy: 92.10%\n",
      "220\tValidation loss: 0.354055\tBest loss: 0.354049\tAccuracy: 92.60%\n",
      "221\tValidation loss: 0.356993\tBest loss: 0.354049\tAccuracy: 92.30%\n",
      "222\tValidation loss: 0.357197\tBest loss: 0.354049\tAccuracy: 92.30%\n",
      "223\tValidation loss: 0.355296\tBest loss: 0.354049\tAccuracy: 92.30%\n",
      "224\tValidation loss: 0.355912\tBest loss: 0.354049\tAccuracy: 92.10%\n",
      "225\tValidation loss: 0.354723\tBest loss: 0.354049\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\tValidation loss: 0.353122\tBest loss: 0.353122\tAccuracy: 92.20%\n",
      "227\tValidation loss: 0.351480\tBest loss: 0.351480\tAccuracy: 92.30%\n",
      "228\tValidation loss: 0.350081\tBest loss: 0.350081\tAccuracy: 92.40%\n",
      "229\tValidation loss: 0.351890\tBest loss: 0.350081\tAccuracy: 92.40%\n",
      "230\tValidation loss: 0.352034\tBest loss: 0.350081\tAccuracy: 92.40%\n",
      "231\tValidation loss: 0.349973\tBest loss: 0.349973\tAccuracy: 92.10%\n",
      "232\tValidation loss: 0.350030\tBest loss: 0.349973\tAccuracy: 92.50%\n",
      "233\tValidation loss: 0.348449\tBest loss: 0.348449\tAccuracy: 92.30%\n",
      "234\tValidation loss: 0.352448\tBest loss: 0.348449\tAccuracy: 92.30%\n",
      "235\tValidation loss: 0.352647\tBest loss: 0.348449\tAccuracy: 92.10%\n",
      "236\tValidation loss: 0.350326\tBest loss: 0.348449\tAccuracy: 92.00%\n",
      "237\tValidation loss: 0.351631\tBest loss: 0.348449\tAccuracy: 92.30%\n",
      "238\tValidation loss: 0.351214\tBest loss: 0.348449\tAccuracy: 92.20%\n",
      "239\tValidation loss: 0.349290\tBest loss: 0.348449\tAccuracy: 92.60%\n",
      "240\tValidation loss: 0.349411\tBest loss: 0.348449\tAccuracy: 92.20%\n",
      "241\tValidation loss: 0.351968\tBest loss: 0.348449\tAccuracy: 92.30%\n",
      "242\tValidation loss: 0.347624\tBest loss: 0.347624\tAccuracy: 92.20%\n",
      "243\tValidation loss: 0.347437\tBest loss: 0.347437\tAccuracy: 92.50%\n",
      "244\tValidation loss: 0.349991\tBest loss: 0.347437\tAccuracy: 92.50%\n",
      "245\tValidation loss: 0.347944\tBest loss: 0.347437\tAccuracy: 92.30%\n",
      "246\tValidation loss: 0.350062\tBest loss: 0.347437\tAccuracy: 92.30%\n",
      "247\tValidation loss: 0.344726\tBest loss: 0.344726\tAccuracy: 92.30%\n",
      "248\tValidation loss: 0.346285\tBest loss: 0.344726\tAccuracy: 92.30%\n",
      "249\tValidation loss: 0.346035\tBest loss: 0.344726\tAccuracy: 92.50%\n",
      "250\tValidation loss: 0.344943\tBest loss: 0.344726\tAccuracy: 92.60%\n",
      "251\tValidation loss: 0.345852\tBest loss: 0.344726\tAccuracy: 92.40%\n",
      "252\tValidation loss: 0.344828\tBest loss: 0.344726\tAccuracy: 92.40%\n",
      "253\tValidation loss: 0.344979\tBest loss: 0.344726\tAccuracy: 92.40%\n",
      "254\tValidation loss: 0.344473\tBest loss: 0.344473\tAccuracy: 92.50%\n",
      "255\tValidation loss: 0.345245\tBest loss: 0.344473\tAccuracy: 92.30%\n",
      "256\tValidation loss: 0.343117\tBest loss: 0.343117\tAccuracy: 92.50%\n",
      "257\tValidation loss: 0.348526\tBest loss: 0.343117\tAccuracy: 92.00%\n",
      "258\tValidation loss: 0.345038\tBest loss: 0.343117\tAccuracy: 92.30%\n",
      "259\tValidation loss: 0.348099\tBest loss: 0.343117\tAccuracy: 92.60%\n",
      "260\tValidation loss: 0.343779\tBest loss: 0.343117\tAccuracy: 92.30%\n",
      "261\tValidation loss: 0.343339\tBest loss: 0.343117\tAccuracy: 92.30%\n",
      "262\tValidation loss: 0.343239\tBest loss: 0.343117\tAccuracy: 92.30%\n",
      "263\tValidation loss: 0.341447\tBest loss: 0.341447\tAccuracy: 92.30%\n",
      "264\tValidation loss: 0.340800\tBest loss: 0.340800\tAccuracy: 92.50%\n",
      "265\tValidation loss: 0.341635\tBest loss: 0.340800\tAccuracy: 92.30%\n",
      "266\tValidation loss: 0.341550\tBest loss: 0.340800\tAccuracy: 92.60%\n",
      "267\tValidation loss: 0.339406\tBest loss: 0.339406\tAccuracy: 92.60%\n",
      "268\tValidation loss: 0.342514\tBest loss: 0.339406\tAccuracy: 92.00%\n",
      "269\tValidation loss: 0.340904\tBest loss: 0.339406\tAccuracy: 92.40%\n",
      "270\tValidation loss: 0.342700\tBest loss: 0.339406\tAccuracy: 92.40%\n",
      "271\tValidation loss: 0.340503\tBest loss: 0.339406\tAccuracy: 92.70%\n",
      "272\tValidation loss: 0.339221\tBest loss: 0.339221\tAccuracy: 92.80%\n",
      "273\tValidation loss: 0.341766\tBest loss: 0.339221\tAccuracy: 92.60%\n",
      "274\tValidation loss: 0.339013\tBest loss: 0.339013\tAccuracy: 92.20%\n",
      "275\tValidation loss: 0.341376\tBest loss: 0.339013\tAccuracy: 92.30%\n",
      "276\tValidation loss: 0.341405\tBest loss: 0.339013\tAccuracy: 92.30%\n",
      "277\tValidation loss: 0.339529\tBest loss: 0.339013\tAccuracy: 92.20%\n",
      "278\tValidation loss: 0.338142\tBest loss: 0.338142\tAccuracy: 92.60%\n",
      "279\tValidation loss: 0.340425\tBest loss: 0.338142\tAccuracy: 92.70%\n",
      "280\tValidation loss: 0.337445\tBest loss: 0.337445\tAccuracy: 92.80%\n",
      "281\tValidation loss: 0.339559\tBest loss: 0.337445\tAccuracy: 92.60%\n",
      "282\tValidation loss: 0.339197\tBest loss: 0.337445\tAccuracy: 92.40%\n",
      "283\tValidation loss: 0.337878\tBest loss: 0.337445\tAccuracy: 92.50%\n",
      "284\tValidation loss: 0.339136\tBest loss: 0.337445\tAccuracy: 92.40%\n",
      "285\tValidation loss: 0.337314\tBest loss: 0.337314\tAccuracy: 92.50%\n",
      "286\tValidation loss: 0.336875\tBest loss: 0.336875\tAccuracy: 92.70%\n",
      "287\tValidation loss: 0.338127\tBest loss: 0.336875\tAccuracy: 92.50%\n",
      "288\tValidation loss: 0.335198\tBest loss: 0.335198\tAccuracy: 92.60%\n",
      "289\tValidation loss: 0.338346\tBest loss: 0.335198\tAccuracy: 92.30%\n",
      "290\tValidation loss: 0.335593\tBest loss: 0.335198\tAccuracy: 92.80%\n",
      "291\tValidation loss: 0.337254\tBest loss: 0.335198\tAccuracy: 92.80%\n",
      "292\tValidation loss: 0.337018\tBest loss: 0.335198\tAccuracy: 92.80%\n",
      "293\tValidation loss: 0.338064\tBest loss: 0.335198\tAccuracy: 92.60%\n",
      "294\tValidation loss: 0.335985\tBest loss: 0.335198\tAccuracy: 92.50%\n",
      "295\tValidation loss: 0.338088\tBest loss: 0.335198\tAccuracy: 92.70%\n",
      "296\tValidation loss: 0.336455\tBest loss: 0.335198\tAccuracy: 92.40%\n",
      "297\tValidation loss: 0.333901\tBest loss: 0.333901\tAccuracy: 92.60%\n",
      "298\tValidation loss: 0.337220\tBest loss: 0.333901\tAccuracy: 92.50%\n",
      "299\tValidation loss: 0.335030\tBest loss: 0.333901\tAccuracy: 92.60%\n",
      "300\tValidation loss: 0.334465\tBest loss: 0.333901\tAccuracy: 92.40%\n",
      "301\tValidation loss: 0.333270\tBest loss: 0.333270\tAccuracy: 92.50%\n",
      "302\tValidation loss: 0.337875\tBest loss: 0.333270\tAccuracy: 92.50%\n",
      "303\tValidation loss: 0.336406\tBest loss: 0.333270\tAccuracy: 92.90%\n",
      "304\tValidation loss: 0.333211\tBest loss: 0.333211\tAccuracy: 92.90%\n",
      "305\tValidation loss: 0.332648\tBest loss: 0.332648\tAccuracy: 92.50%\n",
      "306\tValidation loss: 0.335371\tBest loss: 0.332648\tAccuracy: 92.60%\n",
      "307\tValidation loss: 0.332533\tBest loss: 0.332533\tAccuracy: 92.90%\n",
      "308\tValidation loss: 0.333495\tBest loss: 0.332533\tAccuracy: 92.50%\n",
      "309\tValidation loss: 0.332424\tBest loss: 0.332424\tAccuracy: 92.80%\n",
      "310\tValidation loss: 0.330887\tBest loss: 0.330887\tAccuracy: 92.50%\n",
      "311\tValidation loss: 0.333869\tBest loss: 0.330887\tAccuracy: 92.40%\n",
      "312\tValidation loss: 0.331961\tBest loss: 0.330887\tAccuracy: 92.30%\n",
      "313\tValidation loss: 0.334401\tBest loss: 0.330887\tAccuracy: 92.50%\n",
      "314\tValidation loss: 0.331223\tBest loss: 0.330887\tAccuracy: 92.70%\n",
      "315\tValidation loss: 0.333102\tBest loss: 0.330887\tAccuracy: 92.50%\n",
      "316\tValidation loss: 0.333989\tBest loss: 0.330887\tAccuracy: 92.50%\n",
      "317\tValidation loss: 0.334391\tBest loss: 0.330887\tAccuracy: 92.70%\n",
      "318\tValidation loss: 0.331361\tBest loss: 0.330887\tAccuracy: 92.50%\n",
      "319\tValidation loss: 0.331729\tBest loss: 0.330887\tAccuracy: 92.80%\n",
      "320\tValidation loss: 0.329317\tBest loss: 0.329317\tAccuracy: 92.70%\n",
      "321\tValidation loss: 0.331146\tBest loss: 0.329317\tAccuracy: 92.80%\n",
      "322\tValidation loss: 0.330447\tBest loss: 0.329317\tAccuracy: 92.60%\n",
      "323\tValidation loss: 0.332623\tBest loss: 0.329317\tAccuracy: 92.60%\n",
      "324\tValidation loss: 0.330963\tBest loss: 0.329317\tAccuracy: 92.70%\n",
      "325\tValidation loss: 0.331914\tBest loss: 0.329317\tAccuracy: 92.40%\n",
      "326\tValidation loss: 0.330429\tBest loss: 0.329317\tAccuracy: 92.80%\n",
      "327\tValidation loss: 0.330728\tBest loss: 0.329317\tAccuracy: 92.60%\n",
      "328\tValidation loss: 0.330614\tBest loss: 0.329317\tAccuracy: 92.50%\n",
      "329\tValidation loss: 0.332503\tBest loss: 0.329317\tAccuracy: 92.50%\n",
      "330\tValidation loss: 0.330862\tBest loss: 0.329317\tAccuracy: 93.00%\n",
      "331\tValidation loss: 0.329892\tBest loss: 0.329317\tAccuracy: 92.80%\n",
      "332\tValidation loss: 0.329774\tBest loss: 0.329317\tAccuracy: 92.50%\n",
      "333\tValidation loss: 0.329926\tBest loss: 0.329317\tAccuracy: 92.90%\n",
      "334\tValidation loss: 0.331106\tBest loss: 0.329317\tAccuracy: 92.80%\n",
      "335\tValidation loss: 0.327966\tBest loss: 0.327966\tAccuracy: 92.80%\n",
      "336\tValidation loss: 0.326536\tBest loss: 0.326536\tAccuracy: 92.90%\n",
      "337\tValidation loss: 0.329218\tBest loss: 0.326536\tAccuracy: 92.70%\n",
      "338\tValidation loss: 0.326811\tBest loss: 0.326536\tAccuracy: 92.50%\n",
      "339\tValidation loss: 0.329400\tBest loss: 0.326536\tAccuracy: 92.40%\n",
      "340\tValidation loss: 0.330265\tBest loss: 0.326536\tAccuracy: 92.80%\n",
      "341\tValidation loss: 0.327572\tBest loss: 0.326536\tAccuracy: 92.70%\n",
      "342\tValidation loss: 0.328061\tBest loss: 0.326536\tAccuracy: 92.80%\n",
      "343\tValidation loss: 0.326067\tBest loss: 0.326067\tAccuracy: 92.70%\n",
      "344\tValidation loss: 0.327391\tBest loss: 0.326067\tAccuracy: 92.80%\n",
      "345\tValidation loss: 0.327916\tBest loss: 0.326067\tAccuracy: 92.70%\n",
      "346\tValidation loss: 0.327386\tBest loss: 0.326067\tAccuracy: 92.80%\n",
      "347\tValidation loss: 0.329343\tBest loss: 0.326067\tAccuracy: 92.80%\n",
      "348\tValidation loss: 0.326088\tBest loss: 0.326067\tAccuracy: 92.50%\n",
      "349\tValidation loss: 0.328597\tBest loss: 0.326067\tAccuracy: 92.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\tValidation loss: 0.329801\tBest loss: 0.326067\tAccuracy: 92.80%\n",
      "351\tValidation loss: 0.326463\tBest loss: 0.326067\tAccuracy: 92.80%\n",
      "352\tValidation loss: 0.325885\tBest loss: 0.325885\tAccuracy: 92.70%\n",
      "353\tValidation loss: 0.327923\tBest loss: 0.325885\tAccuracy: 92.50%\n",
      "354\tValidation loss: 0.327988\tBest loss: 0.325885\tAccuracy: 92.60%\n",
      "355\tValidation loss: 0.324575\tBest loss: 0.324575\tAccuracy: 92.90%\n",
      "356\tValidation loss: 0.325716\tBest loss: 0.324575\tAccuracy: 92.70%\n",
      "357\tValidation loss: 0.327164\tBest loss: 0.324575\tAccuracy: 92.80%\n",
      "358\tValidation loss: 0.325595\tBest loss: 0.324575\tAccuracy: 92.50%\n",
      "359\tValidation loss: 0.323480\tBest loss: 0.323480\tAccuracy: 92.80%\n",
      "360\tValidation loss: 0.325782\tBest loss: 0.323480\tAccuracy: 92.80%\n",
      "361\tValidation loss: 0.326236\tBest loss: 0.323480\tAccuracy: 92.60%\n",
      "362\tValidation loss: 0.326623\tBest loss: 0.323480\tAccuracy: 92.90%\n",
      "363\tValidation loss: 0.325963\tBest loss: 0.323480\tAccuracy: 92.80%\n",
      "364\tValidation loss: 0.324720\tBest loss: 0.323480\tAccuracy: 92.70%\n",
      "365\tValidation loss: 0.325757\tBest loss: 0.323480\tAccuracy: 92.40%\n",
      "366\tValidation loss: 0.325662\tBest loss: 0.323480\tAccuracy: 92.60%\n",
      "367\tValidation loss: 0.324420\tBest loss: 0.323480\tAccuracy: 92.70%\n",
      "368\tValidation loss: 0.324353\tBest loss: 0.323480\tAccuracy: 92.70%\n",
      "369\tValidation loss: 0.323470\tBest loss: 0.323470\tAccuracy: 92.80%\n",
      "370\tValidation loss: 0.324349\tBest loss: 0.323470\tAccuracy: 92.60%\n",
      "371\tValidation loss: 0.324399\tBest loss: 0.323470\tAccuracy: 92.60%\n",
      "372\tValidation loss: 0.323525\tBest loss: 0.323470\tAccuracy: 92.70%\n",
      "373\tValidation loss: 0.325005\tBest loss: 0.323470\tAccuracy: 92.80%\n",
      "374\tValidation loss: 0.325297\tBest loss: 0.323470\tAccuracy: 92.70%\n",
      "375\tValidation loss: 0.324559\tBest loss: 0.323470\tAccuracy: 92.60%\n",
      "376\tValidation loss: 0.323628\tBest loss: 0.323470\tAccuracy: 92.70%\n",
      "377\tValidation loss: 0.323334\tBest loss: 0.323334\tAccuracy: 92.70%\n",
      "378\tValidation loss: 0.322600\tBest loss: 0.322600\tAccuracy: 92.60%\n",
      "379\tValidation loss: 0.324264\tBest loss: 0.322600\tAccuracy: 92.60%\n",
      "380\tValidation loss: 0.323449\tBest loss: 0.322600\tAccuracy: 92.60%\n",
      "381\tValidation loss: 0.322866\tBest loss: 0.322600\tAccuracy: 92.80%\n",
      "382\tValidation loss: 0.323960\tBest loss: 0.322600\tAccuracy: 92.70%\n",
      "383\tValidation loss: 0.323157\tBest loss: 0.322600\tAccuracy: 92.70%\n",
      "384\tValidation loss: 0.321957\tBest loss: 0.321957\tAccuracy: 92.80%\n",
      "385\tValidation loss: 0.323043\tBest loss: 0.321957\tAccuracy: 92.70%\n",
      "386\tValidation loss: 0.323528\tBest loss: 0.321957\tAccuracy: 92.70%\n",
      "387\tValidation loss: 0.321959\tBest loss: 0.321957\tAccuracy: 92.80%\n",
      "388\tValidation loss: 0.320476\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "389\tValidation loss: 0.323254\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "390\tValidation loss: 0.325267\tBest loss: 0.320476\tAccuracy: 92.60%\n",
      "391\tValidation loss: 0.321940\tBest loss: 0.320476\tAccuracy: 92.60%\n",
      "392\tValidation loss: 0.322732\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "393\tValidation loss: 0.324367\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "394\tValidation loss: 0.321728\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "395\tValidation loss: 0.320677\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "396\tValidation loss: 0.323727\tBest loss: 0.320476\tAccuracy: 92.60%\n",
      "397\tValidation loss: 0.321898\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "398\tValidation loss: 0.320532\tBest loss: 0.320476\tAccuracy: 92.70%\n",
      "399\tValidation loss: 0.321393\tBest loss: 0.320476\tAccuracy: 92.60%\n",
      "400\tValidation loss: 0.321486\tBest loss: 0.320476\tAccuracy: 92.60%\n",
      "401\tValidation loss: 0.320503\tBest loss: 0.320476\tAccuracy: 92.80%\n",
      "402\tValidation loss: 0.320083\tBest loss: 0.320083\tAccuracy: 92.80%\n",
      "403\tValidation loss: 0.320901\tBest loss: 0.320083\tAccuracy: 92.70%\n",
      "404\tValidation loss: 0.321722\tBest loss: 0.320083\tAccuracy: 92.80%\n",
      "405\tValidation loss: 0.318528\tBest loss: 0.318528\tAccuracy: 92.80%\n",
      "406\tValidation loss: 0.321779\tBest loss: 0.318528\tAccuracy: 92.80%\n",
      "407\tValidation loss: 0.320983\tBest loss: 0.318528\tAccuracy: 92.70%\n",
      "408\tValidation loss: 0.322127\tBest loss: 0.318528\tAccuracy: 92.70%\n",
      "409\tValidation loss: 0.318497\tBest loss: 0.318497\tAccuracy: 92.70%\n",
      "410\tValidation loss: 0.320211\tBest loss: 0.318497\tAccuracy: 92.60%\n",
      "411\tValidation loss: 0.319147\tBest loss: 0.318497\tAccuracy: 92.70%\n",
      "412\tValidation loss: 0.319043\tBest loss: 0.318497\tAccuracy: 92.70%\n",
      "413\tValidation loss: 0.319374\tBest loss: 0.318497\tAccuracy: 92.60%\n",
      "414\tValidation loss: 0.319208\tBest loss: 0.318497\tAccuracy: 92.70%\n",
      "415\tValidation loss: 0.318579\tBest loss: 0.318497\tAccuracy: 92.70%\n",
      "416\tValidation loss: 0.317357\tBest loss: 0.317357\tAccuracy: 92.70%\n",
      "417\tValidation loss: 0.319301\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "418\tValidation loss: 0.319437\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "419\tValidation loss: 0.319373\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "420\tValidation loss: 0.318204\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "421\tValidation loss: 0.318699\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "422\tValidation loss: 0.321034\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "423\tValidation loss: 0.318703\tBest loss: 0.317357\tAccuracy: 92.70%\n",
      "424\tValidation loss: 0.318124\tBest loss: 0.317357\tAccuracy: 92.70%\n",
      "425\tValidation loss: 0.318246\tBest loss: 0.317357\tAccuracy: 92.70%\n",
      "426\tValidation loss: 0.318684\tBest loss: 0.317357\tAccuracy: 92.80%\n",
      "427\tValidation loss: 0.319763\tBest loss: 0.317357\tAccuracy: 92.70%\n",
      "428\tValidation loss: 0.317216\tBest loss: 0.317216\tAccuracy: 92.80%\n",
      "429\tValidation loss: 0.318471\tBest loss: 0.317216\tAccuracy: 92.80%\n",
      "430\tValidation loss: 0.318715\tBest loss: 0.317216\tAccuracy: 92.80%\n",
      "431\tValidation loss: 0.318667\tBest loss: 0.317216\tAccuracy: 92.80%\n",
      "432\tValidation loss: 0.316993\tBest loss: 0.316993\tAccuracy: 92.60%\n",
      "433\tValidation loss: 0.318530\tBest loss: 0.316993\tAccuracy: 92.90%\n",
      "434\tValidation loss: 0.320670\tBest loss: 0.316993\tAccuracy: 92.80%\n",
      "435\tValidation loss: 0.317465\tBest loss: 0.316993\tAccuracy: 92.70%\n",
      "436\tValidation loss: 0.318842\tBest loss: 0.316993\tAccuracy: 92.70%\n",
      "437\tValidation loss: 0.317869\tBest loss: 0.316993\tAccuracy: 92.80%\n",
      "438\tValidation loss: 0.318127\tBest loss: 0.316993\tAccuracy: 92.80%\n",
      "439\tValidation loss: 0.319072\tBest loss: 0.316993\tAccuracy: 92.80%\n",
      "440\tValidation loss: 0.316483\tBest loss: 0.316483\tAccuracy: 92.70%\n",
      "441\tValidation loss: 0.319116\tBest loss: 0.316483\tAccuracy: 92.70%\n",
      "442\tValidation loss: 0.319707\tBest loss: 0.316483\tAccuracy: 92.80%\n",
      "443\tValidation loss: 0.317231\tBest loss: 0.316483\tAccuracy: 92.60%\n",
      "444\tValidation loss: 0.316515\tBest loss: 0.316483\tAccuracy: 92.80%\n",
      "445\tValidation loss: 0.315691\tBest loss: 0.315691\tAccuracy: 92.80%\n",
      "446\tValidation loss: 0.316720\tBest loss: 0.315691\tAccuracy: 92.80%\n",
      "447\tValidation loss: 0.319505\tBest loss: 0.315691\tAccuracy: 92.70%\n",
      "448\tValidation loss: 0.317237\tBest loss: 0.315691\tAccuracy: 92.90%\n",
      "449\tValidation loss: 0.315581\tBest loss: 0.315581\tAccuracy: 92.80%\n",
      "450\tValidation loss: 0.316764\tBest loss: 0.315581\tAccuracy: 92.90%\n",
      "451\tValidation loss: 0.315893\tBest loss: 0.315581\tAccuracy: 92.70%\n",
      "452\tValidation loss: 0.318500\tBest loss: 0.315581\tAccuracy: 92.70%\n",
      "453\tValidation loss: 0.315537\tBest loss: 0.315537\tAccuracy: 92.70%\n",
      "454\tValidation loss: 0.317497\tBest loss: 0.315537\tAccuracy: 92.70%\n",
      "455\tValidation loss: 0.316948\tBest loss: 0.315537\tAccuracy: 92.70%\n",
      "456\tValidation loss: 0.317439\tBest loss: 0.315537\tAccuracy: 92.60%\n",
      "457\tValidation loss: 0.315532\tBest loss: 0.315532\tAccuracy: 92.70%\n",
      "458\tValidation loss: 0.315842\tBest loss: 0.315532\tAccuracy: 92.70%\n",
      "459\tValidation loss: 0.315341\tBest loss: 0.315341\tAccuracy: 92.60%\n",
      "460\tValidation loss: 0.316366\tBest loss: 0.315341\tAccuracy: 92.80%\n",
      "461\tValidation loss: 0.317699\tBest loss: 0.315341\tAccuracy: 92.80%\n",
      "462\tValidation loss: 0.316632\tBest loss: 0.315341\tAccuracy: 92.80%\n",
      "463\tValidation loss: 0.316485\tBest loss: 0.315341\tAccuracy: 92.80%\n",
      "464\tValidation loss: 0.315963\tBest loss: 0.315341\tAccuracy: 92.80%\n",
      "465\tValidation loss: 0.316358\tBest loss: 0.315341\tAccuracy: 92.70%\n",
      "466\tValidation loss: 0.316491\tBest loss: 0.315341\tAccuracy: 92.60%\n",
      "467\tValidation loss: 0.314064\tBest loss: 0.314064\tAccuracy: 92.60%\n",
      "468\tValidation loss: 0.316120\tBest loss: 0.314064\tAccuracy: 92.80%\n",
      "469\tValidation loss: 0.315267\tBest loss: 0.314064\tAccuracy: 92.80%\n",
      "470\tValidation loss: 0.315813\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "471\tValidation loss: 0.318503\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "472\tValidation loss: 0.316097\tBest loss: 0.314064\tAccuracy: 92.80%\n",
      "473\tValidation loss: 0.315834\tBest loss: 0.314064\tAccuracy: 92.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\tValidation loss: 0.318441\tBest loss: 0.314064\tAccuracy: 92.60%\n",
      "475\tValidation loss: 0.315262\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "476\tValidation loss: 0.315656\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "477\tValidation loss: 0.316749\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "478\tValidation loss: 0.314586\tBest loss: 0.314064\tAccuracy: 92.60%\n",
      "479\tValidation loss: 0.315913\tBest loss: 0.314064\tAccuracy: 92.60%\n",
      "480\tValidation loss: 0.316373\tBest loss: 0.314064\tAccuracy: 92.70%\n",
      "481\tValidation loss: 0.314745\tBest loss: 0.314064\tAccuracy: 92.80%\n",
      "482\tValidation loss: 0.313272\tBest loss: 0.313272\tAccuracy: 92.90%\n",
      "483\tValidation loss: 0.312920\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "484\tValidation loss: 0.314375\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "485\tValidation loss: 0.315338\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "486\tValidation loss: 0.315896\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "487\tValidation loss: 0.313873\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "488\tValidation loss: 0.314737\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "489\tValidation loss: 0.315056\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "490\tValidation loss: 0.316815\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "491\tValidation loss: 0.314043\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "492\tValidation loss: 0.314887\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "493\tValidation loss: 0.315225\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "494\tValidation loss: 0.314380\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "495\tValidation loss: 0.315400\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "496\tValidation loss: 0.313508\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "497\tValidation loss: 0.314559\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "498\tValidation loss: 0.314650\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "499\tValidation loss: 0.315647\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "500\tValidation loss: 0.315465\tBest loss: 0.312920\tAccuracy: 92.70%\n",
      "501\tValidation loss: 0.314521\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "502\tValidation loss: 0.313205\tBest loss: 0.312920\tAccuracy: 92.80%\n",
      "503\tValidation loss: 0.313228\tBest loss: 0.312920\tAccuracy: 92.90%\n",
      "504\tValidation loss: 0.313142\tBest loss: 0.312920\tAccuracy: 92.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.1min\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.041769\tBest loss: 3.041769\tAccuracy: 24.40%\n",
      "1\tValidation loss: 2.355861\tBest loss: 2.355861\tAccuracy: 39.60%\n",
      "2\tValidation loss: 1.186719\tBest loss: 1.186719\tAccuracy: 68.70%\n",
      "3\tValidation loss: 1.741439\tBest loss: 1.186719\tAccuracy: 57.50%\n",
      "4\tValidation loss: 0.984685\tBest loss: 0.984685\tAccuracy: 73.80%\n",
      "5\tValidation loss: 1.025221\tBest loss: 0.984685\tAccuracy: 74.60%\n",
      "6\tValidation loss: 0.767529\tBest loss: 0.767529\tAccuracy: 81.00%\n",
      "7\tValidation loss: 0.603283\tBest loss: 0.603283\tAccuracy: 84.50%\n",
      "8\tValidation loss: 1.758322\tBest loss: 0.603283\tAccuracy: 68.50%\n",
      "9\tValidation loss: 0.696341\tBest loss: 0.603283\tAccuracy: 83.10%\n",
      "10\tValidation loss: 0.559612\tBest loss: 0.559612\tAccuracy: 86.20%\n",
      "11\tValidation loss: 0.538531\tBest loss: 0.538531\tAccuracy: 89.20%\n",
      "12\tValidation loss: 0.874127\tBest loss: 0.538531\tAccuracy: 84.70%\n",
      "13\tValidation loss: 0.734399\tBest loss: 0.538531\tAccuracy: 86.70%\n",
      "14\tValidation loss: 0.901524\tBest loss: 0.538531\tAccuracy: 85.10%\n",
      "15\tValidation loss: 0.644105\tBest loss: 0.538531\tAccuracy: 88.10%\n",
      "16\tValidation loss: 0.668097\tBest loss: 0.538531\tAccuracy: 87.20%\n",
      "17\tValidation loss: 0.824223\tBest loss: 0.538531\tAccuracy: 86.80%\n",
      "18\tValidation loss: 0.651203\tBest loss: 0.538531\tAccuracy: 91.30%\n",
      "19\tValidation loss: 1.049651\tBest loss: 0.538531\tAccuracy: 86.10%\n",
      "20\tValidation loss: 0.779181\tBest loss: 0.538531\tAccuracy: 88.90%\n",
      "21\tValidation loss: 0.775990\tBest loss: 0.538531\tAccuracy: 89.50%\n",
      "22\tValidation loss: 0.754242\tBest loss: 0.538531\tAccuracy: 89.20%\n",
      "23\tValidation loss: 0.557721\tBest loss: 0.538531\tAccuracy: 91.30%\n",
      "24\tValidation loss: 0.915767\tBest loss: 0.538531\tAccuracy: 91.40%\n",
      "25\tValidation loss: 1.392229\tBest loss: 0.538531\tAccuracy: 88.20%\n",
      "26\tValidation loss: 0.721787\tBest loss: 0.538531\tAccuracy: 90.90%\n",
      "27\tValidation loss: 0.870160\tBest loss: 0.538531\tAccuracy: 92.20%\n",
      "28\tValidation loss: 0.595856\tBest loss: 0.538531\tAccuracy: 94.30%\n",
      "29\tValidation loss: 1.048727\tBest loss: 0.538531\tAccuracy: 89.30%\n",
      "30\tValidation loss: 0.620906\tBest loss: 0.538531\tAccuracy: 93.60%\n",
      "31\tValidation loss: 0.804057\tBest loss: 0.538531\tAccuracy: 93.70%\n",
      "32\tValidation loss: 0.719954\tBest loss: 0.538531\tAccuracy: 93.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.4s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.958900\tBest loss: 2.958900\tAccuracy: 27.20%\n",
      "1\tValidation loss: 2.009937\tBest loss: 2.009937\tAccuracy: 47.80%\n",
      "2\tValidation loss: 1.207957\tBest loss: 1.207957\tAccuracy: 69.10%\n",
      "3\tValidation loss: 1.162880\tBest loss: 1.162880\tAccuracy: 69.70%\n",
      "4\tValidation loss: 1.428167\tBest loss: 1.162880\tAccuracy: 63.50%\n",
      "5\tValidation loss: 1.658704\tBest loss: 1.162880\tAccuracy: 65.20%\n",
      "6\tValidation loss: 0.601509\tBest loss: 0.601509\tAccuracy: 84.00%\n",
      "7\tValidation loss: 0.892872\tBest loss: 0.601509\tAccuracy: 77.90%\n",
      "8\tValidation loss: 0.933755\tBest loss: 0.601509\tAccuracy: 78.80%\n",
      "9\tValidation loss: 0.560235\tBest loss: 0.560235\tAccuracy: 87.00%\n",
      "10\tValidation loss: 0.592076\tBest loss: 0.560235\tAccuracy: 86.30%\n",
      "11\tValidation loss: 0.570137\tBest loss: 0.560235\tAccuracy: 87.40%\n",
      "12\tValidation loss: 0.599894\tBest loss: 0.560235\tAccuracy: 88.20%\n",
      "13\tValidation loss: 0.906159\tBest loss: 0.560235\tAccuracy: 84.40%\n",
      "14\tValidation loss: 0.598405\tBest loss: 0.560235\tAccuracy: 89.10%\n",
      "15\tValidation loss: 0.601962\tBest loss: 0.560235\tAccuracy: 89.80%\n",
      "16\tValidation loss: 0.684280\tBest loss: 0.560235\tAccuracy: 88.10%\n",
      "17\tValidation loss: 0.587702\tBest loss: 0.560235\tAccuracy: 91.40%\n",
      "18\tValidation loss: 1.212160\tBest loss: 0.560235\tAccuracy: 86.60%\n",
      "19\tValidation loss: 0.510884\tBest loss: 0.510884\tAccuracy: 92.40%\n",
      "20\tValidation loss: 0.716310\tBest loss: 0.510884\tAccuracy: 89.30%\n",
      "21\tValidation loss: 1.290711\tBest loss: 0.510884\tAccuracy: 86.00%\n",
      "22\tValidation loss: 0.738039\tBest loss: 0.510884\tAccuracy: 89.10%\n",
      "23\tValidation loss: 0.923201\tBest loss: 0.510884\tAccuracy: 88.60%\n",
      "24\tValidation loss: 0.855536\tBest loss: 0.510884\tAccuracy: 88.30%\n",
      "25\tValidation loss: 0.720889\tBest loss: 0.510884\tAccuracy: 92.90%\n",
      "26\tValidation loss: 1.086557\tBest loss: 0.510884\tAccuracy: 89.90%\n",
      "27\tValidation loss: 0.848553\tBest loss: 0.510884\tAccuracy: 91.40%\n",
      "28\tValidation loss: 1.131467\tBest loss: 0.510884\tAccuracy: 89.60%\n",
      "29\tValidation loss: 0.694274\tBest loss: 0.510884\tAccuracy: 92.30%\n",
      "30\tValidation loss: 0.883111\tBest loss: 0.510884\tAccuracy: 91.70%\n",
      "31\tValidation loss: 1.347049\tBest loss: 0.510884\tAccuracy: 87.90%\n",
      "32\tValidation loss: 0.888096\tBest loss: 0.510884\tAccuracy: 92.40%\n",
      "33\tValidation loss: 1.069526\tBest loss: 0.510884\tAccuracy: 90.80%\n",
      "34\tValidation loss: 1.103516\tBest loss: 0.510884\tAccuracy: 90.10%\n",
      "35\tValidation loss: 1.217493\tBest loss: 0.510884\tAccuracy: 92.00%\n",
      "36\tValidation loss: 0.955208\tBest loss: 0.510884\tAccuracy: 92.20%\n",
      "37\tValidation loss: 1.270787\tBest loss: 0.510884\tAccuracy: 90.40%\n",
      "38\tValidation loss: 1.161787\tBest loss: 0.510884\tAccuracy: 89.80%\n",
      "39\tValidation loss: 1.113255\tBest loss: 0.510884\tAccuracy: 92.20%\n",
      "40\tValidation loss: 1.099972\tBest loss: 0.510884\tAccuracy: 91.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   5.2s\n",
      "[CV] batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.118266\tBest loss: 3.118266\tAccuracy: 25.40%\n",
      "1\tValidation loss: 1.690436\tBest loss: 1.690436\tAccuracy: 55.50%\n",
      "2\tValidation loss: 1.198839\tBest loss: 1.198839\tAccuracy: 67.60%\n",
      "3\tValidation loss: 1.290990\tBest loss: 1.198839\tAccuracy: 66.00%\n",
      "4\tValidation loss: 0.921845\tBest loss: 0.921845\tAccuracy: 74.30%\n",
      "5\tValidation loss: 0.738077\tBest loss: 0.738077\tAccuracy: 78.90%\n",
      "6\tValidation loss: 0.833602\tBest loss: 0.738077\tAccuracy: 78.30%\n",
      "7\tValidation loss: 0.655404\tBest loss: 0.655404\tAccuracy: 83.60%\n",
      "8\tValidation loss: 0.497892\tBest loss: 0.497892\tAccuracy: 86.80%\n",
      "9\tValidation loss: 0.873811\tBest loss: 0.497892\tAccuracy: 80.60%\n",
      "10\tValidation loss: 0.590978\tBest loss: 0.497892\tAccuracy: 86.40%\n",
      "11\tValidation loss: 0.777020\tBest loss: 0.497892\tAccuracy: 83.90%\n",
      "12\tValidation loss: 0.394270\tBest loss: 0.394270\tAccuracy: 90.40%\n",
      "13\tValidation loss: 0.695328\tBest loss: 0.394270\tAccuracy: 85.50%\n",
      "14\tValidation loss: 0.958511\tBest loss: 0.394270\tAccuracy: 83.20%\n",
      "15\tValidation loss: 0.489809\tBest loss: 0.394270\tAccuracy: 90.30%\n",
      "16\tValidation loss: 0.988104\tBest loss: 0.394270\tAccuracy: 85.50%\n",
      "17\tValidation loss: 0.552157\tBest loss: 0.394270\tAccuracy: 90.70%\n",
      "18\tValidation loss: 0.663527\tBest loss: 0.394270\tAccuracy: 89.10%\n",
      "19\tValidation loss: 0.594791\tBest loss: 0.394270\tAccuracy: 90.50%\n",
      "20\tValidation loss: 0.521875\tBest loss: 0.394270\tAccuracy: 91.00%\n",
      "21\tValidation loss: 0.939417\tBest loss: 0.394270\tAccuracy: 85.50%\n",
      "22\tValidation loss: 0.837088\tBest loss: 0.394270\tAccuracy: 87.70%\n",
      "23\tValidation loss: 1.670104\tBest loss: 0.394270\tAccuracy: 82.30%\n",
      "24\tValidation loss: 1.245474\tBest loss: 0.394270\tAccuracy: 85.60%\n",
      "25\tValidation loss: 0.941588\tBest loss: 0.394270\tAccuracy: 90.50%\n",
      "26\tValidation loss: 0.783728\tBest loss: 0.394270\tAccuracy: 90.20%\n",
      "27\tValidation loss: 1.004094\tBest loss: 0.394270\tAccuracy: 89.90%\n",
      "28\tValidation loss: 0.615881\tBest loss: 0.394270\tAccuracy: 92.40%\n",
      "29\tValidation loss: 0.719826\tBest loss: 0.394270\tAccuracy: 91.50%\n",
      "30\tValidation loss: 0.974427\tBest loss: 0.394270\tAccuracy: 92.30%\n",
      "31\tValidation loss: 0.834619\tBest loss: 0.394270\tAccuracy: 91.90%\n",
      "32\tValidation loss: 0.772228\tBest loss: 0.394270\tAccuracy: 92.80%\n",
      "33\tValidation loss: 2.162992\tBest loss: 0.394270\tAccuracy: 84.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.3s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.610386\tBest loss: 5.610386\tAccuracy: 11.80%\n",
      "1\tValidation loss: 20.706865\tBest loss: 5.610386\tAccuracy: 7.60%\n",
      "2\tValidation loss: 28.127443\tBest loss: 5.610386\tAccuracy: 15.40%\n",
      "3\tValidation loss: 40.027901\tBest loss: 5.610386\tAccuracy: 17.50%\n",
      "4\tValidation loss: 11.948871\tBest loss: 5.610386\tAccuracy: 34.60%\n",
      "5\tValidation loss: 21.383369\tBest loss: 5.610386\tAccuracy: 37.60%\n",
      "6\tValidation loss: 35.212887\tBest loss: 5.610386\tAccuracy: 36.20%\n",
      "7\tValidation loss: 10.750209\tBest loss: 5.610386\tAccuracy: 46.90%\n",
      "8\tValidation loss: 4.996675\tBest loss: 4.996675\tAccuracy: 64.60%\n",
      "9\tValidation loss: 3.301948\tBest loss: 3.301948\tAccuracy: 71.30%\n",
      "10\tValidation loss: 4.017067\tBest loss: 3.301948\tAccuracy: 75.90%\n",
      "11\tValidation loss: 15.323221\tBest loss: 3.301948\tAccuracy: 58.10%\n",
      "12\tValidation loss: 12.143646\tBest loss: 3.301948\tAccuracy: 61.00%\n",
      "13\tValidation loss: 16.419516\tBest loss: 3.301948\tAccuracy: 55.60%\n",
      "14\tValidation loss: 13.390932\tBest loss: 3.301948\tAccuracy: 61.00%\n",
      "15\tValidation loss: 31.825581\tBest loss: 3.301948\tAccuracy: 50.10%\n",
      "16\tValidation loss: 4.170038\tBest loss: 3.301948\tAccuracy: 76.40%\n",
      "17\tValidation loss: 2.651135\tBest loss: 2.651135\tAccuracy: 82.80%\n",
      "18\tValidation loss: 2.128209\tBest loss: 2.128209\tAccuracy: 86.50%\n",
      "19\tValidation loss: 2.567635\tBest loss: 2.128209\tAccuracy: 85.30%\n",
      "20\tValidation loss: 2.924685\tBest loss: 2.128209\tAccuracy: 84.40%\n",
      "21\tValidation loss: 15.213860\tBest loss: 2.128209\tAccuracy: 68.90%\n",
      "22\tValidation loss: 14.972541\tBest loss: 2.128209\tAccuracy: 68.50%\n",
      "23\tValidation loss: 11.066692\tBest loss: 2.128209\tAccuracy: 76.00%\n",
      "24\tValidation loss: 5.402838\tBest loss: 2.128209\tAccuracy: 79.20%\n",
      "25\tValidation loss: 6.213231\tBest loss: 2.128209\tAccuracy: 80.00%\n",
      "26\tValidation loss: 7.446309\tBest loss: 2.128209\tAccuracy: 78.50%\n",
      "27\tValidation loss: 6.504197\tBest loss: 2.128209\tAccuracy: 80.50%\n",
      "28\tValidation loss: 3.075715\tBest loss: 2.128209\tAccuracy: 87.70%\n",
      "29\tValidation loss: 2.942622\tBest loss: 2.128209\tAccuracy: 88.40%\n",
      "30\tValidation loss: 4.038846\tBest loss: 2.128209\tAccuracy: 87.20%\n",
      "31\tValidation loss: 3.636008\tBest loss: 2.128209\tAccuracy: 89.40%\n",
      "32\tValidation loss: 4.037868\tBest loss: 2.128209\tAccuracy: 87.30%\n",
      "33\tValidation loss: 4.756838\tBest loss: 2.128209\tAccuracy: 87.20%\n",
      "34\tValidation loss: 6.333899\tBest loss: 2.128209\tAccuracy: 86.50%\n",
      "35\tValidation loss: 5.449880\tBest loss: 2.128209\tAccuracy: 84.60%\n",
      "36\tValidation loss: 7.603795\tBest loss: 2.128209\tAccuracy: 86.20%\n",
      "37\tValidation loss: 7.578445\tBest loss: 2.128209\tAccuracy: 85.90%\n",
      "38\tValidation loss: 6.919396\tBest loss: 2.128209\tAccuracy: 87.60%\n",
      "39\tValidation loss: 5.698252\tBest loss: 2.128209\tAccuracy: 87.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.1s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.975982\tBest loss: 5.975982\tAccuracy: 11.40%\n",
      "1\tValidation loss: 18.580454\tBest loss: 5.975982\tAccuracy: 6.50%\n",
      "2\tValidation loss: 43.389969\tBest loss: 5.975982\tAccuracy: 8.30%\n",
      "3\tValidation loss: 17.533516\tBest loss: 5.975982\tAccuracy: 23.00%\n",
      "4\tValidation loss: 11.014057\tBest loss: 5.975982\tAccuracy: 36.50%\n",
      "5\tValidation loss: 18.553856\tBest loss: 5.975982\tAccuracy: 35.70%\n",
      "6\tValidation loss: 14.504329\tBest loss: 5.975982\tAccuracy: 45.40%\n",
      "7\tValidation loss: 9.345593\tBest loss: 5.975982\tAccuracy: 55.10%\n",
      "8\tValidation loss: 31.174801\tBest loss: 5.975982\tAccuracy: 36.30%\n",
      "9\tValidation loss: 14.330125\tBest loss: 5.975982\tAccuracy: 51.20%\n",
      "10\tValidation loss: 16.866365\tBest loss: 5.975982\tAccuracy: 46.30%\n",
      "11\tValidation loss: 5.017760\tBest loss: 5.017760\tAccuracy: 67.80%\n",
      "12\tValidation loss: 4.150595\tBest loss: 4.150595\tAccuracy: 72.30%\n",
      "13\tValidation loss: 2.977565\tBest loss: 2.977565\tAccuracy: 77.40%\n",
      "14\tValidation loss: 2.056763\tBest loss: 2.056763\tAccuracy: 83.80%\n",
      "15\tValidation loss: 3.091172\tBest loss: 2.056763\tAccuracy: 76.70%\n",
      "16\tValidation loss: 3.533700\tBest loss: 2.056763\tAccuracy: 76.50%\n",
      "17\tValidation loss: 2.343591\tBest loss: 2.056763\tAccuracy: 85.30%\n",
      "18\tValidation loss: 2.197979\tBest loss: 2.056763\tAccuracy: 86.50%\n",
      "19\tValidation loss: 3.090240\tBest loss: 2.056763\tAccuracy: 84.80%\n",
      "20\tValidation loss: 2.818993\tBest loss: 2.056763\tAccuracy: 84.10%\n",
      "21\tValidation loss: 3.375288\tBest loss: 2.056763\tAccuracy: 82.60%\n",
      "22\tValidation loss: 5.381098\tBest loss: 2.056763\tAccuracy: 76.30%\n",
      "23\tValidation loss: 3.035960\tBest loss: 2.056763\tAccuracy: 86.70%\n",
      "24\tValidation loss: 2.496786\tBest loss: 2.056763\tAccuracy: 87.10%\n",
      "25\tValidation loss: 6.502273\tBest loss: 2.056763\tAccuracy: 80.30%\n",
      "26\tValidation loss: 3.401423\tBest loss: 2.056763\tAccuracy: 86.80%\n",
      "27\tValidation loss: 2.466643\tBest loss: 2.056763\tAccuracy: 88.40%\n",
      "28\tValidation loss: 4.558521\tBest loss: 2.056763\tAccuracy: 84.50%\n",
      "29\tValidation loss: 2.445058\tBest loss: 2.056763\tAccuracy: 89.30%\n",
      "30\tValidation loss: 3.175498\tBest loss: 2.056763\tAccuracy: 89.80%\n",
      "31\tValidation loss: 3.082441\tBest loss: 2.056763\tAccuracy: 88.70%\n",
      "32\tValidation loss: 3.132787\tBest loss: 2.056763\tAccuracy: 89.60%\n",
      "33\tValidation loss: 4.956179\tBest loss: 2.056763\tAccuracy: 86.20%\n",
      "34\tValidation loss: 7.822793\tBest loss: 2.056763\tAccuracy: 84.10%\n",
      "35\tValidation loss: 4.662343\tBest loss: 2.056763\tAccuracy: 86.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   3.8s\n",
      "[CV] batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.363914\tBest loss: 4.363914\tAccuracy: 13.00%\n",
      "1\tValidation loss: 28.330559\tBest loss: 4.363914\tAccuracy: 3.30%\n",
      "2\tValidation loss: 35.331558\tBest loss: 4.363914\tAccuracy: 13.80%\n",
      "3\tValidation loss: 20.573061\tBest loss: 4.363914\tAccuracy: 23.90%\n",
      "4\tValidation loss: 21.085129\tBest loss: 4.363914\tAccuracy: 29.20%\n",
      "5\tValidation loss: 10.372267\tBest loss: 4.363914\tAccuracy: 47.10%\n",
      "6\tValidation loss: 32.132664\tBest loss: 4.363914\tAccuracy: 29.20%\n",
      "7\tValidation loss: 3.306161\tBest loss: 3.306161\tAccuracy: 66.40%\n",
      "8\tValidation loss: 3.868587\tBest loss: 3.306161\tAccuracy: 72.90%\n",
      "9\tValidation loss: 28.921684\tBest loss: 3.306161\tAccuracy: 46.40%\n",
      "10\tValidation loss: 14.432593\tBest loss: 3.306161\tAccuracy: 53.50%\n",
      "11\tValidation loss: 3.989312\tBest loss: 3.306161\tAccuracy: 71.60%\n",
      "12\tValidation loss: 2.698358\tBest loss: 2.698358\tAccuracy: 80.70%\n",
      "13\tValidation loss: 4.264676\tBest loss: 2.698358\tAccuracy: 76.90%\n",
      "14\tValidation loss: 7.105461\tBest loss: 2.698358\tAccuracy: 74.90%\n",
      "15\tValidation loss: 21.683809\tBest loss: 2.698358\tAccuracy: 61.50%\n",
      "16\tValidation loss: 6.423582\tBest loss: 2.698358\tAccuracy: 69.20%\n",
      "17\tValidation loss: 2.841779\tBest loss: 2.698358\tAccuracy: 83.00%\n",
      "18\tValidation loss: 2.604443\tBest loss: 2.604443\tAccuracy: 85.90%\n",
      "19\tValidation loss: 8.939875\tBest loss: 2.604443\tAccuracy: 73.20%\n",
      "20\tValidation loss: 4.956543\tBest loss: 2.604443\tAccuracy: 79.80%\n",
      "21\tValidation loss: 3.946063\tBest loss: 2.604443\tAccuracy: 82.60%\n",
      "22\tValidation loss: 3.286276\tBest loss: 2.604443\tAccuracy: 83.90%\n",
      "23\tValidation loss: 3.575124\tBest loss: 2.604443\tAccuracy: 84.10%\n",
      "24\tValidation loss: 3.238071\tBest loss: 2.604443\tAccuracy: 86.20%\n",
      "25\tValidation loss: 3.073355\tBest loss: 2.604443\tAccuracy: 86.70%\n",
      "26\tValidation loss: 2.637807\tBest loss: 2.604443\tAccuracy: 88.30%\n",
      "27\tValidation loss: 4.011759\tBest loss: 2.604443\tAccuracy: 85.00%\n",
      "28\tValidation loss: 3.803991\tBest loss: 2.604443\tAccuracy: 85.30%\n",
      "29\tValidation loss: 4.240681\tBest loss: 2.604443\tAccuracy: 86.00%\n",
      "30\tValidation loss: 3.179895\tBest loss: 2.604443\tAccuracy: 87.80%\n",
      "31\tValidation loss: 4.900265\tBest loss: 2.604443\tAccuracy: 84.40%\n",
      "32\tValidation loss: 4.815771\tBest loss: 2.604443\tAccuracy: 86.40%\n",
      "33\tValidation loss: 3.212970\tBest loss: 2.604443\tAccuracy: 89.80%\n",
      "34\tValidation loss: 4.653088\tBest loss: 2.604443\tAccuracy: 88.10%\n",
      "35\tValidation loss: 9.457241\tBest loss: 2.604443\tAccuracy: 83.50%\n",
      "36\tValidation loss: 4.763589\tBest loss: 2.604443\tAccuracy: 89.20%\n",
      "37\tValidation loss: 4.026465\tBest loss: 2.604443\tAccuracy: 90.10%\n",
      "38\tValidation loss: 3.731332\tBest loss: 2.604443\tAccuracy: 90.80%\n",
      "39\tValidation loss: 5.688059\tBest loss: 2.604443\tAccuracy: 87.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=250, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.3s\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.272872\tBest loss: 1.272872\tAccuracy: 69.80%\n",
      "1\tValidation loss: 0.934907\tBest loss: 0.934907\tAccuracy: 80.10%\n",
      "2\tValidation loss: 0.778315\tBest loss: 0.778315\tAccuracy: 83.10%\n",
      "3\tValidation loss: 0.695580\tBest loss: 0.695580\tAccuracy: 85.50%\n",
      "4\tValidation loss: 0.638722\tBest loss: 0.638722\tAccuracy: 85.80%\n",
      "5\tValidation loss: 0.601456\tBest loss: 0.601456\tAccuracy: 86.90%\n",
      "6\tValidation loss: 0.570976\tBest loss: 0.570976\tAccuracy: 87.20%\n",
      "7\tValidation loss: 0.546186\tBest loss: 0.546186\tAccuracy: 87.40%\n",
      "8\tValidation loss: 0.527430\tBest loss: 0.527430\tAccuracy: 89.40%\n",
      "9\tValidation loss: 0.499201\tBest loss: 0.499201\tAccuracy: 89.60%\n",
      "10\tValidation loss: 0.477945\tBest loss: 0.477945\tAccuracy: 89.40%\n",
      "11\tValidation loss: 0.461326\tBest loss: 0.461326\tAccuracy: 89.90%\n",
      "12\tValidation loss: 0.444933\tBest loss: 0.444933\tAccuracy: 90.50%\n",
      "13\tValidation loss: 0.449124\tBest loss: 0.444933\tAccuracy: 90.00%\n",
      "14\tValidation loss: 0.441723\tBest loss: 0.441723\tAccuracy: 90.70%\n",
      "15\tValidation loss: 0.444142\tBest loss: 0.441723\tAccuracy: 90.30%\n",
      "16\tValidation loss: 0.433484\tBest loss: 0.433484\tAccuracy: 90.20%\n",
      "17\tValidation loss: 0.411446\tBest loss: 0.411446\tAccuracy: 91.20%\n",
      "18\tValidation loss: 0.406130\tBest loss: 0.406130\tAccuracy: 92.00%\n",
      "19\tValidation loss: 0.398875\tBest loss: 0.398875\tAccuracy: 91.60%\n",
      "20\tValidation loss: 0.403089\tBest loss: 0.398875\tAccuracy: 91.50%\n",
      "21\tValidation loss: 0.417803\tBest loss: 0.398875\tAccuracy: 91.20%\n",
      "22\tValidation loss: 0.393602\tBest loss: 0.393602\tAccuracy: 92.40%\n",
      "23\tValidation loss: 0.394566\tBest loss: 0.393602\tAccuracy: 91.80%\n",
      "24\tValidation loss: 0.402012\tBest loss: 0.393602\tAccuracy: 92.00%\n",
      "25\tValidation loss: 0.411018\tBest loss: 0.393602\tAccuracy: 90.90%\n",
      "26\tValidation loss: 0.401612\tBest loss: 0.393602\tAccuracy: 91.40%\n",
      "27\tValidation loss: 0.392017\tBest loss: 0.392017\tAccuracy: 92.00%\n",
      "28\tValidation loss: 0.390435\tBest loss: 0.390435\tAccuracy: 92.40%\n",
      "29\tValidation loss: 0.391118\tBest loss: 0.390435\tAccuracy: 92.40%\n",
      "30\tValidation loss: 0.374598\tBest loss: 0.374598\tAccuracy: 91.90%\n",
      "31\tValidation loss: 0.404491\tBest loss: 0.374598\tAccuracy: 91.70%\n",
      "32\tValidation loss: 0.373448\tBest loss: 0.373448\tAccuracy: 92.70%\n",
      "33\tValidation loss: 0.371577\tBest loss: 0.371577\tAccuracy: 92.30%\n",
      "34\tValidation loss: 0.377620\tBest loss: 0.371577\tAccuracy: 92.60%\n",
      "35\tValidation loss: 0.380955\tBest loss: 0.371577\tAccuracy: 92.40%\n",
      "36\tValidation loss: 0.362295\tBest loss: 0.362295\tAccuracy: 92.40%\n",
      "37\tValidation loss: 0.387351\tBest loss: 0.362295\tAccuracy: 92.30%\n",
      "38\tValidation loss: 0.377667\tBest loss: 0.362295\tAccuracy: 92.60%\n",
      "39\tValidation loss: 0.383874\tBest loss: 0.362295\tAccuracy: 92.60%\n",
      "40\tValidation loss: 0.381737\tBest loss: 0.362295\tAccuracy: 92.40%\n",
      "41\tValidation loss: 0.361827\tBest loss: 0.361827\tAccuracy: 93.40%\n",
      "42\tValidation loss: 0.362052\tBest loss: 0.361827\tAccuracy: 93.40%\n",
      "43\tValidation loss: 0.374620\tBest loss: 0.361827\tAccuracy: 92.90%\n",
      "44\tValidation loss: 0.389318\tBest loss: 0.361827\tAccuracy: 92.50%\n",
      "45\tValidation loss: 0.379133\tBest loss: 0.361827\tAccuracy: 92.70%\n",
      "46\tValidation loss: 0.366727\tBest loss: 0.361827\tAccuracy: 93.00%\n",
      "47\tValidation loss: 0.368887\tBest loss: 0.361827\tAccuracy: 93.10%\n",
      "48\tValidation loss: 0.411623\tBest loss: 0.361827\tAccuracy: 92.50%\n",
      "49\tValidation loss: 0.397651\tBest loss: 0.361827\tAccuracy: 92.20%\n",
      "50\tValidation loss: 0.388570\tBest loss: 0.361827\tAccuracy: 92.80%\n",
      "51\tValidation loss: 0.366643\tBest loss: 0.361827\tAccuracy: 93.50%\n",
      "52\tValidation loss: 0.377913\tBest loss: 0.361827\tAccuracy: 93.20%\n",
      "53\tValidation loss: 0.396540\tBest loss: 0.361827\tAccuracy: 92.90%\n",
      "54\tValidation loss: 0.379115\tBest loss: 0.361827\tAccuracy: 93.40%\n",
      "55\tValidation loss: 0.377993\tBest loss: 0.361827\tAccuracy: 93.20%\n",
      "56\tValidation loss: 0.386582\tBest loss: 0.361827\tAccuracy: 93.20%\n",
      "57\tValidation loss: 0.393511\tBest loss: 0.361827\tAccuracy: 92.40%\n",
      "58\tValidation loss: 0.391937\tBest loss: 0.361827\tAccuracy: 93.40%\n",
      "59\tValidation loss: 0.410122\tBest loss: 0.361827\tAccuracy: 92.30%\n",
      "60\tValidation loss: 0.379020\tBest loss: 0.361827\tAccuracy: 93.20%\n",
      "61\tValidation loss: 0.374707\tBest loss: 0.361827\tAccuracy: 93.60%\n",
      "62\tValidation loss: 0.401937\tBest loss: 0.361827\tAccuracy: 92.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   7.3s\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.259205\tBest loss: 1.259205\tAccuracy: 71.20%\n",
      "1\tValidation loss: 0.936005\tBest loss: 0.936005\tAccuracy: 78.20%\n",
      "2\tValidation loss: 0.803951\tBest loss: 0.803951\tAccuracy: 82.50%\n",
      "3\tValidation loss: 0.713079\tBest loss: 0.713079\tAccuracy: 85.20%\n",
      "4\tValidation loss: 0.678501\tBest loss: 0.678501\tAccuracy: 85.20%\n",
      "5\tValidation loss: 0.625406\tBest loss: 0.625406\tAccuracy: 86.60%\n",
      "6\tValidation loss: 0.568376\tBest loss: 0.568376\tAccuracy: 88.90%\n",
      "7\tValidation loss: 0.561187\tBest loss: 0.561187\tAccuracy: 88.20%\n",
      "8\tValidation loss: 0.536106\tBest loss: 0.536106\tAccuracy: 90.00%\n",
      "9\tValidation loss: 0.524906\tBest loss: 0.524906\tAccuracy: 89.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 0.536216\tBest loss: 0.524906\tAccuracy: 89.30%\n",
      "11\tValidation loss: 0.499213\tBest loss: 0.499213\tAccuracy: 90.20%\n",
      "12\tValidation loss: 0.489334\tBest loss: 0.489334\tAccuracy: 90.40%\n",
      "13\tValidation loss: 0.472697\tBest loss: 0.472697\tAccuracy: 89.70%\n",
      "14\tValidation loss: 0.483024\tBest loss: 0.472697\tAccuracy: 90.00%\n",
      "15\tValidation loss: 0.466238\tBest loss: 0.466238\tAccuracy: 91.10%\n",
      "16\tValidation loss: 0.456943\tBest loss: 0.456943\tAccuracy: 91.00%\n",
      "17\tValidation loss: 0.456397\tBest loss: 0.456397\tAccuracy: 91.00%\n",
      "18\tValidation loss: 0.458524\tBest loss: 0.456397\tAccuracy: 91.50%\n",
      "19\tValidation loss: 0.452761\tBest loss: 0.452761\tAccuracy: 90.60%\n",
      "20\tValidation loss: 0.458368\tBest loss: 0.452761\tAccuracy: 90.90%\n",
      "21\tValidation loss: 0.444124\tBest loss: 0.444124\tAccuracy: 92.10%\n",
      "22\tValidation loss: 0.455925\tBest loss: 0.444124\tAccuracy: 90.90%\n",
      "23\tValidation loss: 0.451304\tBest loss: 0.444124\tAccuracy: 91.80%\n",
      "24\tValidation loss: 0.464819\tBest loss: 0.444124\tAccuracy: 91.30%\n",
      "25\tValidation loss: 0.449833\tBest loss: 0.444124\tAccuracy: 91.50%\n",
      "26\tValidation loss: 0.458829\tBest loss: 0.444124\tAccuracy: 91.60%\n",
      "27\tValidation loss: 0.441909\tBest loss: 0.441909\tAccuracy: 91.50%\n",
      "28\tValidation loss: 0.440452\tBest loss: 0.440452\tAccuracy: 92.00%\n",
      "29\tValidation loss: 0.443408\tBest loss: 0.440452\tAccuracy: 91.90%\n",
      "30\tValidation loss: 0.459817\tBest loss: 0.440452\tAccuracy: 91.50%\n",
      "31\tValidation loss: 0.448455\tBest loss: 0.440452\tAccuracy: 91.80%\n",
      "32\tValidation loss: 0.464610\tBest loss: 0.440452\tAccuracy: 92.00%\n",
      "33\tValidation loss: 0.439926\tBest loss: 0.439926\tAccuracy: 91.40%\n",
      "34\tValidation loss: 0.463120\tBest loss: 0.439926\tAccuracy: 92.00%\n",
      "35\tValidation loss: 0.436970\tBest loss: 0.436970\tAccuracy: 92.50%\n",
      "36\tValidation loss: 0.461715\tBest loss: 0.436970\tAccuracy: 92.00%\n",
      "37\tValidation loss: 0.466750\tBest loss: 0.436970\tAccuracy: 92.50%\n",
      "38\tValidation loss: 0.464250\tBest loss: 0.436970\tAccuracy: 92.20%\n",
      "39\tValidation loss: 0.449815\tBest loss: 0.436970\tAccuracy: 92.30%\n",
      "40\tValidation loss: 0.458770\tBest loss: 0.436970\tAccuracy: 92.20%\n",
      "41\tValidation loss: 0.455297\tBest loss: 0.436970\tAccuracy: 92.10%\n",
      "42\tValidation loss: 0.461583\tBest loss: 0.436970\tAccuracy: 91.90%\n",
      "43\tValidation loss: 0.473270\tBest loss: 0.436970\tAccuracy: 91.80%\n",
      "44\tValidation loss: 0.459169\tBest loss: 0.436970\tAccuracy: 91.90%\n",
      "45\tValidation loss: 0.462847\tBest loss: 0.436970\tAccuracy: 92.90%\n",
      "46\tValidation loss: 0.476471\tBest loss: 0.436970\tAccuracy: 91.90%\n",
      "47\tValidation loss: 0.465618\tBest loss: 0.436970\tAccuracy: 92.20%\n",
      "48\tValidation loss: 0.461722\tBest loss: 0.436970\tAccuracy: 92.40%\n",
      "49\tValidation loss: 0.473322\tBest loss: 0.436970\tAccuracy: 92.20%\n",
      "50\tValidation loss: 0.475836\tBest loss: 0.436970\tAccuracy: 92.50%\n",
      "51\tValidation loss: 0.478918\tBest loss: 0.436970\tAccuracy: 92.50%\n",
      "52\tValidation loss: 0.493460\tBest loss: 0.436970\tAccuracy: 91.90%\n",
      "53\tValidation loss: 0.460488\tBest loss: 0.436970\tAccuracy: 92.10%\n",
      "54\tValidation loss: 0.474918\tBest loss: 0.436970\tAccuracy: 92.30%\n",
      "55\tValidation loss: 0.478397\tBest loss: 0.436970\tAccuracy: 91.90%\n",
      "56\tValidation loss: 0.485366\tBest loss: 0.436970\tAccuracy: 91.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.7s\n",
      "[CV] batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.310222\tBest loss: 1.310222\tAccuracy: 68.80%\n",
      "1\tValidation loss: 0.936272\tBest loss: 0.936272\tAccuracy: 79.90%\n",
      "2\tValidation loss: 0.820131\tBest loss: 0.820131\tAccuracy: 82.70%\n",
      "3\tValidation loss: 0.716487\tBest loss: 0.716487\tAccuracy: 84.30%\n",
      "4\tValidation loss: 0.649902\tBest loss: 0.649902\tAccuracy: 85.70%\n",
      "5\tValidation loss: 0.631867\tBest loss: 0.631867\tAccuracy: 86.00%\n",
      "6\tValidation loss: 0.576209\tBest loss: 0.576209\tAccuracy: 87.00%\n",
      "7\tValidation loss: 0.545834\tBest loss: 0.545834\tAccuracy: 87.70%\n",
      "8\tValidation loss: 0.535984\tBest loss: 0.535984\tAccuracy: 87.90%\n",
      "9\tValidation loss: 0.532355\tBest loss: 0.532355\tAccuracy: 88.30%\n",
      "10\tValidation loss: 0.500203\tBest loss: 0.500203\tAccuracy: 89.70%\n",
      "11\tValidation loss: 0.489667\tBest loss: 0.489667\tAccuracy: 89.60%\n",
      "12\tValidation loss: 0.477295\tBest loss: 0.477295\tAccuracy: 90.00%\n",
      "13\tValidation loss: 0.472189\tBest loss: 0.472189\tAccuracy: 90.00%\n",
      "14\tValidation loss: 0.460102\tBest loss: 0.460102\tAccuracy: 90.60%\n",
      "15\tValidation loss: 0.458048\tBest loss: 0.458048\tAccuracy: 90.20%\n",
      "16\tValidation loss: 0.437339\tBest loss: 0.437339\tAccuracy: 90.00%\n",
      "17\tValidation loss: 0.434468\tBest loss: 0.434468\tAccuracy: 90.40%\n",
      "18\tValidation loss: 0.438015\tBest loss: 0.434468\tAccuracy: 90.70%\n",
      "19\tValidation loss: 0.433379\tBest loss: 0.433379\tAccuracy: 90.20%\n",
      "20\tValidation loss: 0.420080\tBest loss: 0.420080\tAccuracy: 91.40%\n",
      "21\tValidation loss: 0.412356\tBest loss: 0.412356\tAccuracy: 90.10%\n",
      "22\tValidation loss: 0.422000\tBest loss: 0.412356\tAccuracy: 91.00%\n",
      "23\tValidation loss: 0.425994\tBest loss: 0.412356\tAccuracy: 90.70%\n",
      "24\tValidation loss: 0.408699\tBest loss: 0.408699\tAccuracy: 91.60%\n",
      "25\tValidation loss: 0.414752\tBest loss: 0.408699\tAccuracy: 91.50%\n",
      "26\tValidation loss: 0.420070\tBest loss: 0.408699\tAccuracy: 92.10%\n",
      "27\tValidation loss: 0.419400\tBest loss: 0.408699\tAccuracy: 91.80%\n",
      "28\tValidation loss: 0.391278\tBest loss: 0.391278\tAccuracy: 91.80%\n",
      "29\tValidation loss: 0.402413\tBest loss: 0.391278\tAccuracy: 92.00%\n",
      "30\tValidation loss: 0.406476\tBest loss: 0.391278\tAccuracy: 91.70%\n",
      "31\tValidation loss: 0.420831\tBest loss: 0.391278\tAccuracy: 91.50%\n",
      "32\tValidation loss: 0.415741\tBest loss: 0.391278\tAccuracy: 91.60%\n",
      "33\tValidation loss: 0.407160\tBest loss: 0.391278\tAccuracy: 92.10%\n",
      "34\tValidation loss: 0.401981\tBest loss: 0.391278\tAccuracy: 92.30%\n",
      "35\tValidation loss: 0.414389\tBest loss: 0.391278\tAccuracy: 92.00%\n",
      "36\tValidation loss: 0.410918\tBest loss: 0.391278\tAccuracy: 92.10%\n",
      "37\tValidation loss: 0.397294\tBest loss: 0.391278\tAccuracy: 92.20%\n",
      "38\tValidation loss: 0.391679\tBest loss: 0.391278\tAccuracy: 92.70%\n",
      "39\tValidation loss: 0.405713\tBest loss: 0.391278\tAccuracy: 92.40%\n",
      "40\tValidation loss: 0.414036\tBest loss: 0.391278\tAccuracy: 92.10%\n",
      "41\tValidation loss: 0.396405\tBest loss: 0.391278\tAccuracy: 92.60%\n",
      "42\tValidation loss: 0.414043\tBest loss: 0.391278\tAccuracy: 92.40%\n",
      "43\tValidation loss: 0.411891\tBest loss: 0.391278\tAccuracy: 92.20%\n",
      "44\tValidation loss: 0.429210\tBest loss: 0.391278\tAccuracy: 92.40%\n",
      "45\tValidation loss: 0.426277\tBest loss: 0.391278\tAccuracy: 92.40%\n",
      "46\tValidation loss: 0.420287\tBest loss: 0.391278\tAccuracy: 92.80%\n",
      "47\tValidation loss: 0.396932\tBest loss: 0.391278\tAccuracy: 92.70%\n",
      "48\tValidation loss: 0.411562\tBest loss: 0.391278\tAccuracy: 93.30%\n",
      "49\tValidation loss: 0.390883\tBest loss: 0.390883\tAccuracy: 93.20%\n",
      "50\tValidation loss: 0.417935\tBest loss: 0.390883\tAccuracy: 92.70%\n",
      "51\tValidation loss: 0.397012\tBest loss: 0.390883\tAccuracy: 93.10%\n",
      "52\tValidation loss: 0.415751\tBest loss: 0.390883\tAccuracy: 92.00%\n",
      "53\tValidation loss: 0.415700\tBest loss: 0.390883\tAccuracy: 92.50%\n",
      "54\tValidation loss: 0.412343\tBest loss: 0.390883\tAccuracy: 93.20%\n",
      "55\tValidation loss: 0.420259\tBest loss: 0.390883\tAccuracy: 92.60%\n",
      "56\tValidation loss: 0.406193\tBest loss: 0.390883\tAccuracy: 93.00%\n",
      "57\tValidation loss: 0.399702\tBest loss: 0.390883\tAccuracy: 92.40%\n",
      "58\tValidation loss: 0.402082\tBest loss: 0.390883\tAccuracy: 93.50%\n",
      "59\tValidation loss: 0.418739\tBest loss: 0.390883\tAccuracy: 92.90%\n",
      "60\tValidation loss: 0.415820\tBest loss: 0.390883\tAccuracy: 92.60%\n",
      "61\tValidation loss: 0.419794\tBest loss: 0.390883\tAccuracy: 92.70%\n",
      "62\tValidation loss: 0.426736\tBest loss: 0.390883\tAccuracy: 92.40%\n",
      "63\tValidation loss: 0.399842\tBest loss: 0.390883\tAccuracy: 93.00%\n",
      "64\tValidation loss: 0.453194\tBest loss: 0.390883\tAccuracy: 92.40%\n",
      "65\tValidation loss: 0.414839\tBest loss: 0.390883\tAccuracy: 93.10%\n",
      "66\tValidation loss: 0.432688\tBest loss: 0.390883\tAccuracy: 92.70%\n",
      "67\tValidation loss: 0.422302\tBest loss: 0.390883\tAccuracy: 93.20%\n",
      "68\tValidation loss: 0.407812\tBest loss: 0.390883\tAccuracy: 93.40%\n",
      "69\tValidation loss: 0.437554\tBest loss: 0.390883\tAccuracy: 93.30%\n",
      "70\tValidation loss: 0.434520\tBest loss: 0.390883\tAccuracy: 92.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=700, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   8.2s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.933970\tBest loss: 4.933970\tAccuracy: 3.20%\n",
      "1\tValidation loss: 5.942315\tBest loss: 4.933970\tAccuracy: 3.50%\n",
      "2\tValidation loss: 4.255876\tBest loss: 4.255876\tAccuracy: 6.00%\n",
      "3\tValidation loss: 4.400320\tBest loss: 4.255876\tAccuracy: 6.70%\n",
      "4\tValidation loss: 3.810662\tBest loss: 3.810662\tAccuracy: 11.70%\n",
      "5\tValidation loss: 3.804304\tBest loss: 3.804304\tAccuracy: 14.90%\n",
      "6\tValidation loss: 3.155087\tBest loss: 3.155087\tAccuracy: 25.40%\n",
      "7\tValidation loss: 3.166987\tBest loss: 3.155087\tAccuracy: 25.50%\n",
      "8\tValidation loss: 3.148479\tBest loss: 3.148479\tAccuracy: 22.80%\n",
      "9\tValidation loss: 2.650380\tBest loss: 2.650380\tAccuracy: 30.00%\n",
      "10\tValidation loss: 4.354688\tBest loss: 2.650380\tAccuracy: 25.90%\n",
      "11\tValidation loss: 3.600812\tBest loss: 2.650380\tAccuracy: 27.40%\n",
      "12\tValidation loss: 3.246101\tBest loss: 2.650380\tAccuracy: 31.40%\n",
      "13\tValidation loss: 2.611429\tBest loss: 2.611429\tAccuracy: 39.50%\n",
      "14\tValidation loss: 3.770814\tBest loss: 2.611429\tAccuracy: 30.70%\n",
      "15\tValidation loss: 3.282816\tBest loss: 2.611429\tAccuracy: 29.20%\n",
      "16\tValidation loss: 2.571937\tBest loss: 2.571937\tAccuracy: 39.10%\n",
      "17\tValidation loss: 3.708474\tBest loss: 2.571937\tAccuracy: 30.70%\n",
      "18\tValidation loss: 3.718006\tBest loss: 2.571937\tAccuracy: 31.30%\n",
      "19\tValidation loss: 3.875475\tBest loss: 2.571937\tAccuracy: 27.40%\n",
      "20\tValidation loss: 5.429610\tBest loss: 2.571937\tAccuracy: 25.00%\n",
      "21\tValidation loss: 4.841268\tBest loss: 2.571937\tAccuracy: 29.80%\n",
      "22\tValidation loss: 3.883581\tBest loss: 2.571937\tAccuracy: 30.80%\n",
      "23\tValidation loss: 4.261044\tBest loss: 2.571937\tAccuracy: 33.20%\n",
      "24\tValidation loss: 4.708240\tBest loss: 2.571937\tAccuracy: 28.60%\n",
      "25\tValidation loss: 4.541755\tBest loss: 2.571937\tAccuracy: 25.70%\n",
      "26\tValidation loss: 3.485470\tBest loss: 2.571937\tAccuracy: 31.70%\n",
      "27\tValidation loss: 3.956270\tBest loss: 2.571937\tAccuracy: 32.20%\n",
      "28\tValidation loss: 3.072472\tBest loss: 2.571937\tAccuracy: 37.20%\n",
      "29\tValidation loss: 9.066084\tBest loss: 2.571937\tAccuracy: 16.00%\n",
      "30\tValidation loss: 3.923816\tBest loss: 2.571937\tAccuracy: 30.40%\n",
      "31\tValidation loss: 5.014178\tBest loss: 2.571937\tAccuracy: 32.10%\n",
      "32\tValidation loss: 4.970284\tBest loss: 2.571937\tAccuracy: 31.00%\n",
      "33\tValidation loss: 3.780238\tBest loss: 2.571937\tAccuracy: 34.30%\n",
      "34\tValidation loss: 3.702872\tBest loss: 2.571937\tAccuracy: 32.70%\n",
      "35\tValidation loss: 54.227787\tBest loss: 2.571937\tAccuracy: 2.90%\n",
      "36\tValidation loss: 18.164454\tBest loss: 2.571937\tAccuracy: 3.00%\n",
      "37\tValidation loss: 4.834912\tBest loss: 2.571937\tAccuracy: 3.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=  11.1s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.337508\tBest loss: 4.337508\tAccuracy: 2.10%\n",
      "1\tValidation loss: 3.996381\tBest loss: 3.996381\tAccuracy: 3.80%\n",
      "2\tValidation loss: 3.930173\tBest loss: 3.930173\tAccuracy: 6.10%\n",
      "3\tValidation loss: 3.670276\tBest loss: 3.670276\tAccuracy: 9.60%\n",
      "4\tValidation loss: 3.752037\tBest loss: 3.670276\tAccuracy: 9.00%\n",
      "5\tValidation loss: 4.003183\tBest loss: 3.670276\tAccuracy: 7.30%\n",
      "6\tValidation loss: 4.113627\tBest loss: 3.670276\tAccuracy: 12.20%\n",
      "7\tValidation loss: 3.672966\tBest loss: 3.670276\tAccuracy: 10.40%\n",
      "8\tValidation loss: 3.972359\tBest loss: 3.670276\tAccuracy: 10.40%\n",
      "9\tValidation loss: 4.056386\tBest loss: 3.670276\tAccuracy: 11.60%\n",
      "10\tValidation loss: 10.926355\tBest loss: 3.670276\tAccuracy: 2.90%\n",
      "11\tValidation loss: 5.500004\tBest loss: 3.670276\tAccuracy: 2.00%\n",
      "12\tValidation loss: 5.284228\tBest loss: 3.670276\tAccuracy: 3.40%\n",
      "13\tValidation loss: 5.525296\tBest loss: 3.670276\tAccuracy: 2.60%\n",
      "14\tValidation loss: 6.507767\tBest loss: 3.670276\tAccuracy: 2.40%\n",
      "15\tValidation loss: 8.134018\tBest loss: 3.670276\tAccuracy: 2.30%\n",
      "16\tValidation loss: 7.622461\tBest loss: 3.670276\tAccuracy: 2.60%\n",
      "17\tValidation loss: 5.561017\tBest loss: 3.670276\tAccuracy: 2.90%\n",
      "18\tValidation loss: 9.031679\tBest loss: 3.670276\tAccuracy: 3.80%\n",
      "19\tValidation loss: 5.948364\tBest loss: 3.670276\tAccuracy: 3.80%\n",
      "20\tValidation loss: 10.466163\tBest loss: 3.670276\tAccuracy: 3.00%\n",
      "21\tValidation loss: 10.549328\tBest loss: 3.670276\tAccuracy: 0.70%\n",
      "22\tValidation loss: 6.931402\tBest loss: 3.670276\tAccuracy: 1.70%\n",
      "23\tValidation loss: 10.416711\tBest loss: 3.670276\tAccuracy: 2.00%\n",
      "24\tValidation loss: 12.914902\tBest loss: 3.670276\tAccuracy: 2.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   7.6s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.121701\tBest loss: 4.121701\tAccuracy: 3.90%\n",
      "1\tValidation loss: 4.099558\tBest loss: 4.099558\tAccuracy: 4.70%\n",
      "2\tValidation loss: 4.174820\tBest loss: 4.099558\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.810415\tBest loss: 3.810415\tAccuracy: 4.20%\n",
      "4\tValidation loss: 3.922577\tBest loss: 3.810415\tAccuracy: 7.20%\n",
      "5\tValidation loss: 4.265734\tBest loss: 3.810415\tAccuracy: 9.60%\n",
      "6\tValidation loss: 3.934632\tBest loss: 3.810415\tAccuracy: 7.80%\n",
      "7\tValidation loss: 3.835117\tBest loss: 3.810415\tAccuracy: 7.60%\n",
      "8\tValidation loss: 3.955622\tBest loss: 3.810415\tAccuracy: 8.70%\n",
      "9\tValidation loss: 5.327725\tBest loss: 3.810415\tAccuracy: 10.40%\n",
      "10\tValidation loss: 6.042047\tBest loss: 3.810415\tAccuracy: 2.50%\n",
      "11\tValidation loss: 10.373587\tBest loss: 3.810415\tAccuracy: 2.90%\n",
      "12\tValidation loss: 5.871496\tBest loss: 3.810415\tAccuracy: 2.30%\n",
      "13\tValidation loss: 6.216185\tBest loss: 3.810415\tAccuracy: 2.00%\n",
      "14\tValidation loss: 11.082974\tBest loss: 3.810415\tAccuracy: 1.50%\n",
      "15\tValidation loss: 6.306659\tBest loss: 3.810415\tAccuracy: 1.00%\n",
      "16\tValidation loss: 10.380707\tBest loss: 3.810415\tAccuracy: 3.50%\n",
      "17\tValidation loss: 11.798368\tBest loss: 3.810415\tAccuracy: 1.40%\n",
      "18\tValidation loss: 7.281798\tBest loss: 3.810415\tAccuracy: 1.10%\n",
      "19\tValidation loss: 6.786303\tBest loss: 3.810415\tAccuracy: 1.70%\n",
      "20\tValidation loss: 8.126612\tBest loss: 3.810415\tAccuracy: 3.40%\n",
      "21\tValidation loss: 9.123937\tBest loss: 3.810415\tAccuracy: 3.50%\n",
      "22\tValidation loss: 9.545097\tBest loss: 3.810415\tAccuracy: 2.30%\n",
      "23\tValidation loss: 11.478152\tBest loss: 3.810415\tAccuracy: 3.10%\n",
      "24\tValidation loss: 8.013801\tBest loss: 3.810415\tAccuracy: 3.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   7.6s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.241783\tBest loss: 1.241783\tAccuracy: 65.40%\n",
      "1\tValidation loss: 0.920253\tBest loss: 0.920253\tAccuracy: 74.20%\n",
      "2\tValidation loss: 0.734667\tBest loss: 0.734667\tAccuracy: 80.20%\n",
      "3\tValidation loss: 0.654773\tBest loss: 0.654773\tAccuracy: 81.90%\n",
      "4\tValidation loss: 0.605892\tBest loss: 0.605892\tAccuracy: 82.70%\n",
      "5\tValidation loss: 0.538449\tBest loss: 0.538449\tAccuracy: 85.60%\n",
      "6\tValidation loss: 0.500046\tBest loss: 0.500046\tAccuracy: 87.50%\n",
      "7\tValidation loss: 0.490898\tBest loss: 0.490898\tAccuracy: 85.50%\n",
      "8\tValidation loss: 0.459817\tBest loss: 0.459817\tAccuracy: 87.60%\n",
      "9\tValidation loss: 0.460141\tBest loss: 0.459817\tAccuracy: 87.30%\n",
      "10\tValidation loss: 0.458032\tBest loss: 0.458032\tAccuracy: 86.90%\n",
      "11\tValidation loss: 0.419952\tBest loss: 0.419952\tAccuracy: 89.10%\n",
      "12\tValidation loss: 0.409536\tBest loss: 0.409536\tAccuracy: 88.80%\n",
      "13\tValidation loss: 0.401322\tBest loss: 0.401322\tAccuracy: 88.90%\n",
      "14\tValidation loss: 0.383740\tBest loss: 0.383740\tAccuracy: 89.20%\n",
      "15\tValidation loss: 0.380776\tBest loss: 0.380776\tAccuracy: 89.60%\n",
      "16\tValidation loss: 0.368225\tBest loss: 0.368225\tAccuracy: 90.10%\n",
      "17\tValidation loss: 0.361629\tBest loss: 0.361629\tAccuracy: 90.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 0.352546\tBest loss: 0.352546\tAccuracy: 90.90%\n",
      "19\tValidation loss: 0.364327\tBest loss: 0.352546\tAccuracy: 89.90%\n",
      "20\tValidation loss: 0.341936\tBest loss: 0.341936\tAccuracy: 90.50%\n",
      "21\tValidation loss: 0.337971\tBest loss: 0.337971\tAccuracy: 90.30%\n",
      "22\tValidation loss: 0.336999\tBest loss: 0.336999\tAccuracy: 90.90%\n",
      "23\tValidation loss: 0.319934\tBest loss: 0.319934\tAccuracy: 90.70%\n",
      "24\tValidation loss: 0.323638\tBest loss: 0.319934\tAccuracy: 91.30%\n",
      "25\tValidation loss: 0.315566\tBest loss: 0.315566\tAccuracy: 91.10%\n",
      "26\tValidation loss: 0.316919\tBest loss: 0.315566\tAccuracy: 90.80%\n",
      "27\tValidation loss: 0.308374\tBest loss: 0.308374\tAccuracy: 91.00%\n",
      "28\tValidation loss: 0.309742\tBest loss: 0.308374\tAccuracy: 91.70%\n",
      "29\tValidation loss: 0.310307\tBest loss: 0.308374\tAccuracy: 91.40%\n",
      "30\tValidation loss: 0.307121\tBest loss: 0.307121\tAccuracy: 91.30%\n",
      "31\tValidation loss: 0.296950\tBest loss: 0.296950\tAccuracy: 92.10%\n",
      "32\tValidation loss: 0.301265\tBest loss: 0.296950\tAccuracy: 91.80%\n",
      "33\tValidation loss: 0.296012\tBest loss: 0.296012\tAccuracy: 92.00%\n",
      "34\tValidation loss: 0.294505\tBest loss: 0.294505\tAccuracy: 92.20%\n",
      "35\tValidation loss: 0.285755\tBest loss: 0.285755\tAccuracy: 92.00%\n",
      "36\tValidation loss: 0.290889\tBest loss: 0.285755\tAccuracy: 92.10%\n",
      "37\tValidation loss: 0.288921\tBest loss: 0.285755\tAccuracy: 92.60%\n",
      "38\tValidation loss: 0.278225\tBest loss: 0.278225\tAccuracy: 92.50%\n",
      "39\tValidation loss: 0.286642\tBest loss: 0.278225\tAccuracy: 92.70%\n",
      "40\tValidation loss: 0.281011\tBest loss: 0.278225\tAccuracy: 92.60%\n",
      "41\tValidation loss: 0.282892\tBest loss: 0.278225\tAccuracy: 92.40%\n",
      "42\tValidation loss: 0.278944\tBest loss: 0.278225\tAccuracy: 92.60%\n",
      "43\tValidation loss: 0.271226\tBest loss: 0.271226\tAccuracy: 92.80%\n",
      "44\tValidation loss: 0.278570\tBest loss: 0.271226\tAccuracy: 92.10%\n",
      "45\tValidation loss: 0.264770\tBest loss: 0.264770\tAccuracy: 93.40%\n",
      "46\tValidation loss: 0.274710\tBest loss: 0.264770\tAccuracy: 92.80%\n",
      "47\tValidation loss: 0.267123\tBest loss: 0.264770\tAccuracy: 92.70%\n",
      "48\tValidation loss: 0.277058\tBest loss: 0.264770\tAccuracy: 92.50%\n",
      "49\tValidation loss: 0.274782\tBest loss: 0.264770\tAccuracy: 92.90%\n",
      "50\tValidation loss: 0.278860\tBest loss: 0.264770\tAccuracy: 92.60%\n",
      "51\tValidation loss: 0.269044\tBest loss: 0.264770\tAccuracy: 92.40%\n",
      "52\tValidation loss: 0.266639\tBest loss: 0.264770\tAccuracy: 93.10%\n",
      "53\tValidation loss: 0.273560\tBest loss: 0.264770\tAccuracy: 92.90%\n",
      "54\tValidation loss: 0.262422\tBest loss: 0.262422\tAccuracy: 92.70%\n",
      "55\tValidation loss: 0.269222\tBest loss: 0.262422\tAccuracy: 93.00%\n",
      "56\tValidation loss: 0.275818\tBest loss: 0.262422\tAccuracy: 92.30%\n",
      "57\tValidation loss: 0.265106\tBest loss: 0.262422\tAccuracy: 93.40%\n",
      "58\tValidation loss: 0.262332\tBest loss: 0.262332\tAccuracy: 93.40%\n",
      "59\tValidation loss: 0.265418\tBest loss: 0.262332\tAccuracy: 93.60%\n",
      "60\tValidation loss: 0.264379\tBest loss: 0.262332\tAccuracy: 93.40%\n",
      "61\tValidation loss: 0.267243\tBest loss: 0.262332\tAccuracy: 93.30%\n",
      "62\tValidation loss: 0.260477\tBest loss: 0.260477\tAccuracy: 93.10%\n",
      "63\tValidation loss: 0.264586\tBest loss: 0.260477\tAccuracy: 93.30%\n",
      "64\tValidation loss: 0.260284\tBest loss: 0.260284\tAccuracy: 93.40%\n",
      "65\tValidation loss: 0.262205\tBest loss: 0.260284\tAccuracy: 92.90%\n",
      "66\tValidation loss: 0.261490\tBest loss: 0.260284\tAccuracy: 93.30%\n",
      "67\tValidation loss: 0.259598\tBest loss: 0.259598\tAccuracy: 93.60%\n",
      "68\tValidation loss: 0.264867\tBest loss: 0.259598\tAccuracy: 93.20%\n",
      "69\tValidation loss: 0.262556\tBest loss: 0.259598\tAccuracy: 93.50%\n",
      "70\tValidation loss: 0.266274\tBest loss: 0.259598\tAccuracy: 93.10%\n",
      "71\tValidation loss: 0.267791\tBest loss: 0.259598\tAccuracy: 93.40%\n",
      "72\tValidation loss: 0.266291\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "73\tValidation loss: 0.261667\tBest loss: 0.259598\tAccuracy: 93.60%\n",
      "74\tValidation loss: 0.267462\tBest loss: 0.259598\tAccuracy: 93.70%\n",
      "75\tValidation loss: 0.264437\tBest loss: 0.259598\tAccuracy: 93.40%\n",
      "76\tValidation loss: 0.264605\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "77\tValidation loss: 0.268789\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "78\tValidation loss: 0.261179\tBest loss: 0.259598\tAccuracy: 93.60%\n",
      "79\tValidation loss: 0.263750\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "80\tValidation loss: 0.269737\tBest loss: 0.259598\tAccuracy: 93.70%\n",
      "81\tValidation loss: 0.260782\tBest loss: 0.259598\tAccuracy: 93.60%\n",
      "82\tValidation loss: 0.268940\tBest loss: 0.259598\tAccuracy: 93.50%\n",
      "83\tValidation loss: 0.264695\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "84\tValidation loss: 0.264132\tBest loss: 0.259598\tAccuracy: 93.30%\n",
      "85\tValidation loss: 0.264922\tBest loss: 0.259598\tAccuracy: 93.80%\n",
      "86\tValidation loss: 0.263480\tBest loss: 0.259598\tAccuracy: 93.40%\n",
      "87\tValidation loss: 0.269491\tBest loss: 0.259598\tAccuracy: 93.70%\n",
      "88\tValidation loss: 0.271002\tBest loss: 0.259598\tAccuracy: 93.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  18.7s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.298043\tBest loss: 1.298043\tAccuracy: 65.30%\n",
      "1\tValidation loss: 0.902519\tBest loss: 0.902519\tAccuracy: 75.40%\n",
      "2\tValidation loss: 0.765438\tBest loss: 0.765438\tAccuracy: 79.90%\n",
      "3\tValidation loss: 0.645440\tBest loss: 0.645440\tAccuracy: 82.80%\n",
      "4\tValidation loss: 0.597205\tBest loss: 0.597205\tAccuracy: 84.70%\n",
      "5\tValidation loss: 0.583820\tBest loss: 0.583820\tAccuracy: 84.50%\n",
      "6\tValidation loss: 0.529634\tBest loss: 0.529634\tAccuracy: 85.60%\n",
      "7\tValidation loss: 0.537380\tBest loss: 0.529634\tAccuracy: 84.70%\n",
      "8\tValidation loss: 0.488939\tBest loss: 0.488939\tAccuracy: 86.50%\n",
      "9\tValidation loss: 0.472027\tBest loss: 0.472027\tAccuracy: 87.20%\n",
      "10\tValidation loss: 0.453531\tBest loss: 0.453531\tAccuracy: 88.50%\n",
      "11\tValidation loss: 0.455014\tBest loss: 0.453531\tAccuracy: 88.60%\n",
      "12\tValidation loss: 0.450493\tBest loss: 0.450493\tAccuracy: 88.10%\n",
      "13\tValidation loss: 0.429715\tBest loss: 0.429715\tAccuracy: 89.60%\n",
      "14\tValidation loss: 0.396888\tBest loss: 0.396888\tAccuracy: 89.40%\n",
      "15\tValidation loss: 0.408300\tBest loss: 0.396888\tAccuracy: 89.10%\n",
      "16\tValidation loss: 0.389684\tBest loss: 0.389684\tAccuracy: 89.80%\n",
      "17\tValidation loss: 0.395355\tBest loss: 0.389684\tAccuracy: 90.20%\n",
      "18\tValidation loss: 0.387441\tBest loss: 0.387441\tAccuracy: 90.60%\n",
      "19\tValidation loss: 0.388402\tBest loss: 0.387441\tAccuracy: 90.50%\n",
      "20\tValidation loss: 0.371538\tBest loss: 0.371538\tAccuracy: 90.30%\n",
      "21\tValidation loss: 0.354982\tBest loss: 0.354982\tAccuracy: 90.40%\n",
      "22\tValidation loss: 0.354386\tBest loss: 0.354386\tAccuracy: 90.40%\n",
      "23\tValidation loss: 0.352982\tBest loss: 0.352982\tAccuracy: 90.60%\n",
      "24\tValidation loss: 0.352597\tBest loss: 0.352597\tAccuracy: 90.80%\n",
      "25\tValidation loss: 0.349379\tBest loss: 0.349379\tAccuracy: 91.50%\n",
      "26\tValidation loss: 0.367000\tBest loss: 0.349379\tAccuracy: 91.10%\n",
      "27\tValidation loss: 0.350354\tBest loss: 0.349379\tAccuracy: 91.80%\n",
      "28\tValidation loss: 0.350241\tBest loss: 0.349379\tAccuracy: 91.40%\n",
      "29\tValidation loss: 0.347646\tBest loss: 0.347646\tAccuracy: 91.10%\n",
      "30\tValidation loss: 0.343078\tBest loss: 0.343078\tAccuracy: 91.40%\n",
      "31\tValidation loss: 0.346216\tBest loss: 0.343078\tAccuracy: 91.30%\n",
      "32\tValidation loss: 0.358164\tBest loss: 0.343078\tAccuracy: 91.30%\n",
      "33\tValidation loss: 0.336998\tBest loss: 0.336998\tAccuracy: 92.60%\n",
      "34\tValidation loss: 0.347547\tBest loss: 0.336998\tAccuracy: 91.30%\n",
      "35\tValidation loss: 0.329264\tBest loss: 0.329264\tAccuracy: 92.20%\n",
      "36\tValidation loss: 0.332645\tBest loss: 0.329264\tAccuracy: 91.80%\n",
      "37\tValidation loss: 0.339868\tBest loss: 0.329264\tAccuracy: 91.40%\n",
      "38\tValidation loss: 0.338612\tBest loss: 0.329264\tAccuracy: 91.80%\n",
      "39\tValidation loss: 0.331551\tBest loss: 0.329264\tAccuracy: 92.50%\n",
      "40\tValidation loss: 0.335583\tBest loss: 0.329264\tAccuracy: 92.10%\n",
      "41\tValidation loss: 0.326635\tBest loss: 0.326635\tAccuracy: 92.40%\n",
      "42\tValidation loss: 0.331336\tBest loss: 0.326635\tAccuracy: 92.50%\n",
      "43\tValidation loss: 0.319187\tBest loss: 0.319187\tAccuracy: 92.40%\n",
      "44\tValidation loss: 0.325365\tBest loss: 0.319187\tAccuracy: 92.70%\n",
      "45\tValidation loss: 0.326020\tBest loss: 0.319187\tAccuracy: 92.20%\n",
      "46\tValidation loss: 0.335427\tBest loss: 0.319187\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\tValidation loss: 0.340324\tBest loss: 0.319187\tAccuracy: 92.50%\n",
      "48\tValidation loss: 0.330982\tBest loss: 0.319187\tAccuracy: 92.60%\n",
      "49\tValidation loss: 0.333282\tBest loss: 0.319187\tAccuracy: 92.40%\n",
      "50\tValidation loss: 0.325360\tBest loss: 0.319187\tAccuracy: 92.50%\n",
      "51\tValidation loss: 0.330553\tBest loss: 0.319187\tAccuracy: 92.50%\n",
      "52\tValidation loss: 0.326611\tBest loss: 0.319187\tAccuracy: 92.60%\n",
      "53\tValidation loss: 0.328905\tBest loss: 0.319187\tAccuracy: 92.50%\n",
      "54\tValidation loss: 0.315891\tBest loss: 0.315891\tAccuracy: 92.70%\n",
      "55\tValidation loss: 0.328045\tBest loss: 0.315891\tAccuracy: 92.90%\n",
      "56\tValidation loss: 0.330432\tBest loss: 0.315891\tAccuracy: 92.20%\n",
      "57\tValidation loss: 0.330618\tBest loss: 0.315891\tAccuracy: 92.40%\n",
      "58\tValidation loss: 0.332718\tBest loss: 0.315891\tAccuracy: 92.30%\n",
      "59\tValidation loss: 0.326865\tBest loss: 0.315891\tAccuracy: 92.60%\n",
      "60\tValidation loss: 0.347181\tBest loss: 0.315891\tAccuracy: 92.00%\n",
      "61\tValidation loss: 0.326634\tBest loss: 0.315891\tAccuracy: 92.70%\n",
      "62\tValidation loss: 0.335556\tBest loss: 0.315891\tAccuracy: 92.80%\n",
      "63\tValidation loss: 0.332037\tBest loss: 0.315891\tAccuracy: 93.10%\n",
      "64\tValidation loss: 0.319903\tBest loss: 0.315891\tAccuracy: 93.10%\n",
      "65\tValidation loss: 0.330814\tBest loss: 0.315891\tAccuracy: 92.60%\n",
      "66\tValidation loss: 0.327594\tBest loss: 0.315891\tAccuracy: 93.30%\n",
      "67\tValidation loss: 0.336378\tBest loss: 0.315891\tAccuracy: 93.00%\n",
      "68\tValidation loss: 0.329724\tBest loss: 0.315891\tAccuracy: 92.70%\n",
      "69\tValidation loss: 0.332559\tBest loss: 0.315891\tAccuracy: 92.90%\n",
      "70\tValidation loss: 0.336951\tBest loss: 0.315891\tAccuracy: 93.00%\n",
      "71\tValidation loss: 0.342100\tBest loss: 0.315891\tAccuracy: 92.60%\n",
      "72\tValidation loss: 0.342060\tBest loss: 0.315891\tAccuracy: 92.70%\n",
      "73\tValidation loss: 0.340832\tBest loss: 0.315891\tAccuracy: 92.80%\n",
      "74\tValidation loss: 0.345163\tBest loss: 0.315891\tAccuracy: 92.90%\n",
      "75\tValidation loss: 0.338862\tBest loss: 0.315891\tAccuracy: 92.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  16.2s\n",
      "[CV] batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.331617\tBest loss: 1.331617\tAccuracy: 62.60%\n",
      "1\tValidation loss: 0.910026\tBest loss: 0.910026\tAccuracy: 76.90%\n",
      "2\tValidation loss: 0.745672\tBest loss: 0.745672\tAccuracy: 80.00%\n",
      "3\tValidation loss: 0.681239\tBest loss: 0.681239\tAccuracy: 81.70%\n",
      "4\tValidation loss: 0.609636\tBest loss: 0.609636\tAccuracy: 83.10%\n",
      "5\tValidation loss: 0.553833\tBest loss: 0.553833\tAccuracy: 85.30%\n",
      "6\tValidation loss: 0.510855\tBest loss: 0.510855\tAccuracy: 85.90%\n",
      "7\tValidation loss: 0.492283\tBest loss: 0.492283\tAccuracy: 87.30%\n",
      "8\tValidation loss: 0.483468\tBest loss: 0.483468\tAccuracy: 87.20%\n",
      "9\tValidation loss: 0.462534\tBest loss: 0.462534\tAccuracy: 86.20%\n",
      "10\tValidation loss: 0.443673\tBest loss: 0.443673\tAccuracy: 88.10%\n",
      "11\tValidation loss: 0.422337\tBest loss: 0.422337\tAccuracy: 89.00%\n",
      "12\tValidation loss: 0.410990\tBest loss: 0.410990\tAccuracy: 88.70%\n",
      "13\tValidation loss: 0.393168\tBest loss: 0.393168\tAccuracy: 88.60%\n",
      "14\tValidation loss: 0.385770\tBest loss: 0.385770\tAccuracy: 89.50%\n",
      "15\tValidation loss: 0.377674\tBest loss: 0.377674\tAccuracy: 90.00%\n",
      "16\tValidation loss: 0.383218\tBest loss: 0.377674\tAccuracy: 89.40%\n",
      "17\tValidation loss: 0.366140\tBest loss: 0.366140\tAccuracy: 89.30%\n",
      "18\tValidation loss: 0.349936\tBest loss: 0.349936\tAccuracy: 90.90%\n",
      "19\tValidation loss: 0.350254\tBest loss: 0.349936\tAccuracy: 90.40%\n",
      "20\tValidation loss: 0.350270\tBest loss: 0.349936\tAccuracy: 90.20%\n",
      "21\tValidation loss: 0.334557\tBest loss: 0.334557\tAccuracy: 90.60%\n",
      "22\tValidation loss: 0.330726\tBest loss: 0.330726\tAccuracy: 91.10%\n",
      "23\tValidation loss: 0.327842\tBest loss: 0.327842\tAccuracy: 91.10%\n",
      "24\tValidation loss: 0.316584\tBest loss: 0.316584\tAccuracy: 91.40%\n",
      "25\tValidation loss: 0.313874\tBest loss: 0.313874\tAccuracy: 91.40%\n",
      "26\tValidation loss: 0.308433\tBest loss: 0.308433\tAccuracy: 91.70%\n",
      "27\tValidation loss: 0.310620\tBest loss: 0.308433\tAccuracy: 91.60%\n",
      "28\tValidation loss: 0.302225\tBest loss: 0.302225\tAccuracy: 91.80%\n",
      "29\tValidation loss: 0.312233\tBest loss: 0.302225\tAccuracy: 91.70%\n",
      "30\tValidation loss: 0.288039\tBest loss: 0.288039\tAccuracy: 92.00%\n",
      "31\tValidation loss: 0.304160\tBest loss: 0.288039\tAccuracy: 91.40%\n",
      "32\tValidation loss: 0.302934\tBest loss: 0.288039\tAccuracy: 91.60%\n",
      "33\tValidation loss: 0.291286\tBest loss: 0.288039\tAccuracy: 92.00%\n",
      "34\tValidation loss: 0.284788\tBest loss: 0.284788\tAccuracy: 92.00%\n",
      "35\tValidation loss: 0.288687\tBest loss: 0.284788\tAccuracy: 92.00%\n",
      "36\tValidation loss: 0.284393\tBest loss: 0.284393\tAccuracy: 92.40%\n",
      "37\tValidation loss: 0.277036\tBest loss: 0.277036\tAccuracy: 93.20%\n",
      "38\tValidation loss: 0.281666\tBest loss: 0.277036\tAccuracy: 92.80%\n",
      "39\tValidation loss: 0.268259\tBest loss: 0.268259\tAccuracy: 93.00%\n",
      "40\tValidation loss: 0.270140\tBest loss: 0.268259\tAccuracy: 92.90%\n",
      "41\tValidation loss: 0.266714\tBest loss: 0.266714\tAccuracy: 93.70%\n",
      "42\tValidation loss: 0.268180\tBest loss: 0.266714\tAccuracy: 93.10%\n",
      "43\tValidation loss: 0.271540\tBest loss: 0.266714\tAccuracy: 92.60%\n",
      "44\tValidation loss: 0.268430\tBest loss: 0.266714\tAccuracy: 93.20%\n",
      "45\tValidation loss: 0.266264\tBest loss: 0.266264\tAccuracy: 92.80%\n",
      "46\tValidation loss: 0.268110\tBest loss: 0.266264\tAccuracy: 93.00%\n",
      "47\tValidation loss: 0.274810\tBest loss: 0.266264\tAccuracy: 92.80%\n",
      "48\tValidation loss: 0.259591\tBest loss: 0.259591\tAccuracy: 92.80%\n",
      "49\tValidation loss: 0.257363\tBest loss: 0.257363\tAccuracy: 93.30%\n",
      "50\tValidation loss: 0.261224\tBest loss: 0.257363\tAccuracy: 92.90%\n",
      "51\tValidation loss: 0.253817\tBest loss: 0.253817\tAccuracy: 93.70%\n",
      "52\tValidation loss: 0.257533\tBest loss: 0.253817\tAccuracy: 93.00%\n",
      "53\tValidation loss: 0.256184\tBest loss: 0.253817\tAccuracy: 92.90%\n",
      "54\tValidation loss: 0.252514\tBest loss: 0.252514\tAccuracy: 93.50%\n",
      "55\tValidation loss: 0.259014\tBest loss: 0.252514\tAccuracy: 93.20%\n",
      "56\tValidation loss: 0.251935\tBest loss: 0.251935\tAccuracy: 93.40%\n",
      "57\tValidation loss: 0.255369\tBest loss: 0.251935\tAccuracy: 93.30%\n",
      "58\tValidation loss: 0.245338\tBest loss: 0.245338\tAccuracy: 93.60%\n",
      "59\tValidation loss: 0.251927\tBest loss: 0.245338\tAccuracy: 93.40%\n",
      "60\tValidation loss: 0.255224\tBest loss: 0.245338\tAccuracy: 93.50%\n",
      "61\tValidation loss: 0.256207\tBest loss: 0.245338\tAccuracy: 93.10%\n",
      "62\tValidation loss: 0.249426\tBest loss: 0.245338\tAccuracy: 93.60%\n",
      "63\tValidation loss: 0.248096\tBest loss: 0.245338\tAccuracy: 93.50%\n",
      "64\tValidation loss: 0.246906\tBest loss: 0.245338\tAccuracy: 94.00%\n",
      "65\tValidation loss: 0.250929\tBest loss: 0.245338\tAccuracy: 93.60%\n",
      "66\tValidation loss: 0.254698\tBest loss: 0.245338\tAccuracy: 93.40%\n",
      "67\tValidation loss: 0.250768\tBest loss: 0.245338\tAccuracy: 93.90%\n",
      "68\tValidation loss: 0.248560\tBest loss: 0.245338\tAccuracy: 93.60%\n",
      "69\tValidation loss: 0.246503\tBest loss: 0.245338\tAccuracy: 93.50%\n",
      "70\tValidation loss: 0.250413\tBest loss: 0.245338\tAccuracy: 93.70%\n",
      "71\tValidation loss: 0.251585\tBest loss: 0.245338\tAccuracy: 93.70%\n",
      "72\tValidation loss: 0.243355\tBest loss: 0.243355\tAccuracy: 93.60%\n",
      "73\tValidation loss: 0.255152\tBest loss: 0.243355\tAccuracy: 93.50%\n",
      "74\tValidation loss: 0.250567\tBest loss: 0.243355\tAccuracy: 93.70%\n",
      "75\tValidation loss: 0.248296\tBest loss: 0.243355\tAccuracy: 93.40%\n",
      "76\tValidation loss: 0.252337\tBest loss: 0.243355\tAccuracy: 93.70%\n",
      "77\tValidation loss: 0.247141\tBest loss: 0.243355\tAccuracy: 93.60%\n",
      "78\tValidation loss: 0.252520\tBest loss: 0.243355\tAccuracy: 93.60%\n",
      "79\tValidation loss: 0.248338\tBest loss: 0.243355\tAccuracy: 93.80%\n",
      "80\tValidation loss: 0.254037\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "81\tValidation loss: 0.248074\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "82\tValidation loss: 0.254071\tBest loss: 0.243355\tAccuracy: 93.50%\n",
      "83\tValidation loss: 0.248864\tBest loss: 0.243355\tAccuracy: 94.00%\n",
      "84\tValidation loss: 0.256761\tBest loss: 0.243355\tAccuracy: 93.80%\n",
      "85\tValidation loss: 0.255546\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "86\tValidation loss: 0.252007\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "87\tValidation loss: 0.254042\tBest loss: 0.243355\tAccuracy: 93.80%\n",
      "88\tValidation loss: 0.254108\tBest loss: 0.243355\tAccuracy: 94.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\tValidation loss: 0.251292\tBest loss: 0.243355\tAccuracy: 94.00%\n",
      "90\tValidation loss: 0.247667\tBest loss: 0.243355\tAccuracy: 93.80%\n",
      "91\tValidation loss: 0.260702\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "92\tValidation loss: 0.257328\tBest loss: 0.243355\tAccuracy: 93.60%\n",
      "93\tValidation loss: 0.259667\tBest loss: 0.243355\tAccuracy: 93.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=700, n_hidden_layers=3, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total=  19.9s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.687454\tBest loss: 5.687454\tAccuracy: 19.30%\n",
      "1\tValidation loss: 3.734131\tBest loss: 3.734131\tAccuracy: 45.10%\n",
      "2\tValidation loss: 3.371760\tBest loss: 3.371760\tAccuracy: 55.80%\n",
      "3\tValidation loss: 4.020830\tBest loss: 3.371760\tAccuracy: 50.20%\n",
      "4\tValidation loss: 2.257496\tBest loss: 2.257496\tAccuracy: 62.90%\n",
      "5\tValidation loss: 1.769017\tBest loss: 1.769017\tAccuracy: 70.30%\n",
      "6\tValidation loss: 3.413588\tBest loss: 1.769017\tAccuracy: 61.00%\n",
      "7\tValidation loss: 3.900707\tBest loss: 1.769017\tAccuracy: 58.70%\n",
      "8\tValidation loss: 1.686911\tBest loss: 1.686911\tAccuracy: 74.60%\n",
      "9\tValidation loss: 1.510896\tBest loss: 1.510896\tAccuracy: 78.40%\n",
      "10\tValidation loss: 1.274588\tBest loss: 1.274588\tAccuracy: 79.90%\n",
      "11\tValidation loss: 1.400917\tBest loss: 1.274588\tAccuracy: 79.50%\n",
      "12\tValidation loss: 1.152344\tBest loss: 1.152344\tAccuracy: 83.90%\n",
      "13\tValidation loss: 1.533934\tBest loss: 1.152344\tAccuracy: 79.00%\n",
      "14\tValidation loss: 1.999016\tBest loss: 1.152344\tAccuracy: 76.10%\n",
      "15\tValidation loss: 0.810724\tBest loss: 0.810724\tAccuracy: 85.80%\n",
      "16\tValidation loss: 1.932472\tBest loss: 0.810724\tAccuracy: 75.50%\n",
      "17\tValidation loss: 1.002031\tBest loss: 0.810724\tAccuracy: 82.20%\n",
      "18\tValidation loss: 1.021217\tBest loss: 0.810724\tAccuracy: 85.10%\n",
      "19\tValidation loss: 1.933013\tBest loss: 0.810724\tAccuracy: 81.30%\n",
      "20\tValidation loss: 0.951023\tBest loss: 0.810724\tAccuracy: 84.70%\n",
      "21\tValidation loss: 1.637231\tBest loss: 0.810724\tAccuracy: 80.20%\n",
      "22\tValidation loss: 1.103225\tBest loss: 0.810724\tAccuracy: 84.70%\n",
      "23\tValidation loss: 1.322622\tBest loss: 0.810724\tAccuracy: 83.00%\n",
      "24\tValidation loss: 1.064645\tBest loss: 0.810724\tAccuracy: 85.70%\n",
      "25\tValidation loss: 1.616175\tBest loss: 0.810724\tAccuracy: 78.50%\n",
      "26\tValidation loss: 1.170529\tBest loss: 0.810724\tAccuracy: 85.70%\n",
      "27\tValidation loss: 1.120224\tBest loss: 0.810724\tAccuracy: 84.70%\n",
      "28\tValidation loss: 0.662709\tBest loss: 0.662709\tAccuracy: 89.10%\n",
      "29\tValidation loss: 1.094401\tBest loss: 0.662709\tAccuracy: 83.80%\n",
      "30\tValidation loss: 1.633875\tBest loss: 0.662709\tAccuracy: 82.00%\n",
      "31\tValidation loss: 0.925345\tBest loss: 0.662709\tAccuracy: 87.20%\n",
      "32\tValidation loss: 1.108632\tBest loss: 0.662709\tAccuracy: 85.80%\n",
      "33\tValidation loss: 0.745961\tBest loss: 0.662709\tAccuracy: 90.10%\n",
      "34\tValidation loss: 2.029540\tBest loss: 0.662709\tAccuracy: 80.10%\n",
      "35\tValidation loss: 0.747666\tBest loss: 0.662709\tAccuracy: 89.40%\n",
      "36\tValidation loss: 1.396642\tBest loss: 0.662709\tAccuracy: 85.30%\n",
      "37\tValidation loss: 1.043568\tBest loss: 0.662709\tAccuracy: 84.70%\n",
      "38\tValidation loss: 0.932343\tBest loss: 0.662709\tAccuracy: 88.40%\n",
      "39\tValidation loss: 1.099949\tBest loss: 0.662709\tAccuracy: 87.30%\n",
      "40\tValidation loss: 1.145985\tBest loss: 0.662709\tAccuracy: 86.20%\n",
      "41\tValidation loss: 0.896100\tBest loss: 0.662709\tAccuracy: 89.40%\n",
      "42\tValidation loss: 1.231741\tBest loss: 0.662709\tAccuracy: 84.00%\n",
      "43\tValidation loss: 1.156202\tBest loss: 0.662709\tAccuracy: 86.30%\n",
      "44\tValidation loss: 0.940941\tBest loss: 0.662709\tAccuracy: 89.20%\n",
      "45\tValidation loss: 1.278667\tBest loss: 0.662709\tAccuracy: 85.90%\n",
      "46\tValidation loss: 0.985184\tBest loss: 0.662709\tAccuracy: 87.00%\n",
      "47\tValidation loss: 1.827250\tBest loss: 0.662709\tAccuracy: 83.80%\n",
      "48\tValidation loss: 2.588468\tBest loss: 0.662709\tAccuracy: 79.60%\n",
      "49\tValidation loss: 0.733158\tBest loss: 0.662709\tAccuracy: 90.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.7s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.297009\tBest loss: 4.297009\tAccuracy: 29.90%\n",
      "1\tValidation loss: 5.019297\tBest loss: 4.297009\tAccuracy: 37.80%\n",
      "2\tValidation loss: 3.626959\tBest loss: 3.626959\tAccuracy: 54.20%\n",
      "3\tValidation loss: 5.114365\tBest loss: 3.626959\tAccuracy: 45.00%\n",
      "4\tValidation loss: 2.942553\tBest loss: 2.942553\tAccuracy: 64.80%\n",
      "5\tValidation loss: 2.693717\tBest loss: 2.693717\tAccuracy: 67.80%\n",
      "6\tValidation loss: 2.055487\tBest loss: 2.055487\tAccuracy: 70.30%\n",
      "7\tValidation loss: 2.516966\tBest loss: 2.055487\tAccuracy: 66.80%\n",
      "8\tValidation loss: 2.358277\tBest loss: 2.055487\tAccuracy: 69.30%\n",
      "9\tValidation loss: 0.960395\tBest loss: 0.960395\tAccuracy: 82.00%\n",
      "10\tValidation loss: 1.840601\tBest loss: 0.960395\tAccuracy: 74.80%\n",
      "11\tValidation loss: 2.038522\tBest loss: 0.960395\tAccuracy: 76.00%\n",
      "12\tValidation loss: 2.174349\tBest loss: 0.960395\tAccuracy: 72.30%\n",
      "13\tValidation loss: 0.948657\tBest loss: 0.948657\tAccuracy: 85.10%\n",
      "14\tValidation loss: 1.251629\tBest loss: 0.948657\tAccuracy: 81.40%\n",
      "15\tValidation loss: 1.308735\tBest loss: 0.948657\tAccuracy: 82.60%\n",
      "16\tValidation loss: 1.204691\tBest loss: 0.948657\tAccuracy: 81.70%\n",
      "17\tValidation loss: 2.202089\tBest loss: 0.948657\tAccuracy: 74.10%\n",
      "18\tValidation loss: 1.579510\tBest loss: 0.948657\tAccuracy: 82.40%\n",
      "19\tValidation loss: 1.547489\tBest loss: 0.948657\tAccuracy: 81.90%\n",
      "20\tValidation loss: 1.422594\tBest loss: 0.948657\tAccuracy: 84.20%\n",
      "21\tValidation loss: 0.935607\tBest loss: 0.935607\tAccuracy: 86.70%\n",
      "22\tValidation loss: 0.800604\tBest loss: 0.800604\tAccuracy: 88.40%\n",
      "23\tValidation loss: 1.429823\tBest loss: 0.800604\tAccuracy: 82.80%\n",
      "24\tValidation loss: 1.214883\tBest loss: 0.800604\tAccuracy: 84.90%\n",
      "25\tValidation loss: 0.805376\tBest loss: 0.800604\tAccuracy: 89.70%\n",
      "26\tValidation loss: 1.802562\tBest loss: 0.800604\tAccuracy: 80.10%\n",
      "27\tValidation loss: 0.868993\tBest loss: 0.800604\tAccuracy: 90.60%\n",
      "28\tValidation loss: 1.731464\tBest loss: 0.800604\tAccuracy: 80.50%\n",
      "29\tValidation loss: 2.272686\tBest loss: 0.800604\tAccuracy: 81.40%\n",
      "30\tValidation loss: 1.312965\tBest loss: 0.800604\tAccuracy: 85.90%\n",
      "31\tValidation loss: 1.944345\tBest loss: 0.800604\tAccuracy: 81.30%\n",
      "32\tValidation loss: 1.291479\tBest loss: 0.800604\tAccuracy: 85.80%\n",
      "33\tValidation loss: 2.051922\tBest loss: 0.800604\tAccuracy: 80.80%\n",
      "34\tValidation loss: 0.880424\tBest loss: 0.800604\tAccuracy: 90.10%\n",
      "35\tValidation loss: 1.431805\tBest loss: 0.800604\tAccuracy: 83.50%\n",
      "36\tValidation loss: 1.462350\tBest loss: 0.800604\tAccuracy: 84.50%\n",
      "37\tValidation loss: 0.887048\tBest loss: 0.800604\tAccuracy: 90.20%\n",
      "38\tValidation loss: 1.758613\tBest loss: 0.800604\tAccuracy: 84.50%\n",
      "39\tValidation loss: 2.695848\tBest loss: 0.800604\tAccuracy: 78.70%\n",
      "40\tValidation loss: 0.949730\tBest loss: 0.800604\tAccuracy: 90.40%\n",
      "41\tValidation loss: 1.644295\tBest loss: 0.800604\tAccuracy: 84.90%\n",
      "42\tValidation loss: 1.073051\tBest loss: 0.800604\tAccuracy: 89.20%\n",
      "43\tValidation loss: 1.172060\tBest loss: 0.800604\tAccuracy: 87.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   4.1s\n",
      "[CV] batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 4.467610\tBest loss: 4.467610\tAccuracy: 24.00%\n",
      "1\tValidation loss: 4.089727\tBest loss: 4.089727\tAccuracy: 44.50%\n",
      "2\tValidation loss: 3.107114\tBest loss: 3.107114\tAccuracy: 57.70%\n",
      "3\tValidation loss: 5.073386\tBest loss: 3.107114\tAccuracy: 47.20%\n",
      "4\tValidation loss: 2.961668\tBest loss: 2.961668\tAccuracy: 62.30%\n",
      "5\tValidation loss: 2.006583\tBest loss: 2.006583\tAccuracy: 71.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 2.101245\tBest loss: 2.006583\tAccuracy: 69.20%\n",
      "7\tValidation loss: 3.052557\tBest loss: 2.006583\tAccuracy: 65.40%\n",
      "8\tValidation loss: 3.773841\tBest loss: 2.006583\tAccuracy: 61.50%\n",
      "9\tValidation loss: 1.325545\tBest loss: 1.325545\tAccuracy: 76.40%\n",
      "10\tValidation loss: 2.110372\tBest loss: 1.325545\tAccuracy: 73.50%\n",
      "11\tValidation loss: 0.818279\tBest loss: 0.818279\tAccuracy: 83.90%\n",
      "12\tValidation loss: 1.941286\tBest loss: 0.818279\tAccuracy: 78.60%\n",
      "13\tValidation loss: 1.095507\tBest loss: 0.818279\tAccuracy: 83.50%\n",
      "14\tValidation loss: 1.010623\tBest loss: 0.818279\tAccuracy: 83.80%\n",
      "15\tValidation loss: 1.040582\tBest loss: 0.818279\tAccuracy: 82.90%\n",
      "16\tValidation loss: 1.100306\tBest loss: 0.818279\tAccuracy: 82.30%\n",
      "17\tValidation loss: 0.842347\tBest loss: 0.818279\tAccuracy: 85.80%\n",
      "18\tValidation loss: 2.708477\tBest loss: 0.818279\tAccuracy: 71.80%\n",
      "19\tValidation loss: 1.434791\tBest loss: 0.818279\tAccuracy: 81.70%\n",
      "20\tValidation loss: 0.748495\tBest loss: 0.748495\tAccuracy: 86.90%\n",
      "21\tValidation loss: 0.766118\tBest loss: 0.748495\tAccuracy: 87.30%\n",
      "22\tValidation loss: 1.170401\tBest loss: 0.748495\tAccuracy: 83.10%\n",
      "23\tValidation loss: 0.751373\tBest loss: 0.748495\tAccuracy: 87.00%\n",
      "24\tValidation loss: 1.190079\tBest loss: 0.748495\tAccuracy: 84.30%\n",
      "25\tValidation loss: 0.754058\tBest loss: 0.748495\tAccuracy: 88.70%\n",
      "26\tValidation loss: 1.875283\tBest loss: 0.748495\tAccuracy: 77.50%\n",
      "27\tValidation loss: 1.350638\tBest loss: 0.748495\tAccuracy: 84.10%\n",
      "28\tValidation loss: 0.948527\tBest loss: 0.748495\tAccuracy: 87.00%\n",
      "29\tValidation loss: 1.863334\tBest loss: 0.748495\tAccuracy: 81.90%\n",
      "30\tValidation loss: 1.664960\tBest loss: 0.748495\tAccuracy: 82.60%\n",
      "31\tValidation loss: 0.878861\tBest loss: 0.748495\tAccuracy: 86.80%\n",
      "32\tValidation loss: 1.043084\tBest loss: 0.748495\tAccuracy: 86.50%\n",
      "33\tValidation loss: 1.539298\tBest loss: 0.748495\tAccuracy: 82.90%\n",
      "34\tValidation loss: 0.842305\tBest loss: 0.748495\tAccuracy: 88.10%\n",
      "35\tValidation loss: 0.969132\tBest loss: 0.748495\tAccuracy: 87.10%\n",
      "36\tValidation loss: 0.797328\tBest loss: 0.748495\tAccuracy: 89.00%\n",
      "37\tValidation loss: 1.131559\tBest loss: 0.748495\tAccuracy: 85.10%\n",
      "38\tValidation loss: 1.347957\tBest loss: 0.748495\tAccuracy: 83.40%\n",
      "39\tValidation loss: 0.769243\tBest loss: 0.748495\tAccuracy: 90.50%\n",
      "40\tValidation loss: 0.720179\tBest loss: 0.720179\tAccuracy: 90.90%\n",
      "41\tValidation loss: 0.758978\tBest loss: 0.720179\tAccuracy: 90.70%\n",
      "42\tValidation loss: 1.124883\tBest loss: 0.720179\tAccuracy: 87.70%\n",
      "43\tValidation loss: 0.734422\tBest loss: 0.720179\tAccuracy: 90.90%\n",
      "44\tValidation loss: 1.568261\tBest loss: 0.720179\tAccuracy: 85.00%\n",
      "45\tValidation loss: 1.187770\tBest loss: 0.720179\tAccuracy: 85.30%\n",
      "46\tValidation loss: 2.234499\tBest loss: 0.720179\tAccuracy: 78.80%\n",
      "47\tValidation loss: 1.224807\tBest loss: 0.720179\tAccuracy: 88.10%\n",
      "48\tValidation loss: 1.389913\tBest loss: 0.720179\tAccuracy: 84.60%\n",
      "49\tValidation loss: 0.656316\tBest loss: 0.656316\tAccuracy: 91.60%\n",
      "50\tValidation loss: 0.789921\tBest loss: 0.656316\tAccuracy: 91.10%\n",
      "51\tValidation loss: 1.310901\tBest loss: 0.656316\tAccuracy: 85.10%\n",
      "52\tValidation loss: 0.861072\tBest loss: 0.656316\tAccuracy: 91.00%\n",
      "53\tValidation loss: 0.772823\tBest loss: 0.656316\tAccuracy: 92.00%\n",
      "54\tValidation loss: 0.858810\tBest loss: 0.656316\tAccuracy: 90.60%\n",
      "55\tValidation loss: 0.941911\tBest loss: 0.656316\tAccuracy: 90.10%\n",
      "56\tValidation loss: 1.479006\tBest loss: 0.656316\tAccuracy: 85.60%\n",
      "57\tValidation loss: 1.601974\tBest loss: 0.656316\tAccuracy: 83.20%\n",
      "58\tValidation loss: 0.734572\tBest loss: 0.656316\tAccuracy: 91.20%\n",
      "59\tValidation loss: 1.479607\tBest loss: 0.656316\tAccuracy: 85.20%\n",
      "60\tValidation loss: 1.401297\tBest loss: 0.656316\tAccuracy: 87.00%\n",
      "61\tValidation loss: 1.476856\tBest loss: 0.656316\tAccuracy: 86.60%\n",
      "62\tValidation loss: 0.963571\tBest loss: 0.656316\tAccuracy: 89.90%\n",
      "63\tValidation loss: 1.291691\tBest loss: 0.656316\tAccuracy: 88.10%\n",
      "64\tValidation loss: 1.419658\tBest loss: 0.656316\tAccuracy: 84.80%\n",
      "65\tValidation loss: 1.120700\tBest loss: 0.656316\tAccuracy: 88.10%\n",
      "66\tValidation loss: 1.609073\tBest loss: 0.656316\tAccuracy: 85.60%\n",
      "67\tValidation loss: 1.475590\tBest loss: 0.656316\tAccuracy: 88.10%\n",
      "68\tValidation loss: 0.794957\tBest loss: 0.656316\tAccuracy: 91.30%\n",
      "69\tValidation loss: 1.614367\tBest loss: 0.656316\tAccuracy: 86.10%\n",
      "70\tValidation loss: 1.661163\tBest loss: 0.656316\tAccuracy: 85.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=100, n_hidden_layers=0, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   6.7s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.134269\tBest loss: 1.134269\tAccuracy: 65.70%\n",
      "1\tValidation loss: 0.956512\tBest loss: 0.956512\tAccuracy: 73.80%\n",
      "2\tValidation loss: 0.707219\tBest loss: 0.707219\tAccuracy: 79.60%\n",
      "3\tValidation loss: 0.726558\tBest loss: 0.707219\tAccuracy: 78.00%\n",
      "4\tValidation loss: 0.671298\tBest loss: 0.671298\tAccuracy: 82.80%\n",
      "5\tValidation loss: 0.553073\tBest loss: 0.553073\tAccuracy: 82.60%\n",
      "6\tValidation loss: 0.606761\tBest loss: 0.553073\tAccuracy: 82.20%\n",
      "7\tValidation loss: 0.537987\tBest loss: 0.537987\tAccuracy: 83.90%\n",
      "8\tValidation loss: 0.544677\tBest loss: 0.537987\tAccuracy: 86.70%\n",
      "9\tValidation loss: 0.618850\tBest loss: 0.537987\tAccuracy: 83.70%\n",
      "10\tValidation loss: 0.670754\tBest loss: 0.537987\tAccuracy: 84.00%\n",
      "11\tValidation loss: 0.637564\tBest loss: 0.537987\tAccuracy: 82.70%\n",
      "12\tValidation loss: 0.457634\tBest loss: 0.457634\tAccuracy: 86.10%\n",
      "13\tValidation loss: 0.406572\tBest loss: 0.406572\tAccuracy: 88.90%\n",
      "14\tValidation loss: 0.495545\tBest loss: 0.406572\tAccuracy: 88.10%\n",
      "15\tValidation loss: 0.560163\tBest loss: 0.406572\tAccuracy: 84.90%\n",
      "16\tValidation loss: 0.464483\tBest loss: 0.406572\tAccuracy: 88.70%\n",
      "17\tValidation loss: 0.745118\tBest loss: 0.406572\tAccuracy: 83.70%\n",
      "18\tValidation loss: 0.484399\tBest loss: 0.406572\tAccuracy: 88.40%\n",
      "19\tValidation loss: 0.581855\tBest loss: 0.406572\tAccuracy: 87.30%\n",
      "20\tValidation loss: 0.512396\tBest loss: 0.406572\tAccuracy: 88.50%\n",
      "21\tValidation loss: 0.588219\tBest loss: 0.406572\tAccuracy: 87.80%\n",
      "22\tValidation loss: 0.774718\tBest loss: 0.406572\tAccuracy: 82.80%\n",
      "23\tValidation loss: 0.616036\tBest loss: 0.406572\tAccuracy: 84.70%\n",
      "24\tValidation loss: 0.560764\tBest loss: 0.406572\tAccuracy: 87.30%\n",
      "25\tValidation loss: 0.597919\tBest loss: 0.406572\tAccuracy: 86.10%\n",
      "26\tValidation loss: 0.560124\tBest loss: 0.406572\tAccuracy: 87.90%\n",
      "27\tValidation loss: 0.616423\tBest loss: 0.406572\tAccuracy: 86.40%\n",
      "28\tValidation loss: 0.437247\tBest loss: 0.406572\tAccuracy: 90.70%\n",
      "29\tValidation loss: 0.762602\tBest loss: 0.406572\tAccuracy: 87.60%\n",
      "30\tValidation loss: 0.653502\tBest loss: 0.406572\tAccuracy: 86.30%\n",
      "31\tValidation loss: 0.652154\tBest loss: 0.406572\tAccuracy: 86.10%\n",
      "32\tValidation loss: 0.803051\tBest loss: 0.406572\tAccuracy: 85.20%\n",
      "33\tValidation loss: 0.565997\tBest loss: 0.406572\tAccuracy: 89.20%\n",
      "34\tValidation loss: 0.612177\tBest loss: 0.406572\tAccuracy: 88.20%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   7.1s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.327614\tBest loss: 1.327614\tAccuracy: 62.50%\n",
      "1\tValidation loss: 0.904666\tBest loss: 0.904666\tAccuracy: 73.50%\n",
      "2\tValidation loss: 0.849039\tBest loss: 0.849039\tAccuracy: 78.30%\n",
      "3\tValidation loss: 0.726956\tBest loss: 0.726956\tAccuracy: 80.10%\n",
      "4\tValidation loss: 0.709003\tBest loss: 0.709003\tAccuracy: 80.80%\n",
      "5\tValidation loss: 0.719671\tBest loss: 0.709003\tAccuracy: 80.20%\n",
      "6\tValidation loss: 0.616283\tBest loss: 0.616283\tAccuracy: 83.10%\n",
      "7\tValidation loss: 0.592248\tBest loss: 0.592248\tAccuracy: 83.20%\n",
      "8\tValidation loss: 0.564781\tBest loss: 0.564781\tAccuracy: 84.50%\n",
      "9\tValidation loss: 0.645342\tBest loss: 0.564781\tAccuracy: 82.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 0.610694\tBest loss: 0.564781\tAccuracy: 82.80%\n",
      "11\tValidation loss: 0.569468\tBest loss: 0.564781\tAccuracy: 84.40%\n",
      "12\tValidation loss: 0.575799\tBest loss: 0.564781\tAccuracy: 86.60%\n",
      "13\tValidation loss: 0.569734\tBest loss: 0.564781\tAccuracy: 84.40%\n",
      "14\tValidation loss: 0.627888\tBest loss: 0.564781\tAccuracy: 84.80%\n",
      "15\tValidation loss: 0.588528\tBest loss: 0.564781\tAccuracy: 85.60%\n",
      "16\tValidation loss: 0.615793\tBest loss: 0.564781\tAccuracy: 87.80%\n",
      "17\tValidation loss: 0.792357\tBest loss: 0.564781\tAccuracy: 83.90%\n",
      "18\tValidation loss: 0.637236\tBest loss: 0.564781\tAccuracy: 86.40%\n",
      "19\tValidation loss: 0.499607\tBest loss: 0.499607\tAccuracy: 86.60%\n",
      "20\tValidation loss: 0.643510\tBest loss: 0.499607\tAccuracy: 85.60%\n",
      "21\tValidation loss: 0.615725\tBest loss: 0.499607\tAccuracy: 85.20%\n",
      "22\tValidation loss: 0.699592\tBest loss: 0.499607\tAccuracy: 88.50%\n",
      "23\tValidation loss: 0.582007\tBest loss: 0.499607\tAccuracy: 86.60%\n",
      "24\tValidation loss: 0.746487\tBest loss: 0.499607\tAccuracy: 84.10%\n",
      "25\tValidation loss: 0.648100\tBest loss: 0.499607\tAccuracy: 84.40%\n",
      "26\tValidation loss: 1.005746\tBest loss: 0.499607\tAccuracy: 84.60%\n",
      "27\tValidation loss: 0.800538\tBest loss: 0.499607\tAccuracy: 85.50%\n",
      "28\tValidation loss: 0.716972\tBest loss: 0.499607\tAccuracy: 86.90%\n",
      "29\tValidation loss: 0.694975\tBest loss: 0.499607\tAccuracy: 87.50%\n",
      "30\tValidation loss: 0.807386\tBest loss: 0.499607\tAccuracy: 84.30%\n",
      "31\tValidation loss: 0.795051\tBest loss: 0.499607\tAccuracy: 87.20%\n",
      "32\tValidation loss: 0.678017\tBest loss: 0.499607\tAccuracy: 88.00%\n",
      "33\tValidation loss: 0.674270\tBest loss: 0.499607\tAccuracy: 86.80%\n",
      "34\tValidation loss: 0.844854\tBest loss: 0.499607\tAccuracy: 85.00%\n",
      "35\tValidation loss: 0.557317\tBest loss: 0.499607\tAccuracy: 88.60%\n",
      "36\tValidation loss: 0.725515\tBest loss: 0.499607\tAccuracy: 87.50%\n",
      "37\tValidation loss: 0.725651\tBest loss: 0.499607\tAccuracy: 87.60%\n",
      "38\tValidation loss: 0.807320\tBest loss: 0.499607\tAccuracy: 87.60%\n",
      "39\tValidation loss: 0.931881\tBest loss: 0.499607\tAccuracy: 88.40%\n",
      "40\tValidation loss: 0.914034\tBest loss: 0.499607\tAccuracy: 85.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   8.2s\n",
      "[CV] batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.349563\tBest loss: 1.349563\tAccuracy: 62.00%\n",
      "1\tValidation loss: 0.930399\tBest loss: 0.930399\tAccuracy: 73.20%\n",
      "2\tValidation loss: 0.696649\tBest loss: 0.696649\tAccuracy: 79.90%\n",
      "3\tValidation loss: 0.662138\tBest loss: 0.662138\tAccuracy: 81.10%\n",
      "4\tValidation loss: 0.601705\tBest loss: 0.601705\tAccuracy: 81.90%\n",
      "5\tValidation loss: 0.535960\tBest loss: 0.535960\tAccuracy: 84.50%\n",
      "6\tValidation loss: 0.696359\tBest loss: 0.535960\tAccuracy: 81.60%\n",
      "7\tValidation loss: 0.628705\tBest loss: 0.535960\tAccuracy: 83.90%\n",
      "8\tValidation loss: 0.529889\tBest loss: 0.529889\tAccuracy: 84.00%\n",
      "9\tValidation loss: 0.643576\tBest loss: 0.529889\tAccuracy: 81.90%\n",
      "10\tValidation loss: 0.598738\tBest loss: 0.529889\tAccuracy: 82.00%\n",
      "11\tValidation loss: 0.725316\tBest loss: 0.529889\tAccuracy: 83.90%\n",
      "12\tValidation loss: 0.566842\tBest loss: 0.529889\tAccuracy: 85.10%\n",
      "13\tValidation loss: 0.566712\tBest loss: 0.529889\tAccuracy: 84.40%\n",
      "14\tValidation loss: 0.592945\tBest loss: 0.529889\tAccuracy: 84.00%\n",
      "15\tValidation loss: 0.604613\tBest loss: 0.529889\tAccuracy: 85.60%\n",
      "16\tValidation loss: 0.667344\tBest loss: 0.529889\tAccuracy: 83.40%\n",
      "17\tValidation loss: 0.643561\tBest loss: 0.529889\tAccuracy: 85.80%\n",
      "18\tValidation loss: 0.547332\tBest loss: 0.529889\tAccuracy: 87.40%\n",
      "19\tValidation loss: 0.679196\tBest loss: 0.529889\tAccuracy: 84.90%\n",
      "20\tValidation loss: 0.675026\tBest loss: 0.529889\tAccuracy: 87.10%\n",
      "21\tValidation loss: 0.678391\tBest loss: 0.529889\tAccuracy: 86.30%\n",
      "22\tValidation loss: 0.587514\tBest loss: 0.529889\tAccuracy: 86.10%\n",
      "23\tValidation loss: 0.579577\tBest loss: 0.529889\tAccuracy: 88.30%\n",
      "24\tValidation loss: 0.667043\tBest loss: 0.529889\tAccuracy: 88.10%\n",
      "25\tValidation loss: 0.587306\tBest loss: 0.529889\tAccuracy: 87.50%\n",
      "26\tValidation loss: 0.754921\tBest loss: 0.529889\tAccuracy: 84.30%\n",
      "27\tValidation loss: 0.905634\tBest loss: 0.529889\tAccuracy: 83.30%\n",
      "28\tValidation loss: 0.713918\tBest loss: 0.529889\tAccuracy: 85.00%\n",
      "29\tValidation loss: 0.682849\tBest loss: 0.529889\tAccuracy: 86.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=300, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.2s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 0.951556\tBest loss: 0.951556\tAccuracy: 72.90%\n",
      "1\tValidation loss: 0.759114\tBest loss: 0.759114\tAccuracy: 78.00%\n",
      "2\tValidation loss: 0.580975\tBest loss: 0.580975\tAccuracy: 82.10%\n",
      "3\tValidation loss: 0.826230\tBest loss: 0.580975\tAccuracy: 78.30%\n",
      "4\tValidation loss: 0.536198\tBest loss: 0.536198\tAccuracy: 84.30%\n",
      "5\tValidation loss: 0.652751\tBest loss: 0.536198\tAccuracy: 81.20%\n",
      "6\tValidation loss: 0.687770\tBest loss: 0.536198\tAccuracy: 83.00%\n",
      "7\tValidation loss: 0.678986\tBest loss: 0.536198\tAccuracy: 83.80%\n",
      "8\tValidation loss: 0.713697\tBest loss: 0.536198\tAccuracy: 81.90%\n",
      "9\tValidation loss: 0.640726\tBest loss: 0.536198\tAccuracy: 85.40%\n",
      "10\tValidation loss: 0.654719\tBest loss: 0.536198\tAccuracy: 84.70%\n",
      "11\tValidation loss: 0.540106\tBest loss: 0.536198\tAccuracy: 86.00%\n",
      "12\tValidation loss: 0.710493\tBest loss: 0.536198\tAccuracy: 83.10%\n",
      "13\tValidation loss: 0.780791\tBest loss: 0.536198\tAccuracy: 82.40%\n",
      "14\tValidation loss: 0.611582\tBest loss: 0.536198\tAccuracy: 85.50%\n",
      "15\tValidation loss: 0.682097\tBest loss: 0.536198\tAccuracy: 85.70%\n",
      "16\tValidation loss: 0.627055\tBest loss: 0.536198\tAccuracy: 85.80%\n",
      "17\tValidation loss: 0.726288\tBest loss: 0.536198\tAccuracy: 85.70%\n",
      "18\tValidation loss: 0.760062\tBest loss: 0.536198\tAccuracy: 85.00%\n",
      "19\tValidation loss: 0.772076\tBest loss: 0.536198\tAccuracy: 86.70%\n",
      "20\tValidation loss: 0.794473\tBest loss: 0.536198\tAccuracy: 86.00%\n",
      "21\tValidation loss: 1.052964\tBest loss: 0.536198\tAccuracy: 81.60%\n",
      "22\tValidation loss: 0.688684\tBest loss: 0.536198\tAccuracy: 86.50%\n",
      "23\tValidation loss: 0.663939\tBest loss: 0.536198\tAccuracy: 88.00%\n",
      "24\tValidation loss: 0.759464\tBest loss: 0.536198\tAccuracy: 86.20%\n",
      "25\tValidation loss: 1.501925\tBest loss: 0.536198\tAccuracy: 81.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   8.1s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.149995\tBest loss: 1.149995\tAccuracy: 68.90%\n",
      "1\tValidation loss: 0.759233\tBest loss: 0.759233\tAccuracy: 78.20%\n",
      "2\tValidation loss: 0.810791\tBest loss: 0.759233\tAccuracy: 77.60%\n",
      "3\tValidation loss: 0.572020\tBest loss: 0.572020\tAccuracy: 83.50%\n",
      "4\tValidation loss: 0.662042\tBest loss: 0.572020\tAccuracy: 82.40%\n",
      "5\tValidation loss: 0.758761\tBest loss: 0.572020\tAccuracy: 81.10%\n",
      "6\tValidation loss: 0.721530\tBest loss: 0.572020\tAccuracy: 84.00%\n",
      "7\tValidation loss: 0.710780\tBest loss: 0.572020\tAccuracy: 81.60%\n",
      "8\tValidation loss: 0.668486\tBest loss: 0.572020\tAccuracy: 83.80%\n",
      "9\tValidation loss: 0.602300\tBest loss: 0.572020\tAccuracy: 85.00%\n",
      "10\tValidation loss: 0.698840\tBest loss: 0.572020\tAccuracy: 83.50%\n",
      "11\tValidation loss: 0.672964\tBest loss: 0.572020\tAccuracy: 84.80%\n",
      "12\tValidation loss: 0.746317\tBest loss: 0.572020\tAccuracy: 82.10%\n",
      "13\tValidation loss: 0.715835\tBest loss: 0.572020\tAccuracy: 84.80%\n",
      "14\tValidation loss: 0.671348\tBest loss: 0.572020\tAccuracy: 85.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tValidation loss: 0.796382\tBest loss: 0.572020\tAccuracy: 85.60%\n",
      "16\tValidation loss: 0.868462\tBest loss: 0.572020\tAccuracy: 83.40%\n",
      "17\tValidation loss: 0.767047\tBest loss: 0.572020\tAccuracy: 84.20%\n",
      "18\tValidation loss: 0.636883\tBest loss: 0.572020\tAccuracy: 87.60%\n",
      "19\tValidation loss: 0.687792\tBest loss: 0.572020\tAccuracy: 86.60%\n",
      "20\tValidation loss: 0.962736\tBest loss: 0.572020\tAccuracy: 83.60%\n",
      "21\tValidation loss: 1.007611\tBest loss: 0.572020\tAccuracy: 83.50%\n",
      "22\tValidation loss: 0.753151\tBest loss: 0.572020\tAccuracy: 87.30%\n",
      "23\tValidation loss: 0.699949\tBest loss: 0.572020\tAccuracy: 86.20%\n",
      "24\tValidation loss: 0.742208\tBest loss: 0.572020\tAccuracy: 85.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   7.5s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.205554\tBest loss: 1.205554\tAccuracy: 65.90%\n",
      "1\tValidation loss: 0.842259\tBest loss: 0.842259\tAccuracy: 76.20%\n",
      "2\tValidation loss: 0.855880\tBest loss: 0.842259\tAccuracy: 76.20%\n",
      "3\tValidation loss: 0.599600\tBest loss: 0.599600\tAccuracy: 83.30%\n",
      "4\tValidation loss: 0.733585\tBest loss: 0.599600\tAccuracy: 78.40%\n",
      "5\tValidation loss: 0.612728\tBest loss: 0.599600\tAccuracy: 83.30%\n",
      "6\tValidation loss: 0.632454\tBest loss: 0.599600\tAccuracy: 83.10%\n",
      "7\tValidation loss: 0.805077\tBest loss: 0.599600\tAccuracy: 79.50%\n",
      "8\tValidation loss: 0.738741\tBest loss: 0.599600\tAccuracy: 85.60%\n",
      "9\tValidation loss: 0.853613\tBest loss: 0.599600\tAccuracy: 81.40%\n",
      "10\tValidation loss: 0.739826\tBest loss: 0.599600\tAccuracy: 81.30%\n",
      "11\tValidation loss: 0.538648\tBest loss: 0.538648\tAccuracy: 86.40%\n",
      "12\tValidation loss: 0.642848\tBest loss: 0.538648\tAccuracy: 85.20%\n",
      "13\tValidation loss: 0.775246\tBest loss: 0.538648\tAccuracy: 84.50%\n",
      "14\tValidation loss: 1.309738\tBest loss: 0.538648\tAccuracy: 76.50%\n",
      "15\tValidation loss: 0.651287\tBest loss: 0.538648\tAccuracy: 85.60%\n",
      "16\tValidation loss: 0.628081\tBest loss: 0.538648\tAccuracy: 85.10%\n",
      "17\tValidation loss: 1.250010\tBest loss: 0.538648\tAccuracy: 81.10%\n",
      "18\tValidation loss: 0.664626\tBest loss: 0.538648\tAccuracy: 85.70%\n",
      "19\tValidation loss: 0.839757\tBest loss: 0.538648\tAccuracy: 85.40%\n",
      "20\tValidation loss: 0.783447\tBest loss: 0.538648\tAccuracy: 85.50%\n",
      "21\tValidation loss: 0.940324\tBest loss: 0.538648\tAccuracy: 84.10%\n",
      "22\tValidation loss: 0.837625\tBest loss: 0.538648\tAccuracy: 86.50%\n",
      "23\tValidation loss: 0.816562\tBest loss: 0.538648\tAccuracy: 87.60%\n",
      "24\tValidation loss: 0.796340\tBest loss: 0.538648\tAccuracy: 85.20%\n",
      "25\tValidation loss: 0.829521\tBest loss: 0.538648\tAccuracy: 86.60%\n",
      "26\tValidation loss: 1.456246\tBest loss: 0.538648\tAccuracy: 84.60%\n",
      "27\tValidation loss: 1.007041\tBest loss: 0.538648\tAccuracy: 85.00%\n",
      "28\tValidation loss: 0.968489\tBest loss: 0.538648\tAccuracy: 86.50%\n",
      "29\tValidation loss: 0.804645\tBest loss: 0.538648\tAccuracy: 87.40%\n",
      "30\tValidation loss: 0.980574\tBest loss: 0.538648\tAccuracy: 86.60%\n",
      "31\tValidation loss: 0.923505\tBest loss: 0.538648\tAccuracy: 85.80%\n",
      "32\tValidation loss: 0.937461\tBest loss: 0.538648\tAccuracy: 87.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=2, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=  10.1s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.744598\tBest loss: 1.744598\tAccuracy: 48.50%\n",
      "1\tValidation loss: 1.006677\tBest loss: 1.006677\tAccuracy: 68.50%\n",
      "2\tValidation loss: 0.856224\tBest loss: 0.856224\tAccuracy: 74.20%\n",
      "3\tValidation loss: 0.746871\tBest loss: 0.746871\tAccuracy: 77.30%\n",
      "4\tValidation loss: 0.619435\tBest loss: 0.619435\tAccuracy: 80.40%\n",
      "5\tValidation loss: 0.522374\tBest loss: 0.522374\tAccuracy: 84.40%\n",
      "6\tValidation loss: 0.486948\tBest loss: 0.486948\tAccuracy: 84.90%\n",
      "7\tValidation loss: 0.560548\tBest loss: 0.486948\tAccuracy: 84.00%\n",
      "8\tValidation loss: 0.460047\tBest loss: 0.460047\tAccuracy: 85.80%\n",
      "9\tValidation loss: 0.546234\tBest loss: 0.460047\tAccuracy: 85.80%\n",
      "10\tValidation loss: 0.652745\tBest loss: 0.460047\tAccuracy: 84.00%\n",
      "11\tValidation loss: 0.603848\tBest loss: 0.460047\tAccuracy: 85.80%\n",
      "12\tValidation loss: 0.588311\tBest loss: 0.460047\tAccuracy: 85.00%\n",
      "13\tValidation loss: 0.444379\tBest loss: 0.444379\tAccuracy: 88.20%\n",
      "14\tValidation loss: 0.524212\tBest loss: 0.444379\tAccuracy: 87.60%\n",
      "15\tValidation loss: 0.493916\tBest loss: 0.444379\tAccuracy: 88.70%\n",
      "16\tValidation loss: 0.504724\tBest loss: 0.444379\tAccuracy: 87.90%\n",
      "17\tValidation loss: 0.587525\tBest loss: 0.444379\tAccuracy: 84.90%\n",
      "18\tValidation loss: 0.522142\tBest loss: 0.444379\tAccuracy: 87.10%\n",
      "19\tValidation loss: 0.483305\tBest loss: 0.444379\tAccuracy: 87.50%\n",
      "20\tValidation loss: 0.583836\tBest loss: 0.444379\tAccuracy: 86.40%\n",
      "21\tValidation loss: 0.440524\tBest loss: 0.440524\tAccuracy: 90.50%\n",
      "22\tValidation loss: 0.592120\tBest loss: 0.440524\tAccuracy: 88.50%\n",
      "23\tValidation loss: 0.460927\tBest loss: 0.440524\tAccuracy: 90.20%\n",
      "24\tValidation loss: 0.500593\tBest loss: 0.440524\tAccuracy: 89.90%\n",
      "25\tValidation loss: 0.554008\tBest loss: 0.440524\tAccuracy: 88.60%\n",
      "26\tValidation loss: 0.484042\tBest loss: 0.440524\tAccuracy: 89.10%\n",
      "27\tValidation loss: 0.588548\tBest loss: 0.440524\tAccuracy: 88.80%\n",
      "28\tValidation loss: 0.574089\tBest loss: 0.440524\tAccuracy: 89.40%\n",
      "29\tValidation loss: 0.631796\tBest loss: 0.440524\tAccuracy: 87.20%\n",
      "30\tValidation loss: 0.578784\tBest loss: 0.440524\tAccuracy: 88.80%\n",
      "31\tValidation loss: 0.601887\tBest loss: 0.440524\tAccuracy: 87.00%\n",
      "32\tValidation loss: 0.543763\tBest loss: 0.440524\tAccuracy: 89.70%\n",
      "33\tValidation loss: 0.660640\tBest loss: 0.440524\tAccuracy: 87.60%\n",
      "34\tValidation loss: 0.727138\tBest loss: 0.440524\tAccuracy: 87.80%\n",
      "35\tValidation loss: 0.530329\tBest loss: 0.440524\tAccuracy: 88.50%\n",
      "36\tValidation loss: 0.585664\tBest loss: 0.440524\tAccuracy: 89.20%\n",
      "37\tValidation loss: 0.572221\tBest loss: 0.440524\tAccuracy: 90.50%\n",
      "38\tValidation loss: 0.606891\tBest loss: 0.440524\tAccuracy: 89.80%\n",
      "39\tValidation loss: 0.587801\tBest loss: 0.440524\tAccuracy: 91.40%\n",
      "40\tValidation loss: 0.669491\tBest loss: 0.440524\tAccuracy: 91.20%\n",
      "41\tValidation loss: 0.551500\tBest loss: 0.440524\tAccuracy: 90.00%\n",
      "42\tValidation loss: 0.519581\tBest loss: 0.440524\tAccuracy: 89.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   7.7s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.713881\tBest loss: 1.713881\tAccuracy: 51.10%\n",
      "1\tValidation loss: 0.950646\tBest loss: 0.950646\tAccuracy: 72.00%\n",
      "2\tValidation loss: 0.861502\tBest loss: 0.861502\tAccuracy: 75.00%\n",
      "3\tValidation loss: 0.688341\tBest loss: 0.688341\tAccuracy: 80.00%\n",
      "4\tValidation loss: 0.696371\tBest loss: 0.688341\tAccuracy: 80.40%\n",
      "5\tValidation loss: 0.583372\tBest loss: 0.583372\tAccuracy: 82.10%\n",
      "6\tValidation loss: 0.581819\tBest loss: 0.581819\tAccuracy: 84.80%\n",
      "7\tValidation loss: 0.631726\tBest loss: 0.581819\tAccuracy: 82.80%\n",
      "8\tValidation loss: 0.509803\tBest loss: 0.509803\tAccuracy: 85.90%\n",
      "9\tValidation loss: 0.475541\tBest loss: 0.475541\tAccuracy: 86.90%\n",
      "10\tValidation loss: 0.647700\tBest loss: 0.475541\tAccuracy: 84.60%\n",
      "11\tValidation loss: 0.574670\tBest loss: 0.475541\tAccuracy: 84.80%\n",
      "12\tValidation loss: 0.526688\tBest loss: 0.475541\tAccuracy: 87.30%\n",
      "13\tValidation loss: 0.505787\tBest loss: 0.475541\tAccuracy: 88.30%\n",
      "14\tValidation loss: 0.520589\tBest loss: 0.475541\tAccuracy: 88.10%\n",
      "15\tValidation loss: 0.499001\tBest loss: 0.475541\tAccuracy: 88.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\tValidation loss: 0.576611\tBest loss: 0.475541\tAccuracy: 86.10%\n",
      "17\tValidation loss: 0.568372\tBest loss: 0.475541\tAccuracy: 86.30%\n",
      "18\tValidation loss: 0.666598\tBest loss: 0.475541\tAccuracy: 87.90%\n",
      "19\tValidation loss: 0.539937\tBest loss: 0.475541\tAccuracy: 89.40%\n",
      "20\tValidation loss: 0.640921\tBest loss: 0.475541\tAccuracy: 85.30%\n",
      "21\tValidation loss: 0.482692\tBest loss: 0.475541\tAccuracy: 88.60%\n",
      "22\tValidation loss: 0.658916\tBest loss: 0.475541\tAccuracy: 87.60%\n",
      "23\tValidation loss: 0.654722\tBest loss: 0.475541\tAccuracy: 86.20%\n",
      "24\tValidation loss: 0.552978\tBest loss: 0.475541\tAccuracy: 87.30%\n",
      "25\tValidation loss: 0.490608\tBest loss: 0.475541\tAccuracy: 89.30%\n",
      "26\tValidation loss: 0.703778\tBest loss: 0.475541\tAccuracy: 88.20%\n",
      "27\tValidation loss: 0.584876\tBest loss: 0.475541\tAccuracy: 86.60%\n",
      "28\tValidation loss: 0.689708\tBest loss: 0.475541\tAccuracy: 86.70%\n",
      "29\tValidation loss: 0.599728\tBest loss: 0.475541\tAccuracy: 88.00%\n",
      "30\tValidation loss: 0.630788\tBest loss: 0.475541\tAccuracy: 89.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   5.9s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.908452\tBest loss: 1.908452\tAccuracy: 46.10%\n",
      "1\tValidation loss: 1.026914\tBest loss: 1.026914\tAccuracy: 69.70%\n",
      "2\tValidation loss: 0.846358\tBest loss: 0.846358\tAccuracy: 75.00%\n",
      "3\tValidation loss: 0.733300\tBest loss: 0.733300\tAccuracy: 78.40%\n",
      "4\tValidation loss: 0.733800\tBest loss: 0.733300\tAccuracy: 79.80%\n",
      "5\tValidation loss: 0.618104\tBest loss: 0.618104\tAccuracy: 81.70%\n",
      "6\tValidation loss: 0.572122\tBest loss: 0.572122\tAccuracy: 83.20%\n",
      "7\tValidation loss: 0.679285\tBest loss: 0.572122\tAccuracy: 81.40%\n",
      "8\tValidation loss: 0.506803\tBest loss: 0.506803\tAccuracy: 85.20%\n",
      "9\tValidation loss: 0.439318\tBest loss: 0.439318\tAccuracy: 86.20%\n",
      "10\tValidation loss: 0.532393\tBest loss: 0.439318\tAccuracy: 86.20%\n",
      "11\tValidation loss: 0.533188\tBest loss: 0.439318\tAccuracy: 85.00%\n",
      "12\tValidation loss: 0.573061\tBest loss: 0.439318\tAccuracy: 84.80%\n",
      "13\tValidation loss: 0.508391\tBest loss: 0.439318\tAccuracy: 85.20%\n",
      "14\tValidation loss: 0.503834\tBest loss: 0.439318\tAccuracy: 87.30%\n",
      "15\tValidation loss: 0.481215\tBest loss: 0.439318\tAccuracy: 86.80%\n",
      "16\tValidation loss: 0.441988\tBest loss: 0.439318\tAccuracy: 88.70%\n",
      "17\tValidation loss: 0.458975\tBest loss: 0.439318\tAccuracy: 87.80%\n",
      "18\tValidation loss: 0.559936\tBest loss: 0.439318\tAccuracy: 85.80%\n",
      "19\tValidation loss: 0.700800\tBest loss: 0.439318\tAccuracy: 84.10%\n",
      "20\tValidation loss: 0.531943\tBest loss: 0.439318\tAccuracy: 87.20%\n",
      "21\tValidation loss: 0.535480\tBest loss: 0.439318\tAccuracy: 86.10%\n",
      "22\tValidation loss: 0.531412\tBest loss: 0.439318\tAccuracy: 87.90%\n",
      "23\tValidation loss: 0.431978\tBest loss: 0.431978\tAccuracy: 89.40%\n",
      "24\tValidation loss: 0.488332\tBest loss: 0.431978\tAccuracy: 89.80%\n",
      "25\tValidation loss: 0.535427\tBest loss: 0.431978\tAccuracy: 88.60%\n",
      "26\tValidation loss: 0.624977\tBest loss: 0.431978\tAccuracy: 86.00%\n",
      "27\tValidation loss: 0.564855\tBest loss: 0.431978\tAccuracy: 86.80%\n",
      "28\tValidation loss: 0.689925\tBest loss: 0.431978\tAccuracy: 87.00%\n",
      "29\tValidation loss: 0.534603\tBest loss: 0.431978\tAccuracy: 88.80%\n",
      "30\tValidation loss: 0.646269\tBest loss: 0.431978\tAccuracy: 89.40%\n",
      "31\tValidation loss: 0.469869\tBest loss: 0.431978\tAccuracy: 88.70%\n",
      "32\tValidation loss: 0.779881\tBest loss: 0.431978\tAccuracy: 85.10%\n",
      "33\tValidation loss: 0.602317\tBest loss: 0.431978\tAccuracy: 87.50%\n",
      "34\tValidation loss: 0.843086\tBest loss: 0.431978\tAccuracy: 86.60%\n",
      "35\tValidation loss: 0.677475\tBest loss: 0.431978\tAccuracy: 86.80%\n",
      "36\tValidation loss: 0.851001\tBest loss: 0.431978\tAccuracy: 83.60%\n",
      "37\tValidation loss: 0.694063\tBest loss: 0.431978\tAccuracy: 87.10%\n",
      "38\tValidation loss: 0.750222\tBest loss: 0.431978\tAccuracy: 83.90%\n",
      "39\tValidation loss: 0.729654\tBest loss: 0.431978\tAccuracy: 86.90%\n",
      "40\tValidation loss: 0.686240\tBest loss: 0.431978\tAccuracy: 88.70%\n",
      "41\tValidation loss: 0.632516\tBest loss: 0.431978\tAccuracy: 89.50%\n",
      "42\tValidation loss: 0.697262\tBest loss: 0.431978\tAccuracy: 88.10%\n",
      "43\tValidation loss: 0.781405\tBest loss: 0.431978\tAccuracy: 87.70%\n",
      "44\tValidation loss: 0.746147\tBest loss: 0.431978\tAccuracy: 87.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   8.3s\n",
      "[CV] batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.394731\tBest loss: 2.394731\tAccuracy: 35.50%\n",
      "1\tValidation loss: 1.150670\tBest loss: 1.150670\tAccuracy: 67.30%\n",
      "2\tValidation loss: 0.881084\tBest loss: 0.881084\tAccuracy: 74.70%\n",
      "3\tValidation loss: 0.654435\tBest loss: 0.654435\tAccuracy: 80.40%\n",
      "4\tValidation loss: 0.606901\tBest loss: 0.606901\tAccuracy: 80.50%\n",
      "5\tValidation loss: 0.585102\tBest loss: 0.585102\tAccuracy: 82.30%\n",
      "6\tValidation loss: 0.617847\tBest loss: 0.585102\tAccuracy: 81.60%\n",
      "7\tValidation loss: 0.442606\tBest loss: 0.442606\tAccuracy: 86.60%\n",
      "8\tValidation loss: 0.474127\tBest loss: 0.442606\tAccuracy: 85.80%\n",
      "9\tValidation loss: 0.489784\tBest loss: 0.442606\tAccuracy: 87.00%\n",
      "10\tValidation loss: 0.401779\tBest loss: 0.401779\tAccuracy: 88.80%\n",
      "11\tValidation loss: 0.393213\tBest loss: 0.393213\tAccuracy: 89.50%\n",
      "12\tValidation loss: 0.439558\tBest loss: 0.393213\tAccuracy: 88.70%\n",
      "13\tValidation loss: 0.393110\tBest loss: 0.393110\tAccuracy: 90.60%\n",
      "14\tValidation loss: 0.494892\tBest loss: 0.393110\tAccuracy: 88.40%\n",
      "15\tValidation loss: 0.368610\tBest loss: 0.368610\tAccuracy: 90.50%\n",
      "16\tValidation loss: 0.427936\tBest loss: 0.368610\tAccuracy: 88.80%\n",
      "17\tValidation loss: 0.509109\tBest loss: 0.368610\tAccuracy: 87.10%\n",
      "18\tValidation loss: 0.457749\tBest loss: 0.368610\tAccuracy: 89.70%\n",
      "19\tValidation loss: 0.499965\tBest loss: 0.368610\tAccuracy: 88.90%\n",
      "20\tValidation loss: 0.472205\tBest loss: 0.368610\tAccuracy: 90.40%\n",
      "21\tValidation loss: 0.543892\tBest loss: 0.368610\tAccuracy: 88.00%\n",
      "22\tValidation loss: 0.411534\tBest loss: 0.368610\tAccuracy: 91.80%\n",
      "23\tValidation loss: 0.576776\tBest loss: 0.368610\tAccuracy: 88.20%\n",
      "24\tValidation loss: 0.551734\tBest loss: 0.368610\tAccuracy: 88.80%\n",
      "25\tValidation loss: 0.528428\tBest loss: 0.368610\tAccuracy: 89.50%\n",
      "26\tValidation loss: 0.472223\tBest loss: 0.368610\tAccuracy: 90.40%\n",
      "27\tValidation loss: 0.660891\tBest loss: 0.368610\tAccuracy: 88.40%\n",
      "28\tValidation loss: 0.566983\tBest loss: 0.368610\tAccuracy: 87.90%\n",
      "29\tValidation loss: 0.717086\tBest loss: 0.368610\tAccuracy: 85.80%\n",
      "30\tValidation loss: 0.477846\tBest loss: 0.368610\tAccuracy: 89.80%\n",
      "31\tValidation loss: 0.558810\tBest loss: 0.368610\tAccuracy: 91.10%\n",
      "32\tValidation loss: 0.607524\tBest loss: 0.368610\tAccuracy: 89.10%\n",
      "33\tValidation loss: 0.627584\tBest loss: 0.368610\tAccuracy: 89.40%\n",
      "34\tValidation loss: 0.547527\tBest loss: 0.368610\tAccuracy: 89.20%\n",
      "35\tValidation loss: 0.542232\tBest loss: 0.368610\tAccuracy: 91.10%\n",
      "36\tValidation loss: 0.568167\tBest loss: 0.368610\tAccuracy: 89.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.6s\n",
      "[CV] batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.283948\tBest loss: 2.283948\tAccuracy: 37.20%\n",
      "1\tValidation loss: 1.075614\tBest loss: 1.075614\tAccuracy: 68.30%\n",
      "2\tValidation loss: 0.980859\tBest loss: 0.980859\tAccuracy: 72.90%\n",
      "3\tValidation loss: 0.677495\tBest loss: 0.677495\tAccuracy: 79.50%\n",
      "4\tValidation loss: 0.683186\tBest loss: 0.677495\tAccuracy: 81.90%\n",
      "5\tValidation loss: 0.579953\tBest loss: 0.579953\tAccuracy: 83.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 0.605702\tBest loss: 0.579953\tAccuracy: 83.60%\n",
      "7\tValidation loss: 0.657223\tBest loss: 0.579953\tAccuracy: 82.80%\n",
      "8\tValidation loss: 0.557533\tBest loss: 0.557533\tAccuracy: 85.10%\n",
      "9\tValidation loss: 0.702387\tBest loss: 0.557533\tAccuracy: 82.20%\n",
      "10\tValidation loss: 0.551581\tBest loss: 0.551581\tAccuracy: 86.50%\n",
      "11\tValidation loss: 0.546959\tBest loss: 0.546959\tAccuracy: 85.70%\n",
      "12\tValidation loss: 0.603252\tBest loss: 0.546959\tAccuracy: 86.20%\n",
      "13\tValidation loss: 0.540585\tBest loss: 0.540585\tAccuracy: 86.80%\n",
      "14\tValidation loss: 0.487201\tBest loss: 0.487201\tAccuracy: 87.00%\n",
      "15\tValidation loss: 0.563562\tBest loss: 0.487201\tAccuracy: 89.10%\n",
      "16\tValidation loss: 0.572429\tBest loss: 0.487201\tAccuracy: 86.40%\n",
      "17\tValidation loss: 0.513608\tBest loss: 0.487201\tAccuracy: 88.90%\n",
      "18\tValidation loss: 0.496134\tBest loss: 0.487201\tAccuracy: 89.50%\n",
      "19\tValidation loss: 0.610040\tBest loss: 0.487201\tAccuracy: 88.50%\n",
      "20\tValidation loss: 0.569997\tBest loss: 0.487201\tAccuracy: 88.60%\n",
      "21\tValidation loss: 0.576946\tBest loss: 0.487201\tAccuracy: 88.10%\n",
      "22\tValidation loss: 0.510403\tBest loss: 0.487201\tAccuracy: 88.10%\n",
      "23\tValidation loss: 0.582879\tBest loss: 0.487201\tAccuracy: 87.80%\n",
      "24\tValidation loss: 0.665646\tBest loss: 0.487201\tAccuracy: 88.20%\n",
      "25\tValidation loss: 0.487678\tBest loss: 0.487201\tAccuracy: 89.50%\n",
      "26\tValidation loss: 0.568451\tBest loss: 0.487201\tAccuracy: 88.60%\n",
      "27\tValidation loss: 0.592364\tBest loss: 0.487201\tAccuracy: 89.40%\n",
      "28\tValidation loss: 0.575248\tBest loss: 0.487201\tAccuracy: 89.30%\n",
      "29\tValidation loss: 0.693336\tBest loss: 0.487201\tAccuracy: 87.50%\n",
      "30\tValidation loss: 0.597821\tBest loss: 0.487201\tAccuracy: 87.00%\n",
      "31\tValidation loss: 0.573116\tBest loss: 0.487201\tAccuracy: 89.90%\n",
      "32\tValidation loss: 0.520107\tBest loss: 0.487201\tAccuracy: 90.00%\n",
      "33\tValidation loss: 0.587334\tBest loss: 0.487201\tAccuracy: 90.70%\n",
      "34\tValidation loss: 0.551717\tBest loss: 0.487201\tAccuracy: 90.30%\n",
      "35\tValidation loss: 0.666911\tBest loss: 0.487201\tAccuracy: 88.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   6.4s\n",
      "[CV] batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 2.646218\tBest loss: 2.646218\tAccuracy: 26.70%\n",
      "1\tValidation loss: 1.339360\tBest loss: 1.339360\tAccuracy: 60.00%\n",
      "2\tValidation loss: 0.985670\tBest loss: 0.985670\tAccuracy: 71.10%\n",
      "3\tValidation loss: 0.765543\tBest loss: 0.765543\tAccuracy: 77.40%\n",
      "4\tValidation loss: 0.628487\tBest loss: 0.628487\tAccuracy: 80.20%\n",
      "5\tValidation loss: 0.651362\tBest loss: 0.628487\tAccuracy: 79.70%\n",
      "6\tValidation loss: 0.519326\tBest loss: 0.519326\tAccuracy: 84.50%\n",
      "7\tValidation loss: 0.562382\tBest loss: 0.519326\tAccuracy: 83.10%\n",
      "8\tValidation loss: 0.522925\tBest loss: 0.519326\tAccuracy: 84.30%\n",
      "9\tValidation loss: 0.497431\tBest loss: 0.497431\tAccuracy: 86.10%\n",
      "10\tValidation loss: 0.554023\tBest loss: 0.497431\tAccuracy: 86.20%\n",
      "11\tValidation loss: 0.469355\tBest loss: 0.469355\tAccuracy: 86.20%\n",
      "12\tValidation loss: 0.456783\tBest loss: 0.456783\tAccuracy: 88.30%\n",
      "13\tValidation loss: 0.529390\tBest loss: 0.456783\tAccuracy: 86.80%\n",
      "14\tValidation loss: 0.553081\tBest loss: 0.456783\tAccuracy: 84.50%\n",
      "15\tValidation loss: 0.501046\tBest loss: 0.456783\tAccuracy: 87.20%\n",
      "16\tValidation loss: 0.550559\tBest loss: 0.456783\tAccuracy: 82.80%\n",
      "17\tValidation loss: 0.522868\tBest loss: 0.456783\tAccuracy: 87.30%\n",
      "18\tValidation loss: 0.414801\tBest loss: 0.414801\tAccuracy: 89.70%\n",
      "19\tValidation loss: 0.449996\tBest loss: 0.414801\tAccuracy: 89.00%\n",
      "20\tValidation loss: 0.533052\tBest loss: 0.414801\tAccuracy: 87.30%\n",
      "21\tValidation loss: 0.507462\tBest loss: 0.414801\tAccuracy: 89.50%\n",
      "22\tValidation loss: 0.493339\tBest loss: 0.414801\tAccuracy: 89.20%\n",
      "23\tValidation loss: 0.546683\tBest loss: 0.414801\tAccuracy: 88.30%\n",
      "24\tValidation loss: 0.657726\tBest loss: 0.414801\tAccuracy: 85.50%\n",
      "25\tValidation loss: 0.479726\tBest loss: 0.414801\tAccuracy: 90.00%\n",
      "26\tValidation loss: 0.761101\tBest loss: 0.414801\tAccuracy: 85.50%\n",
      "27\tValidation loss: 0.557943\tBest loss: 0.414801\tAccuracy: 88.80%\n",
      "28\tValidation loss: 0.627570\tBest loss: 0.414801\tAccuracy: 88.00%\n",
      "29\tValidation loss: 0.529714\tBest loss: 0.414801\tAccuracy: 88.90%\n",
      "30\tValidation loss: 0.700839\tBest loss: 0.414801\tAccuracy: 87.60%\n",
      "31\tValidation loss: 0.672114\tBest loss: 0.414801\tAccuracy: 88.00%\n",
      "32\tValidation loss: 0.599666\tBest loss: 0.414801\tAccuracy: 87.60%\n",
      "33\tValidation loss: 0.607705\tBest loss: 0.414801\tAccuracy: 88.60%\n",
      "34\tValidation loss: 0.659210\tBest loss: 0.414801\tAccuracy: 89.80%\n",
      "35\tValidation loss: 0.796177\tBest loss: 0.414801\tAccuracy: 88.20%\n",
      "36\tValidation loss: 0.583672\tBest loss: 0.414801\tAccuracy: 90.60%\n",
      "37\tValidation loss: 0.580666\tBest loss: 0.414801\tAccuracy: 91.20%\n",
      "38\tValidation loss: 0.635703\tBest loss: 0.414801\tAccuracy: 86.60%\n",
      "39\tValidation loss: 0.701377\tBest loss: 0.414801\tAccuracy: 87.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=500, n_hidden_layers=3, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.01, total=   7.0s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.348378\tBest loss: 3.348378\tAccuracy: 19.90%\n",
      "1\tValidation loss: 2.214320\tBest loss: 2.214320\tAccuracy: 41.90%\n",
      "2\tValidation loss: 1.662217\tBest loss: 1.662217\tAccuracy: 55.50%\n",
      "3\tValidation loss: 1.110048\tBest loss: 1.110048\tAccuracy: 67.50%\n",
      "4\tValidation loss: 1.039957\tBest loss: 1.039957\tAccuracy: 71.50%\n",
      "5\tValidation loss: 1.092256\tBest loss: 1.039957\tAccuracy: 68.70%\n",
      "6\tValidation loss: 1.959612\tBest loss: 1.039957\tAccuracy: 60.50%\n",
      "7\tValidation loss: 0.866950\tBest loss: 0.866950\tAccuracy: 76.40%\n",
      "8\tValidation loss: 0.535102\tBest loss: 0.535102\tAccuracy: 85.70%\n",
      "9\tValidation loss: 0.740113\tBest loss: 0.535102\tAccuracy: 80.60%\n",
      "10\tValidation loss: 1.213637\tBest loss: 0.535102\tAccuracy: 73.70%\n",
      "11\tValidation loss: 2.514505\tBest loss: 0.535102\tAccuracy: 67.10%\n",
      "12\tValidation loss: 0.678024\tBest loss: 0.535102\tAccuracy: 83.20%\n",
      "13\tValidation loss: 0.539288\tBest loss: 0.535102\tAccuracy: 88.90%\n",
      "14\tValidation loss: 0.401296\tBest loss: 0.401296\tAccuracy: 90.30%\n",
      "15\tValidation loss: 0.500799\tBest loss: 0.401296\tAccuracy: 91.00%\n",
      "16\tValidation loss: 0.310800\tBest loss: 0.310800\tAccuracy: 92.20%\n",
      "17\tValidation loss: 0.385252\tBest loss: 0.310800\tAccuracy: 91.60%\n",
      "18\tValidation loss: 0.455375\tBest loss: 0.310800\tAccuracy: 90.80%\n",
      "19\tValidation loss: 0.949814\tBest loss: 0.310800\tAccuracy: 85.10%\n",
      "20\tValidation loss: 0.727215\tBest loss: 0.310800\tAccuracy: 87.70%\n",
      "21\tValidation loss: 0.363351\tBest loss: 0.310800\tAccuracy: 93.30%\n",
      "22\tValidation loss: 0.372952\tBest loss: 0.310800\tAccuracy: 92.50%\n",
      "23\tValidation loss: 0.371559\tBest loss: 0.310800\tAccuracy: 93.40%\n",
      "24\tValidation loss: 0.480391\tBest loss: 0.310800\tAccuracy: 91.60%\n",
      "25\tValidation loss: 0.457517\tBest loss: 0.310800\tAccuracy: 93.30%\n",
      "26\tValidation loss: 0.526582\tBest loss: 0.310800\tAccuracy: 92.90%\n",
      "27\tValidation loss: 0.552504\tBest loss: 0.310800\tAccuracy: 91.40%\n",
      "28\tValidation loss: 0.439151\tBest loss: 0.310800\tAccuracy: 94.10%\n",
      "29\tValidation loss: 0.577000\tBest loss: 0.310800\tAccuracy: 92.20%\n",
      "30\tValidation loss: 0.463242\tBest loss: 0.310800\tAccuracy: 93.80%\n",
      "31\tValidation loss: 0.495160\tBest loss: 0.310800\tAccuracy: 93.80%\n",
      "32\tValidation loss: 1.923596\tBest loss: 0.310800\tAccuracy: 84.00%\n",
      "33\tValidation loss: 1.143626\tBest loss: 0.310800\tAccuracy: 86.00%\n",
      "34\tValidation loss: 1.124015\tBest loss: 0.310800\tAccuracy: 88.90%\n",
      "35\tValidation loss: 0.702024\tBest loss: 0.310800\tAccuracy: 91.20%\n",
      "36\tValidation loss: 0.645129\tBest loss: 0.310800\tAccuracy: 93.70%\n",
      "37\tValidation loss: 1.349003\tBest loss: 0.310800\tAccuracy: 88.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.6s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.069402\tBest loss: 3.069402\tAccuracy: 22.10%\n",
      "1\tValidation loss: 2.408079\tBest loss: 2.408079\tAccuracy: 37.70%\n",
      "2\tValidation loss: 1.910673\tBest loss: 1.910673\tAccuracy: 50.60%\n",
      "3\tValidation loss: 3.382280\tBest loss: 1.910673\tAccuracy: 33.40%\n",
      "4\tValidation loss: 2.005811\tBest loss: 1.910673\tAccuracy: 55.00%\n",
      "5\tValidation loss: 2.213474\tBest loss: 1.910673\tAccuracy: 59.50%\n",
      "6\tValidation loss: 2.080454\tBest loss: 1.910673\tAccuracy: 54.90%\n",
      "7\tValidation loss: 0.873513\tBest loss: 0.873513\tAccuracy: 75.30%\n",
      "8\tValidation loss: 1.098837\tBest loss: 0.873513\tAccuracy: 75.80%\n",
      "9\tValidation loss: 0.534649\tBest loss: 0.534649\tAccuracy: 85.20%\n",
      "10\tValidation loss: 0.734655\tBest loss: 0.534649\tAccuracy: 82.00%\n",
      "11\tValidation loss: 0.627982\tBest loss: 0.534649\tAccuracy: 85.40%\n",
      "12\tValidation loss: 0.630179\tBest loss: 0.534649\tAccuracy: 85.30%\n",
      "13\tValidation loss: 0.599675\tBest loss: 0.534649\tAccuracy: 84.60%\n",
      "14\tValidation loss: 0.903064\tBest loss: 0.534649\tAccuracy: 81.10%\n",
      "15\tValidation loss: 0.419115\tBest loss: 0.419115\tAccuracy: 92.10%\n",
      "16\tValidation loss: 0.415587\tBest loss: 0.415587\tAccuracy: 91.90%\n",
      "17\tValidation loss: 0.532664\tBest loss: 0.415587\tAccuracy: 91.60%\n",
      "18\tValidation loss: 0.412195\tBest loss: 0.412195\tAccuracy: 92.40%\n",
      "19\tValidation loss: 0.452513\tBest loss: 0.412195\tAccuracy: 92.40%\n",
      "20\tValidation loss: 0.693760\tBest loss: 0.412195\tAccuracy: 87.80%\n",
      "21\tValidation loss: 0.472214\tBest loss: 0.412195\tAccuracy: 92.80%\n",
      "22\tValidation loss: 0.544449\tBest loss: 0.412195\tAccuracy: 92.70%\n",
      "23\tValidation loss: 0.678640\tBest loss: 0.412195\tAccuracy: 91.40%\n",
      "24\tValidation loss: 0.452310\tBest loss: 0.412195\tAccuracy: 92.80%\n",
      "25\tValidation loss: 0.625686\tBest loss: 0.412195\tAccuracy: 91.40%\n",
      "26\tValidation loss: 0.764622\tBest loss: 0.412195\tAccuracy: 91.20%\n",
      "27\tValidation loss: 0.853207\tBest loss: 0.412195\tAccuracy: 89.40%\n",
      "28\tValidation loss: 1.073997\tBest loss: 0.412195\tAccuracy: 88.20%\n",
      "29\tValidation loss: 0.664367\tBest loss: 0.412195\tAccuracy: 93.20%\n",
      "30\tValidation loss: 1.213307\tBest loss: 0.412195\tAccuracy: 87.60%\n",
      "31\tValidation loss: 0.657643\tBest loss: 0.412195\tAccuracy: 92.70%\n",
      "32\tValidation loss: 0.837578\tBest loss: 0.412195\tAccuracy: 91.30%\n",
      "33\tValidation loss: 2.679900\tBest loss: 0.412195\tAccuracy: 79.00%\n",
      "34\tValidation loss: 1.041084\tBest loss: 0.412195\tAccuracy: 90.10%\n",
      "35\tValidation loss: 0.781168\tBest loss: 0.412195\tAccuracy: 92.50%\n",
      "36\tValidation loss: 1.463441\tBest loss: 0.412195\tAccuracy: 85.70%\n",
      "37\tValidation loss: 2.004802\tBest loss: 0.412195\tAccuracy: 85.00%\n",
      "38\tValidation loss: 0.973554\tBest loss: 0.412195\tAccuracy: 91.20%\n",
      "39\tValidation loss: 1.301872\tBest loss: 0.412195\tAccuracy: 87.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.8s\n",
      "[CV] batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.211531\tBest loss: 3.211531\tAccuracy: 24.00%\n",
      "1\tValidation loss: 2.180742\tBest loss: 2.180742\tAccuracy: 45.30%\n",
      "2\tValidation loss: 1.814373\tBest loss: 1.814373\tAccuracy: 51.80%\n",
      "3\tValidation loss: 1.599133\tBest loss: 1.599133\tAccuracy: 55.80%\n",
      "4\tValidation loss: 1.001871\tBest loss: 1.001871\tAccuracy: 72.80%\n",
      "5\tValidation loss: 0.808417\tBest loss: 0.808417\tAccuracy: 77.70%\n",
      "6\tValidation loss: 1.466138\tBest loss: 0.808417\tAccuracy: 65.20%\n",
      "7\tValidation loss: 1.130301\tBest loss: 0.808417\tAccuracy: 71.50%\n",
      "8\tValidation loss: 0.672752\tBest loss: 0.672752\tAccuracy: 82.40%\n",
      "9\tValidation loss: 0.791328\tBest loss: 0.672752\tAccuracy: 80.70%\n",
      "10\tValidation loss: 0.503383\tBest loss: 0.503383\tAccuracy: 87.00%\n",
      "11\tValidation loss: 0.480111\tBest loss: 0.480111\tAccuracy: 86.70%\n",
      "12\tValidation loss: 1.731473\tBest loss: 0.480111\tAccuracy: 72.30%\n",
      "13\tValidation loss: 0.625906\tBest loss: 0.480111\tAccuracy: 85.80%\n",
      "14\tValidation loss: 0.444404\tBest loss: 0.444404\tAccuracy: 88.80%\n",
      "15\tValidation loss: 0.361423\tBest loss: 0.361423\tAccuracy: 90.70%\n",
      "16\tValidation loss: 0.472312\tBest loss: 0.361423\tAccuracy: 89.70%\n",
      "17\tValidation loss: 0.405951\tBest loss: 0.361423\tAccuracy: 91.00%\n",
      "18\tValidation loss: 0.328296\tBest loss: 0.328296\tAccuracy: 92.60%\n",
      "19\tValidation loss: 0.359833\tBest loss: 0.328296\tAccuracy: 92.60%\n",
      "20\tValidation loss: 0.402024\tBest loss: 0.328296\tAccuracy: 92.40%\n",
      "21\tValidation loss: 0.425148\tBest loss: 0.328296\tAccuracy: 92.20%\n",
      "22\tValidation loss: 1.573229\tBest loss: 0.328296\tAccuracy: 82.00%\n",
      "23\tValidation loss: 0.656029\tBest loss: 0.328296\tAccuracy: 89.90%\n",
      "24\tValidation loss: 1.656163\tBest loss: 0.328296\tAccuracy: 79.80%\n",
      "25\tValidation loss: 1.005006\tBest loss: 0.328296\tAccuracy: 85.60%\n",
      "26\tValidation loss: 0.479372\tBest loss: 0.328296\tAccuracy: 91.00%\n",
      "27\tValidation loss: 0.468401\tBest loss: 0.328296\tAccuracy: 92.60%\n",
      "28\tValidation loss: 0.375930\tBest loss: 0.328296\tAccuracy: 93.40%\n",
      "29\tValidation loss: 0.538076\tBest loss: 0.328296\tAccuracy: 92.90%\n",
      "30\tValidation loss: 0.409920\tBest loss: 0.328296\tAccuracy: 93.80%\n",
      "31\tValidation loss: 0.640809\tBest loss: 0.328296\tAccuracy: 92.20%\n",
      "32\tValidation loss: 0.730963\tBest loss: 0.328296\tAccuracy: 92.00%\n",
      "33\tValidation loss: 1.085273\tBest loss: 0.328296\tAccuracy: 86.20%\n",
      "34\tValidation loss: 1.007810\tBest loss: 0.328296\tAccuracy: 88.60%\n",
      "35\tValidation loss: 0.479088\tBest loss: 0.328296\tAccuracy: 92.20%\n",
      "36\tValidation loss: 1.099833\tBest loss: 0.328296\tAccuracy: 88.70%\n",
      "37\tValidation loss: 0.795908\tBest loss: 0.328296\tAccuracy: 92.00%\n",
      "38\tValidation loss: 1.307047\tBest loss: 0.328296\tAccuracy: 88.20%\n",
      "39\tValidation loss: 0.876482\tBest loss: 0.328296\tAccuracy: 90.70%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=400, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.6s\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.779481\tBest loss: 1.779481\tAccuracy: 58.70%\n",
      "1\tValidation loss: 1.365405\tBest loss: 1.365405\tAccuracy: 68.90%\n",
      "2\tValidation loss: 1.162148\tBest loss: 1.162148\tAccuracy: 73.80%\n",
      "3\tValidation loss: 1.041496\tBest loss: 1.041496\tAccuracy: 77.00%\n",
      "4\tValidation loss: 0.967627\tBest loss: 0.967627\tAccuracy: 78.90%\n",
      "5\tValidation loss: 0.894899\tBest loss: 0.894899\tAccuracy: 81.20%\n",
      "6\tValidation loss: 0.844076\tBest loss: 0.844076\tAccuracy: 82.50%\n",
      "7\tValidation loss: 0.808052\tBest loss: 0.808052\tAccuracy: 82.30%\n",
      "8\tValidation loss: 0.783095\tBest loss: 0.783095\tAccuracy: 83.70%\n",
      "9\tValidation loss: 0.757210\tBest loss: 0.757210\tAccuracy: 82.70%\n",
      "10\tValidation loss: 0.726333\tBest loss: 0.726333\tAccuracy: 84.40%\n",
      "11\tValidation loss: 0.709118\tBest loss: 0.709118\tAccuracy: 84.60%\n",
      "12\tValidation loss: 0.686896\tBest loss: 0.686896\tAccuracy: 84.70%\n",
      "13\tValidation loss: 0.670650\tBest loss: 0.670650\tAccuracy: 84.90%\n",
      "14\tValidation loss: 0.657081\tBest loss: 0.657081\tAccuracy: 85.90%\n",
      "15\tValidation loss: 0.645588\tBest loss: 0.645588\tAccuracy: 85.30%\n",
      "16\tValidation loss: 0.627176\tBest loss: 0.627176\tAccuracy: 86.00%\n",
      "17\tValidation loss: 0.615140\tBest loss: 0.615140\tAccuracy: 85.80%\n",
      "18\tValidation loss: 0.607629\tBest loss: 0.607629\tAccuracy: 86.70%\n",
      "19\tValidation loss: 0.589589\tBest loss: 0.589589\tAccuracy: 86.80%\n",
      "20\tValidation loss: 0.582991\tBest loss: 0.582991\tAccuracy: 87.60%\n",
      "21\tValidation loss: 0.572075\tBest loss: 0.572075\tAccuracy: 87.80%\n",
      "22\tValidation loss: 0.563853\tBest loss: 0.563853\tAccuracy: 87.40%\n",
      "23\tValidation loss: 0.555979\tBest loss: 0.555979\tAccuracy: 87.30%\n",
      "24\tValidation loss: 0.551010\tBest loss: 0.551010\tAccuracy: 88.10%\n",
      "25\tValidation loss: 0.547248\tBest loss: 0.547248\tAccuracy: 88.00%\n",
      "26\tValidation loss: 0.542422\tBest loss: 0.542422\tAccuracy: 87.20%\n",
      "27\tValidation loss: 0.537350\tBest loss: 0.537350\tAccuracy: 88.50%\n",
      "28\tValidation loss: 0.529055\tBest loss: 0.529055\tAccuracy: 88.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\tValidation loss: 0.523919\tBest loss: 0.523919\tAccuracy: 88.10%\n",
      "30\tValidation loss: 0.522862\tBest loss: 0.522862\tAccuracy: 88.20%\n",
      "31\tValidation loss: 0.507164\tBest loss: 0.507164\tAccuracy: 88.70%\n",
      "32\tValidation loss: 0.506315\tBest loss: 0.506315\tAccuracy: 87.60%\n",
      "33\tValidation loss: 0.502380\tBest loss: 0.502380\tAccuracy: 88.70%\n",
      "34\tValidation loss: 0.498937\tBest loss: 0.498937\tAccuracy: 89.00%\n",
      "35\tValidation loss: 0.492559\tBest loss: 0.492559\tAccuracy: 88.80%\n",
      "36\tValidation loss: 0.485535\tBest loss: 0.485535\tAccuracy: 89.30%\n",
      "37\tValidation loss: 0.487473\tBest loss: 0.485535\tAccuracy: 88.90%\n",
      "38\tValidation loss: 0.484798\tBest loss: 0.484798\tAccuracy: 89.20%\n",
      "39\tValidation loss: 0.474465\tBest loss: 0.474465\tAccuracy: 89.40%\n",
      "40\tValidation loss: 0.478998\tBest loss: 0.474465\tAccuracy: 89.60%\n",
      "41\tValidation loss: 0.473236\tBest loss: 0.473236\tAccuracy: 89.40%\n",
      "42\tValidation loss: 0.465609\tBest loss: 0.465609\tAccuracy: 89.30%\n",
      "43\tValidation loss: 0.461052\tBest loss: 0.461052\tAccuracy: 89.60%\n",
      "44\tValidation loss: 0.464053\tBest loss: 0.461052\tAccuracy: 89.40%\n",
      "45\tValidation loss: 0.452523\tBest loss: 0.452523\tAccuracy: 89.50%\n",
      "46\tValidation loss: 0.456535\tBest loss: 0.452523\tAccuracy: 89.50%\n",
      "47\tValidation loss: 0.452913\tBest loss: 0.452523\tAccuracy: 89.60%\n",
      "48\tValidation loss: 0.450631\tBest loss: 0.450631\tAccuracy: 89.80%\n",
      "49\tValidation loss: 0.452214\tBest loss: 0.450631\tAccuracy: 89.70%\n",
      "50\tValidation loss: 0.449504\tBest loss: 0.449504\tAccuracy: 89.70%\n",
      "51\tValidation loss: 0.447055\tBest loss: 0.447055\tAccuracy: 89.70%\n",
      "52\tValidation loss: 0.439124\tBest loss: 0.439124\tAccuracy: 89.70%\n",
      "53\tValidation loss: 0.441916\tBest loss: 0.439124\tAccuracy: 89.60%\n",
      "54\tValidation loss: 0.431364\tBest loss: 0.431364\tAccuracy: 89.70%\n",
      "55\tValidation loss: 0.432627\tBest loss: 0.431364\tAccuracy: 90.10%\n",
      "56\tValidation loss: 0.437475\tBest loss: 0.431364\tAccuracy: 89.40%\n",
      "57\tValidation loss: 0.431628\tBest loss: 0.431364\tAccuracy: 90.00%\n",
      "58\tValidation loss: 0.430347\tBest loss: 0.430347\tAccuracy: 90.00%\n",
      "59\tValidation loss: 0.427768\tBest loss: 0.427768\tAccuracy: 90.30%\n",
      "60\tValidation loss: 0.423661\tBest loss: 0.423661\tAccuracy: 90.30%\n",
      "61\tValidation loss: 0.422194\tBest loss: 0.422194\tAccuracy: 89.90%\n",
      "62\tValidation loss: 0.419797\tBest loss: 0.419797\tAccuracy: 90.10%\n",
      "63\tValidation loss: 0.417596\tBest loss: 0.417596\tAccuracy: 89.60%\n",
      "64\tValidation loss: 0.417141\tBest loss: 0.417141\tAccuracy: 89.80%\n",
      "65\tValidation loss: 0.415362\tBest loss: 0.415362\tAccuracy: 90.40%\n",
      "66\tValidation loss: 0.410424\tBest loss: 0.410424\tAccuracy: 90.30%\n",
      "67\tValidation loss: 0.410536\tBest loss: 0.410424\tAccuracy: 90.40%\n",
      "68\tValidation loss: 0.410623\tBest loss: 0.410424\tAccuracy: 90.00%\n",
      "69\tValidation loss: 0.405421\tBest loss: 0.405421\tAccuracy: 90.60%\n",
      "70\tValidation loss: 0.410909\tBest loss: 0.405421\tAccuracy: 89.90%\n",
      "71\tValidation loss: 0.405988\tBest loss: 0.405421\tAccuracy: 90.60%\n",
      "72\tValidation loss: 0.402604\tBest loss: 0.402604\tAccuracy: 90.50%\n",
      "73\tValidation loss: 0.403218\tBest loss: 0.402604\tAccuracy: 90.50%\n",
      "74\tValidation loss: 0.405072\tBest loss: 0.402604\tAccuracy: 90.10%\n",
      "75\tValidation loss: 0.401771\tBest loss: 0.401771\tAccuracy: 90.00%\n",
      "76\tValidation loss: 0.400427\tBest loss: 0.400427\tAccuracy: 90.50%\n",
      "77\tValidation loss: 0.399667\tBest loss: 0.399667\tAccuracy: 89.90%\n",
      "78\tValidation loss: 0.395613\tBest loss: 0.395613\tAccuracy: 90.20%\n",
      "79\tValidation loss: 0.391345\tBest loss: 0.391345\tAccuracy: 90.40%\n",
      "80\tValidation loss: 0.397889\tBest loss: 0.391345\tAccuracy: 91.10%\n",
      "81\tValidation loss: 0.393125\tBest loss: 0.391345\tAccuracy: 90.60%\n",
      "82\tValidation loss: 0.394843\tBest loss: 0.391345\tAccuracy: 91.10%\n",
      "83\tValidation loss: 0.387271\tBest loss: 0.387271\tAccuracy: 90.40%\n",
      "84\tValidation loss: 0.388455\tBest loss: 0.387271\tAccuracy: 90.40%\n",
      "85\tValidation loss: 0.384893\tBest loss: 0.384893\tAccuracy: 90.30%\n",
      "86\tValidation loss: 0.388017\tBest loss: 0.384893\tAccuracy: 90.80%\n",
      "87\tValidation loss: 0.386362\tBest loss: 0.384893\tAccuracy: 90.60%\n",
      "88\tValidation loss: 0.384884\tBest loss: 0.384884\tAccuracy: 90.90%\n",
      "89\tValidation loss: 0.385721\tBest loss: 0.384884\tAccuracy: 90.70%\n",
      "90\tValidation loss: 0.384757\tBest loss: 0.384757\tAccuracy: 90.30%\n",
      "91\tValidation loss: 0.379173\tBest loss: 0.379173\tAccuracy: 90.70%\n",
      "92\tValidation loss: 0.381956\tBest loss: 0.379173\tAccuracy: 91.00%\n",
      "93\tValidation loss: 0.378065\tBest loss: 0.378065\tAccuracy: 90.50%\n",
      "94\tValidation loss: 0.382264\tBest loss: 0.378065\tAccuracy: 91.30%\n",
      "95\tValidation loss: 0.377825\tBest loss: 0.377825\tAccuracy: 91.60%\n",
      "96\tValidation loss: 0.375052\tBest loss: 0.375052\tAccuracy: 90.60%\n",
      "97\tValidation loss: 0.375672\tBest loss: 0.375052\tAccuracy: 91.50%\n",
      "98\tValidation loss: 0.373850\tBest loss: 0.373850\tAccuracy: 91.10%\n",
      "99\tValidation loss: 0.372974\tBest loss: 0.372974\tAccuracy: 90.90%\n",
      "100\tValidation loss: 0.373873\tBest loss: 0.372974\tAccuracy: 91.30%\n",
      "101\tValidation loss: 0.366821\tBest loss: 0.366821\tAccuracy: 90.90%\n",
      "102\tValidation loss: 0.368140\tBest loss: 0.366821\tAccuracy: 90.70%\n",
      "103\tValidation loss: 0.369154\tBest loss: 0.366821\tAccuracy: 91.30%\n",
      "104\tValidation loss: 0.366774\tBest loss: 0.366774\tAccuracy: 91.20%\n",
      "105\tValidation loss: 0.365631\tBest loss: 0.365631\tAccuracy: 91.10%\n",
      "106\tValidation loss: 0.367802\tBest loss: 0.365631\tAccuracy: 90.90%\n",
      "107\tValidation loss: 0.369847\tBest loss: 0.365631\tAccuracy: 91.50%\n",
      "108\tValidation loss: 0.366922\tBest loss: 0.365631\tAccuracy: 91.30%\n",
      "109\tValidation loss: 0.364224\tBest loss: 0.364224\tAccuracy: 91.30%\n",
      "110\tValidation loss: 0.365109\tBest loss: 0.364224\tAccuracy: 91.20%\n",
      "111\tValidation loss: 0.364361\tBest loss: 0.364224\tAccuracy: 91.70%\n",
      "112\tValidation loss: 0.363284\tBest loss: 0.363284\tAccuracy: 91.50%\n",
      "113\tValidation loss: 0.359211\tBest loss: 0.359211\tAccuracy: 91.10%\n",
      "114\tValidation loss: 0.361109\tBest loss: 0.359211\tAccuracy: 91.60%\n",
      "115\tValidation loss: 0.361640\tBest loss: 0.359211\tAccuracy: 91.60%\n",
      "116\tValidation loss: 0.360597\tBest loss: 0.359211\tAccuracy: 91.70%\n",
      "117\tValidation loss: 0.358192\tBest loss: 0.358192\tAccuracy: 91.80%\n",
      "118\tValidation loss: 0.356533\tBest loss: 0.356533\tAccuracy: 91.80%\n",
      "119\tValidation loss: 0.358877\tBest loss: 0.356533\tAccuracy: 91.70%\n",
      "120\tValidation loss: 0.358025\tBest loss: 0.356533\tAccuracy: 91.60%\n",
      "121\tValidation loss: 0.357532\tBest loss: 0.356533\tAccuracy: 91.70%\n",
      "122\tValidation loss: 0.356438\tBest loss: 0.356438\tAccuracy: 92.10%\n",
      "123\tValidation loss: 0.355329\tBest loss: 0.355329\tAccuracy: 91.40%\n",
      "124\tValidation loss: 0.355769\tBest loss: 0.355329\tAccuracy: 91.80%\n",
      "125\tValidation loss: 0.353945\tBest loss: 0.353945\tAccuracy: 92.10%\n",
      "126\tValidation loss: 0.353940\tBest loss: 0.353940\tAccuracy: 91.50%\n",
      "127\tValidation loss: 0.355173\tBest loss: 0.353940\tAccuracy: 91.80%\n",
      "128\tValidation loss: 0.350132\tBest loss: 0.350132\tAccuracy: 91.50%\n",
      "129\tValidation loss: 0.351196\tBest loss: 0.350132\tAccuracy: 91.70%\n",
      "130\tValidation loss: 0.354957\tBest loss: 0.350132\tAccuracy: 91.90%\n",
      "131\tValidation loss: 0.349857\tBest loss: 0.349857\tAccuracy: 92.10%\n",
      "132\tValidation loss: 0.349764\tBest loss: 0.349764\tAccuracy: 91.70%\n",
      "133\tValidation loss: 0.349732\tBest loss: 0.349732\tAccuracy: 91.80%\n",
      "134\tValidation loss: 0.351150\tBest loss: 0.349732\tAccuracy: 92.20%\n",
      "135\tValidation loss: 0.350088\tBest loss: 0.349732\tAccuracy: 91.90%\n",
      "136\tValidation loss: 0.346247\tBest loss: 0.346247\tAccuracy: 91.60%\n",
      "137\tValidation loss: 0.345118\tBest loss: 0.345118\tAccuracy: 91.40%\n",
      "138\tValidation loss: 0.344599\tBest loss: 0.344599\tAccuracy: 92.00%\n",
      "139\tValidation loss: 0.345613\tBest loss: 0.344599\tAccuracy: 92.10%\n",
      "140\tValidation loss: 0.344402\tBest loss: 0.344402\tAccuracy: 91.90%\n",
      "141\tValidation loss: 0.346093\tBest loss: 0.344402\tAccuracy: 92.00%\n",
      "142\tValidation loss: 0.345143\tBest loss: 0.344402\tAccuracy: 91.80%\n",
      "143\tValidation loss: 0.340429\tBest loss: 0.340429\tAccuracy: 92.20%\n",
      "144\tValidation loss: 0.341579\tBest loss: 0.340429\tAccuracy: 91.90%\n",
      "145\tValidation loss: 0.340737\tBest loss: 0.340429\tAccuracy: 92.20%\n",
      "146\tValidation loss: 0.339713\tBest loss: 0.339713\tAccuracy: 92.30%\n",
      "147\tValidation loss: 0.339543\tBest loss: 0.339543\tAccuracy: 92.30%\n",
      "148\tValidation loss: 0.340936\tBest loss: 0.339543\tAccuracy: 92.20%\n",
      "149\tValidation loss: 0.340371\tBest loss: 0.339543\tAccuracy: 92.10%\n",
      "150\tValidation loss: 0.339216\tBest loss: 0.339216\tAccuracy: 92.30%\n",
      "151\tValidation loss: 0.338227\tBest loss: 0.338227\tAccuracy: 92.20%\n",
      "152\tValidation loss: 0.337468\tBest loss: 0.337468\tAccuracy: 92.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\tValidation loss: 0.335124\tBest loss: 0.335124\tAccuracy: 92.20%\n",
      "154\tValidation loss: 0.338963\tBest loss: 0.335124\tAccuracy: 92.00%\n",
      "155\tValidation loss: 0.337064\tBest loss: 0.335124\tAccuracy: 92.20%\n",
      "156\tValidation loss: 0.339318\tBest loss: 0.335124\tAccuracy: 92.40%\n",
      "157\tValidation loss: 0.340632\tBest loss: 0.335124\tAccuracy: 92.20%\n",
      "158\tValidation loss: 0.337711\tBest loss: 0.335124\tAccuracy: 92.20%\n",
      "159\tValidation loss: 0.334486\tBest loss: 0.334486\tAccuracy: 92.20%\n",
      "160\tValidation loss: 0.338466\tBest loss: 0.334486\tAccuracy: 92.20%\n",
      "161\tValidation loss: 0.336957\tBest loss: 0.334486\tAccuracy: 92.10%\n",
      "162\tValidation loss: 0.334424\tBest loss: 0.334424\tAccuracy: 92.20%\n",
      "163\tValidation loss: 0.334056\tBest loss: 0.334056\tAccuracy: 92.30%\n",
      "164\tValidation loss: 0.332532\tBest loss: 0.332532\tAccuracy: 92.40%\n",
      "165\tValidation loss: 0.333551\tBest loss: 0.332532\tAccuracy: 92.30%\n",
      "166\tValidation loss: 0.333931\tBest loss: 0.332532\tAccuracy: 92.30%\n",
      "167\tValidation loss: 0.330778\tBest loss: 0.330778\tAccuracy: 92.30%\n",
      "168\tValidation loss: 0.334058\tBest loss: 0.330778\tAccuracy: 92.20%\n",
      "169\tValidation loss: 0.329847\tBest loss: 0.329847\tAccuracy: 92.30%\n",
      "170\tValidation loss: 0.331013\tBest loss: 0.329847\tAccuracy: 92.50%\n",
      "171\tValidation loss: 0.329990\tBest loss: 0.329847\tAccuracy: 92.80%\n",
      "172\tValidation loss: 0.330487\tBest loss: 0.329847\tAccuracy: 92.40%\n",
      "173\tValidation loss: 0.331444\tBest loss: 0.329847\tAccuracy: 92.60%\n",
      "174\tValidation loss: 0.329527\tBest loss: 0.329527\tAccuracy: 92.30%\n",
      "175\tValidation loss: 0.327457\tBest loss: 0.327457\tAccuracy: 92.60%\n",
      "176\tValidation loss: 0.332868\tBest loss: 0.327457\tAccuracy: 92.20%\n",
      "177\tValidation loss: 0.326880\tBest loss: 0.326880\tAccuracy: 92.30%\n",
      "178\tValidation loss: 0.330829\tBest loss: 0.326880\tAccuracy: 92.40%\n",
      "179\tValidation loss: 0.326678\tBest loss: 0.326678\tAccuracy: 92.50%\n",
      "180\tValidation loss: 0.326884\tBest loss: 0.326678\tAccuracy: 92.50%\n",
      "181\tValidation loss: 0.326554\tBest loss: 0.326554\tAccuracy: 92.70%\n",
      "182\tValidation loss: 0.327431\tBest loss: 0.326554\tAccuracy: 92.70%\n",
      "183\tValidation loss: 0.326580\tBest loss: 0.326554\tAccuracy: 92.60%\n",
      "184\tValidation loss: 0.326850\tBest loss: 0.326554\tAccuracy: 92.70%\n",
      "185\tValidation loss: 0.324846\tBest loss: 0.324846\tAccuracy: 92.70%\n",
      "186\tValidation loss: 0.322983\tBest loss: 0.322983\tAccuracy: 92.70%\n",
      "187\tValidation loss: 0.325896\tBest loss: 0.322983\tAccuracy: 92.80%\n",
      "188\tValidation loss: 0.325226\tBest loss: 0.322983\tAccuracy: 92.90%\n",
      "189\tValidation loss: 0.325201\tBest loss: 0.322983\tAccuracy: 92.90%\n",
      "190\tValidation loss: 0.323630\tBest loss: 0.322983\tAccuracy: 92.50%\n",
      "191\tValidation loss: 0.323186\tBest loss: 0.322983\tAccuracy: 93.00%\n",
      "192\tValidation loss: 0.324150\tBest loss: 0.322983\tAccuracy: 92.70%\n",
      "193\tValidation loss: 0.322696\tBest loss: 0.322696\tAccuracy: 92.50%\n",
      "194\tValidation loss: 0.322398\tBest loss: 0.322398\tAccuracy: 92.70%\n",
      "195\tValidation loss: 0.320174\tBest loss: 0.320174\tAccuracy: 92.60%\n",
      "196\tValidation loss: 0.322139\tBest loss: 0.320174\tAccuracy: 92.60%\n",
      "197\tValidation loss: 0.320024\tBest loss: 0.320024\tAccuracy: 92.70%\n",
      "198\tValidation loss: 0.319765\tBest loss: 0.319765\tAccuracy: 92.70%\n",
      "199\tValidation loss: 0.321294\tBest loss: 0.319765\tAccuracy: 92.80%\n",
      "200\tValidation loss: 0.323366\tBest loss: 0.319765\tAccuracy: 92.80%\n",
      "201\tValidation loss: 0.321765\tBest loss: 0.319765\tAccuracy: 92.70%\n",
      "202\tValidation loss: 0.322009\tBest loss: 0.319765\tAccuracy: 92.60%\n",
      "203\tValidation loss: 0.322677\tBest loss: 0.319765\tAccuracy: 93.00%\n",
      "204\tValidation loss: 0.323010\tBest loss: 0.319765\tAccuracy: 92.90%\n",
      "205\tValidation loss: 0.319418\tBest loss: 0.319418\tAccuracy: 93.00%\n",
      "206\tValidation loss: 0.317130\tBest loss: 0.317130\tAccuracy: 92.90%\n",
      "207\tValidation loss: 0.319532\tBest loss: 0.317130\tAccuracy: 93.00%\n",
      "208\tValidation loss: 0.321497\tBest loss: 0.317130\tAccuracy: 93.20%\n",
      "209\tValidation loss: 0.315121\tBest loss: 0.315121\tAccuracy: 93.00%\n",
      "210\tValidation loss: 0.314048\tBest loss: 0.314048\tAccuracy: 93.10%\n",
      "211\tValidation loss: 0.317616\tBest loss: 0.314048\tAccuracy: 92.80%\n",
      "212\tValidation loss: 0.316455\tBest loss: 0.314048\tAccuracy: 92.90%\n",
      "213\tValidation loss: 0.317098\tBest loss: 0.314048\tAccuracy: 92.60%\n",
      "214\tValidation loss: 0.315630\tBest loss: 0.314048\tAccuracy: 93.20%\n",
      "215\tValidation loss: 0.316535\tBest loss: 0.314048\tAccuracy: 93.10%\n",
      "216\tValidation loss: 0.313733\tBest loss: 0.313733\tAccuracy: 93.20%\n",
      "217\tValidation loss: 0.315858\tBest loss: 0.313733\tAccuracy: 93.10%\n",
      "218\tValidation loss: 0.316119\tBest loss: 0.313733\tAccuracy: 93.30%\n",
      "219\tValidation loss: 0.315221\tBest loss: 0.313733\tAccuracy: 92.80%\n",
      "220\tValidation loss: 0.316613\tBest loss: 0.313733\tAccuracy: 92.80%\n",
      "221\tValidation loss: 0.316477\tBest loss: 0.313733\tAccuracy: 93.10%\n",
      "222\tValidation loss: 0.315889\tBest loss: 0.313733\tAccuracy: 93.10%\n",
      "223\tValidation loss: 0.315884\tBest loss: 0.313733\tAccuracy: 93.10%\n",
      "224\tValidation loss: 0.312137\tBest loss: 0.312137\tAccuracy: 93.00%\n",
      "225\tValidation loss: 0.313876\tBest loss: 0.312137\tAccuracy: 93.00%\n",
      "226\tValidation loss: 0.313906\tBest loss: 0.312137\tAccuracy: 93.00%\n",
      "227\tValidation loss: 0.311546\tBest loss: 0.311546\tAccuracy: 93.20%\n",
      "228\tValidation loss: 0.314198\tBest loss: 0.311546\tAccuracy: 92.90%\n",
      "229\tValidation loss: 0.314253\tBest loss: 0.311546\tAccuracy: 93.30%\n",
      "230\tValidation loss: 0.313844\tBest loss: 0.311546\tAccuracy: 93.00%\n",
      "231\tValidation loss: 0.314272\tBest loss: 0.311546\tAccuracy: 93.20%\n",
      "232\tValidation loss: 0.311722\tBest loss: 0.311546\tAccuracy: 93.10%\n",
      "233\tValidation loss: 0.311729\tBest loss: 0.311546\tAccuracy: 93.30%\n",
      "234\tValidation loss: 0.311713\tBest loss: 0.311546\tAccuracy: 92.90%\n",
      "235\tValidation loss: 0.311107\tBest loss: 0.311107\tAccuracy: 93.10%\n",
      "236\tValidation loss: 0.311959\tBest loss: 0.311107\tAccuracy: 92.90%\n",
      "237\tValidation loss: 0.310986\tBest loss: 0.310986\tAccuracy: 93.10%\n",
      "238\tValidation loss: 0.312854\tBest loss: 0.310986\tAccuracy: 93.10%\n",
      "239\tValidation loss: 0.309450\tBest loss: 0.309450\tAccuracy: 93.10%\n",
      "240\tValidation loss: 0.312365\tBest loss: 0.309450\tAccuracy: 93.60%\n",
      "241\tValidation loss: 0.312099\tBest loss: 0.309450\tAccuracy: 93.00%\n",
      "242\tValidation loss: 0.309456\tBest loss: 0.309450\tAccuracy: 93.20%\n",
      "243\tValidation loss: 0.308643\tBest loss: 0.308643\tAccuracy: 93.40%\n",
      "244\tValidation loss: 0.311543\tBest loss: 0.308643\tAccuracy: 93.30%\n",
      "245\tValidation loss: 0.309774\tBest loss: 0.308643\tAccuracy: 93.20%\n",
      "246\tValidation loss: 0.307694\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "247\tValidation loss: 0.308927\tBest loss: 0.307694\tAccuracy: 93.20%\n",
      "248\tValidation loss: 0.309748\tBest loss: 0.307694\tAccuracy: 93.40%\n",
      "249\tValidation loss: 0.307716\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "250\tValidation loss: 0.311055\tBest loss: 0.307694\tAccuracy: 93.50%\n",
      "251\tValidation loss: 0.308539\tBest loss: 0.307694\tAccuracy: 93.50%\n",
      "252\tValidation loss: 0.307926\tBest loss: 0.307694\tAccuracy: 93.20%\n",
      "253\tValidation loss: 0.308994\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "254\tValidation loss: 0.308454\tBest loss: 0.307694\tAccuracy: 93.60%\n",
      "255\tValidation loss: 0.308827\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "256\tValidation loss: 0.307918\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "257\tValidation loss: 0.310683\tBest loss: 0.307694\tAccuracy: 93.70%\n",
      "258\tValidation loss: 0.307804\tBest loss: 0.307694\tAccuracy: 93.30%\n",
      "259\tValidation loss: 0.305164\tBest loss: 0.305164\tAccuracy: 93.20%\n",
      "260\tValidation loss: 0.306392\tBest loss: 0.305164\tAccuracy: 93.60%\n",
      "261\tValidation loss: 0.305105\tBest loss: 0.305105\tAccuracy: 93.10%\n",
      "262\tValidation loss: 0.308486\tBest loss: 0.305105\tAccuracy: 93.70%\n",
      "263\tValidation loss: 0.308455\tBest loss: 0.305105\tAccuracy: 93.70%\n",
      "264\tValidation loss: 0.309401\tBest loss: 0.305105\tAccuracy: 93.50%\n",
      "265\tValidation loss: 0.306304\tBest loss: 0.305105\tAccuracy: 93.40%\n",
      "266\tValidation loss: 0.308252\tBest loss: 0.305105\tAccuracy: 93.50%\n",
      "267\tValidation loss: 0.306207\tBest loss: 0.305105\tAccuracy: 93.70%\n",
      "268\tValidation loss: 0.309573\tBest loss: 0.305105\tAccuracy: 93.60%\n",
      "269\tValidation loss: 0.305574\tBest loss: 0.305105\tAccuracy: 93.50%\n",
      "270\tValidation loss: 0.307043\tBest loss: 0.305105\tAccuracy: 93.70%\n",
      "271\tValidation loss: 0.304642\tBest loss: 0.304642\tAccuracy: 93.60%\n",
      "272\tValidation loss: 0.306479\tBest loss: 0.304642\tAccuracy: 93.50%\n",
      "273\tValidation loss: 0.306081\tBest loss: 0.304642\tAccuracy: 93.70%\n",
      "274\tValidation loss: 0.305307\tBest loss: 0.304642\tAccuracy: 93.50%\n",
      "275\tValidation loss: 0.303395\tBest loss: 0.303395\tAccuracy: 93.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\tValidation loss: 0.305730\tBest loss: 0.303395\tAccuracy: 93.50%\n",
      "277\tValidation loss: 0.304066\tBest loss: 0.303395\tAccuracy: 93.70%\n",
      "278\tValidation loss: 0.305736\tBest loss: 0.303395\tAccuracy: 93.50%\n",
      "279\tValidation loss: 0.305612\tBest loss: 0.303395\tAccuracy: 93.70%\n",
      "280\tValidation loss: 0.306540\tBest loss: 0.303395\tAccuracy: 93.80%\n",
      "281\tValidation loss: 0.306098\tBest loss: 0.303395\tAccuracy: 93.70%\n",
      "282\tValidation loss: 0.304498\tBest loss: 0.303395\tAccuracy: 93.60%\n",
      "283\tValidation loss: 0.305119\tBest loss: 0.303395\tAccuracy: 93.60%\n",
      "284\tValidation loss: 0.307775\tBest loss: 0.303395\tAccuracy: 93.70%\n",
      "285\tValidation loss: 0.304480\tBest loss: 0.303395\tAccuracy: 93.80%\n",
      "286\tValidation loss: 0.305277\tBest loss: 0.303395\tAccuracy: 93.80%\n",
      "287\tValidation loss: 0.305208\tBest loss: 0.303395\tAccuracy: 93.90%\n",
      "288\tValidation loss: 0.303586\tBest loss: 0.303395\tAccuracy: 93.70%\n",
      "289\tValidation loss: 0.302392\tBest loss: 0.302392\tAccuracy: 93.80%\n",
      "290\tValidation loss: 0.304463\tBest loss: 0.302392\tAccuracy: 93.90%\n",
      "291\tValidation loss: 0.303491\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "292\tValidation loss: 0.306180\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "293\tValidation loss: 0.305766\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "294\tValidation loss: 0.305239\tBest loss: 0.302392\tAccuracy: 93.90%\n",
      "295\tValidation loss: 0.303268\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "296\tValidation loss: 0.304248\tBest loss: 0.302392\tAccuracy: 93.90%\n",
      "297\tValidation loss: 0.305302\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "298\tValidation loss: 0.304774\tBest loss: 0.302392\tAccuracy: 93.90%\n",
      "299\tValidation loss: 0.302812\tBest loss: 0.302392\tAccuracy: 93.80%\n",
      "300\tValidation loss: 0.302586\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "301\tValidation loss: 0.304318\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "302\tValidation loss: 0.303057\tBest loss: 0.302392\tAccuracy: 93.70%\n",
      "303\tValidation loss: 0.302236\tBest loss: 0.302236\tAccuracy: 93.80%\n",
      "304\tValidation loss: 0.307226\tBest loss: 0.302236\tAccuracy: 93.80%\n",
      "305\tValidation loss: 0.303785\tBest loss: 0.302236\tAccuracy: 93.80%\n",
      "306\tValidation loss: 0.301610\tBest loss: 0.301610\tAccuracy: 93.90%\n",
      "307\tValidation loss: 0.301865\tBest loss: 0.301610\tAccuracy: 93.80%\n",
      "308\tValidation loss: 0.303030\tBest loss: 0.301610\tAccuracy: 93.90%\n",
      "309\tValidation loss: 0.302997\tBest loss: 0.301610\tAccuracy: 93.90%\n",
      "310\tValidation loss: 0.300510\tBest loss: 0.300510\tAccuracy: 93.90%\n",
      "311\tValidation loss: 0.302809\tBest loss: 0.300510\tAccuracy: 93.70%\n",
      "312\tValidation loss: 0.302324\tBest loss: 0.300510\tAccuracy: 93.90%\n",
      "313\tValidation loss: 0.301106\tBest loss: 0.300510\tAccuracy: 93.60%\n",
      "314\tValidation loss: 0.301947\tBest loss: 0.300510\tAccuracy: 93.70%\n",
      "315\tValidation loss: 0.300756\tBest loss: 0.300510\tAccuracy: 93.80%\n",
      "316\tValidation loss: 0.301052\tBest loss: 0.300510\tAccuracy: 93.80%\n",
      "317\tValidation loss: 0.302078\tBest loss: 0.300510\tAccuracy: 94.00%\n",
      "318\tValidation loss: 0.299908\tBest loss: 0.299908\tAccuracy: 93.70%\n",
      "319\tValidation loss: 0.300132\tBest loss: 0.299908\tAccuracy: 93.90%\n",
      "320\tValidation loss: 0.300903\tBest loss: 0.299908\tAccuracy: 94.00%\n",
      "321\tValidation loss: 0.301116\tBest loss: 0.299908\tAccuracy: 93.90%\n",
      "322\tValidation loss: 0.300220\tBest loss: 0.299908\tAccuracy: 93.70%\n",
      "323\tValidation loss: 0.298875\tBest loss: 0.298875\tAccuracy: 93.70%\n",
      "324\tValidation loss: 0.299462\tBest loss: 0.298875\tAccuracy: 93.70%\n",
      "325\tValidation loss: 0.300019\tBest loss: 0.298875\tAccuracy: 93.90%\n",
      "326\tValidation loss: 0.302351\tBest loss: 0.298875\tAccuracy: 94.10%\n",
      "327\tValidation loss: 0.300779\tBest loss: 0.298875\tAccuracy: 93.90%\n",
      "328\tValidation loss: 0.301447\tBest loss: 0.298875\tAccuracy: 94.00%\n",
      "329\tValidation loss: 0.301550\tBest loss: 0.298875\tAccuracy: 93.80%\n",
      "330\tValidation loss: 0.301531\tBest loss: 0.298875\tAccuracy: 93.90%\n",
      "331\tValidation loss: 0.301385\tBest loss: 0.298875\tAccuracy: 94.00%\n",
      "332\tValidation loss: 0.300372\tBest loss: 0.298875\tAccuracy: 94.00%\n",
      "333\tValidation loss: 0.299941\tBest loss: 0.298875\tAccuracy: 94.00%\n",
      "334\tValidation loss: 0.301028\tBest loss: 0.298875\tAccuracy: 94.00%\n",
      "335\tValidation loss: 0.299428\tBest loss: 0.298875\tAccuracy: 94.20%\n",
      "336\tValidation loss: 0.297800\tBest loss: 0.297800\tAccuracy: 94.00%\n",
      "337\tValidation loss: 0.300052\tBest loss: 0.297800\tAccuracy: 93.80%\n",
      "338\tValidation loss: 0.298745\tBest loss: 0.297800\tAccuracy: 94.20%\n",
      "339\tValidation loss: 0.299499\tBest loss: 0.297800\tAccuracy: 94.10%\n",
      "340\tValidation loss: 0.301627\tBest loss: 0.297800\tAccuracy: 93.90%\n",
      "341\tValidation loss: 0.299479\tBest loss: 0.297800\tAccuracy: 93.90%\n",
      "342\tValidation loss: 0.299517\tBest loss: 0.297800\tAccuracy: 94.00%\n",
      "343\tValidation loss: 0.297072\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "344\tValidation loss: 0.297989\tBest loss: 0.297072\tAccuracy: 94.00%\n",
      "345\tValidation loss: 0.298471\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "346\tValidation loss: 0.300387\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "347\tValidation loss: 0.300645\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "348\tValidation loss: 0.301306\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "349\tValidation loss: 0.299819\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "350\tValidation loss: 0.298088\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "351\tValidation loss: 0.299692\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "352\tValidation loss: 0.298682\tBest loss: 0.297072\tAccuracy: 94.00%\n",
      "353\tValidation loss: 0.297995\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "354\tValidation loss: 0.299291\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "355\tValidation loss: 0.298332\tBest loss: 0.297072\tAccuracy: 94.30%\n",
      "356\tValidation loss: 0.298900\tBest loss: 0.297072\tAccuracy: 94.30%\n",
      "357\tValidation loss: 0.297370\tBest loss: 0.297072\tAccuracy: 94.40%\n",
      "358\tValidation loss: 0.298771\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "359\tValidation loss: 0.298658\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "360\tValidation loss: 0.298842\tBest loss: 0.297072\tAccuracy: 94.20%\n",
      "361\tValidation loss: 0.298299\tBest loss: 0.297072\tAccuracy: 94.00%\n",
      "362\tValidation loss: 0.299425\tBest loss: 0.297072\tAccuracy: 94.30%\n",
      "363\tValidation loss: 0.298305\tBest loss: 0.297072\tAccuracy: 94.30%\n",
      "364\tValidation loss: 0.297417\tBest loss: 0.297072\tAccuracy: 94.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.4min\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.794663\tBest loss: 1.794663\tAccuracy: 59.80%\n",
      "1\tValidation loss: 1.355106\tBest loss: 1.355106\tAccuracy: 70.30%\n",
      "2\tValidation loss: 1.178216\tBest loss: 1.178216\tAccuracy: 75.00%\n",
      "3\tValidation loss: 1.033265\tBest loss: 1.033265\tAccuracy: 77.30%\n",
      "4\tValidation loss: 0.972600\tBest loss: 0.972600\tAccuracy: 78.60%\n",
      "5\tValidation loss: 0.905807\tBest loss: 0.905807\tAccuracy: 80.90%\n",
      "6\tValidation loss: 0.870810\tBest loss: 0.870810\tAccuracy: 80.40%\n",
      "7\tValidation loss: 0.824867\tBest loss: 0.824867\tAccuracy: 81.10%\n",
      "8\tValidation loss: 0.785191\tBest loss: 0.785191\tAccuracy: 83.90%\n",
      "9\tValidation loss: 0.766734\tBest loss: 0.766734\tAccuracy: 82.00%\n",
      "10\tValidation loss: 0.737038\tBest loss: 0.737038\tAccuracy: 84.10%\n",
      "11\tValidation loss: 0.724043\tBest loss: 0.724043\tAccuracy: 83.40%\n",
      "12\tValidation loss: 0.705064\tBest loss: 0.705064\tAccuracy: 84.20%\n",
      "13\tValidation loss: 0.680099\tBest loss: 0.680099\tAccuracy: 85.40%\n",
      "14\tValidation loss: 0.656591\tBest loss: 0.656591\tAccuracy: 86.20%\n",
      "15\tValidation loss: 0.648648\tBest loss: 0.648648\tAccuracy: 86.50%\n",
      "16\tValidation loss: 0.635616\tBest loss: 0.635616\tAccuracy: 86.00%\n",
      "17\tValidation loss: 0.628046\tBest loss: 0.628046\tAccuracy: 86.20%\n",
      "18\tValidation loss: 0.624455\tBest loss: 0.624455\tAccuracy: 86.50%\n",
      "19\tValidation loss: 0.613085\tBest loss: 0.613085\tAccuracy: 87.10%\n",
      "20\tValidation loss: 0.597382\tBest loss: 0.597382\tAccuracy: 87.30%\n",
      "21\tValidation loss: 0.590207\tBest loss: 0.590207\tAccuracy: 88.10%\n",
      "22\tValidation loss: 0.580311\tBest loss: 0.580311\tAccuracy: 87.60%\n",
      "23\tValidation loss: 0.579243\tBest loss: 0.579243\tAccuracy: 87.00%\n",
      "24\tValidation loss: 0.571793\tBest loss: 0.571793\tAccuracy: 87.70%\n",
      "25\tValidation loss: 0.566292\tBest loss: 0.566292\tAccuracy: 87.50%\n",
      "26\tValidation loss: 0.563075\tBest loss: 0.563075\tAccuracy: 87.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\tValidation loss: 0.555242\tBest loss: 0.555242\tAccuracy: 87.70%\n",
      "28\tValidation loss: 0.551589\tBest loss: 0.551589\tAccuracy: 87.90%\n",
      "29\tValidation loss: 0.548895\tBest loss: 0.548895\tAccuracy: 87.50%\n",
      "30\tValidation loss: 0.537486\tBest loss: 0.537486\tAccuracy: 88.50%\n",
      "31\tValidation loss: 0.533443\tBest loss: 0.533443\tAccuracy: 87.30%\n",
      "32\tValidation loss: 0.532133\tBest loss: 0.532133\tAccuracy: 87.90%\n",
      "33\tValidation loss: 0.525202\tBest loss: 0.525202\tAccuracy: 88.30%\n",
      "34\tValidation loss: 0.524873\tBest loss: 0.524873\tAccuracy: 88.40%\n",
      "35\tValidation loss: 0.515694\tBest loss: 0.515694\tAccuracy: 88.40%\n",
      "36\tValidation loss: 0.514523\tBest loss: 0.514523\tAccuracy: 88.30%\n",
      "37\tValidation loss: 0.506033\tBest loss: 0.506033\tAccuracy: 88.70%\n",
      "38\tValidation loss: 0.507688\tBest loss: 0.506033\tAccuracy: 88.60%\n",
      "39\tValidation loss: 0.505267\tBest loss: 0.505267\tAccuracy: 88.10%\n",
      "40\tValidation loss: 0.501269\tBest loss: 0.501269\tAccuracy: 88.70%\n",
      "41\tValidation loss: 0.496609\tBest loss: 0.496609\tAccuracy: 89.00%\n",
      "42\tValidation loss: 0.492940\tBest loss: 0.492940\tAccuracy: 88.50%\n",
      "43\tValidation loss: 0.483949\tBest loss: 0.483949\tAccuracy: 89.60%\n",
      "44\tValidation loss: 0.485968\tBest loss: 0.483949\tAccuracy: 88.50%\n",
      "45\tValidation loss: 0.485620\tBest loss: 0.483949\tAccuracy: 89.30%\n",
      "46\tValidation loss: 0.489344\tBest loss: 0.483949\tAccuracy: 88.90%\n",
      "47\tValidation loss: 0.486667\tBest loss: 0.483949\tAccuracy: 88.60%\n",
      "48\tValidation loss: 0.481304\tBest loss: 0.481304\tAccuracy: 89.20%\n",
      "49\tValidation loss: 0.478607\tBest loss: 0.478607\tAccuracy: 89.40%\n",
      "50\tValidation loss: 0.475360\tBest loss: 0.475360\tAccuracy: 89.30%\n",
      "51\tValidation loss: 0.473415\tBest loss: 0.473415\tAccuracy: 88.80%\n",
      "52\tValidation loss: 0.470451\tBest loss: 0.470451\tAccuracy: 88.90%\n",
      "53\tValidation loss: 0.466902\tBest loss: 0.466902\tAccuracy: 89.40%\n",
      "54\tValidation loss: 0.462978\tBest loss: 0.462978\tAccuracy: 89.60%\n",
      "55\tValidation loss: 0.461109\tBest loss: 0.461109\tAccuracy: 89.30%\n",
      "56\tValidation loss: 0.464218\tBest loss: 0.461109\tAccuracy: 88.90%\n",
      "57\tValidation loss: 0.459957\tBest loss: 0.459957\tAccuracy: 89.60%\n",
      "58\tValidation loss: 0.462071\tBest loss: 0.459957\tAccuracy: 89.70%\n",
      "59\tValidation loss: 0.459440\tBest loss: 0.459440\tAccuracy: 89.40%\n",
      "60\tValidation loss: 0.461584\tBest loss: 0.459440\tAccuracy: 89.40%\n",
      "61\tValidation loss: 0.457902\tBest loss: 0.457902\tAccuracy: 89.60%\n",
      "62\tValidation loss: 0.457063\tBest loss: 0.457063\tAccuracy: 90.00%\n",
      "63\tValidation loss: 0.452510\tBest loss: 0.452510\tAccuracy: 90.00%\n",
      "64\tValidation loss: 0.446845\tBest loss: 0.446845\tAccuracy: 90.10%\n",
      "65\tValidation loss: 0.444001\tBest loss: 0.444001\tAccuracy: 90.50%\n",
      "66\tValidation loss: 0.449733\tBest loss: 0.444001\tAccuracy: 89.60%\n",
      "67\tValidation loss: 0.453121\tBest loss: 0.444001\tAccuracy: 90.10%\n",
      "68\tValidation loss: 0.444375\tBest loss: 0.444001\tAccuracy: 89.70%\n",
      "69\tValidation loss: 0.445742\tBest loss: 0.444001\tAccuracy: 90.20%\n",
      "70\tValidation loss: 0.443725\tBest loss: 0.443725\tAccuracy: 90.40%\n",
      "71\tValidation loss: 0.441097\tBest loss: 0.441097\tAccuracy: 89.90%\n",
      "72\tValidation loss: 0.448846\tBest loss: 0.441097\tAccuracy: 89.30%\n",
      "73\tValidation loss: 0.438811\tBest loss: 0.438811\tAccuracy: 90.30%\n",
      "74\tValidation loss: 0.441359\tBest loss: 0.438811\tAccuracy: 90.20%\n",
      "75\tValidation loss: 0.439060\tBest loss: 0.438811\tAccuracy: 89.90%\n",
      "76\tValidation loss: 0.431457\tBest loss: 0.431457\tAccuracy: 90.60%\n",
      "77\tValidation loss: 0.436645\tBest loss: 0.431457\tAccuracy: 89.50%\n",
      "78\tValidation loss: 0.429055\tBest loss: 0.429055\tAccuracy: 91.10%\n",
      "79\tValidation loss: 0.433516\tBest loss: 0.429055\tAccuracy: 90.50%\n",
      "80\tValidation loss: 0.432519\tBest loss: 0.429055\tAccuracy: 90.60%\n",
      "81\tValidation loss: 0.431734\tBest loss: 0.429055\tAccuracy: 90.30%\n",
      "82\tValidation loss: 0.425155\tBest loss: 0.425155\tAccuracy: 91.30%\n",
      "83\tValidation loss: 0.434109\tBest loss: 0.425155\tAccuracy: 90.30%\n",
      "84\tValidation loss: 0.428142\tBest loss: 0.425155\tAccuracy: 90.70%\n",
      "85\tValidation loss: 0.424460\tBest loss: 0.424460\tAccuracy: 90.50%\n",
      "86\tValidation loss: 0.423658\tBest loss: 0.423658\tAccuracy: 91.00%\n",
      "87\tValidation loss: 0.425151\tBest loss: 0.423658\tAccuracy: 90.50%\n",
      "88\tValidation loss: 0.422256\tBest loss: 0.422256\tAccuracy: 90.90%\n",
      "89\tValidation loss: 0.428089\tBest loss: 0.422256\tAccuracy: 90.60%\n",
      "90\tValidation loss: 0.421969\tBest loss: 0.421969\tAccuracy: 90.40%\n",
      "91\tValidation loss: 0.419024\tBest loss: 0.419024\tAccuracy: 90.90%\n",
      "92\tValidation loss: 0.424113\tBest loss: 0.419024\tAccuracy: 90.60%\n",
      "93\tValidation loss: 0.417679\tBest loss: 0.417679\tAccuracy: 90.90%\n",
      "94\tValidation loss: 0.419094\tBest loss: 0.417679\tAccuracy: 91.30%\n",
      "95\tValidation loss: 0.415401\tBest loss: 0.415401\tAccuracy: 91.10%\n",
      "96\tValidation loss: 0.415127\tBest loss: 0.415127\tAccuracy: 91.00%\n",
      "97\tValidation loss: 0.415249\tBest loss: 0.415127\tAccuracy: 90.90%\n",
      "98\tValidation loss: 0.415930\tBest loss: 0.415127\tAccuracy: 90.70%\n",
      "99\tValidation loss: 0.419252\tBest loss: 0.415127\tAccuracy: 90.90%\n",
      "100\tValidation loss: 0.415278\tBest loss: 0.415127\tAccuracy: 90.70%\n",
      "101\tValidation loss: 0.414372\tBest loss: 0.414372\tAccuracy: 91.30%\n",
      "102\tValidation loss: 0.413612\tBest loss: 0.413612\tAccuracy: 91.00%\n",
      "103\tValidation loss: 0.410948\tBest loss: 0.410948\tAccuracy: 91.10%\n",
      "104\tValidation loss: 0.410789\tBest loss: 0.410789\tAccuracy: 91.40%\n",
      "105\tValidation loss: 0.411793\tBest loss: 0.410789\tAccuracy: 91.00%\n",
      "106\tValidation loss: 0.407596\tBest loss: 0.407596\tAccuracy: 91.00%\n",
      "107\tValidation loss: 0.411608\tBest loss: 0.407596\tAccuracy: 91.00%\n",
      "108\tValidation loss: 0.414657\tBest loss: 0.407596\tAccuracy: 91.30%\n",
      "109\tValidation loss: 0.410675\tBest loss: 0.407596\tAccuracy: 91.30%\n",
      "110\tValidation loss: 0.411319\tBest loss: 0.407596\tAccuracy: 91.10%\n",
      "111\tValidation loss: 0.408341\tBest loss: 0.407596\tAccuracy: 91.60%\n",
      "112\tValidation loss: 0.409363\tBest loss: 0.407596\tAccuracy: 90.80%\n",
      "113\tValidation loss: 0.406677\tBest loss: 0.406677\tAccuracy: 91.80%\n",
      "114\tValidation loss: 0.406917\tBest loss: 0.406677\tAccuracy: 91.70%\n",
      "115\tValidation loss: 0.407975\tBest loss: 0.406677\tAccuracy: 91.50%\n",
      "116\tValidation loss: 0.406812\tBest loss: 0.406677\tAccuracy: 91.50%\n",
      "117\tValidation loss: 0.404141\tBest loss: 0.404141\tAccuracy: 91.70%\n",
      "118\tValidation loss: 0.403416\tBest loss: 0.403416\tAccuracy: 91.10%\n",
      "119\tValidation loss: 0.403847\tBest loss: 0.403416\tAccuracy: 91.70%\n",
      "120\tValidation loss: 0.404678\tBest loss: 0.403416\tAccuracy: 91.40%\n",
      "121\tValidation loss: 0.403377\tBest loss: 0.403377\tAccuracy: 91.70%\n",
      "122\tValidation loss: 0.399922\tBest loss: 0.399922\tAccuracy: 91.80%\n",
      "123\tValidation loss: 0.399583\tBest loss: 0.399583\tAccuracy: 91.80%\n",
      "124\tValidation loss: 0.400915\tBest loss: 0.399583\tAccuracy: 91.50%\n",
      "125\tValidation loss: 0.399018\tBest loss: 0.399018\tAccuracy: 91.60%\n",
      "126\tValidation loss: 0.401026\tBest loss: 0.399018\tAccuracy: 91.60%\n",
      "127\tValidation loss: 0.400507\tBest loss: 0.399018\tAccuracy: 92.20%\n",
      "128\tValidation loss: 0.399967\tBest loss: 0.399018\tAccuracy: 91.60%\n",
      "129\tValidation loss: 0.398742\tBest loss: 0.398742\tAccuracy: 91.80%\n",
      "130\tValidation loss: 0.394362\tBest loss: 0.394362\tAccuracy: 92.30%\n",
      "131\tValidation loss: 0.395417\tBest loss: 0.394362\tAccuracy: 92.00%\n",
      "132\tValidation loss: 0.395391\tBest loss: 0.394362\tAccuracy: 92.10%\n",
      "133\tValidation loss: 0.396644\tBest loss: 0.394362\tAccuracy: 92.00%\n",
      "134\tValidation loss: 0.397001\tBest loss: 0.394362\tAccuracy: 91.90%\n",
      "135\tValidation loss: 0.397786\tBest loss: 0.394362\tAccuracy: 92.10%\n",
      "136\tValidation loss: 0.397002\tBest loss: 0.394362\tAccuracy: 91.60%\n",
      "137\tValidation loss: 0.395837\tBest loss: 0.394362\tAccuracy: 91.70%\n",
      "138\tValidation loss: 0.391656\tBest loss: 0.391656\tAccuracy: 91.90%\n",
      "139\tValidation loss: 0.394834\tBest loss: 0.391656\tAccuracy: 91.60%\n",
      "140\tValidation loss: 0.395273\tBest loss: 0.391656\tAccuracy: 91.80%\n",
      "141\tValidation loss: 0.394947\tBest loss: 0.391656\tAccuracy: 92.00%\n",
      "142\tValidation loss: 0.392627\tBest loss: 0.391656\tAccuracy: 92.00%\n",
      "143\tValidation loss: 0.395662\tBest loss: 0.391656\tAccuracy: 91.90%\n",
      "144\tValidation loss: 0.392043\tBest loss: 0.391656\tAccuracy: 92.10%\n",
      "145\tValidation loss: 0.393050\tBest loss: 0.391656\tAccuracy: 91.90%\n",
      "146\tValidation loss: 0.390686\tBest loss: 0.390686\tAccuracy: 91.70%\n",
      "147\tValidation loss: 0.389553\tBest loss: 0.389553\tAccuracy: 92.00%\n",
      "148\tValidation loss: 0.392555\tBest loss: 0.389553\tAccuracy: 92.10%\n",
      "149\tValidation loss: 0.392172\tBest loss: 0.389553\tAccuracy: 92.40%\n",
      "150\tValidation loss: 0.391425\tBest loss: 0.389553\tAccuracy: 92.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\tValidation loss: 0.390295\tBest loss: 0.389553\tAccuracy: 92.00%\n",
      "152\tValidation loss: 0.389742\tBest loss: 0.389553\tAccuracy: 92.20%\n",
      "153\tValidation loss: 0.391461\tBest loss: 0.389553\tAccuracy: 92.00%\n",
      "154\tValidation loss: 0.391294\tBest loss: 0.389553\tAccuracy: 92.10%\n",
      "155\tValidation loss: 0.392269\tBest loss: 0.389553\tAccuracy: 92.00%\n",
      "156\tValidation loss: 0.388458\tBest loss: 0.388458\tAccuracy: 92.00%\n",
      "157\tValidation loss: 0.385722\tBest loss: 0.385722\tAccuracy: 92.20%\n",
      "158\tValidation loss: 0.387586\tBest loss: 0.385722\tAccuracy: 92.20%\n",
      "159\tValidation loss: 0.388566\tBest loss: 0.385722\tAccuracy: 92.10%\n",
      "160\tValidation loss: 0.386122\tBest loss: 0.385722\tAccuracy: 92.10%\n",
      "161\tValidation loss: 0.389445\tBest loss: 0.385722\tAccuracy: 92.20%\n",
      "162\tValidation loss: 0.388237\tBest loss: 0.385722\tAccuracy: 91.90%\n",
      "163\tValidation loss: 0.390576\tBest loss: 0.385722\tAccuracy: 92.20%\n",
      "164\tValidation loss: 0.386420\tBest loss: 0.385722\tAccuracy: 92.20%\n",
      "165\tValidation loss: 0.388126\tBest loss: 0.385722\tAccuracy: 92.00%\n",
      "166\tValidation loss: 0.382805\tBest loss: 0.382805\tAccuracy: 92.40%\n",
      "167\tValidation loss: 0.383698\tBest loss: 0.382805\tAccuracy: 92.20%\n",
      "168\tValidation loss: 0.383010\tBest loss: 0.382805\tAccuracy: 92.00%\n",
      "169\tValidation loss: 0.386563\tBest loss: 0.382805\tAccuracy: 92.10%\n",
      "170\tValidation loss: 0.382304\tBest loss: 0.382304\tAccuracy: 92.20%\n",
      "171\tValidation loss: 0.384664\tBest loss: 0.382304\tAccuracy: 92.10%\n",
      "172\tValidation loss: 0.384689\tBest loss: 0.382304\tAccuracy: 92.10%\n",
      "173\tValidation loss: 0.385641\tBest loss: 0.382304\tAccuracy: 92.20%\n",
      "174\tValidation loss: 0.383025\tBest loss: 0.382304\tAccuracy: 92.30%\n",
      "175\tValidation loss: 0.383729\tBest loss: 0.382304\tAccuracy: 92.10%\n",
      "176\tValidation loss: 0.384650\tBest loss: 0.382304\tAccuracy: 91.70%\n",
      "177\tValidation loss: 0.385437\tBest loss: 0.382304\tAccuracy: 92.00%\n",
      "178\tValidation loss: 0.385138\tBest loss: 0.382304\tAccuracy: 92.10%\n",
      "179\tValidation loss: 0.385168\tBest loss: 0.382304\tAccuracy: 92.10%\n",
      "180\tValidation loss: 0.382226\tBest loss: 0.382226\tAccuracy: 92.10%\n",
      "181\tValidation loss: 0.380179\tBest loss: 0.380179\tAccuracy: 92.40%\n",
      "182\tValidation loss: 0.378147\tBest loss: 0.378147\tAccuracy: 92.10%\n",
      "183\tValidation loss: 0.381609\tBest loss: 0.378147\tAccuracy: 92.20%\n",
      "184\tValidation loss: 0.381553\tBest loss: 0.378147\tAccuracy: 91.90%\n",
      "185\tValidation loss: 0.379394\tBest loss: 0.378147\tAccuracy: 92.20%\n",
      "186\tValidation loss: 0.382320\tBest loss: 0.378147\tAccuracy: 92.10%\n",
      "187\tValidation loss: 0.380091\tBest loss: 0.378147\tAccuracy: 92.40%\n",
      "188\tValidation loss: 0.378604\tBest loss: 0.378147\tAccuracy: 92.10%\n",
      "189\tValidation loss: 0.381099\tBest loss: 0.378147\tAccuracy: 92.20%\n",
      "190\tValidation loss: 0.378706\tBest loss: 0.378147\tAccuracy: 92.10%\n",
      "191\tValidation loss: 0.380228\tBest loss: 0.378147\tAccuracy: 92.00%\n",
      "192\tValidation loss: 0.380879\tBest loss: 0.378147\tAccuracy: 92.20%\n",
      "193\tValidation loss: 0.376048\tBest loss: 0.376048\tAccuracy: 92.00%\n",
      "194\tValidation loss: 0.378699\tBest loss: 0.376048\tAccuracy: 92.30%\n",
      "195\tValidation loss: 0.378304\tBest loss: 0.376048\tAccuracy: 91.80%\n",
      "196\tValidation loss: 0.376156\tBest loss: 0.376048\tAccuracy: 92.20%\n",
      "197\tValidation loss: 0.382691\tBest loss: 0.376048\tAccuracy: 91.90%\n",
      "198\tValidation loss: 0.377343\tBest loss: 0.376048\tAccuracy: 92.10%\n",
      "199\tValidation loss: 0.379770\tBest loss: 0.376048\tAccuracy: 92.20%\n",
      "200\tValidation loss: 0.376121\tBest loss: 0.376048\tAccuracy: 92.20%\n",
      "201\tValidation loss: 0.379979\tBest loss: 0.376048\tAccuracy: 92.20%\n",
      "202\tValidation loss: 0.374954\tBest loss: 0.374954\tAccuracy: 92.40%\n",
      "203\tValidation loss: 0.378211\tBest loss: 0.374954\tAccuracy: 92.00%\n",
      "204\tValidation loss: 0.376182\tBest loss: 0.374954\tAccuracy: 92.00%\n",
      "205\tValidation loss: 0.375629\tBest loss: 0.374954\tAccuracy: 92.10%\n",
      "206\tValidation loss: 0.380757\tBest loss: 0.374954\tAccuracy: 91.80%\n",
      "207\tValidation loss: 0.374181\tBest loss: 0.374181\tAccuracy: 92.30%\n",
      "208\tValidation loss: 0.375353\tBest loss: 0.374181\tAccuracy: 92.30%\n",
      "209\tValidation loss: 0.375975\tBest loss: 0.374181\tAccuracy: 92.10%\n",
      "210\tValidation loss: 0.376468\tBest loss: 0.374181\tAccuracy: 92.30%\n",
      "211\tValidation loss: 0.375796\tBest loss: 0.374181\tAccuracy: 92.30%\n",
      "212\tValidation loss: 0.375023\tBest loss: 0.374181\tAccuracy: 92.20%\n",
      "213\tValidation loss: 0.376061\tBest loss: 0.374181\tAccuracy: 92.20%\n",
      "214\tValidation loss: 0.374460\tBest loss: 0.374181\tAccuracy: 92.30%\n",
      "215\tValidation loss: 0.378034\tBest loss: 0.374181\tAccuracy: 92.10%\n",
      "216\tValidation loss: 0.375450\tBest loss: 0.374181\tAccuracy: 92.10%\n",
      "217\tValidation loss: 0.374478\tBest loss: 0.374181\tAccuracy: 92.10%\n",
      "218\tValidation loss: 0.376220\tBest loss: 0.374181\tAccuracy: 92.10%\n",
      "219\tValidation loss: 0.375547\tBest loss: 0.374181\tAccuracy: 91.90%\n",
      "220\tValidation loss: 0.372088\tBest loss: 0.372088\tAccuracy: 92.10%\n",
      "221\tValidation loss: 0.374706\tBest loss: 0.372088\tAccuracy: 92.40%\n",
      "222\tValidation loss: 0.376850\tBest loss: 0.372088\tAccuracy: 92.30%\n",
      "223\tValidation loss: 0.374275\tBest loss: 0.372088\tAccuracy: 92.20%\n",
      "224\tValidation loss: 0.372480\tBest loss: 0.372088\tAccuracy: 92.30%\n",
      "225\tValidation loss: 0.377541\tBest loss: 0.372088\tAccuracy: 92.10%\n",
      "226\tValidation loss: 0.373097\tBest loss: 0.372088\tAccuracy: 92.50%\n",
      "227\tValidation loss: 0.372926\tBest loss: 0.372088\tAccuracy: 92.30%\n",
      "228\tValidation loss: 0.373198\tBest loss: 0.372088\tAccuracy: 92.50%\n",
      "229\tValidation loss: 0.374281\tBest loss: 0.372088\tAccuracy: 92.20%\n",
      "230\tValidation loss: 0.371148\tBest loss: 0.371148\tAccuracy: 92.20%\n",
      "231\tValidation loss: 0.372999\tBest loss: 0.371148\tAccuracy: 92.00%\n",
      "232\tValidation loss: 0.373968\tBest loss: 0.371148\tAccuracy: 92.10%\n",
      "233\tValidation loss: 0.374471\tBest loss: 0.371148\tAccuracy: 92.10%\n",
      "234\tValidation loss: 0.370568\tBest loss: 0.370568\tAccuracy: 92.60%\n",
      "235\tValidation loss: 0.374800\tBest loss: 0.370568\tAccuracy: 92.20%\n",
      "236\tValidation loss: 0.370934\tBest loss: 0.370568\tAccuracy: 92.60%\n",
      "237\tValidation loss: 0.372188\tBest loss: 0.370568\tAccuracy: 92.40%\n",
      "238\tValidation loss: 0.373398\tBest loss: 0.370568\tAccuracy: 92.40%\n",
      "239\tValidation loss: 0.375325\tBest loss: 0.370568\tAccuracy: 92.50%\n",
      "240\tValidation loss: 0.374393\tBest loss: 0.370568\tAccuracy: 92.20%\n",
      "241\tValidation loss: 0.373795\tBest loss: 0.370568\tAccuracy: 92.30%\n",
      "242\tValidation loss: 0.375885\tBest loss: 0.370568\tAccuracy: 92.20%\n",
      "243\tValidation loss: 0.370845\tBest loss: 0.370568\tAccuracy: 92.50%\n",
      "244\tValidation loss: 0.373061\tBest loss: 0.370568\tAccuracy: 92.60%\n",
      "245\tValidation loss: 0.370129\tBest loss: 0.370129\tAccuracy: 92.60%\n",
      "246\tValidation loss: 0.372806\tBest loss: 0.370129\tAccuracy: 92.20%\n",
      "247\tValidation loss: 0.372257\tBest loss: 0.370129\tAccuracy: 92.20%\n",
      "248\tValidation loss: 0.372870\tBest loss: 0.370129\tAccuracy: 92.50%\n",
      "249\tValidation loss: 0.372210\tBest loss: 0.370129\tAccuracy: 92.40%\n",
      "250\tValidation loss: 0.371953\tBest loss: 0.370129\tAccuracy: 92.50%\n",
      "251\tValidation loss: 0.370780\tBest loss: 0.370129\tAccuracy: 92.70%\n",
      "252\tValidation loss: 0.373195\tBest loss: 0.370129\tAccuracy: 92.30%\n",
      "253\tValidation loss: 0.369756\tBest loss: 0.369756\tAccuracy: 92.40%\n",
      "254\tValidation loss: 0.372559\tBest loss: 0.369756\tAccuracy: 92.40%\n",
      "255\tValidation loss: 0.373789\tBest loss: 0.369756\tAccuracy: 92.20%\n",
      "256\tValidation loss: 0.370540\tBest loss: 0.369756\tAccuracy: 92.60%\n",
      "257\tValidation loss: 0.373421\tBest loss: 0.369756\tAccuracy: 92.30%\n",
      "258\tValidation loss: 0.369761\tBest loss: 0.369756\tAccuracy: 92.70%\n",
      "259\tValidation loss: 0.367559\tBest loss: 0.367559\tAccuracy: 92.80%\n",
      "260\tValidation loss: 0.369527\tBest loss: 0.367559\tAccuracy: 92.60%\n",
      "261\tValidation loss: 0.368993\tBest loss: 0.367559\tAccuracy: 92.70%\n",
      "262\tValidation loss: 0.370327\tBest loss: 0.367559\tAccuracy: 92.70%\n",
      "263\tValidation loss: 0.369074\tBest loss: 0.367559\tAccuracy: 92.60%\n",
      "264\tValidation loss: 0.371883\tBest loss: 0.367559\tAccuracy: 92.20%\n",
      "265\tValidation loss: 0.367727\tBest loss: 0.367559\tAccuracy: 92.60%\n",
      "266\tValidation loss: 0.369985\tBest loss: 0.367559\tAccuracy: 92.70%\n",
      "267\tValidation loss: 0.372126\tBest loss: 0.367559\tAccuracy: 92.60%\n",
      "268\tValidation loss: 0.370055\tBest loss: 0.367559\tAccuracy: 92.70%\n",
      "269\tValidation loss: 0.369858\tBest loss: 0.367559\tAccuracy: 92.60%\n",
      "270\tValidation loss: 0.366608\tBest loss: 0.366608\tAccuracy: 92.80%\n",
      "271\tValidation loss: 0.367645\tBest loss: 0.366608\tAccuracy: 92.80%\n",
      "272\tValidation loss: 0.367517\tBest loss: 0.366608\tAccuracy: 92.60%\n",
      "273\tValidation loss: 0.367967\tBest loss: 0.366608\tAccuracy: 92.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\tValidation loss: 0.369383\tBest loss: 0.366608\tAccuracy: 92.60%\n",
      "275\tValidation loss: 0.367113\tBest loss: 0.366608\tAccuracy: 92.90%\n",
      "276\tValidation loss: 0.369575\tBest loss: 0.366608\tAccuracy: 92.90%\n",
      "277\tValidation loss: 0.371009\tBest loss: 0.366608\tAccuracy: 92.40%\n",
      "278\tValidation loss: 0.367093\tBest loss: 0.366608\tAccuracy: 92.80%\n",
      "279\tValidation loss: 0.368212\tBest loss: 0.366608\tAccuracy: 92.70%\n",
      "280\tValidation loss: 0.365411\tBest loss: 0.365411\tAccuracy: 92.70%\n",
      "281\tValidation loss: 0.367199\tBest loss: 0.365411\tAccuracy: 92.60%\n",
      "282\tValidation loss: 0.368625\tBest loss: 0.365411\tAccuracy: 92.60%\n",
      "283\tValidation loss: 0.369374\tBest loss: 0.365411\tAccuracy: 92.60%\n",
      "284\tValidation loss: 0.366985\tBest loss: 0.365411\tAccuracy: 92.80%\n",
      "285\tValidation loss: 0.366802\tBest loss: 0.365411\tAccuracy: 92.70%\n",
      "286\tValidation loss: 0.367357\tBest loss: 0.365411\tAccuracy: 92.80%\n",
      "287\tValidation loss: 0.369245\tBest loss: 0.365411\tAccuracy: 92.50%\n",
      "288\tValidation loss: 0.366162\tBest loss: 0.365411\tAccuracy: 92.80%\n",
      "289\tValidation loss: 0.365922\tBest loss: 0.365411\tAccuracy: 92.70%\n",
      "290\tValidation loss: 0.366950\tBest loss: 0.365411\tAccuracy: 92.70%\n",
      "291\tValidation loss: 0.367465\tBest loss: 0.365411\tAccuracy: 92.70%\n",
      "292\tValidation loss: 0.369943\tBest loss: 0.365411\tAccuracy: 92.50%\n",
      "293\tValidation loss: 0.366387\tBest loss: 0.365411\tAccuracy: 92.80%\n",
      "294\tValidation loss: 0.364041\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "295\tValidation loss: 0.369079\tBest loss: 0.364041\tAccuracy: 92.60%\n",
      "296\tValidation loss: 0.367451\tBest loss: 0.364041\tAccuracy: 92.70%\n",
      "297\tValidation loss: 0.364879\tBest loss: 0.364041\tAccuracy: 93.00%\n",
      "298\tValidation loss: 0.368280\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "299\tValidation loss: 0.367200\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "300\tValidation loss: 0.369560\tBest loss: 0.364041\tAccuracy: 92.70%\n",
      "301\tValidation loss: 0.368058\tBest loss: 0.364041\tAccuracy: 92.70%\n",
      "302\tValidation loss: 0.365232\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "303\tValidation loss: 0.366837\tBest loss: 0.364041\tAccuracy: 92.70%\n",
      "304\tValidation loss: 0.365546\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "305\tValidation loss: 0.364720\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "306\tValidation loss: 0.365643\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "307\tValidation loss: 0.368467\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "308\tValidation loss: 0.366238\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "309\tValidation loss: 0.368868\tBest loss: 0.364041\tAccuracy: 93.10%\n",
      "310\tValidation loss: 0.365622\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "311\tValidation loss: 0.366912\tBest loss: 0.364041\tAccuracy: 93.00%\n",
      "312\tValidation loss: 0.367770\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "313\tValidation loss: 0.368764\tBest loss: 0.364041\tAccuracy: 92.90%\n",
      "314\tValidation loss: 0.367033\tBest loss: 0.364041\tAccuracy: 92.80%\n",
      "315\tValidation loss: 0.366122\tBest loss: 0.364041\tAccuracy: 93.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.2min\n",
      "[CV] batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 1.807347\tBest loss: 1.807347\tAccuracy: 58.10%\n",
      "1\tValidation loss: 1.369080\tBest loss: 1.369080\tAccuracy: 69.30%\n",
      "2\tValidation loss: 1.173487\tBest loss: 1.173487\tAccuracy: 73.50%\n",
      "3\tValidation loss: 1.059532\tBest loss: 1.059532\tAccuracy: 75.90%\n",
      "4\tValidation loss: 0.968783\tBest loss: 0.968783\tAccuracy: 78.20%\n",
      "5\tValidation loss: 0.906677\tBest loss: 0.906677\tAccuracy: 79.40%\n",
      "6\tValidation loss: 0.848501\tBest loss: 0.848501\tAccuracy: 80.70%\n",
      "7\tValidation loss: 0.812335\tBest loss: 0.812335\tAccuracy: 80.80%\n",
      "8\tValidation loss: 0.786477\tBest loss: 0.786477\tAccuracy: 82.10%\n",
      "9\tValidation loss: 0.767547\tBest loss: 0.767547\tAccuracy: 81.60%\n",
      "10\tValidation loss: 0.727160\tBest loss: 0.727160\tAccuracy: 83.30%\n",
      "11\tValidation loss: 0.711496\tBest loss: 0.711496\tAccuracy: 83.40%\n",
      "12\tValidation loss: 0.690889\tBest loss: 0.690889\tAccuracy: 84.20%\n",
      "13\tValidation loss: 0.669066\tBest loss: 0.669066\tAccuracy: 84.20%\n",
      "14\tValidation loss: 0.655196\tBest loss: 0.655196\tAccuracy: 85.20%\n",
      "15\tValidation loss: 0.643594\tBest loss: 0.643594\tAccuracy: 85.70%\n",
      "16\tValidation loss: 0.639053\tBest loss: 0.639053\tAccuracy: 85.30%\n",
      "17\tValidation loss: 0.615855\tBest loss: 0.615855\tAccuracy: 86.10%\n",
      "18\tValidation loss: 0.613487\tBest loss: 0.613487\tAccuracy: 86.50%\n",
      "19\tValidation loss: 0.596027\tBest loss: 0.596027\tAccuracy: 86.70%\n",
      "20\tValidation loss: 0.596072\tBest loss: 0.596027\tAccuracy: 85.60%\n",
      "21\tValidation loss: 0.585605\tBest loss: 0.585605\tAccuracy: 86.70%\n",
      "22\tValidation loss: 0.570163\tBest loss: 0.570163\tAccuracy: 87.20%\n",
      "23\tValidation loss: 0.568544\tBest loss: 0.568544\tAccuracy: 86.70%\n",
      "24\tValidation loss: 0.565970\tBest loss: 0.565970\tAccuracy: 87.40%\n",
      "25\tValidation loss: 0.554511\tBest loss: 0.554511\tAccuracy: 87.00%\n",
      "26\tValidation loss: 0.545591\tBest loss: 0.545591\tAccuracy: 88.00%\n",
      "27\tValidation loss: 0.539300\tBest loss: 0.539300\tAccuracy: 88.10%\n",
      "28\tValidation loss: 0.539283\tBest loss: 0.539283\tAccuracy: 87.40%\n",
      "29\tValidation loss: 0.532535\tBest loss: 0.532535\tAccuracy: 87.40%\n",
      "30\tValidation loss: 0.526696\tBest loss: 0.526696\tAccuracy: 87.60%\n",
      "31\tValidation loss: 0.524531\tBest loss: 0.524531\tAccuracy: 88.10%\n",
      "32\tValidation loss: 0.518725\tBest loss: 0.518725\tAccuracy: 88.10%\n",
      "33\tValidation loss: 0.516323\tBest loss: 0.516323\tAccuracy: 87.60%\n",
      "34\tValidation loss: 0.508486\tBest loss: 0.508486\tAccuracy: 88.50%\n",
      "35\tValidation loss: 0.506127\tBest loss: 0.506127\tAccuracy: 88.20%\n",
      "36\tValidation loss: 0.505595\tBest loss: 0.505595\tAccuracy: 88.20%\n",
      "37\tValidation loss: 0.492767\tBest loss: 0.492767\tAccuracy: 88.60%\n",
      "38\tValidation loss: 0.490147\tBest loss: 0.490147\tAccuracy: 89.10%\n",
      "39\tValidation loss: 0.487107\tBest loss: 0.487107\tAccuracy: 88.60%\n",
      "40\tValidation loss: 0.488291\tBest loss: 0.487107\tAccuracy: 88.40%\n",
      "41\tValidation loss: 0.476517\tBest loss: 0.476517\tAccuracy: 89.10%\n",
      "42\tValidation loss: 0.478596\tBest loss: 0.476517\tAccuracy: 88.60%\n",
      "43\tValidation loss: 0.472222\tBest loss: 0.472222\tAccuracy: 88.70%\n",
      "44\tValidation loss: 0.470911\tBest loss: 0.470911\tAccuracy: 88.70%\n",
      "45\tValidation loss: 0.475460\tBest loss: 0.470911\tAccuracy: 88.80%\n",
      "46\tValidation loss: 0.469058\tBest loss: 0.469058\tAccuracy: 89.60%\n",
      "47\tValidation loss: 0.466608\tBest loss: 0.466608\tAccuracy: 88.60%\n",
      "48\tValidation loss: 0.461984\tBest loss: 0.461984\tAccuracy: 89.00%\n",
      "49\tValidation loss: 0.457869\tBest loss: 0.457869\tAccuracy: 89.10%\n",
      "50\tValidation loss: 0.458953\tBest loss: 0.457869\tAccuracy: 88.70%\n",
      "51\tValidation loss: 0.453201\tBest loss: 0.453201\tAccuracy: 89.70%\n",
      "52\tValidation loss: 0.454454\tBest loss: 0.453201\tAccuracy: 88.90%\n",
      "53\tValidation loss: 0.449377\tBest loss: 0.449377\tAccuracy: 89.20%\n",
      "54\tValidation loss: 0.444652\tBest loss: 0.444652\tAccuracy: 89.50%\n",
      "55\tValidation loss: 0.447343\tBest loss: 0.444652\tAccuracy: 89.00%\n",
      "56\tValidation loss: 0.445240\tBest loss: 0.444652\tAccuracy: 89.60%\n",
      "57\tValidation loss: 0.440439\tBest loss: 0.440439\tAccuracy: 89.30%\n",
      "58\tValidation loss: 0.440364\tBest loss: 0.440364\tAccuracy: 89.40%\n",
      "59\tValidation loss: 0.438435\tBest loss: 0.438435\tAccuracy: 89.50%\n",
      "60\tValidation loss: 0.436555\tBest loss: 0.436555\tAccuracy: 89.20%\n",
      "61\tValidation loss: 0.440259\tBest loss: 0.436555\tAccuracy: 89.10%\n",
      "62\tValidation loss: 0.435041\tBest loss: 0.435041\tAccuracy: 89.60%\n",
      "63\tValidation loss: 0.429662\tBest loss: 0.429662\tAccuracy: 90.30%\n",
      "64\tValidation loss: 0.427463\tBest loss: 0.427463\tAccuracy: 89.90%\n",
      "65\tValidation loss: 0.426055\tBest loss: 0.426055\tAccuracy: 89.70%\n",
      "66\tValidation loss: 0.425394\tBest loss: 0.425394\tAccuracy: 89.90%\n",
      "67\tValidation loss: 0.425164\tBest loss: 0.425164\tAccuracy: 89.60%\n",
      "68\tValidation loss: 0.418709\tBest loss: 0.418709\tAccuracy: 90.10%\n",
      "69\tValidation loss: 0.420797\tBest loss: 0.418709\tAccuracy: 90.30%\n",
      "70\tValidation loss: 0.418548\tBest loss: 0.418548\tAccuracy: 90.00%\n",
      "71\tValidation loss: 0.418228\tBest loss: 0.418228\tAccuracy: 90.30%\n",
      "72\tValidation loss: 0.416228\tBest loss: 0.416228\tAccuracy: 89.90%\n",
      "73\tValidation loss: 0.415068\tBest loss: 0.415068\tAccuracy: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\tValidation loss: 0.414901\tBest loss: 0.414901\tAccuracy: 90.10%\n",
      "75\tValidation loss: 0.413762\tBest loss: 0.413762\tAccuracy: 90.10%\n",
      "76\tValidation loss: 0.413467\tBest loss: 0.413467\tAccuracy: 89.90%\n",
      "77\tValidation loss: 0.410552\tBest loss: 0.410552\tAccuracy: 90.20%\n",
      "78\tValidation loss: 0.405958\tBest loss: 0.405958\tAccuracy: 90.40%\n",
      "79\tValidation loss: 0.411013\tBest loss: 0.405958\tAccuracy: 90.20%\n",
      "80\tValidation loss: 0.405356\tBest loss: 0.405356\tAccuracy: 90.40%\n",
      "81\tValidation loss: 0.405428\tBest loss: 0.405356\tAccuracy: 90.90%\n",
      "82\tValidation loss: 0.404093\tBest loss: 0.404093\tAccuracy: 90.60%\n",
      "83\tValidation loss: 0.400363\tBest loss: 0.400363\tAccuracy: 90.70%\n",
      "84\tValidation loss: 0.400173\tBest loss: 0.400173\tAccuracy: 90.30%\n",
      "85\tValidation loss: 0.397818\tBest loss: 0.397818\tAccuracy: 90.50%\n",
      "86\tValidation loss: 0.396859\tBest loss: 0.396859\tAccuracy: 90.90%\n",
      "87\tValidation loss: 0.398383\tBest loss: 0.396859\tAccuracy: 91.10%\n",
      "88\tValidation loss: 0.392279\tBest loss: 0.392279\tAccuracy: 90.80%\n",
      "89\tValidation loss: 0.394356\tBest loss: 0.392279\tAccuracy: 90.90%\n",
      "90\tValidation loss: 0.391205\tBest loss: 0.391205\tAccuracy: 90.90%\n",
      "91\tValidation loss: 0.388506\tBest loss: 0.388506\tAccuracy: 91.20%\n",
      "92\tValidation loss: 0.395064\tBest loss: 0.388506\tAccuracy: 90.90%\n",
      "93\tValidation loss: 0.387889\tBest loss: 0.387889\tAccuracy: 91.40%\n",
      "94\tValidation loss: 0.391189\tBest loss: 0.387889\tAccuracy: 91.00%\n",
      "95\tValidation loss: 0.384929\tBest loss: 0.384929\tAccuracy: 90.90%\n",
      "96\tValidation loss: 0.384159\tBest loss: 0.384159\tAccuracy: 91.00%\n",
      "97\tValidation loss: 0.389788\tBest loss: 0.384159\tAccuracy: 91.40%\n",
      "98\tValidation loss: 0.384572\tBest loss: 0.384159\tAccuracy: 90.90%\n",
      "99\tValidation loss: 0.380519\tBest loss: 0.380519\tAccuracy: 91.30%\n",
      "100\tValidation loss: 0.383909\tBest loss: 0.380519\tAccuracy: 90.90%\n",
      "101\tValidation loss: 0.383093\tBest loss: 0.380519\tAccuracy: 91.10%\n",
      "102\tValidation loss: 0.379133\tBest loss: 0.379133\tAccuracy: 91.10%\n",
      "103\tValidation loss: 0.378376\tBest loss: 0.378376\tAccuracy: 91.70%\n",
      "104\tValidation loss: 0.380519\tBest loss: 0.378376\tAccuracy: 91.10%\n",
      "105\tValidation loss: 0.380724\tBest loss: 0.378376\tAccuracy: 91.50%\n",
      "106\tValidation loss: 0.377454\tBest loss: 0.377454\tAccuracy: 91.40%\n",
      "107\tValidation loss: 0.377760\tBest loss: 0.377454\tAccuracy: 91.20%\n",
      "108\tValidation loss: 0.377486\tBest loss: 0.377454\tAccuracy: 91.10%\n",
      "109\tValidation loss: 0.374078\tBest loss: 0.374078\tAccuracy: 91.20%\n",
      "110\tValidation loss: 0.374735\tBest loss: 0.374078\tAccuracy: 91.30%\n",
      "111\tValidation loss: 0.376261\tBest loss: 0.374078\tAccuracy: 91.40%\n",
      "112\tValidation loss: 0.372758\tBest loss: 0.372758\tAccuracy: 91.60%\n",
      "113\tValidation loss: 0.372158\tBest loss: 0.372158\tAccuracy: 91.60%\n",
      "114\tValidation loss: 0.376243\tBest loss: 0.372158\tAccuracy: 91.10%\n",
      "115\tValidation loss: 0.370676\tBest loss: 0.370676\tAccuracy: 91.60%\n",
      "116\tValidation loss: 0.370172\tBest loss: 0.370172\tAccuracy: 91.50%\n",
      "117\tValidation loss: 0.368712\tBest loss: 0.368712\tAccuracy: 91.60%\n",
      "118\tValidation loss: 0.364636\tBest loss: 0.364636\tAccuracy: 91.80%\n",
      "119\tValidation loss: 0.366065\tBest loss: 0.364636\tAccuracy: 91.70%\n",
      "120\tValidation loss: 0.364864\tBest loss: 0.364636\tAccuracy: 91.70%\n",
      "121\tValidation loss: 0.365147\tBest loss: 0.364636\tAccuracy: 91.70%\n",
      "122\tValidation loss: 0.366082\tBest loss: 0.364636\tAccuracy: 91.50%\n",
      "123\tValidation loss: 0.365395\tBest loss: 0.364636\tAccuracy: 91.40%\n",
      "124\tValidation loss: 0.364207\tBest loss: 0.364207\tAccuracy: 91.70%\n",
      "125\tValidation loss: 0.363669\tBest loss: 0.363669\tAccuracy: 91.80%\n",
      "126\tValidation loss: 0.364785\tBest loss: 0.363669\tAccuracy: 91.90%\n",
      "127\tValidation loss: 0.362860\tBest loss: 0.362860\tAccuracy: 91.80%\n",
      "128\tValidation loss: 0.361055\tBest loss: 0.361055\tAccuracy: 91.90%\n",
      "129\tValidation loss: 0.359567\tBest loss: 0.359567\tAccuracy: 91.90%\n",
      "130\tValidation loss: 0.359894\tBest loss: 0.359567\tAccuracy: 91.90%\n",
      "131\tValidation loss: 0.360405\tBest loss: 0.359567\tAccuracy: 92.00%\n",
      "132\tValidation loss: 0.358748\tBest loss: 0.358748\tAccuracy: 92.10%\n",
      "133\tValidation loss: 0.361808\tBest loss: 0.358748\tAccuracy: 91.70%\n",
      "134\tValidation loss: 0.358438\tBest loss: 0.358438\tAccuracy: 91.80%\n",
      "135\tValidation loss: 0.357301\tBest loss: 0.357301\tAccuracy: 91.90%\n",
      "136\tValidation loss: 0.357925\tBest loss: 0.357301\tAccuracy: 91.90%\n",
      "137\tValidation loss: 0.355646\tBest loss: 0.355646\tAccuracy: 92.00%\n",
      "138\tValidation loss: 0.355998\tBest loss: 0.355646\tAccuracy: 92.10%\n",
      "139\tValidation loss: 0.353987\tBest loss: 0.353987\tAccuracy: 92.10%\n",
      "140\tValidation loss: 0.352543\tBest loss: 0.352543\tAccuracy: 92.00%\n",
      "141\tValidation loss: 0.352463\tBest loss: 0.352463\tAccuracy: 92.40%\n",
      "142\tValidation loss: 0.352462\tBest loss: 0.352462\tAccuracy: 92.30%\n",
      "143\tValidation loss: 0.352702\tBest loss: 0.352462\tAccuracy: 92.00%\n",
      "144\tValidation loss: 0.352125\tBest loss: 0.352125\tAccuracy: 92.30%\n",
      "145\tValidation loss: 0.351956\tBest loss: 0.351956\tAccuracy: 92.10%\n",
      "146\tValidation loss: 0.351477\tBest loss: 0.351477\tAccuracy: 92.20%\n",
      "147\tValidation loss: 0.353076\tBest loss: 0.351477\tAccuracy: 92.10%\n",
      "148\tValidation loss: 0.350452\tBest loss: 0.350452\tAccuracy: 92.00%\n",
      "149\tValidation loss: 0.349412\tBest loss: 0.349412\tAccuracy: 92.10%\n",
      "150\tValidation loss: 0.350147\tBest loss: 0.349412\tAccuracy: 92.10%\n",
      "151\tValidation loss: 0.346939\tBest loss: 0.346939\tAccuracy: 92.20%\n",
      "152\tValidation loss: 0.348019\tBest loss: 0.346939\tAccuracy: 92.10%\n",
      "153\tValidation loss: 0.347285\tBest loss: 0.346939\tAccuracy: 92.20%\n",
      "154\tValidation loss: 0.347912\tBest loss: 0.346939\tAccuracy: 92.50%\n",
      "155\tValidation loss: 0.348827\tBest loss: 0.346939\tAccuracy: 92.40%\n",
      "156\tValidation loss: 0.349273\tBest loss: 0.346939\tAccuracy: 92.00%\n",
      "157\tValidation loss: 0.349309\tBest loss: 0.346939\tAccuracy: 92.00%\n",
      "158\tValidation loss: 0.347244\tBest loss: 0.346939\tAccuracy: 92.20%\n",
      "159\tValidation loss: 0.344413\tBest loss: 0.344413\tAccuracy: 92.10%\n",
      "160\tValidation loss: 0.348641\tBest loss: 0.344413\tAccuracy: 92.20%\n",
      "161\tValidation loss: 0.343372\tBest loss: 0.343372\tAccuracy: 92.40%\n",
      "162\tValidation loss: 0.343479\tBest loss: 0.343372\tAccuracy: 92.30%\n",
      "163\tValidation loss: 0.343427\tBest loss: 0.343372\tAccuracy: 92.70%\n",
      "164\tValidation loss: 0.344496\tBest loss: 0.343372\tAccuracy: 92.30%\n",
      "165\tValidation loss: 0.343942\tBest loss: 0.343372\tAccuracy: 92.40%\n",
      "166\tValidation loss: 0.343687\tBest loss: 0.343372\tAccuracy: 92.00%\n",
      "167\tValidation loss: 0.340788\tBest loss: 0.340788\tAccuracy: 92.30%\n",
      "168\tValidation loss: 0.340473\tBest loss: 0.340473\tAccuracy: 92.40%\n",
      "169\tValidation loss: 0.341777\tBest loss: 0.340473\tAccuracy: 92.30%\n",
      "170\tValidation loss: 0.343144\tBest loss: 0.340473\tAccuracy: 92.00%\n",
      "171\tValidation loss: 0.342260\tBest loss: 0.340473\tAccuracy: 92.50%\n",
      "172\tValidation loss: 0.340210\tBest loss: 0.340210\tAccuracy: 92.40%\n",
      "173\tValidation loss: 0.340226\tBest loss: 0.340210\tAccuracy: 92.30%\n",
      "174\tValidation loss: 0.340215\tBest loss: 0.340210\tAccuracy: 92.50%\n",
      "175\tValidation loss: 0.339065\tBest loss: 0.339065\tAccuracy: 92.20%\n",
      "176\tValidation loss: 0.339953\tBest loss: 0.339065\tAccuracy: 92.00%\n",
      "177\tValidation loss: 0.337011\tBest loss: 0.337011\tAccuracy: 92.50%\n",
      "178\tValidation loss: 0.336480\tBest loss: 0.336480\tAccuracy: 92.30%\n",
      "179\tValidation loss: 0.339136\tBest loss: 0.336480\tAccuracy: 92.20%\n",
      "180\tValidation loss: 0.337542\tBest loss: 0.336480\tAccuracy: 92.30%\n",
      "181\tValidation loss: 0.338022\tBest loss: 0.336480\tAccuracy: 92.40%\n",
      "182\tValidation loss: 0.337280\tBest loss: 0.336480\tAccuracy: 92.40%\n",
      "183\tValidation loss: 0.337664\tBest loss: 0.336480\tAccuracy: 92.20%\n",
      "184\tValidation loss: 0.337789\tBest loss: 0.336480\tAccuracy: 92.30%\n",
      "185\tValidation loss: 0.335456\tBest loss: 0.335456\tAccuracy: 92.30%\n",
      "186\tValidation loss: 0.336356\tBest loss: 0.335456\tAccuracy: 92.30%\n",
      "187\tValidation loss: 0.333489\tBest loss: 0.333489\tAccuracy: 92.50%\n",
      "188\tValidation loss: 0.334499\tBest loss: 0.333489\tAccuracy: 92.40%\n",
      "189\tValidation loss: 0.334559\tBest loss: 0.333489\tAccuracy: 92.50%\n",
      "190\tValidation loss: 0.335336\tBest loss: 0.333489\tAccuracy: 92.30%\n",
      "191\tValidation loss: 0.335309\tBest loss: 0.333489\tAccuracy: 92.30%\n",
      "192\tValidation loss: 0.332912\tBest loss: 0.332912\tAccuracy: 92.70%\n",
      "193\tValidation loss: 0.334449\tBest loss: 0.332912\tAccuracy: 92.70%\n",
      "194\tValidation loss: 0.334783\tBest loss: 0.332912\tAccuracy: 92.70%\n",
      "195\tValidation loss: 0.335175\tBest loss: 0.332912\tAccuracy: 92.70%\n",
      "196\tValidation loss: 0.330415\tBest loss: 0.330415\tAccuracy: 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\tValidation loss: 0.333230\tBest loss: 0.330415\tAccuracy: 92.70%\n",
      "198\tValidation loss: 0.334157\tBest loss: 0.330415\tAccuracy: 92.60%\n",
      "199\tValidation loss: 0.333959\tBest loss: 0.330415\tAccuracy: 92.50%\n",
      "200\tValidation loss: 0.331924\tBest loss: 0.330415\tAccuracy: 92.90%\n",
      "201\tValidation loss: 0.332173\tBest loss: 0.330415\tAccuracy: 92.70%\n",
      "202\tValidation loss: 0.330820\tBest loss: 0.330415\tAccuracy: 92.70%\n",
      "203\tValidation loss: 0.330951\tBest loss: 0.330415\tAccuracy: 92.60%\n",
      "204\tValidation loss: 0.331950\tBest loss: 0.330415\tAccuracy: 92.60%\n",
      "205\tValidation loss: 0.331739\tBest loss: 0.330415\tAccuracy: 92.80%\n",
      "206\tValidation loss: 0.330382\tBest loss: 0.330382\tAccuracy: 92.50%\n",
      "207\tValidation loss: 0.332658\tBest loss: 0.330382\tAccuracy: 92.50%\n",
      "208\tValidation loss: 0.331897\tBest loss: 0.330382\tAccuracy: 92.60%\n",
      "209\tValidation loss: 0.330956\tBest loss: 0.330382\tAccuracy: 92.40%\n",
      "210\tValidation loss: 0.332338\tBest loss: 0.330382\tAccuracy: 92.50%\n",
      "211\tValidation loss: 0.330459\tBest loss: 0.330382\tAccuracy: 92.30%\n",
      "212\tValidation loss: 0.330353\tBest loss: 0.330353\tAccuracy: 92.90%\n",
      "213\tValidation loss: 0.329957\tBest loss: 0.329957\tAccuracy: 92.50%\n",
      "214\tValidation loss: 0.328517\tBest loss: 0.328517\tAccuracy: 92.70%\n",
      "215\tValidation loss: 0.330139\tBest loss: 0.328517\tAccuracy: 92.50%\n",
      "216\tValidation loss: 0.329306\tBest loss: 0.328517\tAccuracy: 92.90%\n",
      "217\tValidation loss: 0.329452\tBest loss: 0.328517\tAccuracy: 92.80%\n",
      "218\tValidation loss: 0.328051\tBest loss: 0.328051\tAccuracy: 92.60%\n",
      "219\tValidation loss: 0.329545\tBest loss: 0.328051\tAccuracy: 92.50%\n",
      "220\tValidation loss: 0.327991\tBest loss: 0.327991\tAccuracy: 92.70%\n",
      "221\tValidation loss: 0.328337\tBest loss: 0.327991\tAccuracy: 92.40%\n",
      "222\tValidation loss: 0.330335\tBest loss: 0.327991\tAccuracy: 92.40%\n",
      "223\tValidation loss: 0.328370\tBest loss: 0.327991\tAccuracy: 92.70%\n",
      "224\tValidation loss: 0.329917\tBest loss: 0.327991\tAccuracy: 92.50%\n",
      "225\tValidation loss: 0.328473\tBest loss: 0.327991\tAccuracy: 92.60%\n",
      "226\tValidation loss: 0.327709\tBest loss: 0.327709\tAccuracy: 92.60%\n",
      "227\tValidation loss: 0.326753\tBest loss: 0.326753\tAccuracy: 92.60%\n",
      "228\tValidation loss: 0.326484\tBest loss: 0.326484\tAccuracy: 92.50%\n",
      "229\tValidation loss: 0.326367\tBest loss: 0.326367\tAccuracy: 93.00%\n",
      "230\tValidation loss: 0.327089\tBest loss: 0.326367\tAccuracy: 92.60%\n",
      "231\tValidation loss: 0.325004\tBest loss: 0.325004\tAccuracy: 92.60%\n",
      "232\tValidation loss: 0.326444\tBest loss: 0.325004\tAccuracy: 92.60%\n",
      "233\tValidation loss: 0.326116\tBest loss: 0.325004\tAccuracy: 92.60%\n",
      "234\tValidation loss: 0.326961\tBest loss: 0.325004\tAccuracy: 92.70%\n",
      "235\tValidation loss: 0.328372\tBest loss: 0.325004\tAccuracy: 92.50%\n",
      "236\tValidation loss: 0.325921\tBest loss: 0.325004\tAccuracy: 92.50%\n",
      "237\tValidation loss: 0.327985\tBest loss: 0.325004\tAccuracy: 93.00%\n",
      "238\tValidation loss: 0.327702\tBest loss: 0.325004\tAccuracy: 92.80%\n",
      "239\tValidation loss: 0.325829\tBest loss: 0.325004\tAccuracy: 92.50%\n",
      "240\tValidation loss: 0.325917\tBest loss: 0.325004\tAccuracy: 92.70%\n",
      "241\tValidation loss: 0.327225\tBest loss: 0.325004\tAccuracy: 93.00%\n",
      "242\tValidation loss: 0.324553\tBest loss: 0.324553\tAccuracy: 92.70%\n",
      "243\tValidation loss: 0.325228\tBest loss: 0.324553\tAccuracy: 92.60%\n",
      "244\tValidation loss: 0.327128\tBest loss: 0.324553\tAccuracy: 92.70%\n",
      "245\tValidation loss: 0.325420\tBest loss: 0.324553\tAccuracy: 92.80%\n",
      "246\tValidation loss: 0.326064\tBest loss: 0.324553\tAccuracy: 92.70%\n",
      "247\tValidation loss: 0.322711\tBest loss: 0.322711\tAccuracy: 92.70%\n",
      "248\tValidation loss: 0.324373\tBest loss: 0.322711\tAccuracy: 92.70%\n",
      "249\tValidation loss: 0.324791\tBest loss: 0.322711\tAccuracy: 92.60%\n",
      "250\tValidation loss: 0.323361\tBest loss: 0.322711\tAccuracy: 92.60%\n",
      "251\tValidation loss: 0.324201\tBest loss: 0.322711\tAccuracy: 92.80%\n",
      "252\tValidation loss: 0.322120\tBest loss: 0.322120\tAccuracy: 92.60%\n",
      "253\tValidation loss: 0.323933\tBest loss: 0.322120\tAccuracy: 92.80%\n",
      "254\tValidation loss: 0.322621\tBest loss: 0.322120\tAccuracy: 92.90%\n",
      "255\tValidation loss: 0.324586\tBest loss: 0.322120\tAccuracy: 92.90%\n",
      "256\tValidation loss: 0.321066\tBest loss: 0.321066\tAccuracy: 92.60%\n",
      "257\tValidation loss: 0.325580\tBest loss: 0.321066\tAccuracy: 93.00%\n",
      "258\tValidation loss: 0.323288\tBest loss: 0.321066\tAccuracy: 92.90%\n",
      "259\tValidation loss: 0.325683\tBest loss: 0.321066\tAccuracy: 92.90%\n",
      "260\tValidation loss: 0.323686\tBest loss: 0.321066\tAccuracy: 92.80%\n",
      "261\tValidation loss: 0.322467\tBest loss: 0.321066\tAccuracy: 92.90%\n",
      "262\tValidation loss: 0.321759\tBest loss: 0.321066\tAccuracy: 93.00%\n",
      "263\tValidation loss: 0.322772\tBest loss: 0.321066\tAccuracy: 92.50%\n",
      "264\tValidation loss: 0.320281\tBest loss: 0.320281\tAccuracy: 92.80%\n",
      "265\tValidation loss: 0.322408\tBest loss: 0.320281\tAccuracy: 92.90%\n",
      "266\tValidation loss: 0.322148\tBest loss: 0.320281\tAccuracy: 92.90%\n",
      "267\tValidation loss: 0.319934\tBest loss: 0.319934\tAccuracy: 93.10%\n",
      "268\tValidation loss: 0.323306\tBest loss: 0.319934\tAccuracy: 92.90%\n",
      "269\tValidation loss: 0.320914\tBest loss: 0.319934\tAccuracy: 92.90%\n",
      "270\tValidation loss: 0.323024\tBest loss: 0.319934\tAccuracy: 93.00%\n",
      "271\tValidation loss: 0.320627\tBest loss: 0.319934\tAccuracy: 92.80%\n",
      "272\tValidation loss: 0.320347\tBest loss: 0.319934\tAccuracy: 93.10%\n",
      "273\tValidation loss: 0.321329\tBest loss: 0.319934\tAccuracy: 93.10%\n",
      "274\tValidation loss: 0.321092\tBest loss: 0.319934\tAccuracy: 93.10%\n",
      "275\tValidation loss: 0.323591\tBest loss: 0.319934\tAccuracy: 92.90%\n",
      "276\tValidation loss: 0.322161\tBest loss: 0.319934\tAccuracy: 93.20%\n",
      "277\tValidation loss: 0.321946\tBest loss: 0.319934\tAccuracy: 93.20%\n",
      "278\tValidation loss: 0.320379\tBest loss: 0.319934\tAccuracy: 92.90%\n",
      "279\tValidation loss: 0.320586\tBest loss: 0.319934\tAccuracy: 92.90%\n",
      "280\tValidation loss: 0.319656\tBest loss: 0.319656\tAccuracy: 92.90%\n",
      "281\tValidation loss: 0.321446\tBest loss: 0.319656\tAccuracy: 93.00%\n",
      "282\tValidation loss: 0.321318\tBest loss: 0.319656\tAccuracy: 93.00%\n",
      "283\tValidation loss: 0.320472\tBest loss: 0.319656\tAccuracy: 92.80%\n",
      "284\tValidation loss: 0.321050\tBest loss: 0.319656\tAccuracy: 92.90%\n",
      "285\tValidation loss: 0.320693\tBest loss: 0.319656\tAccuracy: 92.90%\n",
      "286\tValidation loss: 0.319657\tBest loss: 0.319656\tAccuracy: 93.00%\n",
      "287\tValidation loss: 0.320709\tBest loss: 0.319656\tAccuracy: 93.20%\n",
      "288\tValidation loss: 0.319525\tBest loss: 0.319525\tAccuracy: 93.00%\n",
      "289\tValidation loss: 0.321047\tBest loss: 0.319525\tAccuracy: 93.00%\n",
      "290\tValidation loss: 0.319686\tBest loss: 0.319525\tAccuracy: 93.00%\n",
      "291\tValidation loss: 0.320714\tBest loss: 0.319525\tAccuracy: 93.30%\n",
      "292\tValidation loss: 0.319732\tBest loss: 0.319525\tAccuracy: 93.00%\n",
      "293\tValidation loss: 0.319835\tBest loss: 0.319525\tAccuracy: 93.20%\n",
      "294\tValidation loss: 0.319626\tBest loss: 0.319525\tAccuracy: 93.10%\n",
      "295\tValidation loss: 0.320173\tBest loss: 0.319525\tAccuracy: 93.00%\n",
      "296\tValidation loss: 0.320137\tBest loss: 0.319525\tAccuracy: 93.20%\n",
      "297\tValidation loss: 0.317698\tBest loss: 0.317698\tAccuracy: 93.10%\n",
      "298\tValidation loss: 0.320161\tBest loss: 0.317698\tAccuracy: 92.90%\n",
      "299\tValidation loss: 0.320075\tBest loss: 0.317698\tAccuracy: 93.20%\n",
      "300\tValidation loss: 0.319773\tBest loss: 0.317698\tAccuracy: 93.10%\n",
      "301\tValidation loss: 0.319671\tBest loss: 0.317698\tAccuracy: 93.30%\n",
      "302\tValidation loss: 0.321274\tBest loss: 0.317698\tAccuracy: 93.30%\n",
      "303\tValidation loss: 0.320867\tBest loss: 0.317698\tAccuracy: 93.20%\n",
      "304\tValidation loss: 0.318476\tBest loss: 0.317698\tAccuracy: 93.30%\n",
      "305\tValidation loss: 0.317473\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "306\tValidation loss: 0.320570\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "307\tValidation loss: 0.318791\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "308\tValidation loss: 0.318679\tBest loss: 0.317473\tAccuracy: 93.20%\n",
      "309\tValidation loss: 0.318495\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "310\tValidation loss: 0.317709\tBest loss: 0.317473\tAccuracy: 93.30%\n",
      "311\tValidation loss: 0.318987\tBest loss: 0.317473\tAccuracy: 93.20%\n",
      "312\tValidation loss: 0.317720\tBest loss: 0.317473\tAccuracy: 93.20%\n",
      "313\tValidation loss: 0.320675\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "314\tValidation loss: 0.319970\tBest loss: 0.317473\tAccuracy: 93.20%\n",
      "315\tValidation loss: 0.318838\tBest loss: 0.317473\tAccuracy: 93.10%\n",
      "316\tValidation loss: 0.320771\tBest loss: 0.317473\tAccuracy: 93.30%\n",
      "317\tValidation loss: 0.320024\tBest loss: 0.317473\tAccuracy: 93.20%\n",
      "318\tValidation loss: 0.318195\tBest loss: 0.317473\tAccuracy: 93.00%\n",
      "319\tValidation loss: 0.319559\tBest loss: 0.317473\tAccuracy: 93.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\tValidation loss: 0.317365\tBest loss: 0.317365\tAccuracy: 93.30%\n",
      "321\tValidation loss: 0.316971\tBest loss: 0.316971\tAccuracy: 93.00%\n",
      "322\tValidation loss: 0.318821\tBest loss: 0.316971\tAccuracy: 93.40%\n",
      "323\tValidation loss: 0.319171\tBest loss: 0.316971\tAccuracy: 93.30%\n",
      "324\tValidation loss: 0.318269\tBest loss: 0.316971\tAccuracy: 93.10%\n",
      "325\tValidation loss: 0.319406\tBest loss: 0.316971\tAccuracy: 93.10%\n",
      "326\tValidation loss: 0.317050\tBest loss: 0.316971\tAccuracy: 93.30%\n",
      "327\tValidation loss: 0.318303\tBest loss: 0.316971\tAccuracy: 93.10%\n",
      "328\tValidation loss: 0.318950\tBest loss: 0.316971\tAccuracy: 93.10%\n",
      "329\tValidation loss: 0.320128\tBest loss: 0.316971\tAccuracy: 93.20%\n",
      "330\tValidation loss: 0.318130\tBest loss: 0.316971\tAccuracy: 93.40%\n",
      "331\tValidation loss: 0.317616\tBest loss: 0.316971\tAccuracy: 93.40%\n",
      "332\tValidation loss: 0.318866\tBest loss: 0.316971\tAccuracy: 93.40%\n",
      "333\tValidation loss: 0.318937\tBest loss: 0.316971\tAccuracy: 93.30%\n",
      "334\tValidation loss: 0.318305\tBest loss: 0.316971\tAccuracy: 93.60%\n",
      "335\tValidation loss: 0.317157\tBest loss: 0.316971\tAccuracy: 93.30%\n",
      "336\tValidation loss: 0.315115\tBest loss: 0.315115\tAccuracy: 93.30%\n",
      "337\tValidation loss: 0.317526\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "338\tValidation loss: 0.316745\tBest loss: 0.315115\tAccuracy: 93.10%\n",
      "339\tValidation loss: 0.317676\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "340\tValidation loss: 0.318528\tBest loss: 0.315115\tAccuracy: 93.30%\n",
      "341\tValidation loss: 0.316988\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "342\tValidation loss: 0.317466\tBest loss: 0.315115\tAccuracy: 93.10%\n",
      "343\tValidation loss: 0.317268\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "344\tValidation loss: 0.317711\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "345\tValidation loss: 0.318687\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "346\tValidation loss: 0.318289\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "347\tValidation loss: 0.318192\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "348\tValidation loss: 0.317148\tBest loss: 0.315115\tAccuracy: 93.20%\n",
      "349\tValidation loss: 0.318125\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "350\tValidation loss: 0.318589\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "351\tValidation loss: 0.317311\tBest loss: 0.315115\tAccuracy: 93.10%\n",
      "352\tValidation loss: 0.316947\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "353\tValidation loss: 0.317617\tBest loss: 0.315115\tAccuracy: 93.60%\n",
      "354\tValidation loss: 0.317187\tBest loss: 0.315115\tAccuracy: 93.40%\n",
      "355\tValidation loss: 0.317017\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "356\tValidation loss: 0.317961\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "357\tValidation loss: 0.318749\tBest loss: 0.315115\tAccuracy: 93.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=100, n_neurons=300, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate=0.01, total= 1.4min\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 4.043322\tBest loss: 4.043322\tAccuracy: 22.80%\n",
      "1\tValidation loss: 8.143828\tBest loss: 4.043322\tAccuracy: 25.00%\n",
      "2\tValidation loss: 1.940298\tBest loss: 1.940298\tAccuracy: 53.80%\n",
      "3\tValidation loss: 2.253068\tBest loss: 1.940298\tAccuracy: 48.10%\n",
      "4\tValidation loss: 1.117425\tBest loss: 1.117425\tAccuracy: 72.40%\n",
      "5\tValidation loss: 1.264627\tBest loss: 1.117425\tAccuracy: 70.90%\n",
      "6\tValidation loss: 1.129978\tBest loss: 1.117425\tAccuracy: 74.20%\n",
      "7\tValidation loss: 3.533568\tBest loss: 1.117425\tAccuracy: 62.50%\n",
      "8\tValidation loss: 1.098926\tBest loss: 1.098926\tAccuracy: 74.80%\n",
      "9\tValidation loss: 1.399282\tBest loss: 1.098926\tAccuracy: 74.90%\n",
      "10\tValidation loss: 1.155508\tBest loss: 1.098926\tAccuracy: 80.40%\n",
      "11\tValidation loss: 0.756677\tBest loss: 0.756677\tAccuracy: 84.80%\n",
      "12\tValidation loss: 1.594038\tBest loss: 0.756677\tAccuracy: 81.40%\n",
      "13\tValidation loss: 1.245172\tBest loss: 0.756677\tAccuracy: 76.60%\n",
      "14\tValidation loss: 1.259915\tBest loss: 0.756677\tAccuracy: 84.00%\n",
      "15\tValidation loss: 0.962540\tBest loss: 0.756677\tAccuracy: 86.20%\n",
      "16\tValidation loss: 2.530450\tBest loss: 0.756677\tAccuracy: 77.80%\n",
      "17\tValidation loss: 1.708822\tBest loss: 0.756677\tAccuracy: 83.00%\n",
      "18\tValidation loss: 1.552500\tBest loss: 0.756677\tAccuracy: 83.40%\n",
      "19\tValidation loss: 1.560278\tBest loss: 0.756677\tAccuracy: 86.40%\n",
      "20\tValidation loss: 1.155534\tBest loss: 0.756677\tAccuracy: 85.90%\n",
      "21\tValidation loss: 1.417123\tBest loss: 0.756677\tAccuracy: 88.80%\n",
      "22\tValidation loss: 1.558359\tBest loss: 0.756677\tAccuracy: 87.30%\n",
      "23\tValidation loss: 1.588548\tBest loss: 0.756677\tAccuracy: 88.30%\n",
      "24\tValidation loss: 1.847355\tBest loss: 0.756677\tAccuracy: 88.40%\n",
      "25\tValidation loss: 1.490392\tBest loss: 0.756677\tAccuracy: 90.10%\n",
      "26\tValidation loss: 3.302170\tBest loss: 0.756677\tAccuracy: 83.50%\n",
      "27\tValidation loss: 1.889962\tBest loss: 0.756677\tAccuracy: 89.20%\n",
      "28\tValidation loss: 1.823424\tBest loss: 0.756677\tAccuracy: 89.30%\n",
      "29\tValidation loss: 2.351600\tBest loss: 0.756677\tAccuracy: 86.30%\n",
      "30\tValidation loss: 1.704511\tBest loss: 0.756677\tAccuracy: 91.40%\n",
      "31\tValidation loss: 1.799240\tBest loss: 0.756677\tAccuracy: 91.80%\n",
      "32\tValidation loss: 1.593158\tBest loss: 0.756677\tAccuracy: 91.00%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   5.0s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.373654\tBest loss: 3.373654\tAccuracy: 29.30%\n",
      "1\tValidation loss: 5.572430\tBest loss: 3.373654\tAccuracy: 20.10%\n",
      "2\tValidation loss: 1.713417\tBest loss: 1.713417\tAccuracy: 51.70%\n",
      "3\tValidation loss: 1.253200\tBest loss: 1.253200\tAccuracy: 67.40%\n",
      "4\tValidation loss: 1.163980\tBest loss: 1.163980\tAccuracy: 70.20%\n",
      "5\tValidation loss: 1.156260\tBest loss: 1.156260\tAccuracy: 72.70%\n",
      "6\tValidation loss: 1.445985\tBest loss: 1.156260\tAccuracy: 71.00%\n",
      "7\tValidation loss: 0.866714\tBest loss: 0.866714\tAccuracy: 79.10%\n",
      "8\tValidation loss: 2.032830\tBest loss: 0.866714\tAccuracy: 70.60%\n",
      "9\tValidation loss: 1.428928\tBest loss: 0.866714\tAccuracy: 77.30%\n",
      "10\tValidation loss: 1.918815\tBest loss: 0.866714\tAccuracy: 78.10%\n",
      "11\tValidation loss: 0.734364\tBest loss: 0.734364\tAccuracy: 86.70%\n",
      "12\tValidation loss: 3.078513\tBest loss: 0.734364\tAccuracy: 74.70%\n",
      "13\tValidation loss: 1.222426\tBest loss: 0.734364\tAccuracy: 84.00%\n",
      "14\tValidation loss: 0.834675\tBest loss: 0.734364\tAccuracy: 85.80%\n",
      "15\tValidation loss: 1.638589\tBest loss: 0.734364\tAccuracy: 83.30%\n",
      "16\tValidation loss: 0.820229\tBest loss: 0.734364\tAccuracy: 86.60%\n",
      "17\tValidation loss: 1.350576\tBest loss: 0.734364\tAccuracy: 85.00%\n",
      "18\tValidation loss: 1.244129\tBest loss: 0.734364\tAccuracy: 86.00%\n",
      "19\tValidation loss: 1.468815\tBest loss: 0.734364\tAccuracy: 84.80%\n",
      "20\tValidation loss: 1.329745\tBest loss: 0.734364\tAccuracy: 85.70%\n",
      "21\tValidation loss: 1.055587\tBest loss: 0.734364\tAccuracy: 88.80%\n",
      "22\tValidation loss: 1.271734\tBest loss: 0.734364\tAccuracy: 86.30%\n",
      "23\tValidation loss: 1.740591\tBest loss: 0.734364\tAccuracy: 87.80%\n",
      "24\tValidation loss: 2.171108\tBest loss: 0.734364\tAccuracy: 86.90%\n",
      "25\tValidation loss: 1.078637\tBest loss: 0.734364\tAccuracy: 90.50%\n",
      "26\tValidation loss: 1.950182\tBest loss: 0.734364\tAccuracy: 89.10%\n",
      "27\tValidation loss: 1.647787\tBest loss: 0.734364\tAccuracy: 88.60%\n",
      "28\tValidation loss: 1.870187\tBest loss: 0.734364\tAccuracy: 88.10%\n",
      "29\tValidation loss: 2.236203\tBest loss: 0.734364\tAccuracy: 88.00%\n",
      "30\tValidation loss: 1.512681\tBest loss: 0.734364\tAccuracy: 88.60%\n",
      "31\tValidation loss: 1.846785\tBest loss: 0.734364\tAccuracy: 90.10%\n",
      "32\tValidation loss: 2.118822\tBest loss: 0.734364\tAccuracy: 89.30%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.9s\n",
      "[CV] batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 6.238748\tBest loss: 6.238748\tAccuracy: 14.50%\n",
      "1\tValidation loss: 4.600704\tBest loss: 4.600704\tAccuracy: 37.60%\n",
      "2\tValidation loss: 2.538832\tBest loss: 2.538832\tAccuracy: 51.10%\n",
      "3\tValidation loss: 2.182034\tBest loss: 2.182034\tAccuracy: 54.20%\n",
      "4\tValidation loss: 1.165364\tBest loss: 1.165364\tAccuracy: 70.90%\n",
      "5\tValidation loss: 1.856779\tBest loss: 1.165364\tAccuracy: 67.00%\n",
      "6\tValidation loss: 0.747799\tBest loss: 0.747799\tAccuracy: 79.90%\n",
      "7\tValidation loss: 1.063192\tBest loss: 0.747799\tAccuracy: 78.10%\n",
      "8\tValidation loss: 1.606254\tBest loss: 0.747799\tAccuracy: 74.30%\n",
      "9\tValidation loss: 0.840686\tBest loss: 0.747799\tAccuracy: 81.70%\n",
      "10\tValidation loss: 0.708478\tBest loss: 0.708478\tAccuracy: 84.10%\n",
      "11\tValidation loss: 0.852373\tBest loss: 0.708478\tAccuracy: 83.80%\n",
      "12\tValidation loss: 0.961721\tBest loss: 0.708478\tAccuracy: 84.80%\n",
      "13\tValidation loss: 0.883642\tBest loss: 0.708478\tAccuracy: 86.10%\n",
      "14\tValidation loss: 1.483369\tBest loss: 0.708478\tAccuracy: 80.80%\n",
      "15\tValidation loss: 1.041035\tBest loss: 0.708478\tAccuracy: 87.00%\n",
      "16\tValidation loss: 0.942322\tBest loss: 0.708478\tAccuracy: 86.20%\n",
      "17\tValidation loss: 1.250504\tBest loss: 0.708478\tAccuracy: 83.90%\n",
      "18\tValidation loss: 1.364077\tBest loss: 0.708478\tAccuracy: 84.40%\n",
      "19\tValidation loss: 0.835662\tBest loss: 0.708478\tAccuracy: 88.60%\n",
      "20\tValidation loss: 1.315227\tBest loss: 0.708478\tAccuracy: 86.50%\n",
      "21\tValidation loss: 1.583517\tBest loss: 0.708478\tAccuracy: 86.00%\n",
      "22\tValidation loss: 2.267685\tBest loss: 0.708478\tAccuracy: 82.80%\n",
      "23\tValidation loss: 1.380100\tBest loss: 0.708478\tAccuracy: 87.90%\n",
      "24\tValidation loss: 1.029542\tBest loss: 0.708478\tAccuracy: 89.30%\n",
      "25\tValidation loss: 1.573764\tBest loss: 0.708478\tAccuracy: 87.10%\n",
      "26\tValidation loss: 1.581224\tBest loss: 0.708478\tAccuracy: 88.00%\n",
      "27\tValidation loss: 1.466743\tBest loss: 0.708478\tAccuracy: 89.20%\n",
      "28\tValidation loss: 1.666575\tBest loss: 0.708478\tAccuracy: 88.10%\n",
      "29\tValidation loss: 1.769092\tBest loss: 0.708478\tAccuracy: 88.50%\n",
      "30\tValidation loss: 2.585179\tBest loss: 0.708478\tAccuracy: 87.40%\n",
      "31\tValidation loss: 2.032681\tBest loss: 0.708478\tAccuracy: 89.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=250, n_hidden_layers=2, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   4.9s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.166450\tBest loss: 3.166450\tAccuracy: 19.40%\n",
      "1\tValidation loss: 2.169033\tBest loss: 2.169033\tAccuracy: 45.70%\n",
      "2\tValidation loss: 1.469806\tBest loss: 1.469806\tAccuracy: 63.80%\n",
      "3\tValidation loss: 1.237137\tBest loss: 1.237137\tAccuracy: 70.80%\n",
      "4\tValidation loss: 1.011144\tBest loss: 1.011144\tAccuracy: 77.40%\n",
      "5\tValidation loss: 0.862717\tBest loss: 0.862717\tAccuracy: 80.50%\n",
      "6\tValidation loss: 0.843231\tBest loss: 0.843231\tAccuracy: 78.80%\n",
      "7\tValidation loss: 0.876868\tBest loss: 0.843231\tAccuracy: 78.00%\n",
      "8\tValidation loss: 0.812739\tBest loss: 0.812739\tAccuracy: 79.30%\n",
      "9\tValidation loss: 0.677045\tBest loss: 0.677045\tAccuracy: 82.70%\n",
      "10\tValidation loss: 0.704012\tBest loss: 0.677045\tAccuracy: 83.40%\n",
      "11\tValidation loss: 0.602619\tBest loss: 0.602619\tAccuracy: 85.30%\n",
      "12\tValidation loss: 0.643084\tBest loss: 0.602619\tAccuracy: 84.50%\n",
      "13\tValidation loss: 0.613490\tBest loss: 0.602619\tAccuracy: 84.60%\n",
      "14\tValidation loss: 0.558755\tBest loss: 0.558755\tAccuracy: 85.60%\n",
      "15\tValidation loss: 0.521755\tBest loss: 0.521755\tAccuracy: 88.10%\n",
      "16\tValidation loss: 0.576621\tBest loss: 0.521755\tAccuracy: 85.00%\n",
      "17\tValidation loss: 0.525180\tBest loss: 0.521755\tAccuracy: 87.50%\n",
      "18\tValidation loss: 0.520301\tBest loss: 0.520301\tAccuracy: 87.00%\n",
      "19\tValidation loss: 0.571798\tBest loss: 0.520301\tAccuracy: 86.00%\n",
      "20\tValidation loss: 0.477329\tBest loss: 0.477329\tAccuracy: 88.80%\n",
      "21\tValidation loss: 0.457105\tBest loss: 0.457105\tAccuracy: 90.00%\n",
      "22\tValidation loss: 0.646420\tBest loss: 0.457105\tAccuracy: 85.70%\n",
      "23\tValidation loss: 0.475403\tBest loss: 0.457105\tAccuracy: 89.20%\n",
      "24\tValidation loss: 0.470372\tBest loss: 0.457105\tAccuracy: 89.60%\n",
      "25\tValidation loss: 0.491993\tBest loss: 0.457105\tAccuracy: 88.10%\n",
      "26\tValidation loss: 0.433520\tBest loss: 0.433520\tAccuracy: 89.90%\n",
      "27\tValidation loss: 0.465236\tBest loss: 0.433520\tAccuracy: 88.60%\n",
      "28\tValidation loss: 0.417744\tBest loss: 0.417744\tAccuracy: 90.00%\n",
      "29\tValidation loss: 0.489653\tBest loss: 0.417744\tAccuracy: 90.10%\n",
      "30\tValidation loss: 0.517831\tBest loss: 0.417744\tAccuracy: 88.60%\n",
      "31\tValidation loss: 0.454725\tBest loss: 0.417744\tAccuracy: 90.90%\n",
      "32\tValidation loss: 0.420344\tBest loss: 0.417744\tAccuracy: 90.70%\n",
      "33\tValidation loss: 0.397882\tBest loss: 0.397882\tAccuracy: 91.60%\n",
      "34\tValidation loss: 0.413461\tBest loss: 0.397882\tAccuracy: 91.00%\n",
      "35\tValidation loss: 0.415216\tBest loss: 0.397882\tAccuracy: 90.80%\n",
      "36\tValidation loss: 0.396206\tBest loss: 0.396206\tAccuracy: 90.60%\n",
      "37\tValidation loss: 0.423856\tBest loss: 0.396206\tAccuracy: 90.30%\n",
      "38\tValidation loss: 0.389825\tBest loss: 0.389825\tAccuracy: 92.50%\n",
      "39\tValidation loss: 0.385024\tBest loss: 0.385024\tAccuracy: 91.80%\n",
      "40\tValidation loss: 0.435384\tBest loss: 0.385024\tAccuracy: 91.10%\n",
      "41\tValidation loss: 0.413358\tBest loss: 0.385024\tAccuracy: 91.00%\n",
      "42\tValidation loss: 0.464353\tBest loss: 0.385024\tAccuracy: 90.50%\n",
      "43\tValidation loss: 0.395123\tBest loss: 0.385024\tAccuracy: 91.70%\n",
      "44\tValidation loss: 0.397698\tBest loss: 0.385024\tAccuracy: 92.10%\n",
      "45\tValidation loss: 0.359303\tBest loss: 0.359303\tAccuracy: 93.60%\n",
      "46\tValidation loss: 0.397544\tBest loss: 0.359303\tAccuracy: 91.80%\n",
      "47\tValidation loss: 0.412466\tBest loss: 0.359303\tAccuracy: 92.10%\n",
      "48\tValidation loss: 0.471792\tBest loss: 0.359303\tAccuracy: 89.50%\n",
      "49\tValidation loss: 0.410516\tBest loss: 0.359303\tAccuracy: 91.90%\n",
      "50\tValidation loss: 0.414191\tBest loss: 0.359303\tAccuracy: 92.00%\n",
      "51\tValidation loss: 0.388782\tBest loss: 0.359303\tAccuracy: 91.90%\n",
      "52\tValidation loss: 0.422791\tBest loss: 0.359303\tAccuracy: 92.60%\n",
      "53\tValidation loss: 0.423509\tBest loss: 0.359303\tAccuracy: 92.60%\n",
      "54\tValidation loss: 0.373935\tBest loss: 0.359303\tAccuracy: 93.20%\n",
      "55\tValidation loss: 0.440371\tBest loss: 0.359303\tAccuracy: 91.70%\n",
      "56\tValidation loss: 0.400898\tBest loss: 0.359303\tAccuracy: 93.20%\n",
      "57\tValidation loss: 0.388354\tBest loss: 0.359303\tAccuracy: 92.30%\n",
      "58\tValidation loss: 0.378513\tBest loss: 0.359303\tAccuracy: 92.80%\n",
      "59\tValidation loss: 0.399455\tBest loss: 0.359303\tAccuracy: 92.90%\n",
      "60\tValidation loss: 0.383877\tBest loss: 0.359303\tAccuracy: 92.60%\n",
      "61\tValidation loss: 0.424583\tBest loss: 0.359303\tAccuracy: 93.20%\n",
      "62\tValidation loss: 0.397347\tBest loss: 0.359303\tAccuracy: 92.70%\n",
      "63\tValidation loss: 0.382828\tBest loss: 0.359303\tAccuracy: 93.20%\n",
      "64\tValidation loss: 0.412402\tBest loss: 0.359303\tAccuracy: 93.00%\n",
      "65\tValidation loss: 0.445250\tBest loss: 0.359303\tAccuracy: 92.40%\n",
      "66\tValidation loss: 0.426645\tBest loss: 0.359303\tAccuracy: 92.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   6.5s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.170618\tBest loss: 3.170618\tAccuracy: 15.70%\n",
      "1\tValidation loss: 2.122621\tBest loss: 2.122621\tAccuracy: 47.20%\n",
      "2\tValidation loss: 1.635900\tBest loss: 1.635900\tAccuracy: 60.30%\n",
      "3\tValidation loss: 1.318873\tBest loss: 1.318873\tAccuracy: 68.70%\n",
      "4\tValidation loss: 1.105828\tBest loss: 1.105828\tAccuracy: 73.70%\n",
      "5\tValidation loss: 0.935036\tBest loss: 0.935036\tAccuracy: 79.90%\n",
      "6\tValidation loss: 0.868051\tBest loss: 0.868051\tAccuracy: 78.40%\n",
      "7\tValidation loss: 0.872513\tBest loss: 0.868051\tAccuracy: 78.00%\n",
      "8\tValidation loss: 0.789689\tBest loss: 0.789689\tAccuracy: 78.70%\n",
      "9\tValidation loss: 0.607603\tBest loss: 0.607603\tAccuracy: 86.30%\n",
      "10\tValidation loss: 0.677015\tBest loss: 0.607603\tAccuracy: 82.90%\n",
      "11\tValidation loss: 0.751921\tBest loss: 0.607603\tAccuracy: 81.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 0.694152\tBest loss: 0.607603\tAccuracy: 81.70%\n",
      "13\tValidation loss: 0.688217\tBest loss: 0.607603\tAccuracy: 82.40%\n",
      "14\tValidation loss: 0.538002\tBest loss: 0.538002\tAccuracy: 87.10%\n",
      "15\tValidation loss: 0.539820\tBest loss: 0.538002\tAccuracy: 87.50%\n",
      "16\tValidation loss: 0.504359\tBest loss: 0.504359\tAccuracy: 87.50%\n",
      "17\tValidation loss: 0.663535\tBest loss: 0.504359\tAccuracy: 84.30%\n",
      "18\tValidation loss: 0.535034\tBest loss: 0.504359\tAccuracy: 86.80%\n",
      "19\tValidation loss: 0.518685\tBest loss: 0.504359\tAccuracy: 88.60%\n",
      "20\tValidation loss: 0.487853\tBest loss: 0.487853\tAccuracy: 88.80%\n",
      "21\tValidation loss: 0.601784\tBest loss: 0.487853\tAccuracy: 84.10%\n",
      "22\tValidation loss: 0.522935\tBest loss: 0.487853\tAccuracy: 87.80%\n",
      "23\tValidation loss: 0.511383\tBest loss: 0.487853\tAccuracy: 89.60%\n",
      "24\tValidation loss: 0.450644\tBest loss: 0.450644\tAccuracy: 90.10%\n",
      "25\tValidation loss: 0.489811\tBest loss: 0.450644\tAccuracy: 89.40%\n",
      "26\tValidation loss: 0.555589\tBest loss: 0.450644\tAccuracy: 88.20%\n",
      "27\tValidation loss: 0.467934\tBest loss: 0.450644\tAccuracy: 89.80%\n",
      "28\tValidation loss: 0.513687\tBest loss: 0.450644\tAccuracy: 88.70%\n",
      "29\tValidation loss: 0.498507\tBest loss: 0.450644\tAccuracy: 89.50%\n",
      "30\tValidation loss: 0.522786\tBest loss: 0.450644\tAccuracy: 88.70%\n",
      "31\tValidation loss: 0.546602\tBest loss: 0.450644\tAccuracy: 88.90%\n",
      "32\tValidation loss: 0.482035\tBest loss: 0.450644\tAccuracy: 90.70%\n",
      "33\tValidation loss: 0.506613\tBest loss: 0.450644\tAccuracy: 91.20%\n",
      "34\tValidation loss: 0.496172\tBest loss: 0.450644\tAccuracy: 90.70%\n",
      "35\tValidation loss: 0.513674\tBest loss: 0.450644\tAccuracy: 90.20%\n",
      "36\tValidation loss: 0.490521\tBest loss: 0.450644\tAccuracy: 90.40%\n",
      "37\tValidation loss: 0.506595\tBest loss: 0.450644\tAccuracy: 90.00%\n",
      "38\tValidation loss: 0.498870\tBest loss: 0.450644\tAccuracy: 90.30%\n",
      "39\tValidation loss: 0.501366\tBest loss: 0.450644\tAccuracy: 90.60%\n",
      "40\tValidation loss: 0.489944\tBest loss: 0.450644\tAccuracy: 91.00%\n",
      "41\tValidation loss: 0.442546\tBest loss: 0.442546\tAccuracy: 92.20%\n",
      "42\tValidation loss: 0.517365\tBest loss: 0.442546\tAccuracy: 90.00%\n",
      "43\tValidation loss: 0.459549\tBest loss: 0.442546\tAccuracy: 92.80%\n",
      "44\tValidation loss: 0.488503\tBest loss: 0.442546\tAccuracy: 91.30%\n",
      "45\tValidation loss: 0.464364\tBest loss: 0.442546\tAccuracy: 92.10%\n",
      "46\tValidation loss: 0.506513\tBest loss: 0.442546\tAccuracy: 91.70%\n",
      "47\tValidation loss: 0.528893\tBest loss: 0.442546\tAccuracy: 91.50%\n",
      "48\tValidation loss: 0.483078\tBest loss: 0.442546\tAccuracy: 91.20%\n",
      "49\tValidation loss: 0.493824\tBest loss: 0.442546\tAccuracy: 91.20%\n",
      "50\tValidation loss: 0.509711\tBest loss: 0.442546\tAccuracy: 91.60%\n",
      "51\tValidation loss: 0.530485\tBest loss: 0.442546\tAccuracy: 91.50%\n",
      "52\tValidation loss: 0.504615\tBest loss: 0.442546\tAccuracy: 92.10%\n",
      "53\tValidation loss: 0.545096\tBest loss: 0.442546\tAccuracy: 90.90%\n",
      "54\tValidation loss: 0.551888\tBest loss: 0.442546\tAccuracy: 91.50%\n",
      "55\tValidation loss: 0.582789\tBest loss: 0.442546\tAccuracy: 90.80%\n",
      "56\tValidation loss: 0.546813\tBest loss: 0.442546\tAccuracy: 90.30%\n",
      "57\tValidation loss: 0.496274\tBest loss: 0.442546\tAccuracy: 92.40%\n",
      "58\tValidation loss: 0.570649\tBest loss: 0.442546\tAccuracy: 91.30%\n",
      "59\tValidation loss: 0.518469\tBest loss: 0.442546\tAccuracy: 91.20%\n",
      "60\tValidation loss: 0.608222\tBest loss: 0.442546\tAccuracy: 90.70%\n",
      "61\tValidation loss: 0.531982\tBest loss: 0.442546\tAccuracy: 91.80%\n",
      "62\tValidation loss: 0.525807\tBest loss: 0.442546\tAccuracy: 92.10%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   6.2s\n",
      "[CV] batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01 \n",
      "0\tValidation loss: 3.177759\tBest loss: 3.177759\tAccuracy: 18.20%\n",
      "1\tValidation loss: 2.150854\tBest loss: 2.150854\tAccuracy: 47.90%\n",
      "2\tValidation loss: 1.508851\tBest loss: 1.508851\tAccuracy: 64.30%\n",
      "3\tValidation loss: 1.355716\tBest loss: 1.355716\tAccuracy: 63.40%\n",
      "4\tValidation loss: 1.038595\tBest loss: 1.038595\tAccuracy: 75.00%\n",
      "5\tValidation loss: 1.053998\tBest loss: 1.038595\tAccuracy: 75.00%\n",
      "6\tValidation loss: 0.993379\tBest loss: 0.993379\tAccuracy: 74.80%\n",
      "7\tValidation loss: 0.734985\tBest loss: 0.734985\tAccuracy: 82.20%\n",
      "8\tValidation loss: 0.714399\tBest loss: 0.714399\tAccuracy: 81.90%\n",
      "9\tValidation loss: 0.738915\tBest loss: 0.714399\tAccuracy: 83.30%\n",
      "10\tValidation loss: 0.657040\tBest loss: 0.657040\tAccuracy: 84.70%\n",
      "11\tValidation loss: 0.652608\tBest loss: 0.652608\tAccuracy: 84.90%\n",
      "12\tValidation loss: 0.563484\tBest loss: 0.563484\tAccuracy: 86.70%\n",
      "13\tValidation loss: 0.632500\tBest loss: 0.563484\tAccuracy: 83.40%\n",
      "14\tValidation loss: 0.516388\tBest loss: 0.516388\tAccuracy: 87.10%\n",
      "15\tValidation loss: 0.540163\tBest loss: 0.516388\tAccuracy: 87.60%\n",
      "16\tValidation loss: 0.498138\tBest loss: 0.498138\tAccuracy: 87.80%\n",
      "17\tValidation loss: 0.533365\tBest loss: 0.498138\tAccuracy: 86.40%\n",
      "18\tValidation loss: 0.520556\tBest loss: 0.498138\tAccuracy: 87.70%\n",
      "19\tValidation loss: 0.524140\tBest loss: 0.498138\tAccuracy: 86.70%\n",
      "20\tValidation loss: 0.513427\tBest loss: 0.498138\tAccuracy: 87.00%\n",
      "21\tValidation loss: 0.453448\tBest loss: 0.453448\tAccuracy: 89.90%\n",
      "22\tValidation loss: 0.502101\tBest loss: 0.453448\tAccuracy: 87.70%\n",
      "23\tValidation loss: 0.490096\tBest loss: 0.453448\tAccuracy: 89.20%\n",
      "24\tValidation loss: 0.451882\tBest loss: 0.451882\tAccuracy: 89.20%\n",
      "25\tValidation loss: 0.502215\tBest loss: 0.451882\tAccuracy: 89.70%\n",
      "26\tValidation loss: 0.476188\tBest loss: 0.451882\tAccuracy: 89.00%\n",
      "27\tValidation loss: 0.441260\tBest loss: 0.441260\tAccuracy: 89.70%\n",
      "28\tValidation loss: 0.442598\tBest loss: 0.441260\tAccuracy: 89.80%\n",
      "29\tValidation loss: 0.513807\tBest loss: 0.441260\tAccuracy: 87.40%\n",
      "30\tValidation loss: 0.398161\tBest loss: 0.398161\tAccuracy: 91.70%\n",
      "31\tValidation loss: 0.441026\tBest loss: 0.398161\tAccuracy: 90.30%\n",
      "32\tValidation loss: 0.460735\tBest loss: 0.398161\tAccuracy: 89.70%\n",
      "33\tValidation loss: 0.474450\tBest loss: 0.398161\tAccuracy: 90.10%\n",
      "34\tValidation loss: 0.431554\tBest loss: 0.398161\tAccuracy: 90.10%\n",
      "35\tValidation loss: 0.404693\tBest loss: 0.398161\tAccuracy: 91.00%\n",
      "36\tValidation loss: 0.401204\tBest loss: 0.398161\tAccuracy: 91.00%\n",
      "37\tValidation loss: 0.428183\tBest loss: 0.398161\tAccuracy: 90.00%\n",
      "38\tValidation loss: 0.443114\tBest loss: 0.398161\tAccuracy: 89.90%\n",
      "39\tValidation loss: 0.444089\tBest loss: 0.398161\tAccuracy: 91.40%\n",
      "40\tValidation loss: 0.436879\tBest loss: 0.398161\tAccuracy: 90.20%\n",
      "41\tValidation loss: 0.412140\tBest loss: 0.398161\tAccuracy: 91.90%\n",
      "42\tValidation loss: 0.394822\tBest loss: 0.394822\tAccuracy: 91.50%\n",
      "43\tValidation loss: 0.422896\tBest loss: 0.394822\tAccuracy: 90.30%\n",
      "44\tValidation loss: 0.424002\tBest loss: 0.394822\tAccuracy: 91.10%\n",
      "45\tValidation loss: 0.448061\tBest loss: 0.394822\tAccuracy: 91.30%\n",
      "46\tValidation loss: 0.478215\tBest loss: 0.394822\tAccuracy: 90.70%\n",
      "47\tValidation loss: 0.457370\tBest loss: 0.394822\tAccuracy: 90.70%\n",
      "48\tValidation loss: 0.420715\tBest loss: 0.394822\tAccuracy: 91.80%\n",
      "49\tValidation loss: 0.413368\tBest loss: 0.394822\tAccuracy: 92.10%\n",
      "50\tValidation loss: 0.446365\tBest loss: 0.394822\tAccuracy: 91.40%\n",
      "51\tValidation loss: 0.423989\tBest loss: 0.394822\tAccuracy: 91.70%\n",
      "52\tValidation loss: 0.413105\tBest loss: 0.394822\tAccuracy: 91.60%\n",
      "53\tValidation loss: 0.423844\tBest loss: 0.394822\tAccuracy: 91.40%\n",
      "54\tValidation loss: 0.395352\tBest loss: 0.394822\tAccuracy: 92.90%\n",
      "55\tValidation loss: 0.400809\tBest loss: 0.394822\tAccuracy: 92.50%\n",
      "56\tValidation loss: 0.393277\tBest loss: 0.393277\tAccuracy: 91.90%\n",
      "57\tValidation loss: 0.472830\tBest loss: 0.393277\tAccuracy: 90.40%\n",
      "58\tValidation loss: 0.405750\tBest loss: 0.393277\tAccuracy: 91.30%\n",
      "59\tValidation loss: 0.470404\tBest loss: 0.393277\tAccuracy: 92.40%\n",
      "60\tValidation loss: 0.441259\tBest loss: 0.393277\tAccuracy: 91.70%\n",
      "61\tValidation loss: 0.449187\tBest loss: 0.393277\tAccuracy: 92.00%\n",
      "62\tValidation loss: 0.466687\tBest loss: 0.393277\tAccuracy: 91.10%\n",
      "63\tValidation loss: 0.405700\tBest loss: 0.393277\tAccuracy: 92.40%\n",
      "64\tValidation loss: 0.408493\tBest loss: 0.393277\tAccuracy: 93.10%\n",
      "65\tValidation loss: 0.407914\tBest loss: 0.393277\tAccuracy: 93.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\tValidation loss: 0.452122\tBest loss: 0.393277\tAccuracy: 91.70%\n",
      "67\tValidation loss: 0.473321\tBest loss: 0.393277\tAccuracy: 91.70%\n",
      "68\tValidation loss: 0.391634\tBest loss: 0.391634\tAccuracy: 93.30%\n",
      "69\tValidation loss: 0.498258\tBest loss: 0.391634\tAccuracy: 92.30%\n",
      "70\tValidation loss: 0.420839\tBest loss: 0.391634\tAccuracy: 93.00%\n",
      "71\tValidation loss: 0.430697\tBest loss: 0.391634\tAccuracy: 93.20%\n",
      "72\tValidation loss: 0.432297\tBest loss: 0.391634\tAccuracy: 92.10%\n",
      "73\tValidation loss: 0.454306\tBest loss: 0.391634\tAccuracy: 92.20%\n",
      "74\tValidation loss: 0.445767\tBest loss: 0.391634\tAccuracy: 92.70%\n",
      "75\tValidation loss: 0.462814\tBest loss: 0.391634\tAccuracy: 92.80%\n",
      "76\tValidation loss: 0.421339\tBest loss: 0.391634\tAccuracy: 93.20%\n",
      "77\tValidation loss: 0.471250\tBest loss: 0.391634\tAccuracy: 91.80%\n",
      "78\tValidation loss: 0.446050\tBest loss: 0.391634\tAccuracy: 93.00%\n",
      "79\tValidation loss: 0.446310\tBest loss: 0.391634\tAccuracy: 92.50%\n",
      "80\tValidation loss: 0.488156\tBest loss: 0.391634\tAccuracy: 92.50%\n",
      "81\tValidation loss: 0.483232\tBest loss: 0.391634\tAccuracy: 92.90%\n",
      "82\tValidation loss: 0.435762\tBest loss: 0.391634\tAccuracy: 93.10%\n",
      "83\tValidation loss: 0.476665\tBest loss: 0.391634\tAccuracy: 92.60%\n",
      "84\tValidation loss: 0.468608\tBest loss: 0.391634\tAccuracy: 92.70%\n",
      "85\tValidation loss: 0.469611\tBest loss: 0.391634\tAccuracy: 92.40%\n",
      "86\tValidation loss: 0.474983\tBest loss: 0.391634\tAccuracy: 92.00%\n",
      "87\tValidation loss: 0.457642\tBest loss: 0.391634\tAccuracy: 92.30%\n",
      "88\tValidation loss: 0.468055\tBest loss: 0.391634\tAccuracy: 93.00%\n",
      "89\tValidation loss: 0.432652\tBest loss: 0.391634\tAccuracy: 92.80%\n",
      "Early stopping!\n",
      "[CV]  batch_size=500, n_neurons=300, n_hidden_layers=0, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.01, total=   8.9s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 3.815727\tBest loss: 3.815727\tAccuracy: 8.30%\n",
      "1\tValidation loss: 12.979217\tBest loss: 3.815727\tAccuracy: 17.00%\n",
      "2\tValidation loss: 5.187192\tBest loss: 3.815727\tAccuracy: 51.80%\n",
      "3\tValidation loss: 2.817537\tBest loss: 2.817537\tAccuracy: 58.50%\n",
      "4\tValidation loss: 3.419271\tBest loss: 2.817537\tAccuracy: 67.00%\n",
      "5\tValidation loss: 4.848673\tBest loss: 2.817537\tAccuracy: 60.00%\n",
      "6\tValidation loss: 4.807393\tBest loss: 2.817537\tAccuracy: 70.70%\n",
      "7\tValidation loss: 16.646353\tBest loss: 2.817537\tAccuracy: 54.10%\n",
      "8\tValidation loss: 3.317581\tBest loss: 2.817537\tAccuracy: 76.40%\n",
      "9\tValidation loss: 4.266595\tBest loss: 2.817537\tAccuracy: 74.40%\n",
      "10\tValidation loss: 11.285583\tBest loss: 2.817537\tAccuracy: 64.70%\n",
      "11\tValidation loss: 8.637410\tBest loss: 2.817537\tAccuracy: 73.70%\n",
      "12\tValidation loss: 11.717565\tBest loss: 2.817537\tAccuracy: 73.90%\n",
      "13\tValidation loss: 4.892077\tBest loss: 2.817537\tAccuracy: 77.80%\n",
      "14\tValidation loss: 4.739058\tBest loss: 2.817537\tAccuracy: 81.70%\n",
      "15\tValidation loss: 5.840101\tBest loss: 2.817537\tAccuracy: 80.40%\n",
      "16\tValidation loss: 7.144329\tBest loss: 2.817537\tAccuracy: 82.30%\n",
      "17\tValidation loss: 6.129822\tBest loss: 2.817537\tAccuracy: 81.30%\n",
      "18\tValidation loss: 5.049498\tBest loss: 2.817537\tAccuracy: 84.00%\n",
      "19\tValidation loss: 4.236166\tBest loss: 2.817537\tAccuracy: 85.40%\n",
      "20\tValidation loss: 4.997572\tBest loss: 2.817537\tAccuracy: 85.00%\n",
      "21\tValidation loss: 4.583184\tBest loss: 2.817537\tAccuracy: 86.30%\n",
      "22\tValidation loss: 7.810505\tBest loss: 2.817537\tAccuracy: 83.10%\n",
      "23\tValidation loss: 6.886544\tBest loss: 2.817537\tAccuracy: 84.90%\n",
      "24\tValidation loss: 5.783023\tBest loss: 2.817537\tAccuracy: 87.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   3.6s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 8.743588\tBest loss: 8.743588\tAccuracy: 3.10%\n",
      "1\tValidation loss: 7.232898\tBest loss: 7.232898\tAccuracy: 22.90%\n",
      "2\tValidation loss: 2.513266\tBest loss: 2.513266\tAccuracy: 52.20%\n",
      "3\tValidation loss: 4.224656\tBest loss: 2.513266\tAccuracy: 60.00%\n",
      "4\tValidation loss: 7.373429\tBest loss: 2.513266\tAccuracy: 54.70%\n",
      "5\tValidation loss: 2.786917\tBest loss: 2.513266\tAccuracy: 70.30%\n",
      "6\tValidation loss: 10.404744\tBest loss: 2.513266\tAccuracy: 55.40%\n",
      "7\tValidation loss: 2.854108\tBest loss: 2.513266\tAccuracy: 78.20%\n",
      "8\tValidation loss: 4.678905\tBest loss: 2.513266\tAccuracy: 76.70%\n",
      "9\tValidation loss: 4.696397\tBest loss: 2.513266\tAccuracy: 72.90%\n",
      "10\tValidation loss: 11.960786\tBest loss: 2.513266\tAccuracy: 70.10%\n",
      "11\tValidation loss: 4.451636\tBest loss: 2.513266\tAccuracy: 76.80%\n",
      "12\tValidation loss: 25.469080\tBest loss: 2.513266\tAccuracy: 61.70%\n",
      "13\tValidation loss: 5.088923\tBest loss: 2.513266\tAccuracy: 79.10%\n",
      "14\tValidation loss: 3.688109\tBest loss: 2.513266\tAccuracy: 80.80%\n",
      "15\tValidation loss: 3.417362\tBest loss: 2.513266\tAccuracy: 80.40%\n",
      "16\tValidation loss: 6.002780\tBest loss: 2.513266\tAccuracy: 78.70%\n",
      "17\tValidation loss: 5.834482\tBest loss: 2.513266\tAccuracy: 80.50%\n",
      "18\tValidation loss: 6.110690\tBest loss: 2.513266\tAccuracy: 82.50%\n",
      "19\tValidation loss: 7.230031\tBest loss: 2.513266\tAccuracy: 82.50%\n",
      "20\tValidation loss: 10.571149\tBest loss: 2.513266\tAccuracy: 80.00%\n",
      "21\tValidation loss: 10.830133\tBest loss: 2.513266\tAccuracy: 80.50%\n",
      "22\tValidation loss: 12.982575\tBest loss: 2.513266\tAccuracy: 76.70%\n",
      "23\tValidation loss: 5.133229\tBest loss: 2.513266\tAccuracy: 86.60%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   3.6s\n",
      "[CV] batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 5.411203\tBest loss: 5.411203\tAccuracy: 4.00%\n",
      "1\tValidation loss: 10.814868\tBest loss: 5.411203\tAccuracy: 17.10%\n",
      "2\tValidation loss: 6.169714\tBest loss: 5.411203\tAccuracy: 40.90%\n",
      "3\tValidation loss: 15.523964\tBest loss: 5.411203\tAccuracy: 39.30%\n",
      "4\tValidation loss: 9.053132\tBest loss: 5.411203\tAccuracy: 55.20%\n",
      "5\tValidation loss: 3.910065\tBest loss: 3.910065\tAccuracy: 69.00%\n",
      "6\tValidation loss: 7.992362\tBest loss: 3.910065\tAccuracy: 62.90%\n",
      "7\tValidation loss: 6.794199\tBest loss: 3.910065\tAccuracy: 70.20%\n",
      "8\tValidation loss: 5.304641\tBest loss: 3.910065\tAccuracy: 69.90%\n",
      "9\tValidation loss: 14.514820\tBest loss: 3.910065\tAccuracy: 59.60%\n",
      "10\tValidation loss: 4.608543\tBest loss: 3.910065\tAccuracy: 78.10%\n",
      "11\tValidation loss: 5.352620\tBest loss: 3.910065\tAccuracy: 82.00%\n",
      "12\tValidation loss: 4.308719\tBest loss: 3.910065\tAccuracy: 80.90%\n",
      "13\tValidation loss: 6.995044\tBest loss: 3.910065\tAccuracy: 77.50%\n",
      "14\tValidation loss: 5.805781\tBest loss: 3.910065\tAccuracy: 77.90%\n",
      "15\tValidation loss: 8.217350\tBest loss: 3.910065\tAccuracy: 76.80%\n",
      "16\tValidation loss: 6.563177\tBest loss: 3.910065\tAccuracy: 80.20%\n",
      "17\tValidation loss: 8.468362\tBest loss: 3.910065\tAccuracy: 83.80%\n",
      "18\tValidation loss: 4.419533\tBest loss: 3.910065\tAccuracy: 86.70%\n",
      "19\tValidation loss: 7.338349\tBest loss: 3.910065\tAccuracy: 83.90%\n",
      "20\tValidation loss: 4.602157\tBest loss: 3.910065\tAccuracy: 86.20%\n",
      "21\tValidation loss: 11.705658\tBest loss: 3.910065\tAccuracy: 79.10%\n",
      "22\tValidation loss: 9.434252\tBest loss: 3.910065\tAccuracy: 83.70%\n",
      "23\tValidation loss: 5.253929\tBest loss: 3.910065\tAccuracy: 86.90%\n",
      "24\tValidation loss: 6.896847\tBest loss: 3.910065\tAccuracy: 85.50%\n",
      "25\tValidation loss: 7.831090\tBest loss: 3.910065\tAccuracy: 87.80%\n",
      "26\tValidation loss: 8.669091\tBest loss: 3.910065\tAccuracy: 86.40%\n",
      "Early stopping!\n",
      "[CV]  batch_size=200, n_neurons=200, n_hidden_layers=1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, learning_rate=0.05, total=   3.9s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 8.234871\tBest loss: 8.234871\tAccuracy: 5.50%\n",
      "1\tValidation loss: 2.953103\tBest loss: 2.953103\tAccuracy: 27.40%\n",
      "2\tValidation loss: 1.882092\tBest loss: 1.882092\tAccuracy: 43.00%\n",
      "3\tValidation loss: 1.777270\tBest loss: 1.777270\tAccuracy: 51.30%\n",
      "4\tValidation loss: 1.664680\tBest loss: 1.664680\tAccuracy: 58.30%\n",
      "5\tValidation loss: 1.467994\tBest loss: 1.467994\tAccuracy: 63.30%\n",
      "6\tValidation loss: 1.543236\tBest loss: 1.467994\tAccuracy: 62.90%\n",
      "7\tValidation loss: 1.421731\tBest loss: 1.421731\tAccuracy: 67.30%\n",
      "8\tValidation loss: 1.419189\tBest loss: 1.419189\tAccuracy: 69.10%\n",
      "9\tValidation loss: 1.524882\tBest loss: 1.419189\tAccuracy: 70.30%\n",
      "10\tValidation loss: 1.339419\tBest loss: 1.339419\tAccuracy: 73.30%\n",
      "11\tValidation loss: 1.273983\tBest loss: 1.273983\tAccuracy: 72.50%\n",
      "12\tValidation loss: 1.607498\tBest loss: 1.273983\tAccuracy: 72.10%\n",
      "13\tValidation loss: 1.566836\tBest loss: 1.273983\tAccuracy: 72.40%\n",
      "14\tValidation loss: 1.690083\tBest loss: 1.273983\tAccuracy: 70.70%\n",
      "15\tValidation loss: 1.646058\tBest loss: 1.273983\tAccuracy: 74.10%\n",
      "16\tValidation loss: 1.638523\tBest loss: 1.273983\tAccuracy: 75.40%\n",
      "17\tValidation loss: 1.751285\tBest loss: 1.273983\tAccuracy: 73.60%\n",
      "18\tValidation loss: 1.881626\tBest loss: 1.273983\tAccuracy: 74.40%\n",
      "19\tValidation loss: 1.766272\tBest loss: 1.273983\tAccuracy: 73.00%\n",
      "20\tValidation loss: 2.018946\tBest loss: 1.273983\tAccuracy: 74.00%\n",
      "21\tValidation loss: 1.837341\tBest loss: 1.273983\tAccuracy: 74.40%\n",
      "22\tValidation loss: 1.820013\tBest loss: 1.273983\tAccuracy: 76.20%\n",
      "23\tValidation loss: 1.771620\tBest loss: 1.273983\tAccuracy: 77.80%\n",
      "24\tValidation loss: 2.198237\tBest loss: 1.273983\tAccuracy: 74.00%\n",
      "25\tValidation loss: 1.885965\tBest loss: 1.273983\tAccuracy: 77.80%\n",
      "26\tValidation loss: 2.012130\tBest loss: 1.273983\tAccuracy: 76.30%\n",
      "27\tValidation loss: 2.331919\tBest loss: 1.273983\tAccuracy: 76.50%\n",
      "28\tValidation loss: 2.102075\tBest loss: 1.273983\tAccuracy: 78.10%\n",
      "29\tValidation loss: 2.520913\tBest loss: 1.273983\tAccuracy: 74.40%\n",
      "30\tValidation loss: 2.101362\tBest loss: 1.273983\tAccuracy: 81.10%\n",
      "31\tValidation loss: 2.621722\tBest loss: 1.273983\tAccuracy: 75.70%\n",
      "32\tValidation loss: 2.468043\tBest loss: 1.273983\tAccuracy: 78.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.5s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 10.148648\tBest loss: 10.148648\tAccuracy: 9.20%\n",
      "1\tValidation loss: 3.526404\tBest loss: 3.526404\tAccuracy: 19.60%\n",
      "2\tValidation loss: 2.272954\tBest loss: 2.272954\tAccuracy: 36.80%\n",
      "3\tValidation loss: 2.288161\tBest loss: 2.272954\tAccuracy: 47.80%\n",
      "4\tValidation loss: 1.836716\tBest loss: 1.836716\tAccuracy: 53.40%\n",
      "5\tValidation loss: 1.716143\tBest loss: 1.716143\tAccuracy: 56.50%\n",
      "6\tValidation loss: 1.557245\tBest loss: 1.557245\tAccuracy: 60.30%\n",
      "7\tValidation loss: 1.561491\tBest loss: 1.557245\tAccuracy: 63.70%\n",
      "8\tValidation loss: 1.714347\tBest loss: 1.557245\tAccuracy: 63.10%\n",
      "9\tValidation loss: 1.484975\tBest loss: 1.484975\tAccuracy: 65.20%\n",
      "10\tValidation loss: 1.656534\tBest loss: 1.484975\tAccuracy: 62.10%\n",
      "11\tValidation loss: 1.720471\tBest loss: 1.484975\tAccuracy: 62.60%\n",
      "12\tValidation loss: 1.633686\tBest loss: 1.484975\tAccuracy: 65.60%\n",
      "13\tValidation loss: 1.490757\tBest loss: 1.484975\tAccuracy: 72.50%\n",
      "14\tValidation loss: 1.490611\tBest loss: 1.484975\tAccuracy: 70.10%\n",
      "15\tValidation loss: 1.613111\tBest loss: 1.484975\tAccuracy: 68.10%\n",
      "16\tValidation loss: 1.717056\tBest loss: 1.484975\tAccuracy: 69.60%\n",
      "17\tValidation loss: 1.779461\tBest loss: 1.484975\tAccuracy: 69.20%\n",
      "18\tValidation loss: 1.706577\tBest loss: 1.484975\tAccuracy: 70.50%\n",
      "19\tValidation loss: 2.006152\tBest loss: 1.484975\tAccuracy: 65.90%\n",
      "20\tValidation loss: 2.426723\tBest loss: 1.484975\tAccuracy: 64.60%\n",
      "21\tValidation loss: 1.796378\tBest loss: 1.484975\tAccuracy: 71.50%\n",
      "22\tValidation loss: 1.595364\tBest loss: 1.484975\tAccuracy: 72.30%\n",
      "23\tValidation loss: 1.932923\tBest loss: 1.484975\tAccuracy: 68.90%\n",
      "24\tValidation loss: 2.018400\tBest loss: 1.484975\tAccuracy: 69.20%\n",
      "25\tValidation loss: 1.908201\tBest loss: 1.484975\tAccuracy: 70.70%\n",
      "26\tValidation loss: 2.050834\tBest loss: 1.484975\tAccuracy: 72.40%\n",
      "27\tValidation loss: 1.937621\tBest loss: 1.484975\tAccuracy: 70.40%\n",
      "28\tValidation loss: 2.122049\tBest loss: 1.484975\tAccuracy: 69.10%\n",
      "29\tValidation loss: 1.948357\tBest loss: 1.484975\tAccuracy: 73.20%\n",
      "30\tValidation loss: 1.791334\tBest loss: 1.484975\tAccuracy: 73.50%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.4s\n",
      "[CV] batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05 \n",
      "0\tValidation loss: 10.135694\tBest loss: 10.135694\tAccuracy: 5.60%\n",
      "1\tValidation loss: 3.604992\tBest loss: 3.604992\tAccuracy: 23.30%\n",
      "2\tValidation loss: 1.981546\tBest loss: 1.981546\tAccuracy: 46.80%\n",
      "3\tValidation loss: 1.472641\tBest loss: 1.472641\tAccuracy: 57.10%\n",
      "4\tValidation loss: 1.516387\tBest loss: 1.472641\tAccuracy: 60.20%\n",
      "5\tValidation loss: 1.392822\tBest loss: 1.392822\tAccuracy: 62.30%\n",
      "6\tValidation loss: 1.452034\tBest loss: 1.392822\tAccuracy: 63.30%\n",
      "7\tValidation loss: 1.454561\tBest loss: 1.392822\tAccuracy: 67.30%\n",
      "8\tValidation loss: 1.518317\tBest loss: 1.392822\tAccuracy: 65.00%\n",
      "9\tValidation loss: 1.510222\tBest loss: 1.392822\tAccuracy: 66.60%\n",
      "10\tValidation loss: 1.253384\tBest loss: 1.253384\tAccuracy: 72.60%\n",
      "11\tValidation loss: 1.362331\tBest loss: 1.253384\tAccuracy: 69.80%\n",
      "12\tValidation loss: 1.383169\tBest loss: 1.253384\tAccuracy: 72.60%\n",
      "13\tValidation loss: 1.521505\tBest loss: 1.253384\tAccuracy: 70.10%\n",
      "14\tValidation loss: 1.504006\tBest loss: 1.253384\tAccuracy: 69.10%\n",
      "15\tValidation loss: 1.680385\tBest loss: 1.253384\tAccuracy: 70.40%\n",
      "16\tValidation loss: 1.682173\tBest loss: 1.253384\tAccuracy: 70.30%\n",
      "17\tValidation loss: 1.460143\tBest loss: 1.253384\tAccuracy: 74.10%\n",
      "18\tValidation loss: 1.318078\tBest loss: 1.253384\tAccuracy: 75.70%\n",
      "19\tValidation loss: 1.649570\tBest loss: 1.253384\tAccuracy: 73.10%\n",
      "20\tValidation loss: 1.598819\tBest loss: 1.253384\tAccuracy: 74.20%\n",
      "21\tValidation loss: 1.771615\tBest loss: 1.253384\tAccuracy: 72.50%\n",
      "22\tValidation loss: 1.714416\tBest loss: 1.253384\tAccuracy: 73.10%\n",
      "23\tValidation loss: 1.616424\tBest loss: 1.253384\tAccuracy: 74.80%\n",
      "24\tValidation loss: 1.725733\tBest loss: 1.253384\tAccuracy: 75.50%\n",
      "25\tValidation loss: 1.732466\tBest loss: 1.253384\tAccuracy: 74.90%\n",
      "26\tValidation loss: 2.022337\tBest loss: 1.253384\tAccuracy: 73.20%\n",
      "27\tValidation loss: 2.207348\tBest loss: 1.253384\tAccuracy: 73.40%\n",
      "28\tValidation loss: 1.929607\tBest loss: 1.253384\tAccuracy: 77.90%\n",
      "29\tValidation loss: 1.795875\tBest loss: 1.253384\tAccuracy: 76.90%\n",
      "30\tValidation loss: 1.959437\tBest loss: 1.253384\tAccuracy: 76.70%\n",
      "31\tValidation loss: 2.257445\tBest loss: 1.253384\tAccuracy: 72.90%\n",
      "Early stopping!\n",
      "[CV]  batch_size=350, n_neurons=400, n_hidden_layers=1, activation=<function elu at 0x0000024C467CE9D8>, optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, learning_rate=0.05, total=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 52.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.017751\tBest loss: 1.017751\tAccuracy: 73.80%\n",
      "1\tValidation loss: 0.759048\tBest loss: 0.759048\tAccuracy: 78.30%\n",
      "2\tValidation loss: 0.605772\tBest loss: 0.605772\tAccuracy: 83.70%\n",
      "3\tValidation loss: 0.530820\tBest loss: 0.530820\tAccuracy: 85.80%\n",
      "4\tValidation loss: 0.490443\tBest loss: 0.490443\tAccuracy: 87.10%\n",
      "5\tValidation loss: 0.462824\tBest loss: 0.462824\tAccuracy: 88.60%\n",
      "6\tValidation loss: 0.431637\tBest loss: 0.431637\tAccuracy: 89.00%\n",
      "7\tValidation loss: 0.407250\tBest loss: 0.407250\tAccuracy: 89.80%\n",
      "8\tValidation loss: 0.382651\tBest loss: 0.382651\tAccuracy: 90.30%\n",
      "9\tValidation loss: 0.391382\tBest loss: 0.382651\tAccuracy: 88.70%\n",
      "10\tValidation loss: 0.353714\tBest loss: 0.353714\tAccuracy: 90.00%\n",
      "11\tValidation loss: 0.343007\tBest loss: 0.343007\tAccuracy: 91.60%\n",
      "12\tValidation loss: 0.327276\tBest loss: 0.327276\tAccuracy: 91.20%\n",
      "13\tValidation loss: 0.318505\tBest loss: 0.318505\tAccuracy: 91.90%\n",
      "14\tValidation loss: 0.311519\tBest loss: 0.311519\tAccuracy: 91.70%\n",
      "15\tValidation loss: 0.296472\tBest loss: 0.296472\tAccuracy: 91.90%\n",
      "16\tValidation loss: 0.292539\tBest loss: 0.292539\tAccuracy: 92.60%\n",
      "17\tValidation loss: 0.296287\tBest loss: 0.292539\tAccuracy: 91.90%\n",
      "18\tValidation loss: 0.277911\tBest loss: 0.277911\tAccuracy: 92.20%\n",
      "19\tValidation loss: 0.275781\tBest loss: 0.275781\tAccuracy: 92.60%\n",
      "20\tValidation loss: 0.257931\tBest loss: 0.257931\tAccuracy: 92.90%\n",
      "21\tValidation loss: 0.256095\tBest loss: 0.256095\tAccuracy: 93.10%\n",
      "22\tValidation loss: 0.264851\tBest loss: 0.256095\tAccuracy: 92.70%\n",
      "23\tValidation loss: 0.245614\tBest loss: 0.245614\tAccuracy: 93.20%\n",
      "24\tValidation loss: 0.248399\tBest loss: 0.245614\tAccuracy: 93.10%\n",
      "25\tValidation loss: 0.245731\tBest loss: 0.245614\tAccuracy: 93.90%\n",
      "26\tValidation loss: 0.235747\tBest loss: 0.235747\tAccuracy: 93.20%\n",
      "27\tValidation loss: 0.229354\tBest loss: 0.229354\tAccuracy: 94.30%\n",
      "28\tValidation loss: 0.230755\tBest loss: 0.229354\tAccuracy: 93.70%\n",
      "29\tValidation loss: 0.218238\tBest loss: 0.218238\tAccuracy: 94.60%\n",
      "30\tValidation loss: 0.218473\tBest loss: 0.218238\tAccuracy: 94.30%\n",
      "31\tValidation loss: 0.219325\tBest loss: 0.218238\tAccuracy: 94.90%\n",
      "32\tValidation loss: 0.221177\tBest loss: 0.218238\tAccuracy: 94.50%\n",
      "33\tValidation loss: 0.211903\tBest loss: 0.211903\tAccuracy: 94.70%\n",
      "34\tValidation loss: 0.207300\tBest loss: 0.207300\tAccuracy: 95.20%\n",
      "35\tValidation loss: 0.207544\tBest loss: 0.207300\tAccuracy: 94.90%\n",
      "36\tValidation loss: 0.202793\tBest loss: 0.202793\tAccuracy: 95.10%\n",
      "37\tValidation loss: 0.197842\tBest loss: 0.197842\tAccuracy: 94.90%\n",
      "38\tValidation loss: 0.201648\tBest loss: 0.197842\tAccuracy: 95.40%\n",
      "39\tValidation loss: 0.194889\tBest loss: 0.194889\tAccuracy: 95.20%\n",
      "40\tValidation loss: 0.198057\tBest loss: 0.194889\tAccuracy: 95.00%\n",
      "41\tValidation loss: 0.196782\tBest loss: 0.194889\tAccuracy: 95.10%\n",
      "42\tValidation loss: 0.192619\tBest loss: 0.192619\tAccuracy: 95.80%\n",
      "43\tValidation loss: 0.192405\tBest loss: 0.192405\tAccuracy: 95.50%\n",
      "44\tValidation loss: 0.187672\tBest loss: 0.187672\tAccuracy: 95.60%\n",
      "45\tValidation loss: 0.188268\tBest loss: 0.187672\tAccuracy: 95.70%\n",
      "46\tValidation loss: 0.188804\tBest loss: 0.187672\tAccuracy: 95.70%\n",
      "47\tValidation loss: 0.182087\tBest loss: 0.182087\tAccuracy: 95.80%\n",
      "48\tValidation loss: 0.185427\tBest loss: 0.182087\tAccuracy: 95.50%\n",
      "49\tValidation loss: 0.180272\tBest loss: 0.180272\tAccuracy: 95.90%\n",
      "50\tValidation loss: 0.180368\tBest loss: 0.180272\tAccuracy: 95.60%\n",
      "51\tValidation loss: 0.179154\tBest loss: 0.179154\tAccuracy: 95.70%\n",
      "52\tValidation loss: 0.177859\tBest loss: 0.177859\tAccuracy: 96.40%\n",
      "53\tValidation loss: 0.181942\tBest loss: 0.177859\tAccuracy: 95.70%\n",
      "54\tValidation loss: 0.181257\tBest loss: 0.177859\tAccuracy: 95.70%\n",
      "55\tValidation loss: 0.183117\tBest loss: 0.177859\tAccuracy: 95.80%\n",
      "56\tValidation loss: 0.176187\tBest loss: 0.176187\tAccuracy: 96.20%\n",
      "57\tValidation loss: 0.178956\tBest loss: 0.176187\tAccuracy: 96.00%\n",
      "58\tValidation loss: 0.181938\tBest loss: 0.176187\tAccuracy: 95.90%\n",
      "59\tValidation loss: 0.183789\tBest loss: 0.176187\tAccuracy: 95.90%\n",
      "60\tValidation loss: 0.178187\tBest loss: 0.176187\tAccuracy: 96.00%\n",
      "61\tValidation loss: 0.178557\tBest loss: 0.176187\tAccuracy: 96.00%\n",
      "62\tValidation loss: 0.178006\tBest loss: 0.176187\tAccuracy: 96.20%\n",
      "63\tValidation loss: 0.175333\tBest loss: 0.175333\tAccuracy: 96.50%\n",
      "64\tValidation loss: 0.179528\tBest loss: 0.175333\tAccuracy: 96.60%\n",
      "65\tValidation loss: 0.173976\tBest loss: 0.173976\tAccuracy: 96.10%\n",
      "66\tValidation loss: 0.175613\tBest loss: 0.173976\tAccuracy: 96.60%\n",
      "67\tValidation loss: 0.175082\tBest loss: 0.173976\tAccuracy: 96.10%\n",
      "68\tValidation loss: 0.173494\tBest loss: 0.173494\tAccuracy: 96.30%\n",
      "69\tValidation loss: 0.179435\tBest loss: 0.173494\tAccuracy: 96.30%\n",
      "70\tValidation loss: 0.173612\tBest loss: 0.173494\tAccuracy: 96.50%\n",
      "71\tValidation loss: 0.172733\tBest loss: 0.172733\tAccuracy: 96.20%\n",
      "72\tValidation loss: 0.171095\tBest loss: 0.171095\tAccuracy: 96.60%\n",
      "73\tValidation loss: 0.171990\tBest loss: 0.171095\tAccuracy: 96.50%\n",
      "74\tValidation loss: 0.175490\tBest loss: 0.171095\tAccuracy: 96.80%\n",
      "75\tValidation loss: 0.170808\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "76\tValidation loss: 0.174039\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "77\tValidation loss: 0.178370\tBest loss: 0.170808\tAccuracy: 96.50%\n",
      "78\tValidation loss: 0.174956\tBest loss: 0.170808\tAccuracy: 96.70%\n",
      "79\tValidation loss: 0.173909\tBest loss: 0.170808\tAccuracy: 96.40%\n",
      "80\tValidation loss: 0.174109\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "81\tValidation loss: 0.174584\tBest loss: 0.170808\tAccuracy: 96.80%\n",
      "82\tValidation loss: 0.175861\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "83\tValidation loss: 0.178502\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "84\tValidation loss: 0.172617\tBest loss: 0.170808\tAccuracy: 96.80%\n",
      "85\tValidation loss: 0.175773\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "86\tValidation loss: 0.176040\tBest loss: 0.170808\tAccuracy: 96.80%\n",
      "87\tValidation loss: 0.173121\tBest loss: 0.170808\tAccuracy: 96.70%\n",
      "88\tValidation loss: 0.180845\tBest loss: 0.170808\tAccuracy: 96.40%\n",
      "89\tValidation loss: 0.177256\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "90\tValidation loss: 0.176588\tBest loss: 0.170808\tAccuracy: 96.70%\n",
      "91\tValidation loss: 0.178674\tBest loss: 0.170808\tAccuracy: 96.50%\n",
      "92\tValidation loss: 0.178260\tBest loss: 0.170808\tAccuracy: 96.80%\n",
      "93\tValidation loss: 0.177879\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "94\tValidation loss: 0.182526\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "95\tValidation loss: 0.180871\tBest loss: 0.170808\tAccuracy: 96.50%\n",
      "96\tValidation loss: 0.180798\tBest loss: 0.170808\tAccuracy: 96.60%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x0000024C467CE9D8>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x0000024C512A9620>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([ 27.,   5., ...,  10.,   5.]), 'n_epochs': 1000, 'X_valid': array([[  4.06948e-01,   1.94808e+00, ...,   2.11627e-03,   2.11724e-03],\n",
       "       [  1.39164e-01,   4.21989e-01, ...,   4.06587e-03,   4.06615e-03],\n",
       "       ...,\n",
       "       [  1.83723e-01,   2.28311e-01, ...,   5.07058e-04,   5.06819e-04],\n",
       "       [  2.18453e-02,   1.84218e-01, ...,   1.09750e-03,   1.09723e-03]])},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'batch_size': [100, 200, 350, 500], 'n_neurons': [100, 200, 250, 300, 400, 500, 700], 'n_hidden_layers': [0, 1, 2, 3], 'activation': [<function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000024C51A85158>, <function elu at 0x0000024C467CE9D8>], 'optimizer_class': [<class '...er'>, <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>], 'learning_rate': [0.01, 0.05]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [100, 200, 250, 300, 400, 500, 700],\n",
    "    \"batch_size\": [100, 200, 350, 500],\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"activation\": [leaky_relu(alpha=0.01), tf.nn.elu],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    \"n_hidden_layers\": [0, 1, 2, 3],\n",
    "    \"optimizer_class\": [tf.train.AdamOptimizer,\n",
    "                        tf.train.RMSPropOptimizer, tf.train.AdagradOptimizer]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                fit_params={\"X_valid\": X_valid, \"y_valid\": y_valid, \"n_epochs\": 1000},\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.elu>,\n",
       " 'batch_size': 200,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_hidden_layers': 3,\n",
       " 'n_neurons': 700,\n",
       " 'optimizer_class': tensorflow.python.training.adagrad.AdagradOptimizer}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95750000000000002"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rnd_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
