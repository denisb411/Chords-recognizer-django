{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('samples_nylonGuitar_1024_Mm7_R03.csv')\n",
    "\n",
    "X = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "y = np.array(df.iloc[:,-1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.20238646e-01  -5.01544944e-01   1.82757751e-01 ...,   1.73593716e-01\n",
      "    6.20198082e-01   1.67341409e+00]\n",
      " [  7.08208600e-01   3.09872305e-01  -1.14695638e-01 ...,  -1.53498110e-01\n",
      "   -2.44648974e-01  -1.96945409e+00]\n",
      " [ -9.03699447e-01   2.37903816e-01  -1.87462273e-01 ...,   7.58210044e-02\n",
      "   -5.34895728e-01   2.37967327e+00]\n",
      " ..., \n",
      " [  1.05264864e-03   8.77487351e-04   1.83663915e-03 ...,  -2.48573993e-03\n",
      "   -3.26628623e-03  -1.72389814e-03]\n",
      " [ -1.09274858e-03  -4.15664566e-04  -1.70912561e-06 ...,  -3.63465717e-06\n",
      "    6.41556900e-04   1.64839065e-03]\n",
      " [  1.12225790e-03  -2.90219230e-04  -1.83748116e-03 ...,   2.48593392e-03\n",
      "    2.35290024e-03  -1.58178132e-03]]\n",
      "(513, 9)\n",
      "1.0\n",
      "[ 1.         -0.72023865 -0.50154494 ...,  0.00248593  0.0023529\n",
      " -0.00158178]\n",
      "(4618,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "sample = librosa.core.stft(y=X[0], n_fft=1024, hop_length=None, win_length=512, window='hamming', center=True, dtype=np.float, pad_mode='reflect')\n",
    "\n",
    "\n",
    "print(sample)\n",
    "print(sample.shape)\n",
    "print(y[0])\n",
    "sample = np.append(y[0],sample)\n",
    "print(sample)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "test = np.zeros((15000,513,9,3), dtype=np.float)\n",
    "print(test[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14377"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py:180: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  axis=0)[:stft_matrix.shape[0]].conj()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (513,9) into shape (513,9,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-38b9dbb96f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprocessedX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hamming'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reflect'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprocessedy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (513,9) into shape (513,9,3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "processedData_path = \"preprocessedSamples_spect.data\"\n",
    "processedX = np.zeros((len(X),513,9,3), dtype=np.float)\n",
    "processedy = np.zeros(len(y), dtype=np.float)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    processedX[i] = librosa.core.stft(y=X[i], n_fft=1024, hop_length=None, win_length=512, window='hamming', center=True, dtype=np.float, pad_mode='reflect')\n",
    "    processedy[i] = y[i]\n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "        \n",
    "librosa.display.specshow(librosa.amplitude_to_db(processedX[0], ref=np.max), y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10256375  0.19068533  0.12183028 -0.19266205  0.04421633  0.15742663\n",
      " -0.16599489  0.00682489  0.22148408]\n"
     ]
    }
   ],
   "source": [
    "print(processedX[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n",
      "[[  2.97844293e+00   1.30130702e+00  -1.34245538e+00 ...,   7.67613340e-01\n",
      "    5.04967157e+00   7.43393706e+00]\n",
      " [ -2.35150451e+00  -1.36997902e+00   1.77733759e+00 ...,  -1.25938592e+00\n",
      "   -3.58434419e+00  -7.28036473e+00]\n",
      " [  1.83712710e+00   1.29993341e+00  -2.79939003e+00 ...,   2.62375379e+00\n",
      "    2.07262745e-01   6.89277739e+00]\n",
      " ..., \n",
      " [  3.65785286e-04  -8.38407973e-04   3.95548973e-04 ...,  -1.37339454e-02\n",
      "   -1.79509897e-03   3.74207769e-03]\n",
      " [ -2.03914653e-04  -6.14468101e-05   4.72444639e-05 ...,   5.81369967e-06\n",
      "   -1.44742230e-03  -3.70989457e-03]\n",
      " [ -2.50993567e-05   9.30617289e-04  -3.95696431e-04 ...,   1.37340421e-02\n",
      "    3.84878583e-03   3.69412652e-03]]\n",
      "(12377, 513, 9) (12377,) (1000, 513, 9) (1000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEYCAYAAAAXsVIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x155b6ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "processedX, processedy = shuffle(processedX, processedy)\n",
    "\n",
    "X_train = np.array(processedX[:-2000], dtype=np.float)\n",
    "y_train = np.array(processedy[:-2000], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(processedX[-2000:-1000], dtype=np.float)\n",
    "y_valid = np.array(processedy[-2000:-1000], dtype=np.float)\n",
    "\n",
    "X_test = np.array(processedX[-1000:], dtype=np.float)\n",
    "y_test = np.array(processedy[-1000:], dtype=np.float)\n",
    "print(y_test[999])\n",
    "print(X_test[999])\n",
    "\n",
    "print(X_train.shape,y_train.shape, X_valid.shape, y_valid.shape)\n",
    "\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(X_test[999], ref=np.max), y_axis='log', x_axis='time')\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "height = 513\n",
    "width = 9\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.25\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 128\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 10\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n",
    "    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 3342336 values, but the requested shape requires a multiple of 12544\n\t [[Node: pool3/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](pool3/MaxPool, pool3/Reshape/shape)]]\n\nCaused by op 'pool3/Reshape', defined at:\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-96c9989a787c>\", line 43, in <module>\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\n    name=name)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 3342336 values, but the requested shape requires a multiple of 12544\n\t [[Node: pool3/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](pool3/MaxPool, pool3/Reshape/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 3342336 values, but the requested shape requires a multiple of 12544\n\t [[Node: pool3/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](pool3/MaxPool, pool3/Reshape/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a6ec2ccacb71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mX_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_reshaped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcheck_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 loss_val = loss.eval(feed_dict={X: X_valid,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 3342336 values, but the requested shape requires a multiple of 12544\n\t [[Node: pool3/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](pool3/MaxPool, pool3/Reshape/shape)]]\n\nCaused by op 'pool3/Reshape', defined at:\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-96c9989a787c>\", line 43, in <module>\n    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\n    name=name)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/venturus/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 3342336 values, but the requested shape requires a multiple of 12544\n\t [[Node: pool3/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](pool3/MaxPool, pool3/Reshape/shape)]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_reshaped = np.reshape(X_train,(len(X_train),-1))\n",
    "            X_batch, y_batch = X_reshaped[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X: X_valid,\n",
    "                                                y: y_valid})\n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid,\n",
    "                                           y: y_valid})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test,\n",
    "                                        y: y_test})\n",
    "    print(\"Final accuracy on test set:\", acc_test)\n",
    "    #save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "\n",
    "# infer n_inputs and n_outputs from the training set.\n",
    "n_inputs = X_train.shape[1]\n",
    "self.classes_ = np.unique(y)\n",
    "n_outputs = len(self.classes_)\n",
    "\n",
    "# Translate the labels vector to a vector of sorted class indices, containing\n",
    "# integers from 0 to n_outputs - 1.\n",
    "# For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "# labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "# will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "self.class_to_index_ = {label: index\n",
    "                        for index, label in enumerate(self.classes_)}\n",
    "y = np.array([self.class_to_index_[label]\n",
    "              for label in y], dtype=np.int32)\n",
    "\n",
    "self._graph = tf.Graph()\n",
    "with self._graph.as_default():\n",
    "    self._build_graph(n_inputs, n_outputs)\n",
    "\n",
    "# needed in case of early stopping\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "best_params = None\n",
    "\n",
    "# extra ops for batch normalization\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# Now train the model!\n",
    "self._session = tf.Session(graph=self._graph)\n",
    "with self._session.as_default() as sess:\n",
    "    self._init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "            X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "            feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "            if self._training is not None:\n",
    "                feed_dict[self._training] = True\n",
    "            sess.run(self._training_op, feed_dict=feed_dict)\n",
    "            if extra_update_ops:\n",
    "                sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "        if X_valid is not None and y_valid is not None:\n",
    "            loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                         feed_dict={self._X: X_valid,\n",
    "                                                    self._y: y_valid})\n",
    "            if loss_val < best_loss:\n",
    "                best_params = self._get_model_params()\n",
    "                best_loss = loss_val\n",
    "                checks_without_progress = 0\n",
    "            else:\n",
    "                checks_without_progress += 1\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_val, best_loss, acc_val * 100))\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        else:\n",
    "            loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                             feed_dict={self._X: X_batch,\n",
    "                                                        self._y: y_batch})\n",
    "            print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                epoch, loss_train, acc_train * 100))\n",
    "    # If we used early stopping then rollback to the best model found\n",
    "    if best_params:\n",
    "        self._restore_model_params(best_params)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
