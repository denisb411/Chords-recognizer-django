{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('samples_nylonGuitar_1024_Mm7_R03.csv')\n",
    "\n",
    "X = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "y = np.array(df.iloc[:,-1], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "processedData_path = \"preprocessedSamples.data\"\n",
    "\n",
    "if os.path.isfile(processedData_path): #if already preprocessed\n",
    "    df_new = pd.read_pickle(processedData_path)\n",
    "else:\n",
    "    for i in range(len(X)):\n",
    "        sample = np.array(X[i], dtype=np.float)\n",
    "        sample = sample*np.hamming(1024)\n",
    "        sample = np.abs(np.fft.rfft(sample))[1:]\n",
    "        sample = np.append(sample, y[i])\n",
    "        try:\n",
    "            df_new = np.vstack([df_new, sample])\n",
    "        except:\n",
    "            df_new = np.array(sample, dtype=np.float)\n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "            df_new[i]\n",
    "    \n",
    "    df_new = pd.DataFrame(df_new)\n",
    "    \n",
    "    df_new.to_pickle(processedData_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "28.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD/CAYAAAA+LVfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZFBSOEtIjII/X/Qq25YTrF6aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ee6d49ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "npArrayDF = np.array(df_new.iloc[:,:], dtype=np.float) #shuffle randomly all samples\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "\n",
    "for i in range(len(npArrayDF)):\n",
    "    npArrayDF[i,-1] = (npArrayDF[i, -1]) - 1\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "    \n",
    "np.random.shuffle(npArrayDF)\n",
    "\n",
    "X_train = np.array(npArrayDF[:-2000,:-1], dtype=np.float)\n",
    "y_train = np.array(npArrayDF[:-2000,-1], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(npArrayDF[-2000:-1000,:-1], dtype=np.float)\n",
    "y_valid = np.array(npArrayDF[-2000:-1000,-1], dtype=np.float)\n",
    "\n",
    "X_test = np.array(npArrayDF[-1000:,:-1], dtype=np.float)\n",
    "y_test = np.array(npArrayDF[-1000:,-1], dtype=np.float)\n",
    "print(y_test[1])\n",
    "\n",
    "plt.plot(X_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tfr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f7bee64974f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtfr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_pitchgram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpitchgram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSignalFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tfr'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD/CAYAAADi+OGRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMMYYUwgHDGOMMYVwwDDGGFOI/wMJ/vWeuChhjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ee6cb88438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06995721 -0.10837345 -0.10564649 ...,  0.09544712  0.09530358\n",
      "  0.09550307]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD/CAYAAADxL6FlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ee6cdb45f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "y, sr = librosa.load(librosa.util.example_audio_file(),offset=10, duration=15)\n",
    "print(y)\n",
    "plt.plot(y[:2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3)\n",
      "[[  1.62411511e-01   1.84349809e-01   5.61518968e-01]\n",
      " [  2.18694851e-01   2.85292633e-01   7.62448058e-01]\n",
      " [  3.93319450e-01   3.00797875e-01   7.09370439e-01]\n",
      " [  2.19004157e+00   7.86664744e-01   1.05640874e+00]\n",
      " [  3.83122867e+00   2.27064676e+00   2.19990974e+00]\n",
      " [  1.18970745e+00   7.74732239e-01   1.69151990e+00]\n",
      " [  6.84855503e-01   2.64272476e+00   8.36583896e+00]\n",
      " [  2.66721505e+00   7.85287957e+00   7.76925724e+00]\n",
      " [  1.30693657e+01   1.00418168e+01   3.74823679e+00]\n",
      " [  1.75970457e+00   1.58745564e+00   9.96739139e-01]\n",
      " [  2.12873622e-01   6.62090274e-01   8.82837020e-01]\n",
      " [  6.80330438e-01   1.51448090e+00   1.59239481e+00]\n",
      " [  6.26292431e-01   8.77303637e-01   3.48130477e-01]\n",
      " [  4.35821416e-01   2.14151568e-01   1.41434202e-01]\n",
      " [  2.29367813e-02   2.34173429e-02   4.39253670e-03]\n",
      " [  2.69118720e-02   3.60549360e-02   6.83601657e-02]\n",
      " [  3.63231194e-02   5.93649116e-02   1.58393333e-01]\n",
      " [  5.33666633e-02   1.38764330e-01   4.81736016e-01]\n",
      " [  9.30939193e-02   2.08565772e-01   3.31550908e-01]\n",
      " [  2.44861072e-01   1.68598946e-01   1.29730658e-01]\n",
      " [  7.21321995e-01   4.94785027e-01   1.83645841e-01]\n",
      " [  1.65035832e-01   2.01407371e-01   2.14068798e-01]\n",
      " [  1.43566355e-02   7.60896264e-02   2.70219500e-01]\n",
      " [  7.36323789e-02   7.06902461e-02   1.28926602e-01]\n",
      " [  1.27753296e-01   4.19030753e-01   3.34469358e-01]\n",
      " [  2.94613232e-01   4.16304442e-01   5.16323116e-01]\n",
      " [  4.47159540e-02   6.06458870e-02   5.74764779e-02]\n",
      " [  5.78457069e-02   2.23583553e-02   1.33868325e-03]\n",
      " [  1.45864798e-01   6.21261103e-02   3.18012027e-02]\n",
      " [  2.04480931e-01   1.37353511e-01   2.68780658e-01]\n",
      " [  2.01373932e-01   4.80247076e-01   3.07575700e-01]\n",
      " [  7.61569380e-01   5.21908517e-01   4.87094173e-01]\n",
      " [  7.88431388e-01   6.70104568e-01   1.32491213e+00]\n",
      " [  3.02309800e-01   4.71432364e-01   9.82764203e-01]\n",
      " [  1.60777461e-02   3.08923353e-02   1.07550480e-01]\n",
      " [  8.47948431e-02   3.22131157e-02   3.69811668e-02]\n",
      " [  2.90552143e-01   1.08532853e-01   3.44938382e-02]\n",
      " [  2.11708269e-01   5.12144513e-02   8.13129991e-03]\n",
      " [  3.84423226e-01   1.13374691e-01   3.37673634e-02]\n",
      " [  8.49194587e-01   4.18501251e-01   1.28394984e-01]\n",
      " [  6.17879827e-01   1.18863959e+00   9.97301980e-01]\n",
      " [  3.04233714e-01   5.04555302e-01   5.98764391e-01]\n",
      " [  1.95099953e-01   1.13985424e-01   3.56479984e-02]\n",
      " [  1.10572780e-01   3.38237861e-02   9.40582410e-03]\n",
      " [  3.71864106e-02   1.92481992e-02   7.63641427e-03]\n",
      " [  2.96055165e-02   4.92817267e-02   3.35580578e-02]\n",
      " [  1.49029335e-01   7.60265311e-02   5.35423110e-02]\n",
      " [  8.54710485e-02   7.24939906e-02   1.02045123e-01]\n",
      " [  2.64355043e-02   2.28843534e-02   4.14244750e-02]\n",
      " [  3.12129956e-02   1.79051269e-02   2.24687796e-02]\n",
      " [  3.51357280e-03   4.53146217e-03   3.48453821e-03]\n",
      " [  3.69787631e-02   1.26345732e-02   2.33631153e-03]\n",
      " [  4.91719939e-02   3.32396661e-02   1.03375150e-02]\n",
      " [  2.92551762e-02   1.29685430e-02   3.34350997e-03]\n",
      " [  2.02115868e-02   7.09765703e-03   2.57981246e-03]\n",
      " [  8.58414471e-02   7.84320824e-02   8.82648566e-02]\n",
      " [  3.17467601e-02   3.18510709e-02   2.89874256e-02]\n",
      " [  4.11069935e-02   2.19684110e-02   9.24881571e-03]\n",
      " [  3.23170258e-02   1.45047371e-02   1.26305955e-02]\n",
      " [  2.97862149e-03   8.04399371e-03   1.21319941e-02]\n",
      " [  8.54308377e-03   1.58492065e-02   4.27327847e-02]\n",
      " [  3.13218549e-02   5.44311438e-02   1.25382316e-01]\n",
      " [  1.59298401e-02   3.82100446e-02   8.68222163e-02]\n",
      " [  2.44327681e-02   2.94363277e-02   5.10363081e-02]\n",
      " [  9.09282826e-03   2.19164851e-02   5.68889455e-02]\n",
      " [  5.22025885e-01   5.67931183e-01   3.92638731e-01]\n",
      " [  1.79824044e-01   1.93659059e-01   1.77278925e-01]\n",
      " [  3.21416993e-02   6.04878718e-02   1.05776491e-01]\n",
      " [  6.11083310e-02   3.16624863e-02   2.99782976e-02]\n",
      " [  1.03822591e-02   1.34140725e-02   2.85657448e-02]\n",
      " [  1.25121986e-02   1.61209792e-02   2.50605263e-02]\n",
      " [  2.67770000e-02   2.18559214e-02   1.13954239e-02]\n",
      " [  1.32547874e-02   1.42543689e-02   1.65894850e-02]\n",
      " [  3.81543639e-03   4.71052049e-03   5.12620538e-03]\n",
      " [  6.16430896e-03   1.96790043e-02   3.23485524e-02]\n",
      " [  1.17209720e-02   2.15406852e-02   2.83384673e-02]\n",
      " [  3.96779831e-02   4.01929104e-02   3.84631930e-02]\n",
      " [  5.62334632e-02   8.22069556e-02   1.06722447e-01]\n",
      " [  1.32671199e-02   6.41430423e-03   2.28601791e-03]\n",
      " [  5.79419979e-02   5.16524102e-02   3.99154642e-02]\n",
      " [  1.68548368e-02   1.86954942e-02   1.75168769e-02]\n",
      " [  1.22359376e-02   1.92185778e-02   3.86518706e-02]\n",
      " [  1.77395912e-02   1.21229343e-02   8.75605712e-03]\n",
      " [  6.70947025e-03   6.06092174e-03   5.36306055e-03]\n",
      " [  1.07771023e-02   5.63621399e-03   4.57792635e-03]\n",
      " [  5.03623660e-02   2.47322829e-02   4.40294067e-03]\n",
      " [  1.34841341e-02   7.48957137e-03   4.23329047e-03]\n",
      " [  1.75657337e-02   1.75758074e-02   1.94044286e-02]\n",
      " [  1.69833236e-02   1.96174284e-02   2.16397610e-02]\n",
      " [  4.86290051e-02   6.20451357e-02   8.01873025e-02]\n",
      " [  4.02156911e-03   4.09446722e-03   3.99615311e-03]\n",
      " [  2.57230306e-03   2.17508639e-03   1.68780363e-03]\n",
      " [  2.81894161e-03   2.11200651e-03   2.13771822e-03]\n",
      " [  4.62628843e-03   4.16795123e-03   3.29040885e-03]\n",
      " [  2.97662554e-03   2.66184646e-03   2.02431251e-03]\n",
      " [  2.85477247e-03   2.29463396e-03   1.65030108e-03]\n",
      " [  6.14733777e-04   6.76391464e-04   6.74537440e-04]\n",
      " [  8.96720759e-04   1.14842240e-03   1.01589968e-03]\n",
      " [  1.66813322e-03   1.09027815e-03   4.68953171e-04]\n",
      " [  1.40049751e-03   1.37839224e-03   9.12206253e-04]\n",
      " [  1.28538875e-03   1.58903268e-03   2.16040433e-03]\n",
      " [  2.13758815e-03   2.94012956e-03   2.91206642e-03]\n",
      " [  1.06217879e-03   1.03316441e-03   1.24780152e-03]\n",
      " [  6.23260300e-04   5.69843209e-04   6.88816196e-04]\n",
      " [  5.75512472e-04   4.51125484e-04   5.36154854e-04]\n",
      " [  1.27846406e-04   9.01865041e-05   7.05166057e-05]\n",
      " [  3.16485218e-04   1.67942138e-04   1.46272030e-04]\n",
      " [  3.89364114e-04   2.33354373e-04   1.36226128e-04]\n",
      " [  1.02630269e-04   9.83051801e-05   7.42185321e-05]\n",
      " [  7.07241345e-05   6.40800717e-05   6.49615154e-05]\n",
      " [  2.47351242e-04   6.32152147e-04   7.10234243e-04]\n",
      " [  6.61820965e-04   1.20138955e-03   1.24923078e-03]\n",
      " [  2.25866102e-04   3.79234812e-04   4.08236752e-04]\n",
      " [  1.50442193e-04   1.30412219e-04   1.27165104e-04]\n",
      " [  2.73598409e-04   2.14075728e-04   1.55269760e-04]\n",
      " [  1.24501353e-04   7.49411447e-05   5.32688277e-05]\n",
      " [  1.60399231e-03   8.17354491e-04   3.63114932e-04]\n",
      " [  3.53576507e-04   2.29185518e-04   7.47118148e-05]\n",
      " [  2.17127147e-04   1.52307028e-04   7.74339853e-05]\n",
      " [  2.03050556e-04   1.16736163e-04   6.03707209e-05]\n",
      " [  4.31267389e-04   2.90005541e-04   1.43451557e-04]\n",
      " [  2.04139559e-04   1.30125256e-04   6.05977307e-05]\n",
      " [  7.74172029e-05   4.13344124e-05   1.57827028e-05]\n",
      " [  2.64153446e-05   1.27645246e-05   7.88273442e-06]\n",
      " [  1.00309716e-05   5.83110879e-06   6.03315385e-06]\n",
      " [  2.28337679e-06   1.69823568e-06   4.11983093e-06]\n",
      " [  1.95282999e-06   1.43025082e-06   3.69692766e-06]\n",
      " [  1.81338004e-06   1.37421024e-06   3.65652969e-06]]\n"
     ]
    }
   ],
   "source": [
    "# chroma_stft = librosa.feature.chroma_stft(y=X[1], sr=44100,n_chroma=12, n_fft=1024)\n",
    "# print(chroma_stft)\n",
    "# print(type(chroma_stft))\n",
    "# print(chroma_stft.shape)\n",
    "\n",
    "specgram = librosa.feature.melspectrogram(y=X[1], sr=44100)\n",
    "print(specgram.shape)\n",
    "print(specgram)\n",
    "\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAEYCAYAAABsjy9+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ee0f6119b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> import matplotlib.pyplot as plt\n",
    ">>> plt.figure(figsize=(10, 4))\n",
    ">>> librosa.display.specshow(librosa.power_to_db(specgram,\n",
    "...                                              ref=np.max),\n",
    "...                          y_axis='mel', fmax=8000,\n",
    "...                          x_axis='time')\n",
    ">>> plt.colorbar(format='%+2.0f dB')\n",
    ">>> plt.title('Mel spectrogram')\n",
    ">>> plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1534ff5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    ">>> plt.figure()\n",
    ">>> plt.subplot(2,1,1)\n",
    ">>> librosa.display.specshow(chroma_stft, y_axis='chroma')\n",
    ">>> plt.title('chroma_stft')\n",
    ">>> plt.colorbar()\n",
    ">>> plt.subplot(2,1,2)\n",
    ">>> librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time')\n",
    ">>> plt.title('chroma_cqt')\n",
    ">>> plt.colorbar()\n",
    ">>> plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = librosa.feature.chroma_stft(y=X[500], sr=44100,n_chroma=12, n_fft=1024)\n",
    "print(y[500])\n",
    "print(sample)\n",
    "librosa.display.specshow(sample, y_axis='chroma')\n",
    "plt.show()\n",
    "sample = np.append(sample, y[500])\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[  1.74061699e-02   2.97966001e-02   1.04510216e-01   5.78985724e-02\n",
      "   5.13123567e-02   9.79127027e-02   6.26266709e-02   1.08053328e-01\n",
      "   2.16651492e-01   8.53165415e-02   6.07527560e-01   1.31297583e+00\n",
      "   3.29645344e-01   6.35775016e-01   8.30570458e-01   8.35494557e-01\n",
      "   2.26866891e-01   1.24925832e-01   1.47164263e+00   1.41302304e+00\n",
      "   5.71382163e-01   2.62667475e+00   2.95087011e+00   1.05652008e+00\n",
      "   5.71489916e+00   2.69849348e+00   4.76378341e-01   7.31550997e-01\n",
      "   5.09302281e-01   6.57215320e-02   9.79528001e-01   7.98975036e-01\n",
      "   1.19063313e+00   5.91802735e+00   5.25557303e+00   8.03592584e+00\n",
      "   4.24407327e+00   6.49683622e+00   8.19836628e+00   3.51221626e-01\n",
      "   5.92339388e-01   7.64835288e-01   5.83574491e-02   2.23256286e-02\n",
      "   1.13141428e-02   3.91085006e-02   2.44775241e-02   2.21494649e-02\n",
      "   1.58954792e-01   1.38742716e-01   1.13440416e-01   2.22697589e-01\n",
      "   1.40360553e-01   3.63768257e-01   2.18444911e-01   6.37183884e-01\n",
      "   1.07806397e+00   6.36838347e-01   4.05439123e-01   1.03670177e+00\n",
      "   2.75719086e-01   3.95882126e-01   6.56828636e-01   3.37822063e-02\n",
      "   9.65623938e-02   1.63471365e-01   1.87023519e-02   1.36554433e-02\n",
      "   2.83108419e-02   2.55048133e-02   3.61725653e-02   7.76935807e-02\n",
      "   1.56648146e-01   2.36950915e-01   9.03966343e-02   4.63341671e-01\n",
      "   2.21311224e-01   1.90899878e-01   2.87516083e-01   1.18151870e-01\n",
      "   1.14522283e-01   7.81196008e-02   3.21078734e-02   7.39006642e-02\n",
      "   6.78227937e-02   2.29014985e-02   4.67027346e-02   2.16554500e-01\n",
      "   8.04663031e-02   1.21015651e-01   5.18127816e-01   5.40863122e-01\n",
      "   7.28581204e-01   4.33875969e-01   7.72984074e-01   4.37752315e-01\n",
      "   8.48540226e-01   3.68710156e-01   3.83294352e-02   1.73930414e-01\n",
      "   1.50854002e-01   5.36284868e-02   8.47020792e-03   6.12038758e-03\n",
      "   5.10609824e-03   6.65086866e-02   3.23829687e-02   7.03305916e-03\n",
      "   2.84236539e-01   1.72893503e-01   8.26720307e-02   4.49681046e-02\n",
      "   2.57475649e-02   1.24833814e-02   3.34834050e-03   2.51308095e-03\n",
      "   3.51228532e-03   2.15754323e-02   1.76738956e-02   7.65783311e-03\n",
      "   3.66924800e-02   1.03345510e-01   1.48545973e-01   2.87458361e-01\n",
      "   3.21728579e-01   1.92535498e-01   8.67285789e-02   1.10361266e-01\n",
      "   1.68848004e-01   3.65467719e-04   9.07839933e-03   3.74284396e-02\n",
      "   1.54221471e-02   1.86639031e-02   3.56226766e-02   1.71592122e-01\n",
      "   3.77231584e-01   5.09133863e-01   2.06130653e-01   2.75531575e-01\n",
      "   2.26857901e-01   6.70662406e-02   4.46841588e-02   3.37745859e-02\n",
      "   1.31558377e-02   6.76601378e-03   2.39236922e-03   5.07861193e-03\n",
      "   1.43450496e-02   3.03074629e-02   3.93909436e-02   2.09359506e-02\n",
      "   2.46417519e-02   3.29778308e-02   1.01146824e-02   4.22076128e-03\n",
      "   1.23563154e-02   9.16747377e-03   2.94843770e-03   6.20864013e-03\n",
      "   1.11213911e-02   6.70942476e-03   1.24438137e-02   3.27746800e-02\n",
      "   4.92712879e-02   1.36945341e-02   2.66655555e-02   3.85339081e-02\n",
      "   1.29266837e-03   8.88491820e-04   5.72899674e-04   3.54583190e-03\n",
      "   6.74861938e-03   7.00312568e-03   7.51716581e-03   1.87513387e-02\n",
      "   3.35218031e-02   5.29391895e-03   4.85336416e-03   2.85378930e-03\n",
      "   5.39169531e-03   6.45379723e-03   1.00299897e-02   1.41188344e-02\n",
      "   1.98807066e-02   1.74146696e-02   5.18289056e-03   5.19669402e-03\n",
      "   1.07404837e-02   3.17357528e-02   2.74284979e-02   2.47998583e-02\n",
      "   2.00212737e-02   2.36020954e-02   1.22442287e-02   1.89457708e-01\n",
      "   2.04618614e-01   1.23106399e-01   1.11690260e-01   7.55698180e-02\n",
      "   6.15378891e-02   2.56226313e-02   4.29855131e-02   5.53316488e-02\n",
      "   3.45835428e-02   3.54628939e-02   3.38123465e-02   2.16408025e-02\n",
      "   3.29130049e-02   3.75840696e-02   1.12684092e-02   2.19206615e-02\n",
      "   2.62425777e-02   5.92816309e-03   6.50400105e-03   7.01986754e-03\n",
      "   5.34355829e-03   6.27045143e-03   5.73388139e-03   1.28178931e-03\n",
      "   2.16525262e-03   5.02512746e-03   6.53948460e-04   1.13277039e-03\n",
      "   1.61358183e-03   3.79554393e-03   3.76900178e-03   4.05754642e-03\n",
      "   1.27790467e-02   9.22783240e-03   7.67752493e-03   2.39292023e-02\n",
      "   2.33658504e-02   2.37264342e-02   2.49659434e-02   1.68038455e-02\n",
      "   9.25107199e-03   1.76868900e-02   7.77673726e-03   1.73337370e-03\n",
      "   9.23559690e-03   7.23372671e-03   3.62776284e-03   7.56891687e-03\n",
      "   6.31444302e-03   3.78951732e-03   5.12795553e-03   3.71426805e-03\n",
      "   1.62869041e-03   9.84712361e-04   5.82898947e-04   2.18828208e-04\n",
      "   2.61360725e-04   3.92902067e-04   4.09843843e-04   4.71617229e-04\n",
      "   6.26034024e-04   1.10979051e-03   1.37472093e-03   1.57628454e-03\n",
      "   2.65633678e-03   4.00334690e-03   6.09133259e-03   7.09723105e-03\n",
      "   4.56073577e-03   6.21928346e-03   5.40587055e-03   2.42879331e-03\n",
      "   2.59745529e-03   2.44817603e-03   3.70180480e-04   2.84556673e-04\n",
      "   1.63448983e-04   5.66935622e-04   3.54407276e-04   2.02664220e-04\n",
      "   6.68597671e-04   3.52025010e-04   1.17521833e-04   8.33850266e-04\n",
      "   3.05984223e-04   8.36790732e-05   3.15566595e-04   1.88839919e-04\n",
      "   8.26568316e-05   2.16753320e-04   2.15376723e-04   2.04538247e-04\n",
      "   1.12436798e-04   1.82638724e-04   1.61808956e-04   2.48490703e-04\n",
      "   1.42687683e-04   1.09446940e-04   3.25758784e-04   2.02920117e-04\n",
      "   2.10910971e-04   1.46636424e-04   1.20639910e-04   1.14265764e-04\n",
      "   1.58170001e-04   1.13924054e-04   8.01977952e-05   2.67972116e-04\n",
      "   2.00802534e-04   1.35796874e-04   1.24442402e-04   1.13428201e-04\n",
      "   8.19448812e-05   7.85700672e-05   3.91215452e-05   1.04790073e-05\n",
      "   5.82770269e-05   2.31738559e-05   7.20610714e-06   1.51228070e-05\n",
      "   9.10716953e-06   5.64859507e-06   3.67108029e-06   2.73942782e-06\n",
      "   2.33186174e-06   8.64708246e-06   6.82765223e-06   3.35835573e-06\n",
      "   3.19395627e-05   1.91768614e-05   7.07873083e-06   2.43338801e-05\n",
      "   1.59685870e-05   7.09809402e-06   8.25597502e-06   3.86180732e-06\n",
      "   1.57235453e-06   1.26602602e-05   7.30264780e-06   3.10557422e-06\n",
      "   4.96411377e-06   3.26926585e-06   3.23680323e-06   3.01818445e-06\n",
      "   2.02285864e-06   1.46174034e-06   7.04698483e-06   4.65086927e-06\n",
      "   3.89949072e-06   4.84734616e-06   2.06556953e-06   9.36138704e-07\n",
      "   1.38673216e-06   1.09615128e-06   1.08431475e-06   2.17607846e-06\n",
      "   1.40034787e-06   1.13548712e-06   1.74368498e-06   1.14640896e-06\n",
      "   6.85417437e-07   7.51566240e-07   7.84113015e-07   1.13031664e-06\n",
      "   1.49042358e-06   1.30731402e-06   1.17880413e-06   2.70634829e-06\n",
      "   2.12892972e-06   1.20392584e-06   9.61396148e-07   6.00952674e-07\n",
      "   3.64597339e-07   3.92825961e-07   2.57616273e-07   2.16510429e-07\n",
      "   1.84844131e-07   1.90226718e-07   2.57246598e-07   9.09058810e-08\n",
      "   8.00727078e-08   1.46904043e-07   5.71608744e-08   4.74724113e-08\n",
      "   1.26009423e-07   5.53522439e-08   4.62696996e-08   1.28624905e-07\n",
      "   1.00000000e+00]\n",
      "0\n",
      "[  1.74061699e-02   2.97966001e-02   1.04510216e-01   5.78985724e-02\n",
      "   5.13123567e-02   9.79127027e-02   6.26266709e-02   1.08053328e-01\n",
      "   2.16651492e-01   8.53165415e-02   6.07527560e-01   1.31297583e+00\n",
      "   3.29645344e-01   6.35775016e-01   8.30570458e-01   8.35494557e-01\n",
      "   2.26866891e-01   1.24925832e-01   1.47164263e+00   1.41302304e+00\n",
      "   5.71382163e-01   2.62667475e+00   2.95087011e+00   1.05652008e+00\n",
      "   5.71489916e+00   2.69849348e+00   4.76378341e-01   7.31550997e-01\n",
      "   5.09302281e-01   6.57215320e-02   9.79528001e-01   7.98975036e-01\n",
      "   1.19063313e+00   5.91802735e+00   5.25557303e+00   8.03592584e+00\n",
      "   4.24407327e+00   6.49683622e+00   8.19836628e+00   3.51221626e-01\n",
      "   5.92339388e-01   7.64835288e-01   5.83574491e-02   2.23256286e-02\n",
      "   1.13141428e-02   3.91085006e-02   2.44775241e-02   2.21494649e-02\n",
      "   1.58954792e-01   1.38742716e-01   1.13440416e-01   2.22697589e-01\n",
      "   1.40360553e-01   3.63768257e-01   2.18444911e-01   6.37183884e-01\n",
      "   1.07806397e+00   6.36838347e-01   4.05439123e-01   1.03670177e+00\n",
      "   2.75719086e-01   3.95882126e-01   6.56828636e-01   3.37822063e-02\n",
      "   9.65623938e-02   1.63471365e-01   1.87023519e-02   1.36554433e-02\n",
      "   2.83108419e-02   2.55048133e-02   3.61725653e-02   7.76935807e-02\n",
      "   1.56648146e-01   2.36950915e-01   9.03966343e-02   4.63341671e-01\n",
      "   2.21311224e-01   1.90899878e-01   2.87516083e-01   1.18151870e-01\n",
      "   1.14522283e-01   7.81196008e-02   3.21078734e-02   7.39006642e-02\n",
      "   6.78227937e-02   2.29014985e-02   4.67027346e-02   2.16554500e-01\n",
      "   8.04663031e-02   1.21015651e-01   5.18127816e-01   5.40863122e-01\n",
      "   7.28581204e-01   4.33875969e-01   7.72984074e-01   4.37752315e-01\n",
      "   8.48540226e-01   3.68710156e-01   3.83294352e-02   1.73930414e-01\n",
      "   1.50854002e-01   5.36284868e-02   8.47020792e-03   6.12038758e-03\n",
      "   5.10609824e-03   6.65086866e-02   3.23829687e-02   7.03305916e-03\n",
      "   2.84236539e-01   1.72893503e-01   8.26720307e-02   4.49681046e-02\n",
      "   2.57475649e-02   1.24833814e-02   3.34834050e-03   2.51308095e-03\n",
      "   3.51228532e-03   2.15754323e-02   1.76738956e-02   7.65783311e-03\n",
      "   3.66924800e-02   1.03345510e-01   1.48545973e-01   2.87458361e-01\n",
      "   3.21728579e-01   1.92535498e-01   8.67285789e-02   1.10361266e-01\n",
      "   1.68848004e-01   3.65467719e-04   9.07839933e-03   3.74284396e-02\n",
      "   1.54221471e-02   1.86639031e-02   3.56226766e-02   1.71592122e-01\n",
      "   3.77231584e-01   5.09133863e-01   2.06130653e-01   2.75531575e-01\n",
      "   2.26857901e-01   6.70662406e-02   4.46841588e-02   3.37745859e-02\n",
      "   1.31558377e-02   6.76601378e-03   2.39236922e-03   5.07861193e-03\n",
      "   1.43450496e-02   3.03074629e-02   3.93909436e-02   2.09359506e-02\n",
      "   2.46417519e-02   3.29778308e-02   1.01146824e-02   4.22076128e-03\n",
      "   1.23563154e-02   9.16747377e-03   2.94843770e-03   6.20864013e-03\n",
      "   1.11213911e-02   6.70942476e-03   1.24438137e-02   3.27746800e-02\n",
      "   4.92712879e-02   1.36945341e-02   2.66655555e-02   3.85339081e-02\n",
      "   1.29266837e-03   8.88491820e-04   5.72899674e-04   3.54583190e-03\n",
      "   6.74861938e-03   7.00312568e-03   7.51716581e-03   1.87513387e-02\n",
      "   3.35218031e-02   5.29391895e-03   4.85336416e-03   2.85378930e-03\n",
      "   5.39169531e-03   6.45379723e-03   1.00299897e-02   1.41188344e-02\n",
      "   1.98807066e-02   1.74146696e-02   5.18289056e-03   5.19669402e-03\n",
      "   1.07404837e-02   3.17357528e-02   2.74284979e-02   2.47998583e-02\n",
      "   2.00212737e-02   2.36020954e-02   1.22442287e-02   1.89457708e-01\n",
      "   2.04618614e-01   1.23106399e-01   1.11690260e-01   7.55698180e-02\n",
      "   6.15378891e-02   2.56226313e-02   4.29855131e-02   5.53316488e-02\n",
      "   3.45835428e-02   3.54628939e-02   3.38123465e-02   2.16408025e-02\n",
      "   3.29130049e-02   3.75840696e-02   1.12684092e-02   2.19206615e-02\n",
      "   2.62425777e-02   5.92816309e-03   6.50400105e-03   7.01986754e-03\n",
      "   5.34355829e-03   6.27045143e-03   5.73388139e-03   1.28178931e-03\n",
      "   2.16525262e-03   5.02512746e-03   6.53948460e-04   1.13277039e-03\n",
      "   1.61358183e-03   3.79554393e-03   3.76900178e-03   4.05754642e-03\n",
      "   1.27790467e-02   9.22783240e-03   7.67752493e-03   2.39292023e-02\n",
      "   2.33658504e-02   2.37264342e-02   2.49659434e-02   1.68038455e-02\n",
      "   9.25107199e-03   1.76868900e-02   7.77673726e-03   1.73337370e-03\n",
      "   9.23559690e-03   7.23372671e-03   3.62776284e-03   7.56891687e-03\n",
      "   6.31444302e-03   3.78951732e-03   5.12795553e-03   3.71426805e-03\n",
      "   1.62869041e-03   9.84712361e-04   5.82898947e-04   2.18828208e-04\n",
      "   2.61360725e-04   3.92902067e-04   4.09843843e-04   4.71617229e-04\n",
      "   6.26034024e-04   1.10979051e-03   1.37472093e-03   1.57628454e-03\n",
      "   2.65633678e-03   4.00334690e-03   6.09133259e-03   7.09723105e-03\n",
      "   4.56073577e-03   6.21928346e-03   5.40587055e-03   2.42879331e-03\n",
      "   2.59745529e-03   2.44817603e-03   3.70180480e-04   2.84556673e-04\n",
      "   1.63448983e-04   5.66935622e-04   3.54407276e-04   2.02664220e-04\n",
      "   6.68597671e-04   3.52025010e-04   1.17521833e-04   8.33850266e-04\n",
      "   3.05984223e-04   8.36790732e-05   3.15566595e-04   1.88839919e-04\n",
      "   8.26568316e-05   2.16753320e-04   2.15376723e-04   2.04538247e-04\n",
      "   1.12436798e-04   1.82638724e-04   1.61808956e-04   2.48490703e-04\n",
      "   1.42687683e-04   1.09446940e-04   3.25758784e-04   2.02920117e-04\n",
      "   2.10910971e-04   1.46636424e-04   1.20639910e-04   1.14265764e-04\n",
      "   1.58170001e-04   1.13924054e-04   8.01977952e-05   2.67972116e-04\n",
      "   2.00802534e-04   1.35796874e-04   1.24442402e-04   1.13428201e-04\n",
      "   8.19448812e-05   7.85700672e-05   3.91215452e-05   1.04790073e-05\n",
      "   5.82770269e-05   2.31738559e-05   7.20610714e-06   1.51228070e-05\n",
      "   9.10716953e-06   5.64859507e-06   3.67108029e-06   2.73942782e-06\n",
      "   2.33186174e-06   8.64708246e-06   6.82765223e-06   3.35835573e-06\n",
      "   3.19395627e-05   1.91768614e-05   7.07873083e-06   2.43338801e-05\n",
      "   1.59685870e-05   7.09809402e-06   8.25597502e-06   3.86180732e-06\n",
      "   1.57235453e-06   1.26602602e-05   7.30264780e-06   3.10557422e-06\n",
      "   4.96411377e-06   3.26926585e-06   3.23680323e-06   3.01818445e-06\n",
      "   2.02285864e-06   1.46174034e-06   7.04698483e-06   4.65086927e-06\n",
      "   3.89949072e-06   4.84734616e-06   2.06556953e-06   9.36138704e-07\n",
      "   1.38673216e-06   1.09615128e-06   1.08431475e-06   2.17607846e-06\n",
      "   1.40034787e-06   1.13548712e-06   1.74368498e-06   1.14640896e-06\n",
      "   6.85417437e-07   7.51566240e-07   7.84113015e-07   1.13031664e-06\n",
      "   1.49042358e-06   1.30731402e-06   1.17880413e-06   2.70634829e-06\n",
      "   2.12892972e-06   1.20392584e-06   9.61396148e-07   6.00952674e-07\n",
      "   3.64597339e-07   3.92825961e-07   2.57616273e-07   2.16510429e-07\n",
      "   1.84844131e-07   1.90226718e-07   2.57246598e-07   9.09058810e-08\n",
      "   8.00727078e-08   1.46904043e-07   5.71608744e-08   4.74724113e-08\n",
      "   1.26009423e-07   5.53522439e-08   4.62696996e-08   1.28624905e-07\n",
      "   1.00000000e+00]\n",
      "0.0174061698879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[  2.36865683e-02   6.52210882e-01   2.48139213e+00   4.13499224e-01\n",
      "   1.02444004e+00   3.70927925e+00   1.28033823e+00   1.57891470e+00\n",
      "   2.18916898e+00   4.55203527e-01   4.28440136e-01   4.67731901e-01\n",
      "   2.32672890e+00   1.12159022e+00   1.77464248e+00   5.18524750e+00\n",
      "   1.79616041e+01   2.99653522e+01   6.19790595e+01   7.64437932e+01\n",
      "   4.16619804e+01   4.39359144e+01   7.46028603e+01   1.94711446e+01\n",
      "   9.00623669e+01   8.52031587e+01   4.65750555e+01   9.55661760e+00\n",
      "   1.31871701e+01   2.82478634e+01   6.84412148e+00   5.34918714e+00\n",
      "   1.97576331e+00   2.08087375e+00   9.01624517e-01   1.22351007e+00\n",
      "   1.16550615e+00   5.42243659e-01   1.02537410e+00   1.05777473e+00\n",
      "   3.35707314e+00   5.19733807e+00   1.48223489e+00   1.99970870e+00\n",
      "   2.35858860e+00   5.40033124e-01   2.43601841e-01   1.02686894e-01\n",
      "   6.98995003e-02   5.69477171e-02   1.03122928e-01   1.35593014e-01\n",
      "   6.39751431e-02   2.21244202e-02   4.69003391e-02   2.97268459e-02\n",
      "   3.88708747e-02   4.68378402e-01   4.03474470e-01   5.00597812e-01\n",
      "   3.39228408e+00   2.57482976e+00   8.92733527e-01   1.79769202e+00\n",
      "   1.96646621e+00   2.43891644e+00   5.73351925e-02   2.86027875e-01\n",
      "   9.07405392e-01   4.30301572e-02   7.19963194e-02   2.79052907e-01\n",
      "   6.75849012e-01   5.35308386e-01   4.46741731e-01   3.82477196e-01\n",
      "   2.32659563e-01   9.12691520e-02   3.05240938e-01   5.11542111e-01\n",
      "   3.74660714e-01   1.97596454e-01   4.96238226e-01   2.63329283e-01\n",
      "   1.69493280e-01   3.09826550e-01   2.15107172e-01   3.50017959e-02\n",
      "   1.00919925e-01   8.10593848e-02   5.15511917e-01   3.41168877e-01\n",
      "   1.95831974e-01   1.09632683e+00   1.74677235e+00   2.38820352e+00\n",
      "   2.31356955e-01   4.87378215e-01   1.85833655e+00   1.04056434e+00\n",
      "   8.13280146e-01   1.79331265e+00   2.31290662e+00   1.17657941e+00\n",
      "   1.33276400e+00   1.66491900e+00   6.67247521e-01   2.11255417e-01\n",
      "   1.47365517e-01   1.04064298e-01   1.69738531e-02   3.80997766e-02\n",
      "   6.89695535e-02   7.46650710e-02   4.78396186e-02   4.47962204e-02\n",
      "   9.01594442e-02   1.32160396e-01   1.10082146e-01   3.27898208e-02\n",
      "   5.03185705e-01   4.56251727e-01   3.24386201e-01   6.45585702e-01\n",
      "   3.61264906e-01   5.94596864e-01   8.39166768e-02   1.85683802e-01\n",
      "   2.25207931e-01   7.44541526e-02   4.04371406e-02   4.95053230e-03\n",
      "   1.17390338e-01   7.58929932e-02   1.03962006e-01   1.26978334e-01\n",
      "   1.11988909e-01   6.00875657e-02   2.72875039e-02   4.12072323e-02\n",
      "   3.92465099e-02   9.69857608e-02   8.88895558e-02   4.87657758e-02\n",
      "   6.07362326e-03   1.42495274e-02   4.08220113e-02   5.09181742e-02\n",
      "   9.64606649e-02   1.14053909e-01   1.02187812e-01   1.51074646e-01\n",
      "   1.33039447e-01   9.86651901e-03   2.37930225e-02   3.89171727e-02\n",
      "   5.40696727e-02   8.13162767e-02   6.92932318e-02   1.23814496e-02\n",
      "   1.35433322e-02   1.27928341e-02   2.00294511e-03   2.22358437e-03\n",
      "   2.42290094e-03   1.25402569e-03   1.05059103e-03   2.54675812e-03\n",
      "   9.82735243e-04   1.16039713e-03   3.62882941e-03   1.94672193e-02\n",
      "   1.66198191e-02   1.22834482e-02   5.63358539e-03   8.76347098e-03\n",
      "   1.12506290e-02   1.30443517e-03   2.20971602e-03   4.34675037e-03\n",
      "   5.12599947e-03   5.41084012e-03   3.94209608e-03   1.53403604e-03\n",
      "   1.26375733e-03   6.98646732e-04   5.29391476e-04   8.20101970e-04\n",
      "   8.90722215e-04   7.90822431e-05   5.82375227e-05   5.18964933e-05\n",
      "   2.18921368e-04   3.20576360e-04   8.74505654e-04   1.07780357e-02\n",
      "   8.58559789e-03   5.34560314e-03   5.03040451e-03   2.83559749e-03\n",
      "   1.16058648e-03   2.24638653e-04   2.15614510e-04   2.03831227e-04\n",
      "   1.12652110e-03   1.06089751e-03   9.00345137e-04   9.20218545e-04\n",
      "   9.49887214e-04   9.56774929e-04   5.87904621e-05   1.05381386e-04\n",
      "   2.08777142e-04   4.59230328e-04   4.30771707e-04   4.28355212e-04\n",
      "   1.31170479e-03   7.19924942e-04   6.53548099e-04   1.15854621e-04\n",
      "   1.21034392e-04   3.00389585e-04   6.77713075e-05   1.20666963e-04\n",
      "   1.42796133e-04   3.53092246e-05   8.09898784e-05   1.19214584e-04\n",
      "   1.32154084e-04   9.70136925e-05   1.15595626e-04   1.92239006e-04\n",
      "   5.89601222e-04   1.10495232e-03   3.79359325e-04   7.90273435e-04\n",
      "   1.02684375e-03   7.26077921e-04   1.29480949e-03   1.33670800e-03\n",
      "   9.27391088e-04   9.92716301e-04   7.88900979e-04   1.05738201e-04\n",
      "   1.02925391e-04   8.22991498e-05   4.55657719e-05   6.11440568e-05\n",
      "   7.18256371e-05   1.87681996e-05   2.42201816e-05   4.41774197e-05\n",
      "   2.98039075e-05   2.18757170e-05   1.62865281e-05   2.09941696e-05\n",
      "   2.48430671e-05   2.84209481e-05   8.15146257e-05   1.11241053e-04\n",
      "   1.10159464e-04   8.40101111e-05   1.83954869e-04   3.28653774e-04\n",
      "   3.62071356e-04   3.71943107e-04   6.34422734e-04   9.69380686e-04\n",
      "   1.06121717e-03   1.60563438e-03   4.16445656e-04   3.21122704e-03\n",
      "   7.23188423e-03   1.98281580e-04   4.52663697e-04   1.11554499e-03\n",
      "   1.66227229e-05   1.85514199e-05   3.82624310e-05   2.83463470e-05\n",
      "   2.58057670e-05   4.60302344e-05   4.15872341e-06   2.58692176e-05\n",
      "   7.48914514e-05   2.17008183e-06   1.69594219e-05   4.83434889e-05\n",
      "   1.41768035e-06   3.26876812e-06   6.28948668e-06   1.37014794e-06\n",
      "   3.81231675e-06   7.39614896e-06   2.29347179e-06   4.44156170e-06\n",
      "   8.75609980e-06   2.16318796e-05   3.36644570e-05   4.70831489e-05\n",
      "   1.26685003e-04   1.92638933e-04   2.62569527e-04   4.45402803e-05\n",
      "   1.12565292e-04   1.70688554e-04   1.36938100e-05   3.62287235e-05\n",
      "   6.68979505e-05   5.75727856e-06   4.13438789e-06   3.57190582e-06\n",
      "   3.07728066e-05   2.42844229e-05   2.31176652e-05   3.45992320e-05\n",
      "   2.66763462e-05   1.50753257e-05   2.41515024e-06   8.08555590e-06\n",
      "   1.54409549e-05   6.72900732e-07   9.63955988e-06   2.29300994e-05\n",
      "   8.22960264e-07   1.18887409e-05   2.71715137e-05   2.60818644e-07\n",
      "   9.51296802e-07   2.21920435e-06   2.94484601e-07   9.40105456e-07\n",
      "   1.94089777e-06   2.74194956e-07   6.59966444e-07   1.18079717e-06\n",
      "   1.58800927e-07   1.15392813e-06   2.59706779e-06   1.70589179e-07\n",
      "   1.52877217e-06   3.55577090e-06   1.16102229e-07   1.30340273e-06\n",
      "   2.92158389e-06   2.16690203e-07   1.56161308e-06   3.30313259e-06\n",
      "   1.93939789e-07   1.92922658e-06   4.33667376e-06   5.59430814e-07\n",
      "   1.21024100e-05   2.89575592e-05   5.14194864e-06   1.15493284e-04\n",
      "   2.60334955e-04   1.37426828e-06   2.44460068e-05   5.19279999e-05\n",
      "   3.93757679e-07   6.64409592e-06   1.71985487e-05   2.41783477e-07\n",
      "   1.53976257e-06   3.97754417e-06   2.31767029e-07   1.77647104e-06\n",
      "   4.03781352e-06   5.35505398e-08   4.71018030e-07   1.08687331e-06\n",
      "   3.49288652e-08   8.36617303e-07   2.33711622e-06   1.03378401e-08\n",
      "   1.91520697e-07   4.53350566e-07   1.04282229e-09   2.96577330e-08\n",
      "   9.20485909e-08   1.00659342e-10   1.59840669e-08   6.23957334e-08\n",
      "   3.70000000e+01]\n",
      "[  2.36865683e-02   6.52210882e-01   2.48139213e+00   4.13499224e-01\n",
      "   1.02444004e+00   3.70927925e+00   1.28033823e+00   1.57891470e+00\n",
      "   2.18916898e+00   4.55203527e-01   4.28440136e-01   4.67731901e-01\n",
      "   2.32672890e+00   1.12159022e+00   1.77464248e+00   5.18524750e+00\n",
      "   1.79616041e+01   2.99653522e+01   6.19790595e+01   7.64437932e+01\n",
      "   4.16619804e+01   4.39359144e+01   7.46028603e+01   1.94711446e+01\n",
      "   9.00623669e+01   8.52031587e+01   4.65750555e+01   9.55661760e+00\n",
      "   1.31871701e+01   2.82478634e+01   6.84412148e+00   5.34918714e+00\n",
      "   1.97576331e+00   2.08087375e+00   9.01624517e-01   1.22351007e+00\n",
      "   1.16550615e+00   5.42243659e-01   1.02537410e+00   1.05777473e+00\n",
      "   3.35707314e+00   5.19733807e+00   1.48223489e+00   1.99970870e+00\n",
      "   2.35858860e+00   5.40033124e-01   2.43601841e-01   1.02686894e-01\n",
      "   6.98995003e-02   5.69477171e-02   1.03122928e-01   1.35593014e-01\n",
      "   6.39751431e-02   2.21244202e-02   4.69003391e-02   2.97268459e-02\n",
      "   3.88708747e-02   4.68378402e-01   4.03474470e-01   5.00597812e-01\n",
      "   3.39228408e+00   2.57482976e+00   8.92733527e-01   1.79769202e+00\n",
      "   1.96646621e+00   2.43891644e+00   5.73351925e-02   2.86027875e-01\n",
      "   9.07405392e-01   4.30301572e-02   7.19963194e-02   2.79052907e-01\n",
      "   6.75849012e-01   5.35308386e-01   4.46741731e-01   3.82477196e-01\n",
      "   2.32659563e-01   9.12691520e-02   3.05240938e-01   5.11542111e-01\n",
      "   3.74660714e-01   1.97596454e-01   4.96238226e-01   2.63329283e-01\n",
      "   1.69493280e-01   3.09826550e-01   2.15107172e-01   3.50017959e-02\n",
      "   1.00919925e-01   8.10593848e-02   5.15511917e-01   3.41168877e-01\n",
      "   1.95831974e-01   1.09632683e+00   1.74677235e+00   2.38820352e+00\n",
      "   2.31356955e-01   4.87378215e-01   1.85833655e+00   1.04056434e+00\n",
      "   8.13280146e-01   1.79331265e+00   2.31290662e+00   1.17657941e+00\n",
      "   1.33276400e+00   1.66491900e+00   6.67247521e-01   2.11255417e-01\n",
      "   1.47365517e-01   1.04064298e-01   1.69738531e-02   3.80997766e-02\n",
      "   6.89695535e-02   7.46650710e-02   4.78396186e-02   4.47962204e-02\n",
      "   9.01594442e-02   1.32160396e-01   1.10082146e-01   3.27898208e-02\n",
      "   5.03185705e-01   4.56251727e-01   3.24386201e-01   6.45585702e-01\n",
      "   3.61264906e-01   5.94596864e-01   8.39166768e-02   1.85683802e-01\n",
      "   2.25207931e-01   7.44541526e-02   4.04371406e-02   4.95053230e-03\n",
      "   1.17390338e-01   7.58929932e-02   1.03962006e-01   1.26978334e-01\n",
      "   1.11988909e-01   6.00875657e-02   2.72875039e-02   4.12072323e-02\n",
      "   3.92465099e-02   9.69857608e-02   8.88895558e-02   4.87657758e-02\n",
      "   6.07362326e-03   1.42495274e-02   4.08220113e-02   5.09181742e-02\n",
      "   9.64606649e-02   1.14053909e-01   1.02187812e-01   1.51074646e-01\n",
      "   1.33039447e-01   9.86651901e-03   2.37930225e-02   3.89171727e-02\n",
      "   5.40696727e-02   8.13162767e-02   6.92932318e-02   1.23814496e-02\n",
      "   1.35433322e-02   1.27928341e-02   2.00294511e-03   2.22358437e-03\n",
      "   2.42290094e-03   1.25402569e-03   1.05059103e-03   2.54675812e-03\n",
      "   9.82735243e-04   1.16039713e-03   3.62882941e-03   1.94672193e-02\n",
      "   1.66198191e-02   1.22834482e-02   5.63358539e-03   8.76347098e-03\n",
      "   1.12506290e-02   1.30443517e-03   2.20971602e-03   4.34675037e-03\n",
      "   5.12599947e-03   5.41084012e-03   3.94209608e-03   1.53403604e-03\n",
      "   1.26375733e-03   6.98646732e-04   5.29391476e-04   8.20101970e-04\n",
      "   8.90722215e-04   7.90822431e-05   5.82375227e-05   5.18964933e-05\n",
      "   2.18921368e-04   3.20576360e-04   8.74505654e-04   1.07780357e-02\n",
      "   8.58559789e-03   5.34560314e-03   5.03040451e-03   2.83559749e-03\n",
      "   1.16058648e-03   2.24638653e-04   2.15614510e-04   2.03831227e-04\n",
      "   1.12652110e-03   1.06089751e-03   9.00345137e-04   9.20218545e-04\n",
      "   9.49887214e-04   9.56774929e-04   5.87904621e-05   1.05381386e-04\n",
      "   2.08777142e-04   4.59230328e-04   4.30771707e-04   4.28355212e-04\n",
      "   1.31170479e-03   7.19924942e-04   6.53548099e-04   1.15854621e-04\n",
      "   1.21034392e-04   3.00389585e-04   6.77713075e-05   1.20666963e-04\n",
      "   1.42796133e-04   3.53092246e-05   8.09898784e-05   1.19214584e-04\n",
      "   1.32154084e-04   9.70136925e-05   1.15595626e-04   1.92239006e-04\n",
      "   5.89601222e-04   1.10495232e-03   3.79359325e-04   7.90273435e-04\n",
      "   1.02684375e-03   7.26077921e-04   1.29480949e-03   1.33670800e-03\n",
      "   9.27391088e-04   9.92716301e-04   7.88900979e-04   1.05738201e-04\n",
      "   1.02925391e-04   8.22991498e-05   4.55657719e-05   6.11440568e-05\n",
      "   7.18256371e-05   1.87681996e-05   2.42201816e-05   4.41774197e-05\n",
      "   2.98039075e-05   2.18757170e-05   1.62865281e-05   2.09941696e-05\n",
      "   2.48430671e-05   2.84209481e-05   8.15146257e-05   1.11241053e-04\n",
      "   1.10159464e-04   8.40101111e-05   1.83954869e-04   3.28653774e-04\n",
      "   3.62071356e-04   3.71943107e-04   6.34422734e-04   9.69380686e-04\n",
      "   1.06121717e-03   1.60563438e-03   4.16445656e-04   3.21122704e-03\n",
      "   7.23188423e-03   1.98281580e-04   4.52663697e-04   1.11554499e-03\n",
      "   1.66227229e-05   1.85514199e-05   3.82624310e-05   2.83463470e-05\n",
      "   2.58057670e-05   4.60302344e-05   4.15872341e-06   2.58692176e-05\n",
      "   7.48914514e-05   2.17008183e-06   1.69594219e-05   4.83434889e-05\n",
      "   1.41768035e-06   3.26876812e-06   6.28948668e-06   1.37014794e-06\n",
      "   3.81231675e-06   7.39614896e-06   2.29347179e-06   4.44156170e-06\n",
      "   8.75609980e-06   2.16318796e-05   3.36644570e-05   4.70831489e-05\n",
      "   1.26685003e-04   1.92638933e-04   2.62569527e-04   4.45402803e-05\n",
      "   1.12565292e-04   1.70688554e-04   1.36938100e-05   3.62287235e-05\n",
      "   6.68979505e-05   5.75727856e-06   4.13438789e-06   3.57190582e-06\n",
      "   3.07728066e-05   2.42844229e-05   2.31176652e-05   3.45992320e-05\n",
      "   2.66763462e-05   1.50753257e-05   2.41515024e-06   8.08555590e-06\n",
      "   1.54409549e-05   6.72900732e-07   9.63955988e-06   2.29300994e-05\n",
      "   8.22960264e-07   1.18887409e-05   2.71715137e-05   2.60818644e-07\n",
      "   9.51296802e-07   2.21920435e-06   2.94484601e-07   9.40105456e-07\n",
      "   1.94089777e-06   2.74194956e-07   6.59966444e-07   1.18079717e-06\n",
      "   1.58800927e-07   1.15392813e-06   2.59706779e-06   1.70589179e-07\n",
      "   1.52877217e-06   3.55577090e-06   1.16102229e-07   1.30340273e-06\n",
      "   2.92158389e-06   2.16690203e-07   1.56161308e-06   3.30313259e-06\n",
      "   1.93939789e-07   1.92922658e-06   4.33667376e-06   5.59430814e-07\n",
      "   1.21024100e-05   2.89575592e-05   5.14194864e-06   1.15493284e-04\n",
      "   2.60334955e-04   1.37426828e-06   2.44460068e-05   5.19279999e-05\n",
      "   3.93757679e-07   6.64409592e-06   1.71985487e-05   2.41783477e-07\n",
      "   1.53976257e-06   3.97754417e-06   2.31767029e-07   1.77647104e-06\n",
      "   4.03781352e-06   5.35505398e-08   4.71018030e-07   1.08687331e-06\n",
      "   3.49288652e-08   8.36617303e-07   2.33711622e-06   1.03378401e-08\n",
      "   1.91520697e-07   4.53350566e-07   1.04282229e-09   2.96577330e-08\n",
      "   9.20485909e-08   1.00659342e-10   1.59840669e-08   6.23957334e-08\n",
      "   3.70000000e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "[  1.91480484e-02   2.86934884e-02   1.01706887e-01   5.00131136e-02\n",
      "   5.40190302e-02   1.11868872e-01   7.62126635e-02   1.29640479e-01\n",
      "   2.55441898e-01   1.20752772e-01   1.20175463e+00   2.74600931e+00\n",
      "   1.87266783e-01   1.65326122e+00   3.87028579e+00   6.47137496e-01\n",
      "   6.36387518e-01   1.37850039e+00   7.20810672e-01   6.22677065e+00\n",
      "   1.33857085e+01   2.05983977e+00   1.09495741e+01   1.80520415e+01\n",
      "   6.15512858e+00   6.10896503e+00   3.68144329e+00   1.76480829e+00\n",
      "   1.75610344e+00   5.21182477e+00   1.13387813e+00   3.32344267e+00\n",
      "   5.27462887e+00   3.04794900e+00   1.48853673e+00   2.17251483e+00\n",
      "   8.71374063e-01   1.67653769e+00   3.38233082e+00   3.04722858e-02\n",
      "   5.02009068e-01   1.29311758e+00   2.51611832e-01   1.79728123e-01\n",
      "   4.92366638e-02   6.01675352e-01   3.91533583e-01   2.33928720e-01\n",
      "   6.96361108e-02   5.15497041e-02   7.08519914e-02   1.05774221e-02\n",
      "   9.32959806e-03   1.42077146e-02   3.34147132e-02   7.10369107e-02\n",
      "   8.62344049e-02   1.06882931e+00   8.29501690e-01   1.33751038e+00\n",
      "   1.39531387e+00   2.95338686e+00   4.97195282e+00   1.68251870e-01\n",
      "   7.75316616e-01   2.48478138e+00   9.85670836e-01   5.89419195e-01\n",
      "   3.23949543e-01   1.84814781e+00   5.31219324e-01   8.32532882e-03\n",
      "   9.52153565e-01   5.30426151e-01   1.11517730e-01   4.85157071e-02\n",
      "   7.60859565e-02   2.93632087e-01   2.05847547e-01   3.31469544e-01\n",
      "   6.02246408e-01   5.40962285e-02   9.99458593e-02   3.05954713e-01\n",
      "   3.01276175e-02   6.63392484e-02   1.18958468e-01   1.06992708e-02\n",
      "   7.43755908e-02   6.78242634e-02   1.28970956e-02   9.79371802e-02\n",
      "   2.31131298e-01   9.78961958e-02   1.17526059e-01   1.00651279e-01\n",
      "   2.97729650e-01   2.66008852e-01   2.33638565e-01   1.81468774e-01\n",
      "   3.33006308e-01   2.47861582e-01   2.75852006e-01   8.27729003e-02\n",
      "   1.94638922e-02   8.09045739e-01   3.61903493e-01   1.48674893e-01\n",
      "   8.66741591e-01   7.57577367e-01   3.35485306e-01   2.93612095e-02\n",
      "   1.12892691e-01   3.70917882e-01   1.48654950e-02   4.39129108e-02\n",
      "   1.39314879e-01   2.52491488e-02   4.75903908e-02   8.96563022e-02\n",
      "   3.51985731e-02   5.91930117e-02   2.75708971e-02   3.41161632e-02\n",
      "   3.08778895e-02   3.47299191e-02   3.26632188e-02   5.60637991e-02\n",
      "   4.65994066e-02   4.18999833e-02   9.25160582e-02   6.08878504e-02\n",
      "   4.73006302e-02   7.97329906e-02   1.31691156e-01   8.22400905e-02\n",
      "   1.27049450e-01   2.13560859e-01   1.26487561e-01   1.20425062e-01\n",
      "   1.28696516e-01   5.75399593e-02   7.01475918e-02   7.98038855e-02\n",
      "   1.42765154e-03   2.33025868e-03   2.04769379e-03   3.76898600e-03\n",
      "   4.03508849e-03   7.04542647e-03   1.48322862e-02   1.40226383e-02\n",
      "   3.21682753e-02   8.28181259e-03   1.21247934e-02   2.64309925e-02\n",
      "   9.20170493e-02   7.92558965e-02   9.33741102e-02   5.92055531e-02\n",
      "   5.42401303e-02   3.18738356e-02   5.28931074e-02   3.90696473e-02\n",
      "   1.82288194e-02   7.62575480e-02   3.54639053e-02   1.26875308e-02\n",
      "   7.97218386e-03   2.83628286e-03   1.63900323e-03   3.77120114e-02\n",
      "   6.52591422e-02   7.87196328e-02   3.00241906e-02   2.57699113e-02\n",
      "   2.25404493e-02   1.41808806e-03   3.03689178e-03   8.53384040e-03\n",
      "   1.12563151e-03   5.08809097e-03   1.73133802e-02   3.41206334e-03\n",
      "   1.43898885e-02   2.29298688e-02   8.57767799e-03   1.32870700e-02\n",
      "   2.07994679e-02   1.58420916e-02   7.06071236e-03   2.30442208e-03\n",
      "   2.83425656e-02   1.38663639e-02   1.06185282e-02   6.04995276e-02\n",
      "   8.95112522e-02   1.09569265e-01   8.22822232e-02   8.07431953e-02\n",
      "   1.00920558e-01   1.51801104e-01   1.38438548e-01   1.32439796e-01\n",
      "   4.08442365e-02   3.46001258e-02   4.38332661e-02   5.43350498e-03\n",
      "   6.10960248e-03   5.67759942e-03   1.68527125e-02   1.85866522e-02\n",
      "   2.91045515e-02   3.55612066e-03   5.58366895e-03   7.42147353e-03\n",
      "   4.06220653e-03   7.67976680e-03   8.44724815e-03   2.27602396e-03\n",
      "   4.14725949e-03   1.11475160e-02   5.95787395e-02   7.47671024e-02\n",
      "   9.06710178e-02   4.02785528e-02   3.54921022e-02   5.69847545e-02\n",
      "   1.89918822e-02   1.45845744e-02   1.32701364e-02   1.30391872e-02\n",
      "   1.23406854e-02   7.82744041e-03   3.84560878e-03   3.19829887e-03\n",
      "   2.89461284e-03   3.22419181e-02   2.53704138e-02   2.51430820e-02\n",
      "   6.44124316e-03   7.89834965e-03   9.04642450e-03   4.04102213e-03\n",
      "   3.92611713e-03   3.11870659e-03   1.89966262e-03   1.65690060e-03\n",
      "   7.23781090e-04   8.04891411e-03   9.86234067e-03   8.70349616e-03\n",
      "   4.98861317e-03   5.37673973e-03   4.35841200e-03   2.51043663e-03\n",
      "   1.94945547e-03   8.46461757e-04   9.58419697e-04   5.72292897e-04\n",
      "   2.96094125e-04   1.67094497e-02   1.27402939e-02   7.16244378e-03\n",
      "   2.19948846e-03   2.06739209e-03   1.40893281e-03   3.60983510e-03\n",
      "   2.84407485e-03   2.65402224e-03   9.46605922e-04   1.08903463e-03\n",
      "   2.17347219e-03   4.80269858e-04   5.76525021e-04   7.10941031e-04\n",
      "   1.30662061e-03   1.42197356e-03   1.06526857e-03   5.61797308e-04\n",
      "   5.52118244e-04   3.10871202e-04   4.47940586e-04   3.70215949e-04\n",
      "   2.41490929e-04   7.06542015e-04   3.50574960e-04   1.79086288e-04\n",
      "   1.08888817e-04   1.11311645e-04   8.33352776e-05   7.49017158e-05\n",
      "   7.37772891e-05   5.30782440e-05   2.66030258e-04   2.11603589e-04\n",
      "   1.76960792e-04   9.78402719e-04   6.65585566e-04   5.58195888e-04\n",
      "   6.39020147e-04   5.30961026e-04   4.38729119e-04   1.58163448e-04\n",
      "   6.72737667e-05   2.51928730e-05   8.47323787e-05   3.50045315e-05\n",
      "   1.53721206e-05   7.34391528e-05   2.41883463e-05   6.47667789e-06\n",
      "   5.59030288e-06   2.94210947e-06   2.34157785e-06   2.07928114e-06\n",
      "   1.54226324e-06   2.37345793e-06   4.86016123e-06   2.48977453e-06\n",
      "   2.23181370e-06   5.60846537e-06   3.17845693e-06   2.56167015e-06\n",
      "   6.88856638e-06   2.89525297e-06   1.66919065e-06   3.35224588e-06\n",
      "   2.13370239e-06   2.13496873e-06   1.19170741e-05   5.63195761e-06\n",
      "   2.57072872e-06   1.13413311e-05   4.72655530e-06   1.77279570e-06\n",
      "   3.48707837e-06   1.42966069e-06   7.33206929e-07   8.07912709e-06\n",
      "   3.18357962e-06   1.34631694e-06   8.23388127e-06   3.51381196e-06\n",
      "   1.80075761e-06   7.13479449e-06   3.11996491e-06   1.60702646e-06\n",
      "   1.61487256e-06   1.04675880e-06   1.23149599e-06   1.25223973e-06\n",
      "   1.06174948e-06   1.23860355e-06   2.27065770e-06   1.27237392e-06\n",
      "   1.52555900e-06   1.29534652e-06   8.03780091e-07   8.32136277e-07\n",
      "   1.99216553e-06   1.05461886e-06   8.26429776e-07   1.57707620e-06\n",
      "   1.04280532e-06   1.11023395e-06   9.98508137e-07   6.62909690e-07\n",
      "   8.84683129e-07   4.14131970e-07   3.63587172e-07   7.03848532e-07\n",
      "   1.51156526e-07   2.08145099e-07   5.69476222e-07   1.58522240e-07\n",
      "   1.89320152e-07   5.51879979e-07   1.42206841e-07   1.59792250e-07\n",
      "   4.88652691e-07   1.51618304e-07   1.58951167e-07   4.81106543e-07\n",
      "   3.00000000e+00]\n",
      "[  1.91480484e-02   2.86934884e-02   1.01706887e-01   5.00131136e-02\n",
      "   5.40190302e-02   1.11868872e-01   7.62126635e-02   1.29640479e-01\n",
      "   2.55441898e-01   1.20752772e-01   1.20175463e+00   2.74600931e+00\n",
      "   1.87266783e-01   1.65326122e+00   3.87028579e+00   6.47137496e-01\n",
      "   6.36387518e-01   1.37850039e+00   7.20810672e-01   6.22677065e+00\n",
      "   1.33857085e+01   2.05983977e+00   1.09495741e+01   1.80520415e+01\n",
      "   6.15512858e+00   6.10896503e+00   3.68144329e+00   1.76480829e+00\n",
      "   1.75610344e+00   5.21182477e+00   1.13387813e+00   3.32344267e+00\n",
      "   5.27462887e+00   3.04794900e+00   1.48853673e+00   2.17251483e+00\n",
      "   8.71374063e-01   1.67653769e+00   3.38233082e+00   3.04722858e-02\n",
      "   5.02009068e-01   1.29311758e+00   2.51611832e-01   1.79728123e-01\n",
      "   4.92366638e-02   6.01675352e-01   3.91533583e-01   2.33928720e-01\n",
      "   6.96361108e-02   5.15497041e-02   7.08519914e-02   1.05774221e-02\n",
      "   9.32959806e-03   1.42077146e-02   3.34147132e-02   7.10369107e-02\n",
      "   8.62344049e-02   1.06882931e+00   8.29501690e-01   1.33751038e+00\n",
      "   1.39531387e+00   2.95338686e+00   4.97195282e+00   1.68251870e-01\n",
      "   7.75316616e-01   2.48478138e+00   9.85670836e-01   5.89419195e-01\n",
      "   3.23949543e-01   1.84814781e+00   5.31219324e-01   8.32532882e-03\n",
      "   9.52153565e-01   5.30426151e-01   1.11517730e-01   4.85157071e-02\n",
      "   7.60859565e-02   2.93632087e-01   2.05847547e-01   3.31469544e-01\n",
      "   6.02246408e-01   5.40962285e-02   9.99458593e-02   3.05954713e-01\n",
      "   3.01276175e-02   6.63392484e-02   1.18958468e-01   1.06992708e-02\n",
      "   7.43755908e-02   6.78242634e-02   1.28970956e-02   9.79371802e-02\n",
      "   2.31131298e-01   9.78961958e-02   1.17526059e-01   1.00651279e-01\n",
      "   2.97729650e-01   2.66008852e-01   2.33638565e-01   1.81468774e-01\n",
      "   3.33006308e-01   2.47861582e-01   2.75852006e-01   8.27729003e-02\n",
      "   1.94638922e-02   8.09045739e-01   3.61903493e-01   1.48674893e-01\n",
      "   8.66741591e-01   7.57577367e-01   3.35485306e-01   2.93612095e-02\n",
      "   1.12892691e-01   3.70917882e-01   1.48654950e-02   4.39129108e-02\n",
      "   1.39314879e-01   2.52491488e-02   4.75903908e-02   8.96563022e-02\n",
      "   3.51985731e-02   5.91930117e-02   2.75708971e-02   3.41161632e-02\n",
      "   3.08778895e-02   3.47299191e-02   3.26632188e-02   5.60637991e-02\n",
      "   4.65994066e-02   4.18999833e-02   9.25160582e-02   6.08878504e-02\n",
      "   4.73006302e-02   7.97329906e-02   1.31691156e-01   8.22400905e-02\n",
      "   1.27049450e-01   2.13560859e-01   1.26487561e-01   1.20425062e-01\n",
      "   1.28696516e-01   5.75399593e-02   7.01475918e-02   7.98038855e-02\n",
      "   1.42765154e-03   2.33025868e-03   2.04769379e-03   3.76898600e-03\n",
      "   4.03508849e-03   7.04542647e-03   1.48322862e-02   1.40226383e-02\n",
      "   3.21682753e-02   8.28181259e-03   1.21247934e-02   2.64309925e-02\n",
      "   9.20170493e-02   7.92558965e-02   9.33741102e-02   5.92055531e-02\n",
      "   5.42401303e-02   3.18738356e-02   5.28931074e-02   3.90696473e-02\n",
      "   1.82288194e-02   7.62575480e-02   3.54639053e-02   1.26875308e-02\n",
      "   7.97218386e-03   2.83628286e-03   1.63900323e-03   3.77120114e-02\n",
      "   6.52591422e-02   7.87196328e-02   3.00241906e-02   2.57699113e-02\n",
      "   2.25404493e-02   1.41808806e-03   3.03689178e-03   8.53384040e-03\n",
      "   1.12563151e-03   5.08809097e-03   1.73133802e-02   3.41206334e-03\n",
      "   1.43898885e-02   2.29298688e-02   8.57767799e-03   1.32870700e-02\n",
      "   2.07994679e-02   1.58420916e-02   7.06071236e-03   2.30442208e-03\n",
      "   2.83425656e-02   1.38663639e-02   1.06185282e-02   6.04995276e-02\n",
      "   8.95112522e-02   1.09569265e-01   8.22822232e-02   8.07431953e-02\n",
      "   1.00920558e-01   1.51801104e-01   1.38438548e-01   1.32439796e-01\n",
      "   4.08442365e-02   3.46001258e-02   4.38332661e-02   5.43350498e-03\n",
      "   6.10960248e-03   5.67759942e-03   1.68527125e-02   1.85866522e-02\n",
      "   2.91045515e-02   3.55612066e-03   5.58366895e-03   7.42147353e-03\n",
      "   4.06220653e-03   7.67976680e-03   8.44724815e-03   2.27602396e-03\n",
      "   4.14725949e-03   1.11475160e-02   5.95787395e-02   7.47671024e-02\n",
      "   9.06710178e-02   4.02785528e-02   3.54921022e-02   5.69847545e-02\n",
      "   1.89918822e-02   1.45845744e-02   1.32701364e-02   1.30391872e-02\n",
      "   1.23406854e-02   7.82744041e-03   3.84560878e-03   3.19829887e-03\n",
      "   2.89461284e-03   3.22419181e-02   2.53704138e-02   2.51430820e-02\n",
      "   6.44124316e-03   7.89834965e-03   9.04642450e-03   4.04102213e-03\n",
      "   3.92611713e-03   3.11870659e-03   1.89966262e-03   1.65690060e-03\n",
      "   7.23781090e-04   8.04891411e-03   9.86234067e-03   8.70349616e-03\n",
      "   4.98861317e-03   5.37673973e-03   4.35841200e-03   2.51043663e-03\n",
      "   1.94945547e-03   8.46461757e-04   9.58419697e-04   5.72292897e-04\n",
      "   2.96094125e-04   1.67094497e-02   1.27402939e-02   7.16244378e-03\n",
      "   2.19948846e-03   2.06739209e-03   1.40893281e-03   3.60983510e-03\n",
      "   2.84407485e-03   2.65402224e-03   9.46605922e-04   1.08903463e-03\n",
      "   2.17347219e-03   4.80269858e-04   5.76525021e-04   7.10941031e-04\n",
      "   1.30662061e-03   1.42197356e-03   1.06526857e-03   5.61797308e-04\n",
      "   5.52118244e-04   3.10871202e-04   4.47940586e-04   3.70215949e-04\n",
      "   2.41490929e-04   7.06542015e-04   3.50574960e-04   1.79086288e-04\n",
      "   1.08888817e-04   1.11311645e-04   8.33352776e-05   7.49017158e-05\n",
      "   7.37772891e-05   5.30782440e-05   2.66030258e-04   2.11603589e-04\n",
      "   1.76960792e-04   9.78402719e-04   6.65585566e-04   5.58195888e-04\n",
      "   6.39020147e-04   5.30961026e-04   4.38729119e-04   1.58163448e-04\n",
      "   6.72737667e-05   2.51928730e-05   8.47323787e-05   3.50045315e-05\n",
      "   1.53721206e-05   7.34391528e-05   2.41883463e-05   6.47667789e-06\n",
      "   5.59030288e-06   2.94210947e-06   2.34157785e-06   2.07928114e-06\n",
      "   1.54226324e-06   2.37345793e-06   4.86016123e-06   2.48977453e-06\n",
      "   2.23181370e-06   5.60846537e-06   3.17845693e-06   2.56167015e-06\n",
      "   6.88856638e-06   2.89525297e-06   1.66919065e-06   3.35224588e-06\n",
      "   2.13370239e-06   2.13496873e-06   1.19170741e-05   5.63195761e-06\n",
      "   2.57072872e-06   1.13413311e-05   4.72655530e-06   1.77279570e-06\n",
      "   3.48707837e-06   1.42966069e-06   7.33206929e-07   8.07912709e-06\n",
      "   3.18357962e-06   1.34631694e-06   8.23388127e-06   3.51381196e-06\n",
      "   1.80075761e-06   7.13479449e-06   3.11996491e-06   1.60702646e-06\n",
      "   1.61487256e-06   1.04675880e-06   1.23149599e-06   1.25223973e-06\n",
      "   1.06174948e-06   1.23860355e-06   2.27065770e-06   1.27237392e-06\n",
      "   1.52555900e-06   1.29534652e-06   8.03780091e-07   8.32136277e-07\n",
      "   1.99216553e-06   1.05461886e-06   8.26429776e-07   1.57707620e-06\n",
      "   1.04280532e-06   1.11023395e-06   9.98508137e-07   6.62909690e-07\n",
      "   8.84683129e-07   4.14131970e-07   3.63587172e-07   7.03848532e-07\n",
      "   1.51156526e-07   2.08145099e-07   5.69476222e-07   1.58522240e-07\n",
      "   1.89320152e-07   5.51879979e-07   1.42206841e-07   1.59792250e-07\n",
      "   4.88652691e-07   1.51618304e-07   1.58951167e-07   4.81106543e-07\n",
      "   3.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "[  5.14995424e-01   4.10200465e-01   9.98164800e-01   8.00033409e-01\n",
      "   5.47553735e-01   1.28326381e+00   2.71799229e+00   1.78096947e+00\n",
      "   2.76535719e+00   2.34701372e+00   2.75618784e+00   2.08442145e+00\n",
      "   1.02901855e+01   8.31324850e+00   6.30102718e+00   2.15031043e+01\n",
      "   1.72106026e+01   5.83951143e+00   1.32915371e+01   1.13589539e+01\n",
      "   1.90091268e+01   1.08556742e+02   3.69240786e+01   9.22878131e+00\n",
      "   1.86568406e+02   2.15107219e+02   1.86679619e+02   7.98183176e+01\n",
      "   1.06085222e+02   6.24589226e+01   1.60441193e+02   4.66340392e+01\n",
      "   6.28328361e-01   5.56289136e+01   2.57921699e+01   2.04647487e+00\n",
      "   2.32837563e+00   3.37951211e+00   1.89306019e+00   5.02546504e-01\n",
      "   5.14682997e-01   6.48252706e-01   2.71015802e+00   1.14984790e+00\n",
      "   4.54933309e-01   2.41961204e+00   1.50324488e+00   3.40159295e-01\n",
      "   6.20578273e-02   1.18463127e-01   4.05546207e-01   8.14875632e-02\n",
      "   3.94944552e-01   1.06232375e+00   1.65352884e-01   8.03490275e-01\n",
      "   1.58909761e+00   1.64410731e-01   2.31977547e-01   3.70867964e-01\n",
      "   1.14470642e-01   6.00701368e-02   1.31606441e-01   5.97670097e-01\n",
      "   3.57081501e-01   2.86836754e-01   2.55604757e+00   6.75980628e-01\n",
      "   2.40104115e-01   2.20749231e+00   3.17299335e+00   1.87608805e+00\n",
      "   7.56360906e+00   8.71414046e+00   4.61593206e+00   5.68779733e+00\n",
      "   3.14350330e+00   1.07420466e+00   5.90698231e-01   4.01756374e-01\n",
      "   7.11767600e-01   1.69936093e-01   2.88602760e-01   7.58501640e-02\n",
      "   3.16075725e-01   2.74878829e-01   9.94659096e-02   5.69710275e-02\n",
      "   7.10970347e-02   1.48781195e-01   3.39536248e-03   1.71440131e-02\n",
      "   7.85756165e-02   6.59414056e-02   4.65417265e-02   7.99333431e-02\n",
      "   9.30823964e-02   1.83169690e-01   3.16120942e-01   3.97803230e-01\n",
      "   4.39194469e-01   5.03191167e-01   6.58703658e-01   1.74818368e-01\n",
      "   7.41764558e-02   9.71948847e-01   2.68325148e-01   9.12085785e-02\n",
      "   1.12003458e+00   1.77518045e+00   1.88580702e+00   4.89180332e-01\n",
      "   6.74492994e-01   7.80007801e-01   4.44223654e-01   4.21995252e-01\n",
      "   1.25804991e-01   5.40121437e-01   4.17612257e-01   3.74760289e-01\n",
      "   1.53725911e-01   9.68683510e-02   1.14225592e-01   1.23859512e-01\n",
      "   3.77723845e-02   9.53912608e-03   1.61867841e-01   5.53533297e-02\n",
      "   3.39973226e-02   1.83314427e-01   1.66665935e-01   1.06295054e-01\n",
      "   4.43945757e-02   8.79846984e-02   9.80284435e-02   6.33662408e-01\n",
      "   5.28081578e-01   4.51934302e-01   3.02219760e-01   4.01043934e-01\n",
      "   7.52219121e-01   6.93323318e-02   6.65373903e-02   5.52022320e-02\n",
      "   8.32720916e-02   3.64209237e-02   6.68085221e-02   1.79834889e-01\n",
      "   2.24800150e-01   3.23402059e-01   3.77151112e-02   4.71740481e-02\n",
      "   5.84988302e-02   3.47834376e-02   2.02539238e-02   1.01564719e-02\n",
      "   1.16602361e-02   4.37273387e-02   7.63079036e-02   3.65119253e-02\n",
      "   4.14480822e-02   3.56977771e-02   3.69742779e-01   3.01768227e-01\n",
      "   1.67361632e-01   3.67653401e-02   4.06295722e-02   2.19294900e-02\n",
      "   1.73165809e-02   1.28543025e-02   8.93233416e-03   2.88223009e-02\n",
      "   2.30933251e-02   1.07650391e-02   1.15549672e-01   2.11870767e-01\n",
      "   2.54594733e-01   2.70699925e-02   3.85611049e-02   8.20011389e-02\n",
      "   2.24986854e-03   5.77840610e-03   1.47990441e-02   3.86932328e-03\n",
      "   5.93292865e-03   1.60708410e-02   4.49494800e-03   5.77170659e-03\n",
      "   9.08361882e-03   3.90421134e-03   1.03099264e-02   1.70772223e-02\n",
      "   2.35899100e-03   2.94164313e-03   3.02774538e-03   1.82204254e-03\n",
      "   1.06428975e-03   1.48968800e-03   5.46626254e-04   7.07358753e-04\n",
      "   1.53693401e-03   5.05203211e-04   5.10966072e-04   9.55507943e-04\n",
      "   4.59959071e-04   7.32134776e-04   1.17805951e-03   3.08565237e-04\n",
      "   5.52570548e-04   1.21595478e-03   1.83118170e-04   6.08890540e-04\n",
      "   1.33993188e-03   1.75715312e-04   3.72381467e-04   5.11994173e-04\n",
      "   2.43986539e-04   5.12572961e-04   1.09871412e-03   3.45711956e-04\n",
      "   3.58879412e-04   9.36567595e-04   8.44706372e-04   7.01733018e-04\n",
      "   1.17894279e-03   1.63355256e-04   2.54695719e-04   6.95765715e-04\n",
      "   7.26599399e-04   4.37044281e-04   7.24936738e-04   3.87369810e-04\n",
      "   4.30411217e-04   9.96670226e-04   2.33769859e-04   1.60662965e-04\n",
      "   1.49365682e-04   4.33820187e-05   1.87757964e-04   4.71505215e-04\n",
      "   5.39294534e-05   1.60617043e-04   4.23890635e-04   2.17010222e-05\n",
      "   8.69529804e-05   2.56761516e-04   3.64272126e-05   7.97409166e-05\n",
      "   2.00959559e-04   2.42061522e-05   8.86092638e-05   2.25986793e-04\n",
      "   2.85163820e-05   9.45126375e-05   2.62769043e-04   2.72472221e-05\n",
      "   5.52379443e-05   1.11960425e-04   2.35090557e-05   7.57415756e-05\n",
      "   2.39908604e-04   1.29217754e-05   6.58969294e-05   2.20907889e-04\n",
      "   4.66593177e-05   1.08336972e-04   1.95539920e-04   8.66072623e-05\n",
      "   1.99452563e-04   3.87445878e-04   2.26212277e-05   5.40822903e-05\n",
      "   9.30962682e-05   2.54407871e-04   2.12376385e-04   1.42470292e-04\n",
      "   4.31583695e-04   3.31131110e-04   4.77013901e-04   1.65812122e-04\n",
      "   3.30606392e-04   5.14701120e-04   9.63197145e-05   1.87058052e-04\n",
      "   3.39945078e-04   4.85255580e-05   1.36180854e-04   1.52709108e-04\n",
      "   8.38866286e-06   1.86453114e-05   4.57015924e-05   1.22617765e-05\n",
      "   9.67768197e-05   2.95252888e-04   6.12958276e-06   3.01258888e-05\n",
      "   9.36961397e-05   2.72480748e-06   9.98979713e-06   2.62895089e-05\n",
      "   3.22042658e-06   9.28019299e-06   2.84768719e-05   3.02841733e-06\n",
      "   4.48149826e-06   1.15990797e-05   5.41014980e-07   4.44118451e-06\n",
      "   1.52202787e-05   2.65750185e-07   4.11037205e-06   1.48703308e-05\n",
      "   1.47170598e-06   4.63890454e-06   1.55071441e-05   1.30211900e-06\n",
      "   5.11298077e-06   1.64814011e-05   1.19080737e-06   4.94263739e-06\n",
      "   1.45028418e-05   6.49371398e-07   2.79734217e-06   9.85335077e-06\n",
      "   1.80906477e-06   3.36425272e-06   9.89138835e-06   1.19817788e-06\n",
      "   3.61463286e-06   8.82750729e-06   1.06078626e-06   3.42446880e-06\n",
      "   1.07909045e-05   6.56393318e-07   2.27838622e-06   7.41741371e-06\n",
      "   3.45582416e-07   1.86399551e-06   6.27952204e-06   1.18405982e-06\n",
      "   2.07386354e-06   6.00466736e-06   8.75077052e-07   2.50385999e-06\n",
      "   6.05461417e-06   6.62890916e-07   2.15416707e-06   5.53298237e-06\n",
      "   5.36574475e-07   1.70221534e-06   5.24482425e-06   7.45117254e-07\n",
      "   1.90456344e-06   5.24993626e-06   7.16321588e-07   1.55390676e-06\n",
      "   4.94493766e-06   2.06131812e-07   1.13306181e-06   3.78679544e-06\n",
      "   1.55567157e-07   1.12374401e-06   4.02223274e-06   1.00941141e-07\n",
      "   1.13777442e-06   4.10090408e-06   9.37264690e-08   8.63123912e-07\n",
      "   3.21015573e-06   2.60191351e-08   9.35540410e-07   3.59787310e-06\n",
      "   2.74271710e-08   8.59173388e-07   3.34143234e-06   1.20562428e-08\n",
      "   7.81981367e-07   3.08116220e-06   2.22466828e-09   7.70647016e-07\n",
      "   3.05998968e-06   8.50515857e-10   7.52775754e-07   2.99169876e-06\n",
      "   3.10000000e+01]\n",
      "[  5.14995424e-01   4.10200465e-01   9.98164800e-01   8.00033409e-01\n",
      "   5.47553735e-01   1.28326381e+00   2.71799229e+00   1.78096947e+00\n",
      "   2.76535719e+00   2.34701372e+00   2.75618784e+00   2.08442145e+00\n",
      "   1.02901855e+01   8.31324850e+00   6.30102718e+00   2.15031043e+01\n",
      "   1.72106026e+01   5.83951143e+00   1.32915371e+01   1.13589539e+01\n",
      "   1.90091268e+01   1.08556742e+02   3.69240786e+01   9.22878131e+00\n",
      "   1.86568406e+02   2.15107219e+02   1.86679619e+02   7.98183176e+01\n",
      "   1.06085222e+02   6.24589226e+01   1.60441193e+02   4.66340392e+01\n",
      "   6.28328361e-01   5.56289136e+01   2.57921699e+01   2.04647487e+00\n",
      "   2.32837563e+00   3.37951211e+00   1.89306019e+00   5.02546504e-01\n",
      "   5.14682997e-01   6.48252706e-01   2.71015802e+00   1.14984790e+00\n",
      "   4.54933309e-01   2.41961204e+00   1.50324488e+00   3.40159295e-01\n",
      "   6.20578273e-02   1.18463127e-01   4.05546207e-01   8.14875632e-02\n",
      "   3.94944552e-01   1.06232375e+00   1.65352884e-01   8.03490275e-01\n",
      "   1.58909761e+00   1.64410731e-01   2.31977547e-01   3.70867964e-01\n",
      "   1.14470642e-01   6.00701368e-02   1.31606441e-01   5.97670097e-01\n",
      "   3.57081501e-01   2.86836754e-01   2.55604757e+00   6.75980628e-01\n",
      "   2.40104115e-01   2.20749231e+00   3.17299335e+00   1.87608805e+00\n",
      "   7.56360906e+00   8.71414046e+00   4.61593206e+00   5.68779733e+00\n",
      "   3.14350330e+00   1.07420466e+00   5.90698231e-01   4.01756374e-01\n",
      "   7.11767600e-01   1.69936093e-01   2.88602760e-01   7.58501640e-02\n",
      "   3.16075725e-01   2.74878829e-01   9.94659096e-02   5.69710275e-02\n",
      "   7.10970347e-02   1.48781195e-01   3.39536248e-03   1.71440131e-02\n",
      "   7.85756165e-02   6.59414056e-02   4.65417265e-02   7.99333431e-02\n",
      "   9.30823964e-02   1.83169690e-01   3.16120942e-01   3.97803230e-01\n",
      "   4.39194469e-01   5.03191167e-01   6.58703658e-01   1.74818368e-01\n",
      "   7.41764558e-02   9.71948847e-01   2.68325148e-01   9.12085785e-02\n",
      "   1.12003458e+00   1.77518045e+00   1.88580702e+00   4.89180332e-01\n",
      "   6.74492994e-01   7.80007801e-01   4.44223654e-01   4.21995252e-01\n",
      "   1.25804991e-01   5.40121437e-01   4.17612257e-01   3.74760289e-01\n",
      "   1.53725911e-01   9.68683510e-02   1.14225592e-01   1.23859512e-01\n",
      "   3.77723845e-02   9.53912608e-03   1.61867841e-01   5.53533297e-02\n",
      "   3.39973226e-02   1.83314427e-01   1.66665935e-01   1.06295054e-01\n",
      "   4.43945757e-02   8.79846984e-02   9.80284435e-02   6.33662408e-01\n",
      "   5.28081578e-01   4.51934302e-01   3.02219760e-01   4.01043934e-01\n",
      "   7.52219121e-01   6.93323318e-02   6.65373903e-02   5.52022320e-02\n",
      "   8.32720916e-02   3.64209237e-02   6.68085221e-02   1.79834889e-01\n",
      "   2.24800150e-01   3.23402059e-01   3.77151112e-02   4.71740481e-02\n",
      "   5.84988302e-02   3.47834376e-02   2.02539238e-02   1.01564719e-02\n",
      "   1.16602361e-02   4.37273387e-02   7.63079036e-02   3.65119253e-02\n",
      "   4.14480822e-02   3.56977771e-02   3.69742779e-01   3.01768227e-01\n",
      "   1.67361632e-01   3.67653401e-02   4.06295722e-02   2.19294900e-02\n",
      "   1.73165809e-02   1.28543025e-02   8.93233416e-03   2.88223009e-02\n",
      "   2.30933251e-02   1.07650391e-02   1.15549672e-01   2.11870767e-01\n",
      "   2.54594733e-01   2.70699925e-02   3.85611049e-02   8.20011389e-02\n",
      "   2.24986854e-03   5.77840610e-03   1.47990441e-02   3.86932328e-03\n",
      "   5.93292865e-03   1.60708410e-02   4.49494800e-03   5.77170659e-03\n",
      "   9.08361882e-03   3.90421134e-03   1.03099264e-02   1.70772223e-02\n",
      "   2.35899100e-03   2.94164313e-03   3.02774538e-03   1.82204254e-03\n",
      "   1.06428975e-03   1.48968800e-03   5.46626254e-04   7.07358753e-04\n",
      "   1.53693401e-03   5.05203211e-04   5.10966072e-04   9.55507943e-04\n",
      "   4.59959071e-04   7.32134776e-04   1.17805951e-03   3.08565237e-04\n",
      "   5.52570548e-04   1.21595478e-03   1.83118170e-04   6.08890540e-04\n",
      "   1.33993188e-03   1.75715312e-04   3.72381467e-04   5.11994173e-04\n",
      "   2.43986539e-04   5.12572961e-04   1.09871412e-03   3.45711956e-04\n",
      "   3.58879412e-04   9.36567595e-04   8.44706372e-04   7.01733018e-04\n",
      "   1.17894279e-03   1.63355256e-04   2.54695719e-04   6.95765715e-04\n",
      "   7.26599399e-04   4.37044281e-04   7.24936738e-04   3.87369810e-04\n",
      "   4.30411217e-04   9.96670226e-04   2.33769859e-04   1.60662965e-04\n",
      "   1.49365682e-04   4.33820187e-05   1.87757964e-04   4.71505215e-04\n",
      "   5.39294534e-05   1.60617043e-04   4.23890635e-04   2.17010222e-05\n",
      "   8.69529804e-05   2.56761516e-04   3.64272126e-05   7.97409166e-05\n",
      "   2.00959559e-04   2.42061522e-05   8.86092638e-05   2.25986793e-04\n",
      "   2.85163820e-05   9.45126375e-05   2.62769043e-04   2.72472221e-05\n",
      "   5.52379443e-05   1.11960425e-04   2.35090557e-05   7.57415756e-05\n",
      "   2.39908604e-04   1.29217754e-05   6.58969294e-05   2.20907889e-04\n",
      "   4.66593177e-05   1.08336972e-04   1.95539920e-04   8.66072623e-05\n",
      "   1.99452563e-04   3.87445878e-04   2.26212277e-05   5.40822903e-05\n",
      "   9.30962682e-05   2.54407871e-04   2.12376385e-04   1.42470292e-04\n",
      "   4.31583695e-04   3.31131110e-04   4.77013901e-04   1.65812122e-04\n",
      "   3.30606392e-04   5.14701120e-04   9.63197145e-05   1.87058052e-04\n",
      "   3.39945078e-04   4.85255580e-05   1.36180854e-04   1.52709108e-04\n",
      "   8.38866286e-06   1.86453114e-05   4.57015924e-05   1.22617765e-05\n",
      "   9.67768197e-05   2.95252888e-04   6.12958276e-06   3.01258888e-05\n",
      "   9.36961397e-05   2.72480748e-06   9.98979713e-06   2.62895089e-05\n",
      "   3.22042658e-06   9.28019299e-06   2.84768719e-05   3.02841733e-06\n",
      "   4.48149826e-06   1.15990797e-05   5.41014980e-07   4.44118451e-06\n",
      "   1.52202787e-05   2.65750185e-07   4.11037205e-06   1.48703308e-05\n",
      "   1.47170598e-06   4.63890454e-06   1.55071441e-05   1.30211900e-06\n",
      "   5.11298077e-06   1.64814011e-05   1.19080737e-06   4.94263739e-06\n",
      "   1.45028418e-05   6.49371398e-07   2.79734217e-06   9.85335077e-06\n",
      "   1.80906477e-06   3.36425272e-06   9.89138835e-06   1.19817788e-06\n",
      "   3.61463286e-06   8.82750729e-06   1.06078626e-06   3.42446880e-06\n",
      "   1.07909045e-05   6.56393318e-07   2.27838622e-06   7.41741371e-06\n",
      "   3.45582416e-07   1.86399551e-06   6.27952204e-06   1.18405982e-06\n",
      "   2.07386354e-06   6.00466736e-06   8.75077052e-07   2.50385999e-06\n",
      "   6.05461417e-06   6.62890916e-07   2.15416707e-06   5.53298237e-06\n",
      "   5.36574475e-07   1.70221534e-06   5.24482425e-06   7.45117254e-07\n",
      "   1.90456344e-06   5.24993626e-06   7.16321588e-07   1.55390676e-06\n",
      "   4.94493766e-06   2.06131812e-07   1.13306181e-06   3.78679544e-06\n",
      "   1.55567157e-07   1.12374401e-06   4.02223274e-06   1.00941141e-07\n",
      "   1.13777442e-06   4.10090408e-06   9.37264690e-08   8.63123912e-07\n",
      "   3.21015573e-06   2.60191351e-08   9.35540410e-07   3.59787310e-06\n",
      "   2.74271710e-08   8.59173388e-07   3.34143234e-06   1.20562428e-08\n",
      "   7.81981367e-07   3.08116220e-06   2.22466828e-09   7.70647016e-07\n",
      "   3.05998968e-06   8.50515857e-10   7.52775754e-07   2.99169876e-06\n",
      "   3.10000000e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "[  2.23962964e-01   2.23248795e-01   6.49974784e-01   2.62907025e-01\n",
      "   3.46725529e-01   7.79810220e-01   7.28937786e-02   1.23655482e-01\n",
      "   4.64871871e-01   8.00605491e-02   3.29051660e-01   7.96360110e-01\n",
      "   9.79842030e-02   2.23242096e-01   6.75810912e-01   1.17137587e+00\n",
      "   2.63674647e+00   4.77432691e+00   9.53333093e+00   1.20935089e+01\n",
      "   1.14425674e+01   2.04461001e+00   4.28094053e+00   1.55216763e+00\n",
      "   8.76489912e-01   1.01735184e+00   1.12890851e+00   1.33110972e+00\n",
      "   1.24613335e+00   1.06254937e+00   2.10138423e+00   8.94064100e-01\n",
      "   1.11910243e+00   7.41236009e-01   3.70091612e-01   5.42854452e-01\n",
      "   6.89858707e-01   3.34248935e-01   3.67241785e-01   8.68075277e-01\n",
      "   3.24211213e-01   6.71811003e-02   1.21520824e-01   1.74826484e-01\n",
      "   2.38192842e-01   4.25421552e-02   1.52899117e-01   5.43180267e-01\n",
      "   5.66907829e-02   2.09380067e-01   4.19241517e-01   3.58618419e-02\n",
      "   4.22933639e-02   1.15142972e-01   2.08286159e-02   3.61499204e-02\n",
      "   8.57430570e-02   1.50995937e-02   4.48823710e-02   1.47150188e-01\n",
      "   6.09163023e-02   1.07032888e-01   1.27193662e-01   2.56698977e-02\n",
      "   3.53264757e-02   7.12206874e-03   3.17755825e-02   1.47064095e-02\n",
      "   1.95344536e-03   6.89511386e-03   2.90526686e-03   3.16922042e-03\n",
      "   2.00508644e-02   1.29222961e-02   6.80435579e-03   8.51853775e-03\n",
      "   4.99486456e-03   3.83568976e-03   9.36631547e-03   6.53169562e-03\n",
      "   5.07120771e-03   6.49888961e-03   5.20598650e-03   9.96417402e-04\n",
      "   1.96180484e-04   2.65513832e-03   3.41241371e-03   1.57992845e-03\n",
      "   7.45213065e-03   2.02734948e-02   3.58912556e-03   1.11935955e-02\n",
      "   2.37166058e-02   9.57825538e-02   7.48254126e-02   9.16542687e-02\n",
      "   1.35182872e-01   1.17552381e-01   8.80323376e-02   1.56602681e-02\n",
      "   1.67349295e-02   7.51229986e-03   1.12568624e-03   1.10292782e-02\n",
      "   2.28909815e-02   6.19102938e-03   9.95885361e-03   1.80973093e-02\n",
      "   5.26137827e-03   3.12565696e-03   5.90415172e-03   1.10520130e-03\n",
      "   2.40415365e-03   8.64858946e-03   6.66213490e-04   3.99197207e-03\n",
      "   1.60413063e-02   2.10346379e-02   2.66000307e-02   2.84348747e-02\n",
      "   1.92905721e-02   3.65975293e-02   3.21685851e-02   1.90976047e-03\n",
      "   7.22032605e-03   1.53347106e-02   2.20288372e-03   3.80835331e-03\n",
      "   8.26745580e-03   1.88733881e-02   2.72111269e-02   2.68364967e-02\n",
      "   1.84302866e-02   1.26122611e-02   5.83220310e-03   2.30185414e-03\n",
      "   6.92597746e-03   1.56721293e-02   4.32317638e-03   5.95234996e-03\n",
      "   7.36323617e-03   1.05323452e-03   9.02021056e-04   1.09435798e-03\n",
      "   1.02842892e-02   6.22204559e-03   2.19498567e-03   5.10357774e-02\n",
      "   1.59810236e-02   4.51627545e-03   5.74106927e-02   1.80608256e-02\n",
      "   1.05933469e-03   9.99206195e-03   7.29625652e-03   3.34113811e-03\n",
      "   1.96036916e-03   1.89456857e-03   1.80625379e-03   2.56187606e-03\n",
      "   3.86369640e-03   5.19939707e-03   5.78468818e-03   1.89432128e-02\n",
      "   2.31969012e-02   7.35026625e-02   6.31556770e-02   8.39136032e-02\n",
      "   1.37938767e-01   6.09828567e-02   4.68506259e-02   5.55911838e-02\n",
      "   2.31177245e-02   3.92168941e-03   1.47868889e-01   1.05093578e-01\n",
      "   3.47615818e-02   1.51292083e-01   9.90226572e-02   6.12905640e-02\n",
      "   1.24183102e-01   3.40277412e-02   6.83478554e-03   1.33377149e-01\n",
      "   8.35689391e-02   3.70369022e-02   2.83558861e-02   4.68721668e-02\n",
      "   4.44405333e-02   3.95963107e-02   2.88852136e-02   3.19882686e-02\n",
      "   4.62397206e-02   3.40236570e-02   3.56455281e-02   2.36371800e-02\n",
      "   2.38354206e-02   1.35121187e-02   3.76043789e-02   2.72515933e-02\n",
      "   1.05224214e-02   2.47569024e-02   1.80601220e-02   1.15178490e-02\n",
      "   4.31280016e-03   1.17861019e-02   1.46794404e-02   7.02320410e-02\n",
      "   5.51546112e-02   3.01908581e-02   7.29893407e-02   5.70218364e-02\n",
      "   4.05295857e-02   5.15245345e-02   2.18709756e-02   6.62522836e-03\n",
      "   9.80530049e-03   8.91814340e-03   1.29511710e-02   1.37103126e-02\n",
      "   1.42817289e-02   1.46968948e-02   5.05043197e-02   4.35468261e-02\n",
      "   3.18534428e-02   1.14598027e-02   1.18653660e-02   1.35058964e-02\n",
      "   6.40604705e-03   4.23480853e-03   4.20931491e-03   1.72914047e-02\n",
      "   1.45158450e-02   2.02169989e-02   1.13971911e-02   2.20310134e-02\n",
      "   3.20135315e-02   1.05072209e-02   6.54712198e-03   4.98184305e-03\n",
      "   6.41827313e-03   6.59499464e-03   7.34440440e-03   1.80906765e-02\n",
      "   9.11027705e-03   4.14908046e-03   7.86702695e-03   5.94315418e-03\n",
      "   4.13485853e-03   1.17888214e-02   1.56055395e-02   8.24186311e-03\n",
      "   5.82724819e-03   7.93682526e-03   7.50865930e-03   5.25639680e-03\n",
      "   4.30007396e-03   3.24636405e-03   1.31292373e-02   6.51707065e-03\n",
      "   3.26394048e-03   4.53628720e-03   4.16846323e-03   5.23653789e-03\n",
      "   7.25285115e-03   4.46445621e-03   4.29652717e-03   2.67260393e-03\n",
      "   2.51599054e-03   3.14723080e-03   5.61436220e-03   3.83903820e-03\n",
      "   2.36901671e-03   3.18234097e-03   2.17908663e-03   9.76978852e-04\n",
      "   4.23189309e-04   8.81778943e-04   7.67258505e-04   3.36857412e-04\n",
      "   3.12123037e-04   2.99660685e-04   7.76054873e-04   4.64902120e-04\n",
      "   4.49212069e-04   7.35857807e-04   7.04382562e-04   6.46383609e-04\n",
      "   8.47803310e-04   4.21069744e-04   2.15429633e-04   1.20199713e-03\n",
      "   5.70761347e-04   1.36810837e-04   3.77913064e-04   4.11059522e-04\n",
      "   2.31795193e-04   1.49155313e-04   1.69970031e-04   1.15671218e-04\n",
      "   1.21875287e-04   1.08984594e-04   6.40249841e-05   1.27064824e-04\n",
      "   7.11831083e-05   4.49602105e-05   2.69665361e-04   1.89939297e-04\n",
      "   2.16848767e-04   7.45002894e-05   1.25471495e-04   2.38887800e-04\n",
      "   2.16327873e-05   1.43006250e-05   1.22201343e-05   7.53351380e-06\n",
      "   4.69080328e-06   2.91181625e-06   1.00674692e-05   5.48494505e-06\n",
      "   2.70408980e-06   8.48789261e-06   4.88662668e-06   2.79163072e-06\n",
      "   9.23064411e-07   1.52159932e-06   2.98215050e-06   7.90944036e-07\n",
      "   1.33047805e-06   3.09022443e-06   5.07389087e-06   3.87829819e-06\n",
      "   2.42173828e-06   5.46339601e-06   3.52703157e-06   1.37392703e-06\n",
      "   2.57805743e-06   1.91165696e-06   9.79016284e-07   4.63415413e-07\n",
      "   4.04670624e-07   6.30384126e-07   6.72244702e-07   6.43235248e-07\n",
      "   9.73941217e-07   5.47092312e-07   5.06640581e-07   6.34374956e-07\n",
      "   5.80008766e-07   4.73569375e-07   4.87720818e-07   4.86023918e-07\n",
      "   3.24781546e-07   3.11838970e-07   1.96928040e-07   1.44429569e-07\n",
      "   1.23648620e-07   4.61743605e-07   3.19732642e-07   2.04823425e-07\n",
      "   2.30178461e-07   2.30565132e-07   2.44737799e-07   1.30056139e-07\n",
      "   1.11992530e-07   1.06107902e-07   1.89404367e-07   1.22310987e-07\n",
      "   8.28487465e-08   1.07945834e-07   4.99042125e-08   1.58752237e-08\n",
      "   1.71685961e-08   1.28572210e-08   1.03895026e-08   1.14612804e-08\n",
      "   6.42634084e-09   7.86271821e-09   2.47118618e-09   3.01107957e-09\n",
      "   8.74764629e-09   1.52771899e-09   2.84041342e-09   9.70283306e-09\n",
      "   1.10000000e+01]\n",
      "[  2.23962964e-01   2.23248795e-01   6.49974784e-01   2.62907025e-01\n",
      "   3.46725529e-01   7.79810220e-01   7.28937786e-02   1.23655482e-01\n",
      "   4.64871871e-01   8.00605491e-02   3.29051660e-01   7.96360110e-01\n",
      "   9.79842030e-02   2.23242096e-01   6.75810912e-01   1.17137587e+00\n",
      "   2.63674647e+00   4.77432691e+00   9.53333093e+00   1.20935089e+01\n",
      "   1.14425674e+01   2.04461001e+00   4.28094053e+00   1.55216763e+00\n",
      "   8.76489912e-01   1.01735184e+00   1.12890851e+00   1.33110972e+00\n",
      "   1.24613335e+00   1.06254937e+00   2.10138423e+00   8.94064100e-01\n",
      "   1.11910243e+00   7.41236009e-01   3.70091612e-01   5.42854452e-01\n",
      "   6.89858707e-01   3.34248935e-01   3.67241785e-01   8.68075277e-01\n",
      "   3.24211213e-01   6.71811003e-02   1.21520824e-01   1.74826484e-01\n",
      "   2.38192842e-01   4.25421552e-02   1.52899117e-01   5.43180267e-01\n",
      "   5.66907829e-02   2.09380067e-01   4.19241517e-01   3.58618419e-02\n",
      "   4.22933639e-02   1.15142972e-01   2.08286159e-02   3.61499204e-02\n",
      "   8.57430570e-02   1.50995937e-02   4.48823710e-02   1.47150188e-01\n",
      "   6.09163023e-02   1.07032888e-01   1.27193662e-01   2.56698977e-02\n",
      "   3.53264757e-02   7.12206874e-03   3.17755825e-02   1.47064095e-02\n",
      "   1.95344536e-03   6.89511386e-03   2.90526686e-03   3.16922042e-03\n",
      "   2.00508644e-02   1.29222961e-02   6.80435579e-03   8.51853775e-03\n",
      "   4.99486456e-03   3.83568976e-03   9.36631547e-03   6.53169562e-03\n",
      "   5.07120771e-03   6.49888961e-03   5.20598650e-03   9.96417402e-04\n",
      "   1.96180484e-04   2.65513832e-03   3.41241371e-03   1.57992845e-03\n",
      "   7.45213065e-03   2.02734948e-02   3.58912556e-03   1.11935955e-02\n",
      "   2.37166058e-02   9.57825538e-02   7.48254126e-02   9.16542687e-02\n",
      "   1.35182872e-01   1.17552381e-01   8.80323376e-02   1.56602681e-02\n",
      "   1.67349295e-02   7.51229986e-03   1.12568624e-03   1.10292782e-02\n",
      "   2.28909815e-02   6.19102938e-03   9.95885361e-03   1.80973093e-02\n",
      "   5.26137827e-03   3.12565696e-03   5.90415172e-03   1.10520130e-03\n",
      "   2.40415365e-03   8.64858946e-03   6.66213490e-04   3.99197207e-03\n",
      "   1.60413063e-02   2.10346379e-02   2.66000307e-02   2.84348747e-02\n",
      "   1.92905721e-02   3.65975293e-02   3.21685851e-02   1.90976047e-03\n",
      "   7.22032605e-03   1.53347106e-02   2.20288372e-03   3.80835331e-03\n",
      "   8.26745580e-03   1.88733881e-02   2.72111269e-02   2.68364967e-02\n",
      "   1.84302866e-02   1.26122611e-02   5.83220310e-03   2.30185414e-03\n",
      "   6.92597746e-03   1.56721293e-02   4.32317638e-03   5.95234996e-03\n",
      "   7.36323617e-03   1.05323452e-03   9.02021056e-04   1.09435798e-03\n",
      "   1.02842892e-02   6.22204559e-03   2.19498567e-03   5.10357774e-02\n",
      "   1.59810236e-02   4.51627545e-03   5.74106927e-02   1.80608256e-02\n",
      "   1.05933469e-03   9.99206195e-03   7.29625652e-03   3.34113811e-03\n",
      "   1.96036916e-03   1.89456857e-03   1.80625379e-03   2.56187606e-03\n",
      "   3.86369640e-03   5.19939707e-03   5.78468818e-03   1.89432128e-02\n",
      "   2.31969012e-02   7.35026625e-02   6.31556770e-02   8.39136032e-02\n",
      "   1.37938767e-01   6.09828567e-02   4.68506259e-02   5.55911838e-02\n",
      "   2.31177245e-02   3.92168941e-03   1.47868889e-01   1.05093578e-01\n",
      "   3.47615818e-02   1.51292083e-01   9.90226572e-02   6.12905640e-02\n",
      "   1.24183102e-01   3.40277412e-02   6.83478554e-03   1.33377149e-01\n",
      "   8.35689391e-02   3.70369022e-02   2.83558861e-02   4.68721668e-02\n",
      "   4.44405333e-02   3.95963107e-02   2.88852136e-02   3.19882686e-02\n",
      "   4.62397206e-02   3.40236570e-02   3.56455281e-02   2.36371800e-02\n",
      "   2.38354206e-02   1.35121187e-02   3.76043789e-02   2.72515933e-02\n",
      "   1.05224214e-02   2.47569024e-02   1.80601220e-02   1.15178490e-02\n",
      "   4.31280016e-03   1.17861019e-02   1.46794404e-02   7.02320410e-02\n",
      "   5.51546112e-02   3.01908581e-02   7.29893407e-02   5.70218364e-02\n",
      "   4.05295857e-02   5.15245345e-02   2.18709756e-02   6.62522836e-03\n",
      "   9.80530049e-03   8.91814340e-03   1.29511710e-02   1.37103126e-02\n",
      "   1.42817289e-02   1.46968948e-02   5.05043197e-02   4.35468261e-02\n",
      "   3.18534428e-02   1.14598027e-02   1.18653660e-02   1.35058964e-02\n",
      "   6.40604705e-03   4.23480853e-03   4.20931491e-03   1.72914047e-02\n",
      "   1.45158450e-02   2.02169989e-02   1.13971911e-02   2.20310134e-02\n",
      "   3.20135315e-02   1.05072209e-02   6.54712198e-03   4.98184305e-03\n",
      "   6.41827313e-03   6.59499464e-03   7.34440440e-03   1.80906765e-02\n",
      "   9.11027705e-03   4.14908046e-03   7.86702695e-03   5.94315418e-03\n",
      "   4.13485853e-03   1.17888214e-02   1.56055395e-02   8.24186311e-03\n",
      "   5.82724819e-03   7.93682526e-03   7.50865930e-03   5.25639680e-03\n",
      "   4.30007396e-03   3.24636405e-03   1.31292373e-02   6.51707065e-03\n",
      "   3.26394048e-03   4.53628720e-03   4.16846323e-03   5.23653789e-03\n",
      "   7.25285115e-03   4.46445621e-03   4.29652717e-03   2.67260393e-03\n",
      "   2.51599054e-03   3.14723080e-03   5.61436220e-03   3.83903820e-03\n",
      "   2.36901671e-03   3.18234097e-03   2.17908663e-03   9.76978852e-04\n",
      "   4.23189309e-04   8.81778943e-04   7.67258505e-04   3.36857412e-04\n",
      "   3.12123037e-04   2.99660685e-04   7.76054873e-04   4.64902120e-04\n",
      "   4.49212069e-04   7.35857807e-04   7.04382562e-04   6.46383609e-04\n",
      "   8.47803310e-04   4.21069744e-04   2.15429633e-04   1.20199713e-03\n",
      "   5.70761347e-04   1.36810837e-04   3.77913064e-04   4.11059522e-04\n",
      "   2.31795193e-04   1.49155313e-04   1.69970031e-04   1.15671218e-04\n",
      "   1.21875287e-04   1.08984594e-04   6.40249841e-05   1.27064824e-04\n",
      "   7.11831083e-05   4.49602105e-05   2.69665361e-04   1.89939297e-04\n",
      "   2.16848767e-04   7.45002894e-05   1.25471495e-04   2.38887800e-04\n",
      "   2.16327873e-05   1.43006250e-05   1.22201343e-05   7.53351380e-06\n",
      "   4.69080328e-06   2.91181625e-06   1.00674692e-05   5.48494505e-06\n",
      "   2.70408980e-06   8.48789261e-06   4.88662668e-06   2.79163072e-06\n",
      "   9.23064411e-07   1.52159932e-06   2.98215050e-06   7.90944036e-07\n",
      "   1.33047805e-06   3.09022443e-06   5.07389087e-06   3.87829819e-06\n",
      "   2.42173828e-06   5.46339601e-06   3.52703157e-06   1.37392703e-06\n",
      "   2.57805743e-06   1.91165696e-06   9.79016284e-07   4.63415413e-07\n",
      "   4.04670624e-07   6.30384126e-07   6.72244702e-07   6.43235248e-07\n",
      "   9.73941217e-07   5.47092312e-07   5.06640581e-07   6.34374956e-07\n",
      "   5.80008766e-07   4.73569375e-07   4.87720818e-07   4.86023918e-07\n",
      "   3.24781546e-07   3.11838970e-07   1.96928040e-07   1.44429569e-07\n",
      "   1.23648620e-07   4.61743605e-07   3.19732642e-07   2.04823425e-07\n",
      "   2.30178461e-07   2.30565132e-07   2.44737799e-07   1.30056139e-07\n",
      "   1.11992530e-07   1.06107902e-07   1.89404367e-07   1.22310987e-07\n",
      "   8.28487465e-08   1.07945834e-07   4.99042125e-08   1.58752237e-08\n",
      "   1.71685961e-08   1.28572210e-08   1.03895026e-08   1.14612804e-08\n",
      "   6.42634084e-09   7.86271821e-09   2.47118618e-09   3.01107957e-09\n",
      "   8.74764629e-09   1.52771899e-09   2.84041342e-09   9.70283306e-09\n",
      "   1.10000000e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[  4.90468137e+00   1.47893086e+00   1.17889325e+00   4.99983386e+00\n",
      "   2.75843956e+00   2.60599624e+00   3.44777922e+00   2.09170323e+00\n",
      "   1.83311007e+00   1.82157970e+01   1.07478603e+01   6.01251388e+00\n",
      "   3.15971207e+01   8.35948941e+00   4.31738132e+00   3.36725668e+01\n",
      "   6.26654438e+01   6.82200146e+01   1.38258718e+02   1.48789216e+02\n",
      "   7.47849750e+01   1.36531750e+02   7.20397875e+01   3.79361040e+00\n",
      "   3.49436491e+01   4.99655790e+01   1.37031608e+01   2.21429729e+01\n",
      "   2.97264978e+01   1.28659169e+01   1.07017555e+01   1.51515524e+01\n",
      "   9.78775449e+00   6.05305803e+00   5.85811753e+00   1.97546282e+01\n",
      "   6.99217288e+00   1.67315735e+01   1.15745035e+01   2.22925606e+01\n",
      "   1.51884609e+01   7.79809107e+00   4.43835987e+00   2.15108554e+00\n",
      "   4.17244167e+00   3.57381248e-01   2.21388923e+00   3.02858730e+00\n",
      "   2.07759741e+00   3.03472228e+00   1.75335485e+00   1.98468527e+00\n",
      "   1.80835988e+00   1.61387605e+00   8.34325556e-01   1.03818308e+00\n",
      "   1.22975810e+00   1.00959373e+01   8.01574331e+00   6.06953144e+00\n",
      "   7.23220716e+00   3.23398165e+00   1.31437628e+00   1.26553136e+00\n",
      "   3.22707762e-01   2.47005552e-01   2.07241951e+00   9.80965564e-01\n",
      "   1.15526185e+00   3.93073711e+00   1.52729336e+00   1.17087908e+00\n",
      "   2.88002107e+00   7.69437723e+00   5.72395188e+00   3.31774535e+00\n",
      "   5.57315882e+00   7.77860940e+00   6.75758831e-01   7.10995441e-01\n",
      "   8.07843729e-01   1.37112570e-01   3.10596634e-01   3.09395193e-01\n",
      "   4.69184190e-01   5.49958139e-01   2.00611595e-01   8.91136817e-01\n",
      "   8.96298294e-01   1.44636643e-01   1.93033950e+00   8.51644280e-01\n",
      "   1.50128016e-01   8.94693042e-01   2.59194881e-01   2.16950619e-01\n",
      "   3.15199151e-01   5.00616570e-01   1.80294748e-01   1.84173803e+00\n",
      "   1.13649122e+00   2.65343995e-01   6.74005643e-01   1.22317195e+00\n",
      "   8.29287681e-01   4.46900313e-01   4.10414526e-01   1.43350569e-01\n",
      "   7.30145150e-02   3.45439340e-01   7.16709541e-01   6.14153987e-01\n",
      "   8.59589360e-01   1.66842962e+00   1.84258901e+00   3.44587064e+00\n",
      "   2.79084926e+00   3.48480790e-01   2.72523342e+00   5.62690946e+00\n",
      "   3.91048069e-01   8.73401061e-01   1.17116686e+00   1.98593342e+00\n",
      "   3.01173985e+00   2.06590214e+00   3.63517886e+00   3.20064086e+00\n",
      "   1.09312172e+00   3.74893151e+00   2.13443793e+00   9.83855049e-01\n",
      "   3.42887980e+00   1.00162442e+00   4.69366247e-01   2.75006456e+00\n",
      "   1.33154461e+00   7.05229277e-01   3.16382219e-01   1.50543335e-01\n",
      "   1.94555479e-01   4.48506523e-01   4.34981440e-01   6.58362801e-01\n",
      "   2.39975575e-01   2.76592515e-01   5.92545806e-01   3.09826746e-01\n",
      "   3.16714901e-01   2.45450009e-01   1.86884089e-01   2.19884130e-01\n",
      "   2.91412154e-01   7.92572745e-02   3.96862544e-01   9.26790932e-01\n",
      "   7.73796003e-02   8.39758821e-02   1.17888327e-01   2.04821496e-01\n",
      "   2.55819879e-01   2.08326423e-01   4.71724914e-01   6.49774576e-01\n",
      "   7.06089855e-01   2.27342859e-01   4.59559200e-01   9.27574672e-01\n",
      "   5.38104244e-01   1.75363511e-01   3.71418564e-02   3.56078996e-01\n",
      "   2.66830837e-01   1.95096606e-01   2.27957577e-01   1.02296611e-01\n",
      "   1.17038812e-01   3.76691210e-01   2.87196943e-01   1.37868526e-01\n",
      "   1.22581944e+00   1.20608136e+00   1.10831605e+00   3.05440669e-01\n",
      "   2.05041723e-01   3.37875435e-01   4.05218389e-01   3.29830366e-01\n",
      "   4.84033466e-01   2.66703915e-01   2.19436147e-01   1.33309584e-01\n",
      "   4.00525341e-01   6.09591292e-01   4.86189963e-01   2.28823296e-02\n",
      "   1.03549176e-01   1.41547231e-01   1.47809397e-01   1.51366978e-01\n",
      "   1.33656705e-01   5.22105952e-01   4.78114295e-01   1.51457637e-01\n",
      "   5.18796247e-01   3.94614511e-01   1.41518757e-01   1.02289843e-01\n",
      "   1.21113775e-01   1.33954095e-01   4.40106490e-01   4.50600352e-01\n",
      "   5.61579750e-01   3.85643860e-01   2.57985661e-01   1.91685915e-01\n",
      "   1.64082615e-02   1.76630910e-02   1.82293779e-02   3.99989956e-03\n",
      "   6.85073198e-03   1.11042293e-02   8.69164600e-03   8.38759201e-03\n",
      "   8.41953914e-03   4.82234005e-02   9.20973089e-02   9.23393102e-02\n",
      "   6.33125994e-02   4.30115156e-02   3.31872230e-02   8.06640090e-02\n",
      "   4.09256127e-02   3.54513430e-02   4.58931010e-02   5.49641893e-02\n",
      "   4.49689433e-02   1.36406380e-01   1.46292178e-01   1.24425707e-01\n",
      "   4.75942723e-02   3.52206873e-02   5.32688340e-02   2.96935930e-02\n",
      "   5.22281776e-02   8.28305112e-02   3.05570331e-02   7.28318526e-02\n",
      "   9.29645157e-02   1.50241776e-02   1.00254800e-02   5.83025901e-03\n",
      "   3.93427843e-02   2.94535963e-02   1.11910962e-02   1.30007266e-02\n",
      "   1.14942093e-02   1.58509801e-02   2.05480415e-02   2.19444280e-02\n",
      "   1.82912406e-02   3.08157324e-02   2.34829218e-02   1.84593423e-02\n",
      "   3.50027702e-02   2.94076937e-02   2.56183433e-02   1.82560234e-02\n",
      "   2.11689254e-02   1.71374541e-02   2.12841143e-02   1.99629047e-02\n",
      "   1.73126785e-02   2.64991635e-02   2.24605010e-02   2.05537923e-02\n",
      "   2.45189623e-03   3.18440934e-03   3.58727337e-03   4.00077900e-03\n",
      "   7.13750056e-03   1.21881287e-02   2.69320584e-03   5.72497812e-03\n",
      "   6.31074868e-03   2.68451660e-03   4.04627075e-03   3.80106245e-03\n",
      "   1.08995859e-03   1.86082471e-03   1.65744085e-03   2.27948530e-03\n",
      "   3.10321116e-03   2.44219116e-03   1.26895939e-03   1.75122973e-03\n",
      "   1.65876748e-03   1.93824454e-03   1.86369183e-03   1.76484599e-03\n",
      "   2.38963612e-03   2.21767453e-03   1.78775683e-03   1.95917057e-03\n",
      "   2.42214865e-03   3.41255566e-03   2.39963523e-03   1.54640143e-03\n",
      "   1.55492133e-03   1.25782938e-03   1.20215113e-03   1.02532923e-03\n",
      "   2.38029530e-03   1.87013986e-03   1.49238007e-03   1.39802155e-03\n",
      "   6.50983067e-04   3.18395264e-04   9.39504880e-04   9.49495801e-04\n",
      "   6.44897038e-04   8.52402109e-04   9.91231052e-04   9.45610897e-04\n",
      "   8.80808588e-04   1.09648435e-03   1.12135520e-03   1.26905287e-03\n",
      "   1.58094577e-03   1.41984953e-03   7.48245809e-04   7.33985576e-04\n",
      "   5.82751979e-04   4.43564274e-04   5.58073755e-04   4.27420942e-04\n",
      "   4.42721070e-04   4.26930175e-04   4.74672362e-04   5.21942121e-04\n",
      "   4.09253419e-04   3.11414223e-04   1.52577321e-04   1.01228329e-04\n",
      "   8.81102746e-05   6.57301105e-04   2.70162907e-04   1.30140317e-04\n",
      "   3.78610246e-04   1.88074718e-04   1.23451484e-04   5.93455802e-05\n",
      "   2.89489023e-05   1.52171497e-05   6.03169788e-05   2.54919229e-05\n",
      "   1.41289670e-05   9.67275676e-05   6.21882099e-05   4.63643592e-05\n",
      "   6.61852259e-05   5.78742761e-05   3.91916956e-05   1.08528141e-04\n",
      "   1.01850360e-04   5.58714269e-05   2.96816857e-05   1.65087543e-05\n",
      "   5.99830327e-06   7.31029144e-06   4.49659075e-06   2.59657809e-06\n",
      "   1.71807394e-06   1.30040032e-06   1.19221936e-06   1.82128449e-07\n",
      "   1.82260410e-07   3.03636823e-07   1.19965100e-07   8.68176014e-08\n",
      "   1.97216835e-07   1.30786579e-07   7.70909957e-08   1.75369140e-07\n",
      "   3.30000000e+01]\n",
      "[  4.90468137e+00   1.47893086e+00   1.17889325e+00   4.99983386e+00\n",
      "   2.75843956e+00   2.60599624e+00   3.44777922e+00   2.09170323e+00\n",
      "   1.83311007e+00   1.82157970e+01   1.07478603e+01   6.01251388e+00\n",
      "   3.15971207e+01   8.35948941e+00   4.31738132e+00   3.36725668e+01\n",
      "   6.26654438e+01   6.82200146e+01   1.38258718e+02   1.48789216e+02\n",
      "   7.47849750e+01   1.36531750e+02   7.20397875e+01   3.79361040e+00\n",
      "   3.49436491e+01   4.99655790e+01   1.37031608e+01   2.21429729e+01\n",
      "   2.97264978e+01   1.28659169e+01   1.07017555e+01   1.51515524e+01\n",
      "   9.78775449e+00   6.05305803e+00   5.85811753e+00   1.97546282e+01\n",
      "   6.99217288e+00   1.67315735e+01   1.15745035e+01   2.22925606e+01\n",
      "   1.51884609e+01   7.79809107e+00   4.43835987e+00   2.15108554e+00\n",
      "   4.17244167e+00   3.57381248e-01   2.21388923e+00   3.02858730e+00\n",
      "   2.07759741e+00   3.03472228e+00   1.75335485e+00   1.98468527e+00\n",
      "   1.80835988e+00   1.61387605e+00   8.34325556e-01   1.03818308e+00\n",
      "   1.22975810e+00   1.00959373e+01   8.01574331e+00   6.06953144e+00\n",
      "   7.23220716e+00   3.23398165e+00   1.31437628e+00   1.26553136e+00\n",
      "   3.22707762e-01   2.47005552e-01   2.07241951e+00   9.80965564e-01\n",
      "   1.15526185e+00   3.93073711e+00   1.52729336e+00   1.17087908e+00\n",
      "   2.88002107e+00   7.69437723e+00   5.72395188e+00   3.31774535e+00\n",
      "   5.57315882e+00   7.77860940e+00   6.75758831e-01   7.10995441e-01\n",
      "   8.07843729e-01   1.37112570e-01   3.10596634e-01   3.09395193e-01\n",
      "   4.69184190e-01   5.49958139e-01   2.00611595e-01   8.91136817e-01\n",
      "   8.96298294e-01   1.44636643e-01   1.93033950e+00   8.51644280e-01\n",
      "   1.50128016e-01   8.94693042e-01   2.59194881e-01   2.16950619e-01\n",
      "   3.15199151e-01   5.00616570e-01   1.80294748e-01   1.84173803e+00\n",
      "   1.13649122e+00   2.65343995e-01   6.74005643e-01   1.22317195e+00\n",
      "   8.29287681e-01   4.46900313e-01   4.10414526e-01   1.43350569e-01\n",
      "   7.30145150e-02   3.45439340e-01   7.16709541e-01   6.14153987e-01\n",
      "   8.59589360e-01   1.66842962e+00   1.84258901e+00   3.44587064e+00\n",
      "   2.79084926e+00   3.48480790e-01   2.72523342e+00   5.62690946e+00\n",
      "   3.91048069e-01   8.73401061e-01   1.17116686e+00   1.98593342e+00\n",
      "   3.01173985e+00   2.06590214e+00   3.63517886e+00   3.20064086e+00\n",
      "   1.09312172e+00   3.74893151e+00   2.13443793e+00   9.83855049e-01\n",
      "   3.42887980e+00   1.00162442e+00   4.69366247e-01   2.75006456e+00\n",
      "   1.33154461e+00   7.05229277e-01   3.16382219e-01   1.50543335e-01\n",
      "   1.94555479e-01   4.48506523e-01   4.34981440e-01   6.58362801e-01\n",
      "   2.39975575e-01   2.76592515e-01   5.92545806e-01   3.09826746e-01\n",
      "   3.16714901e-01   2.45450009e-01   1.86884089e-01   2.19884130e-01\n",
      "   2.91412154e-01   7.92572745e-02   3.96862544e-01   9.26790932e-01\n",
      "   7.73796003e-02   8.39758821e-02   1.17888327e-01   2.04821496e-01\n",
      "   2.55819879e-01   2.08326423e-01   4.71724914e-01   6.49774576e-01\n",
      "   7.06089855e-01   2.27342859e-01   4.59559200e-01   9.27574672e-01\n",
      "   5.38104244e-01   1.75363511e-01   3.71418564e-02   3.56078996e-01\n",
      "   2.66830837e-01   1.95096606e-01   2.27957577e-01   1.02296611e-01\n",
      "   1.17038812e-01   3.76691210e-01   2.87196943e-01   1.37868526e-01\n",
      "   1.22581944e+00   1.20608136e+00   1.10831605e+00   3.05440669e-01\n",
      "   2.05041723e-01   3.37875435e-01   4.05218389e-01   3.29830366e-01\n",
      "   4.84033466e-01   2.66703915e-01   2.19436147e-01   1.33309584e-01\n",
      "   4.00525341e-01   6.09591292e-01   4.86189963e-01   2.28823296e-02\n",
      "   1.03549176e-01   1.41547231e-01   1.47809397e-01   1.51366978e-01\n",
      "   1.33656705e-01   5.22105952e-01   4.78114295e-01   1.51457637e-01\n",
      "   5.18796247e-01   3.94614511e-01   1.41518757e-01   1.02289843e-01\n",
      "   1.21113775e-01   1.33954095e-01   4.40106490e-01   4.50600352e-01\n",
      "   5.61579750e-01   3.85643860e-01   2.57985661e-01   1.91685915e-01\n",
      "   1.64082615e-02   1.76630910e-02   1.82293779e-02   3.99989956e-03\n",
      "   6.85073198e-03   1.11042293e-02   8.69164600e-03   8.38759201e-03\n",
      "   8.41953914e-03   4.82234005e-02   9.20973089e-02   9.23393102e-02\n",
      "   6.33125994e-02   4.30115156e-02   3.31872230e-02   8.06640090e-02\n",
      "   4.09256127e-02   3.54513430e-02   4.58931010e-02   5.49641893e-02\n",
      "   4.49689433e-02   1.36406380e-01   1.46292178e-01   1.24425707e-01\n",
      "   4.75942723e-02   3.52206873e-02   5.32688340e-02   2.96935930e-02\n",
      "   5.22281776e-02   8.28305112e-02   3.05570331e-02   7.28318526e-02\n",
      "   9.29645157e-02   1.50241776e-02   1.00254800e-02   5.83025901e-03\n",
      "   3.93427843e-02   2.94535963e-02   1.11910962e-02   1.30007266e-02\n",
      "   1.14942093e-02   1.58509801e-02   2.05480415e-02   2.19444280e-02\n",
      "   1.82912406e-02   3.08157324e-02   2.34829218e-02   1.84593423e-02\n",
      "   3.50027702e-02   2.94076937e-02   2.56183433e-02   1.82560234e-02\n",
      "   2.11689254e-02   1.71374541e-02   2.12841143e-02   1.99629047e-02\n",
      "   1.73126785e-02   2.64991635e-02   2.24605010e-02   2.05537923e-02\n",
      "   2.45189623e-03   3.18440934e-03   3.58727337e-03   4.00077900e-03\n",
      "   7.13750056e-03   1.21881287e-02   2.69320584e-03   5.72497812e-03\n",
      "   6.31074868e-03   2.68451660e-03   4.04627075e-03   3.80106245e-03\n",
      "   1.08995859e-03   1.86082471e-03   1.65744085e-03   2.27948530e-03\n",
      "   3.10321116e-03   2.44219116e-03   1.26895939e-03   1.75122973e-03\n",
      "   1.65876748e-03   1.93824454e-03   1.86369183e-03   1.76484599e-03\n",
      "   2.38963612e-03   2.21767453e-03   1.78775683e-03   1.95917057e-03\n",
      "   2.42214865e-03   3.41255566e-03   2.39963523e-03   1.54640143e-03\n",
      "   1.55492133e-03   1.25782938e-03   1.20215113e-03   1.02532923e-03\n",
      "   2.38029530e-03   1.87013986e-03   1.49238007e-03   1.39802155e-03\n",
      "   6.50983067e-04   3.18395264e-04   9.39504880e-04   9.49495801e-04\n",
      "   6.44897038e-04   8.52402109e-04   9.91231052e-04   9.45610897e-04\n",
      "   8.80808588e-04   1.09648435e-03   1.12135520e-03   1.26905287e-03\n",
      "   1.58094577e-03   1.41984953e-03   7.48245809e-04   7.33985576e-04\n",
      "   5.82751979e-04   4.43564274e-04   5.58073755e-04   4.27420942e-04\n",
      "   4.42721070e-04   4.26930175e-04   4.74672362e-04   5.21942121e-04\n",
      "   4.09253419e-04   3.11414223e-04   1.52577321e-04   1.01228329e-04\n",
      "   8.81102746e-05   6.57301105e-04   2.70162907e-04   1.30140317e-04\n",
      "   3.78610246e-04   1.88074718e-04   1.23451484e-04   5.93455802e-05\n",
      "   2.89489023e-05   1.52171497e-05   6.03169788e-05   2.54919229e-05\n",
      "   1.41289670e-05   9.67275676e-05   6.21882099e-05   4.63643592e-05\n",
      "   6.61852259e-05   5.78742761e-05   3.91916956e-05   1.08528141e-04\n",
      "   1.01850360e-04   5.58714269e-05   2.96816857e-05   1.65087543e-05\n",
      "   5.99830327e-06   7.31029144e-06   4.49659075e-06   2.59657809e-06\n",
      "   1.71807394e-06   1.30040032e-06   1.19221936e-06   1.82128449e-07\n",
      "   1.82260410e-07   3.03636823e-07   1.19965100e-07   8.68176014e-08\n",
      "   1.97216835e-07   1.30786579e-07   7.70909957e-08   1.75369140e-07\n",
      "   3.30000000e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "[  4.13991970e+00   1.01838368e+00   2.22976652e-02   6.00216108e+00\n",
      "   1.43299970e+00   2.38801937e-02   8.69943457e+00   2.23939940e+00\n",
      "   2.90847405e-03   7.98381718e+00   4.31135986e+00   2.56504212e+00\n",
      "   5.26788932e+00   6.82279454e+00   1.89640357e+01   3.66563163e+00\n",
      "   1.53885654e+01   2.38840614e+01   1.29707910e+01   5.77793207e+00\n",
      "   5.01077954e+00   1.59273261e+01   1.70701460e+01   1.95895185e+01\n",
      "   1.93237976e+01   3.02893202e+01   8.64611394e+01   4.29387560e+01\n",
      "   5.07546324e+01   3.20830936e+01   1.81713343e+01   2.02891988e+01\n",
      "   1.39154490e+01   6.23717315e+01   4.38098408e+01   5.38961920e+01\n",
      "   4.16934811e+01   5.46290785e+01   5.48064668e+01   2.33274809e+00\n",
      "   6.99288424e+00   6.87814902e+00   2.30267293e-01   1.48815503e+00\n",
      "   2.79029133e+00   6.42437704e+00   3.09248147e+00   1.97608228e+00\n",
      "   1.35789034e+01   7.54645200e+00   1.52215830e+00   4.58805791e+00\n",
      "   2.55740069e+00   2.83149755e+00   4.30250175e-01   1.10830046e+00\n",
      "   8.31435557e-01   2.32121737e+00   2.50678187e+00   1.62261853e+00\n",
      "   9.42380926e-01   9.37806226e-01   5.20032427e-01   9.64690581e-02\n",
      "   2.17129234e-01   1.37922605e-01   7.57274103e-01   5.68092237e-01\n",
      "   7.56739470e-01   7.92733656e-01   4.42568135e-01   8.90276350e-01\n",
      "   1.35229199e+00   2.61818203e+00   1.13234314e+00   2.76000451e+00\n",
      "   2.34461511e+00   2.74983985e+00   5.07436503e-01   3.84243184e-01\n",
      "   9.56524146e-01   1.34697695e-02   1.14017451e-01   4.71500959e-01\n",
      "   6.36997816e-01   5.43988013e-01   1.60340131e-01   3.56066226e+00\n",
      "   1.54579736e+00   1.67367462e-01   3.51162819e+00   8.42929264e-01\n",
      "   6.19686788e-01   5.53026010e+00   2.88394237e+00   5.50664690e+00\n",
      "   1.71004220e+01   1.91007812e+01   2.89681154e+01   7.56570155e+00\n",
      "   1.93105946e+01   1.73671670e+01   5.42513853e+00   2.06424287e+00\n",
      "   7.99141384e-01   1.55037723e+00   4.58965652e-01   3.45120378e-01\n",
      "   1.37735299e+00   4.34882890e-01   1.13953458e-01   1.90475320e+00\n",
      "   4.49102446e-01   4.46635053e-02   1.92564125e+00   1.19821405e+00\n",
      "   5.07448798e-01   2.33567370e-01   5.52853560e-01   5.73058217e-01\n",
      "   1.02029803e-01   1.95378180e-01   1.29427771e-01   9.17487501e-02\n",
      "   3.38169417e-01   2.87229244e-01   7.58520964e-02   2.76016452e-01\n",
      "   5.90668876e-01   1.92878288e-02   1.40190899e-01   5.19128545e-01\n",
      "   1.01457890e-01   1.47975291e-01   4.97761719e-01   1.49207294e+00\n",
      "   1.68124613e+00   1.07541383e+00   6.89287911e-01   1.30128198e+00\n",
      "   1.65120973e+00   1.22323839e-01   1.36364629e-01   2.61166752e-01\n",
      "   5.32999273e-02   6.33928375e-02   3.34176260e-02   2.45656567e-01\n",
      "   4.11375564e-01   4.87569597e-01   6.77833318e-01   6.43131573e-01\n",
      "   5.92079026e-01   2.23336783e-01   2.17735426e-01   1.60811590e-01\n",
      "   1.78742321e-01   1.82220498e-01   1.34849338e-01   9.24975525e-01\n",
      "   4.46901402e-01   1.33631856e-01   1.06298136e+00   1.37827910e+00\n",
      "   1.27935155e+00   1.22261233e+00   1.08542597e+00   7.16151875e-01\n",
      "   7.51255072e-01   6.48536052e-01   3.77251171e-01   2.44668886e-02\n",
      "   6.03007688e-02   8.59995607e-02   6.32519547e-01   7.07545461e-01\n",
      "   5.47726773e-01   1.26770188e-01   2.22495503e-01   3.61009085e-01\n",
      "   2.07798330e-02   1.47432704e-02   2.07676208e-02   3.01153549e-01\n",
      "   3.87337673e-01   4.66399270e-01   2.34113276e-01   3.18649096e-01\n",
      "   5.56892291e-01   1.11582021e+00   8.95452573e-01   6.40337109e-01\n",
      "   1.00211128e+00   6.47864780e-01   7.32016614e-01   1.02034236e-02\n",
      "   3.13210511e-02   8.54458853e-02   4.24666728e-02   6.15243155e-02\n",
      "   5.53616190e-02   2.18759397e-01   3.78253621e-01   4.35679350e-01\n",
      "   1.10873161e-01   1.13724175e-01   1.21058225e-01   1.10637132e-02\n",
      "   4.04029020e-02   1.11672653e-01   1.63143947e-01   1.48488546e-01\n",
      "   2.01740552e-01   1.12164509e+00   9.85453268e-01   6.23108240e-01\n",
      "   4.76756260e-01   5.82036183e-01   4.48550703e-01   9.27060610e-02\n",
      "   1.72866189e-01   1.26501163e-01   1.20667086e-01   1.02086050e-01\n",
      "   5.13505705e-02   4.49799718e-02   5.60788210e-02   5.73556643e-02\n",
      "   6.08395189e-02   5.05443347e-02   4.12786226e-02   2.75495554e-02\n",
      "   2.33590331e-02   3.64876978e-02   8.53335639e-03   9.33366153e-03\n",
      "   1.55653643e-02   2.51502990e-02   2.37491682e-02   2.76465766e-02\n",
      "   5.90831634e-02   3.61057428e-02   2.27105942e-02   1.23526780e-02\n",
      "   9.72716747e-03   7.71423721e-03   9.94992073e-03   1.75791236e-02\n",
      "   1.10444668e-02   1.20843436e-01   9.93575355e-02   6.57588914e-02\n",
      "   5.04621990e-02   4.00653082e-02   2.68060008e-02   2.40300106e-02\n",
      "   1.79394368e-02   1.20970385e-02   2.61680202e-02   3.15926840e-02\n",
      "   2.24994853e-02   1.28309701e-02   1.49597079e-02   1.34234553e-02\n",
      "   2.64220459e-02   3.04269624e-02   2.57875483e-02   3.06488234e-02\n",
      "   3.20354215e-02   3.78018728e-02   1.43911450e-02   2.20922848e-02\n",
      "   2.70764281e-02   7.79172581e-03   1.40768612e-02   1.83978715e-02\n",
      "   9.97741591e-03   9.34465817e-03   6.11761536e-03   5.91630933e-03\n",
      "   5.48398226e-03   3.65313932e-03   3.38802208e-03   5.36414999e-03\n",
      "   4.84644099e-03   3.88751558e-03   4.64229920e-03   6.21641633e-03\n",
      "   2.21319786e-03   3.38109697e-03   3.93149172e-03   2.19000723e-03\n",
      "   2.13101707e-03   1.54379862e-03   1.28969218e-03   2.25220346e-03\n",
      "   3.46951814e-03   8.55777048e-04   1.11419552e-03   1.50950116e-03\n",
      "   1.74721960e-03   1.91094475e-03   1.42991937e-03   3.81649155e-03\n",
      "   2.59482328e-03   2.04193276e-03   2.19655853e-03   1.49252674e-03\n",
      "   1.63631752e-03   7.88782440e-04   8.09243994e-04   9.18355451e-04\n",
      "   5.44899958e-04   7.34431838e-04   9.96152234e-04   5.75594160e-04\n",
      "   4.28552302e-04   2.99360528e-04   1.00686174e-03   8.16062570e-04\n",
      "   9.00995266e-04   8.70265628e-04   1.01713237e-03   1.07965713e-03\n",
      "   1.83880311e-03   1.56975239e-03   1.40174232e-03   1.82469863e-03\n",
      "   1.05412009e-03   4.95760541e-04   1.37947036e-03   8.08613359e-04\n",
      "   4.25146198e-04   6.53243810e-04   5.67233019e-04   5.45114296e-04\n",
      "   8.74118565e-04   8.73074423e-04   6.53883596e-04   2.07001316e-03\n",
      "   1.55951071e-03   9.90065709e-04   1.17567436e-03   1.33411218e-03\n",
      "   1.17142662e-03   6.79007752e-04   8.62200989e-04   1.00161656e-03\n",
      "   1.13290065e-03   9.77635881e-04   7.21362326e-04   7.26996610e-04\n",
      "   6.16109341e-04   3.78083137e-04   6.18528689e-04   3.54369227e-04\n",
      "   2.20540863e-04   9.90919278e-04   5.38122415e-04   2.28161627e-04\n",
      "   4.04702985e-04   2.01839574e-04   9.51077182e-05   2.39446444e-04\n",
      "   9.69270125e-05   2.78710344e-05   2.29246453e-04   1.36613351e-04\n",
      "   7.18959310e-05   7.88641091e-05   4.59924025e-05   2.54387774e-05\n",
      "   2.63469638e-05   1.29025539e-05   7.78691525e-06   7.13574887e-06\n",
      "   2.54166777e-06   1.36752741e-06   5.80365669e-06   1.64201305e-06\n",
      "   6.97263313e-07   5.01423568e-06   1.39908366e-06   5.73309473e-07\n",
      "   4.00000000e+00]\n",
      "[  4.13991970e+00   1.01838368e+00   2.22976652e-02   6.00216108e+00\n",
      "   1.43299970e+00   2.38801937e-02   8.69943457e+00   2.23939940e+00\n",
      "   2.90847405e-03   7.98381718e+00   4.31135986e+00   2.56504212e+00\n",
      "   5.26788932e+00   6.82279454e+00   1.89640357e+01   3.66563163e+00\n",
      "   1.53885654e+01   2.38840614e+01   1.29707910e+01   5.77793207e+00\n",
      "   5.01077954e+00   1.59273261e+01   1.70701460e+01   1.95895185e+01\n",
      "   1.93237976e+01   3.02893202e+01   8.64611394e+01   4.29387560e+01\n",
      "   5.07546324e+01   3.20830936e+01   1.81713343e+01   2.02891988e+01\n",
      "   1.39154490e+01   6.23717315e+01   4.38098408e+01   5.38961920e+01\n",
      "   4.16934811e+01   5.46290785e+01   5.48064668e+01   2.33274809e+00\n",
      "   6.99288424e+00   6.87814902e+00   2.30267293e-01   1.48815503e+00\n",
      "   2.79029133e+00   6.42437704e+00   3.09248147e+00   1.97608228e+00\n",
      "   1.35789034e+01   7.54645200e+00   1.52215830e+00   4.58805791e+00\n",
      "   2.55740069e+00   2.83149755e+00   4.30250175e-01   1.10830046e+00\n",
      "   8.31435557e-01   2.32121737e+00   2.50678187e+00   1.62261853e+00\n",
      "   9.42380926e-01   9.37806226e-01   5.20032427e-01   9.64690581e-02\n",
      "   2.17129234e-01   1.37922605e-01   7.57274103e-01   5.68092237e-01\n",
      "   7.56739470e-01   7.92733656e-01   4.42568135e-01   8.90276350e-01\n",
      "   1.35229199e+00   2.61818203e+00   1.13234314e+00   2.76000451e+00\n",
      "   2.34461511e+00   2.74983985e+00   5.07436503e-01   3.84243184e-01\n",
      "   9.56524146e-01   1.34697695e-02   1.14017451e-01   4.71500959e-01\n",
      "   6.36997816e-01   5.43988013e-01   1.60340131e-01   3.56066226e+00\n",
      "   1.54579736e+00   1.67367462e-01   3.51162819e+00   8.42929264e-01\n",
      "   6.19686788e-01   5.53026010e+00   2.88394237e+00   5.50664690e+00\n",
      "   1.71004220e+01   1.91007812e+01   2.89681154e+01   7.56570155e+00\n",
      "   1.93105946e+01   1.73671670e+01   5.42513853e+00   2.06424287e+00\n",
      "   7.99141384e-01   1.55037723e+00   4.58965652e-01   3.45120378e-01\n",
      "   1.37735299e+00   4.34882890e-01   1.13953458e-01   1.90475320e+00\n",
      "   4.49102446e-01   4.46635053e-02   1.92564125e+00   1.19821405e+00\n",
      "   5.07448798e-01   2.33567370e-01   5.52853560e-01   5.73058217e-01\n",
      "   1.02029803e-01   1.95378180e-01   1.29427771e-01   9.17487501e-02\n",
      "   3.38169417e-01   2.87229244e-01   7.58520964e-02   2.76016452e-01\n",
      "   5.90668876e-01   1.92878288e-02   1.40190899e-01   5.19128545e-01\n",
      "   1.01457890e-01   1.47975291e-01   4.97761719e-01   1.49207294e+00\n",
      "   1.68124613e+00   1.07541383e+00   6.89287911e-01   1.30128198e+00\n",
      "   1.65120973e+00   1.22323839e-01   1.36364629e-01   2.61166752e-01\n",
      "   5.32999273e-02   6.33928375e-02   3.34176260e-02   2.45656567e-01\n",
      "   4.11375564e-01   4.87569597e-01   6.77833318e-01   6.43131573e-01\n",
      "   5.92079026e-01   2.23336783e-01   2.17735426e-01   1.60811590e-01\n",
      "   1.78742321e-01   1.82220498e-01   1.34849338e-01   9.24975525e-01\n",
      "   4.46901402e-01   1.33631856e-01   1.06298136e+00   1.37827910e+00\n",
      "   1.27935155e+00   1.22261233e+00   1.08542597e+00   7.16151875e-01\n",
      "   7.51255072e-01   6.48536052e-01   3.77251171e-01   2.44668886e-02\n",
      "   6.03007688e-02   8.59995607e-02   6.32519547e-01   7.07545461e-01\n",
      "   5.47726773e-01   1.26770188e-01   2.22495503e-01   3.61009085e-01\n",
      "   2.07798330e-02   1.47432704e-02   2.07676208e-02   3.01153549e-01\n",
      "   3.87337673e-01   4.66399270e-01   2.34113276e-01   3.18649096e-01\n",
      "   5.56892291e-01   1.11582021e+00   8.95452573e-01   6.40337109e-01\n",
      "   1.00211128e+00   6.47864780e-01   7.32016614e-01   1.02034236e-02\n",
      "   3.13210511e-02   8.54458853e-02   4.24666728e-02   6.15243155e-02\n",
      "   5.53616190e-02   2.18759397e-01   3.78253621e-01   4.35679350e-01\n",
      "   1.10873161e-01   1.13724175e-01   1.21058225e-01   1.10637132e-02\n",
      "   4.04029020e-02   1.11672653e-01   1.63143947e-01   1.48488546e-01\n",
      "   2.01740552e-01   1.12164509e+00   9.85453268e-01   6.23108240e-01\n",
      "   4.76756260e-01   5.82036183e-01   4.48550703e-01   9.27060610e-02\n",
      "   1.72866189e-01   1.26501163e-01   1.20667086e-01   1.02086050e-01\n",
      "   5.13505705e-02   4.49799718e-02   5.60788210e-02   5.73556643e-02\n",
      "   6.08395189e-02   5.05443347e-02   4.12786226e-02   2.75495554e-02\n",
      "   2.33590331e-02   3.64876978e-02   8.53335639e-03   9.33366153e-03\n",
      "   1.55653643e-02   2.51502990e-02   2.37491682e-02   2.76465766e-02\n",
      "   5.90831634e-02   3.61057428e-02   2.27105942e-02   1.23526780e-02\n",
      "   9.72716747e-03   7.71423721e-03   9.94992073e-03   1.75791236e-02\n",
      "   1.10444668e-02   1.20843436e-01   9.93575355e-02   6.57588914e-02\n",
      "   5.04621990e-02   4.00653082e-02   2.68060008e-02   2.40300106e-02\n",
      "   1.79394368e-02   1.20970385e-02   2.61680202e-02   3.15926840e-02\n",
      "   2.24994853e-02   1.28309701e-02   1.49597079e-02   1.34234553e-02\n",
      "   2.64220459e-02   3.04269624e-02   2.57875483e-02   3.06488234e-02\n",
      "   3.20354215e-02   3.78018728e-02   1.43911450e-02   2.20922848e-02\n",
      "   2.70764281e-02   7.79172581e-03   1.40768612e-02   1.83978715e-02\n",
      "   9.97741591e-03   9.34465817e-03   6.11761536e-03   5.91630933e-03\n",
      "   5.48398226e-03   3.65313932e-03   3.38802208e-03   5.36414999e-03\n",
      "   4.84644099e-03   3.88751558e-03   4.64229920e-03   6.21641633e-03\n",
      "   2.21319786e-03   3.38109697e-03   3.93149172e-03   2.19000723e-03\n",
      "   2.13101707e-03   1.54379862e-03   1.28969218e-03   2.25220346e-03\n",
      "   3.46951814e-03   8.55777048e-04   1.11419552e-03   1.50950116e-03\n",
      "   1.74721960e-03   1.91094475e-03   1.42991937e-03   3.81649155e-03\n",
      "   2.59482328e-03   2.04193276e-03   2.19655853e-03   1.49252674e-03\n",
      "   1.63631752e-03   7.88782440e-04   8.09243994e-04   9.18355451e-04\n",
      "   5.44899958e-04   7.34431838e-04   9.96152234e-04   5.75594160e-04\n",
      "   4.28552302e-04   2.99360528e-04   1.00686174e-03   8.16062570e-04\n",
      "   9.00995266e-04   8.70265628e-04   1.01713237e-03   1.07965713e-03\n",
      "   1.83880311e-03   1.56975239e-03   1.40174232e-03   1.82469863e-03\n",
      "   1.05412009e-03   4.95760541e-04   1.37947036e-03   8.08613359e-04\n",
      "   4.25146198e-04   6.53243810e-04   5.67233019e-04   5.45114296e-04\n",
      "   8.74118565e-04   8.73074423e-04   6.53883596e-04   2.07001316e-03\n",
      "   1.55951071e-03   9.90065709e-04   1.17567436e-03   1.33411218e-03\n",
      "   1.17142662e-03   6.79007752e-04   8.62200989e-04   1.00161656e-03\n",
      "   1.13290065e-03   9.77635881e-04   7.21362326e-04   7.26996610e-04\n",
      "   6.16109341e-04   3.78083137e-04   6.18528689e-04   3.54369227e-04\n",
      "   2.20540863e-04   9.90919278e-04   5.38122415e-04   2.28161627e-04\n",
      "   4.04702985e-04   2.01839574e-04   9.51077182e-05   2.39446444e-04\n",
      "   9.69270125e-05   2.78710344e-05   2.29246453e-04   1.36613351e-04\n",
      "   7.18959310e-05   7.88641091e-05   4.59924025e-05   2.54387774e-05\n",
      "   2.63469638e-05   1.29025539e-05   7.78691525e-06   7.13574887e-06\n",
      "   2.54166777e-06   1.36752741e-06   5.80365669e-06   1.64201305e-06\n",
      "   6.97263313e-07   5.01423568e-06   1.39908366e-06   5.73309473e-07\n",
      "   4.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "[  1.14793372e-03   2.40502420e-01   9.15300492e-01   3.38812492e-02\n",
      "   3.54718820e-01   1.44321491e+00   1.06538104e-01   6.92696494e-01\n",
      "   1.39038735e+00   5.55810391e-01   3.83850724e-01   2.25350247e-01\n",
      "   1.23281889e+00   4.70870930e-01   3.96930600e-01   1.35916049e+01\n",
      "   5.78956693e+00   6.79408226e-01   4.99693660e+01   2.45552288e+01\n",
      "   1.01407688e+01   1.35844935e+01   3.65841714e+01   4.71277316e+01\n",
      "   3.13471219e+00   2.14830274e+01   1.81960430e+01   7.12322784e+00\n",
      "   8.94811096e+00   7.61285116e+00   9.55252242e-01   1.81822890e+00\n",
      "   1.24141498e+00   3.86358226e-01   4.95261801e-01   1.08661825e+00\n",
      "   4.45315600e+00   3.98174152e+00   1.90187152e+00   5.31077247e+00\n",
      "   4.96876641e+00   2.66148169e+00   2.80163411e-01   6.89280307e-01\n",
      "   2.55221313e+00   3.76627583e-01   1.05172025e+00   2.50798661e+00\n",
      "   7.84190542e-02   3.21435641e-01   1.21476721e+00   2.67210367e-01\n",
      "   3.61103587e-01   1.07275265e+00   1.12230622e+00   8.44069059e-01\n",
      "   1.48560121e+00   1.27348766e+00   2.12749957e+00   6.53767059e-01\n",
      "   4.33903288e+00   3.03056300e+00   5.83400191e-01   3.83066936e+00\n",
      "   1.61227386e+00   6.93508682e-01   1.21620167e+00   3.29319112e-01\n",
      "   1.11274859e-01   7.42327498e-01   2.85439830e-01   2.76126071e-02\n",
      "   2.66775481e-01   1.08917632e-01   2.05292108e-01   9.74025416e-02\n",
      "   7.10979377e-02   1.58904882e-01   3.02731029e-01   2.03446588e-01\n",
      "   1.06521481e-01   2.15210694e-01   4.00206683e-01   3.21476357e-01\n",
      "   1.24922387e-01   1.96304453e-01   1.28157677e-01   3.11263319e-02\n",
      "   2.89297204e-02   5.21596911e-02   1.60662427e-01   1.96539922e-01\n",
      "   1.15684383e-01   2.68059058e+00   1.35166170e+00   2.04580466e-01\n",
      "   2.15669354e+00   1.25034599e+00   1.39951142e-01   2.01722357e-01\n",
      "   5.27102955e-01   4.83099321e-01   1.89668617e-01   2.01279795e-01\n",
      "   5.95129354e-02   2.48515732e-01   7.92923758e-02   4.76958202e-02\n",
      "   3.54105982e-01   2.58774721e-01   2.32237807e-01   1.17962036e-01\n",
      "   7.08196612e-02   4.38146274e-02   2.49021702e-01   4.96552225e-01\n",
      "   5.08415840e-01   4.19458602e-01   5.36114319e-01   6.18057558e-01\n",
      "   2.49323997e-01   7.26868277e-02   2.09273318e-02   1.06341730e-01\n",
      "   5.21312787e-02   1.57792000e-02   1.51884135e-02   1.09991600e-02\n",
      "   1.02592207e-02   2.99438043e-02   1.86331242e-02   2.09616773e-02\n",
      "   4.87187566e-03   1.07945502e-02   2.40058651e-02   1.15000935e-02\n",
      "   6.75593838e-03   6.45670722e-03   1.66925910e-02   2.47637404e-02\n",
      "   3.79581731e-02   1.29998797e-02   6.27787864e-02   8.78759594e-02\n",
      "   1.16309461e-02   3.51874619e-02   4.08922140e-02   1.04892692e-02\n",
      "   1.89372124e-02   3.03126847e-02   3.08605029e-02   2.57926645e-02\n",
      "   1.42690739e-02   1.22833100e-02   1.66743294e-02   2.17796484e-02\n",
      "   9.47859130e-02   1.13398102e-01   6.97684969e-02   2.29175428e-01\n",
      "   1.56023257e-01   1.88923451e-01   2.37160434e-02   2.47505010e-02\n",
      "   3.20367793e-02   1.59181889e-02   2.70157399e-02   4.05233970e-02\n",
      "   6.19525639e-01   4.17715601e-01   1.49802807e-01   3.13210915e-01\n",
      "   2.28667752e-01   1.16029090e-01   2.21868983e-01   2.36468708e-01\n",
      "   1.24412978e-01   1.51861256e-01   6.00904951e-02   1.82830026e-02\n",
      "   1.00379906e-01   1.33393167e-01   8.33568823e-02   1.25716953e-01\n",
      "   1.15923035e-01   1.27938312e-01   1.12610646e-01   1.03922542e-01\n",
      "   8.53027706e-02   4.22356157e-02   1.10067551e-01   1.54577977e-01\n",
      "   3.32141712e-02   5.49964164e-02   1.02839754e-01   3.14028379e-01\n",
      "   3.37629278e-01   3.84392503e-01   8.83399801e-02   1.10129104e-01\n",
      "   1.08010105e-01   8.66681167e-02   4.72457579e-02   1.50578206e-02\n",
      "   1.15445568e-01   7.74721587e-02   4.60268689e-02   1.31019293e-02\n",
      "   1.71171733e-02   1.06891205e-02   1.61503911e-02   2.32683630e-02\n",
      "   2.32806793e-02   1.92925113e-02   2.52220271e-02   2.73005390e-02\n",
      "   1.01137873e-02   1.03645732e-02   6.16160561e-03   2.02083223e-03\n",
      "   1.70359130e-03   7.00154179e-04   3.51687793e-02   2.44226358e-02\n",
      "   1.47087389e-02   4.28337852e-02   2.76697778e-02   1.74369109e-02\n",
      "   3.92831880e-02   2.75662173e-02   1.64491553e-02   4.58853086e-02\n",
      "   3.58281176e-02   1.77881677e-02   4.21709529e-03   4.28462731e-03\n",
      "   3.40504115e-03   2.13313230e-03   2.97392625e-03   5.83343079e-03\n",
      "   5.46931596e-03   2.23205093e-03   1.04482185e-03   1.41051417e-03\n",
      "   1.77239968e-03   1.41468307e-03   1.90784567e-03   3.15864055e-03\n",
      "   3.00955621e-03   2.27088812e-03   5.28877510e-03   7.59079442e-03\n",
      "   2.14140497e-03   2.36911525e-03   2.20168311e-03   9.32633201e-03\n",
      "   6.09398013e-03   4.26212837e-03   5.74794226e-03   2.85910083e-03\n",
      "   1.36394868e-03   1.63008322e-03   1.54818187e-03   1.45036265e-03\n",
      "   1.53043840e-03   8.03911808e-04   1.61193151e-04   1.28703154e-03\n",
      "   5.88402242e-04   2.00114691e-04   2.88621766e-03   1.95513999e-03\n",
      "   1.24321699e-03   2.14101698e-03   1.62676871e-03   9.44498885e-04\n",
      "   7.67023473e-03   8.53562229e-03   6.87375441e-03   8.15893425e-04\n",
      "   7.76490896e-04   1.34083784e-03   7.86878589e-05   1.14351616e-04\n",
      "   1.55753447e-04   1.15663553e-04   5.56375967e-05   2.64969803e-05\n",
      "   6.49426658e-05   4.24666651e-05   3.06355574e-05   3.65909117e-04\n",
      "   2.89681648e-04   2.41325203e-04   4.57280260e-04   4.00194085e-04\n",
      "   3.47052079e-04   2.21918206e-04   1.41724775e-04   1.13287178e-04\n",
      "   5.17952512e-05   2.99441115e-05   1.08118687e-05   9.84499975e-06\n",
      "   5.02517093e-06   5.82747457e-06   7.11439808e-06   5.16367071e-06\n",
      "   8.13721659e-06   6.29837481e-06   3.94084257e-06   2.71159327e-06\n",
      "   4.27371490e-06   3.50801975e-06   3.53042632e-06   3.95102962e-06\n",
      "   1.66683559e-06   1.35669814e-06   5.24599194e-06   1.81688393e-06\n",
      "   8.84132828e-07   3.11880139e-06   1.33216246e-06   7.58181771e-07\n",
      "   4.85192275e-06   1.85472501e-06   1.02450258e-06   1.43146007e-06\n",
      "   9.36088854e-07   8.23371686e-07   1.44918811e-06   6.55883053e-07\n",
      "   6.60611721e-07   1.46372639e-06   6.84709448e-07   5.00266847e-07\n",
      "   1.35269833e-06   5.16568902e-07   2.77121724e-07   1.23032572e-06\n",
      "   5.32978930e-07   3.03690218e-07   4.86671561e-07   3.13463382e-07\n",
      "   2.01955182e-07   1.26871018e-06   4.38709561e-07   2.15005164e-07\n",
      "   1.77301081e-06   5.42862910e-07   1.88942085e-07   1.36760639e-06\n",
      "   4.31120888e-07   1.77085651e-07   9.17010094e-07   2.97676917e-07\n",
      "   1.28319946e-07   8.32583853e-07   2.52253623e-07   9.95444170e-08\n",
      "   7.50558374e-07   2.55156905e-07   1.27618286e-07   8.16844004e-07\n",
      "   2.77780852e-07   1.64237379e-07   5.56249881e-07   1.74956179e-07\n",
      "   9.24119513e-08   6.40970335e-07   1.85599840e-07   7.39589773e-08\n",
      "   6.00466081e-07   1.74796455e-07   8.14912292e-08   5.03540242e-07\n",
      "   1.43421481e-07   6.72165947e-08   5.03869682e-07   1.42617006e-07\n",
      "   6.58458886e-08   5.09091261e-07   1.43600861e-07   6.49130999e-08\n",
      "   1.90000000e+01]\n",
      "[  1.14793372e-03   2.40502420e-01   9.15300492e-01   3.38812492e-02\n",
      "   3.54718820e-01   1.44321491e+00   1.06538104e-01   6.92696494e-01\n",
      "   1.39038735e+00   5.55810391e-01   3.83850724e-01   2.25350247e-01\n",
      "   1.23281889e+00   4.70870930e-01   3.96930600e-01   1.35916049e+01\n",
      "   5.78956693e+00   6.79408226e-01   4.99693660e+01   2.45552288e+01\n",
      "   1.01407688e+01   1.35844935e+01   3.65841714e+01   4.71277316e+01\n",
      "   3.13471219e+00   2.14830274e+01   1.81960430e+01   7.12322784e+00\n",
      "   8.94811096e+00   7.61285116e+00   9.55252242e-01   1.81822890e+00\n",
      "   1.24141498e+00   3.86358226e-01   4.95261801e-01   1.08661825e+00\n",
      "   4.45315600e+00   3.98174152e+00   1.90187152e+00   5.31077247e+00\n",
      "   4.96876641e+00   2.66148169e+00   2.80163411e-01   6.89280307e-01\n",
      "   2.55221313e+00   3.76627583e-01   1.05172025e+00   2.50798661e+00\n",
      "   7.84190542e-02   3.21435641e-01   1.21476721e+00   2.67210367e-01\n",
      "   3.61103587e-01   1.07275265e+00   1.12230622e+00   8.44069059e-01\n",
      "   1.48560121e+00   1.27348766e+00   2.12749957e+00   6.53767059e-01\n",
      "   4.33903288e+00   3.03056300e+00   5.83400191e-01   3.83066936e+00\n",
      "   1.61227386e+00   6.93508682e-01   1.21620167e+00   3.29319112e-01\n",
      "   1.11274859e-01   7.42327498e-01   2.85439830e-01   2.76126071e-02\n",
      "   2.66775481e-01   1.08917632e-01   2.05292108e-01   9.74025416e-02\n",
      "   7.10979377e-02   1.58904882e-01   3.02731029e-01   2.03446588e-01\n",
      "   1.06521481e-01   2.15210694e-01   4.00206683e-01   3.21476357e-01\n",
      "   1.24922387e-01   1.96304453e-01   1.28157677e-01   3.11263319e-02\n",
      "   2.89297204e-02   5.21596911e-02   1.60662427e-01   1.96539922e-01\n",
      "   1.15684383e-01   2.68059058e+00   1.35166170e+00   2.04580466e-01\n",
      "   2.15669354e+00   1.25034599e+00   1.39951142e-01   2.01722357e-01\n",
      "   5.27102955e-01   4.83099321e-01   1.89668617e-01   2.01279795e-01\n",
      "   5.95129354e-02   2.48515732e-01   7.92923758e-02   4.76958202e-02\n",
      "   3.54105982e-01   2.58774721e-01   2.32237807e-01   1.17962036e-01\n",
      "   7.08196612e-02   4.38146274e-02   2.49021702e-01   4.96552225e-01\n",
      "   5.08415840e-01   4.19458602e-01   5.36114319e-01   6.18057558e-01\n",
      "   2.49323997e-01   7.26868277e-02   2.09273318e-02   1.06341730e-01\n",
      "   5.21312787e-02   1.57792000e-02   1.51884135e-02   1.09991600e-02\n",
      "   1.02592207e-02   2.99438043e-02   1.86331242e-02   2.09616773e-02\n",
      "   4.87187566e-03   1.07945502e-02   2.40058651e-02   1.15000935e-02\n",
      "   6.75593838e-03   6.45670722e-03   1.66925910e-02   2.47637404e-02\n",
      "   3.79581731e-02   1.29998797e-02   6.27787864e-02   8.78759594e-02\n",
      "   1.16309461e-02   3.51874619e-02   4.08922140e-02   1.04892692e-02\n",
      "   1.89372124e-02   3.03126847e-02   3.08605029e-02   2.57926645e-02\n",
      "   1.42690739e-02   1.22833100e-02   1.66743294e-02   2.17796484e-02\n",
      "   9.47859130e-02   1.13398102e-01   6.97684969e-02   2.29175428e-01\n",
      "   1.56023257e-01   1.88923451e-01   2.37160434e-02   2.47505010e-02\n",
      "   3.20367793e-02   1.59181889e-02   2.70157399e-02   4.05233970e-02\n",
      "   6.19525639e-01   4.17715601e-01   1.49802807e-01   3.13210915e-01\n",
      "   2.28667752e-01   1.16029090e-01   2.21868983e-01   2.36468708e-01\n",
      "   1.24412978e-01   1.51861256e-01   6.00904951e-02   1.82830026e-02\n",
      "   1.00379906e-01   1.33393167e-01   8.33568823e-02   1.25716953e-01\n",
      "   1.15923035e-01   1.27938312e-01   1.12610646e-01   1.03922542e-01\n",
      "   8.53027706e-02   4.22356157e-02   1.10067551e-01   1.54577977e-01\n",
      "   3.32141712e-02   5.49964164e-02   1.02839754e-01   3.14028379e-01\n",
      "   3.37629278e-01   3.84392503e-01   8.83399801e-02   1.10129104e-01\n",
      "   1.08010105e-01   8.66681167e-02   4.72457579e-02   1.50578206e-02\n",
      "   1.15445568e-01   7.74721587e-02   4.60268689e-02   1.31019293e-02\n",
      "   1.71171733e-02   1.06891205e-02   1.61503911e-02   2.32683630e-02\n",
      "   2.32806793e-02   1.92925113e-02   2.52220271e-02   2.73005390e-02\n",
      "   1.01137873e-02   1.03645732e-02   6.16160561e-03   2.02083223e-03\n",
      "   1.70359130e-03   7.00154179e-04   3.51687793e-02   2.44226358e-02\n",
      "   1.47087389e-02   4.28337852e-02   2.76697778e-02   1.74369109e-02\n",
      "   3.92831880e-02   2.75662173e-02   1.64491553e-02   4.58853086e-02\n",
      "   3.58281176e-02   1.77881677e-02   4.21709529e-03   4.28462731e-03\n",
      "   3.40504115e-03   2.13313230e-03   2.97392625e-03   5.83343079e-03\n",
      "   5.46931596e-03   2.23205093e-03   1.04482185e-03   1.41051417e-03\n",
      "   1.77239968e-03   1.41468307e-03   1.90784567e-03   3.15864055e-03\n",
      "   3.00955621e-03   2.27088812e-03   5.28877510e-03   7.59079442e-03\n",
      "   2.14140497e-03   2.36911525e-03   2.20168311e-03   9.32633201e-03\n",
      "   6.09398013e-03   4.26212837e-03   5.74794226e-03   2.85910083e-03\n",
      "   1.36394868e-03   1.63008322e-03   1.54818187e-03   1.45036265e-03\n",
      "   1.53043840e-03   8.03911808e-04   1.61193151e-04   1.28703154e-03\n",
      "   5.88402242e-04   2.00114691e-04   2.88621766e-03   1.95513999e-03\n",
      "   1.24321699e-03   2.14101698e-03   1.62676871e-03   9.44498885e-04\n",
      "   7.67023473e-03   8.53562229e-03   6.87375441e-03   8.15893425e-04\n",
      "   7.76490896e-04   1.34083784e-03   7.86878589e-05   1.14351616e-04\n",
      "   1.55753447e-04   1.15663553e-04   5.56375967e-05   2.64969803e-05\n",
      "   6.49426658e-05   4.24666651e-05   3.06355574e-05   3.65909117e-04\n",
      "   2.89681648e-04   2.41325203e-04   4.57280260e-04   4.00194085e-04\n",
      "   3.47052079e-04   2.21918206e-04   1.41724775e-04   1.13287178e-04\n",
      "   5.17952512e-05   2.99441115e-05   1.08118687e-05   9.84499975e-06\n",
      "   5.02517093e-06   5.82747457e-06   7.11439808e-06   5.16367071e-06\n",
      "   8.13721659e-06   6.29837481e-06   3.94084257e-06   2.71159327e-06\n",
      "   4.27371490e-06   3.50801975e-06   3.53042632e-06   3.95102962e-06\n",
      "   1.66683559e-06   1.35669814e-06   5.24599194e-06   1.81688393e-06\n",
      "   8.84132828e-07   3.11880139e-06   1.33216246e-06   7.58181771e-07\n",
      "   4.85192275e-06   1.85472501e-06   1.02450258e-06   1.43146007e-06\n",
      "   9.36088854e-07   8.23371686e-07   1.44918811e-06   6.55883053e-07\n",
      "   6.60611721e-07   1.46372639e-06   6.84709448e-07   5.00266847e-07\n",
      "   1.35269833e-06   5.16568902e-07   2.77121724e-07   1.23032572e-06\n",
      "   5.32978930e-07   3.03690218e-07   4.86671561e-07   3.13463382e-07\n",
      "   2.01955182e-07   1.26871018e-06   4.38709561e-07   2.15005164e-07\n",
      "   1.77301081e-06   5.42862910e-07   1.88942085e-07   1.36760639e-06\n",
      "   4.31120888e-07   1.77085651e-07   9.17010094e-07   2.97676917e-07\n",
      "   1.28319946e-07   8.32583853e-07   2.52253623e-07   9.95444170e-08\n",
      "   7.50558374e-07   2.55156905e-07   1.27618286e-07   8.16844004e-07\n",
      "   2.77780852e-07   1.64237379e-07   5.56249881e-07   1.74956179e-07\n",
      "   9.24119513e-08   6.40970335e-07   1.85599840e-07   7.39589773e-08\n",
      "   6.00466081e-07   1.74796455e-07   8.14912292e-08   5.03540242e-07\n",
      "   1.43421481e-07   6.72165947e-08   5.03869682e-07   1.42617006e-07\n",
      "   6.58458886e-08   5.09091261e-07   1.43600861e-07   6.49130999e-08\n",
      "   1.90000000e+01]\n"
     ]
    }
   ],
   "source": [
    "#preprocess to chroma\n",
    "import os\n",
    "\n",
    "df_new = None\n",
    "\n",
    "processedData_path = \"preprocessedSamples_spec.data\"\n",
    "\n",
    "if os.path.isfile(processedData_path): #if already preprocessed\n",
    "    df_new = pd.read_pickle(processedData_path)\n",
    "else:\n",
    "    for i in range(len(X)):\n",
    "        sample = librosa.feature.melspectrogram(y=X[i], sr=44100)\n",
    "        sample = np.append(sample, y[i])\n",
    "        try:\n",
    "            df_new = np.vstack([df_new, sample])\n",
    "        except:\n",
    "            df_new = np.array(sample, dtype=np.float)\n",
    "            print('here')\n",
    "            print(df_new)\n",
    "        if i % 2000 == 0:\n",
    "            print(i)\n",
    "            print(sample)\n",
    "            print(df_new[i])\n",
    "    \n",
    "    df_new = pd.DataFrame(df_new)\n",
    "    \n",
    "    df_new.to_pickle(processedData_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParameterError",
     "evalue": "Invalid shape for monophonic audio: ndim=2, shape=(14377, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-08a3a0a20270>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m44100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\feature\\spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, power, **kwargs)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     S, n_fft = _spectrogram(y=y, S=S, n_fft=n_fft, hop_length=hop_length,\n\u001b[1;32m-> 1388\u001b[1;33m                             power=power)\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;31m# Build a Mel filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power)\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Otherwise, compute a magnitude spectrogram from input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1179\u001b[1;33m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;31m# Pad the time series so that frames are centered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_fft\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\librosa\\util\\utils.py\u001b[0m in \u001b[0;36mvalid_audio\u001b[1;34m(y, mono)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmono\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         raise ParameterError('Invalid shape for monophonic audio: '\n\u001b[1;32m--> 151\u001b[1;33m                              'ndim={:d}, shape={}'.format(y.ndim, y.shape))\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         raise ParameterError('Invalid shape for audio: '\n",
      "\u001b[1;31mParameterError\u001b[0m: Invalid shape for monophonic audio: ndim=2, shape=(14377, 1024)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.029797</td>\n",
       "      <td>0.104510</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.097913</td>\n",
       "      <td>0.062627</td>\n",
       "      <td>0.108053</td>\n",
       "      <td>0.216651</td>\n",
       "      <td>0.085317</td>\n",
       "      <td>...</td>\n",
       "      <td>9.090588e-08</td>\n",
       "      <td>8.007271e-08</td>\n",
       "      <td>1.469040e-07</td>\n",
       "      <td>5.716087e-08</td>\n",
       "      <td>4.747241e-08</td>\n",
       "      <td>1.260094e-07</td>\n",
       "      <td>5.535224e-08</td>\n",
       "      <td>4.626970e-08</td>\n",
       "      <td>1.286249e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162412</td>\n",
       "      <td>0.184350</td>\n",
       "      <td>0.561519</td>\n",
       "      <td>0.218695</td>\n",
       "      <td>0.285293</td>\n",
       "      <td>0.762448</td>\n",
       "      <td>0.393319</td>\n",
       "      <td>0.300798</td>\n",
       "      <td>0.709370</td>\n",
       "      <td>2.190042</td>\n",
       "      <td>...</td>\n",
       "      <td>2.283377e-06</td>\n",
       "      <td>1.698236e-06</td>\n",
       "      <td>4.119831e-06</td>\n",
       "      <td>1.952830e-06</td>\n",
       "      <td>1.430251e-06</td>\n",
       "      <td>3.696928e-06</td>\n",
       "      <td>1.813380e-06</td>\n",
       "      <td>1.374210e-06</td>\n",
       "      <td>3.656530e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.471432</td>\n",
       "      <td>0.163872</td>\n",
       "      <td>0.179869</td>\n",
       "      <td>0.643785</td>\n",
       "      <td>0.264899</td>\n",
       "      <td>0.256060</td>\n",
       "      <td>0.701053</td>\n",
       "      <td>0.259163</td>\n",
       "      <td>0.345608</td>\n",
       "      <td>1.374581</td>\n",
       "      <td>...</td>\n",
       "      <td>4.981423e-07</td>\n",
       "      <td>1.252670e-07</td>\n",
       "      <td>1.241049e-09</td>\n",
       "      <td>4.750047e-07</td>\n",
       "      <td>1.188897e-07</td>\n",
       "      <td>2.952262e-10</td>\n",
       "      <td>4.667286e-07</td>\n",
       "      <td>1.167180e-07</td>\n",
       "      <td>1.123269e-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123224</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.170966</td>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.068184</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.599416</td>\n",
       "      <td>...</td>\n",
       "      <td>2.005835e-08</td>\n",
       "      <td>6.414345e-09</td>\n",
       "      <td>3.142349e-09</td>\n",
       "      <td>1.838761e-08</td>\n",
       "      <td>5.118136e-09</td>\n",
       "      <td>1.856533e-09</td>\n",
       "      <td>1.861613e-08</td>\n",
       "      <td>5.165185e-09</td>\n",
       "      <td>2.022390e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.019121</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.056832</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860876e-07</td>\n",
       "      <td>1.275527e-07</td>\n",
       "      <td>2.207807e-07</td>\n",
       "      <td>2.799938e-07</td>\n",
       "      <td>1.247090e-07</td>\n",
       "      <td>2.171458e-07</td>\n",
       "      <td>2.698613e-07</td>\n",
       "      <td>1.224099e-07</td>\n",
       "      <td>2.184646e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.587635</td>\n",
       "      <td>0.324092</td>\n",
       "      <td>0.669588</td>\n",
       "      <td>0.765839</td>\n",
       "      <td>0.495274</td>\n",
       "      <td>0.881200</td>\n",
       "      <td>0.823326</td>\n",
       "      <td>0.412649</td>\n",
       "      <td>0.945610</td>\n",
       "      <td>1.219535</td>\n",
       "      <td>...</td>\n",
       "      <td>2.704927e-07</td>\n",
       "      <td>9.553067e-08</td>\n",
       "      <td>1.080255e-07</td>\n",
       "      <td>2.877697e-07</td>\n",
       "      <td>1.000525e-07</td>\n",
       "      <td>1.113688e-07</td>\n",
       "      <td>2.800855e-07</td>\n",
       "      <td>9.736914e-08</td>\n",
       "      <td>1.087308e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.144512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.880430e-07</td>\n",
       "      <td>8.306559e-08</td>\n",
       "      <td>1.399660e-07</td>\n",
       "      <td>1.844949e-07</td>\n",
       "      <td>8.061540e-08</td>\n",
       "      <td>1.367141e-07</td>\n",
       "      <td>1.859606e-07</td>\n",
       "      <td>8.087657e-08</td>\n",
       "      <td>1.366626e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073514</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.135824</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>0.496028</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>0.662475</td>\n",
       "      <td>...</td>\n",
       "      <td>7.613927e-07</td>\n",
       "      <td>4.421186e-07</td>\n",
       "      <td>9.562601e-07</td>\n",
       "      <td>7.586623e-07</td>\n",
       "      <td>4.333982e-07</td>\n",
       "      <td>9.592334e-07</td>\n",
       "      <td>7.495555e-07</td>\n",
       "      <td>4.280706e-07</td>\n",
       "      <td>9.566685e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.275240</td>\n",
       "      <td>0.172654</td>\n",
       "      <td>0.397972</td>\n",
       "      <td>0.416796</td>\n",
       "      <td>0.267883</td>\n",
       "      <td>0.489636</td>\n",
       "      <td>0.735562</td>\n",
       "      <td>0.304667</td>\n",
       "      <td>0.448268</td>\n",
       "      <td>2.937819</td>\n",
       "      <td>...</td>\n",
       "      <td>2.481534e-07</td>\n",
       "      <td>6.659273e-08</td>\n",
       "      <td>1.477993e-08</td>\n",
       "      <td>2.351923e-07</td>\n",
       "      <td>6.167125e-08</td>\n",
       "      <td>1.103307e-08</td>\n",
       "      <td>2.340248e-07</td>\n",
       "      <td>6.129494e-08</td>\n",
       "      <td>1.105369e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.146581</td>\n",
       "      <td>0.050681</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>0.164493</td>\n",
       "      <td>0.062433</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>0.147687</td>\n",
       "      <td>0.047606</td>\n",
       "      <td>0.059082</td>\n",
       "      <td>0.066963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149026e-07</td>\n",
       "      <td>6.032416e-08</td>\n",
       "      <td>8.157226e-08</td>\n",
       "      <td>1.054747e-07</td>\n",
       "      <td>3.268232e-08</td>\n",
       "      <td>2.015993e-08</td>\n",
       "      <td>1.058438e-07</td>\n",
       "      <td>2.738747e-08</td>\n",
       "      <td>3.479259e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.011721</td>\n",
       "      <td>0.057530</td>\n",
       "      <td>...</td>\n",
       "      <td>8.873226e-09</td>\n",
       "      <td>8.094110e-09</td>\n",
       "      <td>2.198941e-08</td>\n",
       "      <td>9.839131e-09</td>\n",
       "      <td>7.605972e-09</td>\n",
       "      <td>2.023894e-08</td>\n",
       "      <td>9.683474e-09</td>\n",
       "      <td>7.512008e-09</td>\n",
       "      <td>2.023259e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.660213</td>\n",
       "      <td>0.579866</td>\n",
       "      <td>1.452815</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>0.657861</td>\n",
       "      <td>1.622888</td>\n",
       "      <td>0.780504</td>\n",
       "      <td>0.591670</td>\n",
       "      <td>1.660580</td>\n",
       "      <td>2.911524</td>\n",
       "      <td>...</td>\n",
       "      <td>4.419341e-07</td>\n",
       "      <td>6.561166e-07</td>\n",
       "      <td>2.167419e-06</td>\n",
       "      <td>4.312149e-07</td>\n",
       "      <td>6.326150e-07</td>\n",
       "      <td>2.085509e-06</td>\n",
       "      <td>4.270607e-07</td>\n",
       "      <td>6.255225e-07</td>\n",
       "      <td>2.062435e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.059157</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.079010</td>\n",
       "      <td>0.506981</td>\n",
       "      <td>0.694104</td>\n",
       "      <td>1.038531</td>\n",
       "      <td>0.323162</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545414e-07</td>\n",
       "      <td>4.287748e-07</td>\n",
       "      <td>1.147742e-06</td>\n",
       "      <td>3.636460e-08</td>\n",
       "      <td>3.347199e-07</td>\n",
       "      <td>1.251889e-06</td>\n",
       "      <td>1.663899e-09</td>\n",
       "      <td>3.206607e-07</td>\n",
       "      <td>1.271232e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.042377</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>0.025571</td>\n",
       "      <td>0.096179</td>\n",
       "      <td>0.254445</td>\n",
       "      <td>0.195528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.740497e-06</td>\n",
       "      <td>8.414303e-06</td>\n",
       "      <td>2.668249e-05</td>\n",
       "      <td>6.295455e-07</td>\n",
       "      <td>4.518437e-06</td>\n",
       "      <td>1.706315e-05</td>\n",
       "      <td>4.359339e-07</td>\n",
       "      <td>3.587775e-06</td>\n",
       "      <td>1.382303e-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.351830</td>\n",
       "      <td>0.231380</td>\n",
       "      <td>0.528425</td>\n",
       "      <td>0.408486</td>\n",
       "      <td>0.325618</td>\n",
       "      <td>0.644243</td>\n",
       "      <td>0.342645</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>0.452002</td>\n",
       "      <td>0.835412</td>\n",
       "      <td>...</td>\n",
       "      <td>7.040880e-07</td>\n",
       "      <td>5.533228e-07</td>\n",
       "      <td>1.496778e-06</td>\n",
       "      <td>6.939047e-07</td>\n",
       "      <td>5.326182e-07</td>\n",
       "      <td>1.428121e-06</td>\n",
       "      <td>6.805540e-07</td>\n",
       "      <td>5.227933e-07</td>\n",
       "      <td>1.401864e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.247169</td>\n",
       "      <td>0.303930</td>\n",
       "      <td>0.827336</td>\n",
       "      <td>0.356607</td>\n",
       "      <td>0.393295</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.462771</td>\n",
       "      <td>1.039223</td>\n",
       "      <td>...</td>\n",
       "      <td>2.035750e-07</td>\n",
       "      <td>5.371658e-08</td>\n",
       "      <td>8.937892e-09</td>\n",
       "      <td>2.085071e-07</td>\n",
       "      <td>5.441755e-08</td>\n",
       "      <td>8.753429e-09</td>\n",
       "      <td>2.075633e-07</td>\n",
       "      <td>5.398494e-08</td>\n",
       "      <td>8.302371e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>...</td>\n",
       "      <td>4.234258e-09</td>\n",
       "      <td>8.007053e-09</td>\n",
       "      <td>2.428321e-08</td>\n",
       "      <td>2.790132e-09</td>\n",
       "      <td>7.317409e-09</td>\n",
       "      <td>2.596916e-08</td>\n",
       "      <td>2.559721e-09</td>\n",
       "      <td>7.216346e-09</td>\n",
       "      <td>2.613287e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.021590</td>\n",
       "      <td>0.069609</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.031506</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.068275</td>\n",
       "      <td>0.159136</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507528e-08</td>\n",
       "      <td>7.074766e-09</td>\n",
       "      <td>2.833184e-09</td>\n",
       "      <td>4.976909e-09</td>\n",
       "      <td>1.897507e-09</td>\n",
       "      <td>9.485400e-10</td>\n",
       "      <td>4.272376e-09</td>\n",
       "      <td>1.198435e-09</td>\n",
       "      <td>4.678388e-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019416</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.071786</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.084710</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.078447</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>...</td>\n",
       "      <td>4.260997e-06</td>\n",
       "      <td>2.559075e-06</td>\n",
       "      <td>2.580869e-06</td>\n",
       "      <td>9.169897e-07</td>\n",
       "      <td>7.052615e-07</td>\n",
       "      <td>1.817244e-06</td>\n",
       "      <td>8.537278e-07</td>\n",
       "      <td>6.335056e-07</td>\n",
       "      <td>1.661535e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.014637</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.035902</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.320155</td>\n",
       "      <td>...</td>\n",
       "      <td>7.083501e-09</td>\n",
       "      <td>9.065194e-09</td>\n",
       "      <td>2.537623e-08</td>\n",
       "      <td>4.270430e-09</td>\n",
       "      <td>7.199654e-09</td>\n",
       "      <td>2.400764e-08</td>\n",
       "      <td>5.026639e-09</td>\n",
       "      <td>7.555402e-09</td>\n",
       "      <td>2.501359e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.067080</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812771e-06</td>\n",
       "      <td>7.099235e-07</td>\n",
       "      <td>1.412015e-08</td>\n",
       "      <td>2.629961e-06</td>\n",
       "      <td>6.602947e-07</td>\n",
       "      <td>9.192217e-09</td>\n",
       "      <td>2.639494e-06</td>\n",
       "      <td>6.618533e-07</td>\n",
       "      <td>7.724439e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.038487</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.060199</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>...</td>\n",
       "      <td>3.027334e-08</td>\n",
       "      <td>3.471726e-07</td>\n",
       "      <td>1.144857e-06</td>\n",
       "      <td>1.170975e-08</td>\n",
       "      <td>2.077289e-07</td>\n",
       "      <td>8.058633e-07</td>\n",
       "      <td>1.032746e-08</td>\n",
       "      <td>1.924879e-07</td>\n",
       "      <td>7.546390e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.079478</td>\n",
       "      <td>...</td>\n",
       "      <td>2.637879e-08</td>\n",
       "      <td>1.569903e-08</td>\n",
       "      <td>3.462025e-08</td>\n",
       "      <td>2.635825e-08</td>\n",
       "      <td>1.461532e-08</td>\n",
       "      <td>3.166200e-08</td>\n",
       "      <td>2.577407e-08</td>\n",
       "      <td>1.425104e-08</td>\n",
       "      <td>3.103153e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.014280</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.034112</td>\n",
       "      <td>0.079155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344014e-07</td>\n",
       "      <td>3.707503e-08</td>\n",
       "      <td>1.070305e-08</td>\n",
       "      <td>1.402719e-07</td>\n",
       "      <td>3.769242e-08</td>\n",
       "      <td>1.009269e-08</td>\n",
       "      <td>1.349994e-07</td>\n",
       "      <td>3.618721e-08</td>\n",
       "      <td>9.670727e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009309</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.019722</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>...</td>\n",
       "      <td>2.105029e-08</td>\n",
       "      <td>2.431107e-08</td>\n",
       "      <td>6.409554e-08</td>\n",
       "      <td>1.210736e-08</td>\n",
       "      <td>1.761266e-08</td>\n",
       "      <td>5.677641e-08</td>\n",
       "      <td>1.134438e-08</td>\n",
       "      <td>1.615979e-08</td>\n",
       "      <td>5.291235e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.040687</td>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>0.086294</td>\n",
       "      <td>...</td>\n",
       "      <td>4.849274e-07</td>\n",
       "      <td>2.838699e-07</td>\n",
       "      <td>1.926328e-07</td>\n",
       "      <td>3.224454e-07</td>\n",
       "      <td>1.091369e-07</td>\n",
       "      <td>3.468300e-08</td>\n",
       "      <td>2.857067e-07</td>\n",
       "      <td>8.409190e-08</td>\n",
       "      <td>4.494995e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.026109</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.051376</td>\n",
       "      <td>0.041219</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.065746</td>\n",
       "      <td>0.082506</td>\n",
       "      <td>0.041026</td>\n",
       "      <td>0.104378</td>\n",
       "      <td>0.170071</td>\n",
       "      <td>...</td>\n",
       "      <td>8.608236e-07</td>\n",
       "      <td>1.702083e-06</td>\n",
       "      <td>4.895757e-06</td>\n",
       "      <td>3.776639e-07</td>\n",
       "      <td>8.748121e-07</td>\n",
       "      <td>2.958814e-06</td>\n",
       "      <td>3.463804e-07</td>\n",
       "      <td>7.592745e-07</td>\n",
       "      <td>2.669592e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.061893</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.116446</td>\n",
       "      <td>0.048093</td>\n",
       "      <td>0.043772</td>\n",
       "      <td>0.160457</td>\n",
       "      <td>...</td>\n",
       "      <td>4.933069e-09</td>\n",
       "      <td>2.308813e-09</td>\n",
       "      <td>1.936804e-09</td>\n",
       "      <td>2.929023e-09</td>\n",
       "      <td>1.188947e-09</td>\n",
       "      <td>1.580091e-09</td>\n",
       "      <td>3.317613e-09</td>\n",
       "      <td>1.017266e-09</td>\n",
       "      <td>7.396135e-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.031544</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>...</td>\n",
       "      <td>5.047573e-08</td>\n",
       "      <td>1.560538e-08</td>\n",
       "      <td>8.453096e-09</td>\n",
       "      <td>4.310557e-08</td>\n",
       "      <td>1.181053e-08</td>\n",
       "      <td>3.805250e-09</td>\n",
       "      <td>4.284273e-08</td>\n",
       "      <td>1.148417e-08</td>\n",
       "      <td>3.057263e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.036642</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131048e-09</td>\n",
       "      <td>1.784506e-08</td>\n",
       "      <td>6.809890e-08</td>\n",
       "      <td>4.208613e-10</td>\n",
       "      <td>1.658743e-08</td>\n",
       "      <td>6.529406e-08</td>\n",
       "      <td>2.900683e-10</td>\n",
       "      <td>1.643445e-08</td>\n",
       "      <td>6.503863e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.444656</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.128845</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.136447</td>\n",
       "      <td>0.535061</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>...</td>\n",
       "      <td>8.333016e-06</td>\n",
       "      <td>3.243992e-06</td>\n",
       "      <td>4.499178e-06</td>\n",
       "      <td>8.466127e-06</td>\n",
       "      <td>3.175228e-06</td>\n",
       "      <td>4.205197e-06</td>\n",
       "      <td>8.025603e-06</td>\n",
       "      <td>3.055265e-06</td>\n",
       "      <td>4.168758e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>...</td>\n",
       "      <td>5.733073e-09</td>\n",
       "      <td>2.244429e-09</td>\n",
       "      <td>1.128407e-09</td>\n",
       "      <td>6.151758e-09</td>\n",
       "      <td>1.780211e-09</td>\n",
       "      <td>6.651909e-10</td>\n",
       "      <td>5.960987e-09</td>\n",
       "      <td>1.607878e-09</td>\n",
       "      <td>4.537892e-10</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>1.477657</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.264369</td>\n",
       "      <td>2.243291</td>\n",
       "      <td>0.716699</td>\n",
       "      <td>0.158514</td>\n",
       "      <td>1.433502</td>\n",
       "      <td>0.627263</td>\n",
       "      <td>0.051078</td>\n",
       "      <td>0.180540</td>\n",
       "      <td>...</td>\n",
       "      <td>6.481285e-06</td>\n",
       "      <td>4.884009e-06</td>\n",
       "      <td>8.785078e-06</td>\n",
       "      <td>9.121999e-08</td>\n",
       "      <td>1.443675e-06</td>\n",
       "      <td>5.582559e-06</td>\n",
       "      <td>1.272928e-07</td>\n",
       "      <td>1.328989e-06</td>\n",
       "      <td>5.152947e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.279769</td>\n",
       "      <td>1.092318</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>0.330723</td>\n",
       "      <td>1.306990</td>\n",
       "      <td>0.035501</td>\n",
       "      <td>0.396941</td>\n",
       "      <td>1.515628</td>\n",
       "      <td>0.074940</td>\n",
       "      <td>...</td>\n",
       "      <td>6.614217e-07</td>\n",
       "      <td>2.413400e-07</td>\n",
       "      <td>2.870659e-07</td>\n",
       "      <td>6.444980e-07</td>\n",
       "      <td>2.283139e-07</td>\n",
       "      <td>2.650014e-07</td>\n",
       "      <td>6.337901e-07</td>\n",
       "      <td>2.273948e-07</td>\n",
       "      <td>2.738032e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>0.036690</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>0.045047</td>\n",
       "      <td>0.057147</td>\n",
       "      <td>0.145625</td>\n",
       "      <td>0.034741</td>\n",
       "      <td>0.039311</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.103247</td>\n",
       "      <td>...</td>\n",
       "      <td>1.495975e-08</td>\n",
       "      <td>2.120630e-07</td>\n",
       "      <td>6.513750e-07</td>\n",
       "      <td>6.045439e-09</td>\n",
       "      <td>1.198658e-07</td>\n",
       "      <td>4.246887e-07</td>\n",
       "      <td>3.126995e-09</td>\n",
       "      <td>9.960392e-08</td>\n",
       "      <td>3.896438e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14352</th>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719222e-07</td>\n",
       "      <td>6.875318e-08</td>\n",
       "      <td>1.448714e-09</td>\n",
       "      <td>2.710378e-07</td>\n",
       "      <td>6.787396e-08</td>\n",
       "      <td>1.412413e-10</td>\n",
       "      <td>2.642699e-07</td>\n",
       "      <td>6.607904e-08</td>\n",
       "      <td>4.434390e-11</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.017274</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.086931</td>\n",
       "      <td>0.051152</td>\n",
       "      <td>0.035304</td>\n",
       "      <td>0.015195</td>\n",
       "      <td>0.072922</td>\n",
       "      <td>...</td>\n",
       "      <td>1.522014e-07</td>\n",
       "      <td>9.371090e-08</td>\n",
       "      <td>7.310662e-08</td>\n",
       "      <td>6.489082e-08</td>\n",
       "      <td>2.744596e-08</td>\n",
       "      <td>2.305730e-08</td>\n",
       "      <td>4.324977e-08</td>\n",
       "      <td>1.611169e-08</td>\n",
       "      <td>1.968789e-08</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>27.710236</td>\n",
       "      <td>7.207067</td>\n",
       "      <td>1.006533</td>\n",
       "      <td>38.879678</td>\n",
       "      <td>10.335746</td>\n",
       "      <td>1.683986</td>\n",
       "      <td>55.403386</td>\n",
       "      <td>18.321132</td>\n",
       "      <td>7.614234</td>\n",
       "      <td>79.445069</td>\n",
       "      <td>...</td>\n",
       "      <td>1.908863e-03</td>\n",
       "      <td>9.395149e-04</td>\n",
       "      <td>2.557223e-04</td>\n",
       "      <td>1.830687e-04</td>\n",
       "      <td>9.921658e-05</td>\n",
       "      <td>2.234785e-05</td>\n",
       "      <td>2.313409e-05</td>\n",
       "      <td>6.091703e-06</td>\n",
       "      <td>1.164844e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>0.017794</td>\n",
       "      <td>0.076729</td>\n",
       "      <td>0.254835</td>\n",
       "      <td>0.113957</td>\n",
       "      <td>0.217163</td>\n",
       "      <td>0.777967</td>\n",
       "      <td>0.375002</td>\n",
       "      <td>1.004351</td>\n",
       "      <td>1.296182</td>\n",
       "      <td>2.455899</td>\n",
       "      <td>...</td>\n",
       "      <td>1.257494e-05</td>\n",
       "      <td>3.355616e-06</td>\n",
       "      <td>5.890047e-07</td>\n",
       "      <td>1.074863e-05</td>\n",
       "      <td>2.816546e-06</td>\n",
       "      <td>4.930824e-07</td>\n",
       "      <td>1.065474e-05</td>\n",
       "      <td>2.782212e-06</td>\n",
       "      <td>4.698498e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.022263</td>\n",
       "      <td>0.065986</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>...</td>\n",
       "      <td>3.201667e-05</td>\n",
       "      <td>3.183141e-05</td>\n",
       "      <td>8.637395e-05</td>\n",
       "      <td>2.467928e-05</td>\n",
       "      <td>2.467361e-05</td>\n",
       "      <td>7.330951e-05</td>\n",
       "      <td>2.325489e-05</td>\n",
       "      <td>2.309269e-05</td>\n",
       "      <td>6.868881e-05</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>0.649571</td>\n",
       "      <td>0.186052</td>\n",
       "      <td>0.133392</td>\n",
       "      <td>1.184842</td>\n",
       "      <td>0.412882</td>\n",
       "      <td>0.131752</td>\n",
       "      <td>0.879802</td>\n",
       "      <td>0.347711</td>\n",
       "      <td>0.076223</td>\n",
       "      <td>0.347116</td>\n",
       "      <td>...</td>\n",
       "      <td>5.968472e-06</td>\n",
       "      <td>2.182546e-06</td>\n",
       "      <td>2.666472e-06</td>\n",
       "      <td>6.145162e-06</td>\n",
       "      <td>2.185480e-06</td>\n",
       "      <td>2.574719e-06</td>\n",
       "      <td>6.057972e-06</td>\n",
       "      <td>2.163559e-06</td>\n",
       "      <td>2.579719e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14358</th>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.045446</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.037684</td>\n",
       "      <td>...</td>\n",
       "      <td>5.998882e-09</td>\n",
       "      <td>6.501578e-08</td>\n",
       "      <td>2.152728e-07</td>\n",
       "      <td>2.390151e-09</td>\n",
       "      <td>3.754846e-08</td>\n",
       "      <td>1.413201e-07</td>\n",
       "      <td>2.780166e-09</td>\n",
       "      <td>3.089986e-08</td>\n",
       "      <td>1.199358e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14359</th>\n",
       "      <td>0.427138</td>\n",
       "      <td>0.160398</td>\n",
       "      <td>0.174539</td>\n",
       "      <td>1.083729</td>\n",
       "      <td>0.288979</td>\n",
       "      <td>0.238298</td>\n",
       "      <td>2.464417</td>\n",
       "      <td>1.168187</td>\n",
       "      <td>0.243441</td>\n",
       "      <td>1.657603</td>\n",
       "      <td>...</td>\n",
       "      <td>3.662810e-05</td>\n",
       "      <td>1.540358e-05</td>\n",
       "      <td>1.240105e-05</td>\n",
       "      <td>1.279792e-05</td>\n",
       "      <td>5.049140e-06</td>\n",
       "      <td>6.643056e-06</td>\n",
       "      <td>1.123790e-05</td>\n",
       "      <td>4.139090e-06</td>\n",
       "      <td>5.267020e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14360</th>\n",
       "      <td>0.254710</td>\n",
       "      <td>0.159693</td>\n",
       "      <td>0.376915</td>\n",
       "      <td>0.353998</td>\n",
       "      <td>0.266363</td>\n",
       "      <td>0.540452</td>\n",
       "      <td>0.471833</td>\n",
       "      <td>0.273079</td>\n",
       "      <td>0.633934</td>\n",
       "      <td>0.567348</td>\n",
       "      <td>...</td>\n",
       "      <td>5.799831e-06</td>\n",
       "      <td>1.472024e-06</td>\n",
       "      <td>4.374656e-08</td>\n",
       "      <td>5.695618e-06</td>\n",
       "      <td>1.434020e-06</td>\n",
       "      <td>3.591831e-08</td>\n",
       "      <td>5.562314e-06</td>\n",
       "      <td>1.398217e-06</td>\n",
       "      <td>3.010542e-08</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14361</th>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040348e-09</td>\n",
       "      <td>3.350157e-10</td>\n",
       "      <td>7.549448e-11</td>\n",
       "      <td>6.850765e-10</td>\n",
       "      <td>1.889840e-10</td>\n",
       "      <td>2.122283e-11</td>\n",
       "      <td>6.519097e-10</td>\n",
       "      <td>1.645832e-10</td>\n",
       "      <td>5.025662e-12</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14362</th>\n",
       "      <td>0.493466</td>\n",
       "      <td>0.195066</td>\n",
       "      <td>0.216101</td>\n",
       "      <td>0.450212</td>\n",
       "      <td>0.394431</td>\n",
       "      <td>0.917802</td>\n",
       "      <td>4.139749</td>\n",
       "      <td>3.129408</td>\n",
       "      <td>3.210536</td>\n",
       "      <td>18.025169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312733e-05</td>\n",
       "      <td>6.915279e-06</td>\n",
       "      <td>6.432036e-06</td>\n",
       "      <td>7.289869e-06</td>\n",
       "      <td>2.605352e-06</td>\n",
       "      <td>2.948734e-06</td>\n",
       "      <td>8.307214e-06</td>\n",
       "      <td>2.743288e-06</td>\n",
       "      <td>2.641762e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14363</th>\n",
       "      <td>1.602217</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>0.120014</td>\n",
       "      <td>1.654597</td>\n",
       "      <td>0.463531</td>\n",
       "      <td>0.038544</td>\n",
       "      <td>2.647302</td>\n",
       "      <td>0.748212</td>\n",
       "      <td>0.218310</td>\n",
       "      <td>12.269286</td>\n",
       "      <td>...</td>\n",
       "      <td>4.783034e-06</td>\n",
       "      <td>2.282770e-06</td>\n",
       "      <td>4.279844e-06</td>\n",
       "      <td>4.609227e-06</td>\n",
       "      <td>2.190096e-06</td>\n",
       "      <td>4.122942e-06</td>\n",
       "      <td>4.599963e-06</td>\n",
       "      <td>2.187675e-06</td>\n",
       "      <td>4.124190e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14364</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.081533</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.040082</td>\n",
       "      <td>0.109416</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>...</td>\n",
       "      <td>7.081522e-07</td>\n",
       "      <td>3.617835e-07</td>\n",
       "      <td>1.828800e-07</td>\n",
       "      <td>1.489992e-07</td>\n",
       "      <td>7.668584e-08</td>\n",
       "      <td>7.773520e-08</td>\n",
       "      <td>5.082642e-08</td>\n",
       "      <td>1.987715e-08</td>\n",
       "      <td>2.552377e-08</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14365</th>\n",
       "      <td>0.068644</td>\n",
       "      <td>0.023945</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.073577</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>0.113837</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>0.201704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231296e-06</td>\n",
       "      <td>9.459574e-07</td>\n",
       "      <td>1.465031e-06</td>\n",
       "      <td>1.598711e-07</td>\n",
       "      <td>3.597592e-07</td>\n",
       "      <td>1.146428e-06</td>\n",
       "      <td>4.086545e-09</td>\n",
       "      <td>2.480619e-07</td>\n",
       "      <td>9.777740e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14366</th>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>...</td>\n",
       "      <td>4.470341e-07</td>\n",
       "      <td>1.763179e-06</td>\n",
       "      <td>5.779591e-06</td>\n",
       "      <td>1.808012e-07</td>\n",
       "      <td>1.065148e-06</td>\n",
       "      <td>3.993342e-06</td>\n",
       "      <td>1.600962e-07</td>\n",
       "      <td>9.510717e-07</td>\n",
       "      <td>3.617224e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14367</th>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.233646</td>\n",
       "      <td>0.893756</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.273363</td>\n",
       "      <td>1.141529</td>\n",
       "      <td>0.028415</td>\n",
       "      <td>0.321198</td>\n",
       "      <td>1.124732</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>...</td>\n",
       "      <td>7.836133e-07</td>\n",
       "      <td>4.464643e-07</td>\n",
       "      <td>9.773599e-07</td>\n",
       "      <td>7.170186e-07</td>\n",
       "      <td>4.152524e-07</td>\n",
       "      <td>9.378490e-07</td>\n",
       "      <td>7.120335e-07</td>\n",
       "      <td>4.113754e-07</td>\n",
       "      <td>9.275451e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14368</th>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.018269</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>...</td>\n",
       "      <td>3.272927e-08</td>\n",
       "      <td>2.626197e-08</td>\n",
       "      <td>6.963954e-08</td>\n",
       "      <td>3.242437e-08</td>\n",
       "      <td>2.505812e-08</td>\n",
       "      <td>6.713644e-08</td>\n",
       "      <td>3.043640e-08</td>\n",
       "      <td>2.430047e-08</td>\n",
       "      <td>6.633689e-08</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14369</th>\n",
       "      <td>2.143957</td>\n",
       "      <td>0.579837</td>\n",
       "      <td>0.223255</td>\n",
       "      <td>4.012727</td>\n",
       "      <td>0.952775</td>\n",
       "      <td>0.243544</td>\n",
       "      <td>10.532828</td>\n",
       "      <td>3.798784</td>\n",
       "      <td>0.521787</td>\n",
       "      <td>24.313602</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757948e-03</td>\n",
       "      <td>1.302356e-03</td>\n",
       "      <td>1.103665e-03</td>\n",
       "      <td>2.253473e-04</td>\n",
       "      <td>1.992420e-04</td>\n",
       "      <td>2.104496e-04</td>\n",
       "      <td>8.632029e-05</td>\n",
       "      <td>4.043927e-05</td>\n",
       "      <td>7.439592e-05</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14370</th>\n",
       "      <td>0.016338</td>\n",
       "      <td>1.014538</td>\n",
       "      <td>3.909229</td>\n",
       "      <td>0.115720</td>\n",
       "      <td>1.343990</td>\n",
       "      <td>5.784141</td>\n",
       "      <td>0.277797</td>\n",
       "      <td>2.654632</td>\n",
       "      <td>7.171123</td>\n",
       "      <td>1.141819</td>\n",
       "      <td>...</td>\n",
       "      <td>5.549289e-06</td>\n",
       "      <td>1.954695e-06</td>\n",
       "      <td>2.003133e-06</td>\n",
       "      <td>5.060375e-06</td>\n",
       "      <td>1.722248e-06</td>\n",
       "      <td>1.779737e-06</td>\n",
       "      <td>4.843320e-06</td>\n",
       "      <td>1.650915e-06</td>\n",
       "      <td>1.747690e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14371</th>\n",
       "      <td>0.201404</td>\n",
       "      <td>0.298825</td>\n",
       "      <td>1.028999</td>\n",
       "      <td>0.422177</td>\n",
       "      <td>0.386680</td>\n",
       "      <td>1.373943</td>\n",
       "      <td>0.903428</td>\n",
       "      <td>0.582978</td>\n",
       "      <td>0.982181</td>\n",
       "      <td>2.015356</td>\n",
       "      <td>...</td>\n",
       "      <td>9.337588e-07</td>\n",
       "      <td>4.374404e-07</td>\n",
       "      <td>7.715068e-07</td>\n",
       "      <td>8.789650e-07</td>\n",
       "      <td>4.093730e-07</td>\n",
       "      <td>7.473691e-07</td>\n",
       "      <td>8.616954e-07</td>\n",
       "      <td>3.976957e-07</td>\n",
       "      <td>7.241665e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14372</th>\n",
       "      <td>0.035936</td>\n",
       "      <td>0.024542</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>0.114069</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.209508</td>\n",
       "      <td>0.445802</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188572e-05</td>\n",
       "      <td>4.081618e-06</td>\n",
       "      <td>4.306942e-06</td>\n",
       "      <td>1.154567e-05</td>\n",
       "      <td>3.980794e-06</td>\n",
       "      <td>4.340354e-06</td>\n",
       "      <td>1.136951e-05</td>\n",
       "      <td>3.924384e-06</td>\n",
       "      <td>4.299690e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14373</th>\n",
       "      <td>0.299616</td>\n",
       "      <td>0.172899</td>\n",
       "      <td>0.387548</td>\n",
       "      <td>0.804375</td>\n",
       "      <td>0.420698</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>3.295646</td>\n",
       "      <td>2.844192</td>\n",
       "      <td>4.201860</td>\n",
       "      <td>2.931795</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167841e-05</td>\n",
       "      <td>4.063589e-06</td>\n",
       "      <td>3.239738e-06</td>\n",
       "      <td>9.742676e-06</td>\n",
       "      <td>3.139210e-06</td>\n",
       "      <td>2.636924e-06</td>\n",
       "      <td>8.767379e-06</td>\n",
       "      <td>2.837364e-06</td>\n",
       "      <td>2.564979e-06</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14374</th>\n",
       "      <td>0.028409</td>\n",
       "      <td>4.223747</td>\n",
       "      <td>16.736486</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>5.553715</td>\n",
       "      <td>22.473479</td>\n",
       "      <td>0.079924</td>\n",
       "      <td>5.902383</td>\n",
       "      <td>21.858591</td>\n",
       "      <td>0.912929</td>\n",
       "      <td>...</td>\n",
       "      <td>2.707697e-04</td>\n",
       "      <td>1.653051e-04</td>\n",
       "      <td>1.035383e-04</td>\n",
       "      <td>8.666701e-05</td>\n",
       "      <td>3.062666e-05</td>\n",
       "      <td>1.622655e-05</td>\n",
       "      <td>6.100269e-05</td>\n",
       "      <td>1.861265e-05</td>\n",
       "      <td>1.325093e-05</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>0.378087</td>\n",
       "      <td>0.774557</td>\n",
       "      <td>2.656764</td>\n",
       "      <td>0.639296</td>\n",
       "      <td>1.148059</td>\n",
       "      <td>2.730567</td>\n",
       "      <td>0.311959</td>\n",
       "      <td>0.420177</td>\n",
       "      <td>1.246790</td>\n",
       "      <td>0.183939</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237936e-05</td>\n",
       "      <td>5.753253e-06</td>\n",
       "      <td>4.092578e-07</td>\n",
       "      <td>2.347252e-05</td>\n",
       "      <td>5.920641e-06</td>\n",
       "      <td>1.690034e-07</td>\n",
       "      <td>2.367455e-05</td>\n",
       "      <td>5.956111e-06</td>\n",
       "      <td>1.468223e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.227837</td>\n",
       "      <td>...</td>\n",
       "      <td>2.299989e-08</td>\n",
       "      <td>2.022214e-07</td>\n",
       "      <td>7.742250e-07</td>\n",
       "      <td>1.728802e-08</td>\n",
       "      <td>1.883251e-07</td>\n",
       "      <td>7.307018e-07</td>\n",
       "      <td>1.909333e-08</td>\n",
       "      <td>1.898440e-07</td>\n",
       "      <td>7.357148e-07</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14377 rows  385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1          2          3          4          5    \\\n",
       "0       0.017406  0.029797   0.104510   0.057899   0.051312   0.097913   \n",
       "1       0.162412  0.184350   0.561519   0.218695   0.285293   0.762448   \n",
       "2       0.471432  0.163872   0.179869   0.643785   0.264899   0.256060   \n",
       "3       0.123224  0.031634   0.005364   0.170966   0.048312   0.010352   \n",
       "4       0.016514  0.006514   0.006784   0.019121   0.008559   0.011583   \n",
       "5       0.587635  0.324092   0.669588   0.765839   0.495274   0.881200   \n",
       "6       0.017017  0.006185   0.008417   0.016628   0.006847   0.009572   \n",
       "7       0.073514  0.019053   0.003197   0.135824   0.041863   0.025275   \n",
       "8       0.275240  0.172654   0.397972   0.416796   0.267883   0.489636   \n",
       "9       0.146581  0.050681   0.042476   0.164493   0.062433   0.051069   \n",
       "10      0.009848  0.002607   0.000857   0.014387   0.003659   0.002196   \n",
       "11      0.660213  0.579866   1.452815   0.685625   0.657861   1.622888   \n",
       "12      0.059157  0.025762   0.016598   0.083518   0.055418   0.079010   \n",
       "13      0.040908  0.014148   0.002720   0.042377   0.018106   0.014412   \n",
       "14      0.351830  0.231380   0.528425   0.408486   0.325618   0.644243   \n",
       "15      0.648000  0.247169   0.303930   0.827336   0.356607   0.393295   \n",
       "16      0.008908  0.002988   0.002773   0.013641   0.004779   0.004068   \n",
       "17      0.012842  0.021590   0.069609   0.011917   0.029679   0.093067   \n",
       "18      0.019416  0.021173   0.071786   0.012402   0.023207   0.084710   \n",
       "19      0.014637  0.004582   0.002926   0.019449   0.006533   0.002419   \n",
       "20      0.000877  0.003654   0.013950   0.002618   0.006927   0.027977   \n",
       "21      0.000773  0.009513   0.038487   0.000866   0.014434   0.060199   \n",
       "22      0.003043  0.001240   0.001428   0.003091   0.001347   0.001599   \n",
       "23      0.000225  0.003533   0.014280   0.000427   0.005857   0.024492   \n",
       "24      0.009309  0.005878   0.015717   0.008272   0.005855   0.019722   \n",
       "25      0.013352  0.010293   0.028943   0.025549   0.013496   0.040687   \n",
       "26      0.026109  0.018753   0.051376   0.041219   0.021337   0.065746   \n",
       "27      0.031791  0.011300   0.013928   0.061893   0.022327   0.018014   \n",
       "28      0.001899  0.005141   0.018648   0.007804   0.009048   0.031544   \n",
       "29      0.011718  0.008129   0.020588   0.017439   0.013805   0.030211   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "14347   0.003969  0.112846   0.444656   0.006439   0.128845   0.534351   \n",
       "14348   0.002299  0.001014   0.001470   0.004566   0.001716   0.000734   \n",
       "14349   1.477657  0.456000   0.264369   2.243291   0.716699   0.158514   \n",
       "14350   0.004853  0.279769   1.092318   0.009220   0.330723   1.306990   \n",
       "14351   0.036690  0.037992   0.111177   0.045047   0.057147   0.145625   \n",
       "14352   0.023766  0.010533   0.016221   0.033780   0.015271   0.014650   \n",
       "14353   0.000317  0.017274   0.073979   0.004332   0.034161   0.086931   \n",
       "14354  27.710236  7.207067   1.006533  38.879678  10.335746   1.683986   \n",
       "14355   0.017794  0.076729   0.254835   0.113957   0.217163   0.777967   \n",
       "14356   0.000468  0.022263   0.065986   0.000818   0.008842   0.011957   \n",
       "14357   0.649571  0.186052   0.133392   1.184842   0.412882   0.131752   \n",
       "14358   0.026404  0.006630   0.000200   0.031190   0.007358   0.000227   \n",
       "14359   0.427138  0.160398   0.174539   1.083729   0.288979   0.238298   \n",
       "14360   0.254710  0.159693   0.376915   0.353998   0.266363   0.540452   \n",
       "14361   0.001838  0.000461   0.000006   0.002226   0.000541   0.000014   \n",
       "14362   0.493466  0.195066   0.216101   0.450212   0.394431   0.917802   \n",
       "14363   1.602217  0.399675   0.120014   1.654597   0.463531   0.038544   \n",
       "14364   0.000518  0.022861   0.081533   0.004266   0.040082   0.109416   \n",
       "14365   0.068644  0.023945   0.027529   0.073577   0.040316   0.057546   \n",
       "14366   0.000497  0.002015   0.007659   0.001172   0.002920   0.008971   \n",
       "14367   0.001152  0.233646   0.893756   0.018174   0.273363   1.141529   \n",
       "14368   0.014908  0.004566   0.002502   0.018269   0.006337   0.002013   \n",
       "14369   2.143957  0.579837   0.223255   4.012727   0.952775   0.243544   \n",
       "14370   0.016338  1.014538   3.909229   0.115720   1.343990   5.784141   \n",
       "14371   0.201404  0.298825   1.028999   0.422177   0.386680   1.373943   \n",
       "14372   0.035936  0.024542   0.065971   0.028736   0.036058   0.114069   \n",
       "14373   0.299616  0.172899   0.387548   0.804375   0.420698   0.769985   \n",
       "14374   0.028409  4.223747  16.736486   0.071281   5.553715  22.473479   \n",
       "14375   0.378087  0.774557   2.656764   0.639296   1.148059   2.730567   \n",
       "14376   0.076416  0.020856   0.000181   0.040959   0.016823   0.001396   \n",
       "\n",
       "             6          7          8          9    ...            375  \\\n",
       "0       0.062627   0.108053   0.216651   0.085317  ...   9.090588e-08   \n",
       "1       0.393319   0.300798   0.709370   2.190042  ...   2.283377e-06   \n",
       "2       0.701053   0.259163   0.345608   1.374581  ...   4.981423e-07   \n",
       "3       0.258969   0.068184   0.014651   0.599416  ...   2.005835e-08   \n",
       "4       0.056832   0.025389   0.018565   0.216447  ...   2.860876e-07   \n",
       "5       0.823326   0.412649   0.945610   1.219535  ...   2.704927e-07   \n",
       "6       0.002758   0.021091   0.057325   0.144512  ...   1.880430e-07   \n",
       "7       0.496028   0.230953   0.153861   0.662475  ...   7.613927e-07   \n",
       "8       0.735562   0.304667   0.448268   2.937819  ...   2.481534e-07   \n",
       "9       0.147687   0.047606   0.059082   0.066963  ...   1.149026e-07   \n",
       "10      0.025235   0.008125   0.011721   0.057530  ...   8.873226e-09   \n",
       "11      0.780504   0.591670   1.660580   2.911524  ...   4.419341e-07   \n",
       "12      0.506981   0.694104   1.038531   0.323162  ...   1.545414e-07   \n",
       "13      0.025571   0.096179   0.254445   0.195528  ...   1.740497e-06   \n",
       "14      0.342645   0.172959   0.452002   0.835412  ...   7.040880e-07   \n",
       "15      0.957746   0.341702   0.462771   1.039223  ...   2.035750e-07   \n",
       "16      0.024643   0.010795   0.011268   0.023374  ...   4.234258e-09   \n",
       "17      0.031506   0.036740   0.068275   0.159136  ...   1.507528e-08   \n",
       "18      0.003526   0.078447   0.240319   0.136612  ...   4.260997e-06   \n",
       "19      0.035902   0.012040   0.008747   0.320155  ...   7.083501e-09   \n",
       "20      0.003668   0.018178   0.067080   0.017512  ...   2.812771e-06   \n",
       "21      0.004985   0.027709   0.112564   0.029563  ...   3.027334e-08   \n",
       "22      0.001908   0.003365   0.006845   0.079478  ...   2.637879e-08   \n",
       "23      0.000382   0.010719   0.034112   0.079155  ...   1.344014e-07   \n",
       "24      0.002177   0.009680   0.022021   0.011942  ...   2.105029e-08   \n",
       "25      0.059516   0.025327   0.047617   0.086294  ...   4.849274e-07   \n",
       "26      0.082506   0.041026   0.104378   0.170071  ...   8.608236e-07   \n",
       "27      0.116446   0.048093   0.043772   0.160457  ...   4.933069e-09   \n",
       "28      0.015935   0.016314   0.024307   0.014716  ...   5.047573e-08   \n",
       "29      0.036642   0.020188   0.035786   0.113559  ...   1.131048e-09   \n",
       "...          ...        ...        ...        ...  ...            ...   \n",
       "14347   0.007145   0.136447   0.535061   0.040195  ...   8.333016e-06   \n",
       "14348   0.004112   0.001937   0.000429   0.035571  ...   5.733073e-09   \n",
       "14349   1.433502   0.627263   0.051078   0.180540  ...   6.481285e-06   \n",
       "14350   0.035501   0.396941   1.515628   0.074940  ...   6.614217e-07   \n",
       "14351   0.034741   0.039311   0.141667   0.103247  ...   1.495975e-08   \n",
       "14352   0.022456   0.008897   0.009743   0.016196  ...   2.719222e-07   \n",
       "14353   0.051152   0.035304   0.015195   0.072922  ...   1.522014e-07   \n",
       "14354  55.403386  18.321132   7.614234  79.445069  ...   1.908863e-03   \n",
       "14355   0.375002   1.004351   1.296182   2.455899  ...   1.257494e-05   \n",
       "14356   0.002530   0.004799   0.002789   0.005552  ...   3.201667e-05   \n",
       "14357   0.879802   0.347711   0.076223   0.347116  ...   5.968472e-06   \n",
       "14358   0.045446   0.011220   0.000122   0.037684  ...   5.998882e-09   \n",
       "14359   2.464417   1.168187   0.243441   1.657603  ...   3.662810e-05   \n",
       "14360   0.471833   0.273079   0.633934   0.567348  ...   5.799831e-06   \n",
       "14361   0.001957   0.000544   0.000012   0.001626  ...   1.040348e-09   \n",
       "14362   4.139749   3.129408   3.210536  18.025169  ...   1.312733e-05   \n",
       "14363   2.647302   0.748212   0.218310  12.269286  ...   4.783034e-06   \n",
       "14364   0.070301   0.051250   0.016472   0.078240  ...   7.081522e-07   \n",
       "14365   0.113837   0.048554   0.058830   0.201704  ...   1.231296e-06   \n",
       "14366   0.001087   0.003006   0.011677   0.002384  ...   4.470341e-07   \n",
       "14367   0.028415   0.321198   1.124732   0.024001  ...   7.836133e-07   \n",
       "14368   0.008063   0.003270   0.000120   0.001400  ...   3.272927e-08   \n",
       "14369  10.532828   3.798784   0.521787  24.313602  ...   1.757948e-03   \n",
       "14370   0.277797   2.654632   7.171123   1.141819  ...   5.549289e-06   \n",
       "14371   0.903428   0.582978   0.982181   2.015356  ...   9.337588e-07   \n",
       "14372   0.063451   0.209508   0.445802   0.159335  ...   1.188572e-05   \n",
       "14373   3.295646   2.844192   4.201860   2.931795  ...   1.167841e-05   \n",
       "14374   0.079924   5.902383  21.858591   0.912929  ...   2.707697e-04   \n",
       "14375   0.311959   0.420177   1.246790   0.183939  ...   2.237936e-05   \n",
       "14376   0.003373   0.006137   0.005172   0.227837  ...   2.299989e-08   \n",
       "\n",
       "                376           377           378           379           380  \\\n",
       "0      8.007271e-08  1.469040e-07  5.716087e-08  4.747241e-08  1.260094e-07   \n",
       "1      1.698236e-06  4.119831e-06  1.952830e-06  1.430251e-06  3.696928e-06   \n",
       "2      1.252670e-07  1.241049e-09  4.750047e-07  1.188897e-07  2.952262e-10   \n",
       "3      6.414345e-09  3.142349e-09  1.838761e-08  5.118136e-09  1.856533e-09   \n",
       "4      1.275527e-07  2.207807e-07  2.799938e-07  1.247090e-07  2.171458e-07   \n",
       "5      9.553067e-08  1.080255e-07  2.877697e-07  1.000525e-07  1.113688e-07   \n",
       "6      8.306559e-08  1.399660e-07  1.844949e-07  8.061540e-08  1.367141e-07   \n",
       "7      4.421186e-07  9.562601e-07  7.586623e-07  4.333982e-07  9.592334e-07   \n",
       "8      6.659273e-08  1.477993e-08  2.351923e-07  6.167125e-08  1.103307e-08   \n",
       "9      6.032416e-08  8.157226e-08  1.054747e-07  3.268232e-08  2.015993e-08   \n",
       "10     8.094110e-09  2.198941e-08  9.839131e-09  7.605972e-09  2.023894e-08   \n",
       "11     6.561166e-07  2.167419e-06  4.312149e-07  6.326150e-07  2.085509e-06   \n",
       "12     4.287748e-07  1.147742e-06  3.636460e-08  3.347199e-07  1.251889e-06   \n",
       "13     8.414303e-06  2.668249e-05  6.295455e-07  4.518437e-06  1.706315e-05   \n",
       "14     5.533228e-07  1.496778e-06  6.939047e-07  5.326182e-07  1.428121e-06   \n",
       "15     5.371658e-08  8.937892e-09  2.085071e-07  5.441755e-08  8.753429e-09   \n",
       "16     8.007053e-09  2.428321e-08  2.790132e-09  7.317409e-09  2.596916e-08   \n",
       "17     7.074766e-09  2.833184e-09  4.976909e-09  1.897507e-09  9.485400e-10   \n",
       "18     2.559075e-06  2.580869e-06  9.169897e-07  7.052615e-07  1.817244e-06   \n",
       "19     9.065194e-09  2.537623e-08  4.270430e-09  7.199654e-09  2.400764e-08   \n",
       "20     7.099235e-07  1.412015e-08  2.629961e-06  6.602947e-07  9.192217e-09   \n",
       "21     3.471726e-07  1.144857e-06  1.170975e-08  2.077289e-07  8.058633e-07   \n",
       "22     1.569903e-08  3.462025e-08  2.635825e-08  1.461532e-08  3.166200e-08   \n",
       "23     3.707503e-08  1.070305e-08  1.402719e-07  3.769242e-08  1.009269e-08   \n",
       "24     2.431107e-08  6.409554e-08  1.210736e-08  1.761266e-08  5.677641e-08   \n",
       "25     2.838699e-07  1.926328e-07  3.224454e-07  1.091369e-07  3.468300e-08   \n",
       "26     1.702083e-06  4.895757e-06  3.776639e-07  8.748121e-07  2.958814e-06   \n",
       "27     2.308813e-09  1.936804e-09  2.929023e-09  1.188947e-09  1.580091e-09   \n",
       "28     1.560538e-08  8.453096e-09  4.310557e-08  1.181053e-08  3.805250e-09   \n",
       "29     1.784506e-08  6.809890e-08  4.208613e-10  1.658743e-08  6.529406e-08   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "14347  3.243992e-06  4.499178e-06  8.466127e-06  3.175228e-06  4.205197e-06   \n",
       "14348  2.244429e-09  1.128407e-09  6.151758e-09  1.780211e-09  6.651909e-10   \n",
       "14349  4.884009e-06  8.785078e-06  9.121999e-08  1.443675e-06  5.582559e-06   \n",
       "14350  2.413400e-07  2.870659e-07  6.444980e-07  2.283139e-07  2.650014e-07   \n",
       "14351  2.120630e-07  6.513750e-07  6.045439e-09  1.198658e-07  4.246887e-07   \n",
       "14352  6.875318e-08  1.448714e-09  2.710378e-07  6.787396e-08  1.412413e-10   \n",
       "14353  9.371090e-08  7.310662e-08  6.489082e-08  2.744596e-08  2.305730e-08   \n",
       "14354  9.395149e-04  2.557223e-04  1.830687e-04  9.921658e-05  2.234785e-05   \n",
       "14355  3.355616e-06  5.890047e-07  1.074863e-05  2.816546e-06  4.930824e-07   \n",
       "14356  3.183141e-05  8.637395e-05  2.467928e-05  2.467361e-05  7.330951e-05   \n",
       "14357  2.182546e-06  2.666472e-06  6.145162e-06  2.185480e-06  2.574719e-06   \n",
       "14358  6.501578e-08  2.152728e-07  2.390151e-09  3.754846e-08  1.413201e-07   \n",
       "14359  1.540358e-05  1.240105e-05  1.279792e-05  5.049140e-06  6.643056e-06   \n",
       "14360  1.472024e-06  4.374656e-08  5.695618e-06  1.434020e-06  3.591831e-08   \n",
       "14361  3.350157e-10  7.549448e-11  6.850765e-10  1.889840e-10  2.122283e-11   \n",
       "14362  6.915279e-06  6.432036e-06  7.289869e-06  2.605352e-06  2.948734e-06   \n",
       "14363  2.282770e-06  4.279844e-06  4.609227e-06  2.190096e-06  4.122942e-06   \n",
       "14364  3.617835e-07  1.828800e-07  1.489992e-07  7.668584e-08  7.773520e-08   \n",
       "14365  9.459574e-07  1.465031e-06  1.598711e-07  3.597592e-07  1.146428e-06   \n",
       "14366  1.763179e-06  5.779591e-06  1.808012e-07  1.065148e-06  3.993342e-06   \n",
       "14367  4.464643e-07  9.773599e-07  7.170186e-07  4.152524e-07  9.378490e-07   \n",
       "14368  2.626197e-08  6.963954e-08  3.242437e-08  2.505812e-08  6.713644e-08   \n",
       "14369  1.302356e-03  1.103665e-03  2.253473e-04  1.992420e-04  2.104496e-04   \n",
       "14370  1.954695e-06  2.003133e-06  5.060375e-06  1.722248e-06  1.779737e-06   \n",
       "14371  4.374404e-07  7.715068e-07  8.789650e-07  4.093730e-07  7.473691e-07   \n",
       "14372  4.081618e-06  4.306942e-06  1.154567e-05  3.980794e-06  4.340354e-06   \n",
       "14373  4.063589e-06  3.239738e-06  9.742676e-06  3.139210e-06  2.636924e-06   \n",
       "14374  1.653051e-04  1.035383e-04  8.666701e-05  3.062666e-05  1.622655e-05   \n",
       "14375  5.753253e-06  4.092578e-07  2.347252e-05  5.920641e-06  1.690034e-07   \n",
       "14376  2.022214e-07  7.742250e-07  1.728802e-08  1.883251e-07  7.307018e-07   \n",
       "\n",
       "                381           382           383   384  \n",
       "0      5.535224e-08  4.626970e-08  1.286249e-07   1.0  \n",
       "1      1.813380e-06  1.374210e-06  3.656530e-06   1.0  \n",
       "2      4.667286e-07  1.167180e-07  1.123269e-10   1.0  \n",
       "3      1.861613e-08  5.165185e-09  2.022390e-09   1.0  \n",
       "4      2.698613e-07  1.224099e-07  2.184646e-07   1.0  \n",
       "5      2.800855e-07  9.736914e-08  1.087308e-07   1.0  \n",
       "6      1.859606e-07  8.087657e-08  1.366626e-07   1.0  \n",
       "7      7.495555e-07  4.280706e-07  9.566685e-07   1.0  \n",
       "8      2.340248e-07  6.129494e-08  1.105369e-08   1.0  \n",
       "9      1.058438e-07  2.738747e-08  3.479259e-09   1.0  \n",
       "10     9.683474e-09  7.512008e-09  2.023259e-08   1.0  \n",
       "11     4.270607e-07  6.255225e-07  2.062435e-06   1.0  \n",
       "12     1.663899e-09  3.206607e-07  1.271232e-06   1.0  \n",
       "13     4.359339e-07  3.587775e-06  1.382303e-05   1.0  \n",
       "14     6.805540e-07  5.227933e-07  1.401864e-06   1.0  \n",
       "15     2.075633e-07  5.398494e-08  8.302371e-09   1.0  \n",
       "16     2.559721e-09  7.216346e-09  2.613287e-08   1.0  \n",
       "17     4.272376e-09  1.198435e-09  4.678388e-10   1.0  \n",
       "18     8.537278e-07  6.335056e-07  1.661535e-06   1.0  \n",
       "19     5.026639e-09  7.555402e-09  2.501359e-08   1.0  \n",
       "20     2.639494e-06  6.618533e-07  7.724439e-09   1.0  \n",
       "21     1.032746e-08  1.924879e-07  7.546390e-07   1.0  \n",
       "22     2.577407e-08  1.425104e-08  3.103153e-08   1.0  \n",
       "23     1.349994e-07  3.618721e-08  9.670727e-09   1.0  \n",
       "24     1.134438e-08  1.615979e-08  5.291235e-08   1.0  \n",
       "25     2.857067e-07  8.409190e-08  4.494995e-08   1.0  \n",
       "26     3.463804e-07  7.592745e-07  2.669592e-06   1.0  \n",
       "27     3.317613e-09  1.017266e-09  7.396135e-10   1.0  \n",
       "28     4.284273e-08  1.148417e-08  3.057263e-09   1.0  \n",
       "29     2.900683e-10  1.643445e-08  6.503863e-08   1.0  \n",
       "...             ...           ...           ...   ...  \n",
       "14347  8.025603e-06  3.055265e-06  4.168758e-06  20.0  \n",
       "14348  5.960987e-09  1.607878e-09  4.537892e-10  20.0  \n",
       "14349  1.272928e-07  1.328989e-06  5.152947e-06  20.0  \n",
       "14350  6.337901e-07  2.273948e-07  2.738032e-07  20.0  \n",
       "14351  3.126995e-09  9.960392e-08  3.896438e-07  20.0  \n",
       "14352  2.642699e-07  6.607904e-08  4.434390e-11  20.0  \n",
       "14353  4.324977e-08  1.611169e-08  1.968789e-08  20.0  \n",
       "14354  2.313409e-05  6.091703e-06  1.164844e-06  20.0  \n",
       "14355  1.065474e-05  2.782212e-06  4.698498e-07  20.0  \n",
       "14356  2.325489e-05  2.309269e-05  6.868881e-05  20.0  \n",
       "14357  6.057972e-06  2.163559e-06  2.579719e-06  20.0  \n",
       "14358  2.780166e-09  3.089986e-08  1.199358e-07  20.0  \n",
       "14359  1.123790e-05  4.139090e-06  5.267020e-06  20.0  \n",
       "14360  5.562314e-06  1.398217e-06  3.010542e-08  20.0  \n",
       "14361  6.519097e-10  1.645832e-10  5.025662e-12  20.0  \n",
       "14362  8.307214e-06  2.743288e-06  2.641762e-06  20.0  \n",
       "14363  4.599963e-06  2.187675e-06  4.124190e-06  20.0  \n",
       "14364  5.082642e-08  1.987715e-08  2.552377e-08  20.0  \n",
       "14365  4.086545e-09  2.480619e-07  9.777740e-07  20.0  \n",
       "14366  1.600962e-07  9.510717e-07  3.617224e-06  20.0  \n",
       "14367  7.120335e-07  4.113754e-07  9.275451e-07  20.0  \n",
       "14368  3.043640e-08  2.430047e-08  6.633689e-08  20.0  \n",
       "14369  8.632029e-05  4.043927e-05  7.439592e-05  20.0  \n",
       "14370  4.843320e-06  1.650915e-06  1.747690e-06  20.0  \n",
       "14371  8.616954e-07  3.976957e-07  7.241665e-07  20.0  \n",
       "14372  1.136951e-05  3.924384e-06  4.299690e-06  20.0  \n",
       "14373  8.767379e-06  2.837364e-06  2.564979e-06  20.0  \n",
       "14374  6.100269e-05  1.861265e-05  1.325093e-05  20.0  \n",
       "14375  2.367455e-05  5.956111e-06  1.468223e-07  20.0  \n",
       "14376  1.909333e-08  1.898440e-07  7.357148e-07  20.0  \n",
       "\n",
       "[14377 rows x 385 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X))\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "2.0\n",
      "[  8.20324068e-01   2.03040857e-01   2.30183462e-02   1.25008425e+00\n",
      "   2.94113841e-01   2.53973015e-02   1.75860181e+00   4.87797526e-01\n",
      "   6.10606806e-03   2.30900567e+00   5.81829912e-01   7.02938976e-03\n",
      "   4.08001072e+00   1.27814657e+00   1.07514899e+00   2.26279054e+01\n",
      "   1.24576408e+01   4.45831680e+00   1.80384436e+01   6.39611429e+01\n",
      "   6.61479133e+01   4.77462019e+01   4.10621207e+01   1.27331607e+02\n",
      "   1.21117851e+02   8.72578251e+01   8.37616252e+01   4.74825337e+01\n",
      "   3.04717516e+01   8.32852565e+00   1.48409316e+00   3.17969838e+00\n",
      "   1.12583813e+01   1.62357756e+00   2.66690325e+00   4.80824708e+00\n",
      "   2.40509575e+00   7.64794573e-01   5.79418898e-01   1.80517803e+00\n",
      "   1.08695976e+00   2.40209102e-01   1.04842490e-01   2.74640424e-01\n",
      "   1.35056492e-01   3.25606969e-02   5.07117700e-02   1.21111903e-01\n",
      "   5.00440351e-02   4.84870541e-02   5.87795762e-02   1.68248200e-01\n",
      "   7.60421876e-02   5.24329230e-02   4.09679497e-02   1.89334117e-01\n",
      "   2.99664742e-01   6.95504583e-02   2.51504389e-01   3.55797256e-01\n",
      "   1.39484596e+00   1.59882265e+00   1.35198071e+00   1.83448283e+00\n",
      "   1.83785697e+00   1.26262784e+00   1.72134701e-01   2.69556439e-01\n",
      "   1.93551259e-01   1.69539339e-02   4.09680277e-02   2.20378389e-02\n",
      "   1.86656542e-02   1.34799705e-02   4.23242691e-02   4.67306624e-03\n",
      "   2.25966502e-02   7.56862372e-02   3.15191093e-01   3.55766288e-01\n",
      "   5.49085440e-01   1.21666788e+00   1.28925433e+00   5.44677840e-01\n",
      "   4.66072659e-01   1.07902847e+00   1.02627780e+00   3.99515740e-01\n",
      "   2.10298972e-01   3.64905739e-01   1.74494766e-01   6.31700453e-02\n",
      "   2.52279253e-02   6.19831292e-02   3.14200877e-02   1.90734696e-02\n",
      "   1.39309062e-01   2.08522074e-01   3.62180991e-01   4.37208396e-01\n",
      "   1.16684025e+00   2.10805675e+00   5.75577362e-02   3.29129657e-01\n",
      "   8.74176982e-01   1.33456666e-01   7.12283560e-02   7.12815719e-02\n",
      "   1.22695728e-01   3.72399473e-01   5.10393356e-01   1.09927356e-01\n",
      "   2.78634209e-01   7.01979680e-01   5.97717874e-02   1.03302653e-01\n",
      "   2.91581683e-01   8.85952236e-02   1.08836579e-01   2.80350459e-01\n",
      "   3.73313780e-02   1.13694765e-01   2.12271514e-01   3.06161771e-01\n",
      "   7.71056843e-01   1.10104106e+00   1.40462873e+00   1.45464039e+00\n",
      "   1.58139810e+00   3.47509784e-01   1.34380000e-01   8.22829586e-02\n",
      "   4.31683596e-02   2.26228882e-02   1.40725366e-02   6.26058100e-03\n",
      "   7.76198393e-03   3.20238551e-03   3.56991543e-02   1.75515835e-02\n",
      "   3.38131609e-03   1.79373753e-02   1.06269763e-02   6.34387949e-03\n",
      "   2.06712295e-03   4.20375453e-03   4.76051892e-03   5.10196370e-03\n",
      "   2.63165294e-03   1.76272496e-03   2.15799055e-03   3.94478388e-03\n",
      "   1.11245332e-02   3.09289787e-04   4.63577303e-03   1.42541566e-02\n",
      "   9.44366908e-03   5.01032398e-03   2.79548978e-03   2.28275435e-02\n",
      "   3.73410137e-02   2.62074840e-02   1.71343794e-01   1.21261762e-01\n",
      "   3.18010720e-02   3.68171868e-02   2.43798740e-02   1.16089248e-02\n",
      "   1.35013177e-03   3.49725025e-03   9.18010399e-03   9.74114273e-04\n",
      "   7.26377064e-03   2.60449628e-02   4.68749847e-02   3.87715579e-02\n",
      "   7.38330337e-02   7.15124861e-02   1.06002578e-01   1.11020559e-01\n",
      "   2.09366262e-02   3.80504807e-02   6.42233629e-02   5.22844768e-03\n",
      "   7.91895762e-03   9.82290409e-03   1.84567913e-02   2.81836563e-02\n",
      "   3.17337164e-02   3.09470696e-01   3.99651752e-01   3.48349323e-01\n",
      "   3.30407834e-01   2.86090195e-01   2.60222671e-01   4.66560894e-02\n",
      "   7.37191805e-02   7.94451977e-02   1.00668056e-01   7.10938429e-02\n",
      "   7.06383887e-02   1.07113888e-01   7.84319457e-02   1.72758256e-02\n",
      "   1.84512808e-02   2.22249840e-02   2.21022458e-02   2.74014767e-02\n",
      "   7.42699040e-02   1.10526310e-01   3.22650481e-02   2.95802714e-02\n",
      "   3.19399087e-02   1.59206828e-02   1.11338297e-02   6.14338892e-03\n",
      "   2.35745668e-02   1.24753324e-02   1.41504602e-02   2.02989469e-01\n",
      "   1.91909493e-01   1.65181818e-01   1.38914905e-01   1.33768900e-01\n",
      "   1.43512892e-01   5.00807654e-03   4.92712656e-03   7.30688275e-03\n",
      "   2.06422451e-02   1.61455790e-02   1.72038518e-02   1.82427646e-02\n",
      "   9.73606706e-03   9.87065089e-03   2.20863694e-02   1.67084278e-02\n",
      "   1.31000131e-02   2.76667889e-02   1.91284585e-02   2.25626024e-02\n",
      "   5.72444355e-03   8.80329576e-03   1.80564549e-02   5.01236369e-02\n",
      "   6.01252357e-02   6.09461488e-02   8.39475184e-03   7.88726569e-03\n",
      "   1.36455900e-02   5.04700119e-03   2.89091698e-03   4.45400146e-03\n",
      "   1.52395666e-02   5.29536013e-03   3.13803190e-03   2.59032695e-02\n",
      "   1.69738830e-02   2.00816482e-02   2.71301340e-03   2.36896078e-03\n",
      "   3.06740517e-03   7.75965902e-03   4.46980643e-03   3.31306668e-03\n",
      "   4.31452220e-03   5.30546188e-03   1.15191370e-02   2.13803571e-02\n",
      "   2.20701775e-02   2.57833996e-02   5.45030374e-02   4.63515566e-02\n",
      "   3.82971458e-02   7.62914131e-02   7.85135559e-02   7.17545500e-02\n",
      "   2.06515881e-03   1.58261367e-03   3.30947979e-03   1.86298337e-03\n",
      "   2.73061951e-03   3.86101446e-03   1.00857476e-02   1.04226915e-02\n",
      "   8.62487051e-03   1.54088379e-03   1.29356993e-03   8.77530135e-04\n",
      "   2.74374256e-03   2.25685244e-03   1.83456174e-03   6.53805164e-03\n",
      "   4.78491228e-03   3.82339491e-03   2.12632216e-03   1.67256980e-03\n",
      "   9.10981785e-04   8.73074380e-04   4.70331865e-04   3.12552240e-04\n",
      "   1.19259712e-03   5.12994400e-04   2.31814116e-04   1.48759611e-03\n",
      "   7.38148077e-04   3.20491051e-04   5.12399700e-04   4.78386083e-04\n",
      "   3.85436748e-04   1.01187463e-03   1.14221934e-03   5.38598268e-04\n",
      "   6.31456708e-04   1.55930614e-03   2.45739136e-03   2.24663187e-04\n",
      "   4.65346891e-04   7.39006802e-04   8.64151959e-04   6.20610158e-04\n",
      "   2.81248067e-04   4.04313930e-04   3.62642299e-04   1.81062216e-04\n",
      "   1.62740725e-03   8.47092723e-04   2.38585618e-04   1.60254871e-03\n",
      "   7.65602180e-04   2.05263086e-04   1.81045414e-04   1.10588817e-04\n",
      "   5.58008380e-05   3.27771432e-05   2.15143787e-05   1.04061942e-05\n",
      "   3.14294897e-05   1.33109943e-05   4.85837369e-06   1.32170581e-03\n",
      "   8.91336527e-04   4.21595312e-04   9.65433517e-04   5.28595242e-04\n",
      "   2.03812842e-04   1.96986531e-05   1.79134324e-05   6.08425764e-06\n",
      "   1.89265754e-05   5.71195868e-06   1.00322086e-06   8.63004696e-04\n",
      "   3.41265026e-04   7.28878302e-05   5.12362191e-04   2.24829210e-04\n",
      "   7.26002169e-05   8.99060388e-06   6.50372728e-06   4.38448138e-06\n",
      "   8.52556950e-06   5.01050797e-06   4.38360180e-06   6.83565217e-05\n",
      "   5.33695109e-05   4.50588401e-05   2.31568015e-05   1.69731969e-05\n",
      "   1.52226692e-05   8.32679496e-07   5.06164081e-07   2.60455604e-07\n",
      "   1.52706511e-06   6.71248978e-07   3.05499927e-07   7.30359688e-07\n",
      "   2.83147209e-07   1.17673734e-07   3.46896464e-07   1.01444480e-07\n",
      "   3.28162433e-08   3.36694065e-07   9.50828890e-08   4.19017267e-08\n",
      "   1.00000000e+01]\n",
      "[  4.73999685e+00   1.22210545e+00   1.36760900e-01   7.50473965e+00\n",
      "   1.73252447e+00   4.20267869e-01   1.47765219e+01   4.23598820e+00\n",
      "   1.16533710e-01   2.11541471e+01   6.49558865e+00   3.09110335e-01\n",
      "   1.20093267e+01   3.72210934e+00   9.92832816e-01   3.19070520e+01\n",
      "   1.28384234e+01   2.67476374e+00   1.24024186e+02   5.72680450e+01\n",
      "   9.99472630e+00   6.98796136e+01   1.05115857e+02   2.33527202e+01\n",
      "   6.29783413e+02   3.96108894e+02   1.68455481e+02   4.04828174e+02\n",
      "   1.30320724e+02   8.71380649e+00   5.55461106e+01   3.69925796e+01\n",
      "   1.90171060e+00   6.22947263e+00   8.16825926e+00   4.75963322e+00\n",
      "   1.46789079e+00   2.01555138e+00   6.11610344e-01   1.64645269e+00\n",
      "   3.58680895e+00   3.37255380e+00   2.27036779e+00   4.88929573e+00\n",
      "   3.32834623e+00   4.14150609e+00   3.31817627e+00   9.66484996e-01\n",
      "   1.73618215e+00   1.52344936e+00   6.58622471e-02   8.05324456e-01\n",
      "   3.12421577e+00   4.06396123e+00   3.47266973e+00   2.91939840e+00\n",
      "   1.49940006e+00   5.50996590e+00   1.90707492e+00   2.40091422e-01\n",
      "   2.35379799e+00   5.91644919e-01   3.34177397e-01   2.96422415e+00\n",
      "   1.12498472e+00   1.70709594e-01   2.10212453e+00   1.32967553e+00\n",
      "   3.63553175e-01   3.84274088e+00   3.95884133e+00   2.34817689e+00\n",
      "   4.26732602e+00   5.19624519e+00   1.56343319e+00   1.35631131e+00\n",
      "   1.43662474e+00   1.25493138e+00   3.22393938e+00   9.35614179e-01\n",
      "   4.31691981e-01   7.78581487e+00   2.38283085e+00   2.77369978e+00\n",
      "   4.62454020e+01   2.41409098e+01   7.87517730e+00   3.55036707e+01\n",
      "   6.90514339e+01   6.13733296e+01   2.49961324e+01   2.94060144e+01\n",
      "   3.78212271e+01   1.43120103e+01   5.09571056e+00   2.59593831e+00\n",
      "   1.65817916e+00   5.57242541e-01   7.69686474e-01   4.20842100e-01\n",
      "   1.63931623e-01   2.57383636e-01   2.97936399e-01   1.91080604e-01\n",
      "   4.49208991e-01   4.79971396e-01   4.89312597e-01   1.38985345e+00\n",
      "   1.74344535e+00   1.10896447e+00   1.24785423e+00   1.68688022e+00\n",
      "   4.89269258e-01   1.36215811e-01   3.79132969e-01   1.52991201e-01\n",
      "   7.97207802e-02   6.24096557e-02   8.37119127e-02   2.03268104e-01\n",
      "   1.16849140e-01   9.45481188e-02   2.70564317e-01   1.65090412e-01\n",
      "   4.32804707e-01   1.08413300e+00   1.39528543e-01   4.96062855e-01\n",
      "   7.39429226e-01   4.73539501e-01   5.88896357e-01   5.60509850e-01\n",
      "   9.82646312e-02   2.35030153e-01   3.51393625e-01   4.25442201e-02\n",
      "   6.33981913e-02   8.60527691e-02   6.25544764e-02   1.40317041e-01\n",
      "   2.21002751e-01   5.18840398e-01   2.78069580e-01   2.96897913e-01\n",
      "   4.57989402e-01   2.17518561e-01   8.05599170e-02   1.14814725e-01\n",
      "   3.97057962e-02   2.28555608e-02   7.89872550e-01   1.21653187e+00\n",
      "   1.34252062e+00   1.89421908e+00   1.62289313e+00   9.12966218e-01\n",
      "   1.78976083e-01   1.58263260e-01   2.99241759e-01   1.30577033e-01\n",
      "   2.15362743e-01   5.48527821e-01   1.65408997e-01   1.88343914e-01\n",
      "   2.96327027e-01   1.51901171e-01   1.15826657e-01   5.30633275e-02\n",
      "   3.17471444e-01   3.92371330e-01   3.76949665e-01   2.76380617e-01\n",
      "   4.33768221e-01   2.74090941e-01   9.89882795e-02   1.12590982e-01\n",
      "   1.42589862e-01   2.35873144e-01   1.01883188e-01   2.93326114e-02\n",
      "   2.87210465e+00   1.56277947e+00   5.58023911e-01   4.32022396e-01\n",
      "   3.00669106e-01   2.17475057e-01   1.35230765e-01   7.57366877e-02\n",
      "   4.97562504e-02   8.62585441e-01   9.98360843e-01   9.53709026e-01\n",
      "   7.22661634e-01   8.12482676e-01   7.36301869e-01   3.42999786e-01\n",
      "   4.74848680e-01   5.14411036e-01   1.43247367e+00   1.26683691e+00\n",
      "   1.33771700e+00   6.47990574e-01   3.49140315e-01   3.24134469e-01\n",
      "   2.52347211e-02   3.89783066e-02   9.38843760e-02   5.11474389e-01\n",
      "   2.82857585e-01   2.28263464e-01   4.41489295e-01   1.89542047e-01\n",
      "   9.92300141e-02   2.00460278e-02   1.14770566e-02   1.73657755e-02\n",
      "   3.79835006e-02   5.59986641e-02   4.84579405e-02   3.23006870e-02\n",
      "   4.33053680e-02   3.93139496e-02   1.63934443e-01   8.57112137e-02\n",
      "   3.44112059e-02   1.12601548e-01   9.40270414e-02   4.95588378e-02\n",
      "   1.74508954e-01   1.87879707e-01   1.62175763e-01   9.80204661e-02\n",
      "   6.32861739e-02   4.80552921e-02   1.78882127e-01   6.83617386e-02\n",
      "   1.00187711e-02   1.98359319e-01   1.58273143e-01   8.47339096e-02\n",
      "   1.38151372e-01   1.17820521e-01   6.34994546e-02   1.59824616e-02\n",
      "   2.07840052e-02   1.75491824e-02   6.83251977e-03   5.73449034e-03\n",
      "   9.51466022e-03   1.04896832e-02   5.97461949e-03   3.59333402e-03\n",
      "   3.04339662e-03   4.47604325e-03   1.03181790e-02   1.73416033e-01\n",
      "   1.94473922e-01   1.43956826e-01   6.67814914e-02   8.14360655e-02\n",
      "   6.04855630e-02   1.57523283e-02   1.79064299e-02   2.05233223e-02\n",
      "   4.41244484e-02   3.54876233e-02   3.25430795e-02   5.51557284e-03\n",
      "   8.61103839e-03   1.61965055e-02   5.78789225e-02   5.33322120e-02\n",
      "   4.41608915e-02   1.69333063e-02   1.16137157e-02   1.26911705e-02\n",
      "   2.38389670e-03   4.46971982e-03   6.10857476e-03   2.21685120e-03\n",
      "   2.31507688e-03   2.80228991e-03   3.16713156e-03   2.71621672e-03\n",
      "   2.69977160e-03   3.93568110e-03   2.00887219e-03   1.15541802e-03\n",
      "   2.65090715e-03   4.15238592e-03   4.20161175e-03   1.89077397e-03\n",
      "   2.86412656e-03   2.80862089e-03   1.80437957e-03   2.07098105e-03\n",
      "   3.37117196e-03   1.95118515e-03   1.30289723e-03   1.31358253e-03\n",
      "   1.26960015e-03   8.01752089e-04   5.61610259e-04   1.32106100e-03\n",
      "   5.98187588e-04   2.66875334e-04   6.70306326e-04   6.15750655e-04\n",
      "   6.14926192e-04   1.32804114e-03   8.63562240e-04   4.52001658e-04\n",
      "   1.27632338e-03   9.56000951e-04   6.05991398e-04   9.10718313e-04\n",
      "   6.42936411e-04   2.86541944e-04   2.24057745e-04   1.66598695e-04\n",
      "   1.37923141e-04   5.47603961e-04   3.32711949e-04   2.05162902e-04\n",
      "   4.62015892e-04   2.74571796e-04   1.38280972e-04   1.01061991e-03\n",
      "   3.71731972e-04   1.09704038e-04   1.71418195e-04   1.41022172e-04\n",
      "   9.25054055e-05   9.81123230e-05   5.86313659e-05   2.06706129e-05\n",
      "   8.75103136e-05   5.85399671e-05   2.90457677e-05   1.00604570e-04\n",
      "   4.80565587e-05   2.38412403e-05   1.00027249e-04   4.16872033e-05\n",
      "   1.45706019e-05   3.28541027e-05   1.78992313e-05   5.73455501e-06\n",
      "   5.45948630e-05   3.68168021e-05   1.67857218e-05   4.99954307e-05\n",
      "   2.27611398e-05   6.85175159e-06   2.51882198e-05   1.07871468e-05\n",
      "   5.43663563e-06   3.89420022e-05   1.77004365e-05   6.77285129e-06\n",
      "   3.89746595e-05   1.87244070e-05   6.65127149e-06   1.62458183e-05\n",
      "   6.53205594e-06   2.18199020e-06   2.07950239e-05   6.52307795e-06\n",
      "   1.68305238e-06   1.29757771e-05   4.43726427e-06   1.73815434e-06\n",
      "   1.59597362e-05   4.61752302e-06   1.47463119e-06   6.95597534e-06\n",
      "   2.07840023e-06   1.24352763e-06   6.68786319e-06   1.99775866e-06\n",
      "   1.28189650e-06   6.36902136e-06   1.91173636e-06   1.26925400e-06]\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "npArrayDF = np.array(df_new.iloc[:,:], dtype=np.float) #shuffle randomly all samples\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "\n",
    "for i in range(len(npArrayDF)):\n",
    "    npArrayDF[i,-1] = (npArrayDF[i, -1]) - 1\n",
    "\n",
    "print(npArrayDF[0,-1])\n",
    "    \n",
    "np.random.shuffle(npArrayDF)\n",
    "\n",
    "X_train = np.array(npArrayDF[:-2000,:-1], dtype=np.float)\n",
    "y_train = np.array(npArrayDF[:-2000,-1], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(npArrayDF[-2000:-1000,:-1], dtype=np.float)\n",
    "y_valid = np.array(npArrayDF[-2000:-1000,-1], dtype=np.float)\n",
    "\n",
    "X_test = np.array(npArrayDF[-1000:,:-1], dtype=np.float)\n",
    "y_test = np.array(npArrayDF[-1000:,-1], dtype=np.float)\n",
    "print(y_test[1])\n",
    "\n",
    "\n",
    "sample = np.array(df_new.iloc[500,:], dtype=np.float)\n",
    "print(sample)\n",
    "print(X_train[1000])\n",
    "print(y_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "\n",
    "        # extra ops for batch normalization\n",
    "        extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(self.predict_proba(X))\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        print(class_indices)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)\n",
    "\n",
    "    def restore(self, path, X, y):\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        \n",
    "        self._saver.restore(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.897435\tBest loss: 3.897435\tAccuracy: 42.70%\n",
      "1\tValidation loss: 2.624314\tBest loss: 2.624314\tAccuracy: 57.60%\n",
      "2\tValidation loss: 2.055875\tBest loss: 2.055875\tAccuracy: 61.50%\n",
      "3\tValidation loss: 1.919876\tBest loss: 1.919876\tAccuracy: 62.70%\n",
      "4\tValidation loss: 1.748545\tBest loss: 1.748545\tAccuracy: 64.50%\n",
      "5\tValidation loss: 1.795230\tBest loss: 1.748545\tAccuracy: 64.50%\n",
      "6\tValidation loss: 1.447611\tBest loss: 1.447611\tAccuracy: 69.20%\n",
      "7\tValidation loss: 1.657186\tBest loss: 1.447611\tAccuracy: 65.30%\n",
      "8\tValidation loss: 1.499415\tBest loss: 1.447611\tAccuracy: 69.60%\n",
      "9\tValidation loss: 1.452429\tBest loss: 1.447611\tAccuracy: 68.40%\n",
      "10\tValidation loss: 1.323780\tBest loss: 1.323780\tAccuracy: 70.70%\n",
      "11\tValidation loss: 1.370003\tBest loss: 1.323780\tAccuracy: 69.20%\n",
      "12\tValidation loss: 1.335146\tBest loss: 1.323780\tAccuracy: 70.20%\n",
      "13\tValidation loss: 1.315700\tBest loss: 1.315700\tAccuracy: 71.20%\n",
      "14\tValidation loss: 1.279361\tBest loss: 1.279361\tAccuracy: 72.00%\n",
      "15\tValidation loss: 1.243665\tBest loss: 1.243665\tAccuracy: 69.80%\n",
      "16\tValidation loss: 1.288046\tBest loss: 1.243665\tAccuracy: 72.20%\n",
      "17\tValidation loss: 1.228326\tBest loss: 1.228326\tAccuracy: 72.50%\n",
      "18\tValidation loss: 1.208020\tBest loss: 1.208020\tAccuracy: 73.30%\n",
      "19\tValidation loss: 1.203129\tBest loss: 1.203129\tAccuracy: 72.90%\n",
      "20\tValidation loss: 1.184249\tBest loss: 1.184249\tAccuracy: 73.00%\n",
      "21\tValidation loss: 1.157329\tBest loss: 1.157329\tAccuracy: 74.10%\n",
      "22\tValidation loss: 1.226022\tBest loss: 1.157329\tAccuracy: 73.50%\n",
      "23\tValidation loss: 1.168766\tBest loss: 1.157329\tAccuracy: 73.50%\n",
      "24\tValidation loss: 1.167578\tBest loss: 1.157329\tAccuracy: 73.30%\n",
      "25\tValidation loss: 1.155591\tBest loss: 1.155591\tAccuracy: 73.80%\n",
      "26\tValidation loss: 1.137126\tBest loss: 1.137126\tAccuracy: 74.60%\n",
      "27\tValidation loss: 1.165975\tBest loss: 1.137126\tAccuracy: 74.20%\n",
      "28\tValidation loss: 1.131453\tBest loss: 1.131453\tAccuracy: 75.10%\n",
      "29\tValidation loss: 1.103834\tBest loss: 1.103834\tAccuracy: 74.80%\n",
      "30\tValidation loss: 1.569276\tBest loss: 1.103834\tAccuracy: 70.60%\n",
      "31\tValidation loss: 1.105519\tBest loss: 1.103834\tAccuracy: 74.30%\n",
      "32\tValidation loss: 1.138173\tBest loss: 1.103834\tAccuracy: 75.70%\n",
      "33\tValidation loss: 1.112710\tBest loss: 1.103834\tAccuracy: 74.20%\n",
      "34\tValidation loss: 1.088971\tBest loss: 1.088971\tAccuracy: 75.50%\n",
      "35\tValidation loss: 1.168267\tBest loss: 1.088971\tAccuracy: 74.10%\n",
      "36\tValidation loss: 1.106729\tBest loss: 1.088971\tAccuracy: 74.90%\n",
      "37\tValidation loss: 1.128688\tBest loss: 1.088971\tAccuracy: 75.20%\n",
      "38\tValidation loss: 1.122219\tBest loss: 1.088971\tAccuracy: 75.10%\n",
      "39\tValidation loss: 1.115693\tBest loss: 1.088971\tAccuracy: 75.00%\n",
      "40\tValidation loss: 1.127109\tBest loss: 1.088971\tAccuracy: 75.00%\n",
      "41\tValidation loss: 1.088455\tBest loss: 1.088455\tAccuracy: 76.50%\n",
      "42\tValidation loss: 1.110242\tBest loss: 1.088455\tAccuracy: 74.40%\n",
      "43\tValidation loss: 1.109199\tBest loss: 1.088455\tAccuracy: 74.90%\n",
      "44\tValidation loss: 1.132727\tBest loss: 1.088455\tAccuracy: 75.40%\n",
      "45\tValidation loss: 1.197121\tBest loss: 1.088455\tAccuracy: 73.80%\n",
      "46\tValidation loss: 1.068227\tBest loss: 1.068227\tAccuracy: 75.90%\n",
      "47\tValidation loss: 1.098059\tBest loss: 1.068227\tAccuracy: 75.00%\n",
      "48\tValidation loss: 1.139932\tBest loss: 1.068227\tAccuracy: 75.00%\n",
      "49\tValidation loss: 1.097540\tBest loss: 1.068227\tAccuracy: 75.50%\n",
      "50\tValidation loss: 1.071675\tBest loss: 1.068227\tAccuracy: 75.20%\n",
      "51\tValidation loss: 1.117666\tBest loss: 1.068227\tAccuracy: 75.80%\n",
      "52\tValidation loss: 1.097345\tBest loss: 1.068227\tAccuracy: 75.70%\n",
      "53\tValidation loss: 1.160633\tBest loss: 1.068227\tAccuracy: 73.50%\n",
      "54\tValidation loss: 1.054607\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "55\tValidation loss: 1.086254\tBest loss: 1.054607\tAccuracy: 76.30%\n",
      "56\tValidation loss: 1.116948\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "57\tValidation loss: 1.080879\tBest loss: 1.054607\tAccuracy: 76.10%\n",
      "58\tValidation loss: 1.081243\tBest loss: 1.054607\tAccuracy: 75.40%\n",
      "59\tValidation loss: 1.080930\tBest loss: 1.054607\tAccuracy: 74.90%\n",
      "60\tValidation loss: 1.095811\tBest loss: 1.054607\tAccuracy: 75.80%\n",
      "61\tValidation loss: 1.099062\tBest loss: 1.054607\tAccuracy: 75.20%\n",
      "62\tValidation loss: 1.106622\tBest loss: 1.054607\tAccuracy: 75.10%\n",
      "63\tValidation loss: 1.117877\tBest loss: 1.054607\tAccuracy: 75.00%\n",
      "64\tValidation loss: 1.074409\tBest loss: 1.054607\tAccuracy: 75.70%\n",
      "65\tValidation loss: 1.062973\tBest loss: 1.054607\tAccuracy: 77.00%\n",
      "66\tValidation loss: 1.077024\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "67\tValidation loss: 1.098863\tBest loss: 1.054607\tAccuracy: 76.30%\n",
      "68\tValidation loss: 1.117361\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "69\tValidation loss: 1.079637\tBest loss: 1.054607\tAccuracy: 75.60%\n",
      "70\tValidation loss: 1.083755\tBest loss: 1.054607\tAccuracy: 76.40%\n",
      "71\tValidation loss: 1.080464\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "72\tValidation loss: 1.072969\tBest loss: 1.054607\tAccuracy: 76.70%\n",
      "73\tValidation loss: 1.081960\tBest loss: 1.054607\tAccuracy: 75.90%\n",
      "74\tValidation loss: 1.051635\tBest loss: 1.051635\tAccuracy: 77.20%\n",
      "75\tValidation loss: 1.093030\tBest loss: 1.051635\tAccuracy: 76.20%\n",
      "76\tValidation loss: 1.053134\tBest loss: 1.051635\tAccuracy: 77.20%\n",
      "77\tValidation loss: 1.078005\tBest loss: 1.051635\tAccuracy: 76.30%\n",
      "78\tValidation loss: 1.073168\tBest loss: 1.051635\tAccuracy: 76.90%\n",
      "79\tValidation loss: 1.094254\tBest loss: 1.051635\tAccuracy: 76.00%\n",
      "80\tValidation loss: 1.082386\tBest loss: 1.051635\tAccuracy: 77.00%\n",
      "81\tValidation loss: 1.095157\tBest loss: 1.051635\tAccuracy: 77.00%\n",
      "82\tValidation loss: 1.097233\tBest loss: 1.051635\tAccuracy: 75.80%\n",
      "83\tValidation loss: 1.114578\tBest loss: 1.051635\tAccuracy: 76.70%\n",
      "84\tValidation loss: 1.117499\tBest loss: 1.051635\tAccuracy: 76.00%\n",
      "85\tValidation loss: 1.075355\tBest loss: 1.051635\tAccuracy: 76.00%\n",
      "86\tValidation loss: 1.066180\tBest loss: 1.051635\tAccuracy: 76.90%\n",
      "87\tValidation loss: 1.148278\tBest loss: 1.051635\tAccuracy: 75.60%\n",
      "88\tValidation loss: 1.083167\tBest loss: 1.051635\tAccuracy: 76.80%\n",
      "89\tValidation loss: 1.068063\tBest loss: 1.051635\tAccuracy: 76.80%\n",
      "90\tValidation loss: 1.056516\tBest loss: 1.051635\tAccuracy: 76.90%\n",
      "91\tValidation loss: 1.076722\tBest loss: 1.051635\tAccuracy: 76.90%\n",
      "92\tValidation loss: 1.066246\tBest loss: 1.051635\tAccuracy: 76.20%\n",
      "93\tValidation loss: 1.078257\tBest loss: 1.051635\tAccuracy: 76.30%\n",
      "94\tValidation loss: 1.100184\tBest loss: 1.051635\tAccuracy: 77.10%\n",
      "95\tValidation loss: 1.085012\tBest loss: 1.051635\tAccuracy: 76.70%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x000002EE6B234268>,\n",
       "       batch_norm_momentum=None, batch_size=30, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x000002EE0F424400>,\n",
       "       learning_rate=0.1, n_hidden_layers=0, n_neurons=50,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>,\n",
       "       random_state=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = DNNClassifier(batch_size=30, learning_rate=0.1, \n",
    "                    n_hidden_layers=0, n_neurons=50, \n",
    "                    optimizer_class=tf.train.AdagradOptimizer)\n",
    "\n",
    "dnn.fit(X=X_train, y=y_train, X_valid=X_valid, y_valid=y_valid)\n",
    "#dnn.save(\"final_model_test/final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.37152051e-12   1.43376019e-10   9.64112991e-12 ...,   5.39863781e-13\n",
      "    1.30707130e-20   3.86426224e-10]\n",
      " [  1.26474928e-02   4.92718609e-05   3.18927497e-01 ...,   4.80713481e-07\n",
      "    6.85301318e-04   5.04521222e-06]\n",
      " [  1.70156751e-02   2.02009697e-02   5.17719164e-02 ...,   2.83633926e-06\n",
      "    5.63017329e-06   7.27319775e-06]\n",
      " ..., \n",
      " [  1.07038592e-03   1.69957168e-02   5.57763095e-04 ...,   1.47690075e-02\n",
      "    5.93942377e-06   3.31580755e-03]\n",
      " [  2.43170932e-02   2.76044803e-03   2.62973215e-02 ...,   2.27387785e-03\n",
      "    8.26777832e-04   6.40894214e-05]\n",
      " [  2.52600133e-12   1.22823571e-10   1.32048794e-09 ...,   1.84391829e-04\n",
      "    5.56361338e-04   2.04795724e-04]]\n",
      "[38 39 11 34  1 19 16 40 11 16  1  8 35  9  9 17 16 12 45 19 16 16 27 28 19\n",
      " 44 38  2 39 18 40 29 35 38  6 24 45 10 18 19  1 20 22  0  5 12 30 39  3 13\n",
      " 29 16 23 25 16 34 39  8 11 29 17  4 38 11  8  3  3 22 39  3 15 47 18  0 20\n",
      "  5 17 16 38 19 18 11 26 23  5 28 45 28 29 47 24  0 13 39  4 38  6 23 37  6\n",
      " 16  8 18  8 37 34  9 25 44 17  5 47 38  8 18 42 44  6  9  1 10 13  8 27 17\n",
      "  2  0 17 39  7 34  6  6 37  4 45 24  3 10  1 27 13 17  0 38  1 45 44 32 16\n",
      " 28  2 22  3  2 35  8 15 21 39 16 36 17  3  5  1 17 31  3 38 10 34 28  0 44\n",
      " 43 28 36  2 12 13 44  2 35 35 36 25 17 13 26 28  8 18 19  3 17 26 24  0 24\n",
      " 26 13 15 47 14  9 45 11  5 15 18 16 31 35 28  5 37 44 20 20  9 35 39 33 25\n",
      " 18 37 28 16 19 44 47 17 18 45 26 43 14 47 47 26 18 36 26  7 38  3 13 35 36\n",
      " 34 13 30 38 37 28  9  7 17 36 33 34 26 15 44 20 15 10 23  9  3 21  1 17 37\n",
      " 34 30 42 23 13 12 30 41 16  9 12 13 45 47 39 16 45 34 18 18 36 11 36 16 10\n",
      " 38 22 37 17 16 20 29 17  9 18  1  8  7  5 28 16 41  4 41 12 29 17  8 17 32\n",
      " 29 28  9 18 33 43 16  0 25 24 25 23 27 34  8 26 15 36  5 44 19 14  2 26 24\n",
      " 20  6 17  8  3  7 34  3 30 45 26  6  2 15 39 29 20 36 36 27  8 15  2  1 15\n",
      " 16  6 28  3 23  7 32 13 32 44  4 25 18 24 43 43 19 35 41  9 36 28 39 36 27\n",
      " 26 34  8 14 40 29 45  5  4 15 44 10  1 20  8 26 16  8 18  0 46 11 16 28  8\n",
      " 16  9 10 21 47 40 17 17 44 18  8 46 15 10 19 37 10  8 38 25 16  7 29 35 44\n",
      " 31 23 44 18 37 35 36 37 46 18 46  8 41 16 16 23 45 13  2 18 11 23  3 18 17\n",
      "  2 20 36 46 11 38 38 22 30 37 41  0 16 38  3  2 21 16 32 26  5  8 19 15 18\n",
      " 19 38 19 40 27 10  9  8 30 46 17  0  8  9 12  7  2 14 36 28  3 45  1  6 32\n",
      " 20 19  4 34 31 38 36 26  2 19 27 37 30 37 12 14 15 37 19 16  9 27  6 28 13\n",
      " 38 12  8 38 14 35 35 23 45  3 28 15 46 46 24 10 24 37 43  1 43 17 36 10 36\n",
      " 24  1 37 23 34 40 27 37 16 20 12 10 24 24 37 18  2 13 20  0 28 26  2 16 23\n",
      " 21 33 24 16  8 43  9 42 17 19 23 21 26  8 14 16 40 11  5  1 33 18 42  6 20\n",
      " 16  0 23 16 11 13 28 45 28  2 47 36 25 16  0  8  2 30  8 41 41 29 33  5  5\n",
      "  0 16 39 37 10  0 15 36 24  2 29 30  9 23 38 37 11 26 45 25 16  3 36 15  2\n",
      " 17 45  5 37  3 26 10 35  1 16  1 24 38 16 17  4  1 25 18 11  0 14 37  0 14\n",
      "  9 26 41  0 17 19  1 41 39 10 13 20 37 42 17  4 17 18 13 25 24  0  8 44  9\n",
      "  9  6 39 14  6  9 17 46  8 23 32 47 16 18 30 19 45 14 27 20 45 23 26 37 39\n",
      " 10 46 36  7 11 10 10 16  8 26 35 12  2 22 13 10 40 24  1 30 33  3 17 45 18\n",
      " 36 22  9  5  8  7 36 20 17 15 18  1 17 21  4 28 39 14  9 28 41 22 23  4 18\n",
      " 38 22 33 47 20 19 40 20 27 41  4 16 20 18 17 16 30 45  1  7 28  3 16 28  8\n",
      "  5 19  2 40 40  9 38 11 19  3 16 24 43 44  1 19  3  8 28 16 17  6 37 18 16\n",
      " 21 16 37 25 12  8 14  8  5 17 44 16 38 26 18 30 28 45 13 11 23  8 36 16 21\n",
      " 10 34 24 29 24 21  3 37 45  8 25 17 17 28 15 18 37  1 17 25 17  2 39 18 12\n",
      " 23  3 43 18 34 19 17 36  1 17  1  3  2 22 28  9  7 18 17 36 19 33  9 19 23\n",
      " 20 35  5  0 29 28  8 16 25  6 27 17 41 16 17  1 16 22 19 47 36 28 20 10 37\n",
      "  5 47 21 20 44 21  7 16 12 37 14 36 28 27  1 25 25  3 37 14  6 23  0 16  6\n",
      " 31 45 30 16 36 37  7  8 18  7 25  6 11 35 45 12 28 30 11  8 46 29 41 16 35]\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "y_pred = dnn.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.635360\tBest loss: 3.635360\tAccuracy: 16.00%\n",
      "1\tValidation loss: 5.435406\tBest loss: 3.635360\tAccuracy: 16.50%\n",
      "2\tValidation loss: 3.075383\tBest loss: 3.075383\tAccuracy: 30.20%\n",
      "3\tValidation loss: 2.911063\tBest loss: 2.911063\tAccuracy: 35.30%\n",
      "4\tValidation loss: 3.193672\tBest loss: 2.911063\tAccuracy: 34.80%\n",
      "5\tValidation loss: 2.695427\tBest loss: 2.695427\tAccuracy: 43.30%\n",
      "6\tValidation loss: 2.197079\tBest loss: 2.197079\tAccuracy: 51.90%\n",
      "7\tValidation loss: 3.221321\tBest loss: 2.197079\tAccuracy: 45.40%\n",
      "8\tValidation loss: 6.935084\tBest loss: 2.197079\tAccuracy: 36.90%\n",
      "9\tValidation loss: 3.801899\tBest loss: 2.197079\tAccuracy: 39.30%\n",
      "10\tValidation loss: 2.839691\tBest loss: 2.197079\tAccuracy: 49.30%\n",
      "11\tValidation loss: 4.527198\tBest loss: 2.197079\tAccuracy: 44.50%\n",
      "12\tValidation loss: 4.688673\tBest loss: 2.197079\tAccuracy: 42.20%\n",
      "13\tValidation loss: 8.908468\tBest loss: 2.197079\tAccuracy: 38.90%\n",
      "14\tValidation loss: 3.057187\tBest loss: 2.197079\tAccuracy: 59.50%\n",
      "15\tValidation loss: 3.920623\tBest loss: 2.197079\tAccuracy: 53.80%\n",
      "16\tValidation loss: 6.750630\tBest loss: 2.197079\tAccuracy: 44.60%\n",
      "17\tValidation loss: 2.354731\tBest loss: 2.197079\tAccuracy: 63.50%\n",
      "18\tValidation loss: 4.272944\tBest loss: 2.197079\tAccuracy: 58.10%\n",
      "19\tValidation loss: 3.901248\tBest loss: 2.197079\tAccuracy: 55.90%\n",
      "20\tValidation loss: 5.148270\tBest loss: 2.197079\tAccuracy: 57.00%\n",
      "21\tValidation loss: 3.972871\tBest loss: 2.197079\tAccuracy: 60.10%\n",
      "22\tValidation loss: 3.501765\tBest loss: 2.197079\tAccuracy: 61.60%\n",
      "23\tValidation loss: 5.024484\tBest loss: 2.197079\tAccuracy: 55.70%\n",
      "24\tValidation loss: 5.175329\tBest loss: 2.197079\tAccuracy: 58.30%\n",
      "25\tValidation loss: 5.828555\tBest loss: 2.197079\tAccuracy: 57.40%\n",
      "26\tValidation loss: 3.137994\tBest loss: 2.197079\tAccuracy: 65.30%\n",
      "27\tValidation loss: 4.691973\tBest loss: 2.197079\tAccuracy: 60.80%\n",
      "Early stopping!\n",
      "[[  3.91400671e-12   1.47163810e-08   1.34639556e-11 ...,   1.83533003e-15\n",
      "    3.63995813e-11   2.44185943e-12]\n",
      " [  3.52720506e-02   1.64731871e-02   1.33645618e-02 ...,   2.06923834e-03\n",
      "    7.27411825e-04   8.32617225e-04]\n",
      " [  1.08044813e-20   1.50933251e-31   9.11410958e-17 ...,   3.11708699e-23\n",
      "    2.11120609e-28   2.24604277e-32]\n",
      " ..., \n",
      " [  5.50782937e-14   7.19825755e-09   2.01693905e-11 ...,   1.05647416e-06\n",
      "    9.13585420e-04   1.08856533e-04]\n",
      " [  1.81209494e-03   1.80361758e-03   1.59001793e-04 ...,   3.53609413e-01\n",
      "    2.61266157e-02   4.28137816e-02]\n",
      " [  6.77242540e-10   2.54753729e-07   3.73489184e-10 ...,   6.61985996e-06\n",
      "    3.12155571e-05   1.22736295e-04]]\n",
      "[22 19 18 ..., 30 45 25]\n",
      "[[  9.15429609e-06   6.11719850e-04   1.26076120e-04 ...,   1.98167181e-05\n",
      "    6.74345647e-04   1.06674852e-03]\n",
      " [  2.93724193e-24   4.45376647e-16   3.32892928e-23 ...,   2.96375980e-31\n",
      "    1.23977072e-23   1.81457383e-23]\n",
      " [  1.66414022e-14   2.06575890e-09   2.99351337e-14 ...,   4.86995081e-16\n",
      "    2.62832545e-15   8.60271598e-13]\n",
      " ..., \n",
      " [  2.85802049e-20   9.07389149e-23   2.75253664e-22 ...,   3.75325619e-29\n",
      "    3.88169288e-25   8.74911455e-29]\n",
      " [  7.23062502e-03   1.74026459e-03   9.30973608e-03 ...,   2.58360314e-03\n",
      "    6.91545242e-03   1.15109542e-02]\n",
      " [  5.72584867e-24   3.43584939e-16   2.79853658e-19 ...,   2.69746234e-08\n",
      "    8.60820466e-04   9.01693106e-01]]\n",
      "[38 43 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 9.465643\tBest loss: 9.465643\tAccuracy: 9.80%\n",
      "1\tValidation loss: 4.108774\tBest loss: 4.108774\tAccuracy: 17.00%\n",
      "2\tValidation loss: 6.787231\tBest loss: 4.108774\tAccuracy: 17.00%\n",
      "3\tValidation loss: 3.095853\tBest loss: 3.095853\tAccuracy: 29.60%\n",
      "4\tValidation loss: 2.725876\tBest loss: 2.725876\tAccuracy: 40.80%\n",
      "5\tValidation loss: 2.976552\tBest loss: 2.725876\tAccuracy: 41.30%\n",
      "6\tValidation loss: 2.548136\tBest loss: 2.548136\tAccuracy: 49.20%\n",
      "7\tValidation loss: 4.104527\tBest loss: 2.548136\tAccuracy: 42.30%\n",
      "8\tValidation loss: 4.549697\tBest loss: 2.548136\tAccuracy: 37.20%\n",
      "9\tValidation loss: 2.450650\tBest loss: 2.450650\tAccuracy: 51.50%\n",
      "10\tValidation loss: 4.307481\tBest loss: 2.450650\tAccuracy: 45.10%\n",
      "11\tValidation loss: 3.922428\tBest loss: 2.450650\tAccuracy: 49.00%\n",
      "12\tValidation loss: 10.344541\tBest loss: 2.450650\tAccuracy: 37.80%\n",
      "13\tValidation loss: 3.801137\tBest loss: 2.450650\tAccuracy: 49.30%\n",
      "14\tValidation loss: 3.378881\tBest loss: 2.450650\tAccuracy: 54.70%\n",
      "15\tValidation loss: 2.388738\tBest loss: 2.388738\tAccuracy: 60.70%\n",
      "16\tValidation loss: 2.407067\tBest loss: 2.388738\tAccuracy: 60.80%\n",
      "17\tValidation loss: 4.086521\tBest loss: 2.388738\tAccuracy: 59.70%\n",
      "18\tValidation loss: 3.812675\tBest loss: 2.388738\tAccuracy: 57.10%\n",
      "19\tValidation loss: 3.107652\tBest loss: 2.388738\tAccuracy: 55.20%\n",
      "20\tValidation loss: 3.475844\tBest loss: 2.388738\tAccuracy: 59.10%\n",
      "21\tValidation loss: 3.285738\tBest loss: 2.388738\tAccuracy: 61.20%\n",
      "22\tValidation loss: 3.697943\tBest loss: 2.388738\tAccuracy: 58.90%\n",
      "23\tValidation loss: 4.586731\tBest loss: 2.388738\tAccuracy: 55.60%\n",
      "24\tValidation loss: 2.612950\tBest loss: 2.388738\tAccuracy: 64.00%\n",
      "25\tValidation loss: 3.203556\tBest loss: 2.388738\tAccuracy: 60.60%\n",
      "26\tValidation loss: 3.217531\tBest loss: 2.388738\tAccuracy: 64.20%\n",
      "27\tValidation loss: 3.828804\tBest loss: 2.388738\tAccuracy: 64.80%\n",
      "28\tValidation loss: 4.780349\tBest loss: 2.388738\tAccuracy: 61.20%\n",
      "29\tValidation loss: 4.547945\tBest loss: 2.388738\tAccuracy: 61.00%\n",
      "30\tValidation loss: 4.157976\tBest loss: 2.388738\tAccuracy: 62.20%\n",
      "31\tValidation loss: 5.078274\tBest loss: 2.388738\tAccuracy: 61.20%\n",
      "32\tValidation loss: 4.430597\tBest loss: 2.388738\tAccuracy: 63.70%\n",
      "33\tValidation loss: 5.411857\tBest loss: 2.388738\tAccuracy: 57.40%\n",
      "34\tValidation loss: 5.104173\tBest loss: 2.388738\tAccuracy: 62.00%\n",
      "35\tValidation loss: 6.899491\tBest loss: 2.388738\tAccuracy: 61.10%\n",
      "36\tValidation loss: 4.200316\tBest loss: 2.388738\tAccuracy: 65.00%\n",
      "Early stopping!\n",
      "[[  1.03527978e-10   6.24899299e-10   5.72918324e-10 ...,   3.52858714e-12\n",
      "    3.65735081e-11   2.40598904e-12]\n",
      " [  0.00000000e+00   6.85854288e-24   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.78853364e-18   4.50117035e-14   7.51949441e-20 ...,   2.16122594e-22\n",
      "    7.86472197e-26   6.68167459e-21]\n",
      " ..., \n",
      " [  1.54353728e-07   3.20943130e-08   3.37106303e-06 ...,   1.49210859e-06\n",
      "    1.74046712e-04   6.07402762e-04]\n",
      " [  1.12751621e-08   2.18023849e-10   4.46111870e-10 ...,   1.34032138e-03\n",
      "    2.08776928e-05   4.54543151e-05]\n",
      " [  2.65198648e-24   1.25479901e-25   2.28691518e-23 ...,   2.78844464e-16\n",
      "    6.81368346e-14   3.94370214e-12]]\n",
      "[26 43 43 ...,  9 26 26]\n",
      "[[  1.60004040e-30   9.12666337e-18   2.38845044e-22 ...,   3.29499332e-35\n",
      "    1.30805320e-31   1.61873354e-31]\n",
      " [  2.43371591e-01   2.74213813e-02   1.14089876e-01 ...,   1.03703584e-04\n",
      "    7.93175132e-05   1.80333707e-04]\n",
      " [  3.99765727e-21   0.00000000e+00   7.64098734e-16 ...,   0.00000000e+00\n",
      "    6.65079905e-38   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    2.11920539e-38   0.00000000e+00]\n",
      " [  3.90017079e-03   9.53388226e-04   1.75570382e-03 ...,   1.53237465e-03\n",
      "    4.85527143e-03   1.02407783e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   2.14699114e-12\n",
      "    3.76200915e-13   9.96189773e-01]]\n",
      "[42 19 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   6.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 11.807904\tBest loss: 11.807904\tAccuracy: 6.40%\n",
      "1\tValidation loss: 3.974270\tBest loss: 3.974270\tAccuracy: 18.50%\n",
      "2\tValidation loss: 9.483485\tBest loss: 3.974270\tAccuracy: 17.80%\n",
      "3\tValidation loss: 4.651429\tBest loss: 3.974270\tAccuracy: 26.20%\n",
      "4\tValidation loss: 2.896332\tBest loss: 2.896332\tAccuracy: 40.00%\n",
      "5\tValidation loss: 2.517721\tBest loss: 2.517721\tAccuracy: 45.80%\n",
      "6\tValidation loss: 5.852045\tBest loss: 2.517721\tAccuracy: 36.10%\n",
      "7\tValidation loss: 2.673654\tBest loss: 2.517721\tAccuracy: 48.50%\n",
      "8\tValidation loss: 3.131796\tBest loss: 2.517721\tAccuracy: 46.00%\n",
      "9\tValidation loss: 2.994165\tBest loss: 2.517721\tAccuracy: 48.60%\n",
      "10\tValidation loss: 3.696981\tBest loss: 2.517721\tAccuracy: 45.00%\n",
      "11\tValidation loss: 2.718353\tBest loss: 2.517721\tAccuracy: 57.20%\n",
      "12\tValidation loss: 4.219847\tBest loss: 2.517721\tAccuracy: 45.10%\n",
      "13\tValidation loss: 3.712515\tBest loss: 2.517721\tAccuracy: 49.80%\n",
      "14\tValidation loss: 5.597104\tBest loss: 2.517721\tAccuracy: 49.10%\n",
      "15\tValidation loss: 3.992657\tBest loss: 2.517721\tAccuracy: 50.30%\n",
      "16\tValidation loss: 3.176791\tBest loss: 2.517721\tAccuracy: 54.50%\n",
      "17\tValidation loss: 3.226468\tBest loss: 2.517721\tAccuracy: 56.60%\n",
      "18\tValidation loss: 4.613554\tBest loss: 2.517721\tAccuracy: 48.70%\n",
      "19\tValidation loss: 2.837152\tBest loss: 2.517721\tAccuracy: 63.30%\n",
      "20\tValidation loss: 2.655939\tBest loss: 2.517721\tAccuracy: 63.70%\n",
      "21\tValidation loss: 4.219593\tBest loss: 2.517721\tAccuracy: 53.00%\n",
      "22\tValidation loss: 2.862229\tBest loss: 2.517721\tAccuracy: 60.80%\n",
      "23\tValidation loss: 3.421769\tBest loss: 2.517721\tAccuracy: 60.70%\n",
      "24\tValidation loss: 3.323246\tBest loss: 2.517721\tAccuracy: 63.10%\n",
      "25\tValidation loss: 4.394295\tBest loss: 2.517721\tAccuracy: 55.70%\n",
      "26\tValidation loss: 4.631345\tBest loss: 2.517721\tAccuracy: 62.30%\n",
      "Early stopping!\n",
      "[[  4.34031594e-04   8.40594235e-04   2.52905484e-05 ...,   2.81388377e-04\n",
      "    4.01818281e-04   3.79628525e-03]\n",
      " [  2.39071885e-27   1.42547134e-23   6.56531382e-23 ...,   1.76446672e-20\n",
      "    8.28761675e-26   7.06387686e-21]\n",
      " [  1.27247185e-04   8.17185792e-04   2.55606195e-04 ...,   8.33614497e-04\n",
      "    9.21481475e-03   9.76915434e-02]\n",
      " ..., \n",
      " [  5.62612526e-29   1.04334181e-26   4.96605492e-24 ...,   4.94896052e-31\n",
      "    5.01337526e-31   3.07703899e-34]\n",
      " [  1.82496384e-02   8.80843680e-03   2.07109451e-02 ...,   1.16249034e-02\n",
      "    1.10199191e-02   1.06468406e-02]\n",
      " [  3.69056999e-14   2.25819183e-10   1.05544269e-16 ...,   8.56115585e-05\n",
      "    9.45412557e-06   9.65316474e-01]]\n",
      "[36 41 40 ...,  7 10 47]\n",
      "[[  8.48990095e-13   2.78261414e-10   3.73934189e-10 ...,   1.27504798e-10\n",
      "    2.48786564e-11   3.46153683e-08]\n",
      " [  1.07478641e-01   5.22000901e-02   6.85164705e-02 ...,   3.14850896e-03\n",
      "    3.77810746e-03   4.42605885e-03]\n",
      " [  6.09290453e-17   8.20556548e-24   1.38272241e-10 ...,   5.04585311e-20\n",
      "    2.42659605e-25   2.65628960e-21]\n",
      " ..., \n",
      " [  2.62992398e-04   2.25288197e-04   1.04190037e-03 ...,   1.06638658e-03\n",
      "    4.40885359e-03   2.51509994e-02]\n",
      " [  1.05395220e-05   1.16158735e-05   8.46986586e-06 ...,   3.86297219e-02\n",
      "    7.25661303e-05   1.93196759e-02]\n",
      " [  3.55854820e-12   2.33256903e-12   9.62959530e-13 ...,   3.06520853e-09\n",
      "    1.64700424e-07   9.06128495e-04]]\n",
      "[20  0 18 ..., 36  6 36]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=2, n_neurons=150, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   4.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.415097\tBest loss: 3.415097\tAccuracy: 13.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tValidation loss: 3.046364\tBest loss: 3.046364\tAccuracy: 22.60%\n",
      "2\tValidation loss: 2.890699\tBest loss: 2.890699\tAccuracy: 27.30%\n",
      "3\tValidation loss: 2.575024\tBest loss: 2.575024\tAccuracy: 33.50%\n",
      "4\tValidation loss: 2.466355\tBest loss: 2.466355\tAccuracy: 35.10%\n",
      "5\tValidation loss: 2.326384\tBest loss: 2.326384\tAccuracy: 39.00%\n",
      "6\tValidation loss: 2.210100\tBest loss: 2.210100\tAccuracy: 43.50%\n",
      "7\tValidation loss: 2.128885\tBest loss: 2.128885\tAccuracy: 46.20%\n",
      "8\tValidation loss: 2.020548\tBest loss: 2.020548\tAccuracy: 48.30%\n",
      "9\tValidation loss: 2.045604\tBest loss: 2.020548\tAccuracy: 48.40%\n",
      "10\tValidation loss: 2.034439\tBest loss: 2.020548\tAccuracy: 52.20%\n",
      "11\tValidation loss: 1.992589\tBest loss: 1.992589\tAccuracy: 51.70%\n",
      "12\tValidation loss: 1.992888\tBest loss: 1.992589\tAccuracy: 52.40%\n",
      "13\tValidation loss: 1.933245\tBest loss: 1.933245\tAccuracy: 56.10%\n",
      "14\tValidation loss: 1.914140\tBest loss: 1.914140\tAccuracy: 56.40%\n",
      "15\tValidation loss: 2.059462\tBest loss: 1.914140\tAccuracy: 53.70%\n",
      "16\tValidation loss: 1.952410\tBest loss: 1.914140\tAccuracy: 57.60%\n",
      "17\tValidation loss: 1.924478\tBest loss: 1.914140\tAccuracy: 57.60%\n",
      "18\tValidation loss: 1.981568\tBest loss: 1.914140\tAccuracy: 58.70%\n",
      "19\tValidation loss: 1.993451\tBest loss: 1.914140\tAccuracy: 57.00%\n",
      "20\tValidation loss: 1.995174\tBest loss: 1.914140\tAccuracy: 57.60%\n",
      "21\tValidation loss: 1.900894\tBest loss: 1.900894\tAccuracy: 59.20%\n",
      "22\tValidation loss: 2.097039\tBest loss: 1.900894\tAccuracy: 57.80%\n",
      "23\tValidation loss: 1.948807\tBest loss: 1.900894\tAccuracy: 58.00%\n",
      "24\tValidation loss: 1.982665\tBest loss: 1.900894\tAccuracy: 59.00%\n",
      "25\tValidation loss: 1.969552\tBest loss: 1.900894\tAccuracy: 60.50%\n",
      "26\tValidation loss: 1.993787\tBest loss: 1.900894\tAccuracy: 59.50%\n",
      "27\tValidation loss: 1.901453\tBest loss: 1.900894\tAccuracy: 61.20%\n",
      "28\tValidation loss: 2.001979\tBest loss: 1.900894\tAccuracy: 60.20%\n",
      "29\tValidation loss: 2.128816\tBest loss: 1.900894\tAccuracy: 58.80%\n",
      "30\tValidation loss: 2.011612\tBest loss: 1.900894\tAccuracy: 60.70%\n",
      "31\tValidation loss: 1.997211\tBest loss: 1.900894\tAccuracy: 61.10%\n",
      "32\tValidation loss: 2.053919\tBest loss: 1.900894\tAccuracy: 61.30%\n",
      "33\tValidation loss: 2.059617\tBest loss: 1.900894\tAccuracy: 60.90%\n",
      "34\tValidation loss: 2.152247\tBest loss: 1.900894\tAccuracy: 61.60%\n",
      "35\tValidation loss: 2.095347\tBest loss: 1.900894\tAccuracy: 62.10%\n",
      "36\tValidation loss: 2.188603\tBest loss: 1.900894\tAccuracy: 61.00%\n",
      "37\tValidation loss: 2.191937\tBest loss: 1.900894\tAccuracy: 62.10%\n",
      "38\tValidation loss: 2.210538\tBest loss: 1.900894\tAccuracy: 62.00%\n",
      "39\tValidation loss: 2.239362\tBest loss: 1.900894\tAccuracy: 62.40%\n",
      "40\tValidation loss: 2.190691\tBest loss: 1.900894\tAccuracy: 62.00%\n",
      "41\tValidation loss: 2.384263\tBest loss: 1.900894\tAccuracy: 61.60%\n",
      "42\tValidation loss: 2.357031\tBest loss: 1.900894\tAccuracy: 62.40%\n",
      "Early stopping!\n",
      "[[  2.12691612e-24   1.03579816e-15   3.28590063e-15 ...,   1.12771882e-25\n",
      "    2.25418649e-18   6.48687225e-26]\n",
      " [  3.80269811e-02   2.97832172e-02   5.48613444e-02 ...,   4.98442166e-03\n",
      "    1.33792590e-03   2.44755298e-03]\n",
      " [  6.94938263e-21   0.00000000e+00   1.20704379e-17 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  4.84523691e-17   1.54163609e-11   3.09825028e-13 ...,   4.11341019e-13\n",
      "    5.57592429e-15   3.31356807e-17]\n",
      " [  1.14336384e-04   2.04652300e-04   2.84748648e-06 ...,   4.59793024e-02\n",
      "    1.06870102e-04   8.29321289e-05]\n",
      " [  3.44417864e-16   4.76265662e-15   6.21681579e-16 ...,   3.95082751e-12\n",
      "    1.41672850e-14   7.73652289e-07]]\n",
      "[11 19 16 ..., 21 24 36]\n",
      "[[  2.40067766e-05   2.56014027e-05   2.15123966e-03 ...,   4.50410917e-05\n",
      "    3.13059172e-06   5.12615603e-04]\n",
      " [  3.31445302e-26   3.37788283e-12   6.44970392e-17 ...,   3.33692015e-26\n",
      "    2.68587362e-21   1.02532058e-20]\n",
      " [  6.90046165e-14   3.07131098e-09   9.81882652e-13 ...,   2.88544362e-13\n",
      "    4.07719971e-17   1.37920098e-13]\n",
      " ..., \n",
      " [  3.00818415e-20   1.82903960e-17   2.13436832e-19 ...,   7.68927416e-24\n",
      "    1.63374967e-21   7.62199300e-23]\n",
      " [  1.54964710e-02   3.41379456e-03   1.88697297e-02 ...,   1.28125269e-02\n",
      "    2.95294821e-02   1.15928529e-02]\n",
      " [  1.08780905e-28   1.68130776e-27   9.29603954e-30 ...,   2.17171051e-12\n",
      "    4.09469867e-05   9.98205900e-01]]\n",
      "[43 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  17.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.381701\tBest loss: 3.381701\tAccuracy: 16.70%\n",
      "1\tValidation loss: 3.085431\tBest loss: 3.085431\tAccuracy: 22.00%\n",
      "2\tValidation loss: 2.721049\tBest loss: 2.721049\tAccuracy: 28.40%\n",
      "3\tValidation loss: 2.578730\tBest loss: 2.578730\tAccuracy: 32.20%\n",
      "4\tValidation loss: 2.423731\tBest loss: 2.423731\tAccuracy: 34.70%\n",
      "5\tValidation loss: 2.262248\tBest loss: 2.262248\tAccuracy: 39.30%\n",
      "6\tValidation loss: 2.223035\tBest loss: 2.223035\tAccuracy: 42.90%\n",
      "7\tValidation loss: 2.110696\tBest loss: 2.110696\tAccuracy: 45.40%\n",
      "8\tValidation loss: 2.122859\tBest loss: 2.110696\tAccuracy: 46.10%\n",
      "9\tValidation loss: 1.985645\tBest loss: 1.985645\tAccuracy: 49.30%\n",
      "10\tValidation loss: 1.959989\tBest loss: 1.959989\tAccuracy: 50.90%\n",
      "11\tValidation loss: 2.094260\tBest loss: 1.959989\tAccuracy: 49.10%\n",
      "12\tValidation loss: 2.089294\tBest loss: 1.959989\tAccuracy: 49.30%\n",
      "13\tValidation loss: 2.018971\tBest loss: 1.959989\tAccuracy: 53.60%\n",
      "14\tValidation loss: 1.941091\tBest loss: 1.941091\tAccuracy: 53.90%\n",
      "15\tValidation loss: 1.965616\tBest loss: 1.941091\tAccuracy: 55.40%\n",
      "16\tValidation loss: 1.868237\tBest loss: 1.868237\tAccuracy: 57.40%\n",
      "17\tValidation loss: 1.913993\tBest loss: 1.868237\tAccuracy: 57.30%\n",
      "18\tValidation loss: 1.966647\tBest loss: 1.868237\tAccuracy: 57.90%\n",
      "19\tValidation loss: 1.925365\tBest loss: 1.868237\tAccuracy: 56.60%\n",
      "20\tValidation loss: 2.035110\tBest loss: 1.868237\tAccuracy: 57.40%\n",
      "21\tValidation loss: 2.009592\tBest loss: 1.868237\tAccuracy: 57.50%\n",
      "22\tValidation loss: 1.914754\tBest loss: 1.868237\tAccuracy: 59.70%\n",
      "23\tValidation loss: 1.993064\tBest loss: 1.868237\tAccuracy: 57.40%\n",
      "24\tValidation loss: 1.947496\tBest loss: 1.868237\tAccuracy: 59.00%\n",
      "25\tValidation loss: 2.031116\tBest loss: 1.868237\tAccuracy: 58.90%\n",
      "26\tValidation loss: 1.969161\tBest loss: 1.868237\tAccuracy: 60.30%\n",
      "27\tValidation loss: 1.939356\tBest loss: 1.868237\tAccuracy: 61.70%\n",
      "28\tValidation loss: 2.032213\tBest loss: 1.868237\tAccuracy: 60.40%\n",
      "29\tValidation loss: 2.019090\tBest loss: 1.868237\tAccuracy: 61.00%\n",
      "30\tValidation loss: 2.021690\tBest loss: 1.868237\tAccuracy: 61.60%\n",
      "31\tValidation loss: 2.071656\tBest loss: 1.868237\tAccuracy: 60.60%\n",
      "32\tValidation loss: 2.094012\tBest loss: 1.868237\tAccuracy: 60.30%\n",
      "33\tValidation loss: 2.066323\tBest loss: 1.868237\tAccuracy: 62.20%\n",
      "34\tValidation loss: 2.187695\tBest loss: 1.868237\tAccuracy: 59.40%\n",
      "35\tValidation loss: 2.118168\tBest loss: 1.868237\tAccuracy: 62.50%\n",
      "36\tValidation loss: 2.179256\tBest loss: 1.868237\tAccuracy: 62.00%\n",
      "37\tValidation loss: 2.191568\tBest loss: 1.868237\tAccuracy: 63.10%\n",
      "Early stopping!\n",
      "[[  3.41879495e-04   7.96811946e-06   2.88754259e-03 ...,   2.97227120e-06\n",
      "    1.83110117e-07   3.29753220e-07]\n",
      " [  6.35001296e-12   7.05029646e-11   1.67359115e-09 ...,   7.88694847e-13\n",
      "    8.58191240e-10   8.61566605e-08]\n",
      " [  1.78701475e-06   1.13511169e-06   9.58303281e-05 ...,   4.81856555e-10\n",
      "    3.04341947e-12   3.76818455e-12]\n",
      " ..., \n",
      " [  1.05787267e-03   5.07368124e-04   4.28356742e-03 ...,   1.30260174e-04\n",
      "    5.66556846e-05   1.85009092e-04]\n",
      " [  2.90181507e-11   1.77682294e-12   1.29650417e-07 ...,   2.54158862e-03\n",
      "    5.04936883e-03   4.73727379e-03]\n",
      " [  1.62055753e-13   4.05727829e-16   3.15449805e-10 ...,   9.79352103e-12\n",
      "    4.13416778e-13   1.93878424e-09]]\n",
      "[38 43 43 ..., 36 25 27]\n",
      "[[  6.54820260e-17   4.02443785e-14   3.16459814e-12 ...,   2.73306280e-13\n",
      "    1.55075011e-08   1.92135717e-11]\n",
      " [  6.48112968e-02   3.14828195e-02   1.02286525e-01 ...,   5.50842565e-03\n",
      "    2.42248946e-03   1.92161673e-03]\n",
      " [  2.82102338e-18   5.42625827e-29   2.43872278e-09 ...,   8.35376062e-28\n",
      "    1.62862341e-38   0.00000000e+00]\n",
      " ..., \n",
      " [  7.60580401e-12   5.07324455e-14   8.18209129e-12 ...,   1.52543721e-20\n",
      "    2.01560523e-17   7.57271835e-22]\n",
      " [  1.80706177e-02   1.04680425e-02   2.85122022e-02 ...,   1.80935115e-02\n",
      "    2.00175494e-02   1.25589045e-02]\n",
      " [  1.86971401e-29   2.04201499e-26   1.52444165e-26 ...,   2.85601107e-08\n",
      "    5.83710298e-02   9.05366302e-01]]\n",
      "[20 19 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  14.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.385618\tBest loss: 3.385618\tAccuracy: 15.30%\n",
      "1\tValidation loss: 3.091038\tBest loss: 3.091038\tAccuracy: 21.00%\n",
      "2\tValidation loss: 2.732974\tBest loss: 2.732974\tAccuracy: 29.00%\n",
      "3\tValidation loss: 2.553649\tBest loss: 2.553649\tAccuracy: 33.00%\n",
      "4\tValidation loss: 2.450541\tBest loss: 2.450541\tAccuracy: 35.00%\n",
      "5\tValidation loss: 2.293101\tBest loss: 2.293101\tAccuracy: 40.10%\n",
      "6\tValidation loss: 2.269703\tBest loss: 2.269703\tAccuracy: 39.20%\n",
      "7\tValidation loss: 2.287076\tBest loss: 2.269703\tAccuracy: 42.50%\n",
      "8\tValidation loss: 2.153940\tBest loss: 2.153940\tAccuracy: 45.30%\n",
      "9\tValidation loss: 2.086171\tBest loss: 2.086171\tAccuracy: 48.10%\n",
      "10\tValidation loss: 2.049423\tBest loss: 2.049423\tAccuracy: 49.50%\n",
      "11\tValidation loss: 2.009988\tBest loss: 2.009988\tAccuracy: 51.90%\n",
      "12\tValidation loss: 1.970631\tBest loss: 1.970631\tAccuracy: 51.70%\n",
      "13\tValidation loss: 1.914629\tBest loss: 1.914629\tAccuracy: 54.30%\n",
      "14\tValidation loss: 1.876364\tBest loss: 1.876364\tAccuracy: 54.30%\n",
      "15\tValidation loss: 1.967626\tBest loss: 1.876364\tAccuracy: 54.30%\n",
      "16\tValidation loss: 2.034469\tBest loss: 1.876364\tAccuracy: 55.20%\n",
      "17\tValidation loss: 1.881152\tBest loss: 1.876364\tAccuracy: 56.90%\n",
      "18\tValidation loss: 1.853726\tBest loss: 1.853726\tAccuracy: 55.90%\n",
      "19\tValidation loss: 1.872530\tBest loss: 1.853726\tAccuracy: 57.70%\n",
      "20\tValidation loss: 1.885458\tBest loss: 1.853726\tAccuracy: 58.30%\n",
      "21\tValidation loss: 1.916440\tBest loss: 1.853726\tAccuracy: 60.50%\n",
      "22\tValidation loss: 1.889796\tBest loss: 1.853726\tAccuracy: 62.20%\n",
      "23\tValidation loss: 1.994262\tBest loss: 1.853726\tAccuracy: 58.60%\n",
      "24\tValidation loss: 1.970798\tBest loss: 1.853726\tAccuracy: 59.80%\n",
      "25\tValidation loss: 1.991467\tBest loss: 1.853726\tAccuracy: 60.70%\n",
      "26\tValidation loss: 1.929838\tBest loss: 1.853726\tAccuracy: 59.70%\n",
      "27\tValidation loss: 1.968818\tBest loss: 1.853726\tAccuracy: 61.40%\n",
      "28\tValidation loss: 2.040456\tBest loss: 1.853726\tAccuracy: 61.10%\n",
      "29\tValidation loss: 2.165947\tBest loss: 1.853726\tAccuracy: 60.10%\n",
      "30\tValidation loss: 2.081578\tBest loss: 1.853726\tAccuracy: 62.20%\n",
      "31\tValidation loss: 2.085886\tBest loss: 1.853726\tAccuracy: 60.30%\n",
      "32\tValidation loss: 2.053075\tBest loss: 1.853726\tAccuracy: 61.60%\n",
      "33\tValidation loss: 2.049867\tBest loss: 1.853726\tAccuracy: 61.40%\n",
      "34\tValidation loss: 2.126944\tBest loss: 1.853726\tAccuracy: 63.50%\n",
      "35\tValidation loss: 2.067444\tBest loss: 1.853726\tAccuracy: 63.40%\n",
      "36\tValidation loss: 2.163569\tBest loss: 1.853726\tAccuracy: 63.10%\n",
      "37\tValidation loss: 2.144482\tBest loss: 1.853726\tAccuracy: 64.10%\n",
      "38\tValidation loss: 2.131628\tBest loss: 1.853726\tAccuracy: 62.50%\n",
      "39\tValidation loss: 2.181735\tBest loss: 1.853726\tAccuracy: 65.30%\n",
      "Early stopping!\n",
      "[[  9.16319084e-04   4.58132010e-04   1.47045974e-03 ...,   2.40139838e-04\n",
      "    1.16264428e-05   1.48188250e-04]\n",
      " [  2.21588862e-21   2.70985004e-15   8.88934873e-17 ...,   1.98092367e-12\n",
      "    5.28215993e-16   6.49262519e-11]\n",
      " [  6.89404303e-08   6.41586911e-03   2.84640601e-06 ...,   3.77078914e-06\n",
      "    2.72339117e-03   8.07135403e-02]\n",
      " ..., \n",
      " [  1.83720227e-14   1.32274346e-12   7.34038554e-17 ...,   2.15652024e-17\n",
      "    6.97946996e-16   1.69090934e-14]\n",
      " [  9.89340432e-03   7.54178734e-03   1.66718531e-02 ...,   1.57366991e-02\n",
      "    1.54598895e-02   2.17169374e-02]\n",
      " [  2.63324156e-29   5.26289720e-23   1.91916016e-25 ...,   7.82218301e-12\n",
      "    4.47273143e-02   9.52529371e-01]]\n",
      "[36 41 29 ...,  6 10 47]\n",
      "[[  6.48277642e-21   5.14112468e-11   1.83737828e-14 ...,   7.78123334e-13\n",
      "    1.55798929e-10   2.80627503e-08]\n",
      " [  4.89997752e-02   4.36563939e-02   9.68028009e-02 ...,   3.61463032e-03\n",
      "    1.12358655e-03   1.83686812e-03]\n",
      " [  6.59932881e-25   0.00000000e+00   1.39560509e-13 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.02291184e-05   2.57526874e-04   2.45623261e-04 ...,   1.18605688e-03\n",
      "    1.24005892e-03   2.78614108e-02]\n",
      " [  9.96696614e-10   4.62179878e-11   6.39630710e-13 ...,   1.77464858e-01\n",
      "    2.62254644e-02   3.14833014e-03]\n",
      " [  4.26028828e-18   1.49683824e-17   3.34201826e-15 ...,   6.55764384e-16\n",
      "    9.47926441e-19   3.21946528e-12]]\n",
      "[20 19 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  14.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.721268\tBest loss: 3.721268\tAccuracy: 6.60%\n",
      "1\tValidation loss: 3.597693\tBest loss: 3.597693\tAccuracy: 7.00%\n",
      "2\tValidation loss: 3.611545\tBest loss: 3.597693\tAccuracy: 7.40%\n",
      "3\tValidation loss: 3.556606\tBest loss: 3.556606\tAccuracy: 5.90%\n",
      "4\tValidation loss: 3.601477\tBest loss: 3.556606\tAccuracy: 6.80%\n",
      "5\tValidation loss: 3.536010\tBest loss: 3.536010\tAccuracy: 6.00%\n",
      "6\tValidation loss: 3.538193\tBest loss: 3.536010\tAccuracy: 7.30%\n",
      "7\tValidation loss: 3.542283\tBest loss: 3.536010\tAccuracy: 7.00%\n",
      "8\tValidation loss: 3.552838\tBest loss: 3.536010\tAccuracy: 7.30%\n",
      "9\tValidation loss: 3.556957\tBest loss: 3.536010\tAccuracy: 6.80%\n",
      "10\tValidation loss: 3.527533\tBest loss: 3.527533\tAccuracy: 7.90%\n",
      "11\tValidation loss: 3.527417\tBest loss: 3.527417\tAccuracy: 7.20%\n",
      "12\tValidation loss: 3.522479\tBest loss: 3.522479\tAccuracy: 7.20%\n",
      "13\tValidation loss: 3.534613\tBest loss: 3.522479\tAccuracy: 7.00%\n",
      "14\tValidation loss: 3.525612\tBest loss: 3.522479\tAccuracy: 7.00%\n",
      "15\tValidation loss: 3.540069\tBest loss: 3.522479\tAccuracy: 6.90%\n",
      "16\tValidation loss: 3.494940\tBest loss: 3.494940\tAccuracy: 7.60%\n",
      "17\tValidation loss: 3.493394\tBest loss: 3.493394\tAccuracy: 7.80%\n",
      "18\tValidation loss: 3.500930\tBest loss: 3.493394\tAccuracy: 7.30%\n",
      "19\tValidation loss: 3.505872\tBest loss: 3.493394\tAccuracy: 6.40%\n",
      "20\tValidation loss: 3.527816\tBest loss: 3.493394\tAccuracy: 7.20%\n",
      "21\tValidation loss: 3.595598\tBest loss: 3.493394\tAccuracy: 6.00%\n",
      "22\tValidation loss: 3.531677\tBest loss: 3.493394\tAccuracy: 7.60%\n",
      "23\tValidation loss: 3.539128\tBest loss: 3.493394\tAccuracy: 7.40%\n",
      "24\tValidation loss: 3.522578\tBest loss: 3.493394\tAccuracy: 7.70%\n",
      "25\tValidation loss: 3.544050\tBest loss: 3.493394\tAccuracy: 6.80%\n",
      "26\tValidation loss: 3.497225\tBest loss: 3.493394\tAccuracy: 7.40%\n",
      "27\tValidation loss: 3.510061\tBest loss: 3.493394\tAccuracy: 6.80%\n",
      "28\tValidation loss: 3.518143\tBest loss: 3.493394\tAccuracy: 7.20%\n",
      "29\tValidation loss: 3.519143\tBest loss: 3.493394\tAccuracy: 7.20%\n",
      "30\tValidation loss: 3.517822\tBest loss: 3.493394\tAccuracy: 6.80%\n",
      "31\tValidation loss: 3.513013\tBest loss: 3.493394\tAccuracy: 5.80%\n",
      "32\tValidation loss: 3.526594\tBest loss: 3.493394\tAccuracy: 7.30%\n",
      "33\tValidation loss: 3.535975\tBest loss: 3.493394\tAccuracy: 6.20%\n",
      "34\tValidation loss: 3.520787\tBest loss: 3.493394\tAccuracy: 7.30%\n",
      "35\tValidation loss: 3.537682\tBest loss: 3.493394\tAccuracy: 6.00%\n",
      "36\tValidation loss: 3.539705\tBest loss: 3.493394\tAccuracy: 7.00%\n",
      "37\tValidation loss: 3.554223\tBest loss: 3.493394\tAccuracy: 7.00%\n",
      "38\tValidation loss: 3.538255\tBest loss: 3.493394\tAccuracy: 5.40%\n",
      "Early stopping!\n",
      "[[ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " [ 0.04542138  0.06682517  0.03382488 ...,  0.01243188  0.00360557\n",
      "   0.00357184]\n",
      " [ 0.04542138  0.06682517  0.03382488 ...,  0.01243188  0.00360557\n",
      "   0.00357184]\n",
      " ..., \n",
      " [ 0.04542138  0.06682517  0.03382488 ...,  0.01243188  0.00360557\n",
      "   0.00357184]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]]\n",
      "[ 8 17 17 ..., 17  8  8]\n",
      "[[ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " ..., \n",
      " [ 0.04542138  0.06682517  0.03382488 ...,  0.01243188  0.00360557\n",
      "   0.00357184]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]\n",
      " [ 0.00540653  0.01132175  0.00830034 ...,  0.04396204  0.0269895\n",
      "   0.03468342]]\n",
      "[ 8  8  8 ..., 17  8  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total= 1.1min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.720402\tBest loss: 3.720402\tAccuracy: 3.80%\n",
      "1\tValidation loss: 3.590921\tBest loss: 3.590921\tAccuracy: 5.80%\n",
      "2\tValidation loss: 3.575783\tBest loss: 3.575783\tAccuracy: 5.20%\n",
      "3\tValidation loss: 3.606312\tBest loss: 3.575783\tAccuracy: 4.60%\n",
      "4\tValidation loss: 3.704811\tBest loss: 3.575783\tAccuracy: 7.30%\n",
      "5\tValidation loss: 3.689110\tBest loss: 3.575783\tAccuracy: 5.60%\n",
      "6\tValidation loss: 3.627495\tBest loss: 3.575783\tAccuracy: 5.30%\n",
      "7\tValidation loss: 3.612684\tBest loss: 3.575783\tAccuracy: 5.30%\n",
      "8\tValidation loss: 3.639931\tBest loss: 3.575783\tAccuracy: 6.30%\n",
      "9\tValidation loss: 3.597142\tBest loss: 3.575783\tAccuracy: 7.20%\n",
      "10\tValidation loss: 3.681284\tBest loss: 3.575783\tAccuracy: 6.70%\n",
      "11\tValidation loss: 3.644991\tBest loss: 3.575783\tAccuracy: 5.20%\n",
      "12\tValidation loss: 3.614935\tBest loss: 3.575783\tAccuracy: 6.80%\n",
      "13\tValidation loss: 3.616948\tBest loss: 3.575783\tAccuracy: 7.30%\n",
      "14\tValidation loss: 3.608014\tBest loss: 3.575783\tAccuracy: 7.20%\n",
      "15\tValidation loss: 3.583009\tBest loss: 3.575783\tAccuracy: 5.40%\n",
      "16\tValidation loss: 3.574914\tBest loss: 3.574914\tAccuracy: 5.70%\n",
      "17\tValidation loss: 3.587726\tBest loss: 3.574914\tAccuracy: 7.50%\n",
      "18\tValidation loss: 3.592213\tBest loss: 3.574914\tAccuracy: 7.30%\n",
      "19\tValidation loss: 3.643786\tBest loss: 3.574914\tAccuracy: 6.90%\n",
      "20\tValidation loss: 3.592102\tBest loss: 3.574914\tAccuracy: 5.70%\n",
      "21\tValidation loss: 3.567899\tBest loss: 3.567899\tAccuracy: 7.50%\n",
      "22\tValidation loss: 3.581984\tBest loss: 3.567899\tAccuracy: 6.40%\n",
      "23\tValidation loss: 3.567846\tBest loss: 3.567846\tAccuracy: 5.40%\n",
      "24\tValidation loss: 3.606125\tBest loss: 3.567846\tAccuracy: 7.10%\n",
      "25\tValidation loss: 3.564904\tBest loss: 3.564904\tAccuracy: 6.50%\n",
      "26\tValidation loss: 3.564706\tBest loss: 3.564706\tAccuracy: 6.30%\n",
      "27\tValidation loss: 3.637013\tBest loss: 3.564706\tAccuracy: 5.40%\n",
      "28\tValidation loss: 3.545899\tBest loss: 3.545899\tAccuracy: 6.00%\n",
      "29\tValidation loss: 3.544165\tBest loss: 3.544165\tAccuracy: 5.80%\n",
      "30\tValidation loss: 3.555221\tBest loss: 3.544165\tAccuracy: 7.50%\n",
      "31\tValidation loss: 3.545859\tBest loss: 3.544165\tAccuracy: 6.60%\n",
      "32\tValidation loss: 3.547853\tBest loss: 3.544165\tAccuracy: 6.10%\n",
      "33\tValidation loss: 3.534689\tBest loss: 3.534689\tAccuracy: 7.00%\n",
      "34\tValidation loss: 3.544064\tBest loss: 3.534689\tAccuracy: 7.50%\n",
      "35\tValidation loss: 3.528395\tBest loss: 3.528395\tAccuracy: 7.30%\n",
      "36\tValidation loss: 3.568759\tBest loss: 3.528395\tAccuracy: 7.30%\n",
      "37\tValidation loss: 3.556937\tBest loss: 3.528395\tAccuracy: 6.30%\n",
      "38\tValidation loss: 3.558537\tBest loss: 3.528395\tAccuracy: 6.80%\n",
      "39\tValidation loss: 3.555537\tBest loss: 3.528395\tAccuracy: 6.30%\n",
      "40\tValidation loss: 3.593344\tBest loss: 3.528395\tAccuracy: 7.30%\n",
      "41\tValidation loss: 3.576434\tBest loss: 3.528395\tAccuracy: 7.10%\n",
      "42\tValidation loss: 3.583498\tBest loss: 3.528395\tAccuracy: 7.30%\n",
      "43\tValidation loss: 3.573331\tBest loss: 3.528395\tAccuracy: 5.90%\n",
      "44\tValidation loss: 3.550625\tBest loss: 3.528395\tAccuracy: 7.50%\n",
      "45\tValidation loss: 3.551069\tBest loss: 3.528395\tAccuracy: 5.50%\n",
      "46\tValidation loss: 3.543457\tBest loss: 3.528395\tAccuracy: 6.20%\n",
      "47\tValidation loss: 3.533238\tBest loss: 3.528395\tAccuracy: 7.50%\n",
      "48\tValidation loss: 3.541883\tBest loss: 3.528395\tAccuracy: 6.10%\n",
      "49\tValidation loss: 3.629051\tBest loss: 3.528395\tAccuracy: 5.00%\n",
      "50\tValidation loss: 3.594317\tBest loss: 3.528395\tAccuracy: 5.50%\n",
      "51\tValidation loss: 3.552424\tBest loss: 3.528395\tAccuracy: 7.50%\n",
      "52\tValidation loss: 3.563983\tBest loss: 3.528395\tAccuracy: 6.40%\n",
      "53\tValidation loss: 3.539120\tBest loss: 3.528395\tAccuracy: 6.50%\n",
      "54\tValidation loss: 3.540136\tBest loss: 3.528395\tAccuracy: 7.60%\n",
      "55\tValidation loss: 3.542619\tBest loss: 3.528395\tAccuracy: 7.30%\n",
      "56\tValidation loss: 3.558625\tBest loss: 3.528395\tAccuracy: 6.90%\n",
      "Early stopping!\n",
      "[[ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " ..., \n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " [ 0.03353676  0.05662389  0.03166896 ...,  0.00799505  0.00635973\n",
      "   0.00516128]\n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]]\n",
      "[ 8  8  8 ...,  8 18  8]\n",
      "[[ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " [ 0.03353676  0.05662389  0.03166896 ...,  0.00799505  0.00635973\n",
      "   0.00516128]\n",
      " [ 0.03353676  0.05662389  0.03166896 ...,  0.00799505  0.00635973\n",
      "   0.00516128]\n",
      " ..., \n",
      " [ 0.03353676  0.05662389  0.03166896 ...,  0.00799505  0.00635973\n",
      "   0.00516128]\n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]\n",
      " [ 0.00622726  0.01087959  0.01227354 ...,  0.04536365  0.02417928\n",
      "   0.02987344]]\n",
      "[ 8 18 18 ..., 18  8  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total= 1.8min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.798505\tBest loss: 3.798505\tAccuracy: 3.20%\n",
      "1\tValidation loss: 3.798327\tBest loss: 3.798327\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.799356\tBest loss: 3.798327\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.799175\tBest loss: 3.798327\tAccuracy: 4.00%\n",
      "4\tValidation loss: 3.800002\tBest loss: 3.798327\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.799284\tBest loss: 3.798327\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.798122\tBest loss: 3.798122\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.802012\tBest loss: 3.798122\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.798846\tBest loss: 3.798122\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.796920\tBest loss: 3.796920\tAccuracy: 3.00%\n",
      "10\tValidation loss: 3.798062\tBest loss: 3.796920\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.795796\tBest loss: 3.795796\tAccuracy: 3.20%\n",
      "12\tValidation loss: 3.796889\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.800937\tBest loss: 3.795796\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.797662\tBest loss: 3.795796\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.796594\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.800998\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.800663\tBest loss: 3.795796\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.801992\tBest loss: 3.795796\tAccuracy: 4.00%\n",
      "19\tValidation loss: 3.800829\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.795844\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.798647\tBest loss: 3.795796\tAccuracy: 4.00%\n",
      "22\tValidation loss: 3.797884\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.798782\tBest loss: 3.795796\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.794722\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "25\tValidation loss: 3.800399\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.800749\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.802232\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.796050\tBest loss: 3.794722\tAccuracy: 4.10%\n",
      "29\tValidation loss: 3.799994\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "30\tValidation loss: 3.797886\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "31\tValidation loss: 3.799810\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.796314\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "33\tValidation loss: 3.801862\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "34\tValidation loss: 3.799832\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.798485\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "36\tValidation loss: 3.802083\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.799546\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.796855\tBest loss: 3.794722\tAccuracy: 3.20%\n",
      "39\tValidation loss: 3.797123\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.801908\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.800072\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.798325\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.794870\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.796281\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.799598\tBest loss: 3.794722\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " ..., \n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[[ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " ..., \n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]\n",
      " [ 0.01678252  0.03291071  0.02269153 ...,  0.0284542   0.01818439\n",
      "   0.01894031]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total= 1.5min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.877964\tBest loss: 3.877964\tAccuracy: 3.60%\n",
      "1\tValidation loss: 3.865806\tBest loss: 3.865806\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.848991\tBest loss: 3.848991\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.822156\tBest loss: 3.822156\tAccuracy: 4.10%\n",
      "4\tValidation loss: 3.803626\tBest loss: 3.803626\tAccuracy: 3.60%\n",
      "5\tValidation loss: 3.795381\tBest loss: 3.795381\tAccuracy: 3.40%\n",
      "6\tValidation loss: 3.799178\tBest loss: 3.795381\tAccuracy: 3.20%\n",
      "7\tValidation loss: 3.786433\tBest loss: 3.786433\tAccuracy: 4.10%\n",
      "8\tValidation loss: 3.782707\tBest loss: 3.782707\tAccuracy: 4.10%\n",
      "9\tValidation loss: 3.786994\tBest loss: 3.782707\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.751961\tBest loss: 3.751961\tAccuracy: 5.80%\n",
      "11\tValidation loss: 3.726319\tBest loss: 3.726319\tAccuracy: 6.30%\n",
      "12\tValidation loss: 3.686656\tBest loss: 3.686656\tAccuracy: 6.60%\n",
      "13\tValidation loss: 3.646189\tBest loss: 3.646189\tAccuracy: 7.60%\n",
      "14\tValidation loss: 3.707499\tBest loss: 3.646189\tAccuracy: 5.30%\n",
      "15\tValidation loss: 3.778256\tBest loss: 3.646189\tAccuracy: 4.30%\n",
      "16\tValidation loss: 3.621205\tBest loss: 3.621205\tAccuracy: 7.00%\n",
      "17\tValidation loss: 3.611606\tBest loss: 3.611606\tAccuracy: 7.00%\n",
      "18\tValidation loss: 3.606693\tBest loss: 3.606693\tAccuracy: 6.10%\n",
      "19\tValidation loss: 3.667730\tBest loss: 3.606693\tAccuracy: 5.70%\n",
      "20\tValidation loss: 3.624211\tBest loss: 3.606693\tAccuracy: 5.70%\n",
      "21\tValidation loss: 3.597639\tBest loss: 3.597639\tAccuracy: 6.80%\n",
      "22\tValidation loss: 3.680505\tBest loss: 3.597639\tAccuracy: 6.80%\n",
      "23\tValidation loss: 3.572179\tBest loss: 3.572179\tAccuracy: 7.10%\n",
      "24\tValidation loss: 3.571356\tBest loss: 3.571356\tAccuracy: 6.40%\n",
      "25\tValidation loss: 3.565864\tBest loss: 3.565864\tAccuracy: 7.50%\n",
      "26\tValidation loss: 3.597094\tBest loss: 3.565864\tAccuracy: 7.10%\n",
      "27\tValidation loss: 3.581645\tBest loss: 3.565864\tAccuracy: 6.30%\n",
      "28\tValidation loss: 3.551898\tBest loss: 3.551898\tAccuracy: 6.50%\n",
      "29\tValidation loss: 3.591820\tBest loss: 3.551898\tAccuracy: 7.20%\n",
      "30\tValidation loss: 3.553421\tBest loss: 3.551898\tAccuracy: 6.70%\n",
      "31\tValidation loss: 3.561154\tBest loss: 3.551898\tAccuracy: 7.30%\n",
      "32\tValidation loss: 3.529663\tBest loss: 3.529663\tAccuracy: 5.80%\n",
      "33\tValidation loss: 3.557901\tBest loss: 3.529663\tAccuracy: 5.40%\n",
      "34\tValidation loss: 3.549859\tBest loss: 3.529663\tAccuracy: 7.10%\n",
      "35\tValidation loss: 3.561551\tBest loss: 3.529663\tAccuracy: 5.70%\n",
      "36\tValidation loss: 3.554874\tBest loss: 3.529663\tAccuracy: 7.30%\n",
      "37\tValidation loss: 3.553056\tBest loss: 3.529663\tAccuracy: 7.40%\n",
      "38\tValidation loss: 3.536629\tBest loss: 3.529663\tAccuracy: 6.60%\n",
      "39\tValidation loss: 3.560191\tBest loss: 3.529663\tAccuracy: 6.30%\n",
      "40\tValidation loss: 3.526157\tBest loss: 3.526157\tAccuracy: 6.60%\n",
      "41\tValidation loss: 3.555861\tBest loss: 3.526157\tAccuracy: 7.40%\n",
      "42\tValidation loss: 3.509116\tBest loss: 3.509116\tAccuracy: 7.50%\n",
      "43\tValidation loss: 3.536330\tBest loss: 3.509116\tAccuracy: 7.60%\n",
      "44\tValidation loss: 3.525516\tBest loss: 3.509116\tAccuracy: 5.90%\n",
      "45\tValidation loss: 3.618316\tBest loss: 3.509116\tAccuracy: 6.20%\n",
      "46\tValidation loss: 3.535239\tBest loss: 3.509116\tAccuracy: 7.50%\n",
      "47\tValidation loss: 3.528886\tBest loss: 3.509116\tAccuracy: 7.80%\n",
      "48\tValidation loss: 3.532709\tBest loss: 3.509116\tAccuracy: 7.10%\n",
      "49\tValidation loss: 3.526687\tBest loss: 3.509116\tAccuracy: 7.30%\n",
      "50\tValidation loss: 3.510296\tBest loss: 3.509116\tAccuracy: 5.40%\n",
      "51\tValidation loss: 3.520831\tBest loss: 3.509116\tAccuracy: 5.60%\n",
      "52\tValidation loss: 3.514674\tBest loss: 3.509116\tAccuracy: 7.20%\n",
      "53\tValidation loss: 3.495040\tBest loss: 3.495040\tAccuracy: 7.60%\n",
      "54\tValidation loss: 3.540934\tBest loss: 3.495040\tAccuracy: 7.10%\n",
      "55\tValidation loss: 3.504829\tBest loss: 3.495040\tAccuracy: 6.30%\n",
      "56\tValidation loss: 3.517074\tBest loss: 3.495040\tAccuracy: 6.60%\n",
      "57\tValidation loss: 3.515380\tBest loss: 3.495040\tAccuracy: 7.30%\n",
      "58\tValidation loss: 3.534645\tBest loss: 3.495040\tAccuracy: 7.80%\n",
      "59\tValidation loss: 3.527195\tBest loss: 3.495040\tAccuracy: 6.20%\n",
      "60\tValidation loss: 3.519891\tBest loss: 3.495040\tAccuracy: 7.40%\n",
      "61\tValidation loss: 3.516412\tBest loss: 3.495040\tAccuracy: 7.20%\n",
      "62\tValidation loss: 3.510001\tBest loss: 3.495040\tAccuracy: 7.50%\n",
      "63\tValidation loss: 3.512801\tBest loss: 3.495040\tAccuracy: 7.60%\n",
      "64\tValidation loss: 3.515586\tBest loss: 3.495040\tAccuracy: 7.50%\n",
      "65\tValidation loss: 3.507440\tBest loss: 3.495040\tAccuracy: 6.40%\n",
      "66\tValidation loss: 3.488854\tBest loss: 3.488854\tAccuracy: 6.20%\n",
      "67\tValidation loss: 3.502412\tBest loss: 3.488854\tAccuracy: 7.70%\n",
      "68\tValidation loss: 3.510411\tBest loss: 3.488854\tAccuracy: 7.30%\n",
      "69\tValidation loss: 3.539461\tBest loss: 3.488854\tAccuracy: 7.00%\n",
      "70\tValidation loss: 3.514684\tBest loss: 3.488854\tAccuracy: 7.30%\n",
      "71\tValidation loss: 3.516633\tBest loss: 3.488854\tAccuracy: 7.30%\n",
      "72\tValidation loss: 3.502367\tBest loss: 3.488854\tAccuracy: 5.40%\n",
      "73\tValidation loss: 3.489689\tBest loss: 3.488854\tAccuracy: 7.50%\n",
      "74\tValidation loss: 3.518353\tBest loss: 3.488854\tAccuracy: 6.30%\n",
      "75\tValidation loss: 3.470108\tBest loss: 3.470108\tAccuracy: 7.80%\n",
      "76\tValidation loss: 3.482821\tBest loss: 3.470108\tAccuracy: 7.70%\n",
      "77\tValidation loss: 3.518128\tBest loss: 3.470108\tAccuracy: 6.90%\n",
      "78\tValidation loss: 3.497518\tBest loss: 3.470108\tAccuracy: 7.10%\n",
      "79\tValidation loss: 3.533377\tBest loss: 3.470108\tAccuracy: 6.40%\n",
      "80\tValidation loss: 3.498567\tBest loss: 3.470108\tAccuracy: 6.20%\n",
      "81\tValidation loss: 3.498014\tBest loss: 3.470108\tAccuracy: 7.50%\n",
      "82\tValidation loss: 3.493351\tBest loss: 3.470108\tAccuracy: 6.20%\n",
      "83\tValidation loss: 3.523252\tBest loss: 3.470108\tAccuracy: 6.60%\n",
      "84\tValidation loss: 3.525741\tBest loss: 3.470108\tAccuracy: 6.40%\n",
      "85\tValidation loss: 3.499073\tBest loss: 3.470108\tAccuracy: 5.40%\n",
      "86\tValidation loss: 3.526223\tBest loss: 3.470108\tAccuracy: 6.80%\n",
      "87\tValidation loss: 3.506528\tBest loss: 3.470108\tAccuracy: 5.20%\n",
      "88\tValidation loss: 3.491086\tBest loss: 3.470108\tAccuracy: 6.60%\n",
      "89\tValidation loss: 3.512092\tBest loss: 3.470108\tAccuracy: 7.00%\n",
      "90\tValidation loss: 3.494943\tBest loss: 3.470108\tAccuracy: 5.10%\n",
      "91\tValidation loss: 3.496748\tBest loss: 3.470108\tAccuracy: 7.20%\n",
      "92\tValidation loss: 3.509469\tBest loss: 3.470108\tAccuracy: 7.60%\n",
      "93\tValidation loss: 3.521113\tBest loss: 3.470108\tAccuracy: 7.50%\n",
      "94\tValidation loss: 3.511101\tBest loss: 3.470108\tAccuracy: 7.20%\n",
      "95\tValidation loss: 3.494092\tBest loss: 3.470108\tAccuracy: 7.00%\n",
      "96\tValidation loss: 3.489505\tBest loss: 3.470108\tAccuracy: 6.40%\n",
      "Early stopping!\n",
      "[[ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]\n",
      " [ 0.03563463  0.04582144  0.04168208 ...,  0.02008493  0.01108545\n",
      "   0.00762102]\n",
      " [ 0.02547373  0.05599587  0.03340133 ...,  0.01284143  0.00688232\n",
      "   0.0050818 ]\n",
      " ..., \n",
      " [ 0.02547373  0.05599587  0.03340133 ...,  0.01284143  0.00688232\n",
      "   0.0050818 ]\n",
      " [ 0.02547373  0.05599587  0.03340133 ...,  0.01284143  0.00688232\n",
      "   0.0050818 ]\n",
      " [ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]]\n",
      "[ 8 16 18 ..., 18 18  8]\n",
      "[[ 0.04617487  0.02919301  0.04643215 ...,  0.03017097  0.01731286\n",
      "   0.01082814]\n",
      " [ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]\n",
      " [ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]\n",
      " ..., \n",
      " [ 0.02547373  0.05599587  0.03340133 ...,  0.01284143  0.00688232\n",
      "   0.0050818 ]\n",
      " [ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]\n",
      " [ 0.00427766  0.00692643  0.00765569 ...,  0.05487124  0.03017319\n",
      "   0.02818108]]\n",
      "[ 2  8  8 ..., 18  8  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=   8.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.870227\tBest loss: 3.870227\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.864367\tBest loss: 3.864367\tAccuracy: 3.10%\n",
      "2\tValidation loss: 3.848597\tBest loss: 3.848597\tAccuracy: 3.30%\n",
      "3\tValidation loss: 3.822277\tBest loss: 3.822277\tAccuracy: 4.10%\n",
      "4\tValidation loss: 3.793731\tBest loss: 3.793731\tAccuracy: 3.50%\n",
      "5\tValidation loss: 3.788769\tBest loss: 3.788769\tAccuracy: 4.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 3.777524\tBest loss: 3.777524\tAccuracy: 4.70%\n",
      "7\tValidation loss: 3.794108\tBest loss: 3.777524\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.801579\tBest loss: 3.777524\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.793108\tBest loss: 3.777524\tAccuracy: 3.30%\n",
      "10\tValidation loss: 3.789934\tBest loss: 3.777524\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.757931\tBest loss: 3.757931\tAccuracy: 3.90%\n",
      "12\tValidation loss: 3.767739\tBest loss: 3.757931\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.710712\tBest loss: 3.710712\tAccuracy: 4.90%\n",
      "14\tValidation loss: 3.681789\tBest loss: 3.681789\tAccuracy: 6.20%\n",
      "15\tValidation loss: 3.674313\tBest loss: 3.674313\tAccuracy: 5.10%\n",
      "16\tValidation loss: 3.639849\tBest loss: 3.639849\tAccuracy: 5.30%\n",
      "17\tValidation loss: 3.651425\tBest loss: 3.639849\tAccuracy: 7.10%\n",
      "18\tValidation loss: 3.626245\tBest loss: 3.626245\tAccuracy: 7.40%\n",
      "19\tValidation loss: 3.621063\tBest loss: 3.621063\tAccuracy: 7.10%\n",
      "20\tValidation loss: 3.600175\tBest loss: 3.600175\tAccuracy: 6.20%\n",
      "21\tValidation loss: 3.718393\tBest loss: 3.600175\tAccuracy: 5.50%\n",
      "22\tValidation loss: 3.625634\tBest loss: 3.600175\tAccuracy: 6.60%\n",
      "23\tValidation loss: 3.578641\tBest loss: 3.578641\tAccuracy: 7.60%\n",
      "24\tValidation loss: 3.569263\tBest loss: 3.569263\tAccuracy: 7.70%\n",
      "25\tValidation loss: 3.593828\tBest loss: 3.569263\tAccuracy: 7.60%\n",
      "26\tValidation loss: 3.643247\tBest loss: 3.569263\tAccuracy: 7.10%\n",
      "27\tValidation loss: 3.578209\tBest loss: 3.569263\tAccuracy: 6.50%\n",
      "28\tValidation loss: 3.577604\tBest loss: 3.569263\tAccuracy: 6.40%\n",
      "29\tValidation loss: 3.569001\tBest loss: 3.569001\tAccuracy: 7.40%\n",
      "30\tValidation loss: 3.574576\tBest loss: 3.569001\tAccuracy: 6.80%\n",
      "31\tValidation loss: 3.572454\tBest loss: 3.569001\tAccuracy: 7.60%\n",
      "32\tValidation loss: 3.565207\tBest loss: 3.565207\tAccuracy: 6.30%\n",
      "33\tValidation loss: 3.527685\tBest loss: 3.527685\tAccuracy: 7.80%\n",
      "34\tValidation loss: 3.522237\tBest loss: 3.522237\tAccuracy: 5.70%\n",
      "35\tValidation loss: 3.527824\tBest loss: 3.522237\tAccuracy: 7.40%\n",
      "36\tValidation loss: 3.559041\tBest loss: 3.522237\tAccuracy: 7.60%\n",
      "37\tValidation loss: 3.514999\tBest loss: 3.514999\tAccuracy: 7.80%\n",
      "38\tValidation loss: 3.524925\tBest loss: 3.514999\tAccuracy: 7.70%\n",
      "39\tValidation loss: 3.710617\tBest loss: 3.514999\tAccuracy: 5.20%\n",
      "40\tValidation loss: 3.573907\tBest loss: 3.514999\tAccuracy: 7.20%\n",
      "41\tValidation loss: 3.520096\tBest loss: 3.514999\tAccuracy: 7.60%\n",
      "42\tValidation loss: 3.541322\tBest loss: 3.514999\tAccuracy: 6.90%\n",
      "43\tValidation loss: 3.631702\tBest loss: 3.514999\tAccuracy: 6.30%\n",
      "44\tValidation loss: 3.493975\tBest loss: 3.493975\tAccuracy: 7.70%\n",
      "45\tValidation loss: 3.502429\tBest loss: 3.493975\tAccuracy: 6.10%\n",
      "46\tValidation loss: 3.549971\tBest loss: 3.493975\tAccuracy: 7.80%\n",
      "47\tValidation loss: 3.509033\tBest loss: 3.493975\tAccuracy: 7.40%\n",
      "48\tValidation loss: 3.495936\tBest loss: 3.493975\tAccuracy: 7.20%\n",
      "49\tValidation loss: 3.500159\tBest loss: 3.493975\tAccuracy: 6.20%\n",
      "50\tValidation loss: 3.512940\tBest loss: 3.493975\tAccuracy: 6.30%\n",
      "51\tValidation loss: 3.550825\tBest loss: 3.493975\tAccuracy: 7.00%\n",
      "52\tValidation loss: 3.490932\tBest loss: 3.490932\tAccuracy: 6.00%\n",
      "53\tValidation loss: 3.611377\tBest loss: 3.490932\tAccuracy: 7.00%\n",
      "54\tValidation loss: 3.540635\tBest loss: 3.490932\tAccuracy: 7.20%\n",
      "55\tValidation loss: 3.504942\tBest loss: 3.490932\tAccuracy: 7.50%\n",
      "56\tValidation loss: 3.541125\tBest loss: 3.490932\tAccuracy: 7.50%\n",
      "57\tValidation loss: 3.572338\tBest loss: 3.490932\tAccuracy: 7.00%\n",
      "58\tValidation loss: 3.490863\tBest loss: 3.490863\tAccuracy: 6.30%\n",
      "59\tValidation loss: 3.498744\tBest loss: 3.490863\tAccuracy: 7.50%\n",
      "60\tValidation loss: 3.527998\tBest loss: 3.490863\tAccuracy: 7.90%\n",
      "61\tValidation loss: 3.502285\tBest loss: 3.490863\tAccuracy: 7.40%\n",
      "62\tValidation loss: 3.514702\tBest loss: 3.490863\tAccuracy: 6.30%\n",
      "63\tValidation loss: 3.504780\tBest loss: 3.490863\tAccuracy: 7.00%\n",
      "64\tValidation loss: 3.531209\tBest loss: 3.490863\tAccuracy: 7.10%\n",
      "65\tValidation loss: 3.479424\tBest loss: 3.479424\tAccuracy: 6.70%\n",
      "66\tValidation loss: 3.510639\tBest loss: 3.479424\tAccuracy: 7.50%\n",
      "67\tValidation loss: 3.495285\tBest loss: 3.479424\tAccuracy: 7.60%\n",
      "68\tValidation loss: 3.486719\tBest loss: 3.479424\tAccuracy: 6.50%\n",
      "69\tValidation loss: 3.488083\tBest loss: 3.479424\tAccuracy: 6.40%\n",
      "70\tValidation loss: 3.483249\tBest loss: 3.479424\tAccuracy: 7.90%\n",
      "71\tValidation loss: 3.536607\tBest loss: 3.479424\tAccuracy: 6.50%\n",
      "72\tValidation loss: 3.487118\tBest loss: 3.479424\tAccuracy: 5.90%\n",
      "73\tValidation loss: 3.526479\tBest loss: 3.479424\tAccuracy: 5.20%\n",
      "74\tValidation loss: 3.479247\tBest loss: 3.479247\tAccuracy: 7.30%\n",
      "75\tValidation loss: 3.478715\tBest loss: 3.478715\tAccuracy: 7.40%\n",
      "76\tValidation loss: 3.479357\tBest loss: 3.478715\tAccuracy: 7.40%\n",
      "77\tValidation loss: 3.472377\tBest loss: 3.472377\tAccuracy: 6.40%\n",
      "78\tValidation loss: 3.481741\tBest loss: 3.472377\tAccuracy: 7.70%\n",
      "79\tValidation loss: 3.500558\tBest loss: 3.472377\tAccuracy: 6.60%\n",
      "80\tValidation loss: 3.473714\tBest loss: 3.472377\tAccuracy: 7.70%\n",
      "81\tValidation loss: 3.485629\tBest loss: 3.472377\tAccuracy: 7.60%\n",
      "82\tValidation loss: 3.518563\tBest loss: 3.472377\tAccuracy: 5.40%\n",
      "83\tValidation loss: 3.464031\tBest loss: 3.464031\tAccuracy: 7.70%\n",
      "84\tValidation loss: 3.473427\tBest loss: 3.464031\tAccuracy: 7.60%\n",
      "85\tValidation loss: 3.475926\tBest loss: 3.464031\tAccuracy: 7.70%\n",
      "86\tValidation loss: 3.468897\tBest loss: 3.464031\tAccuracy: 5.90%\n",
      "87\tValidation loss: 3.456926\tBest loss: 3.456926\tAccuracy: 6.80%\n",
      "88\tValidation loss: 3.501057\tBest loss: 3.456926\tAccuracy: 6.20%\n",
      "89\tValidation loss: 3.458155\tBest loss: 3.456926\tAccuracy: 7.70%\n",
      "90\tValidation loss: 3.589242\tBest loss: 3.456926\tAccuracy: 4.60%\n",
      "91\tValidation loss: 3.450925\tBest loss: 3.450925\tAccuracy: 7.60%\n",
      "92\tValidation loss: 3.447729\tBest loss: 3.447729\tAccuracy: 7.60%\n",
      "93\tValidation loss: 3.471086\tBest loss: 3.447729\tAccuracy: 7.70%\n",
      "94\tValidation loss: 3.475511\tBest loss: 3.447729\tAccuracy: 7.90%\n",
      "95\tValidation loss: 3.472071\tBest loss: 3.447729\tAccuracy: 6.60%\n",
      "96\tValidation loss: 3.539956\tBest loss: 3.447729\tAccuracy: 7.20%\n",
      "97\tValidation loss: 3.480735\tBest loss: 3.447729\tAccuracy: 6.80%\n",
      "98\tValidation loss: 3.557019\tBest loss: 3.447729\tAccuracy: 6.20%\n",
      "99\tValidation loss: 3.492448\tBest loss: 3.447729\tAccuracy: 6.70%\n",
      "100\tValidation loss: 3.462376\tBest loss: 3.447729\tAccuracy: 7.40%\n",
      "101\tValidation loss: 3.477436\tBest loss: 3.447729\tAccuracy: 7.80%\n",
      "102\tValidation loss: 3.457439\tBest loss: 3.447729\tAccuracy: 7.80%\n",
      "103\tValidation loss: 3.454898\tBest loss: 3.447729\tAccuracy: 6.70%\n",
      "104\tValidation loss: 3.467585\tBest loss: 3.447729\tAccuracy: 7.30%\n",
      "105\tValidation loss: 3.455292\tBest loss: 3.447729\tAccuracy: 6.60%\n",
      "106\tValidation loss: 3.456510\tBest loss: 3.447729\tAccuracy: 6.60%\n",
      "107\tValidation loss: 3.463513\tBest loss: 3.447729\tAccuracy: 7.20%\n",
      "108\tValidation loss: 3.485335\tBest loss: 3.447729\tAccuracy: 6.70%\n",
      "109\tValidation loss: 3.486509\tBest loss: 3.447729\tAccuracy: 6.40%\n",
      "110\tValidation loss: 3.475390\tBest loss: 3.447729\tAccuracy: 7.80%\n",
      "111\tValidation loss: 3.519366\tBest loss: 3.447729\tAccuracy: 6.40%\n",
      "112\tValidation loss: 3.498271\tBest loss: 3.447729\tAccuracy: 7.40%\n",
      "113\tValidation loss: 3.499640\tBest loss: 3.447729\tAccuracy: 7.10%\n",
      "Early stopping!\n",
      "[[ 0.03190488  0.03454343  0.04010814 ...,  0.02139107  0.01567526\n",
      "   0.01173154]\n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]\n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]\n",
      " ..., \n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]\n",
      " [ 0.02426288  0.05252904  0.03010349 ...,  0.01431542  0.00799037\n",
      "   0.00514027]\n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]]\n",
      "[18  8  8 ...,  8 18  8]\n",
      "[[ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]\n",
      " [ 0.02426288  0.05252904  0.03010349 ...,  0.01431542  0.00799037\n",
      "   0.00514027]\n",
      " [ 0.02426288  0.05252904  0.03010349 ...,  0.01431542  0.00799037\n",
      "   0.00514027]\n",
      " ..., \n",
      " [ 0.02426288  0.05252904  0.03010349 ...,  0.01431542  0.00799037\n",
      "   0.00514027]\n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]\n",
      " [ 0.00440339  0.0078683   0.00813438 ...,  0.04854931  0.03389822\n",
      "   0.03581347]]\n",
      "[ 8 18 18 ..., 18  8  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=   9.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.887135\tBest loss: 3.887135\tAccuracy: 3.20%\n",
      "1\tValidation loss: 3.869406\tBest loss: 3.869406\tAccuracy: 3.80%\n",
      "2\tValidation loss: 3.852119\tBest loss: 3.852119\tAccuracy: 3.80%\n",
      "3\tValidation loss: 3.827560\tBest loss: 3.827560\tAccuracy: 4.40%\n",
      "4\tValidation loss: 3.803695\tBest loss: 3.803695\tAccuracy: 3.90%\n",
      "5\tValidation loss: 3.790221\tBest loss: 3.790221\tAccuracy: 4.00%\n",
      "6\tValidation loss: 3.779857\tBest loss: 3.779857\tAccuracy: 4.10%\n",
      "7\tValidation loss: 3.798512\tBest loss: 3.779857\tAccuracy: 3.40%\n",
      "8\tValidation loss: 3.796156\tBest loss: 3.779857\tAccuracy: 3.40%\n",
      "9\tValidation loss: 3.792816\tBest loss: 3.779857\tAccuracy: 4.00%\n",
      "10\tValidation loss: 3.791209\tBest loss: 3.779857\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.791276\tBest loss: 3.779857\tAccuracy: 3.50%\n",
      "12\tValidation loss: 3.793107\tBest loss: 3.779857\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.795765\tBest loss: 3.779857\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.771938\tBest loss: 3.771938\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.728977\tBest loss: 3.728977\tAccuracy: 6.40%\n",
      "16\tValidation loss: 3.812722\tBest loss: 3.728977\tAccuracy: 3.50%\n",
      "17\tValidation loss: 3.675833\tBest loss: 3.675833\tAccuracy: 7.10%\n",
      "18\tValidation loss: 3.653665\tBest loss: 3.653665\tAccuracy: 5.60%\n",
      "19\tValidation loss: 3.719488\tBest loss: 3.653665\tAccuracy: 5.40%\n",
      "20\tValidation loss: 3.637505\tBest loss: 3.637505\tAccuracy: 6.70%\n",
      "21\tValidation loss: 3.625490\tBest loss: 3.625490\tAccuracy: 7.20%\n",
      "22\tValidation loss: 3.635670\tBest loss: 3.625490\tAccuracy: 5.30%\n",
      "23\tValidation loss: 3.610851\tBest loss: 3.610851\tAccuracy: 7.40%\n",
      "24\tValidation loss: 3.617254\tBest loss: 3.610851\tAccuracy: 7.50%\n",
      "25\tValidation loss: 3.603359\tBest loss: 3.603359\tAccuracy: 7.30%\n",
      "26\tValidation loss: 3.592687\tBest loss: 3.592687\tAccuracy: 7.50%\n",
      "27\tValidation loss: 3.589090\tBest loss: 3.589090\tAccuracy: 5.90%\n",
      "28\tValidation loss: 3.584504\tBest loss: 3.584504\tAccuracy: 7.20%\n",
      "29\tValidation loss: 3.573946\tBest loss: 3.573946\tAccuracy: 7.40%\n",
      "30\tValidation loss: 3.573819\tBest loss: 3.573819\tAccuracy: 7.30%\n",
      "31\tValidation loss: 3.578531\tBest loss: 3.573819\tAccuracy: 7.40%\n",
      "32\tValidation loss: 3.569229\tBest loss: 3.569229\tAccuracy: 7.20%\n",
      "33\tValidation loss: 3.570455\tBest loss: 3.569229\tAccuracy: 5.60%\n",
      "34\tValidation loss: 3.590410\tBest loss: 3.569229\tAccuracy: 7.10%\n",
      "35\tValidation loss: 3.641516\tBest loss: 3.569229\tAccuracy: 5.90%\n",
      "36\tValidation loss: 3.544545\tBest loss: 3.544545\tAccuracy: 7.40%\n",
      "37\tValidation loss: 3.532725\tBest loss: 3.532725\tAccuracy: 7.50%\n",
      "38\tValidation loss: 3.554699\tBest loss: 3.532725\tAccuracy: 7.40%\n",
      "39\tValidation loss: 3.658956\tBest loss: 3.532725\tAccuracy: 5.50%\n",
      "40\tValidation loss: 3.534184\tBest loss: 3.532725\tAccuracy: 6.30%\n",
      "41\tValidation loss: 3.565598\tBest loss: 3.532725\tAccuracy: 6.70%\n",
      "42\tValidation loss: 3.577288\tBest loss: 3.532725\tAccuracy: 6.40%\n",
      "43\tValidation loss: 3.543948\tBest loss: 3.532725\tAccuracy: 6.80%\n",
      "44\tValidation loss: 3.542238\tBest loss: 3.532725\tAccuracy: 6.80%\n",
      "45\tValidation loss: 3.529982\tBest loss: 3.529982\tAccuracy: 6.20%\n",
      "46\tValidation loss: 3.529427\tBest loss: 3.529427\tAccuracy: 7.00%\n",
      "47\tValidation loss: 3.521583\tBest loss: 3.521583\tAccuracy: 7.10%\n",
      "48\tValidation loss: 3.518583\tBest loss: 3.518583\tAccuracy: 5.90%\n",
      "49\tValidation loss: 3.558874\tBest loss: 3.518583\tAccuracy: 7.10%\n",
      "50\tValidation loss: 3.538530\tBest loss: 3.518583\tAccuracy: 5.60%\n",
      "51\tValidation loss: 3.535311\tBest loss: 3.518583\tAccuracy: 7.00%\n",
      "52\tValidation loss: 3.517776\tBest loss: 3.517776\tAccuracy: 7.00%\n",
      "53\tValidation loss: 3.534837\tBest loss: 3.517776\tAccuracy: 6.10%\n",
      "54\tValidation loss: 3.525075\tBest loss: 3.517776\tAccuracy: 7.40%\n",
      "55\tValidation loss: 3.514186\tBest loss: 3.514186\tAccuracy: 5.60%\n",
      "56\tValidation loss: 3.513029\tBest loss: 3.513029\tAccuracy: 7.20%\n",
      "57\tValidation loss: 3.488597\tBest loss: 3.488597\tAccuracy: 7.30%\n",
      "58\tValidation loss: 3.507094\tBest loss: 3.488597\tAccuracy: 7.10%\n",
      "59\tValidation loss: 3.510103\tBest loss: 3.488597\tAccuracy: 6.10%\n",
      "60\tValidation loss: 3.526798\tBest loss: 3.488597\tAccuracy: 7.30%\n",
      "61\tValidation loss: 3.505401\tBest loss: 3.488597\tAccuracy: 7.30%\n",
      "62\tValidation loss: 3.520411\tBest loss: 3.488597\tAccuracy: 6.20%\n",
      "63\tValidation loss: 3.534007\tBest loss: 3.488597\tAccuracy: 7.50%\n",
      "64\tValidation loss: 3.505822\tBest loss: 3.488597\tAccuracy: 6.70%\n",
      "65\tValidation loss: 3.518523\tBest loss: 3.488597\tAccuracy: 7.70%\n",
      "66\tValidation loss: 3.506595\tBest loss: 3.488597\tAccuracy: 7.50%\n",
      "67\tValidation loss: 3.534285\tBest loss: 3.488597\tAccuracy: 7.00%\n",
      "68\tValidation loss: 3.532221\tBest loss: 3.488597\tAccuracy: 7.80%\n",
      "69\tValidation loss: 3.556024\tBest loss: 3.488597\tAccuracy: 6.20%\n",
      "70\tValidation loss: 3.522557\tBest loss: 3.488597\tAccuracy: 7.40%\n",
      "71\tValidation loss: 3.502053\tBest loss: 3.488597\tAccuracy: 7.40%\n",
      "72\tValidation loss: 3.488132\tBest loss: 3.488132\tAccuracy: 7.40%\n",
      "73\tValidation loss: 3.503345\tBest loss: 3.488132\tAccuracy: 6.20%\n",
      "74\tValidation loss: 3.506970\tBest loss: 3.488132\tAccuracy: 7.40%\n",
      "75\tValidation loss: 3.491591\tBest loss: 3.488132\tAccuracy: 7.30%\n",
      "76\tValidation loss: 3.495169\tBest loss: 3.488132\tAccuracy: 7.30%\n",
      "77\tValidation loss: 3.509409\tBest loss: 3.488132\tAccuracy: 6.00%\n",
      "78\tValidation loss: 3.486152\tBest loss: 3.486152\tAccuracy: 7.30%\n",
      "79\tValidation loss: 3.519848\tBest loss: 3.486152\tAccuracy: 6.30%\n",
      "80\tValidation loss: 3.497992\tBest loss: 3.486152\tAccuracy: 6.90%\n",
      "81\tValidation loss: 3.493408\tBest loss: 3.486152\tAccuracy: 5.60%\n",
      "82\tValidation loss: 3.530017\tBest loss: 3.486152\tAccuracy: 7.10%\n",
      "83\tValidation loss: 3.490820\tBest loss: 3.486152\tAccuracy: 7.40%\n",
      "84\tValidation loss: 3.487533\tBest loss: 3.486152\tAccuracy: 5.40%\n",
      "85\tValidation loss: 3.490423\tBest loss: 3.486152\tAccuracy: 7.70%\n",
      "86\tValidation loss: 3.518385\tBest loss: 3.486152\tAccuracy: 7.40%\n",
      "87\tValidation loss: 3.495281\tBest loss: 3.486152\tAccuracy: 7.40%\n",
      "88\tValidation loss: 3.498453\tBest loss: 3.486152\tAccuracy: 7.40%\n",
      "89\tValidation loss: 3.499131\tBest loss: 3.486152\tAccuracy: 7.60%\n",
      "90\tValidation loss: 3.503544\tBest loss: 3.486152\tAccuracy: 7.70%\n",
      "91\tValidation loss: 3.504196\tBest loss: 3.486152\tAccuracy: 6.40%\n",
      "92\tValidation loss: 3.516211\tBest loss: 3.486152\tAccuracy: 5.30%\n",
      "93\tValidation loss: 3.541994\tBest loss: 3.486152\tAccuracy: 7.50%\n",
      "94\tValidation loss: 3.490316\tBest loss: 3.486152\tAccuracy: 6.30%\n",
      "95\tValidation loss: 3.532536\tBest loss: 3.486152\tAccuracy: 7.40%\n",
      "96\tValidation loss: 3.505127\tBest loss: 3.486152\tAccuracy: 6.40%\n",
      "97\tValidation loss: 3.489126\tBest loss: 3.486152\tAccuracy: 7.50%\n",
      "98\tValidation loss: 3.486591\tBest loss: 3.486152\tAccuracy: 7.20%\n",
      "99\tValidation loss: 3.514599\tBest loss: 3.486152\tAccuracy: 7.10%\n",
      "Early stopping!\n",
      "[[ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]\n",
      " [ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]\n",
      " [ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]\n",
      " ..., \n",
      " [ 0.02452443  0.05069714  0.03317318 ...,  0.01495819  0.0083362\n",
      "   0.00625022]\n",
      " [ 0.00468705  0.0091516   0.00814442 ...,  0.04672516  0.03253784\n",
      "   0.03035377]\n",
      " [ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]]\n",
      "[ 8  8  8 ..., 18  8  8]\n",
      "[[ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]\n",
      " [ 0.02452443  0.05069714  0.03317318 ...,  0.01495819  0.0083362\n",
      "   0.00625022]\n",
      " [ 0.02452443  0.05069714  0.03317318 ...,  0.01495819  0.0083362\n",
      "   0.00625022]\n",
      " ..., \n",
      " [ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]\n",
      " [ 0.02452443  0.05069714  0.03317318 ...,  0.01495819  0.0083362\n",
      "   0.00625022]\n",
      " [ 0.00463673  0.00905514  0.0080971  ...,  0.04674236  0.03256987\n",
      "   0.03041097]]\n",
      "[ 8 18 18 ...,  8 18  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=   8.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.924964\tBest loss: 3.924964\tAccuracy: 5.50%\n",
      "1\tValidation loss: 3.926509\tBest loss: 3.924964\tAccuracy: 4.40%\n",
      "2\tValidation loss: 3.688016\tBest loss: 3.688016\tAccuracy: 8.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\tValidation loss: 3.660600\tBest loss: 3.660600\tAccuracy: 6.70%\n",
      "4\tValidation loss: 3.640182\tBest loss: 3.640182\tAccuracy: 7.30%\n",
      "5\tValidation loss: 3.603460\tBest loss: 3.603460\tAccuracy: 8.50%\n",
      "6\tValidation loss: 3.556797\tBest loss: 3.556797\tAccuracy: 9.40%\n",
      "7\tValidation loss: 3.603650\tBest loss: 3.556797\tAccuracy: 6.30%\n",
      "8\tValidation loss: 3.560251\tBest loss: 3.556797\tAccuracy: 6.40%\n",
      "9\tValidation loss: 3.536266\tBest loss: 3.536266\tAccuracy: 6.60%\n",
      "10\tValidation loss: 3.531629\tBest loss: 3.531629\tAccuracy: 6.90%\n",
      "11\tValidation loss: 3.493387\tBest loss: 3.493387\tAccuracy: 11.10%\n",
      "12\tValidation loss: 3.462551\tBest loss: 3.462551\tAccuracy: 8.20%\n",
      "13\tValidation loss: 3.431289\tBest loss: 3.431289\tAccuracy: 12.30%\n",
      "14\tValidation loss: 3.425356\tBest loss: 3.425356\tAccuracy: 13.80%\n",
      "15\tValidation loss: 3.377425\tBest loss: 3.377425\tAccuracy: 11.90%\n",
      "16\tValidation loss: 3.383329\tBest loss: 3.377425\tAccuracy: 14.70%\n",
      "17\tValidation loss: 3.331446\tBest loss: 3.331446\tAccuracy: 13.60%\n",
      "18\tValidation loss: 3.335055\tBest loss: 3.331446\tAccuracy: 14.30%\n",
      "19\tValidation loss: 3.285427\tBest loss: 3.285427\tAccuracy: 15.20%\n",
      "20\tValidation loss: 3.319851\tBest loss: 3.285427\tAccuracy: 11.60%\n",
      "21\tValidation loss: 3.249236\tBest loss: 3.249236\tAccuracy: 17.60%\n",
      "22\tValidation loss: 3.300498\tBest loss: 3.249236\tAccuracy: 14.80%\n",
      "23\tValidation loss: 3.212447\tBest loss: 3.212447\tAccuracy: 14.90%\n",
      "24\tValidation loss: 3.189768\tBest loss: 3.189768\tAccuracy: 16.80%\n",
      "25\tValidation loss: 3.178526\tBest loss: 3.178526\tAccuracy: 16.70%\n",
      "26\tValidation loss: 3.146887\tBest loss: 3.146887\tAccuracy: 17.00%\n",
      "27\tValidation loss: 3.147252\tBest loss: 3.146887\tAccuracy: 19.10%\n",
      "28\tValidation loss: 3.098367\tBest loss: 3.098367\tAccuracy: 17.00%\n",
      "29\tValidation loss: 3.098373\tBest loss: 3.098367\tAccuracy: 18.90%\n",
      "30\tValidation loss: 3.030856\tBest loss: 3.030856\tAccuracy: 19.30%\n",
      "31\tValidation loss: 3.001981\tBest loss: 3.001981\tAccuracy: 20.20%\n",
      "32\tValidation loss: 2.976987\tBest loss: 2.976987\tAccuracy: 21.60%\n",
      "33\tValidation loss: 2.931073\tBest loss: 2.931073\tAccuracy: 24.00%\n",
      "34\tValidation loss: 2.934366\tBest loss: 2.931073\tAccuracy: 22.80%\n",
      "35\tValidation loss: 2.915217\tBest loss: 2.915217\tAccuracy: 22.70%\n",
      "36\tValidation loss: 2.942966\tBest loss: 2.915217\tAccuracy: 22.10%\n",
      "37\tValidation loss: 2.842540\tBest loss: 2.842540\tAccuracy: 23.00%\n",
      "38\tValidation loss: 2.859081\tBest loss: 2.842540\tAccuracy: 24.80%\n",
      "39\tValidation loss: 2.793135\tBest loss: 2.793135\tAccuracy: 26.60%\n",
      "40\tValidation loss: 2.782463\tBest loss: 2.782463\tAccuracy: 25.00%\n",
      "41\tValidation loss: 2.743082\tBest loss: 2.743082\tAccuracy: 27.50%\n",
      "42\tValidation loss: 2.703536\tBest loss: 2.703536\tAccuracy: 27.70%\n",
      "43\tValidation loss: 2.749084\tBest loss: 2.703536\tAccuracy: 25.70%\n",
      "44\tValidation loss: 2.667031\tBest loss: 2.667031\tAccuracy: 26.20%\n",
      "45\tValidation loss: 2.643253\tBest loss: 2.643253\tAccuracy: 31.40%\n",
      "46\tValidation loss: 2.649479\tBest loss: 2.643253\tAccuracy: 29.40%\n",
      "47\tValidation loss: 2.596092\tBest loss: 2.596092\tAccuracy: 28.80%\n",
      "48\tValidation loss: 2.598314\tBest loss: 2.596092\tAccuracy: 29.10%\n",
      "49\tValidation loss: 2.549081\tBest loss: 2.549081\tAccuracy: 33.30%\n",
      "50\tValidation loss: 2.530135\tBest loss: 2.530135\tAccuracy: 31.30%\n",
      "51\tValidation loss: 2.523539\tBest loss: 2.523539\tAccuracy: 31.10%\n",
      "52\tValidation loss: 2.517432\tBest loss: 2.517432\tAccuracy: 31.60%\n",
      "53\tValidation loss: 2.470345\tBest loss: 2.470345\tAccuracy: 34.20%\n",
      "54\tValidation loss: 2.475318\tBest loss: 2.470345\tAccuracy: 32.20%\n",
      "55\tValidation loss: 2.400273\tBest loss: 2.400273\tAccuracy: 35.50%\n",
      "56\tValidation loss: 2.401654\tBest loss: 2.400273\tAccuracy: 34.50%\n",
      "57\tValidation loss: 2.372476\tBest loss: 2.372476\tAccuracy: 35.80%\n",
      "58\tValidation loss: 2.346185\tBest loss: 2.346185\tAccuracy: 38.90%\n",
      "59\tValidation loss: 2.324071\tBest loss: 2.324071\tAccuracy: 36.60%\n",
      "60\tValidation loss: 2.315237\tBest loss: 2.315237\tAccuracy: 37.80%\n",
      "61\tValidation loss: 2.257575\tBest loss: 2.257575\tAccuracy: 41.00%\n",
      "62\tValidation loss: 2.265943\tBest loss: 2.257575\tAccuracy: 39.20%\n",
      "63\tValidation loss: 2.229546\tBest loss: 2.229546\tAccuracy: 40.90%\n",
      "64\tValidation loss: 2.254863\tBest loss: 2.229546\tAccuracy: 37.90%\n",
      "65\tValidation loss: 2.219419\tBest loss: 2.219419\tAccuracy: 39.40%\n",
      "66\tValidation loss: 2.185284\tBest loss: 2.185284\tAccuracy: 40.50%\n",
      "67\tValidation loss: 2.177066\tBest loss: 2.177066\tAccuracy: 41.90%\n",
      "68\tValidation loss: 2.179863\tBest loss: 2.177066\tAccuracy: 42.20%\n",
      "69\tValidation loss: 2.183331\tBest loss: 2.177066\tAccuracy: 40.40%\n",
      "70\tValidation loss: 2.169520\tBest loss: 2.169520\tAccuracy: 40.70%\n",
      "71\tValidation loss: 2.126059\tBest loss: 2.126059\tAccuracy: 41.50%\n",
      "72\tValidation loss: 2.123832\tBest loss: 2.123832\tAccuracy: 42.30%\n",
      "73\tValidation loss: 2.120044\tBest loss: 2.120044\tAccuracy: 43.00%\n",
      "74\tValidation loss: 2.092044\tBest loss: 2.092044\tAccuracy: 43.20%\n",
      "75\tValidation loss: 2.101680\tBest loss: 2.092044\tAccuracy: 42.20%\n",
      "76\tValidation loss: 2.111247\tBest loss: 2.092044\tAccuracy: 44.30%\n",
      "77\tValidation loss: 2.027956\tBest loss: 2.027956\tAccuracy: 45.00%\n",
      "78\tValidation loss: 2.035731\tBest loss: 2.027956\tAccuracy: 44.50%\n",
      "79\tValidation loss: 2.006580\tBest loss: 2.006580\tAccuracy: 47.90%\n",
      "80\tValidation loss: 2.031365\tBest loss: 2.006580\tAccuracy: 45.10%\n",
      "81\tValidation loss: 1.987622\tBest loss: 1.987622\tAccuracy: 46.40%\n",
      "82\tValidation loss: 2.010193\tBest loss: 1.987622\tAccuracy: 47.00%\n",
      "83\tValidation loss: 1.942559\tBest loss: 1.942559\tAccuracy: 47.90%\n",
      "84\tValidation loss: 1.926249\tBest loss: 1.926249\tAccuracy: 47.20%\n",
      "85\tValidation loss: 1.955456\tBest loss: 1.926249\tAccuracy: 45.80%\n",
      "86\tValidation loss: 1.976493\tBest loss: 1.926249\tAccuracy: 46.10%\n",
      "87\tValidation loss: 1.976972\tBest loss: 1.926249\tAccuracy: 46.60%\n",
      "88\tValidation loss: 1.899004\tBest loss: 1.899004\tAccuracy: 48.10%\n",
      "89\tValidation loss: 1.884664\tBest loss: 1.884664\tAccuracy: 49.30%\n",
      "90\tValidation loss: 1.848544\tBest loss: 1.848544\tAccuracy: 51.70%\n",
      "91\tValidation loss: 1.888385\tBest loss: 1.848544\tAccuracy: 49.00%\n",
      "92\tValidation loss: 1.880090\tBest loss: 1.848544\tAccuracy: 50.00%\n",
      "93\tValidation loss: 1.839981\tBest loss: 1.839981\tAccuracy: 48.70%\n",
      "94\tValidation loss: 1.854032\tBest loss: 1.839981\tAccuracy: 49.60%\n",
      "95\tValidation loss: 1.844457\tBest loss: 1.839981\tAccuracy: 50.10%\n",
      "96\tValidation loss: 1.892846\tBest loss: 1.839981\tAccuracy: 49.00%\n",
      "97\tValidation loss: 1.865740\tBest loss: 1.839981\tAccuracy: 50.40%\n",
      "98\tValidation loss: 1.812015\tBest loss: 1.812015\tAccuracy: 51.60%\n",
      "99\tValidation loss: 1.846364\tBest loss: 1.812015\tAccuracy: 48.10%\n",
      "100\tValidation loss: 1.832978\tBest loss: 1.812015\tAccuracy: 50.50%\n",
      "101\tValidation loss: 1.785224\tBest loss: 1.785224\tAccuracy: 51.00%\n",
      "102\tValidation loss: 1.811639\tBest loss: 1.785224\tAccuracy: 52.30%\n",
      "103\tValidation loss: 1.767075\tBest loss: 1.767075\tAccuracy: 52.30%\n",
      "104\tValidation loss: 1.767394\tBest loss: 1.767075\tAccuracy: 51.80%\n",
      "105\tValidation loss: 1.820511\tBest loss: 1.767075\tAccuracy: 50.80%\n",
      "106\tValidation loss: 1.727509\tBest loss: 1.727509\tAccuracy: 53.50%\n",
      "107\tValidation loss: 1.791240\tBest loss: 1.727509\tAccuracy: 53.60%\n",
      "108\tValidation loss: 1.712253\tBest loss: 1.712253\tAccuracy: 52.70%\n",
      "109\tValidation loss: 1.750037\tBest loss: 1.712253\tAccuracy: 51.60%\n",
      "110\tValidation loss: 1.713429\tBest loss: 1.712253\tAccuracy: 53.20%\n",
      "111\tValidation loss: 1.696178\tBest loss: 1.696178\tAccuracy: 55.70%\n",
      "112\tValidation loss: 1.785212\tBest loss: 1.696178\tAccuracy: 49.60%\n",
      "113\tValidation loss: 1.701966\tBest loss: 1.696178\tAccuracy: 54.10%\n",
      "114\tValidation loss: 1.681041\tBest loss: 1.681041\tAccuracy: 56.40%\n",
      "115\tValidation loss: 1.666195\tBest loss: 1.666195\tAccuracy: 53.70%\n",
      "116\tValidation loss: 1.680777\tBest loss: 1.666195\tAccuracy: 53.50%\n",
      "117\tValidation loss: 1.689173\tBest loss: 1.666195\tAccuracy: 54.20%\n",
      "118\tValidation loss: 1.668523\tBest loss: 1.666195\tAccuracy: 54.60%\n",
      "119\tValidation loss: 1.703091\tBest loss: 1.666195\tAccuracy: 54.00%\n",
      "120\tValidation loss: 1.642840\tBest loss: 1.642840\tAccuracy: 55.10%\n",
      "121\tValidation loss: 1.645576\tBest loss: 1.642840\tAccuracy: 54.80%\n",
      "122\tValidation loss: 1.637305\tBest loss: 1.637305\tAccuracy: 55.70%\n",
      "123\tValidation loss: 1.673558\tBest loss: 1.637305\tAccuracy: 53.10%\n",
      "124\tValidation loss: 1.671367\tBest loss: 1.637305\tAccuracy: 55.70%\n",
      "125\tValidation loss: 1.643469\tBest loss: 1.637305\tAccuracy: 56.20%\n",
      "126\tValidation loss: 1.641711\tBest loss: 1.637305\tAccuracy: 55.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\tValidation loss: 1.631515\tBest loss: 1.631515\tAccuracy: 53.80%\n",
      "128\tValidation loss: 1.612535\tBest loss: 1.612535\tAccuracy: 56.60%\n",
      "129\tValidation loss: 1.630519\tBest loss: 1.612535\tAccuracy: 56.40%\n",
      "130\tValidation loss: 1.592516\tBest loss: 1.592516\tAccuracy: 57.10%\n",
      "131\tValidation loss: 1.584136\tBest loss: 1.584136\tAccuracy: 57.00%\n",
      "132\tValidation loss: 1.579131\tBest loss: 1.579131\tAccuracy: 57.40%\n",
      "133\tValidation loss: 1.573358\tBest loss: 1.573358\tAccuracy: 56.00%\n",
      "134\tValidation loss: 1.573103\tBest loss: 1.573103\tAccuracy: 57.00%\n",
      "135\tValidation loss: 1.559229\tBest loss: 1.559229\tAccuracy: 58.00%\n",
      "136\tValidation loss: 1.571367\tBest loss: 1.559229\tAccuracy: 54.80%\n",
      "137\tValidation loss: 1.548169\tBest loss: 1.548169\tAccuracy: 58.90%\n",
      "138\tValidation loss: 1.571357\tBest loss: 1.548169\tAccuracy: 57.00%\n",
      "139\tValidation loss: 1.629850\tBest loss: 1.548169\tAccuracy: 53.80%\n",
      "140\tValidation loss: 1.552406\tBest loss: 1.548169\tAccuracy: 56.40%\n",
      "141\tValidation loss: 1.557236\tBest loss: 1.548169\tAccuracy: 58.10%\n",
      "142\tValidation loss: 1.544900\tBest loss: 1.544900\tAccuracy: 57.30%\n",
      "143\tValidation loss: 1.542216\tBest loss: 1.542216\tAccuracy: 57.80%\n",
      "144\tValidation loss: 1.500683\tBest loss: 1.500683\tAccuracy: 60.30%\n",
      "145\tValidation loss: 1.529735\tBest loss: 1.500683\tAccuracy: 58.40%\n",
      "146\tValidation loss: 1.507545\tBest loss: 1.500683\tAccuracy: 57.40%\n",
      "147\tValidation loss: 1.536454\tBest loss: 1.500683\tAccuracy: 56.90%\n",
      "148\tValidation loss: 1.533376\tBest loss: 1.500683\tAccuracy: 59.60%\n",
      "149\tValidation loss: 1.502521\tBest loss: 1.500683\tAccuracy: 58.10%\n",
      "150\tValidation loss: 1.472583\tBest loss: 1.472583\tAccuracy: 60.10%\n",
      "151\tValidation loss: 1.467538\tBest loss: 1.467538\tAccuracy: 60.90%\n",
      "152\tValidation loss: 1.526492\tBest loss: 1.467538\tAccuracy: 60.10%\n",
      "153\tValidation loss: 1.502209\tBest loss: 1.467538\tAccuracy: 59.00%\n",
      "154\tValidation loss: 1.455395\tBest loss: 1.455395\tAccuracy: 60.20%\n",
      "155\tValidation loss: 1.479012\tBest loss: 1.455395\tAccuracy: 59.40%\n",
      "156\tValidation loss: 1.469761\tBest loss: 1.455395\tAccuracy: 59.60%\n",
      "157\tValidation loss: 1.472100\tBest loss: 1.455395\tAccuracy: 58.60%\n",
      "158\tValidation loss: 1.458468\tBest loss: 1.455395\tAccuracy: 62.50%\n",
      "159\tValidation loss: 1.445081\tBest loss: 1.445081\tAccuracy: 62.10%\n",
      "160\tValidation loss: 1.458310\tBest loss: 1.445081\tAccuracy: 59.60%\n",
      "161\tValidation loss: 1.437013\tBest loss: 1.437013\tAccuracy: 61.70%\n",
      "162\tValidation loss: 1.441750\tBest loss: 1.437013\tAccuracy: 62.00%\n",
      "163\tValidation loss: 1.471437\tBest loss: 1.437013\tAccuracy: 59.70%\n",
      "164\tValidation loss: 1.410124\tBest loss: 1.410124\tAccuracy: 61.30%\n",
      "165\tValidation loss: 1.412462\tBest loss: 1.410124\tAccuracy: 61.80%\n",
      "166\tValidation loss: 1.424992\tBest loss: 1.410124\tAccuracy: 62.40%\n",
      "167\tValidation loss: 1.449691\tBest loss: 1.410124\tAccuracy: 61.00%\n",
      "168\tValidation loss: 1.426682\tBest loss: 1.410124\tAccuracy: 62.60%\n",
      "169\tValidation loss: 1.421425\tBest loss: 1.410124\tAccuracy: 63.10%\n",
      "170\tValidation loss: 1.416015\tBest loss: 1.410124\tAccuracy: 60.50%\n",
      "171\tValidation loss: 1.390285\tBest loss: 1.390285\tAccuracy: 63.20%\n",
      "172\tValidation loss: 1.422130\tBest loss: 1.390285\tAccuracy: 61.40%\n",
      "173\tValidation loss: 1.418589\tBest loss: 1.390285\tAccuracy: 62.20%\n",
      "174\tValidation loss: 1.400887\tBest loss: 1.390285\tAccuracy: 62.10%\n",
      "175\tValidation loss: 1.388482\tBest loss: 1.388482\tAccuracy: 62.60%\n",
      "176\tValidation loss: 1.385536\tBest loss: 1.385536\tAccuracy: 63.10%\n",
      "177\tValidation loss: 1.394147\tBest loss: 1.385536\tAccuracy: 62.70%\n",
      "178\tValidation loss: 1.363857\tBest loss: 1.363857\tAccuracy: 64.00%\n",
      "179\tValidation loss: 1.383501\tBest loss: 1.363857\tAccuracy: 63.70%\n",
      "180\tValidation loss: 1.355423\tBest loss: 1.355423\tAccuracy: 65.40%\n",
      "181\tValidation loss: 1.380437\tBest loss: 1.355423\tAccuracy: 63.30%\n",
      "182\tValidation loss: 1.411552\tBest loss: 1.355423\tAccuracy: 61.90%\n",
      "183\tValidation loss: 1.378027\tBest loss: 1.355423\tAccuracy: 64.80%\n",
      "184\tValidation loss: 1.411059\tBest loss: 1.355423\tAccuracy: 63.70%\n",
      "185\tValidation loss: 1.376958\tBest loss: 1.355423\tAccuracy: 63.30%\n",
      "186\tValidation loss: 1.393685\tBest loss: 1.355423\tAccuracy: 61.50%\n",
      "187\tValidation loss: 1.393950\tBest loss: 1.355423\tAccuracy: 61.50%\n",
      "188\tValidation loss: 1.365286\tBest loss: 1.355423\tAccuracy: 63.70%\n",
      "189\tValidation loss: 1.365214\tBest loss: 1.355423\tAccuracy: 62.50%\n",
      "190\tValidation loss: 1.345506\tBest loss: 1.345506\tAccuracy: 63.10%\n",
      "191\tValidation loss: 1.331108\tBest loss: 1.331108\tAccuracy: 64.70%\n",
      "192\tValidation loss: 1.342868\tBest loss: 1.331108\tAccuracy: 63.70%\n",
      "193\tValidation loss: 1.325268\tBest loss: 1.325268\tAccuracy: 63.60%\n",
      "194\tValidation loss: 1.360385\tBest loss: 1.325268\tAccuracy: 65.90%\n",
      "195\tValidation loss: 1.357036\tBest loss: 1.325268\tAccuracy: 62.00%\n",
      "196\tValidation loss: 1.328192\tBest loss: 1.325268\tAccuracy: 64.20%\n",
      "197\tValidation loss: 1.323711\tBest loss: 1.323711\tAccuracy: 63.60%\n",
      "198\tValidation loss: 1.389864\tBest loss: 1.323711\tAccuracy: 62.60%\n",
      "199\tValidation loss: 1.361586\tBest loss: 1.323711\tAccuracy: 63.80%\n",
      "200\tValidation loss: 1.363201\tBest loss: 1.323711\tAccuracy: 63.50%\n",
      "201\tValidation loss: 1.319106\tBest loss: 1.319106\tAccuracy: 64.40%\n",
      "202\tValidation loss: 1.320920\tBest loss: 1.319106\tAccuracy: 65.20%\n",
      "203\tValidation loss: 1.333200\tBest loss: 1.319106\tAccuracy: 64.50%\n",
      "204\tValidation loss: 1.302004\tBest loss: 1.302004\tAccuracy: 66.10%\n",
      "205\tValidation loss: 1.331334\tBest loss: 1.302004\tAccuracy: 65.50%\n",
      "206\tValidation loss: 1.343005\tBest loss: 1.302004\tAccuracy: 63.50%\n",
      "207\tValidation loss: 1.303780\tBest loss: 1.302004\tAccuracy: 65.20%\n",
      "208\tValidation loss: 1.318853\tBest loss: 1.302004\tAccuracy: 62.50%\n",
      "209\tValidation loss: 1.294871\tBest loss: 1.294871\tAccuracy: 65.50%\n",
      "210\tValidation loss: 1.342875\tBest loss: 1.294871\tAccuracy: 62.30%\n",
      "211\tValidation loss: 1.313556\tBest loss: 1.294871\tAccuracy: 64.30%\n",
      "212\tValidation loss: 1.314608\tBest loss: 1.294871\tAccuracy: 66.40%\n",
      "213\tValidation loss: 1.302695\tBest loss: 1.294871\tAccuracy: 62.80%\n",
      "214\tValidation loss: 1.284204\tBest loss: 1.284204\tAccuracy: 66.40%\n",
      "215\tValidation loss: 1.302227\tBest loss: 1.284204\tAccuracy: 65.00%\n",
      "216\tValidation loss: 1.275187\tBest loss: 1.275187\tAccuracy: 65.20%\n",
      "217\tValidation loss: 1.296825\tBest loss: 1.275187\tAccuracy: 65.10%\n",
      "218\tValidation loss: 1.308063\tBest loss: 1.275187\tAccuracy: 66.20%\n",
      "219\tValidation loss: 1.268551\tBest loss: 1.268551\tAccuracy: 66.40%\n",
      "220\tValidation loss: 1.261041\tBest loss: 1.261041\tAccuracy: 66.80%\n",
      "221\tValidation loss: 1.301166\tBest loss: 1.261041\tAccuracy: 66.70%\n",
      "222\tValidation loss: 1.282234\tBest loss: 1.261041\tAccuracy: 65.60%\n",
      "223\tValidation loss: 1.302790\tBest loss: 1.261041\tAccuracy: 65.80%\n",
      "224\tValidation loss: 1.277550\tBest loss: 1.261041\tAccuracy: 65.80%\n",
      "225\tValidation loss: 1.299946\tBest loss: 1.261041\tAccuracy: 64.30%\n",
      "226\tValidation loss: 1.273005\tBest loss: 1.261041\tAccuracy: 63.80%\n",
      "227\tValidation loss: 1.268219\tBest loss: 1.261041\tAccuracy: 65.10%\n",
      "228\tValidation loss: 1.252416\tBest loss: 1.252416\tAccuracy: 66.80%\n",
      "229\tValidation loss: 1.265321\tBest loss: 1.252416\tAccuracy: 64.80%\n",
      "230\tValidation loss: 1.270763\tBest loss: 1.252416\tAccuracy: 65.10%\n",
      "231\tValidation loss: 1.252396\tBest loss: 1.252396\tAccuracy: 66.50%\n",
      "232\tValidation loss: 1.268177\tBest loss: 1.252396\tAccuracy: 65.50%\n",
      "233\tValidation loss: 1.257182\tBest loss: 1.252396\tAccuracy: 65.80%\n",
      "234\tValidation loss: 1.241563\tBest loss: 1.241563\tAccuracy: 66.00%\n",
      "235\tValidation loss: 1.314700\tBest loss: 1.241563\tAccuracy: 65.90%\n",
      "236\tValidation loss: 1.301961\tBest loss: 1.241563\tAccuracy: 65.20%\n",
      "237\tValidation loss: 1.262579\tBest loss: 1.241563\tAccuracy: 65.70%\n",
      "238\tValidation loss: 1.248429\tBest loss: 1.241563\tAccuracy: 66.50%\n",
      "239\tValidation loss: 1.285352\tBest loss: 1.241563\tAccuracy: 64.30%\n",
      "240\tValidation loss: 1.239833\tBest loss: 1.239833\tAccuracy: 65.50%\n",
      "241\tValidation loss: 1.257627\tBest loss: 1.239833\tAccuracy: 65.40%\n",
      "242\tValidation loss: 1.239416\tBest loss: 1.239416\tAccuracy: 67.90%\n",
      "243\tValidation loss: 1.230841\tBest loss: 1.230841\tAccuracy: 66.80%\n",
      "244\tValidation loss: 1.250756\tBest loss: 1.230841\tAccuracy: 65.80%\n",
      "245\tValidation loss: 1.236105\tBest loss: 1.230841\tAccuracy: 67.00%\n",
      "246\tValidation loss: 1.223783\tBest loss: 1.223783\tAccuracy: 66.90%\n",
      "247\tValidation loss: 1.230486\tBest loss: 1.223783\tAccuracy: 67.20%\n",
      "248\tValidation loss: 1.221375\tBest loss: 1.221375\tAccuracy: 67.80%\n",
      "249\tValidation loss: 1.208047\tBest loss: 1.208047\tAccuracy: 67.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 1.221060\tBest loss: 1.208047\tAccuracy: 67.00%\n",
      "251\tValidation loss: 1.225251\tBest loss: 1.208047\tAccuracy: 67.20%\n",
      "252\tValidation loss: 1.241462\tBest loss: 1.208047\tAccuracy: 67.10%\n",
      "253\tValidation loss: 1.210899\tBest loss: 1.208047\tAccuracy: 66.00%\n",
      "254\tValidation loss: 1.205659\tBest loss: 1.205659\tAccuracy: 67.90%\n",
      "255\tValidation loss: 1.224700\tBest loss: 1.205659\tAccuracy: 68.80%\n",
      "256\tValidation loss: 1.200818\tBest loss: 1.200818\tAccuracy: 66.50%\n",
      "257\tValidation loss: 1.204464\tBest loss: 1.200818\tAccuracy: 67.80%\n",
      "258\tValidation loss: 1.224192\tBest loss: 1.200818\tAccuracy: 67.00%\n",
      "259\tValidation loss: 1.225494\tBest loss: 1.200818\tAccuracy: 67.00%\n",
      "260\tValidation loss: 1.202590\tBest loss: 1.200818\tAccuracy: 67.80%\n",
      "261\tValidation loss: 1.194122\tBest loss: 1.194122\tAccuracy: 67.10%\n",
      "262\tValidation loss: 1.195514\tBest loss: 1.194122\tAccuracy: 66.10%\n",
      "263\tValidation loss: 1.221363\tBest loss: 1.194122\tAccuracy: 66.50%\n",
      "264\tValidation loss: 1.192160\tBest loss: 1.192160\tAccuracy: 66.40%\n",
      "265\tValidation loss: 1.203013\tBest loss: 1.192160\tAccuracy: 67.60%\n",
      "266\tValidation loss: 1.206717\tBest loss: 1.192160\tAccuracy: 68.00%\n",
      "267\tValidation loss: 1.191724\tBest loss: 1.191724\tAccuracy: 67.20%\n",
      "268\tValidation loss: 1.194047\tBest loss: 1.191724\tAccuracy: 67.50%\n",
      "269\tValidation loss: 1.206794\tBest loss: 1.191724\tAccuracy: 66.70%\n",
      "270\tValidation loss: 1.166629\tBest loss: 1.166629\tAccuracy: 68.10%\n",
      "271\tValidation loss: 1.171117\tBest loss: 1.166629\tAccuracy: 68.10%\n",
      "272\tValidation loss: 1.200565\tBest loss: 1.166629\tAccuracy: 66.60%\n",
      "273\tValidation loss: 1.200890\tBest loss: 1.166629\tAccuracy: 67.70%\n",
      "274\tValidation loss: 1.184104\tBest loss: 1.166629\tAccuracy: 69.00%\n",
      "275\tValidation loss: 1.186360\tBest loss: 1.166629\tAccuracy: 68.00%\n",
      "276\tValidation loss: 1.157091\tBest loss: 1.157091\tAccuracy: 69.50%\n",
      "277\tValidation loss: 1.170747\tBest loss: 1.157091\tAccuracy: 68.50%\n",
      "278\tValidation loss: 1.189207\tBest loss: 1.157091\tAccuracy: 66.70%\n",
      "279\tValidation loss: 1.182061\tBest loss: 1.157091\tAccuracy: 66.30%\n",
      "280\tValidation loss: 1.195707\tBest loss: 1.157091\tAccuracy: 66.20%\n",
      "281\tValidation loss: 1.200330\tBest loss: 1.157091\tAccuracy: 67.00%\n",
      "282\tValidation loss: 1.201152\tBest loss: 1.157091\tAccuracy: 66.30%\n",
      "283\tValidation loss: 1.195231\tBest loss: 1.157091\tAccuracy: 67.10%\n",
      "284\tValidation loss: 1.193737\tBest loss: 1.157091\tAccuracy: 66.20%\n",
      "285\tValidation loss: 1.184068\tBest loss: 1.157091\tAccuracy: 67.70%\n",
      "286\tValidation loss: 1.153511\tBest loss: 1.153511\tAccuracy: 68.10%\n",
      "287\tValidation loss: 1.171088\tBest loss: 1.153511\tAccuracy: 66.50%\n",
      "288\tValidation loss: 1.143867\tBest loss: 1.143867\tAccuracy: 69.40%\n",
      "289\tValidation loss: 1.176566\tBest loss: 1.143867\tAccuracy: 67.50%\n",
      "290\tValidation loss: 1.147066\tBest loss: 1.143867\tAccuracy: 69.70%\n",
      "291\tValidation loss: 1.151283\tBest loss: 1.143867\tAccuracy: 69.20%\n",
      "292\tValidation loss: 1.200267\tBest loss: 1.143867\tAccuracy: 67.20%\n",
      "293\tValidation loss: 1.131141\tBest loss: 1.131141\tAccuracy: 69.10%\n",
      "294\tValidation loss: 1.145498\tBest loss: 1.131141\tAccuracy: 68.70%\n",
      "295\tValidation loss: 1.161475\tBest loss: 1.131141\tAccuracy: 68.10%\n",
      "296\tValidation loss: 1.181059\tBest loss: 1.131141\tAccuracy: 68.40%\n",
      "297\tValidation loss: 1.135909\tBest loss: 1.131141\tAccuracy: 68.50%\n",
      "298\tValidation loss: 1.132333\tBest loss: 1.131141\tAccuracy: 68.50%\n",
      "299\tValidation loss: 1.212726\tBest loss: 1.131141\tAccuracy: 65.40%\n",
      "300\tValidation loss: 1.147972\tBest loss: 1.131141\tAccuracy: 67.90%\n",
      "301\tValidation loss: 1.163432\tBest loss: 1.131141\tAccuracy: 68.30%\n",
      "302\tValidation loss: 1.131678\tBest loss: 1.131141\tAccuracy: 69.90%\n",
      "303\tValidation loss: 1.161786\tBest loss: 1.131141\tAccuracy: 68.10%\n",
      "304\tValidation loss: 1.140765\tBest loss: 1.131141\tAccuracy: 68.10%\n",
      "305\tValidation loss: 1.150451\tBest loss: 1.131141\tAccuracy: 68.30%\n",
      "306\tValidation loss: 1.150351\tBest loss: 1.131141\tAccuracy: 70.90%\n",
      "307\tValidation loss: 1.128104\tBest loss: 1.128104\tAccuracy: 69.30%\n",
      "308\tValidation loss: 1.137715\tBest loss: 1.128104\tAccuracy: 68.30%\n",
      "309\tValidation loss: 1.148897\tBest loss: 1.128104\tAccuracy: 68.10%\n",
      "310\tValidation loss: 1.123129\tBest loss: 1.123129\tAccuracy: 69.10%\n",
      "311\tValidation loss: 1.154727\tBest loss: 1.123129\tAccuracy: 67.90%\n",
      "312\tValidation loss: 1.145284\tBest loss: 1.123129\tAccuracy: 69.20%\n",
      "313\tValidation loss: 1.119476\tBest loss: 1.119476\tAccuracy: 70.00%\n",
      "314\tValidation loss: 1.155787\tBest loss: 1.119476\tAccuracy: 70.30%\n",
      "315\tValidation loss: 1.139877\tBest loss: 1.119476\tAccuracy: 68.90%\n",
      "316\tValidation loss: 1.125624\tBest loss: 1.119476\tAccuracy: 68.80%\n",
      "317\tValidation loss: 1.103869\tBest loss: 1.103869\tAccuracy: 70.40%\n",
      "318\tValidation loss: 1.126167\tBest loss: 1.103869\tAccuracy: 70.10%\n",
      "319\tValidation loss: 1.143667\tBest loss: 1.103869\tAccuracy: 67.60%\n",
      "320\tValidation loss: 1.118374\tBest loss: 1.103869\tAccuracy: 69.20%\n",
      "321\tValidation loss: 1.124149\tBest loss: 1.103869\tAccuracy: 70.30%\n",
      "322\tValidation loss: 1.148651\tBest loss: 1.103869\tAccuracy: 69.70%\n",
      "323\tValidation loss: 1.086243\tBest loss: 1.086243\tAccuracy: 71.50%\n",
      "324\tValidation loss: 1.106269\tBest loss: 1.086243\tAccuracy: 68.80%\n",
      "325\tValidation loss: 1.102386\tBest loss: 1.086243\tAccuracy: 70.80%\n",
      "326\tValidation loss: 1.115707\tBest loss: 1.086243\tAccuracy: 69.90%\n",
      "327\tValidation loss: 1.100748\tBest loss: 1.086243\tAccuracy: 69.50%\n",
      "328\tValidation loss: 1.101470\tBest loss: 1.086243\tAccuracy: 69.20%\n",
      "329\tValidation loss: 1.101508\tBest loss: 1.086243\tAccuracy: 68.80%\n",
      "330\tValidation loss: 1.083191\tBest loss: 1.083191\tAccuracy: 71.30%\n",
      "331\tValidation loss: 1.148334\tBest loss: 1.083191\tAccuracy: 69.40%\n",
      "332\tValidation loss: 1.121568\tBest loss: 1.083191\tAccuracy: 70.60%\n",
      "333\tValidation loss: 1.119209\tBest loss: 1.083191\tAccuracy: 70.10%\n",
      "334\tValidation loss: 1.086673\tBest loss: 1.083191\tAccuracy: 70.00%\n",
      "335\tValidation loss: 1.101656\tBest loss: 1.083191\tAccuracy: 70.40%\n",
      "336\tValidation loss: 1.108396\tBest loss: 1.083191\tAccuracy: 69.50%\n",
      "337\tValidation loss: 1.118398\tBest loss: 1.083191\tAccuracy: 69.50%\n",
      "338\tValidation loss: 1.130860\tBest loss: 1.083191\tAccuracy: 69.70%\n",
      "339\tValidation loss: 1.100176\tBest loss: 1.083191\tAccuracy: 69.90%\n",
      "340\tValidation loss: 1.102738\tBest loss: 1.083191\tAccuracy: 69.80%\n",
      "341\tValidation loss: 1.108329\tBest loss: 1.083191\tAccuracy: 68.50%\n",
      "342\tValidation loss: 1.104252\tBest loss: 1.083191\tAccuracy: 67.90%\n",
      "343\tValidation loss: 1.098886\tBest loss: 1.083191\tAccuracy: 68.90%\n",
      "344\tValidation loss: 1.082396\tBest loss: 1.082396\tAccuracy: 71.20%\n",
      "345\tValidation loss: 1.087888\tBest loss: 1.082396\tAccuracy: 70.00%\n",
      "346\tValidation loss: 1.096385\tBest loss: 1.082396\tAccuracy: 70.10%\n",
      "347\tValidation loss: 1.087390\tBest loss: 1.082396\tAccuracy: 71.30%\n",
      "348\tValidation loss: 1.104688\tBest loss: 1.082396\tAccuracy: 69.20%\n",
      "349\tValidation loss: 1.097077\tBest loss: 1.082396\tAccuracy: 70.00%\n",
      "350\tValidation loss: 1.089426\tBest loss: 1.082396\tAccuracy: 70.80%\n",
      "351\tValidation loss: 1.090950\tBest loss: 1.082396\tAccuracy: 69.70%\n",
      "352\tValidation loss: 1.092358\tBest loss: 1.082396\tAccuracy: 70.20%\n",
      "353\tValidation loss: 1.102048\tBest loss: 1.082396\tAccuracy: 70.20%\n",
      "354\tValidation loss: 1.099254\tBest loss: 1.082396\tAccuracy: 71.30%\n",
      "355\tValidation loss: 1.099843\tBest loss: 1.082396\tAccuracy: 70.60%\n",
      "356\tValidation loss: 1.078226\tBest loss: 1.078226\tAccuracy: 70.40%\n",
      "357\tValidation loss: 1.087204\tBest loss: 1.078226\tAccuracy: 71.00%\n",
      "358\tValidation loss: 1.082277\tBest loss: 1.078226\tAccuracy: 69.90%\n",
      "359\tValidation loss: 1.073151\tBest loss: 1.073151\tAccuracy: 69.90%\n",
      "360\tValidation loss: 1.094801\tBest loss: 1.073151\tAccuracy: 70.50%\n",
      "361\tValidation loss: 1.070316\tBest loss: 1.070316\tAccuracy: 70.30%\n",
      "362\tValidation loss: 1.088138\tBest loss: 1.070316\tAccuracy: 69.30%\n",
      "363\tValidation loss: 1.077364\tBest loss: 1.070316\tAccuracy: 70.70%\n",
      "364\tValidation loss: 1.071404\tBest loss: 1.070316\tAccuracy: 70.90%\n",
      "365\tValidation loss: 1.075146\tBest loss: 1.070316\tAccuracy: 70.30%\n",
      "366\tValidation loss: 1.104310\tBest loss: 1.070316\tAccuracy: 70.10%\n",
      "367\tValidation loss: 1.085162\tBest loss: 1.070316\tAccuracy: 69.50%\n",
      "368\tValidation loss: 1.076632\tBest loss: 1.070316\tAccuracy: 71.20%\n",
      "369\tValidation loss: 1.112363\tBest loss: 1.070316\tAccuracy: 69.70%\n",
      "370\tValidation loss: 1.069813\tBest loss: 1.069813\tAccuracy: 71.10%\n",
      "371\tValidation loss: 1.094018\tBest loss: 1.069813\tAccuracy: 70.20%\n",
      "372\tValidation loss: 1.097522\tBest loss: 1.069813\tAccuracy: 70.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\tValidation loss: 1.069609\tBest loss: 1.069609\tAccuracy: 70.30%\n",
      "374\tValidation loss: 1.057626\tBest loss: 1.057626\tAccuracy: 70.70%\n",
      "375\tValidation loss: 1.088296\tBest loss: 1.057626\tAccuracy: 70.70%\n",
      "376\tValidation loss: 1.075336\tBest loss: 1.057626\tAccuracy: 71.10%\n",
      "377\tValidation loss: 1.060017\tBest loss: 1.057626\tAccuracy: 71.50%\n",
      "378\tValidation loss: 1.056960\tBest loss: 1.056960\tAccuracy: 71.00%\n",
      "379\tValidation loss: 1.105199\tBest loss: 1.056960\tAccuracy: 70.80%\n",
      "380\tValidation loss: 1.065145\tBest loss: 1.056960\tAccuracy: 72.30%\n",
      "381\tValidation loss: 1.076280\tBest loss: 1.056960\tAccuracy: 71.50%\n",
      "382\tValidation loss: 1.085016\tBest loss: 1.056960\tAccuracy: 71.50%\n",
      "383\tValidation loss: 1.073528\tBest loss: 1.056960\tAccuracy: 70.60%\n",
      "384\tValidation loss: 1.060073\tBest loss: 1.056960\tAccuracy: 71.20%\n",
      "385\tValidation loss: 1.065393\tBest loss: 1.056960\tAccuracy: 70.60%\n",
      "386\tValidation loss: 1.058733\tBest loss: 1.056960\tAccuracy: 71.80%\n",
      "387\tValidation loss: 1.073012\tBest loss: 1.056960\tAccuracy: 70.20%\n",
      "388\tValidation loss: 1.102211\tBest loss: 1.056960\tAccuracy: 68.20%\n",
      "389\tValidation loss: 1.049259\tBest loss: 1.049259\tAccuracy: 70.00%\n",
      "390\tValidation loss: 1.059902\tBest loss: 1.049259\tAccuracy: 70.20%\n",
      "391\tValidation loss: 1.056609\tBest loss: 1.049259\tAccuracy: 71.80%\n",
      "392\tValidation loss: 1.077409\tBest loss: 1.049259\tAccuracy: 71.50%\n",
      "393\tValidation loss: 1.049328\tBest loss: 1.049259\tAccuracy: 70.90%\n",
      "394\tValidation loss: 1.081332\tBest loss: 1.049259\tAccuracy: 69.20%\n",
      "395\tValidation loss: 1.069260\tBest loss: 1.049259\tAccuracy: 70.60%\n",
      "396\tValidation loss: 1.055208\tBest loss: 1.049259\tAccuracy: 70.70%\n",
      "397\tValidation loss: 1.058260\tBest loss: 1.049259\tAccuracy: 70.80%\n",
      "398\tValidation loss: 1.046705\tBest loss: 1.046705\tAccuracy: 73.60%\n",
      "399\tValidation loss: 1.027698\tBest loss: 1.027698\tAccuracy: 71.70%\n",
      "400\tValidation loss: 1.037335\tBest loss: 1.027698\tAccuracy: 71.70%\n",
      "401\tValidation loss: 1.070255\tBest loss: 1.027698\tAccuracy: 70.40%\n",
      "402\tValidation loss: 1.033335\tBest loss: 1.027698\tAccuracy: 69.90%\n",
      "403\tValidation loss: 1.043994\tBest loss: 1.027698\tAccuracy: 71.00%\n",
      "404\tValidation loss: 1.071102\tBest loss: 1.027698\tAccuracy: 70.40%\n",
      "405\tValidation loss: 1.041751\tBest loss: 1.027698\tAccuracy: 70.50%\n",
      "406\tValidation loss: 1.041161\tBest loss: 1.027698\tAccuracy: 70.70%\n",
      "407\tValidation loss: 1.052531\tBest loss: 1.027698\tAccuracy: 72.80%\n",
      "408\tValidation loss: 1.077794\tBest loss: 1.027698\tAccuracy: 71.60%\n",
      "409\tValidation loss: 1.043094\tBest loss: 1.027698\tAccuracy: 70.00%\n",
      "410\tValidation loss: 1.064450\tBest loss: 1.027698\tAccuracy: 71.30%\n",
      "411\tValidation loss: 1.049919\tBest loss: 1.027698\tAccuracy: 71.90%\n",
      "412\tValidation loss: 1.036677\tBest loss: 1.027698\tAccuracy: 72.10%\n",
      "413\tValidation loss: 1.062157\tBest loss: 1.027698\tAccuracy: 70.70%\n",
      "414\tValidation loss: 1.060200\tBest loss: 1.027698\tAccuracy: 70.80%\n",
      "415\tValidation loss: 1.048091\tBest loss: 1.027698\tAccuracy: 69.90%\n",
      "416\tValidation loss: 1.053656\tBest loss: 1.027698\tAccuracy: 69.70%\n",
      "417\tValidation loss: 1.068355\tBest loss: 1.027698\tAccuracy: 70.50%\n",
      "418\tValidation loss: 1.037574\tBest loss: 1.027698\tAccuracy: 70.70%\n",
      "419\tValidation loss: 1.024825\tBest loss: 1.024825\tAccuracy: 71.50%\n",
      "420\tValidation loss: 1.023756\tBest loss: 1.023756\tAccuracy: 71.60%\n",
      "421\tValidation loss: 1.026989\tBest loss: 1.023756\tAccuracy: 71.30%\n",
      "422\tValidation loss: 1.022658\tBest loss: 1.022658\tAccuracy: 72.00%\n",
      "423\tValidation loss: 1.016226\tBest loss: 1.016226\tAccuracy: 70.70%\n",
      "424\tValidation loss: 1.044152\tBest loss: 1.016226\tAccuracy: 70.90%\n",
      "425\tValidation loss: 1.037448\tBest loss: 1.016226\tAccuracy: 71.00%\n",
      "426\tValidation loss: 1.023791\tBest loss: 1.016226\tAccuracy: 73.20%\n",
      "427\tValidation loss: 1.037335\tBest loss: 1.016226\tAccuracy: 69.30%\n",
      "428\tValidation loss: 1.036612\tBest loss: 1.016226\tAccuracy: 71.90%\n",
      "429\tValidation loss: 1.028568\tBest loss: 1.016226\tAccuracy: 71.10%\n",
      "430\tValidation loss: 1.033417\tBest loss: 1.016226\tAccuracy: 70.20%\n",
      "431\tValidation loss: 1.030603\tBest loss: 1.016226\tAccuracy: 72.80%\n",
      "432\tValidation loss: 1.036656\tBest loss: 1.016226\tAccuracy: 72.10%\n",
      "433\tValidation loss: 1.074622\tBest loss: 1.016226\tAccuracy: 70.90%\n",
      "434\tValidation loss: 1.032557\tBest loss: 1.016226\tAccuracy: 71.10%\n",
      "435\tValidation loss: 1.019865\tBest loss: 1.016226\tAccuracy: 70.60%\n",
      "436\tValidation loss: 1.025018\tBest loss: 1.016226\tAccuracy: 71.80%\n",
      "437\tValidation loss: 1.072653\tBest loss: 1.016226\tAccuracy: 68.90%\n",
      "438\tValidation loss: 1.040741\tBest loss: 1.016226\tAccuracy: 71.40%\n",
      "439\tValidation loss: 1.019585\tBest loss: 1.016226\tAccuracy: 72.60%\n",
      "440\tValidation loss: 1.042781\tBest loss: 1.016226\tAccuracy: 71.50%\n",
      "441\tValidation loss: 1.027749\tBest loss: 1.016226\tAccuracy: 72.20%\n",
      "442\tValidation loss: 1.026670\tBest loss: 1.016226\tAccuracy: 70.60%\n",
      "443\tValidation loss: 1.036525\tBest loss: 1.016226\tAccuracy: 73.00%\n",
      "444\tValidation loss: 1.050934\tBest loss: 1.016226\tAccuracy: 71.50%\n",
      "Early stopping!\n",
      "[[  1.18165218e-07   2.17699344e-04   2.48625179e-06 ...,   7.78083320e-10\n",
      "    5.15841014e-09   3.73119358e-09]\n",
      " [  1.01652987e-01   1.22420983e-02   2.02136487e-01 ...,   4.20067227e-04\n",
      "    1.50566426e-04   8.49926655e-05]\n",
      " [  1.07063897e-07   2.45828423e-13   7.28144869e-07 ...,   1.88599275e-10\n",
      "    1.65636182e-13   9.71762276e-13]\n",
      " ..., \n",
      " [  1.32120781e-11   2.40482301e-08   4.72836215e-10 ...,   6.92851927e-07\n",
      "    1.70858186e-07   4.69890750e-07]\n",
      " [  1.66937360e-03   3.24921519e-03   4.78447764e-04 ...,   4.09282446e-02\n",
      "    1.67618357e-02   6.96038827e-03]\n",
      " [  1.01453170e-05   6.00526982e-06   1.09593821e-05 ...,   1.01385862e-02\n",
      "    4.70953668e-03   1.29610971e-02]]\n",
      "[11 19 16 ...,  6 26  8]\n",
      "[[  1.06914260e-04   2.02686782e-03   4.41861292e-03 ...,   8.47222656e-03\n",
      "    2.74832430e-03   4.16191388e-03]\n",
      " [  8.72607986e-10   3.04965874e-06   4.38223902e-09 ...,   1.77904566e-11\n",
      "    9.98447783e-11   9.67466732e-11]\n",
      " [  2.47835260e-07   1.03311631e-05   9.26852479e-08 ...,   6.31692103e-08\n",
      "    2.96098079e-08   3.58083305e-08]\n",
      " ..., \n",
      " [  2.76920196e-06   3.55242300e-05   1.80506813e-05 ...,   1.68761929e-08\n",
      "    7.51222817e-09   5.87643878e-10]\n",
      " [  1.82661153e-02   4.19506431e-03   6.69358531e-03 ...,   1.77839454e-02\n",
      "    8.39623250e-03   7.90733099e-03]\n",
      " [  2.30646502e-13   2.71118492e-11   4.30442527e-14 ...,   7.10016396e-03\n",
      "    1.35930313e-03   7.49187350e-01]]\n",
      "[31 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 3.6min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 4.065844\tBest loss: 4.065844\tAccuracy: 5.10%\n",
      "1\tValidation loss: 3.870600\tBest loss: 3.870600\tAccuracy: 5.60%\n",
      "2\tValidation loss: 3.731514\tBest loss: 3.731514\tAccuracy: 4.30%\n",
      "3\tValidation loss: 3.793541\tBest loss: 3.731514\tAccuracy: 5.70%\n",
      "4\tValidation loss: 3.599657\tBest loss: 3.599657\tAccuracy: 8.80%\n",
      "5\tValidation loss: 3.589807\tBest loss: 3.589807\tAccuracy: 6.60%\n",
      "6\tValidation loss: 3.573385\tBest loss: 3.573385\tAccuracy: 7.10%\n",
      "7\tValidation loss: 3.570851\tBest loss: 3.570851\tAccuracy: 7.20%\n",
      "8\tValidation loss: 3.504412\tBest loss: 3.504412\tAccuracy: 11.40%\n",
      "9\tValidation loss: 3.491612\tBest loss: 3.491612\tAccuracy: 9.90%\n",
      "10\tValidation loss: 3.480774\tBest loss: 3.480774\tAccuracy: 10.90%\n",
      "11\tValidation loss: 3.490023\tBest loss: 3.480774\tAccuracy: 10.70%\n",
      "12\tValidation loss: 3.433217\tBest loss: 3.433217\tAccuracy: 8.70%\n",
      "13\tValidation loss: 3.386055\tBest loss: 3.386055\tAccuracy: 12.90%\n",
      "14\tValidation loss: 3.362084\tBest loss: 3.362084\tAccuracy: 12.80%\n",
      "15\tValidation loss: 3.323429\tBest loss: 3.323429\tAccuracy: 16.50%\n",
      "16\tValidation loss: 3.297472\tBest loss: 3.297472\tAccuracy: 14.10%\n",
      "17\tValidation loss: 3.271036\tBest loss: 3.271036\tAccuracy: 15.90%\n",
      "18\tValidation loss: 3.277192\tBest loss: 3.271036\tAccuracy: 15.00%\n",
      "19\tValidation loss: 3.209036\tBest loss: 3.209036\tAccuracy: 18.10%\n",
      "20\tValidation loss: 3.192716\tBest loss: 3.192716\tAccuracy: 17.60%\n",
      "21\tValidation loss: 3.160074\tBest loss: 3.160074\tAccuracy: 19.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tValidation loss: 3.149193\tBest loss: 3.149193\tAccuracy: 17.90%\n",
      "23\tValidation loss: 3.155370\tBest loss: 3.149193\tAccuracy: 19.10%\n",
      "24\tValidation loss: 3.105756\tBest loss: 3.105756\tAccuracy: 20.10%\n",
      "25\tValidation loss: 3.008154\tBest loss: 3.008154\tAccuracy: 20.50%\n",
      "26\tValidation loss: 3.043290\tBest loss: 3.008154\tAccuracy: 18.60%\n",
      "27\tValidation loss: 3.021156\tBest loss: 3.008154\tAccuracy: 19.40%\n",
      "28\tValidation loss: 2.969272\tBest loss: 2.969272\tAccuracy: 22.70%\n",
      "29\tValidation loss: 2.922048\tBest loss: 2.922048\tAccuracy: 24.10%\n",
      "30\tValidation loss: 2.873455\tBest loss: 2.873455\tAccuracy: 25.20%\n",
      "31\tValidation loss: 2.871318\tBest loss: 2.871318\tAccuracy: 23.10%\n",
      "32\tValidation loss: 2.828800\tBest loss: 2.828800\tAccuracy: 24.90%\n",
      "33\tValidation loss: 2.824637\tBest loss: 2.824637\tAccuracy: 25.80%\n",
      "34\tValidation loss: 2.796337\tBest loss: 2.796337\tAccuracy: 26.40%\n",
      "35\tValidation loss: 2.771095\tBest loss: 2.771095\tAccuracy: 26.60%\n",
      "36\tValidation loss: 2.748113\tBest loss: 2.748113\tAccuracy: 25.00%\n",
      "37\tValidation loss: 2.705889\tBest loss: 2.705889\tAccuracy: 24.80%\n",
      "38\tValidation loss: 2.658328\tBest loss: 2.658328\tAccuracy: 27.90%\n",
      "39\tValidation loss: 2.664300\tBest loss: 2.658328\tAccuracy: 26.40%\n",
      "40\tValidation loss: 2.647479\tBest loss: 2.647479\tAccuracy: 30.30%\n",
      "41\tValidation loss: 2.588457\tBest loss: 2.588457\tAccuracy: 29.90%\n",
      "42\tValidation loss: 2.635283\tBest loss: 2.588457\tAccuracy: 28.20%\n",
      "43\tValidation loss: 2.624982\tBest loss: 2.588457\tAccuracy: 28.30%\n",
      "44\tValidation loss: 2.505944\tBest loss: 2.505944\tAccuracy: 32.90%\n",
      "45\tValidation loss: 2.489620\tBest loss: 2.489620\tAccuracy: 33.10%\n",
      "46\tValidation loss: 2.505366\tBest loss: 2.489620\tAccuracy: 30.90%\n",
      "47\tValidation loss: 2.451674\tBest loss: 2.451674\tAccuracy: 34.30%\n",
      "48\tValidation loss: 2.410437\tBest loss: 2.410437\tAccuracy: 32.50%\n",
      "49\tValidation loss: 2.435728\tBest loss: 2.410437\tAccuracy: 31.30%\n",
      "50\tValidation loss: 2.362933\tBest loss: 2.362933\tAccuracy: 36.40%\n",
      "51\tValidation loss: 2.364860\tBest loss: 2.362933\tAccuracy: 34.20%\n",
      "52\tValidation loss: 2.317587\tBest loss: 2.317587\tAccuracy: 36.10%\n",
      "53\tValidation loss: 2.322135\tBest loss: 2.317587\tAccuracy: 38.00%\n",
      "54\tValidation loss: 2.274905\tBest loss: 2.274905\tAccuracy: 38.50%\n",
      "55\tValidation loss: 2.278578\tBest loss: 2.274905\tAccuracy: 37.50%\n",
      "56\tValidation loss: 2.268369\tBest loss: 2.268369\tAccuracy: 37.10%\n",
      "57\tValidation loss: 2.271718\tBest loss: 2.268369\tAccuracy: 39.20%\n",
      "58\tValidation loss: 2.223844\tBest loss: 2.223844\tAccuracy: 40.90%\n",
      "59\tValidation loss: 2.237396\tBest loss: 2.223844\tAccuracy: 38.10%\n",
      "60\tValidation loss: 2.226476\tBest loss: 2.223844\tAccuracy: 37.20%\n",
      "61\tValidation loss: 2.113481\tBest loss: 2.113481\tAccuracy: 43.90%\n",
      "62\tValidation loss: 2.133772\tBest loss: 2.113481\tAccuracy: 41.90%\n",
      "63\tValidation loss: 2.106190\tBest loss: 2.106190\tAccuracy: 43.60%\n",
      "64\tValidation loss: 2.122418\tBest loss: 2.106190\tAccuracy: 40.50%\n",
      "65\tValidation loss: 2.211431\tBest loss: 2.106190\tAccuracy: 41.80%\n",
      "66\tValidation loss: 2.135911\tBest loss: 2.106190\tAccuracy: 42.90%\n",
      "67\tValidation loss: 2.042954\tBest loss: 2.042954\tAccuracy: 43.20%\n",
      "68\tValidation loss: 2.127038\tBest loss: 2.042954\tAccuracy: 44.80%\n",
      "69\tValidation loss: 2.083772\tBest loss: 2.042954\tAccuracy: 43.40%\n",
      "70\tValidation loss: 2.034511\tBest loss: 2.034511\tAccuracy: 45.80%\n",
      "71\tValidation loss: 1.994192\tBest loss: 1.994192\tAccuracy: 46.00%\n",
      "72\tValidation loss: 2.003192\tBest loss: 1.994192\tAccuracy: 45.00%\n",
      "73\tValidation loss: 1.978680\tBest loss: 1.978680\tAccuracy: 45.40%\n",
      "74\tValidation loss: 1.931037\tBest loss: 1.931037\tAccuracy: 48.00%\n",
      "75\tValidation loss: 1.938047\tBest loss: 1.931037\tAccuracy: 47.00%\n",
      "76\tValidation loss: 1.982601\tBest loss: 1.931037\tAccuracy: 45.00%\n",
      "77\tValidation loss: 1.917373\tBest loss: 1.917373\tAccuracy: 48.80%\n",
      "78\tValidation loss: 1.919194\tBest loss: 1.917373\tAccuracy: 48.30%\n",
      "79\tValidation loss: 1.903831\tBest loss: 1.903831\tAccuracy: 47.70%\n",
      "80\tValidation loss: 1.910901\tBest loss: 1.903831\tAccuracy: 49.30%\n",
      "81\tValidation loss: 1.888373\tBest loss: 1.888373\tAccuracy: 47.50%\n",
      "82\tValidation loss: 1.860214\tBest loss: 1.860214\tAccuracy: 50.60%\n",
      "83\tValidation loss: 1.854649\tBest loss: 1.854649\tAccuracy: 50.00%\n",
      "84\tValidation loss: 1.872845\tBest loss: 1.854649\tAccuracy: 47.60%\n",
      "85\tValidation loss: 1.819885\tBest loss: 1.819885\tAccuracy: 51.40%\n",
      "86\tValidation loss: 1.820902\tBest loss: 1.819885\tAccuracy: 51.60%\n",
      "87\tValidation loss: 1.803491\tBest loss: 1.803491\tAccuracy: 49.90%\n",
      "88\tValidation loss: 1.813666\tBest loss: 1.803491\tAccuracy: 51.90%\n",
      "89\tValidation loss: 1.783013\tBest loss: 1.783013\tAccuracy: 52.90%\n",
      "90\tValidation loss: 1.747527\tBest loss: 1.747527\tAccuracy: 54.30%\n",
      "91\tValidation loss: 1.784573\tBest loss: 1.747527\tAccuracy: 53.00%\n",
      "92\tValidation loss: 1.761550\tBest loss: 1.747527\tAccuracy: 54.40%\n",
      "93\tValidation loss: 1.763643\tBest loss: 1.747527\tAccuracy: 54.90%\n",
      "94\tValidation loss: 1.778542\tBest loss: 1.747527\tAccuracy: 51.70%\n",
      "95\tValidation loss: 1.751645\tBest loss: 1.747527\tAccuracy: 53.20%\n",
      "96\tValidation loss: 1.767851\tBest loss: 1.747527\tAccuracy: 53.30%\n",
      "97\tValidation loss: 1.708169\tBest loss: 1.708169\tAccuracy: 54.20%\n",
      "98\tValidation loss: 1.737582\tBest loss: 1.708169\tAccuracy: 51.90%\n",
      "99\tValidation loss: 1.742534\tBest loss: 1.708169\tAccuracy: 53.30%\n",
      "100\tValidation loss: 1.689789\tBest loss: 1.689789\tAccuracy: 57.10%\n",
      "101\tValidation loss: 1.679896\tBest loss: 1.679896\tAccuracy: 55.10%\n",
      "102\tValidation loss: 1.666626\tBest loss: 1.666626\tAccuracy: 58.30%\n",
      "103\tValidation loss: 1.666497\tBest loss: 1.666497\tAccuracy: 54.50%\n",
      "104\tValidation loss: 1.645628\tBest loss: 1.645628\tAccuracy: 56.00%\n",
      "105\tValidation loss: 1.631679\tBest loss: 1.631679\tAccuracy: 57.70%\n",
      "106\tValidation loss: 1.621976\tBest loss: 1.621976\tAccuracy: 57.50%\n",
      "107\tValidation loss: 1.641271\tBest loss: 1.621976\tAccuracy: 56.50%\n",
      "108\tValidation loss: 1.646262\tBest loss: 1.621976\tAccuracy: 56.40%\n",
      "109\tValidation loss: 1.618792\tBest loss: 1.618792\tAccuracy: 56.70%\n",
      "110\tValidation loss: 1.663194\tBest loss: 1.618792\tAccuracy: 53.60%\n",
      "111\tValidation loss: 1.657506\tBest loss: 1.618792\tAccuracy: 56.50%\n",
      "112\tValidation loss: 1.602144\tBest loss: 1.602144\tAccuracy: 56.40%\n",
      "113\tValidation loss: 1.633234\tBest loss: 1.602144\tAccuracy: 57.80%\n",
      "114\tValidation loss: 1.584238\tBest loss: 1.584238\tAccuracy: 57.90%\n",
      "115\tValidation loss: 1.592767\tBest loss: 1.584238\tAccuracy: 59.40%\n",
      "116\tValidation loss: 1.557761\tBest loss: 1.557761\tAccuracy: 57.80%\n",
      "117\tValidation loss: 1.541454\tBest loss: 1.541454\tAccuracy: 58.60%\n",
      "118\tValidation loss: 1.582865\tBest loss: 1.541454\tAccuracy: 57.40%\n",
      "119\tValidation loss: 1.555485\tBest loss: 1.541454\tAccuracy: 59.20%\n",
      "120\tValidation loss: 1.554078\tBest loss: 1.541454\tAccuracy: 59.70%\n",
      "121\tValidation loss: 1.540027\tBest loss: 1.540027\tAccuracy: 58.50%\n",
      "122\tValidation loss: 1.551985\tBest loss: 1.540027\tAccuracy: 58.70%\n",
      "123\tValidation loss: 1.527896\tBest loss: 1.527896\tAccuracy: 57.30%\n",
      "124\tValidation loss: 1.551075\tBest loss: 1.527896\tAccuracy: 56.80%\n",
      "125\tValidation loss: 1.513871\tBest loss: 1.513871\tAccuracy: 59.30%\n",
      "126\tValidation loss: 1.513939\tBest loss: 1.513871\tAccuracy: 59.50%\n",
      "127\tValidation loss: 1.521006\tBest loss: 1.513871\tAccuracy: 60.40%\n",
      "128\tValidation loss: 1.514800\tBest loss: 1.513871\tAccuracy: 59.40%\n",
      "129\tValidation loss: 1.466350\tBest loss: 1.466350\tAccuracy: 61.00%\n",
      "130\tValidation loss: 1.494622\tBest loss: 1.466350\tAccuracy: 59.70%\n",
      "131\tValidation loss: 1.465526\tBest loss: 1.465526\tAccuracy: 62.30%\n",
      "132\tValidation loss: 1.468433\tBest loss: 1.465526\tAccuracy: 59.80%\n",
      "133\tValidation loss: 1.461111\tBest loss: 1.461111\tAccuracy: 60.00%\n",
      "134\tValidation loss: 1.448362\tBest loss: 1.448362\tAccuracy: 61.60%\n",
      "135\tValidation loss: 1.443784\tBest loss: 1.443784\tAccuracy: 61.20%\n",
      "136\tValidation loss: 1.499112\tBest loss: 1.443784\tAccuracy: 60.30%\n",
      "137\tValidation loss: 1.422427\tBest loss: 1.422427\tAccuracy: 61.40%\n",
      "138\tValidation loss: 1.462313\tBest loss: 1.422427\tAccuracy: 61.00%\n",
      "139\tValidation loss: 1.449968\tBest loss: 1.422427\tAccuracy: 59.10%\n",
      "140\tValidation loss: 1.426591\tBest loss: 1.422427\tAccuracy: 61.60%\n",
      "141\tValidation loss: 1.442805\tBest loss: 1.422427\tAccuracy: 58.50%\n",
      "142\tValidation loss: 1.448161\tBest loss: 1.422427\tAccuracy: 60.50%\n",
      "143\tValidation loss: 1.433511\tBest loss: 1.422427\tAccuracy: 61.50%\n",
      "144\tValidation loss: 1.440574\tBest loss: 1.422427\tAccuracy: 62.10%\n",
      "145\tValidation loss: 1.409043\tBest loss: 1.409043\tAccuracy: 61.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\tValidation loss: 1.470817\tBest loss: 1.409043\tAccuracy: 60.70%\n",
      "147\tValidation loss: 1.378703\tBest loss: 1.378703\tAccuracy: 61.60%\n",
      "148\tValidation loss: 1.396397\tBest loss: 1.378703\tAccuracy: 62.60%\n",
      "149\tValidation loss: 1.399173\tBest loss: 1.378703\tAccuracy: 61.70%\n",
      "150\tValidation loss: 1.422064\tBest loss: 1.378703\tAccuracy: 63.10%\n",
      "151\tValidation loss: 1.400100\tBest loss: 1.378703\tAccuracy: 63.80%\n",
      "152\tValidation loss: 1.346916\tBest loss: 1.346916\tAccuracy: 64.70%\n",
      "153\tValidation loss: 1.387931\tBest loss: 1.346916\tAccuracy: 62.30%\n",
      "154\tValidation loss: 1.372554\tBest loss: 1.346916\tAccuracy: 62.10%\n",
      "155\tValidation loss: 1.395594\tBest loss: 1.346916\tAccuracy: 63.60%\n",
      "156\tValidation loss: 1.367433\tBest loss: 1.346916\tAccuracy: 63.20%\n",
      "157\tValidation loss: 1.354774\tBest loss: 1.346916\tAccuracy: 62.90%\n",
      "158\tValidation loss: 1.348124\tBest loss: 1.346916\tAccuracy: 64.10%\n",
      "159\tValidation loss: 1.357112\tBest loss: 1.346916\tAccuracy: 62.20%\n",
      "160\tValidation loss: 1.374872\tBest loss: 1.346916\tAccuracy: 62.80%\n",
      "161\tValidation loss: 1.352018\tBest loss: 1.346916\tAccuracy: 62.80%\n",
      "162\tValidation loss: 1.376249\tBest loss: 1.346916\tAccuracy: 62.10%\n",
      "163\tValidation loss: 1.336919\tBest loss: 1.336919\tAccuracy: 63.80%\n",
      "164\tValidation loss: 1.367755\tBest loss: 1.336919\tAccuracy: 63.40%\n",
      "165\tValidation loss: 1.343825\tBest loss: 1.336919\tAccuracy: 62.10%\n",
      "166\tValidation loss: 1.364722\tBest loss: 1.336919\tAccuracy: 61.80%\n",
      "167\tValidation loss: 1.370355\tBest loss: 1.336919\tAccuracy: 63.00%\n",
      "168\tValidation loss: 1.333312\tBest loss: 1.333312\tAccuracy: 63.00%\n",
      "169\tValidation loss: 1.328666\tBest loss: 1.328666\tAccuracy: 63.00%\n",
      "170\tValidation loss: 1.293260\tBest loss: 1.293260\tAccuracy: 64.50%\n",
      "171\tValidation loss: 1.316364\tBest loss: 1.293260\tAccuracy: 64.40%\n",
      "172\tValidation loss: 1.275864\tBest loss: 1.275864\tAccuracy: 64.40%\n",
      "173\tValidation loss: 1.282147\tBest loss: 1.275864\tAccuracy: 64.40%\n",
      "174\tValidation loss: 1.312784\tBest loss: 1.275864\tAccuracy: 64.60%\n",
      "175\tValidation loss: 1.295812\tBest loss: 1.275864\tAccuracy: 64.90%\n",
      "176\tValidation loss: 1.308335\tBest loss: 1.275864\tAccuracy: 64.50%\n",
      "177\tValidation loss: 1.289710\tBest loss: 1.275864\tAccuracy: 65.10%\n",
      "178\tValidation loss: 1.283059\tBest loss: 1.275864\tAccuracy: 64.40%\n",
      "179\tValidation loss: 1.274940\tBest loss: 1.274940\tAccuracy: 65.80%\n",
      "180\tValidation loss: 1.285014\tBest loss: 1.274940\tAccuracy: 65.50%\n",
      "181\tValidation loss: 1.261414\tBest loss: 1.261414\tAccuracy: 66.20%\n",
      "182\tValidation loss: 1.278667\tBest loss: 1.261414\tAccuracy: 66.30%\n",
      "183\tValidation loss: 1.293223\tBest loss: 1.261414\tAccuracy: 63.60%\n",
      "184\tValidation loss: 1.269848\tBest loss: 1.261414\tAccuracy: 65.30%\n",
      "185\tValidation loss: 1.293257\tBest loss: 1.261414\tAccuracy: 63.90%\n",
      "186\tValidation loss: 1.273931\tBest loss: 1.261414\tAccuracy: 63.80%\n",
      "187\tValidation loss: 1.246915\tBest loss: 1.246915\tAccuracy: 65.70%\n",
      "188\tValidation loss: 1.255169\tBest loss: 1.246915\tAccuracy: 65.70%\n",
      "189\tValidation loss: 1.231628\tBest loss: 1.231628\tAccuracy: 65.70%\n",
      "190\tValidation loss: 1.248132\tBest loss: 1.231628\tAccuracy: 64.80%\n",
      "191\tValidation loss: 1.250641\tBest loss: 1.231628\tAccuracy: 65.90%\n",
      "192\tValidation loss: 1.235216\tBest loss: 1.231628\tAccuracy: 65.50%\n",
      "193\tValidation loss: 1.247829\tBest loss: 1.231628\tAccuracy: 65.40%\n",
      "194\tValidation loss: 1.276778\tBest loss: 1.231628\tAccuracy: 64.60%\n",
      "195\tValidation loss: 1.230253\tBest loss: 1.230253\tAccuracy: 65.60%\n",
      "196\tValidation loss: 1.213624\tBest loss: 1.213624\tAccuracy: 68.00%\n",
      "197\tValidation loss: 1.248639\tBest loss: 1.213624\tAccuracy: 66.40%\n",
      "198\tValidation loss: 1.254618\tBest loss: 1.213624\tAccuracy: 65.20%\n",
      "199\tValidation loss: 1.216473\tBest loss: 1.213624\tAccuracy: 66.40%\n",
      "200\tValidation loss: 1.226114\tBest loss: 1.213624\tAccuracy: 65.50%\n",
      "201\tValidation loss: 1.260864\tBest loss: 1.213624\tAccuracy: 65.30%\n",
      "202\tValidation loss: 1.230693\tBest loss: 1.213624\tAccuracy: 66.50%\n",
      "203\tValidation loss: 1.210286\tBest loss: 1.210286\tAccuracy: 65.40%\n",
      "204\tValidation loss: 1.221621\tBest loss: 1.210286\tAccuracy: 66.10%\n",
      "205\tValidation loss: 1.217204\tBest loss: 1.210286\tAccuracy: 65.80%\n",
      "206\tValidation loss: 1.212930\tBest loss: 1.210286\tAccuracy: 66.60%\n",
      "207\tValidation loss: 1.224328\tBest loss: 1.210286\tAccuracy: 67.90%\n",
      "208\tValidation loss: 1.231183\tBest loss: 1.210286\tAccuracy: 66.60%\n",
      "209\tValidation loss: 1.214985\tBest loss: 1.210286\tAccuracy: 66.70%\n",
      "210\tValidation loss: 1.207557\tBest loss: 1.207557\tAccuracy: 67.40%\n",
      "211\tValidation loss: 1.199991\tBest loss: 1.199991\tAccuracy: 68.70%\n",
      "212\tValidation loss: 1.239984\tBest loss: 1.199991\tAccuracy: 65.60%\n",
      "213\tValidation loss: 1.207410\tBest loss: 1.199991\tAccuracy: 67.20%\n",
      "214\tValidation loss: 1.216513\tBest loss: 1.199991\tAccuracy: 65.70%\n",
      "215\tValidation loss: 1.218160\tBest loss: 1.199991\tAccuracy: 65.10%\n",
      "216\tValidation loss: 1.198624\tBest loss: 1.198624\tAccuracy: 66.40%\n",
      "217\tValidation loss: 1.203040\tBest loss: 1.198624\tAccuracy: 67.00%\n",
      "218\tValidation loss: 1.195527\tBest loss: 1.195527\tAccuracy: 68.00%\n",
      "219\tValidation loss: 1.186523\tBest loss: 1.186523\tAccuracy: 68.50%\n",
      "220\tValidation loss: 1.202463\tBest loss: 1.186523\tAccuracy: 67.70%\n",
      "221\tValidation loss: 1.209568\tBest loss: 1.186523\tAccuracy: 67.00%\n",
      "222\tValidation loss: 1.220136\tBest loss: 1.186523\tAccuracy: 67.30%\n",
      "223\tValidation loss: 1.169177\tBest loss: 1.169177\tAccuracy: 68.50%\n",
      "224\tValidation loss: 1.200141\tBest loss: 1.169177\tAccuracy: 68.40%\n",
      "225\tValidation loss: 1.205158\tBest loss: 1.169177\tAccuracy: 68.20%\n",
      "226\tValidation loss: 1.219326\tBest loss: 1.169177\tAccuracy: 66.50%\n",
      "227\tValidation loss: 1.198275\tBest loss: 1.169177\tAccuracy: 65.90%\n",
      "228\tValidation loss: 1.201509\tBest loss: 1.169177\tAccuracy: 67.40%\n",
      "229\tValidation loss: 1.198111\tBest loss: 1.169177\tAccuracy: 67.20%\n",
      "230\tValidation loss: 1.158960\tBest loss: 1.158960\tAccuracy: 69.90%\n",
      "231\tValidation loss: 1.193484\tBest loss: 1.158960\tAccuracy: 67.20%\n",
      "232\tValidation loss: 1.187338\tBest loss: 1.158960\tAccuracy: 66.90%\n",
      "233\tValidation loss: 1.166860\tBest loss: 1.158960\tAccuracy: 67.70%\n",
      "234\tValidation loss: 1.154349\tBest loss: 1.154349\tAccuracy: 66.30%\n",
      "235\tValidation loss: 1.141359\tBest loss: 1.141359\tAccuracy: 68.50%\n",
      "236\tValidation loss: 1.159616\tBest loss: 1.141359\tAccuracy: 68.40%\n",
      "237\tValidation loss: 1.170620\tBest loss: 1.141359\tAccuracy: 67.00%\n",
      "238\tValidation loss: 1.206041\tBest loss: 1.141359\tAccuracy: 68.30%\n",
      "239\tValidation loss: 1.137705\tBest loss: 1.137705\tAccuracy: 67.40%\n",
      "240\tValidation loss: 1.194868\tBest loss: 1.137705\tAccuracy: 66.70%\n",
      "241\tValidation loss: 1.146689\tBest loss: 1.137705\tAccuracy: 69.00%\n",
      "242\tValidation loss: 1.148150\tBest loss: 1.137705\tAccuracy: 68.30%\n",
      "243\tValidation loss: 1.159691\tBest loss: 1.137705\tAccuracy: 68.90%\n",
      "244\tValidation loss: 1.171211\tBest loss: 1.137705\tAccuracy: 69.20%\n",
      "245\tValidation loss: 1.166968\tBest loss: 1.137705\tAccuracy: 69.20%\n",
      "246\tValidation loss: 1.149941\tBest loss: 1.137705\tAccuracy: 67.80%\n",
      "247\tValidation loss: 1.163271\tBest loss: 1.137705\tAccuracy: 69.00%\n",
      "248\tValidation loss: 1.138121\tBest loss: 1.137705\tAccuracy: 69.10%\n",
      "249\tValidation loss: 1.149904\tBest loss: 1.137705\tAccuracy: 68.30%\n",
      "250\tValidation loss: 1.138897\tBest loss: 1.137705\tAccuracy: 68.30%\n",
      "251\tValidation loss: 1.117859\tBest loss: 1.117859\tAccuracy: 69.60%\n",
      "252\tValidation loss: 1.173746\tBest loss: 1.117859\tAccuracy: 68.40%\n",
      "253\tValidation loss: 1.133052\tBest loss: 1.117859\tAccuracy: 68.40%\n",
      "254\tValidation loss: 1.123669\tBest loss: 1.117859\tAccuracy: 69.10%\n",
      "255\tValidation loss: 1.153433\tBest loss: 1.117859\tAccuracy: 69.60%\n",
      "256\tValidation loss: 1.111293\tBest loss: 1.111293\tAccuracy: 70.70%\n",
      "257\tValidation loss: 1.144562\tBest loss: 1.111293\tAccuracy: 69.60%\n",
      "258\tValidation loss: 1.128716\tBest loss: 1.111293\tAccuracy: 69.20%\n",
      "259\tValidation loss: 1.183962\tBest loss: 1.111293\tAccuracy: 66.80%\n",
      "260\tValidation loss: 1.142446\tBest loss: 1.111293\tAccuracy: 68.20%\n",
      "261\tValidation loss: 1.128789\tBest loss: 1.111293\tAccuracy: 68.90%\n",
      "262\tValidation loss: 1.102722\tBest loss: 1.102722\tAccuracy: 69.60%\n",
      "263\tValidation loss: 1.138984\tBest loss: 1.102722\tAccuracy: 67.30%\n",
      "264\tValidation loss: 1.118462\tBest loss: 1.102722\tAccuracy: 69.20%\n",
      "265\tValidation loss: 1.142851\tBest loss: 1.102722\tAccuracy: 68.20%\n",
      "266\tValidation loss: 1.137434\tBest loss: 1.102722\tAccuracy: 68.10%\n",
      "267\tValidation loss: 1.111456\tBest loss: 1.102722\tAccuracy: 69.30%\n",
      "268\tValidation loss: 1.125472\tBest loss: 1.102722\tAccuracy: 69.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\tValidation loss: 1.132337\tBest loss: 1.102722\tAccuracy: 68.00%\n",
      "270\tValidation loss: 1.098544\tBest loss: 1.098544\tAccuracy: 68.00%\n",
      "271\tValidation loss: 1.116083\tBest loss: 1.098544\tAccuracy: 69.70%\n",
      "272\tValidation loss: 1.113500\tBest loss: 1.098544\tAccuracy: 68.40%\n",
      "273\tValidation loss: 1.109371\tBest loss: 1.098544\tAccuracy: 69.40%\n",
      "274\tValidation loss: 1.095225\tBest loss: 1.095225\tAccuracy: 70.00%\n",
      "275\tValidation loss: 1.089278\tBest loss: 1.089278\tAccuracy: 69.80%\n",
      "276\tValidation loss: 1.093589\tBest loss: 1.089278\tAccuracy: 69.00%\n",
      "277\tValidation loss: 1.119709\tBest loss: 1.089278\tAccuracy: 68.00%\n",
      "278\tValidation loss: 1.119089\tBest loss: 1.089278\tAccuracy: 68.80%\n",
      "279\tValidation loss: 1.135586\tBest loss: 1.089278\tAccuracy: 68.00%\n",
      "280\tValidation loss: 1.119567\tBest loss: 1.089278\tAccuracy: 69.70%\n",
      "281\tValidation loss: 1.090440\tBest loss: 1.089278\tAccuracy: 70.90%\n",
      "282\tValidation loss: 1.120155\tBest loss: 1.089278\tAccuracy: 68.40%\n",
      "283\tValidation loss: 1.113422\tBest loss: 1.089278\tAccuracy: 68.30%\n",
      "284\tValidation loss: 1.108663\tBest loss: 1.089278\tAccuracy: 68.10%\n",
      "285\tValidation loss: 1.114244\tBest loss: 1.089278\tAccuracy: 69.50%\n",
      "286\tValidation loss: 1.091074\tBest loss: 1.089278\tAccuracy: 70.30%\n",
      "287\tValidation loss: 1.137833\tBest loss: 1.089278\tAccuracy: 69.50%\n",
      "288\tValidation loss: 1.099883\tBest loss: 1.089278\tAccuracy: 69.70%\n",
      "289\tValidation loss: 1.089998\tBest loss: 1.089278\tAccuracy: 70.50%\n",
      "290\tValidation loss: 1.076787\tBest loss: 1.076787\tAccuracy: 70.50%\n",
      "291\tValidation loss: 1.131553\tBest loss: 1.076787\tAccuracy: 68.40%\n",
      "292\tValidation loss: 1.078669\tBest loss: 1.076787\tAccuracy: 70.50%\n",
      "293\tValidation loss: 1.086031\tBest loss: 1.076787\tAccuracy: 70.00%\n",
      "294\tValidation loss: 1.080115\tBest loss: 1.076787\tAccuracy: 70.20%\n",
      "295\tValidation loss: 1.099415\tBest loss: 1.076787\tAccuracy: 69.50%\n",
      "296\tValidation loss: 1.120780\tBest loss: 1.076787\tAccuracy: 69.20%\n",
      "297\tValidation loss: 1.088792\tBest loss: 1.076787\tAccuracy: 70.10%\n",
      "298\tValidation loss: 1.107650\tBest loss: 1.076787\tAccuracy: 69.20%\n",
      "299\tValidation loss: 1.121287\tBest loss: 1.076787\tAccuracy: 69.60%\n",
      "300\tValidation loss: 1.104310\tBest loss: 1.076787\tAccuracy: 70.70%\n",
      "301\tValidation loss: 1.068357\tBest loss: 1.068357\tAccuracy: 70.90%\n",
      "302\tValidation loss: 1.073079\tBest loss: 1.068357\tAccuracy: 70.20%\n",
      "303\tValidation loss: 1.070978\tBest loss: 1.068357\tAccuracy: 70.80%\n",
      "304\tValidation loss: 1.088177\tBest loss: 1.068357\tAccuracy: 70.20%\n",
      "305\tValidation loss: 1.115576\tBest loss: 1.068357\tAccuracy: 69.00%\n",
      "306\tValidation loss: 1.098220\tBest loss: 1.068357\tAccuracy: 69.90%\n",
      "307\tValidation loss: 1.084404\tBest loss: 1.068357\tAccuracy: 69.60%\n",
      "308\tValidation loss: 1.075678\tBest loss: 1.068357\tAccuracy: 69.60%\n",
      "309\tValidation loss: 1.075315\tBest loss: 1.068357\tAccuracy: 70.00%\n",
      "310\tValidation loss: 1.081287\tBest loss: 1.068357\tAccuracy: 69.50%\n",
      "311\tValidation loss: 1.075796\tBest loss: 1.068357\tAccuracy: 71.40%\n",
      "312\tValidation loss: 1.078683\tBest loss: 1.068357\tAccuracy: 70.20%\n",
      "313\tValidation loss: 1.059655\tBest loss: 1.059655\tAccuracy: 70.40%\n",
      "314\tValidation loss: 1.039775\tBest loss: 1.039775\tAccuracy: 71.60%\n",
      "315\tValidation loss: 1.057430\tBest loss: 1.039775\tAccuracy: 72.10%\n",
      "316\tValidation loss: 1.062769\tBest loss: 1.039775\tAccuracy: 69.90%\n",
      "317\tValidation loss: 1.075218\tBest loss: 1.039775\tAccuracy: 70.00%\n",
      "318\tValidation loss: 1.085600\tBest loss: 1.039775\tAccuracy: 68.70%\n",
      "319\tValidation loss: 1.064114\tBest loss: 1.039775\tAccuracy: 68.70%\n",
      "320\tValidation loss: 1.061290\tBest loss: 1.039775\tAccuracy: 71.00%\n",
      "321\tValidation loss: 1.065162\tBest loss: 1.039775\tAccuracy: 72.60%\n",
      "322\tValidation loss: 1.076947\tBest loss: 1.039775\tAccuracy: 70.30%\n",
      "323\tValidation loss: 1.052497\tBest loss: 1.039775\tAccuracy: 71.20%\n",
      "324\tValidation loss: 1.043334\tBest loss: 1.039775\tAccuracy: 70.40%\n",
      "325\tValidation loss: 1.058921\tBest loss: 1.039775\tAccuracy: 71.10%\n",
      "326\tValidation loss: 1.048447\tBest loss: 1.039775\tAccuracy: 71.30%\n",
      "327\tValidation loss: 1.046609\tBest loss: 1.039775\tAccuracy: 71.00%\n",
      "328\tValidation loss: 1.054834\tBest loss: 1.039775\tAccuracy: 70.70%\n",
      "329\tValidation loss: 1.034288\tBest loss: 1.034288\tAccuracy: 72.00%\n",
      "330\tValidation loss: 1.078448\tBest loss: 1.034288\tAccuracy: 69.90%\n",
      "331\tValidation loss: 1.042386\tBest loss: 1.034288\tAccuracy: 71.60%\n",
      "332\tValidation loss: 1.039691\tBest loss: 1.034288\tAccuracy: 71.10%\n",
      "333\tValidation loss: 1.035429\tBest loss: 1.034288\tAccuracy: 71.70%\n",
      "334\tValidation loss: 1.034779\tBest loss: 1.034288\tAccuracy: 71.50%\n",
      "335\tValidation loss: 1.040827\tBest loss: 1.034288\tAccuracy: 70.40%\n",
      "336\tValidation loss: 1.014667\tBest loss: 1.014667\tAccuracy: 72.70%\n",
      "337\tValidation loss: 1.039145\tBest loss: 1.014667\tAccuracy: 72.10%\n",
      "338\tValidation loss: 1.061472\tBest loss: 1.014667\tAccuracy: 71.10%\n",
      "339\tValidation loss: 1.052247\tBest loss: 1.014667\tAccuracy: 70.40%\n",
      "340\tValidation loss: 1.041378\tBest loss: 1.014667\tAccuracy: 70.40%\n",
      "341\tValidation loss: 1.024262\tBest loss: 1.014667\tAccuracy: 71.80%\n",
      "342\tValidation loss: 1.014608\tBest loss: 1.014608\tAccuracy: 71.40%\n",
      "343\tValidation loss: 1.043338\tBest loss: 1.014608\tAccuracy: 70.50%\n",
      "344\tValidation loss: 1.043457\tBest loss: 1.014608\tAccuracy: 69.80%\n",
      "345\tValidation loss: 1.036565\tBest loss: 1.014608\tAccuracy: 70.40%\n",
      "346\tValidation loss: 1.057637\tBest loss: 1.014608\tAccuracy: 71.30%\n",
      "347\tValidation loss: 1.014854\tBest loss: 1.014608\tAccuracy: 73.10%\n",
      "348\tValidation loss: 1.049696\tBest loss: 1.014608\tAccuracy: 71.20%\n",
      "349\tValidation loss: 1.028533\tBest loss: 1.014608\tAccuracy: 71.70%\n",
      "350\tValidation loss: 1.047094\tBest loss: 1.014608\tAccuracy: 70.40%\n",
      "351\tValidation loss: 1.033628\tBest loss: 1.014608\tAccuracy: 71.60%\n",
      "352\tValidation loss: 1.046739\tBest loss: 1.014608\tAccuracy: 71.10%\n",
      "353\tValidation loss: 1.036193\tBest loss: 1.014608\tAccuracy: 71.70%\n",
      "354\tValidation loss: 1.027445\tBest loss: 1.014608\tAccuracy: 71.90%\n",
      "355\tValidation loss: 1.050707\tBest loss: 1.014608\tAccuracy: 71.30%\n",
      "356\tValidation loss: 1.035165\tBest loss: 1.014608\tAccuracy: 71.30%\n",
      "357\tValidation loss: 1.033416\tBest loss: 1.014608\tAccuracy: 70.50%\n",
      "358\tValidation loss: 1.026481\tBest loss: 1.014608\tAccuracy: 71.60%\n",
      "359\tValidation loss: 1.054605\tBest loss: 1.014608\tAccuracy: 71.10%\n",
      "360\tValidation loss: 1.035112\tBest loss: 1.014608\tAccuracy: 70.40%\n",
      "361\tValidation loss: 1.068870\tBest loss: 1.014608\tAccuracy: 69.10%\n",
      "362\tValidation loss: 1.032176\tBest loss: 1.014608\tAccuracy: 71.10%\n",
      "363\tValidation loss: 1.052642\tBest loss: 1.014608\tAccuracy: 72.60%\n",
      "Early stopping!\n",
      "[[  3.81315011e-04   2.68298481e-03   1.15740271e-02 ...,   3.76892509e-04\n",
      "    1.61309878e-03   1.54645834e-03]\n",
      " [  2.50861051e-11   2.26128918e-07   1.63675984e-09 ...,   6.47046110e-13\n",
      "    2.80568944e-13   4.53399818e-11]\n",
      " [  1.69194107e-06   9.26523935e-05   9.67547749e-06 ...,   9.46303714e-07\n",
      "    7.10126301e-07   3.69524287e-06]\n",
      " ..., \n",
      " [  2.74301827e-04   1.15598385e-04   3.69281595e-04 ...,   2.06236145e-03\n",
      "    2.54515046e-03   4.63353191e-03]\n",
      " [  5.93772802e-06   8.92939352e-06   1.03089742e-05 ...,   1.03746161e-01\n",
      "    3.77415097e-03   5.96381677e-03]\n",
      " [  2.82806297e-07   2.22606127e-06   1.73578564e-06 ...,   2.76270825e-02\n",
      "    1.41107086e-02   1.09554986e-02]]\n",
      "[26 43 43 ..., 36 26 25]\n",
      "[[  4.37634753e-07   3.20956933e-05   5.21879247e-06 ...,   6.87690738e-11\n",
      "    3.89781735e-10   1.14778071e-08]\n",
      " [  1.71273246e-01   1.32294092e-02   8.96001756e-02 ...,   1.78782808e-04\n",
      "    1.57732909e-04   1.41983401e-04]\n",
      " [  5.44454481e-09   2.71209216e-13   1.86025572e-05 ...,   8.05848721e-11\n",
      "    3.77890536e-14   7.35868004e-15]\n",
      " ..., \n",
      " [  3.44139989e-05   2.77199259e-04   2.32603861e-06 ...,   6.31649399e-08\n",
      "    2.32245981e-07   1.36299514e-08]\n",
      " [  2.40328312e-02   4.77324426e-03   1.29655367e-02 ...,   1.17256334e-02\n",
      "    1.92180686e-02   1.36103434e-02]\n",
      " [  4.73124873e-10   2.83980395e-10   9.48703355e-12 ...,   3.65359373e-02\n",
      "    1.55702629e-03   8.97438467e-01]]\n",
      "[20 19 16 ...,  6 20 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 2.5min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.942559\tBest loss: 3.942559\tAccuracy: 4.10%\n",
      "1\tValidation loss: 3.781525\tBest loss: 3.781525\tAccuracy: 4.40%\n",
      "2\tValidation loss: 3.648438\tBest loss: 3.648438\tAccuracy: 8.60%\n",
      "3\tValidation loss: 3.651055\tBest loss: 3.648438\tAccuracy: 7.60%\n",
      "4\tValidation loss: 3.640229\tBest loss: 3.640229\tAccuracy: 5.30%\n",
      "5\tValidation loss: 3.582793\tBest loss: 3.582793\tAccuracy: 5.60%\n",
      "6\tValidation loss: 3.549215\tBest loss: 3.549215\tAccuracy: 10.70%\n",
      "7\tValidation loss: 3.548339\tBest loss: 3.548339\tAccuracy: 9.10%\n",
      "8\tValidation loss: 3.492910\tBest loss: 3.492910\tAccuracy: 10.90%\n",
      "9\tValidation loss: 3.491223\tBest loss: 3.491223\tAccuracy: 11.40%\n",
      "10\tValidation loss: 3.481479\tBest loss: 3.481479\tAccuracy: 10.90%\n",
      "11\tValidation loss: 3.414992\tBest loss: 3.414992\tAccuracy: 12.90%\n",
      "12\tValidation loss: 3.428147\tBest loss: 3.414992\tAccuracy: 13.00%\n",
      "13\tValidation loss: 3.371804\tBest loss: 3.371804\tAccuracy: 14.70%\n",
      "14\tValidation loss: 3.372139\tBest loss: 3.371804\tAccuracy: 14.30%\n",
      "15\tValidation loss: 3.289309\tBest loss: 3.289309\tAccuracy: 14.20%\n",
      "16\tValidation loss: 3.287653\tBest loss: 3.287653\tAccuracy: 15.10%\n",
      "17\tValidation loss: 3.247645\tBest loss: 3.247645\tAccuracy: 15.90%\n",
      "18\tValidation loss: 3.199375\tBest loss: 3.199375\tAccuracy: 16.30%\n",
      "19\tValidation loss: 3.211922\tBest loss: 3.199375\tAccuracy: 15.90%\n",
      "20\tValidation loss: 3.167924\tBest loss: 3.167924\tAccuracy: 17.30%\n",
      "21\tValidation loss: 3.090419\tBest loss: 3.090419\tAccuracy: 19.80%\n",
      "22\tValidation loss: 3.098826\tBest loss: 3.090419\tAccuracy: 17.70%\n",
      "23\tValidation loss: 3.007753\tBest loss: 3.007753\tAccuracy: 20.00%\n",
      "24\tValidation loss: 2.982681\tBest loss: 2.982681\tAccuracy: 20.60%\n",
      "25\tValidation loss: 2.984860\tBest loss: 2.982681\tAccuracy: 20.60%\n",
      "26\tValidation loss: 2.906631\tBest loss: 2.906631\tAccuracy: 23.00%\n",
      "27\tValidation loss: 2.884422\tBest loss: 2.884422\tAccuracy: 22.50%\n",
      "28\tValidation loss: 2.873855\tBest loss: 2.873855\tAccuracy: 22.60%\n",
      "29\tValidation loss: 2.851382\tBest loss: 2.851382\tAccuracy: 21.50%\n",
      "30\tValidation loss: 2.794839\tBest loss: 2.794839\tAccuracy: 24.80%\n",
      "31\tValidation loss: 2.782448\tBest loss: 2.782448\tAccuracy: 24.80%\n",
      "32\tValidation loss: 2.760343\tBest loss: 2.760343\tAccuracy: 26.10%\n",
      "33\tValidation loss: 2.715577\tBest loss: 2.715577\tAccuracy: 25.30%\n",
      "34\tValidation loss: 2.698289\tBest loss: 2.698289\tAccuracy: 30.20%\n",
      "35\tValidation loss: 2.625253\tBest loss: 2.625253\tAccuracy: 27.50%\n",
      "36\tValidation loss: 2.613050\tBest loss: 2.613050\tAccuracy: 28.70%\n",
      "37\tValidation loss: 2.619780\tBest loss: 2.613050\tAccuracy: 28.80%\n",
      "38\tValidation loss: 2.547077\tBest loss: 2.547077\tAccuracy: 31.00%\n",
      "39\tValidation loss: 2.508019\tBest loss: 2.508019\tAccuracy: 29.20%\n",
      "40\tValidation loss: 2.553466\tBest loss: 2.508019\tAccuracy: 31.70%\n",
      "41\tValidation loss: 2.524915\tBest loss: 2.508019\tAccuracy: 32.00%\n",
      "42\tValidation loss: 2.471405\tBest loss: 2.471405\tAccuracy: 32.20%\n",
      "43\tValidation loss: 2.468306\tBest loss: 2.468306\tAccuracy: 32.50%\n",
      "44\tValidation loss: 2.426870\tBest loss: 2.426870\tAccuracy: 32.30%\n",
      "45\tValidation loss: 2.456469\tBest loss: 2.426870\tAccuracy: 29.70%\n",
      "46\tValidation loss: 2.380565\tBest loss: 2.380565\tAccuracy: 33.00%\n",
      "47\tValidation loss: 2.367847\tBest loss: 2.367847\tAccuracy: 35.70%\n",
      "48\tValidation loss: 2.333656\tBest loss: 2.333656\tAccuracy: 34.90%\n",
      "49\tValidation loss: 2.348812\tBest loss: 2.333656\tAccuracy: 32.90%\n",
      "50\tValidation loss: 2.333005\tBest loss: 2.333005\tAccuracy: 36.00%\n",
      "51\tValidation loss: 2.269757\tBest loss: 2.269757\tAccuracy: 38.30%\n",
      "52\tValidation loss: 2.292471\tBest loss: 2.269757\tAccuracy: 39.40%\n",
      "53\tValidation loss: 2.244955\tBest loss: 2.244955\tAccuracy: 39.40%\n",
      "54\tValidation loss: 2.195697\tBest loss: 2.195697\tAccuracy: 37.80%\n",
      "55\tValidation loss: 2.232872\tBest loss: 2.195697\tAccuracy: 38.70%\n",
      "56\tValidation loss: 2.151226\tBest loss: 2.151226\tAccuracy: 40.70%\n",
      "57\tValidation loss: 2.178067\tBest loss: 2.151226\tAccuracy: 38.50%\n",
      "58\tValidation loss: 2.106800\tBest loss: 2.106800\tAccuracy: 42.50%\n",
      "59\tValidation loss: 2.149869\tBest loss: 2.106800\tAccuracy: 40.50%\n",
      "60\tValidation loss: 2.083425\tBest loss: 2.083425\tAccuracy: 43.00%\n",
      "61\tValidation loss: 2.141132\tBest loss: 2.083425\tAccuracy: 39.80%\n",
      "62\tValidation loss: 2.090959\tBest loss: 2.083425\tAccuracy: 42.90%\n",
      "63\tValidation loss: 2.097225\tBest loss: 2.083425\tAccuracy: 41.50%\n",
      "64\tValidation loss: 2.055806\tBest loss: 2.055806\tAccuracy: 45.20%\n",
      "65\tValidation loss: 2.065711\tBest loss: 2.055806\tAccuracy: 38.90%\n",
      "66\tValidation loss: 2.076534\tBest loss: 2.055806\tAccuracy: 44.40%\n",
      "67\tValidation loss: 2.043894\tBest loss: 2.043894\tAccuracy: 42.70%\n",
      "68\tValidation loss: 2.005048\tBest loss: 2.005048\tAccuracy: 44.50%\n",
      "69\tValidation loss: 1.981047\tBest loss: 1.981047\tAccuracy: 45.10%\n",
      "70\tValidation loss: 2.015445\tBest loss: 1.981047\tAccuracy: 42.10%\n",
      "71\tValidation loss: 1.954008\tBest loss: 1.954008\tAccuracy: 46.10%\n",
      "72\tValidation loss: 1.997400\tBest loss: 1.954008\tAccuracy: 45.40%\n",
      "73\tValidation loss: 1.910180\tBest loss: 1.910180\tAccuracy: 48.40%\n",
      "74\tValidation loss: 1.926752\tBest loss: 1.910180\tAccuracy: 46.30%\n",
      "75\tValidation loss: 1.943676\tBest loss: 1.910180\tAccuracy: 48.30%\n",
      "76\tValidation loss: 1.878838\tBest loss: 1.878838\tAccuracy: 49.50%\n",
      "77\tValidation loss: 1.891954\tBest loss: 1.878838\tAccuracy: 47.10%\n",
      "78\tValidation loss: 1.860552\tBest loss: 1.860552\tAccuracy: 47.70%\n",
      "79\tValidation loss: 1.833110\tBest loss: 1.833110\tAccuracy: 52.30%\n",
      "80\tValidation loss: 1.857676\tBest loss: 1.833110\tAccuracy: 49.10%\n",
      "81\tValidation loss: 1.891780\tBest loss: 1.833110\tAccuracy: 46.80%\n",
      "82\tValidation loss: 1.835697\tBest loss: 1.833110\tAccuracy: 51.20%\n",
      "83\tValidation loss: 1.817111\tBest loss: 1.817111\tAccuracy: 51.80%\n",
      "84\tValidation loss: 1.813320\tBest loss: 1.813320\tAccuracy: 50.30%\n",
      "85\tValidation loss: 1.833033\tBest loss: 1.813320\tAccuracy: 52.80%\n",
      "86\tValidation loss: 1.786569\tBest loss: 1.786569\tAccuracy: 52.50%\n",
      "87\tValidation loss: 1.814328\tBest loss: 1.786569\tAccuracy: 50.10%\n",
      "88\tValidation loss: 1.758937\tBest loss: 1.758937\tAccuracy: 50.80%\n",
      "89\tValidation loss: 1.830715\tBest loss: 1.758937\tAccuracy: 47.90%\n",
      "90\tValidation loss: 1.775175\tBest loss: 1.758937\tAccuracy: 51.80%\n",
      "91\tValidation loss: 1.770554\tBest loss: 1.758937\tAccuracy: 50.30%\n",
      "92\tValidation loss: 1.754070\tBest loss: 1.754070\tAccuracy: 52.10%\n",
      "93\tValidation loss: 1.772344\tBest loss: 1.754070\tAccuracy: 51.10%\n",
      "94\tValidation loss: 1.767344\tBest loss: 1.754070\tAccuracy: 50.40%\n",
      "95\tValidation loss: 1.695725\tBest loss: 1.695725\tAccuracy: 54.90%\n",
      "96\tValidation loss: 1.700256\tBest loss: 1.695725\tAccuracy: 53.40%\n",
      "97\tValidation loss: 1.701592\tBest loss: 1.695725\tAccuracy: 54.10%\n",
      "98\tValidation loss: 1.673517\tBest loss: 1.673517\tAccuracy: 53.70%\n",
      "99\tValidation loss: 1.686043\tBest loss: 1.673517\tAccuracy: 54.90%\n",
      "100\tValidation loss: 1.676825\tBest loss: 1.673517\tAccuracy: 54.90%\n",
      "101\tValidation loss: 1.662420\tBest loss: 1.662420\tAccuracy: 55.70%\n",
      "102\tValidation loss: 1.660377\tBest loss: 1.660377\tAccuracy: 55.00%\n",
      "103\tValidation loss: 1.756183\tBest loss: 1.660377\tAccuracy: 51.50%\n",
      "104\tValidation loss: 1.640611\tBest loss: 1.640611\tAccuracy: 54.90%\n",
      "105\tValidation loss: 1.635082\tBest loss: 1.635082\tAccuracy: 55.80%\n",
      "106\tValidation loss: 1.644143\tBest loss: 1.635082\tAccuracy: 54.80%\n",
      "107\tValidation loss: 1.594554\tBest loss: 1.594554\tAccuracy: 56.30%\n",
      "108\tValidation loss: 1.578244\tBest loss: 1.578244\tAccuracy: 55.60%\n",
      "109\tValidation loss: 1.636719\tBest loss: 1.578244\tAccuracy: 56.60%\n",
      "110\tValidation loss: 1.621727\tBest loss: 1.578244\tAccuracy: 56.50%\n",
      "111\tValidation loss: 1.581347\tBest loss: 1.578244\tAccuracy: 57.30%\n",
      "112\tValidation loss: 1.608026\tBest loss: 1.578244\tAccuracy: 56.10%\n",
      "113\tValidation loss: 1.646411\tBest loss: 1.578244\tAccuracy: 52.40%\n",
      "114\tValidation loss: 1.579307\tBest loss: 1.578244\tAccuracy: 55.30%\n",
      "115\tValidation loss: 1.585164\tBest loss: 1.578244\tAccuracy: 55.60%\n",
      "116\tValidation loss: 1.585162\tBest loss: 1.578244\tAccuracy: 57.10%\n",
      "117\tValidation loss: 1.514246\tBest loss: 1.514246\tAccuracy: 59.70%\n",
      "118\tValidation loss: 1.582289\tBest loss: 1.514246\tAccuracy: 57.00%\n",
      "119\tValidation loss: 1.536972\tBest loss: 1.514246\tAccuracy: 57.90%\n",
      "120\tValidation loss: 1.546025\tBest loss: 1.514246\tAccuracy: 59.50%\n",
      "121\tValidation loss: 1.532532\tBest loss: 1.514246\tAccuracy: 58.20%\n",
      "122\tValidation loss: 1.520396\tBest loss: 1.514246\tAccuracy: 58.30%\n",
      "123\tValidation loss: 1.532014\tBest loss: 1.514246\tAccuracy: 59.60%\n",
      "124\tValidation loss: 1.512544\tBest loss: 1.512544\tAccuracy: 59.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 1.577082\tBest loss: 1.512544\tAccuracy: 57.30%\n",
      "126\tValidation loss: 1.517370\tBest loss: 1.512544\tAccuracy: 58.30%\n",
      "127\tValidation loss: 1.510564\tBest loss: 1.510564\tAccuracy: 59.30%\n",
      "128\tValidation loss: 1.544732\tBest loss: 1.510564\tAccuracy: 57.50%\n",
      "129\tValidation loss: 1.560134\tBest loss: 1.510564\tAccuracy: 56.80%\n",
      "130\tValidation loss: 1.500023\tBest loss: 1.500023\tAccuracy: 58.70%\n",
      "131\tValidation loss: 1.475388\tBest loss: 1.475388\tAccuracy: 60.80%\n",
      "132\tValidation loss: 1.496587\tBest loss: 1.475388\tAccuracy: 58.00%\n",
      "133\tValidation loss: 1.454498\tBest loss: 1.454498\tAccuracy: 62.20%\n",
      "134\tValidation loss: 1.466251\tBest loss: 1.454498\tAccuracy: 60.10%\n",
      "135\tValidation loss: 1.456843\tBest loss: 1.454498\tAccuracy: 61.10%\n",
      "136\tValidation loss: 1.439872\tBest loss: 1.439872\tAccuracy: 60.30%\n",
      "137\tValidation loss: 1.422824\tBest loss: 1.422824\tAccuracy: 62.40%\n",
      "138\tValidation loss: 1.479587\tBest loss: 1.422824\tAccuracy: 60.90%\n",
      "139\tValidation loss: 1.404217\tBest loss: 1.404217\tAccuracy: 60.80%\n",
      "140\tValidation loss: 1.417868\tBest loss: 1.404217\tAccuracy: 61.70%\n",
      "141\tValidation loss: 1.428019\tBest loss: 1.404217\tAccuracy: 61.70%\n",
      "142\tValidation loss: 1.436222\tBest loss: 1.404217\tAccuracy: 60.70%\n",
      "143\tValidation loss: 1.461162\tBest loss: 1.404217\tAccuracy: 59.10%\n",
      "144\tValidation loss: 1.429430\tBest loss: 1.404217\tAccuracy: 60.60%\n",
      "145\tValidation loss: 1.404727\tBest loss: 1.404217\tAccuracy: 63.00%\n",
      "146\tValidation loss: 1.417119\tBest loss: 1.404217\tAccuracy: 62.10%\n",
      "147\tValidation loss: 1.408514\tBest loss: 1.404217\tAccuracy: 62.00%\n",
      "148\tValidation loss: 1.389290\tBest loss: 1.389290\tAccuracy: 61.90%\n",
      "149\tValidation loss: 1.402307\tBest loss: 1.389290\tAccuracy: 61.60%\n",
      "150\tValidation loss: 1.387837\tBest loss: 1.387837\tAccuracy: 61.30%\n",
      "151\tValidation loss: 1.387886\tBest loss: 1.387837\tAccuracy: 60.70%\n",
      "152\tValidation loss: 1.423116\tBest loss: 1.387837\tAccuracy: 60.90%\n",
      "153\tValidation loss: 1.422814\tBest loss: 1.387837\tAccuracy: 61.80%\n",
      "154\tValidation loss: 1.389155\tBest loss: 1.387837\tAccuracy: 61.70%\n",
      "155\tValidation loss: 1.434415\tBest loss: 1.387837\tAccuracy: 60.60%\n",
      "156\tValidation loss: 1.395204\tBest loss: 1.387837\tAccuracy: 61.70%\n",
      "157\tValidation loss: 1.373557\tBest loss: 1.373557\tAccuracy: 64.10%\n",
      "158\tValidation loss: 1.368640\tBest loss: 1.368640\tAccuracy: 63.50%\n",
      "159\tValidation loss: 1.399181\tBest loss: 1.368640\tAccuracy: 62.20%\n",
      "160\tValidation loss: 1.347264\tBest loss: 1.347264\tAccuracy: 63.60%\n",
      "161\tValidation loss: 1.380264\tBest loss: 1.347264\tAccuracy: 61.40%\n",
      "162\tValidation loss: 1.341942\tBest loss: 1.341942\tAccuracy: 63.40%\n",
      "163\tValidation loss: 1.359393\tBest loss: 1.341942\tAccuracy: 61.50%\n",
      "164\tValidation loss: 1.356089\tBest loss: 1.341942\tAccuracy: 63.30%\n",
      "165\tValidation loss: 1.365276\tBest loss: 1.341942\tAccuracy: 62.70%\n",
      "166\tValidation loss: 1.349222\tBest loss: 1.341942\tAccuracy: 63.30%\n",
      "167\tValidation loss: 1.344368\tBest loss: 1.341942\tAccuracy: 63.10%\n",
      "168\tValidation loss: 1.335156\tBest loss: 1.335156\tAccuracy: 65.60%\n",
      "169\tValidation loss: 1.371034\tBest loss: 1.335156\tAccuracy: 61.90%\n",
      "170\tValidation loss: 1.339693\tBest loss: 1.335156\tAccuracy: 64.40%\n",
      "171\tValidation loss: 1.338724\tBest loss: 1.335156\tAccuracy: 64.10%\n",
      "172\tValidation loss: 1.342372\tBest loss: 1.335156\tAccuracy: 65.50%\n",
      "173\tValidation loss: 1.354360\tBest loss: 1.335156\tAccuracy: 65.30%\n",
      "174\tValidation loss: 1.297540\tBest loss: 1.297540\tAccuracy: 65.20%\n",
      "175\tValidation loss: 1.297045\tBest loss: 1.297045\tAccuracy: 64.90%\n",
      "176\tValidation loss: 1.344966\tBest loss: 1.297045\tAccuracy: 63.20%\n",
      "177\tValidation loss: 1.310882\tBest loss: 1.297045\tAccuracy: 65.50%\n",
      "178\tValidation loss: 1.309240\tBest loss: 1.297045\tAccuracy: 64.20%\n",
      "179\tValidation loss: 1.293875\tBest loss: 1.293875\tAccuracy: 65.20%\n",
      "180\tValidation loss: 1.311548\tBest loss: 1.293875\tAccuracy: 66.30%\n",
      "181\tValidation loss: 1.314251\tBest loss: 1.293875\tAccuracy: 64.10%\n",
      "182\tValidation loss: 1.328016\tBest loss: 1.293875\tAccuracy: 63.70%\n",
      "183\tValidation loss: 1.322318\tBest loss: 1.293875\tAccuracy: 65.40%\n",
      "184\tValidation loss: 1.292413\tBest loss: 1.292413\tAccuracy: 64.60%\n",
      "185\tValidation loss: 1.296857\tBest loss: 1.292413\tAccuracy: 64.10%\n",
      "186\tValidation loss: 1.304264\tBest loss: 1.292413\tAccuracy: 65.60%\n",
      "187\tValidation loss: 1.294272\tBest loss: 1.292413\tAccuracy: 64.30%\n",
      "188\tValidation loss: 1.268139\tBest loss: 1.268139\tAccuracy: 65.90%\n",
      "189\tValidation loss: 1.277050\tBest loss: 1.268139\tAccuracy: 64.80%\n",
      "190\tValidation loss: 1.238407\tBest loss: 1.238407\tAccuracy: 67.00%\n",
      "191\tValidation loss: 1.243605\tBest loss: 1.238407\tAccuracy: 65.50%\n",
      "192\tValidation loss: 1.284075\tBest loss: 1.238407\tAccuracy: 65.20%\n",
      "193\tValidation loss: 1.293362\tBest loss: 1.238407\tAccuracy: 65.80%\n",
      "194\tValidation loss: 1.284446\tBest loss: 1.238407\tAccuracy: 65.60%\n",
      "195\tValidation loss: 1.293481\tBest loss: 1.238407\tAccuracy: 65.20%\n",
      "196\tValidation loss: 1.254023\tBest loss: 1.238407\tAccuracy: 66.60%\n",
      "197\tValidation loss: 1.258217\tBest loss: 1.238407\tAccuracy: 66.20%\n",
      "198\tValidation loss: 1.250177\tBest loss: 1.238407\tAccuracy: 67.00%\n",
      "199\tValidation loss: 1.259483\tBest loss: 1.238407\tAccuracy: 64.00%\n",
      "200\tValidation loss: 1.263251\tBest loss: 1.238407\tAccuracy: 66.00%\n",
      "201\tValidation loss: 1.238473\tBest loss: 1.238407\tAccuracy: 65.50%\n",
      "202\tValidation loss: 1.256756\tBest loss: 1.238407\tAccuracy: 65.70%\n",
      "203\tValidation loss: 1.254976\tBest loss: 1.238407\tAccuracy: 65.00%\n",
      "204\tValidation loss: 1.268924\tBest loss: 1.238407\tAccuracy: 65.50%\n",
      "205\tValidation loss: 1.249082\tBest loss: 1.238407\tAccuracy: 64.50%\n",
      "206\tValidation loss: 1.245171\tBest loss: 1.238407\tAccuracy: 66.50%\n",
      "207\tValidation loss: 1.288717\tBest loss: 1.238407\tAccuracy: 66.10%\n",
      "208\tValidation loss: 1.292197\tBest loss: 1.238407\tAccuracy: 65.00%\n",
      "209\tValidation loss: 1.254114\tBest loss: 1.238407\tAccuracy: 68.30%\n",
      "210\tValidation loss: 1.220088\tBest loss: 1.220088\tAccuracy: 66.40%\n",
      "211\tValidation loss: 1.212749\tBest loss: 1.212749\tAccuracy: 67.70%\n",
      "212\tValidation loss: 1.227024\tBest loss: 1.212749\tAccuracy: 67.30%\n",
      "213\tValidation loss: 1.232525\tBest loss: 1.212749\tAccuracy: 67.30%\n",
      "214\tValidation loss: 1.227126\tBest loss: 1.212749\tAccuracy: 67.40%\n",
      "215\tValidation loss: 1.221438\tBest loss: 1.212749\tAccuracy: 68.60%\n",
      "216\tValidation loss: 1.235636\tBest loss: 1.212749\tAccuracy: 66.80%\n",
      "217\tValidation loss: 1.238715\tBest loss: 1.212749\tAccuracy: 67.40%\n",
      "218\tValidation loss: 1.202281\tBest loss: 1.202281\tAccuracy: 67.50%\n",
      "219\tValidation loss: 1.225381\tBest loss: 1.202281\tAccuracy: 66.40%\n",
      "220\tValidation loss: 1.221198\tBest loss: 1.202281\tAccuracy: 68.10%\n",
      "221\tValidation loss: 1.227226\tBest loss: 1.202281\tAccuracy: 66.00%\n",
      "222\tValidation loss: 1.189634\tBest loss: 1.189634\tAccuracy: 67.90%\n",
      "223\tValidation loss: 1.230053\tBest loss: 1.189634\tAccuracy: 64.70%\n",
      "224\tValidation loss: 1.198007\tBest loss: 1.189634\tAccuracy: 66.50%\n",
      "225\tValidation loss: 1.206008\tBest loss: 1.189634\tAccuracy: 67.70%\n",
      "226\tValidation loss: 1.184285\tBest loss: 1.184285\tAccuracy: 69.80%\n",
      "227\tValidation loss: 1.181582\tBest loss: 1.181582\tAccuracy: 66.70%\n",
      "228\tValidation loss: 1.222776\tBest loss: 1.181582\tAccuracy: 65.60%\n",
      "229\tValidation loss: 1.183695\tBest loss: 1.181582\tAccuracy: 68.50%\n",
      "230\tValidation loss: 1.197904\tBest loss: 1.181582\tAccuracy: 66.20%\n",
      "231\tValidation loss: 1.206591\tBest loss: 1.181582\tAccuracy: 67.00%\n",
      "232\tValidation loss: 1.195326\tBest loss: 1.181582\tAccuracy: 68.20%\n",
      "233\tValidation loss: 1.194307\tBest loss: 1.181582\tAccuracy: 67.40%\n",
      "234\tValidation loss: 1.189658\tBest loss: 1.181582\tAccuracy: 68.00%\n",
      "235\tValidation loss: 1.177925\tBest loss: 1.177925\tAccuracy: 68.30%\n",
      "236\tValidation loss: 1.191585\tBest loss: 1.177925\tAccuracy: 67.20%\n",
      "237\tValidation loss: 1.192961\tBest loss: 1.177925\tAccuracy: 68.20%\n",
      "238\tValidation loss: 1.196942\tBest loss: 1.177925\tAccuracy: 67.50%\n",
      "239\tValidation loss: 1.182001\tBest loss: 1.177925\tAccuracy: 67.50%\n",
      "240\tValidation loss: 1.185357\tBest loss: 1.177925\tAccuracy: 68.40%\n",
      "241\tValidation loss: 1.156120\tBest loss: 1.156120\tAccuracy: 67.30%\n",
      "242\tValidation loss: 1.187773\tBest loss: 1.156120\tAccuracy: 69.10%\n",
      "243\tValidation loss: 1.177257\tBest loss: 1.156120\tAccuracy: 69.60%\n",
      "244\tValidation loss: 1.163859\tBest loss: 1.156120\tAccuracy: 68.70%\n",
      "245\tValidation loss: 1.158951\tBest loss: 1.156120\tAccuracy: 66.70%\n",
      "246\tValidation loss: 1.168023\tBest loss: 1.156120\tAccuracy: 69.00%\n",
      "247\tValidation loss: 1.194473\tBest loss: 1.156120\tAccuracy: 68.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 1.177550\tBest loss: 1.156120\tAccuracy: 69.10%\n",
      "249\tValidation loss: 1.153751\tBest loss: 1.153751\tAccuracy: 69.20%\n",
      "250\tValidation loss: 1.175349\tBest loss: 1.153751\tAccuracy: 68.40%\n",
      "251\tValidation loss: 1.160679\tBest loss: 1.153751\tAccuracy: 68.80%\n",
      "252\tValidation loss: 1.170505\tBest loss: 1.153751\tAccuracy: 67.60%\n",
      "253\tValidation loss: 1.164926\tBest loss: 1.153751\tAccuracy: 68.30%\n",
      "254\tValidation loss: 1.147190\tBest loss: 1.147190\tAccuracy: 69.30%\n",
      "255\tValidation loss: 1.113699\tBest loss: 1.113699\tAccuracy: 69.30%\n",
      "256\tValidation loss: 1.149527\tBest loss: 1.113699\tAccuracy: 68.40%\n",
      "257\tValidation loss: 1.147762\tBest loss: 1.113699\tAccuracy: 69.60%\n",
      "258\tValidation loss: 1.164314\tBest loss: 1.113699\tAccuracy: 70.90%\n",
      "259\tValidation loss: 1.160999\tBest loss: 1.113699\tAccuracy: 68.30%\n",
      "260\tValidation loss: 1.125222\tBest loss: 1.113699\tAccuracy: 69.20%\n",
      "261\tValidation loss: 1.128058\tBest loss: 1.113699\tAccuracy: 69.80%\n",
      "262\tValidation loss: 1.154875\tBest loss: 1.113699\tAccuracy: 68.60%\n",
      "263\tValidation loss: 1.133372\tBest loss: 1.113699\tAccuracy: 69.30%\n",
      "264\tValidation loss: 1.131325\tBest loss: 1.113699\tAccuracy: 70.40%\n",
      "265\tValidation loss: 1.160936\tBest loss: 1.113699\tAccuracy: 68.40%\n",
      "266\tValidation loss: 1.155530\tBest loss: 1.113699\tAccuracy: 68.70%\n",
      "267\tValidation loss: 1.145829\tBest loss: 1.113699\tAccuracy: 69.20%\n",
      "268\tValidation loss: 1.139614\tBest loss: 1.113699\tAccuracy: 68.30%\n",
      "269\tValidation loss: 1.160427\tBest loss: 1.113699\tAccuracy: 67.70%\n",
      "270\tValidation loss: 1.122429\tBest loss: 1.113699\tAccuracy: 69.50%\n",
      "271\tValidation loss: 1.118381\tBest loss: 1.113699\tAccuracy: 68.70%\n",
      "272\tValidation loss: 1.098470\tBest loss: 1.098470\tAccuracy: 70.80%\n",
      "273\tValidation loss: 1.099083\tBest loss: 1.098470\tAccuracy: 68.50%\n",
      "274\tValidation loss: 1.135616\tBest loss: 1.098470\tAccuracy: 69.00%\n",
      "275\tValidation loss: 1.117081\tBest loss: 1.098470\tAccuracy: 70.50%\n",
      "276\tValidation loss: 1.138618\tBest loss: 1.098470\tAccuracy: 68.40%\n",
      "277\tValidation loss: 1.102715\tBest loss: 1.098470\tAccuracy: 70.90%\n",
      "278\tValidation loss: 1.134467\tBest loss: 1.098470\tAccuracy: 69.80%\n",
      "279\tValidation loss: 1.115033\tBest loss: 1.098470\tAccuracy: 69.70%\n",
      "280\tValidation loss: 1.122989\tBest loss: 1.098470\tAccuracy: 69.10%\n",
      "281\tValidation loss: 1.119478\tBest loss: 1.098470\tAccuracy: 70.70%\n",
      "282\tValidation loss: 1.106114\tBest loss: 1.098470\tAccuracy: 69.50%\n",
      "283\tValidation loss: 1.105062\tBest loss: 1.098470\tAccuracy: 69.60%\n",
      "284\tValidation loss: 1.112600\tBest loss: 1.098470\tAccuracy: 71.10%\n",
      "285\tValidation loss: 1.123701\tBest loss: 1.098470\tAccuracy: 69.40%\n",
      "286\tValidation loss: 1.090322\tBest loss: 1.090322\tAccuracy: 70.90%\n",
      "287\tValidation loss: 1.107065\tBest loss: 1.090322\tAccuracy: 69.20%\n",
      "288\tValidation loss: 1.113621\tBest loss: 1.090322\tAccuracy: 69.60%\n",
      "289\tValidation loss: 1.116248\tBest loss: 1.090322\tAccuracy: 70.10%\n",
      "290\tValidation loss: 1.138458\tBest loss: 1.090322\tAccuracy: 68.80%\n",
      "291\tValidation loss: 1.100680\tBest loss: 1.090322\tAccuracy: 69.40%\n",
      "292\tValidation loss: 1.090571\tBest loss: 1.090322\tAccuracy: 70.70%\n",
      "293\tValidation loss: 1.092728\tBest loss: 1.090322\tAccuracy: 69.20%\n",
      "294\tValidation loss: 1.083639\tBest loss: 1.083639\tAccuracy: 70.10%\n",
      "295\tValidation loss: 1.108297\tBest loss: 1.083639\tAccuracy: 69.90%\n",
      "296\tValidation loss: 1.115290\tBest loss: 1.083639\tAccuracy: 69.80%\n",
      "297\tValidation loss: 1.125345\tBest loss: 1.083639\tAccuracy: 69.90%\n",
      "298\tValidation loss: 1.101987\tBest loss: 1.083639\tAccuracy: 70.40%\n",
      "299\tValidation loss: 1.091975\tBest loss: 1.083639\tAccuracy: 70.10%\n",
      "300\tValidation loss: 1.099797\tBest loss: 1.083639\tAccuracy: 69.50%\n",
      "301\tValidation loss: 1.070198\tBest loss: 1.070198\tAccuracy: 71.50%\n",
      "302\tValidation loss: 1.103297\tBest loss: 1.070198\tAccuracy: 69.40%\n",
      "303\tValidation loss: 1.119907\tBest loss: 1.070198\tAccuracy: 70.10%\n",
      "304\tValidation loss: 1.077884\tBest loss: 1.070198\tAccuracy: 69.70%\n",
      "305\tValidation loss: 1.081922\tBest loss: 1.070198\tAccuracy: 70.80%\n",
      "306\tValidation loss: 1.084149\tBest loss: 1.070198\tAccuracy: 71.00%\n",
      "307\tValidation loss: 1.077076\tBest loss: 1.070198\tAccuracy: 70.20%\n",
      "308\tValidation loss: 1.121403\tBest loss: 1.070198\tAccuracy: 69.60%\n",
      "309\tValidation loss: 1.097848\tBest loss: 1.070198\tAccuracy: 70.10%\n",
      "310\tValidation loss: 1.081625\tBest loss: 1.070198\tAccuracy: 70.70%\n",
      "311\tValidation loss: 1.081542\tBest loss: 1.070198\tAccuracy: 70.40%\n",
      "312\tValidation loss: 1.099257\tBest loss: 1.070198\tAccuracy: 69.90%\n",
      "313\tValidation loss: 1.098113\tBest loss: 1.070198\tAccuracy: 71.70%\n",
      "314\tValidation loss: 1.078166\tBest loss: 1.070198\tAccuracy: 71.10%\n",
      "315\tValidation loss: 1.116304\tBest loss: 1.070198\tAccuracy: 71.60%\n",
      "316\tValidation loss: 1.088071\tBest loss: 1.070198\tAccuracy: 70.70%\n",
      "317\tValidation loss: 1.080407\tBest loss: 1.070198\tAccuracy: 71.10%\n",
      "318\tValidation loss: 1.062833\tBest loss: 1.062833\tAccuracy: 72.30%\n",
      "319\tValidation loss: 1.070038\tBest loss: 1.062833\tAccuracy: 70.80%\n",
      "320\tValidation loss: 1.076873\tBest loss: 1.062833\tAccuracy: 70.00%\n",
      "321\tValidation loss: 1.075771\tBest loss: 1.062833\tAccuracy: 71.20%\n",
      "322\tValidation loss: 1.082646\tBest loss: 1.062833\tAccuracy: 70.10%\n",
      "323\tValidation loss: 1.053452\tBest loss: 1.053452\tAccuracy: 70.80%\n",
      "324\tValidation loss: 1.066484\tBest loss: 1.053452\tAccuracy: 71.30%\n",
      "325\tValidation loss: 1.080692\tBest loss: 1.053452\tAccuracy: 69.80%\n",
      "326\tValidation loss: 1.086313\tBest loss: 1.053452\tAccuracy: 70.60%\n",
      "327\tValidation loss: 1.080965\tBest loss: 1.053452\tAccuracy: 70.10%\n",
      "328\tValidation loss: 1.057188\tBest loss: 1.053452\tAccuracy: 72.50%\n",
      "329\tValidation loss: 1.111511\tBest loss: 1.053452\tAccuracy: 70.60%\n",
      "330\tValidation loss: 1.057765\tBest loss: 1.053452\tAccuracy: 72.10%\n",
      "331\tValidation loss: 1.087049\tBest loss: 1.053452\tAccuracy: 71.00%\n",
      "332\tValidation loss: 1.033334\tBest loss: 1.033334\tAccuracy: 72.70%\n",
      "333\tValidation loss: 1.063255\tBest loss: 1.033334\tAccuracy: 72.30%\n",
      "334\tValidation loss: 1.076400\tBest loss: 1.033334\tAccuracy: 71.50%\n",
      "335\tValidation loss: 1.050900\tBest loss: 1.033334\tAccuracy: 71.00%\n",
      "336\tValidation loss: 1.045250\tBest loss: 1.033334\tAccuracy: 72.70%\n",
      "337\tValidation loss: 1.069401\tBest loss: 1.033334\tAccuracy: 70.10%\n",
      "338\tValidation loss: 1.036659\tBest loss: 1.033334\tAccuracy: 71.60%\n",
      "339\tValidation loss: 1.077242\tBest loss: 1.033334\tAccuracy: 69.70%\n",
      "340\tValidation loss: 1.075519\tBest loss: 1.033334\tAccuracy: 71.20%\n",
      "341\tValidation loss: 1.032492\tBest loss: 1.032492\tAccuracy: 71.30%\n",
      "342\tValidation loss: 1.086589\tBest loss: 1.032492\tAccuracy: 71.20%\n",
      "343\tValidation loss: 1.053347\tBest loss: 1.032492\tAccuracy: 71.60%\n",
      "344\tValidation loss: 1.074951\tBest loss: 1.032492\tAccuracy: 72.30%\n",
      "345\tValidation loss: 1.049350\tBest loss: 1.032492\tAccuracy: 71.50%\n",
      "346\tValidation loss: 1.046651\tBest loss: 1.032492\tAccuracy: 71.10%\n",
      "347\tValidation loss: 1.055282\tBest loss: 1.032492\tAccuracy: 72.00%\n",
      "348\tValidation loss: 1.051263\tBest loss: 1.032492\tAccuracy: 70.30%\n",
      "349\tValidation loss: 1.065964\tBest loss: 1.032492\tAccuracy: 72.20%\n",
      "350\tValidation loss: 1.041965\tBest loss: 1.032492\tAccuracy: 72.20%\n",
      "351\tValidation loss: 1.045932\tBest loss: 1.032492\tAccuracy: 73.00%\n",
      "352\tValidation loss: 1.038023\tBest loss: 1.032492\tAccuracy: 73.20%\n",
      "353\tValidation loss: 1.034442\tBest loss: 1.032492\tAccuracy: 73.00%\n",
      "354\tValidation loss: 1.054218\tBest loss: 1.032492\tAccuracy: 71.20%\n",
      "355\tValidation loss: 1.035609\tBest loss: 1.032492\tAccuracy: 73.00%\n",
      "356\tValidation loss: 1.018294\tBest loss: 1.018294\tAccuracy: 71.90%\n",
      "357\tValidation loss: 1.086066\tBest loss: 1.018294\tAccuracy: 70.80%\n",
      "358\tValidation loss: 1.044008\tBest loss: 1.018294\tAccuracy: 70.80%\n",
      "359\tValidation loss: 1.034439\tBest loss: 1.018294\tAccuracy: 71.40%\n",
      "360\tValidation loss: 1.033595\tBest loss: 1.018294\tAccuracy: 70.00%\n",
      "361\tValidation loss: 1.033861\tBest loss: 1.018294\tAccuracy: 72.00%\n",
      "362\tValidation loss: 1.031737\tBest loss: 1.018294\tAccuracy: 71.50%\n",
      "363\tValidation loss: 1.066614\tBest loss: 1.018294\tAccuracy: 68.90%\n",
      "364\tValidation loss: 1.023215\tBest loss: 1.018294\tAccuracy: 72.40%\n",
      "365\tValidation loss: 1.027888\tBest loss: 1.018294\tAccuracy: 72.10%\n",
      "366\tValidation loss: 1.022237\tBest loss: 1.018294\tAccuracy: 71.40%\n",
      "367\tValidation loss: 1.020882\tBest loss: 1.018294\tAccuracy: 72.90%\n",
      "368\tValidation loss: 1.058352\tBest loss: 1.018294\tAccuracy: 70.60%\n",
      "369\tValidation loss: 1.025593\tBest loss: 1.018294\tAccuracy: 72.10%\n",
      "370\tValidation loss: 1.032651\tBest loss: 1.018294\tAccuracy: 72.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\tValidation loss: 1.041829\tBest loss: 1.018294\tAccuracy: 71.70%\n",
      "372\tValidation loss: 1.033180\tBest loss: 1.018294\tAccuracy: 71.50%\n",
      "373\tValidation loss: 1.019945\tBest loss: 1.018294\tAccuracy: 72.30%\n",
      "374\tValidation loss: 1.004325\tBest loss: 1.004325\tAccuracy: 72.60%\n",
      "375\tValidation loss: 1.028124\tBest loss: 1.004325\tAccuracy: 70.80%\n",
      "376\tValidation loss: 1.032691\tBest loss: 1.004325\tAccuracy: 72.40%\n",
      "377\tValidation loss: 1.002701\tBest loss: 1.002701\tAccuracy: 71.20%\n",
      "378\tValidation loss: 1.023015\tBest loss: 1.002701\tAccuracy: 71.90%\n",
      "379\tValidation loss: 1.008662\tBest loss: 1.002701\tAccuracy: 73.60%\n",
      "380\tValidation loss: 1.059523\tBest loss: 1.002701\tAccuracy: 71.40%\n",
      "381\tValidation loss: 1.005565\tBest loss: 1.002701\tAccuracy: 73.00%\n",
      "382\tValidation loss: 1.008921\tBest loss: 1.002701\tAccuracy: 71.70%\n",
      "383\tValidation loss: 1.006552\tBest loss: 1.002701\tAccuracy: 72.20%\n",
      "384\tValidation loss: 1.027625\tBest loss: 1.002701\tAccuracy: 70.70%\n",
      "385\tValidation loss: 1.029036\tBest loss: 1.002701\tAccuracy: 72.20%\n",
      "386\tValidation loss: 1.033250\tBest loss: 1.002701\tAccuracy: 72.60%\n",
      "387\tValidation loss: 1.008941\tBest loss: 1.002701\tAccuracy: 71.80%\n",
      "388\tValidation loss: 1.001646\tBest loss: 1.001646\tAccuracy: 73.10%\n",
      "389\tValidation loss: 0.996392\tBest loss: 0.996392\tAccuracy: 73.50%\n",
      "390\tValidation loss: 1.021393\tBest loss: 0.996392\tAccuracy: 72.20%\n",
      "391\tValidation loss: 1.004509\tBest loss: 0.996392\tAccuracy: 72.70%\n",
      "392\tValidation loss: 1.001271\tBest loss: 0.996392\tAccuracy: 72.70%\n",
      "393\tValidation loss: 0.995519\tBest loss: 0.995519\tAccuracy: 73.10%\n",
      "394\tValidation loss: 1.029098\tBest loss: 0.995519\tAccuracy: 73.00%\n",
      "395\tValidation loss: 1.008706\tBest loss: 0.995519\tAccuracy: 73.30%\n",
      "396\tValidation loss: 0.998019\tBest loss: 0.995519\tAccuracy: 72.80%\n",
      "397\tValidation loss: 1.008618\tBest loss: 0.995519\tAccuracy: 71.80%\n",
      "398\tValidation loss: 1.007930\tBest loss: 0.995519\tAccuracy: 72.70%\n",
      "399\tValidation loss: 0.994674\tBest loss: 0.994674\tAccuracy: 72.90%\n",
      "400\tValidation loss: 1.011308\tBest loss: 0.994674\tAccuracy: 72.50%\n",
      "401\tValidation loss: 1.000161\tBest loss: 0.994674\tAccuracy: 72.90%\n",
      "402\tValidation loss: 1.007431\tBest loss: 0.994674\tAccuracy: 72.30%\n",
      "403\tValidation loss: 1.028294\tBest loss: 0.994674\tAccuracy: 71.50%\n",
      "404\tValidation loss: 1.008093\tBest loss: 0.994674\tAccuracy: 72.90%\n",
      "405\tValidation loss: 1.011225\tBest loss: 0.994674\tAccuracy: 73.40%\n",
      "406\tValidation loss: 0.996086\tBest loss: 0.994674\tAccuracy: 73.30%\n",
      "407\tValidation loss: 0.983912\tBest loss: 0.983912\tAccuracy: 71.80%\n",
      "408\tValidation loss: 0.977156\tBest loss: 0.977156\tAccuracy: 72.30%\n",
      "409\tValidation loss: 1.036065\tBest loss: 0.977156\tAccuracy: 72.10%\n",
      "410\tValidation loss: 0.998381\tBest loss: 0.977156\tAccuracy: 72.10%\n",
      "411\tValidation loss: 1.045577\tBest loss: 0.977156\tAccuracy: 71.20%\n",
      "412\tValidation loss: 1.020393\tBest loss: 0.977156\tAccuracy: 73.00%\n",
      "413\tValidation loss: 0.988002\tBest loss: 0.977156\tAccuracy: 73.40%\n",
      "414\tValidation loss: 0.994102\tBest loss: 0.977156\tAccuracy: 72.40%\n",
      "415\tValidation loss: 1.002101\tBest loss: 0.977156\tAccuracy: 72.30%\n",
      "416\tValidation loss: 0.994978\tBest loss: 0.977156\tAccuracy: 72.30%\n",
      "417\tValidation loss: 0.994940\tBest loss: 0.977156\tAccuracy: 73.80%\n",
      "418\tValidation loss: 0.998692\tBest loss: 0.977156\tAccuracy: 73.00%\n",
      "419\tValidation loss: 1.011742\tBest loss: 0.977156\tAccuracy: 72.30%\n",
      "420\tValidation loss: 0.979883\tBest loss: 0.977156\tAccuracy: 72.90%\n",
      "421\tValidation loss: 1.001195\tBest loss: 0.977156\tAccuracy: 72.00%\n",
      "422\tValidation loss: 0.979974\tBest loss: 0.977156\tAccuracy: 74.00%\n",
      "423\tValidation loss: 0.990602\tBest loss: 0.977156\tAccuracy: 73.40%\n",
      "424\tValidation loss: 0.997388\tBest loss: 0.977156\tAccuracy: 74.00%\n",
      "425\tValidation loss: 0.983127\tBest loss: 0.977156\tAccuracy: 73.30%\n",
      "426\tValidation loss: 0.991972\tBest loss: 0.977156\tAccuracy: 73.10%\n",
      "427\tValidation loss: 1.020466\tBest loss: 0.977156\tAccuracy: 72.20%\n",
      "428\tValidation loss: 0.986350\tBest loss: 0.977156\tAccuracy: 72.40%\n",
      "429\tValidation loss: 1.003193\tBest loss: 0.977156\tAccuracy: 72.50%\n",
      "Early stopping!\n",
      "[[  3.34259903e-06   9.71703266e-05   1.43694524e-05 ...,   1.13717870e-04\n",
      "    6.64284642e-07   1.33937317e-06]\n",
      " [  5.83417418e-23   1.59775859e-14   5.31702883e-13 ...,   1.61815505e-12\n",
      "    6.73158971e-14   6.88770262e-14]\n",
      " [  7.78737103e-06   1.83431688e-03   7.16352428e-04 ...,   1.51251625e-05\n",
      "    4.93792395e-05   9.79661636e-05]\n",
      " ..., \n",
      " [  1.75638088e-05   1.18308424e-04   5.05602620e-05 ...,   3.95814617e-08\n",
      "    2.25518040e-08   5.51936996e-10]\n",
      " [  4.90741245e-02   1.37261786e-02   1.18937483e-02 ...,   2.53695305e-02\n",
      "    8.71994253e-03   7.66134355e-03]\n",
      " [  7.73165851e-17   1.47827584e-12   3.77340845e-14 ...,   9.71995387e-03\n",
      "    2.13440857e-03   9.61274385e-01]]\n",
      "[41 41 20 ...,  6 11 47]\n",
      "[[  4.42054528e-07   6.24054461e-04   4.88598162e-05 ...,   2.22962985e-11\n",
      "    6.86845095e-11   6.14546247e-10]\n",
      " [  1.37893081e-01   1.09630078e-02   6.97519183e-02 ...,   1.70907821e-04\n",
      "    1.43215540e-04   4.71454186e-05]\n",
      " [  1.19728142e-12   3.58844932e-14   2.14956266e-08 ...,   9.68059855e-09\n",
      "    2.46319061e-14   2.33743570e-15]\n",
      " ..., \n",
      " [  6.13329175e-04   1.91861240e-04   1.16707364e-04 ...,   2.03698664e-03\n",
      "    7.75052409e-04   5.08920150e-03]\n",
      " [  2.24273844e-08   5.97336225e-08   2.74606208e-07 ...,   5.75261936e-02\n",
      "    1.21567519e-02   5.86689031e-03]\n",
      " [  1.15922568e-07   1.23601978e-07   5.78633035e-07 ...,   1.78563148e-02\n",
      "    6.69781258e-03   7.44470162e-03]]\n",
      "[20 19 16 ...,  9 26 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 2.7min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 8.976316\tBest loss: 8.976316\tAccuracy: 2.50%\n",
      "1\tValidation loss: 6.753126\tBest loss: 6.753126\tAccuracy: 2.90%\n",
      "2\tValidation loss: 4.344424\tBest loss: 4.344424\tAccuracy: 4.00%\n",
      "3\tValidation loss: 4.042170\tBest loss: 4.042170\tAccuracy: 3.00%\n",
      "4\tValidation loss: 3.987183\tBest loss: 3.987183\tAccuracy: 3.80%\n",
      "5\tValidation loss: 3.869053\tBest loss: 3.869053\tAccuracy: 1.90%\n",
      "6\tValidation loss: 3.944287\tBest loss: 3.869053\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.962279\tBest loss: 3.869053\tAccuracy: 3.70%\n",
      "8\tValidation loss: 4.006392\tBest loss: 3.869053\tAccuracy: 3.00%\n",
      "9\tValidation loss: 3.967088\tBest loss: 3.869053\tAccuracy: 4.00%\n",
      "10\tValidation loss: 4.016913\tBest loss: 3.869053\tAccuracy: 4.50%\n",
      "11\tValidation loss: 4.014966\tBest loss: 3.869053\tAccuracy: 3.70%\n",
      "12\tValidation loss: 4.044222\tBest loss: 3.869053\tAccuracy: 4.50%\n",
      "13\tValidation loss: 3.951820\tBest loss: 3.869053\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.958941\tBest loss: 3.869053\tAccuracy: 3.70%\n",
      "15\tValidation loss: 4.046794\tBest loss: 3.869053\tAccuracy: 3.00%\n",
      "16\tValidation loss: 3.963321\tBest loss: 3.869053\tAccuracy: 3.00%\n",
      "17\tValidation loss: 3.926934\tBest loss: 3.869053\tAccuracy: 3.10%\n",
      "18\tValidation loss: 3.968432\tBest loss: 3.869053\tAccuracy: 2.20%\n",
      "19\tValidation loss: 4.005541\tBest loss: 3.869053\tAccuracy: 4.50%\n",
      "20\tValidation loss: 4.021541\tBest loss: 3.869053\tAccuracy: 3.00%\n",
      "21\tValidation loss: 3.992214\tBest loss: 3.869053\tAccuracy: 3.70%\n",
      "22\tValidation loss: 4.013907\tBest loss: 3.869053\tAccuracy: 0.90%\n",
      "23\tValidation loss: 4.081538\tBest loss: 3.869053\tAccuracy: 0.90%\n",
      "24\tValidation loss: 4.055112\tBest loss: 3.869053\tAccuracy: 2.20%\n",
      "25\tValidation loss: 4.119255\tBest loss: 3.869053\tAccuracy: 2.20%\n",
      "26\tValidation loss: 4.031699\tBest loss: 3.869053\tAccuracy: 3.80%\n",
      "Early stopping!\n",
      "[[ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " ..., \n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]]\n",
      "[39 39 39 ..., 39 39 39]\n",
      "[[ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " ..., \n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]\n",
      " [ 0.02787921  0.03814876  0.01698679 ...,  0.02988351  0.00993307\n",
      "   0.01868918]]\n",
      "[39 39 39 ..., 39 39 39]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   2.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 10.022703\tBest loss: 10.022703\tAccuracy: 1.80%\n",
      "1\tValidation loss: 6.150612\tBest loss: 6.150612\tAccuracy: 2.20%\n",
      "2\tValidation loss: 4.323010\tBest loss: 4.323010\tAccuracy: 1.80%\n",
      "3\tValidation loss: 3.986566\tBest loss: 3.986566\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.982142\tBest loss: 3.982142\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.986630\tBest loss: 3.982142\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.944937\tBest loss: 3.944937\tAccuracy: 2.30%\n",
      "7\tValidation loss: 3.933224\tBest loss: 3.933224\tAccuracy: 3.00%\n",
      "8\tValidation loss: 3.899641\tBest loss: 3.899641\tAccuracy: 2.20%\n",
      "9\tValidation loss: 3.943661\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.954900\tBest loss: 3.899641\tAccuracy: 2.30%\n",
      "11\tValidation loss: 4.019789\tBest loss: 3.899641\tAccuracy: 2.30%\n",
      "12\tValidation loss: 4.158895\tBest loss: 3.899641\tAccuracy: 3.80%\n",
      "13\tValidation loss: 4.064096\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "14\tValidation loss: 4.002132\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.979136\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.919296\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.991729\tBest loss: 3.899641\tAccuracy: 3.60%\n",
      "18\tValidation loss: 4.019849\tBest loss: 3.899641\tAccuracy: 1.90%\n",
      "19\tValidation loss: 4.033827\tBest loss: 3.899641\tAccuracy: 1.70%\n",
      "20\tValidation loss: 4.036844\tBest loss: 3.899641\tAccuracy: 2.30%\n",
      "21\tValidation loss: 4.246018\tBest loss: 3.899641\tAccuracy: 3.60%\n",
      "22\tValidation loss: 4.351830\tBest loss: 3.899641\tAccuracy: 3.60%\n",
      "23\tValidation loss: 4.259566\tBest loss: 3.899641\tAccuracy: 3.00%\n",
      "24\tValidation loss: 4.007528\tBest loss: 3.899641\tAccuracy: 3.20%\n",
      "25\tValidation loss: 4.049582\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "26\tValidation loss: 4.274539\tBest loss: 3.899641\tAccuracy: 3.20%\n",
      "27\tValidation loss: 4.084589\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "28\tValidation loss: 4.139665\tBest loss: 3.899641\tAccuracy: 2.30%\n",
      "29\tValidation loss: 4.120295\tBest loss: 3.899641\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " ..., \n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]]\n",
      "[10 10 10 ..., 10 10 10]\n",
      "[[ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " ..., \n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]\n",
      " [ 0.00604218  0.04279464  0.02281785 ...,  0.03310909  0.00764295\n",
      "   0.01682361]]\n",
      "[10 10 10 ..., 10 10 10]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   2.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 10.130575\tBest loss: 10.130575\tAccuracy: 2.30%\n",
      "1\tValidation loss: 7.843312\tBest loss: 7.843312\tAccuracy: 3.70%\n",
      "2\tValidation loss: 4.427358\tBest loss: 4.427358\tAccuracy: 2.50%\n",
      "3\tValidation loss: 3.990759\tBest loss: 3.990759\tAccuracy: 4.00%\n",
      "4\tValidation loss: 3.906029\tBest loss: 3.906029\tAccuracy: 4.50%\n",
      "5\tValidation loss: 3.871943\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.951026\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.952510\tBest loss: 3.871943\tAccuracy: 4.50%\n",
      "8\tValidation loss: 3.889833\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "9\tValidation loss: 4.185869\tBest loss: 3.871943\tAccuracy: 3.00%\n",
      "10\tValidation loss: 3.905402\tBest loss: 3.871943\tAccuracy: 3.80%\n",
      "11\tValidation loss: 3.908363\tBest loss: 3.871943\tAccuracy: 3.80%\n",
      "12\tValidation loss: 4.080077\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.924989\tBest loss: 3.871943\tAccuracy: 3.00%\n",
      "14\tValidation loss: 3.934676\tBest loss: 3.871943\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.889544\tBest loss: 3.871943\tAccuracy: 3.60%\n",
      "16\tValidation loss: 3.977717\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.994799\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "18\tValidation loss: 4.022386\tBest loss: 3.871943\tAccuracy: 4.00%\n",
      "19\tValidation loss: 4.034063\tBest loss: 3.871943\tAccuracy: 3.20%\n",
      "20\tValidation loss: 4.011152\tBest loss: 3.871943\tAccuracy: 2.20%\n",
      "21\tValidation loss: 3.962034\tBest loss: 3.871943\tAccuracy: 3.00%\n",
      "22\tValidation loss: 4.029115\tBest loss: 3.871943\tAccuracy: 3.30%\n",
      "23\tValidation loss: 4.039185\tBest loss: 3.871943\tAccuracy: 3.10%\n",
      "24\tValidation loss: 4.040185\tBest loss: 3.871943\tAccuracy: 4.00%\n",
      "25\tValidation loss: 4.156454\tBest loss: 3.871943\tAccuracy: 3.70%\n",
      "26\tValidation loss: 4.293194\tBest loss: 3.871943\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " ..., \n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " ..., \n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]\n",
      " [ 0.00599728  0.02452354  0.01273498 ...,  0.03090868  0.01536272\n",
      "   0.01530403]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   2.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 5.708571\tBest loss: 5.708571\tAccuracy: 2.50%\n",
      "1\tValidation loss: 4.305632\tBest loss: 4.305632\tAccuracy: 4.10%\n",
      "2\tValidation loss: 3.978353\tBest loss: 3.978353\tAccuracy: 4.20%\n",
      "3\tValidation loss: 3.894342\tBest loss: 3.894342\tAccuracy: 1.90%\n",
      "4\tValidation loss: 3.822148\tBest loss: 3.822148\tAccuracy: 1.70%\n",
      "5\tValidation loss: 3.799258\tBest loss: 3.799258\tAccuracy: 3.60%\n",
      "6\tValidation loss: 3.795562\tBest loss: 3.795562\tAccuracy: 3.50%\n",
      "7\tValidation loss: 3.800313\tBest loss: 3.795562\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.795376\tBest loss: 3.795376\tAccuracy: 4.00%\n",
      "9\tValidation loss: 3.794902\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "10\tValidation loss: 3.801033\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "11\tValidation loss: 3.798348\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.800768\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "13\tValidation loss: 3.800129\tBest loss: 3.794902\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.797606\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.802159\tBest loss: 3.794902\tAccuracy: 3.20%\n",
      "16\tValidation loss: 3.798172\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.801930\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "18\tValidation loss: 3.806420\tBest loss: 3.794902\tAccuracy: 4.00%\n",
      "19\tValidation loss: 3.800303\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.804067\tBest loss: 3.794902\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.803098\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.799390\tBest loss: 3.794902\tAccuracy: 3.00%\n",
      "23\tValidation loss: 3.806967\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "24\tValidation loss: 3.801646\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.809205\tBest loss: 3.794902\tAccuracy: 4.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\tValidation loss: 3.807836\tBest loss: 3.794902\tAccuracy: 3.30%\n",
      "27\tValidation loss: 3.809253\tBest loss: 3.794902\tAccuracy: 3.80%\n",
      "28\tValidation loss: 3.800436\tBest loss: 3.794902\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.807799\tBest loss: 3.794902\tAccuracy: 3.20%\n",
      "30\tValidation loss: 3.799398\tBest loss: 3.794902\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176673  0.03685544  0.0231044  ...,  0.02769572  0.0156169\n",
      "   0.01612534]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " ..., \n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " ..., \n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]\n",
      " [ 0.02176674  0.03685546  0.02310441 ...,  0.02769573  0.0156169\n",
      "   0.01612534]\n",
      " [ 0.02176675  0.03685543  0.02310441 ...,  0.02769572  0.0156169\n",
      "   0.01612533]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   2.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 5.492828\tBest loss: 5.492828\tAccuracy: 3.70%\n",
      "1\tValidation loss: 4.273698\tBest loss: 4.273698\tAccuracy: 2.70%\n",
      "2\tValidation loss: 3.975338\tBest loss: 3.975338\tAccuracy: 1.90%\n",
      "3\tValidation loss: 3.822960\tBest loss: 3.822960\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.803273\tBest loss: 3.803273\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.801570\tBest loss: 3.801570\tAccuracy: 3.20%\n",
      "6\tValidation loss: 3.798450\tBest loss: 3.798450\tAccuracy: 3.40%\n",
      "7\tValidation loss: 3.801656\tBest loss: 3.798450\tAccuracy: 3.60%\n",
      "8\tValidation loss: 3.796166\tBest loss: 3.796166\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.798697\tBest loss: 3.796166\tAccuracy: 4.00%\n",
      "10\tValidation loss: 3.798313\tBest loss: 3.796166\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.795658\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.797054\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.799482\tBest loss: 3.795658\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.800829\tBest loss: 3.795658\tAccuracy: 4.50%\n",
      "15\tValidation loss: 3.803574\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.803731\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.797721\tBest loss: 3.795658\tAccuracy: 3.30%\n",
      "18\tValidation loss: 3.810935\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.802865\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.804024\tBest loss: 3.795658\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.798472\tBest loss: 3.795658\tAccuracy: 4.00%\n",
      "22\tValidation loss: 3.800498\tBest loss: 3.795658\tAccuracy: 3.20%\n",
      "23\tValidation loss: 3.804501\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.806055\tBest loss: 3.795658\tAccuracy: 4.50%\n",
      "25\tValidation loss: 3.811783\tBest loss: 3.795658\tAccuracy: 4.00%\n",
      "26\tValidation loss: 3.813003\tBest loss: 3.795658\tAccuracy: 3.60%\n",
      "27\tValidation loss: 3.810346\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.805546\tBest loss: 3.795658\tAccuracy: 4.00%\n",
      "29\tValidation loss: 3.810276\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.804339\tBest loss: 3.795658\tAccuracy: 3.00%\n",
      "31\tValidation loss: 3.807238\tBest loss: 3.795658\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.802357\tBest loss: 3.795658\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " ..., \n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " [ 0.0150873   0.02961141  0.01832379 ...,  0.030233    0.01661932\n",
      "   0.02020812]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]\n",
      " ..., \n",
      " [ 0.01508722  0.02961125  0.01832342 ...,  0.03023278  0.01661965\n",
      "   0.02020811]\n",
      " [ 0.01508731  0.02961143  0.01832385 ...,  0.03023303  0.01661927\n",
      "   0.02020812]\n",
      " [ 0.01508722  0.02961124  0.01832341 ...,  0.03023277  0.01661966\n",
      "   0.0202081 ]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   3.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 5.843081\tBest loss: 5.843081\tAccuracy: 2.70%\n",
      "1\tValidation loss: 4.844710\tBest loss: 4.844710\tAccuracy: 2.30%\n",
      "2\tValidation loss: 4.289714\tBest loss: 4.289714\tAccuracy: 1.90%\n",
      "3\tValidation loss: 3.945958\tBest loss: 3.945958\tAccuracy: 1.90%\n",
      "4\tValidation loss: 3.807107\tBest loss: 3.807107\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.799427\tBest loss: 3.799427\tAccuracy: 3.40%\n",
      "6\tValidation loss: 3.794979\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.799625\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.797974\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.800099\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "10\tValidation loss: 3.795452\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.799265\tBest loss: 3.794979\tAccuracy: 4.00%\n",
      "12\tValidation loss: 3.800159\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.801514\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.801210\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.802591\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.801754\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.807091\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.805430\tBest loss: 3.794979\tAccuracy: 3.60%\n",
      "19\tValidation loss: 3.807220\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.802303\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.800847\tBest loss: 3.794979\tAccuracy: 4.00%\n",
      "22\tValidation loss: 3.801332\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "23\tValidation loss: 3.807158\tBest loss: 3.794979\tAccuracy: 4.00%\n",
      "24\tValidation loss: 3.805842\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.804644\tBest loss: 3.794979\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.799080\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.809146\tBest loss: 3.794979\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01312494  0.03302804  0.02329968 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " ..., \n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312505  0.0330284   0.02329999 ...,  0.02988808  0.01773367\n",
      "   0.01671419]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312503  0.03302836  0.02329996 ...,  0.02988806  0.01773366\n",
      "   0.01671417]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " ..., \n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]\n",
      " [ 0.01312494  0.03302804  0.02329967 ...,  0.02988771  0.01773376\n",
      "   0.01671406]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   2.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 7.608202\tBest loss: 7.608202\tAccuracy: 37.50%\n",
      "1\tValidation loss: 9.216641\tBest loss: 7.608202\tAccuracy: 39.40%\n",
      "2\tValidation loss: 6.319709\tBest loss: 6.319709\tAccuracy: 49.90%\n",
      "3\tValidation loss: 6.787862\tBest loss: 6.319709\tAccuracy: 51.70%\n",
      "4\tValidation loss: 6.807263\tBest loss: 6.319709\tAccuracy: 53.80%\n",
      "5\tValidation loss: 8.155212\tBest loss: 6.319709\tAccuracy: 55.00%\n",
      "6\tValidation loss: 6.440064\tBest loss: 6.319709\tAccuracy: 58.50%\n",
      "7\tValidation loss: 8.411229\tBest loss: 6.319709\tAccuracy: 56.20%\n",
      "8\tValidation loss: 8.194443\tBest loss: 6.319709\tAccuracy: 58.70%\n",
      "9\tValidation loss: 7.422209\tBest loss: 6.319709\tAccuracy: 55.40%\n",
      "10\tValidation loss: 8.159418\tBest loss: 6.319709\tAccuracy: 60.30%\n",
      "11\tValidation loss: 7.041246\tBest loss: 6.319709\tAccuracy: 62.30%\n",
      "12\tValidation loss: 6.374191\tBest loss: 6.319709\tAccuracy: 62.20%\n",
      "13\tValidation loss: 6.458417\tBest loss: 6.319709\tAccuracy: 61.00%\n",
      "14\tValidation loss: 6.818721\tBest loss: 6.319709\tAccuracy: 62.30%\n",
      "15\tValidation loss: 5.357794\tBest loss: 5.357794\tAccuracy: 67.10%\n",
      "16\tValidation loss: 6.318211\tBest loss: 5.357794\tAccuracy: 64.30%\n",
      "17\tValidation loss: 6.490766\tBest loss: 5.357794\tAccuracy: 61.90%\n",
      "18\tValidation loss: 6.232077\tBest loss: 5.357794\tAccuracy: 64.40%\n",
      "19\tValidation loss: 9.616485\tBest loss: 5.357794\tAccuracy: 62.40%\n",
      "20\tValidation loss: 9.984265\tBest loss: 5.357794\tAccuracy: 59.40%\n",
      "21\tValidation loss: 4.302618\tBest loss: 4.302618\tAccuracy: 69.30%\n",
      "22\tValidation loss: 6.588729\tBest loss: 4.302618\tAccuracy: 65.40%\n",
      "23\tValidation loss: 7.002508\tBest loss: 4.302618\tAccuracy: 62.30%\n",
      "24\tValidation loss: 5.466470\tBest loss: 4.302618\tAccuracy: 69.10%\n",
      "25\tValidation loss: 5.211464\tBest loss: 4.302618\tAccuracy: 71.50%\n",
      "26\tValidation loss: 4.965838\tBest loss: 4.302618\tAccuracy: 71.00%\n",
      "27\tValidation loss: 7.175379\tBest loss: 4.302618\tAccuracy: 65.70%\n",
      "28\tValidation loss: 5.847295\tBest loss: 4.302618\tAccuracy: 69.10%\n",
      "29\tValidation loss: 7.130569\tBest loss: 4.302618\tAccuracy: 66.60%\n",
      "30\tValidation loss: 6.594105\tBest loss: 4.302618\tAccuracy: 67.90%\n",
      "31\tValidation loss: 6.590014\tBest loss: 4.302618\tAccuracy: 65.50%\n",
      "32\tValidation loss: 6.575303\tBest loss: 4.302618\tAccuracy: 67.10%\n",
      "33\tValidation loss: 6.183503\tBest loss: 4.302618\tAccuracy: 70.70%\n",
      "34\tValidation loss: 7.402976\tBest loss: 4.302618\tAccuracy: 67.30%\n",
      "35\tValidation loss: 7.159678\tBest loss: 4.302618\tAccuracy: 68.60%\n",
      "36\tValidation loss: 6.359564\tBest loss: 4.302618\tAccuracy: 69.60%\n",
      "37\tValidation loss: 6.263388\tBest loss: 4.302618\tAccuracy: 67.90%\n",
      "38\tValidation loss: 5.776249\tBest loss: 4.302618\tAccuracy: 69.90%\n",
      "39\tValidation loss: 7.101751\tBest loss: 4.302618\tAccuracy: 65.90%\n",
      "40\tValidation loss: 6.690619\tBest loss: 4.302618\tAccuracy: 67.60%\n",
      "41\tValidation loss: 5.669851\tBest loss: 4.302618\tAccuracy: 70.60%\n",
      "42\tValidation loss: 6.331593\tBest loss: 4.302618\tAccuracy: 69.40%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  5.98174930e-02   3.45089510e-02   4.79293987e-02 ...,   1.81539654e-05\n",
      "    3.98372540e-05   7.18309730e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.23312407e-25   5.56178964e-13   3.37481501e-11 ...,   1.86206416e-05\n",
      "    2.99338731e-20   1.93500484e-15]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.23505735e-29]]\n",
      "[22 19 16 ...,  6 24 25]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.77165417e-03   1.47129660e-02   2.00289339e-02 ...,   1.27357733e-03\n",
      "    6.42038975e-03   8.12802638e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[43 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   8.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 10.156683\tBest loss: 10.156683\tAccuracy: 33.50%\n",
      "1\tValidation loss: 10.612671\tBest loss: 10.156683\tAccuracy: 37.80%\n",
      "2\tValidation loss: 8.784431\tBest loss: 8.784431\tAccuracy: 46.10%\n",
      "3\tValidation loss: 15.858147\tBest loss: 8.784431\tAccuracy: 38.00%\n",
      "4\tValidation loss: 7.043046\tBest loss: 7.043046\tAccuracy: 57.50%\n",
      "5\tValidation loss: 5.512198\tBest loss: 5.512198\tAccuracy: 58.20%\n",
      "6\tValidation loss: 6.189093\tBest loss: 5.512198\tAccuracy: 58.20%\n",
      "7\tValidation loss: 8.736258\tBest loss: 5.512198\tAccuracy: 57.30%\n",
      "8\tValidation loss: 6.571793\tBest loss: 5.512198\tAccuracy: 60.10%\n",
      "9\tValidation loss: 5.872787\tBest loss: 5.512198\tAccuracy: 59.80%\n",
      "10\tValidation loss: 6.051238\tBest loss: 5.512198\tAccuracy: 64.60%\n",
      "11\tValidation loss: 8.570831\tBest loss: 5.512198\tAccuracy: 56.10%\n",
      "12\tValidation loss: 7.603699\tBest loss: 5.512198\tAccuracy: 61.00%\n",
      "13\tValidation loss: 7.344567\tBest loss: 5.512198\tAccuracy: 61.50%\n",
      "14\tValidation loss: 6.417645\tBest loss: 5.512198\tAccuracy: 60.00%\n",
      "15\tValidation loss: 7.165765\tBest loss: 5.512198\tAccuracy: 61.50%\n",
      "16\tValidation loss: 6.651589\tBest loss: 5.512198\tAccuracy: 63.50%\n",
      "17\tValidation loss: 5.168496\tBest loss: 5.168496\tAccuracy: 67.70%\n",
      "18\tValidation loss: 5.725996\tBest loss: 5.168496\tAccuracy: 67.90%\n",
      "19\tValidation loss: 7.037193\tBest loss: 5.168496\tAccuracy: 64.30%\n",
      "20\tValidation loss: 8.256543\tBest loss: 5.168496\tAccuracy: 64.00%\n",
      "21\tValidation loss: 6.090747\tBest loss: 5.168496\tAccuracy: 64.50%\n",
      "22\tValidation loss: 7.515814\tBest loss: 5.168496\tAccuracy: 65.10%\n",
      "23\tValidation loss: 7.311086\tBest loss: 5.168496\tAccuracy: 64.50%\n",
      "24\tValidation loss: 5.856574\tBest loss: 5.168496\tAccuracy: 68.10%\n",
      "25\tValidation loss: 6.199721\tBest loss: 5.168496\tAccuracy: 66.60%\n",
      "26\tValidation loss: 6.064191\tBest loss: 5.168496\tAccuracy: 66.90%\n",
      "27\tValidation loss: 6.467384\tBest loss: 5.168496\tAccuracy: 68.90%\n",
      "28\tValidation loss: 5.683781\tBest loss: 5.168496\tAccuracy: 69.50%\n",
      "29\tValidation loss: 5.653886\tBest loss: 5.168496\tAccuracy: 71.00%\n",
      "30\tValidation loss: 6.198637\tBest loss: 5.168496\tAccuracy: 67.70%\n",
      "31\tValidation loss: 7.112876\tBest loss: 5.168496\tAccuracy: 67.40%\n",
      "32\tValidation loss: 7.245862\tBest loss: 5.168496\tAccuracy: 66.90%\n",
      "33\tValidation loss: 7.455995\tBest loss: 5.168496\tAccuracy: 66.00%\n",
      "34\tValidation loss: 5.735410\tBest loss: 5.168496\tAccuracy: 69.50%\n",
      "35\tValidation loss: 6.491651\tBest loss: 5.168496\tAccuracy: 68.90%\n",
      "36\tValidation loss: 6.994614\tBest loss: 5.168496\tAccuracy: 68.10%\n",
      "37\tValidation loss: 6.076949\tBest loss: 5.168496\tAccuracy: 69.30%\n",
      "38\tValidation loss: 6.813211\tBest loss: 5.168496\tAccuracy: 69.30%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   1.81611053e-27 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  3.85765993e-35   2.45171363e-27   4.54078384e-30 ...,   1.89513601e-21\n",
      "    3.16218542e-24   1.67691591e-15]\n",
      " [  1.01968350e-36   0.00000000e+00   0.00000000e+00 ...,   8.03710603e-18\n",
      "    1.74733985e-26   1.63626278e-15]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   3.09369157e-28]]\n",
      "[14 43 43 ..., 36  6 27]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.29407212e-01   3.17469724e-02   3.79150696e-02 ...,   4.07832231e-05\n",
      "    3.67989924e-05   2.33976898e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  9.80383391e-27   1.01570353e-33   1.01095456e-37 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.13919377e-02   8.28105677e-03   8.87235440e-03 ...,   7.07069994e-04\n",
      "    1.18358489e-02   1.94864825e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[20 19 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   7.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 10.934595\tBest loss: 10.934595\tAccuracy: 32.40%\n",
      "1\tValidation loss: 7.993239\tBest loss: 7.993239\tAccuracy: 41.30%\n",
      "2\tValidation loss: 5.829128\tBest loss: 5.829128\tAccuracy: 52.90%\n",
      "3\tValidation loss: 6.236550\tBest loss: 5.829128\tAccuracy: 57.00%\n",
      "4\tValidation loss: 8.138210\tBest loss: 5.829128\tAccuracy: 52.30%\n",
      "5\tValidation loss: 6.489376\tBest loss: 5.829128\tAccuracy: 56.10%\n",
      "6\tValidation loss: 6.494259\tBest loss: 5.829128\tAccuracy: 57.40%\n",
      "7\tValidation loss: 5.724302\tBest loss: 5.724302\tAccuracy: 62.60%\n",
      "8\tValidation loss: 5.656920\tBest loss: 5.656920\tAccuracy: 62.70%\n",
      "9\tValidation loss: 5.570551\tBest loss: 5.570551\tAccuracy: 61.50%\n",
      "10\tValidation loss: 6.760767\tBest loss: 5.570551\tAccuracy: 62.80%\n",
      "11\tValidation loss: 6.137824\tBest loss: 5.570551\tAccuracy: 61.60%\n",
      "12\tValidation loss: 7.694798\tBest loss: 5.570551\tAccuracy: 59.40%\n",
      "13\tValidation loss: 6.518472\tBest loss: 5.570551\tAccuracy: 66.70%\n",
      "14\tValidation loss: 6.559605\tBest loss: 5.570551\tAccuracy: 63.90%\n",
      "15\tValidation loss: 6.722146\tBest loss: 5.570551\tAccuracy: 63.60%\n",
      "16\tValidation loss: 5.486278\tBest loss: 5.486278\tAccuracy: 64.30%\n",
      "17\tValidation loss: 6.106524\tBest loss: 5.486278\tAccuracy: 66.50%\n",
      "18\tValidation loss: 6.498268\tBest loss: 5.486278\tAccuracy: 66.10%\n",
      "19\tValidation loss: 4.793617\tBest loss: 4.793617\tAccuracy: 71.00%\n",
      "20\tValidation loss: 5.772206\tBest loss: 4.793617\tAccuracy: 66.70%\n",
      "21\tValidation loss: 5.474262\tBest loss: 4.793617\tAccuracy: 68.10%\n",
      "22\tValidation loss: 5.775403\tBest loss: 4.793617\tAccuracy: 67.80%\n",
      "23\tValidation loss: 7.107519\tBest loss: 4.793617\tAccuracy: 65.10%\n",
      "24\tValidation loss: 5.353681\tBest loss: 4.793617\tAccuracy: 69.10%\n",
      "25\tValidation loss: 5.168641\tBest loss: 4.793617\tAccuracy: 68.70%\n",
      "26\tValidation loss: 6.675952\tBest loss: 4.793617\tAccuracy: 65.90%\n",
      "27\tValidation loss: 5.874097\tBest loss: 4.793617\tAccuracy: 69.60%\n",
      "28\tValidation loss: 6.463768\tBest loss: 4.793617\tAccuracy: 67.40%\n",
      "29\tValidation loss: 6.439185\tBest loss: 4.793617\tAccuracy: 67.80%\n",
      "30\tValidation loss: 6.349368\tBest loss: 4.793617\tAccuracy: 67.50%\n",
      "31\tValidation loss: 7.314406\tBest loss: 4.793617\tAccuracy: 67.70%\n",
      "32\tValidation loss: 7.194457\tBest loss: 4.793617\tAccuracy: 69.10%\n",
      "33\tValidation loss: 5.056136\tBest loss: 4.793617\tAccuracy: 72.00%\n",
      "34\tValidation loss: 7.851417\tBest loss: 4.793617\tAccuracy: 67.10%\n",
      "35\tValidation loss: 7.548165\tBest loss: 4.793617\tAccuracy: 69.00%\n",
      "36\tValidation loss: 5.782200\tBest loss: 4.793617\tAccuracy: 70.20%\n",
      "37\tValidation loss: 6.343403\tBest loss: 4.793617\tAccuracy: 69.40%\n",
      "38\tValidation loss: 5.890174\tBest loss: 4.793617\tAccuracy: 71.10%\n",
      "39\tValidation loss: 5.914137\tBest loss: 4.793617\tAccuracy: 69.90%\n",
      "40\tValidation loss: 6.327280\tBest loss: 4.793617\tAccuracy: 69.30%\n",
      "Early stopping!\n",
      "[[  4.54316328e-15   4.69903005e-09   3.38637430e-12 ...,   2.56622701e-09\n",
      "    3.99594063e-28   1.07782383e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   1.43116053e-15 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.16390350e-21]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   3.09965545e-29 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.18438897e-02   1.72873922e-02   8.98107700e-03 ...,   3.11174360e-03\n",
      "    1.00858770e-02   4.36970312e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[41 41 33 ...,  6 10 47]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.22734481e-02   6.73359409e-02   2.11047947e-01 ...,   1.04216218e-04\n",
      "    9.88321190e-05   5.75935264e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.42963454e-30   3.40228743e-19   3.26522964e-25 ...,   6.41598724e-21\n",
      "    8.95793588e-23   1.06030344e-10]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   4.48218194e-25\n",
      "    3.52440736e-31   4.48942201e-24]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   3.34511536e-24]]\n",
      "[22 19 16 ..., 36  6 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   8.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.900150\tBest loss: 3.900150\tAccuracy: 3.40%\n",
      "1\tValidation loss: 3.880654\tBest loss: 3.880654\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.870493\tBest loss: 3.870493\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.865077\tBest loss: 3.865077\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.863473\tBest loss: 3.863473\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.861486\tBest loss: 3.861486\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.862015\tBest loss: 3.861486\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.857963\tBest loss: 3.857963\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.852608\tBest loss: 3.852608\tAccuracy: 4.80%\n",
      "9\tValidation loss: 3.856123\tBest loss: 3.852608\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.844150\tBest loss: 3.844150\tAccuracy: 3.90%\n",
      "11\tValidation loss: 3.846633\tBest loss: 3.844150\tAccuracy: 4.00%\n",
      "12\tValidation loss: 3.833963\tBest loss: 3.833963\tAccuracy: 4.30%\n",
      "13\tValidation loss: 3.809522\tBest loss: 3.809522\tAccuracy: 4.90%\n",
      "14\tValidation loss: 3.806512\tBest loss: 3.806512\tAccuracy: 5.30%\n",
      "15\tValidation loss: 3.807287\tBest loss: 3.806512\tAccuracy: 6.60%\n",
      "16\tValidation loss: 3.798663\tBest loss: 3.798663\tAccuracy: 6.00%\n",
      "17\tValidation loss: 3.800399\tBest loss: 3.798663\tAccuracy: 5.60%\n",
      "18\tValidation loss: 3.793306\tBest loss: 3.793306\tAccuracy: 6.20%\n",
      "19\tValidation loss: 3.829748\tBest loss: 3.793306\tAccuracy: 5.20%\n",
      "20\tValidation loss: 3.807019\tBest loss: 3.793306\tAccuracy: 6.40%\n",
      "21\tValidation loss: 3.767835\tBest loss: 3.767835\tAccuracy: 7.00%\n",
      "22\tValidation loss: 3.780353\tBest loss: 3.767835\tAccuracy: 6.60%\n",
      "23\tValidation loss: 3.696812\tBest loss: 3.696812\tAccuracy: 7.10%\n",
      "24\tValidation loss: 3.677880\tBest loss: 3.677880\tAccuracy: 6.20%\n",
      "25\tValidation loss: 3.610203\tBest loss: 3.610203\tAccuracy: 8.00%\n",
      "26\tValidation loss: 3.629748\tBest loss: 3.610203\tAccuracy: 7.60%\n",
      "27\tValidation loss: 3.622688\tBest loss: 3.610203\tAccuracy: 7.80%\n",
      "28\tValidation loss: 3.533516\tBest loss: 3.533516\tAccuracy: 9.20%\n",
      "29\tValidation loss: 3.566635\tBest loss: 3.533516\tAccuracy: 7.20%\n",
      "30\tValidation loss: 3.467259\tBest loss: 3.467259\tAccuracy: 14.00%\n",
      "31\tValidation loss: 3.739997\tBest loss: 3.467259\tAccuracy: 11.60%\n",
      "32\tValidation loss: 3.407180\tBest loss: 3.407180\tAccuracy: 14.80%\n",
      "33\tValidation loss: 3.412667\tBest loss: 3.407180\tAccuracy: 15.10%\n",
      "34\tValidation loss: 3.373695\tBest loss: 3.373695\tAccuracy: 15.80%\n",
      "35\tValidation loss: 3.447539\tBest loss: 3.373695\tAccuracy: 12.70%\n",
      "36\tValidation loss: 3.519331\tBest loss: 3.373695\tAccuracy: 13.00%\n",
      "37\tValidation loss: 3.327620\tBest loss: 3.327620\tAccuracy: 15.10%\n",
      "38\tValidation loss: 3.541366\tBest loss: 3.327620\tAccuracy: 12.00%\n",
      "39\tValidation loss: 3.281843\tBest loss: 3.281843\tAccuracy: 17.40%\n",
      "40\tValidation loss: 3.245091\tBest loss: 3.245091\tAccuracy: 17.00%\n",
      "41\tValidation loss: 3.222189\tBest loss: 3.222189\tAccuracy: 19.20%\n",
      "42\tValidation loss: 3.210082\tBest loss: 3.210082\tAccuracy: 18.20%\n",
      "43\tValidation loss: 3.301791\tBest loss: 3.210082\tAccuracy: 15.70%\n",
      "44\tValidation loss: 3.432670\tBest loss: 3.210082\tAccuracy: 15.50%\n",
      "45\tValidation loss: 3.182687\tBest loss: 3.182687\tAccuracy: 18.30%\n",
      "46\tValidation loss: 3.125546\tBest loss: 3.125546\tAccuracy: 20.10%\n",
      "47\tValidation loss: 3.098063\tBest loss: 3.098063\tAccuracy: 20.30%\n",
      "48\tValidation loss: 3.105124\tBest loss: 3.098063\tAccuracy: 20.20%\n",
      "49\tValidation loss: 3.106474\tBest loss: 3.098063\tAccuracy: 19.70%\n",
      "50\tValidation loss: 3.340475\tBest loss: 3.098063\tAccuracy: 16.40%\n",
      "51\tValidation loss: 3.134137\tBest loss: 3.098063\tAccuracy: 19.70%\n",
      "52\tValidation loss: 3.204888\tBest loss: 3.098063\tAccuracy: 18.50%\n",
      "53\tValidation loss: 3.052204\tBest loss: 3.052204\tAccuracy: 19.90%\n",
      "54\tValidation loss: 3.020026\tBest loss: 3.020026\tAccuracy: 22.00%\n",
      "55\tValidation loss: 3.217656\tBest loss: 3.020026\tAccuracy: 18.00%\n",
      "56\tValidation loss: 3.042310\tBest loss: 3.020026\tAccuracy: 19.60%\n",
      "57\tValidation loss: 3.045515\tBest loss: 3.020026\tAccuracy: 20.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\tValidation loss: 3.091913\tBest loss: 3.020026\tAccuracy: 19.80%\n",
      "59\tValidation loss: 2.959481\tBest loss: 2.959481\tAccuracy: 21.80%\n",
      "60\tValidation loss: 2.993105\tBest loss: 2.959481\tAccuracy: 21.30%\n",
      "61\tValidation loss: 2.918145\tBest loss: 2.918145\tAccuracy: 24.00%\n",
      "62\tValidation loss: 3.038512\tBest loss: 2.918145\tAccuracy: 23.50%\n",
      "63\tValidation loss: 3.109996\tBest loss: 2.918145\tAccuracy: 21.40%\n",
      "64\tValidation loss: 3.000621\tBest loss: 2.918145\tAccuracy: 20.60%\n",
      "65\tValidation loss: 3.014029\tBest loss: 2.918145\tAccuracy: 21.00%\n",
      "66\tValidation loss: 3.018016\tBest loss: 2.918145\tAccuracy: 21.90%\n",
      "67\tValidation loss: 3.209045\tBest loss: 2.918145\tAccuracy: 18.90%\n",
      "68\tValidation loss: 3.362504\tBest loss: 2.918145\tAccuracy: 17.90%\n",
      "69\tValidation loss: 2.923776\tBest loss: 2.918145\tAccuracy: 23.40%\n",
      "70\tValidation loss: 3.351793\tBest loss: 2.918145\tAccuracy: 17.40%\n",
      "71\tValidation loss: 2.841682\tBest loss: 2.841682\tAccuracy: 25.10%\n",
      "72\tValidation loss: 2.863205\tBest loss: 2.841682\tAccuracy: 23.90%\n",
      "73\tValidation loss: 2.922732\tBest loss: 2.841682\tAccuracy: 21.00%\n",
      "74\tValidation loss: 2.974607\tBest loss: 2.841682\tAccuracy: 22.00%\n",
      "75\tValidation loss: 2.921030\tBest loss: 2.841682\tAccuracy: 20.40%\n",
      "76\tValidation loss: 2.799631\tBest loss: 2.799631\tAccuracy: 23.80%\n",
      "77\tValidation loss: 2.802712\tBest loss: 2.799631\tAccuracy: 24.70%\n",
      "78\tValidation loss: 2.869848\tBest loss: 2.799631\tAccuracy: 22.30%\n",
      "79\tValidation loss: 2.827882\tBest loss: 2.799631\tAccuracy: 24.10%\n",
      "80\tValidation loss: 3.290976\tBest loss: 2.799631\tAccuracy: 17.30%\n",
      "81\tValidation loss: 2.849768\tBest loss: 2.799631\tAccuracy: 22.10%\n",
      "82\tValidation loss: 2.795494\tBest loss: 2.795494\tAccuracy: 24.40%\n",
      "83\tValidation loss: 2.712860\tBest loss: 2.712860\tAccuracy: 27.60%\n",
      "84\tValidation loss: 2.917551\tBest loss: 2.712860\tAccuracy: 24.90%\n",
      "85\tValidation loss: 3.033687\tBest loss: 2.712860\tAccuracy: 20.70%\n",
      "86\tValidation loss: 2.748297\tBest loss: 2.712860\tAccuracy: 25.70%\n",
      "87\tValidation loss: 2.760380\tBest loss: 2.712860\tAccuracy: 25.90%\n",
      "88\tValidation loss: 3.099233\tBest loss: 2.712860\tAccuracy: 22.00%\n",
      "89\tValidation loss: 2.671971\tBest loss: 2.671971\tAccuracy: 26.80%\n",
      "90\tValidation loss: 2.765121\tBest loss: 2.671971\tAccuracy: 25.40%\n",
      "91\tValidation loss: 2.825640\tBest loss: 2.671971\tAccuracy: 25.40%\n",
      "92\tValidation loss: 3.135508\tBest loss: 2.671971\tAccuracy: 18.80%\n",
      "93\tValidation loss: 2.622713\tBest loss: 2.622713\tAccuracy: 28.30%\n",
      "94\tValidation loss: 2.669111\tBest loss: 2.622713\tAccuracy: 27.30%\n",
      "95\tValidation loss: 2.813390\tBest loss: 2.622713\tAccuracy: 25.30%\n",
      "96\tValidation loss: 2.974034\tBest loss: 2.622713\tAccuracy: 24.70%\n",
      "97\tValidation loss: 2.619820\tBest loss: 2.619820\tAccuracy: 27.50%\n",
      "98\tValidation loss: 2.598554\tBest loss: 2.598554\tAccuracy: 29.50%\n",
      "99\tValidation loss: 2.556246\tBest loss: 2.556246\tAccuracy: 29.20%\n",
      "100\tValidation loss: 2.546386\tBest loss: 2.546386\tAccuracy: 30.30%\n",
      "101\tValidation loss: 3.091376\tBest loss: 2.546386\tAccuracy: 21.30%\n",
      "102\tValidation loss: 2.799349\tBest loss: 2.546386\tAccuracy: 25.30%\n",
      "103\tValidation loss: 2.654230\tBest loss: 2.546386\tAccuracy: 27.70%\n",
      "104\tValidation loss: 2.809553\tBest loss: 2.546386\tAccuracy: 22.50%\n",
      "105\tValidation loss: 2.607962\tBest loss: 2.546386\tAccuracy: 27.70%\n",
      "106\tValidation loss: 2.830359\tBest loss: 2.546386\tAccuracy: 21.60%\n",
      "107\tValidation loss: 2.783607\tBest loss: 2.546386\tAccuracy: 23.90%\n",
      "108\tValidation loss: 2.455195\tBest loss: 2.455195\tAccuracy: 30.10%\n",
      "109\tValidation loss: 2.522675\tBest loss: 2.455195\tAccuracy: 27.30%\n",
      "110\tValidation loss: 2.778942\tBest loss: 2.455195\tAccuracy: 26.00%\n",
      "111\tValidation loss: 2.522611\tBest loss: 2.455195\tAccuracy: 30.90%\n",
      "112\tValidation loss: 2.465641\tBest loss: 2.455195\tAccuracy: 29.90%\n",
      "113\tValidation loss: 2.545759\tBest loss: 2.455195\tAccuracy: 27.90%\n",
      "114\tValidation loss: 2.840291\tBest loss: 2.455195\tAccuracy: 29.80%\n",
      "115\tValidation loss: 2.656751\tBest loss: 2.455195\tAccuracy: 29.40%\n",
      "116\tValidation loss: 2.494402\tBest loss: 2.455195\tAccuracy: 30.90%\n",
      "117\tValidation loss: 2.462141\tBest loss: 2.455195\tAccuracy: 32.30%\n",
      "118\tValidation loss: 3.500432\tBest loss: 2.455195\tAccuracy: 11.80%\n",
      "119\tValidation loss: 3.221653\tBest loss: 2.455195\tAccuracy: 15.10%\n",
      "120\tValidation loss: 3.035833\tBest loss: 2.455195\tAccuracy: 17.90%\n",
      "121\tValidation loss: 2.925584\tBest loss: 2.455195\tAccuracy: 19.60%\n",
      "122\tValidation loss: 2.842987\tBest loss: 2.455195\tAccuracy: 23.20%\n",
      "123\tValidation loss: 2.763840\tBest loss: 2.455195\tAccuracy: 23.70%\n",
      "124\tValidation loss: 2.715834\tBest loss: 2.455195\tAccuracy: 25.00%\n",
      "125\tValidation loss: 2.855647\tBest loss: 2.455195\tAccuracy: 23.40%\n",
      "126\tValidation loss: 2.699355\tBest loss: 2.455195\tAccuracy: 25.50%\n",
      "127\tValidation loss: 2.811796\tBest loss: 2.455195\tAccuracy: 24.60%\n",
      "128\tValidation loss: 2.709409\tBest loss: 2.455195\tAccuracy: 24.00%\n",
      "129\tValidation loss: 2.810463\tBest loss: 2.455195\tAccuracy: 23.80%\n",
      "Early stopping!\n",
      "[[  2.29472457e-03   2.87040207e-03   1.34174945e-02 ...,   1.02005703e-02\n",
      "    1.62872730e-03   7.25684105e-04]\n",
      " [  2.81580742e-02   3.66255865e-02   3.47318090e-02 ...,   1.40704243e-02\n",
      "    1.15591316e-02   8.03765655e-03]\n",
      " [  5.79999494e-07   5.34907786e-15   5.78009667e-06 ...,   4.45014847e-15\n",
      "    7.21030245e-17   8.09232992e-25]\n",
      " ..., \n",
      " [  5.37669791e-07   2.07776748e-06   2.38741880e-08 ...,   4.04059829e-05\n",
      "    8.27457541e-07   1.73364292e-11]\n",
      " [  6.38410170e-03   2.22319867e-02   1.17031885e-02 ...,   1.07312284e-01\n",
      "    3.51477824e-02   1.61126032e-02]\n",
      " [  2.62693712e-03   6.61362382e-03   8.49067327e-03 ...,   1.13462959e-03\n",
      "    9.28110257e-03   1.62568334e-02]]\n",
      "[20 18 16 ...,  6 45  8]\n",
      "[[  2.62693712e-03   6.61362382e-03   8.49067327e-03 ...,   1.13462959e-03\n",
      "    9.28110257e-03   1.62568334e-02]\n",
      " [  3.36137484e-03   2.02764403e-02   9.74252261e-03 ...,   6.93887845e-03\n",
      "    7.87780620e-03   7.27160973e-03]\n",
      " [  3.46617261e-03   1.76220238e-02   4.68207384e-03 ...,   7.61318719e-04\n",
      "    1.18113263e-03   4.76251077e-03]\n",
      " ..., \n",
      " [  2.34167330e-09   1.71525670e-07   4.72778934e-11 ...,   3.57592076e-13\n",
      "    4.17041540e-10   4.15291418e-13]\n",
      " [  1.09482855e-02   1.50229149e-02   2.27108710e-02 ...,   2.08077803e-02\n",
      "    1.94182098e-02   2.33659148e-02]\n",
      " [  1.87617051e-08   1.81550222e-05   4.80589506e-07 ...,   5.42148985e-02\n",
      "    4.14897472e-01   2.97459990e-01]]\n",
      "[ 8  9 15 ...,  6  8 46]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=   7.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.915215\tBest loss: 3.915215\tAccuracy: 3.30%\n",
      "1\tValidation loss: 3.891555\tBest loss: 3.891555\tAccuracy: 3.80%\n",
      "2\tValidation loss: 3.882720\tBest loss: 3.882720\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.873250\tBest loss: 3.873250\tAccuracy: 3.90%\n",
      "4\tValidation loss: 3.840851\tBest loss: 3.840851\tAccuracy: 5.00%\n",
      "5\tValidation loss: 3.842212\tBest loss: 3.840851\tAccuracy: 3.80%\n",
      "6\tValidation loss: 3.776709\tBest loss: 3.776709\tAccuracy: 4.10%\n",
      "7\tValidation loss: 3.784899\tBest loss: 3.776709\tAccuracy: 3.90%\n",
      "8\tValidation loss: 3.719953\tBest loss: 3.719953\tAccuracy: 7.20%\n",
      "9\tValidation loss: 3.720276\tBest loss: 3.719953\tAccuracy: 7.10%\n",
      "10\tValidation loss: 3.707258\tBest loss: 3.707258\tAccuracy: 6.50%\n",
      "11\tValidation loss: 3.692467\tBest loss: 3.692467\tAccuracy: 7.30%\n",
      "12\tValidation loss: 3.650980\tBest loss: 3.650980\tAccuracy: 7.80%\n",
      "13\tValidation loss: 3.715918\tBest loss: 3.650980\tAccuracy: 7.80%\n",
      "14\tValidation loss: 3.643314\tBest loss: 3.643314\tAccuracy: 7.50%\n",
      "15\tValidation loss: 3.625656\tBest loss: 3.625656\tAccuracy: 8.00%\n",
      "16\tValidation loss: 3.639546\tBest loss: 3.625656\tAccuracy: 7.80%\n",
      "17\tValidation loss: 3.594922\tBest loss: 3.594922\tAccuracy: 7.90%\n",
      "18\tValidation loss: 3.597265\tBest loss: 3.594922\tAccuracy: 7.70%\n",
      "19\tValidation loss: 3.589805\tBest loss: 3.589805\tAccuracy: 7.80%\n",
      "20\tValidation loss: 3.580179\tBest loss: 3.580179\tAccuracy: 8.40%\n",
      "21\tValidation loss: 3.557701\tBest loss: 3.557701\tAccuracy: 8.20%\n",
      "22\tValidation loss: 3.559093\tBest loss: 3.557701\tAccuracy: 7.90%\n",
      "23\tValidation loss: 3.551497\tBest loss: 3.551497\tAccuracy: 8.30%\n",
      "24\tValidation loss: 3.594511\tBest loss: 3.551497\tAccuracy: 7.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\tValidation loss: 3.601595\tBest loss: 3.551497\tAccuracy: 7.40%\n",
      "26\tValidation loss: 3.546199\tBest loss: 3.546199\tAccuracy: 8.50%\n",
      "27\tValidation loss: 3.540743\tBest loss: 3.540743\tAccuracy: 7.80%\n",
      "28\tValidation loss: 3.552437\tBest loss: 3.540743\tAccuracy: 8.50%\n",
      "29\tValidation loss: 3.507412\tBest loss: 3.507412\tAccuracy: 8.70%\n",
      "30\tValidation loss: 3.519839\tBest loss: 3.507412\tAccuracy: 8.70%\n",
      "31\tValidation loss: 3.505959\tBest loss: 3.505959\tAccuracy: 8.70%\n",
      "32\tValidation loss: 3.502521\tBest loss: 3.502521\tAccuracy: 9.10%\n",
      "33\tValidation loss: 3.488310\tBest loss: 3.488310\tAccuracy: 9.00%\n",
      "34\tValidation loss: 3.504163\tBest loss: 3.488310\tAccuracy: 8.90%\n",
      "35\tValidation loss: 3.562860\tBest loss: 3.488310\tAccuracy: 8.90%\n",
      "36\tValidation loss: 3.523303\tBest loss: 3.488310\tAccuracy: 9.00%\n",
      "37\tValidation loss: 3.479817\tBest loss: 3.479817\tAccuracy: 9.50%\n",
      "38\tValidation loss: 3.550725\tBest loss: 3.479817\tAccuracy: 7.90%\n",
      "39\tValidation loss: 3.451296\tBest loss: 3.451296\tAccuracy: 9.70%\n",
      "40\tValidation loss: 3.452452\tBest loss: 3.451296\tAccuracy: 9.10%\n",
      "41\tValidation loss: 3.430679\tBest loss: 3.430679\tAccuracy: 9.30%\n",
      "42\tValidation loss: 3.445957\tBest loss: 3.430679\tAccuracy: 9.10%\n",
      "43\tValidation loss: 3.422328\tBest loss: 3.422328\tAccuracy: 9.90%\n",
      "44\tValidation loss: 3.407947\tBest loss: 3.407947\tAccuracy: 10.00%\n",
      "45\tValidation loss: 3.395122\tBest loss: 3.395122\tAccuracy: 9.30%\n",
      "46\tValidation loss: 3.374898\tBest loss: 3.374898\tAccuracy: 10.20%\n",
      "47\tValidation loss: 3.389221\tBest loss: 3.374898\tAccuracy: 9.90%\n",
      "48\tValidation loss: 3.342490\tBest loss: 3.342490\tAccuracy: 11.50%\n",
      "49\tValidation loss: 3.371758\tBest loss: 3.342490\tAccuracy: 11.00%\n",
      "50\tValidation loss: 3.337373\tBest loss: 3.337373\tAccuracy: 11.30%\n",
      "51\tValidation loss: 3.327968\tBest loss: 3.327968\tAccuracy: 11.40%\n",
      "52\tValidation loss: 3.503290\tBest loss: 3.327968\tAccuracy: 9.90%\n",
      "53\tValidation loss: 3.349146\tBest loss: 3.327968\tAccuracy: 10.00%\n",
      "54\tValidation loss: 3.282193\tBest loss: 3.282193\tAccuracy: 11.50%\n",
      "55\tValidation loss: 3.258766\tBest loss: 3.258766\tAccuracy: 12.10%\n",
      "56\tValidation loss: 3.424218\tBest loss: 3.258766\tAccuracy: 10.20%\n",
      "57\tValidation loss: 3.496968\tBest loss: 3.258766\tAccuracy: 9.20%\n",
      "58\tValidation loss: 3.340165\tBest loss: 3.258766\tAccuracy: 10.50%\n",
      "59\tValidation loss: 3.476149\tBest loss: 3.258766\tAccuracy: 7.70%\n",
      "60\tValidation loss: 3.379141\tBest loss: 3.258766\tAccuracy: 10.50%\n",
      "61\tValidation loss: 3.317568\tBest loss: 3.258766\tAccuracy: 11.00%\n",
      "62\tValidation loss: 3.297364\tBest loss: 3.258766\tAccuracy: 10.90%\n",
      "63\tValidation loss: 3.304775\tBest loss: 3.258766\tAccuracy: 11.20%\n",
      "64\tValidation loss: 3.365254\tBest loss: 3.258766\tAccuracy: 10.60%\n",
      "65\tValidation loss: 3.279642\tBest loss: 3.258766\tAccuracy: 13.50%\n",
      "66\tValidation loss: 3.241661\tBest loss: 3.241661\tAccuracy: 13.20%\n",
      "67\tValidation loss: 3.228599\tBest loss: 3.228599\tAccuracy: 12.70%\n",
      "68\tValidation loss: 3.268919\tBest loss: 3.228599\tAccuracy: 10.70%\n",
      "69\tValidation loss: 3.262439\tBest loss: 3.228599\tAccuracy: 13.60%\n",
      "70\tValidation loss: 3.226075\tBest loss: 3.226075\tAccuracy: 11.40%\n",
      "71\tValidation loss: 3.258488\tBest loss: 3.226075\tAccuracy: 12.20%\n",
      "72\tValidation loss: 3.195297\tBest loss: 3.195297\tAccuracy: 14.30%\n",
      "73\tValidation loss: 3.525964\tBest loss: 3.195297\tAccuracy: 11.00%\n",
      "74\tValidation loss: 3.224530\tBest loss: 3.195297\tAccuracy: 13.20%\n",
      "75\tValidation loss: 3.210354\tBest loss: 3.195297\tAccuracy: 13.40%\n",
      "76\tValidation loss: 3.648748\tBest loss: 3.195297\tAccuracy: 12.30%\n",
      "77\tValidation loss: 3.687886\tBest loss: 3.195297\tAccuracy: 10.00%\n",
      "78\tValidation loss: 3.570277\tBest loss: 3.195297\tAccuracy: 8.90%\n",
      "79\tValidation loss: 3.650548\tBest loss: 3.195297\tAccuracy: 8.40%\n",
      "80\tValidation loss: 3.428124\tBest loss: 3.195297\tAccuracy: 10.70%\n",
      "81\tValidation loss: 3.510708\tBest loss: 3.195297\tAccuracy: 10.30%\n",
      "82\tValidation loss: 3.414355\tBest loss: 3.195297\tAccuracy: 12.30%\n",
      "83\tValidation loss: 3.427057\tBest loss: 3.195297\tAccuracy: 10.30%\n",
      "84\tValidation loss: 3.303586\tBest loss: 3.195297\tAccuracy: 11.40%\n",
      "85\tValidation loss: 3.372267\tBest loss: 3.195297\tAccuracy: 9.20%\n",
      "86\tValidation loss: 3.183245\tBest loss: 3.183245\tAccuracy: 12.70%\n",
      "87\tValidation loss: 3.239429\tBest loss: 3.183245\tAccuracy: 13.30%\n",
      "88\tValidation loss: 3.142511\tBest loss: 3.142511\tAccuracy: 13.90%\n",
      "89\tValidation loss: 3.218013\tBest loss: 3.142511\tAccuracy: 13.50%\n",
      "90\tValidation loss: 3.287307\tBest loss: 3.142511\tAccuracy: 11.60%\n",
      "91\tValidation loss: 3.051482\tBest loss: 3.051482\tAccuracy: 15.80%\n",
      "92\tValidation loss: 3.052550\tBest loss: 3.051482\tAccuracy: 15.00%\n",
      "93\tValidation loss: 3.148391\tBest loss: 3.051482\tAccuracy: 12.00%\n",
      "94\tValidation loss: 3.507820\tBest loss: 3.051482\tAccuracy: 9.50%\n",
      "95\tValidation loss: 3.140712\tBest loss: 3.051482\tAccuracy: 15.00%\n",
      "96\tValidation loss: 3.152882\tBest loss: 3.051482\tAccuracy: 13.40%\n",
      "97\tValidation loss: 3.206239\tBest loss: 3.051482\tAccuracy: 12.20%\n",
      "98\tValidation loss: 3.279871\tBest loss: 3.051482\tAccuracy: 11.90%\n",
      "99\tValidation loss: 3.300045\tBest loss: 3.051482\tAccuracy: 11.70%\n",
      "100\tValidation loss: 3.140289\tBest loss: 3.051482\tAccuracy: 13.30%\n",
      "101\tValidation loss: 3.140006\tBest loss: 3.051482\tAccuracy: 13.60%\n",
      "102\tValidation loss: 3.116970\tBest loss: 3.051482\tAccuracy: 13.00%\n",
      "103\tValidation loss: 3.306564\tBest loss: 3.051482\tAccuracy: 11.80%\n",
      "104\tValidation loss: 3.106887\tBest loss: 3.051482\tAccuracy: 16.50%\n",
      "105\tValidation loss: 3.286669\tBest loss: 3.051482\tAccuracy: 12.60%\n",
      "106\tValidation loss: 3.161055\tBest loss: 3.051482\tAccuracy: 15.20%\n",
      "107\tValidation loss: 3.093566\tBest loss: 3.051482\tAccuracy: 16.60%\n",
      "108\tValidation loss: 3.064940\tBest loss: 3.051482\tAccuracy: 15.50%\n",
      "109\tValidation loss: 3.123984\tBest loss: 3.051482\tAccuracy: 13.80%\n",
      "110\tValidation loss: 3.066706\tBest loss: 3.051482\tAccuracy: 16.20%\n",
      "111\tValidation loss: 3.048627\tBest loss: 3.048627\tAccuracy: 17.20%\n",
      "112\tValidation loss: 2.986490\tBest loss: 2.986490\tAccuracy: 18.30%\n",
      "113\tValidation loss: 3.002492\tBest loss: 2.986490\tAccuracy: 17.00%\n",
      "114\tValidation loss: 3.079202\tBest loss: 2.986490\tAccuracy: 15.90%\n",
      "115\tValidation loss: 2.973896\tBest loss: 2.973896\tAccuracy: 16.90%\n",
      "116\tValidation loss: 2.993732\tBest loss: 2.973896\tAccuracy: 17.20%\n",
      "117\tValidation loss: 2.947012\tBest loss: 2.947012\tAccuracy: 19.10%\n",
      "118\tValidation loss: 2.932044\tBest loss: 2.932044\tAccuracy: 18.00%\n",
      "119\tValidation loss: 2.910329\tBest loss: 2.910329\tAccuracy: 18.90%\n",
      "120\tValidation loss: 2.987755\tBest loss: 2.910329\tAccuracy: 18.10%\n",
      "121\tValidation loss: 3.255077\tBest loss: 2.910329\tAccuracy: 14.00%\n",
      "122\tValidation loss: 2.901637\tBest loss: 2.901637\tAccuracy: 19.00%\n",
      "123\tValidation loss: 2.934490\tBest loss: 2.901637\tAccuracy: 19.10%\n",
      "124\tValidation loss: 2.892827\tBest loss: 2.892827\tAccuracy: 19.80%\n",
      "125\tValidation loss: 2.874098\tBest loss: 2.874098\tAccuracy: 20.80%\n",
      "126\tValidation loss: 3.239790\tBest loss: 2.874098\tAccuracy: 13.40%\n",
      "127\tValidation loss: 3.112696\tBest loss: 2.874098\tAccuracy: 16.50%\n",
      "128\tValidation loss: 2.969745\tBest loss: 2.874098\tAccuracy: 18.80%\n",
      "129\tValidation loss: 3.299047\tBest loss: 2.874098\tAccuracy: 13.70%\n",
      "130\tValidation loss: 2.935412\tBest loss: 2.874098\tAccuracy: 18.50%\n",
      "131\tValidation loss: 2.984077\tBest loss: 2.874098\tAccuracy: 18.30%\n",
      "132\tValidation loss: 3.128257\tBest loss: 2.874098\tAccuracy: 18.00%\n",
      "133\tValidation loss: 2.913559\tBest loss: 2.874098\tAccuracy: 20.10%\n",
      "134\tValidation loss: 3.011772\tBest loss: 2.874098\tAccuracy: 17.60%\n",
      "135\tValidation loss: 2.871761\tBest loss: 2.871761\tAccuracy: 19.10%\n",
      "136\tValidation loss: 3.112700\tBest loss: 2.871761\tAccuracy: 13.60%\n",
      "137\tValidation loss: 3.017926\tBest loss: 2.871761\tAccuracy: 15.40%\n",
      "138\tValidation loss: 3.212896\tBest loss: 2.871761\tAccuracy: 15.00%\n",
      "139\tValidation loss: 2.899670\tBest loss: 2.871761\tAccuracy: 20.70%\n",
      "140\tValidation loss: 2.856917\tBest loss: 2.856917\tAccuracy: 20.00%\n",
      "141\tValidation loss: 2.929891\tBest loss: 2.856917\tAccuracy: 21.10%\n",
      "142\tValidation loss: 2.855876\tBest loss: 2.855876\tAccuracy: 21.60%\n",
      "143\tValidation loss: 2.788413\tBest loss: 2.788413\tAccuracy: 23.00%\n",
      "144\tValidation loss: 2.799367\tBest loss: 2.788413\tAccuracy: 20.70%\n",
      "145\tValidation loss: 3.213655\tBest loss: 2.788413\tAccuracy: 17.00%\n",
      "146\tValidation loss: 2.867679\tBest loss: 2.788413\tAccuracy: 20.40%\n",
      "147\tValidation loss: 2.758660\tBest loss: 2.758660\tAccuracy: 21.70%\n",
      "148\tValidation loss: 2.751006\tBest loss: 2.751006\tAccuracy: 22.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\tValidation loss: 2.913321\tBest loss: 2.751006\tAccuracy: 22.00%\n",
      "150\tValidation loss: 2.735920\tBest loss: 2.735920\tAccuracy: 25.30%\n",
      "151\tValidation loss: 2.974759\tBest loss: 2.735920\tAccuracy: 20.50%\n",
      "152\tValidation loss: 2.749776\tBest loss: 2.735920\tAccuracy: 23.40%\n",
      "153\tValidation loss: 2.687648\tBest loss: 2.687648\tAccuracy: 25.20%\n",
      "154\tValidation loss: 2.644704\tBest loss: 2.644704\tAccuracy: 27.80%\n",
      "155\tValidation loss: 2.709474\tBest loss: 2.644704\tAccuracy: 25.10%\n",
      "156\tValidation loss: 2.745165\tBest loss: 2.644704\tAccuracy: 22.50%\n",
      "157\tValidation loss: 3.327768\tBest loss: 2.644704\tAccuracy: 19.20%\n",
      "158\tValidation loss: 2.660486\tBest loss: 2.644704\tAccuracy: 24.90%\n",
      "159\tValidation loss: 2.928400\tBest loss: 2.644704\tAccuracy: 22.80%\n",
      "160\tValidation loss: 2.808355\tBest loss: 2.644704\tAccuracy: 21.10%\n",
      "161\tValidation loss: 3.305490\tBest loss: 2.644704\tAccuracy: 17.80%\n",
      "162\tValidation loss: 2.717833\tBest loss: 2.644704\tAccuracy: 22.90%\n",
      "163\tValidation loss: 2.600071\tBest loss: 2.600071\tAccuracy: 27.70%\n",
      "164\tValidation loss: 2.768856\tBest loss: 2.600071\tAccuracy: 23.20%\n",
      "165\tValidation loss: 2.647215\tBest loss: 2.600071\tAccuracy: 27.70%\n",
      "166\tValidation loss: 2.876983\tBest loss: 2.600071\tAccuracy: 23.10%\n",
      "167\tValidation loss: 2.866873\tBest loss: 2.600071\tAccuracy: 25.10%\n",
      "168\tValidation loss: 2.743410\tBest loss: 2.600071\tAccuracy: 27.10%\n",
      "169\tValidation loss: 2.811570\tBest loss: 2.600071\tAccuracy: 22.80%\n",
      "170\tValidation loss: 2.731575\tBest loss: 2.600071\tAccuracy: 23.80%\n",
      "171\tValidation loss: 2.511579\tBest loss: 2.511579\tAccuracy: 29.30%\n",
      "172\tValidation loss: 2.636771\tBest loss: 2.511579\tAccuracy: 25.10%\n",
      "173\tValidation loss: 3.067654\tBest loss: 2.511579\tAccuracy: 21.30%\n",
      "174\tValidation loss: 2.524253\tBest loss: 2.511579\tAccuracy: 30.80%\n",
      "175\tValidation loss: 2.568525\tBest loss: 2.511579\tAccuracy: 27.00%\n",
      "176\tValidation loss: 2.645400\tBest loss: 2.511579\tAccuracy: 24.60%\n",
      "177\tValidation loss: 2.616862\tBest loss: 2.511579\tAccuracy: 27.50%\n",
      "178\tValidation loss: 2.471040\tBest loss: 2.471040\tAccuracy: 30.40%\n",
      "179\tValidation loss: 2.682472\tBest loss: 2.471040\tAccuracy: 25.90%\n",
      "180\tValidation loss: 2.618062\tBest loss: 2.471040\tAccuracy: 27.00%\n",
      "181\tValidation loss: 2.546324\tBest loss: 2.471040\tAccuracy: 30.00%\n",
      "182\tValidation loss: 2.709924\tBest loss: 2.471040\tAccuracy: 26.20%\n",
      "183\tValidation loss: 2.450342\tBest loss: 2.450342\tAccuracy: 31.30%\n",
      "184\tValidation loss: 2.495856\tBest loss: 2.450342\tAccuracy: 31.00%\n",
      "185\tValidation loss: 2.593081\tBest loss: 2.450342\tAccuracy: 24.60%\n",
      "186\tValidation loss: 2.479769\tBest loss: 2.450342\tAccuracy: 29.60%\n",
      "187\tValidation loss: 2.366781\tBest loss: 2.366781\tAccuracy: 32.00%\n",
      "188\tValidation loss: 2.408306\tBest loss: 2.366781\tAccuracy: 31.80%\n",
      "189\tValidation loss: 2.369509\tBest loss: 2.366781\tAccuracy: 32.90%\n",
      "190\tValidation loss: 2.420448\tBest loss: 2.366781\tAccuracy: 31.80%\n",
      "191\tValidation loss: 2.470649\tBest loss: 2.366781\tAccuracy: 32.80%\n",
      "192\tValidation loss: 2.504440\tBest loss: 2.366781\tAccuracy: 30.10%\n",
      "193\tValidation loss: 2.570009\tBest loss: 2.366781\tAccuracy: 29.00%\n",
      "194\tValidation loss: 2.439204\tBest loss: 2.366781\tAccuracy: 27.90%\n",
      "195\tValidation loss: 2.320734\tBest loss: 2.320734\tAccuracy: 33.40%\n",
      "196\tValidation loss: 2.407809\tBest loss: 2.320734\tAccuracy: 30.80%\n",
      "197\tValidation loss: 2.613711\tBest loss: 2.320734\tAccuracy: 28.70%\n",
      "198\tValidation loss: 2.641609\tBest loss: 2.320734\tAccuracy: 26.30%\n",
      "199\tValidation loss: 2.638725\tBest loss: 2.320734\tAccuracy: 24.60%\n",
      "200\tValidation loss: 2.465700\tBest loss: 2.320734\tAccuracy: 30.90%\n",
      "201\tValidation loss: 2.406862\tBest loss: 2.320734\tAccuracy: 30.10%\n",
      "202\tValidation loss: 2.357889\tBest loss: 2.320734\tAccuracy: 32.60%\n",
      "203\tValidation loss: 2.509732\tBest loss: 2.320734\tAccuracy: 29.00%\n",
      "204\tValidation loss: 2.460900\tBest loss: 2.320734\tAccuracy: 28.50%\n",
      "205\tValidation loss: 2.305946\tBest loss: 2.305946\tAccuracy: 33.30%\n",
      "206\tValidation loss: 2.298821\tBest loss: 2.298821\tAccuracy: 33.00%\n",
      "207\tValidation loss: 2.367242\tBest loss: 2.298821\tAccuracy: 31.90%\n",
      "208\tValidation loss: 2.486149\tBest loss: 2.298821\tAccuracy: 29.10%\n",
      "209\tValidation loss: 2.279520\tBest loss: 2.279520\tAccuracy: 33.60%\n",
      "210\tValidation loss: 2.272392\tBest loss: 2.272392\tAccuracy: 33.20%\n",
      "211\tValidation loss: 2.526583\tBest loss: 2.272392\tAccuracy: 27.00%\n",
      "212\tValidation loss: 2.243205\tBest loss: 2.243205\tAccuracy: 34.10%\n",
      "213\tValidation loss: 2.831127\tBest loss: 2.243205\tAccuracy: 23.40%\n",
      "214\tValidation loss: 2.331823\tBest loss: 2.243205\tAccuracy: 34.60%\n",
      "215\tValidation loss: 2.637573\tBest loss: 2.243205\tAccuracy: 26.80%\n",
      "216\tValidation loss: 2.683661\tBest loss: 2.243205\tAccuracy: 23.80%\n",
      "217\tValidation loss: 2.619923\tBest loss: 2.243205\tAccuracy: 24.10%\n",
      "218\tValidation loss: 2.560269\tBest loss: 2.243205\tAccuracy: 27.40%\n",
      "219\tValidation loss: 2.694074\tBest loss: 2.243205\tAccuracy: 24.30%\n",
      "220\tValidation loss: 2.535465\tBest loss: 2.243205\tAccuracy: 28.60%\n",
      "221\tValidation loss: 2.852575\tBest loss: 2.243205\tAccuracy: 21.30%\n",
      "222\tValidation loss: 2.931577\tBest loss: 2.243205\tAccuracy: 20.20%\n",
      "223\tValidation loss: 2.651970\tBest loss: 2.243205\tAccuracy: 24.70%\n",
      "224\tValidation loss: 2.687410\tBest loss: 2.243205\tAccuracy: 24.40%\n",
      "225\tValidation loss: 2.625193\tBest loss: 2.243205\tAccuracy: 28.10%\n",
      "226\tValidation loss: 2.571432\tBest loss: 2.243205\tAccuracy: 26.20%\n",
      "227\tValidation loss: 2.599688\tBest loss: 2.243205\tAccuracy: 25.90%\n",
      "228\tValidation loss: 2.594370\tBest loss: 2.243205\tAccuracy: 27.80%\n",
      "229\tValidation loss: 2.686247\tBest loss: 2.243205\tAccuracy: 27.90%\n",
      "230\tValidation loss: 2.437588\tBest loss: 2.243205\tAccuracy: 31.70%\n",
      "231\tValidation loss: 2.556425\tBest loss: 2.243205\tAccuracy: 31.00%\n",
      "232\tValidation loss: 2.448926\tBest loss: 2.243205\tAccuracy: 31.30%\n",
      "233\tValidation loss: 2.611052\tBest loss: 2.243205\tAccuracy: 26.30%\n",
      "Early stopping!\n",
      "[[ 0.0015729   0.00214019  0.00272546 ...,  0.00423771  0.00359794\n",
      "   0.01251199]\n",
      " [ 0.00951761  0.00875856  0.0355879  ...,  0.00026503  0.00597046\n",
      "   0.00041226]\n",
      " [ 0.00132636  0.00538709  0.00174302 ...,  0.00585669  0.00173684\n",
      "   0.00829012]\n",
      " ..., \n",
      " [ 0.00068098  0.00058713  0.00222098 ...,  0.0013282   0.00576053\n",
      "   0.01420498]\n",
      " [ 0.00576699  0.0065961   0.00558766 ...,  0.00172564  0.00876746\n",
      "   0.00248871]\n",
      " [ 0.00061579  0.00515457  0.00202113 ...,  0.00090099  0.00770981\n",
      "   0.01344818]]\n",
      "[41 20 38 ..., 36 18  9]\n",
      "[[  1.51046540e-03   2.95064575e-03   1.33582344e-02 ...,   4.01428042e-06\n",
      "    2.01874669e-03   6.37889434e-06]\n",
      " [  3.64393331e-02   4.42625135e-02   5.47184534e-02 ...,   2.90647037e-02\n",
      "    1.11253988e-02   9.63352155e-03]\n",
      " [  3.75595890e-14   2.70606033e-24   7.48366702e-09 ...,   2.97359556e-21\n",
      "    2.26195500e-17   1.98794005e-23]\n",
      " ..., \n",
      " [  7.98349404e-08   2.57604054e-08   9.04776462e-11 ...,   1.03649253e-14\n",
      "    5.00725814e-15   5.09023478e-19]\n",
      " [  7.77110737e-03   7.05463206e-03   2.04456523e-02 ...,   8.07539560e-03\n",
      "    1.79631077e-02   2.22484190e-02]\n",
      " [  4.20707746e-14   4.94819408e-10   3.88755084e-10 ...,   1.61595657e-04\n",
      "    3.40021431e-01   3.38996649e-01]]\n",
      "[20 19 16 ...,  6 10 46]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  13.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=   1.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.683831\tBest loss: 3.683831\tAccuracy: 9.20%\n",
      "1\tValidation loss: 3.247203\tBest loss: 3.247203\tAccuracy: 14.70%\n",
      "2\tValidation loss: 2.990672\tBest loss: 2.990672\tAccuracy: 20.10%\n",
      "3\tValidation loss: 3.042809\tBest loss: 2.990672\tAccuracy: 20.40%\n",
      "4\tValidation loss: 2.655552\tBest loss: 2.655552\tAccuracy: 26.10%\n",
      "5\tValidation loss: 2.641590\tBest loss: 2.641590\tAccuracy: 25.40%\n",
      "6\tValidation loss: 2.435019\tBest loss: 2.435019\tAccuracy: 31.60%\n",
      "7\tValidation loss: 2.997272\tBest loss: 2.435019\tAccuracy: 32.70%\n",
      "8\tValidation loss: 2.563234\tBest loss: 2.435019\tAccuracy: 31.20%\n",
      "9\tValidation loss: 2.720577\tBest loss: 2.435019\tAccuracy: 30.40%\n",
      "10\tValidation loss: 2.307511\tBest loss: 2.307511\tAccuracy: 35.60%\n",
      "11\tValidation loss: 2.332907\tBest loss: 2.307511\tAccuracy: 36.70%\n",
      "12\tValidation loss: 2.348342\tBest loss: 2.307511\tAccuracy: 36.50%\n",
      "13\tValidation loss: 2.226145\tBest loss: 2.226145\tAccuracy: 41.50%\n",
      "14\tValidation loss: 2.027262\tBest loss: 2.027262\tAccuracy: 42.00%\n",
      "15\tValidation loss: 2.058734\tBest loss: 2.027262\tAccuracy: 42.70%\n",
      "16\tValidation loss: 2.254671\tBest loss: 2.027262\tAccuracy: 36.70%\n",
      "17\tValidation loss: 2.094047\tBest loss: 2.027262\tAccuracy: 45.10%\n",
      "18\tValidation loss: 2.115960\tBest loss: 2.027262\tAccuracy: 43.20%\n",
      "19\tValidation loss: 2.038636\tBest loss: 2.027262\tAccuracy: 44.80%\n",
      "20\tValidation loss: 2.306225\tBest loss: 2.027262\tAccuracy: 42.90%\n",
      "21\tValidation loss: 2.077727\tBest loss: 2.027262\tAccuracy: 46.60%\n",
      "22\tValidation loss: 2.060544\tBest loss: 2.027262\tAccuracy: 46.10%\n",
      "23\tValidation loss: 2.165771\tBest loss: 2.027262\tAccuracy: 42.90%\n",
      "24\tValidation loss: 2.107389\tBest loss: 2.027262\tAccuracy: 48.80%\n",
      "25\tValidation loss: 1.981266\tBest loss: 1.981266\tAccuracy: 48.40%\n",
      "26\tValidation loss: 2.172721\tBest loss: 1.981266\tAccuracy: 47.50%\n",
      "27\tValidation loss: 2.035920\tBest loss: 1.981266\tAccuracy: 41.50%\n",
      "28\tValidation loss: 1.952408\tBest loss: 1.952408\tAccuracy: 46.10%\n",
      "29\tValidation loss: 2.006849\tBest loss: 1.952408\tAccuracy: 46.80%\n",
      "30\tValidation loss: 2.099129\tBest loss: 1.952408\tAccuracy: 48.10%\n",
      "31\tValidation loss: 2.127244\tBest loss: 1.952408\tAccuracy: 43.40%\n",
      "32\tValidation loss: 2.031773\tBest loss: 1.952408\tAccuracy: 48.10%\n",
      "33\tValidation loss: 2.203817\tBest loss: 1.952408\tAccuracy: 50.40%\n",
      "34\tValidation loss: 2.244832\tBest loss: 1.952408\tAccuracy: 48.20%\n",
      "35\tValidation loss: 2.425774\tBest loss: 1.952408\tAccuracy: 49.90%\n",
      "36\tValidation loss: 2.275201\tBest loss: 1.952408\tAccuracy: 45.80%\n",
      "37\tValidation loss: 2.244282\tBest loss: 1.952408\tAccuracy: 49.10%\n",
      "38\tValidation loss: 2.191260\tBest loss: 1.952408\tAccuracy: 48.00%\n",
      "39\tValidation loss: 2.267036\tBest loss: 1.952408\tAccuracy: 45.60%\n",
      "40\tValidation loss: 2.381546\tBest loss: 1.952408\tAccuracy: 49.10%\n",
      "41\tValidation loss: 2.232491\tBest loss: 1.952408\tAccuracy: 51.70%\n",
      "42\tValidation loss: 2.215358\tBest loss: 1.952408\tAccuracy: 51.00%\n",
      "43\tValidation loss: 2.488981\tBest loss: 1.952408\tAccuracy: 45.70%\n",
      "44\tValidation loss: 1.981571\tBest loss: 1.952408\tAccuracy: 50.90%\n",
      "45\tValidation loss: 1.885561\tBest loss: 1.885561\tAccuracy: 51.50%\n",
      "46\tValidation loss: 1.799595\tBest loss: 1.799595\tAccuracy: 55.20%\n",
      "47\tValidation loss: 1.841714\tBest loss: 1.799595\tAccuracy: 54.70%\n",
      "48\tValidation loss: 1.895764\tBest loss: 1.799595\tAccuracy: 51.60%\n",
      "49\tValidation loss: 2.342032\tBest loss: 1.799595\tAccuracy: 54.10%\n",
      "50\tValidation loss: 2.010508\tBest loss: 1.799595\tAccuracy: 51.80%\n",
      "51\tValidation loss: 1.844736\tBest loss: 1.799595\tAccuracy: 52.60%\n",
      "52\tValidation loss: 2.111444\tBest loss: 1.799595\tAccuracy: 46.20%\n",
      "53\tValidation loss: 2.032850\tBest loss: 1.799595\tAccuracy: 53.50%\n",
      "54\tValidation loss: 1.993570\tBest loss: 1.799595\tAccuracy: 55.50%\n",
      "55\tValidation loss: 2.059437\tBest loss: 1.799595\tAccuracy: 49.20%\n",
      "56\tValidation loss: 2.170646\tBest loss: 1.799595\tAccuracy: 51.40%\n",
      "57\tValidation loss: 1.928540\tBest loss: 1.799595\tAccuracy: 55.90%\n",
      "58\tValidation loss: 2.149719\tBest loss: 1.799595\tAccuracy: 49.80%\n",
      "59\tValidation loss: 2.041383\tBest loss: 1.799595\tAccuracy: 48.60%\n",
      "60\tValidation loss: 3.085272\tBest loss: 1.799595\tAccuracy: 55.50%\n",
      "61\tValidation loss: 2.640565\tBest loss: 1.799595\tAccuracy: 49.50%\n",
      "62\tValidation loss: 2.462706\tBest loss: 1.799595\tAccuracy: 51.80%\n",
      "63\tValidation loss: 1.952120\tBest loss: 1.799595\tAccuracy: 54.10%\n",
      "64\tValidation loss: 2.048939\tBest loss: 1.799595\tAccuracy: 51.60%\n",
      "65\tValidation loss: 2.663161\tBest loss: 1.799595\tAccuracy: 55.80%\n",
      "66\tValidation loss: 2.308187\tBest loss: 1.799595\tAccuracy: 57.20%\n",
      "67\tValidation loss: 2.399816\tBest loss: 1.799595\tAccuracy: 53.50%\n",
      "Early stopping!\n",
      "[[  1.94499480e-05   2.68010423e-02   1.87277689e-03 ...,   8.43051318e-09\n",
      "    7.36244283e-06   7.27210470e-09]\n",
      " [  6.91993460e-02   2.52113044e-02   4.46294807e-02 ...,   5.49446908e-04\n",
      "    5.45067131e-04   1.03257902e-04]\n",
      " [  5.02521857e-07   2.68886561e-19   7.49718902e-06 ...,   4.94819337e-16\n",
      "    6.56744804e-18   6.07231228e-21]\n",
      " ..., \n",
      " [  1.86312511e-12   4.71928033e-05   2.58701398e-08 ...,   1.53518064e-04\n",
      "    6.53976458e-04   3.42743966e-04]\n",
      " [  6.28303662e-02   1.27855480e-01   6.27900511e-02 ...,   5.44409407e-03\n",
      "    1.24924781e-03   1.10419828e-03]\n",
      " [  1.68806878e-07   1.26177201e-05   2.30676851e-05 ...,   6.78467841e-05\n",
      "    2.24861069e-04   2.22019778e-04]]\n",
      "[20 38 16 ...,  6  1 36]\n",
      "[[  6.49746566e-04   1.37165245e-02   1.08563574e-02 ...,   7.72541855e-03\n",
      "    1.16138291e-02   1.33455517e-02]\n",
      " [  2.84869806e-16   7.07249046e-06   4.92486000e-12 ...,   3.49303695e-26\n",
      "    8.87713128e-22   1.12632596e-21]\n",
      " [  1.02998897e-07   3.56098026e-04   2.57165470e-06 ...,   9.20297349e-09\n",
      "    1.03875700e-10   1.29503618e-07]\n",
      " ..., \n",
      " [  5.17337329e-09   3.19363680e-05   6.05167827e-09 ...,   1.79604887e-09\n",
      "    2.01302219e-09   1.89721364e-11]\n",
      " [  7.10552558e-03   1.97253865e-03   1.17529382e-03 ...,   8.46663199e-04\n",
      "    2.86827970e-04   2.51435325e-04]\n",
      " [  5.68191660e-16   1.33969537e-11   1.43324793e-15 ...,   9.18296538e-03\n",
      "    8.19762424e-02   8.26663613e-01]]\n",
      "[38 43 43 ...,  6 20 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  12.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.706716\tBest loss: 3.706716\tAccuracy: 9.40%\n",
      "1\tValidation loss: 3.365235\tBest loss: 3.365235\tAccuracy: 12.30%\n",
      "2\tValidation loss: 3.088665\tBest loss: 3.088665\tAccuracy: 21.50%\n",
      "3\tValidation loss: 2.792145\tBest loss: 2.792145\tAccuracy: 25.70%\n",
      "4\tValidation loss: 2.748029\tBest loss: 2.748029\tAccuracy: 27.40%\n",
      "5\tValidation loss: 2.849299\tBest loss: 2.748029\tAccuracy: 29.80%\n",
      "6\tValidation loss: 2.477999\tBest loss: 2.477999\tAccuracy: 34.10%\n",
      "7\tValidation loss: 2.605258\tBest loss: 2.477999\tAccuracy: 31.00%\n",
      "8\tValidation loss: 2.958072\tBest loss: 2.477999\tAccuracy: 35.20%\n",
      "9\tValidation loss: 2.706470\tBest loss: 2.477999\tAccuracy: 34.20%\n",
      "10\tValidation loss: 2.698748\tBest loss: 2.477999\tAccuracy: 33.40%\n",
      "11\tValidation loss: 2.586998\tBest loss: 2.477999\tAccuracy: 37.30%\n",
      "12\tValidation loss: 2.438937\tBest loss: 2.438937\tAccuracy: 37.50%\n",
      "13\tValidation loss: 2.735197\tBest loss: 2.438937\tAccuracy: 36.50%\n",
      "14\tValidation loss: 2.761774\tBest loss: 2.438937\tAccuracy: 36.50%\n",
      "15\tValidation loss: 2.574531\tBest loss: 2.438937\tAccuracy: 38.50%\n",
      "16\tValidation loss: 2.326188\tBest loss: 2.326188\tAccuracy: 39.60%\n",
      "17\tValidation loss: 2.298501\tBest loss: 2.298501\tAccuracy: 44.70%\n",
      "18\tValidation loss: 2.308201\tBest loss: 2.298501\tAccuracy: 39.30%\n",
      "19\tValidation loss: 2.084579\tBest loss: 2.084579\tAccuracy: 41.70%\n",
      "20\tValidation loss: 2.243258\tBest loss: 2.084579\tAccuracy: 42.80%\n",
      "21\tValidation loss: 2.210002\tBest loss: 2.084579\tAccuracy: 38.60%\n",
      "22\tValidation loss: 2.648498\tBest loss: 2.084579\tAccuracy: 37.30%\n",
      "23\tValidation loss: 2.435660\tBest loss: 2.084579\tAccuracy: 44.40%\n",
      "24\tValidation loss: 2.057089\tBest loss: 2.057089\tAccuracy: 47.80%\n",
      "25\tValidation loss: 1.952023\tBest loss: 1.952023\tAccuracy: 47.70%\n",
      "26\tValidation loss: 3.194662\tBest loss: 1.952023\tAccuracy: 47.30%\n",
      "27\tValidation loss: 2.770588\tBest loss: 1.952023\tAccuracy: 44.20%\n",
      "28\tValidation loss: 3.155859\tBest loss: 1.952023\tAccuracy: 47.30%\n",
      "29\tValidation loss: 2.775217\tBest loss: 1.952023\tAccuracy: 45.60%\n",
      "30\tValidation loss: 2.965837\tBest loss: 1.952023\tAccuracy: 47.20%\n",
      "31\tValidation loss: 3.336346\tBest loss: 1.952023\tAccuracy: 42.70%\n",
      "32\tValidation loss: 4.134005\tBest loss: 1.952023\tAccuracy: 46.40%\n",
      "33\tValidation loss: 3.118351\tBest loss: 1.952023\tAccuracy: 48.60%\n",
      "34\tValidation loss: 2.912616\tBest loss: 1.952023\tAccuracy: 46.40%\n",
      "35\tValidation loss: 2.809889\tBest loss: 1.952023\tAccuracy: 46.80%\n",
      "36\tValidation loss: 3.135975\tBest loss: 1.952023\tAccuracy: 46.10%\n",
      "37\tValidation loss: 3.218155\tBest loss: 1.952023\tAccuracy: 52.00%\n",
      "38\tValidation loss: 3.093715\tBest loss: 1.952023\tAccuracy: 49.60%\n",
      "39\tValidation loss: 3.379294\tBest loss: 1.952023\tAccuracy: 49.80%\n",
      "40\tValidation loss: 3.171659\tBest loss: 1.952023\tAccuracy: 47.40%\n",
      "41\tValidation loss: 2.861722\tBest loss: 1.952023\tAccuracy: 47.20%\n",
      "42\tValidation loss: 2.647402\tBest loss: 1.952023\tAccuracy: 48.80%\n",
      "43\tValidation loss: 3.967283\tBest loss: 1.952023\tAccuracy: 43.40%\n",
      "44\tValidation loss: 3.227068\tBest loss: 1.952023\tAccuracy: 47.20%\n",
      "45\tValidation loss: 3.243282\tBest loss: 1.952023\tAccuracy: 50.90%\n",
      "46\tValidation loss: 3.026067\tBest loss: 1.952023\tAccuracy: 44.90%\n",
      "Early stopping!\n",
      "[[  4.00584610e-03   1.73529349e-02   5.83160529e-03 ...,   8.93905293e-03\n",
      "    7.04974495e-03   4.72657429e-03]\n",
      " [  3.40806966e-10   5.76987443e-03   4.19158187e-06 ...,   9.44320637e-18\n",
      "    1.03747631e-12   3.73976363e-14]\n",
      " [  2.72749632e-04   8.93625803e-03   1.59384497e-03 ...,   4.80838162e-06\n",
      "    2.07050704e-07   3.29232671e-06]\n",
      " ..., \n",
      " [  4.04397584e-03   2.69323797e-03   4.98012500e-03 ...,   2.88883597e-02\n",
      "    1.34566687e-02   1.66331213e-02]\n",
      " [  3.06416932e-03   9.09408368e-03   1.40597334e-03 ...,   3.67182158e-02\n",
      "    1.86542161e-02   2.18656138e-02]\n",
      " [  2.90560074e-05   9.72192269e-04   1.58644572e-04 ...,   2.16929149e-02\n",
      "    2.24124286e-02   6.62044017e-03]]\n",
      "[38  9 43 ..., 36 26 36]\n",
      "[[  2.22418315e-08   1.21557266e-02   1.15751827e-04 ...,   7.99084021e-15\n",
      "    1.50308835e-10   4.88615398e-12]\n",
      " [  4.02901098e-02   1.17554339e-02   1.05930008e-02 ...,   7.63155054e-04\n",
      "    3.69999185e-03   7.03785277e-04]\n",
      " [  4.61729115e-07   1.31372111e-18   2.65142024e-08 ...,   4.07427586e-16\n",
      "    2.09119029e-12   2.59721560e-17]\n",
      " ..., \n",
      " [  6.80853304e-07   2.08721231e-05   2.47455878e-09 ...,   5.99603787e-12\n",
      "    8.29445401e-11   1.88832847e-12]\n",
      " [  1.87649298e-02   6.82926155e-04   1.77904218e-02 ...,   3.96856153e-03\n",
      "    7.37012504e-03   1.14602153e-03]\n",
      " [  9.87969706e-10   5.79473536e-08   6.09466817e-12 ...,   9.32131931e-02\n",
      "    5.69867119e-02   7.11909831e-01]]\n",
      "[21 18 16 ...,  4 16 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   8.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.818504\tBest loss: 3.818504\tAccuracy: 6.70%\n",
      "1\tValidation loss: 3.646319\tBest loss: 3.646319\tAccuracy: 9.30%\n",
      "2\tValidation loss: 3.019217\tBest loss: 3.019217\tAccuracy: 19.80%\n",
      "3\tValidation loss: 2.735128\tBest loss: 2.735128\tAccuracy: 21.00%\n",
      "4\tValidation loss: 2.580354\tBest loss: 2.580354\tAccuracy: 27.60%\n",
      "5\tValidation loss: 2.474596\tBest loss: 2.474596\tAccuracy: 30.30%\n",
      "6\tValidation loss: 2.496562\tBest loss: 2.474596\tAccuracy: 30.80%\n",
      "7\tValidation loss: 2.309721\tBest loss: 2.309721\tAccuracy: 35.40%\n",
      "8\tValidation loss: 2.408254\tBest loss: 2.309721\tAccuracy: 33.00%\n",
      "9\tValidation loss: 2.344849\tBest loss: 2.309721\tAccuracy: 33.30%\n",
      "10\tValidation loss: 2.205966\tBest loss: 2.205966\tAccuracy: 36.70%\n",
      "11\tValidation loss: 2.240539\tBest loss: 2.205966\tAccuracy: 37.80%\n",
      "12\tValidation loss: 2.301788\tBest loss: 2.205966\tAccuracy: 37.30%\n",
      "13\tValidation loss: 2.325622\tBest loss: 2.205966\tAccuracy: 38.80%\n",
      "14\tValidation loss: 2.395010\tBest loss: 2.205966\tAccuracy: 37.20%\n",
      "15\tValidation loss: 2.251803\tBest loss: 2.205966\tAccuracy: 42.80%\n",
      "16\tValidation loss: 2.324631\tBest loss: 2.205966\tAccuracy: 36.30%\n",
      "17\tValidation loss: 2.130249\tBest loss: 2.130249\tAccuracy: 41.00%\n",
      "18\tValidation loss: 2.130724\tBest loss: 2.130249\tAccuracy: 42.00%\n",
      "19\tValidation loss: 2.068539\tBest loss: 2.068539\tAccuracy: 43.50%\n",
      "20\tValidation loss: 2.064683\tBest loss: 2.064683\tAccuracy: 42.10%\n",
      "21\tValidation loss: 2.348812\tBest loss: 2.064683\tAccuracy: 43.80%\n",
      "22\tValidation loss: 2.081128\tBest loss: 2.064683\tAccuracy: 44.10%\n",
      "23\tValidation loss: 1.966728\tBest loss: 1.966728\tAccuracy: 46.20%\n",
      "24\tValidation loss: 1.986938\tBest loss: 1.966728\tAccuracy: 46.90%\n",
      "25\tValidation loss: 2.042172\tBest loss: 1.966728\tAccuracy: 43.60%\n",
      "26\tValidation loss: 1.993077\tBest loss: 1.966728\tAccuracy: 46.50%\n",
      "27\tValidation loss: 2.269935\tBest loss: 1.966728\tAccuracy: 46.00%\n",
      "28\tValidation loss: 2.176580\tBest loss: 1.966728\tAccuracy: 46.10%\n",
      "29\tValidation loss: 1.996298\tBest loss: 1.966728\tAccuracy: 44.80%\n",
      "30\tValidation loss: 2.119906\tBest loss: 1.966728\tAccuracy: 45.80%\n",
      "31\tValidation loss: 2.235075\tBest loss: 1.966728\tAccuracy: 43.90%\n",
      "32\tValidation loss: 2.138192\tBest loss: 1.966728\tAccuracy: 47.20%\n",
      "33\tValidation loss: 2.112535\tBest loss: 1.966728\tAccuracy: 48.70%\n",
      "34\tValidation loss: 2.775041\tBest loss: 1.966728\tAccuracy: 47.50%\n",
      "35\tValidation loss: 2.247711\tBest loss: 1.966728\tAccuracy: 47.80%\n",
      "36\tValidation loss: 2.192536\tBest loss: 1.966728\tAccuracy: 45.30%\n",
      "37\tValidation loss: 2.029420\tBest loss: 1.966728\tAccuracy: 48.80%\n",
      "38\tValidation loss: 2.262744\tBest loss: 1.966728\tAccuracy: 45.90%\n",
      "39\tValidation loss: 2.103205\tBest loss: 1.966728\tAccuracy: 47.80%\n",
      "40\tValidation loss: 2.089893\tBest loss: 1.966728\tAccuracy: 46.10%\n",
      "41\tValidation loss: 1.917667\tBest loss: 1.917667\tAccuracy: 48.20%\n",
      "42\tValidation loss: 2.119667\tBest loss: 1.917667\tAccuracy: 46.70%\n",
      "43\tValidation loss: 2.193448\tBest loss: 1.917667\tAccuracy: 42.70%\n",
      "44\tValidation loss: 2.023222\tBest loss: 1.917667\tAccuracy: 48.00%\n",
      "45\tValidation loss: 1.943106\tBest loss: 1.917667\tAccuracy: 50.90%\n",
      "46\tValidation loss: 2.261133\tBest loss: 1.917667\tAccuracy: 48.60%\n",
      "47\tValidation loss: 2.084949\tBest loss: 1.917667\tAccuracy: 49.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\tValidation loss: 2.088046\tBest loss: 1.917667\tAccuracy: 50.00%\n",
      "49\tValidation loss: 1.967606\tBest loss: 1.917667\tAccuracy: 49.10%\n",
      "50\tValidation loss: 2.095462\tBest loss: 1.917667\tAccuracy: 52.30%\n",
      "51\tValidation loss: 1.912688\tBest loss: 1.912688\tAccuracy: 54.20%\n",
      "52\tValidation loss: 1.985652\tBest loss: 1.912688\tAccuracy: 49.80%\n",
      "53\tValidation loss: 2.021718\tBest loss: 1.912688\tAccuracy: 52.70%\n",
      "54\tValidation loss: 2.025815\tBest loss: 1.912688\tAccuracy: 54.10%\n",
      "55\tValidation loss: 2.038144\tBest loss: 1.912688\tAccuracy: 52.20%\n",
      "56\tValidation loss: 2.245222\tBest loss: 1.912688\tAccuracy: 51.90%\n",
      "57\tValidation loss: 1.826082\tBest loss: 1.826082\tAccuracy: 54.40%\n",
      "58\tValidation loss: 2.028825\tBest loss: 1.826082\tAccuracy: 51.40%\n",
      "59\tValidation loss: 2.230469\tBest loss: 1.826082\tAccuracy: 54.60%\n",
      "60\tValidation loss: 2.163534\tBest loss: 1.826082\tAccuracy: 53.00%\n",
      "61\tValidation loss: 2.206356\tBest loss: 1.826082\tAccuracy: 54.00%\n",
      "62\tValidation loss: 2.139207\tBest loss: 1.826082\tAccuracy: 53.40%\n",
      "63\tValidation loss: 2.197288\tBest loss: 1.826082\tAccuracy: 50.70%\n",
      "64\tValidation loss: 2.376569\tBest loss: 1.826082\tAccuracy: 52.50%\n",
      "65\tValidation loss: 2.312952\tBest loss: 1.826082\tAccuracy: 46.90%\n",
      "66\tValidation loss: 2.449984\tBest loss: 1.826082\tAccuracy: 51.70%\n",
      "67\tValidation loss: 2.593117\tBest loss: 1.826082\tAccuracy: 51.20%\n",
      "68\tValidation loss: 2.321666\tBest loss: 1.826082\tAccuracy: 54.60%\n",
      "69\tValidation loss: 2.568618\tBest loss: 1.826082\tAccuracy: 56.20%\n",
      "70\tValidation loss: 2.773848\tBest loss: 1.826082\tAccuracy: 50.90%\n",
      "71\tValidation loss: 2.620497\tBest loss: 1.826082\tAccuracy: 50.90%\n",
      "72\tValidation loss: 2.571165\tBest loss: 1.826082\tAccuracy: 54.50%\n",
      "73\tValidation loss: 2.208876\tBest loss: 1.826082\tAccuracy: 56.70%\n",
      "74\tValidation loss: 2.542805\tBest loss: 1.826082\tAccuracy: 51.80%\n",
      "75\tValidation loss: 2.332013\tBest loss: 1.826082\tAccuracy: 53.00%\n",
      "76\tValidation loss: 2.381101\tBest loss: 1.826082\tAccuracy: 56.60%\n",
      "77\tValidation loss: 2.318690\tBest loss: 1.826082\tAccuracy: 52.50%\n",
      "78\tValidation loss: 2.397200\tBest loss: 1.826082\tAccuracy: 52.20%\n",
      "Early stopping!\n",
      "[[  6.67989525e-06   2.47260847e-04   1.21233700e-06 ...,   3.09796560e-05\n",
      "    2.03667511e-07   1.56833539e-05]\n",
      " [  0.00000000e+00   6.39977041e-30   2.66421570e-34 ...,   4.27767019e-20\n",
      "    1.77193752e-25   9.22773389e-23]\n",
      " [  3.44787637e-04   1.00549767e-02   2.56322790e-03 ...,   6.70828717e-03\n",
      "    7.82616530e-03   1.34248482e-02]\n",
      " ..., \n",
      " [  6.36041575e-09   1.16137722e-09   3.06293213e-10 ...,   1.07382849e-08\n",
      "    1.35389611e-08   4.03645476e-12]\n",
      " [  2.67558750e-02   3.47582554e-03   3.47165763e-03 ...,   8.82626511e-03\n",
      "    1.38361927e-03   7.56456750e-03]\n",
      " [  4.41573222e-23   5.74868503e-16   1.45218769e-23 ...,   3.74758020e-02\n",
      "    9.70398716e-04   8.06102812e-01]]\n",
      "[41 41 11 ...,  6 11 47]\n",
      "[[  1.26699305e-07   5.09235426e-04   1.63073230e-06 ...,   5.58715499e-07\n",
      "    3.93602234e-10   5.30644775e-06]\n",
      " [  6.79167174e-03   5.57171740e-02   4.93225642e-03 ...,   1.37381838e-04\n",
      "    1.19652999e-04   4.98601403e-05]\n",
      " [  2.45830456e-13   2.04725123e-24   8.65474703e-06 ...,   2.63634029e-20\n",
      "    5.08236408e-25   1.10720129e-25]\n",
      " ..., \n",
      " [  1.73845619e-03   2.56633549e-03   1.88633858e-03 ...,   4.58130315e-02\n",
      "    1.81557033e-02   4.51497622e-02]\n",
      " [  1.65321489e-05   2.75152212e-04   4.76508612e-05 ...,   4.26062316e-01\n",
      "    5.03288433e-02   1.31738381e-02]\n",
      " [  4.70193384e-10   1.38645447e-07   5.60314684e-09 ...,   3.27525198e-01\n",
      "    2.71682143e-02   2.88314130e-02]]\n",
      "[21 19 16 ...,  8 45 45]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  14.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 4.547494\tBest loss: 4.547494\tAccuracy: 6.90%\n",
      "1\tValidation loss: 3.302689\tBest loss: 3.302689\tAccuracy: 19.80%\n",
      "2\tValidation loss: 2.732960\tBest loss: 2.732960\tAccuracy: 29.80%\n",
      "3\tValidation loss: 2.611447\tBest loss: 2.611447\tAccuracy: 33.30%\n",
      "4\tValidation loss: 2.710717\tBest loss: 2.611447\tAccuracy: 34.10%\n",
      "5\tValidation loss: 2.409861\tBest loss: 2.409861\tAccuracy: 37.80%\n",
      "6\tValidation loss: 2.286483\tBest loss: 2.286483\tAccuracy: 40.00%\n",
      "7\tValidation loss: 2.360964\tBest loss: 2.286483\tAccuracy: 40.70%\n",
      "8\tValidation loss: 2.494829\tBest loss: 2.286483\tAccuracy: 44.50%\n",
      "9\tValidation loss: 2.353378\tBest loss: 2.286483\tAccuracy: 43.20%\n",
      "10\tValidation loss: 2.239513\tBest loss: 2.239513\tAccuracy: 46.10%\n",
      "11\tValidation loss: 2.245163\tBest loss: 2.239513\tAccuracy: 44.50%\n",
      "12\tValidation loss: 2.904770\tBest loss: 2.239513\tAccuracy: 45.50%\n",
      "13\tValidation loss: 2.800634\tBest loss: 2.239513\tAccuracy: 46.70%\n",
      "14\tValidation loss: 2.530828\tBest loss: 2.239513\tAccuracy: 49.50%\n",
      "15\tValidation loss: 2.510916\tBest loss: 2.239513\tAccuracy: 50.60%\n",
      "16\tValidation loss: 2.986753\tBest loss: 2.239513\tAccuracy: 47.50%\n",
      "17\tValidation loss: 2.726043\tBest loss: 2.239513\tAccuracy: 47.00%\n",
      "18\tValidation loss: 2.493020\tBest loss: 2.239513\tAccuracy: 51.00%\n",
      "19\tValidation loss: 2.406795\tBest loss: 2.239513\tAccuracy: 53.30%\n",
      "20\tValidation loss: 2.720485\tBest loss: 2.239513\tAccuracy: 53.20%\n",
      "21\tValidation loss: 2.651589\tBest loss: 2.239513\tAccuracy: 55.40%\n",
      "22\tValidation loss: 3.150011\tBest loss: 2.239513\tAccuracy: 51.10%\n",
      "23\tValidation loss: 2.663042\tBest loss: 2.239513\tAccuracy: 50.30%\n",
      "24\tValidation loss: 2.690580\tBest loss: 2.239513\tAccuracy: 53.00%\n",
      "25\tValidation loss: 2.970837\tBest loss: 2.239513\tAccuracy: 48.90%\n",
      "26\tValidation loss: 2.908469\tBest loss: 2.239513\tAccuracy: 53.40%\n",
      "27\tValidation loss: 2.952924\tBest loss: 2.239513\tAccuracy: 54.10%\n",
      "28\tValidation loss: 3.515357\tBest loss: 2.239513\tAccuracy: 51.20%\n",
      "29\tValidation loss: 2.981524\tBest loss: 2.239513\tAccuracy: 53.40%\n",
      "30\tValidation loss: 3.314208\tBest loss: 2.239513\tAccuracy: 55.20%\n",
      "31\tValidation loss: 3.570756\tBest loss: 2.239513\tAccuracy: 56.20%\n",
      "Early stopping!\n",
      "[[  1.56189117e-09   2.10581653e-04   1.72543660e-04 ...,   8.33454215e-16\n",
      "    1.27172551e-13   4.54751661e-16]\n",
      " [  5.83745167e-02   5.10391295e-02   8.39379802e-02 ...,   3.14793992e-03\n",
      "    6.90851535e-04   1.09778523e-06]\n",
      " [  1.23564450e-10   0.00000000e+00   1.51922043e-16 ...,   1.30950817e-34\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.40955914e-09   3.32070267e-05   1.97375027e-09 ...,   4.05710423e-03\n",
      "    1.32149369e-01   1.94088385e-01]\n",
      " [  2.04657530e-03   8.70695990e-03   6.78978208e-03 ...,   3.20526391e-01\n",
      "    2.02563867e-01   3.95861417e-02]\n",
      " [  1.04215826e-06   1.20074295e-09   1.55622831e-06 ...,   2.52320297e-06\n",
      "    5.05019937e-09   5.03612441e-08]]\n",
      "[20 19 17 ..., 47 45 25]\n",
      "[[  1.57034250e-07   4.65798268e-11   8.65340610e-07 ...,   3.03626672e-11\n",
      "    8.02675486e-17   2.83500339e-17]\n",
      " [  1.72863551e-03   1.25345781e-01   9.55531650e-05 ...,   4.87418558e-17\n",
      "    1.37475385e-13   1.71032132e-17]\n",
      " [  2.52667833e-05   4.89487604e-07   1.90246647e-05 ...,   3.32702805e-13\n",
      "    1.42047976e-15   2.00267573e-17]\n",
      " ..., \n",
      " [  4.00669143e-23   4.44284249e-31   6.28834603e-25 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.44280584e-02   5.99198509e-03   4.86934818e-02 ...,   1.68228578e-02\n",
      "    2.12777797e-02   5.92959695e-04]\n",
      " [  3.52710821e-19   1.34780065e-09   2.36293310e-21 ...,   3.70310694e-02\n",
      "    1.48314014e-01   7.20785320e-01]]\n",
      "[41 21 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=   4.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.760389\tBest loss: 3.760389\tAccuracy: 7.10%\n",
      "1\tValidation loss: 3.065522\tBest loss: 3.065522\tAccuracy: 20.90%\n",
      "2\tValidation loss: 3.061082\tBest loss: 3.061082\tAccuracy: 24.60%\n",
      "3\tValidation loss: 2.488001\tBest loss: 2.488001\tAccuracy: 31.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\tValidation loss: 2.321880\tBest loss: 2.321880\tAccuracy: 36.50%\n",
      "5\tValidation loss: 2.223086\tBest loss: 2.223086\tAccuracy: 42.00%\n",
      "6\tValidation loss: 2.552263\tBest loss: 2.223086\tAccuracy: 40.30%\n",
      "7\tValidation loss: 2.952947\tBest loss: 2.223086\tAccuracy: 37.00%\n",
      "8\tValidation loss: 4.348178\tBest loss: 2.223086\tAccuracy: 39.30%\n",
      "9\tValidation loss: 2.333709\tBest loss: 2.223086\tAccuracy: 46.80%\n",
      "10\tValidation loss: 2.470326\tBest loss: 2.223086\tAccuracy: 49.70%\n",
      "11\tValidation loss: 2.277677\tBest loss: 2.223086\tAccuracy: 51.80%\n",
      "12\tValidation loss: 2.416680\tBest loss: 2.223086\tAccuracy: 49.60%\n",
      "13\tValidation loss: 2.932655\tBest loss: 2.223086\tAccuracy: 47.70%\n",
      "14\tValidation loss: 2.969954\tBest loss: 2.223086\tAccuracy: 48.70%\n",
      "15\tValidation loss: 2.752537\tBest loss: 2.223086\tAccuracy: 51.40%\n",
      "16\tValidation loss: 2.561263\tBest loss: 2.223086\tAccuracy: 50.10%\n",
      "17\tValidation loss: 2.868868\tBest loss: 2.223086\tAccuracy: 52.50%\n",
      "18\tValidation loss: 2.743783\tBest loss: 2.223086\tAccuracy: 54.40%\n",
      "19\tValidation loss: 2.849768\tBest loss: 2.223086\tAccuracy: 53.60%\n",
      "20\tValidation loss: 3.276625\tBest loss: 2.223086\tAccuracy: 53.90%\n",
      "21\tValidation loss: 2.954908\tBest loss: 2.223086\tAccuracy: 53.60%\n",
      "22\tValidation loss: 3.246405\tBest loss: 2.223086\tAccuracy: 55.10%\n",
      "23\tValidation loss: 3.144249\tBest loss: 2.223086\tAccuracy: 55.00%\n",
      "24\tValidation loss: 3.293915\tBest loss: 2.223086\tAccuracy: 53.00%\n",
      "25\tValidation loss: 3.909984\tBest loss: 2.223086\tAccuracy: 52.30%\n",
      "26\tValidation loss: 3.711093\tBest loss: 2.223086\tAccuracy: 54.10%\n",
      "Early stopping!\n",
      "[[  1.67525224e-02   1.75795835e-02   1.11778351e-02 ...,   1.27417026e-02\n",
      "    1.11445962e-02   1.16818193e-02]\n",
      " [  1.41685208e-19   2.00192951e-09   2.01896384e-08 ...,   7.35052684e-14\n",
      "    4.25627361e-19   2.90660079e-10]\n",
      " [  1.92603689e-09   3.22317755e-05   6.95115668e-05 ...,   6.01330953e-07\n",
      "    3.01403413e-09   1.55486323e-05]\n",
      " ..., \n",
      " [  3.83549705e-05   1.72298527e-07   5.07159821e-05 ...,   3.35932896e-03\n",
      "    4.05104226e-03   1.70089472e-02]\n",
      " [  1.67525224e-02   1.75795835e-02   1.11778351e-02 ...,   1.27417026e-02\n",
      "    1.11445962e-02   1.16818193e-02]\n",
      " [  1.47546798e-05   3.34285382e-08   2.12559808e-05 ...,   2.34490423e-03\n",
      "    2.94416049e-03   1.47138694e-02]]\n",
      "[26 43 43 ..., 36 26 36]\n",
      "[[  4.65184158e-08   4.95599181e-07   5.01018549e-05 ...,   1.26896283e-13\n",
      "    9.45335824e-11   7.73314044e-14]\n",
      " [  5.05041331e-02   3.37513052e-02   5.23261242e-02 ...,   4.72030835e-03\n",
      "    4.34948364e-03   4.50332137e-03]\n",
      " [  4.54886932e-15   0.00000000e+00   3.05069769e-09 ...,   4.46274901e-19\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  3.98169318e-13   4.24653192e-14   1.24605916e-15 ...,   1.29370230e-21\n",
      "    1.36405704e-29   2.33832376e-29]\n",
      " [  2.01593395e-02   8.45909957e-03   2.13672053e-02 ...,   1.51152974e-02\n",
      "    9.24228411e-03   7.27167167e-03]\n",
      " [  1.41026277e-21   5.79012212e-19   1.79860240e-26 ...,   7.20546556e-09\n",
      "    2.14032173e-01   6.98721588e-01]]\n",
      "[21 19 16 ...,  6 20 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=   3.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.803310\tBest loss: 3.803310\tAccuracy: 8.20%\n",
      "1\tValidation loss: 3.164698\tBest loss: 3.164698\tAccuracy: 18.70%\n",
      "2\tValidation loss: 2.834293\tBest loss: 2.834293\tAccuracy: 24.30%\n",
      "3\tValidation loss: 2.629667\tBest loss: 2.629667\tAccuracy: 31.10%\n",
      "4\tValidation loss: 2.430904\tBest loss: 2.430904\tAccuracy: 34.90%\n",
      "5\tValidation loss: 2.243109\tBest loss: 2.243109\tAccuracy: 38.80%\n",
      "6\tValidation loss: 2.371388\tBest loss: 2.243109\tAccuracy: 42.10%\n",
      "7\tValidation loss: 2.343830\tBest loss: 2.243109\tAccuracy: 41.10%\n",
      "8\tValidation loss: 2.263803\tBest loss: 2.243109\tAccuracy: 46.00%\n",
      "9\tValidation loss: 2.166454\tBest loss: 2.166454\tAccuracy: 47.90%\n",
      "10\tValidation loss: 2.569609\tBest loss: 2.166454\tAccuracy: 43.00%\n",
      "11\tValidation loss: 2.449551\tBest loss: 2.166454\tAccuracy: 45.70%\n",
      "12\tValidation loss: 2.374099\tBest loss: 2.166454\tAccuracy: 49.50%\n",
      "13\tValidation loss: 2.978232\tBest loss: 2.166454\tAccuracy: 48.30%\n",
      "14\tValidation loss: 2.402573\tBest loss: 2.166454\tAccuracy: 50.30%\n",
      "15\tValidation loss: 2.505393\tBest loss: 2.166454\tAccuracy: 49.10%\n",
      "16\tValidation loss: 2.479956\tBest loss: 2.166454\tAccuracy: 48.10%\n",
      "17\tValidation loss: 2.496246\tBest loss: 2.166454\tAccuracy: 52.30%\n",
      "18\tValidation loss: 2.674283\tBest loss: 2.166454\tAccuracy: 51.90%\n",
      "19\tValidation loss: 2.889623\tBest loss: 2.166454\tAccuracy: 53.20%\n",
      "20\tValidation loss: 2.868040\tBest loss: 2.166454\tAccuracy: 50.40%\n",
      "21\tValidation loss: 2.637274\tBest loss: 2.166454\tAccuracy: 53.70%\n",
      "22\tValidation loss: 2.959121\tBest loss: 2.166454\tAccuracy: 50.20%\n",
      "23\tValidation loss: 2.811915\tBest loss: 2.166454\tAccuracy: 56.20%\n",
      "24\tValidation loss: 2.997068\tBest loss: 2.166454\tAccuracy: 52.10%\n",
      "25\tValidation loss: 3.029427\tBest loss: 2.166454\tAccuracy: 51.20%\n",
      "26\tValidation loss: 3.015982\tBest loss: 2.166454\tAccuracy: 55.40%\n",
      "27\tValidation loss: 3.254360\tBest loss: 2.166454\tAccuracy: 51.30%\n",
      "28\tValidation loss: 3.067799\tBest loss: 2.166454\tAccuracy: 53.10%\n",
      "29\tValidation loss: 3.360748\tBest loss: 2.166454\tAccuracy: 50.70%\n",
      "30\tValidation loss: 3.210656\tBest loss: 2.166454\tAccuracy: 55.40%\n",
      "Early stopping!\n",
      "[[  8.60917033e-04   4.24845872e-04   2.94149533e-04 ...,   1.51181972e-04\n",
      "    5.36562038e-05   6.73047616e-05]\n",
      " [  1.64864013e-18   1.58551523e-14   1.85259916e-13 ...,   1.24626031e-24\n",
      "    1.85310553e-27   3.36566658e-28]\n",
      " [  1.45862243e-04   2.92094573e-02   2.67664291e-04 ...,   8.06283730e-04\n",
      "    1.82965752e-02   2.77375393e-02]\n",
      " ..., \n",
      " [  7.73685395e-19   4.40939253e-16   2.64831882e-17 ...,   3.12118783e-30\n",
      "    1.59374949e-25   5.12688563e-37]\n",
      " [  9.28907003e-03   1.14396624e-02   1.95233915e-02 ...,   4.48334916e-03\n",
      "    1.35397762e-02   3.40615143e-03]\n",
      " [  2.09775109e-26   5.03523709e-19   1.39174150e-28 ...,   7.44008594e-06\n",
      "    1.21579668e-03   9.88368452e-01]]\n",
      "[38 41 31 ...,  6 10 47]\n",
      "[[  3.72772263e-07   6.40232814e-03   2.62003567e-07 ...,   2.51373925e-15\n",
      "    4.99146216e-14   2.76480183e-19]\n",
      " [  2.91056260e-02   8.30146149e-02   2.49095988e-02 ...,   3.43385292e-03\n",
      "    5.35753882e-03   9.59955389e-04]\n",
      " [  2.01075017e-17   0.00000000e+00   2.34601119e-18 ...,   5.58383426e-21\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  5.56237414e-04   3.74632073e-05   3.87574523e-03 ...,   1.18700194e-03\n",
      "    5.02718752e-03   5.54389274e-03]\n",
      " [  4.76334305e-09   2.39703809e-07   6.35950625e-10 ...,   8.11427474e-01\n",
      "    1.77659504e-02   4.28221039e-02]\n",
      " [  5.64527181e-06   1.85452311e-08   1.32195726e-06 ...,   6.15499262e-03\n",
      "    2.05031992e-03   2.40772981e-02]]\n",
      "[20 28 17 ..., 36 45 36]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=1, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=   4.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 303.612335\tBest loss: 303.612335\tAccuracy: 1.50%\n",
      "1\tValidation loss: 122.066818\tBest loss: 122.066818\tAccuracy: 4.10%\n",
      "2\tValidation loss: 75.273529\tBest loss: 75.273529\tAccuracy: 1.80%\n",
      "3\tValidation loss: 228.816010\tBest loss: 75.273529\tAccuracy: 3.60%\n",
      "4\tValidation loss: 122.035416\tBest loss: 75.273529\tAccuracy: 3.00%\n",
      "5\tValidation loss: 155.514893\tBest loss: 75.273529\tAccuracy: 2.40%\n",
      "6\tValidation loss: 2311.995117\tBest loss: 75.273529\tAccuracy: 1.90%\n",
      "7\tValidation loss: 807.549438\tBest loss: 75.273529\tAccuracy: 2.10%\n",
      "8\tValidation loss: 388.399170\tBest loss: 75.273529\tAccuracy: 1.70%\n",
      "9\tValidation loss: 136.128387\tBest loss: 75.273529\tAccuracy: 2.40%\n",
      "10\tValidation loss: 469.735626\tBest loss: 75.273529\tAccuracy: 4.20%\n",
      "11\tValidation loss: 211.623459\tBest loss: 75.273529\tAccuracy: 2.40%\n",
      "12\tValidation loss: 442.714294\tBest loss: 75.273529\tAccuracy: 1.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\tValidation loss: 250.458527\tBest loss: 75.273529\tAccuracy: 1.80%\n",
      "14\tValidation loss: 230.002167\tBest loss: 75.273529\tAccuracy: 2.70%\n",
      "15\tValidation loss: 95.595627\tBest loss: 75.273529\tAccuracy: 4.10%\n",
      "16\tValidation loss: 422.648468\tBest loss: 75.273529\tAccuracy: 3.10%\n",
      "17\tValidation loss: 108.033211\tBest loss: 75.273529\tAccuracy: 4.50%\n",
      "18\tValidation loss: 124.205986\tBest loss: 75.273529\tAccuracy: 1.90%\n",
      "19\tValidation loss: 369.621521\tBest loss: 75.273529\tAccuracy: 3.10%\n",
      "20\tValidation loss: 113.679657\tBest loss: 75.273529\tAccuracy: 3.20%\n",
      "21\tValidation loss: 110.425758\tBest loss: 75.273529\tAccuracy: 2.40%\n",
      "22\tValidation loss: 607.758789\tBest loss: 75.273529\tAccuracy: 1.80%\n",
      "23\tValidation loss: 161.429459\tBest loss: 75.273529\tAccuracy: 1.80%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   2.55478928e-22   0.00000000e+00 ...,   0.00000000e+00\n",
      "    3.32693255e-35   0.00000000e+00]\n",
      " [  7.61085772e-04   3.22444900e-03   3.47281370e-04 ...,   1.85847466e-06\n",
      "    1.48149984e-05   4.55970167e-06]\n",
      " [  0.00000000e+00   1.14119698e-27   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.05499178e-13   3.39818911e-07   2.06788610e-15 ...,   2.18329484e-18\n",
      "    7.73991114e-13   4.48905778e-15]\n",
      " [  0.00000000e+00   1.93212339e-31   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[15  9 15 ..., 15  9 15]\n",
      "[[  2.80362603e-32   8.95310268e-18   4.33774807e-35 ...,   0.00000000e+00\n",
      "    1.22912187e-28   4.15131541e-35]\n",
      " [  0.00000000e+00   3.77423236e-31   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  8.69763429e-30   1.12207252e-21   1.25017463e-34 ...,   2.89440707e-33\n",
      "    1.77301393e-30   0.00000000e+00]\n",
      " ..., \n",
      " [  2.41425649e-18   1.49224610e-09   1.90864394e-21 ...,   1.50080861e-25\n",
      "    4.76565088e-17   2.04072041e-21]\n",
      " [  6.51694019e-04   2.83426046e-03   2.93907971e-04 ...,   1.40129612e-06\n",
      "    1.35783112e-05   3.91567346e-06]\n",
      " [  0.00000000e+00   1.47768476e-25   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[15 15  8 ..., 15  9 15]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  10.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 179.652771\tBest loss: 179.652771\tAccuracy: 3.10%\n",
      "1\tValidation loss: 98.469261\tBest loss: 98.469261\tAccuracy: 2.00%\n",
      "2\tValidation loss: 200.436783\tBest loss: 98.469261\tAccuracy: 3.70%\n",
      "3\tValidation loss: 321.078369\tBest loss: 98.469261\tAccuracy: 3.10%\n",
      "4\tValidation loss: 131.674377\tBest loss: 98.469261\tAccuracy: 2.20%\n",
      "5\tValidation loss: 370.394836\tBest loss: 98.469261\tAccuracy: 2.30%\n",
      "6\tValidation loss: 143.513901\tBest loss: 98.469261\tAccuracy: 2.40%\n",
      "7\tValidation loss: 129.727661\tBest loss: 98.469261\tAccuracy: 2.70%\n",
      "8\tValidation loss: 527.289185\tBest loss: 98.469261\tAccuracy: 2.80%\n",
      "9\tValidation loss: 349.946259\tBest loss: 98.469261\tAccuracy: 3.40%\n",
      "10\tValidation loss: 654.717407\tBest loss: 98.469261\tAccuracy: 2.30%\n",
      "11\tValidation loss: 784.903625\tBest loss: 98.469261\tAccuracy: 2.20%\n",
      "12\tValidation loss: 264.411530\tBest loss: 98.469261\tAccuracy: 2.40%\n",
      "13\tValidation loss: 621.613831\tBest loss: 98.469261\tAccuracy: 2.10%\n",
      "14\tValidation loss: 281.829956\tBest loss: 98.469261\tAccuracy: 4.70%\n",
      "15\tValidation loss: 391.667999\tBest loss: 98.469261\tAccuracy: 3.10%\n",
      "16\tValidation loss: 491.580505\tBest loss: 98.469261\tAccuracy: 2.50%\n",
      "17\tValidation loss: 215.346939\tBest loss: 98.469261\tAccuracy: 1.00%\n",
      "18\tValidation loss: 246.982117\tBest loss: 98.469261\tAccuracy: 3.00%\n",
      "19\tValidation loss: 305.063293\tBest loss: 98.469261\tAccuracy: 2.30%\n",
      "20\tValidation loss: 204.383102\tBest loss: 98.469261\tAccuracy: 1.40%\n",
      "21\tValidation loss: 228.821136\tBest loss: 98.469261\tAccuracy: 2.00%\n",
      "22\tValidation loss: 141.528702\tBest loss: 98.469261\tAccuracy: 2.00%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   1.05468590e-20   0.00000000e+00 ...,   0.00000000e+00\n",
      "    3.93540341e-24   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.78282103e-31   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.02777579e-23   1.17806366e-07   8.22733328e-19 ...,   3.64542352e-30\n",
      "    8.43480939e-06   4.56099426e-14]\n",
      " [  0.00000000e+00   5.21474140e-13   4.87684012e-32 ...,   0.00000000e+00\n",
      "    3.89066320e-17   9.46364923e-31]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[25 25 25 ..., 25 25 25]\n",
      "[[  0.00000000e+00   6.60366754e-25   0.00000000e+00 ...,   0.00000000e+00\n",
      "    2.28766018e-23   0.00000000e+00]\n",
      " [  3.72964249e-04   6.06368855e-02   4.94770473e-03 ...,   1.49138805e-06\n",
      "    1.78536344e-02   6.75422547e-04]\n",
      " [  0.00000000e+00   6.33961046e-24   0.00000000e+00 ...,   0.00000000e+00\n",
      "    8.09458631e-22   0.00000000e+00]\n",
      " ..., \n",
      " [  2.39643049e-21   5.98886341e-04   2.07481080e-26 ...,   0.00000000e+00\n",
      "    2.69455465e-13   4.71004983e-25]\n",
      " [  7.55739049e-04   4.33805250e-02   4.95638279e-03 ...,   4.67152222e-06\n",
      "    2.18441579e-02   1.10953988e-03]\n",
      " [  0.00000000e+00   5.66622293e-17   0.00000000e+00 ...,   0.00000000e+00\n",
      "    1.38242657e-24   0.00000000e+00]]\n",
      "[25  9 25 ..., 25  9 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  10.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 498.393494\tBest loss: 498.393494\tAccuracy: 2.50%\n",
      "1\tValidation loss: 115.484261\tBest loss: 115.484261\tAccuracy: 2.30%\n",
      "2\tValidation loss: 131.445572\tBest loss: 115.484261\tAccuracy: 2.30%\n",
      "3\tValidation loss: 138.706161\tBest loss: 115.484261\tAccuracy: 4.20%\n",
      "4\tValidation loss: 90.347206\tBest loss: 90.347206\tAccuracy: 3.10%\n",
      "5\tValidation loss: 188.732544\tBest loss: 90.347206\tAccuracy: 5.00%\n",
      "6\tValidation loss: 114.318008\tBest loss: 90.347206\tAccuracy: 3.30%\n",
      "7\tValidation loss: 1467.870850\tBest loss: 90.347206\tAccuracy: 2.40%\n",
      "8\tValidation loss: 133.729385\tBest loss: 90.347206\tAccuracy: 3.70%\n",
      "9\tValidation loss: 111.070572\tBest loss: 90.347206\tAccuracy: 2.20%\n",
      "10\tValidation loss: 660.766663\tBest loss: 90.347206\tAccuracy: 1.70%\n",
      "11\tValidation loss: 111.803131\tBest loss: 90.347206\tAccuracy: 1.70%\n",
      "12\tValidation loss: 129.886642\tBest loss: 90.347206\tAccuracy: 1.50%\n",
      "13\tValidation loss: 206.021225\tBest loss: 90.347206\tAccuracy: 4.20%\n",
      "14\tValidation loss: 149.706375\tBest loss: 90.347206\tAccuracy: 2.50%\n",
      "15\tValidation loss: 464.403870\tBest loss: 90.347206\tAccuracy: 2.40%\n",
      "16\tValidation loss: 271.244324\tBest loss: 90.347206\tAccuracy: 4.40%\n",
      "17\tValidation loss: 195.494690\tBest loss: 90.347206\tAccuracy: 1.30%\n",
      "18\tValidation loss: 458.925995\tBest loss: 90.347206\tAccuracy: 2.00%\n",
      "19\tValidation loss: 99.758240\tBest loss: 90.347206\tAccuracy: 2.30%\n",
      "20\tValidation loss: 191.958939\tBest loss: 90.347206\tAccuracy: 1.70%\n",
      "21\tValidation loss: 738.589111\tBest loss: 90.347206\tAccuracy: 4.80%\n",
      "22\tValidation loss: 165.367493\tBest loss: 90.347206\tAccuracy: 3.00%\n",
      "23\tValidation loss: 395.580627\tBest loss: 90.347206\tAccuracy: 1.00%\n",
      "24\tValidation loss: 935.469727\tBest loss: 90.347206\tAccuracy: 2.80%\n",
      "25\tValidation loss: 155.686905\tBest loss: 90.347206\tAccuracy: 2.60%\n",
      "Early stopping!\n",
      "[[  3.27841243e-15   1.59684566e-06   2.67220912e-10 ...,   4.89814234e-08\n",
      "    2.10274660e-08   2.62769640e-06]\n",
      " [  0.00000000e+00   1.81081126e-26   0.00000000e+00 ...,   3.42965884e-21\n",
      "    1.11322772e-26   1.99381273e-14]\n",
      " [  0.00000000e+00   8.82048551e-25   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   5.25258903e-09]\n",
      " ..., \n",
      " [  8.13857933e-36   5.82989451e-18   4.93405822e-28 ...,   1.65436360e-18\n",
      "    9.74431484e-22   2.50509518e-16]\n",
      " [  8.21152062e-05   2.36000549e-02   3.06775531e-04 ...,   4.57678507e-05\n",
      "    4.11818946e-05   9.87344611e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   9.76765896e-35\n",
      "    0.00000000e+00   4.91016231e-18]]\n",
      "[ 3  3 28 ...,  3  3  3]\n",
      "[[  0.00000000e+00   3.70233144e-38   0.00000000e+00 ...,   7.07331161e-37\n",
      "    1.42522907e-35   2.37821585e-24]\n",
      " [  7.51438929e-05   2.16940865e-02   3.41725448e-04 ...,   4.17403608e-05\n",
      "    3.99138007e-05   8.35889441e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.23511605e-34]\n",
      " ..., \n",
      " [  3.57351602e-27   4.57385865e-12   1.35853144e-23 ...,   1.65044139e-13\n",
      "    1.75345209e-12   4.10606162e-08]\n",
      " [  0.00000000e+00   3.65471515e-27   0.00000000e+00 ...,   1.46831065e-24\n",
      "    8.59611567e-29   1.35364440e-20]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.53779571e-25]]\n",
      "[3 3 3 ..., 3 3 3]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=50, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  11.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.150079\tBest loss: 4.150079\tAccuracy: 4.40%\n",
      "1\tValidation loss: 3.919967\tBest loss: 3.919967\tAccuracy: 4.90%\n",
      "2\tValidation loss: 3.875917\tBest loss: 3.875917\tAccuracy: 5.00%\n",
      "3\tValidation loss: 3.836572\tBest loss: 3.836572\tAccuracy: 5.00%\n",
      "4\tValidation loss: 3.807936\tBest loss: 3.807936\tAccuracy: 5.00%\n",
      "5\tValidation loss: 3.785131\tBest loss: 3.785131\tAccuracy: 5.90%\n",
      "6\tValidation loss: 3.765731\tBest loss: 3.765731\tAccuracy: 5.90%\n",
      "7\tValidation loss: 3.749190\tBest loss: 3.749190\tAccuracy: 6.20%\n",
      "8\tValidation loss: 3.736951\tBest loss: 3.736951\tAccuracy: 6.40%\n",
      "9\tValidation loss: 3.726622\tBest loss: 3.726622\tAccuracy: 7.00%\n",
      "10\tValidation loss: 3.717282\tBest loss: 3.717282\tAccuracy: 8.10%\n",
      "11\tValidation loss: 3.709368\tBest loss: 3.709368\tAccuracy: 8.20%\n",
      "12\tValidation loss: 3.701788\tBest loss: 3.701788\tAccuracy: 8.40%\n",
      "13\tValidation loss: 3.695649\tBest loss: 3.695649\tAccuracy: 8.20%\n",
      "14\tValidation loss: 3.689520\tBest loss: 3.689520\tAccuracy: 8.60%\n",
      "15\tValidation loss: 3.684067\tBest loss: 3.684067\tAccuracy: 8.80%\n",
      "16\tValidation loss: 3.678634\tBest loss: 3.678634\tAccuracy: 9.30%\n",
      "17\tValidation loss: 3.674128\tBest loss: 3.674128\tAccuracy: 9.50%\n",
      "18\tValidation loss: 3.669012\tBest loss: 3.669012\tAccuracy: 9.70%\n",
      "19\tValidation loss: 3.663949\tBest loss: 3.663949\tAccuracy: 9.30%\n",
      "20\tValidation loss: 3.658961\tBest loss: 3.658961\tAccuracy: 9.90%\n",
      "21\tValidation loss: 3.655384\tBest loss: 3.655384\tAccuracy: 9.50%\n",
      "22\tValidation loss: 3.651685\tBest loss: 3.651685\tAccuracy: 9.80%\n",
      "23\tValidation loss: 3.647302\tBest loss: 3.647302\tAccuracy: 9.70%\n",
      "24\tValidation loss: 3.643250\tBest loss: 3.643250\tAccuracy: 9.70%\n",
      "25\tValidation loss: 3.640006\tBest loss: 3.640006\tAccuracy: 9.60%\n",
      "26\tValidation loss: 3.635801\tBest loss: 3.635801\tAccuracy: 9.70%\n",
      "27\tValidation loss: 3.630862\tBest loss: 3.630862\tAccuracy: 10.00%\n",
      "28\tValidation loss: 3.625375\tBest loss: 3.625375\tAccuracy: 10.10%\n",
      "29\tValidation loss: 3.618636\tBest loss: 3.618636\tAccuracy: 9.90%\n",
      "30\tValidation loss: 3.613197\tBest loss: 3.613197\tAccuracy: 10.20%\n",
      "31\tValidation loss: 3.604815\tBest loss: 3.604815\tAccuracy: 10.40%\n",
      "32\tValidation loss: 3.599260\tBest loss: 3.599260\tAccuracy: 10.50%\n",
      "33\tValidation loss: 3.590399\tBest loss: 3.590399\tAccuracy: 9.90%\n",
      "34\tValidation loss: 3.583993\tBest loss: 3.583993\tAccuracy: 10.60%\n",
      "35\tValidation loss: 3.578351\tBest loss: 3.578351\tAccuracy: 11.00%\n",
      "36\tValidation loss: 3.574580\tBest loss: 3.574580\tAccuracy: 11.90%\n",
      "37\tValidation loss: 3.566780\tBest loss: 3.566780\tAccuracy: 12.10%\n",
      "38\tValidation loss: 3.561157\tBest loss: 3.561157\tAccuracy: 11.50%\n",
      "39\tValidation loss: 3.551924\tBest loss: 3.551924\tAccuracy: 12.00%\n",
      "40\tValidation loss: 3.547089\tBest loss: 3.547089\tAccuracy: 11.90%\n",
      "41\tValidation loss: 3.541536\tBest loss: 3.541536\tAccuracy: 11.90%\n",
      "42\tValidation loss: 3.537190\tBest loss: 3.537190\tAccuracy: 12.20%\n",
      "43\tValidation loss: 3.531453\tBest loss: 3.531453\tAccuracy: 12.20%\n",
      "44\tValidation loss: 3.524667\tBest loss: 3.524667\tAccuracy: 12.00%\n",
      "45\tValidation loss: 3.519238\tBest loss: 3.519238\tAccuracy: 12.40%\n",
      "46\tValidation loss: 3.515568\tBest loss: 3.515568\tAccuracy: 12.30%\n",
      "47\tValidation loss: 3.508812\tBest loss: 3.508812\tAccuracy: 12.80%\n",
      "48\tValidation loss: 3.500623\tBest loss: 3.500623\tAccuracy: 13.00%\n",
      "49\tValidation loss: 3.495666\tBest loss: 3.495666\tAccuracy: 13.00%\n",
      "50\tValidation loss: 3.491267\tBest loss: 3.491267\tAccuracy: 13.20%\n",
      "51\tValidation loss: 3.481652\tBest loss: 3.481652\tAccuracy: 13.40%\n",
      "52\tValidation loss: 3.475392\tBest loss: 3.475392\tAccuracy: 13.00%\n",
      "53\tValidation loss: 3.470498\tBest loss: 3.470498\tAccuracy: 12.90%\n",
      "54\tValidation loss: 3.464033\tBest loss: 3.464033\tAccuracy: 12.90%\n",
      "55\tValidation loss: 3.459327\tBest loss: 3.459327\tAccuracy: 13.40%\n",
      "56\tValidation loss: 3.452813\tBest loss: 3.452813\tAccuracy: 13.40%\n",
      "57\tValidation loss: 3.444155\tBest loss: 3.444155\tAccuracy: 14.00%\n",
      "58\tValidation loss: 3.437778\tBest loss: 3.437778\tAccuracy: 13.90%\n",
      "59\tValidation loss: 3.430773\tBest loss: 3.430773\tAccuracy: 13.90%\n",
      "60\tValidation loss: 3.423164\tBest loss: 3.423164\tAccuracy: 14.00%\n",
      "61\tValidation loss: 3.417993\tBest loss: 3.417993\tAccuracy: 14.00%\n",
      "62\tValidation loss: 3.412328\tBest loss: 3.412328\tAccuracy: 14.10%\n",
      "63\tValidation loss: 3.407709\tBest loss: 3.407709\tAccuracy: 15.20%\n",
      "64\tValidation loss: 3.402683\tBest loss: 3.402683\tAccuracy: 15.20%\n",
      "65\tValidation loss: 3.394619\tBest loss: 3.394619\tAccuracy: 15.20%\n",
      "66\tValidation loss: 3.387185\tBest loss: 3.387185\tAccuracy: 15.60%\n",
      "67\tValidation loss: 3.380187\tBest loss: 3.380187\tAccuracy: 15.90%\n",
      "68\tValidation loss: 3.375152\tBest loss: 3.375152\tAccuracy: 15.60%\n",
      "69\tValidation loss: 3.370990\tBest loss: 3.370990\tAccuracy: 15.70%\n",
      "70\tValidation loss: 3.362740\tBest loss: 3.362740\tAccuracy: 16.10%\n",
      "71\tValidation loss: 3.352937\tBest loss: 3.352937\tAccuracy: 16.20%\n",
      "72\tValidation loss: 3.349081\tBest loss: 3.349081\tAccuracy: 16.80%\n",
      "73\tValidation loss: 3.347099\tBest loss: 3.347099\tAccuracy: 16.40%\n",
      "74\tValidation loss: 3.341492\tBest loss: 3.341492\tAccuracy: 16.50%\n",
      "75\tValidation loss: 3.335181\tBest loss: 3.335181\tAccuracy: 16.40%\n",
      "76\tValidation loss: 3.327380\tBest loss: 3.327380\tAccuracy: 16.90%\n",
      "77\tValidation loss: 3.326740\tBest loss: 3.326740\tAccuracy: 16.60%\n",
      "78\tValidation loss: 3.320848\tBest loss: 3.320848\tAccuracy: 16.70%\n",
      "79\tValidation loss: 3.312319\tBest loss: 3.312319\tAccuracy: 17.00%\n",
      "80\tValidation loss: 3.305231\tBest loss: 3.305231\tAccuracy: 17.30%\n",
      "81\tValidation loss: 3.301009\tBest loss: 3.301009\tAccuracy: 17.10%\n",
      "82\tValidation loss: 3.288945\tBest loss: 3.288945\tAccuracy: 17.10%\n",
      "83\tValidation loss: 3.282102\tBest loss: 3.282102\tAccuracy: 17.60%\n",
      "84\tValidation loss: 3.276949\tBest loss: 3.276949\tAccuracy: 17.40%\n",
      "85\tValidation loss: 3.269772\tBest loss: 3.269772\tAccuracy: 17.70%\n",
      "86\tValidation loss: 3.255933\tBest loss: 3.255933\tAccuracy: 18.00%\n",
      "87\tValidation loss: 3.247579\tBest loss: 3.247579\tAccuracy: 18.10%\n",
      "88\tValidation loss: 3.245033\tBest loss: 3.245033\tAccuracy: 18.20%\n",
      "89\tValidation loss: 3.239071\tBest loss: 3.239071\tAccuracy: 17.90%\n",
      "90\tValidation loss: 3.223997\tBest loss: 3.223997\tAccuracy: 18.50%\n",
      "91\tValidation loss: 3.221170\tBest loss: 3.221170\tAccuracy: 18.70%\n",
      "92\tValidation loss: 3.211946\tBest loss: 3.211946\tAccuracy: 18.20%\n",
      "93\tValidation loss: 3.206976\tBest loss: 3.206976\tAccuracy: 18.40%\n",
      "94\tValidation loss: 3.200045\tBest loss: 3.200045\tAccuracy: 19.00%\n",
      "95\tValidation loss: 3.189867\tBest loss: 3.189867\tAccuracy: 19.20%\n",
      "96\tValidation loss: 3.179507\tBest loss: 3.179507\tAccuracy: 19.60%\n",
      "97\tValidation loss: 3.172101\tBest loss: 3.172101\tAccuracy: 19.50%\n",
      "98\tValidation loss: 3.162547\tBest loss: 3.162547\tAccuracy: 19.70%\n",
      "99\tValidation loss: 3.151643\tBest loss: 3.151643\tAccuracy: 19.70%\n",
      "100\tValidation loss: 3.148121\tBest loss: 3.148121\tAccuracy: 20.30%\n",
      "101\tValidation loss: 3.136154\tBest loss: 3.136154\tAccuracy: 20.80%\n",
      "102\tValidation loss: 3.125885\tBest loss: 3.125885\tAccuracy: 21.00%\n",
      "103\tValidation loss: 3.116273\tBest loss: 3.116273\tAccuracy: 21.10%\n",
      "104\tValidation loss: 3.102487\tBest loss: 3.102487\tAccuracy: 21.20%\n",
      "105\tValidation loss: 3.095037\tBest loss: 3.095037\tAccuracy: 21.70%\n",
      "106\tValidation loss: 3.081650\tBest loss: 3.081650\tAccuracy: 21.60%\n",
      "107\tValidation loss: 3.079350\tBest loss: 3.079350\tAccuracy: 21.40%\n",
      "108\tValidation loss: 3.067697\tBest loss: 3.067697\tAccuracy: 22.60%\n",
      "109\tValidation loss: 3.057957\tBest loss: 3.057957\tAccuracy: 22.00%\n",
      "110\tValidation loss: 3.045720\tBest loss: 3.045720\tAccuracy: 22.70%\n",
      "111\tValidation loss: 3.033904\tBest loss: 3.033904\tAccuracy: 23.10%\n",
      "112\tValidation loss: 3.025392\tBest loss: 3.025392\tAccuracy: 23.40%\n",
      "113\tValidation loss: 3.004618\tBest loss: 3.004618\tAccuracy: 24.40%\n",
      "114\tValidation loss: 2.998299\tBest loss: 2.998299\tAccuracy: 24.10%\n",
      "115\tValidation loss: 2.984336\tBest loss: 2.984336\tAccuracy: 24.10%\n",
      "116\tValidation loss: 2.978497\tBest loss: 2.978497\tAccuracy: 24.00%\n",
      "117\tValidation loss: 2.970941\tBest loss: 2.970941\tAccuracy: 24.90%\n",
      "118\tValidation loss: 2.959190\tBest loss: 2.959190\tAccuracy: 25.30%\n",
      "119\tValidation loss: 2.949676\tBest loss: 2.949676\tAccuracy: 24.80%\n",
      "120\tValidation loss: 2.935082\tBest loss: 2.935082\tAccuracy: 25.70%\n",
      "121\tValidation loss: 2.923500\tBest loss: 2.923500\tAccuracy: 25.40%\n",
      "122\tValidation loss: 2.921390\tBest loss: 2.921390\tAccuracy: 25.80%\n",
      "123\tValidation loss: 2.903916\tBest loss: 2.903916\tAccuracy: 26.40%\n",
      "124\tValidation loss: 2.897282\tBest loss: 2.897282\tAccuracy: 26.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 2.872461\tBest loss: 2.872461\tAccuracy: 26.80%\n",
      "126\tValidation loss: 2.871087\tBest loss: 2.871087\tAccuracy: 26.70%\n",
      "127\tValidation loss: 2.862269\tBest loss: 2.862269\tAccuracy: 27.10%\n",
      "128\tValidation loss: 2.846098\tBest loss: 2.846098\tAccuracy: 27.60%\n",
      "129\tValidation loss: 2.852078\tBest loss: 2.846098\tAccuracy: 26.70%\n",
      "130\tValidation loss: 2.831325\tBest loss: 2.831325\tAccuracy: 27.20%\n",
      "131\tValidation loss: 2.815493\tBest loss: 2.815493\tAccuracy: 27.90%\n",
      "132\tValidation loss: 2.804900\tBest loss: 2.804900\tAccuracy: 28.20%\n",
      "133\tValidation loss: 2.797428\tBest loss: 2.797428\tAccuracy: 28.80%\n",
      "134\tValidation loss: 2.781332\tBest loss: 2.781332\tAccuracy: 29.40%\n",
      "135\tValidation loss: 2.766963\tBest loss: 2.766963\tAccuracy: 30.20%\n",
      "136\tValidation loss: 2.747584\tBest loss: 2.747584\tAccuracy: 29.70%\n",
      "137\tValidation loss: 2.743916\tBest loss: 2.743916\tAccuracy: 28.60%\n",
      "138\tValidation loss: 2.728164\tBest loss: 2.728164\tAccuracy: 29.50%\n",
      "139\tValidation loss: 2.721351\tBest loss: 2.721351\tAccuracy: 29.40%\n",
      "140\tValidation loss: 2.706544\tBest loss: 2.706544\tAccuracy: 28.40%\n",
      "141\tValidation loss: 2.701443\tBest loss: 2.701443\tAccuracy: 29.70%\n",
      "142\tValidation loss: 2.684720\tBest loss: 2.684720\tAccuracy: 29.70%\n",
      "143\tValidation loss: 2.675563\tBest loss: 2.675563\tAccuracy: 30.40%\n",
      "144\tValidation loss: 2.665878\tBest loss: 2.665878\tAccuracy: 30.70%\n",
      "145\tValidation loss: 2.647350\tBest loss: 2.647350\tAccuracy: 31.20%\n",
      "146\tValidation loss: 2.647736\tBest loss: 2.647350\tAccuracy: 31.00%\n",
      "147\tValidation loss: 2.641490\tBest loss: 2.641490\tAccuracy: 31.10%\n",
      "148\tValidation loss: 2.625107\tBest loss: 2.625107\tAccuracy: 31.40%\n",
      "149\tValidation loss: 2.609014\tBest loss: 2.609014\tAccuracy: 31.80%\n",
      "150\tValidation loss: 2.610939\tBest loss: 2.609014\tAccuracy: 31.70%\n",
      "151\tValidation loss: 2.601076\tBest loss: 2.601076\tAccuracy: 32.40%\n",
      "152\tValidation loss: 2.597784\tBest loss: 2.597784\tAccuracy: 31.50%\n",
      "153\tValidation loss: 2.590507\tBest loss: 2.590507\tAccuracy: 31.70%\n",
      "154\tValidation loss: 2.576833\tBest loss: 2.576833\tAccuracy: 32.10%\n",
      "155\tValidation loss: 2.575068\tBest loss: 2.575068\tAccuracy: 32.10%\n",
      "156\tValidation loss: 2.557444\tBest loss: 2.557444\tAccuracy: 33.00%\n",
      "157\tValidation loss: 2.546321\tBest loss: 2.546321\tAccuracy: 33.10%\n",
      "158\tValidation loss: 2.541919\tBest loss: 2.541919\tAccuracy: 33.20%\n",
      "159\tValidation loss: 2.526968\tBest loss: 2.526968\tAccuracy: 34.20%\n",
      "160\tValidation loss: 2.519636\tBest loss: 2.519636\tAccuracy: 33.50%\n",
      "161\tValidation loss: 2.507598\tBest loss: 2.507598\tAccuracy: 34.70%\n",
      "162\tValidation loss: 2.500299\tBest loss: 2.500299\tAccuracy: 35.10%\n",
      "163\tValidation loss: 2.492912\tBest loss: 2.492912\tAccuracy: 35.20%\n",
      "164\tValidation loss: 2.483039\tBest loss: 2.483039\tAccuracy: 34.60%\n",
      "165\tValidation loss: 2.477899\tBest loss: 2.477899\tAccuracy: 35.70%\n",
      "166\tValidation loss: 2.467771\tBest loss: 2.467771\tAccuracy: 35.80%\n",
      "167\tValidation loss: 2.462480\tBest loss: 2.462480\tAccuracy: 36.40%\n",
      "168\tValidation loss: 2.453842\tBest loss: 2.453842\tAccuracy: 37.10%\n",
      "169\tValidation loss: 2.446525\tBest loss: 2.446525\tAccuracy: 37.00%\n",
      "170\tValidation loss: 2.441353\tBest loss: 2.441353\tAccuracy: 37.30%\n",
      "171\tValidation loss: 2.429801\tBest loss: 2.429801\tAccuracy: 38.10%\n",
      "172\tValidation loss: 2.417898\tBest loss: 2.417898\tAccuracy: 37.30%\n",
      "173\tValidation loss: 2.407465\tBest loss: 2.407465\tAccuracy: 37.10%\n",
      "174\tValidation loss: 2.402210\tBest loss: 2.402210\tAccuracy: 37.50%\n",
      "175\tValidation loss: 2.387396\tBest loss: 2.387396\tAccuracy: 37.90%\n",
      "176\tValidation loss: 2.380266\tBest loss: 2.380266\tAccuracy: 37.50%\n",
      "177\tValidation loss: 2.367690\tBest loss: 2.367690\tAccuracy: 38.80%\n",
      "178\tValidation loss: 2.357075\tBest loss: 2.357075\tAccuracy: 39.40%\n",
      "179\tValidation loss: 2.353165\tBest loss: 2.353165\tAccuracy: 38.90%\n",
      "180\tValidation loss: 2.338471\tBest loss: 2.338471\tAccuracy: 39.60%\n",
      "181\tValidation loss: 2.330149\tBest loss: 2.330149\tAccuracy: 40.20%\n",
      "182\tValidation loss: 2.339229\tBest loss: 2.330149\tAccuracy: 39.60%\n",
      "183\tValidation loss: 2.321715\tBest loss: 2.321715\tAccuracy: 39.90%\n",
      "184\tValidation loss: 2.308573\tBest loss: 2.308573\tAccuracy: 40.20%\n",
      "185\tValidation loss: 2.304262\tBest loss: 2.304262\tAccuracy: 40.70%\n",
      "186\tValidation loss: 2.296235\tBest loss: 2.296235\tAccuracy: 40.90%\n",
      "187\tValidation loss: 2.292828\tBest loss: 2.292828\tAccuracy: 40.50%\n",
      "188\tValidation loss: 2.288722\tBest loss: 2.288722\tAccuracy: 40.40%\n",
      "189\tValidation loss: 2.282660\tBest loss: 2.282660\tAccuracy: 40.50%\n",
      "190\tValidation loss: 2.274226\tBest loss: 2.274226\tAccuracy: 41.20%\n",
      "191\tValidation loss: 2.263252\tBest loss: 2.263252\tAccuracy: 41.80%\n",
      "192\tValidation loss: 2.256079\tBest loss: 2.256079\tAccuracy: 41.10%\n",
      "193\tValidation loss: 2.262126\tBest loss: 2.256079\tAccuracy: 42.30%\n",
      "194\tValidation loss: 2.247689\tBest loss: 2.247689\tAccuracy: 42.50%\n",
      "195\tValidation loss: 2.250793\tBest loss: 2.247689\tAccuracy: 41.70%\n",
      "196\tValidation loss: 2.241631\tBest loss: 2.241631\tAccuracy: 42.80%\n",
      "197\tValidation loss: 2.238585\tBest loss: 2.238585\tAccuracy: 42.30%\n",
      "198\tValidation loss: 2.237210\tBest loss: 2.237210\tAccuracy: 42.20%\n",
      "199\tValidation loss: 2.221455\tBest loss: 2.221455\tAccuracy: 43.20%\n",
      "200\tValidation loss: 2.222176\tBest loss: 2.221455\tAccuracy: 43.30%\n",
      "201\tValidation loss: 2.207421\tBest loss: 2.207421\tAccuracy: 44.50%\n",
      "202\tValidation loss: 2.199311\tBest loss: 2.199311\tAccuracy: 44.00%\n",
      "203\tValidation loss: 2.194414\tBest loss: 2.194414\tAccuracy: 43.90%\n",
      "204\tValidation loss: 2.197978\tBest loss: 2.194414\tAccuracy: 43.90%\n",
      "205\tValidation loss: 2.186891\tBest loss: 2.186891\tAccuracy: 44.70%\n",
      "206\tValidation loss: 2.185175\tBest loss: 2.185175\tAccuracy: 45.00%\n",
      "207\tValidation loss: 2.182869\tBest loss: 2.182869\tAccuracy: 44.90%\n",
      "208\tValidation loss: 2.182048\tBest loss: 2.182048\tAccuracy: 44.60%\n",
      "209\tValidation loss: 2.171528\tBest loss: 2.171528\tAccuracy: 45.30%\n",
      "210\tValidation loss: 2.174586\tBest loss: 2.171528\tAccuracy: 44.90%\n",
      "211\tValidation loss: 2.171115\tBest loss: 2.171115\tAccuracy: 44.50%\n",
      "212\tValidation loss: 2.170555\tBest loss: 2.170555\tAccuracy: 44.70%\n",
      "213\tValidation loss: 2.157123\tBest loss: 2.157123\tAccuracy: 45.20%\n",
      "214\tValidation loss: 2.147015\tBest loss: 2.147015\tAccuracy: 45.40%\n",
      "215\tValidation loss: 2.143039\tBest loss: 2.143039\tAccuracy: 46.40%\n",
      "216\tValidation loss: 2.139822\tBest loss: 2.139822\tAccuracy: 46.20%\n",
      "217\tValidation loss: 2.134145\tBest loss: 2.134145\tAccuracy: 46.30%\n",
      "218\tValidation loss: 2.139359\tBest loss: 2.134145\tAccuracy: 46.30%\n",
      "219\tValidation loss: 2.130556\tBest loss: 2.130556\tAccuracy: 46.80%\n",
      "220\tValidation loss: 2.127517\tBest loss: 2.127517\tAccuracy: 46.10%\n",
      "221\tValidation loss: 2.123217\tBest loss: 2.123217\tAccuracy: 46.10%\n",
      "222\tValidation loss: 2.125451\tBest loss: 2.123217\tAccuracy: 46.30%\n",
      "223\tValidation loss: 2.114252\tBest loss: 2.114252\tAccuracy: 46.70%\n",
      "224\tValidation loss: 2.110086\tBest loss: 2.110086\tAccuracy: 47.40%\n",
      "225\tValidation loss: 2.104458\tBest loss: 2.104458\tAccuracy: 46.10%\n",
      "226\tValidation loss: 2.103162\tBest loss: 2.103162\tAccuracy: 46.10%\n",
      "227\tValidation loss: 2.095209\tBest loss: 2.095209\tAccuracy: 46.70%\n",
      "228\tValidation loss: 2.095927\tBest loss: 2.095209\tAccuracy: 46.60%\n",
      "229\tValidation loss: 2.099262\tBest loss: 2.095209\tAccuracy: 46.90%\n",
      "230\tValidation loss: 2.093925\tBest loss: 2.093925\tAccuracy: 47.60%\n",
      "231\tValidation loss: 2.096157\tBest loss: 2.093925\tAccuracy: 47.60%\n",
      "232\tValidation loss: 2.091595\tBest loss: 2.091595\tAccuracy: 47.50%\n",
      "233\tValidation loss: 2.080931\tBest loss: 2.080931\tAccuracy: 48.00%\n",
      "234\tValidation loss: 2.085773\tBest loss: 2.080931\tAccuracy: 47.40%\n",
      "235\tValidation loss: 2.076875\tBest loss: 2.076875\tAccuracy: 47.40%\n",
      "236\tValidation loss: 2.071954\tBest loss: 2.071954\tAccuracy: 47.60%\n",
      "237\tValidation loss: 2.067718\tBest loss: 2.067718\tAccuracy: 47.70%\n",
      "238\tValidation loss: 2.073594\tBest loss: 2.067718\tAccuracy: 47.80%\n",
      "239\tValidation loss: 2.072708\tBest loss: 2.067718\tAccuracy: 47.80%\n",
      "240\tValidation loss: 2.073925\tBest loss: 2.067718\tAccuracy: 47.10%\n",
      "241\tValidation loss: 2.064121\tBest loss: 2.064121\tAccuracy: 48.70%\n",
      "242\tValidation loss: 2.059493\tBest loss: 2.059493\tAccuracy: 48.30%\n",
      "243\tValidation loss: 2.058281\tBest loss: 2.058281\tAccuracy: 48.10%\n",
      "244\tValidation loss: 2.051956\tBest loss: 2.051956\tAccuracy: 48.90%\n",
      "245\tValidation loss: 2.045821\tBest loss: 2.045821\tAccuracy: 48.80%\n",
      "246\tValidation loss: 2.050979\tBest loss: 2.045821\tAccuracy: 48.60%\n",
      "247\tValidation loss: 2.046053\tBest loss: 2.045821\tAccuracy: 48.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 2.039862\tBest loss: 2.039862\tAccuracy: 48.60%\n",
      "249\tValidation loss: 2.038362\tBest loss: 2.038362\tAccuracy: 48.50%\n",
      "250\tValidation loss: 2.036057\tBest loss: 2.036057\tAccuracy: 48.20%\n",
      "251\tValidation loss: 2.031571\tBest loss: 2.031571\tAccuracy: 48.50%\n",
      "252\tValidation loss: 2.032480\tBest loss: 2.031571\tAccuracy: 49.00%\n",
      "253\tValidation loss: 2.028400\tBest loss: 2.028400\tAccuracy: 50.00%\n",
      "254\tValidation loss: 2.023946\tBest loss: 2.023946\tAccuracy: 49.60%\n",
      "255\tValidation loss: 2.025885\tBest loss: 2.023946\tAccuracy: 48.60%\n",
      "256\tValidation loss: 2.022007\tBest loss: 2.022007\tAccuracy: 48.70%\n",
      "257\tValidation loss: 2.019526\tBest loss: 2.019526\tAccuracy: 48.60%\n",
      "258\tValidation loss: 2.019069\tBest loss: 2.019069\tAccuracy: 48.60%\n",
      "259\tValidation loss: 2.021404\tBest loss: 2.019069\tAccuracy: 48.90%\n",
      "260\tValidation loss: 2.013808\tBest loss: 2.013808\tAccuracy: 48.60%\n",
      "261\tValidation loss: 2.006999\tBest loss: 2.006999\tAccuracy: 49.10%\n",
      "262\tValidation loss: 2.003441\tBest loss: 2.003441\tAccuracy: 49.60%\n",
      "263\tValidation loss: 2.007905\tBest loss: 2.003441\tAccuracy: 49.00%\n",
      "264\tValidation loss: 2.000226\tBest loss: 2.000226\tAccuracy: 48.70%\n",
      "265\tValidation loss: 2.000944\tBest loss: 2.000226\tAccuracy: 49.20%\n",
      "266\tValidation loss: 1.995236\tBest loss: 1.995236\tAccuracy: 48.70%\n",
      "267\tValidation loss: 1.995296\tBest loss: 1.995236\tAccuracy: 49.50%\n",
      "268\tValidation loss: 1.993138\tBest loss: 1.993138\tAccuracy: 49.60%\n",
      "269\tValidation loss: 1.990807\tBest loss: 1.990807\tAccuracy: 49.90%\n",
      "270\tValidation loss: 1.989299\tBest loss: 1.989299\tAccuracy: 49.20%\n",
      "271\tValidation loss: 1.987018\tBest loss: 1.987018\tAccuracy: 50.00%\n",
      "272\tValidation loss: 1.989722\tBest loss: 1.987018\tAccuracy: 49.40%\n",
      "273\tValidation loss: 1.981886\tBest loss: 1.981886\tAccuracy: 50.10%\n",
      "274\tValidation loss: 1.981238\tBest loss: 1.981238\tAccuracy: 50.40%\n",
      "275\tValidation loss: 1.974119\tBest loss: 1.974119\tAccuracy: 50.40%\n",
      "276\tValidation loss: 1.970998\tBest loss: 1.970998\tAccuracy: 50.60%\n",
      "277\tValidation loss: 1.970954\tBest loss: 1.970954\tAccuracy: 50.10%\n",
      "278\tValidation loss: 1.969751\tBest loss: 1.969751\tAccuracy: 50.30%\n",
      "279\tValidation loss: 1.967021\tBest loss: 1.967021\tAccuracy: 50.20%\n",
      "280\tValidation loss: 1.965297\tBest loss: 1.965297\tAccuracy: 50.40%\n",
      "281\tValidation loss: 1.961469\tBest loss: 1.961469\tAccuracy: 50.90%\n",
      "282\tValidation loss: 1.960624\tBest loss: 1.960624\tAccuracy: 50.60%\n",
      "283\tValidation loss: 1.957278\tBest loss: 1.957278\tAccuracy: 50.90%\n",
      "284\tValidation loss: 1.957299\tBest loss: 1.957278\tAccuracy: 50.40%\n",
      "285\tValidation loss: 1.957998\tBest loss: 1.957278\tAccuracy: 51.00%\n",
      "286\tValidation loss: 1.954639\tBest loss: 1.954639\tAccuracy: 50.90%\n",
      "287\tValidation loss: 1.952390\tBest loss: 1.952390\tAccuracy: 51.80%\n",
      "288\tValidation loss: 1.948524\tBest loss: 1.948524\tAccuracy: 51.40%\n",
      "289\tValidation loss: 1.946482\tBest loss: 1.946482\tAccuracy: 51.20%\n",
      "290\tValidation loss: 1.949269\tBest loss: 1.946482\tAccuracy: 50.60%\n",
      "291\tValidation loss: 1.947255\tBest loss: 1.946482\tAccuracy: 51.20%\n",
      "292\tValidation loss: 1.943198\tBest loss: 1.943198\tAccuracy: 50.90%\n",
      "293\tValidation loss: 1.950988\tBest loss: 1.943198\tAccuracy: 50.40%\n",
      "294\tValidation loss: 1.945926\tBest loss: 1.943198\tAccuracy: 51.40%\n",
      "295\tValidation loss: 1.942320\tBest loss: 1.942320\tAccuracy: 51.30%\n",
      "296\tValidation loss: 1.945079\tBest loss: 1.942320\tAccuracy: 50.90%\n",
      "297\tValidation loss: 1.940192\tBest loss: 1.940192\tAccuracy: 50.70%\n",
      "298\tValidation loss: 1.935901\tBest loss: 1.935901\tAccuracy: 51.50%\n",
      "299\tValidation loss: 1.931579\tBest loss: 1.931579\tAccuracy: 51.10%\n",
      "300\tValidation loss: 1.930635\tBest loss: 1.930635\tAccuracy: 51.40%\n",
      "301\tValidation loss: 1.927137\tBest loss: 1.927137\tAccuracy: 51.50%\n",
      "302\tValidation loss: 1.922551\tBest loss: 1.922551\tAccuracy: 51.70%\n",
      "303\tValidation loss: 1.925765\tBest loss: 1.922551\tAccuracy: 51.90%\n",
      "304\tValidation loss: 1.928182\tBest loss: 1.922551\tAccuracy: 52.10%\n",
      "305\tValidation loss: 1.929088\tBest loss: 1.922551\tAccuracy: 51.70%\n",
      "306\tValidation loss: 1.924110\tBest loss: 1.922551\tAccuracy: 51.70%\n",
      "307\tValidation loss: 1.921400\tBest loss: 1.921400\tAccuracy: 51.80%\n",
      "308\tValidation loss: 1.918590\tBest loss: 1.918590\tAccuracy: 51.60%\n",
      "309\tValidation loss: 1.921800\tBest loss: 1.918590\tAccuracy: 51.50%\n",
      "310\tValidation loss: 1.920223\tBest loss: 1.918590\tAccuracy: 51.00%\n",
      "311\tValidation loss: 1.922040\tBest loss: 1.918590\tAccuracy: 51.40%\n",
      "312\tValidation loss: 1.919046\tBest loss: 1.918590\tAccuracy: 51.50%\n",
      "313\tValidation loss: 1.917066\tBest loss: 1.917066\tAccuracy: 51.40%\n",
      "314\tValidation loss: 1.912926\tBest loss: 1.912926\tAccuracy: 52.40%\n",
      "315\tValidation loss: 1.912503\tBest loss: 1.912503\tAccuracy: 51.80%\n",
      "316\tValidation loss: 1.911027\tBest loss: 1.911027\tAccuracy: 51.70%\n",
      "317\tValidation loss: 1.907508\tBest loss: 1.907508\tAccuracy: 51.70%\n",
      "318\tValidation loss: 1.911926\tBest loss: 1.907508\tAccuracy: 51.70%\n",
      "319\tValidation loss: 1.906577\tBest loss: 1.906577\tAccuracy: 51.60%\n",
      "320\tValidation loss: 1.906451\tBest loss: 1.906451\tAccuracy: 52.20%\n",
      "321\tValidation loss: 1.905086\tBest loss: 1.905086\tAccuracy: 52.10%\n",
      "322\tValidation loss: 1.903063\tBest loss: 1.903063\tAccuracy: 51.80%\n",
      "323\tValidation loss: 1.900144\tBest loss: 1.900144\tAccuracy: 52.10%\n",
      "324\tValidation loss: 1.897652\tBest loss: 1.897652\tAccuracy: 52.20%\n",
      "325\tValidation loss: 1.897335\tBest loss: 1.897335\tAccuracy: 52.30%\n",
      "326\tValidation loss: 1.898639\tBest loss: 1.897335\tAccuracy: 52.20%\n",
      "327\tValidation loss: 1.898840\tBest loss: 1.897335\tAccuracy: 52.10%\n",
      "328\tValidation loss: 1.897230\tBest loss: 1.897230\tAccuracy: 51.90%\n",
      "329\tValidation loss: 1.892375\tBest loss: 1.892375\tAccuracy: 52.10%\n",
      "330\tValidation loss: 1.897434\tBest loss: 1.892375\tAccuracy: 52.00%\n",
      "331\tValidation loss: 1.892140\tBest loss: 1.892140\tAccuracy: 52.80%\n",
      "332\tValidation loss: 1.895623\tBest loss: 1.892140\tAccuracy: 52.70%\n",
      "333\tValidation loss: 1.886577\tBest loss: 1.886577\tAccuracy: 52.60%\n",
      "334\tValidation loss: 1.887934\tBest loss: 1.886577\tAccuracy: 52.50%\n",
      "335\tValidation loss: 1.883417\tBest loss: 1.883417\tAccuracy: 53.00%\n",
      "336\tValidation loss: 1.877457\tBest loss: 1.877457\tAccuracy: 51.90%\n",
      "337\tValidation loss: 1.880250\tBest loss: 1.877457\tAccuracy: 52.00%\n",
      "338\tValidation loss: 1.883654\tBest loss: 1.877457\tAccuracy: 52.00%\n",
      "339\tValidation loss: 1.879111\tBest loss: 1.877457\tAccuracy: 52.00%\n",
      "340\tValidation loss: 1.882511\tBest loss: 1.877457\tAccuracy: 51.70%\n",
      "341\tValidation loss: 1.879311\tBest loss: 1.877457\tAccuracy: 51.90%\n",
      "342\tValidation loss: 1.878591\tBest loss: 1.877457\tAccuracy: 52.10%\n",
      "343\tValidation loss: 1.876833\tBest loss: 1.876833\tAccuracy: 51.80%\n",
      "344\tValidation loss: 1.872495\tBest loss: 1.872495\tAccuracy: 52.60%\n",
      "345\tValidation loss: 1.869448\tBest loss: 1.869448\tAccuracy: 53.00%\n",
      "346\tValidation loss: 1.871704\tBest loss: 1.869448\tAccuracy: 51.70%\n",
      "347\tValidation loss: 1.866363\tBest loss: 1.866363\tAccuracy: 52.10%\n",
      "348\tValidation loss: 1.865169\tBest loss: 1.865169\tAccuracy: 52.40%\n",
      "349\tValidation loss: 1.868086\tBest loss: 1.865169\tAccuracy: 52.70%\n",
      "350\tValidation loss: 1.866631\tBest loss: 1.865169\tAccuracy: 52.80%\n",
      "351\tValidation loss: 1.862130\tBest loss: 1.862130\tAccuracy: 52.50%\n",
      "352\tValidation loss: 1.864679\tBest loss: 1.862130\tAccuracy: 52.60%\n",
      "353\tValidation loss: 1.864840\tBest loss: 1.862130\tAccuracy: 53.20%\n",
      "354\tValidation loss: 1.865767\tBest loss: 1.862130\tAccuracy: 52.30%\n",
      "355\tValidation loss: 1.860611\tBest loss: 1.860611\tAccuracy: 52.50%\n",
      "356\tValidation loss: 1.860881\tBest loss: 1.860611\tAccuracy: 53.20%\n",
      "357\tValidation loss: 1.858992\tBest loss: 1.858992\tAccuracy: 53.70%\n",
      "358\tValidation loss: 1.858669\tBest loss: 1.858669\tAccuracy: 52.70%\n",
      "359\tValidation loss: 1.855728\tBest loss: 1.855728\tAccuracy: 52.80%\n",
      "360\tValidation loss: 1.858053\tBest loss: 1.855728\tAccuracy: 53.00%\n",
      "361\tValidation loss: 1.856590\tBest loss: 1.855728\tAccuracy: 52.50%\n",
      "362\tValidation loss: 1.855973\tBest loss: 1.855728\tAccuracy: 52.60%\n",
      "363\tValidation loss: 1.851600\tBest loss: 1.851600\tAccuracy: 53.10%\n",
      "364\tValidation loss: 1.852602\tBest loss: 1.851600\tAccuracy: 52.90%\n",
      "365\tValidation loss: 1.851098\tBest loss: 1.851098\tAccuracy: 53.10%\n",
      "366\tValidation loss: 1.849637\tBest loss: 1.849637\tAccuracy: 52.80%\n",
      "367\tValidation loss: 1.853587\tBest loss: 1.849637\tAccuracy: 52.60%\n",
      "368\tValidation loss: 1.849668\tBest loss: 1.849637\tAccuracy: 52.10%\n",
      "369\tValidation loss: 1.846093\tBest loss: 1.846093\tAccuracy: 53.40%\n",
      "370\tValidation loss: 1.845939\tBest loss: 1.845939\tAccuracy: 52.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\tValidation loss: 1.843625\tBest loss: 1.843625\tAccuracy: 53.30%\n",
      "372\tValidation loss: 1.847522\tBest loss: 1.843625\tAccuracy: 53.20%\n",
      "373\tValidation loss: 1.845780\tBest loss: 1.843625\tAccuracy: 53.30%\n",
      "374\tValidation loss: 1.842056\tBest loss: 1.842056\tAccuracy: 53.00%\n",
      "375\tValidation loss: 1.844023\tBest loss: 1.842056\tAccuracy: 53.10%\n",
      "376\tValidation loss: 1.839847\tBest loss: 1.839847\tAccuracy: 53.10%\n",
      "377\tValidation loss: 1.841179\tBest loss: 1.839847\tAccuracy: 53.30%\n",
      "378\tValidation loss: 1.839892\tBest loss: 1.839847\tAccuracy: 52.90%\n",
      "379\tValidation loss: 1.843727\tBest loss: 1.839847\tAccuracy: 53.90%\n",
      "380\tValidation loss: 1.837868\tBest loss: 1.837868\tAccuracy: 53.60%\n",
      "381\tValidation loss: 1.836758\tBest loss: 1.836758\tAccuracy: 53.10%\n",
      "382\tValidation loss: 1.840667\tBest loss: 1.836758\tAccuracy: 53.00%\n",
      "383\tValidation loss: 1.834331\tBest loss: 1.834331\tAccuracy: 53.20%\n",
      "384\tValidation loss: 1.835831\tBest loss: 1.834331\tAccuracy: 54.00%\n",
      "385\tValidation loss: 1.835049\tBest loss: 1.834331\tAccuracy: 53.60%\n",
      "386\tValidation loss: 1.835044\tBest loss: 1.834331\tAccuracy: 53.90%\n",
      "387\tValidation loss: 1.830174\tBest loss: 1.830174\tAccuracy: 53.70%\n",
      "388\tValidation loss: 1.831835\tBest loss: 1.830174\tAccuracy: 53.80%\n",
      "389\tValidation loss: 1.834128\tBest loss: 1.830174\tAccuracy: 53.80%\n",
      "390\tValidation loss: 1.831242\tBest loss: 1.830174\tAccuracy: 53.70%\n",
      "391\tValidation loss: 1.828229\tBest loss: 1.828229\tAccuracy: 53.80%\n",
      "392\tValidation loss: 1.826524\tBest loss: 1.826524\tAccuracy: 53.90%\n",
      "393\tValidation loss: 1.827939\tBest loss: 1.826524\tAccuracy: 53.30%\n",
      "394\tValidation loss: 1.824953\tBest loss: 1.824953\tAccuracy: 53.40%\n",
      "395\tValidation loss: 1.825485\tBest loss: 1.824953\tAccuracy: 53.60%\n",
      "396\tValidation loss: 1.825074\tBest loss: 1.824953\tAccuracy: 53.80%\n",
      "397\tValidation loss: 1.822421\tBest loss: 1.822421\tAccuracy: 53.10%\n",
      "398\tValidation loss: 1.824738\tBest loss: 1.822421\tAccuracy: 53.70%\n",
      "399\tValidation loss: 1.822555\tBest loss: 1.822421\tAccuracy: 53.70%\n",
      "400\tValidation loss: 1.819383\tBest loss: 1.819383\tAccuracy: 54.00%\n",
      "401\tValidation loss: 1.817245\tBest loss: 1.817245\tAccuracy: 53.30%\n",
      "402\tValidation loss: 1.819631\tBest loss: 1.817245\tAccuracy: 54.00%\n",
      "403\tValidation loss: 1.819362\tBest loss: 1.817245\tAccuracy: 54.40%\n",
      "404\tValidation loss: 1.821366\tBest loss: 1.817245\tAccuracy: 54.60%\n",
      "405\tValidation loss: 1.815859\tBest loss: 1.815859\tAccuracy: 54.80%\n",
      "406\tValidation loss: 1.813342\tBest loss: 1.813342\tAccuracy: 54.30%\n",
      "407\tValidation loss: 1.813957\tBest loss: 1.813342\tAccuracy: 54.40%\n",
      "408\tValidation loss: 1.814992\tBest loss: 1.813342\tAccuracy: 53.90%\n",
      "409\tValidation loss: 1.815618\tBest loss: 1.813342\tAccuracy: 54.40%\n",
      "410\tValidation loss: 1.812669\tBest loss: 1.812669\tAccuracy: 54.30%\n",
      "411\tValidation loss: 1.816277\tBest loss: 1.812669\tAccuracy: 54.30%\n",
      "412\tValidation loss: 1.814122\tBest loss: 1.812669\tAccuracy: 54.00%\n",
      "413\tValidation loss: 1.809743\tBest loss: 1.809743\tAccuracy: 54.90%\n",
      "414\tValidation loss: 1.812888\tBest loss: 1.809743\tAccuracy: 54.40%\n",
      "415\tValidation loss: 1.807888\tBest loss: 1.807888\tAccuracy: 55.00%\n",
      "416\tValidation loss: 1.810812\tBest loss: 1.807888\tAccuracy: 54.50%\n",
      "417\tValidation loss: 1.808658\tBest loss: 1.807888\tAccuracy: 54.30%\n",
      "418\tValidation loss: 1.807657\tBest loss: 1.807657\tAccuracy: 54.40%\n",
      "419\tValidation loss: 1.807362\tBest loss: 1.807362\tAccuracy: 55.20%\n",
      "420\tValidation loss: 1.806949\tBest loss: 1.806949\tAccuracy: 53.80%\n",
      "421\tValidation loss: 1.802761\tBest loss: 1.802761\tAccuracy: 54.20%\n",
      "422\tValidation loss: 1.802370\tBest loss: 1.802370\tAccuracy: 53.70%\n",
      "423\tValidation loss: 1.800578\tBest loss: 1.800578\tAccuracy: 54.30%\n",
      "424\tValidation loss: 1.801650\tBest loss: 1.800578\tAccuracy: 54.40%\n",
      "425\tValidation loss: 1.805377\tBest loss: 1.800578\tAccuracy: 54.00%\n",
      "426\tValidation loss: 1.799975\tBest loss: 1.799975\tAccuracy: 54.80%\n",
      "427\tValidation loss: 1.800931\tBest loss: 1.799975\tAccuracy: 55.30%\n",
      "428\tValidation loss: 1.797999\tBest loss: 1.797999\tAccuracy: 54.40%\n",
      "429\tValidation loss: 1.796775\tBest loss: 1.796775\tAccuracy: 54.20%\n",
      "430\tValidation loss: 1.795812\tBest loss: 1.795812\tAccuracy: 54.30%\n",
      "431\tValidation loss: 1.796209\tBest loss: 1.795812\tAccuracy: 55.00%\n",
      "432\tValidation loss: 1.788721\tBest loss: 1.788721\tAccuracy: 54.80%\n",
      "433\tValidation loss: 1.792606\tBest loss: 1.788721\tAccuracy: 54.30%\n",
      "434\tValidation loss: 1.791580\tBest loss: 1.788721\tAccuracy: 55.30%\n",
      "435\tValidation loss: 1.792148\tBest loss: 1.788721\tAccuracy: 55.00%\n",
      "436\tValidation loss: 1.792228\tBest loss: 1.788721\tAccuracy: 54.70%\n",
      "437\tValidation loss: 1.791360\tBest loss: 1.788721\tAccuracy: 54.80%\n",
      "438\tValidation loss: 1.792394\tBest loss: 1.788721\tAccuracy: 54.60%\n",
      "439\tValidation loss: 1.790583\tBest loss: 1.788721\tAccuracy: 54.40%\n",
      "440\tValidation loss: 1.790097\tBest loss: 1.788721\tAccuracy: 54.30%\n",
      "441\tValidation loss: 1.792590\tBest loss: 1.788721\tAccuracy: 53.70%\n",
      "442\tValidation loss: 1.791074\tBest loss: 1.788721\tAccuracy: 54.40%\n",
      "443\tValidation loss: 1.790134\tBest loss: 1.788721\tAccuracy: 54.20%\n",
      "444\tValidation loss: 1.789272\tBest loss: 1.788721\tAccuracy: 54.10%\n",
      "445\tValidation loss: 1.787045\tBest loss: 1.787045\tAccuracy: 54.90%\n",
      "446\tValidation loss: 1.789068\tBest loss: 1.787045\tAccuracy: 54.60%\n",
      "447\tValidation loss: 1.789953\tBest loss: 1.787045\tAccuracy: 54.90%\n",
      "448\tValidation loss: 1.788065\tBest loss: 1.787045\tAccuracy: 54.80%\n",
      "449\tValidation loss: 1.787437\tBest loss: 1.787045\tAccuracy: 54.50%\n",
      "450\tValidation loss: 1.786925\tBest loss: 1.786925\tAccuracy: 54.90%\n",
      "451\tValidation loss: 1.787664\tBest loss: 1.786925\tAccuracy: 54.70%\n",
      "452\tValidation loss: 1.783126\tBest loss: 1.783126\tAccuracy: 55.10%\n",
      "453\tValidation loss: 1.785376\tBest loss: 1.783126\tAccuracy: 54.90%\n",
      "454\tValidation loss: 1.783330\tBest loss: 1.783126\tAccuracy: 55.20%\n",
      "455\tValidation loss: 1.780012\tBest loss: 1.780012\tAccuracy: 55.10%\n",
      "456\tValidation loss: 1.780106\tBest loss: 1.780012\tAccuracy: 55.40%\n",
      "457\tValidation loss: 1.779429\tBest loss: 1.779429\tAccuracy: 55.20%\n",
      "458\tValidation loss: 1.778665\tBest loss: 1.778665\tAccuracy: 55.40%\n",
      "459\tValidation loss: 1.774012\tBest loss: 1.774012\tAccuracy: 55.30%\n",
      "460\tValidation loss: 1.776130\tBest loss: 1.774012\tAccuracy: 54.90%\n",
      "461\tValidation loss: 1.777468\tBest loss: 1.774012\tAccuracy: 55.20%\n",
      "462\tValidation loss: 1.775120\tBest loss: 1.774012\tAccuracy: 55.20%\n",
      "463\tValidation loss: 1.772175\tBest loss: 1.772175\tAccuracy: 55.10%\n",
      "464\tValidation loss: 1.772510\tBest loss: 1.772175\tAccuracy: 54.00%\n",
      "465\tValidation loss: 1.771408\tBest loss: 1.771408\tAccuracy: 55.70%\n",
      "466\tValidation loss: 1.773073\tBest loss: 1.771408\tAccuracy: 55.40%\n",
      "467\tValidation loss: 1.772428\tBest loss: 1.771408\tAccuracy: 55.50%\n",
      "468\tValidation loss: 1.774549\tBest loss: 1.771408\tAccuracy: 54.70%\n",
      "469\tValidation loss: 1.773058\tBest loss: 1.771408\tAccuracy: 55.10%\n",
      "470\tValidation loss: 1.776974\tBest loss: 1.771408\tAccuracy: 54.40%\n",
      "471\tValidation loss: 1.773464\tBest loss: 1.771408\tAccuracy: 54.60%\n",
      "472\tValidation loss: 1.770994\tBest loss: 1.770994\tAccuracy: 55.30%\n",
      "473\tValidation loss: 1.767985\tBest loss: 1.767985\tAccuracy: 55.20%\n",
      "474\tValidation loss: 1.769121\tBest loss: 1.767985\tAccuracy: 55.50%\n",
      "475\tValidation loss: 1.765487\tBest loss: 1.765487\tAccuracy: 55.80%\n",
      "476\tValidation loss: 1.767929\tBest loss: 1.765487\tAccuracy: 55.70%\n",
      "477\tValidation loss: 1.765398\tBest loss: 1.765398\tAccuracy: 55.20%\n",
      "478\tValidation loss: 1.765876\tBest loss: 1.765398\tAccuracy: 55.10%\n",
      "479\tValidation loss: 1.766148\tBest loss: 1.765398\tAccuracy: 55.00%\n",
      "480\tValidation loss: 1.761840\tBest loss: 1.761840\tAccuracy: 56.30%\n",
      "481\tValidation loss: 1.761692\tBest loss: 1.761692\tAccuracy: 55.80%\n",
      "482\tValidation loss: 1.763301\tBest loss: 1.761692\tAccuracy: 55.70%\n",
      "483\tValidation loss: 1.764941\tBest loss: 1.761692\tAccuracy: 55.40%\n",
      "484\tValidation loss: 1.760893\tBest loss: 1.760893\tAccuracy: 55.50%\n",
      "485\tValidation loss: 1.759202\tBest loss: 1.759202\tAccuracy: 55.90%\n",
      "486\tValidation loss: 1.762936\tBest loss: 1.759202\tAccuracy: 55.50%\n",
      "487\tValidation loss: 1.764110\tBest loss: 1.759202\tAccuracy: 56.10%\n",
      "488\tValidation loss: 1.761839\tBest loss: 1.759202\tAccuracy: 55.90%\n",
      "489\tValidation loss: 1.761530\tBest loss: 1.759202\tAccuracy: 56.00%\n",
      "490\tValidation loss: 1.759621\tBest loss: 1.759202\tAccuracy: 56.20%\n",
      "491\tValidation loss: 1.756816\tBest loss: 1.756816\tAccuracy: 55.80%\n",
      "492\tValidation loss: 1.756443\tBest loss: 1.756443\tAccuracy: 55.20%\n",
      "493\tValidation loss: 1.755949\tBest loss: 1.755949\tAccuracy: 55.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\tValidation loss: 1.755756\tBest loss: 1.755756\tAccuracy: 55.80%\n",
      "495\tValidation loss: 1.752939\tBest loss: 1.752939\tAccuracy: 55.30%\n",
      "496\tValidation loss: 1.753537\tBest loss: 1.752939\tAccuracy: 55.30%\n",
      "497\tValidation loss: 1.754969\tBest loss: 1.752939\tAccuracy: 54.90%\n",
      "498\tValidation loss: 1.754188\tBest loss: 1.752939\tAccuracy: 56.20%\n",
      "499\tValidation loss: 1.752986\tBest loss: 1.752939\tAccuracy: 55.80%\n",
      "500\tValidation loss: 1.752205\tBest loss: 1.752205\tAccuracy: 55.40%\n",
      "501\tValidation loss: 1.749371\tBest loss: 1.749371\tAccuracy: 55.60%\n",
      "502\tValidation loss: 1.748517\tBest loss: 1.748517\tAccuracy: 55.10%\n",
      "503\tValidation loss: 1.747352\tBest loss: 1.747352\tAccuracy: 55.30%\n",
      "504\tValidation loss: 1.748079\tBest loss: 1.747352\tAccuracy: 55.40%\n",
      "505\tValidation loss: 1.747288\tBest loss: 1.747288\tAccuracy: 55.50%\n",
      "506\tValidation loss: 1.749194\tBest loss: 1.747288\tAccuracy: 55.10%\n",
      "507\tValidation loss: 1.747292\tBest loss: 1.747288\tAccuracy: 55.30%\n",
      "508\tValidation loss: 1.749147\tBest loss: 1.747288\tAccuracy: 55.40%\n",
      "509\tValidation loss: 1.746769\tBest loss: 1.746769\tAccuracy: 55.40%\n",
      "510\tValidation loss: 1.745412\tBest loss: 1.745412\tAccuracy: 55.00%\n",
      "511\tValidation loss: 1.746456\tBest loss: 1.745412\tAccuracy: 55.60%\n",
      "512\tValidation loss: 1.747591\tBest loss: 1.745412\tAccuracy: 55.20%\n",
      "513\tValidation loss: 1.750018\tBest loss: 1.745412\tAccuracy: 54.70%\n",
      "514\tValidation loss: 1.748072\tBest loss: 1.745412\tAccuracy: 56.10%\n",
      "515\tValidation loss: 1.748745\tBest loss: 1.745412\tAccuracy: 55.20%\n",
      "516\tValidation loss: 1.750021\tBest loss: 1.745412\tAccuracy: 55.00%\n",
      "517\tValidation loss: 1.745343\tBest loss: 1.745343\tAccuracy: 55.80%\n",
      "518\tValidation loss: 1.743295\tBest loss: 1.743295\tAccuracy: 55.80%\n",
      "519\tValidation loss: 1.743396\tBest loss: 1.743295\tAccuracy: 55.30%\n",
      "520\tValidation loss: 1.742772\tBest loss: 1.742772\tAccuracy: 55.20%\n",
      "521\tValidation loss: 1.742385\tBest loss: 1.742385\tAccuracy: 55.10%\n",
      "522\tValidation loss: 1.739385\tBest loss: 1.739385\tAccuracy: 55.50%\n",
      "523\tValidation loss: 1.738536\tBest loss: 1.738536\tAccuracy: 55.60%\n",
      "524\tValidation loss: 1.738414\tBest loss: 1.738414\tAccuracy: 55.50%\n",
      "525\tValidation loss: 1.738886\tBest loss: 1.738414\tAccuracy: 56.10%\n",
      "526\tValidation loss: 1.737935\tBest loss: 1.737935\tAccuracy: 54.80%\n",
      "527\tValidation loss: 1.736165\tBest loss: 1.736165\tAccuracy: 55.70%\n",
      "528\tValidation loss: 1.735829\tBest loss: 1.735829\tAccuracy: 55.20%\n",
      "529\tValidation loss: 1.735559\tBest loss: 1.735559\tAccuracy: 55.70%\n",
      "530\tValidation loss: 1.737286\tBest loss: 1.735559\tAccuracy: 55.10%\n",
      "531\tValidation loss: 1.736500\tBest loss: 1.735559\tAccuracy: 55.60%\n",
      "532\tValidation loss: 1.733557\tBest loss: 1.733557\tAccuracy: 55.60%\n",
      "533\tValidation loss: 1.738120\tBest loss: 1.733557\tAccuracy: 55.30%\n",
      "534\tValidation loss: 1.734492\tBest loss: 1.733557\tAccuracy: 56.30%\n",
      "535\tValidation loss: 1.734568\tBest loss: 1.733557\tAccuracy: 55.20%\n",
      "536\tValidation loss: 1.734146\tBest loss: 1.733557\tAccuracy: 54.90%\n",
      "537\tValidation loss: 1.734168\tBest loss: 1.733557\tAccuracy: 55.10%\n",
      "538\tValidation loss: 1.736369\tBest loss: 1.733557\tAccuracy: 55.50%\n",
      "539\tValidation loss: 1.735978\tBest loss: 1.733557\tAccuracy: 56.00%\n",
      "540\tValidation loss: 1.734471\tBest loss: 1.733557\tAccuracy: 56.00%\n",
      "541\tValidation loss: 1.731102\tBest loss: 1.731102\tAccuracy: 56.20%\n",
      "542\tValidation loss: 1.730238\tBest loss: 1.730238\tAccuracy: 55.10%\n",
      "543\tValidation loss: 1.728765\tBest loss: 1.728765\tAccuracy: 56.00%\n",
      "544\tValidation loss: 1.728424\tBest loss: 1.728424\tAccuracy: 55.50%\n",
      "545\tValidation loss: 1.728820\tBest loss: 1.728424\tAccuracy: 56.00%\n",
      "546\tValidation loss: 1.726976\tBest loss: 1.726976\tAccuracy: 55.80%\n",
      "547\tValidation loss: 1.724082\tBest loss: 1.724082\tAccuracy: 56.30%\n",
      "548\tValidation loss: 1.725071\tBest loss: 1.724082\tAccuracy: 55.70%\n",
      "549\tValidation loss: 1.726805\tBest loss: 1.724082\tAccuracy: 55.60%\n",
      "550\tValidation loss: 1.728294\tBest loss: 1.724082\tAccuracy: 55.50%\n",
      "551\tValidation loss: 1.724655\tBest loss: 1.724082\tAccuracy: 55.40%\n",
      "552\tValidation loss: 1.726949\tBest loss: 1.724082\tAccuracy: 55.90%\n",
      "553\tValidation loss: 1.727156\tBest loss: 1.724082\tAccuracy: 56.20%\n",
      "554\tValidation loss: 1.727120\tBest loss: 1.724082\tAccuracy: 56.00%\n",
      "555\tValidation loss: 1.727271\tBest loss: 1.724082\tAccuracy: 56.10%\n",
      "556\tValidation loss: 1.726742\tBest loss: 1.724082\tAccuracy: 55.60%\n",
      "557\tValidation loss: 1.724690\tBest loss: 1.724082\tAccuracy: 55.10%\n",
      "558\tValidation loss: 1.724054\tBest loss: 1.724054\tAccuracy: 56.50%\n",
      "559\tValidation loss: 1.725802\tBest loss: 1.724054\tAccuracy: 55.30%\n",
      "560\tValidation loss: 1.724307\tBest loss: 1.724054\tAccuracy: 55.70%\n",
      "561\tValidation loss: 1.723574\tBest loss: 1.723574\tAccuracy: 56.30%\n",
      "562\tValidation loss: 1.722431\tBest loss: 1.722431\tAccuracy: 55.90%\n",
      "563\tValidation loss: 1.724132\tBest loss: 1.722431\tAccuracy: 56.00%\n",
      "564\tValidation loss: 1.722483\tBest loss: 1.722431\tAccuracy: 55.70%\n",
      "565\tValidation loss: 1.720779\tBest loss: 1.720779\tAccuracy: 56.40%\n",
      "566\tValidation loss: 1.719520\tBest loss: 1.719520\tAccuracy: 56.80%\n",
      "567\tValidation loss: 1.715811\tBest loss: 1.715811\tAccuracy: 56.50%\n",
      "568\tValidation loss: 1.720869\tBest loss: 1.715811\tAccuracy: 55.90%\n",
      "569\tValidation loss: 1.717712\tBest loss: 1.715811\tAccuracy: 56.20%\n",
      "570\tValidation loss: 1.716228\tBest loss: 1.715811\tAccuracy: 56.10%\n",
      "571\tValidation loss: 1.718208\tBest loss: 1.715811\tAccuracy: 56.50%\n",
      "572\tValidation loss: 1.715666\tBest loss: 1.715666\tAccuracy: 56.20%\n",
      "573\tValidation loss: 1.715754\tBest loss: 1.715666\tAccuracy: 56.10%\n",
      "574\tValidation loss: 1.717436\tBest loss: 1.715666\tAccuracy: 55.40%\n",
      "575\tValidation loss: 1.719912\tBest loss: 1.715666\tAccuracy: 55.60%\n",
      "576\tValidation loss: 1.718142\tBest loss: 1.715666\tAccuracy: 56.00%\n",
      "577\tValidation loss: 1.715080\tBest loss: 1.715080\tAccuracy: 56.00%\n",
      "578\tValidation loss: 1.713996\tBest loss: 1.713996\tAccuracy: 55.90%\n",
      "579\tValidation loss: 1.716946\tBest loss: 1.713996\tAccuracy: 56.30%\n",
      "580\tValidation loss: 1.712211\tBest loss: 1.712211\tAccuracy: 56.30%\n",
      "581\tValidation loss: 1.711894\tBest loss: 1.711894\tAccuracy: 56.50%\n",
      "582\tValidation loss: 1.710524\tBest loss: 1.710524\tAccuracy: 55.90%\n",
      "583\tValidation loss: 1.712560\tBest loss: 1.710524\tAccuracy: 55.50%\n",
      "584\tValidation loss: 1.714098\tBest loss: 1.710524\tAccuracy: 55.60%\n",
      "585\tValidation loss: 1.711289\tBest loss: 1.710524\tAccuracy: 56.00%\n",
      "586\tValidation loss: 1.713793\tBest loss: 1.710524\tAccuracy: 56.50%\n",
      "587\tValidation loss: 1.711584\tBest loss: 1.710524\tAccuracy: 56.40%\n",
      "588\tValidation loss: 1.712849\tBest loss: 1.710524\tAccuracy: 56.30%\n",
      "589\tValidation loss: 1.711513\tBest loss: 1.710524\tAccuracy: 56.40%\n",
      "590\tValidation loss: 1.710730\tBest loss: 1.710524\tAccuracy: 57.00%\n",
      "591\tValidation loss: 1.711475\tBest loss: 1.710524\tAccuracy: 56.60%\n",
      "592\tValidation loss: 1.711160\tBest loss: 1.710524\tAccuracy: 55.90%\n",
      "593\tValidation loss: 1.710431\tBest loss: 1.710431\tAccuracy: 56.50%\n",
      "594\tValidation loss: 1.708916\tBest loss: 1.708916\tAccuracy: 56.00%\n",
      "595\tValidation loss: 1.708346\tBest loss: 1.708346\tAccuracy: 56.70%\n",
      "596\tValidation loss: 1.708389\tBest loss: 1.708346\tAccuracy: 56.00%\n",
      "597\tValidation loss: 1.707178\tBest loss: 1.707178\tAccuracy: 56.80%\n",
      "598\tValidation loss: 1.709719\tBest loss: 1.707178\tAccuracy: 56.30%\n",
      "599\tValidation loss: 1.707895\tBest loss: 1.707178\tAccuracy: 55.90%\n",
      "600\tValidation loss: 1.707242\tBest loss: 1.707178\tAccuracy: 55.80%\n",
      "601\tValidation loss: 1.707801\tBest loss: 1.707178\tAccuracy: 56.50%\n",
      "602\tValidation loss: 1.706403\tBest loss: 1.706403\tAccuracy: 56.50%\n",
      "603\tValidation loss: 1.706608\tBest loss: 1.706403\tAccuracy: 56.70%\n",
      "604\tValidation loss: 1.707497\tBest loss: 1.706403\tAccuracy: 56.60%\n",
      "605\tValidation loss: 1.704183\tBest loss: 1.704183\tAccuracy: 56.40%\n",
      "606\tValidation loss: 1.701509\tBest loss: 1.701509\tAccuracy: 56.80%\n",
      "607\tValidation loss: 1.703731\tBest loss: 1.701509\tAccuracy: 56.40%\n",
      "608\tValidation loss: 1.706539\tBest loss: 1.701509\tAccuracy: 56.40%\n",
      "609\tValidation loss: 1.702178\tBest loss: 1.701509\tAccuracy: 56.80%\n",
      "610\tValidation loss: 1.701556\tBest loss: 1.701509\tAccuracy: 56.50%\n",
      "611\tValidation loss: 1.700836\tBest loss: 1.700836\tAccuracy: 56.30%\n",
      "612\tValidation loss: 1.701421\tBest loss: 1.700836\tAccuracy: 56.20%\n",
      "613\tValidation loss: 1.701463\tBest loss: 1.700836\tAccuracy: 56.20%\n",
      "614\tValidation loss: 1.702575\tBest loss: 1.700836\tAccuracy: 56.70%\n",
      "615\tValidation loss: 1.698087\tBest loss: 1.698087\tAccuracy: 56.60%\n",
      "616\tValidation loss: 1.697553\tBest loss: 1.697553\tAccuracy: 56.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\tValidation loss: 1.694716\tBest loss: 1.694716\tAccuracy: 57.10%\n",
      "618\tValidation loss: 1.700133\tBest loss: 1.694716\tAccuracy: 56.20%\n",
      "619\tValidation loss: 1.699477\tBest loss: 1.694716\tAccuracy: 56.30%\n",
      "620\tValidation loss: 1.696525\tBest loss: 1.694716\tAccuracy: 56.90%\n",
      "621\tValidation loss: 1.696264\tBest loss: 1.694716\tAccuracy: 56.40%\n",
      "622\tValidation loss: 1.698826\tBest loss: 1.694716\tAccuracy: 57.00%\n",
      "623\tValidation loss: 1.698484\tBest loss: 1.694716\tAccuracy: 56.20%\n",
      "624\tValidation loss: 1.699325\tBest loss: 1.694716\tAccuracy: 56.70%\n",
      "625\tValidation loss: 1.697582\tBest loss: 1.694716\tAccuracy: 56.40%\n",
      "626\tValidation loss: 1.696944\tBest loss: 1.694716\tAccuracy: 56.60%\n",
      "627\tValidation loss: 1.693564\tBest loss: 1.693564\tAccuracy: 56.70%\n",
      "628\tValidation loss: 1.692695\tBest loss: 1.692695\tAccuracy: 56.90%\n",
      "629\tValidation loss: 1.691917\tBest loss: 1.691917\tAccuracy: 56.80%\n",
      "630\tValidation loss: 1.694219\tBest loss: 1.691917\tAccuracy: 57.00%\n",
      "631\tValidation loss: 1.695919\tBest loss: 1.691917\tAccuracy: 56.50%\n",
      "632\tValidation loss: 1.695181\tBest loss: 1.691917\tAccuracy: 56.80%\n",
      "633\tValidation loss: 1.695393\tBest loss: 1.691917\tAccuracy: 57.00%\n",
      "634\tValidation loss: 1.696140\tBest loss: 1.691917\tAccuracy: 57.00%\n",
      "635\tValidation loss: 1.694330\tBest loss: 1.691917\tAccuracy: 56.60%\n",
      "636\tValidation loss: 1.692547\tBest loss: 1.691917\tAccuracy: 56.70%\n",
      "637\tValidation loss: 1.690444\tBest loss: 1.690444\tAccuracy: 57.10%\n",
      "638\tValidation loss: 1.691098\tBest loss: 1.690444\tAccuracy: 56.90%\n",
      "639\tValidation loss: 1.692543\tBest loss: 1.690444\tAccuracy: 56.30%\n",
      "640\tValidation loss: 1.691126\tBest loss: 1.690444\tAccuracy: 57.20%\n",
      "641\tValidation loss: 1.693102\tBest loss: 1.690444\tAccuracy: 57.30%\n",
      "642\tValidation loss: 1.689978\tBest loss: 1.689978\tAccuracy: 57.40%\n",
      "643\tValidation loss: 1.690336\tBest loss: 1.689978\tAccuracy: 57.00%\n",
      "644\tValidation loss: 1.688559\tBest loss: 1.688559\tAccuracy: 56.90%\n",
      "645\tValidation loss: 1.687793\tBest loss: 1.687793\tAccuracy: 57.10%\n",
      "646\tValidation loss: 1.688104\tBest loss: 1.687793\tAccuracy: 56.50%\n",
      "647\tValidation loss: 1.687986\tBest loss: 1.687793\tAccuracy: 57.20%\n",
      "648\tValidation loss: 1.688824\tBest loss: 1.687793\tAccuracy: 56.80%\n",
      "649\tValidation loss: 1.684363\tBest loss: 1.684363\tAccuracy: 57.40%\n",
      "650\tValidation loss: 1.684656\tBest loss: 1.684363\tAccuracy: 57.70%\n",
      "651\tValidation loss: 1.686446\tBest loss: 1.684363\tAccuracy: 57.00%\n",
      "652\tValidation loss: 1.685547\tBest loss: 1.684363\tAccuracy: 57.20%\n",
      "653\tValidation loss: 1.686293\tBest loss: 1.684363\tAccuracy: 57.00%\n",
      "654\tValidation loss: 1.687102\tBest loss: 1.684363\tAccuracy: 56.70%\n",
      "655\tValidation loss: 1.687608\tBest loss: 1.684363\tAccuracy: 57.00%\n",
      "656\tValidation loss: 1.685803\tBest loss: 1.684363\tAccuracy: 56.80%\n",
      "657\tValidation loss: 1.686928\tBest loss: 1.684363\tAccuracy: 57.30%\n",
      "658\tValidation loss: 1.687985\tBest loss: 1.684363\tAccuracy: 57.10%\n",
      "659\tValidation loss: 1.688894\tBest loss: 1.684363\tAccuracy: 56.70%\n",
      "660\tValidation loss: 1.686746\tBest loss: 1.684363\tAccuracy: 56.90%\n",
      "661\tValidation loss: 1.684307\tBest loss: 1.684307\tAccuracy: 57.40%\n",
      "662\tValidation loss: 1.680777\tBest loss: 1.680777\tAccuracy: 57.30%\n",
      "663\tValidation loss: 1.683460\tBest loss: 1.680777\tAccuracy: 57.30%\n",
      "664\tValidation loss: 1.683271\tBest loss: 1.680777\tAccuracy: 57.70%\n",
      "665\tValidation loss: 1.681697\tBest loss: 1.680777\tAccuracy: 57.50%\n",
      "666\tValidation loss: 1.679772\tBest loss: 1.679772\tAccuracy: 57.20%\n",
      "667\tValidation loss: 1.680363\tBest loss: 1.679772\tAccuracy: 57.20%\n",
      "668\tValidation loss: 1.679585\tBest loss: 1.679585\tAccuracy: 57.50%\n",
      "669\tValidation loss: 1.678440\tBest loss: 1.678440\tAccuracy: 57.70%\n",
      "670\tValidation loss: 1.682922\tBest loss: 1.678440\tAccuracy: 56.70%\n",
      "671\tValidation loss: 1.683004\tBest loss: 1.678440\tAccuracy: 56.80%\n",
      "672\tValidation loss: 1.681975\tBest loss: 1.678440\tAccuracy: 57.30%\n",
      "673\tValidation loss: 1.678430\tBest loss: 1.678430\tAccuracy: 57.40%\n",
      "674\tValidation loss: 1.678696\tBest loss: 1.678430\tAccuracy: 57.70%\n",
      "675\tValidation loss: 1.679930\tBest loss: 1.678430\tAccuracy: 57.10%\n",
      "676\tValidation loss: 1.676376\tBest loss: 1.676376\tAccuracy: 57.10%\n",
      "677\tValidation loss: 1.674925\tBest loss: 1.674925\tAccuracy: 57.10%\n",
      "678\tValidation loss: 1.675362\tBest loss: 1.674925\tAccuracy: 57.30%\n",
      "679\tValidation loss: 1.678326\tBest loss: 1.674925\tAccuracy: 57.00%\n",
      "680\tValidation loss: 1.679389\tBest loss: 1.674925\tAccuracy: 57.50%\n",
      "681\tValidation loss: 1.678435\tBest loss: 1.674925\tAccuracy: 57.40%\n",
      "682\tValidation loss: 1.678658\tBest loss: 1.674925\tAccuracy: 57.30%\n",
      "683\tValidation loss: 1.676517\tBest loss: 1.674925\tAccuracy: 57.60%\n",
      "684\tValidation loss: 1.674380\tBest loss: 1.674380\tAccuracy: 57.30%\n",
      "685\tValidation loss: 1.675028\tBest loss: 1.674380\tAccuracy: 57.50%\n",
      "686\tValidation loss: 1.674383\tBest loss: 1.674380\tAccuracy: 57.10%\n",
      "687\tValidation loss: 1.672953\tBest loss: 1.672953\tAccuracy: 56.30%\n",
      "688\tValidation loss: 1.671572\tBest loss: 1.671572\tAccuracy: 56.70%\n",
      "689\tValidation loss: 1.668118\tBest loss: 1.668118\tAccuracy: 57.20%\n",
      "690\tValidation loss: 1.670555\tBest loss: 1.668118\tAccuracy: 57.00%\n",
      "691\tValidation loss: 1.669305\tBest loss: 1.668118\tAccuracy: 57.10%\n",
      "692\tValidation loss: 1.669250\tBest loss: 1.668118\tAccuracy: 57.30%\n",
      "693\tValidation loss: 1.666738\tBest loss: 1.666738\tAccuracy: 58.10%\n",
      "694\tValidation loss: 1.668161\tBest loss: 1.666738\tAccuracy: 57.30%\n",
      "695\tValidation loss: 1.664932\tBest loss: 1.664932\tAccuracy: 57.90%\n",
      "696\tValidation loss: 1.667755\tBest loss: 1.664932\tAccuracy: 57.70%\n",
      "697\tValidation loss: 1.668726\tBest loss: 1.664932\tAccuracy: 58.40%\n",
      "698\tValidation loss: 1.669008\tBest loss: 1.664932\tAccuracy: 58.10%\n",
      "699\tValidation loss: 1.670747\tBest loss: 1.664932\tAccuracy: 57.50%\n",
      "700\tValidation loss: 1.667606\tBest loss: 1.664932\tAccuracy: 57.40%\n",
      "701\tValidation loss: 1.668510\tBest loss: 1.664932\tAccuracy: 57.70%\n",
      "702\tValidation loss: 1.665630\tBest loss: 1.664932\tAccuracy: 58.00%\n",
      "703\tValidation loss: 1.665565\tBest loss: 1.664932\tAccuracy: 58.20%\n",
      "704\tValidation loss: 1.664603\tBest loss: 1.664603\tAccuracy: 57.50%\n",
      "705\tValidation loss: 1.664031\tBest loss: 1.664031\tAccuracy: 57.50%\n",
      "706\tValidation loss: 1.665964\tBest loss: 1.664031\tAccuracy: 57.80%\n",
      "707\tValidation loss: 1.666094\tBest loss: 1.664031\tAccuracy: 57.90%\n",
      "708\tValidation loss: 1.666179\tBest loss: 1.664031\tAccuracy: 57.80%\n",
      "709\tValidation loss: 1.665970\tBest loss: 1.664031\tAccuracy: 58.00%\n",
      "710\tValidation loss: 1.665645\tBest loss: 1.664031\tAccuracy: 57.90%\n",
      "711\tValidation loss: 1.661917\tBest loss: 1.661917\tAccuracy: 57.70%\n",
      "712\tValidation loss: 1.662314\tBest loss: 1.661917\tAccuracy: 57.70%\n",
      "713\tValidation loss: 1.661158\tBest loss: 1.661158\tAccuracy: 57.70%\n",
      "714\tValidation loss: 1.661524\tBest loss: 1.661158\tAccuracy: 57.10%\n",
      "715\tValidation loss: 1.661069\tBest loss: 1.661069\tAccuracy: 57.90%\n",
      "716\tValidation loss: 1.660225\tBest loss: 1.660225\tAccuracy: 58.20%\n",
      "717\tValidation loss: 1.658208\tBest loss: 1.658208\tAccuracy: 58.40%\n",
      "718\tValidation loss: 1.661420\tBest loss: 1.658208\tAccuracy: 57.40%\n",
      "719\tValidation loss: 1.661370\tBest loss: 1.658208\tAccuracy: 57.40%\n",
      "720\tValidation loss: 1.659910\tBest loss: 1.658208\tAccuracy: 57.60%\n",
      "721\tValidation loss: 1.660473\tBest loss: 1.658208\tAccuracy: 57.90%\n",
      "722\tValidation loss: 1.658810\tBest loss: 1.658208\tAccuracy: 58.00%\n",
      "723\tValidation loss: 1.660281\tBest loss: 1.658208\tAccuracy: 57.60%\n",
      "724\tValidation loss: 1.659614\tBest loss: 1.658208\tAccuracy: 58.20%\n",
      "725\tValidation loss: 1.658754\tBest loss: 1.658208\tAccuracy: 57.90%\n",
      "726\tValidation loss: 1.657992\tBest loss: 1.657992\tAccuracy: 58.30%\n",
      "727\tValidation loss: 1.656080\tBest loss: 1.656080\tAccuracy: 58.70%\n",
      "728\tValidation loss: 1.656098\tBest loss: 1.656080\tAccuracy: 58.70%\n",
      "729\tValidation loss: 1.657293\tBest loss: 1.656080\tAccuracy: 58.00%\n",
      "730\tValidation loss: 1.656555\tBest loss: 1.656080\tAccuracy: 58.30%\n",
      "731\tValidation loss: 1.655258\tBest loss: 1.655258\tAccuracy: 58.50%\n",
      "732\tValidation loss: 1.656170\tBest loss: 1.655258\tAccuracy: 58.40%\n",
      "733\tValidation loss: 1.658239\tBest loss: 1.655258\tAccuracy: 57.80%\n",
      "734\tValidation loss: 1.656586\tBest loss: 1.655258\tAccuracy: 58.00%\n",
      "735\tValidation loss: 1.655972\tBest loss: 1.655258\tAccuracy: 58.30%\n",
      "736\tValidation loss: 1.654340\tBest loss: 1.654340\tAccuracy: 58.20%\n",
      "737\tValidation loss: 1.655404\tBest loss: 1.654340\tAccuracy: 58.10%\n",
      "738\tValidation loss: 1.654715\tBest loss: 1.654340\tAccuracy: 58.40%\n",
      "739\tValidation loss: 1.654411\tBest loss: 1.654340\tAccuracy: 58.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\tValidation loss: 1.652430\tBest loss: 1.652430\tAccuracy: 58.70%\n",
      "741\tValidation loss: 1.652535\tBest loss: 1.652430\tAccuracy: 58.60%\n",
      "742\tValidation loss: 1.654370\tBest loss: 1.652430\tAccuracy: 58.20%\n",
      "743\tValidation loss: 1.651535\tBest loss: 1.651535\tAccuracy: 58.20%\n",
      "744\tValidation loss: 1.653572\tBest loss: 1.651535\tAccuracy: 57.70%\n",
      "745\tValidation loss: 1.650116\tBest loss: 1.650116\tAccuracy: 58.60%\n",
      "746\tValidation loss: 1.649119\tBest loss: 1.649119\tAccuracy: 58.50%\n",
      "747\tValidation loss: 1.651177\tBest loss: 1.649119\tAccuracy: 58.00%\n",
      "748\tValidation loss: 1.653024\tBest loss: 1.649119\tAccuracy: 58.10%\n",
      "749\tValidation loss: 1.652230\tBest loss: 1.649119\tAccuracy: 58.60%\n",
      "750\tValidation loss: 1.650143\tBest loss: 1.649119\tAccuracy: 58.10%\n",
      "751\tValidation loss: 1.649776\tBest loss: 1.649119\tAccuracy: 58.70%\n",
      "752\tValidation loss: 1.649206\tBest loss: 1.649119\tAccuracy: 58.10%\n",
      "753\tValidation loss: 1.650107\tBest loss: 1.649119\tAccuracy: 58.00%\n",
      "754\tValidation loss: 1.647825\tBest loss: 1.647825\tAccuracy: 58.20%\n",
      "755\tValidation loss: 1.648663\tBest loss: 1.647825\tAccuracy: 58.10%\n",
      "756\tValidation loss: 1.649189\tBest loss: 1.647825\tAccuracy: 57.90%\n",
      "757\tValidation loss: 1.650249\tBest loss: 1.647825\tAccuracy: 58.60%\n",
      "758\tValidation loss: 1.651497\tBest loss: 1.647825\tAccuracy: 58.70%\n",
      "759\tValidation loss: 1.652209\tBest loss: 1.647825\tAccuracy: 58.90%\n",
      "760\tValidation loss: 1.651207\tBest loss: 1.647825\tAccuracy: 59.20%\n",
      "761\tValidation loss: 1.647943\tBest loss: 1.647825\tAccuracy: 59.10%\n",
      "762\tValidation loss: 1.648951\tBest loss: 1.647825\tAccuracy: 58.90%\n",
      "763\tValidation loss: 1.646743\tBest loss: 1.646743\tAccuracy: 58.70%\n",
      "764\tValidation loss: 1.643803\tBest loss: 1.643803\tAccuracy: 58.60%\n",
      "765\tValidation loss: 1.642074\tBest loss: 1.642074\tAccuracy: 58.20%\n",
      "766\tValidation loss: 1.640774\tBest loss: 1.640774\tAccuracy: 58.70%\n",
      "767\tValidation loss: 1.641032\tBest loss: 1.640774\tAccuracy: 58.90%\n",
      "768\tValidation loss: 1.639810\tBest loss: 1.639810\tAccuracy: 58.80%\n",
      "769\tValidation loss: 1.636811\tBest loss: 1.636811\tAccuracy: 59.30%\n",
      "770\tValidation loss: 1.638463\tBest loss: 1.636811\tAccuracy: 58.70%\n",
      "771\tValidation loss: 1.640225\tBest loss: 1.636811\tAccuracy: 59.00%\n",
      "772\tValidation loss: 1.640131\tBest loss: 1.636811\tAccuracy: 58.90%\n",
      "773\tValidation loss: 1.637755\tBest loss: 1.636811\tAccuracy: 59.20%\n",
      "774\tValidation loss: 1.639587\tBest loss: 1.636811\tAccuracy: 58.20%\n",
      "775\tValidation loss: 1.640710\tBest loss: 1.636811\tAccuracy: 58.70%\n",
      "776\tValidation loss: 1.641663\tBest loss: 1.636811\tAccuracy: 58.10%\n",
      "777\tValidation loss: 1.641495\tBest loss: 1.636811\tAccuracy: 58.20%\n",
      "778\tValidation loss: 1.643370\tBest loss: 1.636811\tAccuracy: 58.10%\n",
      "779\tValidation loss: 1.641529\tBest loss: 1.636811\tAccuracy: 58.60%\n",
      "780\tValidation loss: 1.639208\tBest loss: 1.636811\tAccuracy: 58.10%\n",
      "781\tValidation loss: 1.640951\tBest loss: 1.636811\tAccuracy: 58.80%\n",
      "782\tValidation loss: 1.641631\tBest loss: 1.636811\tAccuracy: 58.90%\n",
      "783\tValidation loss: 1.639855\tBest loss: 1.636811\tAccuracy: 59.20%\n",
      "784\tValidation loss: 1.642232\tBest loss: 1.636811\tAccuracy: 58.50%\n",
      "785\tValidation loss: 1.640218\tBest loss: 1.636811\tAccuracy: 58.80%\n",
      "786\tValidation loss: 1.639556\tBest loss: 1.636811\tAccuracy: 58.40%\n",
      "787\tValidation loss: 1.640033\tBest loss: 1.636811\tAccuracy: 58.70%\n",
      "788\tValidation loss: 1.639457\tBest loss: 1.636811\tAccuracy: 58.90%\n",
      "789\tValidation loss: 1.639712\tBest loss: 1.636811\tAccuracy: 58.30%\n",
      "790\tValidation loss: 1.638276\tBest loss: 1.636811\tAccuracy: 58.70%\n",
      "Early stopping!\n",
      "[[  1.72130768e-10   6.79483446e-06   1.66857561e-07 ...,   8.60043306e-14\n",
      "    4.85217422e-10   6.40243622e-11]\n",
      " [  5.53082451e-02   3.05929091e-02   5.24262451e-02 ...,   1.50801791e-02\n",
      "    7.96220358e-03   5.48695121e-03]\n",
      " [  3.26451669e-07   8.94309835e-11   7.73179563e-05 ...,   3.48885804e-16\n",
      "    1.06533716e-16   2.37702240e-19]\n",
      " ..., \n",
      " [  2.39879206e-23   1.15133046e-16   5.97206601e-17 ...,   1.28939784e-11\n",
      "    8.67254255e-11   1.12931160e-12]\n",
      " [  1.23281991e-02   3.22879367e-02   1.58581585e-02 ...,   6.09263889e-02\n",
      "    1.76214296e-02   1.29665611e-02]\n",
      " [  1.18098251e-05   2.24584401e-05   2.68540716e-05 ...,   4.06917883e-03\n",
      "    4.01418656e-03   1.06647788e-02]]\n",
      "[20  0 16 ...,  6 24  9]\n",
      "[[  1.36351093e-06   4.26406950e-05   1.39908167e-03 ...,   1.26964494e-03\n",
      "    1.86322513e-03   4.53542831e-04]\n",
      " [  7.81682635e-11   1.26024020e-06   2.08621511e-08 ...,   3.82736750e-14\n",
      "    3.03050501e-10   1.93091810e-11]\n",
      " [  4.13165208e-06   1.28852625e-04   2.75333296e-05 ...,   3.65850184e-07\n",
      "    3.44434693e-06   2.85029455e-06]\n",
      " ..., \n",
      " [  1.53205381e-03   2.75721252e-02   1.20345212e-03 ...,   1.03951379e-05\n",
      "    6.39107975e-06   3.37941771e-07]\n",
      " [  4.14850861e-02   1.97147634e-02   3.98534350e-02 ...,   1.96374115e-02\n",
      "    1.14819920e-02   9.74753127e-03]\n",
      " [  2.82966170e-07   1.89588741e-06   5.03176913e-08 ...,   1.50011033e-01\n",
      "    1.63080499e-01   5.55990517e-01]]\n",
      "[41 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 3.4min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.987146\tBest loss: 3.987146\tAccuracy: 3.20%\n",
      "1\tValidation loss: 3.911153\tBest loss: 3.911153\tAccuracy: 4.60%\n",
      "2\tValidation loss: 3.862933\tBest loss: 3.862933\tAccuracy: 4.90%\n",
      "3\tValidation loss: 3.822792\tBest loss: 3.822792\tAccuracy: 4.90%\n",
      "4\tValidation loss: 3.793683\tBest loss: 3.793683\tAccuracy: 4.90%\n",
      "5\tValidation loss: 3.770755\tBest loss: 3.770755\tAccuracy: 6.10%\n",
      "6\tValidation loss: 3.753169\tBest loss: 3.753169\tAccuracy: 6.50%\n",
      "7\tValidation loss: 3.739667\tBest loss: 3.739667\tAccuracy: 7.00%\n",
      "8\tValidation loss: 3.727353\tBest loss: 3.727353\tAccuracy: 8.50%\n",
      "9\tValidation loss: 3.718148\tBest loss: 3.718148\tAccuracy: 8.10%\n",
      "10\tValidation loss: 3.710293\tBest loss: 3.710293\tAccuracy: 8.90%\n",
      "11\tValidation loss: 3.702505\tBest loss: 3.702505\tAccuracy: 8.50%\n",
      "12\tValidation loss: 3.695554\tBest loss: 3.695554\tAccuracy: 8.90%\n",
      "13\tValidation loss: 3.689960\tBest loss: 3.689960\tAccuracy: 9.00%\n",
      "14\tValidation loss: 3.684009\tBest loss: 3.684009\tAccuracy: 8.90%\n",
      "15\tValidation loss: 3.678180\tBest loss: 3.678180\tAccuracy: 8.50%\n",
      "16\tValidation loss: 3.672775\tBest loss: 3.672775\tAccuracy: 8.90%\n",
      "17\tValidation loss: 3.667895\tBest loss: 3.667895\tAccuracy: 9.00%\n",
      "18\tValidation loss: 3.663655\tBest loss: 3.663655\tAccuracy: 8.90%\n",
      "19\tValidation loss: 3.659761\tBest loss: 3.659761\tAccuracy: 8.80%\n",
      "20\tValidation loss: 3.654953\tBest loss: 3.654953\tAccuracy: 8.90%\n",
      "21\tValidation loss: 3.650141\tBest loss: 3.650141\tAccuracy: 9.40%\n",
      "22\tValidation loss: 3.644605\tBest loss: 3.644605\tAccuracy: 9.40%\n",
      "23\tValidation loss: 3.639442\tBest loss: 3.639442\tAccuracy: 10.20%\n",
      "24\tValidation loss: 3.630308\tBest loss: 3.630308\tAccuracy: 10.30%\n",
      "25\tValidation loss: 3.625601\tBest loss: 3.625601\tAccuracy: 10.30%\n",
      "26\tValidation loss: 3.619743\tBest loss: 3.619743\tAccuracy: 10.00%\n",
      "27\tValidation loss: 3.612273\tBest loss: 3.612273\tAccuracy: 9.70%\n",
      "28\tValidation loss: 3.606567\tBest loss: 3.606567\tAccuracy: 9.80%\n",
      "29\tValidation loss: 3.600235\tBest loss: 3.600235\tAccuracy: 10.10%\n",
      "30\tValidation loss: 3.592860\tBest loss: 3.592860\tAccuracy: 10.40%\n",
      "31\tValidation loss: 3.586424\tBest loss: 3.586424\tAccuracy: 10.40%\n",
      "32\tValidation loss: 3.579954\tBest loss: 3.579954\tAccuracy: 10.30%\n",
      "33\tValidation loss: 3.573399\tBest loss: 3.573399\tAccuracy: 10.40%\n",
      "34\tValidation loss: 3.568407\tBest loss: 3.568407\tAccuracy: 10.40%\n",
      "35\tValidation loss: 3.564101\tBest loss: 3.564101\tAccuracy: 10.30%\n",
      "36\tValidation loss: 3.559510\tBest loss: 3.559510\tAccuracy: 10.80%\n",
      "37\tValidation loss: 3.554344\tBest loss: 3.554344\tAccuracy: 10.70%\n",
      "38\tValidation loss: 3.551577\tBest loss: 3.551577\tAccuracy: 11.20%\n",
      "39\tValidation loss: 3.544577\tBest loss: 3.544577\tAccuracy: 11.20%\n",
      "40\tValidation loss: 3.538262\tBest loss: 3.538262\tAccuracy: 11.60%\n",
      "41\tValidation loss: 3.535495\tBest loss: 3.535495\tAccuracy: 11.60%\n",
      "42\tValidation loss: 3.527098\tBest loss: 3.527098\tAccuracy: 12.60%\n",
      "43\tValidation loss: 3.520773\tBest loss: 3.520773\tAccuracy: 12.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\tValidation loss: 3.512515\tBest loss: 3.512515\tAccuracy: 12.00%\n",
      "45\tValidation loss: 3.506577\tBest loss: 3.506577\tAccuracy: 12.20%\n",
      "46\tValidation loss: 3.500295\tBest loss: 3.500295\tAccuracy: 12.30%\n",
      "47\tValidation loss: 3.497638\tBest loss: 3.497638\tAccuracy: 12.50%\n",
      "48\tValidation loss: 3.492039\tBest loss: 3.492039\tAccuracy: 12.50%\n",
      "49\tValidation loss: 3.489646\tBest loss: 3.489646\tAccuracy: 12.90%\n",
      "50\tValidation loss: 3.486148\tBest loss: 3.486148\tAccuracy: 12.60%\n",
      "51\tValidation loss: 3.475771\tBest loss: 3.475771\tAccuracy: 12.90%\n",
      "52\tValidation loss: 3.470877\tBest loss: 3.470877\tAccuracy: 13.20%\n",
      "53\tValidation loss: 3.463322\tBest loss: 3.463322\tAccuracy: 13.70%\n",
      "54\tValidation loss: 3.461937\tBest loss: 3.461937\tAccuracy: 13.40%\n",
      "55\tValidation loss: 3.455359\tBest loss: 3.455359\tAccuracy: 13.80%\n",
      "56\tValidation loss: 3.446048\tBest loss: 3.446048\tAccuracy: 14.10%\n",
      "57\tValidation loss: 3.439753\tBest loss: 3.439753\tAccuracy: 14.30%\n",
      "58\tValidation loss: 3.436460\tBest loss: 3.436460\tAccuracy: 14.60%\n",
      "59\tValidation loss: 3.426357\tBest loss: 3.426357\tAccuracy: 15.00%\n",
      "60\tValidation loss: 3.426516\tBest loss: 3.426357\tAccuracy: 15.20%\n",
      "61\tValidation loss: 3.419357\tBest loss: 3.419357\tAccuracy: 15.20%\n",
      "62\tValidation loss: 3.415116\tBest loss: 3.415116\tAccuracy: 15.10%\n",
      "63\tValidation loss: 3.405623\tBest loss: 3.405623\tAccuracy: 15.40%\n",
      "64\tValidation loss: 3.399483\tBest loss: 3.399483\tAccuracy: 15.40%\n",
      "65\tValidation loss: 3.396664\tBest loss: 3.396664\tAccuracy: 15.00%\n",
      "66\tValidation loss: 3.394374\tBest loss: 3.394374\tAccuracy: 15.20%\n",
      "67\tValidation loss: 3.385157\tBest loss: 3.385157\tAccuracy: 15.00%\n",
      "68\tValidation loss: 3.382146\tBest loss: 3.382146\tAccuracy: 14.80%\n",
      "69\tValidation loss: 3.372391\tBest loss: 3.372391\tAccuracy: 14.60%\n",
      "70\tValidation loss: 3.368322\tBest loss: 3.368322\tAccuracy: 15.10%\n",
      "71\tValidation loss: 3.357361\tBest loss: 3.357361\tAccuracy: 14.90%\n",
      "72\tValidation loss: 3.349236\tBest loss: 3.349236\tAccuracy: 15.20%\n",
      "73\tValidation loss: 3.348091\tBest loss: 3.348091\tAccuracy: 15.60%\n",
      "74\tValidation loss: 3.337387\tBest loss: 3.337387\tAccuracy: 15.50%\n",
      "75\tValidation loss: 3.330670\tBest loss: 3.330670\tAccuracy: 15.80%\n",
      "76\tValidation loss: 3.326196\tBest loss: 3.326196\tAccuracy: 15.70%\n",
      "77\tValidation loss: 3.307823\tBest loss: 3.307823\tAccuracy: 15.90%\n",
      "78\tValidation loss: 3.294049\tBest loss: 3.294049\tAccuracy: 16.80%\n",
      "79\tValidation loss: 3.291114\tBest loss: 3.291114\tAccuracy: 16.80%\n",
      "80\tValidation loss: 3.279594\tBest loss: 3.279594\tAccuracy: 16.50%\n",
      "81\tValidation loss: 3.267852\tBest loss: 3.267852\tAccuracy: 16.60%\n",
      "82\tValidation loss: 3.255714\tBest loss: 3.255714\tAccuracy: 17.10%\n",
      "83\tValidation loss: 3.244189\tBest loss: 3.244189\tAccuracy: 17.60%\n",
      "84\tValidation loss: 3.233937\tBest loss: 3.233937\tAccuracy: 17.60%\n",
      "85\tValidation loss: 3.228303\tBest loss: 3.228303\tAccuracy: 17.10%\n",
      "86\tValidation loss: 3.212068\tBest loss: 3.212068\tAccuracy: 17.50%\n",
      "87\tValidation loss: 3.185277\tBest loss: 3.185277\tAccuracy: 17.80%\n",
      "88\tValidation loss: 3.176405\tBest loss: 3.176405\tAccuracy: 18.40%\n",
      "89\tValidation loss: 3.159957\tBest loss: 3.159957\tAccuracy: 19.00%\n",
      "90\tValidation loss: 3.137080\tBest loss: 3.137080\tAccuracy: 19.00%\n",
      "91\tValidation loss: 3.123014\tBest loss: 3.123014\tAccuracy: 19.30%\n",
      "92\tValidation loss: 3.119846\tBest loss: 3.119846\tAccuracy: 19.80%\n",
      "93\tValidation loss: 3.099189\tBest loss: 3.099189\tAccuracy: 19.80%\n",
      "94\tValidation loss: 3.082747\tBest loss: 3.082747\tAccuracy: 20.50%\n",
      "95\tValidation loss: 3.080193\tBest loss: 3.080193\tAccuracy: 20.90%\n",
      "96\tValidation loss: 3.069023\tBest loss: 3.069023\tAccuracy: 21.00%\n",
      "97\tValidation loss: 3.053765\tBest loss: 3.053765\tAccuracy: 21.10%\n",
      "98\tValidation loss: 3.038381\tBest loss: 3.038381\tAccuracy: 22.00%\n",
      "99\tValidation loss: 3.031581\tBest loss: 3.031581\tAccuracy: 22.30%\n",
      "100\tValidation loss: 3.009490\tBest loss: 3.009490\tAccuracy: 23.30%\n",
      "101\tValidation loss: 2.993821\tBest loss: 2.993821\tAccuracy: 23.90%\n",
      "102\tValidation loss: 2.981830\tBest loss: 2.981830\tAccuracy: 23.00%\n",
      "103\tValidation loss: 2.977744\tBest loss: 2.977744\tAccuracy: 23.40%\n",
      "104\tValidation loss: 2.945064\tBest loss: 2.945064\tAccuracy: 23.50%\n",
      "105\tValidation loss: 2.930774\tBest loss: 2.930774\tAccuracy: 24.30%\n",
      "106\tValidation loss: 2.934003\tBest loss: 2.930774\tAccuracy: 24.40%\n",
      "107\tValidation loss: 2.916243\tBest loss: 2.916243\tAccuracy: 24.90%\n",
      "108\tValidation loss: 2.895459\tBest loss: 2.895459\tAccuracy: 24.70%\n",
      "109\tValidation loss: 2.876709\tBest loss: 2.876709\tAccuracy: 24.80%\n",
      "110\tValidation loss: 2.860193\tBest loss: 2.860193\tAccuracy: 25.10%\n",
      "111\tValidation loss: 2.853098\tBest loss: 2.853098\tAccuracy: 25.90%\n",
      "112\tValidation loss: 2.840562\tBest loss: 2.840562\tAccuracy: 25.30%\n",
      "113\tValidation loss: 2.818354\tBest loss: 2.818354\tAccuracy: 26.50%\n",
      "114\tValidation loss: 2.814913\tBest loss: 2.814913\tAccuracy: 27.00%\n",
      "115\tValidation loss: 2.802062\tBest loss: 2.802062\tAccuracy: 26.70%\n",
      "116\tValidation loss: 2.779982\tBest loss: 2.779982\tAccuracy: 27.50%\n",
      "117\tValidation loss: 2.773368\tBest loss: 2.773368\tAccuracy: 26.90%\n",
      "118\tValidation loss: 2.759507\tBest loss: 2.759507\tAccuracy: 27.20%\n",
      "119\tValidation loss: 2.750426\tBest loss: 2.750426\tAccuracy: 27.00%\n",
      "120\tValidation loss: 2.732973\tBest loss: 2.732973\tAccuracy: 28.00%\n",
      "121\tValidation loss: 2.722132\tBest loss: 2.722132\tAccuracy: 28.00%\n",
      "122\tValidation loss: 2.710593\tBest loss: 2.710593\tAccuracy: 28.20%\n",
      "123\tValidation loss: 2.696872\tBest loss: 2.696872\tAccuracy: 28.50%\n",
      "124\tValidation loss: 2.689033\tBest loss: 2.689033\tAccuracy: 29.50%\n",
      "125\tValidation loss: 2.683633\tBest loss: 2.683633\tAccuracy: 29.10%\n",
      "126\tValidation loss: 2.677883\tBest loss: 2.677883\tAccuracy: 29.60%\n",
      "127\tValidation loss: 2.660823\tBest loss: 2.660823\tAccuracy: 30.10%\n",
      "128\tValidation loss: 2.644352\tBest loss: 2.644352\tAccuracy: 29.80%\n",
      "129\tValidation loss: 2.643466\tBest loss: 2.643466\tAccuracy: 30.30%\n",
      "130\tValidation loss: 2.631741\tBest loss: 2.631741\tAccuracy: 31.00%\n",
      "131\tValidation loss: 2.614312\tBest loss: 2.614312\tAccuracy: 31.20%\n",
      "132\tValidation loss: 2.617807\tBest loss: 2.614312\tAccuracy: 31.20%\n",
      "133\tValidation loss: 2.611401\tBest loss: 2.611401\tAccuracy: 31.50%\n",
      "134\tValidation loss: 2.604441\tBest loss: 2.604441\tAccuracy: 30.80%\n",
      "135\tValidation loss: 2.592183\tBest loss: 2.592183\tAccuracy: 31.40%\n",
      "136\tValidation loss: 2.584104\tBest loss: 2.584104\tAccuracy: 32.10%\n",
      "137\tValidation loss: 2.574515\tBest loss: 2.574515\tAccuracy: 32.50%\n",
      "138\tValidation loss: 2.566658\tBest loss: 2.566658\tAccuracy: 32.50%\n",
      "139\tValidation loss: 2.557778\tBest loss: 2.557778\tAccuracy: 32.10%\n",
      "140\tValidation loss: 2.547776\tBest loss: 2.547776\tAccuracy: 32.70%\n",
      "141\tValidation loss: 2.553339\tBest loss: 2.547776\tAccuracy: 33.30%\n",
      "142\tValidation loss: 2.539479\tBest loss: 2.539479\tAccuracy: 33.60%\n",
      "143\tValidation loss: 2.532095\tBest loss: 2.532095\tAccuracy: 33.90%\n",
      "144\tValidation loss: 2.529566\tBest loss: 2.529566\tAccuracy: 33.80%\n",
      "145\tValidation loss: 2.519521\tBest loss: 2.519521\tAccuracy: 34.00%\n",
      "146\tValidation loss: 2.518828\tBest loss: 2.518828\tAccuracy: 34.20%\n",
      "147\tValidation loss: 2.512699\tBest loss: 2.512699\tAccuracy: 34.20%\n",
      "148\tValidation loss: 2.504041\tBest loss: 2.504041\tAccuracy: 34.60%\n",
      "149\tValidation loss: 2.493571\tBest loss: 2.493571\tAccuracy: 35.10%\n",
      "150\tValidation loss: 2.493428\tBest loss: 2.493428\tAccuracy: 35.10%\n",
      "151\tValidation loss: 2.482322\tBest loss: 2.482322\tAccuracy: 35.40%\n",
      "152\tValidation loss: 2.475190\tBest loss: 2.475190\tAccuracy: 36.10%\n",
      "153\tValidation loss: 2.474951\tBest loss: 2.474951\tAccuracy: 35.30%\n",
      "154\tValidation loss: 2.467144\tBest loss: 2.467144\tAccuracy: 35.70%\n",
      "155\tValidation loss: 2.471055\tBest loss: 2.467144\tAccuracy: 34.90%\n",
      "156\tValidation loss: 2.450997\tBest loss: 2.450997\tAccuracy: 36.00%\n",
      "157\tValidation loss: 2.446937\tBest loss: 2.446937\tAccuracy: 35.90%\n",
      "158\tValidation loss: 2.444117\tBest loss: 2.444117\tAccuracy: 35.90%\n",
      "159\tValidation loss: 2.431555\tBest loss: 2.431555\tAccuracy: 36.50%\n",
      "160\tValidation loss: 2.431043\tBest loss: 2.431043\tAccuracy: 36.30%\n",
      "161\tValidation loss: 2.430007\tBest loss: 2.430007\tAccuracy: 36.50%\n",
      "162\tValidation loss: 2.420780\tBest loss: 2.420780\tAccuracy: 36.70%\n",
      "163\tValidation loss: 2.416152\tBest loss: 2.416152\tAccuracy: 37.20%\n",
      "164\tValidation loss: 2.414907\tBest loss: 2.414907\tAccuracy: 37.80%\n",
      "165\tValidation loss: 2.405760\tBest loss: 2.405760\tAccuracy: 37.70%\n",
      "166\tValidation loss: 2.400805\tBest loss: 2.400805\tAccuracy: 37.80%\n",
      "167\tValidation loss: 2.395715\tBest loss: 2.395715\tAccuracy: 38.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\tValidation loss: 2.391168\tBest loss: 2.391168\tAccuracy: 38.50%\n",
      "169\tValidation loss: 2.392096\tBest loss: 2.391168\tAccuracy: 38.30%\n",
      "170\tValidation loss: 2.388328\tBest loss: 2.388328\tAccuracy: 38.00%\n",
      "171\tValidation loss: 2.390931\tBest loss: 2.388328\tAccuracy: 37.70%\n",
      "172\tValidation loss: 2.383022\tBest loss: 2.383022\tAccuracy: 38.50%\n",
      "173\tValidation loss: 2.373599\tBest loss: 2.373599\tAccuracy: 39.30%\n",
      "174\tValidation loss: 2.371788\tBest loss: 2.371788\tAccuracy: 39.30%\n",
      "175\tValidation loss: 2.364589\tBest loss: 2.364589\tAccuracy: 39.60%\n",
      "176\tValidation loss: 2.363423\tBest loss: 2.363423\tAccuracy: 39.70%\n",
      "177\tValidation loss: 2.357270\tBest loss: 2.357270\tAccuracy: 39.70%\n",
      "178\tValidation loss: 2.349440\tBest loss: 2.349440\tAccuracy: 39.80%\n",
      "179\tValidation loss: 2.347253\tBest loss: 2.347253\tAccuracy: 39.70%\n",
      "180\tValidation loss: 2.344265\tBest loss: 2.344265\tAccuracy: 40.30%\n",
      "181\tValidation loss: 2.339665\tBest loss: 2.339665\tAccuracy: 39.70%\n",
      "182\tValidation loss: 2.333527\tBest loss: 2.333527\tAccuracy: 40.10%\n",
      "183\tValidation loss: 2.329546\tBest loss: 2.329546\tAccuracy: 41.00%\n",
      "184\tValidation loss: 2.324680\tBest loss: 2.324680\tAccuracy: 40.50%\n",
      "185\tValidation loss: 2.322468\tBest loss: 2.322468\tAccuracy: 40.70%\n",
      "186\tValidation loss: 2.318861\tBest loss: 2.318861\tAccuracy: 40.80%\n",
      "187\tValidation loss: 2.315992\tBest loss: 2.315992\tAccuracy: 40.70%\n",
      "188\tValidation loss: 2.309860\tBest loss: 2.309860\tAccuracy: 41.00%\n",
      "189\tValidation loss: 2.310498\tBest loss: 2.309860\tAccuracy: 41.20%\n",
      "190\tValidation loss: 2.304434\tBest loss: 2.304434\tAccuracy: 41.10%\n",
      "191\tValidation loss: 2.300170\tBest loss: 2.300170\tAccuracy: 41.20%\n",
      "192\tValidation loss: 2.298290\tBest loss: 2.298290\tAccuracy: 41.50%\n",
      "193\tValidation loss: 2.294756\tBest loss: 2.294756\tAccuracy: 41.30%\n",
      "194\tValidation loss: 2.289880\tBest loss: 2.289880\tAccuracy: 41.50%\n",
      "195\tValidation loss: 2.286656\tBest loss: 2.286656\tAccuracy: 41.70%\n",
      "196\tValidation loss: 2.282276\tBest loss: 2.282276\tAccuracy: 41.60%\n",
      "197\tValidation loss: 2.278723\tBest loss: 2.278723\tAccuracy: 42.30%\n",
      "198\tValidation loss: 2.279569\tBest loss: 2.278723\tAccuracy: 41.90%\n",
      "199\tValidation loss: 2.273864\tBest loss: 2.273864\tAccuracy: 42.20%\n",
      "200\tValidation loss: 2.270335\tBest loss: 2.270335\tAccuracy: 42.50%\n",
      "201\tValidation loss: 2.271743\tBest loss: 2.270335\tAccuracy: 41.60%\n",
      "202\tValidation loss: 2.269347\tBest loss: 2.269347\tAccuracy: 41.90%\n",
      "203\tValidation loss: 2.264181\tBest loss: 2.264181\tAccuracy: 41.50%\n",
      "204\tValidation loss: 2.258357\tBest loss: 2.258357\tAccuracy: 41.90%\n",
      "205\tValidation loss: 2.257784\tBest loss: 2.257784\tAccuracy: 42.70%\n",
      "206\tValidation loss: 2.258591\tBest loss: 2.257784\tAccuracy: 41.70%\n",
      "207\tValidation loss: 2.249791\tBest loss: 2.249791\tAccuracy: 43.30%\n",
      "208\tValidation loss: 2.246610\tBest loss: 2.246610\tAccuracy: 42.90%\n",
      "209\tValidation loss: 2.243413\tBest loss: 2.243413\tAccuracy: 43.20%\n",
      "210\tValidation loss: 2.244940\tBest loss: 2.243413\tAccuracy: 42.70%\n",
      "211\tValidation loss: 2.238088\tBest loss: 2.238088\tAccuracy: 42.50%\n",
      "212\tValidation loss: 2.237159\tBest loss: 2.237159\tAccuracy: 42.30%\n",
      "213\tValidation loss: 2.233481\tBest loss: 2.233481\tAccuracy: 43.20%\n",
      "214\tValidation loss: 2.232095\tBest loss: 2.232095\tAccuracy: 42.40%\n",
      "215\tValidation loss: 2.231519\tBest loss: 2.231519\tAccuracy: 43.00%\n",
      "216\tValidation loss: 2.228861\tBest loss: 2.228861\tAccuracy: 43.70%\n",
      "217\tValidation loss: 2.225101\tBest loss: 2.225101\tAccuracy: 43.30%\n",
      "218\tValidation loss: 2.218389\tBest loss: 2.218389\tAccuracy: 43.80%\n",
      "219\tValidation loss: 2.216348\tBest loss: 2.216348\tAccuracy: 43.40%\n",
      "220\tValidation loss: 2.219405\tBest loss: 2.216348\tAccuracy: 43.20%\n",
      "221\tValidation loss: 2.209422\tBest loss: 2.209422\tAccuracy: 43.80%\n",
      "222\tValidation loss: 2.211252\tBest loss: 2.209422\tAccuracy: 43.10%\n",
      "223\tValidation loss: 2.207132\tBest loss: 2.207132\tAccuracy: 43.70%\n",
      "224\tValidation loss: 2.202332\tBest loss: 2.202332\tAccuracy: 43.90%\n",
      "225\tValidation loss: 2.201746\tBest loss: 2.201746\tAccuracy: 43.90%\n",
      "226\tValidation loss: 2.198171\tBest loss: 2.198171\tAccuracy: 44.20%\n",
      "227\tValidation loss: 2.196051\tBest loss: 2.196051\tAccuracy: 44.00%\n",
      "228\tValidation loss: 2.190389\tBest loss: 2.190389\tAccuracy: 45.10%\n",
      "229\tValidation loss: 2.193562\tBest loss: 2.190389\tAccuracy: 44.30%\n",
      "230\tValidation loss: 2.192519\tBest loss: 2.190389\tAccuracy: 44.20%\n",
      "231\tValidation loss: 2.187105\tBest loss: 2.187105\tAccuracy: 44.20%\n",
      "232\tValidation loss: 2.183691\tBest loss: 2.183691\tAccuracy: 44.60%\n",
      "233\tValidation loss: 2.184363\tBest loss: 2.183691\tAccuracy: 43.80%\n",
      "234\tValidation loss: 2.176273\tBest loss: 2.176273\tAccuracy: 44.90%\n",
      "235\tValidation loss: 2.180810\tBest loss: 2.176273\tAccuracy: 44.50%\n",
      "236\tValidation loss: 2.178786\tBest loss: 2.176273\tAccuracy: 44.50%\n",
      "237\tValidation loss: 2.172797\tBest loss: 2.172797\tAccuracy: 44.60%\n",
      "238\tValidation loss: 2.167928\tBest loss: 2.167928\tAccuracy: 44.70%\n",
      "239\tValidation loss: 2.169686\tBest loss: 2.167928\tAccuracy: 44.70%\n",
      "240\tValidation loss: 2.170676\tBest loss: 2.167928\tAccuracy: 44.00%\n",
      "241\tValidation loss: 2.159909\tBest loss: 2.159909\tAccuracy: 45.30%\n",
      "242\tValidation loss: 2.161681\tBest loss: 2.159909\tAccuracy: 44.80%\n",
      "243\tValidation loss: 2.162690\tBest loss: 2.159909\tAccuracy: 45.00%\n",
      "244\tValidation loss: 2.149641\tBest loss: 2.149641\tAccuracy: 45.80%\n",
      "245\tValidation loss: 2.152620\tBest loss: 2.149641\tAccuracy: 46.10%\n",
      "246\tValidation loss: 2.149338\tBest loss: 2.149338\tAccuracy: 45.90%\n",
      "247\tValidation loss: 2.152210\tBest loss: 2.149338\tAccuracy: 45.90%\n",
      "248\tValidation loss: 2.150879\tBest loss: 2.149338\tAccuracy: 45.40%\n",
      "249\tValidation loss: 2.141604\tBest loss: 2.141604\tAccuracy: 46.40%\n",
      "250\tValidation loss: 2.141037\tBest loss: 2.141037\tAccuracy: 46.20%\n",
      "251\tValidation loss: 2.138839\tBest loss: 2.138839\tAccuracy: 46.40%\n",
      "252\tValidation loss: 2.138796\tBest loss: 2.138796\tAccuracy: 46.00%\n",
      "253\tValidation loss: 2.136800\tBest loss: 2.136800\tAccuracy: 46.40%\n",
      "254\tValidation loss: 2.132065\tBest loss: 2.132065\tAccuracy: 47.20%\n",
      "255\tValidation loss: 2.133279\tBest loss: 2.132065\tAccuracy: 46.40%\n",
      "256\tValidation loss: 2.129624\tBest loss: 2.129624\tAccuracy: 46.30%\n",
      "257\tValidation loss: 2.132748\tBest loss: 2.129624\tAccuracy: 46.30%\n",
      "258\tValidation loss: 2.131117\tBest loss: 2.129624\tAccuracy: 46.60%\n",
      "259\tValidation loss: 2.121598\tBest loss: 2.121598\tAccuracy: 46.90%\n",
      "260\tValidation loss: 2.124667\tBest loss: 2.121598\tAccuracy: 46.90%\n",
      "261\tValidation loss: 2.118941\tBest loss: 2.118941\tAccuracy: 46.50%\n",
      "262\tValidation loss: 2.115794\tBest loss: 2.115794\tAccuracy: 46.90%\n",
      "263\tValidation loss: 2.113313\tBest loss: 2.113313\tAccuracy: 47.00%\n",
      "264\tValidation loss: 2.116502\tBest loss: 2.113313\tAccuracy: 46.60%\n",
      "265\tValidation loss: 2.108371\tBest loss: 2.108371\tAccuracy: 46.40%\n",
      "266\tValidation loss: 2.107411\tBest loss: 2.107411\tAccuracy: 47.00%\n",
      "267\tValidation loss: 2.105365\tBest loss: 2.105365\tAccuracy: 47.20%\n",
      "268\tValidation loss: 2.105912\tBest loss: 2.105365\tAccuracy: 47.10%\n",
      "269\tValidation loss: 2.098793\tBest loss: 2.098793\tAccuracy: 46.80%\n",
      "270\tValidation loss: 2.105163\tBest loss: 2.098793\tAccuracy: 46.90%\n",
      "271\tValidation loss: 2.097213\tBest loss: 2.097213\tAccuracy: 47.00%\n",
      "272\tValidation loss: 2.101027\tBest loss: 2.097213\tAccuracy: 47.50%\n",
      "273\tValidation loss: 2.094259\tBest loss: 2.094259\tAccuracy: 47.20%\n",
      "274\tValidation loss: 2.094734\tBest loss: 2.094259\tAccuracy: 47.10%\n",
      "275\tValidation loss: 2.093134\tBest loss: 2.093134\tAccuracy: 47.20%\n",
      "276\tValidation loss: 2.087106\tBest loss: 2.087106\tAccuracy: 47.40%\n",
      "277\tValidation loss: 2.095177\tBest loss: 2.087106\tAccuracy: 46.70%\n",
      "278\tValidation loss: 2.089714\tBest loss: 2.087106\tAccuracy: 48.40%\n",
      "279\tValidation loss: 2.085950\tBest loss: 2.085950\tAccuracy: 48.40%\n",
      "280\tValidation loss: 2.091044\tBest loss: 2.085950\tAccuracy: 47.20%\n",
      "281\tValidation loss: 2.076249\tBest loss: 2.076249\tAccuracy: 48.30%\n",
      "282\tValidation loss: 2.075872\tBest loss: 2.075872\tAccuracy: 48.70%\n",
      "283\tValidation loss: 2.073549\tBest loss: 2.073549\tAccuracy: 47.70%\n",
      "284\tValidation loss: 2.073676\tBest loss: 2.073549\tAccuracy: 48.90%\n",
      "285\tValidation loss: 2.074699\tBest loss: 2.073549\tAccuracy: 48.00%\n",
      "286\tValidation loss: 2.071060\tBest loss: 2.071060\tAccuracy: 48.60%\n",
      "287\tValidation loss: 2.064408\tBest loss: 2.064408\tAccuracy: 48.90%\n",
      "288\tValidation loss: 2.063142\tBest loss: 2.063142\tAccuracy: 49.10%\n",
      "289\tValidation loss: 2.060127\tBest loss: 2.060127\tAccuracy: 48.90%\n",
      "290\tValidation loss: 2.066158\tBest loss: 2.060127\tAccuracy: 49.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\tValidation loss: 2.058240\tBest loss: 2.058240\tAccuracy: 48.30%\n",
      "292\tValidation loss: 2.060002\tBest loss: 2.058240\tAccuracy: 49.60%\n",
      "293\tValidation loss: 2.054720\tBest loss: 2.054720\tAccuracy: 49.20%\n",
      "294\tValidation loss: 2.057537\tBest loss: 2.054720\tAccuracy: 49.10%\n",
      "295\tValidation loss: 2.059168\tBest loss: 2.054720\tAccuracy: 49.10%\n",
      "296\tValidation loss: 2.055129\tBest loss: 2.054720\tAccuracy: 48.90%\n",
      "297\tValidation loss: 2.053816\tBest loss: 2.053816\tAccuracy: 49.10%\n",
      "298\tValidation loss: 2.055200\tBest loss: 2.053816\tAccuracy: 49.00%\n",
      "299\tValidation loss: 2.051877\tBest loss: 2.051877\tAccuracy: 49.00%\n",
      "300\tValidation loss: 2.047935\tBest loss: 2.047935\tAccuracy: 49.00%\n",
      "301\tValidation loss: 2.045893\tBest loss: 2.045893\tAccuracy: 49.90%\n",
      "302\tValidation loss: 2.040946\tBest loss: 2.040946\tAccuracy: 49.70%\n",
      "303\tValidation loss: 2.041347\tBest loss: 2.040946\tAccuracy: 49.00%\n",
      "304\tValidation loss: 2.037320\tBest loss: 2.037320\tAccuracy: 49.80%\n",
      "305\tValidation loss: 2.038763\tBest loss: 2.037320\tAccuracy: 50.20%\n",
      "306\tValidation loss: 2.036810\tBest loss: 2.036810\tAccuracy: 50.20%\n",
      "307\tValidation loss: 2.042314\tBest loss: 2.036810\tAccuracy: 50.50%\n",
      "308\tValidation loss: 2.034622\tBest loss: 2.034622\tAccuracy: 50.40%\n",
      "309\tValidation loss: 2.032258\tBest loss: 2.032258\tAccuracy: 50.10%\n",
      "310\tValidation loss: 2.030431\tBest loss: 2.030431\tAccuracy: 50.50%\n",
      "311\tValidation loss: 2.030724\tBest loss: 2.030431\tAccuracy: 50.00%\n",
      "312\tValidation loss: 2.030503\tBest loss: 2.030431\tAccuracy: 50.10%\n",
      "313\tValidation loss: 2.028953\tBest loss: 2.028953\tAccuracy: 50.20%\n",
      "314\tValidation loss: 2.028228\tBest loss: 2.028228\tAccuracy: 50.50%\n",
      "315\tValidation loss: 2.023858\tBest loss: 2.023858\tAccuracy: 51.00%\n",
      "316\tValidation loss: 2.029050\tBest loss: 2.023858\tAccuracy: 50.20%\n",
      "317\tValidation loss: 2.020813\tBest loss: 2.020813\tAccuracy: 50.30%\n",
      "318\tValidation loss: 2.018958\tBest loss: 2.018958\tAccuracy: 50.60%\n",
      "319\tValidation loss: 2.019120\tBest loss: 2.018958\tAccuracy: 51.40%\n",
      "320\tValidation loss: 2.019560\tBest loss: 2.018958\tAccuracy: 50.40%\n",
      "321\tValidation loss: 2.020833\tBest loss: 2.018958\tAccuracy: 50.40%\n",
      "322\tValidation loss: 2.015224\tBest loss: 2.015224\tAccuracy: 51.00%\n",
      "323\tValidation loss: 2.010947\tBest loss: 2.010947\tAccuracy: 51.40%\n",
      "324\tValidation loss: 2.006685\tBest loss: 2.006685\tAccuracy: 50.80%\n",
      "325\tValidation loss: 2.008092\tBest loss: 2.006685\tAccuracy: 50.80%\n",
      "326\tValidation loss: 2.004729\tBest loss: 2.004729\tAccuracy: 51.00%\n",
      "327\tValidation loss: 2.009120\tBest loss: 2.004729\tAccuracy: 50.90%\n",
      "328\tValidation loss: 2.006795\tBest loss: 2.004729\tAccuracy: 51.10%\n",
      "329\tValidation loss: 2.008424\tBest loss: 2.004729\tAccuracy: 50.60%\n",
      "330\tValidation loss: 2.004368\tBest loss: 2.004368\tAccuracy: 50.80%\n",
      "331\tValidation loss: 1.998930\tBest loss: 1.998930\tAccuracy: 51.10%\n",
      "332\tValidation loss: 1.996325\tBest loss: 1.996325\tAccuracy: 51.20%\n",
      "333\tValidation loss: 1.995960\tBest loss: 1.995960\tAccuracy: 51.20%\n",
      "334\tValidation loss: 1.994614\tBest loss: 1.994614\tAccuracy: 51.30%\n",
      "335\tValidation loss: 1.998308\tBest loss: 1.994614\tAccuracy: 50.90%\n",
      "336\tValidation loss: 1.992207\tBest loss: 1.992207\tAccuracy: 50.90%\n",
      "337\tValidation loss: 1.991142\tBest loss: 1.991142\tAccuracy: 51.10%\n",
      "338\tValidation loss: 1.987466\tBest loss: 1.987466\tAccuracy: 51.40%\n",
      "339\tValidation loss: 1.988169\tBest loss: 1.987466\tAccuracy: 50.50%\n",
      "340\tValidation loss: 1.992329\tBest loss: 1.987466\tAccuracy: 50.90%\n",
      "341\tValidation loss: 1.985359\tBest loss: 1.985359\tAccuracy: 50.90%\n",
      "342\tValidation loss: 1.984459\tBest loss: 1.984459\tAccuracy: 51.40%\n",
      "343\tValidation loss: 1.981296\tBest loss: 1.981296\tAccuracy: 52.00%\n",
      "344\tValidation loss: 1.984236\tBest loss: 1.981296\tAccuracy: 52.20%\n",
      "345\tValidation loss: 1.982269\tBest loss: 1.981296\tAccuracy: 52.00%\n",
      "346\tValidation loss: 1.979167\tBest loss: 1.979167\tAccuracy: 51.90%\n",
      "347\tValidation loss: 1.979587\tBest loss: 1.979167\tAccuracy: 52.10%\n",
      "348\tValidation loss: 1.975306\tBest loss: 1.975306\tAccuracy: 52.50%\n",
      "349\tValidation loss: 1.970595\tBest loss: 1.970595\tAccuracy: 52.60%\n",
      "350\tValidation loss: 1.971318\tBest loss: 1.970595\tAccuracy: 52.20%\n",
      "351\tValidation loss: 1.972645\tBest loss: 1.970595\tAccuracy: 51.80%\n",
      "352\tValidation loss: 1.967615\tBest loss: 1.967615\tAccuracy: 51.70%\n",
      "353\tValidation loss: 1.969406\tBest loss: 1.967615\tAccuracy: 51.70%\n",
      "354\tValidation loss: 1.972380\tBest loss: 1.967615\tAccuracy: 52.40%\n",
      "355\tValidation loss: 1.969770\tBest loss: 1.967615\tAccuracy: 51.70%\n",
      "356\tValidation loss: 1.967160\tBest loss: 1.967160\tAccuracy: 52.10%\n",
      "357\tValidation loss: 1.965184\tBest loss: 1.965184\tAccuracy: 52.50%\n",
      "358\tValidation loss: 1.966080\tBest loss: 1.965184\tAccuracy: 52.60%\n",
      "359\tValidation loss: 1.969450\tBest loss: 1.965184\tAccuracy: 52.20%\n",
      "360\tValidation loss: 1.967010\tBest loss: 1.965184\tAccuracy: 52.40%\n",
      "361\tValidation loss: 1.964535\tBest loss: 1.964535\tAccuracy: 52.90%\n",
      "362\tValidation loss: 1.964092\tBest loss: 1.964092\tAccuracy: 51.40%\n",
      "363\tValidation loss: 1.964539\tBest loss: 1.964092\tAccuracy: 52.20%\n",
      "364\tValidation loss: 1.966058\tBest loss: 1.964092\tAccuracy: 51.70%\n",
      "365\tValidation loss: 1.956836\tBest loss: 1.956836\tAccuracy: 52.30%\n",
      "366\tValidation loss: 1.956069\tBest loss: 1.956069\tAccuracy: 52.90%\n",
      "367\tValidation loss: 1.953028\tBest loss: 1.953028\tAccuracy: 53.00%\n",
      "368\tValidation loss: 1.957300\tBest loss: 1.953028\tAccuracy: 52.20%\n",
      "369\tValidation loss: 1.954027\tBest loss: 1.953028\tAccuracy: 53.10%\n",
      "370\tValidation loss: 1.955301\tBest loss: 1.953028\tAccuracy: 53.20%\n",
      "371\tValidation loss: 1.951443\tBest loss: 1.951443\tAccuracy: 53.10%\n",
      "372\tValidation loss: 1.951337\tBest loss: 1.951337\tAccuracy: 53.20%\n",
      "373\tValidation loss: 1.950129\tBest loss: 1.950129\tAccuracy: 53.00%\n",
      "374\tValidation loss: 1.950326\tBest loss: 1.950129\tAccuracy: 53.70%\n",
      "375\tValidation loss: 1.949820\tBest loss: 1.949820\tAccuracy: 53.20%\n",
      "376\tValidation loss: 1.948223\tBest loss: 1.948223\tAccuracy: 53.30%\n",
      "377\tValidation loss: 1.944200\tBest loss: 1.944200\tAccuracy: 53.10%\n",
      "378\tValidation loss: 1.945946\tBest loss: 1.944200\tAccuracy: 53.40%\n",
      "379\tValidation loss: 1.941536\tBest loss: 1.941536\tAccuracy: 53.40%\n",
      "380\tValidation loss: 1.940358\tBest loss: 1.940358\tAccuracy: 53.10%\n",
      "381\tValidation loss: 1.940743\tBest loss: 1.940358\tAccuracy: 53.20%\n",
      "382\tValidation loss: 1.938912\tBest loss: 1.938912\tAccuracy: 53.80%\n",
      "383\tValidation loss: 1.940968\tBest loss: 1.938912\tAccuracy: 52.70%\n",
      "384\tValidation loss: 1.936648\tBest loss: 1.936648\tAccuracy: 53.30%\n",
      "385\tValidation loss: 1.933064\tBest loss: 1.933064\tAccuracy: 54.00%\n",
      "386\tValidation loss: 1.934669\tBest loss: 1.933064\tAccuracy: 53.70%\n",
      "387\tValidation loss: 1.935925\tBest loss: 1.933064\tAccuracy: 53.60%\n",
      "388\tValidation loss: 1.933787\tBest loss: 1.933064\tAccuracy: 53.70%\n",
      "389\tValidation loss: 1.938693\tBest loss: 1.933064\tAccuracy: 53.60%\n",
      "390\tValidation loss: 1.933853\tBest loss: 1.933064\tAccuracy: 53.30%\n",
      "391\tValidation loss: 1.934622\tBest loss: 1.933064\tAccuracy: 53.40%\n",
      "392\tValidation loss: 1.930452\tBest loss: 1.930452\tAccuracy: 54.20%\n",
      "393\tValidation loss: 1.929610\tBest loss: 1.929610\tAccuracy: 54.00%\n",
      "394\tValidation loss: 1.927466\tBest loss: 1.927466\tAccuracy: 54.00%\n",
      "395\tValidation loss: 1.930004\tBest loss: 1.927466\tAccuracy: 53.40%\n",
      "396\tValidation loss: 1.924983\tBest loss: 1.924983\tAccuracy: 53.80%\n",
      "397\tValidation loss: 1.924697\tBest loss: 1.924697\tAccuracy: 53.70%\n",
      "398\tValidation loss: 1.923140\tBest loss: 1.923140\tAccuracy: 53.20%\n",
      "399\tValidation loss: 1.920749\tBest loss: 1.920749\tAccuracy: 54.30%\n",
      "400\tValidation loss: 1.914655\tBest loss: 1.914655\tAccuracy: 53.80%\n",
      "401\tValidation loss: 1.918713\tBest loss: 1.914655\tAccuracy: 53.30%\n",
      "402\tValidation loss: 1.921583\tBest loss: 1.914655\tAccuracy: 54.00%\n",
      "403\tValidation loss: 1.916983\tBest loss: 1.914655\tAccuracy: 53.40%\n",
      "404\tValidation loss: 1.917605\tBest loss: 1.914655\tAccuracy: 53.20%\n",
      "405\tValidation loss: 1.918130\tBest loss: 1.914655\tAccuracy: 53.70%\n",
      "406\tValidation loss: 1.914975\tBest loss: 1.914655\tAccuracy: 53.70%\n",
      "407\tValidation loss: 1.913584\tBest loss: 1.913584\tAccuracy: 53.70%\n",
      "408\tValidation loss: 1.914511\tBest loss: 1.913584\tAccuracy: 53.40%\n",
      "409\tValidation loss: 1.913697\tBest loss: 1.913584\tAccuracy: 53.60%\n",
      "410\tValidation loss: 1.909202\tBest loss: 1.909202\tAccuracy: 53.90%\n",
      "411\tValidation loss: 1.909377\tBest loss: 1.909202\tAccuracy: 53.70%\n",
      "412\tValidation loss: 1.910008\tBest loss: 1.909202\tAccuracy: 53.40%\n",
      "413\tValidation loss: 1.912293\tBest loss: 1.909202\tAccuracy: 53.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\tValidation loss: 1.909069\tBest loss: 1.909069\tAccuracy: 53.50%\n",
      "415\tValidation loss: 1.906184\tBest loss: 1.906184\tAccuracy: 53.80%\n",
      "416\tValidation loss: 1.904971\tBest loss: 1.904971\tAccuracy: 53.50%\n",
      "417\tValidation loss: 1.903580\tBest loss: 1.903580\tAccuracy: 53.90%\n",
      "418\tValidation loss: 1.905478\tBest loss: 1.903580\tAccuracy: 54.10%\n",
      "419\tValidation loss: 1.902373\tBest loss: 1.902373\tAccuracy: 53.70%\n",
      "420\tValidation loss: 1.901433\tBest loss: 1.901433\tAccuracy: 54.10%\n",
      "421\tValidation loss: 1.902020\tBest loss: 1.901433\tAccuracy: 54.00%\n",
      "422\tValidation loss: 1.901192\tBest loss: 1.901192\tAccuracy: 53.80%\n",
      "423\tValidation loss: 1.900240\tBest loss: 1.900240\tAccuracy: 53.20%\n",
      "424\tValidation loss: 1.898190\tBest loss: 1.898190\tAccuracy: 53.70%\n",
      "425\tValidation loss: 1.898091\tBest loss: 1.898091\tAccuracy: 53.50%\n",
      "426\tValidation loss: 1.897522\tBest loss: 1.897522\tAccuracy: 53.40%\n",
      "427\tValidation loss: 1.894596\tBest loss: 1.894596\tAccuracy: 54.00%\n",
      "428\tValidation loss: 1.897695\tBest loss: 1.894596\tAccuracy: 53.90%\n",
      "429\tValidation loss: 1.895809\tBest loss: 1.894596\tAccuracy: 53.90%\n",
      "430\tValidation loss: 1.892353\tBest loss: 1.892353\tAccuracy: 53.50%\n",
      "431\tValidation loss: 1.893437\tBest loss: 1.892353\tAccuracy: 53.90%\n",
      "432\tValidation loss: 1.890399\tBest loss: 1.890399\tAccuracy: 54.20%\n",
      "433\tValidation loss: 1.889915\tBest loss: 1.889915\tAccuracy: 53.90%\n",
      "434\tValidation loss: 1.888726\tBest loss: 1.888726\tAccuracy: 53.90%\n",
      "435\tValidation loss: 1.889591\tBest loss: 1.888726\tAccuracy: 53.40%\n",
      "436\tValidation loss: 1.885585\tBest loss: 1.885585\tAccuracy: 53.70%\n",
      "437\tValidation loss: 1.884734\tBest loss: 1.884734\tAccuracy: 53.80%\n",
      "438\tValidation loss: 1.886864\tBest loss: 1.884734\tAccuracy: 53.80%\n",
      "439\tValidation loss: 1.885288\tBest loss: 1.884734\tAccuracy: 53.70%\n",
      "440\tValidation loss: 1.881889\tBest loss: 1.881889\tAccuracy: 53.70%\n",
      "441\tValidation loss: 1.881311\tBest loss: 1.881311\tAccuracy: 53.50%\n",
      "442\tValidation loss: 1.884953\tBest loss: 1.881311\tAccuracy: 53.50%\n",
      "443\tValidation loss: 1.878985\tBest loss: 1.878985\tAccuracy: 54.00%\n",
      "444\tValidation loss: 1.878129\tBest loss: 1.878129\tAccuracy: 53.60%\n",
      "445\tValidation loss: 1.877827\tBest loss: 1.877827\tAccuracy: 53.50%\n",
      "446\tValidation loss: 1.877740\tBest loss: 1.877740\tAccuracy: 54.10%\n",
      "447\tValidation loss: 1.878302\tBest loss: 1.877740\tAccuracy: 53.40%\n",
      "448\tValidation loss: 1.880532\tBest loss: 1.877740\tAccuracy: 54.00%\n",
      "449\tValidation loss: 1.879836\tBest loss: 1.877740\tAccuracy: 54.20%\n",
      "450\tValidation loss: 1.879370\tBest loss: 1.877740\tAccuracy: 53.80%\n",
      "451\tValidation loss: 1.878467\tBest loss: 1.877740\tAccuracy: 53.80%\n",
      "452\tValidation loss: 1.875333\tBest loss: 1.875333\tAccuracy: 53.30%\n",
      "453\tValidation loss: 1.874931\tBest loss: 1.874931\tAccuracy: 53.50%\n",
      "454\tValidation loss: 1.874395\tBest loss: 1.874395\tAccuracy: 53.80%\n",
      "455\tValidation loss: 1.872919\tBest loss: 1.872919\tAccuracy: 53.60%\n",
      "456\tValidation loss: 1.873876\tBest loss: 1.872919\tAccuracy: 53.40%\n",
      "457\tValidation loss: 1.870548\tBest loss: 1.870548\tAccuracy: 53.60%\n",
      "458\tValidation loss: 1.870181\tBest loss: 1.870181\tAccuracy: 53.30%\n",
      "459\tValidation loss: 1.870498\tBest loss: 1.870181\tAccuracy: 53.80%\n",
      "460\tValidation loss: 1.870626\tBest loss: 1.870181\tAccuracy: 53.30%\n",
      "461\tValidation loss: 1.868904\tBest loss: 1.868904\tAccuracy: 53.50%\n",
      "462\tValidation loss: 1.868934\tBest loss: 1.868904\tAccuracy: 53.50%\n",
      "463\tValidation loss: 1.864945\tBest loss: 1.864945\tAccuracy: 52.70%\n",
      "464\tValidation loss: 1.867646\tBest loss: 1.864945\tAccuracy: 53.40%\n",
      "465\tValidation loss: 1.865622\tBest loss: 1.864945\tAccuracy: 53.80%\n",
      "466\tValidation loss: 1.864478\tBest loss: 1.864478\tAccuracy: 53.60%\n",
      "467\tValidation loss: 1.865597\tBest loss: 1.864478\tAccuracy: 53.50%\n",
      "468\tValidation loss: 1.863211\tBest loss: 1.863211\tAccuracy: 53.70%\n",
      "469\tValidation loss: 1.865050\tBest loss: 1.863211\tAccuracy: 53.10%\n",
      "470\tValidation loss: 1.864486\tBest loss: 1.863211\tAccuracy: 53.70%\n",
      "471\tValidation loss: 1.858904\tBest loss: 1.858904\tAccuracy: 53.70%\n",
      "472\tValidation loss: 1.855951\tBest loss: 1.855951\tAccuracy: 53.80%\n",
      "473\tValidation loss: 1.858038\tBest loss: 1.855951\tAccuracy: 53.60%\n",
      "474\tValidation loss: 1.857367\tBest loss: 1.855951\tAccuracy: 53.60%\n",
      "475\tValidation loss: 1.855188\tBest loss: 1.855188\tAccuracy: 53.60%\n",
      "476\tValidation loss: 1.854249\tBest loss: 1.854249\tAccuracy: 53.40%\n",
      "477\tValidation loss: 1.854764\tBest loss: 1.854249\tAccuracy: 53.40%\n",
      "478\tValidation loss: 1.851937\tBest loss: 1.851937\tAccuracy: 53.50%\n",
      "479\tValidation loss: 1.853883\tBest loss: 1.851937\tAccuracy: 53.50%\n",
      "480\tValidation loss: 1.855199\tBest loss: 1.851937\tAccuracy: 53.50%\n",
      "481\tValidation loss: 1.850370\tBest loss: 1.850370\tAccuracy: 53.20%\n",
      "482\tValidation loss: 1.852772\tBest loss: 1.850370\tAccuracy: 53.40%\n",
      "483\tValidation loss: 1.849278\tBest loss: 1.849278\tAccuracy: 53.30%\n",
      "484\tValidation loss: 1.848811\tBest loss: 1.848811\tAccuracy: 53.10%\n",
      "485\tValidation loss: 1.848678\tBest loss: 1.848678\tAccuracy: 53.40%\n",
      "486\tValidation loss: 1.845020\tBest loss: 1.845020\tAccuracy: 53.30%\n",
      "487\tValidation loss: 1.846358\tBest loss: 1.845020\tAccuracy: 54.00%\n",
      "488\tValidation loss: 1.846414\tBest loss: 1.845020\tAccuracy: 53.60%\n",
      "489\tValidation loss: 1.844939\tBest loss: 1.844939\tAccuracy: 54.20%\n",
      "490\tValidation loss: 1.845432\tBest loss: 1.844939\tAccuracy: 53.60%\n",
      "491\tValidation loss: 1.844298\tBest loss: 1.844298\tAccuracy: 54.10%\n",
      "492\tValidation loss: 1.844703\tBest loss: 1.844298\tAccuracy: 53.50%\n",
      "493\tValidation loss: 1.844776\tBest loss: 1.844298\tAccuracy: 53.80%\n",
      "494\tValidation loss: 1.843005\tBest loss: 1.843005\tAccuracy: 53.90%\n",
      "495\tValidation loss: 1.843786\tBest loss: 1.843005\tAccuracy: 53.50%\n",
      "496\tValidation loss: 1.845552\tBest loss: 1.843005\tAccuracy: 53.80%\n",
      "497\tValidation loss: 1.843177\tBest loss: 1.843005\tAccuracy: 52.90%\n",
      "498\tValidation loss: 1.839026\tBest loss: 1.839026\tAccuracy: 53.60%\n",
      "499\tValidation loss: 1.840954\tBest loss: 1.839026\tAccuracy: 53.80%\n",
      "500\tValidation loss: 1.838114\tBest loss: 1.838114\tAccuracy: 53.30%\n",
      "501\tValidation loss: 1.837554\tBest loss: 1.837554\tAccuracy: 53.00%\n",
      "502\tValidation loss: 1.838848\tBest loss: 1.837554\tAccuracy: 54.00%\n",
      "503\tValidation loss: 1.837125\tBest loss: 1.837125\tAccuracy: 52.70%\n",
      "504\tValidation loss: 1.838659\tBest loss: 1.837125\tAccuracy: 53.20%\n",
      "505\tValidation loss: 1.833886\tBest loss: 1.833886\tAccuracy: 53.50%\n",
      "506\tValidation loss: 1.835625\tBest loss: 1.833886\tAccuracy: 53.10%\n",
      "507\tValidation loss: 1.834467\tBest loss: 1.833886\tAccuracy: 54.00%\n",
      "508\tValidation loss: 1.831833\tBest loss: 1.831833\tAccuracy: 53.80%\n",
      "509\tValidation loss: 1.836700\tBest loss: 1.831833\tAccuracy: 53.20%\n",
      "510\tValidation loss: 1.836122\tBest loss: 1.831833\tAccuracy: 53.00%\n",
      "511\tValidation loss: 1.835739\tBest loss: 1.831833\tAccuracy: 54.00%\n",
      "512\tValidation loss: 1.834281\tBest loss: 1.831833\tAccuracy: 53.10%\n",
      "513\tValidation loss: 1.831251\tBest loss: 1.831251\tAccuracy: 53.60%\n",
      "514\tValidation loss: 1.834406\tBest loss: 1.831251\tAccuracy: 53.30%\n",
      "515\tValidation loss: 1.830526\tBest loss: 1.830526\tAccuracy: 53.80%\n",
      "516\tValidation loss: 1.830936\tBest loss: 1.830526\tAccuracy: 54.20%\n",
      "517\tValidation loss: 1.830928\tBest loss: 1.830526\tAccuracy: 53.70%\n",
      "518\tValidation loss: 1.828642\tBest loss: 1.828642\tAccuracy: 53.30%\n",
      "519\tValidation loss: 1.826459\tBest loss: 1.826459\tAccuracy: 54.00%\n",
      "520\tValidation loss: 1.827930\tBest loss: 1.826459\tAccuracy: 54.20%\n",
      "521\tValidation loss: 1.825652\tBest loss: 1.825652\tAccuracy: 53.60%\n",
      "522\tValidation loss: 1.823779\tBest loss: 1.823779\tAccuracy: 53.20%\n",
      "523\tValidation loss: 1.822587\tBest loss: 1.822587\tAccuracy: 53.60%\n",
      "524\tValidation loss: 1.825349\tBest loss: 1.822587\tAccuracy: 53.80%\n",
      "525\tValidation loss: 1.821962\tBest loss: 1.821962\tAccuracy: 54.00%\n",
      "526\tValidation loss: 1.824481\tBest loss: 1.821962\tAccuracy: 54.20%\n",
      "527\tValidation loss: 1.823483\tBest loss: 1.821962\tAccuracy: 53.50%\n",
      "528\tValidation loss: 1.824347\tBest loss: 1.821962\tAccuracy: 53.80%\n",
      "529\tValidation loss: 1.822609\tBest loss: 1.821962\tAccuracy: 53.80%\n",
      "530\tValidation loss: 1.820676\tBest loss: 1.820676\tAccuracy: 53.80%\n",
      "531\tValidation loss: 1.820354\tBest loss: 1.820354\tAccuracy: 53.20%\n",
      "532\tValidation loss: 1.821835\tBest loss: 1.820354\tAccuracy: 54.40%\n",
      "533\tValidation loss: 1.818084\tBest loss: 1.818084\tAccuracy: 53.80%\n",
      "534\tValidation loss: 1.818502\tBest loss: 1.818084\tAccuracy: 54.30%\n",
      "535\tValidation loss: 1.820917\tBest loss: 1.818084\tAccuracy: 53.60%\n",
      "536\tValidation loss: 1.820517\tBest loss: 1.818084\tAccuracy: 53.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\tValidation loss: 1.819968\tBest loss: 1.818084\tAccuracy: 53.90%\n",
      "538\tValidation loss: 1.817257\tBest loss: 1.817257\tAccuracy: 54.40%\n",
      "539\tValidation loss: 1.817544\tBest loss: 1.817257\tAccuracy: 53.90%\n",
      "540\tValidation loss: 1.818144\tBest loss: 1.817257\tAccuracy: 54.00%\n",
      "541\tValidation loss: 1.818181\tBest loss: 1.817257\tAccuracy: 54.10%\n",
      "542\tValidation loss: 1.818988\tBest loss: 1.817257\tAccuracy: 54.30%\n",
      "543\tValidation loss: 1.815025\tBest loss: 1.815025\tAccuracy: 55.30%\n",
      "544\tValidation loss: 1.815562\tBest loss: 1.815025\tAccuracy: 54.20%\n",
      "545\tValidation loss: 1.816725\tBest loss: 1.815025\tAccuracy: 54.50%\n",
      "546\tValidation loss: 1.810720\tBest loss: 1.810720\tAccuracy: 54.20%\n",
      "547\tValidation loss: 1.810469\tBest loss: 1.810469\tAccuracy: 54.60%\n",
      "548\tValidation loss: 1.811666\tBest loss: 1.810469\tAccuracy: 54.60%\n",
      "549\tValidation loss: 1.813004\tBest loss: 1.810469\tAccuracy: 54.00%\n",
      "550\tValidation loss: 1.809068\tBest loss: 1.809068\tAccuracy: 54.10%\n",
      "551\tValidation loss: 1.810185\tBest loss: 1.809068\tAccuracy: 54.50%\n",
      "552\tValidation loss: 1.812222\tBest loss: 1.809068\tAccuracy: 54.10%\n",
      "553\tValidation loss: 1.809552\tBest loss: 1.809068\tAccuracy: 54.30%\n",
      "554\tValidation loss: 1.807299\tBest loss: 1.807299\tAccuracy: 54.10%\n",
      "555\tValidation loss: 1.810507\tBest loss: 1.807299\tAccuracy: 53.90%\n",
      "556\tValidation loss: 1.811585\tBest loss: 1.807299\tAccuracy: 54.30%\n",
      "557\tValidation loss: 1.805101\tBest loss: 1.805101\tAccuracy: 54.30%\n",
      "558\tValidation loss: 1.804543\tBest loss: 1.804543\tAccuracy: 54.40%\n",
      "559\tValidation loss: 1.804311\tBest loss: 1.804311\tAccuracy: 54.90%\n",
      "560\tValidation loss: 1.802904\tBest loss: 1.802904\tAccuracy: 55.20%\n",
      "561\tValidation loss: 1.806118\tBest loss: 1.802904\tAccuracy: 54.20%\n",
      "562\tValidation loss: 1.806673\tBest loss: 1.802904\tAccuracy: 54.60%\n",
      "563\tValidation loss: 1.807993\tBest loss: 1.802904\tAccuracy: 55.20%\n",
      "564\tValidation loss: 1.806642\tBest loss: 1.802904\tAccuracy: 54.70%\n",
      "565\tValidation loss: 1.806453\tBest loss: 1.802904\tAccuracy: 54.80%\n",
      "566\tValidation loss: 1.804213\tBest loss: 1.802904\tAccuracy: 54.90%\n",
      "567\tValidation loss: 1.808887\tBest loss: 1.802904\tAccuracy: 55.10%\n",
      "568\tValidation loss: 1.803827\tBest loss: 1.802904\tAccuracy: 54.70%\n",
      "569\tValidation loss: 1.800743\tBest loss: 1.800743\tAccuracy: 54.70%\n",
      "570\tValidation loss: 1.799634\tBest loss: 1.799634\tAccuracy: 54.90%\n",
      "571\tValidation loss: 1.796968\tBest loss: 1.796968\tAccuracy: 54.60%\n",
      "572\tValidation loss: 1.796831\tBest loss: 1.796831\tAccuracy: 55.10%\n",
      "573\tValidation loss: 1.797733\tBest loss: 1.796831\tAccuracy: 54.60%\n",
      "574\tValidation loss: 1.795629\tBest loss: 1.795629\tAccuracy: 54.60%\n",
      "575\tValidation loss: 1.793847\tBest loss: 1.793847\tAccuracy: 54.80%\n",
      "576\tValidation loss: 1.792271\tBest loss: 1.792271\tAccuracy: 54.60%\n",
      "577\tValidation loss: 1.795177\tBest loss: 1.792271\tAccuracy: 54.50%\n",
      "578\tValidation loss: 1.795086\tBest loss: 1.792271\tAccuracy: 54.50%\n",
      "579\tValidation loss: 1.796565\tBest loss: 1.792271\tAccuracy: 54.00%\n",
      "580\tValidation loss: 1.794766\tBest loss: 1.792271\tAccuracy: 54.80%\n",
      "581\tValidation loss: 1.793099\tBest loss: 1.792271\tAccuracy: 54.20%\n",
      "582\tValidation loss: 1.792463\tBest loss: 1.792271\tAccuracy: 54.60%\n",
      "583\tValidation loss: 1.792524\tBest loss: 1.792271\tAccuracy: 54.60%\n",
      "584\tValidation loss: 1.792997\tBest loss: 1.792271\tAccuracy: 54.70%\n",
      "585\tValidation loss: 1.789711\tBest loss: 1.789711\tAccuracy: 54.70%\n",
      "586\tValidation loss: 1.788398\tBest loss: 1.788398\tAccuracy: 54.50%\n",
      "587\tValidation loss: 1.790268\tBest loss: 1.788398\tAccuracy: 54.60%\n",
      "588\tValidation loss: 1.790005\tBest loss: 1.788398\tAccuracy: 54.80%\n",
      "589\tValidation loss: 1.787807\tBest loss: 1.787807\tAccuracy: 54.00%\n",
      "590\tValidation loss: 1.790644\tBest loss: 1.787807\tAccuracy: 54.30%\n",
      "591\tValidation loss: 1.789564\tBest loss: 1.787807\tAccuracy: 54.90%\n",
      "592\tValidation loss: 1.788983\tBest loss: 1.787807\tAccuracy: 55.00%\n",
      "593\tValidation loss: 1.789177\tBest loss: 1.787807\tAccuracy: 54.80%\n",
      "594\tValidation loss: 1.786491\tBest loss: 1.786491\tAccuracy: 54.90%\n",
      "595\tValidation loss: 1.784394\tBest loss: 1.784394\tAccuracy: 54.50%\n",
      "596\tValidation loss: 1.784742\tBest loss: 1.784394\tAccuracy: 55.30%\n",
      "597\tValidation loss: 1.782468\tBest loss: 1.782468\tAccuracy: 54.70%\n",
      "598\tValidation loss: 1.782920\tBest loss: 1.782468\tAccuracy: 55.20%\n",
      "599\tValidation loss: 1.785427\tBest loss: 1.782468\tAccuracy: 55.00%\n",
      "600\tValidation loss: 1.785312\tBest loss: 1.782468\tAccuracy: 54.90%\n",
      "601\tValidation loss: 1.782884\tBest loss: 1.782468\tAccuracy: 54.80%\n",
      "602\tValidation loss: 1.783021\tBest loss: 1.782468\tAccuracy: 55.90%\n",
      "603\tValidation loss: 1.781125\tBest loss: 1.781125\tAccuracy: 55.40%\n",
      "604\tValidation loss: 1.780884\tBest loss: 1.780884\tAccuracy: 55.30%\n",
      "605\tValidation loss: 1.782776\tBest loss: 1.780884\tAccuracy: 55.10%\n",
      "606\tValidation loss: 1.781308\tBest loss: 1.780884\tAccuracy: 55.10%\n",
      "607\tValidation loss: 1.779412\tBest loss: 1.779412\tAccuracy: 55.30%\n",
      "608\tValidation loss: 1.783689\tBest loss: 1.779412\tAccuracy: 55.60%\n",
      "609\tValidation loss: 1.779917\tBest loss: 1.779412\tAccuracy: 55.50%\n",
      "610\tValidation loss: 1.780115\tBest loss: 1.779412\tAccuracy: 55.70%\n",
      "611\tValidation loss: 1.777221\tBest loss: 1.777221\tAccuracy: 55.30%\n",
      "612\tValidation loss: 1.774217\tBest loss: 1.774217\tAccuracy: 55.60%\n",
      "613\tValidation loss: 1.778636\tBest loss: 1.774217\tAccuracy: 55.40%\n",
      "614\tValidation loss: 1.776478\tBest loss: 1.774217\tAccuracy: 55.50%\n",
      "615\tValidation loss: 1.777076\tBest loss: 1.774217\tAccuracy: 55.50%\n",
      "616\tValidation loss: 1.775681\tBest loss: 1.774217\tAccuracy: 55.00%\n",
      "617\tValidation loss: 1.776287\tBest loss: 1.774217\tAccuracy: 55.40%\n",
      "618\tValidation loss: 1.773785\tBest loss: 1.773785\tAccuracy: 55.30%\n",
      "619\tValidation loss: 1.774629\tBest loss: 1.773785\tAccuracy: 55.20%\n",
      "620\tValidation loss: 1.774682\tBest loss: 1.773785\tAccuracy: 55.70%\n",
      "621\tValidation loss: 1.773115\tBest loss: 1.773115\tAccuracy: 55.40%\n",
      "622\tValidation loss: 1.770688\tBest loss: 1.770688\tAccuracy: 55.70%\n",
      "623\tValidation loss: 1.771830\tBest loss: 1.770688\tAccuracy: 55.50%\n",
      "624\tValidation loss: 1.770280\tBest loss: 1.770280\tAccuracy: 55.20%\n",
      "625\tValidation loss: 1.769748\tBest loss: 1.769748\tAccuracy: 55.70%\n",
      "626\tValidation loss: 1.767831\tBest loss: 1.767831\tAccuracy: 55.50%\n",
      "627\tValidation loss: 1.768469\tBest loss: 1.767831\tAccuracy: 55.40%\n",
      "628\tValidation loss: 1.763504\tBest loss: 1.763504\tAccuracy: 55.60%\n",
      "629\tValidation loss: 1.764029\tBest loss: 1.763504\tAccuracy: 56.30%\n",
      "630\tValidation loss: 1.767926\tBest loss: 1.763504\tAccuracy: 55.70%\n",
      "631\tValidation loss: 1.765710\tBest loss: 1.763504\tAccuracy: 55.50%\n",
      "632\tValidation loss: 1.763132\tBest loss: 1.763132\tAccuracy: 55.40%\n",
      "633\tValidation loss: 1.763718\tBest loss: 1.763132\tAccuracy: 55.00%\n",
      "634\tValidation loss: 1.764229\tBest loss: 1.763132\tAccuracy: 55.50%\n",
      "635\tValidation loss: 1.764384\tBest loss: 1.763132\tAccuracy: 55.60%\n",
      "636\tValidation loss: 1.759857\tBest loss: 1.759857\tAccuracy: 55.50%\n",
      "637\tValidation loss: 1.763967\tBest loss: 1.759857\tAccuracy: 55.90%\n",
      "638\tValidation loss: 1.763782\tBest loss: 1.759857\tAccuracy: 55.70%\n",
      "639\tValidation loss: 1.762524\tBest loss: 1.759857\tAccuracy: 56.40%\n",
      "640\tValidation loss: 1.762866\tBest loss: 1.759857\tAccuracy: 56.40%\n",
      "641\tValidation loss: 1.758951\tBest loss: 1.758951\tAccuracy: 55.80%\n",
      "642\tValidation loss: 1.758271\tBest loss: 1.758271\tAccuracy: 55.90%\n",
      "643\tValidation loss: 1.756848\tBest loss: 1.756848\tAccuracy: 55.30%\n",
      "644\tValidation loss: 1.756883\tBest loss: 1.756848\tAccuracy: 55.40%\n",
      "645\tValidation loss: 1.757849\tBest loss: 1.756848\tAccuracy: 56.00%\n",
      "646\tValidation loss: 1.755884\tBest loss: 1.755884\tAccuracy: 55.80%\n",
      "647\tValidation loss: 1.756666\tBest loss: 1.755884\tAccuracy: 55.60%\n",
      "648\tValidation loss: 1.757165\tBest loss: 1.755884\tAccuracy: 56.00%\n",
      "649\tValidation loss: 1.755206\tBest loss: 1.755206\tAccuracy: 55.10%\n",
      "650\tValidation loss: 1.754635\tBest loss: 1.754635\tAccuracy: 55.10%\n",
      "651\tValidation loss: 1.756314\tBest loss: 1.754635\tAccuracy: 54.80%\n",
      "652\tValidation loss: 1.753678\tBest loss: 1.753678\tAccuracy: 55.70%\n",
      "653\tValidation loss: 1.753418\tBest loss: 1.753418\tAccuracy: 55.60%\n",
      "654\tValidation loss: 1.753396\tBest loss: 1.753396\tAccuracy: 56.10%\n",
      "655\tValidation loss: 1.751369\tBest loss: 1.751369\tAccuracy: 56.30%\n",
      "656\tValidation loss: 1.754108\tBest loss: 1.751369\tAccuracy: 55.90%\n",
      "657\tValidation loss: 1.752878\tBest loss: 1.751369\tAccuracy: 56.30%\n",
      "658\tValidation loss: 1.752792\tBest loss: 1.751369\tAccuracy: 56.20%\n",
      "659\tValidation loss: 1.753912\tBest loss: 1.751369\tAccuracy: 56.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660\tValidation loss: 1.752751\tBest loss: 1.751369\tAccuracy: 55.30%\n",
      "661\tValidation loss: 1.752946\tBest loss: 1.751369\tAccuracy: 55.50%\n",
      "662\tValidation loss: 1.752513\tBest loss: 1.751369\tAccuracy: 55.30%\n",
      "663\tValidation loss: 1.752636\tBest loss: 1.751369\tAccuracy: 55.80%\n",
      "664\tValidation loss: 1.751585\tBest loss: 1.751369\tAccuracy: 55.70%\n",
      "665\tValidation loss: 1.751388\tBest loss: 1.751369\tAccuracy: 56.10%\n",
      "666\tValidation loss: 1.751563\tBest loss: 1.751369\tAccuracy: 55.80%\n",
      "667\tValidation loss: 1.750729\tBest loss: 1.750729\tAccuracy: 56.50%\n",
      "668\tValidation loss: 1.750369\tBest loss: 1.750369\tAccuracy: 56.30%\n",
      "669\tValidation loss: 1.750891\tBest loss: 1.750369\tAccuracy: 56.40%\n",
      "670\tValidation loss: 1.750778\tBest loss: 1.750369\tAccuracy: 55.60%\n",
      "671\tValidation loss: 1.751178\tBest loss: 1.750369\tAccuracy: 55.80%\n",
      "672\tValidation loss: 1.751192\tBest loss: 1.750369\tAccuracy: 56.20%\n",
      "673\tValidation loss: 1.752267\tBest loss: 1.750369\tAccuracy: 55.60%\n",
      "674\tValidation loss: 1.748452\tBest loss: 1.748452\tAccuracy: 55.70%\n",
      "675\tValidation loss: 1.749291\tBest loss: 1.748452\tAccuracy: 56.00%\n",
      "676\tValidation loss: 1.749243\tBest loss: 1.748452\tAccuracy: 56.80%\n",
      "677\tValidation loss: 1.749569\tBest loss: 1.748452\tAccuracy: 56.40%\n",
      "678\tValidation loss: 1.746838\tBest loss: 1.746838\tAccuracy: 56.70%\n",
      "679\tValidation loss: 1.747211\tBest loss: 1.746838\tAccuracy: 56.20%\n",
      "680\tValidation loss: 1.745326\tBest loss: 1.745326\tAccuracy: 56.80%\n",
      "681\tValidation loss: 1.746051\tBest loss: 1.745326\tAccuracy: 56.60%\n",
      "682\tValidation loss: 1.748222\tBest loss: 1.745326\tAccuracy: 56.40%\n",
      "683\tValidation loss: 1.747838\tBest loss: 1.745326\tAccuracy: 56.40%\n",
      "684\tValidation loss: 1.744566\tBest loss: 1.744566\tAccuracy: 56.30%\n",
      "685\tValidation loss: 1.743153\tBest loss: 1.743153\tAccuracy: 56.40%\n",
      "686\tValidation loss: 1.743606\tBest loss: 1.743153\tAccuracy: 56.90%\n",
      "687\tValidation loss: 1.743815\tBest loss: 1.743153\tAccuracy: 56.60%\n",
      "688\tValidation loss: 1.742147\tBest loss: 1.742147\tAccuracy: 56.80%\n",
      "689\tValidation loss: 1.745017\tBest loss: 1.742147\tAccuracy: 56.60%\n",
      "690\tValidation loss: 1.742936\tBest loss: 1.742147\tAccuracy: 55.80%\n",
      "691\tValidation loss: 1.742623\tBest loss: 1.742147\tAccuracy: 56.10%\n",
      "692\tValidation loss: 1.742539\tBest loss: 1.742147\tAccuracy: 56.40%\n",
      "693\tValidation loss: 1.742171\tBest loss: 1.742147\tAccuracy: 56.40%\n",
      "694\tValidation loss: 1.743410\tBest loss: 1.742147\tAccuracy: 56.10%\n",
      "695\tValidation loss: 1.738419\tBest loss: 1.738419\tAccuracy: 56.40%\n",
      "696\tValidation loss: 1.741242\tBest loss: 1.738419\tAccuracy: 56.40%\n",
      "697\tValidation loss: 1.738348\tBest loss: 1.738348\tAccuracy: 55.70%\n",
      "698\tValidation loss: 1.741518\tBest loss: 1.738348\tAccuracy: 56.20%\n",
      "699\tValidation loss: 1.742264\tBest loss: 1.738348\tAccuracy: 56.00%\n",
      "700\tValidation loss: 1.741300\tBest loss: 1.738348\tAccuracy: 56.00%\n",
      "701\tValidation loss: 1.738516\tBest loss: 1.738348\tAccuracy: 56.40%\n",
      "702\tValidation loss: 1.737712\tBest loss: 1.737712\tAccuracy: 56.80%\n",
      "703\tValidation loss: 1.735289\tBest loss: 1.735289\tAccuracy: 56.50%\n",
      "704\tValidation loss: 1.734847\tBest loss: 1.734847\tAccuracy: 56.80%\n",
      "705\tValidation loss: 1.735642\tBest loss: 1.734847\tAccuracy: 56.10%\n",
      "706\tValidation loss: 1.739570\tBest loss: 1.734847\tAccuracy: 56.40%\n",
      "707\tValidation loss: 1.737150\tBest loss: 1.734847\tAccuracy: 56.30%\n",
      "708\tValidation loss: 1.738655\tBest loss: 1.734847\tAccuracy: 56.40%\n",
      "709\tValidation loss: 1.740456\tBest loss: 1.734847\tAccuracy: 56.80%\n",
      "710\tValidation loss: 1.738983\tBest loss: 1.734847\tAccuracy: 56.20%\n",
      "711\tValidation loss: 1.738715\tBest loss: 1.734847\tAccuracy: 56.70%\n",
      "712\tValidation loss: 1.738869\tBest loss: 1.734847\tAccuracy: 56.70%\n",
      "713\tValidation loss: 1.735046\tBest loss: 1.734847\tAccuracy: 56.00%\n",
      "714\tValidation loss: 1.736162\tBest loss: 1.734847\tAccuracy: 56.40%\n",
      "715\tValidation loss: 1.732248\tBest loss: 1.732248\tAccuracy: 56.40%\n",
      "716\tValidation loss: 1.737376\tBest loss: 1.732248\tAccuracy: 56.80%\n",
      "717\tValidation loss: 1.735632\tBest loss: 1.732248\tAccuracy: 56.50%\n",
      "718\tValidation loss: 1.735898\tBest loss: 1.732248\tAccuracy: 56.10%\n",
      "719\tValidation loss: 1.735853\tBest loss: 1.732248\tAccuracy: 55.60%\n",
      "720\tValidation loss: 1.735265\tBest loss: 1.732248\tAccuracy: 55.80%\n",
      "721\tValidation loss: 1.736425\tBest loss: 1.732248\tAccuracy: 55.60%\n",
      "722\tValidation loss: 1.736383\tBest loss: 1.732248\tAccuracy: 56.20%\n",
      "723\tValidation loss: 1.731508\tBest loss: 1.731508\tAccuracy: 55.60%\n",
      "724\tValidation loss: 1.730154\tBest loss: 1.730154\tAccuracy: 56.60%\n",
      "725\tValidation loss: 1.729453\tBest loss: 1.729453\tAccuracy: 56.20%\n",
      "726\tValidation loss: 1.728888\tBest loss: 1.728888\tAccuracy: 56.20%\n",
      "727\tValidation loss: 1.728794\tBest loss: 1.728794\tAccuracy: 56.20%\n",
      "728\tValidation loss: 1.729492\tBest loss: 1.728794\tAccuracy: 56.40%\n",
      "729\tValidation loss: 1.727180\tBest loss: 1.727180\tAccuracy: 56.30%\n",
      "730\tValidation loss: 1.730133\tBest loss: 1.727180\tAccuracy: 56.40%\n",
      "731\tValidation loss: 1.728462\tBest loss: 1.727180\tAccuracy: 56.10%\n",
      "732\tValidation loss: 1.728401\tBest loss: 1.727180\tAccuracy: 56.40%\n",
      "733\tValidation loss: 1.726714\tBest loss: 1.726714\tAccuracy: 56.30%\n",
      "734\tValidation loss: 1.728577\tBest loss: 1.726714\tAccuracy: 56.60%\n",
      "735\tValidation loss: 1.729058\tBest loss: 1.726714\tAccuracy: 56.10%\n",
      "736\tValidation loss: 1.727775\tBest loss: 1.726714\tAccuracy: 56.60%\n",
      "737\tValidation loss: 1.727547\tBest loss: 1.726714\tAccuracy: 57.00%\n",
      "738\tValidation loss: 1.726260\tBest loss: 1.726260\tAccuracy: 56.50%\n",
      "739\tValidation loss: 1.727197\tBest loss: 1.726260\tAccuracy: 56.50%\n",
      "740\tValidation loss: 1.727315\tBest loss: 1.726260\tAccuracy: 55.30%\n",
      "741\tValidation loss: 1.726292\tBest loss: 1.726260\tAccuracy: 55.80%\n",
      "742\tValidation loss: 1.728153\tBest loss: 1.726260\tAccuracy: 56.00%\n",
      "743\tValidation loss: 1.724631\tBest loss: 1.724631\tAccuracy: 56.00%\n",
      "744\tValidation loss: 1.722416\tBest loss: 1.722416\tAccuracy: 56.20%\n",
      "745\tValidation loss: 1.722551\tBest loss: 1.722416\tAccuracy: 56.10%\n",
      "746\tValidation loss: 1.722255\tBest loss: 1.722255\tAccuracy: 57.00%\n",
      "747\tValidation loss: 1.723031\tBest loss: 1.722255\tAccuracy: 57.30%\n",
      "748\tValidation loss: 1.723480\tBest loss: 1.722255\tAccuracy: 56.60%\n",
      "749\tValidation loss: 1.723097\tBest loss: 1.722255\tAccuracy: 56.50%\n",
      "750\tValidation loss: 1.724309\tBest loss: 1.722255\tAccuracy: 56.50%\n",
      "751\tValidation loss: 1.723737\tBest loss: 1.722255\tAccuracy: 56.60%\n",
      "752\tValidation loss: 1.722690\tBest loss: 1.722255\tAccuracy: 57.00%\n",
      "753\tValidation loss: 1.719568\tBest loss: 1.719568\tAccuracy: 56.80%\n",
      "754\tValidation loss: 1.723710\tBest loss: 1.719568\tAccuracy: 56.40%\n",
      "755\tValidation loss: 1.723162\tBest loss: 1.719568\tAccuracy: 56.30%\n",
      "756\tValidation loss: 1.723524\tBest loss: 1.719568\tAccuracy: 56.10%\n",
      "757\tValidation loss: 1.718935\tBest loss: 1.718935\tAccuracy: 56.90%\n",
      "758\tValidation loss: 1.719022\tBest loss: 1.718935\tAccuracy: 56.50%\n",
      "759\tValidation loss: 1.719065\tBest loss: 1.718935\tAccuracy: 56.90%\n",
      "760\tValidation loss: 1.718585\tBest loss: 1.718585\tAccuracy: 57.10%\n",
      "761\tValidation loss: 1.716957\tBest loss: 1.716957\tAccuracy: 56.90%\n",
      "762\tValidation loss: 1.716297\tBest loss: 1.716297\tAccuracy: 57.10%\n",
      "763\tValidation loss: 1.718382\tBest loss: 1.716297\tAccuracy: 57.10%\n",
      "764\tValidation loss: 1.716829\tBest loss: 1.716297\tAccuracy: 56.50%\n",
      "765\tValidation loss: 1.716860\tBest loss: 1.716297\tAccuracy: 56.80%\n",
      "766\tValidation loss: 1.714347\tBest loss: 1.714347\tAccuracy: 56.30%\n",
      "767\tValidation loss: 1.711864\tBest loss: 1.711864\tAccuracy: 56.80%\n",
      "768\tValidation loss: 1.713798\tBest loss: 1.711864\tAccuracy: 57.20%\n",
      "769\tValidation loss: 1.714617\tBest loss: 1.711864\tAccuracy: 56.40%\n",
      "770\tValidation loss: 1.714645\tBest loss: 1.711864\tAccuracy: 56.70%\n",
      "771\tValidation loss: 1.714365\tBest loss: 1.711864\tAccuracy: 56.20%\n",
      "772\tValidation loss: 1.711924\tBest loss: 1.711864\tAccuracy: 56.40%\n",
      "773\tValidation loss: 1.710353\tBest loss: 1.710353\tAccuracy: 57.00%\n",
      "774\tValidation loss: 1.711751\tBest loss: 1.710353\tAccuracy: 56.90%\n",
      "775\tValidation loss: 1.712440\tBest loss: 1.710353\tAccuracy: 57.20%\n",
      "776\tValidation loss: 1.710523\tBest loss: 1.710353\tAccuracy: 56.80%\n",
      "777\tValidation loss: 1.712186\tBest loss: 1.710353\tAccuracy: 56.80%\n",
      "778\tValidation loss: 1.713275\tBest loss: 1.710353\tAccuracy: 56.90%\n",
      "779\tValidation loss: 1.711287\tBest loss: 1.710353\tAccuracy: 56.80%\n",
      "780\tValidation loss: 1.711833\tBest loss: 1.710353\tAccuracy: 56.60%\n",
      "781\tValidation loss: 1.711344\tBest loss: 1.710353\tAccuracy: 56.20%\n",
      "782\tValidation loss: 1.711075\tBest loss: 1.710353\tAccuracy: 56.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783\tValidation loss: 1.712490\tBest loss: 1.710353\tAccuracy: 56.80%\n",
      "784\tValidation loss: 1.710217\tBest loss: 1.710217\tAccuracy: 56.60%\n",
      "785\tValidation loss: 1.710518\tBest loss: 1.710217\tAccuracy: 56.60%\n",
      "786\tValidation loss: 1.705916\tBest loss: 1.705916\tAccuracy: 56.90%\n",
      "787\tValidation loss: 1.707310\tBest loss: 1.705916\tAccuracy: 56.20%\n",
      "788\tValidation loss: 1.707401\tBest loss: 1.705916\tAccuracy: 56.70%\n",
      "789\tValidation loss: 1.706555\tBest loss: 1.705916\tAccuracy: 56.30%\n",
      "790\tValidation loss: 1.706736\tBest loss: 1.705916\tAccuracy: 56.90%\n",
      "791\tValidation loss: 1.703895\tBest loss: 1.703895\tAccuracy: 56.70%\n",
      "792\tValidation loss: 1.709094\tBest loss: 1.703895\tAccuracy: 56.60%\n",
      "793\tValidation loss: 1.708352\tBest loss: 1.703895\tAccuracy: 56.10%\n",
      "794\tValidation loss: 1.706065\tBest loss: 1.703895\tAccuracy: 56.80%\n",
      "795\tValidation loss: 1.704328\tBest loss: 1.703895\tAccuracy: 57.20%\n",
      "796\tValidation loss: 1.701940\tBest loss: 1.701940\tAccuracy: 56.40%\n",
      "797\tValidation loss: 1.707759\tBest loss: 1.701940\tAccuracy: 56.50%\n",
      "798\tValidation loss: 1.706204\tBest loss: 1.701940\tAccuracy: 57.10%\n",
      "799\tValidation loss: 1.705136\tBest loss: 1.701940\tAccuracy: 56.80%\n",
      "800\tValidation loss: 1.711758\tBest loss: 1.701940\tAccuracy: 56.80%\n",
      "801\tValidation loss: 1.707296\tBest loss: 1.701940\tAccuracy: 56.20%\n",
      "802\tValidation loss: 1.704779\tBest loss: 1.701940\tAccuracy: 56.50%\n",
      "803\tValidation loss: 1.708677\tBest loss: 1.701940\tAccuracy: 56.60%\n",
      "804\tValidation loss: 1.708151\tBest loss: 1.701940\tAccuracy: 56.80%\n",
      "805\tValidation loss: 1.706025\tBest loss: 1.701940\tAccuracy: 56.70%\n",
      "806\tValidation loss: 1.707216\tBest loss: 1.701940\tAccuracy: 57.20%\n",
      "807\tValidation loss: 1.706490\tBest loss: 1.701940\tAccuracy: 56.50%\n",
      "808\tValidation loss: 1.701535\tBest loss: 1.701535\tAccuracy: 56.50%\n",
      "809\tValidation loss: 1.699915\tBest loss: 1.699915\tAccuracy: 56.60%\n",
      "810\tValidation loss: 1.702328\tBest loss: 1.699915\tAccuracy: 57.00%\n",
      "811\tValidation loss: 1.702608\tBest loss: 1.699915\tAccuracy: 56.80%\n",
      "812\tValidation loss: 1.701556\tBest loss: 1.699915\tAccuracy: 56.60%\n",
      "813\tValidation loss: 1.700696\tBest loss: 1.699915\tAccuracy: 56.80%\n",
      "814\tValidation loss: 1.702067\tBest loss: 1.699915\tAccuracy: 56.90%\n",
      "815\tValidation loss: 1.703090\tBest loss: 1.699915\tAccuracy: 56.80%\n",
      "816\tValidation loss: 1.702238\tBest loss: 1.699915\tAccuracy: 56.70%\n",
      "817\tValidation loss: 1.701980\tBest loss: 1.699915\tAccuracy: 56.70%\n",
      "818\tValidation loss: 1.699191\tBest loss: 1.699191\tAccuracy: 56.50%\n",
      "819\tValidation loss: 1.700254\tBest loss: 1.699191\tAccuracy: 56.80%\n",
      "820\tValidation loss: 1.698147\tBest loss: 1.698147\tAccuracy: 57.40%\n",
      "821\tValidation loss: 1.699980\tBest loss: 1.698147\tAccuracy: 56.50%\n",
      "822\tValidation loss: 1.697014\tBest loss: 1.697014\tAccuracy: 56.60%\n",
      "823\tValidation loss: 1.697106\tBest loss: 1.697014\tAccuracy: 56.30%\n",
      "824\tValidation loss: 1.700613\tBest loss: 1.697014\tAccuracy: 57.00%\n",
      "825\tValidation loss: 1.699663\tBest loss: 1.697014\tAccuracy: 56.80%\n",
      "826\tValidation loss: 1.698138\tBest loss: 1.697014\tAccuracy: 56.80%\n",
      "827\tValidation loss: 1.698132\tBest loss: 1.697014\tAccuracy: 56.60%\n",
      "828\tValidation loss: 1.700819\tBest loss: 1.697014\tAccuracy: 56.20%\n",
      "829\tValidation loss: 1.700426\tBest loss: 1.697014\tAccuracy: 56.60%\n",
      "830\tValidation loss: 1.697495\tBest loss: 1.697014\tAccuracy: 56.80%\n",
      "831\tValidation loss: 1.696239\tBest loss: 1.696239\tAccuracy: 56.70%\n",
      "832\tValidation loss: 1.698441\tBest loss: 1.696239\tAccuracy: 57.40%\n",
      "833\tValidation loss: 1.697381\tBest loss: 1.696239\tAccuracy: 56.50%\n",
      "834\tValidation loss: 1.696637\tBest loss: 1.696239\tAccuracy: 56.80%\n",
      "835\tValidation loss: 1.695275\tBest loss: 1.695275\tAccuracy: 56.70%\n",
      "836\tValidation loss: 1.692968\tBest loss: 1.692968\tAccuracy: 57.10%\n",
      "837\tValidation loss: 1.692494\tBest loss: 1.692494\tAccuracy: 56.90%\n",
      "838\tValidation loss: 1.691868\tBest loss: 1.691868\tAccuracy: 56.90%\n",
      "839\tValidation loss: 1.691696\tBest loss: 1.691696\tAccuracy: 56.80%\n",
      "840\tValidation loss: 1.689430\tBest loss: 1.689430\tAccuracy: 57.10%\n",
      "841\tValidation loss: 1.691008\tBest loss: 1.689430\tAccuracy: 56.80%\n",
      "842\tValidation loss: 1.691313\tBest loss: 1.689430\tAccuracy: 57.00%\n",
      "843\tValidation loss: 1.690876\tBest loss: 1.689430\tAccuracy: 56.60%\n",
      "844\tValidation loss: 1.692741\tBest loss: 1.689430\tAccuracy: 57.20%\n",
      "845\tValidation loss: 1.690090\tBest loss: 1.689430\tAccuracy: 56.60%\n",
      "846\tValidation loss: 1.690615\tBest loss: 1.689430\tAccuracy: 57.10%\n",
      "847\tValidation loss: 1.692263\tBest loss: 1.689430\tAccuracy: 56.60%\n",
      "848\tValidation loss: 1.693071\tBest loss: 1.689430\tAccuracy: 56.00%\n",
      "849\tValidation loss: 1.690179\tBest loss: 1.689430\tAccuracy: 56.80%\n",
      "850\tValidation loss: 1.692168\tBest loss: 1.689430\tAccuracy: 57.00%\n",
      "851\tValidation loss: 1.691566\tBest loss: 1.689430\tAccuracy: 56.20%\n",
      "852\tValidation loss: 1.688492\tBest loss: 1.688492\tAccuracy: 56.50%\n",
      "853\tValidation loss: 1.688513\tBest loss: 1.688492\tAccuracy: 56.40%\n",
      "854\tValidation loss: 1.685926\tBest loss: 1.685926\tAccuracy: 56.50%\n",
      "855\tValidation loss: 1.686249\tBest loss: 1.685926\tAccuracy: 56.90%\n",
      "856\tValidation loss: 1.690366\tBest loss: 1.685926\tAccuracy: 56.50%\n",
      "857\tValidation loss: 1.690499\tBest loss: 1.685926\tAccuracy: 56.70%\n",
      "858\tValidation loss: 1.687566\tBest loss: 1.685926\tAccuracy: 56.40%\n",
      "859\tValidation loss: 1.686916\tBest loss: 1.685926\tAccuracy: 56.90%\n",
      "860\tValidation loss: 1.688235\tBest loss: 1.685926\tAccuracy: 56.20%\n",
      "861\tValidation loss: 1.687437\tBest loss: 1.685926\tAccuracy: 56.60%\n",
      "862\tValidation loss: 1.688300\tBest loss: 1.685926\tAccuracy: 56.50%\n",
      "863\tValidation loss: 1.685718\tBest loss: 1.685718\tAccuracy: 56.50%\n",
      "864\tValidation loss: 1.687974\tBest loss: 1.685718\tAccuracy: 56.70%\n",
      "865\tValidation loss: 1.685022\tBest loss: 1.685022\tAccuracy: 56.80%\n",
      "866\tValidation loss: 1.685151\tBest loss: 1.685022\tAccuracy: 57.40%\n",
      "867\tValidation loss: 1.686810\tBest loss: 1.685022\tAccuracy: 56.70%\n",
      "868\tValidation loss: 1.684025\tBest loss: 1.684025\tAccuracy: 56.90%\n",
      "869\tValidation loss: 1.686486\tBest loss: 1.684025\tAccuracy: 56.70%\n",
      "870\tValidation loss: 1.686653\tBest loss: 1.684025\tAccuracy: 56.90%\n",
      "871\tValidation loss: 1.684371\tBest loss: 1.684025\tAccuracy: 56.30%\n",
      "872\tValidation loss: 1.680187\tBest loss: 1.680187\tAccuracy: 56.80%\n",
      "873\tValidation loss: 1.683442\tBest loss: 1.680187\tAccuracy: 56.80%\n",
      "874\tValidation loss: 1.682429\tBest loss: 1.680187\tAccuracy: 56.40%\n",
      "875\tValidation loss: 1.682263\tBest loss: 1.680187\tAccuracy: 56.80%\n",
      "876\tValidation loss: 1.681894\tBest loss: 1.680187\tAccuracy: 56.60%\n",
      "877\tValidation loss: 1.679451\tBest loss: 1.679451\tAccuracy: 57.10%\n",
      "878\tValidation loss: 1.678606\tBest loss: 1.678606\tAccuracy: 57.50%\n",
      "879\tValidation loss: 1.679378\tBest loss: 1.678606\tAccuracy: 57.00%\n",
      "880\tValidation loss: 1.680598\tBest loss: 1.678606\tAccuracy: 57.40%\n",
      "881\tValidation loss: 1.682380\tBest loss: 1.678606\tAccuracy: 57.10%\n",
      "882\tValidation loss: 1.681353\tBest loss: 1.678606\tAccuracy: 56.80%\n",
      "883\tValidation loss: 1.679593\tBest loss: 1.678606\tAccuracy: 57.00%\n",
      "884\tValidation loss: 1.680780\tBest loss: 1.678606\tAccuracy: 57.50%\n",
      "885\tValidation loss: 1.677361\tBest loss: 1.677361\tAccuracy: 57.50%\n",
      "886\tValidation loss: 1.677241\tBest loss: 1.677241\tAccuracy: 57.40%\n",
      "887\tValidation loss: 1.676831\tBest loss: 1.676831\tAccuracy: 57.30%\n",
      "888\tValidation loss: 1.676339\tBest loss: 1.676339\tAccuracy: 56.90%\n",
      "889\tValidation loss: 1.679662\tBest loss: 1.676339\tAccuracy: 57.20%\n",
      "890\tValidation loss: 1.681280\tBest loss: 1.676339\tAccuracy: 57.00%\n",
      "891\tValidation loss: 1.679675\tBest loss: 1.676339\tAccuracy: 56.80%\n",
      "892\tValidation loss: 1.675900\tBest loss: 1.675900\tAccuracy: 57.10%\n",
      "893\tValidation loss: 1.675920\tBest loss: 1.675900\tAccuracy: 56.90%\n",
      "894\tValidation loss: 1.676892\tBest loss: 1.675900\tAccuracy: 57.30%\n",
      "895\tValidation loss: 1.672327\tBest loss: 1.672327\tAccuracy: 57.50%\n",
      "896\tValidation loss: 1.673566\tBest loss: 1.672327\tAccuracy: 57.40%\n",
      "897\tValidation loss: 1.673612\tBest loss: 1.672327\tAccuracy: 57.30%\n",
      "898\tValidation loss: 1.674039\tBest loss: 1.672327\tAccuracy: 57.30%\n",
      "899\tValidation loss: 1.675094\tBest loss: 1.672327\tAccuracy: 57.00%\n",
      "900\tValidation loss: 1.672194\tBest loss: 1.672194\tAccuracy: 56.70%\n",
      "901\tValidation loss: 1.676304\tBest loss: 1.672194\tAccuracy: 56.70%\n",
      "902\tValidation loss: 1.676169\tBest loss: 1.672194\tAccuracy: 57.10%\n",
      "903\tValidation loss: 1.674973\tBest loss: 1.672194\tAccuracy: 57.00%\n",
      "904\tValidation loss: 1.675908\tBest loss: 1.672194\tAccuracy: 56.80%\n",
      "905\tValidation loss: 1.672553\tBest loss: 1.672194\tAccuracy: 57.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\tValidation loss: 1.675185\tBest loss: 1.672194\tAccuracy: 56.80%\n",
      "907\tValidation loss: 1.674768\tBest loss: 1.672194\tAccuracy: 56.90%\n",
      "908\tValidation loss: 1.675807\tBest loss: 1.672194\tAccuracy: 56.60%\n",
      "909\tValidation loss: 1.674197\tBest loss: 1.672194\tAccuracy: 56.70%\n",
      "910\tValidation loss: 1.673657\tBest loss: 1.672194\tAccuracy: 56.80%\n",
      "911\tValidation loss: 1.672859\tBest loss: 1.672194\tAccuracy: 57.10%\n",
      "912\tValidation loss: 1.672779\tBest loss: 1.672194\tAccuracy: 57.10%\n",
      "913\tValidation loss: 1.674221\tBest loss: 1.672194\tAccuracy: 56.70%\n",
      "914\tValidation loss: 1.673274\tBest loss: 1.672194\tAccuracy: 57.00%\n",
      "915\tValidation loss: 1.670455\tBest loss: 1.670455\tAccuracy: 57.10%\n",
      "916\tValidation loss: 1.672852\tBest loss: 1.670455\tAccuracy: 56.60%\n",
      "917\tValidation loss: 1.670204\tBest loss: 1.670204\tAccuracy: 56.80%\n",
      "918\tValidation loss: 1.668512\tBest loss: 1.668512\tAccuracy: 56.90%\n",
      "919\tValidation loss: 1.669984\tBest loss: 1.668512\tAccuracy: 57.20%\n",
      "920\tValidation loss: 1.669278\tBest loss: 1.668512\tAccuracy: 57.10%\n",
      "921\tValidation loss: 1.670678\tBest loss: 1.668512\tAccuracy: 56.90%\n",
      "922\tValidation loss: 1.672490\tBest loss: 1.668512\tAccuracy: 57.00%\n",
      "923\tValidation loss: 1.671236\tBest loss: 1.668512\tAccuracy: 57.30%\n",
      "924\tValidation loss: 1.671417\tBest loss: 1.668512\tAccuracy: 57.00%\n",
      "925\tValidation loss: 1.670984\tBest loss: 1.668512\tAccuracy: 56.90%\n",
      "926\tValidation loss: 1.670541\tBest loss: 1.668512\tAccuracy: 57.30%\n",
      "927\tValidation loss: 1.670345\tBest loss: 1.668512\tAccuracy: 56.80%\n",
      "928\tValidation loss: 1.669288\tBest loss: 1.668512\tAccuracy: 57.00%\n",
      "929\tValidation loss: 1.668678\tBest loss: 1.668512\tAccuracy: 57.00%\n",
      "930\tValidation loss: 1.665926\tBest loss: 1.665926\tAccuracy: 56.90%\n",
      "931\tValidation loss: 1.666305\tBest loss: 1.665926\tAccuracy: 56.40%\n",
      "932\tValidation loss: 1.668521\tBest loss: 1.665926\tAccuracy: 56.40%\n",
      "933\tValidation loss: 1.665375\tBest loss: 1.665375\tAccuracy: 57.30%\n",
      "934\tValidation loss: 1.666363\tBest loss: 1.665375\tAccuracy: 56.80%\n",
      "935\tValidation loss: 1.667437\tBest loss: 1.665375\tAccuracy: 57.20%\n",
      "936\tValidation loss: 1.668935\tBest loss: 1.665375\tAccuracy: 56.70%\n",
      "937\tValidation loss: 1.669413\tBest loss: 1.665375\tAccuracy: 57.10%\n",
      "938\tValidation loss: 1.668263\tBest loss: 1.665375\tAccuracy: 56.90%\n",
      "939\tValidation loss: 1.666755\tBest loss: 1.665375\tAccuracy: 57.00%\n",
      "940\tValidation loss: 1.664349\tBest loss: 1.664349\tAccuracy: 57.10%\n",
      "941\tValidation loss: 1.664370\tBest loss: 1.664349\tAccuracy: 57.10%\n",
      "942\tValidation loss: 1.664627\tBest loss: 1.664349\tAccuracy: 56.80%\n",
      "943\tValidation loss: 1.665119\tBest loss: 1.664349\tAccuracy: 56.70%\n",
      "944\tValidation loss: 1.667449\tBest loss: 1.664349\tAccuracy: 56.70%\n",
      "945\tValidation loss: 1.665952\tBest loss: 1.664349\tAccuracy: 57.40%\n",
      "946\tValidation loss: 1.664670\tBest loss: 1.664349\tAccuracy: 56.90%\n",
      "947\tValidation loss: 1.666666\tBest loss: 1.664349\tAccuracy: 56.90%\n",
      "948\tValidation loss: 1.666206\tBest loss: 1.664349\tAccuracy: 56.80%\n",
      "949\tValidation loss: 1.663481\tBest loss: 1.663481\tAccuracy: 56.90%\n",
      "950\tValidation loss: 1.665471\tBest loss: 1.663481\tAccuracy: 57.00%\n",
      "951\tValidation loss: 1.663857\tBest loss: 1.663481\tAccuracy: 56.60%\n",
      "952\tValidation loss: 1.663678\tBest loss: 1.663481\tAccuracy: 57.50%\n",
      "953\tValidation loss: 1.661698\tBest loss: 1.661698\tAccuracy: 57.10%\n",
      "954\tValidation loss: 1.661313\tBest loss: 1.661313\tAccuracy: 56.90%\n",
      "955\tValidation loss: 1.659624\tBest loss: 1.659624\tAccuracy: 56.70%\n",
      "956\tValidation loss: 1.661435\tBest loss: 1.659624\tAccuracy: 57.00%\n",
      "957\tValidation loss: 1.659420\tBest loss: 1.659420\tAccuracy: 56.90%\n",
      "958\tValidation loss: 1.659945\tBest loss: 1.659420\tAccuracy: 57.00%\n",
      "959\tValidation loss: 1.659709\tBest loss: 1.659420\tAccuracy: 56.60%\n",
      "960\tValidation loss: 1.661306\tBest loss: 1.659420\tAccuracy: 57.30%\n",
      "961\tValidation loss: 1.662520\tBest loss: 1.659420\tAccuracy: 57.40%\n",
      "962\tValidation loss: 1.661654\tBest loss: 1.659420\tAccuracy: 57.20%\n",
      "963\tValidation loss: 1.660146\tBest loss: 1.659420\tAccuracy: 56.90%\n",
      "964\tValidation loss: 1.656870\tBest loss: 1.656870\tAccuracy: 57.10%\n",
      "965\tValidation loss: 1.658745\tBest loss: 1.656870\tAccuracy: 57.10%\n",
      "966\tValidation loss: 1.658825\tBest loss: 1.656870\tAccuracy: 57.00%\n",
      "967\tValidation loss: 1.659518\tBest loss: 1.656870\tAccuracy: 57.00%\n",
      "968\tValidation loss: 1.662406\tBest loss: 1.656870\tAccuracy: 57.30%\n",
      "969\tValidation loss: 1.659171\tBest loss: 1.656870\tAccuracy: 56.90%\n",
      "970\tValidation loss: 1.658849\tBest loss: 1.656870\tAccuracy: 57.60%\n",
      "971\tValidation loss: 1.659387\tBest loss: 1.656870\tAccuracy: 57.30%\n",
      "972\tValidation loss: 1.655862\tBest loss: 1.655862\tAccuracy: 57.00%\n",
      "973\tValidation loss: 1.656164\tBest loss: 1.655862\tAccuracy: 57.00%\n",
      "974\tValidation loss: 1.656657\tBest loss: 1.655862\tAccuracy: 57.20%\n",
      "975\tValidation loss: 1.655791\tBest loss: 1.655791\tAccuracy: 56.70%\n",
      "976\tValidation loss: 1.656858\tBest loss: 1.655791\tAccuracy: 56.80%\n",
      "977\tValidation loss: 1.658276\tBest loss: 1.655791\tAccuracy: 56.80%\n",
      "978\tValidation loss: 1.657345\tBest loss: 1.655791\tAccuracy: 57.30%\n",
      "979\tValidation loss: 1.656549\tBest loss: 1.655791\tAccuracy: 57.00%\n",
      "980\tValidation loss: 1.655814\tBest loss: 1.655791\tAccuracy: 57.20%\n",
      "981\tValidation loss: 1.657835\tBest loss: 1.655791\tAccuracy: 57.60%\n",
      "982\tValidation loss: 1.657020\tBest loss: 1.655791\tAccuracy: 57.50%\n",
      "983\tValidation loss: 1.655895\tBest loss: 1.655791\tAccuracy: 57.40%\n",
      "984\tValidation loss: 1.655839\tBest loss: 1.655791\tAccuracy: 57.70%\n",
      "985\tValidation loss: 1.656464\tBest loss: 1.655791\tAccuracy: 57.40%\n",
      "986\tValidation loss: 1.655811\tBest loss: 1.655791\tAccuracy: 57.60%\n",
      "987\tValidation loss: 1.655062\tBest loss: 1.655062\tAccuracy: 57.40%\n",
      "988\tValidation loss: 1.655658\tBest loss: 1.655062\tAccuracy: 57.30%\n",
      "989\tValidation loss: 1.654227\tBest loss: 1.654227\tAccuracy: 57.40%\n",
      "990\tValidation loss: 1.654975\tBest loss: 1.654227\tAccuracy: 57.80%\n",
      "991\tValidation loss: 1.654185\tBest loss: 1.654185\tAccuracy: 57.50%\n",
      "992\tValidation loss: 1.652888\tBest loss: 1.652888\tAccuracy: 57.70%\n",
      "993\tValidation loss: 1.652211\tBest loss: 1.652211\tAccuracy: 57.40%\n",
      "994\tValidation loss: 1.652261\tBest loss: 1.652211\tAccuracy: 58.00%\n",
      "995\tValidation loss: 1.652692\tBest loss: 1.652211\tAccuracy: 57.20%\n",
      "996\tValidation loss: 1.651099\tBest loss: 1.651099\tAccuracy: 56.80%\n",
      "997\tValidation loss: 1.651365\tBest loss: 1.651099\tAccuracy: 57.20%\n",
      "998\tValidation loss: 1.651724\tBest loss: 1.651099\tAccuracy: 57.60%\n",
      "999\tValidation loss: 1.650334\tBest loss: 1.650334\tAccuracy: 57.70%\n",
      "[[  4.04011899e-07   5.51364719e-05   3.21537373e-03 ...,   5.63364483e-05\n",
      "    1.67773291e-03   3.90625471e-04]\n",
      " [  2.80126877e-11   4.44505258e-06   8.81590356e-10 ...,   1.51942005e-18\n",
      "    5.68456686e-13   4.25054143e-13]\n",
      " [  3.33950311e-06   1.18093635e-03   2.36874566e-05 ...,   1.85850606e-08\n",
      "    1.01804414e-06   1.07906374e-06]\n",
      " ..., \n",
      " [  2.78179557e-03   4.78644157e-03   3.89332254e-03 ...,   2.44097654e-02\n",
      "    1.07284086e-02   1.23940809e-02]\n",
      " [  1.31108927e-05   3.82036851e-05   1.03993465e-04 ...,   1.41058952e-01\n",
      "    6.52448833e-02   9.04163253e-03]\n",
      " [  2.25959740e-09   2.44405356e-07   6.55369163e-08 ...,   4.19310108e-03\n",
      "    3.36380824e-02   7.26242037e-03]]\n",
      "[31 43 43 ...,  8 24 27]\n",
      "[[  3.48141543e-10   2.03901436e-05   7.05901329e-08 ...,   9.33004620e-19\n",
      "    3.51373173e-13   6.13610942e-13]\n",
      " [  5.87355793e-02   4.68676239e-02   4.21795063e-02 ...,   1.10510383e-02\n",
      "    6.65559992e-03   7.16018816e-03]\n",
      " [  6.66819655e-10   2.42187970e-13   5.47551110e-07 ...,   5.73408711e-14\n",
      "    6.80461112e-16   1.88899514e-17]\n",
      " ..., \n",
      " [  3.27314320e-03   2.07031462e-02   1.74354855e-03 ...,   1.35026357e-06\n",
      "    8.43107955e-06   5.38420409e-07]\n",
      " [  3.24756391e-02   2.10190602e-02   2.48643234e-02 ...,   1.88316423e-02\n",
      "    1.62155237e-02   1.67871341e-02]\n",
      " [  9.75697212e-09   2.73461040e-08   5.64242896e-07 ...,   1.67695522e-01\n",
      "    4.29101400e-02   7.10666120e-01]]\n",
      "[20  0 16 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 3.9min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.160596\tBest loss: 4.160596\tAccuracy: 4.20%\n",
      "1\tValidation loss: 3.913897\tBest loss: 3.913897\tAccuracy: 3.60%\n",
      "2\tValidation loss: 3.869547\tBest loss: 3.869547\tAccuracy: 4.80%\n",
      "3\tValidation loss: 3.831150\tBest loss: 3.831150\tAccuracy: 5.60%\n",
      "4\tValidation loss: 3.805996\tBest loss: 3.805996\tAccuracy: 5.90%\n",
      "5\tValidation loss: 3.784214\tBest loss: 3.784214\tAccuracy: 6.30%\n",
      "6\tValidation loss: 3.766228\tBest loss: 3.766228\tAccuracy: 6.50%\n",
      "7\tValidation loss: 3.751014\tBest loss: 3.751014\tAccuracy: 6.40%\n",
      "8\tValidation loss: 3.738835\tBest loss: 3.738835\tAccuracy: 6.30%\n",
      "9\tValidation loss: 3.728207\tBest loss: 3.728207\tAccuracy: 7.70%\n",
      "10\tValidation loss: 3.718444\tBest loss: 3.718444\tAccuracy: 8.10%\n",
      "11\tValidation loss: 3.710156\tBest loss: 3.710156\tAccuracy: 8.20%\n",
      "12\tValidation loss: 3.702640\tBest loss: 3.702640\tAccuracy: 8.70%\n",
      "13\tValidation loss: 3.696198\tBest loss: 3.696198\tAccuracy: 8.90%\n",
      "14\tValidation loss: 3.690562\tBest loss: 3.690562\tAccuracy: 8.50%\n",
      "15\tValidation loss: 3.685142\tBest loss: 3.685142\tAccuracy: 8.40%\n",
      "16\tValidation loss: 3.680614\tBest loss: 3.680614\tAccuracy: 8.70%\n",
      "17\tValidation loss: 3.676014\tBest loss: 3.676014\tAccuracy: 9.00%\n",
      "18\tValidation loss: 3.671439\tBest loss: 3.671439\tAccuracy: 9.40%\n",
      "19\tValidation loss: 3.667592\tBest loss: 3.667592\tAccuracy: 10.10%\n",
      "20\tValidation loss: 3.663301\tBest loss: 3.663301\tAccuracy: 10.10%\n",
      "21\tValidation loss: 3.659395\tBest loss: 3.659395\tAccuracy: 10.20%\n",
      "22\tValidation loss: 3.654969\tBest loss: 3.654969\tAccuracy: 10.50%\n",
      "23\tValidation loss: 3.650783\tBest loss: 3.650783\tAccuracy: 10.90%\n",
      "24\tValidation loss: 3.647086\tBest loss: 3.647086\tAccuracy: 10.80%\n",
      "25\tValidation loss: 3.643134\tBest loss: 3.643134\tAccuracy: 10.90%\n",
      "26\tValidation loss: 3.639579\tBest loss: 3.639579\tAccuracy: 11.10%\n",
      "27\tValidation loss: 3.635254\tBest loss: 3.635254\tAccuracy: 11.20%\n",
      "28\tValidation loss: 3.631268\tBest loss: 3.631268\tAccuracy: 11.80%\n",
      "29\tValidation loss: 3.627105\tBest loss: 3.627105\tAccuracy: 12.00%\n",
      "30\tValidation loss: 3.622592\tBest loss: 3.622592\tAccuracy: 11.90%\n",
      "31\tValidation loss: 3.617893\tBest loss: 3.617893\tAccuracy: 12.00%\n",
      "32\tValidation loss: 3.612664\tBest loss: 3.612664\tAccuracy: 12.70%\n",
      "33\tValidation loss: 3.608741\tBest loss: 3.608741\tAccuracy: 12.60%\n",
      "34\tValidation loss: 3.603390\tBest loss: 3.603390\tAccuracy: 13.10%\n",
      "35\tValidation loss: 3.596218\tBest loss: 3.596218\tAccuracy: 13.10%\n",
      "36\tValidation loss: 3.588725\tBest loss: 3.588725\tAccuracy: 13.10%\n",
      "37\tValidation loss: 3.583688\tBest loss: 3.583688\tAccuracy: 13.20%\n",
      "38\tValidation loss: 3.569869\tBest loss: 3.569869\tAccuracy: 12.90%\n",
      "39\tValidation loss: 3.562553\tBest loss: 3.562553\tAccuracy: 12.60%\n",
      "40\tValidation loss: 3.553756\tBest loss: 3.553756\tAccuracy: 12.80%\n",
      "41\tValidation loss: 3.535453\tBest loss: 3.535453\tAccuracy: 13.20%\n",
      "42\tValidation loss: 3.532677\tBest loss: 3.532677\tAccuracy: 12.60%\n",
      "43\tValidation loss: 3.522780\tBest loss: 3.522780\tAccuracy: 12.70%\n",
      "44\tValidation loss: 3.515718\tBest loss: 3.515718\tAccuracy: 13.40%\n",
      "45\tValidation loss: 3.515033\tBest loss: 3.515033\tAccuracy: 13.10%\n",
      "46\tValidation loss: 3.505462\tBest loss: 3.505462\tAccuracy: 13.70%\n",
      "47\tValidation loss: 3.496429\tBest loss: 3.496429\tAccuracy: 13.90%\n",
      "48\tValidation loss: 3.488202\tBest loss: 3.488202\tAccuracy: 13.70%\n",
      "49\tValidation loss: 3.486695\tBest loss: 3.486695\tAccuracy: 13.50%\n",
      "50\tValidation loss: 3.478299\tBest loss: 3.478299\tAccuracy: 13.50%\n",
      "51\tValidation loss: 3.473519\tBest loss: 3.473519\tAccuracy: 13.30%\n",
      "52\tValidation loss: 3.469717\tBest loss: 3.469717\tAccuracy: 13.30%\n",
      "53\tValidation loss: 3.459417\tBest loss: 3.459417\tAccuracy: 13.40%\n",
      "54\tValidation loss: 3.453085\tBest loss: 3.453085\tAccuracy: 13.80%\n",
      "55\tValidation loss: 3.445477\tBest loss: 3.445477\tAccuracy: 13.70%\n",
      "56\tValidation loss: 3.439767\tBest loss: 3.439767\tAccuracy: 13.70%\n",
      "57\tValidation loss: 3.434453\tBest loss: 3.434453\tAccuracy: 13.50%\n",
      "58\tValidation loss: 3.428776\tBest loss: 3.428776\tAccuracy: 13.60%\n",
      "59\tValidation loss: 3.419217\tBest loss: 3.419217\tAccuracy: 13.90%\n",
      "60\tValidation loss: 3.415135\tBest loss: 3.415135\tAccuracy: 14.20%\n",
      "61\tValidation loss: 3.408650\tBest loss: 3.408650\tAccuracy: 14.60%\n",
      "62\tValidation loss: 3.400395\tBest loss: 3.400395\tAccuracy: 14.90%\n",
      "63\tValidation loss: 3.396908\tBest loss: 3.396908\tAccuracy: 14.80%\n",
      "64\tValidation loss: 3.388031\tBest loss: 3.388031\tAccuracy: 15.40%\n",
      "65\tValidation loss: 3.373156\tBest loss: 3.373156\tAccuracy: 15.20%\n",
      "66\tValidation loss: 3.366957\tBest loss: 3.366957\tAccuracy: 15.70%\n",
      "67\tValidation loss: 3.357570\tBest loss: 3.357570\tAccuracy: 15.50%\n",
      "68\tValidation loss: 3.352939\tBest loss: 3.352939\tAccuracy: 16.10%\n",
      "69\tValidation loss: 3.342629\tBest loss: 3.342629\tAccuracy: 16.10%\n",
      "70\tValidation loss: 3.325561\tBest loss: 3.325561\tAccuracy: 16.00%\n",
      "71\tValidation loss: 3.316691\tBest loss: 3.316691\tAccuracy: 16.90%\n",
      "72\tValidation loss: 3.307355\tBest loss: 3.307355\tAccuracy: 16.80%\n",
      "73\tValidation loss: 3.294404\tBest loss: 3.294404\tAccuracy: 16.60%\n",
      "74\tValidation loss: 3.291826\tBest loss: 3.291826\tAccuracy: 16.90%\n",
      "75\tValidation loss: 3.267893\tBest loss: 3.267893\tAccuracy: 17.50%\n",
      "76\tValidation loss: 3.261039\tBest loss: 3.261039\tAccuracy: 17.20%\n",
      "77\tValidation loss: 3.257776\tBest loss: 3.257776\tAccuracy: 17.90%\n",
      "78\tValidation loss: 3.240865\tBest loss: 3.240865\tAccuracy: 17.90%\n",
      "79\tValidation loss: 3.229205\tBest loss: 3.229205\tAccuracy: 18.10%\n",
      "80\tValidation loss: 3.221915\tBest loss: 3.221915\tAccuracy: 18.50%\n",
      "81\tValidation loss: 3.204668\tBest loss: 3.204668\tAccuracy: 18.30%\n",
      "82\tValidation loss: 3.197718\tBest loss: 3.197718\tAccuracy: 18.20%\n",
      "83\tValidation loss: 3.183433\tBest loss: 3.183433\tAccuracy: 18.20%\n",
      "84\tValidation loss: 3.174399\tBest loss: 3.174399\tAccuracy: 18.50%\n",
      "85\tValidation loss: 3.173744\tBest loss: 3.173744\tAccuracy: 18.50%\n",
      "86\tValidation loss: 3.155125\tBest loss: 3.155125\tAccuracy: 18.50%\n",
      "87\tValidation loss: 3.142740\tBest loss: 3.142740\tAccuracy: 18.60%\n",
      "88\tValidation loss: 3.137183\tBest loss: 3.137183\tAccuracy: 19.20%\n",
      "89\tValidation loss: 3.127306\tBest loss: 3.127306\tAccuracy: 19.00%\n",
      "90\tValidation loss: 3.110252\tBest loss: 3.110252\tAccuracy: 19.80%\n",
      "91\tValidation loss: 3.104033\tBest loss: 3.104033\tAccuracy: 19.80%\n",
      "92\tValidation loss: 3.098885\tBest loss: 3.098885\tAccuracy: 19.20%\n",
      "93\tValidation loss: 3.081732\tBest loss: 3.081732\tAccuracy: 20.40%\n",
      "94\tValidation loss: 3.088479\tBest loss: 3.081732\tAccuracy: 19.90%\n",
      "95\tValidation loss: 3.072116\tBest loss: 3.072116\tAccuracy: 21.00%\n",
      "96\tValidation loss: 3.065987\tBest loss: 3.065987\tAccuracy: 20.50%\n",
      "97\tValidation loss: 3.061874\tBest loss: 3.061874\tAccuracy: 20.70%\n",
      "98\tValidation loss: 3.051896\tBest loss: 3.051896\tAccuracy: 20.80%\n",
      "99\tValidation loss: 3.034039\tBest loss: 3.034039\tAccuracy: 21.60%\n",
      "100\tValidation loss: 3.030995\tBest loss: 3.030995\tAccuracy: 21.30%\n",
      "101\tValidation loss: 3.021094\tBest loss: 3.021094\tAccuracy: 21.60%\n",
      "102\tValidation loss: 3.013885\tBest loss: 3.013885\tAccuracy: 21.80%\n",
      "103\tValidation loss: 3.000023\tBest loss: 3.000023\tAccuracy: 21.90%\n",
      "104\tValidation loss: 2.997940\tBest loss: 2.997940\tAccuracy: 21.80%\n",
      "105\tValidation loss: 2.989699\tBest loss: 2.989699\tAccuracy: 21.90%\n",
      "106\tValidation loss: 2.972618\tBest loss: 2.972618\tAccuracy: 22.70%\n",
      "107\tValidation loss: 2.967695\tBest loss: 2.967695\tAccuracy: 22.80%\n",
      "108\tValidation loss: 2.966479\tBest loss: 2.966479\tAccuracy: 22.60%\n",
      "109\tValidation loss: 2.954923\tBest loss: 2.954923\tAccuracy: 22.70%\n",
      "110\tValidation loss: 2.945192\tBest loss: 2.945192\tAccuracy: 22.90%\n",
      "111\tValidation loss: 2.932770\tBest loss: 2.932770\tAccuracy: 23.30%\n",
      "112\tValidation loss: 2.922939\tBest loss: 2.922939\tAccuracy: 24.40%\n",
      "113\tValidation loss: 2.909301\tBest loss: 2.909301\tAccuracy: 23.70%\n",
      "114\tValidation loss: 2.898921\tBest loss: 2.898921\tAccuracy: 23.90%\n",
      "115\tValidation loss: 2.890421\tBest loss: 2.890421\tAccuracy: 24.30%\n",
      "116\tValidation loss: 2.877935\tBest loss: 2.877935\tAccuracy: 25.30%\n",
      "117\tValidation loss: 2.866589\tBest loss: 2.866589\tAccuracy: 25.10%\n",
      "118\tValidation loss: 2.859650\tBest loss: 2.859650\tAccuracy: 24.90%\n",
      "119\tValidation loss: 2.841297\tBest loss: 2.841297\tAccuracy: 26.00%\n",
      "120\tValidation loss: 2.828678\tBest loss: 2.828678\tAccuracy: 26.20%\n",
      "121\tValidation loss: 2.821721\tBest loss: 2.821721\tAccuracy: 26.60%\n",
      "122\tValidation loss: 2.806879\tBest loss: 2.806879\tAccuracy: 26.70%\n",
      "123\tValidation loss: 2.798318\tBest loss: 2.798318\tAccuracy: 27.20%\n",
      "124\tValidation loss: 2.784133\tBest loss: 2.784133\tAccuracy: 27.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 2.766644\tBest loss: 2.766644\tAccuracy: 28.50%\n",
      "126\tValidation loss: 2.756524\tBest loss: 2.756524\tAccuracy: 28.10%\n",
      "127\tValidation loss: 2.746769\tBest loss: 2.746769\tAccuracy: 29.40%\n",
      "128\tValidation loss: 2.740890\tBest loss: 2.740890\tAccuracy: 29.20%\n",
      "129\tValidation loss: 2.728840\tBest loss: 2.728840\tAccuracy: 28.70%\n",
      "130\tValidation loss: 2.714794\tBest loss: 2.714794\tAccuracy: 30.00%\n",
      "131\tValidation loss: 2.704983\tBest loss: 2.704983\tAccuracy: 30.10%\n",
      "132\tValidation loss: 2.694912\tBest loss: 2.694912\tAccuracy: 30.10%\n",
      "133\tValidation loss: 2.688280\tBest loss: 2.688280\tAccuracy: 30.00%\n",
      "134\tValidation loss: 2.672943\tBest loss: 2.672943\tAccuracy: 30.50%\n",
      "135\tValidation loss: 2.666027\tBest loss: 2.666027\tAccuracy: 30.50%\n",
      "136\tValidation loss: 2.661341\tBest loss: 2.661341\tAccuracy: 30.40%\n",
      "137\tValidation loss: 2.645341\tBest loss: 2.645341\tAccuracy: 31.40%\n",
      "138\tValidation loss: 2.641824\tBest loss: 2.641824\tAccuracy: 30.70%\n",
      "139\tValidation loss: 2.629977\tBest loss: 2.629977\tAccuracy: 31.40%\n",
      "140\tValidation loss: 2.614710\tBest loss: 2.614710\tAccuracy: 31.70%\n",
      "141\tValidation loss: 2.613756\tBest loss: 2.613756\tAccuracy: 31.30%\n",
      "142\tValidation loss: 2.608068\tBest loss: 2.608068\tAccuracy: 32.30%\n",
      "143\tValidation loss: 2.600146\tBest loss: 2.600146\tAccuracy: 31.50%\n",
      "144\tValidation loss: 2.592585\tBest loss: 2.592585\tAccuracy: 31.80%\n",
      "145\tValidation loss: 2.591383\tBest loss: 2.591383\tAccuracy: 32.40%\n",
      "146\tValidation loss: 2.578401\tBest loss: 2.578401\tAccuracy: 33.70%\n",
      "147\tValidation loss: 2.577745\tBest loss: 2.577745\tAccuracy: 32.50%\n",
      "148\tValidation loss: 2.568000\tBest loss: 2.568000\tAccuracy: 33.10%\n",
      "149\tValidation loss: 2.563225\tBest loss: 2.563225\tAccuracy: 32.80%\n",
      "150\tValidation loss: 2.550855\tBest loss: 2.550855\tAccuracy: 33.60%\n",
      "151\tValidation loss: 2.545909\tBest loss: 2.545909\tAccuracy: 32.90%\n",
      "152\tValidation loss: 2.539225\tBest loss: 2.539225\tAccuracy: 33.50%\n",
      "153\tValidation loss: 2.531309\tBest loss: 2.531309\tAccuracy: 34.30%\n",
      "154\tValidation loss: 2.522988\tBest loss: 2.522988\tAccuracy: 34.60%\n",
      "155\tValidation loss: 2.519154\tBest loss: 2.519154\tAccuracy: 34.40%\n",
      "156\tValidation loss: 2.514732\tBest loss: 2.514732\tAccuracy: 34.20%\n",
      "157\tValidation loss: 2.510311\tBest loss: 2.510311\tAccuracy: 35.20%\n",
      "158\tValidation loss: 2.502716\tBest loss: 2.502716\tAccuracy: 34.60%\n",
      "159\tValidation loss: 2.499005\tBest loss: 2.499005\tAccuracy: 34.20%\n",
      "160\tValidation loss: 2.492061\tBest loss: 2.492061\tAccuracy: 34.50%\n",
      "161\tValidation loss: 2.481243\tBest loss: 2.481243\tAccuracy: 35.00%\n",
      "162\tValidation loss: 2.483503\tBest loss: 2.481243\tAccuracy: 35.10%\n",
      "163\tValidation loss: 2.470749\tBest loss: 2.470749\tAccuracy: 34.80%\n",
      "164\tValidation loss: 2.466340\tBest loss: 2.466340\tAccuracy: 34.70%\n",
      "165\tValidation loss: 2.463712\tBest loss: 2.463712\tAccuracy: 34.90%\n",
      "166\tValidation loss: 2.466510\tBest loss: 2.463712\tAccuracy: 34.70%\n",
      "167\tValidation loss: 2.453431\tBest loss: 2.453431\tAccuracy: 35.90%\n",
      "168\tValidation loss: 2.455393\tBest loss: 2.453431\tAccuracy: 36.10%\n",
      "169\tValidation loss: 2.450279\tBest loss: 2.450279\tAccuracy: 35.60%\n",
      "170\tValidation loss: 2.440830\tBest loss: 2.440830\tAccuracy: 35.80%\n",
      "171\tValidation loss: 2.438262\tBest loss: 2.438262\tAccuracy: 36.20%\n",
      "172\tValidation loss: 2.428378\tBest loss: 2.428378\tAccuracy: 36.40%\n",
      "173\tValidation loss: 2.429412\tBest loss: 2.428378\tAccuracy: 35.90%\n",
      "174\tValidation loss: 2.427795\tBest loss: 2.427795\tAccuracy: 36.50%\n",
      "175\tValidation loss: 2.420552\tBest loss: 2.420552\tAccuracy: 36.70%\n",
      "176\tValidation loss: 2.416059\tBest loss: 2.416059\tAccuracy: 36.80%\n",
      "177\tValidation loss: 2.410477\tBest loss: 2.410477\tAccuracy: 36.20%\n",
      "178\tValidation loss: 2.406953\tBest loss: 2.406953\tAccuracy: 37.40%\n",
      "179\tValidation loss: 2.406729\tBest loss: 2.406729\tAccuracy: 37.00%\n",
      "180\tValidation loss: 2.401842\tBest loss: 2.401842\tAccuracy: 37.30%\n",
      "181\tValidation loss: 2.402881\tBest loss: 2.401842\tAccuracy: 37.30%\n",
      "182\tValidation loss: 2.397730\tBest loss: 2.397730\tAccuracy: 37.10%\n",
      "183\tValidation loss: 2.393907\tBest loss: 2.393907\tAccuracy: 38.20%\n",
      "184\tValidation loss: 2.386668\tBest loss: 2.386668\tAccuracy: 38.00%\n",
      "185\tValidation loss: 2.381147\tBest loss: 2.381147\tAccuracy: 38.70%\n",
      "186\tValidation loss: 2.369936\tBest loss: 2.369936\tAccuracy: 38.70%\n",
      "187\tValidation loss: 2.367990\tBest loss: 2.367990\tAccuracy: 38.40%\n",
      "188\tValidation loss: 2.364519\tBest loss: 2.364519\tAccuracy: 39.00%\n",
      "189\tValidation loss: 2.367646\tBest loss: 2.364519\tAccuracy: 39.00%\n",
      "190\tValidation loss: 2.358448\tBest loss: 2.358448\tAccuracy: 38.70%\n",
      "191\tValidation loss: 2.360090\tBest loss: 2.358448\tAccuracy: 38.30%\n",
      "192\tValidation loss: 2.355579\tBest loss: 2.355579\tAccuracy: 38.50%\n",
      "193\tValidation loss: 2.349209\tBest loss: 2.349209\tAccuracy: 39.40%\n",
      "194\tValidation loss: 2.349161\tBest loss: 2.349161\tAccuracy: 38.30%\n",
      "195\tValidation loss: 2.341001\tBest loss: 2.341001\tAccuracy: 39.30%\n",
      "196\tValidation loss: 2.342282\tBest loss: 2.341001\tAccuracy: 39.10%\n",
      "197\tValidation loss: 2.338622\tBest loss: 2.338622\tAccuracy: 39.20%\n",
      "198\tValidation loss: 2.334193\tBest loss: 2.334193\tAccuracy: 38.80%\n",
      "199\tValidation loss: 2.327494\tBest loss: 2.327494\tAccuracy: 39.10%\n",
      "200\tValidation loss: 2.321090\tBest loss: 2.321090\tAccuracy: 39.40%\n",
      "201\tValidation loss: 2.317930\tBest loss: 2.317930\tAccuracy: 40.10%\n",
      "202\tValidation loss: 2.319860\tBest loss: 2.317930\tAccuracy: 39.10%\n",
      "203\tValidation loss: 2.308297\tBest loss: 2.308297\tAccuracy: 40.40%\n",
      "204\tValidation loss: 2.309398\tBest loss: 2.308297\tAccuracy: 40.10%\n",
      "205\tValidation loss: 2.295441\tBest loss: 2.295441\tAccuracy: 40.40%\n",
      "206\tValidation loss: 2.293722\tBest loss: 2.293722\tAccuracy: 41.10%\n",
      "207\tValidation loss: 2.291923\tBest loss: 2.291923\tAccuracy: 39.60%\n",
      "208\tValidation loss: 2.290903\tBest loss: 2.290903\tAccuracy: 40.60%\n",
      "209\tValidation loss: 2.284380\tBest loss: 2.284380\tAccuracy: 40.80%\n",
      "210\tValidation loss: 2.283616\tBest loss: 2.283616\tAccuracy: 39.90%\n",
      "211\tValidation loss: 2.280528\tBest loss: 2.280528\tAccuracy: 40.70%\n",
      "212\tValidation loss: 2.273251\tBest loss: 2.273251\tAccuracy: 40.60%\n",
      "213\tValidation loss: 2.269310\tBest loss: 2.269310\tAccuracy: 40.80%\n",
      "214\tValidation loss: 2.262769\tBest loss: 2.262769\tAccuracy: 40.60%\n",
      "215\tValidation loss: 2.268708\tBest loss: 2.262769\tAccuracy: 41.10%\n",
      "216\tValidation loss: 2.266722\tBest loss: 2.262769\tAccuracy: 41.60%\n",
      "217\tValidation loss: 2.252321\tBest loss: 2.252321\tAccuracy: 42.40%\n",
      "218\tValidation loss: 2.252535\tBest loss: 2.252321\tAccuracy: 41.80%\n",
      "219\tValidation loss: 2.253300\tBest loss: 2.252321\tAccuracy: 41.60%\n",
      "220\tValidation loss: 2.246037\tBest loss: 2.246037\tAccuracy: 42.20%\n",
      "221\tValidation loss: 2.244498\tBest loss: 2.244498\tAccuracy: 42.10%\n",
      "222\tValidation loss: 2.249402\tBest loss: 2.244498\tAccuracy: 41.60%\n",
      "223\tValidation loss: 2.242108\tBest loss: 2.242108\tAccuracy: 42.00%\n",
      "224\tValidation loss: 2.245025\tBest loss: 2.242108\tAccuracy: 42.50%\n",
      "225\tValidation loss: 2.232896\tBest loss: 2.232896\tAccuracy: 42.60%\n",
      "226\tValidation loss: 2.226582\tBest loss: 2.226582\tAccuracy: 42.70%\n",
      "227\tValidation loss: 2.229633\tBest loss: 2.226582\tAccuracy: 42.70%\n",
      "228\tValidation loss: 2.217179\tBest loss: 2.217179\tAccuracy: 43.20%\n",
      "229\tValidation loss: 2.215369\tBest loss: 2.215369\tAccuracy: 43.70%\n",
      "230\tValidation loss: 2.211331\tBest loss: 2.211331\tAccuracy: 44.20%\n",
      "231\tValidation loss: 2.207014\tBest loss: 2.207014\tAccuracy: 43.60%\n",
      "232\tValidation loss: 2.202947\tBest loss: 2.202947\tAccuracy: 44.30%\n",
      "233\tValidation loss: 2.212986\tBest loss: 2.202947\tAccuracy: 44.60%\n",
      "234\tValidation loss: 2.201072\tBest loss: 2.201072\tAccuracy: 44.40%\n",
      "235\tValidation loss: 2.204545\tBest loss: 2.201072\tAccuracy: 44.20%\n",
      "236\tValidation loss: 2.193377\tBest loss: 2.193377\tAccuracy: 43.40%\n",
      "237\tValidation loss: 2.194676\tBest loss: 2.193377\tAccuracy: 44.10%\n",
      "238\tValidation loss: 2.194035\tBest loss: 2.193377\tAccuracy: 43.80%\n",
      "239\tValidation loss: 2.187210\tBest loss: 2.187210\tAccuracy: 44.60%\n",
      "240\tValidation loss: 2.180859\tBest loss: 2.180859\tAccuracy: 45.00%\n",
      "241\tValidation loss: 2.186712\tBest loss: 2.180859\tAccuracy: 44.50%\n",
      "242\tValidation loss: 2.178738\tBest loss: 2.178738\tAccuracy: 45.20%\n",
      "243\tValidation loss: 2.182092\tBest loss: 2.178738\tAccuracy: 44.70%\n",
      "244\tValidation loss: 2.184818\tBest loss: 2.178738\tAccuracy: 45.00%\n",
      "245\tValidation loss: 2.173711\tBest loss: 2.173711\tAccuracy: 44.80%\n",
      "246\tValidation loss: 2.170693\tBest loss: 2.170693\tAccuracy: 44.30%\n",
      "247\tValidation loss: 2.174928\tBest loss: 2.170693\tAccuracy: 45.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 2.162939\tBest loss: 2.162939\tAccuracy: 44.90%\n",
      "249\tValidation loss: 2.156224\tBest loss: 2.156224\tAccuracy: 45.00%\n",
      "250\tValidation loss: 2.156891\tBest loss: 2.156224\tAccuracy: 45.60%\n",
      "251\tValidation loss: 2.156636\tBest loss: 2.156224\tAccuracy: 44.50%\n",
      "252\tValidation loss: 2.154382\tBest loss: 2.154382\tAccuracy: 45.00%\n",
      "253\tValidation loss: 2.149956\tBest loss: 2.149956\tAccuracy: 45.60%\n",
      "254\tValidation loss: 2.153681\tBest loss: 2.149956\tAccuracy: 45.50%\n",
      "255\tValidation loss: 2.149121\tBest loss: 2.149121\tAccuracy: 45.30%\n",
      "256\tValidation loss: 2.150889\tBest loss: 2.149121\tAccuracy: 45.30%\n",
      "257\tValidation loss: 2.147335\tBest loss: 2.147335\tAccuracy: 45.60%\n",
      "258\tValidation loss: 2.144555\tBest loss: 2.144555\tAccuracy: 45.10%\n",
      "259\tValidation loss: 2.138892\tBest loss: 2.138892\tAccuracy: 45.80%\n",
      "260\tValidation loss: 2.144018\tBest loss: 2.138892\tAccuracy: 45.50%\n",
      "261\tValidation loss: 2.133753\tBest loss: 2.133753\tAccuracy: 46.20%\n",
      "262\tValidation loss: 2.137527\tBest loss: 2.133753\tAccuracy: 46.40%\n",
      "263\tValidation loss: 2.134985\tBest loss: 2.133753\tAccuracy: 44.90%\n",
      "264\tValidation loss: 2.126792\tBest loss: 2.126792\tAccuracy: 46.50%\n",
      "265\tValidation loss: 2.123653\tBest loss: 2.123653\tAccuracy: 45.80%\n",
      "266\tValidation loss: 2.126729\tBest loss: 2.123653\tAccuracy: 46.20%\n",
      "267\tValidation loss: 2.121500\tBest loss: 2.121500\tAccuracy: 46.70%\n",
      "268\tValidation loss: 2.122500\tBest loss: 2.121500\tAccuracy: 45.90%\n",
      "269\tValidation loss: 2.123569\tBest loss: 2.121500\tAccuracy: 46.10%\n",
      "270\tValidation loss: 2.113599\tBest loss: 2.113599\tAccuracy: 46.20%\n",
      "271\tValidation loss: 2.114290\tBest loss: 2.113599\tAccuracy: 46.90%\n",
      "272\tValidation loss: 2.114431\tBest loss: 2.113599\tAccuracy: 46.80%\n",
      "273\tValidation loss: 2.109295\tBest loss: 2.109295\tAccuracy: 46.20%\n",
      "274\tValidation loss: 2.108043\tBest loss: 2.108043\tAccuracy: 46.70%\n",
      "275\tValidation loss: 2.112345\tBest loss: 2.108043\tAccuracy: 46.10%\n",
      "276\tValidation loss: 2.105574\tBest loss: 2.105574\tAccuracy: 46.60%\n",
      "277\tValidation loss: 2.105462\tBest loss: 2.105462\tAccuracy: 46.30%\n",
      "278\tValidation loss: 2.102706\tBest loss: 2.102706\tAccuracy: 47.10%\n",
      "279\tValidation loss: 2.093053\tBest loss: 2.093053\tAccuracy: 47.10%\n",
      "280\tValidation loss: 2.101030\tBest loss: 2.093053\tAccuracy: 46.70%\n",
      "281\tValidation loss: 2.103345\tBest loss: 2.093053\tAccuracy: 46.40%\n",
      "282\tValidation loss: 2.095246\tBest loss: 2.093053\tAccuracy: 46.80%\n",
      "283\tValidation loss: 2.091389\tBest loss: 2.091389\tAccuracy: 47.00%\n",
      "284\tValidation loss: 2.098068\tBest loss: 2.091389\tAccuracy: 47.20%\n",
      "285\tValidation loss: 2.096012\tBest loss: 2.091389\tAccuracy: 47.30%\n",
      "286\tValidation loss: 2.095446\tBest loss: 2.091389\tAccuracy: 47.00%\n",
      "287\tValidation loss: 2.088969\tBest loss: 2.088969\tAccuracy: 47.40%\n",
      "288\tValidation loss: 2.086534\tBest loss: 2.086534\tAccuracy: 48.30%\n",
      "289\tValidation loss: 2.089047\tBest loss: 2.086534\tAccuracy: 47.70%\n",
      "290\tValidation loss: 2.085300\tBest loss: 2.085300\tAccuracy: 47.70%\n",
      "291\tValidation loss: 2.085518\tBest loss: 2.085300\tAccuracy: 48.40%\n",
      "292\tValidation loss: 2.080451\tBest loss: 2.080451\tAccuracy: 47.90%\n",
      "293\tValidation loss: 2.082310\tBest loss: 2.080451\tAccuracy: 47.80%\n",
      "294\tValidation loss: 2.077922\tBest loss: 2.077922\tAccuracy: 47.50%\n",
      "295\tValidation loss: 2.071171\tBest loss: 2.071171\tAccuracy: 47.40%\n",
      "296\tValidation loss: 2.073523\tBest loss: 2.071171\tAccuracy: 47.50%\n",
      "297\tValidation loss: 2.077095\tBest loss: 2.071171\tAccuracy: 47.50%\n",
      "298\tValidation loss: 2.068350\tBest loss: 2.068350\tAccuracy: 48.60%\n",
      "299\tValidation loss: 2.068146\tBest loss: 2.068146\tAccuracy: 47.60%\n",
      "300\tValidation loss: 2.064439\tBest loss: 2.064439\tAccuracy: 47.00%\n",
      "301\tValidation loss: 2.061191\tBest loss: 2.061191\tAccuracy: 47.80%\n",
      "302\tValidation loss: 2.063484\tBest loss: 2.061191\tAccuracy: 47.60%\n",
      "303\tValidation loss: 2.062551\tBest loss: 2.061191\tAccuracy: 48.00%\n",
      "304\tValidation loss: 2.055726\tBest loss: 2.055726\tAccuracy: 48.70%\n",
      "305\tValidation loss: 2.059088\tBest loss: 2.055726\tAccuracy: 48.10%\n",
      "306\tValidation loss: 2.055561\tBest loss: 2.055561\tAccuracy: 47.90%\n",
      "307\tValidation loss: 2.060946\tBest loss: 2.055561\tAccuracy: 48.00%\n",
      "308\tValidation loss: 2.060324\tBest loss: 2.055561\tAccuracy: 47.50%\n",
      "309\tValidation loss: 2.056240\tBest loss: 2.055561\tAccuracy: 48.30%\n",
      "310\tValidation loss: 2.056472\tBest loss: 2.055561\tAccuracy: 48.00%\n",
      "311\tValidation loss: 2.055062\tBest loss: 2.055062\tAccuracy: 48.20%\n",
      "312\tValidation loss: 2.053601\tBest loss: 2.053601\tAccuracy: 48.40%\n",
      "313\tValidation loss: 2.052169\tBest loss: 2.052169\tAccuracy: 48.10%\n",
      "314\tValidation loss: 2.046957\tBest loss: 2.046957\tAccuracy: 48.10%\n",
      "315\tValidation loss: 2.048469\tBest loss: 2.046957\tAccuracy: 47.90%\n",
      "316\tValidation loss: 2.045692\tBest loss: 2.045692\tAccuracy: 48.00%\n",
      "317\tValidation loss: 2.047695\tBest loss: 2.045692\tAccuracy: 48.70%\n",
      "318\tValidation loss: 2.040256\tBest loss: 2.040256\tAccuracy: 48.60%\n",
      "319\tValidation loss: 2.037030\tBest loss: 2.037030\tAccuracy: 47.80%\n",
      "320\tValidation loss: 2.039637\tBest loss: 2.037030\tAccuracy: 48.40%\n",
      "321\tValidation loss: 2.037340\tBest loss: 2.037030\tAccuracy: 48.00%\n",
      "322\tValidation loss: 2.033705\tBest loss: 2.033705\tAccuracy: 48.30%\n",
      "323\tValidation loss: 2.033558\tBest loss: 2.033558\tAccuracy: 49.00%\n",
      "324\tValidation loss: 2.032892\tBest loss: 2.032892\tAccuracy: 48.80%\n",
      "325\tValidation loss: 2.027516\tBest loss: 2.027516\tAccuracy: 48.50%\n",
      "326\tValidation loss: 2.026951\tBest loss: 2.026951\tAccuracy: 49.10%\n",
      "327\tValidation loss: 2.025858\tBest loss: 2.025858\tAccuracy: 49.00%\n",
      "328\tValidation loss: 2.020327\tBest loss: 2.020327\tAccuracy: 48.30%\n",
      "329\tValidation loss: 2.026060\tBest loss: 2.020327\tAccuracy: 48.70%\n",
      "330\tValidation loss: 2.019008\tBest loss: 2.019008\tAccuracy: 49.20%\n",
      "331\tValidation loss: 2.017797\tBest loss: 2.017797\tAccuracy: 48.80%\n",
      "332\tValidation loss: 2.017444\tBest loss: 2.017444\tAccuracy: 48.80%\n",
      "333\tValidation loss: 2.013217\tBest loss: 2.013217\tAccuracy: 48.90%\n",
      "334\tValidation loss: 2.014667\tBest loss: 2.013217\tAccuracy: 49.00%\n",
      "335\tValidation loss: 2.014855\tBest loss: 2.013217\tAccuracy: 48.90%\n",
      "336\tValidation loss: 2.011415\tBest loss: 2.011415\tAccuracy: 49.00%\n",
      "337\tValidation loss: 2.009095\tBest loss: 2.009095\tAccuracy: 49.40%\n",
      "338\tValidation loss: 2.003999\tBest loss: 2.003999\tAccuracy: 48.70%\n",
      "339\tValidation loss: 2.008372\tBest loss: 2.003999\tAccuracy: 49.50%\n",
      "340\tValidation loss: 2.008617\tBest loss: 2.003999\tAccuracy: 50.20%\n",
      "341\tValidation loss: 2.007715\tBest loss: 2.003999\tAccuracy: 49.30%\n",
      "342\tValidation loss: 2.005863\tBest loss: 2.003999\tAccuracy: 49.60%\n",
      "343\tValidation loss: 2.006312\tBest loss: 2.003999\tAccuracy: 49.20%\n",
      "344\tValidation loss: 2.008443\tBest loss: 2.003999\tAccuracy: 48.70%\n",
      "345\tValidation loss: 2.000670\tBest loss: 2.000670\tAccuracy: 49.40%\n",
      "346\tValidation loss: 2.001845\tBest loss: 2.000670\tAccuracy: 49.30%\n",
      "347\tValidation loss: 2.002481\tBest loss: 2.000670\tAccuracy: 49.70%\n",
      "348\tValidation loss: 2.003312\tBest loss: 2.000670\tAccuracy: 49.20%\n",
      "349\tValidation loss: 1.998346\tBest loss: 1.998346\tAccuracy: 49.20%\n",
      "350\tValidation loss: 2.000251\tBest loss: 1.998346\tAccuracy: 49.60%\n",
      "351\tValidation loss: 1.996553\tBest loss: 1.996553\tAccuracy: 49.70%\n",
      "352\tValidation loss: 1.991123\tBest loss: 1.991123\tAccuracy: 49.10%\n",
      "353\tValidation loss: 1.990622\tBest loss: 1.990622\tAccuracy: 49.30%\n",
      "354\tValidation loss: 1.992542\tBest loss: 1.990622\tAccuracy: 49.20%\n",
      "355\tValidation loss: 1.984151\tBest loss: 1.984151\tAccuracy: 49.90%\n",
      "356\tValidation loss: 1.986676\tBest loss: 1.984151\tAccuracy: 49.60%\n",
      "357\tValidation loss: 1.988630\tBest loss: 1.984151\tAccuracy: 50.10%\n",
      "358\tValidation loss: 1.983932\tBest loss: 1.983932\tAccuracy: 50.20%\n",
      "359\tValidation loss: 1.982389\tBest loss: 1.982389\tAccuracy: 50.00%\n",
      "360\tValidation loss: 1.985392\tBest loss: 1.982389\tAccuracy: 49.50%\n",
      "361\tValidation loss: 1.981110\tBest loss: 1.981110\tAccuracy: 49.60%\n",
      "362\tValidation loss: 1.981060\tBest loss: 1.981060\tAccuracy: 50.10%\n",
      "363\tValidation loss: 1.980093\tBest loss: 1.980093\tAccuracy: 49.80%\n",
      "364\tValidation loss: 1.975449\tBest loss: 1.975449\tAccuracy: 50.30%\n",
      "365\tValidation loss: 1.980769\tBest loss: 1.975449\tAccuracy: 49.30%\n",
      "366\tValidation loss: 1.974171\tBest loss: 1.974171\tAccuracy: 49.90%\n",
      "367\tValidation loss: 1.978114\tBest loss: 1.974171\tAccuracy: 50.70%\n",
      "368\tValidation loss: 1.973154\tBest loss: 1.973154\tAccuracy: 50.00%\n",
      "369\tValidation loss: 1.974335\tBest loss: 1.973154\tAccuracy: 50.00%\n",
      "370\tValidation loss: 1.971715\tBest loss: 1.971715\tAccuracy: 50.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\tValidation loss: 1.972274\tBest loss: 1.971715\tAccuracy: 50.50%\n",
      "372\tValidation loss: 1.973309\tBest loss: 1.971715\tAccuracy: 50.50%\n",
      "373\tValidation loss: 1.974940\tBest loss: 1.971715\tAccuracy: 50.50%\n",
      "374\tValidation loss: 1.969908\tBest loss: 1.969908\tAccuracy: 50.80%\n",
      "375\tValidation loss: 1.967115\tBest loss: 1.967115\tAccuracy: 50.90%\n",
      "376\tValidation loss: 1.969347\tBest loss: 1.967115\tAccuracy: 50.70%\n",
      "377\tValidation loss: 1.967544\tBest loss: 1.967115\tAccuracy: 50.60%\n",
      "378\tValidation loss: 1.964669\tBest loss: 1.964669\tAccuracy: 50.30%\n",
      "379\tValidation loss: 1.964013\tBest loss: 1.964013\tAccuracy: 50.10%\n",
      "380\tValidation loss: 1.963241\tBest loss: 1.963241\tAccuracy: 51.00%\n",
      "381\tValidation loss: 1.964078\tBest loss: 1.963241\tAccuracy: 51.00%\n",
      "382\tValidation loss: 1.963245\tBest loss: 1.963241\tAccuracy: 50.70%\n",
      "383\tValidation loss: 1.961776\tBest loss: 1.961776\tAccuracy: 50.90%\n",
      "384\tValidation loss: 1.962255\tBest loss: 1.961776\tAccuracy: 50.60%\n",
      "385\tValidation loss: 1.955880\tBest loss: 1.955880\tAccuracy: 50.90%\n",
      "386\tValidation loss: 1.954655\tBest loss: 1.954655\tAccuracy: 50.80%\n",
      "387\tValidation loss: 1.953785\tBest loss: 1.953785\tAccuracy: 50.90%\n",
      "388\tValidation loss: 1.956130\tBest loss: 1.953785\tAccuracy: 50.80%\n",
      "389\tValidation loss: 1.948877\tBest loss: 1.948877\tAccuracy: 50.80%\n",
      "390\tValidation loss: 1.951239\tBest loss: 1.948877\tAccuracy: 51.50%\n",
      "391\tValidation loss: 1.951872\tBest loss: 1.948877\tAccuracy: 51.50%\n",
      "392\tValidation loss: 1.952181\tBest loss: 1.948877\tAccuracy: 51.10%\n",
      "393\tValidation loss: 1.951087\tBest loss: 1.948877\tAccuracy: 51.10%\n",
      "394\tValidation loss: 1.951030\tBest loss: 1.948877\tAccuracy: 51.20%\n",
      "395\tValidation loss: 1.949952\tBest loss: 1.948877\tAccuracy: 51.00%\n",
      "396\tValidation loss: 1.948481\tBest loss: 1.948481\tAccuracy: 51.20%\n",
      "397\tValidation loss: 1.949868\tBest loss: 1.948481\tAccuracy: 51.00%\n",
      "398\tValidation loss: 1.949424\tBest loss: 1.948481\tAccuracy: 51.50%\n",
      "399\tValidation loss: 1.947093\tBest loss: 1.947093\tAccuracy: 52.00%\n",
      "400\tValidation loss: 1.942429\tBest loss: 1.942429\tAccuracy: 51.60%\n",
      "401\tValidation loss: 1.944826\tBest loss: 1.942429\tAccuracy: 51.20%\n",
      "402\tValidation loss: 1.942199\tBest loss: 1.942199\tAccuracy: 51.60%\n",
      "403\tValidation loss: 1.941352\tBest loss: 1.941352\tAccuracy: 50.80%\n",
      "404\tValidation loss: 1.944479\tBest loss: 1.941352\tAccuracy: 51.50%\n",
      "405\tValidation loss: 1.941004\tBest loss: 1.941004\tAccuracy: 51.10%\n",
      "406\tValidation loss: 1.944033\tBest loss: 1.941004\tAccuracy: 51.70%\n",
      "407\tValidation loss: 1.941451\tBest loss: 1.941004\tAccuracy: 51.50%\n",
      "408\tValidation loss: 1.940064\tBest loss: 1.940064\tAccuracy: 51.90%\n",
      "409\tValidation loss: 1.936452\tBest loss: 1.936452\tAccuracy: 51.40%\n",
      "410\tValidation loss: 1.935789\tBest loss: 1.935789\tAccuracy: 52.60%\n",
      "411\tValidation loss: 1.937156\tBest loss: 1.935789\tAccuracy: 52.80%\n",
      "412\tValidation loss: 1.934944\tBest loss: 1.934944\tAccuracy: 52.60%\n",
      "413\tValidation loss: 1.938272\tBest loss: 1.934944\tAccuracy: 52.40%\n",
      "414\tValidation loss: 1.934607\tBest loss: 1.934607\tAccuracy: 52.10%\n",
      "415\tValidation loss: 1.931844\tBest loss: 1.931844\tAccuracy: 52.20%\n",
      "416\tValidation loss: 1.932491\tBest loss: 1.931844\tAccuracy: 52.40%\n",
      "417\tValidation loss: 1.929758\tBest loss: 1.929758\tAccuracy: 52.20%\n",
      "418\tValidation loss: 1.927583\tBest loss: 1.927583\tAccuracy: 52.80%\n",
      "419\tValidation loss: 1.932397\tBest loss: 1.927583\tAccuracy: 52.10%\n",
      "420\tValidation loss: 1.924247\tBest loss: 1.924247\tAccuracy: 52.80%\n",
      "421\tValidation loss: 1.925433\tBest loss: 1.924247\tAccuracy: 51.80%\n",
      "422\tValidation loss: 1.924711\tBest loss: 1.924247\tAccuracy: 51.40%\n",
      "423\tValidation loss: 1.926490\tBest loss: 1.924247\tAccuracy: 51.80%\n",
      "424\tValidation loss: 1.928413\tBest loss: 1.924247\tAccuracy: 52.50%\n",
      "425\tValidation loss: 1.921946\tBest loss: 1.921946\tAccuracy: 52.20%\n",
      "426\tValidation loss: 1.918487\tBest loss: 1.918487\tAccuracy: 51.70%\n",
      "427\tValidation loss: 1.919253\tBest loss: 1.918487\tAccuracy: 52.50%\n",
      "428\tValidation loss: 1.922177\tBest loss: 1.918487\tAccuracy: 52.70%\n",
      "429\tValidation loss: 1.922916\tBest loss: 1.918487\tAccuracy: 52.80%\n",
      "430\tValidation loss: 1.918859\tBest loss: 1.918487\tAccuracy: 52.50%\n",
      "431\tValidation loss: 1.915822\tBest loss: 1.915822\tAccuracy: 53.10%\n",
      "432\tValidation loss: 1.914618\tBest loss: 1.914618\tAccuracy: 52.20%\n",
      "433\tValidation loss: 1.910363\tBest loss: 1.910363\tAccuracy: 52.80%\n",
      "434\tValidation loss: 1.911181\tBest loss: 1.910363\tAccuracy: 52.40%\n",
      "435\tValidation loss: 1.915348\tBest loss: 1.910363\tAccuracy: 52.90%\n",
      "436\tValidation loss: 1.909940\tBest loss: 1.909940\tAccuracy: 52.40%\n",
      "437\tValidation loss: 1.912060\tBest loss: 1.909940\tAccuracy: 52.30%\n",
      "438\tValidation loss: 1.910998\tBest loss: 1.909940\tAccuracy: 52.50%\n",
      "439\tValidation loss: 1.911188\tBest loss: 1.909940\tAccuracy: 53.20%\n",
      "440\tValidation loss: 1.907024\tBest loss: 1.907024\tAccuracy: 53.70%\n",
      "441\tValidation loss: 1.907076\tBest loss: 1.907024\tAccuracy: 53.20%\n",
      "442\tValidation loss: 1.910296\tBest loss: 1.907024\tAccuracy: 53.10%\n",
      "443\tValidation loss: 1.905880\tBest loss: 1.905880\tAccuracy: 52.90%\n",
      "444\tValidation loss: 1.906521\tBest loss: 1.905880\tAccuracy: 53.30%\n",
      "445\tValidation loss: 1.901602\tBest loss: 1.901602\tAccuracy: 53.20%\n",
      "446\tValidation loss: 1.900491\tBest loss: 1.900491\tAccuracy: 53.60%\n",
      "447\tValidation loss: 1.900992\tBest loss: 1.900491\tAccuracy: 52.80%\n",
      "448\tValidation loss: 1.901897\tBest loss: 1.900491\tAccuracy: 52.90%\n",
      "449\tValidation loss: 1.900848\tBest loss: 1.900491\tAccuracy: 53.60%\n",
      "450\tValidation loss: 1.902240\tBest loss: 1.900491\tAccuracy: 52.80%\n",
      "451\tValidation loss: 1.906301\tBest loss: 1.900491\tAccuracy: 52.70%\n",
      "452\tValidation loss: 1.898898\tBest loss: 1.898898\tAccuracy: 52.80%\n",
      "453\tValidation loss: 1.901178\tBest loss: 1.898898\tAccuracy: 52.60%\n",
      "454\tValidation loss: 1.900583\tBest loss: 1.898898\tAccuracy: 53.00%\n",
      "455\tValidation loss: 1.897161\tBest loss: 1.897161\tAccuracy: 52.90%\n",
      "456\tValidation loss: 1.894600\tBest loss: 1.894600\tAccuracy: 53.20%\n",
      "457\tValidation loss: 1.893515\tBest loss: 1.893515\tAccuracy: 53.00%\n",
      "458\tValidation loss: 1.891284\tBest loss: 1.891284\tAccuracy: 53.00%\n",
      "459\tValidation loss: 1.893695\tBest loss: 1.891284\tAccuracy: 53.80%\n",
      "460\tValidation loss: 1.893636\tBest loss: 1.891284\tAccuracy: 53.50%\n",
      "461\tValidation loss: 1.889851\tBest loss: 1.889851\tAccuracy: 53.60%\n",
      "462\tValidation loss: 1.888057\tBest loss: 1.888057\tAccuracy: 53.10%\n",
      "463\tValidation loss: 1.890251\tBest loss: 1.888057\tAccuracy: 52.80%\n",
      "464\tValidation loss: 1.890142\tBest loss: 1.888057\tAccuracy: 53.20%\n",
      "465\tValidation loss: 1.887700\tBest loss: 1.887700\tAccuracy: 53.50%\n",
      "466\tValidation loss: 1.885447\tBest loss: 1.885447\tAccuracy: 53.30%\n",
      "467\tValidation loss: 1.884636\tBest loss: 1.884636\tAccuracy: 53.30%\n",
      "468\tValidation loss: 1.886149\tBest loss: 1.884636\tAccuracy: 53.50%\n",
      "469\tValidation loss: 1.882902\tBest loss: 1.882902\tAccuracy: 53.30%\n",
      "470\tValidation loss: 1.883247\tBest loss: 1.882902\tAccuracy: 53.40%\n",
      "471\tValidation loss: 1.880602\tBest loss: 1.880602\tAccuracy: 53.70%\n",
      "472\tValidation loss: 1.880869\tBest loss: 1.880602\tAccuracy: 54.10%\n",
      "473\tValidation loss: 1.879466\tBest loss: 1.879466\tAccuracy: 53.70%\n",
      "474\tValidation loss: 1.880747\tBest loss: 1.879466\tAccuracy: 53.50%\n",
      "475\tValidation loss: 1.877881\tBest loss: 1.877881\tAccuracy: 53.70%\n",
      "476\tValidation loss: 1.879045\tBest loss: 1.877881\tAccuracy: 53.10%\n",
      "477\tValidation loss: 1.880760\tBest loss: 1.877881\tAccuracy: 53.40%\n",
      "478\tValidation loss: 1.877107\tBest loss: 1.877107\tAccuracy: 53.50%\n",
      "479\tValidation loss: 1.877640\tBest loss: 1.877107\tAccuracy: 53.70%\n",
      "480\tValidation loss: 1.876499\tBest loss: 1.876499\tAccuracy: 53.80%\n",
      "481\tValidation loss: 1.877550\tBest loss: 1.876499\tAccuracy: 53.80%\n",
      "482\tValidation loss: 1.878537\tBest loss: 1.876499\tAccuracy: 54.30%\n",
      "483\tValidation loss: 1.874999\tBest loss: 1.874999\tAccuracy: 53.70%\n",
      "484\tValidation loss: 1.874105\tBest loss: 1.874105\tAccuracy: 53.40%\n",
      "485\tValidation loss: 1.874020\tBest loss: 1.874020\tAccuracy: 52.90%\n",
      "486\tValidation loss: 1.871840\tBest loss: 1.871840\tAccuracy: 53.10%\n",
      "487\tValidation loss: 1.871450\tBest loss: 1.871450\tAccuracy: 53.90%\n",
      "488\tValidation loss: 1.870127\tBest loss: 1.870127\tAccuracy: 53.60%\n",
      "489\tValidation loss: 1.873261\tBest loss: 1.870127\tAccuracy: 53.40%\n",
      "490\tValidation loss: 1.870881\tBest loss: 1.870127\tAccuracy: 53.80%\n",
      "491\tValidation loss: 1.868679\tBest loss: 1.868679\tAccuracy: 53.80%\n",
      "492\tValidation loss: 1.868215\tBest loss: 1.868215\tAccuracy: 53.60%\n",
      "493\tValidation loss: 1.868088\tBest loss: 1.868088\tAccuracy: 54.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\tValidation loss: 1.867281\tBest loss: 1.867281\tAccuracy: 53.60%\n",
      "495\tValidation loss: 1.868450\tBest loss: 1.867281\tAccuracy: 53.60%\n",
      "496\tValidation loss: 1.865493\tBest loss: 1.865493\tAccuracy: 53.80%\n",
      "497\tValidation loss: 1.865339\tBest loss: 1.865339\tAccuracy: 53.90%\n",
      "498\tValidation loss: 1.864346\tBest loss: 1.864346\tAccuracy: 53.50%\n",
      "499\tValidation loss: 1.865019\tBest loss: 1.864346\tAccuracy: 52.90%\n",
      "500\tValidation loss: 1.862124\tBest loss: 1.862124\tAccuracy: 53.70%\n",
      "501\tValidation loss: 1.864896\tBest loss: 1.862124\tAccuracy: 53.50%\n",
      "502\tValidation loss: 1.862319\tBest loss: 1.862124\tAccuracy: 53.20%\n",
      "503\tValidation loss: 1.857280\tBest loss: 1.857280\tAccuracy: 54.30%\n",
      "504\tValidation loss: 1.859005\tBest loss: 1.857280\tAccuracy: 54.00%\n",
      "505\tValidation loss: 1.860445\tBest loss: 1.857280\tAccuracy: 54.00%\n",
      "506\tValidation loss: 1.859176\tBest loss: 1.857280\tAccuracy: 53.90%\n",
      "507\tValidation loss: 1.856709\tBest loss: 1.856709\tAccuracy: 54.20%\n",
      "508\tValidation loss: 1.856825\tBest loss: 1.856709\tAccuracy: 54.50%\n",
      "509\tValidation loss: 1.855119\tBest loss: 1.855119\tAccuracy: 53.50%\n",
      "510\tValidation loss: 1.855721\tBest loss: 1.855119\tAccuracy: 53.90%\n",
      "511\tValidation loss: 1.857095\tBest loss: 1.855119\tAccuracy: 53.30%\n",
      "512\tValidation loss: 1.854931\tBest loss: 1.854931\tAccuracy: 53.80%\n",
      "513\tValidation loss: 1.858700\tBest loss: 1.854931\tAccuracy: 54.40%\n",
      "514\tValidation loss: 1.856614\tBest loss: 1.854931\tAccuracy: 53.80%\n",
      "515\tValidation loss: 1.854550\tBest loss: 1.854550\tAccuracy: 54.40%\n",
      "516\tValidation loss: 1.855597\tBest loss: 1.854550\tAccuracy: 54.20%\n",
      "517\tValidation loss: 1.853547\tBest loss: 1.853547\tAccuracy: 53.80%\n",
      "518\tValidation loss: 1.855996\tBest loss: 1.853547\tAccuracy: 54.50%\n",
      "519\tValidation loss: 1.852230\tBest loss: 1.852230\tAccuracy: 53.90%\n",
      "520\tValidation loss: 1.856007\tBest loss: 1.852230\tAccuracy: 53.80%\n",
      "521\tValidation loss: 1.851193\tBest loss: 1.851193\tAccuracy: 54.50%\n",
      "522\tValidation loss: 1.850315\tBest loss: 1.850315\tAccuracy: 53.90%\n",
      "523\tValidation loss: 1.848445\tBest loss: 1.848445\tAccuracy: 53.90%\n",
      "524\tValidation loss: 1.846524\tBest loss: 1.846524\tAccuracy: 53.90%\n",
      "525\tValidation loss: 1.845189\tBest loss: 1.845189\tAccuracy: 53.70%\n",
      "526\tValidation loss: 1.843967\tBest loss: 1.843967\tAccuracy: 53.50%\n",
      "527\tValidation loss: 1.845825\tBest loss: 1.843967\tAccuracy: 53.70%\n",
      "528\tValidation loss: 1.844904\tBest loss: 1.843967\tAccuracy: 53.30%\n",
      "529\tValidation loss: 1.848497\tBest loss: 1.843967\tAccuracy: 54.10%\n",
      "530\tValidation loss: 1.843336\tBest loss: 1.843336\tAccuracy: 54.10%\n",
      "531\tValidation loss: 1.843975\tBest loss: 1.843336\tAccuracy: 53.80%\n",
      "532\tValidation loss: 1.843557\tBest loss: 1.843336\tAccuracy: 53.50%\n",
      "533\tValidation loss: 1.843987\tBest loss: 1.843336\tAccuracy: 54.00%\n",
      "534\tValidation loss: 1.842878\tBest loss: 1.842878\tAccuracy: 53.80%\n",
      "535\tValidation loss: 1.840891\tBest loss: 1.840891\tAccuracy: 53.10%\n",
      "536\tValidation loss: 1.840741\tBest loss: 1.840741\tAccuracy: 54.00%\n",
      "537\tValidation loss: 1.840785\tBest loss: 1.840741\tAccuracy: 54.00%\n",
      "538\tValidation loss: 1.840475\tBest loss: 1.840475\tAccuracy: 54.00%\n",
      "539\tValidation loss: 1.841383\tBest loss: 1.840475\tAccuracy: 54.30%\n",
      "540\tValidation loss: 1.839624\tBest loss: 1.839624\tAccuracy: 53.80%\n",
      "541\tValidation loss: 1.838951\tBest loss: 1.838951\tAccuracy: 54.40%\n",
      "542\tValidation loss: 1.835177\tBest loss: 1.835177\tAccuracy: 54.00%\n",
      "543\tValidation loss: 1.835595\tBest loss: 1.835177\tAccuracy: 53.90%\n",
      "544\tValidation loss: 1.834756\tBest loss: 1.834756\tAccuracy: 53.70%\n",
      "545\tValidation loss: 1.834664\tBest loss: 1.834664\tAccuracy: 53.90%\n",
      "546\tValidation loss: 1.833028\tBest loss: 1.833028\tAccuracy: 53.80%\n",
      "547\tValidation loss: 1.829869\tBest loss: 1.829869\tAccuracy: 54.40%\n",
      "548\tValidation loss: 1.830135\tBest loss: 1.829869\tAccuracy: 54.30%\n",
      "549\tValidation loss: 1.831403\tBest loss: 1.829869\tAccuracy: 54.30%\n",
      "550\tValidation loss: 1.827228\tBest loss: 1.827228\tAccuracy: 54.40%\n",
      "551\tValidation loss: 1.833702\tBest loss: 1.827228\tAccuracy: 54.30%\n",
      "552\tValidation loss: 1.830378\tBest loss: 1.827228\tAccuracy: 54.40%\n",
      "553\tValidation loss: 1.832090\tBest loss: 1.827228\tAccuracy: 53.80%\n",
      "554\tValidation loss: 1.828613\tBest loss: 1.827228\tAccuracy: 53.40%\n",
      "555\tValidation loss: 1.830110\tBest loss: 1.827228\tAccuracy: 53.50%\n",
      "556\tValidation loss: 1.828995\tBest loss: 1.827228\tAccuracy: 54.00%\n",
      "557\tValidation loss: 1.828914\tBest loss: 1.827228\tAccuracy: 53.90%\n",
      "558\tValidation loss: 1.829026\tBest loss: 1.827228\tAccuracy: 53.60%\n",
      "559\tValidation loss: 1.828389\tBest loss: 1.827228\tAccuracy: 53.40%\n",
      "560\tValidation loss: 1.825209\tBest loss: 1.825209\tAccuracy: 53.90%\n",
      "561\tValidation loss: 1.823694\tBest loss: 1.823694\tAccuracy: 53.70%\n",
      "562\tValidation loss: 1.825959\tBest loss: 1.823694\tAccuracy: 53.70%\n",
      "563\tValidation loss: 1.824810\tBest loss: 1.823694\tAccuracy: 53.80%\n",
      "564\tValidation loss: 1.824539\tBest loss: 1.823694\tAccuracy: 53.60%\n",
      "565\tValidation loss: 1.824079\tBest loss: 1.823694\tAccuracy: 54.20%\n",
      "566\tValidation loss: 1.822569\tBest loss: 1.822569\tAccuracy: 53.00%\n",
      "567\tValidation loss: 1.824068\tBest loss: 1.822569\tAccuracy: 53.50%\n",
      "568\tValidation loss: 1.824182\tBest loss: 1.822569\tAccuracy: 53.70%\n",
      "569\tValidation loss: 1.823925\tBest loss: 1.822569\tAccuracy: 53.30%\n",
      "570\tValidation loss: 1.825354\tBest loss: 1.822569\tAccuracy: 53.80%\n",
      "571\tValidation loss: 1.824829\tBest loss: 1.822569\tAccuracy: 53.60%\n",
      "572\tValidation loss: 1.822890\tBest loss: 1.822569\tAccuracy: 53.30%\n",
      "573\tValidation loss: 1.821224\tBest loss: 1.821224\tAccuracy: 53.50%\n",
      "574\tValidation loss: 1.818267\tBest loss: 1.818267\tAccuracy: 53.60%\n",
      "575\tValidation loss: 1.820864\tBest loss: 1.818267\tAccuracy: 53.80%\n",
      "576\tValidation loss: 1.818359\tBest loss: 1.818267\tAccuracy: 53.60%\n",
      "577\tValidation loss: 1.817947\tBest loss: 1.817947\tAccuracy: 53.70%\n",
      "578\tValidation loss: 1.816723\tBest loss: 1.816723\tAccuracy: 53.20%\n",
      "579\tValidation loss: 1.814198\tBest loss: 1.814198\tAccuracy: 53.30%\n",
      "580\tValidation loss: 1.814799\tBest loss: 1.814198\tAccuracy: 53.40%\n",
      "581\tValidation loss: 1.811746\tBest loss: 1.811746\tAccuracy: 53.50%\n",
      "582\tValidation loss: 1.816374\tBest loss: 1.811746\tAccuracy: 54.00%\n",
      "583\tValidation loss: 1.814394\tBest loss: 1.811746\tAccuracy: 54.10%\n",
      "584\tValidation loss: 1.814337\tBest loss: 1.811746\tAccuracy: 53.80%\n",
      "585\tValidation loss: 1.809288\tBest loss: 1.809288\tAccuracy: 53.50%\n",
      "586\tValidation loss: 1.810007\tBest loss: 1.809288\tAccuracy: 53.40%\n",
      "587\tValidation loss: 1.810916\tBest loss: 1.809288\tAccuracy: 53.20%\n",
      "588\tValidation loss: 1.811158\tBest loss: 1.809288\tAccuracy: 53.30%\n",
      "589\tValidation loss: 1.809014\tBest loss: 1.809014\tAccuracy: 53.10%\n",
      "590\tValidation loss: 1.808955\tBest loss: 1.808955\tAccuracy: 53.70%\n",
      "591\tValidation loss: 1.808560\tBest loss: 1.808560\tAccuracy: 53.30%\n",
      "592\tValidation loss: 1.811187\tBest loss: 1.808560\tAccuracy: 53.80%\n",
      "593\tValidation loss: 1.808991\tBest loss: 1.808560\tAccuracy: 53.90%\n",
      "594\tValidation loss: 1.807193\tBest loss: 1.807193\tAccuracy: 54.10%\n",
      "595\tValidation loss: 1.807640\tBest loss: 1.807193\tAccuracy: 53.90%\n",
      "596\tValidation loss: 1.806550\tBest loss: 1.806550\tAccuracy: 54.20%\n",
      "597\tValidation loss: 1.805589\tBest loss: 1.805589\tAccuracy: 53.50%\n",
      "598\tValidation loss: 1.802200\tBest loss: 1.802200\tAccuracy: 53.80%\n",
      "599\tValidation loss: 1.803892\tBest loss: 1.802200\tAccuracy: 53.80%\n",
      "600\tValidation loss: 1.801045\tBest loss: 1.801045\tAccuracy: 53.40%\n",
      "601\tValidation loss: 1.799182\tBest loss: 1.799182\tAccuracy: 53.60%\n",
      "602\tValidation loss: 1.799475\tBest loss: 1.799182\tAccuracy: 54.00%\n",
      "603\tValidation loss: 1.802540\tBest loss: 1.799182\tAccuracy: 54.00%\n",
      "604\tValidation loss: 1.801351\tBest loss: 1.799182\tAccuracy: 53.60%\n",
      "605\tValidation loss: 1.798349\tBest loss: 1.798349\tAccuracy: 53.60%\n",
      "606\tValidation loss: 1.797946\tBest loss: 1.797946\tAccuracy: 52.90%\n",
      "607\tValidation loss: 1.799767\tBest loss: 1.797946\tAccuracy: 53.10%\n",
      "608\tValidation loss: 1.802359\tBest loss: 1.797946\tAccuracy: 53.60%\n",
      "609\tValidation loss: 1.801435\tBest loss: 1.797946\tAccuracy: 53.80%\n",
      "610\tValidation loss: 1.798892\tBest loss: 1.797946\tAccuracy: 53.60%\n",
      "611\tValidation loss: 1.798384\tBest loss: 1.797946\tAccuracy: 53.80%\n",
      "612\tValidation loss: 1.799169\tBest loss: 1.797946\tAccuracy: 53.90%\n",
      "613\tValidation loss: 1.799716\tBest loss: 1.797946\tAccuracy: 53.90%\n",
      "614\tValidation loss: 1.794921\tBest loss: 1.794921\tAccuracy: 53.80%\n",
      "615\tValidation loss: 1.793604\tBest loss: 1.793604\tAccuracy: 54.10%\n",
      "616\tValidation loss: 1.795256\tBest loss: 1.793604\tAccuracy: 54.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\tValidation loss: 1.793500\tBest loss: 1.793500\tAccuracy: 53.60%\n",
      "618\tValidation loss: 1.797071\tBest loss: 1.793500\tAccuracy: 54.30%\n",
      "619\tValidation loss: 1.796322\tBest loss: 1.793500\tAccuracy: 53.70%\n",
      "620\tValidation loss: 1.794615\tBest loss: 1.793500\tAccuracy: 54.30%\n",
      "621\tValidation loss: 1.796961\tBest loss: 1.793500\tAccuracy: 53.70%\n",
      "622\tValidation loss: 1.793370\tBest loss: 1.793370\tAccuracy: 53.60%\n",
      "623\tValidation loss: 1.793101\tBest loss: 1.793101\tAccuracy: 53.60%\n",
      "624\tValidation loss: 1.794825\tBest loss: 1.793101\tAccuracy: 53.20%\n",
      "625\tValidation loss: 1.791786\tBest loss: 1.791786\tAccuracy: 54.00%\n",
      "626\tValidation loss: 1.791109\tBest loss: 1.791109\tAccuracy: 53.80%\n",
      "627\tValidation loss: 1.792202\tBest loss: 1.791109\tAccuracy: 53.10%\n",
      "628\tValidation loss: 1.789796\tBest loss: 1.789796\tAccuracy: 53.30%\n",
      "629\tValidation loss: 1.787822\tBest loss: 1.787822\tAccuracy: 53.30%\n",
      "630\tValidation loss: 1.786578\tBest loss: 1.786578\tAccuracy: 53.30%\n",
      "631\tValidation loss: 1.788960\tBest loss: 1.786578\tAccuracy: 53.70%\n",
      "632\tValidation loss: 1.787022\tBest loss: 1.786578\tAccuracy: 53.80%\n",
      "633\tValidation loss: 1.786541\tBest loss: 1.786541\tAccuracy: 53.60%\n",
      "634\tValidation loss: 1.785634\tBest loss: 1.785634\tAccuracy: 54.20%\n",
      "635\tValidation loss: 1.780921\tBest loss: 1.780921\tAccuracy: 54.10%\n",
      "636\tValidation loss: 1.780625\tBest loss: 1.780625\tAccuracy: 53.80%\n",
      "637\tValidation loss: 1.781191\tBest loss: 1.780625\tAccuracy: 53.80%\n",
      "638\tValidation loss: 1.783208\tBest loss: 1.780625\tAccuracy: 53.80%\n",
      "639\tValidation loss: 1.780351\tBest loss: 1.780351\tAccuracy: 53.90%\n",
      "640\tValidation loss: 1.779548\tBest loss: 1.779548\tAccuracy: 54.00%\n",
      "641\tValidation loss: 1.777663\tBest loss: 1.777663\tAccuracy: 54.20%\n",
      "642\tValidation loss: 1.780557\tBest loss: 1.777663\tAccuracy: 53.90%\n",
      "643\tValidation loss: 1.777622\tBest loss: 1.777622\tAccuracy: 53.90%\n",
      "644\tValidation loss: 1.779569\tBest loss: 1.777622\tAccuracy: 54.00%\n",
      "645\tValidation loss: 1.776443\tBest loss: 1.776443\tAccuracy: 54.00%\n",
      "646\tValidation loss: 1.776116\tBest loss: 1.776116\tAccuracy: 54.60%\n",
      "647\tValidation loss: 1.774149\tBest loss: 1.774149\tAccuracy: 54.40%\n",
      "648\tValidation loss: 1.777972\tBest loss: 1.774149\tAccuracy: 54.10%\n",
      "649\tValidation loss: 1.776172\tBest loss: 1.774149\tAccuracy: 53.80%\n",
      "650\tValidation loss: 1.773053\tBest loss: 1.773053\tAccuracy: 53.70%\n",
      "651\tValidation loss: 1.771302\tBest loss: 1.771302\tAccuracy: 54.50%\n",
      "652\tValidation loss: 1.771880\tBest loss: 1.771302\tAccuracy: 54.40%\n",
      "653\tValidation loss: 1.772960\tBest loss: 1.771302\tAccuracy: 54.40%\n",
      "654\tValidation loss: 1.772465\tBest loss: 1.771302\tAccuracy: 54.40%\n",
      "655\tValidation loss: 1.775582\tBest loss: 1.771302\tAccuracy: 54.00%\n",
      "656\tValidation loss: 1.779061\tBest loss: 1.771302\tAccuracy: 53.80%\n",
      "657\tValidation loss: 1.774821\tBest loss: 1.771302\tAccuracy: 53.80%\n",
      "658\tValidation loss: 1.776091\tBest loss: 1.771302\tAccuracy: 54.00%\n",
      "659\tValidation loss: 1.771630\tBest loss: 1.771302\tAccuracy: 54.40%\n",
      "660\tValidation loss: 1.773186\tBest loss: 1.771302\tAccuracy: 54.50%\n",
      "661\tValidation loss: 1.772813\tBest loss: 1.771302\tAccuracy: 54.80%\n",
      "662\tValidation loss: 1.772472\tBest loss: 1.771302\tAccuracy: 54.40%\n",
      "663\tValidation loss: 1.772148\tBest loss: 1.771302\tAccuracy: 54.20%\n",
      "664\tValidation loss: 1.772089\tBest loss: 1.771302\tAccuracy: 54.10%\n",
      "665\tValidation loss: 1.770867\tBest loss: 1.770867\tAccuracy: 54.70%\n",
      "666\tValidation loss: 1.768149\tBest loss: 1.768149\tAccuracy: 54.50%\n",
      "667\tValidation loss: 1.769491\tBest loss: 1.768149\tAccuracy: 54.30%\n",
      "668\tValidation loss: 1.771374\tBest loss: 1.768149\tAccuracy: 54.30%\n",
      "669\tValidation loss: 1.767637\tBest loss: 1.767637\tAccuracy: 54.50%\n",
      "670\tValidation loss: 1.767095\tBest loss: 1.767095\tAccuracy: 54.30%\n",
      "671\tValidation loss: 1.766030\tBest loss: 1.766030\tAccuracy: 54.40%\n",
      "672\tValidation loss: 1.763966\tBest loss: 1.763966\tAccuracy: 54.60%\n",
      "673\tValidation loss: 1.764599\tBest loss: 1.763966\tAccuracy: 54.60%\n",
      "674\tValidation loss: 1.764615\tBest loss: 1.763966\tAccuracy: 54.60%\n",
      "675\tValidation loss: 1.758690\tBest loss: 1.758690\tAccuracy: 54.60%\n",
      "676\tValidation loss: 1.762987\tBest loss: 1.758690\tAccuracy: 54.70%\n",
      "677\tValidation loss: 1.764226\tBest loss: 1.758690\tAccuracy: 54.60%\n",
      "678\tValidation loss: 1.763740\tBest loss: 1.758690\tAccuracy: 54.30%\n",
      "679\tValidation loss: 1.763385\tBest loss: 1.758690\tAccuracy: 54.80%\n",
      "680\tValidation loss: 1.760365\tBest loss: 1.758690\tAccuracy: 54.90%\n",
      "681\tValidation loss: 1.763255\tBest loss: 1.758690\tAccuracy: 54.90%\n",
      "682\tValidation loss: 1.761040\tBest loss: 1.758690\tAccuracy: 54.50%\n",
      "683\tValidation loss: 1.761804\tBest loss: 1.758690\tAccuracy: 54.60%\n",
      "684\tValidation loss: 1.762892\tBest loss: 1.758690\tAccuracy: 54.90%\n",
      "685\tValidation loss: 1.759543\tBest loss: 1.758690\tAccuracy: 55.10%\n",
      "686\tValidation loss: 1.758081\tBest loss: 1.758081\tAccuracy: 54.50%\n",
      "687\tValidation loss: 1.762037\tBest loss: 1.758081\tAccuracy: 54.90%\n",
      "688\tValidation loss: 1.758365\tBest loss: 1.758081\tAccuracy: 55.30%\n",
      "689\tValidation loss: 1.756101\tBest loss: 1.756101\tAccuracy: 54.70%\n",
      "690\tValidation loss: 1.758655\tBest loss: 1.756101\tAccuracy: 54.70%\n",
      "691\tValidation loss: 1.757004\tBest loss: 1.756101\tAccuracy: 55.20%\n",
      "692\tValidation loss: 1.757355\tBest loss: 1.756101\tAccuracy: 55.00%\n",
      "693\tValidation loss: 1.755841\tBest loss: 1.755841\tAccuracy: 54.60%\n",
      "694\tValidation loss: 1.753288\tBest loss: 1.753288\tAccuracy: 54.70%\n",
      "695\tValidation loss: 1.755155\tBest loss: 1.753288\tAccuracy: 55.60%\n",
      "696\tValidation loss: 1.754623\tBest loss: 1.753288\tAccuracy: 55.00%\n",
      "697\tValidation loss: 1.750882\tBest loss: 1.750882\tAccuracy: 55.50%\n",
      "698\tValidation loss: 1.753102\tBest loss: 1.750882\tAccuracy: 55.10%\n",
      "699\tValidation loss: 1.751808\tBest loss: 1.750882\tAccuracy: 55.10%\n",
      "700\tValidation loss: 1.749647\tBest loss: 1.749647\tAccuracy: 54.90%\n",
      "701\tValidation loss: 1.747751\tBest loss: 1.747751\tAccuracy: 54.80%\n",
      "702\tValidation loss: 1.746970\tBest loss: 1.746970\tAccuracy: 55.10%\n",
      "703\tValidation loss: 1.746509\tBest loss: 1.746509\tAccuracy: 55.50%\n",
      "704\tValidation loss: 1.748110\tBest loss: 1.746509\tAccuracy: 55.70%\n",
      "705\tValidation loss: 1.743305\tBest loss: 1.743305\tAccuracy: 55.70%\n",
      "706\tValidation loss: 1.745666\tBest loss: 1.743305\tAccuracy: 55.00%\n",
      "707\tValidation loss: 1.743206\tBest loss: 1.743206\tAccuracy: 55.40%\n",
      "708\tValidation loss: 1.743873\tBest loss: 1.743206\tAccuracy: 55.50%\n",
      "709\tValidation loss: 1.744760\tBest loss: 1.743206\tAccuracy: 55.10%\n",
      "710\tValidation loss: 1.747329\tBest loss: 1.743206\tAccuracy: 55.30%\n",
      "711\tValidation loss: 1.746031\tBest loss: 1.743206\tAccuracy: 55.50%\n",
      "712\tValidation loss: 1.745232\tBest loss: 1.743206\tAccuracy: 55.20%\n",
      "713\tValidation loss: 1.742206\tBest loss: 1.742206\tAccuracy: 55.40%\n",
      "714\tValidation loss: 1.743926\tBest loss: 1.742206\tAccuracy: 55.00%\n",
      "715\tValidation loss: 1.747174\tBest loss: 1.742206\tAccuracy: 55.20%\n",
      "716\tValidation loss: 1.746038\tBest loss: 1.742206\tAccuracy: 55.10%\n",
      "717\tValidation loss: 1.743909\tBest loss: 1.742206\tAccuracy: 55.10%\n",
      "718\tValidation loss: 1.739167\tBest loss: 1.739167\tAccuracy: 54.90%\n",
      "719\tValidation loss: 1.737852\tBest loss: 1.737852\tAccuracy: 55.40%\n",
      "720\tValidation loss: 1.736074\tBest loss: 1.736074\tAccuracy: 55.30%\n",
      "721\tValidation loss: 1.739594\tBest loss: 1.736074\tAccuracy: 55.60%\n",
      "722\tValidation loss: 1.739498\tBest loss: 1.736074\tAccuracy: 56.00%\n",
      "723\tValidation loss: 1.739026\tBest loss: 1.736074\tAccuracy: 56.30%\n",
      "724\tValidation loss: 1.737364\tBest loss: 1.736074\tAccuracy: 55.80%\n",
      "725\tValidation loss: 1.735819\tBest loss: 1.735819\tAccuracy: 55.40%\n",
      "726\tValidation loss: 1.737423\tBest loss: 1.735819\tAccuracy: 55.40%\n",
      "727\tValidation loss: 1.737503\tBest loss: 1.735819\tAccuracy: 55.70%\n",
      "728\tValidation loss: 1.736077\tBest loss: 1.735819\tAccuracy: 55.00%\n",
      "729\tValidation loss: 1.735949\tBest loss: 1.735819\tAccuracy: 55.80%\n",
      "730\tValidation loss: 1.735220\tBest loss: 1.735220\tAccuracy: 55.50%\n",
      "731\tValidation loss: 1.736610\tBest loss: 1.735220\tAccuracy: 55.90%\n",
      "732\tValidation loss: 1.731927\tBest loss: 1.731927\tAccuracy: 56.10%\n",
      "733\tValidation loss: 1.732527\tBest loss: 1.731927\tAccuracy: 56.00%\n",
      "734\tValidation loss: 1.732998\tBest loss: 1.731927\tAccuracy: 56.30%\n",
      "735\tValidation loss: 1.732505\tBest loss: 1.731927\tAccuracy: 55.50%\n",
      "736\tValidation loss: 1.731625\tBest loss: 1.731625\tAccuracy: 55.60%\n",
      "737\tValidation loss: 1.730203\tBest loss: 1.730203\tAccuracy: 55.80%\n",
      "738\tValidation loss: 1.728554\tBest loss: 1.728554\tAccuracy: 56.30%\n",
      "739\tValidation loss: 1.730414\tBest loss: 1.728554\tAccuracy: 55.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\tValidation loss: 1.733445\tBest loss: 1.728554\tAccuracy: 56.10%\n",
      "741\tValidation loss: 1.728690\tBest loss: 1.728554\tAccuracy: 56.30%\n",
      "742\tValidation loss: 1.725118\tBest loss: 1.725118\tAccuracy: 55.70%\n",
      "743\tValidation loss: 1.725561\tBest loss: 1.725118\tAccuracy: 55.90%\n",
      "744\tValidation loss: 1.726295\tBest loss: 1.725118\tAccuracy: 56.50%\n",
      "745\tValidation loss: 1.724490\tBest loss: 1.724490\tAccuracy: 56.30%\n",
      "746\tValidation loss: 1.723842\tBest loss: 1.723842\tAccuracy: 56.80%\n",
      "747\tValidation loss: 1.728105\tBest loss: 1.723842\tAccuracy: 56.20%\n",
      "748\tValidation loss: 1.723690\tBest loss: 1.723690\tAccuracy: 56.50%\n",
      "749\tValidation loss: 1.721932\tBest loss: 1.721932\tAccuracy: 56.00%\n",
      "750\tValidation loss: 1.723271\tBest loss: 1.721932\tAccuracy: 57.00%\n",
      "751\tValidation loss: 1.720831\tBest loss: 1.720831\tAccuracy: 56.70%\n",
      "752\tValidation loss: 1.720472\tBest loss: 1.720472\tAccuracy: 56.70%\n",
      "753\tValidation loss: 1.719375\tBest loss: 1.719375\tAccuracy: 56.40%\n",
      "754\tValidation loss: 1.718298\tBest loss: 1.718298\tAccuracy: 56.80%\n",
      "755\tValidation loss: 1.719498\tBest loss: 1.718298\tAccuracy: 56.10%\n",
      "756\tValidation loss: 1.723052\tBest loss: 1.718298\tAccuracy: 56.10%\n",
      "757\tValidation loss: 1.719545\tBest loss: 1.718298\tAccuracy: 56.30%\n",
      "758\tValidation loss: 1.718700\tBest loss: 1.718298\tAccuracy: 56.50%\n",
      "759\tValidation loss: 1.717929\tBest loss: 1.717929\tAccuracy: 56.50%\n",
      "760\tValidation loss: 1.718749\tBest loss: 1.717929\tAccuracy: 56.60%\n",
      "761\tValidation loss: 1.718198\tBest loss: 1.717929\tAccuracy: 56.80%\n",
      "762\tValidation loss: 1.714822\tBest loss: 1.714822\tAccuracy: 56.30%\n",
      "763\tValidation loss: 1.714060\tBest loss: 1.714060\tAccuracy: 56.90%\n",
      "764\tValidation loss: 1.713492\tBest loss: 1.713492\tAccuracy: 56.60%\n",
      "765\tValidation loss: 1.713881\tBest loss: 1.713492\tAccuracy: 56.80%\n",
      "766\tValidation loss: 1.711308\tBest loss: 1.711308\tAccuracy: 56.10%\n",
      "767\tValidation loss: 1.712529\tBest loss: 1.711308\tAccuracy: 56.60%\n",
      "768\tValidation loss: 1.711609\tBest loss: 1.711308\tAccuracy: 56.50%\n",
      "769\tValidation loss: 1.710002\tBest loss: 1.710002\tAccuracy: 56.20%\n",
      "770\tValidation loss: 1.711625\tBest loss: 1.710002\tAccuracy: 56.40%\n",
      "771\tValidation loss: 1.710768\tBest loss: 1.710002\tAccuracy: 56.80%\n",
      "772\tValidation loss: 1.708982\tBest loss: 1.708982\tAccuracy: 56.50%\n",
      "773\tValidation loss: 1.709098\tBest loss: 1.708982\tAccuracy: 56.40%\n",
      "774\tValidation loss: 1.709352\tBest loss: 1.708982\tAccuracy: 56.40%\n",
      "775\tValidation loss: 1.708238\tBest loss: 1.708238\tAccuracy: 56.50%\n",
      "776\tValidation loss: 1.706619\tBest loss: 1.706619\tAccuracy: 56.60%\n",
      "777\tValidation loss: 1.707280\tBest loss: 1.706619\tAccuracy: 56.60%\n",
      "778\tValidation loss: 1.705777\tBest loss: 1.705777\tAccuracy: 56.30%\n",
      "779\tValidation loss: 1.706692\tBest loss: 1.705777\tAccuracy: 56.60%\n",
      "780\tValidation loss: 1.704796\tBest loss: 1.704796\tAccuracy: 56.30%\n",
      "781\tValidation loss: 1.710486\tBest loss: 1.704796\tAccuracy: 56.30%\n",
      "782\tValidation loss: 1.707883\tBest loss: 1.704796\tAccuracy: 56.40%\n",
      "783\tValidation loss: 1.708879\tBest loss: 1.704796\tAccuracy: 56.20%\n",
      "784\tValidation loss: 1.706574\tBest loss: 1.704796\tAccuracy: 56.60%\n",
      "785\tValidation loss: 1.706234\tBest loss: 1.704796\tAccuracy: 56.50%\n",
      "786\tValidation loss: 1.707271\tBest loss: 1.704796\tAccuracy: 56.30%\n",
      "787\tValidation loss: 1.705199\tBest loss: 1.704796\tAccuracy: 56.30%\n",
      "788\tValidation loss: 1.704632\tBest loss: 1.704632\tAccuracy: 57.00%\n",
      "789\tValidation loss: 1.703332\tBest loss: 1.703332\tAccuracy: 56.90%\n",
      "790\tValidation loss: 1.702008\tBest loss: 1.702008\tAccuracy: 57.10%\n",
      "791\tValidation loss: 1.702498\tBest loss: 1.702008\tAccuracy: 56.60%\n",
      "792\tValidation loss: 1.700878\tBest loss: 1.700878\tAccuracy: 56.60%\n",
      "793\tValidation loss: 1.701467\tBest loss: 1.700878\tAccuracy: 55.80%\n",
      "794\tValidation loss: 1.702401\tBest loss: 1.700878\tAccuracy: 56.30%\n",
      "795\tValidation loss: 1.702440\tBest loss: 1.700878\tAccuracy: 56.40%\n",
      "796\tValidation loss: 1.702778\tBest loss: 1.700878\tAccuracy: 56.30%\n",
      "797\tValidation loss: 1.703148\tBest loss: 1.700878\tAccuracy: 56.90%\n",
      "798\tValidation loss: 1.703898\tBest loss: 1.700878\tAccuracy: 56.50%\n",
      "799\tValidation loss: 1.702145\tBest loss: 1.700878\tAccuracy: 56.90%\n",
      "800\tValidation loss: 1.701510\tBest loss: 1.700878\tAccuracy: 56.60%\n",
      "801\tValidation loss: 1.702745\tBest loss: 1.700878\tAccuracy: 57.00%\n",
      "802\tValidation loss: 1.700146\tBest loss: 1.700146\tAccuracy: 57.20%\n",
      "803\tValidation loss: 1.697931\tBest loss: 1.697931\tAccuracy: 56.60%\n",
      "804\tValidation loss: 1.699442\tBest loss: 1.697931\tAccuracy: 57.00%\n",
      "805\tValidation loss: 1.698763\tBest loss: 1.697931\tAccuracy: 57.00%\n",
      "806\tValidation loss: 1.698485\tBest loss: 1.697931\tAccuracy: 56.40%\n",
      "807\tValidation loss: 1.697738\tBest loss: 1.697738\tAccuracy: 56.50%\n",
      "808\tValidation loss: 1.694209\tBest loss: 1.694209\tAccuracy: 57.20%\n",
      "809\tValidation loss: 1.693658\tBest loss: 1.693658\tAccuracy: 57.30%\n",
      "810\tValidation loss: 1.694159\tBest loss: 1.693658\tAccuracy: 56.60%\n",
      "811\tValidation loss: 1.694192\tBest loss: 1.693658\tAccuracy: 56.70%\n",
      "812\tValidation loss: 1.694569\tBest loss: 1.693658\tAccuracy: 56.90%\n",
      "813\tValidation loss: 1.695830\tBest loss: 1.693658\tAccuracy: 56.60%\n",
      "814\tValidation loss: 1.697172\tBest loss: 1.693658\tAccuracy: 56.70%\n",
      "815\tValidation loss: 1.695560\tBest loss: 1.693658\tAccuracy: 56.70%\n",
      "816\tValidation loss: 1.695066\tBest loss: 1.693658\tAccuracy: 57.30%\n",
      "817\tValidation loss: 1.697539\tBest loss: 1.693658\tAccuracy: 56.80%\n",
      "818\tValidation loss: 1.698929\tBest loss: 1.693658\tAccuracy: 56.60%\n",
      "819\tValidation loss: 1.696334\tBest loss: 1.693658\tAccuracy: 56.40%\n",
      "820\tValidation loss: 1.693757\tBest loss: 1.693658\tAccuracy: 56.80%\n",
      "821\tValidation loss: 1.695012\tBest loss: 1.693658\tAccuracy: 56.70%\n",
      "822\tValidation loss: 1.693293\tBest loss: 1.693293\tAccuracy: 57.00%\n",
      "823\tValidation loss: 1.693385\tBest loss: 1.693293\tAccuracy: 57.10%\n",
      "824\tValidation loss: 1.695288\tBest loss: 1.693293\tAccuracy: 56.10%\n",
      "825\tValidation loss: 1.690783\tBest loss: 1.690783\tAccuracy: 56.90%\n",
      "826\tValidation loss: 1.693166\tBest loss: 1.690783\tAccuracy: 56.80%\n",
      "827\tValidation loss: 1.692655\tBest loss: 1.690783\tAccuracy: 56.70%\n",
      "828\tValidation loss: 1.692996\tBest loss: 1.690783\tAccuracy: 56.90%\n",
      "829\tValidation loss: 1.690105\tBest loss: 1.690105\tAccuracy: 57.20%\n",
      "830\tValidation loss: 1.691767\tBest loss: 1.690105\tAccuracy: 56.90%\n",
      "831\tValidation loss: 1.692709\tBest loss: 1.690105\tAccuracy: 57.10%\n",
      "832\tValidation loss: 1.690365\tBest loss: 1.690105\tAccuracy: 56.80%\n",
      "833\tValidation loss: 1.689393\tBest loss: 1.689393\tAccuracy: 56.90%\n",
      "834\tValidation loss: 1.687512\tBest loss: 1.687512\tAccuracy: 56.70%\n",
      "835\tValidation loss: 1.691163\tBest loss: 1.687512\tAccuracy: 56.90%\n",
      "836\tValidation loss: 1.692099\tBest loss: 1.687512\tAccuracy: 56.60%\n",
      "837\tValidation loss: 1.689542\tBest loss: 1.687512\tAccuracy: 56.40%\n",
      "838\tValidation loss: 1.689548\tBest loss: 1.687512\tAccuracy: 56.80%\n",
      "839\tValidation loss: 1.685456\tBest loss: 1.685456\tAccuracy: 56.20%\n",
      "840\tValidation loss: 1.685767\tBest loss: 1.685456\tAccuracy: 56.50%\n",
      "841\tValidation loss: 1.686254\tBest loss: 1.685456\tAccuracy: 56.90%\n",
      "842\tValidation loss: 1.686373\tBest loss: 1.685456\tAccuracy: 56.50%\n",
      "843\tValidation loss: 1.685158\tBest loss: 1.685158\tAccuracy: 56.60%\n",
      "844\tValidation loss: 1.683716\tBest loss: 1.683716\tAccuracy: 56.80%\n",
      "845\tValidation loss: 1.684796\tBest loss: 1.683716\tAccuracy: 56.40%\n",
      "846\tValidation loss: 1.682352\tBest loss: 1.682352\tAccuracy: 56.40%\n",
      "847\tValidation loss: 1.682174\tBest loss: 1.682174\tAccuracy: 57.00%\n",
      "848\tValidation loss: 1.683298\tBest loss: 1.682174\tAccuracy: 56.90%\n",
      "849\tValidation loss: 1.683604\tBest loss: 1.682174\tAccuracy: 56.60%\n",
      "850\tValidation loss: 1.686274\tBest loss: 1.682174\tAccuracy: 57.10%\n",
      "851\tValidation loss: 1.685092\tBest loss: 1.682174\tAccuracy: 57.10%\n",
      "852\tValidation loss: 1.684072\tBest loss: 1.682174\tAccuracy: 57.40%\n",
      "853\tValidation loss: 1.684232\tBest loss: 1.682174\tAccuracy: 57.30%\n",
      "854\tValidation loss: 1.681147\tBest loss: 1.681147\tAccuracy: 57.20%\n",
      "855\tValidation loss: 1.681510\tBest loss: 1.681147\tAccuracy: 57.20%\n",
      "856\tValidation loss: 1.679637\tBest loss: 1.679637\tAccuracy: 56.50%\n",
      "857\tValidation loss: 1.679666\tBest loss: 1.679637\tAccuracy: 56.50%\n",
      "858\tValidation loss: 1.677839\tBest loss: 1.677839\tAccuracy: 57.10%\n",
      "859\tValidation loss: 1.681578\tBest loss: 1.677839\tAccuracy: 57.00%\n",
      "860\tValidation loss: 1.680665\tBest loss: 1.677839\tAccuracy: 56.90%\n",
      "861\tValidation loss: 1.680670\tBest loss: 1.677839\tAccuracy: 57.40%\n",
      "862\tValidation loss: 1.680169\tBest loss: 1.677839\tAccuracy: 57.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863\tValidation loss: 1.677804\tBest loss: 1.677804\tAccuracy: 57.00%\n",
      "864\tValidation loss: 1.677263\tBest loss: 1.677263\tAccuracy: 56.90%\n",
      "865\tValidation loss: 1.677353\tBest loss: 1.677263\tAccuracy: 57.20%\n",
      "866\tValidation loss: 1.675355\tBest loss: 1.675355\tAccuracy: 56.80%\n",
      "867\tValidation loss: 1.676384\tBest loss: 1.675355\tAccuracy: 56.80%\n",
      "868\tValidation loss: 1.673758\tBest loss: 1.673758\tAccuracy: 57.40%\n",
      "869\tValidation loss: 1.675691\tBest loss: 1.673758\tAccuracy: 57.90%\n",
      "870\tValidation loss: 1.673813\tBest loss: 1.673758\tAccuracy: 57.70%\n",
      "871\tValidation loss: 1.673088\tBest loss: 1.673088\tAccuracy: 57.40%\n",
      "872\tValidation loss: 1.675498\tBest loss: 1.673088\tAccuracy: 57.40%\n",
      "873\tValidation loss: 1.675521\tBest loss: 1.673088\tAccuracy: 57.30%\n",
      "874\tValidation loss: 1.675050\tBest loss: 1.673088\tAccuracy: 57.50%\n",
      "875\tValidation loss: 1.675694\tBest loss: 1.673088\tAccuracy: 56.70%\n",
      "876\tValidation loss: 1.674521\tBest loss: 1.673088\tAccuracy: 57.50%\n",
      "877\tValidation loss: 1.674670\tBest loss: 1.673088\tAccuracy: 57.10%\n",
      "878\tValidation loss: 1.674668\tBest loss: 1.673088\tAccuracy: 56.70%\n",
      "879\tValidation loss: 1.673151\tBest loss: 1.673088\tAccuracy: 57.00%\n",
      "880\tValidation loss: 1.675415\tBest loss: 1.673088\tAccuracy: 57.00%\n",
      "881\tValidation loss: 1.673762\tBest loss: 1.673088\tAccuracy: 56.80%\n",
      "882\tValidation loss: 1.674082\tBest loss: 1.673088\tAccuracy: 57.20%\n",
      "883\tValidation loss: 1.673380\tBest loss: 1.673088\tAccuracy: 56.70%\n",
      "884\tValidation loss: 1.675555\tBest loss: 1.673088\tAccuracy: 56.80%\n",
      "885\tValidation loss: 1.672308\tBest loss: 1.672308\tAccuracy: 56.60%\n",
      "886\tValidation loss: 1.672868\tBest loss: 1.672308\tAccuracy: 57.20%\n",
      "887\tValidation loss: 1.670611\tBest loss: 1.670611\tAccuracy: 56.80%\n",
      "888\tValidation loss: 1.670096\tBest loss: 1.670096\tAccuracy: 57.60%\n",
      "889\tValidation loss: 1.668895\tBest loss: 1.668895\tAccuracy: 57.10%\n",
      "890\tValidation loss: 1.669765\tBest loss: 1.668895\tAccuracy: 57.60%\n",
      "891\tValidation loss: 1.672285\tBest loss: 1.668895\tAccuracy: 57.20%\n",
      "892\tValidation loss: 1.671581\tBest loss: 1.668895\tAccuracy: 56.70%\n",
      "893\tValidation loss: 1.666923\tBest loss: 1.666923\tAccuracy: 57.40%\n",
      "894\tValidation loss: 1.667332\tBest loss: 1.666923\tAccuracy: 57.10%\n",
      "895\tValidation loss: 1.665615\tBest loss: 1.665615\tAccuracy: 57.00%\n",
      "896\tValidation loss: 1.668746\tBest loss: 1.665615\tAccuracy: 57.40%\n",
      "897\tValidation loss: 1.664509\tBest loss: 1.664509\tAccuracy: 57.70%\n",
      "898\tValidation loss: 1.666049\tBest loss: 1.664509\tAccuracy: 57.50%\n",
      "899\tValidation loss: 1.665262\tBest loss: 1.664509\tAccuracy: 57.70%\n",
      "900\tValidation loss: 1.668056\tBest loss: 1.664509\tAccuracy: 57.20%\n",
      "901\tValidation loss: 1.665243\tBest loss: 1.664509\tAccuracy: 57.40%\n",
      "902\tValidation loss: 1.666851\tBest loss: 1.664509\tAccuracy: 57.60%\n",
      "903\tValidation loss: 1.664848\tBest loss: 1.664509\tAccuracy: 57.40%\n",
      "904\tValidation loss: 1.663505\tBest loss: 1.663505\tAccuracy: 58.00%\n",
      "905\tValidation loss: 1.662473\tBest loss: 1.662473\tAccuracy: 57.80%\n",
      "906\tValidation loss: 1.662601\tBest loss: 1.662473\tAccuracy: 57.30%\n",
      "907\tValidation loss: 1.663155\tBest loss: 1.662473\tAccuracy: 57.50%\n",
      "908\tValidation loss: 1.664518\tBest loss: 1.662473\tAccuracy: 57.60%\n",
      "909\tValidation loss: 1.662795\tBest loss: 1.662473\tAccuracy: 57.40%\n",
      "910\tValidation loss: 1.662864\tBest loss: 1.662473\tAccuracy: 57.70%\n",
      "911\tValidation loss: 1.661396\tBest loss: 1.661396\tAccuracy: 57.80%\n",
      "912\tValidation loss: 1.662520\tBest loss: 1.661396\tAccuracy: 57.50%\n",
      "913\tValidation loss: 1.660782\tBest loss: 1.660782\tAccuracy: 57.40%\n",
      "914\tValidation loss: 1.659861\tBest loss: 1.659861\tAccuracy: 57.80%\n",
      "915\tValidation loss: 1.660703\tBest loss: 1.659861\tAccuracy: 57.10%\n",
      "916\tValidation loss: 1.659697\tBest loss: 1.659697\tAccuracy: 57.60%\n",
      "917\tValidation loss: 1.662495\tBest loss: 1.659697\tAccuracy: 57.80%\n",
      "918\tValidation loss: 1.662830\tBest loss: 1.659697\tAccuracy: 57.30%\n",
      "919\tValidation loss: 1.662795\tBest loss: 1.659697\tAccuracy: 57.60%\n",
      "920\tValidation loss: 1.660617\tBest loss: 1.659697\tAccuracy: 57.90%\n",
      "921\tValidation loss: 1.657326\tBest loss: 1.657326\tAccuracy: 57.80%\n",
      "922\tValidation loss: 1.656585\tBest loss: 1.656585\tAccuracy: 57.40%\n",
      "923\tValidation loss: 1.657217\tBest loss: 1.656585\tAccuracy: 57.30%\n",
      "924\tValidation loss: 1.658393\tBest loss: 1.656585\tAccuracy: 57.90%\n",
      "925\tValidation loss: 1.658436\tBest loss: 1.656585\tAccuracy: 58.10%\n",
      "926\tValidation loss: 1.658170\tBest loss: 1.656585\tAccuracy: 58.20%\n",
      "927\tValidation loss: 1.658069\tBest loss: 1.656585\tAccuracy: 58.00%\n",
      "928\tValidation loss: 1.657311\tBest loss: 1.656585\tAccuracy: 57.60%\n",
      "929\tValidation loss: 1.655865\tBest loss: 1.655865\tAccuracy: 57.50%\n",
      "930\tValidation loss: 1.654553\tBest loss: 1.654553\tAccuracy: 57.60%\n",
      "931\tValidation loss: 1.658529\tBest loss: 1.654553\tAccuracy: 57.80%\n",
      "932\tValidation loss: 1.655942\tBest loss: 1.654553\tAccuracy: 57.30%\n",
      "933\tValidation loss: 1.654912\tBest loss: 1.654553\tAccuracy: 57.70%\n",
      "934\tValidation loss: 1.654464\tBest loss: 1.654464\tAccuracy: 57.70%\n",
      "935\tValidation loss: 1.658638\tBest loss: 1.654464\tAccuracy: 57.70%\n",
      "936\tValidation loss: 1.658119\tBest loss: 1.654464\tAccuracy: 57.60%\n",
      "937\tValidation loss: 1.659071\tBest loss: 1.654464\tAccuracy: 58.30%\n",
      "938\tValidation loss: 1.658489\tBest loss: 1.654464\tAccuracy: 57.70%\n",
      "939\tValidation loss: 1.657599\tBest loss: 1.654464\tAccuracy: 57.40%\n",
      "940\tValidation loss: 1.658938\tBest loss: 1.654464\tAccuracy: 57.50%\n",
      "941\tValidation loss: 1.656174\tBest loss: 1.654464\tAccuracy: 57.50%\n",
      "942\tValidation loss: 1.654450\tBest loss: 1.654450\tAccuracy: 57.40%\n",
      "943\tValidation loss: 1.653877\tBest loss: 1.653877\tAccuracy: 57.50%\n",
      "944\tValidation loss: 1.652520\tBest loss: 1.652520\tAccuracy: 57.70%\n",
      "945\tValidation loss: 1.650902\tBest loss: 1.650902\tAccuracy: 58.10%\n",
      "946\tValidation loss: 1.652054\tBest loss: 1.650902\tAccuracy: 57.80%\n",
      "947\tValidation loss: 1.653053\tBest loss: 1.650902\tAccuracy: 57.50%\n",
      "948\tValidation loss: 1.655287\tBest loss: 1.650902\tAccuracy: 57.20%\n",
      "949\tValidation loss: 1.651883\tBest loss: 1.650902\tAccuracy: 57.80%\n",
      "950\tValidation loss: 1.652390\tBest loss: 1.650902\tAccuracy: 57.90%\n",
      "951\tValidation loss: 1.653298\tBest loss: 1.650902\tAccuracy: 57.90%\n",
      "952\tValidation loss: 1.651271\tBest loss: 1.650902\tAccuracy: 57.50%\n",
      "953\tValidation loss: 1.652213\tBest loss: 1.650902\tAccuracy: 57.80%\n",
      "954\tValidation loss: 1.651293\tBest loss: 1.650902\tAccuracy: 58.10%\n",
      "955\tValidation loss: 1.653260\tBest loss: 1.650902\tAccuracy: 57.70%\n",
      "956\tValidation loss: 1.652290\tBest loss: 1.650902\tAccuracy: 57.40%\n",
      "957\tValidation loss: 1.654754\tBest loss: 1.650902\tAccuracy: 57.40%\n",
      "958\tValidation loss: 1.651108\tBest loss: 1.650902\tAccuracy: 57.80%\n",
      "959\tValidation loss: 1.649712\tBest loss: 1.649712\tAccuracy: 57.50%\n",
      "960\tValidation loss: 1.649385\tBest loss: 1.649385\tAccuracy: 57.70%\n",
      "961\tValidation loss: 1.651205\tBest loss: 1.649385\tAccuracy: 57.10%\n",
      "962\tValidation loss: 1.652309\tBest loss: 1.649385\tAccuracy: 58.00%\n",
      "963\tValidation loss: 1.650349\tBest loss: 1.649385\tAccuracy: 57.60%\n",
      "964\tValidation loss: 1.647788\tBest loss: 1.647788\tAccuracy: 57.70%\n",
      "965\tValidation loss: 1.645653\tBest loss: 1.645653\tAccuracy: 57.80%\n",
      "966\tValidation loss: 1.647292\tBest loss: 1.645653\tAccuracy: 58.30%\n",
      "967\tValidation loss: 1.650588\tBest loss: 1.645653\tAccuracy: 58.40%\n",
      "968\tValidation loss: 1.650643\tBest loss: 1.645653\tAccuracy: 58.30%\n",
      "969\tValidation loss: 1.648502\tBest loss: 1.645653\tAccuracy: 57.30%\n",
      "970\tValidation loss: 1.649753\tBest loss: 1.645653\tAccuracy: 57.50%\n",
      "971\tValidation loss: 1.649150\tBest loss: 1.645653\tAccuracy: 58.20%\n",
      "972\tValidation loss: 1.646223\tBest loss: 1.645653\tAccuracy: 58.00%\n",
      "973\tValidation loss: 1.648814\tBest loss: 1.645653\tAccuracy: 57.90%\n",
      "974\tValidation loss: 1.643776\tBest loss: 1.643776\tAccuracy: 58.30%\n",
      "975\tValidation loss: 1.644125\tBest loss: 1.643776\tAccuracy: 58.50%\n",
      "976\tValidation loss: 1.643905\tBest loss: 1.643776\tAccuracy: 58.00%\n",
      "977\tValidation loss: 1.643651\tBest loss: 1.643651\tAccuracy: 58.40%\n",
      "978\tValidation loss: 1.643242\tBest loss: 1.643242\tAccuracy: 58.80%\n",
      "979\tValidation loss: 1.644967\tBest loss: 1.643242\tAccuracy: 58.30%\n",
      "980\tValidation loss: 1.643615\tBest loss: 1.643242\tAccuracy: 58.70%\n",
      "981\tValidation loss: 1.643976\tBest loss: 1.643242\tAccuracy: 58.50%\n",
      "982\tValidation loss: 1.643062\tBest loss: 1.643062\tAccuracy: 58.50%\n",
      "983\tValidation loss: 1.641293\tBest loss: 1.641293\tAccuracy: 58.20%\n",
      "984\tValidation loss: 1.642389\tBest loss: 1.641293\tAccuracy: 58.60%\n",
      "985\tValidation loss: 1.641983\tBest loss: 1.641293\tAccuracy: 58.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986\tValidation loss: 1.641939\tBest loss: 1.641293\tAccuracy: 58.50%\n",
      "987\tValidation loss: 1.642689\tBest loss: 1.641293\tAccuracy: 57.80%\n",
      "988\tValidation loss: 1.642304\tBest loss: 1.641293\tAccuracy: 57.90%\n",
      "989\tValidation loss: 1.641068\tBest loss: 1.641068\tAccuracy: 57.90%\n",
      "990\tValidation loss: 1.639487\tBest loss: 1.639487\tAccuracy: 58.10%\n",
      "991\tValidation loss: 1.639836\tBest loss: 1.639487\tAccuracy: 58.80%\n",
      "992\tValidation loss: 1.639733\tBest loss: 1.639487\tAccuracy: 58.60%\n",
      "993\tValidation loss: 1.640889\tBest loss: 1.639487\tAccuracy: 58.40%\n",
      "994\tValidation loss: 1.642017\tBest loss: 1.639487\tAccuracy: 58.40%\n",
      "995\tValidation loss: 1.639500\tBest loss: 1.639487\tAccuracy: 57.70%\n",
      "996\tValidation loss: 1.638760\tBest loss: 1.638760\tAccuracy: 58.20%\n",
      "997\tValidation loss: 1.641784\tBest loss: 1.638760\tAccuracy: 58.70%\n",
      "998\tValidation loss: 1.638653\tBest loss: 1.638653\tAccuracy: 58.10%\n",
      "999\tValidation loss: 1.639583\tBest loss: 1.638653\tAccuracy: 58.30%\n",
      "[[  7.95950927e-03   2.28883438e-02   1.27915749e-02 ...,   2.40025260e-02\n",
      "    1.00045819e-02   1.05662746e-02]\n",
      " [  5.46831892e-15   3.45889373e-10   9.27196687e-12 ...,   1.43818308e-08\n",
      "    4.88731411e-09   1.32557160e-11]\n",
      " [  1.24092376e-05   2.66647199e-03   1.62927376e-04 ...,   2.10789494e-05\n",
      "    1.75026915e-04   3.28067690e-04]\n",
      " ..., \n",
      " [  4.62224567e-03   1.47494795e-02   7.43933348e-03 ...,   4.84322391e-06\n",
      "    8.63908645e-06   6.27941574e-07]\n",
      " [  2.97658462e-02   2.61490215e-02   3.07365805e-02 ...,   2.52097063e-02\n",
      "    1.54787758e-02   1.50866937e-02]\n",
      " [  4.33524079e-08   5.94330629e-07   6.04249806e-09 ...,   4.04041931e-02\n",
      "    4.78832098e-03   7.86387742e-01]]\n",
      "[15 41 22 ...,  6  8 47]\n",
      "[[  2.55335153e-09   7.73279025e-05   9.03196394e-07 ...,   7.61273085e-16\n",
      "    7.97291747e-12   4.52309284e-12]\n",
      " [  5.29481396e-02   4.77799699e-02   4.28557657e-02 ...,   1.58444494e-02\n",
      "    9.76289436e-03   8.04149546e-03]\n",
      " [  7.13703407e-09   1.88644239e-13   3.74147567e-06 ...,   4.74257439e-11\n",
      "    5.50096495e-16   4.05398968e-17]\n",
      " ..., \n",
      " [  3.05428752e-03   3.71363945e-03   6.10504253e-03 ...,   3.36146019e-02\n",
      "    1.36384331e-02   2.09250171e-02]\n",
      " [  1.29233504e-05   4.06279396e-05   1.49316795e-04 ...,   2.10125715e-01\n",
      "    5.73551655e-02   9.73796565e-03]\n",
      " [  1.18152080e-07   8.51310119e-07   1.56144992e-07 ...,   1.14587016e-01\n",
      "    2.98916344e-02   2.31224559e-02]]\n",
      "[20 18 16 ...,  8 24 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 4.0min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.167866\tBest loss: 4.167866\tAccuracy: 1.60%\n",
      "1\tValidation loss: 3.967915\tBest loss: 3.967915\tAccuracy: 1.50%\n",
      "2\tValidation loss: 3.928852\tBest loss: 3.928852\tAccuracy: 2.60%\n",
      "3\tValidation loss: 3.914630\tBest loss: 3.914630\tAccuracy: 2.70%\n",
      "4\tValidation loss: 3.902479\tBest loss: 3.902479\tAccuracy: 2.70%\n",
      "5\tValidation loss: 3.893100\tBest loss: 3.893100\tAccuracy: 2.70%\n",
      "6\tValidation loss: 3.885777\tBest loss: 3.885777\tAccuracy: 2.70%\n",
      "7\tValidation loss: 3.875898\tBest loss: 3.875898\tAccuracy: 2.60%\n",
      "8\tValidation loss: 3.867697\tBest loss: 3.867697\tAccuracy: 2.50%\n",
      "9\tValidation loss: 3.858083\tBest loss: 3.858083\tAccuracy: 2.40%\n",
      "10\tValidation loss: 3.850370\tBest loss: 3.850370\tAccuracy: 2.50%\n",
      "11\tValidation loss: 3.844338\tBest loss: 3.844338\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.838004\tBest loss: 3.838004\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.833505\tBest loss: 3.833505\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.829595\tBest loss: 3.829595\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.826417\tBest loss: 3.826417\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.822855\tBest loss: 3.822855\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.819504\tBest loss: 3.819504\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.816908\tBest loss: 3.816908\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.814079\tBest loss: 3.814079\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.812990\tBest loss: 3.812990\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.812115\tBest loss: 3.812115\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.809826\tBest loss: 3.809826\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.807587\tBest loss: 3.807587\tAccuracy: 3.40%\n",
      "24\tValidation loss: 3.806361\tBest loss: 3.806361\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.805520\tBest loss: 3.805520\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.804642\tBest loss: 3.804642\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.804235\tBest loss: 3.804235\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.803442\tBest loss: 3.803442\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.803252\tBest loss: 3.803252\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.803013\tBest loss: 3.803013\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.802205\tBest loss: 3.802205\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.801173\tBest loss: 3.801173\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.800692\tBest loss: 3.800692\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.800113\tBest loss: 3.800113\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.799825\tBest loss: 3.799825\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.799363\tBest loss: 3.799363\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.798836\tBest loss: 3.798836\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.798318\tBest loss: 3.798318\tAccuracy: 3.40%\n",
      "39\tValidation loss: 3.797318\tBest loss: 3.797318\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.797073\tBest loss: 3.797073\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.797259\tBest loss: 3.797073\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.796814\tBest loss: 3.796814\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.796984\tBest loss: 3.796814\tAccuracy: 3.40%\n",
      "44\tValidation loss: 3.797072\tBest loss: 3.796814\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.797100\tBest loss: 3.796814\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.796602\tBest loss: 3.796602\tAccuracy: 4.10%\n",
      "47\tValidation loss: 3.796273\tBest loss: 3.796273\tAccuracy: 3.70%\n",
      "48\tValidation loss: 3.795732\tBest loss: 3.795732\tAccuracy: 3.70%\n",
      "49\tValidation loss: 3.795767\tBest loss: 3.795732\tAccuracy: 3.70%\n",
      "50\tValidation loss: 3.795955\tBest loss: 3.795732\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.795979\tBest loss: 3.795732\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.795796\tBest loss: 3.795732\tAccuracy: 3.40%\n",
      "53\tValidation loss: 3.795738\tBest loss: 3.795732\tAccuracy: 3.40%\n",
      "54\tValidation loss: 3.795898\tBest loss: 3.795732\tAccuracy: 3.40%\n",
      "55\tValidation loss: 3.796007\tBest loss: 3.795732\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.796021\tBest loss: 3.795732\tAccuracy: 3.40%\n",
      "57\tValidation loss: 3.795680\tBest loss: 3.795680\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.795462\tBest loss: 3.795462\tAccuracy: 3.70%\n",
      "59\tValidation loss: 3.795754\tBest loss: 3.795462\tAccuracy: 3.70%\n",
      "60\tValidation loss: 3.795599\tBest loss: 3.795462\tAccuracy: 3.40%\n",
      "61\tValidation loss: 3.795496\tBest loss: 3.795462\tAccuracy: 3.70%\n",
      "62\tValidation loss: 3.795644\tBest loss: 3.795462\tAccuracy: 3.70%\n",
      "63\tValidation loss: 3.795940\tBest loss: 3.795462\tAccuracy: 3.40%\n",
      "64\tValidation loss: 3.795749\tBest loss: 3.795462\tAccuracy: 3.70%\n",
      "65\tValidation loss: 3.795206\tBest loss: 3.795206\tAccuracy: 3.40%\n",
      "66\tValidation loss: 3.795192\tBest loss: 3.795192\tAccuracy: 3.70%\n",
      "67\tValidation loss: 3.795349\tBest loss: 3.795192\tAccuracy: 3.70%\n",
      "68\tValidation loss: 3.795178\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "69\tValidation loss: 3.795432\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "70\tValidation loss: 3.795278\tBest loss: 3.795178\tAccuracy: 3.70%\n",
      "71\tValidation loss: 3.795357\tBest loss: 3.795178\tAccuracy: 3.70%\n",
      "72\tValidation loss: 3.795506\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "73\tValidation loss: 3.795468\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "74\tValidation loss: 3.795640\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "75\tValidation loss: 3.795734\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "76\tValidation loss: 3.795585\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "77\tValidation loss: 3.795525\tBest loss: 3.795178\tAccuracy: 3.40%\n",
      "78\tValidation loss: 3.795614\tBest loss: 3.795178\tAccuracy: 3.70%\n",
      "79\tValidation loss: 3.795467\tBest loss: 3.795178\tAccuracy: 3.70%\n",
      "80\tValidation loss: 3.795166\tBest loss: 3.795166\tAccuracy: 3.70%\n",
      "81\tValidation loss: 3.795151\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "82\tValidation loss: 3.795204\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "83\tValidation loss: 3.795475\tBest loss: 3.795151\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\tValidation loss: 3.795417\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "85\tValidation loss: 3.795634\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "86\tValidation loss: 3.795660\tBest loss: 3.795151\tAccuracy: 3.40%\n",
      "87\tValidation loss: 3.795619\tBest loss: 3.795151\tAccuracy: 3.40%\n",
      "88\tValidation loss: 3.795807\tBest loss: 3.795151\tAccuracy: 3.40%\n",
      "89\tValidation loss: 3.795620\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "90\tValidation loss: 3.795598\tBest loss: 3.795151\tAccuracy: 3.40%\n",
      "91\tValidation loss: 3.795626\tBest loss: 3.795151\tAccuracy: 3.40%\n",
      "92\tValidation loss: 3.795411\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "93\tValidation loss: 3.795487\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "94\tValidation loss: 3.795285\tBest loss: 3.795151\tAccuracy: 3.70%\n",
      "95\tValidation loss: 3.795053\tBest loss: 3.795053\tAccuracy: 3.70%\n",
      "96\tValidation loss: 3.795046\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "97\tValidation loss: 3.795237\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "98\tValidation loss: 3.795197\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "99\tValidation loss: 3.795752\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "100\tValidation loss: 3.795651\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "101\tValidation loss: 3.795440\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "102\tValidation loss: 3.795324\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "103\tValidation loss: 3.795096\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "104\tValidation loss: 3.795464\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "105\tValidation loss: 3.795755\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "106\tValidation loss: 3.795648\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "107\tValidation loss: 3.795737\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "108\tValidation loss: 3.795930\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "109\tValidation loss: 3.796137\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "110\tValidation loss: 3.795789\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "111\tValidation loss: 3.796117\tBest loss: 3.795046\tAccuracy: 3.70%\n",
      "112\tValidation loss: 3.796124\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "113\tValidation loss: 3.796191\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "114\tValidation loss: 3.795992\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "115\tValidation loss: 3.795906\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "116\tValidation loss: 3.795955\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "117\tValidation loss: 3.795416\tBest loss: 3.795046\tAccuracy: 3.40%\n",
      "Early stopping!\n",
      "[[ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " [ 0.01633658  0.03229618  0.02264212 ...,  0.02903287  0.01732964\n",
      "   0.01820764]\n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " ..., \n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " [ 0.01642211  0.03230469  0.02251662 ...,  0.0294204   0.01713567\n",
      "   0.01830263]\n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " ..., \n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]\n",
      " [ 0.01630713  0.03231371  0.02265126 ...,  0.02895978  0.01735539\n",
      "   0.01821067]\n",
      " [ 0.01642211  0.03230468  0.02251662 ...,  0.02942041  0.01713566\n",
      "   0.01830263]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   7.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.194767\tBest loss: 4.194767\tAccuracy: 2.00%\n",
      "1\tValidation loss: 3.968870\tBest loss: 3.968870\tAccuracy: 1.60%\n",
      "2\tValidation loss: 3.924341\tBest loss: 3.924341\tAccuracy: 1.50%\n",
      "3\tValidation loss: 3.908325\tBest loss: 3.908325\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.897260\tBest loss: 3.897260\tAccuracy: 2.70%\n",
      "5\tValidation loss: 3.888947\tBest loss: 3.888947\tAccuracy: 2.50%\n",
      "6\tValidation loss: 3.880265\tBest loss: 3.880265\tAccuracy: 3.80%\n",
      "7\tValidation loss: 3.870937\tBest loss: 3.870937\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.863017\tBest loss: 3.863017\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.856605\tBest loss: 3.856605\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.852001\tBest loss: 3.852001\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.846231\tBest loss: 3.846231\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.841947\tBest loss: 3.841947\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.836942\tBest loss: 3.836942\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.832737\tBest loss: 3.832737\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.828797\tBest loss: 3.828797\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.824346\tBest loss: 3.824346\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.821169\tBest loss: 3.821169\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.818074\tBest loss: 3.818074\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.815522\tBest loss: 3.815522\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.813182\tBest loss: 3.813182\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.811561\tBest loss: 3.811561\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.810637\tBest loss: 3.810637\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.808593\tBest loss: 3.808593\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.808136\tBest loss: 3.808136\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.806722\tBest loss: 3.806722\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.805975\tBest loss: 3.805975\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.804396\tBest loss: 3.804396\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.804322\tBest loss: 3.804322\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.803296\tBest loss: 3.803296\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.802479\tBest loss: 3.802479\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.801941\tBest loss: 3.801941\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.801289\tBest loss: 3.801289\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.801181\tBest loss: 3.801181\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.800709\tBest loss: 3.800709\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.800802\tBest loss: 3.800709\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.800246\tBest loss: 3.800246\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.800079\tBest loss: 3.800079\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.799432\tBest loss: 3.799432\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.799086\tBest loss: 3.799086\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.798982\tBest loss: 3.798982\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.798526\tBest loss: 3.798526\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.798294\tBest loss: 3.798294\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.797806\tBest loss: 3.797806\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.797419\tBest loss: 3.797419\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.797555\tBest loss: 3.797419\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.797240\tBest loss: 3.797240\tAccuracy: 3.70%\n",
      "47\tValidation loss: 3.797014\tBest loss: 3.797014\tAccuracy: 3.70%\n",
      "48\tValidation loss: 3.796661\tBest loss: 3.796661\tAccuracy: 3.70%\n",
      "49\tValidation loss: 3.796556\tBest loss: 3.796556\tAccuracy: 3.70%\n",
      "50\tValidation loss: 3.796659\tBest loss: 3.796556\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.796230\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.796364\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "53\tValidation loss: 3.796525\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "54\tValidation loss: 3.796578\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "55\tValidation loss: 3.796321\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.796262\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "57\tValidation loss: 3.796325\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.796401\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "59\tValidation loss: 3.796272\tBest loss: 3.796230\tAccuracy: 3.70%\n",
      "60\tValidation loss: 3.795933\tBest loss: 3.795933\tAccuracy: 3.70%\n",
      "61\tValidation loss: 3.795967\tBest loss: 3.795933\tAccuracy: 3.70%\n",
      "62\tValidation loss: 3.796028\tBest loss: 3.795933\tAccuracy: 3.70%\n",
      "63\tValidation loss: 3.795920\tBest loss: 3.795920\tAccuracy: 3.70%\n",
      "64\tValidation loss: 3.795902\tBest loss: 3.795902\tAccuracy: 3.70%\n",
      "65\tValidation loss: 3.795496\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "66\tValidation loss: 3.795669\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "67\tValidation loss: 3.795703\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "68\tValidation loss: 3.795734\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "69\tValidation loss: 3.795943\tBest loss: 3.795496\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\tValidation loss: 3.796090\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "71\tValidation loss: 3.795957\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "72\tValidation loss: 3.795925\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "73\tValidation loss: 3.796097\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "74\tValidation loss: 3.795633\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "75\tValidation loss: 3.795964\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "76\tValidation loss: 3.795634\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "77\tValidation loss: 3.796031\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "78\tValidation loss: 3.795742\tBest loss: 3.795496\tAccuracy: 3.70%\n",
      "79\tValidation loss: 3.795491\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "80\tValidation loss: 3.795641\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "81\tValidation loss: 3.795628\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "82\tValidation loss: 3.795770\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "83\tValidation loss: 3.795762\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "84\tValidation loss: 3.795791\tBest loss: 3.795491\tAccuracy: 3.40%\n",
      "85\tValidation loss: 3.795824\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "86\tValidation loss: 3.795875\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "87\tValidation loss: 3.795661\tBest loss: 3.795491\tAccuracy: 3.40%\n",
      "88\tValidation loss: 3.795938\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "89\tValidation loss: 3.795949\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "90\tValidation loss: 3.795801\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "91\tValidation loss: 3.795724\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "92\tValidation loss: 3.795722\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "93\tValidation loss: 3.795723\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "94\tValidation loss: 3.795828\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "95\tValidation loss: 3.795820\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "96\tValidation loss: 3.795648\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "97\tValidation loss: 3.795719\tBest loss: 3.795491\tAccuracy: 3.40%\n",
      "98\tValidation loss: 3.795494\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "99\tValidation loss: 3.795553\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "100\tValidation loss: 3.795570\tBest loss: 3.795491\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01644561  0.03221713  0.02266009 ...,  0.0294529   0.01655202\n",
      "   0.01802386]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " ..., \n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.02945289  0.01655203\n",
      "   0.01802386]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " [ 0.01642238  0.03222335  0.02279651 ...,  0.02921451  0.0167269\n",
      "   0.01799395]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " ..., \n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]\n",
      " [ 0.01640781  0.03222816  0.02282801 ...,  0.02913427  0.01675989\n",
      "   0.01800339]\n",
      " [ 0.01644561  0.03221714  0.02266009 ...,  0.0294529   0.01655203\n",
      "   0.01802386]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   7.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.169622\tBest loss: 4.169622\tAccuracy: 2.10%\n",
      "1\tValidation loss: 3.955508\tBest loss: 3.955508\tAccuracy: 1.60%\n",
      "2\tValidation loss: 3.919682\tBest loss: 3.919682\tAccuracy: 3.60%\n",
      "3\tValidation loss: 3.903666\tBest loss: 3.903666\tAccuracy: 3.80%\n",
      "4\tValidation loss: 3.892513\tBest loss: 3.892513\tAccuracy: 3.80%\n",
      "5\tValidation loss: 3.881695\tBest loss: 3.881695\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.870399\tBest loss: 3.870399\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.859547\tBest loss: 3.859547\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.851191\tBest loss: 3.851191\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.844946\tBest loss: 3.844946\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.837178\tBest loss: 3.837178\tAccuracy: 3.30%\n",
      "11\tValidation loss: 3.830800\tBest loss: 3.830800\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.825303\tBest loss: 3.825303\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.820155\tBest loss: 3.820155\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.814532\tBest loss: 3.814532\tAccuracy: 3.80%\n",
      "15\tValidation loss: 3.811201\tBest loss: 3.811201\tAccuracy: 3.80%\n",
      "16\tValidation loss: 3.808251\tBest loss: 3.808251\tAccuracy: 3.80%\n",
      "17\tValidation loss: 3.805784\tBest loss: 3.805784\tAccuracy: 3.80%\n",
      "18\tValidation loss: 3.804160\tBest loss: 3.804160\tAccuracy: 3.80%\n",
      "19\tValidation loss: 3.802195\tBest loss: 3.802195\tAccuracy: 3.80%\n",
      "20\tValidation loss: 3.800125\tBest loss: 3.800125\tAccuracy: 3.80%\n",
      "21\tValidation loss: 3.800055\tBest loss: 3.800055\tAccuracy: 3.80%\n",
      "22\tValidation loss: 3.799731\tBest loss: 3.799731\tAccuracy: 3.80%\n",
      "23\tValidation loss: 3.799719\tBest loss: 3.799719\tAccuracy: 3.80%\n",
      "24\tValidation loss: 3.798579\tBest loss: 3.798579\tAccuracy: 3.80%\n",
      "25\tValidation loss: 3.798768\tBest loss: 3.798579\tAccuracy: 3.80%\n",
      "26\tValidation loss: 3.798493\tBest loss: 3.798493\tAccuracy: 3.80%\n",
      "27\tValidation loss: 3.798747\tBest loss: 3.798493\tAccuracy: 3.80%\n",
      "28\tValidation loss: 3.798645\tBest loss: 3.798493\tAccuracy: 3.80%\n",
      "29\tValidation loss: 3.798169\tBest loss: 3.798169\tAccuracy: 3.80%\n",
      "30\tValidation loss: 3.797587\tBest loss: 3.797587\tAccuracy: 3.80%\n",
      "31\tValidation loss: 3.797814\tBest loss: 3.797587\tAccuracy: 4.20%\n",
      "32\tValidation loss: 3.797554\tBest loss: 3.797554\tAccuracy: 4.10%\n",
      "33\tValidation loss: 3.797246\tBest loss: 3.797246\tAccuracy: 4.40%\n",
      "34\tValidation loss: 3.797112\tBest loss: 3.797112\tAccuracy: 4.40%\n",
      "35\tValidation loss: 3.796599\tBest loss: 3.796599\tAccuracy: 4.20%\n",
      "36\tValidation loss: 3.796200\tBest loss: 3.796200\tAccuracy: 3.80%\n",
      "37\tValidation loss: 3.796266\tBest loss: 3.796200\tAccuracy: 3.80%\n",
      "38\tValidation loss: 3.795849\tBest loss: 3.795849\tAccuracy: 3.80%\n",
      "39\tValidation loss: 3.795880\tBest loss: 3.795849\tAccuracy: 3.80%\n",
      "40\tValidation loss: 3.795974\tBest loss: 3.795849\tAccuracy: 3.80%\n",
      "41\tValidation loss: 3.795916\tBest loss: 3.795849\tAccuracy: 3.80%\n",
      "42\tValidation loss: 3.795757\tBest loss: 3.795757\tAccuracy: 3.80%\n",
      "43\tValidation loss: 3.795568\tBest loss: 3.795568\tAccuracy: 3.80%\n",
      "44\tValidation loss: 3.795493\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "45\tValidation loss: 3.795795\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "46\tValidation loss: 3.795954\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "47\tValidation loss: 3.795817\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "48\tValidation loss: 3.796132\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "49\tValidation loss: 3.796075\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "50\tValidation loss: 3.795592\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "51\tValidation loss: 3.795542\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "52\tValidation loss: 3.795711\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "53\tValidation loss: 3.795917\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "54\tValidation loss: 3.796074\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "55\tValidation loss: 3.795999\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "56\tValidation loss: 3.796160\tBest loss: 3.795493\tAccuracy: 3.40%\n",
      "57\tValidation loss: 3.796058\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "58\tValidation loss: 3.796179\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "59\tValidation loss: 3.795849\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "60\tValidation loss: 3.795677\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "61\tValidation loss: 3.796162\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "62\tValidation loss: 3.796233\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "63\tValidation loss: 3.796017\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "64\tValidation loss: 3.795785\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "65\tValidation loss: 3.795748\tBest loss: 3.795493\tAccuracy: 3.80%\n",
      "Early stopping!\n",
      "[[ 0.01723894  0.03054476  0.02210606 ...,  0.02975655  0.01577913\n",
      "   0.01858683]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]\n",
      " ..., \n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975918  0.01577559\n",
      "   0.0185909 ]\n",
      " [ 0.0170685   0.03098041  0.02244018 ...,  0.02915791  0.01634603\n",
      "   0.01836612]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]\n",
      " [ 0.01717233  0.03088362  0.02241912 ...,  0.02936552  0.0163013\n",
      "   0.01830077]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]\n",
      " ..., \n",
      " [ 0.01723787  0.03054493  0.02210031 ...,  0.02975913  0.01577562\n",
      "   0.01859089]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]\n",
      " [ 0.01723789  0.03054488  0.02210029 ...,  0.02975917  0.01577559\n",
      "   0.0185909 ]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=3, n_neurons=50, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   4.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.227455\tBest loss: 4.227455\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.992573\tBest loss: 3.992573\tAccuracy: 4.60%\n",
      "2\tValidation loss: 3.921144\tBest loss: 3.921144\tAccuracy: 5.10%\n",
      "3\tValidation loss: 3.882605\tBest loss: 3.882605\tAccuracy: 4.50%\n",
      "4\tValidation loss: 3.851493\tBest loss: 3.851493\tAccuracy: 4.90%\n",
      "5\tValidation loss: 3.825607\tBest loss: 3.825607\tAccuracy: 5.40%\n",
      "6\tValidation loss: 3.803009\tBest loss: 3.803009\tAccuracy: 5.10%\n",
      "7\tValidation loss: 3.784375\tBest loss: 3.784375\tAccuracy: 5.90%\n",
      "8\tValidation loss: 3.768926\tBest loss: 3.768926\tAccuracy: 5.90%\n",
      "9\tValidation loss: 3.754613\tBest loss: 3.754613\tAccuracy: 6.50%\n",
      "10\tValidation loss: 3.742929\tBest loss: 3.742929\tAccuracy: 7.10%\n",
      "11\tValidation loss: 3.731684\tBest loss: 3.731684\tAccuracy: 7.80%\n",
      "12\tValidation loss: 3.723878\tBest loss: 3.723878\tAccuracy: 8.30%\n",
      "13\tValidation loss: 3.716183\tBest loss: 3.716183\tAccuracy: 9.20%\n",
      "14\tValidation loss: 3.709827\tBest loss: 3.709827\tAccuracy: 9.30%\n",
      "15\tValidation loss: 3.703447\tBest loss: 3.703447\tAccuracy: 9.10%\n",
      "16\tValidation loss: 3.697824\tBest loss: 3.697824\tAccuracy: 9.70%\n",
      "17\tValidation loss: 3.692858\tBest loss: 3.692858\tAccuracy: 9.30%\n",
      "18\tValidation loss: 3.688269\tBest loss: 3.688269\tAccuracy: 9.60%\n",
      "19\tValidation loss: 3.683217\tBest loss: 3.683217\tAccuracy: 9.90%\n",
      "20\tValidation loss: 3.678871\tBest loss: 3.678871\tAccuracy: 10.10%\n",
      "21\tValidation loss: 3.674182\tBest loss: 3.674182\tAccuracy: 10.20%\n",
      "22\tValidation loss: 3.670580\tBest loss: 3.670580\tAccuracy: 10.50%\n",
      "23\tValidation loss: 3.666291\tBest loss: 3.666291\tAccuracy: 10.10%\n",
      "24\tValidation loss: 3.661847\tBest loss: 3.661847\tAccuracy: 10.20%\n",
      "25\tValidation loss: 3.658448\tBest loss: 3.658448\tAccuracy: 10.20%\n",
      "26\tValidation loss: 3.654375\tBest loss: 3.654375\tAccuracy: 10.50%\n",
      "27\tValidation loss: 3.651423\tBest loss: 3.651423\tAccuracy: 10.40%\n",
      "28\tValidation loss: 3.647670\tBest loss: 3.647670\tAccuracy: 10.50%\n",
      "29\tValidation loss: 3.643539\tBest loss: 3.643539\tAccuracy: 10.30%\n",
      "30\tValidation loss: 3.639918\tBest loss: 3.639918\tAccuracy: 10.10%\n",
      "31\tValidation loss: 3.637015\tBest loss: 3.637015\tAccuracy: 9.70%\n",
      "32\tValidation loss: 3.632433\tBest loss: 3.632433\tAccuracy: 9.90%\n",
      "33\tValidation loss: 3.626542\tBest loss: 3.626542\tAccuracy: 10.10%\n",
      "34\tValidation loss: 3.621529\tBest loss: 3.621529\tAccuracy: 10.80%\n",
      "35\tValidation loss: 3.614471\tBest loss: 3.614471\tAccuracy: 10.80%\n",
      "36\tValidation loss: 3.609418\tBest loss: 3.609418\tAccuracy: 11.30%\n",
      "37\tValidation loss: 3.603274\tBest loss: 3.603274\tAccuracy: 11.10%\n",
      "38\tValidation loss: 3.597649\tBest loss: 3.597649\tAccuracy: 10.80%\n",
      "39\tValidation loss: 3.591584\tBest loss: 3.591584\tAccuracy: 10.90%\n",
      "40\tValidation loss: 3.586044\tBest loss: 3.586044\tAccuracy: 10.90%\n",
      "41\tValidation loss: 3.583722\tBest loss: 3.583722\tAccuracy: 11.00%\n",
      "42\tValidation loss: 3.577919\tBest loss: 3.577919\tAccuracy: 11.10%\n",
      "43\tValidation loss: 3.570366\tBest loss: 3.570366\tAccuracy: 11.40%\n",
      "44\tValidation loss: 3.565758\tBest loss: 3.565758\tAccuracy: 12.00%\n",
      "45\tValidation loss: 3.560084\tBest loss: 3.560084\tAccuracy: 12.00%\n",
      "46\tValidation loss: 3.558218\tBest loss: 3.558218\tAccuracy: 11.70%\n",
      "47\tValidation loss: 3.553662\tBest loss: 3.553662\tAccuracy: 12.30%\n",
      "48\tValidation loss: 3.550498\tBest loss: 3.550498\tAccuracy: 12.30%\n",
      "49\tValidation loss: 3.545604\tBest loss: 3.545604\tAccuracy: 12.60%\n",
      "50\tValidation loss: 3.541571\tBest loss: 3.541571\tAccuracy: 12.40%\n",
      "51\tValidation loss: 3.536666\tBest loss: 3.536666\tAccuracy: 12.30%\n",
      "52\tValidation loss: 3.531509\tBest loss: 3.531509\tAccuracy: 12.20%\n",
      "53\tValidation loss: 3.525565\tBest loss: 3.525565\tAccuracy: 12.50%\n",
      "54\tValidation loss: 3.519399\tBest loss: 3.519399\tAccuracy: 12.20%\n",
      "55\tValidation loss: 3.511227\tBest loss: 3.511227\tAccuracy: 12.60%\n",
      "56\tValidation loss: 3.506738\tBest loss: 3.506738\tAccuracy: 12.60%\n",
      "57\tValidation loss: 3.502906\tBest loss: 3.502906\tAccuracy: 12.80%\n",
      "58\tValidation loss: 3.498457\tBest loss: 3.498457\tAccuracy: 12.40%\n",
      "59\tValidation loss: 3.495639\tBest loss: 3.495639\tAccuracy: 12.50%\n",
      "60\tValidation loss: 3.490320\tBest loss: 3.490320\tAccuracy: 12.70%\n",
      "61\tValidation loss: 3.488797\tBest loss: 3.488797\tAccuracy: 12.80%\n",
      "62\tValidation loss: 3.483042\tBest loss: 3.483042\tAccuracy: 13.00%\n",
      "63\tValidation loss: 3.476544\tBest loss: 3.476544\tAccuracy: 13.40%\n",
      "64\tValidation loss: 3.469700\tBest loss: 3.469700\tAccuracy: 14.10%\n",
      "65\tValidation loss: 3.465736\tBest loss: 3.465736\tAccuracy: 14.20%\n",
      "66\tValidation loss: 3.460759\tBest loss: 3.460759\tAccuracy: 14.30%\n",
      "67\tValidation loss: 3.455290\tBest loss: 3.455290\tAccuracy: 14.30%\n",
      "68\tValidation loss: 3.451641\tBest loss: 3.451641\tAccuracy: 14.30%\n",
      "69\tValidation loss: 3.446043\tBest loss: 3.446043\tAccuracy: 14.50%\n",
      "70\tValidation loss: 3.441349\tBest loss: 3.441349\tAccuracy: 14.60%\n",
      "71\tValidation loss: 3.436844\tBest loss: 3.436844\tAccuracy: 14.50%\n",
      "72\tValidation loss: 3.430735\tBest loss: 3.430735\tAccuracy: 14.30%\n",
      "73\tValidation loss: 3.421707\tBest loss: 3.421707\tAccuracy: 14.60%\n",
      "74\tValidation loss: 3.416265\tBest loss: 3.416265\tAccuracy: 14.90%\n",
      "75\tValidation loss: 3.411293\tBest loss: 3.411293\tAccuracy: 15.10%\n",
      "76\tValidation loss: 3.408715\tBest loss: 3.408715\tAccuracy: 15.70%\n",
      "77\tValidation loss: 3.402604\tBest loss: 3.402604\tAccuracy: 15.20%\n",
      "78\tValidation loss: 3.396521\tBest loss: 3.396521\tAccuracy: 15.60%\n",
      "79\tValidation loss: 3.393551\tBest loss: 3.393551\tAccuracy: 15.40%\n",
      "80\tValidation loss: 3.387073\tBest loss: 3.387073\tAccuracy: 15.80%\n",
      "81\tValidation loss: 3.381602\tBest loss: 3.381602\tAccuracy: 15.90%\n",
      "82\tValidation loss: 3.376727\tBest loss: 3.376727\tAccuracy: 15.60%\n",
      "83\tValidation loss: 3.367935\tBest loss: 3.367935\tAccuracy: 15.20%\n",
      "84\tValidation loss: 3.360763\tBest loss: 3.360763\tAccuracy: 15.50%\n",
      "85\tValidation loss: 3.362155\tBest loss: 3.360763\tAccuracy: 15.30%\n",
      "86\tValidation loss: 3.354833\tBest loss: 3.354833\tAccuracy: 15.20%\n",
      "87\tValidation loss: 3.346938\tBest loss: 3.346938\tAccuracy: 15.70%\n",
      "88\tValidation loss: 3.343583\tBest loss: 3.343583\tAccuracy: 15.20%\n",
      "89\tValidation loss: 3.335864\tBest loss: 3.335864\tAccuracy: 15.90%\n",
      "90\tValidation loss: 3.329134\tBest loss: 3.329134\tAccuracy: 15.60%\n",
      "91\tValidation loss: 3.324941\tBest loss: 3.324941\tAccuracy: 15.60%\n",
      "92\tValidation loss: 3.314718\tBest loss: 3.314718\tAccuracy: 15.70%\n",
      "93\tValidation loss: 3.312796\tBest loss: 3.312796\tAccuracy: 16.00%\n",
      "94\tValidation loss: 3.307018\tBest loss: 3.307018\tAccuracy: 16.20%\n",
      "95\tValidation loss: 3.298682\tBest loss: 3.298682\tAccuracy: 16.00%\n",
      "96\tValidation loss: 3.293626\tBest loss: 3.293626\tAccuracy: 16.50%\n",
      "97\tValidation loss: 3.289763\tBest loss: 3.289763\tAccuracy: 16.40%\n",
      "98\tValidation loss: 3.284321\tBest loss: 3.284321\tAccuracy: 17.10%\n",
      "99\tValidation loss: 3.280349\tBest loss: 3.280349\tAccuracy: 16.80%\n",
      "100\tValidation loss: 3.275413\tBest loss: 3.275413\tAccuracy: 16.90%\n",
      "101\tValidation loss: 3.271507\tBest loss: 3.271507\tAccuracy: 16.60%\n",
      "102\tValidation loss: 3.263425\tBest loss: 3.263425\tAccuracy: 17.00%\n",
      "103\tValidation loss: 3.260838\tBest loss: 3.260838\tAccuracy: 17.00%\n",
      "104\tValidation loss: 3.250424\tBest loss: 3.250424\tAccuracy: 17.10%\n",
      "105\tValidation loss: 3.241322\tBest loss: 3.241322\tAccuracy: 17.20%\n",
      "106\tValidation loss: 3.233076\tBest loss: 3.233076\tAccuracy: 17.70%\n",
      "107\tValidation loss: 3.229072\tBest loss: 3.229072\tAccuracy: 17.60%\n",
      "108\tValidation loss: 3.222113\tBest loss: 3.222113\tAccuracy: 17.60%\n",
      "109\tValidation loss: 3.216729\tBest loss: 3.216729\tAccuracy: 17.90%\n",
      "110\tValidation loss: 3.215221\tBest loss: 3.215221\tAccuracy: 18.30%\n",
      "111\tValidation loss: 3.206345\tBest loss: 3.206345\tAccuracy: 18.10%\n",
      "112\tValidation loss: 3.190738\tBest loss: 3.190738\tAccuracy: 18.10%\n",
      "113\tValidation loss: 3.181842\tBest loss: 3.181842\tAccuracy: 19.40%\n",
      "114\tValidation loss: 3.179412\tBest loss: 3.179412\tAccuracy: 19.20%\n",
      "115\tValidation loss: 3.173573\tBest loss: 3.173573\tAccuracy: 19.00%\n",
      "116\tValidation loss: 3.161336\tBest loss: 3.161336\tAccuracy: 20.00%\n",
      "117\tValidation loss: 3.157801\tBest loss: 3.157801\tAccuracy: 18.90%\n",
      "118\tValidation loss: 3.148240\tBest loss: 3.148240\tAccuracy: 20.30%\n",
      "119\tValidation loss: 3.139620\tBest loss: 3.139620\tAccuracy: 20.80%\n",
      "120\tValidation loss: 3.129746\tBest loss: 3.129746\tAccuracy: 20.70%\n",
      "121\tValidation loss: 3.110640\tBest loss: 3.110640\tAccuracy: 21.00%\n",
      "122\tValidation loss: 3.099266\tBest loss: 3.099266\tAccuracy: 21.00%\n",
      "123\tValidation loss: 3.089234\tBest loss: 3.089234\tAccuracy: 20.90%\n",
      "124\tValidation loss: 3.085731\tBest loss: 3.085731\tAccuracy: 20.70%\n",
      "125\tValidation loss: 3.081999\tBest loss: 3.081999\tAccuracy: 21.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 3.065204\tBest loss: 3.065204\tAccuracy: 21.30%\n",
      "127\tValidation loss: 3.056926\tBest loss: 3.056926\tAccuracy: 21.60%\n",
      "128\tValidation loss: 3.045906\tBest loss: 3.045906\tAccuracy: 21.90%\n",
      "129\tValidation loss: 3.033426\tBest loss: 3.033426\tAccuracy: 21.80%\n",
      "130\tValidation loss: 3.012459\tBest loss: 3.012459\tAccuracy: 23.20%\n",
      "131\tValidation loss: 3.003461\tBest loss: 3.003461\tAccuracy: 23.30%\n",
      "132\tValidation loss: 2.981088\tBest loss: 2.981088\tAccuracy: 24.00%\n",
      "133\tValidation loss: 2.975083\tBest loss: 2.975083\tAccuracy: 23.70%\n",
      "134\tValidation loss: 2.957350\tBest loss: 2.957350\tAccuracy: 24.80%\n",
      "135\tValidation loss: 2.962010\tBest loss: 2.957350\tAccuracy: 24.60%\n",
      "136\tValidation loss: 2.945800\tBest loss: 2.945800\tAccuracy: 24.30%\n",
      "137\tValidation loss: 2.939099\tBest loss: 2.939099\tAccuracy: 24.80%\n",
      "138\tValidation loss: 2.926279\tBest loss: 2.926279\tAccuracy: 25.60%\n",
      "139\tValidation loss: 2.923641\tBest loss: 2.923641\tAccuracy: 25.20%\n",
      "140\tValidation loss: 2.899520\tBest loss: 2.899520\tAccuracy: 26.10%\n",
      "141\tValidation loss: 2.892017\tBest loss: 2.892017\tAccuracy: 25.60%\n",
      "142\tValidation loss: 2.877547\tBest loss: 2.877547\tAccuracy: 26.30%\n",
      "143\tValidation loss: 2.873968\tBest loss: 2.873968\tAccuracy: 26.70%\n",
      "144\tValidation loss: 2.859017\tBest loss: 2.859017\tAccuracy: 27.20%\n",
      "145\tValidation loss: 2.846908\tBest loss: 2.846908\tAccuracy: 27.60%\n",
      "146\tValidation loss: 2.827816\tBest loss: 2.827816\tAccuracy: 28.00%\n",
      "147\tValidation loss: 2.825612\tBest loss: 2.825612\tAccuracy: 28.10%\n",
      "148\tValidation loss: 2.816449\tBest loss: 2.816449\tAccuracy: 28.30%\n",
      "149\tValidation loss: 2.797373\tBest loss: 2.797373\tAccuracy: 28.30%\n",
      "150\tValidation loss: 2.785282\tBest loss: 2.785282\tAccuracy: 28.60%\n",
      "151\tValidation loss: 2.776795\tBest loss: 2.776795\tAccuracy: 29.70%\n",
      "152\tValidation loss: 2.764076\tBest loss: 2.764076\tAccuracy: 29.80%\n",
      "153\tValidation loss: 2.758770\tBest loss: 2.758770\tAccuracy: 30.10%\n",
      "154\tValidation loss: 2.737319\tBest loss: 2.737319\tAccuracy: 30.80%\n",
      "155\tValidation loss: 2.730974\tBest loss: 2.730974\tAccuracy: 31.40%\n",
      "156\tValidation loss: 2.725807\tBest loss: 2.725807\tAccuracy: 30.70%\n",
      "157\tValidation loss: 2.721932\tBest loss: 2.721932\tAccuracy: 30.60%\n",
      "158\tValidation loss: 2.701514\tBest loss: 2.701514\tAccuracy: 31.20%\n",
      "159\tValidation loss: 2.694855\tBest loss: 2.694855\tAccuracy: 31.30%\n",
      "160\tValidation loss: 2.679199\tBest loss: 2.679199\tAccuracy: 31.60%\n",
      "161\tValidation loss: 2.671847\tBest loss: 2.671847\tAccuracy: 32.40%\n",
      "162\tValidation loss: 2.654913\tBest loss: 2.654913\tAccuracy: 32.20%\n",
      "163\tValidation loss: 2.642608\tBest loss: 2.642608\tAccuracy: 31.50%\n",
      "164\tValidation loss: 2.638618\tBest loss: 2.638618\tAccuracy: 32.20%\n",
      "165\tValidation loss: 2.617871\tBest loss: 2.617871\tAccuracy: 32.50%\n",
      "166\tValidation loss: 2.615567\tBest loss: 2.615567\tAccuracy: 33.40%\n",
      "167\tValidation loss: 2.604738\tBest loss: 2.604738\tAccuracy: 32.70%\n",
      "168\tValidation loss: 2.598139\tBest loss: 2.598139\tAccuracy: 33.40%\n",
      "169\tValidation loss: 2.580009\tBest loss: 2.580009\tAccuracy: 34.10%\n",
      "170\tValidation loss: 2.578758\tBest loss: 2.578758\tAccuracy: 33.80%\n",
      "171\tValidation loss: 2.567822\tBest loss: 2.567822\tAccuracy: 33.50%\n",
      "172\tValidation loss: 2.560877\tBest loss: 2.560877\tAccuracy: 33.40%\n",
      "173\tValidation loss: 2.553592\tBest loss: 2.553592\tAccuracy: 34.00%\n",
      "174\tValidation loss: 2.530343\tBest loss: 2.530343\tAccuracy: 34.50%\n",
      "175\tValidation loss: 2.516643\tBest loss: 2.516643\tAccuracy: 34.70%\n",
      "176\tValidation loss: 2.518606\tBest loss: 2.516643\tAccuracy: 34.70%\n",
      "177\tValidation loss: 2.506722\tBest loss: 2.506722\tAccuracy: 35.90%\n",
      "178\tValidation loss: 2.500432\tBest loss: 2.500432\tAccuracy: 35.70%\n",
      "179\tValidation loss: 2.488092\tBest loss: 2.488092\tAccuracy: 35.50%\n",
      "180\tValidation loss: 2.475090\tBest loss: 2.475090\tAccuracy: 36.10%\n",
      "181\tValidation loss: 2.477332\tBest loss: 2.475090\tAccuracy: 35.20%\n",
      "182\tValidation loss: 2.466746\tBest loss: 2.466746\tAccuracy: 37.00%\n",
      "183\tValidation loss: 2.461992\tBest loss: 2.461992\tAccuracy: 36.10%\n",
      "184\tValidation loss: 2.447843\tBest loss: 2.447843\tAccuracy: 37.00%\n",
      "185\tValidation loss: 2.439381\tBest loss: 2.439381\tAccuracy: 37.50%\n",
      "186\tValidation loss: 2.430386\tBest loss: 2.430386\tAccuracy: 37.30%\n",
      "187\tValidation loss: 2.420141\tBest loss: 2.420141\tAccuracy: 37.50%\n",
      "188\tValidation loss: 2.411329\tBest loss: 2.411329\tAccuracy: 37.90%\n",
      "189\tValidation loss: 2.406616\tBest loss: 2.406616\tAccuracy: 38.20%\n",
      "190\tValidation loss: 2.400079\tBest loss: 2.400079\tAccuracy: 38.80%\n",
      "191\tValidation loss: 2.393385\tBest loss: 2.393385\tAccuracy: 38.20%\n",
      "192\tValidation loss: 2.385972\tBest loss: 2.385972\tAccuracy: 38.20%\n",
      "193\tValidation loss: 2.386770\tBest loss: 2.385972\tAccuracy: 38.40%\n",
      "194\tValidation loss: 2.375936\tBest loss: 2.375936\tAccuracy: 38.40%\n",
      "195\tValidation loss: 2.365592\tBest loss: 2.365592\tAccuracy: 38.80%\n",
      "196\tValidation loss: 2.365539\tBest loss: 2.365539\tAccuracy: 39.70%\n",
      "197\tValidation loss: 2.355538\tBest loss: 2.355538\tAccuracy: 39.70%\n",
      "198\tValidation loss: 2.359974\tBest loss: 2.355538\tAccuracy: 39.50%\n",
      "199\tValidation loss: 2.345904\tBest loss: 2.345904\tAccuracy: 38.90%\n",
      "200\tValidation loss: 2.341586\tBest loss: 2.341586\tAccuracy: 39.50%\n",
      "201\tValidation loss: 2.337913\tBest loss: 2.337913\tAccuracy: 40.00%\n",
      "202\tValidation loss: 2.332995\tBest loss: 2.332995\tAccuracy: 40.10%\n",
      "203\tValidation loss: 2.332505\tBest loss: 2.332505\tAccuracy: 40.00%\n",
      "204\tValidation loss: 2.318546\tBest loss: 2.318546\tAccuracy: 40.70%\n",
      "205\tValidation loss: 2.311380\tBest loss: 2.311380\tAccuracy: 41.10%\n",
      "206\tValidation loss: 2.306997\tBest loss: 2.306997\tAccuracy: 40.70%\n",
      "207\tValidation loss: 2.299945\tBest loss: 2.299945\tAccuracy: 40.70%\n",
      "208\tValidation loss: 2.298680\tBest loss: 2.298680\tAccuracy: 40.10%\n",
      "209\tValidation loss: 2.295189\tBest loss: 2.295189\tAccuracy: 40.60%\n",
      "210\tValidation loss: 2.294634\tBest loss: 2.294634\tAccuracy: 40.90%\n",
      "211\tValidation loss: 2.285488\tBest loss: 2.285488\tAccuracy: 41.10%\n",
      "212\tValidation loss: 2.282197\tBest loss: 2.282197\tAccuracy: 41.60%\n",
      "213\tValidation loss: 2.274114\tBest loss: 2.274114\tAccuracy: 41.60%\n",
      "214\tValidation loss: 2.263944\tBest loss: 2.263944\tAccuracy: 41.90%\n",
      "215\tValidation loss: 2.260277\tBest loss: 2.260277\tAccuracy: 41.80%\n",
      "216\tValidation loss: 2.253629\tBest loss: 2.253629\tAccuracy: 43.10%\n",
      "217\tValidation loss: 2.249148\tBest loss: 2.249148\tAccuracy: 42.80%\n",
      "218\tValidation loss: 2.237559\tBest loss: 2.237559\tAccuracy: 42.90%\n",
      "219\tValidation loss: 2.240038\tBest loss: 2.237559\tAccuracy: 42.60%\n",
      "220\tValidation loss: 2.233833\tBest loss: 2.233833\tAccuracy: 42.70%\n",
      "221\tValidation loss: 2.233091\tBest loss: 2.233091\tAccuracy: 42.90%\n",
      "222\tValidation loss: 2.223551\tBest loss: 2.223551\tAccuracy: 43.30%\n",
      "223\tValidation loss: 2.221329\tBest loss: 2.221329\tAccuracy: 42.80%\n",
      "224\tValidation loss: 2.222817\tBest loss: 2.221329\tAccuracy: 43.40%\n",
      "225\tValidation loss: 2.208641\tBest loss: 2.208641\tAccuracy: 42.50%\n",
      "226\tValidation loss: 2.203763\tBest loss: 2.203763\tAccuracy: 43.10%\n",
      "227\tValidation loss: 2.198059\tBest loss: 2.198059\tAccuracy: 44.00%\n",
      "228\tValidation loss: 2.196959\tBest loss: 2.196959\tAccuracy: 43.70%\n",
      "229\tValidation loss: 2.194184\tBest loss: 2.194184\tAccuracy: 44.40%\n",
      "230\tValidation loss: 2.190594\tBest loss: 2.190594\tAccuracy: 43.30%\n",
      "231\tValidation loss: 2.179175\tBest loss: 2.179175\tAccuracy: 43.70%\n",
      "232\tValidation loss: 2.177640\tBest loss: 2.177640\tAccuracy: 43.30%\n",
      "233\tValidation loss: 2.171895\tBest loss: 2.171895\tAccuracy: 44.30%\n",
      "234\tValidation loss: 2.169434\tBest loss: 2.169434\tAccuracy: 45.50%\n",
      "235\tValidation loss: 2.162419\tBest loss: 2.162419\tAccuracy: 44.60%\n",
      "236\tValidation loss: 2.152453\tBest loss: 2.152453\tAccuracy: 45.40%\n",
      "237\tValidation loss: 2.143579\tBest loss: 2.143579\tAccuracy: 45.50%\n",
      "238\tValidation loss: 2.146688\tBest loss: 2.143579\tAccuracy: 45.60%\n",
      "239\tValidation loss: 2.149288\tBest loss: 2.143579\tAccuracy: 44.90%\n",
      "240\tValidation loss: 2.147934\tBest loss: 2.143579\tAccuracy: 44.80%\n",
      "241\tValidation loss: 2.144383\tBest loss: 2.143579\tAccuracy: 45.50%\n",
      "242\tValidation loss: 2.139053\tBest loss: 2.139053\tAccuracy: 46.10%\n",
      "243\tValidation loss: 2.140184\tBest loss: 2.139053\tAccuracy: 45.70%\n",
      "244\tValidation loss: 2.136059\tBest loss: 2.136059\tAccuracy: 45.30%\n",
      "245\tValidation loss: 2.126274\tBest loss: 2.126274\tAccuracy: 45.50%\n",
      "246\tValidation loss: 2.117554\tBest loss: 2.117554\tAccuracy: 45.90%\n",
      "247\tValidation loss: 2.114649\tBest loss: 2.114649\tAccuracy: 45.10%\n",
      "248\tValidation loss: 2.111243\tBest loss: 2.111243\tAccuracy: 46.00%\n",
      "249\tValidation loss: 2.108221\tBest loss: 2.108221\tAccuracy: 45.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 2.106138\tBest loss: 2.106138\tAccuracy: 46.30%\n",
      "251\tValidation loss: 2.101416\tBest loss: 2.101416\tAccuracy: 46.70%\n",
      "252\tValidation loss: 2.101703\tBest loss: 2.101416\tAccuracy: 46.20%\n",
      "253\tValidation loss: 2.094038\tBest loss: 2.094038\tAccuracy: 46.20%\n",
      "254\tValidation loss: 2.087505\tBest loss: 2.087505\tAccuracy: 46.80%\n",
      "255\tValidation loss: 2.093324\tBest loss: 2.087505\tAccuracy: 46.10%\n",
      "256\tValidation loss: 2.088204\tBest loss: 2.087505\tAccuracy: 46.80%\n",
      "257\tValidation loss: 2.087052\tBest loss: 2.087052\tAccuracy: 46.30%\n",
      "258\tValidation loss: 2.087204\tBest loss: 2.087052\tAccuracy: 46.70%\n",
      "259\tValidation loss: 2.080383\tBest loss: 2.080383\tAccuracy: 46.40%\n",
      "260\tValidation loss: 2.071392\tBest loss: 2.071392\tAccuracy: 47.20%\n",
      "261\tValidation loss: 2.067394\tBest loss: 2.067394\tAccuracy: 47.50%\n",
      "262\tValidation loss: 2.057975\tBest loss: 2.057975\tAccuracy: 48.60%\n",
      "263\tValidation loss: 2.067179\tBest loss: 2.057975\tAccuracy: 46.80%\n",
      "264\tValidation loss: 2.061610\tBest loss: 2.057975\tAccuracy: 47.40%\n",
      "265\tValidation loss: 2.060417\tBest loss: 2.057975\tAccuracy: 47.80%\n",
      "266\tValidation loss: 2.053471\tBest loss: 2.053471\tAccuracy: 47.00%\n",
      "267\tValidation loss: 2.049592\tBest loss: 2.049592\tAccuracy: 47.00%\n",
      "268\tValidation loss: 2.043006\tBest loss: 2.043006\tAccuracy: 47.20%\n",
      "269\tValidation loss: 2.046797\tBest loss: 2.043006\tAccuracy: 48.10%\n",
      "270\tValidation loss: 2.035483\tBest loss: 2.035483\tAccuracy: 48.30%\n",
      "271\tValidation loss: 2.041811\tBest loss: 2.035483\tAccuracy: 48.90%\n",
      "272\tValidation loss: 2.034010\tBest loss: 2.034010\tAccuracy: 49.20%\n",
      "273\tValidation loss: 2.032487\tBest loss: 2.032487\tAccuracy: 49.20%\n",
      "274\tValidation loss: 2.031161\tBest loss: 2.031161\tAccuracy: 49.30%\n",
      "275\tValidation loss: 2.027788\tBest loss: 2.027788\tAccuracy: 48.50%\n",
      "276\tValidation loss: 2.021797\tBest loss: 2.021797\tAccuracy: 48.10%\n",
      "277\tValidation loss: 2.017386\tBest loss: 2.017386\tAccuracy: 49.60%\n",
      "278\tValidation loss: 2.018445\tBest loss: 2.017386\tAccuracy: 49.30%\n",
      "279\tValidation loss: 2.012486\tBest loss: 2.012486\tAccuracy: 49.40%\n",
      "280\tValidation loss: 2.007480\tBest loss: 2.007480\tAccuracy: 49.10%\n",
      "281\tValidation loss: 2.007113\tBest loss: 2.007113\tAccuracy: 49.50%\n",
      "282\tValidation loss: 2.003682\tBest loss: 2.003682\tAccuracy: 49.70%\n",
      "283\tValidation loss: 2.007471\tBest loss: 2.003682\tAccuracy: 49.20%\n",
      "284\tValidation loss: 2.006217\tBest loss: 2.003682\tAccuracy: 49.50%\n",
      "285\tValidation loss: 2.001608\tBest loss: 2.001608\tAccuracy: 49.60%\n",
      "286\tValidation loss: 1.995679\tBest loss: 1.995679\tAccuracy: 49.50%\n",
      "287\tValidation loss: 1.995200\tBest loss: 1.995200\tAccuracy: 50.20%\n",
      "288\tValidation loss: 1.985340\tBest loss: 1.985340\tAccuracy: 49.90%\n",
      "289\tValidation loss: 1.988613\tBest loss: 1.985340\tAccuracy: 49.90%\n",
      "290\tValidation loss: 1.990464\tBest loss: 1.985340\tAccuracy: 49.60%\n",
      "291\tValidation loss: 1.990123\tBest loss: 1.985340\tAccuracy: 49.80%\n",
      "292\tValidation loss: 1.978878\tBest loss: 1.978878\tAccuracy: 50.00%\n",
      "293\tValidation loss: 1.984455\tBest loss: 1.978878\tAccuracy: 50.40%\n",
      "294\tValidation loss: 1.977461\tBest loss: 1.977461\tAccuracy: 50.60%\n",
      "295\tValidation loss: 1.969301\tBest loss: 1.969301\tAccuracy: 50.60%\n",
      "296\tValidation loss: 1.974839\tBest loss: 1.969301\tAccuracy: 50.90%\n",
      "297\tValidation loss: 1.970669\tBest loss: 1.969301\tAccuracy: 50.50%\n",
      "298\tValidation loss: 1.965588\tBest loss: 1.965588\tAccuracy: 50.10%\n",
      "299\tValidation loss: 1.966190\tBest loss: 1.965588\tAccuracy: 51.50%\n",
      "300\tValidation loss: 1.964405\tBest loss: 1.964405\tAccuracy: 50.70%\n",
      "301\tValidation loss: 1.955290\tBest loss: 1.955290\tAccuracy: 51.10%\n",
      "302\tValidation loss: 1.959467\tBest loss: 1.955290\tAccuracy: 51.30%\n",
      "303\tValidation loss: 1.959136\tBest loss: 1.955290\tAccuracy: 50.30%\n",
      "304\tValidation loss: 1.955481\tBest loss: 1.955290\tAccuracy: 51.30%\n",
      "305\tValidation loss: 1.955559\tBest loss: 1.955290\tAccuracy: 51.40%\n",
      "306\tValidation loss: 1.951388\tBest loss: 1.951388\tAccuracy: 51.30%\n",
      "307\tValidation loss: 1.948354\tBest loss: 1.948354\tAccuracy: 51.80%\n",
      "308\tValidation loss: 1.951074\tBest loss: 1.948354\tAccuracy: 51.00%\n",
      "309\tValidation loss: 1.950408\tBest loss: 1.948354\tAccuracy: 50.60%\n",
      "310\tValidation loss: 1.946648\tBest loss: 1.946648\tAccuracy: 51.70%\n",
      "311\tValidation loss: 1.946231\tBest loss: 1.946231\tAccuracy: 51.60%\n",
      "312\tValidation loss: 1.945575\tBest loss: 1.945575\tAccuracy: 51.70%\n",
      "313\tValidation loss: 1.940347\tBest loss: 1.940347\tAccuracy: 51.10%\n",
      "314\tValidation loss: 1.938801\tBest loss: 1.938801\tAccuracy: 51.90%\n",
      "315\tValidation loss: 1.939074\tBest loss: 1.938801\tAccuracy: 51.40%\n",
      "316\tValidation loss: 1.934479\tBest loss: 1.934479\tAccuracy: 52.00%\n",
      "317\tValidation loss: 1.927973\tBest loss: 1.927973\tAccuracy: 51.90%\n",
      "318\tValidation loss: 1.928989\tBest loss: 1.927973\tAccuracy: 51.80%\n",
      "319\tValidation loss: 1.929636\tBest loss: 1.927973\tAccuracy: 52.30%\n",
      "320\tValidation loss: 1.926176\tBest loss: 1.926176\tAccuracy: 51.80%\n",
      "321\tValidation loss: 1.918843\tBest loss: 1.918843\tAccuracy: 52.80%\n",
      "322\tValidation loss: 1.921798\tBest loss: 1.918843\tAccuracy: 52.30%\n",
      "323\tValidation loss: 1.916337\tBest loss: 1.916337\tAccuracy: 52.20%\n",
      "324\tValidation loss: 1.915436\tBest loss: 1.915436\tAccuracy: 52.70%\n",
      "325\tValidation loss: 1.920336\tBest loss: 1.915436\tAccuracy: 52.20%\n",
      "326\tValidation loss: 1.916086\tBest loss: 1.915436\tAccuracy: 51.90%\n",
      "327\tValidation loss: 1.910818\tBest loss: 1.910818\tAccuracy: 52.30%\n",
      "328\tValidation loss: 1.906377\tBest loss: 1.906377\tAccuracy: 52.70%\n",
      "329\tValidation loss: 1.908822\tBest loss: 1.906377\tAccuracy: 52.40%\n",
      "330\tValidation loss: 1.906445\tBest loss: 1.906377\tAccuracy: 51.60%\n",
      "331\tValidation loss: 1.902598\tBest loss: 1.902598\tAccuracy: 53.00%\n",
      "332\tValidation loss: 1.903663\tBest loss: 1.902598\tAccuracy: 52.40%\n",
      "333\tValidation loss: 1.904235\tBest loss: 1.902598\tAccuracy: 51.90%\n",
      "334\tValidation loss: 1.907580\tBest loss: 1.902598\tAccuracy: 52.50%\n",
      "335\tValidation loss: 1.899027\tBest loss: 1.899027\tAccuracy: 53.10%\n",
      "336\tValidation loss: 1.897756\tBest loss: 1.897756\tAccuracy: 52.60%\n",
      "337\tValidation loss: 1.899638\tBest loss: 1.897756\tAccuracy: 52.70%\n",
      "338\tValidation loss: 1.898355\tBest loss: 1.897756\tAccuracy: 53.40%\n",
      "339\tValidation loss: 1.895593\tBest loss: 1.895593\tAccuracy: 53.30%\n",
      "340\tValidation loss: 1.892736\tBest loss: 1.892736\tAccuracy: 53.00%\n",
      "341\tValidation loss: 1.888356\tBest loss: 1.888356\tAccuracy: 53.70%\n",
      "342\tValidation loss: 1.892841\tBest loss: 1.888356\tAccuracy: 53.50%\n",
      "343\tValidation loss: 1.885707\tBest loss: 1.885707\tAccuracy: 53.50%\n",
      "344\tValidation loss: 1.887882\tBest loss: 1.885707\tAccuracy: 53.30%\n",
      "345\tValidation loss: 1.881885\tBest loss: 1.881885\tAccuracy: 53.10%\n",
      "346\tValidation loss: 1.883354\tBest loss: 1.881885\tAccuracy: 52.20%\n",
      "347\tValidation loss: 1.879441\tBest loss: 1.879441\tAccuracy: 52.50%\n",
      "348\tValidation loss: 1.876275\tBest loss: 1.876275\tAccuracy: 53.40%\n",
      "349\tValidation loss: 1.876275\tBest loss: 1.876275\tAccuracy: 54.90%\n",
      "350\tValidation loss: 1.875163\tBest loss: 1.875163\tAccuracy: 52.80%\n",
      "351\tValidation loss: 1.874516\tBest loss: 1.874516\tAccuracy: 52.90%\n",
      "352\tValidation loss: 1.873786\tBest loss: 1.873786\tAccuracy: 53.20%\n",
      "353\tValidation loss: 1.874009\tBest loss: 1.873786\tAccuracy: 53.10%\n",
      "354\tValidation loss: 1.876557\tBest loss: 1.873786\tAccuracy: 52.50%\n",
      "355\tValidation loss: 1.868378\tBest loss: 1.868378\tAccuracy: 53.00%\n",
      "356\tValidation loss: 1.869557\tBest loss: 1.868378\tAccuracy: 53.70%\n",
      "357\tValidation loss: 1.863047\tBest loss: 1.863047\tAccuracy: 54.20%\n",
      "358\tValidation loss: 1.868335\tBest loss: 1.863047\tAccuracy: 53.60%\n",
      "359\tValidation loss: 1.868287\tBest loss: 1.863047\tAccuracy: 53.20%\n",
      "360\tValidation loss: 1.870125\tBest loss: 1.863047\tAccuracy: 54.20%\n",
      "361\tValidation loss: 1.864931\tBest loss: 1.863047\tAccuracy: 53.60%\n",
      "362\tValidation loss: 1.861301\tBest loss: 1.861301\tAccuracy: 53.80%\n",
      "363\tValidation loss: 1.857694\tBest loss: 1.857694\tAccuracy: 54.10%\n",
      "364\tValidation loss: 1.853858\tBest loss: 1.853858\tAccuracy: 54.20%\n",
      "365\tValidation loss: 1.857058\tBest loss: 1.853858\tAccuracy: 53.10%\n",
      "366\tValidation loss: 1.857038\tBest loss: 1.853858\tAccuracy: 53.60%\n",
      "367\tValidation loss: 1.852906\tBest loss: 1.852906\tAccuracy: 53.80%\n",
      "368\tValidation loss: 1.853500\tBest loss: 1.852906\tAccuracy: 53.40%\n",
      "369\tValidation loss: 1.854396\tBest loss: 1.852906\tAccuracy: 53.10%\n",
      "370\tValidation loss: 1.853882\tBest loss: 1.852906\tAccuracy: 54.50%\n",
      "371\tValidation loss: 1.849629\tBest loss: 1.849629\tAccuracy: 53.80%\n",
      "372\tValidation loss: 1.849707\tBest loss: 1.849629\tAccuracy: 54.30%\n",
      "373\tValidation loss: 1.845343\tBest loss: 1.845343\tAccuracy: 53.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\tValidation loss: 1.845779\tBest loss: 1.845343\tAccuracy: 53.60%\n",
      "375\tValidation loss: 1.842977\tBest loss: 1.842977\tAccuracy: 55.10%\n",
      "376\tValidation loss: 1.845845\tBest loss: 1.842977\tAccuracy: 54.70%\n",
      "377\tValidation loss: 1.845009\tBest loss: 1.842977\tAccuracy: 54.90%\n",
      "378\tValidation loss: 1.838844\tBest loss: 1.838844\tAccuracy: 54.40%\n",
      "379\tValidation loss: 1.842741\tBest loss: 1.838844\tAccuracy: 54.70%\n",
      "380\tValidation loss: 1.837112\tBest loss: 1.837112\tAccuracy: 55.20%\n",
      "381\tValidation loss: 1.836327\tBest loss: 1.836327\tAccuracy: 55.10%\n",
      "382\tValidation loss: 1.841476\tBest loss: 1.836327\tAccuracy: 54.70%\n",
      "383\tValidation loss: 1.836470\tBest loss: 1.836327\tAccuracy: 54.30%\n",
      "384\tValidation loss: 1.836458\tBest loss: 1.836327\tAccuracy: 55.10%\n",
      "385\tValidation loss: 1.834929\tBest loss: 1.834929\tAccuracy: 54.90%\n",
      "386\tValidation loss: 1.835617\tBest loss: 1.834929\tAccuracy: 55.10%\n",
      "387\tValidation loss: 1.829758\tBest loss: 1.829758\tAccuracy: 55.10%\n",
      "388\tValidation loss: 1.834516\tBest loss: 1.829758\tAccuracy: 55.50%\n",
      "389\tValidation loss: 1.832036\tBest loss: 1.829758\tAccuracy: 55.60%\n",
      "390\tValidation loss: 1.834101\tBest loss: 1.829758\tAccuracy: 56.40%\n",
      "391\tValidation loss: 1.831496\tBest loss: 1.829758\tAccuracy: 55.30%\n",
      "392\tValidation loss: 1.827684\tBest loss: 1.827684\tAccuracy: 55.60%\n",
      "393\tValidation loss: 1.828777\tBest loss: 1.827684\tAccuracy: 55.30%\n",
      "394\tValidation loss: 1.825153\tBest loss: 1.825153\tAccuracy: 56.50%\n",
      "395\tValidation loss: 1.825349\tBest loss: 1.825153\tAccuracy: 55.50%\n",
      "396\tValidation loss: 1.822835\tBest loss: 1.822835\tAccuracy: 55.20%\n",
      "397\tValidation loss: 1.821242\tBest loss: 1.821242\tAccuracy: 56.00%\n",
      "398\tValidation loss: 1.822752\tBest loss: 1.821242\tAccuracy: 55.30%\n",
      "399\tValidation loss: 1.822236\tBest loss: 1.821242\tAccuracy: 55.60%\n",
      "400\tValidation loss: 1.823153\tBest loss: 1.821242\tAccuracy: 55.00%\n",
      "401\tValidation loss: 1.822738\tBest loss: 1.821242\tAccuracy: 55.40%\n",
      "402\tValidation loss: 1.819929\tBest loss: 1.819929\tAccuracy: 55.30%\n",
      "403\tValidation loss: 1.818674\tBest loss: 1.818674\tAccuracy: 55.30%\n",
      "404\tValidation loss: 1.818371\tBest loss: 1.818371\tAccuracy: 55.40%\n",
      "405\tValidation loss: 1.810851\tBest loss: 1.810851\tAccuracy: 55.10%\n",
      "406\tValidation loss: 1.813584\tBest loss: 1.810851\tAccuracy: 55.10%\n",
      "407\tValidation loss: 1.814563\tBest loss: 1.810851\tAccuracy: 55.30%\n",
      "408\tValidation loss: 1.816618\tBest loss: 1.810851\tAccuracy: 55.00%\n",
      "409\tValidation loss: 1.810784\tBest loss: 1.810784\tAccuracy: 55.50%\n",
      "410\tValidation loss: 1.809856\tBest loss: 1.809856\tAccuracy: 55.40%\n",
      "411\tValidation loss: 1.811683\tBest loss: 1.809856\tAccuracy: 56.00%\n",
      "412\tValidation loss: 1.809185\tBest loss: 1.809185\tAccuracy: 55.60%\n",
      "413\tValidation loss: 1.806634\tBest loss: 1.806634\tAccuracy: 55.60%\n",
      "414\tValidation loss: 1.804808\tBest loss: 1.804808\tAccuracy: 55.80%\n",
      "415\tValidation loss: 1.799339\tBest loss: 1.799339\tAccuracy: 55.90%\n",
      "416\tValidation loss: 1.808239\tBest loss: 1.799339\tAccuracy: 55.40%\n",
      "417\tValidation loss: 1.802563\tBest loss: 1.799339\tAccuracy: 55.00%\n",
      "418\tValidation loss: 1.804577\tBest loss: 1.799339\tAccuracy: 56.40%\n",
      "419\tValidation loss: 1.803271\tBest loss: 1.799339\tAccuracy: 56.50%\n",
      "420\tValidation loss: 1.801714\tBest loss: 1.799339\tAccuracy: 56.00%\n",
      "421\tValidation loss: 1.803961\tBest loss: 1.799339\tAccuracy: 56.40%\n",
      "422\tValidation loss: 1.802034\tBest loss: 1.799339\tAccuracy: 55.90%\n",
      "423\tValidation loss: 1.798752\tBest loss: 1.798752\tAccuracy: 56.20%\n",
      "424\tValidation loss: 1.798601\tBest loss: 1.798601\tAccuracy: 56.10%\n",
      "425\tValidation loss: 1.798482\tBest loss: 1.798482\tAccuracy: 56.20%\n",
      "426\tValidation loss: 1.794242\tBest loss: 1.794242\tAccuracy: 56.80%\n",
      "427\tValidation loss: 1.795980\tBest loss: 1.794242\tAccuracy: 55.70%\n",
      "428\tValidation loss: 1.797936\tBest loss: 1.794242\tAccuracy: 56.40%\n",
      "429\tValidation loss: 1.794017\tBest loss: 1.794017\tAccuracy: 56.30%\n",
      "430\tValidation loss: 1.795895\tBest loss: 1.794017\tAccuracy: 56.10%\n",
      "431\tValidation loss: 1.793823\tBest loss: 1.793823\tAccuracy: 56.40%\n",
      "432\tValidation loss: 1.793062\tBest loss: 1.793062\tAccuracy: 55.80%\n",
      "433\tValidation loss: 1.790223\tBest loss: 1.790223\tAccuracy: 56.30%\n",
      "434\tValidation loss: 1.789992\tBest loss: 1.789992\tAccuracy: 57.10%\n",
      "435\tValidation loss: 1.789489\tBest loss: 1.789489\tAccuracy: 56.90%\n",
      "436\tValidation loss: 1.788513\tBest loss: 1.788513\tAccuracy: 56.80%\n",
      "437\tValidation loss: 1.791256\tBest loss: 1.788513\tAccuracy: 55.90%\n",
      "438\tValidation loss: 1.790389\tBest loss: 1.788513\tAccuracy: 56.50%\n",
      "439\tValidation loss: 1.787361\tBest loss: 1.787361\tAccuracy: 56.20%\n",
      "440\tValidation loss: 1.786269\tBest loss: 1.786269\tAccuracy: 56.30%\n",
      "441\tValidation loss: 1.785817\tBest loss: 1.785817\tAccuracy: 55.90%\n",
      "442\tValidation loss: 1.784529\tBest loss: 1.784529\tAccuracy: 55.90%\n",
      "443\tValidation loss: 1.786936\tBest loss: 1.784529\tAccuracy: 55.70%\n",
      "444\tValidation loss: 1.782223\tBest loss: 1.782223\tAccuracy: 56.20%\n",
      "445\tValidation loss: 1.780339\tBest loss: 1.780339\tAccuracy: 56.20%\n",
      "446\tValidation loss: 1.783438\tBest loss: 1.780339\tAccuracy: 56.60%\n",
      "447\tValidation loss: 1.782284\tBest loss: 1.780339\tAccuracy: 56.60%\n",
      "448\tValidation loss: 1.785051\tBest loss: 1.780339\tAccuracy: 56.30%\n",
      "449\tValidation loss: 1.780562\tBest loss: 1.780339\tAccuracy: 55.90%\n",
      "450\tValidation loss: 1.777371\tBest loss: 1.777371\tAccuracy: 56.10%\n",
      "451\tValidation loss: 1.777098\tBest loss: 1.777098\tAccuracy: 56.00%\n",
      "452\tValidation loss: 1.776964\tBest loss: 1.776964\tAccuracy: 56.60%\n",
      "453\tValidation loss: 1.780130\tBest loss: 1.776964\tAccuracy: 56.00%\n",
      "454\tValidation loss: 1.778254\tBest loss: 1.776964\tAccuracy: 56.20%\n",
      "455\tValidation loss: 1.776386\tBest loss: 1.776386\tAccuracy: 56.10%\n",
      "456\tValidation loss: 1.772641\tBest loss: 1.772641\tAccuracy: 56.40%\n",
      "457\tValidation loss: 1.771423\tBest loss: 1.771423\tAccuracy: 56.30%\n",
      "458\tValidation loss: 1.775089\tBest loss: 1.771423\tAccuracy: 55.80%\n",
      "459\tValidation loss: 1.771166\tBest loss: 1.771166\tAccuracy: 56.10%\n",
      "460\tValidation loss: 1.773107\tBest loss: 1.771166\tAccuracy: 55.70%\n",
      "461\tValidation loss: 1.771733\tBest loss: 1.771166\tAccuracy: 56.30%\n",
      "462\tValidation loss: 1.767187\tBest loss: 1.767187\tAccuracy: 57.10%\n",
      "463\tValidation loss: 1.763884\tBest loss: 1.763884\tAccuracy: 56.90%\n",
      "464\tValidation loss: 1.764948\tBest loss: 1.763884\tAccuracy: 56.40%\n",
      "465\tValidation loss: 1.765504\tBest loss: 1.763884\tAccuracy: 56.30%\n",
      "466\tValidation loss: 1.763344\tBest loss: 1.763344\tAccuracy: 56.70%\n",
      "467\tValidation loss: 1.763232\tBest loss: 1.763232\tAccuracy: 56.70%\n",
      "468\tValidation loss: 1.762768\tBest loss: 1.762768\tAccuracy: 56.70%\n",
      "469\tValidation loss: 1.764563\tBest loss: 1.762768\tAccuracy: 56.60%\n",
      "470\tValidation loss: 1.767976\tBest loss: 1.762768\tAccuracy: 56.10%\n",
      "471\tValidation loss: 1.759445\tBest loss: 1.759445\tAccuracy: 56.90%\n",
      "472\tValidation loss: 1.761045\tBest loss: 1.759445\tAccuracy: 56.00%\n",
      "473\tValidation loss: 1.758705\tBest loss: 1.758705\tAccuracy: 56.70%\n",
      "474\tValidation loss: 1.757988\tBest loss: 1.757988\tAccuracy: 56.70%\n",
      "475\tValidation loss: 1.752404\tBest loss: 1.752404\tAccuracy: 57.20%\n",
      "476\tValidation loss: 1.755750\tBest loss: 1.752404\tAccuracy: 57.30%\n",
      "477\tValidation loss: 1.759112\tBest loss: 1.752404\tAccuracy: 56.70%\n",
      "478\tValidation loss: 1.757823\tBest loss: 1.752404\tAccuracy: 56.60%\n",
      "479\tValidation loss: 1.759038\tBest loss: 1.752404\tAccuracy: 56.80%\n",
      "480\tValidation loss: 1.754071\tBest loss: 1.752404\tAccuracy: 56.80%\n",
      "481\tValidation loss: 1.756375\tBest loss: 1.752404\tAccuracy: 56.70%\n",
      "482\tValidation loss: 1.757471\tBest loss: 1.752404\tAccuracy: 56.60%\n",
      "483\tValidation loss: 1.755644\tBest loss: 1.752404\tAccuracy: 56.90%\n",
      "484\tValidation loss: 1.758052\tBest loss: 1.752404\tAccuracy: 57.00%\n",
      "485\tValidation loss: 1.749854\tBest loss: 1.749854\tAccuracy: 56.70%\n",
      "486\tValidation loss: 1.752326\tBest loss: 1.749854\tAccuracy: 56.70%\n",
      "487\tValidation loss: 1.753583\tBest loss: 1.749854\tAccuracy: 56.70%\n",
      "488\tValidation loss: 1.749830\tBest loss: 1.749830\tAccuracy: 57.30%\n",
      "489\tValidation loss: 1.750063\tBest loss: 1.749830\tAccuracy: 57.00%\n",
      "490\tValidation loss: 1.749158\tBest loss: 1.749158\tAccuracy: 57.60%\n",
      "491\tValidation loss: 1.747770\tBest loss: 1.747770\tAccuracy: 57.30%\n",
      "492\tValidation loss: 1.746266\tBest loss: 1.746266\tAccuracy: 57.20%\n",
      "493\tValidation loss: 1.746882\tBest loss: 1.746266\tAccuracy: 57.10%\n",
      "494\tValidation loss: 1.747141\tBest loss: 1.746266\tAccuracy: 56.80%\n",
      "495\tValidation loss: 1.742849\tBest loss: 1.742849\tAccuracy: 57.30%\n",
      "496\tValidation loss: 1.743701\tBest loss: 1.742849\tAccuracy: 57.70%\n",
      "497\tValidation loss: 1.741503\tBest loss: 1.741503\tAccuracy: 57.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\tValidation loss: 1.744545\tBest loss: 1.741503\tAccuracy: 57.50%\n",
      "499\tValidation loss: 1.744508\tBest loss: 1.741503\tAccuracy: 57.10%\n",
      "500\tValidation loss: 1.747764\tBest loss: 1.741503\tAccuracy: 57.10%\n",
      "501\tValidation loss: 1.743304\tBest loss: 1.741503\tAccuracy: 57.40%\n",
      "502\tValidation loss: 1.741228\tBest loss: 1.741228\tAccuracy: 57.60%\n",
      "503\tValidation loss: 1.738888\tBest loss: 1.738888\tAccuracy: 57.40%\n",
      "504\tValidation loss: 1.741208\tBest loss: 1.738888\tAccuracy: 57.40%\n",
      "505\tValidation loss: 1.739295\tBest loss: 1.738888\tAccuracy: 57.70%\n",
      "506\tValidation loss: 1.738536\tBest loss: 1.738536\tAccuracy: 58.10%\n",
      "507\tValidation loss: 1.739107\tBest loss: 1.738536\tAccuracy: 57.90%\n",
      "508\tValidation loss: 1.743105\tBest loss: 1.738536\tAccuracy: 57.40%\n",
      "509\tValidation loss: 1.736603\tBest loss: 1.736603\tAccuracy: 57.90%\n",
      "510\tValidation loss: 1.737839\tBest loss: 1.736603\tAccuracy: 57.70%\n",
      "511\tValidation loss: 1.737371\tBest loss: 1.736603\tAccuracy: 57.60%\n",
      "512\tValidation loss: 1.738621\tBest loss: 1.736603\tAccuracy: 57.00%\n",
      "513\tValidation loss: 1.736757\tBest loss: 1.736603\tAccuracy: 57.50%\n",
      "514\tValidation loss: 1.735440\tBest loss: 1.735440\tAccuracy: 57.70%\n",
      "515\tValidation loss: 1.735075\tBest loss: 1.735075\tAccuracy: 58.00%\n",
      "516\tValidation loss: 1.736965\tBest loss: 1.735075\tAccuracy: 57.40%\n",
      "517\tValidation loss: 1.734196\tBest loss: 1.734196\tAccuracy: 57.40%\n",
      "518\tValidation loss: 1.732711\tBest loss: 1.732711\tAccuracy: 57.50%\n",
      "519\tValidation loss: 1.735005\tBest loss: 1.732711\tAccuracy: 57.00%\n",
      "520\tValidation loss: 1.730884\tBest loss: 1.730884\tAccuracy: 58.20%\n",
      "521\tValidation loss: 1.731779\tBest loss: 1.730884\tAccuracy: 57.10%\n",
      "522\tValidation loss: 1.734542\tBest loss: 1.730884\tAccuracy: 56.90%\n",
      "523\tValidation loss: 1.730599\tBest loss: 1.730599\tAccuracy: 57.60%\n",
      "524\tValidation loss: 1.731690\tBest loss: 1.730599\tAccuracy: 57.70%\n",
      "525\tValidation loss: 1.733232\tBest loss: 1.730599\tAccuracy: 58.20%\n",
      "526\tValidation loss: 1.728541\tBest loss: 1.728541\tAccuracy: 58.20%\n",
      "527\tValidation loss: 1.729995\tBest loss: 1.728541\tAccuracy: 56.90%\n",
      "528\tValidation loss: 1.727230\tBest loss: 1.727230\tAccuracy: 57.80%\n",
      "529\tValidation loss: 1.726022\tBest loss: 1.726022\tAccuracy: 57.30%\n",
      "530\tValidation loss: 1.728322\tBest loss: 1.726022\tAccuracy: 57.60%\n",
      "531\tValidation loss: 1.726126\tBest loss: 1.726022\tAccuracy: 57.90%\n",
      "532\tValidation loss: 1.726534\tBest loss: 1.726022\tAccuracy: 57.40%\n",
      "533\tValidation loss: 1.729517\tBest loss: 1.726022\tAccuracy: 57.70%\n",
      "534\tValidation loss: 1.728246\tBest loss: 1.726022\tAccuracy: 57.80%\n",
      "535\tValidation loss: 1.722872\tBest loss: 1.722872\tAccuracy: 58.00%\n",
      "536\tValidation loss: 1.728128\tBest loss: 1.722872\tAccuracy: 57.00%\n",
      "537\tValidation loss: 1.726590\tBest loss: 1.722872\tAccuracy: 57.60%\n",
      "538\tValidation loss: 1.724476\tBest loss: 1.722872\tAccuracy: 57.90%\n",
      "539\tValidation loss: 1.724715\tBest loss: 1.722872\tAccuracy: 58.00%\n",
      "540\tValidation loss: 1.727250\tBest loss: 1.722872\tAccuracy: 58.40%\n",
      "541\tValidation loss: 1.719688\tBest loss: 1.719688\tAccuracy: 57.90%\n",
      "542\tValidation loss: 1.721881\tBest loss: 1.719688\tAccuracy: 57.80%\n",
      "543\tValidation loss: 1.722006\tBest loss: 1.719688\tAccuracy: 57.70%\n",
      "544\tValidation loss: 1.720866\tBest loss: 1.719688\tAccuracy: 57.80%\n",
      "545\tValidation loss: 1.720251\tBest loss: 1.719688\tAccuracy: 57.60%\n",
      "546\tValidation loss: 1.722894\tBest loss: 1.719688\tAccuracy: 57.20%\n",
      "547\tValidation loss: 1.724026\tBest loss: 1.719688\tAccuracy: 57.40%\n",
      "548\tValidation loss: 1.719311\tBest loss: 1.719311\tAccuracy: 57.60%\n",
      "549\tValidation loss: 1.721732\tBest loss: 1.719311\tAccuracy: 57.90%\n",
      "550\tValidation loss: 1.720525\tBest loss: 1.719311\tAccuracy: 57.50%\n",
      "551\tValidation loss: 1.717807\tBest loss: 1.717807\tAccuracy: 57.90%\n",
      "552\tValidation loss: 1.720100\tBest loss: 1.717807\tAccuracy: 58.00%\n",
      "553\tValidation loss: 1.721535\tBest loss: 1.717807\tAccuracy: 57.90%\n",
      "554\tValidation loss: 1.718714\tBest loss: 1.717807\tAccuracy: 57.50%\n",
      "555\tValidation loss: 1.716155\tBest loss: 1.716155\tAccuracy: 57.50%\n",
      "556\tValidation loss: 1.716116\tBest loss: 1.716116\tAccuracy: 58.00%\n",
      "557\tValidation loss: 1.716578\tBest loss: 1.716116\tAccuracy: 57.60%\n",
      "558\tValidation loss: 1.718603\tBest loss: 1.716116\tAccuracy: 57.90%\n",
      "559\tValidation loss: 1.717851\tBest loss: 1.716116\tAccuracy: 58.20%\n",
      "560\tValidation loss: 1.718988\tBest loss: 1.716116\tAccuracy: 57.60%\n",
      "561\tValidation loss: 1.718305\tBest loss: 1.716116\tAccuracy: 58.00%\n",
      "562\tValidation loss: 1.715609\tBest loss: 1.715609\tAccuracy: 58.20%\n",
      "563\tValidation loss: 1.714913\tBest loss: 1.714913\tAccuracy: 57.90%\n",
      "564\tValidation loss: 1.714989\tBest loss: 1.714913\tAccuracy: 57.90%\n",
      "565\tValidation loss: 1.713881\tBest loss: 1.713881\tAccuracy: 58.50%\n",
      "566\tValidation loss: 1.713885\tBest loss: 1.713881\tAccuracy: 58.80%\n",
      "567\tValidation loss: 1.709217\tBest loss: 1.709217\tAccuracy: 58.30%\n",
      "568\tValidation loss: 1.711837\tBest loss: 1.709217\tAccuracy: 57.50%\n",
      "569\tValidation loss: 1.707976\tBest loss: 1.707976\tAccuracy: 57.80%\n",
      "570\tValidation loss: 1.711082\tBest loss: 1.707976\tAccuracy: 58.20%\n",
      "571\tValidation loss: 1.709040\tBest loss: 1.707976\tAccuracy: 58.60%\n",
      "572\tValidation loss: 1.711776\tBest loss: 1.707976\tAccuracy: 57.80%\n",
      "573\tValidation loss: 1.709603\tBest loss: 1.707976\tAccuracy: 58.30%\n",
      "574\tValidation loss: 1.709148\tBest loss: 1.707976\tAccuracy: 58.20%\n",
      "575\tValidation loss: 1.710027\tBest loss: 1.707976\tAccuracy: 58.30%\n",
      "576\tValidation loss: 1.706974\tBest loss: 1.706974\tAccuracy: 58.30%\n",
      "577\tValidation loss: 1.706171\tBest loss: 1.706171\tAccuracy: 58.40%\n",
      "578\tValidation loss: 1.705848\tBest loss: 1.705848\tAccuracy: 57.90%\n",
      "579\tValidation loss: 1.708076\tBest loss: 1.705848\tAccuracy: 57.80%\n",
      "580\tValidation loss: 1.709597\tBest loss: 1.705848\tAccuracy: 57.60%\n",
      "581\tValidation loss: 1.704548\tBest loss: 1.704548\tAccuracy: 57.90%\n",
      "582\tValidation loss: 1.706412\tBest loss: 1.704548\tAccuracy: 58.10%\n",
      "583\tValidation loss: 1.707042\tBest loss: 1.704548\tAccuracy: 58.00%\n",
      "584\tValidation loss: 1.708257\tBest loss: 1.704548\tAccuracy: 58.30%\n",
      "585\tValidation loss: 1.704639\tBest loss: 1.704548\tAccuracy: 58.30%\n",
      "586\tValidation loss: 1.708684\tBest loss: 1.704548\tAccuracy: 58.00%\n",
      "587\tValidation loss: 1.709286\tBest loss: 1.704548\tAccuracy: 58.10%\n",
      "588\tValidation loss: 1.709757\tBest loss: 1.704548\tAccuracy: 58.10%\n",
      "589\tValidation loss: 1.707166\tBest loss: 1.704548\tAccuracy: 58.30%\n",
      "590\tValidation loss: 1.706540\tBest loss: 1.704548\tAccuracy: 58.10%\n",
      "591\tValidation loss: 1.704691\tBest loss: 1.704548\tAccuracy: 58.60%\n",
      "592\tValidation loss: 1.701240\tBest loss: 1.701240\tAccuracy: 58.40%\n",
      "593\tValidation loss: 1.700381\tBest loss: 1.700381\tAccuracy: 59.00%\n",
      "594\tValidation loss: 1.699539\tBest loss: 1.699539\tAccuracy: 58.00%\n",
      "595\tValidation loss: 1.701200\tBest loss: 1.699539\tAccuracy: 58.40%\n",
      "596\tValidation loss: 1.699821\tBest loss: 1.699539\tAccuracy: 58.00%\n",
      "597\tValidation loss: 1.696587\tBest loss: 1.696587\tAccuracy: 58.30%\n",
      "598\tValidation loss: 1.696726\tBest loss: 1.696587\tAccuracy: 58.30%\n",
      "599\tValidation loss: 1.697525\tBest loss: 1.696587\tAccuracy: 58.10%\n",
      "600\tValidation loss: 1.699452\tBest loss: 1.696587\tAccuracy: 58.20%\n",
      "601\tValidation loss: 1.696665\tBest loss: 1.696587\tAccuracy: 58.10%\n",
      "602\tValidation loss: 1.694786\tBest loss: 1.694786\tAccuracy: 58.10%\n",
      "603\tValidation loss: 1.693820\tBest loss: 1.693820\tAccuracy: 57.90%\n",
      "604\tValidation loss: 1.693972\tBest loss: 1.693820\tAccuracy: 59.00%\n",
      "605\tValidation loss: 1.694043\tBest loss: 1.693820\tAccuracy: 57.90%\n",
      "606\tValidation loss: 1.694842\tBest loss: 1.693820\tAccuracy: 58.70%\n",
      "607\tValidation loss: 1.693455\tBest loss: 1.693455\tAccuracy: 58.30%\n",
      "608\tValidation loss: 1.698713\tBest loss: 1.693455\tAccuracy: 58.60%\n",
      "609\tValidation loss: 1.695367\tBest loss: 1.693455\tAccuracy: 58.70%\n",
      "610\tValidation loss: 1.696762\tBest loss: 1.693455\tAccuracy: 59.20%\n",
      "611\tValidation loss: 1.691262\tBest loss: 1.691262\tAccuracy: 59.10%\n",
      "612\tValidation loss: 1.688135\tBest loss: 1.688135\tAccuracy: 59.20%\n",
      "613\tValidation loss: 1.691555\tBest loss: 1.688135\tAccuracy: 58.80%\n",
      "614\tValidation loss: 1.692267\tBest loss: 1.688135\tAccuracy: 59.00%\n",
      "615\tValidation loss: 1.690449\tBest loss: 1.688135\tAccuracy: 59.30%\n",
      "616\tValidation loss: 1.693249\tBest loss: 1.688135\tAccuracy: 58.60%\n",
      "617\tValidation loss: 1.687751\tBest loss: 1.687751\tAccuracy: 58.50%\n",
      "618\tValidation loss: 1.689683\tBest loss: 1.687751\tAccuracy: 58.50%\n",
      "619\tValidation loss: 1.687978\tBest loss: 1.687751\tAccuracy: 59.00%\n",
      "620\tValidation loss: 1.688099\tBest loss: 1.687751\tAccuracy: 58.20%\n",
      "621\tValidation loss: 1.688644\tBest loss: 1.687751\tAccuracy: 58.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\tValidation loss: 1.686799\tBest loss: 1.686799\tAccuracy: 59.20%\n",
      "623\tValidation loss: 1.688345\tBest loss: 1.686799\tAccuracy: 58.70%\n",
      "624\tValidation loss: 1.686615\tBest loss: 1.686615\tAccuracy: 59.10%\n",
      "625\tValidation loss: 1.689980\tBest loss: 1.686615\tAccuracy: 58.80%\n",
      "626\tValidation loss: 1.685747\tBest loss: 1.685747\tAccuracy: 58.80%\n",
      "627\tValidation loss: 1.684986\tBest loss: 1.684986\tAccuracy: 58.40%\n",
      "628\tValidation loss: 1.684530\tBest loss: 1.684530\tAccuracy: 58.90%\n",
      "629\tValidation loss: 1.682793\tBest loss: 1.682793\tAccuracy: 58.60%\n",
      "630\tValidation loss: 1.684610\tBest loss: 1.682793\tAccuracy: 59.00%\n",
      "631\tValidation loss: 1.688208\tBest loss: 1.682793\tAccuracy: 58.40%\n",
      "632\tValidation loss: 1.680367\tBest loss: 1.680367\tAccuracy: 58.50%\n",
      "633\tValidation loss: 1.679816\tBest loss: 1.679816\tAccuracy: 58.50%\n",
      "634\tValidation loss: 1.681807\tBest loss: 1.679816\tAccuracy: 58.90%\n",
      "635\tValidation loss: 1.679744\tBest loss: 1.679744\tAccuracy: 58.10%\n",
      "636\tValidation loss: 1.682835\tBest loss: 1.679744\tAccuracy: 59.50%\n",
      "637\tValidation loss: 1.679472\tBest loss: 1.679472\tAccuracy: 59.10%\n",
      "638\tValidation loss: 1.681237\tBest loss: 1.679472\tAccuracy: 58.90%\n",
      "639\tValidation loss: 1.682644\tBest loss: 1.679472\tAccuracy: 58.90%\n",
      "640\tValidation loss: 1.681190\tBest loss: 1.679472\tAccuracy: 58.50%\n",
      "641\tValidation loss: 1.681559\tBest loss: 1.679472\tAccuracy: 58.80%\n",
      "642\tValidation loss: 1.678774\tBest loss: 1.678774\tAccuracy: 58.40%\n",
      "643\tValidation loss: 1.678090\tBest loss: 1.678090\tAccuracy: 58.50%\n",
      "644\tValidation loss: 1.675135\tBest loss: 1.675135\tAccuracy: 59.00%\n",
      "645\tValidation loss: 1.674085\tBest loss: 1.674085\tAccuracy: 59.40%\n",
      "646\tValidation loss: 1.677304\tBest loss: 1.674085\tAccuracy: 59.10%\n",
      "647\tValidation loss: 1.678657\tBest loss: 1.674085\tAccuracy: 58.70%\n",
      "648\tValidation loss: 1.680899\tBest loss: 1.674085\tAccuracy: 58.80%\n",
      "649\tValidation loss: 1.676161\tBest loss: 1.674085\tAccuracy: 59.10%\n",
      "650\tValidation loss: 1.675996\tBest loss: 1.674085\tAccuracy: 58.90%\n",
      "651\tValidation loss: 1.674127\tBest loss: 1.674085\tAccuracy: 58.40%\n",
      "652\tValidation loss: 1.676862\tBest loss: 1.674085\tAccuracy: 58.30%\n",
      "653\tValidation loss: 1.676600\tBest loss: 1.674085\tAccuracy: 59.00%\n",
      "654\tValidation loss: 1.674599\tBest loss: 1.674085\tAccuracy: 59.20%\n",
      "655\tValidation loss: 1.676594\tBest loss: 1.674085\tAccuracy: 58.80%\n",
      "656\tValidation loss: 1.674682\tBest loss: 1.674085\tAccuracy: 59.20%\n",
      "657\tValidation loss: 1.680487\tBest loss: 1.674085\tAccuracy: 58.80%\n",
      "658\tValidation loss: 1.675429\tBest loss: 1.674085\tAccuracy: 58.70%\n",
      "659\tValidation loss: 1.674390\tBest loss: 1.674085\tAccuracy: 59.30%\n",
      "660\tValidation loss: 1.672875\tBest loss: 1.672875\tAccuracy: 59.30%\n",
      "661\tValidation loss: 1.671501\tBest loss: 1.671501\tAccuracy: 59.20%\n",
      "662\tValidation loss: 1.669494\tBest loss: 1.669494\tAccuracy: 58.50%\n",
      "663\tValidation loss: 1.673707\tBest loss: 1.669494\tAccuracy: 59.40%\n",
      "664\tValidation loss: 1.669227\tBest loss: 1.669227\tAccuracy: 59.30%\n",
      "665\tValidation loss: 1.671487\tBest loss: 1.669227\tAccuracy: 58.90%\n",
      "666\tValidation loss: 1.674717\tBest loss: 1.669227\tAccuracy: 58.80%\n",
      "667\tValidation loss: 1.670270\tBest loss: 1.669227\tAccuracy: 59.50%\n",
      "668\tValidation loss: 1.672978\tBest loss: 1.669227\tAccuracy: 60.10%\n",
      "669\tValidation loss: 1.669680\tBest loss: 1.669227\tAccuracy: 59.00%\n",
      "670\tValidation loss: 1.670211\tBest loss: 1.669227\tAccuracy: 59.90%\n",
      "671\tValidation loss: 1.671841\tBest loss: 1.669227\tAccuracy: 59.20%\n",
      "672\tValidation loss: 1.669256\tBest loss: 1.669227\tAccuracy: 59.20%\n",
      "673\tValidation loss: 1.669830\tBest loss: 1.669227\tAccuracy: 59.30%\n",
      "674\tValidation loss: 1.667891\tBest loss: 1.667891\tAccuracy: 59.70%\n",
      "675\tValidation loss: 1.668593\tBest loss: 1.667891\tAccuracy: 59.50%\n",
      "676\tValidation loss: 1.666916\tBest loss: 1.666916\tAccuracy: 59.30%\n",
      "677\tValidation loss: 1.669238\tBest loss: 1.666916\tAccuracy: 59.50%\n",
      "678\tValidation loss: 1.668281\tBest loss: 1.666916\tAccuracy: 59.90%\n",
      "679\tValidation loss: 1.669623\tBest loss: 1.666916\tAccuracy: 59.10%\n",
      "680\tValidation loss: 1.668590\tBest loss: 1.666916\tAccuracy: 59.00%\n",
      "681\tValidation loss: 1.674016\tBest loss: 1.666916\tAccuracy: 59.00%\n",
      "682\tValidation loss: 1.667659\tBest loss: 1.666916\tAccuracy: 59.50%\n",
      "683\tValidation loss: 1.662561\tBest loss: 1.662561\tAccuracy: 59.60%\n",
      "684\tValidation loss: 1.670193\tBest loss: 1.662561\tAccuracy: 59.10%\n",
      "685\tValidation loss: 1.671354\tBest loss: 1.662561\tAccuracy: 59.00%\n",
      "686\tValidation loss: 1.668638\tBest loss: 1.662561\tAccuracy: 60.20%\n",
      "687\tValidation loss: 1.664088\tBest loss: 1.662561\tAccuracy: 59.30%\n",
      "688\tValidation loss: 1.663428\tBest loss: 1.662561\tAccuracy: 59.90%\n",
      "689\tValidation loss: 1.663730\tBest loss: 1.662561\tAccuracy: 59.70%\n",
      "690\tValidation loss: 1.663182\tBest loss: 1.662561\tAccuracy: 59.60%\n",
      "691\tValidation loss: 1.663445\tBest loss: 1.662561\tAccuracy: 59.60%\n",
      "692\tValidation loss: 1.663099\tBest loss: 1.662561\tAccuracy: 59.50%\n",
      "693\tValidation loss: 1.661105\tBest loss: 1.661105\tAccuracy: 59.40%\n",
      "694\tValidation loss: 1.661831\tBest loss: 1.661105\tAccuracy: 59.70%\n",
      "695\tValidation loss: 1.659478\tBest loss: 1.659478\tAccuracy: 59.80%\n",
      "696\tValidation loss: 1.662205\tBest loss: 1.659478\tAccuracy: 60.50%\n",
      "697\tValidation loss: 1.665557\tBest loss: 1.659478\tAccuracy: 60.00%\n",
      "698\tValidation loss: 1.664131\tBest loss: 1.659478\tAccuracy: 59.50%\n",
      "699\tValidation loss: 1.664880\tBest loss: 1.659478\tAccuracy: 60.20%\n",
      "700\tValidation loss: 1.663568\tBest loss: 1.659478\tAccuracy: 59.70%\n",
      "701\tValidation loss: 1.662944\tBest loss: 1.659478\tAccuracy: 60.20%\n",
      "702\tValidation loss: 1.662041\tBest loss: 1.659478\tAccuracy: 59.70%\n",
      "703\tValidation loss: 1.660587\tBest loss: 1.659478\tAccuracy: 60.20%\n",
      "704\tValidation loss: 1.659551\tBest loss: 1.659478\tAccuracy: 59.60%\n",
      "705\tValidation loss: 1.659032\tBest loss: 1.659032\tAccuracy: 59.60%\n",
      "706\tValidation loss: 1.657875\tBest loss: 1.657875\tAccuracy: 60.10%\n",
      "707\tValidation loss: 1.658777\tBest loss: 1.657875\tAccuracy: 59.70%\n",
      "708\tValidation loss: 1.657990\tBest loss: 1.657875\tAccuracy: 59.70%\n",
      "709\tValidation loss: 1.660810\tBest loss: 1.657875\tAccuracy: 60.10%\n",
      "710\tValidation loss: 1.659790\tBest loss: 1.657875\tAccuracy: 59.70%\n",
      "711\tValidation loss: 1.660026\tBest loss: 1.657875\tAccuracy: 59.20%\n",
      "712\tValidation loss: 1.658964\tBest loss: 1.657875\tAccuracy: 59.30%\n",
      "713\tValidation loss: 1.656650\tBest loss: 1.656650\tAccuracy: 59.50%\n",
      "714\tValidation loss: 1.659522\tBest loss: 1.656650\tAccuracy: 59.20%\n",
      "715\tValidation loss: 1.654478\tBest loss: 1.654478\tAccuracy: 60.30%\n",
      "716\tValidation loss: 1.655782\tBest loss: 1.654478\tAccuracy: 60.20%\n",
      "717\tValidation loss: 1.656030\tBest loss: 1.654478\tAccuracy: 59.90%\n",
      "718\tValidation loss: 1.661077\tBest loss: 1.654478\tAccuracy: 59.50%\n",
      "719\tValidation loss: 1.657069\tBest loss: 1.654478\tAccuracy: 59.80%\n",
      "720\tValidation loss: 1.656858\tBest loss: 1.654478\tAccuracy: 60.40%\n",
      "721\tValidation loss: 1.653885\tBest loss: 1.653885\tAccuracy: 59.90%\n",
      "722\tValidation loss: 1.657215\tBest loss: 1.653885\tAccuracy: 60.00%\n",
      "723\tValidation loss: 1.656677\tBest loss: 1.653885\tAccuracy: 59.90%\n",
      "724\tValidation loss: 1.654673\tBest loss: 1.653885\tAccuracy: 59.90%\n",
      "725\tValidation loss: 1.653306\tBest loss: 1.653306\tAccuracy: 59.90%\n",
      "726\tValidation loss: 1.651214\tBest loss: 1.651214\tAccuracy: 59.80%\n",
      "727\tValidation loss: 1.649102\tBest loss: 1.649102\tAccuracy: 60.50%\n",
      "728\tValidation loss: 1.653878\tBest loss: 1.649102\tAccuracy: 60.40%\n",
      "729\tValidation loss: 1.648730\tBest loss: 1.648730\tAccuracy: 60.60%\n",
      "730\tValidation loss: 1.649395\tBest loss: 1.648730\tAccuracy: 60.70%\n",
      "731\tValidation loss: 1.647737\tBest loss: 1.647737\tAccuracy: 60.70%\n",
      "732\tValidation loss: 1.649330\tBest loss: 1.647737\tAccuracy: 60.70%\n",
      "733\tValidation loss: 1.649884\tBest loss: 1.647737\tAccuracy: 60.20%\n",
      "734\tValidation loss: 1.646633\tBest loss: 1.646633\tAccuracy: 60.80%\n",
      "735\tValidation loss: 1.652196\tBest loss: 1.646633\tAccuracy: 60.00%\n",
      "736\tValidation loss: 1.650903\tBest loss: 1.646633\tAccuracy: 60.10%\n",
      "737\tValidation loss: 1.649603\tBest loss: 1.646633\tAccuracy: 59.60%\n",
      "738\tValidation loss: 1.647765\tBest loss: 1.646633\tAccuracy: 59.90%\n",
      "739\tValidation loss: 1.649758\tBest loss: 1.646633\tAccuracy: 60.20%\n",
      "740\tValidation loss: 1.652012\tBest loss: 1.646633\tAccuracy: 60.00%\n",
      "741\tValidation loss: 1.648152\tBest loss: 1.646633\tAccuracy: 60.30%\n",
      "742\tValidation loss: 1.649296\tBest loss: 1.646633\tAccuracy: 59.80%\n",
      "743\tValidation loss: 1.651293\tBest loss: 1.646633\tAccuracy: 60.00%\n",
      "744\tValidation loss: 1.648769\tBest loss: 1.646633\tAccuracy: 59.30%\n",
      "745\tValidation loss: 1.645240\tBest loss: 1.645240\tAccuracy: 60.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746\tValidation loss: 1.646591\tBest loss: 1.645240\tAccuracy: 60.20%\n",
      "747\tValidation loss: 1.646235\tBest loss: 1.645240\tAccuracy: 60.10%\n",
      "748\tValidation loss: 1.647853\tBest loss: 1.645240\tAccuracy: 59.80%\n",
      "749\tValidation loss: 1.645625\tBest loss: 1.645240\tAccuracy: 60.30%\n",
      "750\tValidation loss: 1.647420\tBest loss: 1.645240\tAccuracy: 60.50%\n",
      "751\tValidation loss: 1.646762\tBest loss: 1.645240\tAccuracy: 60.20%\n",
      "752\tValidation loss: 1.646491\tBest loss: 1.645240\tAccuracy: 60.30%\n",
      "753\tValidation loss: 1.649881\tBest loss: 1.645240\tAccuracy: 60.20%\n",
      "754\tValidation loss: 1.650093\tBest loss: 1.645240\tAccuracy: 60.20%\n",
      "755\tValidation loss: 1.648027\tBest loss: 1.645240\tAccuracy: 59.70%\n",
      "756\tValidation loss: 1.648670\tBest loss: 1.645240\tAccuracy: 59.70%\n",
      "757\tValidation loss: 1.646927\tBest loss: 1.645240\tAccuracy: 60.00%\n",
      "758\tValidation loss: 1.649018\tBest loss: 1.645240\tAccuracy: 59.70%\n",
      "759\tValidation loss: 1.649608\tBest loss: 1.645240\tAccuracy: 59.70%\n",
      "760\tValidation loss: 1.644068\tBest loss: 1.644068\tAccuracy: 59.90%\n",
      "761\tValidation loss: 1.644025\tBest loss: 1.644025\tAccuracy: 60.90%\n",
      "762\tValidation loss: 1.646404\tBest loss: 1.644025\tAccuracy: 60.40%\n",
      "763\tValidation loss: 1.643736\tBest loss: 1.643736\tAccuracy: 60.90%\n",
      "764\tValidation loss: 1.644606\tBest loss: 1.643736\tAccuracy: 60.20%\n",
      "765\tValidation loss: 1.641358\tBest loss: 1.641358\tAccuracy: 59.90%\n",
      "766\tValidation loss: 1.641296\tBest loss: 1.641296\tAccuracy: 60.70%\n",
      "767\tValidation loss: 1.640455\tBest loss: 1.640455\tAccuracy: 60.50%\n",
      "768\tValidation loss: 1.643830\tBest loss: 1.640455\tAccuracy: 60.10%\n",
      "769\tValidation loss: 1.639235\tBest loss: 1.639235\tAccuracy: 61.30%\n",
      "770\tValidation loss: 1.639029\tBest loss: 1.639029\tAccuracy: 60.50%\n",
      "771\tValidation loss: 1.638476\tBest loss: 1.638476\tAccuracy: 61.00%\n",
      "772\tValidation loss: 1.636715\tBest loss: 1.636715\tAccuracy: 61.00%\n",
      "773\tValidation loss: 1.638416\tBest loss: 1.636715\tAccuracy: 60.30%\n",
      "774\tValidation loss: 1.639084\tBest loss: 1.636715\tAccuracy: 60.90%\n",
      "775\tValidation loss: 1.637297\tBest loss: 1.636715\tAccuracy: 60.80%\n",
      "776\tValidation loss: 1.640785\tBest loss: 1.636715\tAccuracy: 60.10%\n",
      "777\tValidation loss: 1.637509\tBest loss: 1.636715\tAccuracy: 59.60%\n",
      "778\tValidation loss: 1.642581\tBest loss: 1.636715\tAccuracy: 59.40%\n",
      "779\tValidation loss: 1.639329\tBest loss: 1.636715\tAccuracy: 59.90%\n",
      "780\tValidation loss: 1.636579\tBest loss: 1.636579\tAccuracy: 60.50%\n",
      "781\tValidation loss: 1.637432\tBest loss: 1.636579\tAccuracy: 60.80%\n",
      "782\tValidation loss: 1.640837\tBest loss: 1.636579\tAccuracy: 60.20%\n",
      "783\tValidation loss: 1.641468\tBest loss: 1.636579\tAccuracy: 60.40%\n",
      "784\tValidation loss: 1.640725\tBest loss: 1.636579\tAccuracy: 60.30%\n",
      "785\tValidation loss: 1.638584\tBest loss: 1.636579\tAccuracy: 60.30%\n",
      "786\tValidation loss: 1.635569\tBest loss: 1.635569\tAccuracy: 60.80%\n",
      "787\tValidation loss: 1.634577\tBest loss: 1.634577\tAccuracy: 61.60%\n",
      "788\tValidation loss: 1.639482\tBest loss: 1.634577\tAccuracy: 60.40%\n",
      "789\tValidation loss: 1.640824\tBest loss: 1.634577\tAccuracy: 60.50%\n",
      "790\tValidation loss: 1.636400\tBest loss: 1.634577\tAccuracy: 60.70%\n",
      "791\tValidation loss: 1.634876\tBest loss: 1.634577\tAccuracy: 60.80%\n",
      "792\tValidation loss: 1.638180\tBest loss: 1.634577\tAccuracy: 60.60%\n",
      "793\tValidation loss: 1.638020\tBest loss: 1.634577\tAccuracy: 60.80%\n",
      "794\tValidation loss: 1.636740\tBest loss: 1.634577\tAccuracy: 60.70%\n",
      "795\tValidation loss: 1.639950\tBest loss: 1.634577\tAccuracy: 60.70%\n",
      "796\tValidation loss: 1.637254\tBest loss: 1.634577\tAccuracy: 60.20%\n",
      "797\tValidation loss: 1.634252\tBest loss: 1.634252\tAccuracy: 60.60%\n",
      "798\tValidation loss: 1.636470\tBest loss: 1.634252\tAccuracy: 60.60%\n",
      "799\tValidation loss: 1.634912\tBest loss: 1.634252\tAccuracy: 60.60%\n",
      "800\tValidation loss: 1.639639\tBest loss: 1.634252\tAccuracy: 60.00%\n",
      "801\tValidation loss: 1.633485\tBest loss: 1.633485\tAccuracy: 60.40%\n",
      "802\tValidation loss: 1.636914\tBest loss: 1.633485\tAccuracy: 60.30%\n",
      "803\tValidation loss: 1.635161\tBest loss: 1.633485\tAccuracy: 60.30%\n",
      "804\tValidation loss: 1.631206\tBest loss: 1.631206\tAccuracy: 60.50%\n",
      "805\tValidation loss: 1.633070\tBest loss: 1.631206\tAccuracy: 60.30%\n",
      "806\tValidation loss: 1.631671\tBest loss: 1.631206\tAccuracy: 59.90%\n",
      "807\tValidation loss: 1.630494\tBest loss: 1.630494\tAccuracy: 60.40%\n",
      "808\tValidation loss: 1.631050\tBest loss: 1.630494\tAccuracy: 60.90%\n",
      "809\tValidation loss: 1.632512\tBest loss: 1.630494\tAccuracy: 60.00%\n",
      "810\tValidation loss: 1.631715\tBest loss: 1.630494\tAccuracy: 60.60%\n",
      "811\tValidation loss: 1.633388\tBest loss: 1.630494\tAccuracy: 60.10%\n",
      "812\tValidation loss: 1.631531\tBest loss: 1.630494\tAccuracy: 59.50%\n",
      "813\tValidation loss: 1.629713\tBest loss: 1.629713\tAccuracy: 59.90%\n",
      "814\tValidation loss: 1.630621\tBest loss: 1.629713\tAccuracy: 60.10%\n",
      "815\tValidation loss: 1.627235\tBest loss: 1.627235\tAccuracy: 59.70%\n",
      "816\tValidation loss: 1.630365\tBest loss: 1.627235\tAccuracy: 61.00%\n",
      "817\tValidation loss: 1.627459\tBest loss: 1.627235\tAccuracy: 60.70%\n",
      "818\tValidation loss: 1.625896\tBest loss: 1.625896\tAccuracy: 60.50%\n",
      "819\tValidation loss: 1.623632\tBest loss: 1.623632\tAccuracy: 61.10%\n",
      "820\tValidation loss: 1.627575\tBest loss: 1.623632\tAccuracy: 60.50%\n",
      "821\tValidation loss: 1.629331\tBest loss: 1.623632\tAccuracy: 60.50%\n",
      "822\tValidation loss: 1.626625\tBest loss: 1.623632\tAccuracy: 60.60%\n",
      "823\tValidation loss: 1.626644\tBest loss: 1.623632\tAccuracy: 60.10%\n",
      "824\tValidation loss: 1.625384\tBest loss: 1.623632\tAccuracy: 60.20%\n",
      "825\tValidation loss: 1.626788\tBest loss: 1.623632\tAccuracy: 60.20%\n",
      "826\tValidation loss: 1.626536\tBest loss: 1.623632\tAccuracy: 60.30%\n",
      "827\tValidation loss: 1.628478\tBest loss: 1.623632\tAccuracy: 60.70%\n",
      "828\tValidation loss: 1.625405\tBest loss: 1.623632\tAccuracy: 60.60%\n",
      "829\tValidation loss: 1.627869\tBest loss: 1.623632\tAccuracy: 61.20%\n",
      "830\tValidation loss: 1.626445\tBest loss: 1.623632\tAccuracy: 60.70%\n",
      "831\tValidation loss: 1.625951\tBest loss: 1.623632\tAccuracy: 61.30%\n",
      "832\tValidation loss: 1.627373\tBest loss: 1.623632\tAccuracy: 60.60%\n",
      "833\tValidation loss: 1.626868\tBest loss: 1.623632\tAccuracy: 60.50%\n",
      "834\tValidation loss: 1.624898\tBest loss: 1.623632\tAccuracy: 60.70%\n",
      "835\tValidation loss: 1.627387\tBest loss: 1.623632\tAccuracy: 60.60%\n",
      "836\tValidation loss: 1.626305\tBest loss: 1.623632\tAccuracy: 60.80%\n",
      "837\tValidation loss: 1.623954\tBest loss: 1.623632\tAccuracy: 60.10%\n",
      "838\tValidation loss: 1.626993\tBest loss: 1.623632\tAccuracy: 60.20%\n",
      "839\tValidation loss: 1.627492\tBest loss: 1.623632\tAccuracy: 60.50%\n",
      "840\tValidation loss: 1.625122\tBest loss: 1.623632\tAccuracy: 60.00%\n",
      "Early stopping!\n",
      "[[  1.33682365e-09   1.31465129e-06   1.10095499e-07 ...,   7.46227421e-14\n",
      "    5.34027987e-12   3.59626773e-11]\n",
      " [  4.99447286e-02   3.18240039e-02   4.88445610e-02 ...,   1.71004664e-02\n",
      "    7.90562574e-03   7.76721258e-03]\n",
      " [  4.03289732e-06   1.21764862e-10   2.63046149e-05 ...,   1.70680510e-14\n",
      "    6.68563241e-14   3.61720576e-16]\n",
      " ..., \n",
      " [  8.40444028e-22   3.94716956e-17   3.47865261e-16 ...,   9.19221817e-12\n",
      "    6.79748792e-13   3.69432078e-13]\n",
      " [  1.40387136e-02   3.36364508e-02   1.50048835e-02 ...,   7.27701932e-02\n",
      "    1.83710959e-02   1.20238271e-02]\n",
      " [  5.57222120e-06   2.19091580e-05   5.89477640e-05 ...,   1.31848827e-02\n",
      "    2.69497000e-03   1.41281169e-02]]\n",
      "[20  0 16 ...,  6 24  8]\n",
      "[[  3.33911430e-06   8.68082498e-06   2.18838989e-03 ...,   4.82670912e-05\n",
      "    5.64096670e-04   2.26537421e-04]\n",
      " [  2.34924052e-10   2.54888550e-06   4.09828793e-09 ...,   3.66503321e-15\n",
      "    5.74288924e-12   1.41361653e-11]\n",
      " [  9.04354965e-06   2.00324925e-04   7.40688847e-06 ...,   6.76420981e-08\n",
      "    3.79669245e-07   1.54565419e-06]\n",
      " ..., \n",
      " [  1.76887086e-03   1.69551838e-02   4.76715574e-03 ...,   2.58901255e-05\n",
      "    1.98562138e-05   3.97418262e-06]\n",
      " [  4.00924049e-02   2.32744012e-02   3.39919478e-02 ...,   2.34775282e-02\n",
      "    8.36861879e-03   9.96124744e-03]\n",
      " [  1.43318344e-08   7.91574593e-08   1.76973849e-08 ...,   1.17355352e-02\n",
      "    1.00945853e-01   6.28134310e-01]]\n",
      "[31 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 1.8min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.244755\tBest loss: 4.244755\tAccuracy: 3.20%\n",
      "1\tValidation loss: 3.956371\tBest loss: 3.956371\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.908364\tBest loss: 3.908364\tAccuracy: 4.30%\n",
      "3\tValidation loss: 3.875413\tBest loss: 3.875413\tAccuracy: 4.50%\n",
      "4\tValidation loss: 3.844614\tBest loss: 3.844614\tAccuracy: 5.00%\n",
      "5\tValidation loss: 3.819302\tBest loss: 3.819302\tAccuracy: 5.50%\n",
      "6\tValidation loss: 3.798953\tBest loss: 3.798953\tAccuracy: 5.40%\n",
      "7\tValidation loss: 3.782798\tBest loss: 3.782798\tAccuracy: 6.00%\n",
      "8\tValidation loss: 3.766639\tBest loss: 3.766639\tAccuracy: 5.50%\n",
      "9\tValidation loss: 3.753436\tBest loss: 3.753436\tAccuracy: 6.30%\n",
      "10\tValidation loss: 3.742739\tBest loss: 3.742739\tAccuracy: 7.00%\n",
      "11\tValidation loss: 3.733208\tBest loss: 3.733208\tAccuracy: 7.40%\n",
      "12\tValidation loss: 3.724503\tBest loss: 3.724503\tAccuracy: 7.90%\n",
      "13\tValidation loss: 3.717495\tBest loss: 3.717495\tAccuracy: 8.10%\n",
      "14\tValidation loss: 3.710504\tBest loss: 3.710504\tAccuracy: 8.50%\n",
      "15\tValidation loss: 3.704309\tBest loss: 3.704309\tAccuracy: 8.40%\n",
      "16\tValidation loss: 3.698686\tBest loss: 3.698686\tAccuracy: 8.60%\n",
      "17\tValidation loss: 3.694224\tBest loss: 3.694224\tAccuracy: 8.40%\n",
      "18\tValidation loss: 3.689572\tBest loss: 3.689572\tAccuracy: 8.60%\n",
      "19\tValidation loss: 3.685023\tBest loss: 3.685023\tAccuracy: 8.50%\n",
      "20\tValidation loss: 3.680350\tBest loss: 3.680350\tAccuracy: 8.80%\n",
      "21\tValidation loss: 3.675712\tBest loss: 3.675712\tAccuracy: 8.80%\n",
      "22\tValidation loss: 3.672139\tBest loss: 3.672139\tAccuracy: 8.30%\n",
      "23\tValidation loss: 3.667788\tBest loss: 3.667788\tAccuracy: 8.50%\n",
      "24\tValidation loss: 3.663612\tBest loss: 3.663612\tAccuracy: 9.10%\n",
      "25\tValidation loss: 3.659923\tBest loss: 3.659923\tAccuracy: 9.30%\n",
      "26\tValidation loss: 3.655120\tBest loss: 3.655120\tAccuracy: 9.10%\n",
      "27\tValidation loss: 3.649590\tBest loss: 3.649590\tAccuracy: 9.20%\n",
      "28\tValidation loss: 3.645713\tBest loss: 3.645713\tAccuracy: 9.30%\n",
      "29\tValidation loss: 3.640056\tBest loss: 3.640056\tAccuracy: 9.20%\n",
      "30\tValidation loss: 3.636231\tBest loss: 3.636231\tAccuracy: 9.10%\n",
      "31\tValidation loss: 3.630899\tBest loss: 3.630899\tAccuracy: 8.90%\n",
      "32\tValidation loss: 3.624145\tBest loss: 3.624145\tAccuracy: 9.00%\n",
      "33\tValidation loss: 3.616519\tBest loss: 3.616519\tAccuracy: 9.20%\n",
      "34\tValidation loss: 3.609766\tBest loss: 3.609766\tAccuracy: 9.10%\n",
      "35\tValidation loss: 3.605149\tBest loss: 3.605149\tAccuracy: 9.00%\n",
      "36\tValidation loss: 3.601682\tBest loss: 3.601682\tAccuracy: 9.50%\n",
      "37\tValidation loss: 3.597186\tBest loss: 3.597186\tAccuracy: 9.70%\n",
      "38\tValidation loss: 3.589938\tBest loss: 3.589938\tAccuracy: 9.40%\n",
      "39\tValidation loss: 3.583699\tBest loss: 3.583699\tAccuracy: 9.40%\n",
      "40\tValidation loss: 3.582065\tBest loss: 3.582065\tAccuracy: 9.10%\n",
      "41\tValidation loss: 3.578828\tBest loss: 3.578828\tAccuracy: 9.60%\n",
      "42\tValidation loss: 3.574076\tBest loss: 3.574076\tAccuracy: 9.80%\n",
      "43\tValidation loss: 3.570084\tBest loss: 3.570084\tAccuracy: 10.00%\n",
      "44\tValidation loss: 3.564741\tBest loss: 3.564741\tAccuracy: 9.60%\n",
      "45\tValidation loss: 3.558808\tBest loss: 3.558808\tAccuracy: 10.00%\n",
      "46\tValidation loss: 3.554214\tBest loss: 3.554214\tAccuracy: 10.60%\n",
      "47\tValidation loss: 3.548392\tBest loss: 3.548392\tAccuracy: 10.60%\n",
      "48\tValidation loss: 3.546469\tBest loss: 3.546469\tAccuracy: 10.60%\n",
      "49\tValidation loss: 3.542319\tBest loss: 3.542319\tAccuracy: 10.90%\n",
      "50\tValidation loss: 3.535360\tBest loss: 3.535360\tAccuracy: 10.80%\n",
      "51\tValidation loss: 3.528883\tBest loss: 3.528883\tAccuracy: 11.00%\n",
      "52\tValidation loss: 3.528157\tBest loss: 3.528157\tAccuracy: 10.90%\n",
      "53\tValidation loss: 3.525574\tBest loss: 3.525574\tAccuracy: 11.20%\n",
      "54\tValidation loss: 3.522288\tBest loss: 3.522288\tAccuracy: 11.20%\n",
      "55\tValidation loss: 3.509125\tBest loss: 3.509125\tAccuracy: 11.30%\n",
      "56\tValidation loss: 3.500576\tBest loss: 3.500576\tAccuracy: 11.70%\n",
      "57\tValidation loss: 3.496314\tBest loss: 3.496314\tAccuracy: 11.60%\n",
      "58\tValidation loss: 3.484691\tBest loss: 3.484691\tAccuracy: 11.90%\n",
      "59\tValidation loss: 3.476259\tBest loss: 3.476259\tAccuracy: 12.20%\n",
      "60\tValidation loss: 3.473692\tBest loss: 3.473692\tAccuracy: 11.90%\n",
      "61\tValidation loss: 3.464996\tBest loss: 3.464996\tAccuracy: 11.70%\n",
      "62\tValidation loss: 3.457920\tBest loss: 3.457920\tAccuracy: 12.40%\n",
      "63\tValidation loss: 3.453218\tBest loss: 3.453218\tAccuracy: 12.60%\n",
      "64\tValidation loss: 3.455102\tBest loss: 3.453218\tAccuracy: 12.20%\n",
      "65\tValidation loss: 3.446586\tBest loss: 3.446586\tAccuracy: 12.50%\n",
      "66\tValidation loss: 3.445833\tBest loss: 3.445833\tAccuracy: 12.60%\n",
      "67\tValidation loss: 3.435614\tBest loss: 3.435614\tAccuracy: 12.30%\n",
      "68\tValidation loss: 3.433159\tBest loss: 3.433159\tAccuracy: 12.20%\n",
      "69\tValidation loss: 3.423704\tBest loss: 3.423704\tAccuracy: 12.90%\n",
      "70\tValidation loss: 3.420733\tBest loss: 3.420733\tAccuracy: 13.20%\n",
      "71\tValidation loss: 3.412435\tBest loss: 3.412435\tAccuracy: 13.10%\n",
      "72\tValidation loss: 3.412374\tBest loss: 3.412374\tAccuracy: 13.00%\n",
      "73\tValidation loss: 3.408039\tBest loss: 3.408039\tAccuracy: 12.70%\n",
      "74\tValidation loss: 3.404016\tBest loss: 3.404016\tAccuracy: 12.90%\n",
      "75\tValidation loss: 3.399145\tBest loss: 3.399145\tAccuracy: 13.30%\n",
      "76\tValidation loss: 3.394923\tBest loss: 3.394923\tAccuracy: 13.10%\n",
      "77\tValidation loss: 3.387371\tBest loss: 3.387371\tAccuracy: 13.80%\n",
      "78\tValidation loss: 3.378967\tBest loss: 3.378967\tAccuracy: 14.30%\n",
      "79\tValidation loss: 3.379940\tBest loss: 3.378967\tAccuracy: 14.10%\n",
      "80\tValidation loss: 3.376380\tBest loss: 3.376380\tAccuracy: 14.20%\n",
      "81\tValidation loss: 3.367270\tBest loss: 3.367270\tAccuracy: 13.70%\n",
      "82\tValidation loss: 3.367865\tBest loss: 3.367270\tAccuracy: 14.20%\n",
      "83\tValidation loss: 3.364059\tBest loss: 3.364059\tAccuracy: 14.60%\n",
      "84\tValidation loss: 3.359462\tBest loss: 3.359462\tAccuracy: 14.90%\n",
      "85\tValidation loss: 3.351625\tBest loss: 3.351625\tAccuracy: 14.90%\n",
      "86\tValidation loss: 3.344657\tBest loss: 3.344657\tAccuracy: 14.60%\n",
      "87\tValidation loss: 3.341666\tBest loss: 3.341666\tAccuracy: 15.00%\n",
      "88\tValidation loss: 3.333216\tBest loss: 3.333216\tAccuracy: 14.60%\n",
      "89\tValidation loss: 3.330836\tBest loss: 3.330836\tAccuracy: 15.50%\n",
      "90\tValidation loss: 3.319905\tBest loss: 3.319905\tAccuracy: 15.50%\n",
      "91\tValidation loss: 3.317140\tBest loss: 3.317140\tAccuracy: 15.10%\n",
      "92\tValidation loss: 3.313000\tBest loss: 3.313000\tAccuracy: 16.00%\n",
      "93\tValidation loss: 3.307684\tBest loss: 3.307684\tAccuracy: 15.50%\n",
      "94\tValidation loss: 3.304871\tBest loss: 3.304871\tAccuracy: 16.00%\n",
      "95\tValidation loss: 3.301861\tBest loss: 3.301861\tAccuracy: 15.70%\n",
      "96\tValidation loss: 3.291592\tBest loss: 3.291592\tAccuracy: 16.20%\n",
      "97\tValidation loss: 3.287329\tBest loss: 3.287329\tAccuracy: 16.40%\n",
      "98\tValidation loss: 3.280305\tBest loss: 3.280305\tAccuracy: 16.40%\n",
      "99\tValidation loss: 3.277218\tBest loss: 3.277218\tAccuracy: 16.50%\n",
      "100\tValidation loss: 3.270204\tBest loss: 3.270204\tAccuracy: 16.80%\n",
      "101\tValidation loss: 3.258131\tBest loss: 3.258131\tAccuracy: 17.30%\n",
      "102\tValidation loss: 3.249715\tBest loss: 3.249715\tAccuracy: 17.60%\n",
      "103\tValidation loss: 3.241583\tBest loss: 3.241583\tAccuracy: 17.80%\n",
      "104\tValidation loss: 3.234796\tBest loss: 3.234796\tAccuracy: 18.00%\n",
      "105\tValidation loss: 3.232257\tBest loss: 3.232257\tAccuracy: 18.00%\n",
      "106\tValidation loss: 3.227432\tBest loss: 3.227432\tAccuracy: 18.30%\n",
      "107\tValidation loss: 3.215035\tBest loss: 3.215035\tAccuracy: 19.00%\n",
      "108\tValidation loss: 3.206425\tBest loss: 3.206425\tAccuracy: 18.50%\n",
      "109\tValidation loss: 3.200547\tBest loss: 3.200547\tAccuracy: 19.10%\n",
      "110\tValidation loss: 3.194033\tBest loss: 3.194033\tAccuracy: 19.10%\n",
      "111\tValidation loss: 3.186564\tBest loss: 3.186564\tAccuracy: 19.50%\n",
      "112\tValidation loss: 3.176321\tBest loss: 3.176321\tAccuracy: 19.80%\n",
      "113\tValidation loss: 3.162975\tBest loss: 3.162975\tAccuracy: 19.90%\n",
      "114\tValidation loss: 3.162790\tBest loss: 3.162790\tAccuracy: 20.40%\n",
      "115\tValidation loss: 3.148598\tBest loss: 3.148598\tAccuracy: 21.20%\n",
      "116\tValidation loss: 3.140936\tBest loss: 3.140936\tAccuracy: 20.70%\n",
      "117\tValidation loss: 3.131496\tBest loss: 3.131496\tAccuracy: 21.10%\n",
      "118\tValidation loss: 3.127413\tBest loss: 3.127413\tAccuracy: 21.40%\n",
      "119\tValidation loss: 3.110193\tBest loss: 3.110193\tAccuracy: 21.00%\n",
      "120\tValidation loss: 3.106922\tBest loss: 3.106922\tAccuracy: 21.70%\n",
      "121\tValidation loss: 3.086898\tBest loss: 3.086898\tAccuracy: 21.20%\n",
      "122\tValidation loss: 3.070304\tBest loss: 3.070304\tAccuracy: 21.70%\n",
      "123\tValidation loss: 3.066231\tBest loss: 3.066231\tAccuracy: 21.60%\n",
      "124\tValidation loss: 3.051654\tBest loss: 3.051654\tAccuracy: 22.50%\n",
      "125\tValidation loss: 3.038105\tBest loss: 3.038105\tAccuracy: 22.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 3.025072\tBest loss: 3.025072\tAccuracy: 22.30%\n",
      "127\tValidation loss: 3.016673\tBest loss: 3.016673\tAccuracy: 22.60%\n",
      "128\tValidation loss: 3.002005\tBest loss: 3.002005\tAccuracy: 22.50%\n",
      "129\tValidation loss: 2.980646\tBest loss: 2.980646\tAccuracy: 23.00%\n",
      "130\tValidation loss: 2.971162\tBest loss: 2.971162\tAccuracy: 23.10%\n",
      "131\tValidation loss: 2.956141\tBest loss: 2.956141\tAccuracy: 23.40%\n",
      "132\tValidation loss: 2.946162\tBest loss: 2.946162\tAccuracy: 24.00%\n",
      "133\tValidation loss: 2.937667\tBest loss: 2.937667\tAccuracy: 24.20%\n",
      "134\tValidation loss: 2.925231\tBest loss: 2.925231\tAccuracy: 24.10%\n",
      "135\tValidation loss: 2.903946\tBest loss: 2.903946\tAccuracy: 24.30%\n",
      "136\tValidation loss: 2.901637\tBest loss: 2.901637\tAccuracy: 24.90%\n",
      "137\tValidation loss: 2.885262\tBest loss: 2.885262\tAccuracy: 24.80%\n",
      "138\tValidation loss: 2.864775\tBest loss: 2.864775\tAccuracy: 25.80%\n",
      "139\tValidation loss: 2.853110\tBest loss: 2.853110\tAccuracy: 25.60%\n",
      "140\tValidation loss: 2.845959\tBest loss: 2.845959\tAccuracy: 25.70%\n",
      "141\tValidation loss: 2.835669\tBest loss: 2.835669\tAccuracy: 25.60%\n",
      "142\tValidation loss: 2.822272\tBest loss: 2.822272\tAccuracy: 26.00%\n",
      "143\tValidation loss: 2.807227\tBest loss: 2.807227\tAccuracy: 25.90%\n",
      "144\tValidation loss: 2.804082\tBest loss: 2.804082\tAccuracy: 26.30%\n",
      "145\tValidation loss: 2.790562\tBest loss: 2.790562\tAccuracy: 26.10%\n",
      "146\tValidation loss: 2.782487\tBest loss: 2.782487\tAccuracy: 26.50%\n",
      "147\tValidation loss: 2.776152\tBest loss: 2.776152\tAccuracy: 27.10%\n",
      "148\tValidation loss: 2.761926\tBest loss: 2.761926\tAccuracy: 26.70%\n",
      "149\tValidation loss: 2.751392\tBest loss: 2.751392\tAccuracy: 27.50%\n",
      "150\tValidation loss: 2.739465\tBest loss: 2.739465\tAccuracy: 27.00%\n",
      "151\tValidation loss: 2.730335\tBest loss: 2.730335\tAccuracy: 27.40%\n",
      "152\tValidation loss: 2.726713\tBest loss: 2.726713\tAccuracy: 27.40%\n",
      "153\tValidation loss: 2.716786\tBest loss: 2.716786\tAccuracy: 27.50%\n",
      "154\tValidation loss: 2.701822\tBest loss: 2.701822\tAccuracy: 27.40%\n",
      "155\tValidation loss: 2.691056\tBest loss: 2.691056\tAccuracy: 27.40%\n",
      "156\tValidation loss: 2.680398\tBest loss: 2.680398\tAccuracy: 27.70%\n",
      "157\tValidation loss: 2.678139\tBest loss: 2.678139\tAccuracy: 28.30%\n",
      "158\tValidation loss: 2.666141\tBest loss: 2.666141\tAccuracy: 28.60%\n",
      "159\tValidation loss: 2.655135\tBest loss: 2.655135\tAccuracy: 28.60%\n",
      "160\tValidation loss: 2.648995\tBest loss: 2.648995\tAccuracy: 30.30%\n",
      "161\tValidation loss: 2.637096\tBest loss: 2.637096\tAccuracy: 29.80%\n",
      "162\tValidation loss: 2.630726\tBest loss: 2.630726\tAccuracy: 29.60%\n",
      "163\tValidation loss: 2.622917\tBest loss: 2.622917\tAccuracy: 30.10%\n",
      "164\tValidation loss: 2.618945\tBest loss: 2.618945\tAccuracy: 31.50%\n",
      "165\tValidation loss: 2.608265\tBest loss: 2.608265\tAccuracy: 31.70%\n",
      "166\tValidation loss: 2.601719\tBest loss: 2.601719\tAccuracy: 31.90%\n",
      "167\tValidation loss: 2.600181\tBest loss: 2.600181\tAccuracy: 31.80%\n",
      "168\tValidation loss: 2.591487\tBest loss: 2.591487\tAccuracy: 32.60%\n",
      "169\tValidation loss: 2.581283\tBest loss: 2.581283\tAccuracy: 32.20%\n",
      "170\tValidation loss: 2.575417\tBest loss: 2.575417\tAccuracy: 32.80%\n",
      "171\tValidation loss: 2.561772\tBest loss: 2.561772\tAccuracy: 32.70%\n",
      "172\tValidation loss: 2.554718\tBest loss: 2.554718\tAccuracy: 33.00%\n",
      "173\tValidation loss: 2.555544\tBest loss: 2.554718\tAccuracy: 33.30%\n",
      "174\tValidation loss: 2.552425\tBest loss: 2.552425\tAccuracy: 33.10%\n",
      "175\tValidation loss: 2.539333\tBest loss: 2.539333\tAccuracy: 33.80%\n",
      "176\tValidation loss: 2.528396\tBest loss: 2.528396\tAccuracy: 34.20%\n",
      "177\tValidation loss: 2.533700\tBest loss: 2.528396\tAccuracy: 33.70%\n",
      "178\tValidation loss: 2.521934\tBest loss: 2.521934\tAccuracy: 34.30%\n",
      "179\tValidation loss: 2.513666\tBest loss: 2.513666\tAccuracy: 34.70%\n",
      "180\tValidation loss: 2.511391\tBest loss: 2.511391\tAccuracy: 34.70%\n",
      "181\tValidation loss: 2.506468\tBest loss: 2.506468\tAccuracy: 34.50%\n",
      "182\tValidation loss: 2.497660\tBest loss: 2.497660\tAccuracy: 34.80%\n",
      "183\tValidation loss: 2.488997\tBest loss: 2.488997\tAccuracy: 35.70%\n",
      "184\tValidation loss: 2.483473\tBest loss: 2.483473\tAccuracy: 36.10%\n",
      "185\tValidation loss: 2.484110\tBest loss: 2.483473\tAccuracy: 34.80%\n",
      "186\tValidation loss: 2.469594\tBest loss: 2.469594\tAccuracy: 36.70%\n",
      "187\tValidation loss: 2.461772\tBest loss: 2.461772\tAccuracy: 36.00%\n",
      "188\tValidation loss: 2.458985\tBest loss: 2.458985\tAccuracy: 36.10%\n",
      "189\tValidation loss: 2.457461\tBest loss: 2.457461\tAccuracy: 36.00%\n",
      "190\tValidation loss: 2.447384\tBest loss: 2.447384\tAccuracy: 36.30%\n",
      "191\tValidation loss: 2.443525\tBest loss: 2.443525\tAccuracy: 36.60%\n",
      "192\tValidation loss: 2.443671\tBest loss: 2.443525\tAccuracy: 35.90%\n",
      "193\tValidation loss: 2.435759\tBest loss: 2.435759\tAccuracy: 36.40%\n",
      "194\tValidation loss: 2.425968\tBest loss: 2.425968\tAccuracy: 37.20%\n",
      "195\tValidation loss: 2.419779\tBest loss: 2.419779\tAccuracy: 37.60%\n",
      "196\tValidation loss: 2.415815\tBest loss: 2.415815\tAccuracy: 37.40%\n",
      "197\tValidation loss: 2.403691\tBest loss: 2.403691\tAccuracy: 37.60%\n",
      "198\tValidation loss: 2.407497\tBest loss: 2.403691\tAccuracy: 37.60%\n",
      "199\tValidation loss: 2.400585\tBest loss: 2.400585\tAccuracy: 38.10%\n",
      "200\tValidation loss: 2.394833\tBest loss: 2.394833\tAccuracy: 37.90%\n",
      "201\tValidation loss: 2.397103\tBest loss: 2.394833\tAccuracy: 37.70%\n",
      "202\tValidation loss: 2.397447\tBest loss: 2.394833\tAccuracy: 38.50%\n",
      "203\tValidation loss: 2.381714\tBest loss: 2.381714\tAccuracy: 39.00%\n",
      "204\tValidation loss: 2.380919\tBest loss: 2.380919\tAccuracy: 38.30%\n",
      "205\tValidation loss: 2.379124\tBest loss: 2.379124\tAccuracy: 38.70%\n",
      "206\tValidation loss: 2.379747\tBest loss: 2.379124\tAccuracy: 38.90%\n",
      "207\tValidation loss: 2.367049\tBest loss: 2.367049\tAccuracy: 39.40%\n",
      "208\tValidation loss: 2.363631\tBest loss: 2.363631\tAccuracy: 39.30%\n",
      "209\tValidation loss: 2.353602\tBest loss: 2.353602\tAccuracy: 40.10%\n",
      "210\tValidation loss: 2.357098\tBest loss: 2.353602\tAccuracy: 40.00%\n",
      "211\tValidation loss: 2.346370\tBest loss: 2.346370\tAccuracy: 39.40%\n",
      "212\tValidation loss: 2.349252\tBest loss: 2.346370\tAccuracy: 40.10%\n",
      "213\tValidation loss: 2.340649\tBest loss: 2.340649\tAccuracy: 40.10%\n",
      "214\tValidation loss: 2.332806\tBest loss: 2.332806\tAccuracy: 40.70%\n",
      "215\tValidation loss: 2.330012\tBest loss: 2.330012\tAccuracy: 40.00%\n",
      "216\tValidation loss: 2.322575\tBest loss: 2.322575\tAccuracy: 39.90%\n",
      "217\tValidation loss: 2.318820\tBest loss: 2.318820\tAccuracy: 41.20%\n",
      "218\tValidation loss: 2.316014\tBest loss: 2.316014\tAccuracy: 41.00%\n",
      "219\tValidation loss: 2.315400\tBest loss: 2.315400\tAccuracy: 40.80%\n",
      "220\tValidation loss: 2.314269\tBest loss: 2.314269\tAccuracy: 41.50%\n",
      "221\tValidation loss: 2.305905\tBest loss: 2.305905\tAccuracy: 41.60%\n",
      "222\tValidation loss: 2.305432\tBest loss: 2.305432\tAccuracy: 41.40%\n",
      "223\tValidation loss: 2.298568\tBest loss: 2.298568\tAccuracy: 41.50%\n",
      "224\tValidation loss: 2.289967\tBest loss: 2.289967\tAccuracy: 41.80%\n",
      "225\tValidation loss: 2.285180\tBest loss: 2.285180\tAccuracy: 41.50%\n",
      "226\tValidation loss: 2.281464\tBest loss: 2.281464\tAccuracy: 41.60%\n",
      "227\tValidation loss: 2.277678\tBest loss: 2.277678\tAccuracy: 41.60%\n",
      "228\tValidation loss: 2.272564\tBest loss: 2.272564\tAccuracy: 41.80%\n",
      "229\tValidation loss: 2.269563\tBest loss: 2.269563\tAccuracy: 41.80%\n",
      "230\tValidation loss: 2.266406\tBest loss: 2.266406\tAccuracy: 41.90%\n",
      "231\tValidation loss: 2.261850\tBest loss: 2.261850\tAccuracy: 42.20%\n",
      "232\tValidation loss: 2.264924\tBest loss: 2.261850\tAccuracy: 41.50%\n",
      "233\tValidation loss: 2.255154\tBest loss: 2.255154\tAccuracy: 41.80%\n",
      "234\tValidation loss: 2.251338\tBest loss: 2.251338\tAccuracy: 42.30%\n",
      "235\tValidation loss: 2.253447\tBest loss: 2.251338\tAccuracy: 42.20%\n",
      "236\tValidation loss: 2.252525\tBest loss: 2.251338\tAccuracy: 41.70%\n",
      "237\tValidation loss: 2.247702\tBest loss: 2.247702\tAccuracy: 41.80%\n",
      "238\tValidation loss: 2.239544\tBest loss: 2.239544\tAccuracy: 43.40%\n",
      "239\tValidation loss: 2.238964\tBest loss: 2.238964\tAccuracy: 42.70%\n",
      "240\tValidation loss: 2.239537\tBest loss: 2.238964\tAccuracy: 42.50%\n",
      "241\tValidation loss: 2.229746\tBest loss: 2.229746\tAccuracy: 42.80%\n",
      "242\tValidation loss: 2.224757\tBest loss: 2.224757\tAccuracy: 43.40%\n",
      "243\tValidation loss: 2.215614\tBest loss: 2.215614\tAccuracy: 44.30%\n",
      "244\tValidation loss: 2.212842\tBest loss: 2.212842\tAccuracy: 42.90%\n",
      "245\tValidation loss: 2.212759\tBest loss: 2.212759\tAccuracy: 43.20%\n",
      "246\tValidation loss: 2.208749\tBest loss: 2.208749\tAccuracy: 43.60%\n",
      "247\tValidation loss: 2.212450\tBest loss: 2.208749\tAccuracy: 43.40%\n",
      "248\tValidation loss: 2.207443\tBest loss: 2.207443\tAccuracy: 43.60%\n",
      "249\tValidation loss: 2.200995\tBest loss: 2.200995\tAccuracy: 43.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 2.195362\tBest loss: 2.195362\tAccuracy: 44.10%\n",
      "251\tValidation loss: 2.186534\tBest loss: 2.186534\tAccuracy: 44.30%\n",
      "252\tValidation loss: 2.194157\tBest loss: 2.186534\tAccuracy: 44.10%\n",
      "253\tValidation loss: 2.192789\tBest loss: 2.186534\tAccuracy: 44.40%\n",
      "254\tValidation loss: 2.187401\tBest loss: 2.186534\tAccuracy: 44.90%\n",
      "255\tValidation loss: 2.186339\tBest loss: 2.186339\tAccuracy: 44.90%\n",
      "256\tValidation loss: 2.186546\tBest loss: 2.186339\tAccuracy: 45.80%\n",
      "257\tValidation loss: 2.186982\tBest loss: 2.186339\tAccuracy: 44.90%\n",
      "258\tValidation loss: 2.177547\tBest loss: 2.177547\tAccuracy: 44.90%\n",
      "259\tValidation loss: 2.172744\tBest loss: 2.172744\tAccuracy: 44.90%\n",
      "260\tValidation loss: 2.168854\tBest loss: 2.168854\tAccuracy: 45.30%\n",
      "261\tValidation loss: 2.167647\tBest loss: 2.167647\tAccuracy: 44.60%\n",
      "262\tValidation loss: 2.165789\tBest loss: 2.165789\tAccuracy: 44.70%\n",
      "263\tValidation loss: 2.164349\tBest loss: 2.164349\tAccuracy: 44.50%\n",
      "264\tValidation loss: 2.163902\tBest loss: 2.163902\tAccuracy: 45.20%\n",
      "265\tValidation loss: 2.155060\tBest loss: 2.155060\tAccuracy: 45.40%\n",
      "266\tValidation loss: 2.147483\tBest loss: 2.147483\tAccuracy: 46.30%\n",
      "267\tValidation loss: 2.150709\tBest loss: 2.147483\tAccuracy: 45.90%\n",
      "268\tValidation loss: 2.151327\tBest loss: 2.147483\tAccuracy: 45.60%\n",
      "269\tValidation loss: 2.149084\tBest loss: 2.147483\tAccuracy: 45.70%\n",
      "270\tValidation loss: 2.142974\tBest loss: 2.142974\tAccuracy: 45.70%\n",
      "271\tValidation loss: 2.140659\tBest loss: 2.140659\tAccuracy: 46.60%\n",
      "272\tValidation loss: 2.138253\tBest loss: 2.138253\tAccuracy: 46.40%\n",
      "273\tValidation loss: 2.137268\tBest loss: 2.137268\tAccuracy: 45.80%\n",
      "274\tValidation loss: 2.134951\tBest loss: 2.134951\tAccuracy: 46.20%\n",
      "275\tValidation loss: 2.131840\tBest loss: 2.131840\tAccuracy: 46.30%\n",
      "276\tValidation loss: 2.126817\tBest loss: 2.126817\tAccuracy: 46.80%\n",
      "277\tValidation loss: 2.122982\tBest loss: 2.122982\tAccuracy: 46.40%\n",
      "278\tValidation loss: 2.122583\tBest loss: 2.122583\tAccuracy: 46.30%\n",
      "279\tValidation loss: 2.120509\tBest loss: 2.120509\tAccuracy: 46.60%\n",
      "280\tValidation loss: 2.115072\tBest loss: 2.115072\tAccuracy: 46.60%\n",
      "281\tValidation loss: 2.116809\tBest loss: 2.115072\tAccuracy: 46.60%\n",
      "282\tValidation loss: 2.108746\tBest loss: 2.108746\tAccuracy: 47.50%\n",
      "283\tValidation loss: 2.107063\tBest loss: 2.107063\tAccuracy: 47.20%\n",
      "284\tValidation loss: 2.101651\tBest loss: 2.101651\tAccuracy: 47.90%\n",
      "285\tValidation loss: 2.102381\tBest loss: 2.101651\tAccuracy: 47.60%\n",
      "286\tValidation loss: 2.101060\tBest loss: 2.101060\tAccuracy: 47.90%\n",
      "287\tValidation loss: 2.102195\tBest loss: 2.101060\tAccuracy: 47.10%\n",
      "288\tValidation loss: 2.100582\tBest loss: 2.100582\tAccuracy: 47.40%\n",
      "289\tValidation loss: 2.100533\tBest loss: 2.100533\tAccuracy: 47.20%\n",
      "290\tValidation loss: 2.095946\tBest loss: 2.095946\tAccuracy: 47.10%\n",
      "291\tValidation loss: 2.094764\tBest loss: 2.094764\tAccuracy: 47.00%\n",
      "292\tValidation loss: 2.091169\tBest loss: 2.091169\tAccuracy: 47.80%\n",
      "293\tValidation loss: 2.088377\tBest loss: 2.088377\tAccuracy: 47.40%\n",
      "294\tValidation loss: 2.082713\tBest loss: 2.082713\tAccuracy: 47.40%\n",
      "295\tValidation loss: 2.090962\tBest loss: 2.082713\tAccuracy: 46.50%\n",
      "296\tValidation loss: 2.085162\tBest loss: 2.082713\tAccuracy: 47.40%\n",
      "297\tValidation loss: 2.084807\tBest loss: 2.082713\tAccuracy: 47.40%\n",
      "298\tValidation loss: 2.084087\tBest loss: 2.082713\tAccuracy: 47.30%\n",
      "299\tValidation loss: 2.082152\tBest loss: 2.082152\tAccuracy: 47.50%\n",
      "300\tValidation loss: 2.076407\tBest loss: 2.076407\tAccuracy: 47.40%\n",
      "301\tValidation loss: 2.074960\tBest loss: 2.074960\tAccuracy: 47.30%\n",
      "302\tValidation loss: 2.072325\tBest loss: 2.072325\tAccuracy: 47.30%\n",
      "303\tValidation loss: 2.069271\tBest loss: 2.069271\tAccuracy: 48.50%\n",
      "304\tValidation loss: 2.069368\tBest loss: 2.069271\tAccuracy: 47.70%\n",
      "305\tValidation loss: 2.066827\tBest loss: 2.066827\tAccuracy: 47.90%\n",
      "306\tValidation loss: 2.065972\tBest loss: 2.065972\tAccuracy: 48.10%\n",
      "307\tValidation loss: 2.069185\tBest loss: 2.065972\tAccuracy: 47.40%\n",
      "308\tValidation loss: 2.068263\tBest loss: 2.065972\tAccuracy: 48.00%\n",
      "309\tValidation loss: 2.067269\tBest loss: 2.065972\tAccuracy: 48.20%\n",
      "310\tValidation loss: 2.067277\tBest loss: 2.065972\tAccuracy: 47.60%\n",
      "311\tValidation loss: 2.067796\tBest loss: 2.065972\tAccuracy: 47.20%\n",
      "312\tValidation loss: 2.062810\tBest loss: 2.062810\tAccuracy: 48.30%\n",
      "313\tValidation loss: 2.058527\tBest loss: 2.058527\tAccuracy: 48.60%\n",
      "314\tValidation loss: 2.057411\tBest loss: 2.057411\tAccuracy: 48.40%\n",
      "315\tValidation loss: 2.057400\tBest loss: 2.057400\tAccuracy: 48.00%\n",
      "316\tValidation loss: 2.056789\tBest loss: 2.056789\tAccuracy: 48.30%\n",
      "317\tValidation loss: 2.050236\tBest loss: 2.050236\tAccuracy: 47.90%\n",
      "318\tValidation loss: 2.045726\tBest loss: 2.045726\tAccuracy: 48.70%\n",
      "319\tValidation loss: 2.047950\tBest loss: 2.045726\tAccuracy: 48.80%\n",
      "320\tValidation loss: 2.047255\tBest loss: 2.045726\tAccuracy: 48.60%\n",
      "321\tValidation loss: 2.042128\tBest loss: 2.042128\tAccuracy: 47.90%\n",
      "322\tValidation loss: 2.042519\tBest loss: 2.042128\tAccuracy: 48.30%\n",
      "323\tValidation loss: 2.042206\tBest loss: 2.042128\tAccuracy: 48.10%\n",
      "324\tValidation loss: 2.036713\tBest loss: 2.036713\tAccuracy: 48.00%\n",
      "325\tValidation loss: 2.035571\tBest loss: 2.035571\tAccuracy: 49.40%\n",
      "326\tValidation loss: 2.029148\tBest loss: 2.029148\tAccuracy: 48.70%\n",
      "327\tValidation loss: 2.035307\tBest loss: 2.029148\tAccuracy: 48.70%\n",
      "328\tValidation loss: 2.033304\tBest loss: 2.029148\tAccuracy: 48.80%\n",
      "329\tValidation loss: 2.038250\tBest loss: 2.029148\tAccuracy: 48.90%\n",
      "330\tValidation loss: 2.030825\tBest loss: 2.029148\tAccuracy: 48.90%\n",
      "331\tValidation loss: 2.026328\tBest loss: 2.026328\tAccuracy: 49.60%\n",
      "332\tValidation loss: 2.024179\tBest loss: 2.024179\tAccuracy: 49.20%\n",
      "333\tValidation loss: 2.023242\tBest loss: 2.023242\tAccuracy: 49.10%\n",
      "334\tValidation loss: 2.023392\tBest loss: 2.023242\tAccuracy: 48.60%\n",
      "335\tValidation loss: 2.024510\tBest loss: 2.023242\tAccuracy: 49.60%\n",
      "336\tValidation loss: 2.017422\tBest loss: 2.017422\tAccuracy: 49.50%\n",
      "337\tValidation loss: 2.020499\tBest loss: 2.017422\tAccuracy: 49.50%\n",
      "338\tValidation loss: 2.019454\tBest loss: 2.017422\tAccuracy: 49.20%\n",
      "339\tValidation loss: 2.015459\tBest loss: 2.015459\tAccuracy: 50.20%\n",
      "340\tValidation loss: 2.019016\tBest loss: 2.015459\tAccuracy: 49.40%\n",
      "341\tValidation loss: 2.012577\tBest loss: 2.012577\tAccuracy: 48.90%\n",
      "342\tValidation loss: 2.012227\tBest loss: 2.012227\tAccuracy: 49.20%\n",
      "343\tValidation loss: 2.018132\tBest loss: 2.012227\tAccuracy: 49.20%\n",
      "344\tValidation loss: 2.016099\tBest loss: 2.012227\tAccuracy: 49.40%\n",
      "345\tValidation loss: 2.010435\tBest loss: 2.010435\tAccuracy: 49.10%\n",
      "346\tValidation loss: 2.011014\tBest loss: 2.010435\tAccuracy: 49.30%\n",
      "347\tValidation loss: 2.008914\tBest loss: 2.008914\tAccuracy: 49.70%\n",
      "348\tValidation loss: 2.007500\tBest loss: 2.007500\tAccuracy: 49.10%\n",
      "349\tValidation loss: 1.999833\tBest loss: 1.999833\tAccuracy: 49.80%\n",
      "350\tValidation loss: 1.997837\tBest loss: 1.997837\tAccuracy: 49.10%\n",
      "351\tValidation loss: 2.002347\tBest loss: 1.997837\tAccuracy: 49.00%\n",
      "352\tValidation loss: 1.998575\tBest loss: 1.997837\tAccuracy: 50.20%\n",
      "353\tValidation loss: 1.997901\tBest loss: 1.997837\tAccuracy: 49.40%\n",
      "354\tValidation loss: 2.004264\tBest loss: 1.997837\tAccuracy: 49.60%\n",
      "355\tValidation loss: 1.998827\tBest loss: 1.997837\tAccuracy: 50.10%\n",
      "356\tValidation loss: 1.998258\tBest loss: 1.997837\tAccuracy: 49.80%\n",
      "357\tValidation loss: 1.991895\tBest loss: 1.991895\tAccuracy: 50.50%\n",
      "358\tValidation loss: 1.993024\tBest loss: 1.991895\tAccuracy: 50.00%\n",
      "359\tValidation loss: 1.993511\tBest loss: 1.991895\tAccuracy: 49.40%\n",
      "360\tValidation loss: 1.994205\tBest loss: 1.991895\tAccuracy: 49.40%\n",
      "361\tValidation loss: 1.988728\tBest loss: 1.988728\tAccuracy: 49.40%\n",
      "362\tValidation loss: 1.990469\tBest loss: 1.988728\tAccuracy: 50.20%\n",
      "363\tValidation loss: 1.987703\tBest loss: 1.987703\tAccuracy: 49.70%\n",
      "364\tValidation loss: 1.985467\tBest loss: 1.985467\tAccuracy: 50.50%\n",
      "365\tValidation loss: 1.979634\tBest loss: 1.979634\tAccuracy: 50.20%\n",
      "366\tValidation loss: 1.980535\tBest loss: 1.979634\tAccuracy: 50.30%\n",
      "367\tValidation loss: 1.975928\tBest loss: 1.975928\tAccuracy: 49.80%\n",
      "368\tValidation loss: 1.980683\tBest loss: 1.975928\tAccuracy: 50.20%\n",
      "369\tValidation loss: 1.977054\tBest loss: 1.975928\tAccuracy: 49.60%\n",
      "370\tValidation loss: 1.973528\tBest loss: 1.973528\tAccuracy: 49.40%\n",
      "371\tValidation loss: 1.973253\tBest loss: 1.973253\tAccuracy: 50.60%\n",
      "372\tValidation loss: 1.972910\tBest loss: 1.972910\tAccuracy: 50.50%\n",
      "373\tValidation loss: 1.972032\tBest loss: 1.972032\tAccuracy: 51.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\tValidation loss: 1.969524\tBest loss: 1.969524\tAccuracy: 50.70%\n",
      "375\tValidation loss: 1.963350\tBest loss: 1.963350\tAccuracy: 50.60%\n",
      "376\tValidation loss: 1.966976\tBest loss: 1.963350\tAccuracy: 50.40%\n",
      "377\tValidation loss: 1.961028\tBest loss: 1.961028\tAccuracy: 50.80%\n",
      "378\tValidation loss: 1.964555\tBest loss: 1.961028\tAccuracy: 50.80%\n",
      "379\tValidation loss: 1.958188\tBest loss: 1.958188\tAccuracy: 50.30%\n",
      "380\tValidation loss: 1.959146\tBest loss: 1.958188\tAccuracy: 50.60%\n",
      "381\tValidation loss: 1.958491\tBest loss: 1.958188\tAccuracy: 50.70%\n",
      "382\tValidation loss: 1.960322\tBest loss: 1.958188\tAccuracy: 49.20%\n",
      "383\tValidation loss: 1.958856\tBest loss: 1.958188\tAccuracy: 50.40%\n",
      "384\tValidation loss: 1.957073\tBest loss: 1.957073\tAccuracy: 50.20%\n",
      "385\tValidation loss: 1.959539\tBest loss: 1.957073\tAccuracy: 50.20%\n",
      "386\tValidation loss: 1.956794\tBest loss: 1.956794\tAccuracy: 50.80%\n",
      "387\tValidation loss: 1.954981\tBest loss: 1.954981\tAccuracy: 50.60%\n",
      "388\tValidation loss: 1.952465\tBest loss: 1.952465\tAccuracy: 51.20%\n",
      "389\tValidation loss: 1.951985\tBest loss: 1.951985\tAccuracy: 50.70%\n",
      "390\tValidation loss: 1.948360\tBest loss: 1.948360\tAccuracy: 51.10%\n",
      "391\tValidation loss: 1.949620\tBest loss: 1.948360\tAccuracy: 51.60%\n",
      "392\tValidation loss: 1.947257\tBest loss: 1.947257\tAccuracy: 51.40%\n",
      "393\tValidation loss: 1.947272\tBest loss: 1.947257\tAccuracy: 51.40%\n",
      "394\tValidation loss: 1.943068\tBest loss: 1.943068\tAccuracy: 51.60%\n",
      "395\tValidation loss: 1.939107\tBest loss: 1.939107\tAccuracy: 51.90%\n",
      "396\tValidation loss: 1.940577\tBest loss: 1.939107\tAccuracy: 51.80%\n",
      "397\tValidation loss: 1.940351\tBest loss: 1.939107\tAccuracy: 51.40%\n",
      "398\tValidation loss: 1.941430\tBest loss: 1.939107\tAccuracy: 51.60%\n",
      "399\tValidation loss: 1.940555\tBest loss: 1.939107\tAccuracy: 52.20%\n",
      "400\tValidation loss: 1.936731\tBest loss: 1.936731\tAccuracy: 51.40%\n",
      "401\tValidation loss: 1.932284\tBest loss: 1.932284\tAccuracy: 51.70%\n",
      "402\tValidation loss: 1.934192\tBest loss: 1.932284\tAccuracy: 51.40%\n",
      "403\tValidation loss: 1.933105\tBest loss: 1.932284\tAccuracy: 52.20%\n",
      "404\tValidation loss: 1.935861\tBest loss: 1.932284\tAccuracy: 52.20%\n",
      "405\tValidation loss: 1.931094\tBest loss: 1.931094\tAccuracy: 51.90%\n",
      "406\tValidation loss: 1.928151\tBest loss: 1.928151\tAccuracy: 51.80%\n",
      "407\tValidation loss: 1.926642\tBest loss: 1.926642\tAccuracy: 51.80%\n",
      "408\tValidation loss: 1.926363\tBest loss: 1.926363\tAccuracy: 52.00%\n",
      "409\tValidation loss: 1.929611\tBest loss: 1.926363\tAccuracy: 51.70%\n",
      "410\tValidation loss: 1.928598\tBest loss: 1.926363\tAccuracy: 51.20%\n",
      "411\tValidation loss: 1.928720\tBest loss: 1.926363\tAccuracy: 52.10%\n",
      "412\tValidation loss: 1.927831\tBest loss: 1.926363\tAccuracy: 52.00%\n",
      "413\tValidation loss: 1.924563\tBest loss: 1.924563\tAccuracy: 52.20%\n",
      "414\tValidation loss: 1.926255\tBest loss: 1.924563\tAccuracy: 52.00%\n",
      "415\tValidation loss: 1.924997\tBest loss: 1.924563\tAccuracy: 52.00%\n",
      "416\tValidation loss: 1.918302\tBest loss: 1.918302\tAccuracy: 52.60%\n",
      "417\tValidation loss: 1.918999\tBest loss: 1.918302\tAccuracy: 53.10%\n",
      "418\tValidation loss: 1.915761\tBest loss: 1.915761\tAccuracy: 52.70%\n",
      "419\tValidation loss: 1.918493\tBest loss: 1.915761\tAccuracy: 52.70%\n",
      "420\tValidation loss: 1.916785\tBest loss: 1.915761\tAccuracy: 52.40%\n",
      "421\tValidation loss: 1.918901\tBest loss: 1.915761\tAccuracy: 52.80%\n",
      "422\tValidation loss: 1.915529\tBest loss: 1.915529\tAccuracy: 52.70%\n",
      "423\tValidation loss: 1.916520\tBest loss: 1.915529\tAccuracy: 52.10%\n",
      "424\tValidation loss: 1.912219\tBest loss: 1.912219\tAccuracy: 52.10%\n",
      "425\tValidation loss: 1.912173\tBest loss: 1.912173\tAccuracy: 52.30%\n",
      "426\tValidation loss: 1.913114\tBest loss: 1.912173\tAccuracy: 52.20%\n",
      "427\tValidation loss: 1.907136\tBest loss: 1.907136\tAccuracy: 52.30%\n",
      "428\tValidation loss: 1.910334\tBest loss: 1.907136\tAccuracy: 53.10%\n",
      "429\tValidation loss: 1.910061\tBest loss: 1.907136\tAccuracy: 52.80%\n",
      "430\tValidation loss: 1.904470\tBest loss: 1.904470\tAccuracy: 52.90%\n",
      "431\tValidation loss: 1.908629\tBest loss: 1.904470\tAccuracy: 53.10%\n",
      "432\tValidation loss: 1.910383\tBest loss: 1.904470\tAccuracy: 52.70%\n",
      "433\tValidation loss: 1.904400\tBest loss: 1.904400\tAccuracy: 52.90%\n",
      "434\tValidation loss: 1.903306\tBest loss: 1.903306\tAccuracy: 53.00%\n",
      "435\tValidation loss: 1.898504\tBest loss: 1.898504\tAccuracy: 53.60%\n",
      "436\tValidation loss: 1.896642\tBest loss: 1.896642\tAccuracy: 53.90%\n",
      "437\tValidation loss: 1.898948\tBest loss: 1.896642\tAccuracy: 53.20%\n",
      "438\tValidation loss: 1.900680\tBest loss: 1.896642\tAccuracy: 53.40%\n",
      "439\tValidation loss: 1.895889\tBest loss: 1.895889\tAccuracy: 53.40%\n",
      "440\tValidation loss: 1.898169\tBest loss: 1.895889\tAccuracy: 53.30%\n",
      "441\tValidation loss: 1.895957\tBest loss: 1.895889\tAccuracy: 53.10%\n",
      "442\tValidation loss: 1.902905\tBest loss: 1.895889\tAccuracy: 53.20%\n",
      "443\tValidation loss: 1.896294\tBest loss: 1.895889\tAccuracy: 53.60%\n",
      "444\tValidation loss: 1.894958\tBest loss: 1.894958\tAccuracy: 53.40%\n",
      "445\tValidation loss: 1.896459\tBest loss: 1.894958\tAccuracy: 53.60%\n",
      "446\tValidation loss: 1.898526\tBest loss: 1.894958\tAccuracy: 53.20%\n",
      "447\tValidation loss: 1.892694\tBest loss: 1.892694\tAccuracy: 53.10%\n",
      "448\tValidation loss: 1.896683\tBest loss: 1.892694\tAccuracy: 53.40%\n",
      "449\tValidation loss: 1.893423\tBest loss: 1.892694\tAccuracy: 53.00%\n",
      "450\tValidation loss: 1.890745\tBest loss: 1.890745\tAccuracy: 53.60%\n",
      "451\tValidation loss: 1.894144\tBest loss: 1.890745\tAccuracy: 53.50%\n",
      "452\tValidation loss: 1.894578\tBest loss: 1.890745\tAccuracy: 53.50%\n",
      "453\tValidation loss: 1.895703\tBest loss: 1.890745\tAccuracy: 52.80%\n",
      "454\tValidation loss: 1.890833\tBest loss: 1.890745\tAccuracy: 53.30%\n",
      "455\tValidation loss: 1.895038\tBest loss: 1.890745\tAccuracy: 53.10%\n",
      "456\tValidation loss: 1.893609\tBest loss: 1.890745\tAccuracy: 53.20%\n",
      "457\tValidation loss: 1.885844\tBest loss: 1.885844\tAccuracy: 53.80%\n",
      "458\tValidation loss: 1.884675\tBest loss: 1.884675\tAccuracy: 53.40%\n",
      "459\tValidation loss: 1.884099\tBest loss: 1.884099\tAccuracy: 53.70%\n",
      "460\tValidation loss: 1.887844\tBest loss: 1.884099\tAccuracy: 52.90%\n",
      "461\tValidation loss: 1.883215\tBest loss: 1.883215\tAccuracy: 53.40%\n",
      "462\tValidation loss: 1.883971\tBest loss: 1.883215\tAccuracy: 52.90%\n",
      "463\tValidation loss: 1.882044\tBest loss: 1.882044\tAccuracy: 53.10%\n",
      "464\tValidation loss: 1.883550\tBest loss: 1.882044\tAccuracy: 53.30%\n",
      "465\tValidation loss: 1.878616\tBest loss: 1.878616\tAccuracy: 53.60%\n",
      "466\tValidation loss: 1.883059\tBest loss: 1.878616\tAccuracy: 52.50%\n",
      "467\tValidation loss: 1.882056\tBest loss: 1.878616\tAccuracy: 53.80%\n",
      "468\tValidation loss: 1.879759\tBest loss: 1.878616\tAccuracy: 53.30%\n",
      "469\tValidation loss: 1.881608\tBest loss: 1.878616\tAccuracy: 53.10%\n",
      "470\tValidation loss: 1.875484\tBest loss: 1.875484\tAccuracy: 53.10%\n",
      "471\tValidation loss: 1.878257\tBest loss: 1.875484\tAccuracy: 54.00%\n",
      "472\tValidation loss: 1.877642\tBest loss: 1.875484\tAccuracy: 53.60%\n",
      "473\tValidation loss: 1.877960\tBest loss: 1.875484\tAccuracy: 54.50%\n",
      "474\tValidation loss: 1.877728\tBest loss: 1.875484\tAccuracy: 54.00%\n",
      "475\tValidation loss: 1.877621\tBest loss: 1.875484\tAccuracy: 53.10%\n",
      "476\tValidation loss: 1.876618\tBest loss: 1.875484\tAccuracy: 54.10%\n",
      "477\tValidation loss: 1.879929\tBest loss: 1.875484\tAccuracy: 53.10%\n",
      "478\tValidation loss: 1.873535\tBest loss: 1.873535\tAccuracy: 53.10%\n",
      "479\tValidation loss: 1.870695\tBest loss: 1.870695\tAccuracy: 53.30%\n",
      "480\tValidation loss: 1.872490\tBest loss: 1.870695\tAccuracy: 53.60%\n",
      "481\tValidation loss: 1.869517\tBest loss: 1.869517\tAccuracy: 53.20%\n",
      "482\tValidation loss: 1.869923\tBest loss: 1.869517\tAccuracy: 53.00%\n",
      "483\tValidation loss: 1.869935\tBest loss: 1.869517\tAccuracy: 54.00%\n",
      "484\tValidation loss: 1.866304\tBest loss: 1.866304\tAccuracy: 53.80%\n",
      "485\tValidation loss: 1.866820\tBest loss: 1.866304\tAccuracy: 54.00%\n",
      "486\tValidation loss: 1.863650\tBest loss: 1.863650\tAccuracy: 54.30%\n",
      "487\tValidation loss: 1.871190\tBest loss: 1.863650\tAccuracy: 54.20%\n",
      "488\tValidation loss: 1.870955\tBest loss: 1.863650\tAccuracy: 54.00%\n",
      "489\tValidation loss: 1.867291\tBest loss: 1.863650\tAccuracy: 54.20%\n",
      "490\tValidation loss: 1.866144\tBest loss: 1.863650\tAccuracy: 54.20%\n",
      "491\tValidation loss: 1.867635\tBest loss: 1.863650\tAccuracy: 54.10%\n",
      "492\tValidation loss: 1.864368\tBest loss: 1.863650\tAccuracy: 54.20%\n",
      "493\tValidation loss: 1.868545\tBest loss: 1.863650\tAccuracy: 54.20%\n",
      "494\tValidation loss: 1.860284\tBest loss: 1.860284\tAccuracy: 54.20%\n",
      "495\tValidation loss: 1.862891\tBest loss: 1.860284\tAccuracy: 54.60%\n",
      "496\tValidation loss: 1.866035\tBest loss: 1.860284\tAccuracy: 54.00%\n",
      "497\tValidation loss: 1.857983\tBest loss: 1.857983\tAccuracy: 55.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\tValidation loss: 1.856476\tBest loss: 1.856476\tAccuracy: 54.30%\n",
      "499\tValidation loss: 1.860784\tBest loss: 1.856476\tAccuracy: 54.70%\n",
      "500\tValidation loss: 1.853467\tBest loss: 1.853467\tAccuracy: 54.30%\n",
      "501\tValidation loss: 1.859475\tBest loss: 1.853467\tAccuracy: 54.30%\n",
      "502\tValidation loss: 1.862489\tBest loss: 1.853467\tAccuracy: 54.30%\n",
      "503\tValidation loss: 1.860942\tBest loss: 1.853467\tAccuracy: 53.50%\n",
      "504\tValidation loss: 1.861434\tBest loss: 1.853467\tAccuracy: 54.20%\n",
      "505\tValidation loss: 1.857353\tBest loss: 1.853467\tAccuracy: 53.80%\n",
      "506\tValidation loss: 1.856662\tBest loss: 1.853467\tAccuracy: 53.80%\n",
      "507\tValidation loss: 1.853474\tBest loss: 1.853467\tAccuracy: 54.60%\n",
      "508\tValidation loss: 1.858543\tBest loss: 1.853467\tAccuracy: 53.50%\n",
      "509\tValidation loss: 1.859789\tBest loss: 1.853467\tAccuracy: 53.50%\n",
      "510\tValidation loss: 1.860793\tBest loss: 1.853467\tAccuracy: 53.20%\n",
      "511\tValidation loss: 1.856889\tBest loss: 1.853467\tAccuracy: 54.00%\n",
      "512\tValidation loss: 1.856910\tBest loss: 1.853467\tAccuracy: 53.10%\n",
      "513\tValidation loss: 1.856959\tBest loss: 1.853467\tAccuracy: 53.80%\n",
      "514\tValidation loss: 1.853721\tBest loss: 1.853467\tAccuracy: 53.20%\n",
      "515\tValidation loss: 1.849844\tBest loss: 1.849844\tAccuracy: 54.70%\n",
      "516\tValidation loss: 1.848513\tBest loss: 1.848513\tAccuracy: 54.10%\n",
      "517\tValidation loss: 1.850728\tBest loss: 1.848513\tAccuracy: 54.10%\n",
      "518\tValidation loss: 1.847016\tBest loss: 1.847016\tAccuracy: 54.50%\n",
      "519\tValidation loss: 1.849413\tBest loss: 1.847016\tAccuracy: 54.00%\n",
      "520\tValidation loss: 1.849970\tBest loss: 1.847016\tAccuracy: 54.20%\n",
      "521\tValidation loss: 1.848027\tBest loss: 1.847016\tAccuracy: 54.10%\n",
      "522\tValidation loss: 1.850368\tBest loss: 1.847016\tAccuracy: 54.20%\n",
      "523\tValidation loss: 1.846720\tBest loss: 1.846720\tAccuracy: 54.80%\n",
      "524\tValidation loss: 1.850005\tBest loss: 1.846720\tAccuracy: 54.10%\n",
      "525\tValidation loss: 1.841753\tBest loss: 1.841753\tAccuracy: 54.40%\n",
      "526\tValidation loss: 1.848037\tBest loss: 1.841753\tAccuracy: 54.00%\n",
      "527\tValidation loss: 1.846808\tBest loss: 1.841753\tAccuracy: 54.30%\n",
      "528\tValidation loss: 1.844187\tBest loss: 1.841753\tAccuracy: 54.70%\n",
      "529\tValidation loss: 1.845464\tBest loss: 1.841753\tAccuracy: 54.60%\n",
      "530\tValidation loss: 1.840960\tBest loss: 1.840960\tAccuracy: 54.70%\n",
      "531\tValidation loss: 1.843186\tBest loss: 1.840960\tAccuracy: 54.80%\n",
      "532\tValidation loss: 1.843965\tBest loss: 1.840960\tAccuracy: 54.50%\n",
      "533\tValidation loss: 1.836896\tBest loss: 1.836896\tAccuracy: 54.20%\n",
      "534\tValidation loss: 1.840005\tBest loss: 1.836896\tAccuracy: 55.10%\n",
      "535\tValidation loss: 1.843591\tBest loss: 1.836896\tAccuracy: 54.80%\n",
      "536\tValidation loss: 1.839293\tBest loss: 1.836896\tAccuracy: 54.70%\n",
      "537\tValidation loss: 1.841576\tBest loss: 1.836896\tAccuracy: 54.40%\n",
      "538\tValidation loss: 1.832711\tBest loss: 1.832711\tAccuracy: 54.90%\n",
      "539\tValidation loss: 1.837063\tBest loss: 1.832711\tAccuracy: 55.00%\n",
      "540\tValidation loss: 1.841599\tBest loss: 1.832711\tAccuracy: 54.00%\n",
      "541\tValidation loss: 1.835220\tBest loss: 1.832711\tAccuracy: 54.30%\n",
      "542\tValidation loss: 1.833919\tBest loss: 1.832711\tAccuracy: 54.50%\n",
      "543\tValidation loss: 1.832571\tBest loss: 1.832571\tAccuracy: 54.50%\n",
      "544\tValidation loss: 1.837732\tBest loss: 1.832571\tAccuracy: 55.00%\n",
      "545\tValidation loss: 1.833565\tBest loss: 1.832571\tAccuracy: 54.20%\n",
      "546\tValidation loss: 1.828842\tBest loss: 1.828842\tAccuracy: 54.20%\n",
      "547\tValidation loss: 1.833268\tBest loss: 1.828842\tAccuracy: 54.70%\n",
      "548\tValidation loss: 1.831493\tBest loss: 1.828842\tAccuracy: 54.60%\n",
      "549\tValidation loss: 1.831468\tBest loss: 1.828842\tAccuracy: 54.90%\n",
      "550\tValidation loss: 1.831941\tBest loss: 1.828842\tAccuracy: 54.50%\n",
      "551\tValidation loss: 1.834275\tBest loss: 1.828842\tAccuracy: 54.10%\n",
      "552\tValidation loss: 1.836884\tBest loss: 1.828842\tAccuracy: 54.50%\n",
      "553\tValidation loss: 1.833391\tBest loss: 1.828842\tAccuracy: 53.20%\n",
      "554\tValidation loss: 1.832812\tBest loss: 1.828842\tAccuracy: 54.80%\n",
      "555\tValidation loss: 1.838538\tBest loss: 1.828842\tAccuracy: 54.30%\n",
      "556\tValidation loss: 1.836708\tBest loss: 1.828842\tAccuracy: 54.50%\n",
      "557\tValidation loss: 1.831675\tBest loss: 1.828842\tAccuracy: 54.60%\n",
      "558\tValidation loss: 1.833951\tBest loss: 1.828842\tAccuracy: 54.30%\n",
      "559\tValidation loss: 1.834956\tBest loss: 1.828842\tAccuracy: 54.30%\n",
      "560\tValidation loss: 1.829114\tBest loss: 1.828842\tAccuracy: 53.40%\n",
      "561\tValidation loss: 1.828754\tBest loss: 1.828754\tAccuracy: 54.30%\n",
      "562\tValidation loss: 1.833446\tBest loss: 1.828754\tAccuracy: 53.70%\n",
      "563\tValidation loss: 1.830197\tBest loss: 1.828754\tAccuracy: 53.40%\n",
      "564\tValidation loss: 1.830770\tBest loss: 1.828754\tAccuracy: 54.20%\n",
      "565\tValidation loss: 1.830805\tBest loss: 1.828754\tAccuracy: 54.90%\n",
      "566\tValidation loss: 1.825531\tBest loss: 1.825531\tAccuracy: 54.90%\n",
      "567\tValidation loss: 1.830564\tBest loss: 1.825531\tAccuracy: 54.30%\n",
      "568\tValidation loss: 1.825145\tBest loss: 1.825145\tAccuracy: 53.90%\n",
      "569\tValidation loss: 1.826355\tBest loss: 1.825145\tAccuracy: 54.10%\n",
      "570\tValidation loss: 1.825699\tBest loss: 1.825145\tAccuracy: 53.90%\n",
      "571\tValidation loss: 1.825646\tBest loss: 1.825145\tAccuracy: 54.00%\n",
      "572\tValidation loss: 1.822871\tBest loss: 1.822871\tAccuracy: 53.80%\n",
      "573\tValidation loss: 1.825890\tBest loss: 1.822871\tAccuracy: 54.10%\n",
      "574\tValidation loss: 1.825680\tBest loss: 1.822871\tAccuracy: 54.50%\n",
      "575\tValidation loss: 1.819428\tBest loss: 1.819428\tAccuracy: 53.80%\n",
      "576\tValidation loss: 1.821093\tBest loss: 1.819428\tAccuracy: 54.20%\n",
      "577\tValidation loss: 1.825894\tBest loss: 1.819428\tAccuracy: 53.80%\n",
      "578\tValidation loss: 1.818275\tBest loss: 1.818275\tAccuracy: 53.50%\n",
      "579\tValidation loss: 1.826134\tBest loss: 1.818275\tAccuracy: 53.60%\n",
      "580\tValidation loss: 1.818401\tBest loss: 1.818275\tAccuracy: 53.30%\n",
      "581\tValidation loss: 1.816800\tBest loss: 1.816800\tAccuracy: 54.40%\n",
      "582\tValidation loss: 1.818278\tBest loss: 1.816800\tAccuracy: 53.90%\n",
      "583\tValidation loss: 1.818177\tBest loss: 1.816800\tAccuracy: 53.90%\n",
      "584\tValidation loss: 1.816211\tBest loss: 1.816211\tAccuracy: 53.70%\n",
      "585\tValidation loss: 1.817559\tBest loss: 1.816211\tAccuracy: 54.20%\n",
      "586\tValidation loss: 1.813538\tBest loss: 1.813538\tAccuracy: 54.00%\n",
      "587\tValidation loss: 1.822820\tBest loss: 1.813538\tAccuracy: 54.00%\n",
      "588\tValidation loss: 1.814292\tBest loss: 1.813538\tAccuracy: 54.00%\n",
      "589\tValidation loss: 1.813034\tBest loss: 1.813034\tAccuracy: 54.20%\n",
      "590\tValidation loss: 1.815346\tBest loss: 1.813034\tAccuracy: 54.00%\n",
      "591\tValidation loss: 1.816784\tBest loss: 1.813034\tAccuracy: 54.00%\n",
      "592\tValidation loss: 1.816678\tBest loss: 1.813034\tAccuracy: 54.30%\n",
      "593\tValidation loss: 1.813712\tBest loss: 1.813034\tAccuracy: 54.00%\n",
      "594\tValidation loss: 1.813987\tBest loss: 1.813034\tAccuracy: 54.50%\n",
      "595\tValidation loss: 1.817910\tBest loss: 1.813034\tAccuracy: 53.40%\n",
      "596\tValidation loss: 1.814219\tBest loss: 1.813034\tAccuracy: 54.50%\n",
      "597\tValidation loss: 1.816305\tBest loss: 1.813034\tAccuracy: 53.80%\n",
      "598\tValidation loss: 1.813411\tBest loss: 1.813034\tAccuracy: 54.30%\n",
      "599\tValidation loss: 1.813103\tBest loss: 1.813034\tAccuracy: 54.60%\n",
      "600\tValidation loss: 1.814167\tBest loss: 1.813034\tAccuracy: 55.00%\n",
      "601\tValidation loss: 1.808668\tBest loss: 1.808668\tAccuracy: 54.30%\n",
      "602\tValidation loss: 1.810289\tBest loss: 1.808668\tAccuracy: 53.50%\n",
      "603\tValidation loss: 1.809827\tBest loss: 1.808668\tAccuracy: 54.20%\n",
      "604\tValidation loss: 1.812851\tBest loss: 1.808668\tAccuracy: 53.70%\n",
      "605\tValidation loss: 1.809000\tBest loss: 1.808668\tAccuracy: 53.50%\n",
      "606\tValidation loss: 1.810296\tBest loss: 1.808668\tAccuracy: 53.80%\n",
      "607\tValidation loss: 1.811593\tBest loss: 1.808668\tAccuracy: 53.30%\n",
      "608\tValidation loss: 1.814488\tBest loss: 1.808668\tAccuracy: 53.60%\n",
      "609\tValidation loss: 1.805225\tBest loss: 1.805225\tAccuracy: 54.10%\n",
      "610\tValidation loss: 1.806589\tBest loss: 1.805225\tAccuracy: 54.70%\n",
      "611\tValidation loss: 1.803019\tBest loss: 1.803019\tAccuracy: 54.50%\n",
      "612\tValidation loss: 1.803378\tBest loss: 1.803019\tAccuracy: 54.40%\n",
      "613\tValidation loss: 1.804598\tBest loss: 1.803019\tAccuracy: 53.90%\n",
      "614\tValidation loss: 1.804111\tBest loss: 1.803019\tAccuracy: 54.40%\n",
      "615\tValidation loss: 1.807699\tBest loss: 1.803019\tAccuracy: 54.40%\n",
      "616\tValidation loss: 1.805506\tBest loss: 1.803019\tAccuracy: 53.90%\n",
      "617\tValidation loss: 1.801575\tBest loss: 1.801575\tAccuracy: 54.10%\n",
      "618\tValidation loss: 1.803495\tBest loss: 1.801575\tAccuracy: 54.00%\n",
      "619\tValidation loss: 1.806845\tBest loss: 1.801575\tAccuracy: 54.50%\n",
      "620\tValidation loss: 1.804471\tBest loss: 1.801575\tAccuracy: 54.30%\n",
      "621\tValidation loss: 1.801804\tBest loss: 1.801575\tAccuracy: 54.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\tValidation loss: 1.804252\tBest loss: 1.801575\tAccuracy: 54.50%\n",
      "623\tValidation loss: 1.802912\tBest loss: 1.801575\tAccuracy: 53.60%\n",
      "624\tValidation loss: 1.803406\tBest loss: 1.801575\tAccuracy: 54.10%\n",
      "625\tValidation loss: 1.799517\tBest loss: 1.799517\tAccuracy: 54.20%\n",
      "626\tValidation loss: 1.801355\tBest loss: 1.799517\tAccuracy: 54.10%\n",
      "627\tValidation loss: 1.799433\tBest loss: 1.799433\tAccuracy: 54.20%\n",
      "628\tValidation loss: 1.796960\tBest loss: 1.796960\tAccuracy: 54.00%\n",
      "629\tValidation loss: 1.801460\tBest loss: 1.796960\tAccuracy: 54.30%\n",
      "630\tValidation loss: 1.802078\tBest loss: 1.796960\tAccuracy: 54.30%\n",
      "631\tValidation loss: 1.800976\tBest loss: 1.796960\tAccuracy: 54.40%\n",
      "632\tValidation loss: 1.802245\tBest loss: 1.796960\tAccuracy: 54.10%\n",
      "633\tValidation loss: 1.801518\tBest loss: 1.796960\tAccuracy: 54.20%\n",
      "634\tValidation loss: 1.800132\tBest loss: 1.796960\tAccuracy: 54.90%\n",
      "635\tValidation loss: 1.800685\tBest loss: 1.796960\tAccuracy: 54.70%\n",
      "636\tValidation loss: 1.794686\tBest loss: 1.794686\tAccuracy: 54.60%\n",
      "637\tValidation loss: 1.799530\tBest loss: 1.794686\tAccuracy: 53.50%\n",
      "638\tValidation loss: 1.796786\tBest loss: 1.794686\tAccuracy: 53.80%\n",
      "639\tValidation loss: 1.798611\tBest loss: 1.794686\tAccuracy: 53.70%\n",
      "640\tValidation loss: 1.799099\tBest loss: 1.794686\tAccuracy: 54.50%\n",
      "641\tValidation loss: 1.799062\tBest loss: 1.794686\tAccuracy: 54.50%\n",
      "642\tValidation loss: 1.793800\tBest loss: 1.793800\tAccuracy: 54.40%\n",
      "643\tValidation loss: 1.794760\tBest loss: 1.793800\tAccuracy: 54.30%\n",
      "644\tValidation loss: 1.789587\tBest loss: 1.789587\tAccuracy: 55.00%\n",
      "645\tValidation loss: 1.790469\tBest loss: 1.789587\tAccuracy: 55.00%\n",
      "646\tValidation loss: 1.789900\tBest loss: 1.789587\tAccuracy: 54.70%\n",
      "647\tValidation loss: 1.786190\tBest loss: 1.786190\tAccuracy: 54.70%\n",
      "648\tValidation loss: 1.791306\tBest loss: 1.786190\tAccuracy: 55.00%\n",
      "649\tValidation loss: 1.792311\tBest loss: 1.786190\tAccuracy: 54.80%\n",
      "650\tValidation loss: 1.793807\tBest loss: 1.786190\tAccuracy: 54.50%\n",
      "651\tValidation loss: 1.792753\tBest loss: 1.786190\tAccuracy: 54.60%\n",
      "652\tValidation loss: 1.792068\tBest loss: 1.786190\tAccuracy: 54.80%\n",
      "653\tValidation loss: 1.797995\tBest loss: 1.786190\tAccuracy: 54.20%\n",
      "654\tValidation loss: 1.795027\tBest loss: 1.786190\tAccuracy: 54.50%\n",
      "655\tValidation loss: 1.791939\tBest loss: 1.786190\tAccuracy: 55.30%\n",
      "656\tValidation loss: 1.792144\tBest loss: 1.786190\tAccuracy: 54.70%\n",
      "657\tValidation loss: 1.791534\tBest loss: 1.786190\tAccuracy: 55.20%\n",
      "658\tValidation loss: 1.794254\tBest loss: 1.786190\tAccuracy: 54.30%\n",
      "659\tValidation loss: 1.794212\tBest loss: 1.786190\tAccuracy: 54.40%\n",
      "660\tValidation loss: 1.791131\tBest loss: 1.786190\tAccuracy: 54.90%\n",
      "661\tValidation loss: 1.794782\tBest loss: 1.786190\tAccuracy: 54.20%\n",
      "662\tValidation loss: 1.793435\tBest loss: 1.786190\tAccuracy: 54.20%\n",
      "663\tValidation loss: 1.793025\tBest loss: 1.786190\tAccuracy: 54.90%\n",
      "664\tValidation loss: 1.793169\tBest loss: 1.786190\tAccuracy: 54.80%\n",
      "665\tValidation loss: 1.789528\tBest loss: 1.786190\tAccuracy: 54.50%\n",
      "666\tValidation loss: 1.788961\tBest loss: 1.786190\tAccuracy: 54.50%\n",
      "667\tValidation loss: 1.789516\tBest loss: 1.786190\tAccuracy: 54.50%\n",
      "668\tValidation loss: 1.791547\tBest loss: 1.786190\tAccuracy: 54.60%\n",
      "Early stopping!\n",
      "[[  6.39274440e-05   1.29501075e-02   6.65054517e-03 ...,   8.54038899e-06\n",
      "    4.42475633e-04   7.45982970e-06]\n",
      " [  8.91420360e-09   2.79789656e-05   1.88966112e-07 ...,   1.27547449e-15\n",
      "    1.90835867e-12   3.40458759e-12]\n",
      " [  5.94740277e-06   1.79394917e-03   3.37099264e-05 ...,   3.37177823e-08\n",
      "    9.52014773e-07   7.50794413e-07]\n",
      " ..., \n",
      " [  6.39701914e-03   8.05459078e-03   6.72119344e-03 ...,   2.05826052e-02\n",
      "    1.01163760e-02   1.59667656e-02]\n",
      " [  1.27626525e-04   2.66360294e-04   2.55546212e-04 ...,   2.57898152e-01\n",
      "    8.39382112e-02   2.13747416e-02]\n",
      " [  4.61274325e-08   4.98571296e-07   2.83605544e-07 ...,   3.90582792e-02\n",
      "    4.40898314e-02   1.27390549e-02]]\n",
      "[23 43 43 ...,  8 45 25]\n",
      "[[  6.63998065e-08   2.73015175e-04   3.42139829e-05 ...,   8.99205518e-15\n",
      "    8.02532433e-12   6.45414347e-11]\n",
      " [  4.60138656e-02   3.62413973e-02   4.51272577e-02 ...,   1.77589133e-02\n",
      "    8.35684221e-03   9.06009693e-03]\n",
      " [  2.36816319e-07   9.00188805e-14   9.87775547e-06 ...,   4.25546879e-14\n",
      "    5.01663310e-15   4.90161423e-17]\n",
      " ..., \n",
      " [  4.44586901e-03   1.20172137e-02   6.24114065e-04 ...,   8.53826168e-06\n",
      "    3.31666670e-05   6.55963220e-07]\n",
      " [  3.60638164e-02   2.61789579e-02   3.34515385e-02 ...,   1.86568927e-02\n",
      "    1.00437133e-02   1.16654942e-02]\n",
      " [  5.26327177e-08   1.22974683e-07   5.49380502e-07 ...,   1.27845541e-01\n",
      "    3.37345526e-02   7.29060829e-01]]\n",
      "[20 18 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 1.4min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 4.295065\tBest loss: 4.295065\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.936267\tBest loss: 3.936267\tAccuracy: 5.30%\n",
      "2\tValidation loss: 3.888312\tBest loss: 3.888312\tAccuracy: 5.20%\n",
      "3\tValidation loss: 3.862204\tBest loss: 3.862204\tAccuracy: 5.40%\n",
      "4\tValidation loss: 3.841882\tBest loss: 3.841882\tAccuracy: 5.20%\n",
      "5\tValidation loss: 3.820207\tBest loss: 3.820207\tAccuracy: 5.70%\n",
      "6\tValidation loss: 3.801028\tBest loss: 3.801028\tAccuracy: 5.70%\n",
      "7\tValidation loss: 3.784977\tBest loss: 3.784977\tAccuracy: 6.20%\n",
      "8\tValidation loss: 3.770851\tBest loss: 3.770851\tAccuracy: 6.40%\n",
      "9\tValidation loss: 3.758248\tBest loss: 3.758248\tAccuracy: 6.60%\n",
      "10\tValidation loss: 3.747694\tBest loss: 3.747694\tAccuracy: 7.00%\n",
      "11\tValidation loss: 3.737874\tBest loss: 3.737874\tAccuracy: 7.20%\n",
      "12\tValidation loss: 3.728960\tBest loss: 3.728960\tAccuracy: 7.50%\n",
      "13\tValidation loss: 3.721269\tBest loss: 3.721269\tAccuracy: 7.80%\n",
      "14\tValidation loss: 3.714065\tBest loss: 3.714065\tAccuracy: 8.40%\n",
      "15\tValidation loss: 3.707710\tBest loss: 3.707710\tAccuracy: 8.40%\n",
      "16\tValidation loss: 3.701404\tBest loss: 3.701404\tAccuracy: 9.10%\n",
      "17\tValidation loss: 3.696086\tBest loss: 3.696086\tAccuracy: 9.90%\n",
      "18\tValidation loss: 3.690435\tBest loss: 3.690435\tAccuracy: 9.80%\n",
      "19\tValidation loss: 3.685948\tBest loss: 3.685948\tAccuracy: 9.50%\n",
      "20\tValidation loss: 3.682395\tBest loss: 3.682395\tAccuracy: 9.60%\n",
      "21\tValidation loss: 3.678701\tBest loss: 3.678701\tAccuracy: 9.70%\n",
      "22\tValidation loss: 3.673943\tBest loss: 3.673943\tAccuracy: 9.80%\n",
      "23\tValidation loss: 3.670238\tBest loss: 3.670238\tAccuracy: 10.10%\n",
      "24\tValidation loss: 3.666624\tBest loss: 3.666624\tAccuracy: 10.40%\n",
      "25\tValidation loss: 3.663354\tBest loss: 3.663354\tAccuracy: 10.60%\n",
      "26\tValidation loss: 3.659842\tBest loss: 3.659842\tAccuracy: 10.20%\n",
      "27\tValidation loss: 3.656404\tBest loss: 3.656404\tAccuracy: 10.10%\n",
      "28\tValidation loss: 3.653893\tBest loss: 3.653893\tAccuracy: 10.40%\n",
      "29\tValidation loss: 3.649704\tBest loss: 3.649704\tAccuracy: 10.40%\n",
      "30\tValidation loss: 3.646587\tBest loss: 3.646587\tAccuracy: 10.50%\n",
      "31\tValidation loss: 3.643052\tBest loss: 3.643052\tAccuracy: 10.90%\n",
      "32\tValidation loss: 3.639359\tBest loss: 3.639359\tAccuracy: 11.20%\n",
      "33\tValidation loss: 3.635680\tBest loss: 3.635680\tAccuracy: 11.10%\n",
      "34\tValidation loss: 3.632524\tBest loss: 3.632524\tAccuracy: 11.20%\n",
      "35\tValidation loss: 3.627920\tBest loss: 3.627920\tAccuracy: 11.20%\n",
      "36\tValidation loss: 3.623260\tBest loss: 3.623260\tAccuracy: 11.40%\n",
      "37\tValidation loss: 3.618851\tBest loss: 3.618851\tAccuracy: 11.10%\n",
      "38\tValidation loss: 3.614804\tBest loss: 3.614804\tAccuracy: 11.20%\n",
      "39\tValidation loss: 3.610815\tBest loss: 3.610815\tAccuracy: 11.60%\n",
      "40\tValidation loss: 3.606587\tBest loss: 3.606587\tAccuracy: 11.30%\n",
      "41\tValidation loss: 3.602800\tBest loss: 3.602800\tAccuracy: 11.00%\n",
      "42\tValidation loss: 3.596833\tBest loss: 3.596833\tAccuracy: 11.30%\n",
      "43\tValidation loss: 3.591023\tBest loss: 3.591023\tAccuracy: 11.40%\n",
      "44\tValidation loss: 3.584248\tBest loss: 3.584248\tAccuracy: 11.10%\n",
      "45\tValidation loss: 3.579244\tBest loss: 3.579244\tAccuracy: 11.10%\n",
      "46\tValidation loss: 3.575511\tBest loss: 3.575511\tAccuracy: 11.20%\n",
      "47\tValidation loss: 3.572617\tBest loss: 3.572617\tAccuracy: 11.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\tValidation loss: 3.566607\tBest loss: 3.566607\tAccuracy: 11.90%\n",
      "49\tValidation loss: 3.563612\tBest loss: 3.563612\tAccuracy: 12.30%\n",
      "50\tValidation loss: 3.560847\tBest loss: 3.560847\tAccuracy: 12.60%\n",
      "51\tValidation loss: 3.554028\tBest loss: 3.554028\tAccuracy: 12.80%\n",
      "52\tValidation loss: 3.549009\tBest loss: 3.549009\tAccuracy: 12.60%\n",
      "53\tValidation loss: 3.545890\tBest loss: 3.545890\tAccuracy: 12.70%\n",
      "54\tValidation loss: 3.544754\tBest loss: 3.544754\tAccuracy: 12.70%\n",
      "55\tValidation loss: 3.542611\tBest loss: 3.542611\tAccuracy: 12.20%\n",
      "56\tValidation loss: 3.537848\tBest loss: 3.537848\tAccuracy: 12.40%\n",
      "57\tValidation loss: 3.530185\tBest loss: 3.530185\tAccuracy: 12.50%\n",
      "58\tValidation loss: 3.525923\tBest loss: 3.525923\tAccuracy: 12.80%\n",
      "59\tValidation loss: 3.524034\tBest loss: 3.524034\tAccuracy: 12.70%\n",
      "60\tValidation loss: 3.520840\tBest loss: 3.520840\tAccuracy: 12.70%\n",
      "61\tValidation loss: 3.515326\tBest loss: 3.515326\tAccuracy: 12.60%\n",
      "62\tValidation loss: 3.513278\tBest loss: 3.513278\tAccuracy: 12.60%\n",
      "63\tValidation loss: 3.508279\tBest loss: 3.508279\tAccuracy: 12.70%\n",
      "64\tValidation loss: 3.502864\tBest loss: 3.502864\tAccuracy: 12.70%\n",
      "65\tValidation loss: 3.498383\tBest loss: 3.498383\tAccuracy: 12.70%\n",
      "66\tValidation loss: 3.490878\tBest loss: 3.490878\tAccuracy: 12.90%\n",
      "67\tValidation loss: 3.488774\tBest loss: 3.488774\tAccuracy: 12.70%\n",
      "68\tValidation loss: 3.487060\tBest loss: 3.487060\tAccuracy: 13.00%\n",
      "69\tValidation loss: 3.478603\tBest loss: 3.478603\tAccuracy: 12.90%\n",
      "70\tValidation loss: 3.479530\tBest loss: 3.478603\tAccuracy: 13.40%\n",
      "71\tValidation loss: 3.475133\tBest loss: 3.475133\tAccuracy: 13.10%\n",
      "72\tValidation loss: 3.470787\tBest loss: 3.470787\tAccuracy: 13.20%\n",
      "73\tValidation loss: 3.466501\tBest loss: 3.466501\tAccuracy: 13.50%\n",
      "74\tValidation loss: 3.462053\tBest loss: 3.462053\tAccuracy: 13.50%\n",
      "75\tValidation loss: 3.457582\tBest loss: 3.457582\tAccuracy: 13.30%\n",
      "76\tValidation loss: 3.451902\tBest loss: 3.451902\tAccuracy: 13.90%\n",
      "77\tValidation loss: 3.447124\tBest loss: 3.447124\tAccuracy: 14.40%\n",
      "78\tValidation loss: 3.441243\tBest loss: 3.441243\tAccuracy: 14.60%\n",
      "79\tValidation loss: 3.438357\tBest loss: 3.438357\tAccuracy: 14.80%\n",
      "80\tValidation loss: 3.428929\tBest loss: 3.428929\tAccuracy: 15.00%\n",
      "81\tValidation loss: 3.422373\tBest loss: 3.422373\tAccuracy: 14.90%\n",
      "82\tValidation loss: 3.415378\tBest loss: 3.415378\tAccuracy: 15.00%\n",
      "83\tValidation loss: 3.406942\tBest loss: 3.406942\tAccuracy: 14.80%\n",
      "84\tValidation loss: 3.396499\tBest loss: 3.396499\tAccuracy: 14.60%\n",
      "85\tValidation loss: 3.396320\tBest loss: 3.396320\tAccuracy: 14.70%\n",
      "86\tValidation loss: 3.386695\tBest loss: 3.386695\tAccuracy: 14.80%\n",
      "87\tValidation loss: 3.377354\tBest loss: 3.377354\tAccuracy: 14.70%\n",
      "88\tValidation loss: 3.373408\tBest loss: 3.373408\tAccuracy: 15.10%\n",
      "89\tValidation loss: 3.364002\tBest loss: 3.364002\tAccuracy: 15.10%\n",
      "90\tValidation loss: 3.357892\tBest loss: 3.357892\tAccuracy: 15.50%\n",
      "91\tValidation loss: 3.345888\tBest loss: 3.345888\tAccuracy: 14.90%\n",
      "92\tValidation loss: 3.333866\tBest loss: 3.333866\tAccuracy: 15.50%\n",
      "93\tValidation loss: 3.323214\tBest loss: 3.323214\tAccuracy: 15.20%\n",
      "94\tValidation loss: 3.317206\tBest loss: 3.317206\tAccuracy: 15.50%\n",
      "95\tValidation loss: 3.307971\tBest loss: 3.307971\tAccuracy: 15.60%\n",
      "96\tValidation loss: 3.292002\tBest loss: 3.292002\tAccuracy: 14.90%\n",
      "97\tValidation loss: 3.281754\tBest loss: 3.281754\tAccuracy: 15.60%\n",
      "98\tValidation loss: 3.266891\tBest loss: 3.266891\tAccuracy: 15.40%\n",
      "99\tValidation loss: 3.263468\tBest loss: 3.263468\tAccuracy: 16.60%\n",
      "100\tValidation loss: 3.251915\tBest loss: 3.251915\tAccuracy: 16.10%\n",
      "101\tValidation loss: 3.244979\tBest loss: 3.244979\tAccuracy: 16.20%\n",
      "102\tValidation loss: 3.235849\tBest loss: 3.235849\tAccuracy: 16.50%\n",
      "103\tValidation loss: 3.220416\tBest loss: 3.220416\tAccuracy: 17.20%\n",
      "104\tValidation loss: 3.210761\tBest loss: 3.210761\tAccuracy: 17.50%\n",
      "105\tValidation loss: 3.202548\tBest loss: 3.202548\tAccuracy: 17.30%\n",
      "106\tValidation loss: 3.183858\tBest loss: 3.183858\tAccuracy: 18.00%\n",
      "107\tValidation loss: 3.175477\tBest loss: 3.175477\tAccuracy: 17.50%\n",
      "108\tValidation loss: 3.164203\tBest loss: 3.164203\tAccuracy: 18.00%\n",
      "109\tValidation loss: 3.160164\tBest loss: 3.160164\tAccuracy: 18.00%\n",
      "110\tValidation loss: 3.144306\tBest loss: 3.144306\tAccuracy: 19.00%\n",
      "111\tValidation loss: 3.127718\tBest loss: 3.127718\tAccuracy: 19.50%\n",
      "112\tValidation loss: 3.124463\tBest loss: 3.124463\tAccuracy: 19.40%\n",
      "113\tValidation loss: 3.114437\tBest loss: 3.114437\tAccuracy: 20.10%\n",
      "114\tValidation loss: 3.097635\tBest loss: 3.097635\tAccuracy: 20.50%\n",
      "115\tValidation loss: 3.088511\tBest loss: 3.088511\tAccuracy: 20.20%\n",
      "116\tValidation loss: 3.081258\tBest loss: 3.081258\tAccuracy: 20.40%\n",
      "117\tValidation loss: 3.072389\tBest loss: 3.072389\tAccuracy: 21.00%\n",
      "118\tValidation loss: 3.062603\tBest loss: 3.062603\tAccuracy: 20.50%\n",
      "119\tValidation loss: 3.052029\tBest loss: 3.052029\tAccuracy: 21.60%\n",
      "120\tValidation loss: 3.037386\tBest loss: 3.037386\tAccuracy: 21.30%\n",
      "121\tValidation loss: 3.024395\tBest loss: 3.024395\tAccuracy: 20.70%\n",
      "122\tValidation loss: 3.026419\tBest loss: 3.024395\tAccuracy: 21.00%\n",
      "123\tValidation loss: 3.012004\tBest loss: 3.012004\tAccuracy: 23.00%\n",
      "124\tValidation loss: 2.999860\tBest loss: 2.999860\tAccuracy: 21.20%\n",
      "125\tValidation loss: 2.990834\tBest loss: 2.990834\tAccuracy: 22.40%\n",
      "126\tValidation loss: 2.983627\tBest loss: 2.983627\tAccuracy: 22.30%\n",
      "127\tValidation loss: 2.980097\tBest loss: 2.980097\tAccuracy: 22.90%\n",
      "128\tValidation loss: 2.973455\tBest loss: 2.973455\tAccuracy: 22.30%\n",
      "129\tValidation loss: 2.962817\tBest loss: 2.962817\tAccuracy: 22.70%\n",
      "130\tValidation loss: 2.946215\tBest loss: 2.946215\tAccuracy: 22.90%\n",
      "131\tValidation loss: 2.939170\tBest loss: 2.939170\tAccuracy: 23.50%\n",
      "132\tValidation loss: 2.928787\tBest loss: 2.928787\tAccuracy: 24.20%\n",
      "133\tValidation loss: 2.916449\tBest loss: 2.916449\tAccuracy: 24.70%\n",
      "134\tValidation loss: 2.907200\tBest loss: 2.907200\tAccuracy: 24.10%\n",
      "135\tValidation loss: 2.895286\tBest loss: 2.895286\tAccuracy: 25.10%\n",
      "136\tValidation loss: 2.872946\tBest loss: 2.872946\tAccuracy: 24.70%\n",
      "137\tValidation loss: 2.871783\tBest loss: 2.871783\tAccuracy: 24.50%\n",
      "138\tValidation loss: 2.859564\tBest loss: 2.859564\tAccuracy: 24.30%\n",
      "139\tValidation loss: 2.849936\tBest loss: 2.849936\tAccuracy: 25.60%\n",
      "140\tValidation loss: 2.833717\tBest loss: 2.833717\tAccuracy: 25.40%\n",
      "141\tValidation loss: 2.823208\tBest loss: 2.823208\tAccuracy: 25.20%\n",
      "142\tValidation loss: 2.819099\tBest loss: 2.819099\tAccuracy: 25.10%\n",
      "143\tValidation loss: 2.821418\tBest loss: 2.819099\tAccuracy: 25.10%\n",
      "144\tValidation loss: 2.782772\tBest loss: 2.782772\tAccuracy: 26.20%\n",
      "145\tValidation loss: 2.782133\tBest loss: 2.782133\tAccuracy: 25.90%\n",
      "146\tValidation loss: 2.770482\tBest loss: 2.770482\tAccuracy: 26.00%\n",
      "147\tValidation loss: 2.757068\tBest loss: 2.757068\tAccuracy: 26.30%\n",
      "148\tValidation loss: 2.759485\tBest loss: 2.757068\tAccuracy: 26.40%\n",
      "149\tValidation loss: 2.749435\tBest loss: 2.749435\tAccuracy: 27.30%\n",
      "150\tValidation loss: 2.742420\tBest loss: 2.742420\tAccuracy: 27.50%\n",
      "151\tValidation loss: 2.732935\tBest loss: 2.732935\tAccuracy: 27.00%\n",
      "152\tValidation loss: 2.716645\tBest loss: 2.716645\tAccuracy: 27.30%\n",
      "153\tValidation loss: 2.715054\tBest loss: 2.715054\tAccuracy: 28.40%\n",
      "154\tValidation loss: 2.706019\tBest loss: 2.706019\tAccuracy: 28.20%\n",
      "155\tValidation loss: 2.698650\tBest loss: 2.698650\tAccuracy: 28.40%\n",
      "156\tValidation loss: 2.686181\tBest loss: 2.686181\tAccuracy: 29.30%\n",
      "157\tValidation loss: 2.680628\tBest loss: 2.680628\tAccuracy: 28.90%\n",
      "158\tValidation loss: 2.673355\tBest loss: 2.673355\tAccuracy: 29.40%\n",
      "159\tValidation loss: 2.653582\tBest loss: 2.653582\tAccuracy: 30.10%\n",
      "160\tValidation loss: 2.649380\tBest loss: 2.649380\tAccuracy: 29.60%\n",
      "161\tValidation loss: 2.644830\tBest loss: 2.644830\tAccuracy: 29.60%\n",
      "162\tValidation loss: 2.643216\tBest loss: 2.643216\tAccuracy: 29.30%\n",
      "163\tValidation loss: 2.627223\tBest loss: 2.627223\tAccuracy: 30.20%\n",
      "164\tValidation loss: 2.622585\tBest loss: 2.622585\tAccuracy: 30.00%\n",
      "165\tValidation loss: 2.615969\tBest loss: 2.615969\tAccuracy: 30.30%\n",
      "166\tValidation loss: 2.616651\tBest loss: 2.615969\tAccuracy: 30.10%\n",
      "167\tValidation loss: 2.600706\tBest loss: 2.600706\tAccuracy: 30.10%\n",
      "168\tValidation loss: 2.599384\tBest loss: 2.599384\tAccuracy: 30.60%\n",
      "169\tValidation loss: 2.599153\tBest loss: 2.599153\tAccuracy: 31.20%\n",
      "170\tValidation loss: 2.577222\tBest loss: 2.577222\tAccuracy: 31.10%\n",
      "171\tValidation loss: 2.571727\tBest loss: 2.571727\tAccuracy: 31.00%\n",
      "172\tValidation loss: 2.561885\tBest loss: 2.561885\tAccuracy: 32.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\tValidation loss: 2.552155\tBest loss: 2.552155\tAccuracy: 31.60%\n",
      "174\tValidation loss: 2.553114\tBest loss: 2.552155\tAccuracy: 31.80%\n",
      "175\tValidation loss: 2.545054\tBest loss: 2.545054\tAccuracy: 32.40%\n",
      "176\tValidation loss: 2.540112\tBest loss: 2.540112\tAccuracy: 32.20%\n",
      "177\tValidation loss: 2.526963\tBest loss: 2.526963\tAccuracy: 32.50%\n",
      "178\tValidation loss: 2.521621\tBest loss: 2.521621\tAccuracy: 32.40%\n",
      "179\tValidation loss: 2.529722\tBest loss: 2.521621\tAccuracy: 32.50%\n",
      "180\tValidation loss: 2.509816\tBest loss: 2.509816\tAccuracy: 32.90%\n",
      "181\tValidation loss: 2.510432\tBest loss: 2.509816\tAccuracy: 33.10%\n",
      "182\tValidation loss: 2.503759\tBest loss: 2.503759\tAccuracy: 33.40%\n",
      "183\tValidation loss: 2.497333\tBest loss: 2.497333\tAccuracy: 33.30%\n",
      "184\tValidation loss: 2.488369\tBest loss: 2.488369\tAccuracy: 33.30%\n",
      "185\tValidation loss: 2.488730\tBest loss: 2.488369\tAccuracy: 33.90%\n",
      "186\tValidation loss: 2.481908\tBest loss: 2.481908\tAccuracy: 34.20%\n",
      "187\tValidation loss: 2.461717\tBest loss: 2.461717\tAccuracy: 35.40%\n",
      "188\tValidation loss: 2.454164\tBest loss: 2.454164\tAccuracy: 35.60%\n",
      "189\tValidation loss: 2.452216\tBest loss: 2.452216\tAccuracy: 34.70%\n",
      "190\tValidation loss: 2.444518\tBest loss: 2.444518\tAccuracy: 35.60%\n",
      "191\tValidation loss: 2.440336\tBest loss: 2.440336\tAccuracy: 35.70%\n",
      "192\tValidation loss: 2.433450\tBest loss: 2.433450\tAccuracy: 35.80%\n",
      "193\tValidation loss: 2.433032\tBest loss: 2.433032\tAccuracy: 36.80%\n",
      "194\tValidation loss: 2.425879\tBest loss: 2.425879\tAccuracy: 36.40%\n",
      "195\tValidation loss: 2.411526\tBest loss: 2.411526\tAccuracy: 37.60%\n",
      "196\tValidation loss: 2.407536\tBest loss: 2.407536\tAccuracy: 37.80%\n",
      "197\tValidation loss: 2.398543\tBest loss: 2.398543\tAccuracy: 37.40%\n",
      "198\tValidation loss: 2.394403\tBest loss: 2.394403\tAccuracy: 37.00%\n",
      "199\tValidation loss: 2.389758\tBest loss: 2.389758\tAccuracy: 37.50%\n",
      "200\tValidation loss: 2.380669\tBest loss: 2.380669\tAccuracy: 38.20%\n",
      "201\tValidation loss: 2.375561\tBest loss: 2.375561\tAccuracy: 38.40%\n",
      "202\tValidation loss: 2.367907\tBest loss: 2.367907\tAccuracy: 38.80%\n",
      "203\tValidation loss: 2.358215\tBest loss: 2.358215\tAccuracy: 38.90%\n",
      "204\tValidation loss: 2.355861\tBest loss: 2.355861\tAccuracy: 38.90%\n",
      "205\tValidation loss: 2.347828\tBest loss: 2.347828\tAccuracy: 38.80%\n",
      "206\tValidation loss: 2.351615\tBest loss: 2.347828\tAccuracy: 39.60%\n",
      "207\tValidation loss: 2.339965\tBest loss: 2.339965\tAccuracy: 39.60%\n",
      "208\tValidation loss: 2.337937\tBest loss: 2.337937\tAccuracy: 40.10%\n",
      "209\tValidation loss: 2.332086\tBest loss: 2.332086\tAccuracy: 39.80%\n",
      "210\tValidation loss: 2.328141\tBest loss: 2.328141\tAccuracy: 40.00%\n",
      "211\tValidation loss: 2.323894\tBest loss: 2.323894\tAccuracy: 40.90%\n",
      "212\tValidation loss: 2.317697\tBest loss: 2.317697\tAccuracy: 39.90%\n",
      "213\tValidation loss: 2.307050\tBest loss: 2.307050\tAccuracy: 40.80%\n",
      "214\tValidation loss: 2.298658\tBest loss: 2.298658\tAccuracy: 40.70%\n",
      "215\tValidation loss: 2.306361\tBest loss: 2.298658\tAccuracy: 40.80%\n",
      "216\tValidation loss: 2.291288\tBest loss: 2.291288\tAccuracy: 41.90%\n",
      "217\tValidation loss: 2.283999\tBest loss: 2.283999\tAccuracy: 41.80%\n",
      "218\tValidation loss: 2.288979\tBest loss: 2.283999\tAccuracy: 41.30%\n",
      "219\tValidation loss: 2.283498\tBest loss: 2.283498\tAccuracy: 42.30%\n",
      "220\tValidation loss: 2.281876\tBest loss: 2.281876\tAccuracy: 41.80%\n",
      "221\tValidation loss: 2.273870\tBest loss: 2.273870\tAccuracy: 42.70%\n",
      "222\tValidation loss: 2.276170\tBest loss: 2.273870\tAccuracy: 42.10%\n",
      "223\tValidation loss: 2.266412\tBest loss: 2.266412\tAccuracy: 41.70%\n",
      "224\tValidation loss: 2.259167\tBest loss: 2.259167\tAccuracy: 41.50%\n",
      "225\tValidation loss: 2.260054\tBest loss: 2.259167\tAccuracy: 42.60%\n",
      "226\tValidation loss: 2.253653\tBest loss: 2.253653\tAccuracy: 42.10%\n",
      "227\tValidation loss: 2.241958\tBest loss: 2.241958\tAccuracy: 41.90%\n",
      "228\tValidation loss: 2.241678\tBest loss: 2.241678\tAccuracy: 42.30%\n",
      "229\tValidation loss: 2.238894\tBest loss: 2.238894\tAccuracy: 42.40%\n",
      "230\tValidation loss: 2.233858\tBest loss: 2.233858\tAccuracy: 41.90%\n",
      "231\tValidation loss: 2.227652\tBest loss: 2.227652\tAccuracy: 41.90%\n",
      "232\tValidation loss: 2.224924\tBest loss: 2.224924\tAccuracy: 42.40%\n",
      "233\tValidation loss: 2.225191\tBest loss: 2.224924\tAccuracy: 42.80%\n",
      "234\tValidation loss: 2.210510\tBest loss: 2.210510\tAccuracy: 42.60%\n",
      "235\tValidation loss: 2.212382\tBest loss: 2.210510\tAccuracy: 42.50%\n",
      "236\tValidation loss: 2.206053\tBest loss: 2.206053\tAccuracy: 41.90%\n",
      "237\tValidation loss: 2.204084\tBest loss: 2.204084\tAccuracy: 42.70%\n",
      "238\tValidation loss: 2.195180\tBest loss: 2.195180\tAccuracy: 42.30%\n",
      "239\tValidation loss: 2.191050\tBest loss: 2.191050\tAccuracy: 43.10%\n",
      "240\tValidation loss: 2.183822\tBest loss: 2.183822\tAccuracy: 42.80%\n",
      "241\tValidation loss: 2.189921\tBest loss: 2.183822\tAccuracy: 43.20%\n",
      "242\tValidation loss: 2.185986\tBest loss: 2.183822\tAccuracy: 42.90%\n",
      "243\tValidation loss: 2.186131\tBest loss: 2.183822\tAccuracy: 42.90%\n",
      "244\tValidation loss: 2.182058\tBest loss: 2.182058\tAccuracy: 43.10%\n",
      "245\tValidation loss: 2.175878\tBest loss: 2.175878\tAccuracy: 42.50%\n",
      "246\tValidation loss: 2.174563\tBest loss: 2.174563\tAccuracy: 43.20%\n",
      "247\tValidation loss: 2.169837\tBest loss: 2.169837\tAccuracy: 43.60%\n",
      "248\tValidation loss: 2.164267\tBest loss: 2.164267\tAccuracy: 43.50%\n",
      "249\tValidation loss: 2.159292\tBest loss: 2.159292\tAccuracy: 43.60%\n",
      "250\tValidation loss: 2.153732\tBest loss: 2.153732\tAccuracy: 43.20%\n",
      "251\tValidation loss: 2.152893\tBest loss: 2.152893\tAccuracy: 43.20%\n",
      "252\tValidation loss: 2.149546\tBest loss: 2.149546\tAccuracy: 44.00%\n",
      "253\tValidation loss: 2.144275\tBest loss: 2.144275\tAccuracy: 43.60%\n",
      "254\tValidation loss: 2.149426\tBest loss: 2.144275\tAccuracy: 44.60%\n",
      "255\tValidation loss: 2.141044\tBest loss: 2.141044\tAccuracy: 44.40%\n",
      "256\tValidation loss: 2.137003\tBest loss: 2.137003\tAccuracy: 44.00%\n",
      "257\tValidation loss: 2.133162\tBest loss: 2.133162\tAccuracy: 44.40%\n",
      "258\tValidation loss: 2.133477\tBest loss: 2.133162\tAccuracy: 43.90%\n",
      "259\tValidation loss: 2.127332\tBest loss: 2.127332\tAccuracy: 44.30%\n",
      "260\tValidation loss: 2.128272\tBest loss: 2.127332\tAccuracy: 43.50%\n",
      "261\tValidation loss: 2.124237\tBest loss: 2.124237\tAccuracy: 44.90%\n",
      "262\tValidation loss: 2.121891\tBest loss: 2.121891\tAccuracy: 44.40%\n",
      "263\tValidation loss: 2.120757\tBest loss: 2.120757\tAccuracy: 44.30%\n",
      "264\tValidation loss: 2.115693\tBest loss: 2.115693\tAccuracy: 45.30%\n",
      "265\tValidation loss: 2.112778\tBest loss: 2.112778\tAccuracy: 45.20%\n",
      "266\tValidation loss: 2.109715\tBest loss: 2.109715\tAccuracy: 45.10%\n",
      "267\tValidation loss: 2.111719\tBest loss: 2.109715\tAccuracy: 45.30%\n",
      "268\tValidation loss: 2.107601\tBest loss: 2.107601\tAccuracy: 44.50%\n",
      "269\tValidation loss: 2.106072\tBest loss: 2.106072\tAccuracy: 44.90%\n",
      "270\tValidation loss: 2.097152\tBest loss: 2.097152\tAccuracy: 45.30%\n",
      "271\tValidation loss: 2.100212\tBest loss: 2.097152\tAccuracy: 46.40%\n",
      "272\tValidation loss: 2.099603\tBest loss: 2.097152\tAccuracy: 46.80%\n",
      "273\tValidation loss: 2.091207\tBest loss: 2.091207\tAccuracy: 45.90%\n",
      "274\tValidation loss: 2.090435\tBest loss: 2.090435\tAccuracy: 46.30%\n",
      "275\tValidation loss: 2.089920\tBest loss: 2.089920\tAccuracy: 46.30%\n",
      "276\tValidation loss: 2.081243\tBest loss: 2.081243\tAccuracy: 46.70%\n",
      "277\tValidation loss: 2.077549\tBest loss: 2.077549\tAccuracy: 46.20%\n",
      "278\tValidation loss: 2.078062\tBest loss: 2.077549\tAccuracy: 46.80%\n",
      "279\tValidation loss: 2.072577\tBest loss: 2.072577\tAccuracy: 45.90%\n",
      "280\tValidation loss: 2.077216\tBest loss: 2.072577\tAccuracy: 46.40%\n",
      "281\tValidation loss: 2.073175\tBest loss: 2.072577\tAccuracy: 46.70%\n",
      "282\tValidation loss: 2.068907\tBest loss: 2.068907\tAccuracy: 45.60%\n",
      "283\tValidation loss: 2.070644\tBest loss: 2.068907\tAccuracy: 46.30%\n",
      "284\tValidation loss: 2.072752\tBest loss: 2.068907\tAccuracy: 46.60%\n",
      "285\tValidation loss: 2.068801\tBest loss: 2.068801\tAccuracy: 46.80%\n",
      "286\tValidation loss: 2.066101\tBest loss: 2.066101\tAccuracy: 46.90%\n",
      "287\tValidation loss: 2.061735\tBest loss: 2.061735\tAccuracy: 47.30%\n",
      "288\tValidation loss: 2.061727\tBest loss: 2.061727\tAccuracy: 47.30%\n",
      "289\tValidation loss: 2.065481\tBest loss: 2.061727\tAccuracy: 47.30%\n",
      "290\tValidation loss: 2.061583\tBest loss: 2.061583\tAccuracy: 47.20%\n",
      "291\tValidation loss: 2.058188\tBest loss: 2.058188\tAccuracy: 47.80%\n",
      "292\tValidation loss: 2.052074\tBest loss: 2.052074\tAccuracy: 47.90%\n",
      "293\tValidation loss: 2.049261\tBest loss: 2.049261\tAccuracy: 47.80%\n",
      "294\tValidation loss: 2.046754\tBest loss: 2.046754\tAccuracy: 47.20%\n",
      "295\tValidation loss: 2.045834\tBest loss: 2.045834\tAccuracy: 47.80%\n",
      "296\tValidation loss: 2.046707\tBest loss: 2.045834\tAccuracy: 47.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\tValidation loss: 2.043751\tBest loss: 2.043751\tAccuracy: 47.50%\n",
      "298\tValidation loss: 2.041671\tBest loss: 2.041671\tAccuracy: 47.70%\n",
      "299\tValidation loss: 2.035708\tBest loss: 2.035708\tAccuracy: 47.50%\n",
      "300\tValidation loss: 2.035756\tBest loss: 2.035708\tAccuracy: 47.70%\n",
      "301\tValidation loss: 2.036547\tBest loss: 2.035708\tAccuracy: 47.60%\n",
      "302\tValidation loss: 2.034153\tBest loss: 2.034153\tAccuracy: 47.80%\n",
      "303\tValidation loss: 2.031935\tBest loss: 2.031935\tAccuracy: 47.50%\n",
      "304\tValidation loss: 2.031844\tBest loss: 2.031844\tAccuracy: 47.60%\n",
      "305\tValidation loss: 2.033144\tBest loss: 2.031844\tAccuracy: 47.20%\n",
      "306\tValidation loss: 2.030664\tBest loss: 2.030664\tAccuracy: 47.50%\n",
      "307\tValidation loss: 2.029424\tBest loss: 2.029424\tAccuracy: 47.20%\n",
      "308\tValidation loss: 2.023287\tBest loss: 2.023287\tAccuracy: 47.40%\n",
      "309\tValidation loss: 2.025608\tBest loss: 2.023287\tAccuracy: 47.30%\n",
      "310\tValidation loss: 2.019009\tBest loss: 2.019009\tAccuracy: 48.20%\n",
      "311\tValidation loss: 2.023082\tBest loss: 2.019009\tAccuracy: 47.60%\n",
      "312\tValidation loss: 2.020802\tBest loss: 2.019009\tAccuracy: 48.60%\n",
      "313\tValidation loss: 2.015231\tBest loss: 2.015231\tAccuracy: 48.50%\n",
      "314\tValidation loss: 2.016582\tBest loss: 2.015231\tAccuracy: 48.50%\n",
      "315\tValidation loss: 2.019880\tBest loss: 2.015231\tAccuracy: 48.90%\n",
      "316\tValidation loss: 2.017055\tBest loss: 2.015231\tAccuracy: 48.70%\n",
      "317\tValidation loss: 2.013538\tBest loss: 2.013538\tAccuracy: 48.70%\n",
      "318\tValidation loss: 2.008647\tBest loss: 2.008647\tAccuracy: 48.30%\n",
      "319\tValidation loss: 2.008232\tBest loss: 2.008232\tAccuracy: 48.40%\n",
      "320\tValidation loss: 2.008884\tBest loss: 2.008232\tAccuracy: 48.70%\n",
      "321\tValidation loss: 2.003127\tBest loss: 2.003127\tAccuracy: 48.20%\n",
      "322\tValidation loss: 2.002805\tBest loss: 2.002805\tAccuracy: 48.60%\n",
      "323\tValidation loss: 2.000995\tBest loss: 2.000995\tAccuracy: 47.50%\n",
      "324\tValidation loss: 2.004673\tBest loss: 2.000995\tAccuracy: 49.00%\n",
      "325\tValidation loss: 2.002455\tBest loss: 2.000995\tAccuracy: 49.00%\n",
      "326\tValidation loss: 1.996405\tBest loss: 1.996405\tAccuracy: 49.20%\n",
      "327\tValidation loss: 1.998350\tBest loss: 1.996405\tAccuracy: 48.40%\n",
      "328\tValidation loss: 1.994499\tBest loss: 1.994499\tAccuracy: 48.20%\n",
      "329\tValidation loss: 1.997175\tBest loss: 1.994499\tAccuracy: 48.90%\n",
      "330\tValidation loss: 1.992780\tBest loss: 1.992780\tAccuracy: 48.70%\n",
      "331\tValidation loss: 1.991183\tBest loss: 1.991183\tAccuracy: 49.00%\n",
      "332\tValidation loss: 1.990492\tBest loss: 1.990492\tAccuracy: 48.40%\n",
      "333\tValidation loss: 1.987102\tBest loss: 1.987102\tAccuracy: 49.30%\n",
      "334\tValidation loss: 1.990122\tBest loss: 1.987102\tAccuracy: 50.00%\n",
      "335\tValidation loss: 1.988490\tBest loss: 1.987102\tAccuracy: 49.10%\n",
      "336\tValidation loss: 1.988312\tBest loss: 1.987102\tAccuracy: 48.70%\n",
      "337\tValidation loss: 1.983724\tBest loss: 1.983724\tAccuracy: 49.10%\n",
      "338\tValidation loss: 1.982481\tBest loss: 1.982481\tAccuracy: 48.80%\n",
      "339\tValidation loss: 1.984946\tBest loss: 1.982481\tAccuracy: 48.70%\n",
      "340\tValidation loss: 1.983391\tBest loss: 1.982481\tAccuracy: 48.90%\n",
      "341\tValidation loss: 1.984061\tBest loss: 1.982481\tAccuracy: 49.10%\n",
      "342\tValidation loss: 1.983571\tBest loss: 1.982481\tAccuracy: 48.80%\n",
      "343\tValidation loss: 1.982279\tBest loss: 1.982279\tAccuracy: 49.60%\n",
      "344\tValidation loss: 1.982381\tBest loss: 1.982279\tAccuracy: 48.90%\n",
      "345\tValidation loss: 1.976552\tBest loss: 1.976552\tAccuracy: 49.80%\n",
      "346\tValidation loss: 1.975662\tBest loss: 1.975662\tAccuracy: 50.30%\n",
      "347\tValidation loss: 1.974046\tBest loss: 1.974046\tAccuracy: 49.60%\n",
      "348\tValidation loss: 1.977848\tBest loss: 1.974046\tAccuracy: 49.70%\n",
      "349\tValidation loss: 1.972362\tBest loss: 1.972362\tAccuracy: 49.90%\n",
      "350\tValidation loss: 1.971376\tBest loss: 1.971376\tAccuracy: 50.20%\n",
      "351\tValidation loss: 1.970793\tBest loss: 1.970793\tAccuracy: 50.30%\n",
      "352\tValidation loss: 1.972174\tBest loss: 1.970793\tAccuracy: 49.50%\n",
      "353\tValidation loss: 1.968196\tBest loss: 1.968196\tAccuracy: 49.50%\n",
      "354\tValidation loss: 1.968497\tBest loss: 1.968196\tAccuracy: 50.30%\n",
      "355\tValidation loss: 1.967964\tBest loss: 1.967964\tAccuracy: 49.40%\n",
      "356\tValidation loss: 1.967489\tBest loss: 1.967489\tAccuracy: 50.10%\n",
      "357\tValidation loss: 1.966355\tBest loss: 1.966355\tAccuracy: 50.60%\n",
      "358\tValidation loss: 1.965646\tBest loss: 1.965646\tAccuracy: 50.10%\n",
      "359\tValidation loss: 1.966074\tBest loss: 1.965646\tAccuracy: 50.90%\n",
      "360\tValidation loss: 1.961919\tBest loss: 1.961919\tAccuracy: 50.30%\n",
      "361\tValidation loss: 1.959217\tBest loss: 1.959217\tAccuracy: 50.40%\n",
      "362\tValidation loss: 1.957613\tBest loss: 1.957613\tAccuracy: 51.30%\n",
      "363\tValidation loss: 1.953243\tBest loss: 1.953243\tAccuracy: 50.10%\n",
      "364\tValidation loss: 1.959438\tBest loss: 1.953243\tAccuracy: 49.90%\n",
      "365\tValidation loss: 1.955084\tBest loss: 1.953243\tAccuracy: 50.30%\n",
      "366\tValidation loss: 1.955941\tBest loss: 1.953243\tAccuracy: 50.40%\n",
      "367\tValidation loss: 1.956754\tBest loss: 1.953243\tAccuracy: 50.10%\n",
      "368\tValidation loss: 1.956463\tBest loss: 1.953243\tAccuracy: 51.50%\n",
      "369\tValidation loss: 1.954373\tBest loss: 1.953243\tAccuracy: 50.00%\n",
      "370\tValidation loss: 1.952569\tBest loss: 1.952569\tAccuracy: 50.40%\n",
      "371\tValidation loss: 1.951293\tBest loss: 1.951293\tAccuracy: 51.00%\n",
      "372\tValidation loss: 1.954209\tBest loss: 1.951293\tAccuracy: 50.30%\n",
      "373\tValidation loss: 1.950667\tBest loss: 1.950667\tAccuracy: 50.10%\n",
      "374\tValidation loss: 1.945889\tBest loss: 1.945889\tAccuracy: 50.00%\n",
      "375\tValidation loss: 1.949254\tBest loss: 1.945889\tAccuracy: 50.80%\n",
      "376\tValidation loss: 1.951706\tBest loss: 1.945889\tAccuracy: 50.90%\n",
      "377\tValidation loss: 1.942622\tBest loss: 1.942622\tAccuracy: 49.90%\n",
      "378\tValidation loss: 1.942086\tBest loss: 1.942086\tAccuracy: 50.60%\n",
      "379\tValidation loss: 1.943343\tBest loss: 1.942086\tAccuracy: 51.50%\n",
      "380\tValidation loss: 1.943644\tBest loss: 1.942086\tAccuracy: 50.70%\n",
      "381\tValidation loss: 1.940389\tBest loss: 1.940389\tAccuracy: 50.40%\n",
      "382\tValidation loss: 1.940871\tBest loss: 1.940389\tAccuracy: 50.60%\n",
      "383\tValidation loss: 1.942920\tBest loss: 1.940389\tAccuracy: 50.90%\n",
      "384\tValidation loss: 1.941533\tBest loss: 1.940389\tAccuracy: 51.00%\n",
      "385\tValidation loss: 1.938857\tBest loss: 1.938857\tAccuracy: 51.40%\n",
      "386\tValidation loss: 1.934912\tBest loss: 1.934912\tAccuracy: 51.10%\n",
      "387\tValidation loss: 1.937255\tBest loss: 1.934912\tAccuracy: 51.00%\n",
      "388\tValidation loss: 1.935581\tBest loss: 1.934912\tAccuracy: 50.90%\n",
      "389\tValidation loss: 1.932558\tBest loss: 1.932558\tAccuracy: 51.50%\n",
      "390\tValidation loss: 1.932365\tBest loss: 1.932365\tAccuracy: 51.10%\n",
      "391\tValidation loss: 1.932087\tBest loss: 1.932087\tAccuracy: 51.10%\n",
      "392\tValidation loss: 1.931274\tBest loss: 1.931274\tAccuracy: 51.70%\n",
      "393\tValidation loss: 1.929823\tBest loss: 1.929823\tAccuracy: 50.80%\n",
      "394\tValidation loss: 1.926718\tBest loss: 1.926718\tAccuracy: 50.90%\n",
      "395\tValidation loss: 1.925968\tBest loss: 1.925968\tAccuracy: 50.60%\n",
      "396\tValidation loss: 1.927121\tBest loss: 1.925968\tAccuracy: 51.50%\n",
      "397\tValidation loss: 1.929436\tBest loss: 1.925968\tAccuracy: 51.20%\n",
      "398\tValidation loss: 1.926185\tBest loss: 1.925968\tAccuracy: 51.60%\n",
      "399\tValidation loss: 1.922951\tBest loss: 1.922951\tAccuracy: 51.50%\n",
      "400\tValidation loss: 1.922129\tBest loss: 1.922129\tAccuracy: 51.70%\n",
      "401\tValidation loss: 1.924215\tBest loss: 1.922129\tAccuracy: 51.70%\n",
      "402\tValidation loss: 1.923555\tBest loss: 1.922129\tAccuracy: 51.80%\n",
      "403\tValidation loss: 1.926420\tBest loss: 1.922129\tAccuracy: 51.40%\n",
      "404\tValidation loss: 1.925221\tBest loss: 1.922129\tAccuracy: 51.30%\n",
      "405\tValidation loss: 1.923227\tBest loss: 1.922129\tAccuracy: 51.80%\n",
      "406\tValidation loss: 1.919501\tBest loss: 1.919501\tAccuracy: 51.30%\n",
      "407\tValidation loss: 1.921129\tBest loss: 1.919501\tAccuracy: 51.60%\n",
      "408\tValidation loss: 1.921394\tBest loss: 1.919501\tAccuracy: 51.20%\n",
      "409\tValidation loss: 1.920465\tBest loss: 1.919501\tAccuracy: 52.00%\n",
      "410\tValidation loss: 1.921054\tBest loss: 1.919501\tAccuracy: 51.70%\n",
      "411\tValidation loss: 1.922862\tBest loss: 1.919501\tAccuracy: 51.60%\n",
      "412\tValidation loss: 1.916970\tBest loss: 1.916970\tAccuracy: 51.40%\n",
      "413\tValidation loss: 1.915687\tBest loss: 1.915687\tAccuracy: 51.60%\n",
      "414\tValidation loss: 1.921405\tBest loss: 1.915687\tAccuracy: 52.60%\n",
      "415\tValidation loss: 1.916990\tBest loss: 1.915687\tAccuracy: 52.20%\n",
      "416\tValidation loss: 1.914541\tBest loss: 1.914541\tAccuracy: 52.40%\n",
      "417\tValidation loss: 1.916610\tBest loss: 1.914541\tAccuracy: 51.70%\n",
      "418\tValidation loss: 1.913489\tBest loss: 1.913489\tAccuracy: 51.50%\n",
      "419\tValidation loss: 1.918175\tBest loss: 1.913489\tAccuracy: 52.10%\n",
      "420\tValidation loss: 1.914011\tBest loss: 1.913489\tAccuracy: 51.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\tValidation loss: 1.917660\tBest loss: 1.913489\tAccuracy: 52.20%\n",
      "422\tValidation loss: 1.912971\tBest loss: 1.912971\tAccuracy: 51.20%\n",
      "423\tValidation loss: 1.913355\tBest loss: 1.912971\tAccuracy: 51.70%\n",
      "424\tValidation loss: 1.914057\tBest loss: 1.912971\tAccuracy: 51.60%\n",
      "425\tValidation loss: 1.909933\tBest loss: 1.909933\tAccuracy: 51.00%\n",
      "426\tValidation loss: 1.909568\tBest loss: 1.909568\tAccuracy: 51.00%\n",
      "427\tValidation loss: 1.907786\tBest loss: 1.907786\tAccuracy: 51.60%\n",
      "428\tValidation loss: 1.910617\tBest loss: 1.907786\tAccuracy: 52.10%\n",
      "429\tValidation loss: 1.909052\tBest loss: 1.907786\tAccuracy: 52.30%\n",
      "430\tValidation loss: 1.909822\tBest loss: 1.907786\tAccuracy: 52.50%\n",
      "431\tValidation loss: 1.909412\tBest loss: 1.907786\tAccuracy: 52.10%\n",
      "432\tValidation loss: 1.905795\tBest loss: 1.905795\tAccuracy: 51.80%\n",
      "433\tValidation loss: 1.904578\tBest loss: 1.904578\tAccuracy: 51.80%\n",
      "434\tValidation loss: 1.904912\tBest loss: 1.904578\tAccuracy: 51.70%\n",
      "435\tValidation loss: 1.907098\tBest loss: 1.904578\tAccuracy: 52.50%\n",
      "436\tValidation loss: 1.902664\tBest loss: 1.902664\tAccuracy: 52.20%\n",
      "437\tValidation loss: 1.901783\tBest loss: 1.901783\tAccuracy: 52.30%\n",
      "438\tValidation loss: 1.898553\tBest loss: 1.898553\tAccuracy: 52.10%\n",
      "439\tValidation loss: 1.902227\tBest loss: 1.898553\tAccuracy: 52.90%\n",
      "440\tValidation loss: 1.898623\tBest loss: 1.898553\tAccuracy: 52.50%\n",
      "441\tValidation loss: 1.898368\tBest loss: 1.898368\tAccuracy: 51.70%\n",
      "442\tValidation loss: 1.901187\tBest loss: 1.898368\tAccuracy: 52.80%\n",
      "443\tValidation loss: 1.898805\tBest loss: 1.898368\tAccuracy: 52.60%\n",
      "444\tValidation loss: 1.899129\tBest loss: 1.898368\tAccuracy: 52.40%\n",
      "445\tValidation loss: 1.895367\tBest loss: 1.895367\tAccuracy: 52.10%\n",
      "446\tValidation loss: 1.894182\tBest loss: 1.894182\tAccuracy: 52.60%\n",
      "447\tValidation loss: 1.896189\tBest loss: 1.894182\tAccuracy: 52.10%\n",
      "448\tValidation loss: 1.896653\tBest loss: 1.894182\tAccuracy: 51.70%\n",
      "449\tValidation loss: 1.895162\tBest loss: 1.894182\tAccuracy: 52.00%\n",
      "450\tValidation loss: 1.894160\tBest loss: 1.894160\tAccuracy: 52.30%\n",
      "451\tValidation loss: 1.891400\tBest loss: 1.891400\tAccuracy: 51.40%\n",
      "452\tValidation loss: 1.890514\tBest loss: 1.890514\tAccuracy: 51.70%\n",
      "453\tValidation loss: 1.889910\tBest loss: 1.889910\tAccuracy: 52.70%\n",
      "454\tValidation loss: 1.890733\tBest loss: 1.889910\tAccuracy: 53.00%\n",
      "455\tValidation loss: 1.892373\tBest loss: 1.889910\tAccuracy: 52.70%\n",
      "456\tValidation loss: 1.891975\tBest loss: 1.889910\tAccuracy: 52.00%\n",
      "457\tValidation loss: 1.892441\tBest loss: 1.889910\tAccuracy: 52.80%\n",
      "458\tValidation loss: 1.887875\tBest loss: 1.887875\tAccuracy: 52.50%\n",
      "459\tValidation loss: 1.888140\tBest loss: 1.887875\tAccuracy: 52.60%\n",
      "460\tValidation loss: 1.891340\tBest loss: 1.887875\tAccuracy: 52.90%\n",
      "461\tValidation loss: 1.890945\tBest loss: 1.887875\tAccuracy: 52.50%\n",
      "462\tValidation loss: 1.885942\tBest loss: 1.885942\tAccuracy: 52.40%\n",
      "463\tValidation loss: 1.886837\tBest loss: 1.885942\tAccuracy: 52.00%\n",
      "464\tValidation loss: 1.885398\tBest loss: 1.885398\tAccuracy: 51.50%\n",
      "465\tValidation loss: 1.886551\tBest loss: 1.885398\tAccuracy: 52.00%\n",
      "466\tValidation loss: 1.888022\tBest loss: 1.885398\tAccuracy: 51.60%\n",
      "467\tValidation loss: 1.887769\tBest loss: 1.885398\tAccuracy: 52.20%\n",
      "468\tValidation loss: 1.882279\tBest loss: 1.882279\tAccuracy: 52.80%\n",
      "469\tValidation loss: 1.879838\tBest loss: 1.879838\tAccuracy: 53.40%\n",
      "470\tValidation loss: 1.877930\tBest loss: 1.877930\tAccuracy: 52.90%\n",
      "471\tValidation loss: 1.878558\tBest loss: 1.877930\tAccuracy: 53.40%\n",
      "472\tValidation loss: 1.878349\tBest loss: 1.877930\tAccuracy: 53.00%\n",
      "473\tValidation loss: 1.877937\tBest loss: 1.877930\tAccuracy: 53.50%\n",
      "474\tValidation loss: 1.878618\tBest loss: 1.877930\tAccuracy: 53.20%\n",
      "475\tValidation loss: 1.876799\tBest loss: 1.876799\tAccuracy: 52.90%\n",
      "476\tValidation loss: 1.877587\tBest loss: 1.876799\tAccuracy: 52.80%\n",
      "477\tValidation loss: 1.875233\tBest loss: 1.875233\tAccuracy: 52.10%\n",
      "478\tValidation loss: 1.875571\tBest loss: 1.875233\tAccuracy: 52.90%\n",
      "479\tValidation loss: 1.878044\tBest loss: 1.875233\tAccuracy: 53.40%\n",
      "480\tValidation loss: 1.876433\tBest loss: 1.875233\tAccuracy: 53.30%\n",
      "481\tValidation loss: 1.877455\tBest loss: 1.875233\tAccuracy: 53.00%\n",
      "482\tValidation loss: 1.877072\tBest loss: 1.875233\tAccuracy: 53.30%\n",
      "483\tValidation loss: 1.877024\tBest loss: 1.875233\tAccuracy: 53.60%\n",
      "484\tValidation loss: 1.872546\tBest loss: 1.872546\tAccuracy: 52.90%\n",
      "485\tValidation loss: 1.872372\tBest loss: 1.872372\tAccuracy: 53.30%\n",
      "486\tValidation loss: 1.873171\tBest loss: 1.872372\tAccuracy: 53.40%\n",
      "487\tValidation loss: 1.875803\tBest loss: 1.872372\tAccuracy: 52.60%\n",
      "488\tValidation loss: 1.874790\tBest loss: 1.872372\tAccuracy: 52.60%\n",
      "489\tValidation loss: 1.876529\tBest loss: 1.872372\tAccuracy: 52.40%\n",
      "490\tValidation loss: 1.871368\tBest loss: 1.871368\tAccuracy: 53.30%\n",
      "491\tValidation loss: 1.870305\tBest loss: 1.870305\tAccuracy: 53.50%\n",
      "492\tValidation loss: 1.865907\tBest loss: 1.865907\tAccuracy: 53.30%\n",
      "493\tValidation loss: 1.865940\tBest loss: 1.865907\tAccuracy: 53.40%\n",
      "494\tValidation loss: 1.865760\tBest loss: 1.865760\tAccuracy: 53.80%\n",
      "495\tValidation loss: 1.864961\tBest loss: 1.864961\tAccuracy: 53.50%\n",
      "496\tValidation loss: 1.866014\tBest loss: 1.864961\tAccuracy: 53.30%\n",
      "497\tValidation loss: 1.866636\tBest loss: 1.864961\tAccuracy: 53.90%\n",
      "498\tValidation loss: 1.867936\tBest loss: 1.864961\tAccuracy: 53.30%\n",
      "499\tValidation loss: 1.863329\tBest loss: 1.863329\tAccuracy: 53.40%\n",
      "500\tValidation loss: 1.865891\tBest loss: 1.863329\tAccuracy: 52.90%\n",
      "501\tValidation loss: 1.866688\tBest loss: 1.863329\tAccuracy: 52.90%\n",
      "502\tValidation loss: 1.863278\tBest loss: 1.863278\tAccuracy: 53.30%\n",
      "503\tValidation loss: 1.864004\tBest loss: 1.863278\tAccuracy: 53.10%\n",
      "504\tValidation loss: 1.862033\tBest loss: 1.862033\tAccuracy: 53.60%\n",
      "505\tValidation loss: 1.860779\tBest loss: 1.860779\tAccuracy: 53.80%\n",
      "506\tValidation loss: 1.861168\tBest loss: 1.860779\tAccuracy: 53.80%\n",
      "507\tValidation loss: 1.859686\tBest loss: 1.859686\tAccuracy: 53.10%\n",
      "508\tValidation loss: 1.858190\tBest loss: 1.858190\tAccuracy: 53.30%\n",
      "509\tValidation loss: 1.861734\tBest loss: 1.858190\tAccuracy: 53.00%\n",
      "510\tValidation loss: 1.860871\tBest loss: 1.858190\tAccuracy: 52.70%\n",
      "511\tValidation loss: 1.861240\tBest loss: 1.858190\tAccuracy: 53.20%\n",
      "512\tValidation loss: 1.860098\tBest loss: 1.858190\tAccuracy: 53.20%\n",
      "513\tValidation loss: 1.857734\tBest loss: 1.857734\tAccuracy: 53.70%\n",
      "514\tValidation loss: 1.860147\tBest loss: 1.857734\tAccuracy: 53.30%\n",
      "515\tValidation loss: 1.859823\tBest loss: 1.857734\tAccuracy: 52.80%\n",
      "516\tValidation loss: 1.859400\tBest loss: 1.857734\tAccuracy: 53.00%\n",
      "517\tValidation loss: 1.856861\tBest loss: 1.856861\tAccuracy: 52.50%\n",
      "518\tValidation loss: 1.858277\tBest loss: 1.856861\tAccuracy: 53.10%\n",
      "519\tValidation loss: 1.857746\tBest loss: 1.856861\tAccuracy: 52.80%\n",
      "520\tValidation loss: 1.859896\tBest loss: 1.856861\tAccuracy: 52.80%\n",
      "521\tValidation loss: 1.858838\tBest loss: 1.856861\tAccuracy: 52.90%\n",
      "522\tValidation loss: 1.856727\tBest loss: 1.856727\tAccuracy: 53.00%\n",
      "523\tValidation loss: 1.856351\tBest loss: 1.856351\tAccuracy: 53.70%\n",
      "524\tValidation loss: 1.855798\tBest loss: 1.855798\tAccuracy: 53.20%\n",
      "525\tValidation loss: 1.856362\tBest loss: 1.855798\tAccuracy: 53.30%\n",
      "526\tValidation loss: 1.854508\tBest loss: 1.854508\tAccuracy: 53.60%\n",
      "527\tValidation loss: 1.859033\tBest loss: 1.854508\tAccuracy: 53.40%\n",
      "528\tValidation loss: 1.853486\tBest loss: 1.853486\tAccuracy: 53.60%\n",
      "529\tValidation loss: 1.851854\tBest loss: 1.851854\tAccuracy: 53.30%\n",
      "530\tValidation loss: 1.855456\tBest loss: 1.851854\tAccuracy: 53.20%\n",
      "531\tValidation loss: 1.852446\tBest loss: 1.851854\tAccuracy: 53.10%\n",
      "532\tValidation loss: 1.854972\tBest loss: 1.851854\tAccuracy: 53.30%\n",
      "533\tValidation loss: 1.850752\tBest loss: 1.850752\tAccuracy: 52.90%\n",
      "534\tValidation loss: 1.849095\tBest loss: 1.849095\tAccuracy: 53.00%\n",
      "535\tValidation loss: 1.846614\tBest loss: 1.846614\tAccuracy: 53.10%\n",
      "536\tValidation loss: 1.847161\tBest loss: 1.846614\tAccuracy: 53.70%\n",
      "537\tValidation loss: 1.845837\tBest loss: 1.845837\tAccuracy: 52.60%\n",
      "538\tValidation loss: 1.846018\tBest loss: 1.845837\tAccuracy: 53.40%\n",
      "539\tValidation loss: 1.849171\tBest loss: 1.845837\tAccuracy: 53.20%\n",
      "540\tValidation loss: 1.846978\tBest loss: 1.845837\tAccuracy: 53.30%\n",
      "541\tValidation loss: 1.846441\tBest loss: 1.845837\tAccuracy: 53.30%\n",
      "542\tValidation loss: 1.844655\tBest loss: 1.844655\tAccuracy: 53.40%\n",
      "543\tValidation loss: 1.850163\tBest loss: 1.844655\tAccuracy: 53.50%\n",
      "544\tValidation loss: 1.847178\tBest loss: 1.844655\tAccuracy: 53.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\tValidation loss: 1.849750\tBest loss: 1.844655\tAccuracy: 53.40%\n",
      "546\tValidation loss: 1.848579\tBest loss: 1.844655\tAccuracy: 53.40%\n",
      "547\tValidation loss: 1.846518\tBest loss: 1.844655\tAccuracy: 53.30%\n",
      "548\tValidation loss: 1.844076\tBest loss: 1.844076\tAccuracy: 53.10%\n",
      "549\tValidation loss: 1.842885\tBest loss: 1.842885\tAccuracy: 53.80%\n",
      "550\tValidation loss: 1.841306\tBest loss: 1.841306\tAccuracy: 53.70%\n",
      "551\tValidation loss: 1.843250\tBest loss: 1.841306\tAccuracy: 54.00%\n",
      "552\tValidation loss: 1.844551\tBest loss: 1.841306\tAccuracy: 54.00%\n",
      "553\tValidation loss: 1.842982\tBest loss: 1.841306\tAccuracy: 53.80%\n",
      "554\tValidation loss: 1.844870\tBest loss: 1.841306\tAccuracy: 54.10%\n",
      "555\tValidation loss: 1.843582\tBest loss: 1.841306\tAccuracy: 54.20%\n",
      "556\tValidation loss: 1.843899\tBest loss: 1.841306\tAccuracy: 54.40%\n",
      "557\tValidation loss: 1.841846\tBest loss: 1.841306\tAccuracy: 53.80%\n",
      "558\tValidation loss: 1.840906\tBest loss: 1.840906\tAccuracy: 54.20%\n",
      "559\tValidation loss: 1.838781\tBest loss: 1.838781\tAccuracy: 54.10%\n",
      "560\tValidation loss: 1.836222\tBest loss: 1.836222\tAccuracy: 53.50%\n",
      "561\tValidation loss: 1.838407\tBest loss: 1.836222\tAccuracy: 54.00%\n",
      "562\tValidation loss: 1.837889\tBest loss: 1.836222\tAccuracy: 53.50%\n",
      "563\tValidation loss: 1.837675\tBest loss: 1.836222\tAccuracy: 53.30%\n",
      "564\tValidation loss: 1.838240\tBest loss: 1.836222\tAccuracy: 54.30%\n",
      "565\tValidation loss: 1.840032\tBest loss: 1.836222\tAccuracy: 54.10%\n",
      "566\tValidation loss: 1.838559\tBest loss: 1.836222\tAccuracy: 53.30%\n",
      "567\tValidation loss: 1.838147\tBest loss: 1.836222\tAccuracy: 53.90%\n",
      "568\tValidation loss: 1.838351\tBest loss: 1.836222\tAccuracy: 53.90%\n",
      "569\tValidation loss: 1.835942\tBest loss: 1.835942\tAccuracy: 53.50%\n",
      "570\tValidation loss: 1.835672\tBest loss: 1.835672\tAccuracy: 53.90%\n",
      "571\tValidation loss: 1.837166\tBest loss: 1.835672\tAccuracy: 54.30%\n",
      "572\tValidation loss: 1.834030\tBest loss: 1.834030\tAccuracy: 53.80%\n",
      "573\tValidation loss: 1.836537\tBest loss: 1.834030\tAccuracy: 54.30%\n",
      "574\tValidation loss: 1.835666\tBest loss: 1.834030\tAccuracy: 54.40%\n",
      "575\tValidation loss: 1.835887\tBest loss: 1.834030\tAccuracy: 53.70%\n",
      "576\tValidation loss: 1.834038\tBest loss: 1.834030\tAccuracy: 54.00%\n",
      "577\tValidation loss: 1.834510\tBest loss: 1.834030\tAccuracy: 53.80%\n",
      "578\tValidation loss: 1.834640\tBest loss: 1.834030\tAccuracy: 53.90%\n",
      "579\tValidation loss: 1.831042\tBest loss: 1.831042\tAccuracy: 53.40%\n",
      "580\tValidation loss: 1.833024\tBest loss: 1.831042\tAccuracy: 53.50%\n",
      "581\tValidation loss: 1.832557\tBest loss: 1.831042\tAccuracy: 53.50%\n",
      "582\tValidation loss: 1.830446\tBest loss: 1.830446\tAccuracy: 53.60%\n",
      "583\tValidation loss: 1.830510\tBest loss: 1.830446\tAccuracy: 53.60%\n",
      "584\tValidation loss: 1.831950\tBest loss: 1.830446\tAccuracy: 54.20%\n",
      "585\tValidation loss: 1.829326\tBest loss: 1.829326\tAccuracy: 53.90%\n",
      "586\tValidation loss: 1.831548\tBest loss: 1.829326\tAccuracy: 54.00%\n",
      "587\tValidation loss: 1.829065\tBest loss: 1.829065\tAccuracy: 53.80%\n",
      "588\tValidation loss: 1.831114\tBest loss: 1.829065\tAccuracy: 54.40%\n",
      "589\tValidation loss: 1.829738\tBest loss: 1.829065\tAccuracy: 54.20%\n",
      "590\tValidation loss: 1.827399\tBest loss: 1.827399\tAccuracy: 53.80%\n",
      "591\tValidation loss: 1.826255\tBest loss: 1.826255\tAccuracy: 54.10%\n",
      "592\tValidation loss: 1.824600\tBest loss: 1.824600\tAccuracy: 54.00%\n",
      "593\tValidation loss: 1.826940\tBest loss: 1.824600\tAccuracy: 54.10%\n",
      "594\tValidation loss: 1.826107\tBest loss: 1.824600\tAccuracy: 54.20%\n",
      "595\tValidation loss: 1.827538\tBest loss: 1.824600\tAccuracy: 53.80%\n",
      "596\tValidation loss: 1.827927\tBest loss: 1.824600\tAccuracy: 53.70%\n",
      "597\tValidation loss: 1.827489\tBest loss: 1.824600\tAccuracy: 53.90%\n",
      "598\tValidation loss: 1.824492\tBest loss: 1.824492\tAccuracy: 53.90%\n",
      "599\tValidation loss: 1.826084\tBest loss: 1.824492\tAccuracy: 54.20%\n",
      "600\tValidation loss: 1.828260\tBest loss: 1.824492\tAccuracy: 54.30%\n",
      "601\tValidation loss: 1.823864\tBest loss: 1.823864\tAccuracy: 54.10%\n",
      "602\tValidation loss: 1.823645\tBest loss: 1.823645\tAccuracy: 53.80%\n",
      "603\tValidation loss: 1.826251\tBest loss: 1.823645\tAccuracy: 54.00%\n",
      "604\tValidation loss: 1.824460\tBest loss: 1.823645\tAccuracy: 54.10%\n",
      "605\tValidation loss: 1.822405\tBest loss: 1.822405\tAccuracy: 54.00%\n",
      "606\tValidation loss: 1.823947\tBest loss: 1.822405\tAccuracy: 53.90%\n",
      "607\tValidation loss: 1.824963\tBest loss: 1.822405\tAccuracy: 54.30%\n",
      "608\tValidation loss: 1.821713\tBest loss: 1.821713\tAccuracy: 54.30%\n",
      "609\tValidation loss: 1.822593\tBest loss: 1.821713\tAccuracy: 54.40%\n",
      "610\tValidation loss: 1.823504\tBest loss: 1.821713\tAccuracy: 53.90%\n",
      "611\tValidation loss: 1.820776\tBest loss: 1.820776\tAccuracy: 54.70%\n",
      "612\tValidation loss: 1.819890\tBest loss: 1.819890\tAccuracy: 54.00%\n",
      "613\tValidation loss: 1.818216\tBest loss: 1.818216\tAccuracy: 54.40%\n",
      "614\tValidation loss: 1.817934\tBest loss: 1.817934\tAccuracy: 54.20%\n",
      "615\tValidation loss: 1.816300\tBest loss: 1.816300\tAccuracy: 54.30%\n",
      "616\tValidation loss: 1.820386\tBest loss: 1.816300\tAccuracy: 54.10%\n",
      "617\tValidation loss: 1.818391\tBest loss: 1.816300\tAccuracy: 53.90%\n",
      "618\tValidation loss: 1.817440\tBest loss: 1.816300\tAccuracy: 54.50%\n",
      "619\tValidation loss: 1.819429\tBest loss: 1.816300\tAccuracy: 54.10%\n",
      "620\tValidation loss: 1.816589\tBest loss: 1.816300\tAccuracy: 54.70%\n",
      "621\tValidation loss: 1.818628\tBest loss: 1.816300\tAccuracy: 54.70%\n",
      "622\tValidation loss: 1.817610\tBest loss: 1.816300\tAccuracy: 54.70%\n",
      "623\tValidation loss: 1.816071\tBest loss: 1.816071\tAccuracy: 54.40%\n",
      "624\tValidation loss: 1.815435\tBest loss: 1.815435\tAccuracy: 54.70%\n",
      "625\tValidation loss: 1.814784\tBest loss: 1.814784\tAccuracy: 54.50%\n",
      "626\tValidation loss: 1.815472\tBest loss: 1.814784\tAccuracy: 54.90%\n",
      "627\tValidation loss: 1.813766\tBest loss: 1.813766\tAccuracy: 55.00%\n",
      "628\tValidation loss: 1.812973\tBest loss: 1.812973\tAccuracy: 54.90%\n",
      "629\tValidation loss: 1.812485\tBest loss: 1.812485\tAccuracy: 54.60%\n",
      "630\tValidation loss: 1.813049\tBest loss: 1.812485\tAccuracy: 55.40%\n",
      "631\tValidation loss: 1.813612\tBest loss: 1.812485\tAccuracy: 54.80%\n",
      "632\tValidation loss: 1.812819\tBest loss: 1.812485\tAccuracy: 54.60%\n",
      "633\tValidation loss: 1.816513\tBest loss: 1.812485\tAccuracy: 54.80%\n",
      "634\tValidation loss: 1.814788\tBest loss: 1.812485\tAccuracy: 54.60%\n",
      "635\tValidation loss: 1.815472\tBest loss: 1.812485\tAccuracy: 55.00%\n",
      "636\tValidation loss: 1.815483\tBest loss: 1.812485\tAccuracy: 54.50%\n",
      "637\tValidation loss: 1.813486\tBest loss: 1.812485\tAccuracy: 54.70%\n",
      "638\tValidation loss: 1.814214\tBest loss: 1.812485\tAccuracy: 54.50%\n",
      "639\tValidation loss: 1.812945\tBest loss: 1.812485\tAccuracy: 54.50%\n",
      "640\tValidation loss: 1.815070\tBest loss: 1.812485\tAccuracy: 54.20%\n",
      "641\tValidation loss: 1.815487\tBest loss: 1.812485\tAccuracy: 54.70%\n",
      "642\tValidation loss: 1.814236\tBest loss: 1.812485\tAccuracy: 54.60%\n",
      "643\tValidation loss: 1.810507\tBest loss: 1.810507\tAccuracy: 54.10%\n",
      "644\tValidation loss: 1.811367\tBest loss: 1.810507\tAccuracy: 54.80%\n",
      "645\tValidation loss: 1.809885\tBest loss: 1.809885\tAccuracy: 54.50%\n",
      "646\tValidation loss: 1.811803\tBest loss: 1.809885\tAccuracy: 55.30%\n",
      "647\tValidation loss: 1.808906\tBest loss: 1.808906\tAccuracy: 54.40%\n",
      "648\tValidation loss: 1.809064\tBest loss: 1.808906\tAccuracy: 54.10%\n",
      "649\tValidation loss: 1.809908\tBest loss: 1.808906\tAccuracy: 54.50%\n",
      "650\tValidation loss: 1.811165\tBest loss: 1.808906\tAccuracy: 54.80%\n",
      "651\tValidation loss: 1.809152\tBest loss: 1.808906\tAccuracy: 54.70%\n",
      "652\tValidation loss: 1.809343\tBest loss: 1.808906\tAccuracy: 54.50%\n",
      "653\tValidation loss: 1.807836\tBest loss: 1.807836\tAccuracy: 54.80%\n",
      "654\tValidation loss: 1.807478\tBest loss: 1.807478\tAccuracy: 55.20%\n",
      "655\tValidation loss: 1.808264\tBest loss: 1.807478\tAccuracy: 55.10%\n",
      "656\tValidation loss: 1.808742\tBest loss: 1.807478\tAccuracy: 55.10%\n",
      "657\tValidation loss: 1.809422\tBest loss: 1.807478\tAccuracy: 54.50%\n",
      "658\tValidation loss: 1.809186\tBest loss: 1.807478\tAccuracy: 54.70%\n",
      "659\tValidation loss: 1.807972\tBest loss: 1.807478\tAccuracy: 55.00%\n",
      "660\tValidation loss: 1.808893\tBest loss: 1.807478\tAccuracy: 55.00%\n",
      "661\tValidation loss: 1.807511\tBest loss: 1.807478\tAccuracy: 54.90%\n",
      "662\tValidation loss: 1.810497\tBest loss: 1.807478\tAccuracy: 54.60%\n",
      "663\tValidation loss: 1.808861\tBest loss: 1.807478\tAccuracy: 54.60%\n",
      "664\tValidation loss: 1.811239\tBest loss: 1.807478\tAccuracy: 55.20%\n",
      "665\tValidation loss: 1.808967\tBest loss: 1.807478\tAccuracy: 54.80%\n",
      "666\tValidation loss: 1.805805\tBest loss: 1.805805\tAccuracy: 54.50%\n",
      "667\tValidation loss: 1.808115\tBest loss: 1.805805\tAccuracy: 54.60%\n",
      "668\tValidation loss: 1.808310\tBest loss: 1.805805\tAccuracy: 54.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\tValidation loss: 1.805706\tBest loss: 1.805706\tAccuracy: 55.00%\n",
      "670\tValidation loss: 1.806611\tBest loss: 1.805706\tAccuracy: 54.80%\n",
      "671\tValidation loss: 1.806326\tBest loss: 1.805706\tAccuracy: 55.20%\n",
      "672\tValidation loss: 1.803270\tBest loss: 1.803270\tAccuracy: 54.80%\n",
      "673\tValidation loss: 1.805235\tBest loss: 1.803270\tAccuracy: 54.70%\n",
      "674\tValidation loss: 1.805092\tBest loss: 1.803270\tAccuracy: 54.80%\n",
      "675\tValidation loss: 1.805558\tBest loss: 1.803270\tAccuracy: 54.80%\n",
      "676\tValidation loss: 1.803498\tBest loss: 1.803270\tAccuracy: 55.20%\n",
      "677\tValidation loss: 1.805038\tBest loss: 1.803270\tAccuracy: 55.40%\n",
      "678\tValidation loss: 1.802632\tBest loss: 1.802632\tAccuracy: 54.90%\n",
      "679\tValidation loss: 1.801459\tBest loss: 1.801459\tAccuracy: 55.30%\n",
      "680\tValidation loss: 1.799509\tBest loss: 1.799509\tAccuracy: 55.00%\n",
      "681\tValidation loss: 1.800165\tBest loss: 1.799509\tAccuracy: 54.60%\n",
      "682\tValidation loss: 1.801011\tBest loss: 1.799509\tAccuracy: 54.90%\n",
      "683\tValidation loss: 1.800477\tBest loss: 1.799509\tAccuracy: 54.50%\n",
      "684\tValidation loss: 1.800241\tBest loss: 1.799509\tAccuracy: 55.10%\n",
      "685\tValidation loss: 1.799162\tBest loss: 1.799162\tAccuracy: 54.80%\n",
      "686\tValidation loss: 1.798530\tBest loss: 1.798530\tAccuracy: 54.70%\n",
      "687\tValidation loss: 1.799986\tBest loss: 1.798530\tAccuracy: 54.60%\n",
      "688\tValidation loss: 1.798124\tBest loss: 1.798124\tAccuracy: 54.90%\n",
      "689\tValidation loss: 1.799827\tBest loss: 1.798124\tAccuracy: 55.40%\n",
      "690\tValidation loss: 1.798890\tBest loss: 1.798124\tAccuracy: 54.80%\n",
      "691\tValidation loss: 1.799162\tBest loss: 1.798124\tAccuracy: 55.30%\n",
      "692\tValidation loss: 1.797522\tBest loss: 1.797522\tAccuracy: 54.80%\n",
      "693\tValidation loss: 1.798558\tBest loss: 1.797522\tAccuracy: 55.20%\n",
      "694\tValidation loss: 1.799858\tBest loss: 1.797522\tAccuracy: 54.80%\n",
      "695\tValidation loss: 1.800488\tBest loss: 1.797522\tAccuracy: 55.30%\n",
      "696\tValidation loss: 1.798140\tBest loss: 1.797522\tAccuracy: 55.30%\n",
      "697\tValidation loss: 1.797068\tBest loss: 1.797068\tAccuracy: 54.70%\n",
      "698\tValidation loss: 1.798280\tBest loss: 1.797068\tAccuracy: 55.10%\n",
      "699\tValidation loss: 1.795961\tBest loss: 1.795961\tAccuracy: 55.40%\n",
      "700\tValidation loss: 1.794770\tBest loss: 1.794770\tAccuracy: 54.80%\n",
      "701\tValidation loss: 1.796566\tBest loss: 1.794770\tAccuracy: 55.60%\n",
      "702\tValidation loss: 1.792624\tBest loss: 1.792624\tAccuracy: 55.40%\n",
      "703\tValidation loss: 1.796562\tBest loss: 1.792624\tAccuracy: 55.60%\n",
      "704\tValidation loss: 1.795919\tBest loss: 1.792624\tAccuracy: 55.20%\n",
      "705\tValidation loss: 1.793445\tBest loss: 1.792624\tAccuracy: 55.10%\n",
      "706\tValidation loss: 1.794325\tBest loss: 1.792624\tAccuracy: 55.20%\n",
      "707\tValidation loss: 1.794738\tBest loss: 1.792624\tAccuracy: 55.50%\n",
      "708\tValidation loss: 1.792945\tBest loss: 1.792624\tAccuracy: 55.40%\n",
      "709\tValidation loss: 1.795411\tBest loss: 1.792624\tAccuracy: 55.30%\n",
      "710\tValidation loss: 1.794357\tBest loss: 1.792624\tAccuracy: 55.30%\n",
      "711\tValidation loss: 1.795200\tBest loss: 1.792624\tAccuracy: 55.20%\n",
      "712\tValidation loss: 1.794826\tBest loss: 1.792624\tAccuracy: 55.40%\n",
      "713\tValidation loss: 1.795891\tBest loss: 1.792624\tAccuracy: 55.30%\n",
      "714\tValidation loss: 1.792201\tBest loss: 1.792201\tAccuracy: 55.10%\n",
      "715\tValidation loss: 1.793202\tBest loss: 1.792201\tAccuracy: 54.80%\n",
      "716\tValidation loss: 1.794299\tBest loss: 1.792201\tAccuracy: 55.30%\n",
      "717\tValidation loss: 1.793439\tBest loss: 1.792201\tAccuracy: 55.40%\n",
      "718\tValidation loss: 1.794379\tBest loss: 1.792201\tAccuracy: 55.30%\n",
      "719\tValidation loss: 1.794939\tBest loss: 1.792201\tAccuracy: 55.20%\n",
      "720\tValidation loss: 1.797034\tBest loss: 1.792201\tAccuracy: 54.90%\n",
      "721\tValidation loss: 1.794682\tBest loss: 1.792201\tAccuracy: 54.80%\n",
      "722\tValidation loss: 1.790182\tBest loss: 1.790182\tAccuracy: 54.70%\n",
      "723\tValidation loss: 1.790524\tBest loss: 1.790182\tAccuracy: 55.40%\n",
      "724\tValidation loss: 1.792608\tBest loss: 1.790182\tAccuracy: 54.90%\n",
      "725\tValidation loss: 1.790596\tBest loss: 1.790182\tAccuracy: 55.20%\n",
      "726\tValidation loss: 1.790967\tBest loss: 1.790182\tAccuracy: 54.50%\n",
      "727\tValidation loss: 1.791027\tBest loss: 1.790182\tAccuracy: 55.30%\n",
      "728\tValidation loss: 1.791350\tBest loss: 1.790182\tAccuracy: 55.00%\n",
      "729\tValidation loss: 1.788194\tBest loss: 1.788194\tAccuracy: 54.80%\n",
      "730\tValidation loss: 1.791226\tBest loss: 1.788194\tAccuracy: 55.00%\n",
      "731\tValidation loss: 1.790566\tBest loss: 1.788194\tAccuracy: 55.30%\n",
      "732\tValidation loss: 1.787692\tBest loss: 1.787692\tAccuracy: 55.30%\n",
      "733\tValidation loss: 1.787164\tBest loss: 1.787164\tAccuracy: 55.40%\n",
      "734\tValidation loss: 1.784043\tBest loss: 1.784043\tAccuracy: 55.10%\n",
      "735\tValidation loss: 1.784649\tBest loss: 1.784043\tAccuracy: 54.90%\n",
      "736\tValidation loss: 1.786570\tBest loss: 1.784043\tAccuracy: 54.70%\n",
      "737\tValidation loss: 1.790348\tBest loss: 1.784043\tAccuracy: 55.20%\n",
      "738\tValidation loss: 1.784068\tBest loss: 1.784043\tAccuracy: 55.20%\n",
      "739\tValidation loss: 1.785884\tBest loss: 1.784043\tAccuracy: 55.30%\n",
      "740\tValidation loss: 1.789581\tBest loss: 1.784043\tAccuracy: 55.60%\n",
      "741\tValidation loss: 1.787689\tBest loss: 1.784043\tAccuracy: 54.80%\n",
      "742\tValidation loss: 1.785098\tBest loss: 1.784043\tAccuracy: 55.50%\n",
      "743\tValidation loss: 1.783314\tBest loss: 1.783314\tAccuracy: 55.90%\n",
      "744\tValidation loss: 1.784214\tBest loss: 1.783314\tAccuracy: 55.10%\n",
      "745\tValidation loss: 1.782943\tBest loss: 1.782943\tAccuracy: 54.80%\n",
      "746\tValidation loss: 1.783184\tBest loss: 1.782943\tAccuracy: 55.50%\n",
      "747\tValidation loss: 1.781518\tBest loss: 1.781518\tAccuracy: 55.50%\n",
      "748\tValidation loss: 1.784401\tBest loss: 1.781518\tAccuracy: 55.40%\n",
      "749\tValidation loss: 1.782675\tBest loss: 1.781518\tAccuracy: 55.20%\n",
      "750\tValidation loss: 1.783169\tBest loss: 1.781518\tAccuracy: 55.20%\n",
      "751\tValidation loss: 1.782726\tBest loss: 1.781518\tAccuracy: 54.80%\n",
      "752\tValidation loss: 1.780306\tBest loss: 1.780306\tAccuracy: 55.00%\n",
      "753\tValidation loss: 1.783305\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "754\tValidation loss: 1.781928\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "755\tValidation loss: 1.783283\tBest loss: 1.780306\tAccuracy: 54.90%\n",
      "756\tValidation loss: 1.785174\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "757\tValidation loss: 1.782466\tBest loss: 1.780306\tAccuracy: 55.00%\n",
      "758\tValidation loss: 1.782574\tBest loss: 1.780306\tAccuracy: 54.90%\n",
      "759\tValidation loss: 1.783711\tBest loss: 1.780306\tAccuracy: 54.20%\n",
      "760\tValidation loss: 1.782534\tBest loss: 1.780306\tAccuracy: 55.40%\n",
      "761\tValidation loss: 1.785023\tBest loss: 1.780306\tAccuracy: 54.90%\n",
      "762\tValidation loss: 1.782537\tBest loss: 1.780306\tAccuracy: 54.90%\n",
      "763\tValidation loss: 1.785431\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "764\tValidation loss: 1.782484\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "765\tValidation loss: 1.782367\tBest loss: 1.780306\tAccuracy: 55.00%\n",
      "766\tValidation loss: 1.780368\tBest loss: 1.780306\tAccuracy: 54.60%\n",
      "767\tValidation loss: 1.780568\tBest loss: 1.780306\tAccuracy: 55.10%\n",
      "768\tValidation loss: 1.778452\tBest loss: 1.778452\tAccuracy: 54.90%\n",
      "769\tValidation loss: 1.780417\tBest loss: 1.778452\tAccuracy: 55.50%\n",
      "770\tValidation loss: 1.777853\tBest loss: 1.777853\tAccuracy: 55.40%\n",
      "771\tValidation loss: 1.779349\tBest loss: 1.777853\tAccuracy: 55.50%\n",
      "772\tValidation loss: 1.779440\tBest loss: 1.777853\tAccuracy: 55.40%\n",
      "773\tValidation loss: 1.779812\tBest loss: 1.777853\tAccuracy: 55.30%\n",
      "774\tValidation loss: 1.778740\tBest loss: 1.777853\tAccuracy: 55.40%\n",
      "775\tValidation loss: 1.778368\tBest loss: 1.777853\tAccuracy: 55.80%\n",
      "776\tValidation loss: 1.778845\tBest loss: 1.777853\tAccuracy: 55.60%\n",
      "777\tValidation loss: 1.776899\tBest loss: 1.776899\tAccuracy: 55.50%\n",
      "778\tValidation loss: 1.776156\tBest loss: 1.776156\tAccuracy: 55.10%\n",
      "779\tValidation loss: 1.778032\tBest loss: 1.776156\tAccuracy: 55.40%\n",
      "780\tValidation loss: 1.780474\tBest loss: 1.776156\tAccuracy: 55.80%\n",
      "781\tValidation loss: 1.777581\tBest loss: 1.776156\tAccuracy: 55.60%\n",
      "782\tValidation loss: 1.776681\tBest loss: 1.776156\tAccuracy: 55.70%\n",
      "783\tValidation loss: 1.776141\tBest loss: 1.776141\tAccuracy: 55.70%\n",
      "784\tValidation loss: 1.775421\tBest loss: 1.775421\tAccuracy: 55.60%\n",
      "785\tValidation loss: 1.776958\tBest loss: 1.775421\tAccuracy: 55.70%\n",
      "786\tValidation loss: 1.779683\tBest loss: 1.775421\tAccuracy: 55.60%\n",
      "787\tValidation loss: 1.779801\tBest loss: 1.775421\tAccuracy: 55.60%\n",
      "788\tValidation loss: 1.776936\tBest loss: 1.775421\tAccuracy: 55.40%\n",
      "789\tValidation loss: 1.774515\tBest loss: 1.774515\tAccuracy: 55.80%\n",
      "790\tValidation loss: 1.771615\tBest loss: 1.771615\tAccuracy: 55.30%\n",
      "791\tValidation loss: 1.772988\tBest loss: 1.771615\tAccuracy: 54.80%\n",
      "792\tValidation loss: 1.772715\tBest loss: 1.771615\tAccuracy: 55.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793\tValidation loss: 1.772133\tBest loss: 1.771615\tAccuracy: 55.00%\n",
      "794\tValidation loss: 1.771495\tBest loss: 1.771495\tAccuracy: 55.20%\n",
      "795\tValidation loss: 1.771292\tBest loss: 1.771292\tAccuracy: 54.70%\n",
      "796\tValidation loss: 1.772102\tBest loss: 1.771292\tAccuracy: 54.80%\n",
      "797\tValidation loss: 1.771929\tBest loss: 1.771292\tAccuracy: 54.90%\n",
      "798\tValidation loss: 1.772336\tBest loss: 1.771292\tAccuracy: 55.10%\n",
      "799\tValidation loss: 1.773691\tBest loss: 1.771292\tAccuracy: 55.40%\n",
      "800\tValidation loss: 1.774618\tBest loss: 1.771292\tAccuracy: 55.30%\n",
      "801\tValidation loss: 1.775069\tBest loss: 1.771292\tAccuracy: 55.60%\n",
      "802\tValidation loss: 1.773305\tBest loss: 1.771292\tAccuracy: 55.10%\n",
      "803\tValidation loss: 1.770668\tBest loss: 1.770668\tAccuracy: 55.30%\n",
      "804\tValidation loss: 1.772283\tBest loss: 1.770668\tAccuracy: 55.40%\n",
      "805\tValidation loss: 1.769768\tBest loss: 1.769768\tAccuracy: 55.20%\n",
      "806\tValidation loss: 1.768996\tBest loss: 1.768996\tAccuracy: 55.20%\n",
      "807\tValidation loss: 1.771552\tBest loss: 1.768996\tAccuracy: 55.20%\n",
      "808\tValidation loss: 1.771878\tBest loss: 1.768996\tAccuracy: 54.80%\n",
      "809\tValidation loss: 1.770143\tBest loss: 1.768996\tAccuracy: 55.30%\n",
      "810\tValidation loss: 1.769458\tBest loss: 1.768996\tAccuracy: 55.60%\n",
      "811\tValidation loss: 1.768043\tBest loss: 1.768043\tAccuracy: 55.70%\n",
      "812\tValidation loss: 1.768597\tBest loss: 1.768043\tAccuracy: 55.90%\n",
      "813\tValidation loss: 1.769658\tBest loss: 1.768043\tAccuracy: 55.40%\n",
      "814\tValidation loss: 1.766269\tBest loss: 1.766269\tAccuracy: 55.30%\n",
      "815\tValidation loss: 1.766742\tBest loss: 1.766269\tAccuracy: 55.60%\n",
      "816\tValidation loss: 1.767837\tBest loss: 1.766269\tAccuracy: 55.20%\n",
      "817\tValidation loss: 1.764390\tBest loss: 1.764390\tAccuracy: 55.50%\n",
      "818\tValidation loss: 1.764669\tBest loss: 1.764390\tAccuracy: 55.40%\n",
      "819\tValidation loss: 1.763823\tBest loss: 1.763823\tAccuracy: 55.30%\n",
      "820\tValidation loss: 1.764972\tBest loss: 1.763823\tAccuracy: 55.60%\n",
      "821\tValidation loss: 1.765591\tBest loss: 1.763823\tAccuracy: 55.80%\n",
      "822\tValidation loss: 1.766810\tBest loss: 1.763823\tAccuracy: 55.60%\n",
      "823\tValidation loss: 1.766691\tBest loss: 1.763823\tAccuracy: 55.50%\n",
      "824\tValidation loss: 1.767199\tBest loss: 1.763823\tAccuracy: 55.70%\n",
      "825\tValidation loss: 1.765706\tBest loss: 1.763823\tAccuracy: 55.60%\n",
      "826\tValidation loss: 1.762738\tBest loss: 1.762738\tAccuracy: 55.30%\n",
      "827\tValidation loss: 1.762555\tBest loss: 1.762555\tAccuracy: 55.10%\n",
      "828\tValidation loss: 1.762381\tBest loss: 1.762381\tAccuracy: 55.20%\n",
      "829\tValidation loss: 1.762285\tBest loss: 1.762285\tAccuracy: 55.20%\n",
      "830\tValidation loss: 1.761836\tBest loss: 1.761836\tAccuracy: 54.90%\n",
      "831\tValidation loss: 1.763515\tBest loss: 1.761836\tAccuracy: 55.10%\n",
      "832\tValidation loss: 1.763715\tBest loss: 1.761836\tAccuracy: 55.30%\n",
      "833\tValidation loss: 1.763347\tBest loss: 1.761836\tAccuracy: 55.40%\n",
      "834\tValidation loss: 1.759032\tBest loss: 1.759032\tAccuracy: 55.90%\n",
      "835\tValidation loss: 1.764158\tBest loss: 1.759032\tAccuracy: 55.40%\n",
      "836\tValidation loss: 1.760079\tBest loss: 1.759032\tAccuracy: 55.20%\n",
      "837\tValidation loss: 1.757986\tBest loss: 1.757986\tAccuracy: 55.30%\n",
      "838\tValidation loss: 1.760209\tBest loss: 1.757986\tAccuracy: 55.80%\n",
      "839\tValidation loss: 1.760121\tBest loss: 1.757986\tAccuracy: 55.10%\n",
      "840\tValidation loss: 1.759728\tBest loss: 1.757986\tAccuracy: 55.80%\n",
      "841\tValidation loss: 1.757736\tBest loss: 1.757736\tAccuracy: 55.20%\n",
      "842\tValidation loss: 1.757041\tBest loss: 1.757041\tAccuracy: 55.30%\n",
      "843\tValidation loss: 1.757721\tBest loss: 1.757041\tAccuracy: 54.80%\n",
      "844\tValidation loss: 1.757728\tBest loss: 1.757041\tAccuracy: 55.10%\n",
      "845\tValidation loss: 1.759417\tBest loss: 1.757041\tAccuracy: 55.00%\n",
      "846\tValidation loss: 1.760406\tBest loss: 1.757041\tAccuracy: 55.40%\n",
      "847\tValidation loss: 1.758396\tBest loss: 1.757041\tAccuracy: 55.40%\n",
      "848\tValidation loss: 1.758894\tBest loss: 1.757041\tAccuracy: 54.90%\n",
      "849\tValidation loss: 1.757199\tBest loss: 1.757041\tAccuracy: 55.90%\n",
      "850\tValidation loss: 1.759089\tBest loss: 1.757041\tAccuracy: 55.40%\n",
      "851\tValidation loss: 1.758626\tBest loss: 1.757041\tAccuracy: 55.20%\n",
      "852\tValidation loss: 1.759453\tBest loss: 1.757041\tAccuracy: 55.00%\n",
      "853\tValidation loss: 1.758649\tBest loss: 1.757041\tAccuracy: 55.80%\n",
      "854\tValidation loss: 1.760439\tBest loss: 1.757041\tAccuracy: 55.50%\n",
      "855\tValidation loss: 1.756446\tBest loss: 1.756446\tAccuracy: 55.70%\n",
      "856\tValidation loss: 1.756768\tBest loss: 1.756446\tAccuracy: 55.60%\n",
      "857\tValidation loss: 1.756029\tBest loss: 1.756029\tAccuracy: 55.80%\n",
      "858\tValidation loss: 1.755116\tBest loss: 1.755116\tAccuracy: 55.60%\n",
      "859\tValidation loss: 1.753868\tBest loss: 1.753868\tAccuracy: 55.70%\n",
      "860\tValidation loss: 1.754266\tBest loss: 1.753868\tAccuracy: 55.80%\n",
      "861\tValidation loss: 1.756524\tBest loss: 1.753868\tAccuracy: 55.40%\n",
      "862\tValidation loss: 1.753543\tBest loss: 1.753543\tAccuracy: 55.70%\n",
      "863\tValidation loss: 1.752127\tBest loss: 1.752127\tAccuracy: 56.10%\n",
      "864\tValidation loss: 1.752178\tBest loss: 1.752127\tAccuracy: 55.80%\n",
      "865\tValidation loss: 1.755019\tBest loss: 1.752127\tAccuracy: 56.10%\n",
      "866\tValidation loss: 1.751347\tBest loss: 1.751347\tAccuracy: 56.00%\n",
      "867\tValidation loss: 1.751692\tBest loss: 1.751347\tAccuracy: 55.40%\n",
      "868\tValidation loss: 1.751780\tBest loss: 1.751347\tAccuracy: 55.70%\n",
      "869\tValidation loss: 1.752335\tBest loss: 1.751347\tAccuracy: 55.40%\n",
      "870\tValidation loss: 1.752024\tBest loss: 1.751347\tAccuracy: 55.40%\n",
      "871\tValidation loss: 1.749147\tBest loss: 1.749147\tAccuracy: 55.40%\n",
      "872\tValidation loss: 1.749671\tBest loss: 1.749147\tAccuracy: 55.60%\n",
      "873\tValidation loss: 1.754097\tBest loss: 1.749147\tAccuracy: 55.10%\n",
      "874\tValidation loss: 1.752443\tBest loss: 1.749147\tAccuracy: 55.30%\n",
      "875\tValidation loss: 1.750003\tBest loss: 1.749147\tAccuracy: 55.60%\n",
      "876\tValidation loss: 1.747878\tBest loss: 1.747878\tAccuracy: 55.60%\n",
      "877\tValidation loss: 1.751295\tBest loss: 1.747878\tAccuracy: 55.10%\n",
      "878\tValidation loss: 1.749800\tBest loss: 1.747878\tAccuracy: 55.10%\n",
      "879\tValidation loss: 1.747811\tBest loss: 1.747811\tAccuracy: 55.20%\n",
      "880\tValidation loss: 1.746880\tBest loss: 1.746880\tAccuracy: 55.10%\n",
      "881\tValidation loss: 1.750273\tBest loss: 1.746880\tAccuracy: 55.20%\n",
      "882\tValidation loss: 1.749067\tBest loss: 1.746880\tAccuracy: 55.20%\n",
      "883\tValidation loss: 1.748803\tBest loss: 1.746880\tAccuracy: 55.00%\n",
      "884\tValidation loss: 1.749450\tBest loss: 1.746880\tAccuracy: 54.90%\n",
      "885\tValidation loss: 1.746241\tBest loss: 1.746241\tAccuracy: 54.80%\n",
      "886\tValidation loss: 1.747486\tBest loss: 1.746241\tAccuracy: 55.20%\n",
      "887\tValidation loss: 1.746403\tBest loss: 1.746241\tAccuracy: 55.20%\n",
      "888\tValidation loss: 1.747638\tBest loss: 1.746241\tAccuracy: 55.30%\n",
      "889\tValidation loss: 1.746619\tBest loss: 1.746241\tAccuracy: 54.90%\n",
      "890\tValidation loss: 1.747889\tBest loss: 1.746241\tAccuracy: 54.60%\n",
      "891\tValidation loss: 1.749760\tBest loss: 1.746241\tAccuracy: 55.00%\n",
      "892\tValidation loss: 1.746874\tBest loss: 1.746241\tAccuracy: 54.80%\n",
      "893\tValidation loss: 1.746181\tBest loss: 1.746181\tAccuracy: 54.80%\n",
      "894\tValidation loss: 1.743719\tBest loss: 1.743719\tAccuracy: 54.90%\n",
      "895\tValidation loss: 1.746041\tBest loss: 1.743719\tAccuracy: 54.60%\n",
      "896\tValidation loss: 1.747132\tBest loss: 1.743719\tAccuracy: 55.00%\n",
      "897\tValidation loss: 1.745757\tBest loss: 1.743719\tAccuracy: 55.20%\n",
      "898\tValidation loss: 1.743733\tBest loss: 1.743719\tAccuracy: 54.90%\n",
      "899\tValidation loss: 1.742768\tBest loss: 1.742768\tAccuracy: 54.50%\n",
      "900\tValidation loss: 1.746453\tBest loss: 1.742768\tAccuracy: 54.80%\n",
      "901\tValidation loss: 1.742508\tBest loss: 1.742508\tAccuracy: 55.00%\n",
      "902\tValidation loss: 1.741585\tBest loss: 1.741585\tAccuracy: 55.10%\n",
      "903\tValidation loss: 1.742438\tBest loss: 1.741585\tAccuracy: 55.20%\n",
      "904\tValidation loss: 1.739970\tBest loss: 1.739970\tAccuracy: 55.00%\n",
      "905\tValidation loss: 1.740284\tBest loss: 1.739970\tAccuracy: 55.20%\n",
      "906\tValidation loss: 1.739392\tBest loss: 1.739392\tAccuracy: 55.10%\n",
      "907\tValidation loss: 1.740454\tBest loss: 1.739392\tAccuracy: 54.90%\n",
      "908\tValidation loss: 1.739325\tBest loss: 1.739325\tAccuracy: 54.50%\n",
      "909\tValidation loss: 1.739734\tBest loss: 1.739325\tAccuracy: 54.30%\n",
      "910\tValidation loss: 1.740622\tBest loss: 1.739325\tAccuracy: 54.50%\n",
      "911\tValidation loss: 1.741424\tBest loss: 1.739325\tAccuracy: 54.90%\n",
      "912\tValidation loss: 1.739527\tBest loss: 1.739325\tAccuracy: 54.70%\n",
      "913\tValidation loss: 1.738522\tBest loss: 1.738522\tAccuracy: 54.50%\n",
      "914\tValidation loss: 1.738350\tBest loss: 1.738350\tAccuracy: 55.40%\n",
      "915\tValidation loss: 1.736887\tBest loss: 1.736887\tAccuracy: 55.20%\n",
      "916\tValidation loss: 1.738051\tBest loss: 1.736887\tAccuracy: 54.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917\tValidation loss: 1.736429\tBest loss: 1.736429\tAccuracy: 55.00%\n",
      "918\tValidation loss: 1.736357\tBest loss: 1.736357\tAccuracy: 55.00%\n",
      "919\tValidation loss: 1.734846\tBest loss: 1.734846\tAccuracy: 54.80%\n",
      "920\tValidation loss: 1.734295\tBest loss: 1.734295\tAccuracy: 55.30%\n",
      "921\tValidation loss: 1.731420\tBest loss: 1.731420\tAccuracy: 55.00%\n",
      "922\tValidation loss: 1.731847\tBest loss: 1.731420\tAccuracy: 55.20%\n",
      "923\tValidation loss: 1.733781\tBest loss: 1.731420\tAccuracy: 55.00%\n",
      "924\tValidation loss: 1.731374\tBest loss: 1.731374\tAccuracy: 54.90%\n",
      "925\tValidation loss: 1.731539\tBest loss: 1.731374\tAccuracy: 54.90%\n",
      "926\tValidation loss: 1.732501\tBest loss: 1.731374\tAccuracy: 55.10%\n",
      "927\tValidation loss: 1.733407\tBest loss: 1.731374\tAccuracy: 55.10%\n",
      "928\tValidation loss: 1.734531\tBest loss: 1.731374\tAccuracy: 55.60%\n",
      "929\tValidation loss: 1.733336\tBest loss: 1.731374\tAccuracy: 55.00%\n",
      "930\tValidation loss: 1.731361\tBest loss: 1.731361\tAccuracy: 55.00%\n",
      "931\tValidation loss: 1.734010\tBest loss: 1.731361\tAccuracy: 55.10%\n",
      "932\tValidation loss: 1.730868\tBest loss: 1.730868\tAccuracy: 54.80%\n",
      "933\tValidation loss: 1.730187\tBest loss: 1.730187\tAccuracy: 54.90%\n",
      "934\tValidation loss: 1.730717\tBest loss: 1.730187\tAccuracy: 54.70%\n",
      "935\tValidation loss: 1.728907\tBest loss: 1.728907\tAccuracy: 55.60%\n",
      "936\tValidation loss: 1.731217\tBest loss: 1.728907\tAccuracy: 55.40%\n",
      "937\tValidation loss: 1.729644\tBest loss: 1.728907\tAccuracy: 55.50%\n",
      "938\tValidation loss: 1.732551\tBest loss: 1.728907\tAccuracy: 54.90%\n",
      "939\tValidation loss: 1.730886\tBest loss: 1.728907\tAccuracy: 54.90%\n",
      "940\tValidation loss: 1.732010\tBest loss: 1.728907\tAccuracy: 55.20%\n",
      "941\tValidation loss: 1.731649\tBest loss: 1.728907\tAccuracy: 55.20%\n",
      "942\tValidation loss: 1.731698\tBest loss: 1.728907\tAccuracy: 54.80%\n",
      "943\tValidation loss: 1.729641\tBest loss: 1.728907\tAccuracy: 55.40%\n",
      "944\tValidation loss: 1.731267\tBest loss: 1.728907\tAccuracy: 55.60%\n",
      "945\tValidation loss: 1.729036\tBest loss: 1.728907\tAccuracy: 55.60%\n",
      "946\tValidation loss: 1.727757\tBest loss: 1.727757\tAccuracy: 55.10%\n",
      "947\tValidation loss: 1.730321\tBest loss: 1.727757\tAccuracy: 55.00%\n",
      "948\tValidation loss: 1.727693\tBest loss: 1.727693\tAccuracy: 54.90%\n",
      "949\tValidation loss: 1.726477\tBest loss: 1.726477\tAccuracy: 55.10%\n",
      "950\tValidation loss: 1.725400\tBest loss: 1.725400\tAccuracy: 55.30%\n",
      "951\tValidation loss: 1.725394\tBest loss: 1.725394\tAccuracy: 55.40%\n",
      "952\tValidation loss: 1.726313\tBest loss: 1.725394\tAccuracy: 55.50%\n",
      "953\tValidation loss: 1.724726\tBest loss: 1.724726\tAccuracy: 55.10%\n",
      "954\tValidation loss: 1.725163\tBest loss: 1.724726\tAccuracy: 55.30%\n",
      "955\tValidation loss: 1.720230\tBest loss: 1.720230\tAccuracy: 55.60%\n",
      "956\tValidation loss: 1.723535\tBest loss: 1.720230\tAccuracy: 54.90%\n",
      "957\tValidation loss: 1.722899\tBest loss: 1.720230\tAccuracy: 55.50%\n",
      "958\tValidation loss: 1.721402\tBest loss: 1.720230\tAccuracy: 56.00%\n",
      "959\tValidation loss: 1.725359\tBest loss: 1.720230\tAccuracy: 55.20%\n",
      "960\tValidation loss: 1.722528\tBest loss: 1.720230\tAccuracy: 55.20%\n",
      "961\tValidation loss: 1.722922\tBest loss: 1.720230\tAccuracy: 55.40%\n",
      "962\tValidation loss: 1.721864\tBest loss: 1.720230\tAccuracy: 55.40%\n",
      "963\tValidation loss: 1.721330\tBest loss: 1.720230\tAccuracy: 55.20%\n",
      "964\tValidation loss: 1.724151\tBest loss: 1.720230\tAccuracy: 54.90%\n",
      "965\tValidation loss: 1.721983\tBest loss: 1.720230\tAccuracy: 55.10%\n",
      "966\tValidation loss: 1.721961\tBest loss: 1.720230\tAccuracy: 55.20%\n",
      "967\tValidation loss: 1.723216\tBest loss: 1.720230\tAccuracy: 55.10%\n",
      "968\tValidation loss: 1.721482\tBest loss: 1.720230\tAccuracy: 55.30%\n",
      "969\tValidation loss: 1.721095\tBest loss: 1.720230\tAccuracy: 55.10%\n",
      "970\tValidation loss: 1.720321\tBest loss: 1.720230\tAccuracy: 55.30%\n",
      "971\tValidation loss: 1.719618\tBest loss: 1.719618\tAccuracy: 55.00%\n",
      "972\tValidation loss: 1.716303\tBest loss: 1.716303\tAccuracy: 55.50%\n",
      "973\tValidation loss: 1.718690\tBest loss: 1.716303\tAccuracy: 55.40%\n",
      "974\tValidation loss: 1.717366\tBest loss: 1.716303\tAccuracy: 55.30%\n",
      "975\tValidation loss: 1.719682\tBest loss: 1.716303\tAccuracy: 55.00%\n",
      "976\tValidation loss: 1.720951\tBest loss: 1.716303\tAccuracy: 55.40%\n",
      "977\tValidation loss: 1.719927\tBest loss: 1.716303\tAccuracy: 55.40%\n",
      "978\tValidation loss: 1.719778\tBest loss: 1.716303\tAccuracy: 55.00%\n",
      "979\tValidation loss: 1.716342\tBest loss: 1.716303\tAccuracy: 55.30%\n",
      "980\tValidation loss: 1.716114\tBest loss: 1.716114\tAccuracy: 55.20%\n",
      "981\tValidation loss: 1.716218\tBest loss: 1.716114\tAccuracy: 55.50%\n",
      "982\tValidation loss: 1.716646\tBest loss: 1.716114\tAccuracy: 55.00%\n",
      "983\tValidation loss: 1.716476\tBest loss: 1.716114\tAccuracy: 55.50%\n",
      "984\tValidation loss: 1.717064\tBest loss: 1.716114\tAccuracy: 55.80%\n",
      "985\tValidation loss: 1.717782\tBest loss: 1.716114\tAccuracy: 54.90%\n",
      "986\tValidation loss: 1.718216\tBest loss: 1.716114\tAccuracy: 55.50%\n",
      "987\tValidation loss: 1.714063\tBest loss: 1.714063\tAccuracy: 55.20%\n",
      "988\tValidation loss: 1.713123\tBest loss: 1.713123\tAccuracy: 55.20%\n",
      "989\tValidation loss: 1.714118\tBest loss: 1.713123\tAccuracy: 55.40%\n",
      "990\tValidation loss: 1.713796\tBest loss: 1.713123\tAccuracy: 55.50%\n",
      "991\tValidation loss: 1.712214\tBest loss: 1.712214\tAccuracy: 55.00%\n",
      "992\tValidation loss: 1.714274\tBest loss: 1.712214\tAccuracy: 55.40%\n",
      "993\tValidation loss: 1.712099\tBest loss: 1.712099\tAccuracy: 55.10%\n",
      "994\tValidation loss: 1.713114\tBest loss: 1.712099\tAccuracy: 55.40%\n",
      "995\tValidation loss: 1.711848\tBest loss: 1.711848\tAccuracy: 55.50%\n",
      "996\tValidation loss: 1.711585\tBest loss: 1.711585\tAccuracy: 55.40%\n",
      "997\tValidation loss: 1.711858\tBest loss: 1.711585\tAccuracy: 55.60%\n",
      "998\tValidation loss: 1.707999\tBest loss: 1.707999\tAccuracy: 55.40%\n",
      "999\tValidation loss: 1.707501\tBest loss: 1.707501\tAccuracy: 55.20%\n",
      "[[  1.63912773e-02   3.22053656e-02   1.64508224e-02 ...,   3.38930935e-02\n",
      "    5.99857792e-03   7.56009202e-03]\n",
      " [  1.84607155e-14   4.25129543e-10   7.85996684e-11 ...,   2.03472794e-09\n",
      "    6.09289827e-07   5.71050360e-11]\n",
      " [  1.71544543e-05   3.73676349e-03   4.34205605e-04 ...,   3.34520519e-05\n",
      "    2.13727253e-04   7.15596601e-04]\n",
      " ..., \n",
      " [  5.84381912e-03   3.65588181e-02   3.09853628e-03 ...,   9.04905937e-06\n",
      "    2.35229018e-05   4.41421980e-06]\n",
      " [  4.29499112e-02   2.30889171e-02   2.89791021e-02 ...,   1.90503057e-02\n",
      "    1.36147812e-02   9.04576015e-03]\n",
      " [  2.22845369e-08   1.98376100e-07   3.47547626e-08 ...,   5.66130579e-02\n",
      "    1.25912046e-02   8.41779768e-01]]\n",
      "[41 41 11 ...,  6  9 47]\n",
      "[[  9.50274028e-08   1.28121510e-05   8.37570042e-06 ...,   4.74913789e-14\n",
      "    1.27655400e-10   1.26698785e-09]\n",
      " [  5.41964658e-02   4.09540311e-02   3.96944173e-02 ...,   1.61551535e-02\n",
      "    9.22349747e-03   7.05751451e-03]\n",
      " [  6.20480867e-09   1.27915126e-12   2.13769708e-05 ...,   2.35660151e-14\n",
      "    1.81427215e-15   7.94096296e-20]\n",
      " ..., \n",
      " [  4.35731793e-03   3.90026625e-03   6.37747161e-03 ...,   2.35744175e-02\n",
      "    1.74966175e-02   2.44912729e-02]\n",
      " [  7.60458488e-06   5.46865267e-05   1.29385240e-04 ...,   1.52850628e-01\n",
      "    8.37533996e-02   1.44893834e-02]\n",
      " [  3.79772978e-08   1.23605616e-06   7.69379881e-07 ...,   7.06282407e-02\n",
      "    4.08679619e-02   1.45465359e-02]]\n",
      "[20  0 16 ...,  9 26 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total= 2.1min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 7.043621\tBest loss: 7.043621\tAccuracy: 2.20%\n",
      "1\tValidation loss: 9.872602\tBest loss: 7.043621\tAccuracy: 3.00%\n",
      "2\tValidation loss: 9.745366\tBest loss: 7.043621\tAccuracy: 2.80%\n",
      "3\tValidation loss: 10.758999\tBest loss: 7.043621\tAccuracy: 1.50%\n",
      "4\tValidation loss: 11.958426\tBest loss: 7.043621\tAccuracy: 4.10%\n",
      "5\tValidation loss: 10.269349\tBest loss: 7.043621\tAccuracy: 3.70%\n",
      "6\tValidation loss: 8.954967\tBest loss: 7.043621\tAccuracy: 2.00%\n",
      "7\tValidation loss: 7.803504\tBest loss: 7.043621\tAccuracy: 4.00%\n",
      "8\tValidation loss: 9.329064\tBest loss: 7.043621\tAccuracy: 2.20%\n",
      "9\tValidation loss: 9.023162\tBest loss: 7.043621\tAccuracy: 2.00%\n",
      "10\tValidation loss: 7.653988\tBest loss: 7.043621\tAccuracy: 2.00%\n",
      "11\tValidation loss: 8.992264\tBest loss: 7.043621\tAccuracy: 2.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 7.987381\tBest loss: 7.043621\tAccuracy: 3.20%\n",
      "13\tValidation loss: 11.638280\tBest loss: 7.043621\tAccuracy: 3.50%\n",
      "14\tValidation loss: 10.003513\tBest loss: 7.043621\tAccuracy: 3.70%\n",
      "15\tValidation loss: 10.421452\tBest loss: 7.043621\tAccuracy: 2.30%\n",
      "16\tValidation loss: 8.918608\tBest loss: 7.043621\tAccuracy: 0.80%\n",
      "17\tValidation loss: 10.079067\tBest loss: 7.043621\tAccuracy: 2.20%\n",
      "18\tValidation loss: 10.051121\tBest loss: 7.043621\tAccuracy: 2.20%\n",
      "19\tValidation loss: 9.970289\tBest loss: 7.043621\tAccuracy: 3.60%\n",
      "20\tValidation loss: 14.060199\tBest loss: 7.043621\tAccuracy: 3.10%\n",
      "21\tValidation loss: 10.783478\tBest loss: 7.043621\tAccuracy: 1.90%\n",
      "Early stopping!\n",
      "[[  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.74435052e-07   8.75183177e-05   4.21032635e-03 ...,   6.49458598e-05\n",
      "    1.54217065e-04   1.63248878e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " ..., \n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]]\n",
      "[10 10 10 ..., 10 10 10]\n",
      "[[  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " ..., \n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]\n",
      " [  2.73968254e-07   8.60877917e-05   4.27512499e-03 ...,   6.63101600e-05\n",
      "    1.53734683e-04   1.64564262e-05]\n",
      " [  2.71039369e-07   8.59137290e-05   4.22895327e-03 ...,   6.60444421e-05\n",
      "    1.51883622e-04   1.63308778e-05]]\n",
      "[10 10 10 ..., 10 10 10]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   5.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 10.385468\tBest loss: 10.385468\tAccuracy: 4.60%\n",
      "1\tValidation loss: 12.253851\tBest loss: 10.385468\tAccuracy: 3.80%\n",
      "2\tValidation loss: 10.102827\tBest loss: 10.102827\tAccuracy: 3.50%\n",
      "3\tValidation loss: 10.047425\tBest loss: 10.047425\tAccuracy: 1.90%\n",
      "4\tValidation loss: 9.936893\tBest loss: 9.936893\tAccuracy: 1.90%\n",
      "5\tValidation loss: 11.498071\tBest loss: 9.936893\tAccuracy: 4.10%\n",
      "6\tValidation loss: 10.441671\tBest loss: 9.936893\tAccuracy: 3.50%\n",
      "7\tValidation loss: 7.024481\tBest loss: 7.024481\tAccuracy: 3.20%\n",
      "8\tValidation loss: 11.786362\tBest loss: 7.024481\tAccuracy: 4.00%\n",
      "9\tValidation loss: 7.476321\tBest loss: 7.024481\tAccuracy: 4.10%\n",
      "10\tValidation loss: 7.967811\tBest loss: 7.024481\tAccuracy: 2.30%\n",
      "11\tValidation loss: 10.525885\tBest loss: 7.024481\tAccuracy: 2.70%\n",
      "12\tValidation loss: 13.572360\tBest loss: 7.024481\tAccuracy: 0.80%\n",
      "13\tValidation loss: 9.200962\tBest loss: 7.024481\tAccuracy: 1.10%\n",
      "14\tValidation loss: 10.433434\tBest loss: 7.024481\tAccuracy: 2.40%\n",
      "15\tValidation loss: 12.038893\tBest loss: 7.024481\tAccuracy: 3.20%\n",
      "16\tValidation loss: 11.681906\tBest loss: 7.024481\tAccuracy: 3.80%\n",
      "17\tValidation loss: 10.633634\tBest loss: 7.024481\tAccuracy: 1.50%\n",
      "18\tValidation loss: 11.046978\tBest loss: 7.024481\tAccuracy: 4.00%\n",
      "19\tValidation loss: 9.348022\tBest loss: 7.024481\tAccuracy: 2.30%\n",
      "20\tValidation loss: 13.007695\tBest loss: 7.024481\tAccuracy: 1.10%\n",
      "21\tValidation loss: 12.839727\tBest loss: 7.024481\tAccuracy: 2.20%\n",
      "22\tValidation loss: 9.820670\tBest loss: 7.024481\tAccuracy: 2.10%\n",
      "23\tValidation loss: 11.003328\tBest loss: 7.024481\tAccuracy: 3.10%\n",
      "24\tValidation loss: 8.303138\tBest loss: 7.024481\tAccuracy: 2.50%\n",
      "25\tValidation loss: 10.443576\tBest loss: 7.024481\tAccuracy: 0.90%\n",
      "26\tValidation loss: 9.170682\tBest loss: 7.024481\tAccuracy: 1.70%\n",
      "27\tValidation loss: 14.067772\tBest loss: 7.024481\tAccuracy: 2.00%\n",
      "28\tValidation loss: 13.363246\tBest loss: 7.024481\tAccuracy: 1.40%\n",
      "Early stopping!\n",
      "[[  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " ..., \n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[[  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50671983e-03   1.25418928e-05   1.14558252e-05 ...,   2.43883836e-03\n",
      "    2.70557794e-04   6.16714306e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " ..., \n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]\n",
      " [  3.50679201e-03   1.25421520e-05   1.14560617e-05 ...,   2.43888865e-03\n",
      "    2.70546851e-04   6.16764692e-06]\n",
      " [  3.50673799e-03   1.25419583e-05   1.14558843e-05 ...,   2.43885093e-03\n",
      "    2.70559191e-04   6.16755142e-06]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   7.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 10.927137\tBest loss: 10.927137\tAccuracy: 2.30%\n",
      "1\tValidation loss: 11.840291\tBest loss: 10.927137\tAccuracy: 0.50%\n",
      "2\tValidation loss: 7.110352\tBest loss: 7.110352\tAccuracy: 3.90%\n",
      "3\tValidation loss: 11.657734\tBest loss: 7.110352\tAccuracy: 3.60%\n",
      "4\tValidation loss: 10.910461\tBest loss: 7.110352\tAccuracy: 1.30%\n",
      "5\tValidation loss: 14.936841\tBest loss: 7.110352\tAccuracy: 1.20%\n",
      "6\tValidation loss: 14.044321\tBest loss: 7.110352\tAccuracy: 2.30%\n",
      "7\tValidation loss: 10.500818\tBest loss: 7.110352\tAccuracy: 2.10%\n",
      "8\tValidation loss: 8.277924\tBest loss: 7.110352\tAccuracy: 1.70%\n",
      "9\tValidation loss: 8.974024\tBest loss: 7.110352\tAccuracy: 1.20%\n",
      "10\tValidation loss: 8.939852\tBest loss: 7.110352\tAccuracy: 3.60%\n",
      "11\tValidation loss: 11.204242\tBest loss: 7.110352\tAccuracy: 2.30%\n",
      "12\tValidation loss: 13.617649\tBest loss: 7.110352\tAccuracy: 1.40%\n",
      "13\tValidation loss: 7.711135\tBest loss: 7.110352\tAccuracy: 3.60%\n",
      "14\tValidation loss: 9.271076\tBest loss: 7.110352\tAccuracy: 2.40%\n",
      "15\tValidation loss: 10.765645\tBest loss: 7.110352\tAccuracy: 1.10%\n",
      "16\tValidation loss: 8.556672\tBest loss: 7.110352\tAccuracy: 2.00%\n",
      "17\tValidation loss: 9.345530\tBest loss: 7.110352\tAccuracy: 2.10%\n",
      "18\tValidation loss: 13.946012\tBest loss: 7.110352\tAccuracy: 3.20%\n",
      "19\tValidation loss: 10.567181\tBest loss: 7.110352\tAccuracy: 2.40%\n",
      "20\tValidation loss: 9.427930\tBest loss: 7.110352\tAccuracy: 3.20%\n",
      "21\tValidation loss: 9.651125\tBest loss: 7.110352\tAccuracy: 3.50%\n",
      "22\tValidation loss: 9.652441\tBest loss: 7.110352\tAccuracy: 3.70%\n",
      "23\tValidation loss: 8.988271\tBest loss: 7.110352\tAccuracy: 2.20%\n",
      "Early stopping!\n",
      "[[  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " ..., \n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95966812e-05   8.74548778e-03   4.03251324e-05 ...,   3.25017512e-01\n",
      "    1.50531356e-03   1.26840517e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]]\n",
      "[45 45 45 ..., 45 45 45]\n",
      "[[  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95979691e-05   8.74527544e-03   4.03198501e-05 ...,   3.25029492e-01\n",
      "    1.50525395e-03   1.26835510e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " ..., \n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]\n",
      " [  5.95954225e-05   8.74530245e-03   4.03199701e-05 ...,   3.25025499e-01\n",
      "    1.50521263e-03   1.26837835e-01]]\n",
      "[45 45 45 ..., 45 45 45]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   6.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.866492\tBest loss: 3.866492\tAccuracy: 4.00%\n",
      "1\tValidation loss: 3.861587\tBest loss: 3.861587\tAccuracy: 3.90%\n",
      "2\tValidation loss: 3.856985\tBest loss: 3.856985\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.852650\tBest loss: 3.852650\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.848573\tBest loss: 3.848573\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.844698\tBest loss: 3.844698\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.841109\tBest loss: 3.841109\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.837842\tBest loss: 3.837842\tAccuracy: 3.10%\n",
      "8\tValidation loss: 3.834566\tBest loss: 3.834566\tAccuracy: 3.10%\n",
      "9\tValidation loss: 3.831399\tBest loss: 3.831399\tAccuracy: 3.10%\n",
      "10\tValidation loss: 3.828446\tBest loss: 3.828446\tAccuracy: 3.10%\n",
      "11\tValidation loss: 3.825675\tBest loss: 3.825675\tAccuracy: 3.20%\n",
      "12\tValidation loss: 3.823112\tBest loss: 3.823112\tAccuracy: 3.30%\n",
      "13\tValidation loss: 3.820946\tBest loss: 3.820946\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.818828\tBest loss: 3.818828\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.816885\tBest loss: 3.816885\tAccuracy: 3.10%\n",
      "16\tValidation loss: 3.815285\tBest loss: 3.815285\tAccuracy: 3.10%\n",
      "17\tValidation loss: 3.813642\tBest loss: 3.813642\tAccuracy: 3.10%\n",
      "18\tValidation loss: 3.812503\tBest loss: 3.812503\tAccuracy: 3.20%\n",
      "19\tValidation loss: 3.811249\tBest loss: 3.811249\tAccuracy: 3.30%\n",
      "20\tValidation loss: 3.810165\tBest loss: 3.810165\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.809224\tBest loss: 3.809224\tAccuracy: 3.20%\n",
      "22\tValidation loss: 3.808361\tBest loss: 3.808361\tAccuracy: 3.10%\n",
      "23\tValidation loss: 3.807511\tBest loss: 3.807511\tAccuracy: 3.10%\n",
      "24\tValidation loss: 3.806802\tBest loss: 3.806802\tAccuracy: 3.10%\n",
      "25\tValidation loss: 3.806128\tBest loss: 3.806128\tAccuracy: 3.10%\n",
      "26\tValidation loss: 3.805579\tBest loss: 3.805579\tAccuracy: 3.10%\n",
      "27\tValidation loss: 3.804980\tBest loss: 3.804980\tAccuracy: 3.20%\n",
      "28\tValidation loss: 3.804539\tBest loss: 3.804539\tAccuracy: 3.20%\n",
      "29\tValidation loss: 3.804127\tBest loss: 3.804127\tAccuracy: 3.10%\n",
      "30\tValidation loss: 3.803663\tBest loss: 3.803663\tAccuracy: 3.10%\n",
      "31\tValidation loss: 3.803237\tBest loss: 3.803237\tAccuracy: 3.10%\n",
      "32\tValidation loss: 3.802754\tBest loss: 3.802754\tAccuracy: 3.20%\n",
      "33\tValidation loss: 3.802373\tBest loss: 3.802373\tAccuracy: 3.20%\n",
      "34\tValidation loss: 3.801991\tBest loss: 3.801991\tAccuracy: 3.20%\n",
      "35\tValidation loss: 3.801680\tBest loss: 3.801680\tAccuracy: 3.10%\n",
      "36\tValidation loss: 3.801435\tBest loss: 3.801435\tAccuracy: 3.10%\n",
      "37\tValidation loss: 3.801193\tBest loss: 3.801193\tAccuracy: 3.10%\n",
      "38\tValidation loss: 3.800830\tBest loss: 3.800830\tAccuracy: 3.20%\n",
      "39\tValidation loss: 3.800518\tBest loss: 3.800518\tAccuracy: 3.20%\n",
      "40\tValidation loss: 3.800430\tBest loss: 3.800430\tAccuracy: 3.20%\n",
      "41\tValidation loss: 3.800122\tBest loss: 3.800122\tAccuracy: 3.20%\n",
      "42\tValidation loss: 3.799944\tBest loss: 3.799944\tAccuracy: 3.20%\n",
      "43\tValidation loss: 3.799800\tBest loss: 3.799800\tAccuracy: 3.10%\n",
      "44\tValidation loss: 3.799593\tBest loss: 3.799593\tAccuracy: 3.10%\n",
      "45\tValidation loss: 3.799409\tBest loss: 3.799409\tAccuracy: 3.10%\n",
      "46\tValidation loss: 3.799256\tBest loss: 3.799256\tAccuracy: 3.10%\n",
      "47\tValidation loss: 3.799066\tBest loss: 3.799066\tAccuracy: 3.10%\n",
      "48\tValidation loss: 3.798937\tBest loss: 3.798937\tAccuracy: 3.10%\n",
      "49\tValidation loss: 3.798791\tBest loss: 3.798791\tAccuracy: 3.10%\n",
      "50\tValidation loss: 3.798607\tBest loss: 3.798607\tAccuracy: 3.10%\n",
      "51\tValidation loss: 3.798454\tBest loss: 3.798454\tAccuracy: 3.10%\n",
      "52\tValidation loss: 3.798304\tBest loss: 3.798304\tAccuracy: 3.10%\n",
      "53\tValidation loss: 3.798177\tBest loss: 3.798177\tAccuracy: 3.10%\n",
      "54\tValidation loss: 3.798048\tBest loss: 3.798048\tAccuracy: 3.10%\n",
      "55\tValidation loss: 3.797965\tBest loss: 3.797965\tAccuracy: 3.10%\n",
      "56\tValidation loss: 3.797876\tBest loss: 3.797876\tAccuracy: 3.10%\n",
      "57\tValidation loss: 3.797682\tBest loss: 3.797682\tAccuracy: 3.10%\n",
      "58\tValidation loss: 3.797587\tBest loss: 3.797587\tAccuracy: 3.10%\n",
      "59\tValidation loss: 3.797400\tBest loss: 3.797400\tAccuracy: 3.20%\n",
      "60\tValidation loss: 3.797356\tBest loss: 3.797356\tAccuracy: 3.20%\n",
      "61\tValidation loss: 3.797348\tBest loss: 3.797348\tAccuracy: 3.10%\n",
      "62\tValidation loss: 3.797283\tBest loss: 3.797283\tAccuracy: 3.10%\n",
      "63\tValidation loss: 3.797163\tBest loss: 3.797163\tAccuracy: 3.10%\n",
      "64\tValidation loss: 3.797049\tBest loss: 3.797049\tAccuracy: 3.10%\n",
      "65\tValidation loss: 3.797021\tBest loss: 3.797021\tAccuracy: 3.10%\n",
      "66\tValidation loss: 3.797025\tBest loss: 3.797021\tAccuracy: 3.10%\n",
      "67\tValidation loss: 3.796950\tBest loss: 3.796950\tAccuracy: 3.10%\n",
      "68\tValidation loss: 3.796882\tBest loss: 3.796882\tAccuracy: 3.10%\n",
      "69\tValidation loss: 3.796894\tBest loss: 3.796882\tAccuracy: 3.10%\n",
      "70\tValidation loss: 3.796760\tBest loss: 3.796760\tAccuracy: 3.10%\n",
      "71\tValidation loss: 3.796637\tBest loss: 3.796637\tAccuracy: 3.10%\n",
      "72\tValidation loss: 3.796666\tBest loss: 3.796637\tAccuracy: 3.10%\n",
      "73\tValidation loss: 3.796568\tBest loss: 3.796568\tAccuracy: 3.10%\n",
      "74\tValidation loss: 3.796514\tBest loss: 3.796514\tAccuracy: 3.10%\n",
      "75\tValidation loss: 3.796571\tBest loss: 3.796514\tAccuracy: 3.10%\n",
      "76\tValidation loss: 3.796508\tBest loss: 3.796508\tAccuracy: 3.10%\n",
      "77\tValidation loss: 3.796388\tBest loss: 3.796388\tAccuracy: 3.20%\n",
      "78\tValidation loss: 3.796418\tBest loss: 3.796388\tAccuracy: 3.20%\n",
      "79\tValidation loss: 3.796406\tBest loss: 3.796388\tAccuracy: 3.10%\n",
      "80\tValidation loss: 3.796445\tBest loss: 3.796388\tAccuracy: 3.10%\n",
      "81\tValidation loss: 3.796449\tBest loss: 3.796388\tAccuracy: 3.10%\n",
      "82\tValidation loss: 3.796378\tBest loss: 3.796378\tAccuracy: 3.10%\n",
      "83\tValidation loss: 3.796361\tBest loss: 3.796361\tAccuracy: 3.10%\n",
      "84\tValidation loss: 3.796350\tBest loss: 3.796350\tAccuracy: 3.10%\n",
      "85\tValidation loss: 3.796360\tBest loss: 3.796350\tAccuracy: 3.10%\n",
      "86\tValidation loss: 3.796276\tBest loss: 3.796276\tAccuracy: 3.10%\n",
      "87\tValidation loss: 3.796186\tBest loss: 3.796186\tAccuracy: 3.10%\n",
      "88\tValidation loss: 3.796172\tBest loss: 3.796172\tAccuracy: 3.10%\n",
      "89\tValidation loss: 3.796126\tBest loss: 3.796126\tAccuracy: 3.10%\n",
      "90\tValidation loss: 3.796035\tBest loss: 3.796035\tAccuracy: 3.10%\n",
      "91\tValidation loss: 3.795957\tBest loss: 3.795957\tAccuracy: 3.10%\n",
      "92\tValidation loss: 3.795985\tBest loss: 3.795957\tAccuracy: 3.10%\n",
      "93\tValidation loss: 3.795901\tBest loss: 3.795901\tAccuracy: 3.10%\n",
      "94\tValidation loss: 3.795860\tBest loss: 3.795860\tAccuracy: 3.10%\n",
      "95\tValidation loss: 3.795774\tBest loss: 3.795774\tAccuracy: 3.10%\n",
      "96\tValidation loss: 3.795712\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "97\tValidation loss: 3.795731\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "98\tValidation loss: 3.795750\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "99\tValidation loss: 3.795733\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "100\tValidation loss: 3.795764\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "101\tValidation loss: 3.795737\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "102\tValidation loss: 3.795713\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "103\tValidation loss: 3.795721\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "104\tValidation loss: 3.795716\tBest loss: 3.795712\tAccuracy: 3.10%\n",
      "105\tValidation loss: 3.795627\tBest loss: 3.795627\tAccuracy: 3.10%\n",
      "106\tValidation loss: 3.795639\tBest loss: 3.795627\tAccuracy: 3.10%\n",
      "107\tValidation loss: 3.795635\tBest loss: 3.795627\tAccuracy: 3.10%\n",
      "108\tValidation loss: 3.795584\tBest loss: 3.795584\tAccuracy: 3.10%\n",
      "109\tValidation loss: 3.795574\tBest loss: 3.795574\tAccuracy: 3.10%\n",
      "110\tValidation loss: 3.795569\tBest loss: 3.795569\tAccuracy: 3.10%\n",
      "111\tValidation loss: 3.795583\tBest loss: 3.795569\tAccuracy: 3.10%\n",
      "112\tValidation loss: 3.795605\tBest loss: 3.795569\tAccuracy: 3.10%\n",
      "113\tValidation loss: 3.795586\tBest loss: 3.795569\tAccuracy: 3.10%\n",
      "114\tValidation loss: 3.795538\tBest loss: 3.795538\tAccuracy: 3.10%\n",
      "115\tValidation loss: 3.795521\tBest loss: 3.795521\tAccuracy: 3.10%\n",
      "116\tValidation loss: 3.795479\tBest loss: 3.795479\tAccuracy: 3.10%\n",
      "117\tValidation loss: 3.795434\tBest loss: 3.795434\tAccuracy: 3.10%\n",
      "118\tValidation loss: 3.795426\tBest loss: 3.795426\tAccuracy: 3.10%\n",
      "119\tValidation loss: 3.795398\tBest loss: 3.795398\tAccuracy: 3.10%\n",
      "120\tValidation loss: 3.795362\tBest loss: 3.795362\tAccuracy: 3.10%\n",
      "121\tValidation loss: 3.795333\tBest loss: 3.795333\tAccuracy: 3.10%\n",
      "122\tValidation loss: 3.795317\tBest loss: 3.795317\tAccuracy: 3.10%\n",
      "123\tValidation loss: 3.795355\tBest loss: 3.795317\tAccuracy: 3.10%\n",
      "124\tValidation loss: 3.795403\tBest loss: 3.795317\tAccuracy: 3.10%\n",
      "125\tValidation loss: 3.795392\tBest loss: 3.795317\tAccuracy: 3.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\tValidation loss: 3.795292\tBest loss: 3.795292\tAccuracy: 3.10%\n",
      "127\tValidation loss: 3.795274\tBest loss: 3.795274\tAccuracy: 3.10%\n",
      "128\tValidation loss: 3.795278\tBest loss: 3.795274\tAccuracy: 3.10%\n",
      "129\tValidation loss: 3.795243\tBest loss: 3.795243\tAccuracy: 3.10%\n",
      "130\tValidation loss: 3.795195\tBest loss: 3.795195\tAccuracy: 3.10%\n",
      "131\tValidation loss: 3.795176\tBest loss: 3.795176\tAccuracy: 3.10%\n",
      "132\tValidation loss: 3.795128\tBest loss: 3.795128\tAccuracy: 3.10%\n",
      "133\tValidation loss: 3.795146\tBest loss: 3.795128\tAccuracy: 3.10%\n",
      "134\tValidation loss: 3.795160\tBest loss: 3.795128\tAccuracy: 3.10%\n",
      "135\tValidation loss: 3.795018\tBest loss: 3.795018\tAccuracy: 3.10%\n",
      "136\tValidation loss: 3.794932\tBest loss: 3.794932\tAccuracy: 3.10%\n",
      "137\tValidation loss: 3.794817\tBest loss: 3.794817\tAccuracy: 3.10%\n",
      "138\tValidation loss: 3.794699\tBest loss: 3.794699\tAccuracy: 3.10%\n",
      "139\tValidation loss: 3.794742\tBest loss: 3.794699\tAccuracy: 3.10%\n",
      "140\tValidation loss: 3.794529\tBest loss: 3.794529\tAccuracy: 3.10%\n",
      "141\tValidation loss: 3.794435\tBest loss: 3.794435\tAccuracy: 3.00%\n",
      "142\tValidation loss: 3.794604\tBest loss: 3.794435\tAccuracy: 3.10%\n",
      "143\tValidation loss: 3.793412\tBest loss: 3.793412\tAccuracy: 3.10%\n",
      "144\tValidation loss: 3.792080\tBest loss: 3.792080\tAccuracy: 3.10%\n",
      "145\tValidation loss: 3.790290\tBest loss: 3.790290\tAccuracy: 3.10%\n",
      "146\tValidation loss: 3.790520\tBest loss: 3.790290\tAccuracy: 3.20%\n",
      "147\tValidation loss: 3.790534\tBest loss: 3.790290\tAccuracy: 3.10%\n",
      "148\tValidation loss: 3.790912\tBest loss: 3.790290\tAccuracy: 3.10%\n",
      "149\tValidation loss: 3.790491\tBest loss: 3.790290\tAccuracy: 3.10%\n",
      "150\tValidation loss: 3.789701\tBest loss: 3.789701\tAccuracy: 3.10%\n",
      "151\tValidation loss: 3.787807\tBest loss: 3.787807\tAccuracy: 3.10%\n",
      "152\tValidation loss: 3.787575\tBest loss: 3.787575\tAccuracy: 3.10%\n",
      "153\tValidation loss: 3.789167\tBest loss: 3.787575\tAccuracy: 3.20%\n",
      "154\tValidation loss: 3.789025\tBest loss: 3.787575\tAccuracy: 3.10%\n",
      "155\tValidation loss: 3.787859\tBest loss: 3.787575\tAccuracy: 3.20%\n",
      "156\tValidation loss: 3.788853\tBest loss: 3.787575\tAccuracy: 3.10%\n",
      "157\tValidation loss: 3.789456\tBest loss: 3.787575\tAccuracy: 3.10%\n",
      "158\tValidation loss: 3.788404\tBest loss: 3.787575\tAccuracy: 3.20%\n",
      "159\tValidation loss: 3.788891\tBest loss: 3.787575\tAccuracy: 3.20%\n",
      "160\tValidation loss: 3.786273\tBest loss: 3.786273\tAccuracy: 3.20%\n",
      "161\tValidation loss: 3.785786\tBest loss: 3.785786\tAccuracy: 3.30%\n",
      "162\tValidation loss: 3.785021\tBest loss: 3.785021\tAccuracy: 3.30%\n",
      "163\tValidation loss: 3.784424\tBest loss: 3.784424\tAccuracy: 3.30%\n",
      "164\tValidation loss: 3.784506\tBest loss: 3.784424\tAccuracy: 3.30%\n",
      "165\tValidation loss: 3.785430\tBest loss: 3.784424\tAccuracy: 3.30%\n",
      "166\tValidation loss: 3.783985\tBest loss: 3.783985\tAccuracy: 3.30%\n",
      "167\tValidation loss: 3.784646\tBest loss: 3.783985\tAccuracy: 3.30%\n",
      "168\tValidation loss: 3.784821\tBest loss: 3.783985\tAccuracy: 3.30%\n",
      "169\tValidation loss: 3.784652\tBest loss: 3.783985\tAccuracy: 3.30%\n",
      "170\tValidation loss: 3.783568\tBest loss: 3.783568\tAccuracy: 3.30%\n",
      "171\tValidation loss: 3.782382\tBest loss: 3.782382\tAccuracy: 3.30%\n",
      "172\tValidation loss: 3.779558\tBest loss: 3.779558\tAccuracy: 3.40%\n",
      "173\tValidation loss: 3.779439\tBest loss: 3.779439\tAccuracy: 3.50%\n",
      "174\tValidation loss: 3.779646\tBest loss: 3.779439\tAccuracy: 3.40%\n",
      "175\tValidation loss: 3.779359\tBest loss: 3.779359\tAccuracy: 3.40%\n",
      "176\tValidation loss: 3.779178\tBest loss: 3.779178\tAccuracy: 3.40%\n",
      "177\tValidation loss: 3.777575\tBest loss: 3.777575\tAccuracy: 3.50%\n",
      "178\tValidation loss: 3.777276\tBest loss: 3.777276\tAccuracy: 3.50%\n",
      "179\tValidation loss: 3.777130\tBest loss: 3.777130\tAccuracy: 3.50%\n",
      "180\tValidation loss: 3.776824\tBest loss: 3.776824\tAccuracy: 3.50%\n",
      "181\tValidation loss: 3.777619\tBest loss: 3.776824\tAccuracy: 3.60%\n",
      "182\tValidation loss: 3.777343\tBest loss: 3.776824\tAccuracy: 3.60%\n",
      "183\tValidation loss: 3.776457\tBest loss: 3.776457\tAccuracy: 3.60%\n",
      "184\tValidation loss: 3.778359\tBest loss: 3.776457\tAccuracy: 3.10%\n",
      "185\tValidation loss: 3.777602\tBest loss: 3.776457\tAccuracy: 3.10%\n",
      "186\tValidation loss: 3.777682\tBest loss: 3.776457\tAccuracy: 3.10%\n",
      "187\tValidation loss: 3.776372\tBest loss: 3.776372\tAccuracy: 2.90%\n",
      "188\tValidation loss: 3.777432\tBest loss: 3.776372\tAccuracy: 3.00%\n",
      "189\tValidation loss: 3.777116\tBest loss: 3.776372\tAccuracy: 3.00%\n",
      "190\tValidation loss: 3.773152\tBest loss: 3.773152\tAccuracy: 3.20%\n",
      "191\tValidation loss: 3.775032\tBest loss: 3.773152\tAccuracy: 3.00%\n",
      "192\tValidation loss: 3.774396\tBest loss: 3.773152\tAccuracy: 3.00%\n",
      "193\tValidation loss: 3.771516\tBest loss: 3.771516\tAccuracy: 3.30%\n",
      "194\tValidation loss: 3.771904\tBest loss: 3.771516\tAccuracy: 3.20%\n",
      "195\tValidation loss: 3.772015\tBest loss: 3.771516\tAccuracy: 3.40%\n",
      "196\tValidation loss: 3.770352\tBest loss: 3.770352\tAccuracy: 3.30%\n",
      "197\tValidation loss: 3.769572\tBest loss: 3.769572\tAccuracy: 3.10%\n",
      "198\tValidation loss: 3.768843\tBest loss: 3.768843\tAccuracy: 3.20%\n",
      "199\tValidation loss: 3.771877\tBest loss: 3.768843\tAccuracy: 3.10%\n",
      "200\tValidation loss: 3.771392\tBest loss: 3.768843\tAccuracy: 3.10%\n",
      "201\tValidation loss: 3.769045\tBest loss: 3.768843\tAccuracy: 3.00%\n",
      "202\tValidation loss: 3.767498\tBest loss: 3.767498\tAccuracy: 3.20%\n",
      "203\tValidation loss: 3.765142\tBest loss: 3.765142\tAccuracy: 3.60%\n",
      "204\tValidation loss: 3.762608\tBest loss: 3.762608\tAccuracy: 3.60%\n",
      "205\tValidation loss: 3.762960\tBest loss: 3.762608\tAccuracy: 3.50%\n",
      "206\tValidation loss: 3.761261\tBest loss: 3.761261\tAccuracy: 3.60%\n",
      "207\tValidation loss: 3.758075\tBest loss: 3.758075\tAccuracy: 3.70%\n",
      "208\tValidation loss: 3.756427\tBest loss: 3.756427\tAccuracy: 4.10%\n",
      "209\tValidation loss: 3.760826\tBest loss: 3.756427\tAccuracy: 3.40%\n",
      "210\tValidation loss: 3.760713\tBest loss: 3.756427\tAccuracy: 3.70%\n",
      "211\tValidation loss: 3.761152\tBest loss: 3.756427\tAccuracy: 4.20%\n",
      "212\tValidation loss: 3.758725\tBest loss: 3.756427\tAccuracy: 4.30%\n",
      "213\tValidation loss: 3.756935\tBest loss: 3.756427\tAccuracy: 4.60%\n",
      "214\tValidation loss: 3.753344\tBest loss: 3.753344\tAccuracy: 4.60%\n",
      "215\tValidation loss: 3.749320\tBest loss: 3.749320\tAccuracy: 4.80%\n",
      "216\tValidation loss: 3.747437\tBest loss: 3.747437\tAccuracy: 5.00%\n",
      "217\tValidation loss: 3.749670\tBest loss: 3.747437\tAccuracy: 3.90%\n",
      "218\tValidation loss: 3.749150\tBest loss: 3.747437\tAccuracy: 3.70%\n",
      "219\tValidation loss: 3.748056\tBest loss: 3.747437\tAccuracy: 4.70%\n",
      "220\tValidation loss: 3.742564\tBest loss: 3.742564\tAccuracy: 4.80%\n",
      "221\tValidation loss: 3.741847\tBest loss: 3.741847\tAccuracy: 4.60%\n",
      "222\tValidation loss: 3.740308\tBest loss: 3.740308\tAccuracy: 3.80%\n",
      "223\tValidation loss: 3.739952\tBest loss: 3.739952\tAccuracy: 3.90%\n",
      "224\tValidation loss: 3.738584\tBest loss: 3.738584\tAccuracy: 4.10%\n",
      "225\tValidation loss: 3.734214\tBest loss: 3.734214\tAccuracy: 4.20%\n",
      "226\tValidation loss: 3.736235\tBest loss: 3.734214\tAccuracy: 3.80%\n",
      "227\tValidation loss: 3.731294\tBest loss: 3.731294\tAccuracy: 4.10%\n",
      "228\tValidation loss: 3.729849\tBest loss: 3.729849\tAccuracy: 4.30%\n",
      "229\tValidation loss: 3.727757\tBest loss: 3.727757\tAccuracy: 4.30%\n",
      "230\tValidation loss: 3.730331\tBest loss: 3.727757\tAccuracy: 3.60%\n",
      "231\tValidation loss: 3.725953\tBest loss: 3.725953\tAccuracy: 4.00%\n",
      "232\tValidation loss: 3.727120\tBest loss: 3.725953\tAccuracy: 4.50%\n",
      "233\tValidation loss: 3.717846\tBest loss: 3.717846\tAccuracy: 4.60%\n",
      "234\tValidation loss: 3.721349\tBest loss: 3.717846\tAccuracy: 4.00%\n",
      "235\tValidation loss: 3.721882\tBest loss: 3.717846\tAccuracy: 3.90%\n",
      "236\tValidation loss: 3.722544\tBest loss: 3.717846\tAccuracy: 4.10%\n",
      "237\tValidation loss: 3.714133\tBest loss: 3.714133\tAccuracy: 4.60%\n",
      "238\tValidation loss: 3.718965\tBest loss: 3.714133\tAccuracy: 4.30%\n",
      "239\tValidation loss: 3.712159\tBest loss: 3.712159\tAccuracy: 4.20%\n",
      "240\tValidation loss: 3.711604\tBest loss: 3.711604\tAccuracy: 4.00%\n",
      "241\tValidation loss: 3.709893\tBest loss: 3.709893\tAccuracy: 4.60%\n",
      "242\tValidation loss: 3.708504\tBest loss: 3.708504\tAccuracy: 4.40%\n",
      "243\tValidation loss: 3.705518\tBest loss: 3.705518\tAccuracy: 4.70%\n",
      "244\tValidation loss: 3.710041\tBest loss: 3.705518\tAccuracy: 4.60%\n",
      "245\tValidation loss: 3.708760\tBest loss: 3.705518\tAccuracy: 4.40%\n",
      "246\tValidation loss: 3.700871\tBest loss: 3.700871\tAccuracy: 4.40%\n",
      "247\tValidation loss: 3.805221\tBest loss: 3.700871\tAccuracy: 3.10%\n",
      "248\tValidation loss: 3.754256\tBest loss: 3.700871\tAccuracy: 4.60%\n",
      "249\tValidation loss: 3.693305\tBest loss: 3.693305\tAccuracy: 6.40%\n",
      "250\tValidation loss: 3.696604\tBest loss: 3.693305\tAccuracy: 6.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\tValidation loss: 3.696100\tBest loss: 3.693305\tAccuracy: 6.30%\n",
      "252\tValidation loss: 3.694260\tBest loss: 3.693305\tAccuracy: 6.30%\n",
      "253\tValidation loss: 3.691938\tBest loss: 3.691938\tAccuracy: 6.40%\n",
      "254\tValidation loss: 3.694433\tBest loss: 3.691938\tAccuracy: 6.80%\n",
      "255\tValidation loss: 3.694468\tBest loss: 3.691938\tAccuracy: 7.00%\n",
      "256\tValidation loss: 3.690189\tBest loss: 3.690189\tAccuracy: 6.80%\n",
      "257\tValidation loss: 3.688648\tBest loss: 3.688648\tAccuracy: 6.80%\n",
      "258\tValidation loss: 3.687018\tBest loss: 3.687018\tAccuracy: 6.80%\n",
      "259\tValidation loss: 3.688501\tBest loss: 3.687018\tAccuracy: 6.80%\n",
      "260\tValidation loss: 3.681298\tBest loss: 3.681298\tAccuracy: 7.10%\n",
      "261\tValidation loss: 3.680626\tBest loss: 3.680626\tAccuracy: 7.10%\n",
      "262\tValidation loss: 3.677954\tBest loss: 3.677954\tAccuracy: 7.00%\n",
      "263\tValidation loss: 3.681071\tBest loss: 3.677954\tAccuracy: 7.10%\n",
      "264\tValidation loss: 3.678207\tBest loss: 3.677954\tAccuracy: 7.10%\n",
      "265\tValidation loss: 3.671705\tBest loss: 3.671705\tAccuracy: 7.30%\n",
      "266\tValidation loss: 3.678100\tBest loss: 3.671705\tAccuracy: 6.80%\n",
      "267\tValidation loss: 3.675323\tBest loss: 3.671705\tAccuracy: 6.60%\n",
      "268\tValidation loss: 3.674972\tBest loss: 3.671705\tAccuracy: 6.80%\n",
      "269\tValidation loss: 3.667329\tBest loss: 3.667329\tAccuracy: 6.40%\n",
      "270\tValidation loss: 3.663502\tBest loss: 3.663502\tAccuracy: 6.60%\n",
      "271\tValidation loss: 3.668160\tBest loss: 3.663502\tAccuracy: 7.30%\n",
      "272\tValidation loss: 3.659879\tBest loss: 3.659879\tAccuracy: 7.50%\n",
      "273\tValidation loss: 3.660260\tBest loss: 3.659879\tAccuracy: 7.40%\n",
      "274\tValidation loss: 3.664617\tBest loss: 3.659879\tAccuracy: 6.80%\n",
      "275\tValidation loss: 3.691168\tBest loss: 3.659879\tAccuracy: 6.50%\n",
      "276\tValidation loss: 3.663435\tBest loss: 3.659879\tAccuracy: 7.40%\n",
      "277\tValidation loss: 3.665070\tBest loss: 3.659879\tAccuracy: 7.10%\n",
      "278\tValidation loss: 3.652894\tBest loss: 3.652894\tAccuracy: 7.10%\n",
      "279\tValidation loss: 3.652987\tBest loss: 3.652894\tAccuracy: 7.00%\n",
      "280\tValidation loss: 3.727028\tBest loss: 3.652894\tAccuracy: 6.10%\n",
      "281\tValidation loss: 3.701854\tBest loss: 3.652894\tAccuracy: 6.70%\n",
      "282\tValidation loss: 3.696589\tBest loss: 3.652894\tAccuracy: 6.80%\n",
      "283\tValidation loss: 3.669451\tBest loss: 3.652894\tAccuracy: 7.30%\n",
      "284\tValidation loss: 3.668154\tBest loss: 3.652894\tAccuracy: 7.30%\n",
      "285\tValidation loss: 3.667171\tBest loss: 3.652894\tAccuracy: 7.30%\n",
      "286\tValidation loss: 3.668081\tBest loss: 3.652894\tAccuracy: 7.40%\n",
      "287\tValidation loss: 3.660758\tBest loss: 3.652894\tAccuracy: 7.40%\n",
      "288\tValidation loss: 3.665962\tBest loss: 3.652894\tAccuracy: 6.40%\n",
      "289\tValidation loss: 3.665494\tBest loss: 3.652894\tAccuracy: 6.30%\n",
      "290\tValidation loss: 3.662733\tBest loss: 3.652894\tAccuracy: 7.10%\n",
      "291\tValidation loss: 3.656170\tBest loss: 3.652894\tAccuracy: 7.10%\n",
      "292\tValidation loss: 3.656794\tBest loss: 3.652894\tAccuracy: 7.20%\n",
      "293\tValidation loss: 3.656266\tBest loss: 3.652894\tAccuracy: 7.10%\n",
      "294\tValidation loss: 3.651734\tBest loss: 3.651734\tAccuracy: 7.10%\n",
      "295\tValidation loss: 3.649333\tBest loss: 3.649333\tAccuracy: 7.30%\n",
      "296\tValidation loss: 3.651798\tBest loss: 3.649333\tAccuracy: 7.30%\n",
      "297\tValidation loss: 3.646711\tBest loss: 3.646711\tAccuracy: 7.50%\n",
      "298\tValidation loss: 3.649737\tBest loss: 3.646711\tAccuracy: 6.90%\n",
      "299\tValidation loss: 3.643566\tBest loss: 3.643566\tAccuracy: 7.50%\n",
      "300\tValidation loss: 3.647195\tBest loss: 3.643566\tAccuracy: 7.30%\n",
      "301\tValidation loss: 3.643014\tBest loss: 3.643014\tAccuracy: 7.40%\n",
      "302\tValidation loss: 3.679070\tBest loss: 3.643014\tAccuracy: 5.80%\n",
      "303\tValidation loss: 3.656172\tBest loss: 3.643014\tAccuracy: 5.80%\n",
      "304\tValidation loss: 3.656710\tBest loss: 3.643014\tAccuracy: 7.40%\n",
      "305\tValidation loss: 3.636704\tBest loss: 3.636704\tAccuracy: 7.50%\n",
      "306\tValidation loss: 3.638174\tBest loss: 3.636704\tAccuracy: 6.10%\n",
      "307\tValidation loss: 3.644967\tBest loss: 3.636704\tAccuracy: 6.20%\n",
      "308\tValidation loss: 3.634135\tBest loss: 3.634135\tAccuracy: 6.20%\n",
      "309\tValidation loss: 3.633285\tBest loss: 3.633285\tAccuracy: 6.10%\n",
      "310\tValidation loss: 3.631763\tBest loss: 3.631763\tAccuracy: 7.20%\n",
      "311\tValidation loss: 3.636103\tBest loss: 3.631763\tAccuracy: 6.80%\n",
      "312\tValidation loss: 3.632590\tBest loss: 3.631763\tAccuracy: 7.10%\n",
      "313\tValidation loss: 3.634058\tBest loss: 3.631763\tAccuracy: 7.60%\n",
      "314\tValidation loss: 3.627949\tBest loss: 3.627949\tAccuracy: 7.20%\n",
      "315\tValidation loss: 3.631088\tBest loss: 3.627949\tAccuracy: 7.40%\n",
      "316\tValidation loss: 3.632952\tBest loss: 3.627949\tAccuracy: 7.10%\n",
      "317\tValidation loss: 3.640925\tBest loss: 3.627949\tAccuracy: 7.10%\n",
      "318\tValidation loss: 3.639863\tBest loss: 3.627949\tAccuracy: 7.10%\n",
      "319\tValidation loss: 3.639858\tBest loss: 3.627949\tAccuracy: 7.20%\n",
      "320\tValidation loss: 3.635677\tBest loss: 3.627949\tAccuracy: 6.90%\n",
      "321\tValidation loss: 3.639663\tBest loss: 3.627949\tAccuracy: 7.00%\n",
      "322\tValidation loss: 3.640986\tBest loss: 3.627949\tAccuracy: 7.00%\n",
      "323\tValidation loss: 3.645751\tBest loss: 3.627949\tAccuracy: 7.00%\n",
      "324\tValidation loss: 3.651727\tBest loss: 3.627949\tAccuracy: 7.40%\n",
      "325\tValidation loss: 3.646475\tBest loss: 3.627949\tAccuracy: 7.20%\n",
      "326\tValidation loss: 3.643901\tBest loss: 3.627949\tAccuracy: 7.40%\n",
      "327\tValidation loss: 3.643993\tBest loss: 3.627949\tAccuracy: 7.30%\n",
      "328\tValidation loss: 3.640706\tBest loss: 3.627949\tAccuracy: 7.20%\n",
      "329\tValidation loss: 3.633985\tBest loss: 3.627949\tAccuracy: 7.20%\n",
      "330\tValidation loss: 3.633854\tBest loss: 3.627949\tAccuracy: 7.50%\n",
      "331\tValidation loss: 3.628239\tBest loss: 3.627949\tAccuracy: 7.30%\n",
      "332\tValidation loss: 3.624446\tBest loss: 3.624446\tAccuracy: 7.10%\n",
      "333\tValidation loss: 3.618798\tBest loss: 3.618798\tAccuracy: 7.40%\n",
      "334\tValidation loss: 3.639487\tBest loss: 3.618798\tAccuracy: 6.80%\n",
      "335\tValidation loss: 3.619876\tBest loss: 3.618798\tAccuracy: 7.50%\n",
      "336\tValidation loss: 3.623787\tBest loss: 3.618798\tAccuracy: 7.50%\n",
      "337\tValidation loss: 3.620995\tBest loss: 3.618798\tAccuracy: 7.20%\n",
      "338\tValidation loss: 3.622264\tBest loss: 3.618798\tAccuracy: 7.30%\n",
      "339\tValidation loss: 3.619769\tBest loss: 3.618798\tAccuracy: 7.50%\n",
      "340\tValidation loss: 3.613367\tBest loss: 3.613367\tAccuracy: 7.50%\n",
      "341\tValidation loss: 3.622128\tBest loss: 3.613367\tAccuracy: 7.50%\n",
      "342\tValidation loss: 3.620513\tBest loss: 3.613367\tAccuracy: 7.70%\n",
      "343\tValidation loss: 3.623449\tBest loss: 3.613367\tAccuracy: 7.10%\n",
      "344\tValidation loss: 3.621131\tBest loss: 3.613367\tAccuracy: 5.90%\n",
      "345\tValidation loss: 3.620651\tBest loss: 3.613367\tAccuracy: 7.30%\n",
      "346\tValidation loss: 3.613992\tBest loss: 3.613367\tAccuracy: 5.80%\n",
      "347\tValidation loss: 3.641168\tBest loss: 3.613367\tAccuracy: 5.50%\n",
      "348\tValidation loss: 3.619884\tBest loss: 3.613367\tAccuracy: 6.00%\n",
      "349\tValidation loss: 3.628223\tBest loss: 3.613367\tAccuracy: 5.70%\n",
      "350\tValidation loss: 3.625497\tBest loss: 3.613367\tAccuracy: 7.40%\n",
      "351\tValidation loss: 3.618704\tBest loss: 3.613367\tAccuracy: 5.80%\n",
      "352\tValidation loss: 3.619824\tBest loss: 3.613367\tAccuracy: 5.90%\n",
      "353\tValidation loss: 3.618351\tBest loss: 3.613367\tAccuracy: 5.70%\n",
      "354\tValidation loss: 3.636603\tBest loss: 3.613367\tAccuracy: 5.90%\n",
      "355\tValidation loss: 3.631810\tBest loss: 3.613367\tAccuracy: 6.00%\n",
      "356\tValidation loss: 3.620289\tBest loss: 3.613367\tAccuracy: 5.80%\n",
      "357\tValidation loss: 3.624173\tBest loss: 3.613367\tAccuracy: 5.70%\n",
      "358\tValidation loss: 3.626008\tBest loss: 3.613367\tAccuracy: 5.70%\n",
      "359\tValidation loss: 3.628107\tBest loss: 3.613367\tAccuracy: 5.60%\n",
      "360\tValidation loss: 3.618856\tBest loss: 3.613367\tAccuracy: 5.50%\n",
      "361\tValidation loss: 3.619811\tBest loss: 3.613367\tAccuracy: 5.40%\n",
      "Early stopping!\n",
      "[[ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]\n",
      " [ 0.0220032   0.05319214  0.02985314 ...,  0.01739894  0.01439275\n",
      "   0.01253719]\n",
      " [ 0.0220297   0.05344211  0.0298576  ...,  0.01727304  0.01433664\n",
      "   0.01248512]\n",
      " ..., \n",
      " [ 0.0220297   0.05344211  0.0298576  ...,  0.01727304  0.01433664\n",
      "   0.01248512]\n",
      " [ 0.0220297   0.05344211  0.0298576  ...,  0.01727304  0.01433664\n",
      "   0.01248512]\n",
      " [ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]]\n",
      "[ 8 19 19 ..., 19 19  8]\n",
      "[[ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]\n",
      " [ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]\n",
      " [ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]\n",
      " ..., \n",
      " [ 0.0220297   0.05344211  0.0298576  ...,  0.01727304  0.01433664\n",
      "   0.01248512]\n",
      " [ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]\n",
      " [ 0.00998731  0.01393081  0.0151239  ...,  0.03911012  0.0204165\n",
      "   0.02375357]]\n",
      "[ 8  8  8 ..., 19  8  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total= 2.1min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.864959\tBest loss: 3.864959\tAccuracy: 3.60%\n",
      "1\tValidation loss: 3.858377\tBest loss: 3.858377\tAccuracy: 3.10%\n",
      "2\tValidation loss: 3.851729\tBest loss: 3.851729\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.844571\tBest loss: 3.844571\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.838380\tBest loss: 3.838380\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.832691\tBest loss: 3.832691\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.827670\tBest loss: 3.827670\tAccuracy: 3.80%\n",
      "7\tValidation loss: 3.823826\tBest loss: 3.823826\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.819919\tBest loss: 3.819919\tAccuracy: 3.80%\n",
      "9\tValidation loss: 3.816284\tBest loss: 3.816284\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.813483\tBest loss: 3.813483\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.810926\tBest loss: 3.810926\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.809363\tBest loss: 3.809363\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.807141\tBest loss: 3.807141\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.805480\tBest loss: 3.805480\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.803911\tBest loss: 3.803911\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.802771\tBest loss: 3.802771\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.801718\tBest loss: 3.801718\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.800705\tBest loss: 3.800705\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.799991\tBest loss: 3.799991\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.799434\tBest loss: 3.799434\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.799172\tBest loss: 3.799172\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.798761\tBest loss: 3.798761\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.798237\tBest loss: 3.798237\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.798252\tBest loss: 3.798237\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.798005\tBest loss: 3.798005\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.797940\tBest loss: 3.797940\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.797689\tBest loss: 3.797689\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.797404\tBest loss: 3.797404\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.797216\tBest loss: 3.797216\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.797575\tBest loss: 3.797216\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.797386\tBest loss: 3.797216\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.797226\tBest loss: 3.797216\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.796993\tBest loss: 3.796993\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.796905\tBest loss: 3.796905\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.797022\tBest loss: 3.796905\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.796870\tBest loss: 3.796870\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.796934\tBest loss: 3.796870\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.796830\tBest loss: 3.796830\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.796935\tBest loss: 3.796830\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.796849\tBest loss: 3.796830\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.796584\tBest loss: 3.796584\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.796627\tBest loss: 3.796584\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.796547\tBest loss: 3.796547\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.796574\tBest loss: 3.796547\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.796513\tBest loss: 3.796513\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.796451\tBest loss: 3.796451\tAccuracy: 3.70%\n",
      "47\tValidation loss: 3.796397\tBest loss: 3.796397\tAccuracy: 3.70%\n",
      "48\tValidation loss: 3.796562\tBest loss: 3.796397\tAccuracy: 3.70%\n",
      "49\tValidation loss: 3.796422\tBest loss: 3.796397\tAccuracy: 3.70%\n",
      "50\tValidation loss: 3.796469\tBest loss: 3.796397\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.796411\tBest loss: 3.796397\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.796332\tBest loss: 3.796332\tAccuracy: 3.70%\n",
      "53\tValidation loss: 3.796381\tBest loss: 3.796332\tAccuracy: 3.70%\n",
      "54\tValidation loss: 3.796280\tBest loss: 3.796280\tAccuracy: 3.70%\n",
      "55\tValidation loss: 3.796109\tBest loss: 3.796109\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.796086\tBest loss: 3.796086\tAccuracy: 3.70%\n",
      "57\tValidation loss: 3.796108\tBest loss: 3.796086\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.796113\tBest loss: 3.796086\tAccuracy: 3.70%\n",
      "59\tValidation loss: 3.796150\tBest loss: 3.796086\tAccuracy: 3.70%\n",
      "60\tValidation loss: 3.796026\tBest loss: 3.796026\tAccuracy: 3.70%\n",
      "61\tValidation loss: 3.795983\tBest loss: 3.795983\tAccuracy: 3.70%\n",
      "62\tValidation loss: 3.795999\tBest loss: 3.795983\tAccuracy: 3.70%\n",
      "63\tValidation loss: 3.795978\tBest loss: 3.795978\tAccuracy: 3.70%\n",
      "64\tValidation loss: 3.795998\tBest loss: 3.795978\tAccuracy: 3.70%\n",
      "65\tValidation loss: 3.795982\tBest loss: 3.795978\tAccuracy: 3.70%\n",
      "66\tValidation loss: 3.795877\tBest loss: 3.795877\tAccuracy: 3.70%\n",
      "67\tValidation loss: 3.795942\tBest loss: 3.795877\tAccuracy: 3.70%\n",
      "68\tValidation loss: 3.795856\tBest loss: 3.795856\tAccuracy: 3.70%\n",
      "69\tValidation loss: 3.795817\tBest loss: 3.795817\tAccuracy: 3.80%\n",
      "70\tValidation loss: 3.795943\tBest loss: 3.795817\tAccuracy: 3.80%\n",
      "71\tValidation loss: 3.795798\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "72\tValidation loss: 3.795966\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "73\tValidation loss: 3.796073\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "74\tValidation loss: 3.795827\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "75\tValidation loss: 3.795890\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "76\tValidation loss: 3.795913\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "77\tValidation loss: 3.795984\tBest loss: 3.795798\tAccuracy: 3.80%\n",
      "78\tValidation loss: 3.795490\tBest loss: 3.795490\tAccuracy: 3.80%\n",
      "79\tValidation loss: 3.794994\tBest loss: 3.794994\tAccuracy: 3.90%\n",
      "80\tValidation loss: 3.795289\tBest loss: 3.794994\tAccuracy: 3.90%\n",
      "81\tValidation loss: 3.795287\tBest loss: 3.794994\tAccuracy: 3.90%\n",
      "82\tValidation loss: 3.795382\tBest loss: 3.794994\tAccuracy: 3.90%\n",
      "83\tValidation loss: 3.795644\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "84\tValidation loss: 3.795633\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "85\tValidation loss: 3.795667\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "86\tValidation loss: 3.795806\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "87\tValidation loss: 3.795726\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "88\tValidation loss: 3.795898\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "89\tValidation loss: 3.795957\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "90\tValidation loss: 3.795916\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "91\tValidation loss: 3.795708\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "92\tValidation loss: 3.795607\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "93\tValidation loss: 3.795192\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "94\tValidation loss: 3.795466\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "95\tValidation loss: 3.795347\tBest loss: 3.794994\tAccuracy: 3.80%\n",
      "96\tValidation loss: 3.795093\tBest loss: 3.794994\tAccuracy: 3.40%\n",
      "97\tValidation loss: 3.795235\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "98\tValidation loss: 3.795392\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "99\tValidation loss: 3.795278\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "100\tValidation loss: 3.795758\tBest loss: 3.794994\tAccuracy: 3.30%\n",
      "Early stopping!\n",
      "[[ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " ..., \n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " ..., \n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]\n",
      " [ 0.01674959  0.03224911  0.02266034 ...,  0.02879792  0.0170855\n",
      "   0.01773649]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  35.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.866167\tBest loss: 3.866167\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.861342\tBest loss: 3.861342\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\tValidation loss: 3.856821\tBest loss: 3.856821\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.852620\tBest loss: 3.852620\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.848699\tBest loss: 3.848699\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.845042\tBest loss: 3.845042\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.841645\tBest loss: 3.841645\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.838492\tBest loss: 3.838492\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.835549\tBest loss: 3.835549\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.832823\tBest loss: 3.832823\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.830277\tBest loss: 3.830277\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.827935\tBest loss: 3.827935\tAccuracy: 3.70%\n",
      "12\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "21\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "22\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "23\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "24\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "25\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "26\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "27\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "28\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "29\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "30\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "31\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "32\tValidation loss: nan\tBest loss: 3.827935\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " ..., \n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " ..., \n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]\n",
      " [ 0.01950134  0.02491057  0.02147836 ...,  0.02355733  0.01937478\n",
      "   0.01973331]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  12.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=  29.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=  29.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=  29.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 4.025641\tBest loss: 4.025641\tAccuracy: 12.70%\n",
      "1\tValidation loss: 3.674177\tBest loss: 3.674177\tAccuracy: 18.40%\n",
      "2\tValidation loss: 3.483739\tBest loss: 3.483739\tAccuracy: 19.90%\n",
      "3\tValidation loss: 3.131545\tBest loss: 3.131545\tAccuracy: 21.60%\n",
      "4\tValidation loss: 2.977613\tBest loss: 2.977613\tAccuracy: 26.80%\n",
      "5\tValidation loss: 2.945659\tBest loss: 2.945659\tAccuracy: 29.30%\n",
      "6\tValidation loss: 2.764525\tBest loss: 2.764525\tAccuracy: 31.10%\n",
      "7\tValidation loss: 2.808614\tBest loss: 2.764525\tAccuracy: 31.20%\n",
      "8\tValidation loss: 2.840253\tBest loss: 2.764525\tAccuracy: 31.10%\n",
      "9\tValidation loss: 2.858430\tBest loss: 2.764525\tAccuracy: 29.10%\n",
      "10\tValidation loss: 2.701805\tBest loss: 2.701805\tAccuracy: 31.50%\n",
      "11\tValidation loss: 2.630648\tBest loss: 2.630648\tAccuracy: 33.40%\n",
      "12\tValidation loss: 2.576683\tBest loss: 2.576683\tAccuracy: 36.00%\n",
      "13\tValidation loss: 2.745685\tBest loss: 2.576683\tAccuracy: 33.50%\n",
      "14\tValidation loss: 2.538507\tBest loss: 2.538507\tAccuracy: 38.00%\n",
      "15\tValidation loss: 2.541882\tBest loss: 2.538507\tAccuracy: 36.70%\n",
      "16\tValidation loss: 2.629287\tBest loss: 2.538507\tAccuracy: 35.60%\n",
      "17\tValidation loss: 2.558885\tBest loss: 2.538507\tAccuracy: 35.20%\n",
      "18\tValidation loss: 2.428545\tBest loss: 2.428545\tAccuracy: 39.40%\n",
      "19\tValidation loss: 2.386990\tBest loss: 2.386990\tAccuracy: 39.40%\n",
      "20\tValidation loss: 2.420385\tBest loss: 2.386990\tAccuracy: 38.30%\n",
      "21\tValidation loss: 2.311798\tBest loss: 2.311798\tAccuracy: 42.20%\n",
      "22\tValidation loss: 2.323298\tBest loss: 2.311798\tAccuracy: 42.10%\n",
      "23\tValidation loss: 2.340527\tBest loss: 2.311798\tAccuracy: 41.50%\n",
      "24\tValidation loss: 2.378254\tBest loss: 2.311798\tAccuracy: 42.50%\n",
      "25\tValidation loss: 2.290963\tBest loss: 2.290963\tAccuracy: 41.10%\n",
      "26\tValidation loss: 2.269144\tBest loss: 2.269144\tAccuracy: 44.80%\n",
      "27\tValidation loss: 2.284806\tBest loss: 2.269144\tAccuracy: 43.80%\n",
      "28\tValidation loss: 2.265927\tBest loss: 2.265927\tAccuracy: 41.30%\n",
      "29\tValidation loss: 2.409951\tBest loss: 2.265927\tAccuracy: 37.80%\n",
      "30\tValidation loss: 2.251284\tBest loss: 2.251284\tAccuracy: 44.30%\n",
      "31\tValidation loss: 2.300318\tBest loss: 2.251284\tAccuracy: 41.50%\n",
      "32\tValidation loss: 2.297414\tBest loss: 2.251284\tAccuracy: 42.40%\n",
      "33\tValidation loss: 2.173088\tBest loss: 2.173088\tAccuracy: 45.60%\n",
      "34\tValidation loss: 2.411619\tBest loss: 2.173088\tAccuracy: 37.70%\n",
      "35\tValidation loss: 2.302082\tBest loss: 2.173088\tAccuracy: 42.50%\n",
      "36\tValidation loss: 2.137857\tBest loss: 2.137857\tAccuracy: 44.20%\n",
      "37\tValidation loss: 2.145053\tBest loss: 2.137857\tAccuracy: 47.00%\n",
      "38\tValidation loss: 2.517412\tBest loss: 2.137857\tAccuracy: 38.70%\n",
      "39\tValidation loss: 2.341151\tBest loss: 2.137857\tAccuracy: 41.30%\n",
      "40\tValidation loss: 2.108454\tBest loss: 2.108454\tAccuracy: 45.10%\n",
      "41\tValidation loss: 2.148560\tBest loss: 2.108454\tAccuracy: 45.50%\n",
      "42\tValidation loss: 2.144463\tBest loss: 2.108454\tAccuracy: 44.10%\n",
      "43\tValidation loss: 2.076181\tBest loss: 2.076181\tAccuracy: 47.60%\n",
      "44\tValidation loss: 2.292434\tBest loss: 2.076181\tAccuracy: 41.00%\n",
      "45\tValidation loss: 2.147138\tBest loss: 2.076181\tAccuracy: 43.90%\n",
      "46\tValidation loss: 2.196489\tBest loss: 2.076181\tAccuracy: 43.80%\n",
      "47\tValidation loss: 2.089185\tBest loss: 2.076181\tAccuracy: 44.70%\n",
      "48\tValidation loss: 2.014225\tBest loss: 2.014225\tAccuracy: 48.10%\n",
      "49\tValidation loss: 2.061739\tBest loss: 2.014225\tAccuracy: 47.40%\n",
      "50\tValidation loss: 1.997498\tBest loss: 1.997498\tAccuracy: 47.90%\n",
      "51\tValidation loss: 1.985551\tBest loss: 1.985551\tAccuracy: 48.00%\n",
      "52\tValidation loss: 2.451253\tBest loss: 1.985551\tAccuracy: 42.80%\n",
      "53\tValidation loss: 2.078867\tBest loss: 1.985551\tAccuracy: 46.60%\n",
      "54\tValidation loss: 2.029029\tBest loss: 1.985551\tAccuracy: 45.90%\n",
      "55\tValidation loss: 1.956074\tBest loss: 1.956074\tAccuracy: 49.60%\n",
      "56\tValidation loss: 2.020455\tBest loss: 1.956074\tAccuracy: 48.00%\n",
      "57\tValidation loss: 2.050299\tBest loss: 1.956074\tAccuracy: 47.50%\n",
      "58\tValidation loss: 1.888565\tBest loss: 1.888565\tAccuracy: 48.60%\n",
      "59\tValidation loss: 1.983024\tBest loss: 1.888565\tAccuracy: 48.60%\n",
      "60\tValidation loss: 1.929837\tBest loss: 1.888565\tAccuracy: 50.40%\n",
      "61\tValidation loss: 2.070910\tBest loss: 1.888565\tAccuracy: 45.70%\n",
      "62\tValidation loss: 2.168675\tBest loss: 1.888565\tAccuracy: 44.30%\n",
      "63\tValidation loss: 2.025760\tBest loss: 1.888565\tAccuracy: 47.30%\n",
      "64\tValidation loss: 1.975529\tBest loss: 1.888565\tAccuracy: 47.10%\n",
      "65\tValidation loss: 2.012395\tBest loss: 1.888565\tAccuracy: 46.70%\n",
      "66\tValidation loss: 1.873591\tBest loss: 1.873591\tAccuracy: 52.20%\n",
      "67\tValidation loss: 1.885619\tBest loss: 1.873591\tAccuracy: 49.30%\n",
      "68\tValidation loss: 2.346272\tBest loss: 1.873591\tAccuracy: 44.10%\n",
      "69\tValidation loss: 1.855885\tBest loss: 1.855885\tAccuracy: 51.20%\n",
      "70\tValidation loss: 1.975832\tBest loss: 1.855885\tAccuracy: 48.60%\n",
      "71\tValidation loss: 1.871881\tBest loss: 1.855885\tAccuracy: 50.60%\n",
      "72\tValidation loss: 1.894963\tBest loss: 1.855885\tAccuracy: 51.80%\n",
      "73\tValidation loss: 1.975544\tBest loss: 1.855885\tAccuracy: 48.80%\n",
      "74\tValidation loss: 1.950876\tBest loss: 1.855885\tAccuracy: 50.80%\n",
      "75\tValidation loss: 1.916198\tBest loss: 1.855885\tAccuracy: 50.30%\n",
      "76\tValidation loss: 1.984415\tBest loss: 1.855885\tAccuracy: 47.30%\n",
      "77\tValidation loss: 1.836147\tBest loss: 1.836147\tAccuracy: 51.30%\n",
      "78\tValidation loss: 1.915724\tBest loss: 1.836147\tAccuracy: 48.90%\n",
      "79\tValidation loss: 1.938938\tBest loss: 1.836147\tAccuracy: 49.60%\n",
      "80\tValidation loss: 1.926965\tBest loss: 1.836147\tAccuracy: 49.20%\n",
      "81\tValidation loss: 1.865493\tBest loss: 1.836147\tAccuracy: 50.10%\n",
      "82\tValidation loss: 1.792101\tBest loss: 1.792101\tAccuracy: 53.50%\n",
      "83\tValidation loss: 1.835151\tBest loss: 1.792101\tAccuracy: 50.50%\n",
      "84\tValidation loss: 2.364547\tBest loss: 1.792101\tAccuracy: 47.60%\n",
      "85\tValidation loss: 1.856418\tBest loss: 1.792101\tAccuracy: 50.60%\n",
      "86\tValidation loss: 1.817196\tBest loss: 1.792101\tAccuracy: 51.40%\n",
      "87\tValidation loss: 1.888536\tBest loss: 1.792101\tAccuracy: 48.70%\n",
      "88\tValidation loss: 2.141138\tBest loss: 1.792101\tAccuracy: 44.70%\n",
      "89\tValidation loss: 1.884827\tBest loss: 1.792101\tAccuracy: 50.10%\n",
      "90\tValidation loss: 2.003071\tBest loss: 1.792101\tAccuracy: 47.20%\n",
      "91\tValidation loss: 1.965441\tBest loss: 1.792101\tAccuracy: 50.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\tValidation loss: 1.793382\tBest loss: 1.792101\tAccuracy: 51.40%\n",
      "93\tValidation loss: 1.800253\tBest loss: 1.792101\tAccuracy: 52.40%\n",
      "94\tValidation loss: 1.768158\tBest loss: 1.768158\tAccuracy: 53.20%\n",
      "95\tValidation loss: 1.768889\tBest loss: 1.768158\tAccuracy: 53.30%\n",
      "96\tValidation loss: 1.924491\tBest loss: 1.768158\tAccuracy: 49.50%\n",
      "97\tValidation loss: 1.808662\tBest loss: 1.768158\tAccuracy: 53.20%\n",
      "98\tValidation loss: 1.717476\tBest loss: 1.717476\tAccuracy: 55.40%\n",
      "99\tValidation loss: 1.859868\tBest loss: 1.717476\tAccuracy: 53.20%\n",
      "100\tValidation loss: 1.856421\tBest loss: 1.717476\tAccuracy: 50.30%\n",
      "101\tValidation loss: 1.802321\tBest loss: 1.717476\tAccuracy: 51.90%\n",
      "102\tValidation loss: 1.878841\tBest loss: 1.717476\tAccuracy: 51.10%\n",
      "103\tValidation loss: 1.774940\tBest loss: 1.717476\tAccuracy: 53.00%\n",
      "104\tValidation loss: 1.776909\tBest loss: 1.717476\tAccuracy: 53.20%\n",
      "105\tValidation loss: 1.881768\tBest loss: 1.717476\tAccuracy: 52.80%\n",
      "106\tValidation loss: 2.219482\tBest loss: 1.717476\tAccuracy: 46.40%\n",
      "107\tValidation loss: 2.023407\tBest loss: 1.717476\tAccuracy: 48.10%\n",
      "108\tValidation loss: 1.764180\tBest loss: 1.717476\tAccuracy: 55.20%\n",
      "109\tValidation loss: 1.820272\tBest loss: 1.717476\tAccuracy: 52.80%\n",
      "110\tValidation loss: 1.736745\tBest loss: 1.717476\tAccuracy: 54.30%\n",
      "111\tValidation loss: 1.706932\tBest loss: 1.706932\tAccuracy: 53.20%\n",
      "112\tValidation loss: 1.822379\tBest loss: 1.706932\tAccuracy: 51.90%\n",
      "113\tValidation loss: 1.880234\tBest loss: 1.706932\tAccuracy: 51.10%\n",
      "114\tValidation loss: 1.971454\tBest loss: 1.706932\tAccuracy: 49.50%\n",
      "115\tValidation loss: 1.753443\tBest loss: 1.706932\tAccuracy: 54.40%\n",
      "116\tValidation loss: 1.795505\tBest loss: 1.706932\tAccuracy: 52.30%\n",
      "117\tValidation loss: 2.182908\tBest loss: 1.706932\tAccuracy: 48.30%\n",
      "118\tValidation loss: 1.740353\tBest loss: 1.706932\tAccuracy: 52.80%\n",
      "119\tValidation loss: 1.787831\tBest loss: 1.706932\tAccuracy: 53.40%\n",
      "120\tValidation loss: 1.820007\tBest loss: 1.706932\tAccuracy: 52.50%\n",
      "121\tValidation loss: 1.836502\tBest loss: 1.706932\tAccuracy: 53.20%\n",
      "122\tValidation loss: 1.687793\tBest loss: 1.687793\tAccuracy: 53.90%\n",
      "123\tValidation loss: 1.766166\tBest loss: 1.687793\tAccuracy: 53.70%\n",
      "124\tValidation loss: 1.792642\tBest loss: 1.687793\tAccuracy: 51.80%\n",
      "125\tValidation loss: 1.817242\tBest loss: 1.687793\tAccuracy: 51.60%\n",
      "126\tValidation loss: 2.000110\tBest loss: 1.687793\tAccuracy: 47.70%\n",
      "127\tValidation loss: 1.790250\tBest loss: 1.687793\tAccuracy: 54.30%\n",
      "128\tValidation loss: 1.749464\tBest loss: 1.687793\tAccuracy: 55.80%\n",
      "129\tValidation loss: 1.921837\tBest loss: 1.687793\tAccuracy: 52.30%\n",
      "130\tValidation loss: 1.740575\tBest loss: 1.687793\tAccuracy: 55.10%\n",
      "131\tValidation loss: 1.714718\tBest loss: 1.687793\tAccuracy: 53.90%\n",
      "132\tValidation loss: 1.776672\tBest loss: 1.687793\tAccuracy: 53.00%\n",
      "133\tValidation loss: 1.850323\tBest loss: 1.687793\tAccuracy: 51.00%\n",
      "134\tValidation loss: 1.753034\tBest loss: 1.687793\tAccuracy: 53.00%\n",
      "135\tValidation loss: 1.726793\tBest loss: 1.687793\tAccuracy: 55.00%\n",
      "136\tValidation loss: 1.924199\tBest loss: 1.687793\tAccuracy: 51.90%\n",
      "137\tValidation loss: 1.804188\tBest loss: 1.687793\tAccuracy: 54.50%\n",
      "138\tValidation loss: 1.788222\tBest loss: 1.687793\tAccuracy: 52.00%\n",
      "139\tValidation loss: 1.776396\tBest loss: 1.687793\tAccuracy: 54.40%\n",
      "140\tValidation loss: 1.843063\tBest loss: 1.687793\tAccuracy: 50.20%\n",
      "141\tValidation loss: 1.713021\tBest loss: 1.687793\tAccuracy: 54.60%\n",
      "142\tValidation loss: 1.686164\tBest loss: 1.686164\tAccuracy: 56.40%\n",
      "143\tValidation loss: 1.712502\tBest loss: 1.686164\tAccuracy: 55.50%\n",
      "144\tValidation loss: 1.744487\tBest loss: 1.686164\tAccuracy: 55.80%\n",
      "145\tValidation loss: 1.846453\tBest loss: 1.686164\tAccuracy: 53.80%\n",
      "146\tValidation loss: 1.956426\tBest loss: 1.686164\tAccuracy: 50.30%\n",
      "147\tValidation loss: 1.714651\tBest loss: 1.686164\tAccuracy: 55.50%\n",
      "148\tValidation loss: 1.752655\tBest loss: 1.686164\tAccuracy: 53.90%\n",
      "149\tValidation loss: 1.755846\tBest loss: 1.686164\tAccuracy: 52.00%\n",
      "150\tValidation loss: 1.641886\tBest loss: 1.641886\tAccuracy: 56.50%\n",
      "151\tValidation loss: 1.904193\tBest loss: 1.641886\tAccuracy: 53.30%\n",
      "152\tValidation loss: 1.794989\tBest loss: 1.641886\tAccuracy: 52.60%\n",
      "153\tValidation loss: 1.714345\tBest loss: 1.641886\tAccuracy: 54.50%\n",
      "154\tValidation loss: 1.704532\tBest loss: 1.641886\tAccuracy: 55.30%\n",
      "155\tValidation loss: 2.131645\tBest loss: 1.641886\tAccuracy: 50.20%\n",
      "156\tValidation loss: 1.849051\tBest loss: 1.641886\tAccuracy: 54.60%\n",
      "157\tValidation loss: 1.756035\tBest loss: 1.641886\tAccuracy: 52.90%\n",
      "158\tValidation loss: 1.650130\tBest loss: 1.641886\tAccuracy: 56.50%\n",
      "159\tValidation loss: 1.633176\tBest loss: 1.633176\tAccuracy: 55.30%\n",
      "160\tValidation loss: 1.608954\tBest loss: 1.608954\tAccuracy: 57.80%\n",
      "161\tValidation loss: 1.713074\tBest loss: 1.608954\tAccuracy: 53.30%\n",
      "162\tValidation loss: 1.720645\tBest loss: 1.608954\tAccuracy: 55.20%\n",
      "163\tValidation loss: 1.851831\tBest loss: 1.608954\tAccuracy: 53.10%\n",
      "164\tValidation loss: 1.673214\tBest loss: 1.608954\tAccuracy: 55.30%\n",
      "165\tValidation loss: 1.717260\tBest loss: 1.608954\tAccuracy: 54.10%\n",
      "166\tValidation loss: 1.755867\tBest loss: 1.608954\tAccuracy: 54.20%\n",
      "167\tValidation loss: 1.766859\tBest loss: 1.608954\tAccuracy: 54.90%\n",
      "168\tValidation loss: 1.638358\tBest loss: 1.608954\tAccuracy: 56.90%\n",
      "169\tValidation loss: 1.703648\tBest loss: 1.608954\tAccuracy: 56.50%\n",
      "170\tValidation loss: 1.640997\tBest loss: 1.608954\tAccuracy: 56.30%\n",
      "171\tValidation loss: 1.654320\tBest loss: 1.608954\tAccuracy: 55.90%\n",
      "172\tValidation loss: 1.741044\tBest loss: 1.608954\tAccuracy: 54.00%\n",
      "173\tValidation loss: 1.747355\tBest loss: 1.608954\tAccuracy: 54.50%\n",
      "174\tValidation loss: 1.750721\tBest loss: 1.608954\tAccuracy: 55.50%\n",
      "175\tValidation loss: 1.908718\tBest loss: 1.608954\tAccuracy: 51.20%\n",
      "176\tValidation loss: 1.664386\tBest loss: 1.608954\tAccuracy: 52.60%\n",
      "177\tValidation loss: 1.593819\tBest loss: 1.593819\tAccuracy: 57.60%\n",
      "178\tValidation loss: 1.674086\tBest loss: 1.593819\tAccuracy: 54.70%\n",
      "179\tValidation loss: 1.849788\tBest loss: 1.593819\tAccuracy: 53.20%\n",
      "180\tValidation loss: 1.713641\tBest loss: 1.593819\tAccuracy: 55.80%\n",
      "181\tValidation loss: 1.538724\tBest loss: 1.538724\tAccuracy: 58.80%\n",
      "182\tValidation loss: 1.660034\tBest loss: 1.538724\tAccuracy: 56.20%\n",
      "183\tValidation loss: 1.681131\tBest loss: 1.538724\tAccuracy: 56.90%\n",
      "184\tValidation loss: 1.850829\tBest loss: 1.538724\tAccuracy: 53.80%\n",
      "185\tValidation loss: 1.712572\tBest loss: 1.538724\tAccuracy: 55.20%\n",
      "186\tValidation loss: 1.687432\tBest loss: 1.538724\tAccuracy: 54.80%\n",
      "187\tValidation loss: 1.640689\tBest loss: 1.538724\tAccuracy: 57.70%\n",
      "188\tValidation loss: 1.675704\tBest loss: 1.538724\tAccuracy: 55.30%\n",
      "189\tValidation loss: 1.707528\tBest loss: 1.538724\tAccuracy: 57.30%\n",
      "190\tValidation loss: 1.782923\tBest loss: 1.538724\tAccuracy: 56.40%\n",
      "191\tValidation loss: 1.824286\tBest loss: 1.538724\tAccuracy: 54.40%\n",
      "192\tValidation loss: 1.869849\tBest loss: 1.538724\tAccuracy: 50.40%\n",
      "193\tValidation loss: 1.605944\tBest loss: 1.538724\tAccuracy: 56.10%\n",
      "194\tValidation loss: 1.719917\tBest loss: 1.538724\tAccuracy: 54.60%\n",
      "195\tValidation loss: 1.700050\tBest loss: 1.538724\tAccuracy: 56.00%\n",
      "196\tValidation loss: 1.772144\tBest loss: 1.538724\tAccuracy: 54.20%\n",
      "197\tValidation loss: 1.754229\tBest loss: 1.538724\tAccuracy: 56.00%\n",
      "198\tValidation loss: 2.533568\tBest loss: 1.538724\tAccuracy: 50.80%\n",
      "199\tValidation loss: 1.721202\tBest loss: 1.538724\tAccuracy: 57.90%\n",
      "200\tValidation loss: 1.638056\tBest loss: 1.538724\tAccuracy: 56.80%\n",
      "201\tValidation loss: 1.661791\tBest loss: 1.538724\tAccuracy: 57.30%\n",
      "202\tValidation loss: 1.650490\tBest loss: 1.538724\tAccuracy: 56.80%\n",
      "Early stopping!\n",
      "[[  2.75736012e-15   4.40356335e-10   7.97460320e-09 ...,   1.79644698e-15\n",
      "    1.72273068e-14   1.26745462e-14]\n",
      " [  7.40559623e-02   3.54338624e-02   6.99252039e-02 ...,   6.30778680e-03\n",
      "    4.07864805e-03   2.59860675e-03]\n",
      " [  1.43861307e-22   7.34334923e-37   8.24844580e-15 ...,   2.28800493e-37\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  5.04127573e-11   9.77964447e-08   5.73316894e-10 ...,   7.44966092e-04\n",
      "    3.61500097e-05   2.04144535e-03]\n",
      " [  4.80318296e-04   5.62201627e-03   1.35145383e-03 ...,   9.96089652e-02\n",
      "    6.25093048e-03   2.23739278e-02]\n",
      " [  1.26516726e-08   6.31253670e-06   5.19593641e-07 ...,   1.15101568e-04\n",
      "    2.54559331e-04   3.13940516e-04]]\n",
      "[11 19 16 ..., 21 24 36]\n",
      "[[  1.19246688e-05   1.71730784e-03   5.65633085e-03 ...,   2.48668457e-05\n",
      "    2.11955867e-05   6.19086903e-04]\n",
      " [  7.12757561e-11   1.25439419e-06   1.28690147e-09 ...,   5.79168050e-12\n",
      "    3.05116453e-11   1.53276017e-10]\n",
      " [  1.79700550e-07   8.61869103e-06   1.73443737e-09 ...,   2.15119460e-08\n",
      "    9.84481051e-13   8.17180545e-09]\n",
      " ..., \n",
      " [  2.17020979e-09   5.12273779e-10   1.03303201e-07 ...,   3.25055842e-17\n",
      "    3.59657914e-13   2.19798707e-13]\n",
      " [  4.19366658e-02   1.96637958e-02   2.80965921e-02 ...,   1.90672241e-02\n",
      "    1.38235940e-02   1.15478924e-02]\n",
      " [  1.82279588e-18   2.20221419e-16   4.76053533e-16 ...,   6.79098943e-04\n",
      "    2.52024531e-02   9.65867877e-01]]\n",
      "[43 43 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  24.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.391160\tBest loss: 4.391160\tAccuracy: 14.40%\n",
      "1\tValidation loss: 4.159237\tBest loss: 4.159237\tAccuracy: 13.30%\n",
      "2\tValidation loss: 3.327777\tBest loss: 3.327777\tAccuracy: 20.50%\n",
      "3\tValidation loss: 3.690001\tBest loss: 3.327777\tAccuracy: 21.40%\n",
      "4\tValidation loss: 2.960284\tBest loss: 2.960284\tAccuracy: 27.60%\n",
      "5\tValidation loss: 2.988415\tBest loss: 2.960284\tAccuracy: 26.10%\n",
      "6\tValidation loss: 2.865189\tBest loss: 2.865189\tAccuracy: 29.90%\n",
      "7\tValidation loss: 2.957641\tBest loss: 2.865189\tAccuracy: 28.70%\n",
      "8\tValidation loss: 2.954292\tBest loss: 2.865189\tAccuracy: 28.30%\n",
      "9\tValidation loss: 2.829568\tBest loss: 2.829568\tAccuracy: 29.90%\n",
      "10\tValidation loss: 2.679315\tBest loss: 2.679315\tAccuracy: 33.40%\n",
      "11\tValidation loss: 2.878213\tBest loss: 2.679315\tAccuracy: 28.60%\n",
      "12\tValidation loss: 2.935171\tBest loss: 2.679315\tAccuracy: 32.10%\n",
      "13\tValidation loss: 2.612323\tBest loss: 2.612323\tAccuracy: 33.70%\n",
      "14\tValidation loss: 2.579282\tBest loss: 2.579282\tAccuracy: 35.10%\n",
      "15\tValidation loss: 2.505248\tBest loss: 2.505248\tAccuracy: 38.90%\n",
      "16\tValidation loss: 2.547480\tBest loss: 2.505248\tAccuracy: 35.90%\n",
      "17\tValidation loss: 2.457016\tBest loss: 2.457016\tAccuracy: 38.40%\n",
      "18\tValidation loss: 2.529731\tBest loss: 2.457016\tAccuracy: 37.20%\n",
      "19\tValidation loss: 2.520339\tBest loss: 2.457016\tAccuracy: 36.00%\n",
      "20\tValidation loss: 2.525850\tBest loss: 2.457016\tAccuracy: 36.10%\n",
      "21\tValidation loss: 2.538225\tBest loss: 2.457016\tAccuracy: 37.70%\n",
      "22\tValidation loss: 2.376503\tBest loss: 2.376503\tAccuracy: 39.20%\n",
      "23\tValidation loss: 2.526051\tBest loss: 2.376503\tAccuracy: 38.50%\n",
      "24\tValidation loss: 2.285511\tBest loss: 2.285511\tAccuracy: 42.80%\n",
      "25\tValidation loss: 2.321479\tBest loss: 2.285511\tAccuracy: 41.10%\n",
      "26\tValidation loss: 2.357033\tBest loss: 2.285511\tAccuracy: 42.90%\n",
      "27\tValidation loss: 2.358521\tBest loss: 2.285511\tAccuracy: 38.20%\n",
      "28\tValidation loss: 2.303634\tBest loss: 2.285511\tAccuracy: 43.10%\n",
      "29\tValidation loss: 2.234138\tBest loss: 2.234138\tAccuracy: 41.90%\n",
      "30\tValidation loss: 2.238507\tBest loss: 2.234138\tAccuracy: 46.10%\n",
      "31\tValidation loss: 2.211083\tBest loss: 2.211083\tAccuracy: 42.60%\n",
      "32\tValidation loss: 2.222153\tBest loss: 2.211083\tAccuracy: 45.00%\n",
      "33\tValidation loss: 2.165652\tBest loss: 2.165652\tAccuracy: 46.00%\n",
      "34\tValidation loss: 2.179643\tBest loss: 2.165652\tAccuracy: 44.30%\n",
      "35\tValidation loss: 2.244290\tBest loss: 2.165652\tAccuracy: 42.60%\n",
      "36\tValidation loss: 2.240083\tBest loss: 2.165652\tAccuracy: 39.90%\n",
      "37\tValidation loss: 2.227258\tBest loss: 2.165652\tAccuracy: 43.40%\n",
      "38\tValidation loss: 2.173673\tBest loss: 2.165652\tAccuracy: 43.70%\n",
      "39\tValidation loss: 2.150340\tBest loss: 2.150340\tAccuracy: 43.90%\n",
      "40\tValidation loss: 2.318655\tBest loss: 2.150340\tAccuracy: 41.40%\n",
      "41\tValidation loss: 2.021630\tBest loss: 2.021630\tAccuracy: 48.30%\n",
      "42\tValidation loss: 2.141861\tBest loss: 2.021630\tAccuracy: 47.00%\n",
      "43\tValidation loss: 2.609457\tBest loss: 2.021630\tAccuracy: 40.20%\n",
      "44\tValidation loss: 2.091639\tBest loss: 2.021630\tAccuracy: 48.10%\n",
      "45\tValidation loss: 2.098148\tBest loss: 2.021630\tAccuracy: 46.00%\n",
      "46\tValidation loss: 2.035923\tBest loss: 2.021630\tAccuracy: 45.70%\n",
      "47\tValidation loss: 2.004516\tBest loss: 2.004516\tAccuracy: 48.50%\n",
      "48\tValidation loss: 2.125178\tBest loss: 2.004516\tAccuracy: 44.10%\n",
      "49\tValidation loss: 2.087455\tBest loss: 2.004516\tAccuracy: 45.40%\n",
      "50\tValidation loss: 2.086146\tBest loss: 2.004516\tAccuracy: 47.00%\n",
      "51\tValidation loss: 2.092686\tBest loss: 2.004516\tAccuracy: 45.10%\n",
      "52\tValidation loss: 2.104862\tBest loss: 2.004516\tAccuracy: 46.70%\n",
      "53\tValidation loss: 2.099115\tBest loss: 2.004516\tAccuracy: 43.70%\n",
      "54\tValidation loss: 2.057602\tBest loss: 2.004516\tAccuracy: 47.80%\n",
      "55\tValidation loss: 2.132409\tBest loss: 2.004516\tAccuracy: 46.30%\n",
      "56\tValidation loss: 2.056825\tBest loss: 2.004516\tAccuracy: 46.90%\n",
      "57\tValidation loss: 1.943096\tBest loss: 1.943096\tAccuracy: 49.80%\n",
      "58\tValidation loss: 2.072225\tBest loss: 1.943096\tAccuracy: 47.60%\n",
      "59\tValidation loss: 1.982119\tBest loss: 1.943096\tAccuracy: 49.30%\n",
      "60\tValidation loss: 2.008541\tBest loss: 1.943096\tAccuracy: 49.10%\n",
      "61\tValidation loss: 2.024704\tBest loss: 1.943096\tAccuracy: 49.20%\n",
      "62\tValidation loss: 2.049693\tBest loss: 1.943096\tAccuracy: 47.50%\n",
      "63\tValidation loss: 1.951954\tBest loss: 1.943096\tAccuracy: 49.30%\n",
      "64\tValidation loss: 2.021725\tBest loss: 1.943096\tAccuracy: 50.50%\n",
      "65\tValidation loss: 1.898551\tBest loss: 1.898551\tAccuracy: 52.50%\n",
      "66\tValidation loss: 1.976160\tBest loss: 1.898551\tAccuracy: 49.50%\n",
      "67\tValidation loss: 1.955233\tBest loss: 1.898551\tAccuracy: 50.70%\n",
      "68\tValidation loss: 1.953393\tBest loss: 1.898551\tAccuracy: 51.30%\n",
      "69\tValidation loss: 1.916801\tBest loss: 1.898551\tAccuracy: 51.10%\n",
      "70\tValidation loss: 1.888076\tBest loss: 1.888076\tAccuracy: 49.50%\n",
      "71\tValidation loss: 1.934490\tBest loss: 1.888076\tAccuracy: 51.00%\n",
      "72\tValidation loss: 1.988513\tBest loss: 1.888076\tAccuracy: 48.90%\n",
      "73\tValidation loss: 2.086717\tBest loss: 1.888076\tAccuracy: 47.90%\n",
      "74\tValidation loss: 1.859530\tBest loss: 1.859530\tAccuracy: 51.10%\n",
      "75\tValidation loss: 1.899011\tBest loss: 1.859530\tAccuracy: 50.10%\n",
      "76\tValidation loss: 2.089882\tBest loss: 1.859530\tAccuracy: 46.80%\n",
      "77\tValidation loss: 1.935283\tBest loss: 1.859530\tAccuracy: 50.10%\n",
      "78\tValidation loss: 2.149482\tBest loss: 1.859530\tAccuracy: 42.20%\n",
      "79\tValidation loss: 1.895926\tBest loss: 1.859530\tAccuracy: 51.00%\n",
      "80\tValidation loss: 1.962376\tBest loss: 1.859530\tAccuracy: 50.30%\n",
      "81\tValidation loss: 1.872231\tBest loss: 1.859530\tAccuracy: 49.70%\n",
      "82\tValidation loss: 1.859823\tBest loss: 1.859530\tAccuracy: 51.90%\n",
      "83\tValidation loss: 1.867548\tBest loss: 1.859530\tAccuracy: 53.50%\n",
      "84\tValidation loss: 1.872721\tBest loss: 1.859530\tAccuracy: 50.80%\n",
      "85\tValidation loss: 1.958597\tBest loss: 1.859530\tAccuracy: 50.80%\n",
      "86\tValidation loss: 1.830023\tBest loss: 1.830023\tAccuracy: 51.30%\n",
      "87\tValidation loss: 1.987183\tBest loss: 1.830023\tAccuracy: 48.20%\n",
      "88\tValidation loss: 1.873672\tBest loss: 1.830023\tAccuracy: 49.60%\n",
      "89\tValidation loss: 1.894106\tBest loss: 1.830023\tAccuracy: 50.50%\n",
      "90\tValidation loss: 1.837780\tBest loss: 1.830023\tAccuracy: 50.60%\n",
      "91\tValidation loss: 1.872251\tBest loss: 1.830023\tAccuracy: 51.80%\n",
      "92\tValidation loss: 1.842244\tBest loss: 1.830023\tAccuracy: 53.60%\n",
      "93\tValidation loss: 1.850781\tBest loss: 1.830023\tAccuracy: 51.80%\n",
      "94\tValidation loss: 1.854977\tBest loss: 1.830023\tAccuracy: 50.40%\n",
      "95\tValidation loss: 1.912927\tBest loss: 1.830023\tAccuracy: 52.90%\n",
      "96\tValidation loss: 1.879761\tBest loss: 1.830023\tAccuracy: 50.60%\n",
      "97\tValidation loss: 1.999192\tBest loss: 1.830023\tAccuracy: 49.50%\n",
      "98\tValidation loss: 1.762676\tBest loss: 1.762676\tAccuracy: 54.10%\n",
      "99\tValidation loss: 1.936389\tBest loss: 1.762676\tAccuracy: 51.80%\n",
      "100\tValidation loss: 1.753645\tBest loss: 1.753645\tAccuracy: 52.50%\n",
      "101\tValidation loss: 1.816421\tBest loss: 1.753645\tAccuracy: 51.00%\n",
      "102\tValidation loss: 1.865254\tBest loss: 1.753645\tAccuracy: 52.80%\n",
      "103\tValidation loss: 1.877400\tBest loss: 1.753645\tAccuracy: 50.40%\n",
      "104\tValidation loss: 1.758192\tBest loss: 1.753645\tAccuracy: 54.80%\n",
      "105\tValidation loss: 1.773375\tBest loss: 1.753645\tAccuracy: 52.60%\n",
      "106\tValidation loss: 1.827631\tBest loss: 1.753645\tAccuracy: 54.20%\n",
      "107\tValidation loss: 1.761692\tBest loss: 1.753645\tAccuracy: 53.00%\n",
      "108\tValidation loss: 2.100977\tBest loss: 1.753645\tAccuracy: 46.60%\n",
      "109\tValidation loss: 1.738220\tBest loss: 1.738220\tAccuracy: 53.90%\n",
      "110\tValidation loss: 1.687357\tBest loss: 1.687357\tAccuracy: 54.50%\n",
      "111\tValidation loss: 1.833245\tBest loss: 1.687357\tAccuracy: 52.90%\n",
      "112\tValidation loss: 1.781095\tBest loss: 1.687357\tAccuracy: 54.10%\n",
      "113\tValidation loss: 1.745478\tBest loss: 1.687357\tAccuracy: 53.90%\n",
      "114\tValidation loss: 1.756745\tBest loss: 1.687357\tAccuracy: 53.60%\n",
      "115\tValidation loss: 1.844009\tBest loss: 1.687357\tAccuracy: 51.80%\n",
      "116\tValidation loss: 1.860405\tBest loss: 1.687357\tAccuracy: 52.50%\n",
      "117\tValidation loss: 1.805447\tBest loss: 1.687357\tAccuracy: 53.30%\n",
      "118\tValidation loss: 2.025537\tBest loss: 1.687357\tAccuracy: 51.50%\n",
      "119\tValidation loss: 1.943096\tBest loss: 1.687357\tAccuracy: 50.90%\n",
      "120\tValidation loss: 1.968095\tBest loss: 1.687357\tAccuracy: 50.20%\n",
      "121\tValidation loss: 1.825546\tBest loss: 1.687357\tAccuracy: 52.30%\n",
      "122\tValidation loss: 1.721238\tBest loss: 1.687357\tAccuracy: 54.90%\n",
      "123\tValidation loss: 1.992009\tBest loss: 1.687357\tAccuracy: 49.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 1.793037\tBest loss: 1.687357\tAccuracy: 53.50%\n",
      "125\tValidation loss: 1.681642\tBest loss: 1.681642\tAccuracy: 56.80%\n",
      "126\tValidation loss: 1.680662\tBest loss: 1.680662\tAccuracy: 54.50%\n",
      "127\tValidation loss: 1.745506\tBest loss: 1.680662\tAccuracy: 55.30%\n",
      "128\tValidation loss: 1.827677\tBest loss: 1.680662\tAccuracy: 51.90%\n",
      "129\tValidation loss: 1.786158\tBest loss: 1.680662\tAccuracy: 52.10%\n",
      "130\tValidation loss: 1.813650\tBest loss: 1.680662\tAccuracy: 52.20%\n",
      "131\tValidation loss: 1.793128\tBest loss: 1.680662\tAccuracy: 51.80%\n",
      "132\tValidation loss: 1.713937\tBest loss: 1.680662\tAccuracy: 55.50%\n",
      "133\tValidation loss: 1.764484\tBest loss: 1.680662\tAccuracy: 53.40%\n",
      "134\tValidation loss: 1.715023\tBest loss: 1.680662\tAccuracy: 54.60%\n",
      "135\tValidation loss: 1.740830\tBest loss: 1.680662\tAccuracy: 54.00%\n",
      "136\tValidation loss: 1.725058\tBest loss: 1.680662\tAccuracy: 55.90%\n",
      "137\tValidation loss: 1.729293\tBest loss: 1.680662\tAccuracy: 53.80%\n",
      "138\tValidation loss: 1.729369\tBest loss: 1.680662\tAccuracy: 53.60%\n",
      "139\tValidation loss: 1.734029\tBest loss: 1.680662\tAccuracy: 54.40%\n",
      "140\tValidation loss: 1.704005\tBest loss: 1.680662\tAccuracy: 54.90%\n",
      "141\tValidation loss: 1.839202\tBest loss: 1.680662\tAccuracy: 51.20%\n",
      "142\tValidation loss: 1.939894\tBest loss: 1.680662\tAccuracy: 50.00%\n",
      "143\tValidation loss: 1.669281\tBest loss: 1.669281\tAccuracy: 55.40%\n",
      "144\tValidation loss: 1.687747\tBest loss: 1.669281\tAccuracy: 56.80%\n",
      "145\tValidation loss: 1.792206\tBest loss: 1.669281\tAccuracy: 55.50%\n",
      "146\tValidation loss: 1.703331\tBest loss: 1.669281\tAccuracy: 55.40%\n",
      "147\tValidation loss: 2.148558\tBest loss: 1.669281\tAccuracy: 48.10%\n",
      "148\tValidation loss: 1.808543\tBest loss: 1.669281\tAccuracy: 54.40%\n",
      "149\tValidation loss: 1.766132\tBest loss: 1.669281\tAccuracy: 53.80%\n",
      "150\tValidation loss: 1.767177\tBest loss: 1.669281\tAccuracy: 52.60%\n",
      "151\tValidation loss: 1.748110\tBest loss: 1.669281\tAccuracy: 54.80%\n",
      "152\tValidation loss: 1.649908\tBest loss: 1.649908\tAccuracy: 55.90%\n",
      "153\tValidation loss: 1.724632\tBest loss: 1.649908\tAccuracy: 55.30%\n",
      "154\tValidation loss: 1.851087\tBest loss: 1.649908\tAccuracy: 53.50%\n",
      "155\tValidation loss: 2.076779\tBest loss: 1.649908\tAccuracy: 50.00%\n",
      "156\tValidation loss: 1.645038\tBest loss: 1.645038\tAccuracy: 56.70%\n",
      "157\tValidation loss: 1.737600\tBest loss: 1.645038\tAccuracy: 54.80%\n",
      "158\tValidation loss: 1.748049\tBest loss: 1.645038\tAccuracy: 54.90%\n",
      "159\tValidation loss: 1.708919\tBest loss: 1.645038\tAccuracy: 55.80%\n",
      "160\tValidation loss: 1.842776\tBest loss: 1.645038\tAccuracy: 52.10%\n",
      "161\tValidation loss: 1.738467\tBest loss: 1.645038\tAccuracy: 54.20%\n",
      "162\tValidation loss: 1.736373\tBest loss: 1.645038\tAccuracy: 57.10%\n",
      "163\tValidation loss: 1.661917\tBest loss: 1.645038\tAccuracy: 55.10%\n",
      "164\tValidation loss: 1.730353\tBest loss: 1.645038\tAccuracy: 56.00%\n",
      "165\tValidation loss: 1.731935\tBest loss: 1.645038\tAccuracy: 56.00%\n",
      "166\tValidation loss: 1.798765\tBest loss: 1.645038\tAccuracy: 51.90%\n",
      "167\tValidation loss: 1.785211\tBest loss: 1.645038\tAccuracy: 53.50%\n",
      "168\tValidation loss: 1.658496\tBest loss: 1.645038\tAccuracy: 57.30%\n",
      "169\tValidation loss: 1.763155\tBest loss: 1.645038\tAccuracy: 52.50%\n",
      "170\tValidation loss: 1.969509\tBest loss: 1.645038\tAccuracy: 50.90%\n",
      "171\tValidation loss: 1.792079\tBest loss: 1.645038\tAccuracy: 55.00%\n",
      "172\tValidation loss: 1.739381\tBest loss: 1.645038\tAccuracy: 51.60%\n",
      "173\tValidation loss: 1.660559\tBest loss: 1.645038\tAccuracy: 56.30%\n",
      "174\tValidation loss: 1.727878\tBest loss: 1.645038\tAccuracy: 55.50%\n",
      "175\tValidation loss: 1.705522\tBest loss: 1.645038\tAccuracy: 56.40%\n",
      "176\tValidation loss: 1.717566\tBest loss: 1.645038\tAccuracy: 57.70%\n",
      "177\tValidation loss: 1.706625\tBest loss: 1.645038\tAccuracy: 57.20%\n",
      "Early stopping!\n",
      "[[  5.72098303e-04   1.20022835e-03   1.89140439e-03 ...,   1.93026470e-04\n",
      "    1.79469062e-04   5.88206691e-04]\n",
      " [  6.68561384e-09   2.74113813e-06   5.26292752e-06 ...,   4.01450054e-11\n",
      "    4.69733363e-10   4.87495377e-09]\n",
      " [  1.02711883e-05   8.50892538e-05   4.97797846e-05 ...,   7.39815448e-07\n",
      "    3.46890872e-08   9.82379561e-07]\n",
      " ..., \n",
      " [  2.74274568e-03   2.59981584e-03   5.27106924e-03 ...,   1.42243812e-02\n",
      "    1.58951879e-02   2.33940110e-02]\n",
      " [  2.72248644e-06   4.62745857e-06   7.28229179e-06 ...,   1.35227665e-01\n",
      "    9.03013721e-02   1.20460741e-01]\n",
      " [  2.81115753e-09   7.64587469e-08   2.76200236e-08 ...,   4.84336168e-04\n",
      "    4.76853596e-03   2.23096665e-02]]\n",
      "[38 43 43 ...,  8 24  8]\n",
      "[[  2.04315193e-11   2.60250466e-09   2.10585881e-07 ...,   4.70059376e-14\n",
      "    6.47760491e-13   4.42391393e-12]\n",
      " [  8.02536756e-02   3.70488279e-02   8.04999843e-02 ...,   7.23600667e-03\n",
      "    6.35138014e-03   3.35948425e-03]\n",
      " [  1.77517819e-19   6.34294824e-31   6.20142693e-09 ...,   5.54627951e-31\n",
      "    1.18840127e-36   0.00000000e+00]\n",
      " ..., \n",
      " [  4.84060925e-12   2.15919571e-09   4.68630246e-09 ...,   3.11193404e-21\n",
      "    5.43336696e-16   4.16315668e-17]\n",
      " [  3.92655283e-02   2.33383458e-02   3.16187292e-02 ...,   1.48203950e-02\n",
      "    1.51509810e-02   1.26895616e-02]\n",
      " [  5.00235195e-14   6.07226454e-13   2.58945317e-12 ...,   2.15258973e-04\n",
      "    2.74541192e-02   9.05415952e-01]]\n",
      "[22 19 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  21.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 4.283622\tBest loss: 4.283622\tAccuracy: 10.90%\n",
      "1\tValidation loss: 3.474928\tBest loss: 3.474928\tAccuracy: 16.90%\n",
      "2\tValidation loss: 3.345227\tBest loss: 3.345227\tAccuracy: 21.20%\n",
      "3\tValidation loss: 3.186743\tBest loss: 3.186743\tAccuracy: 23.40%\n",
      "4\tValidation loss: 3.000972\tBest loss: 3.000972\tAccuracy: 27.10%\n",
      "5\tValidation loss: 2.879995\tBest loss: 2.879995\tAccuracy: 27.70%\n",
      "6\tValidation loss: 2.987230\tBest loss: 2.879995\tAccuracy: 24.50%\n",
      "7\tValidation loss: 2.925151\tBest loss: 2.879995\tAccuracy: 27.80%\n",
      "8\tValidation loss: 2.758346\tBest loss: 2.758346\tAccuracy: 32.40%\n",
      "9\tValidation loss: 2.760374\tBest loss: 2.758346\tAccuracy: 32.50%\n",
      "10\tValidation loss: 2.822707\tBest loss: 2.758346\tAccuracy: 31.30%\n",
      "11\tValidation loss: 2.555923\tBest loss: 2.555923\tAccuracy: 35.30%\n",
      "12\tValidation loss: 2.713302\tBest loss: 2.555923\tAccuracy: 33.10%\n",
      "13\tValidation loss: 2.520137\tBest loss: 2.520137\tAccuracy: 39.10%\n",
      "14\tValidation loss: 2.529853\tBest loss: 2.520137\tAccuracy: 37.80%\n",
      "15\tValidation loss: 2.536738\tBest loss: 2.520137\tAccuracy: 38.40%\n",
      "16\tValidation loss: 2.558939\tBest loss: 2.520137\tAccuracy: 39.40%\n",
      "17\tValidation loss: 2.481359\tBest loss: 2.481359\tAccuracy: 37.30%\n",
      "18\tValidation loss: 2.511102\tBest loss: 2.481359\tAccuracy: 38.60%\n",
      "19\tValidation loss: 2.431663\tBest loss: 2.431663\tAccuracy: 37.60%\n",
      "20\tValidation loss: 2.508325\tBest loss: 2.431663\tAccuracy: 39.50%\n",
      "21\tValidation loss: 2.499918\tBest loss: 2.431663\tAccuracy: 38.20%\n",
      "22\tValidation loss: 2.434285\tBest loss: 2.431663\tAccuracy: 38.40%\n",
      "23\tValidation loss: 2.396580\tBest loss: 2.396580\tAccuracy: 38.60%\n",
      "24\tValidation loss: 2.420753\tBest loss: 2.396580\tAccuracy: 39.30%\n",
      "25\tValidation loss: 2.470860\tBest loss: 2.396580\tAccuracy: 38.80%\n",
      "26\tValidation loss: 2.485852\tBest loss: 2.396580\tAccuracy: 42.10%\n",
      "27\tValidation loss: 2.419193\tBest loss: 2.396580\tAccuracy: 39.00%\n",
      "28\tValidation loss: 2.317980\tBest loss: 2.317980\tAccuracy: 42.60%\n",
      "29\tValidation loss: 2.399997\tBest loss: 2.317980\tAccuracy: 41.40%\n",
      "30\tValidation loss: 2.331242\tBest loss: 2.317980\tAccuracy: 45.50%\n",
      "31\tValidation loss: 2.381395\tBest loss: 2.317980\tAccuracy: 41.90%\n",
      "32\tValidation loss: 2.214396\tBest loss: 2.214396\tAccuracy: 45.40%\n",
      "33\tValidation loss: 2.141851\tBest loss: 2.141851\tAccuracy: 48.80%\n",
      "34\tValidation loss: 2.219132\tBest loss: 2.141851\tAccuracy: 43.30%\n",
      "35\tValidation loss: 2.233078\tBest loss: 2.141851\tAccuracy: 43.20%\n",
      "36\tValidation loss: 2.231887\tBest loss: 2.141851\tAccuracy: 44.20%\n",
      "37\tValidation loss: 2.215035\tBest loss: 2.141851\tAccuracy: 42.80%\n",
      "38\tValidation loss: 2.284211\tBest loss: 2.141851\tAccuracy: 44.20%\n",
      "39\tValidation loss: 2.174469\tBest loss: 2.141851\tAccuracy: 45.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\tValidation loss: 2.251892\tBest loss: 2.141851\tAccuracy: 44.10%\n",
      "41\tValidation loss: 2.067917\tBest loss: 2.067917\tAccuracy: 49.20%\n",
      "42\tValidation loss: 2.408349\tBest loss: 2.067917\tAccuracy: 41.50%\n",
      "43\tValidation loss: 2.149225\tBest loss: 2.067917\tAccuracy: 46.70%\n",
      "44\tValidation loss: 2.147243\tBest loss: 2.067917\tAccuracy: 45.20%\n",
      "45\tValidation loss: 1.995720\tBest loss: 1.995720\tAccuracy: 49.10%\n",
      "46\tValidation loss: 2.226604\tBest loss: 1.995720\tAccuracy: 45.70%\n",
      "47\tValidation loss: 2.038246\tBest loss: 1.995720\tAccuracy: 48.50%\n",
      "48\tValidation loss: 2.048627\tBest loss: 1.995720\tAccuracy: 48.70%\n",
      "49\tValidation loss: 2.060687\tBest loss: 1.995720\tAccuracy: 49.50%\n",
      "50\tValidation loss: 2.135046\tBest loss: 1.995720\tAccuracy: 45.70%\n",
      "51\tValidation loss: 2.457995\tBest loss: 1.995720\tAccuracy: 40.00%\n",
      "52\tValidation loss: 2.058046\tBest loss: 1.995720\tAccuracy: 46.40%\n",
      "53\tValidation loss: 2.059057\tBest loss: 1.995720\tAccuracy: 48.50%\n",
      "54\tValidation loss: 2.012504\tBest loss: 1.995720\tAccuracy: 47.20%\n",
      "55\tValidation loss: 2.009572\tBest loss: 1.995720\tAccuracy: 48.50%\n",
      "56\tValidation loss: 2.041546\tBest loss: 1.995720\tAccuracy: 48.60%\n",
      "57\tValidation loss: 2.100568\tBest loss: 1.995720\tAccuracy: 47.90%\n",
      "58\tValidation loss: 2.124240\tBest loss: 1.995720\tAccuracy: 46.70%\n",
      "59\tValidation loss: 1.986333\tBest loss: 1.986333\tAccuracy: 48.20%\n",
      "60\tValidation loss: 1.960059\tBest loss: 1.960059\tAccuracy: 49.20%\n",
      "61\tValidation loss: 2.090148\tBest loss: 1.960059\tAccuracy: 48.50%\n",
      "62\tValidation loss: 2.119806\tBest loss: 1.960059\tAccuracy: 46.00%\n",
      "63\tValidation loss: 2.263422\tBest loss: 1.960059\tAccuracy: 46.70%\n",
      "64\tValidation loss: 1.998737\tBest loss: 1.960059\tAccuracy: 49.40%\n",
      "65\tValidation loss: 2.137576\tBest loss: 1.960059\tAccuracy: 45.90%\n",
      "66\tValidation loss: 1.974286\tBest loss: 1.960059\tAccuracy: 50.40%\n",
      "67\tValidation loss: 1.954368\tBest loss: 1.954368\tAccuracy: 50.60%\n",
      "68\tValidation loss: 1.871581\tBest loss: 1.871581\tAccuracy: 53.50%\n",
      "69\tValidation loss: 1.968985\tBest loss: 1.871581\tAccuracy: 51.00%\n",
      "70\tValidation loss: 2.188888\tBest loss: 1.871581\tAccuracy: 44.30%\n",
      "71\tValidation loss: 1.963465\tBest loss: 1.871581\tAccuracy: 49.00%\n",
      "72\tValidation loss: 1.878141\tBest loss: 1.871581\tAccuracy: 49.90%\n",
      "73\tValidation loss: 2.014576\tBest loss: 1.871581\tAccuracy: 47.90%\n",
      "74\tValidation loss: 1.899194\tBest loss: 1.871581\tAccuracy: 52.00%\n",
      "75\tValidation loss: 2.062636\tBest loss: 1.871581\tAccuracy: 47.30%\n",
      "76\tValidation loss: 1.944044\tBest loss: 1.871581\tAccuracy: 51.20%\n",
      "77\tValidation loss: 2.099883\tBest loss: 1.871581\tAccuracy: 49.00%\n",
      "78\tValidation loss: 1.920712\tBest loss: 1.871581\tAccuracy: 49.50%\n",
      "79\tValidation loss: 1.869856\tBest loss: 1.869856\tAccuracy: 53.20%\n",
      "80\tValidation loss: 1.832947\tBest loss: 1.832947\tAccuracy: 51.90%\n",
      "81\tValidation loss: 2.052183\tBest loss: 1.832947\tAccuracy: 48.50%\n",
      "82\tValidation loss: 1.890160\tBest loss: 1.832947\tAccuracy: 49.90%\n",
      "83\tValidation loss: 1.940920\tBest loss: 1.832947\tAccuracy: 49.80%\n",
      "84\tValidation loss: 1.975652\tBest loss: 1.832947\tAccuracy: 52.20%\n",
      "85\tValidation loss: 2.336460\tBest loss: 1.832947\tAccuracy: 44.60%\n",
      "86\tValidation loss: 1.918572\tBest loss: 1.832947\tAccuracy: 50.90%\n",
      "87\tValidation loss: 1.971115\tBest loss: 1.832947\tAccuracy: 49.80%\n",
      "88\tValidation loss: 1.939207\tBest loss: 1.832947\tAccuracy: 50.00%\n",
      "89\tValidation loss: 1.790578\tBest loss: 1.790578\tAccuracy: 52.80%\n",
      "90\tValidation loss: 1.978914\tBest loss: 1.790578\tAccuracy: 48.90%\n",
      "91\tValidation loss: 1.949006\tBest loss: 1.790578\tAccuracy: 48.60%\n",
      "92\tValidation loss: 1.836913\tBest loss: 1.790578\tAccuracy: 51.70%\n",
      "93\tValidation loss: 1.932208\tBest loss: 1.790578\tAccuracy: 50.00%\n",
      "94\tValidation loss: 1.948679\tBest loss: 1.790578\tAccuracy: 51.70%\n",
      "95\tValidation loss: 2.156760\tBest loss: 1.790578\tAccuracy: 48.20%\n",
      "96\tValidation loss: 1.769464\tBest loss: 1.769464\tAccuracy: 54.20%\n",
      "97\tValidation loss: 1.783390\tBest loss: 1.769464\tAccuracy: 55.10%\n",
      "98\tValidation loss: 1.980300\tBest loss: 1.769464\tAccuracy: 50.60%\n",
      "99\tValidation loss: 1.883229\tBest loss: 1.769464\tAccuracy: 52.50%\n",
      "100\tValidation loss: 1.858268\tBest loss: 1.769464\tAccuracy: 52.50%\n",
      "101\tValidation loss: 1.809109\tBest loss: 1.769464\tAccuracy: 54.20%\n",
      "102\tValidation loss: 1.841621\tBest loss: 1.769464\tAccuracy: 51.60%\n",
      "103\tValidation loss: 1.788925\tBest loss: 1.769464\tAccuracy: 52.90%\n",
      "104\tValidation loss: 1.909122\tBest loss: 1.769464\tAccuracy: 52.80%\n",
      "105\tValidation loss: 1.806202\tBest loss: 1.769464\tAccuracy: 53.90%\n",
      "106\tValidation loss: 1.801892\tBest loss: 1.769464\tAccuracy: 51.40%\n",
      "107\tValidation loss: 1.776682\tBest loss: 1.769464\tAccuracy: 53.20%\n",
      "108\tValidation loss: 1.731055\tBest loss: 1.731055\tAccuracy: 55.20%\n",
      "109\tValidation loss: 1.920594\tBest loss: 1.731055\tAccuracy: 51.50%\n",
      "110\tValidation loss: 1.836035\tBest loss: 1.731055\tAccuracy: 52.70%\n",
      "111\tValidation loss: 1.902903\tBest loss: 1.731055\tAccuracy: 51.80%\n",
      "112\tValidation loss: 1.833911\tBest loss: 1.731055\tAccuracy: 54.00%\n",
      "113\tValidation loss: 1.807054\tBest loss: 1.731055\tAccuracy: 53.20%\n",
      "114\tValidation loss: 1.765936\tBest loss: 1.731055\tAccuracy: 54.70%\n",
      "115\tValidation loss: 2.125794\tBest loss: 1.731055\tAccuracy: 49.30%\n",
      "116\tValidation loss: 1.761486\tBest loss: 1.731055\tAccuracy: 53.00%\n",
      "117\tValidation loss: 1.793702\tBest loss: 1.731055\tAccuracy: 53.90%\n",
      "118\tValidation loss: 1.716331\tBest loss: 1.716331\tAccuracy: 55.70%\n",
      "119\tValidation loss: 1.769773\tBest loss: 1.716331\tAccuracy: 57.00%\n",
      "120\tValidation loss: 2.047037\tBest loss: 1.716331\tAccuracy: 50.30%\n",
      "121\tValidation loss: 2.757338\tBest loss: 1.716331\tAccuracy: 45.40%\n",
      "122\tValidation loss: 1.857001\tBest loss: 1.716331\tAccuracy: 54.70%\n",
      "123\tValidation loss: 1.685005\tBest loss: 1.685005\tAccuracy: 57.00%\n",
      "124\tValidation loss: 1.753753\tBest loss: 1.685005\tAccuracy: 54.80%\n",
      "125\tValidation loss: 1.792434\tBest loss: 1.685005\tAccuracy: 55.60%\n",
      "126\tValidation loss: 1.852496\tBest loss: 1.685005\tAccuracy: 54.90%\n",
      "127\tValidation loss: 1.878089\tBest loss: 1.685005\tAccuracy: 51.90%\n",
      "128\tValidation loss: 1.833439\tBest loss: 1.685005\tAccuracy: 53.00%\n",
      "129\tValidation loss: 1.745831\tBest loss: 1.685005\tAccuracy: 55.40%\n",
      "130\tValidation loss: 1.722463\tBest loss: 1.685005\tAccuracy: 54.70%\n",
      "131\tValidation loss: 1.654441\tBest loss: 1.654441\tAccuracy: 56.90%\n",
      "132\tValidation loss: 1.625994\tBest loss: 1.625994\tAccuracy: 56.70%\n",
      "133\tValidation loss: 1.716216\tBest loss: 1.625994\tAccuracy: 55.90%\n",
      "134\tValidation loss: 1.777482\tBest loss: 1.625994\tAccuracy: 54.70%\n",
      "135\tValidation loss: 1.782565\tBest loss: 1.625994\tAccuracy: 52.30%\n",
      "136\tValidation loss: 1.710990\tBest loss: 1.625994\tAccuracy: 54.60%\n",
      "137\tValidation loss: 1.700261\tBest loss: 1.625994\tAccuracy: 54.70%\n",
      "138\tValidation loss: 1.729417\tBest loss: 1.625994\tAccuracy: 55.00%\n",
      "139\tValidation loss: 1.737717\tBest loss: 1.625994\tAccuracy: 55.90%\n",
      "140\tValidation loss: 1.751179\tBest loss: 1.625994\tAccuracy: 56.00%\n",
      "141\tValidation loss: 2.012799\tBest loss: 1.625994\tAccuracy: 51.20%\n",
      "142\tValidation loss: 1.763917\tBest loss: 1.625994\tAccuracy: 55.30%\n",
      "143\tValidation loss: 1.793309\tBest loss: 1.625994\tAccuracy: 52.00%\n",
      "144\tValidation loss: 1.919967\tBest loss: 1.625994\tAccuracy: 51.20%\n",
      "145\tValidation loss: 1.651890\tBest loss: 1.625994\tAccuracy: 56.80%\n",
      "146\tValidation loss: 1.840793\tBest loss: 1.625994\tAccuracy: 51.00%\n",
      "147\tValidation loss: 1.675354\tBest loss: 1.625994\tAccuracy: 56.60%\n",
      "148\tValidation loss: 1.706154\tBest loss: 1.625994\tAccuracy: 56.30%\n",
      "149\tValidation loss: 1.766349\tBest loss: 1.625994\tAccuracy: 55.30%\n",
      "150\tValidation loss: 1.645608\tBest loss: 1.625994\tAccuracy: 57.10%\n",
      "151\tValidation loss: 1.745874\tBest loss: 1.625994\tAccuracy: 55.40%\n",
      "152\tValidation loss: 1.987928\tBest loss: 1.625994\tAccuracy: 49.60%\n",
      "153\tValidation loss: 1.767908\tBest loss: 1.625994\tAccuracy: 55.40%\n",
      "Early stopping!\n",
      "[[  1.18658151e-02   1.80846546e-02   2.73200101e-03 ...,   1.78832971e-02\n",
      "    1.02249428e-03   3.86563106e-03]\n",
      " [  6.29989681e-21   2.09606328e-15   5.54641705e-15 ...,   3.72774300e-09\n",
      "    6.71991562e-18   1.14621854e-13]\n",
      " [  5.23877934e-05   5.97020669e-04   1.03503140e-03 ...,   1.10456043e-04\n",
      "    5.83746238e-04   5.13948360e-03]\n",
      " ..., \n",
      " [  1.10001794e-08   9.39592737e-10   8.45616643e-09 ...,   2.90119008e-17\n",
      "    1.79896161e-14   4.22723735e-15]\n",
      " [  3.95223983e-02   2.36632861e-02   2.38295905e-02 ...,   2.14674734e-02\n",
      "    1.48512488e-02   1.30446805e-02]\n",
      " [  3.03932159e-14   3.09352628e-14   1.12777483e-13 ...,   1.93198747e-03\n",
      "    2.67152712e-02   8.72865021e-01]]\n",
      "[41 41 22 ...,  6  8 47]\n",
      "[[  5.40748490e-13   3.10310844e-09   1.01755304e-09 ...,   1.16912671e-14\n",
      "    1.62828884e-13   1.95945343e-11]\n",
      " [  5.65505102e-02   3.71813364e-02   5.13984226e-02 ...,   1.07382694e-02\n",
      "    7.67080113e-03   4.60994197e-03]\n",
      " [  1.19823051e-17   4.09294347e-28   1.44971413e-11 ...,   2.15012726e-27\n",
      "    7.53240244e-38   0.00000000e+00]\n",
      " ..., \n",
      " [  9.90113243e-04   9.49881680e-04   1.59158092e-03 ...,   1.67242922e-02\n",
      "    1.92122534e-02   3.47401984e-02]\n",
      " [  2.70416167e-05   2.51743427e-06   6.76679110e-06 ...,   9.58858132e-02\n",
      "    9.03437752e-03   2.17211973e-02]\n",
      " [  1.05891067e-10   7.32097121e-08   7.61683105e-10 ...,   1.37339334e-03\n",
      "    8.10260361e-04   3.11516132e-03]]\n",
      "[11 19 16 ...,  8 27 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  18.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.869310\tBest loss: 3.869310\tAccuracy: 4.80%\n",
      "1\tValidation loss: 3.752657\tBest loss: 3.752657\tAccuracy: 7.00%\n",
      "2\tValidation loss: 3.667762\tBest loss: 3.667762\tAccuracy: 9.40%\n",
      "3\tValidation loss: 3.544249\tBest loss: 3.544249\tAccuracy: 11.80%\n",
      "4\tValidation loss: 3.469278\tBest loss: 3.469278\tAccuracy: 16.40%\n",
      "5\tValidation loss: 3.393275\tBest loss: 3.393275\tAccuracy: 14.80%\n",
      "6\tValidation loss: 3.312660\tBest loss: 3.312660\tAccuracy: 17.20%\n",
      "7\tValidation loss: 3.212292\tBest loss: 3.212292\tAccuracy: 18.60%\n",
      "8\tValidation loss: 3.168512\tBest loss: 3.168512\tAccuracy: 17.00%\n",
      "9\tValidation loss: 3.158611\tBest loss: 3.158611\tAccuracy: 16.30%\n",
      "10\tValidation loss: 3.042719\tBest loss: 3.042719\tAccuracy: 20.20%\n",
      "11\tValidation loss: 2.978338\tBest loss: 2.978338\tAccuracy: 21.70%\n",
      "12\tValidation loss: 2.929699\tBest loss: 2.929699\tAccuracy: 22.10%\n",
      "13\tValidation loss: 2.839825\tBest loss: 2.839825\tAccuracy: 25.90%\n",
      "14\tValidation loss: 2.871220\tBest loss: 2.839825\tAccuracy: 23.40%\n",
      "15\tValidation loss: 2.869315\tBest loss: 2.839825\tAccuracy: 23.40%\n",
      "16\tValidation loss: 2.943018\tBest loss: 2.839825\tAccuracy: 23.00%\n",
      "17\tValidation loss: 2.672183\tBest loss: 2.672183\tAccuracy: 28.50%\n",
      "18\tValidation loss: 2.716086\tBest loss: 2.672183\tAccuracy: 27.30%\n",
      "19\tValidation loss: 2.748410\tBest loss: 2.672183\tAccuracy: 26.60%\n",
      "20\tValidation loss: 2.699531\tBest loss: 2.672183\tAccuracy: 30.70%\n",
      "21\tValidation loss: 2.642382\tBest loss: 2.642382\tAccuracy: 29.40%\n",
      "22\tValidation loss: 2.900251\tBest loss: 2.642382\tAccuracy: 23.00%\n",
      "23\tValidation loss: 2.699856\tBest loss: 2.642382\tAccuracy: 25.30%\n",
      "24\tValidation loss: 2.629729\tBest loss: 2.629729\tAccuracy: 30.60%\n",
      "25\tValidation loss: 2.555364\tBest loss: 2.555364\tAccuracy: 29.50%\n",
      "26\tValidation loss: 2.535046\tBest loss: 2.535046\tAccuracy: 32.40%\n",
      "27\tValidation loss: 2.556087\tBest loss: 2.535046\tAccuracy: 31.60%\n",
      "28\tValidation loss: 2.482044\tBest loss: 2.482044\tAccuracy: 34.10%\n",
      "29\tValidation loss: 2.618681\tBest loss: 2.482044\tAccuracy: 30.00%\n",
      "30\tValidation loss: 2.600288\tBest loss: 2.482044\tAccuracy: 29.80%\n",
      "31\tValidation loss: 2.738575\tBest loss: 2.482044\tAccuracy: 27.90%\n",
      "32\tValidation loss: 2.495142\tBest loss: 2.482044\tAccuracy: 30.20%\n",
      "33\tValidation loss: 2.545318\tBest loss: 2.482044\tAccuracy: 29.40%\n",
      "34\tValidation loss: 2.565930\tBest loss: 2.482044\tAccuracy: 32.10%\n",
      "35\tValidation loss: 2.544086\tBest loss: 2.482044\tAccuracy: 31.70%\n",
      "36\tValidation loss: 2.626494\tBest loss: 2.482044\tAccuracy: 27.20%\n",
      "37\tValidation loss: 2.472171\tBest loss: 2.472171\tAccuracy: 32.30%\n",
      "38\tValidation loss: 2.906413\tBest loss: 2.472171\tAccuracy: 25.10%\n",
      "39\tValidation loss: 2.585269\tBest loss: 2.472171\tAccuracy: 29.40%\n",
      "40\tValidation loss: 3.724298\tBest loss: 2.472171\tAccuracy: 24.30%\n",
      "41\tValidation loss: 2.406886\tBest loss: 2.406886\tAccuracy: 35.60%\n",
      "42\tValidation loss: 2.413132\tBest loss: 2.406886\tAccuracy: 32.00%\n",
      "43\tValidation loss: 2.566241\tBest loss: 2.406886\tAccuracy: 31.80%\n",
      "44\tValidation loss: 2.514115\tBest loss: 2.406886\tAccuracy: 31.40%\n",
      "45\tValidation loss: 2.362142\tBest loss: 2.362142\tAccuracy: 34.80%\n",
      "46\tValidation loss: 2.552166\tBest loss: 2.362142\tAccuracy: 32.10%\n",
      "47\tValidation loss: 2.455549\tBest loss: 2.362142\tAccuracy: 32.90%\n",
      "48\tValidation loss: 2.303960\tBest loss: 2.303960\tAccuracy: 36.70%\n",
      "49\tValidation loss: 2.388684\tBest loss: 2.303960\tAccuracy: 34.60%\n",
      "50\tValidation loss: 2.533387\tBest loss: 2.303960\tAccuracy: 32.40%\n",
      "51\tValidation loss: 2.486388\tBest loss: 2.303960\tAccuracy: 32.80%\n",
      "52\tValidation loss: 2.688006\tBest loss: 2.303960\tAccuracy: 34.50%\n",
      "53\tValidation loss: 2.557354\tBest loss: 2.303960\tAccuracy: 30.60%\n",
      "54\tValidation loss: 2.315400\tBest loss: 2.303960\tAccuracy: 37.70%\n",
      "55\tValidation loss: 2.301878\tBest loss: 2.301878\tAccuracy: 38.10%\n",
      "56\tValidation loss: 2.385381\tBest loss: 2.301878\tAccuracy: 33.00%\n",
      "57\tValidation loss: 2.261218\tBest loss: 2.261218\tAccuracy: 37.00%\n",
      "58\tValidation loss: 2.255896\tBest loss: 2.255896\tAccuracy: 39.10%\n",
      "59\tValidation loss: 2.352925\tBest loss: 2.255896\tAccuracy: 35.80%\n",
      "60\tValidation loss: 2.403194\tBest loss: 2.255896\tAccuracy: 33.60%\n",
      "61\tValidation loss: 2.525386\tBest loss: 2.255896\tAccuracy: 31.10%\n",
      "62\tValidation loss: 2.486669\tBest loss: 2.255896\tAccuracy: 33.50%\n",
      "63\tValidation loss: 2.324650\tBest loss: 2.255896\tAccuracy: 38.10%\n",
      "64\tValidation loss: 2.252617\tBest loss: 2.252617\tAccuracy: 36.30%\n",
      "65\tValidation loss: 2.359061\tBest loss: 2.252617\tAccuracy: 39.30%\n",
      "66\tValidation loss: 2.263090\tBest loss: 2.252617\tAccuracy: 37.30%\n",
      "67\tValidation loss: 2.276416\tBest loss: 2.252617\tAccuracy: 37.90%\n",
      "68\tValidation loss: 2.297331\tBest loss: 2.252617\tAccuracy: 35.50%\n",
      "69\tValidation loss: 2.245951\tBest loss: 2.245951\tAccuracy: 40.20%\n",
      "70\tValidation loss: 2.270884\tBest loss: 2.245951\tAccuracy: 38.00%\n",
      "71\tValidation loss: 2.352947\tBest loss: 2.245951\tAccuracy: 37.50%\n",
      "72\tValidation loss: 2.266225\tBest loss: 2.245951\tAccuracy: 39.30%\n",
      "73\tValidation loss: 2.283356\tBest loss: 2.245951\tAccuracy: 35.40%\n",
      "74\tValidation loss: 2.258905\tBest loss: 2.245951\tAccuracy: 37.50%\n",
      "75\tValidation loss: 2.150814\tBest loss: 2.150814\tAccuracy: 40.30%\n",
      "76\tValidation loss: 2.463324\tBest loss: 2.150814\tAccuracy: 35.60%\n",
      "77\tValidation loss: 2.746629\tBest loss: 2.150814\tAccuracy: 34.40%\n",
      "78\tValidation loss: 2.339397\tBest loss: 2.150814\tAccuracy: 39.90%\n",
      "79\tValidation loss: 2.194433\tBest loss: 2.150814\tAccuracy: 38.80%\n",
      "80\tValidation loss: 2.142263\tBest loss: 2.142263\tAccuracy: 41.00%\n",
      "81\tValidation loss: 2.251533\tBest loss: 2.142263\tAccuracy: 38.40%\n",
      "82\tValidation loss: 2.247702\tBest loss: 2.142263\tAccuracy: 39.60%\n",
      "83\tValidation loss: 2.325743\tBest loss: 2.142263\tAccuracy: 36.90%\n",
      "84\tValidation loss: 2.066217\tBest loss: 2.066217\tAccuracy: 42.10%\n",
      "85\tValidation loss: 2.211273\tBest loss: 2.066217\tAccuracy: 38.30%\n",
      "86\tValidation loss: 2.311450\tBest loss: 2.066217\tAccuracy: 38.80%\n",
      "87\tValidation loss: 2.202779\tBest loss: 2.066217\tAccuracy: 39.30%\n",
      "88\tValidation loss: 2.129227\tBest loss: 2.066217\tAccuracy: 41.20%\n",
      "89\tValidation loss: 2.131928\tBest loss: 2.066217\tAccuracy: 42.10%\n",
      "90\tValidation loss: 2.212706\tBest loss: 2.066217\tAccuracy: 37.80%\n",
      "91\tValidation loss: 2.135248\tBest loss: 2.066217\tAccuracy: 40.70%\n",
      "92\tValidation loss: 2.357130\tBest loss: 2.066217\tAccuracy: 40.60%\n",
      "93\tValidation loss: 2.073031\tBest loss: 2.066217\tAccuracy: 42.10%\n",
      "94\tValidation loss: 2.254197\tBest loss: 2.066217\tAccuracy: 39.40%\n",
      "95\tValidation loss: 2.171595\tBest loss: 2.066217\tAccuracy: 41.60%\n",
      "96\tValidation loss: 2.235385\tBest loss: 2.066217\tAccuracy: 39.60%\n",
      "97\tValidation loss: 2.108061\tBest loss: 2.066217\tAccuracy: 42.10%\n",
      "98\tValidation loss: 2.156688\tBest loss: 2.066217\tAccuracy: 40.40%\n",
      "99\tValidation loss: 2.107075\tBest loss: 2.066217\tAccuracy: 41.90%\n",
      "100\tValidation loss: 2.107010\tBest loss: 2.066217\tAccuracy: 42.30%\n",
      "101\tValidation loss: 2.581550\tBest loss: 2.066217\tAccuracy: 38.00%\n",
      "102\tValidation loss: 2.212381\tBest loss: 2.066217\tAccuracy: 40.00%\n",
      "103\tValidation loss: 2.060172\tBest loss: 2.060172\tAccuracy: 44.70%\n",
      "104\tValidation loss: 2.029747\tBest loss: 2.029747\tAccuracy: 45.50%\n",
      "105\tValidation loss: 2.210713\tBest loss: 2.029747\tAccuracy: 40.20%\n",
      "106\tValidation loss: 2.233154\tBest loss: 2.029747\tAccuracy: 38.00%\n",
      "107\tValidation loss: 2.096935\tBest loss: 2.029747\tAccuracy: 41.10%\n",
      "108\tValidation loss: 2.170145\tBest loss: 2.029747\tAccuracy: 38.40%\n",
      "109\tValidation loss: 2.007503\tBest loss: 2.007503\tAccuracy: 43.00%\n",
      "110\tValidation loss: 2.056931\tBest loss: 2.007503\tAccuracy: 42.40%\n",
      "111\tValidation loss: 2.031502\tBest loss: 2.007503\tAccuracy: 44.40%\n",
      "112\tValidation loss: 2.114084\tBest loss: 2.007503\tAccuracy: 43.60%\n",
      "113\tValidation loss: 2.005931\tBest loss: 2.005931\tAccuracy: 45.10%\n",
      "114\tValidation loss: 2.129426\tBest loss: 2.005931\tAccuracy: 41.10%\n",
      "115\tValidation loss: 1.998144\tBest loss: 1.998144\tAccuracy: 44.80%\n",
      "116\tValidation loss: 2.058691\tBest loss: 1.998144\tAccuracy: 42.30%\n",
      "117\tValidation loss: 2.219808\tBest loss: 1.998144\tAccuracy: 42.30%\n",
      "118\tValidation loss: 2.001628\tBest loss: 1.998144\tAccuracy: 45.00%\n",
      "119\tValidation loss: 2.193723\tBest loss: 1.998144\tAccuracy: 42.00%\n",
      "120\tValidation loss: 2.034618\tBest loss: 1.998144\tAccuracy: 42.50%\n",
      "121\tValidation loss: 1.995155\tBest loss: 1.995155\tAccuracy: 46.40%\n",
      "122\tValidation loss: 2.019784\tBest loss: 1.995155\tAccuracy: 44.30%\n",
      "123\tValidation loss: 2.104284\tBest loss: 1.995155\tAccuracy: 41.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 2.094873\tBest loss: 1.995155\tAccuracy: 40.80%\n",
      "125\tValidation loss: 2.035428\tBest loss: 1.995155\tAccuracy: 45.30%\n",
      "126\tValidation loss: 2.034328\tBest loss: 1.995155\tAccuracy: 42.20%\n",
      "127\tValidation loss: 1.966413\tBest loss: 1.966413\tAccuracy: 46.50%\n",
      "128\tValidation loss: 2.892716\tBest loss: 1.966413\tAccuracy: 35.50%\n",
      "129\tValidation loss: 1.903090\tBest loss: 1.903090\tAccuracy: 46.00%\n",
      "130\tValidation loss: 2.018375\tBest loss: 1.903090\tAccuracy: 46.00%\n",
      "131\tValidation loss: 2.104100\tBest loss: 1.903090\tAccuracy: 41.50%\n",
      "132\tValidation loss: 2.157360\tBest loss: 1.903090\tAccuracy: 40.80%\n",
      "133\tValidation loss: 2.148726\tBest loss: 1.903090\tAccuracy: 39.80%\n",
      "134\tValidation loss: 1.954946\tBest loss: 1.903090\tAccuracy: 48.70%\n",
      "135\tValidation loss: 1.950862\tBest loss: 1.903090\tAccuracy: 45.40%\n",
      "136\tValidation loss: 2.069584\tBest loss: 1.903090\tAccuracy: 42.40%\n",
      "137\tValidation loss: 2.086432\tBest loss: 1.903090\tAccuracy: 45.40%\n",
      "138\tValidation loss: 2.104073\tBest loss: 1.903090\tAccuracy: 45.20%\n",
      "139\tValidation loss: 2.067530\tBest loss: 1.903090\tAccuracy: 42.50%\n",
      "140\tValidation loss: 1.972257\tBest loss: 1.903090\tAccuracy: 44.80%\n",
      "141\tValidation loss: 2.009577\tBest loss: 1.903090\tAccuracy: 44.30%\n",
      "142\tValidation loss: 1.911595\tBest loss: 1.903090\tAccuracy: 46.20%\n",
      "143\tValidation loss: 2.052846\tBest loss: 1.903090\tAccuracy: 43.10%\n",
      "144\tValidation loss: 2.053135\tBest loss: 1.903090\tAccuracy: 42.80%\n",
      "145\tValidation loss: 2.017550\tBest loss: 1.903090\tAccuracy: 44.20%\n",
      "146\tValidation loss: 2.020776\tBest loss: 1.903090\tAccuracy: 43.40%\n",
      "147\tValidation loss: 1.863849\tBest loss: 1.863849\tAccuracy: 49.00%\n",
      "148\tValidation loss: 2.127914\tBest loss: 1.863849\tAccuracy: 45.20%\n",
      "149\tValidation loss: 1.975670\tBest loss: 1.863849\tAccuracy: 44.30%\n",
      "150\tValidation loss: 1.887240\tBest loss: 1.863849\tAccuracy: 46.60%\n",
      "151\tValidation loss: 2.004524\tBest loss: 1.863849\tAccuracy: 46.80%\n",
      "152\tValidation loss: 2.084334\tBest loss: 1.863849\tAccuracy: 44.00%\n",
      "153\tValidation loss: 2.041173\tBest loss: 1.863849\tAccuracy: 43.50%\n",
      "154\tValidation loss: 1.902479\tBest loss: 1.863849\tAccuracy: 48.50%\n",
      "155\tValidation loss: 1.941868\tBest loss: 1.863849\tAccuracy: 47.50%\n",
      "156\tValidation loss: 2.034199\tBest loss: 1.863849\tAccuracy: 46.00%\n",
      "157\tValidation loss: 2.237468\tBest loss: 1.863849\tAccuracy: 41.70%\n",
      "158\tValidation loss: 1.768544\tBest loss: 1.768544\tAccuracy: 51.80%\n",
      "159\tValidation loss: 2.170959\tBest loss: 1.768544\tAccuracy: 39.60%\n",
      "160\tValidation loss: 2.121563\tBest loss: 1.768544\tAccuracy: 45.20%\n",
      "161\tValidation loss: 2.044718\tBest loss: 1.768544\tAccuracy: 45.80%\n",
      "162\tValidation loss: 1.863827\tBest loss: 1.768544\tAccuracy: 48.50%\n",
      "163\tValidation loss: 1.892355\tBest loss: 1.768544\tAccuracy: 49.30%\n",
      "164\tValidation loss: 2.011193\tBest loss: 1.768544\tAccuracy: 45.30%\n",
      "165\tValidation loss: 1.981989\tBest loss: 1.768544\tAccuracy: 46.00%\n",
      "166\tValidation loss: 2.004883\tBest loss: 1.768544\tAccuracy: 45.40%\n",
      "167\tValidation loss: 2.025842\tBest loss: 1.768544\tAccuracy: 48.60%\n",
      "168\tValidation loss: 2.256982\tBest loss: 1.768544\tAccuracy: 43.10%\n",
      "169\tValidation loss: 1.876296\tBest loss: 1.768544\tAccuracy: 49.40%\n",
      "170\tValidation loss: 2.162195\tBest loss: 1.768544\tAccuracy: 45.20%\n",
      "171\tValidation loss: 1.883188\tBest loss: 1.768544\tAccuracy: 48.40%\n",
      "172\tValidation loss: 2.175668\tBest loss: 1.768544\tAccuracy: 43.40%\n",
      "173\tValidation loss: 1.863356\tBest loss: 1.768544\tAccuracy: 50.80%\n",
      "174\tValidation loss: 1.947755\tBest loss: 1.768544\tAccuracy: 46.70%\n",
      "175\tValidation loss: 2.037952\tBest loss: 1.768544\tAccuracy: 46.60%\n",
      "176\tValidation loss: 1.944183\tBest loss: 1.768544\tAccuracy: 47.70%\n",
      "177\tValidation loss: 2.193049\tBest loss: 1.768544\tAccuracy: 45.70%\n",
      "178\tValidation loss: 1.786030\tBest loss: 1.768544\tAccuracy: 51.60%\n",
      "179\tValidation loss: 2.197728\tBest loss: 1.768544\tAccuracy: 43.30%\n",
      "Early stopping!\n",
      "[[  2.73389557e-14   2.46159676e-10   3.39197442e-07 ...,   9.46546986e-13\n",
      "    8.13589051e-13   7.38076213e-13]\n",
      " [  6.29445463e-02   3.84341069e-02   4.95800152e-02 ...,   1.22714490e-02\n",
      "    5.05429413e-03   6.78599952e-03]\n",
      " [  2.93216813e-13   1.30527462e-33   8.55110898e-08 ...,   4.19351005e-20\n",
      "    1.20961520e-26   2.66250637e-29]\n",
      " ..., \n",
      " [  5.50040360e-14   3.98145579e-11   6.89520446e-12 ...,   9.64199174e-08\n",
      "    2.14982032e-09   4.61762504e-08]\n",
      " [  2.23969249e-03   6.83995429e-03   3.08799208e-03 ...,   1.50112391e-01\n",
      "    1.37404623e-02   2.87523381e-02]\n",
      " [  9.79574907e-05   3.26205773e-05   5.71275875e-03 ...,   1.15740404e-03\n",
      "    1.23903935e-03   1.67528947e-03]]\n",
      "[20 18 16 ...,  6 45 36]\n",
      "[[  3.64132051e-04   1.00340694e-03   1.99696957e-03 ...,   1.20164163e-03\n",
      "    1.48416319e-07   1.89493294e-04]\n",
      " [  3.23793455e-14   4.77249386e-11   2.92993946e-07 ...,   1.04018992e-14\n",
      "    3.35499722e-13   5.34699672e-12]\n",
      " [  1.22469373e-07   2.94190977e-06   2.03648906e-05 ...,   2.86645900e-07\n",
      "    3.06507619e-12   1.00945883e-07]\n",
      " ..., \n",
      " [  3.45224771e-06   1.17903191e-07   1.04037645e-06 ...,   1.20421033e-15\n",
      "    2.70972802e-14   1.68675051e-13]\n",
      " [  3.04641463e-02   1.50718046e-02   3.00331637e-02 ...,   2.05501933e-02\n",
      "    1.33128706e-02   1.35037713e-02]\n",
      " [  4.23975352e-18   1.04695473e-12   3.36234069e-16 ...,   2.51864791e-02\n",
      "    1.97770044e-01   5.70708990e-01]]\n",
      "[40 11 43 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  40.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.830372\tBest loss: 3.830372\tAccuracy: 6.40%\n",
      "1\tValidation loss: 3.746022\tBest loss: 3.746022\tAccuracy: 6.50%\n",
      "2\tValidation loss: 3.648883\tBest loss: 3.648883\tAccuracy: 8.80%\n",
      "3\tValidation loss: 3.557179\tBest loss: 3.557179\tAccuracy: 10.40%\n",
      "4\tValidation loss: 3.498419\tBest loss: 3.498419\tAccuracy: 13.90%\n",
      "5\tValidation loss: 3.451720\tBest loss: 3.451720\tAccuracy: 14.80%\n",
      "6\tValidation loss: 3.379585\tBest loss: 3.379585\tAccuracy: 15.30%\n",
      "7\tValidation loss: 3.272769\tBest loss: 3.272769\tAccuracy: 18.10%\n",
      "8\tValidation loss: 3.214885\tBest loss: 3.214885\tAccuracy: 19.20%\n",
      "9\tValidation loss: 3.159246\tBest loss: 3.159246\tAccuracy: 21.30%\n",
      "10\tValidation loss: 3.146977\tBest loss: 3.146977\tAccuracy: 20.50%\n",
      "11\tValidation loss: 3.060176\tBest loss: 3.060176\tAccuracy: 23.00%\n",
      "12\tValidation loss: 3.148327\tBest loss: 3.060176\tAccuracy: 20.00%\n",
      "13\tValidation loss: 3.011014\tBest loss: 3.011014\tAccuracy: 21.40%\n",
      "14\tValidation loss: 2.981078\tBest loss: 2.981078\tAccuracy: 24.10%\n",
      "15\tValidation loss: 2.909976\tBest loss: 2.909976\tAccuracy: 23.70%\n",
      "16\tValidation loss: 2.961739\tBest loss: 2.909976\tAccuracy: 21.70%\n",
      "17\tValidation loss: 2.839626\tBest loss: 2.839626\tAccuracy: 25.80%\n",
      "18\tValidation loss: 2.805699\tBest loss: 2.805699\tAccuracy: 25.20%\n",
      "19\tValidation loss: 2.841555\tBest loss: 2.805699\tAccuracy: 25.00%\n",
      "20\tValidation loss: 2.794219\tBest loss: 2.794219\tAccuracy: 26.00%\n",
      "21\tValidation loss: 2.786363\tBest loss: 2.786363\tAccuracy: 26.60%\n",
      "22\tValidation loss: 2.656548\tBest loss: 2.656548\tAccuracy: 29.10%\n",
      "23\tValidation loss: 2.845490\tBest loss: 2.656548\tAccuracy: 24.70%\n",
      "24\tValidation loss: 2.666728\tBest loss: 2.656548\tAccuracy: 28.60%\n",
      "25\tValidation loss: 2.564598\tBest loss: 2.564598\tAccuracy: 28.30%\n",
      "26\tValidation loss: 2.568798\tBest loss: 2.564598\tAccuracy: 29.20%\n",
      "27\tValidation loss: 2.651269\tBest loss: 2.564598\tAccuracy: 26.60%\n",
      "28\tValidation loss: 2.714322\tBest loss: 2.564598\tAccuracy: 25.60%\n",
      "29\tValidation loss: 2.491314\tBest loss: 2.491314\tAccuracy: 32.90%\n",
      "30\tValidation loss: 2.429370\tBest loss: 2.429370\tAccuracy: 33.20%\n",
      "31\tValidation loss: 2.476397\tBest loss: 2.429370\tAccuracy: 31.10%\n",
      "32\tValidation loss: 2.414901\tBest loss: 2.414901\tAccuracy: 32.90%\n",
      "33\tValidation loss: 2.553943\tBest loss: 2.414901\tAccuracy: 30.70%\n",
      "34\tValidation loss: 2.492467\tBest loss: 2.414901\tAccuracy: 30.10%\n",
      "35\tValidation loss: 2.444495\tBest loss: 2.414901\tAccuracy: 33.90%\n",
      "36\tValidation loss: 2.515992\tBest loss: 2.414901\tAccuracy: 30.80%\n",
      "37\tValidation loss: 2.386883\tBest loss: 2.386883\tAccuracy: 34.70%\n",
      "38\tValidation loss: 2.483188\tBest loss: 2.386883\tAccuracy: 32.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\tValidation loss: 2.449461\tBest loss: 2.386883\tAccuracy: 32.90%\n",
      "40\tValidation loss: 2.502610\tBest loss: 2.386883\tAccuracy: 30.20%\n",
      "41\tValidation loss: 2.306463\tBest loss: 2.306463\tAccuracy: 36.50%\n",
      "42\tValidation loss: 2.428586\tBest loss: 2.306463\tAccuracy: 32.70%\n",
      "43\tValidation loss: 2.733070\tBest loss: 2.306463\tAccuracy: 25.90%\n",
      "44\tValidation loss: 2.429116\tBest loss: 2.306463\tAccuracy: 33.30%\n",
      "45\tValidation loss: 2.302006\tBest loss: 2.302006\tAccuracy: 38.20%\n",
      "46\tValidation loss: 2.290489\tBest loss: 2.290489\tAccuracy: 34.50%\n",
      "47\tValidation loss: 2.383898\tBest loss: 2.290489\tAccuracy: 33.40%\n",
      "48\tValidation loss: 2.280466\tBest loss: 2.280466\tAccuracy: 36.20%\n",
      "49\tValidation loss: 2.315130\tBest loss: 2.280466\tAccuracy: 34.70%\n",
      "50\tValidation loss: 2.440510\tBest loss: 2.280466\tAccuracy: 34.00%\n",
      "51\tValidation loss: 2.317489\tBest loss: 2.280466\tAccuracy: 35.50%\n",
      "52\tValidation loss: 2.374500\tBest loss: 2.280466\tAccuracy: 34.90%\n",
      "53\tValidation loss: 2.265516\tBest loss: 2.265516\tAccuracy: 37.70%\n",
      "54\tValidation loss: 2.379373\tBest loss: 2.265516\tAccuracy: 34.00%\n",
      "55\tValidation loss: 2.323120\tBest loss: 2.265516\tAccuracy: 36.80%\n",
      "56\tValidation loss: 2.435173\tBest loss: 2.265516\tAccuracy: 34.10%\n",
      "57\tValidation loss: 2.141522\tBest loss: 2.141522\tAccuracy: 39.50%\n",
      "58\tValidation loss: 2.185423\tBest loss: 2.141522\tAccuracy: 39.20%\n",
      "59\tValidation loss: 2.405514\tBest loss: 2.141522\tAccuracy: 34.00%\n",
      "60\tValidation loss: 2.355353\tBest loss: 2.141522\tAccuracy: 34.60%\n",
      "61\tValidation loss: 2.350035\tBest loss: 2.141522\tAccuracy: 34.50%\n",
      "62\tValidation loss: 2.245031\tBest loss: 2.141522\tAccuracy: 38.40%\n",
      "63\tValidation loss: 2.249351\tBest loss: 2.141522\tAccuracy: 38.80%\n",
      "64\tValidation loss: 2.411925\tBest loss: 2.141522\tAccuracy: 36.00%\n",
      "65\tValidation loss: 2.338218\tBest loss: 2.141522\tAccuracy: 37.30%\n",
      "66\tValidation loss: 2.219679\tBest loss: 2.141522\tAccuracy: 39.20%\n",
      "67\tValidation loss: 2.175866\tBest loss: 2.141522\tAccuracy: 41.70%\n",
      "68\tValidation loss: 2.214544\tBest loss: 2.141522\tAccuracy: 40.40%\n",
      "69\tValidation loss: 2.770073\tBest loss: 2.141522\tAccuracy: 33.50%\n",
      "70\tValidation loss: 2.179655\tBest loss: 2.141522\tAccuracy: 41.40%\n",
      "71\tValidation loss: 2.325569\tBest loss: 2.141522\tAccuracy: 38.40%\n",
      "72\tValidation loss: 2.163589\tBest loss: 2.141522\tAccuracy: 39.20%\n",
      "73\tValidation loss: 2.213606\tBest loss: 2.141522\tAccuracy: 40.10%\n",
      "74\tValidation loss: 2.127102\tBest loss: 2.127102\tAccuracy: 42.50%\n",
      "75\tValidation loss: 2.173203\tBest loss: 2.127102\tAccuracy: 40.50%\n",
      "76\tValidation loss: 2.182265\tBest loss: 2.127102\tAccuracy: 41.20%\n",
      "77\tValidation loss: 2.164921\tBest loss: 2.127102\tAccuracy: 42.30%\n",
      "78\tValidation loss: 2.302662\tBest loss: 2.127102\tAccuracy: 38.40%\n",
      "79\tValidation loss: 2.120572\tBest loss: 2.120572\tAccuracy: 42.50%\n",
      "80\tValidation loss: 2.201559\tBest loss: 2.120572\tAccuracy: 39.00%\n",
      "81\tValidation loss: 2.255896\tBest loss: 2.120572\tAccuracy: 40.20%\n",
      "82\tValidation loss: 2.117175\tBest loss: 2.117175\tAccuracy: 41.30%\n",
      "83\tValidation loss: 2.062560\tBest loss: 2.062560\tAccuracy: 41.40%\n",
      "84\tValidation loss: 2.021167\tBest loss: 2.021167\tAccuracy: 43.80%\n",
      "85\tValidation loss: 2.177602\tBest loss: 2.021167\tAccuracy: 42.00%\n",
      "86\tValidation loss: 2.393647\tBest loss: 2.021167\tAccuracy: 37.00%\n",
      "87\tValidation loss: 2.216220\tBest loss: 2.021167\tAccuracy: 39.20%\n",
      "88\tValidation loss: 1.975892\tBest loss: 1.975892\tAccuracy: 46.90%\n",
      "89\tValidation loss: 2.154672\tBest loss: 1.975892\tAccuracy: 43.00%\n",
      "90\tValidation loss: 2.236511\tBest loss: 1.975892\tAccuracy: 40.60%\n",
      "91\tValidation loss: 2.199865\tBest loss: 1.975892\tAccuracy: 42.40%\n",
      "92\tValidation loss: 2.029124\tBest loss: 1.975892\tAccuracy: 43.30%\n",
      "93\tValidation loss: 2.086144\tBest loss: 1.975892\tAccuracy: 43.50%\n",
      "94\tValidation loss: 2.158487\tBest loss: 1.975892\tAccuracy: 40.40%\n",
      "95\tValidation loss: 2.223568\tBest loss: 1.975892\tAccuracy: 42.90%\n",
      "96\tValidation loss: 2.322191\tBest loss: 1.975892\tAccuracy: 40.30%\n",
      "97\tValidation loss: 2.248234\tBest loss: 1.975892\tAccuracy: 40.10%\n",
      "98\tValidation loss: 2.055766\tBest loss: 1.975892\tAccuracy: 43.50%\n",
      "99\tValidation loss: 2.236617\tBest loss: 1.975892\tAccuracy: 43.10%\n",
      "100\tValidation loss: 2.229158\tBest loss: 1.975892\tAccuracy: 41.60%\n",
      "101\tValidation loss: 2.103031\tBest loss: 1.975892\tAccuracy: 44.40%\n",
      "102\tValidation loss: 2.131588\tBest loss: 1.975892\tAccuracy: 43.20%\n",
      "103\tValidation loss: 2.090654\tBest loss: 1.975892\tAccuracy: 44.20%\n",
      "104\tValidation loss: 2.042889\tBest loss: 1.975892\tAccuracy: 43.30%\n",
      "105\tValidation loss: 2.108756\tBest loss: 1.975892\tAccuracy: 45.20%\n",
      "106\tValidation loss: 2.142180\tBest loss: 1.975892\tAccuracy: 42.70%\n",
      "107\tValidation loss: 2.181594\tBest loss: 1.975892\tAccuracy: 40.80%\n",
      "108\tValidation loss: 1.991107\tBest loss: 1.975892\tAccuracy: 47.20%\n",
      "109\tValidation loss: 2.102894\tBest loss: 1.975892\tAccuracy: 43.40%\n",
      "Early stopping!\n",
      "[[  4.42575337e-03   5.58478897e-03   1.51445214e-02 ...,   2.08172412e-03\n",
      "    2.30705785e-03   1.23999733e-03]\n",
      " [  2.39225710e-06   2.93364536e-07   5.54563128e-04 ...,   6.69724068e-11\n",
      "    1.28626043e-09   2.57504507e-09]\n",
      " [  2.80398353e-06   1.19440313e-06   1.01364648e-03 ...,   1.49603366e-05\n",
      "    9.97339043e-07   1.27547319e-05]\n",
      " ..., \n",
      " [  2.67299241e-03   5.14908321e-03   4.63774055e-03 ...,   1.69927888e-02\n",
      "    2.55271178e-02   2.93383040e-02]\n",
      " [  2.76892151e-05   1.77970051e-05   1.52629013e-06 ...,   1.12066180e-01\n",
      "    6.42729551e-02   7.01360218e-03]\n",
      " [  9.34538366e-06   2.15289001e-05   2.52716945e-05 ...,   8.00965130e-02\n",
      "    1.24942604e-02   4.90952991e-02]]\n",
      "[36 11 43 ...,  8 27  8]\n",
      "[[  9.03341686e-08   9.27498363e-08   3.18348029e-05 ...,   1.15659539e-11\n",
      "    1.15152277e-09   5.85676396e-10]\n",
      " [  3.48536558e-02   3.21966968e-02   4.08966392e-02 ...,   1.34857483e-02\n",
      "    8.95335805e-03   8.49067885e-03]\n",
      " [  3.70519197e-12   3.01726832e-23   3.45191999e-08 ...,   7.20453634e-20\n",
      "    2.18786445e-22   1.62985997e-26]\n",
      " ..., \n",
      " [  8.50043783e-04   2.73382975e-05   1.46173144e-04 ...,   2.38197240e-11\n",
      "    1.39422816e-12   5.63619789e-14]\n",
      " [  2.97037065e-02   2.55376324e-02   2.75264643e-02 ...,   1.81032587e-02\n",
      "    1.54154897e-02   1.46683641e-02]\n",
      " [  7.55496875e-14   1.50731788e-10   1.20404256e-13 ...,   1.04543447e-01\n",
      "    1.64144471e-01   6.93353593e-01]]\n",
      "[20 18 17 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  23.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.863416\tBest loss: 3.863416\tAccuracy: 5.50%\n",
      "1\tValidation loss: 3.766347\tBest loss: 3.766347\tAccuracy: 5.80%\n",
      "2\tValidation loss: 3.686122\tBest loss: 3.686122\tAccuracy: 7.60%\n",
      "3\tValidation loss: 3.581017\tBest loss: 3.581017\tAccuracy: 9.40%\n",
      "4\tValidation loss: 3.539277\tBest loss: 3.539277\tAccuracy: 12.70%\n",
      "5\tValidation loss: 3.418064\tBest loss: 3.418064\tAccuracy: 14.70%\n",
      "6\tValidation loss: 3.322191\tBest loss: 3.322191\tAccuracy: 16.90%\n",
      "7\tValidation loss: 3.288478\tBest loss: 3.288478\tAccuracy: 17.60%\n",
      "8\tValidation loss: 3.193572\tBest loss: 3.193572\tAccuracy: 20.30%\n",
      "9\tValidation loss: 3.158864\tBest loss: 3.158864\tAccuracy: 19.60%\n",
      "10\tValidation loss: 3.148545\tBest loss: 3.148545\tAccuracy: 20.10%\n",
      "11\tValidation loss: 3.108542\tBest loss: 3.108542\tAccuracy: 20.20%\n",
      "12\tValidation loss: 3.073698\tBest loss: 3.073698\tAccuracy: 22.00%\n",
      "13\tValidation loss: 2.983915\tBest loss: 2.983915\tAccuracy: 23.30%\n",
      "14\tValidation loss: 2.955290\tBest loss: 2.955290\tAccuracy: 23.40%\n",
      "15\tValidation loss: 3.010031\tBest loss: 2.955290\tAccuracy: 22.40%\n",
      "16\tValidation loss: 2.961541\tBest loss: 2.955290\tAccuracy: 22.00%\n",
      "17\tValidation loss: 2.771879\tBest loss: 2.771879\tAccuracy: 27.60%\n",
      "18\tValidation loss: 2.829659\tBest loss: 2.771879\tAccuracy: 26.10%\n",
      "19\tValidation loss: 2.723286\tBest loss: 2.723286\tAccuracy: 28.30%\n",
      "20\tValidation loss: 2.807841\tBest loss: 2.723286\tAccuracy: 26.70%\n",
      "21\tValidation loss: 2.727752\tBest loss: 2.723286\tAccuracy: 29.60%\n",
      "22\tValidation loss: 2.604875\tBest loss: 2.604875\tAccuracy: 31.50%\n",
      "23\tValidation loss: 2.561667\tBest loss: 2.561667\tAccuracy: 31.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\tValidation loss: 2.624882\tBest loss: 2.561667\tAccuracy: 28.60%\n",
      "25\tValidation loss: 2.582905\tBest loss: 2.561667\tAccuracy: 28.90%\n",
      "26\tValidation loss: 2.721040\tBest loss: 2.561667\tAccuracy: 27.10%\n",
      "27\tValidation loss: 2.572484\tBest loss: 2.561667\tAccuracy: 31.80%\n",
      "28\tValidation loss: 2.649849\tBest loss: 2.561667\tAccuracy: 28.70%\n",
      "29\tValidation loss: 2.525546\tBest loss: 2.525546\tAccuracy: 33.60%\n",
      "30\tValidation loss: 2.512452\tBest loss: 2.512452\tAccuracy: 32.00%\n",
      "31\tValidation loss: 2.653525\tBest loss: 2.512452\tAccuracy: 30.50%\n",
      "32\tValidation loss: 2.594353\tBest loss: 2.512452\tAccuracy: 30.20%\n",
      "33\tValidation loss: 2.471096\tBest loss: 2.471096\tAccuracy: 33.80%\n",
      "34\tValidation loss: 2.432874\tBest loss: 2.432874\tAccuracy: 32.70%\n",
      "35\tValidation loss: 2.352450\tBest loss: 2.352450\tAccuracy: 34.40%\n",
      "36\tValidation loss: 2.466362\tBest loss: 2.352450\tAccuracy: 32.10%\n",
      "37\tValidation loss: 2.405334\tBest loss: 2.352450\tAccuracy: 35.40%\n",
      "38\tValidation loss: 2.388580\tBest loss: 2.352450\tAccuracy: 35.70%\n",
      "39\tValidation loss: 2.493855\tBest loss: 2.352450\tAccuracy: 34.30%\n",
      "40\tValidation loss: 2.391704\tBest loss: 2.352450\tAccuracy: 35.40%\n",
      "41\tValidation loss: 2.268139\tBest loss: 2.268139\tAccuracy: 38.20%\n",
      "42\tValidation loss: 2.438176\tBest loss: 2.268139\tAccuracy: 35.00%\n",
      "43\tValidation loss: 2.408817\tBest loss: 2.268139\tAccuracy: 37.30%\n",
      "44\tValidation loss: 2.453309\tBest loss: 2.268139\tAccuracy: 34.30%\n",
      "45\tValidation loss: 2.259284\tBest loss: 2.259284\tAccuracy: 41.00%\n",
      "46\tValidation loss: 2.470323\tBest loss: 2.259284\tAccuracy: 33.50%\n",
      "47\tValidation loss: 2.333363\tBest loss: 2.259284\tAccuracy: 37.80%\n",
      "48\tValidation loss: 2.334893\tBest loss: 2.259284\tAccuracy: 38.80%\n",
      "49\tValidation loss: 2.437611\tBest loss: 2.259284\tAccuracy: 34.90%\n",
      "50\tValidation loss: 2.434359\tBest loss: 2.259284\tAccuracy: 33.10%\n",
      "51\tValidation loss: 2.317913\tBest loss: 2.259284\tAccuracy: 37.80%\n",
      "52\tValidation loss: 2.385832\tBest loss: 2.259284\tAccuracy: 35.30%\n",
      "53\tValidation loss: 2.227086\tBest loss: 2.227086\tAccuracy: 38.50%\n",
      "54\tValidation loss: 2.317971\tBest loss: 2.227086\tAccuracy: 38.60%\n",
      "55\tValidation loss: 2.352091\tBest loss: 2.227086\tAccuracy: 36.70%\n",
      "56\tValidation loss: 2.410055\tBest loss: 2.227086\tAccuracy: 35.30%\n",
      "57\tValidation loss: 2.259351\tBest loss: 2.227086\tAccuracy: 40.90%\n",
      "58\tValidation loss: 2.376442\tBest loss: 2.227086\tAccuracy: 36.80%\n",
      "59\tValidation loss: 2.118641\tBest loss: 2.118641\tAccuracy: 42.50%\n",
      "60\tValidation loss: 2.443602\tBest loss: 2.118641\tAccuracy: 37.00%\n",
      "61\tValidation loss: 2.487196\tBest loss: 2.118641\tAccuracy: 34.90%\n",
      "62\tValidation loss: 2.284588\tBest loss: 2.118641\tAccuracy: 38.40%\n",
      "63\tValidation loss: 2.437159\tBest loss: 2.118641\tAccuracy: 37.00%\n",
      "64\tValidation loss: 2.258071\tBest loss: 2.118641\tAccuracy: 39.70%\n",
      "65\tValidation loss: 2.321815\tBest loss: 2.118641\tAccuracy: 37.70%\n",
      "66\tValidation loss: 2.397493\tBest loss: 2.118641\tAccuracy: 35.20%\n",
      "67\tValidation loss: 2.211100\tBest loss: 2.118641\tAccuracy: 39.50%\n",
      "68\tValidation loss: 2.233014\tBest loss: 2.118641\tAccuracy: 40.50%\n",
      "69\tValidation loss: 2.337280\tBest loss: 2.118641\tAccuracy: 38.10%\n",
      "70\tValidation loss: 2.295901\tBest loss: 2.118641\tAccuracy: 40.30%\n",
      "71\tValidation loss: 2.117475\tBest loss: 2.117475\tAccuracy: 44.90%\n",
      "72\tValidation loss: 2.539433\tBest loss: 2.117475\tAccuracy: 35.50%\n",
      "73\tValidation loss: 2.197602\tBest loss: 2.117475\tAccuracy: 40.40%\n",
      "74\tValidation loss: 2.141358\tBest loss: 2.117475\tAccuracy: 44.30%\n",
      "75\tValidation loss: 2.432797\tBest loss: 2.117475\tAccuracy: 36.90%\n",
      "76\tValidation loss: 2.204677\tBest loss: 2.117475\tAccuracy: 42.60%\n",
      "77\tValidation loss: 2.388246\tBest loss: 2.117475\tAccuracy: 36.40%\n",
      "78\tValidation loss: 2.308217\tBest loss: 2.117475\tAccuracy: 38.50%\n",
      "79\tValidation loss: 2.335074\tBest loss: 2.117475\tAccuracy: 36.80%\n",
      "80\tValidation loss: 2.250402\tBest loss: 2.117475\tAccuracy: 41.00%\n",
      "81\tValidation loss: 2.601846\tBest loss: 2.117475\tAccuracy: 37.20%\n",
      "82\tValidation loss: 2.151802\tBest loss: 2.117475\tAccuracy: 42.30%\n",
      "83\tValidation loss: 2.143938\tBest loss: 2.117475\tAccuracy: 41.70%\n",
      "84\tValidation loss: 2.597435\tBest loss: 2.117475\tAccuracy: 37.00%\n",
      "85\tValidation loss: 2.328151\tBest loss: 2.117475\tAccuracy: 38.70%\n",
      "86\tValidation loss: 2.139066\tBest loss: 2.117475\tAccuracy: 42.00%\n",
      "87\tValidation loss: 2.389298\tBest loss: 2.117475\tAccuracy: 37.30%\n",
      "88\tValidation loss: 2.159416\tBest loss: 2.117475\tAccuracy: 41.20%\n",
      "89\tValidation loss: 2.109258\tBest loss: 2.109258\tAccuracy: 43.20%\n",
      "90\tValidation loss: 2.172460\tBest loss: 2.109258\tAccuracy: 42.60%\n",
      "91\tValidation loss: 2.313969\tBest loss: 2.109258\tAccuracy: 38.80%\n",
      "92\tValidation loss: 2.069981\tBest loss: 2.069981\tAccuracy: 44.30%\n",
      "93\tValidation loss: 2.297500\tBest loss: 2.069981\tAccuracy: 40.90%\n",
      "94\tValidation loss: 2.192911\tBest loss: 2.069981\tAccuracy: 41.40%\n",
      "95\tValidation loss: 2.165543\tBest loss: 2.069981\tAccuracy: 42.00%\n",
      "96\tValidation loss: 2.068133\tBest loss: 2.068133\tAccuracy: 45.40%\n",
      "97\tValidation loss: 2.108382\tBest loss: 2.068133\tAccuracy: 43.10%\n",
      "98\tValidation loss: 2.243711\tBest loss: 2.068133\tAccuracy: 40.70%\n",
      "99\tValidation loss: 2.177905\tBest loss: 2.068133\tAccuracy: 41.80%\n",
      "100\tValidation loss: 2.030013\tBest loss: 2.030013\tAccuracy: 45.80%\n",
      "101\tValidation loss: 1.999107\tBest loss: 1.999107\tAccuracy: 45.90%\n",
      "102\tValidation loss: 2.382967\tBest loss: 1.999107\tAccuracy: 39.10%\n",
      "103\tValidation loss: 2.478477\tBest loss: 1.999107\tAccuracy: 40.90%\n",
      "104\tValidation loss: 2.171967\tBest loss: 1.999107\tAccuracy: 41.20%\n",
      "105\tValidation loss: 2.265248\tBest loss: 1.999107\tAccuracy: 40.60%\n",
      "106\tValidation loss: 1.992945\tBest loss: 1.992945\tAccuracy: 48.10%\n",
      "107\tValidation loss: 2.281314\tBest loss: 1.992945\tAccuracy: 40.40%\n",
      "108\tValidation loss: 2.267567\tBest loss: 1.992945\tAccuracy: 43.40%\n",
      "109\tValidation loss: 2.098501\tBest loss: 1.992945\tAccuracy: 41.50%\n",
      "110\tValidation loss: 1.960854\tBest loss: 1.960854\tAccuracy: 48.20%\n",
      "111\tValidation loss: 2.116375\tBest loss: 1.960854\tAccuracy: 44.30%\n",
      "112\tValidation loss: 2.230863\tBest loss: 1.960854\tAccuracy: 41.50%\n",
      "113\tValidation loss: 1.996907\tBest loss: 1.960854\tAccuracy: 47.30%\n",
      "114\tValidation loss: 2.192226\tBest loss: 1.960854\tAccuracy: 43.30%\n",
      "115\tValidation loss: 1.999777\tBest loss: 1.960854\tAccuracy: 47.30%\n",
      "116\tValidation loss: 2.135555\tBest loss: 1.960854\tAccuracy: 41.50%\n",
      "117\tValidation loss: 1.954051\tBest loss: 1.954051\tAccuracy: 45.80%\n",
      "118\tValidation loss: 1.917112\tBest loss: 1.917112\tAccuracy: 46.70%\n",
      "119\tValidation loss: 2.031811\tBest loss: 1.917112\tAccuracy: 45.30%\n",
      "120\tValidation loss: 2.278309\tBest loss: 1.917112\tAccuracy: 41.50%\n",
      "121\tValidation loss: 2.149659\tBest loss: 1.917112\tAccuracy: 43.40%\n",
      "122\tValidation loss: 2.022912\tBest loss: 1.917112\tAccuracy: 45.30%\n",
      "123\tValidation loss: 1.992314\tBest loss: 1.917112\tAccuracy: 46.10%\n",
      "124\tValidation loss: 2.019628\tBest loss: 1.917112\tAccuracy: 44.90%\n",
      "125\tValidation loss: 2.185671\tBest loss: 1.917112\tAccuracy: 44.30%\n",
      "126\tValidation loss: 2.108998\tBest loss: 1.917112\tAccuracy: 44.30%\n",
      "127\tValidation loss: 1.985270\tBest loss: 1.917112\tAccuracy: 46.40%\n",
      "128\tValidation loss: 2.187823\tBest loss: 1.917112\tAccuracy: 42.80%\n",
      "129\tValidation loss: 2.007173\tBest loss: 1.917112\tAccuracy: 47.40%\n",
      "130\tValidation loss: 2.053410\tBest loss: 1.917112\tAccuracy: 45.40%\n",
      "131\tValidation loss: 1.976993\tBest loss: 1.917112\tAccuracy: 49.90%\n",
      "132\tValidation loss: 2.015048\tBest loss: 1.917112\tAccuracy: 46.10%\n",
      "133\tValidation loss: 2.286295\tBest loss: 1.917112\tAccuracy: 43.20%\n",
      "134\tValidation loss: 2.320698\tBest loss: 1.917112\tAccuracy: 43.30%\n",
      "135\tValidation loss: 1.962159\tBest loss: 1.917112\tAccuracy: 46.50%\n",
      "136\tValidation loss: 2.046451\tBest loss: 1.917112\tAccuracy: 46.00%\n",
      "137\tValidation loss: 2.022893\tBest loss: 1.917112\tAccuracy: 45.70%\n",
      "138\tValidation loss: 2.443746\tBest loss: 1.917112\tAccuracy: 46.40%\n",
      "139\tValidation loss: 2.092083\tBest loss: 1.917112\tAccuracy: 44.00%\n",
      "Early stopping!\n",
      "[[  3.33024724e-03   7.40987528e-03   7.30833411e-03 ...,   1.35146352e-02\n",
      "    2.43414030e-03   3.48787825e-03]\n",
      " [  8.67864672e-14   3.65825229e-14   3.79499432e-10 ...,   6.36257935e-09\n",
      "    7.54066026e-13   4.30387566e-11]\n",
      " [  3.03495381e-06   1.24493803e-04   6.02004468e-04 ...,   3.71209026e-04\n",
      "    3.20275431e-04   3.00686760e-03]\n",
      " ..., \n",
      " [  7.75078079e-04   1.38470880e-03   1.75854017e-03 ...,   3.53479190e-10\n",
      "    3.41463538e-13   1.69978194e-13]\n",
      " [  4.21382375e-02   2.90504601e-02   2.76645888e-02 ...,   2.02008318e-02\n",
      "    1.26356613e-02   1.32292639e-02]\n",
      " [  1.37024825e-14   8.62666102e-12   3.66109161e-13 ...,   8.05863366e-03\n",
      "    4.64526266e-02   8.91072571e-01]]\n",
      "[36 41 30 ...,  4 10 47]\n",
      "[[  6.90832813e-09   3.43255056e-06   3.82297985e-05 ...,   1.45189728e-13\n",
      "    4.24138636e-14   2.61175819e-13]\n",
      " [  5.02792709e-02   3.89851853e-02   4.06057313e-02 ...,   1.53543670e-02\n",
      "    9.20208544e-03   6.94248686e-03]\n",
      " [  2.65858494e-12   5.38274442e-23   9.70542402e-09 ...,   1.06455597e-17\n",
      "    1.32241976e-21   6.06761629e-28]\n",
      " ..., \n",
      " [  1.11076972e-02   8.19101557e-03   1.92951243e-02 ...,   2.12680213e-02\n",
      "    1.73527282e-02   1.79466847e-02]\n",
      " [  5.45853247e-08   4.39832121e-07   2.99071523e-08 ...,   7.72512078e-01\n",
      "    1.24334032e-02   5.93769457e-03]\n",
      " [  4.10911355e-07   4.80060976e-07   5.70301063e-06 ...,   2.10729092e-02\n",
      "    1.76886329e-03   1.30204605e-02]]\n",
      "[20 19 17 ..., 36 45 38]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=150, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  30.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 7.439465\tBest loss: 7.439465\tAccuracy: 13.90%\n",
      "1\tValidation loss: 5.327319\tBest loss: 5.327319\tAccuracy: 20.20%\n",
      "2\tValidation loss: 4.125795\tBest loss: 4.125795\tAccuracy: 26.40%\n",
      "3\tValidation loss: 3.603446\tBest loss: 3.603446\tAccuracy: 30.10%\n",
      "4\tValidation loss: 3.274084\tBest loss: 3.274084\tAccuracy: 34.50%\n",
      "5\tValidation loss: 3.098430\tBest loss: 3.098430\tAccuracy: 34.70%\n",
      "6\tValidation loss: 2.829935\tBest loss: 2.829935\tAccuracy: 39.40%\n",
      "7\tValidation loss: 2.775406\tBest loss: 2.775406\tAccuracy: 40.90%\n",
      "8\tValidation loss: 2.649014\tBest loss: 2.649014\tAccuracy: 43.10%\n",
      "9\tValidation loss: 2.557547\tBest loss: 2.557547\tAccuracy: 43.80%\n",
      "10\tValidation loss: 2.560514\tBest loss: 2.557547\tAccuracy: 44.70%\n",
      "11\tValidation loss: 2.417737\tBest loss: 2.417737\tAccuracy: 46.30%\n",
      "12\tValidation loss: 2.390508\tBest loss: 2.390508\tAccuracy: 46.70%\n",
      "13\tValidation loss: 2.343013\tBest loss: 2.343013\tAccuracy: 47.70%\n",
      "14\tValidation loss: 2.295536\tBest loss: 2.295536\tAccuracy: 48.50%\n",
      "15\tValidation loss: 2.247485\tBest loss: 2.247485\tAccuracy: 48.60%\n",
      "16\tValidation loss: 2.170702\tBest loss: 2.170702\tAccuracy: 51.60%\n",
      "17\tValidation loss: 2.156855\tBest loss: 2.156855\tAccuracy: 51.40%\n",
      "18\tValidation loss: 2.101352\tBest loss: 2.101352\tAccuracy: 52.80%\n",
      "19\tValidation loss: 2.080158\tBest loss: 2.080158\tAccuracy: 53.00%\n",
      "20\tValidation loss: 2.042336\tBest loss: 2.042336\tAccuracy: 53.70%\n",
      "21\tValidation loss: 2.014494\tBest loss: 2.014494\tAccuracy: 54.50%\n",
      "22\tValidation loss: 1.986321\tBest loss: 1.986321\tAccuracy: 55.90%\n",
      "23\tValidation loss: 1.994264\tBest loss: 1.986321\tAccuracy: 55.60%\n",
      "24\tValidation loss: 1.948644\tBest loss: 1.948644\tAccuracy: 56.00%\n",
      "25\tValidation loss: 1.931149\tBest loss: 1.931149\tAccuracy: 54.70%\n",
      "26\tValidation loss: 1.919402\tBest loss: 1.919402\tAccuracy: 56.60%\n",
      "27\tValidation loss: 1.904489\tBest loss: 1.904489\tAccuracy: 55.40%\n",
      "28\tValidation loss: 1.876088\tBest loss: 1.876088\tAccuracy: 57.40%\n",
      "29\tValidation loss: 1.895426\tBest loss: 1.876088\tAccuracy: 57.40%\n",
      "30\tValidation loss: 1.832852\tBest loss: 1.832852\tAccuracy: 58.50%\n",
      "31\tValidation loss: 1.864653\tBest loss: 1.832852\tAccuracy: 58.40%\n",
      "32\tValidation loss: 1.825422\tBest loss: 1.825422\tAccuracy: 58.10%\n",
      "33\tValidation loss: 1.806215\tBest loss: 1.806215\tAccuracy: 59.00%\n",
      "34\tValidation loss: 1.803362\tBest loss: 1.803362\tAccuracy: 58.90%\n",
      "35\tValidation loss: 1.802284\tBest loss: 1.802284\tAccuracy: 58.70%\n",
      "36\tValidation loss: 1.752200\tBest loss: 1.752200\tAccuracy: 59.70%\n",
      "37\tValidation loss: 1.762969\tBest loss: 1.752200\tAccuracy: 59.70%\n",
      "38\tValidation loss: 1.759655\tBest loss: 1.752200\tAccuracy: 59.80%\n",
      "39\tValidation loss: 1.752073\tBest loss: 1.752073\tAccuracy: 60.20%\n",
      "40\tValidation loss: 1.717936\tBest loss: 1.717936\tAccuracy: 61.00%\n",
      "41\tValidation loss: 1.751295\tBest loss: 1.717936\tAccuracy: 61.00%\n",
      "42\tValidation loss: 1.700450\tBest loss: 1.700450\tAccuracy: 62.00%\n",
      "43\tValidation loss: 1.690211\tBest loss: 1.690211\tAccuracy: 60.70%\n",
      "44\tValidation loss: 1.706572\tBest loss: 1.690211\tAccuracy: 61.70%\n",
      "45\tValidation loss: 1.678387\tBest loss: 1.678387\tAccuracy: 61.70%\n",
      "46\tValidation loss: 1.684248\tBest loss: 1.678387\tAccuracy: 61.60%\n",
      "47\tValidation loss: 1.669780\tBest loss: 1.669780\tAccuracy: 62.10%\n",
      "48\tValidation loss: 1.656885\tBest loss: 1.656885\tAccuracy: 62.60%\n",
      "49\tValidation loss: 1.658447\tBest loss: 1.656885\tAccuracy: 61.90%\n",
      "50\tValidation loss: 1.655102\tBest loss: 1.655102\tAccuracy: 62.30%\n",
      "51\tValidation loss: 1.647302\tBest loss: 1.647302\tAccuracy: 62.70%\n",
      "52\tValidation loss: 1.652987\tBest loss: 1.647302\tAccuracy: 62.10%\n",
      "53\tValidation loss: 1.646620\tBest loss: 1.646620\tAccuracy: 62.80%\n",
      "54\tValidation loss: 1.621564\tBest loss: 1.621564\tAccuracy: 62.70%\n",
      "55\tValidation loss: 1.637200\tBest loss: 1.621564\tAccuracy: 62.70%\n",
      "56\tValidation loss: 1.614811\tBest loss: 1.614811\tAccuracy: 63.40%\n",
      "57\tValidation loss: 1.620764\tBest loss: 1.614811\tAccuracy: 62.70%\n",
      "58\tValidation loss: 1.595446\tBest loss: 1.595446\tAccuracy: 63.60%\n",
      "59\tValidation loss: 1.603613\tBest loss: 1.595446\tAccuracy: 63.60%\n",
      "60\tValidation loss: 1.599436\tBest loss: 1.595446\tAccuracy: 63.50%\n",
      "61\tValidation loss: 1.593726\tBest loss: 1.593726\tAccuracy: 63.40%\n",
      "62\tValidation loss: 1.578398\tBest loss: 1.578398\tAccuracy: 64.20%\n",
      "63\tValidation loss: 1.586682\tBest loss: 1.578398\tAccuracy: 64.10%\n",
      "64\tValidation loss: 1.574141\tBest loss: 1.574141\tAccuracy: 64.40%\n",
      "65\tValidation loss: 1.592300\tBest loss: 1.574141\tAccuracy: 64.20%\n",
      "66\tValidation loss: 1.561757\tBest loss: 1.561757\tAccuracy: 64.20%\n",
      "67\tValidation loss: 1.572168\tBest loss: 1.561757\tAccuracy: 64.20%\n",
      "68\tValidation loss: 1.560303\tBest loss: 1.560303\tAccuracy: 63.10%\n",
      "69\tValidation loss: 1.554829\tBest loss: 1.554829\tAccuracy: 64.40%\n",
      "70\tValidation loss: 1.564433\tBest loss: 1.554829\tAccuracy: 64.60%\n",
      "71\tValidation loss: 1.552620\tBest loss: 1.552620\tAccuracy: 64.00%\n",
      "72\tValidation loss: 1.549628\tBest loss: 1.549628\tAccuracy: 64.40%\n",
      "73\tValidation loss: 1.537261\tBest loss: 1.537261\tAccuracy: 64.60%\n",
      "74\tValidation loss: 1.569735\tBest loss: 1.537261\tAccuracy: 63.80%\n",
      "75\tValidation loss: 1.542733\tBest loss: 1.537261\tAccuracy: 64.70%\n",
      "76\tValidation loss: 1.538918\tBest loss: 1.537261\tAccuracy: 64.70%\n",
      "77\tValidation loss: 1.529972\tBest loss: 1.529972\tAccuracy: 64.60%\n",
      "78\tValidation loss: 1.528986\tBest loss: 1.528986\tAccuracy: 64.70%\n",
      "79\tValidation loss: 1.520189\tBest loss: 1.520189\tAccuracy: 64.70%\n",
      "80\tValidation loss: 1.520778\tBest loss: 1.520189\tAccuracy: 64.70%\n",
      "81\tValidation loss: 1.522025\tBest loss: 1.520189\tAccuracy: 64.80%\n",
      "82\tValidation loss: 1.512756\tBest loss: 1.512756\tAccuracy: 64.60%\n",
      "83\tValidation loss: 1.513356\tBest loss: 1.512756\tAccuracy: 64.60%\n",
      "84\tValidation loss: 1.507767\tBest loss: 1.507767\tAccuracy: 64.40%\n",
      "85\tValidation loss: 1.509594\tBest loss: 1.507767\tAccuracy: 64.80%\n",
      "86\tValidation loss: 1.516112\tBest loss: 1.507767\tAccuracy: 64.50%\n",
      "87\tValidation loss: 1.496840\tBest loss: 1.496840\tAccuracy: 65.60%\n",
      "88\tValidation loss: 1.494872\tBest loss: 1.494872\tAccuracy: 65.50%\n",
      "89\tValidation loss: 1.489965\tBest loss: 1.489965\tAccuracy: 65.10%\n",
      "90\tValidation loss: 1.486584\tBest loss: 1.486584\tAccuracy: 65.70%\n",
      "91\tValidation loss: 1.483491\tBest loss: 1.483491\tAccuracy: 65.60%\n",
      "92\tValidation loss: 1.477508\tBest loss: 1.477508\tAccuracy: 66.00%\n",
      "93\tValidation loss: 1.483589\tBest loss: 1.477508\tAccuracy: 65.50%\n",
      "94\tValidation loss: 1.474901\tBest loss: 1.474901\tAccuracy: 66.60%\n",
      "95\tValidation loss: 1.480669\tBest loss: 1.474901\tAccuracy: 66.40%\n",
      "96\tValidation loss: 1.484745\tBest loss: 1.474901\tAccuracy: 64.80%\n",
      "97\tValidation loss: 1.470148\tBest loss: 1.470148\tAccuracy: 65.80%\n",
      "98\tValidation loss: 1.468172\tBest loss: 1.468172\tAccuracy: 66.40%\n",
      "99\tValidation loss: 1.461892\tBest loss: 1.461892\tAccuracy: 65.90%\n",
      "100\tValidation loss: 1.468753\tBest loss: 1.461892\tAccuracy: 65.60%\n",
      "101\tValidation loss: 1.466035\tBest loss: 1.461892\tAccuracy: 66.00%\n",
      "102\tValidation loss: 1.462259\tBest loss: 1.461892\tAccuracy: 66.10%\n",
      "103\tValidation loss: 1.456464\tBest loss: 1.456464\tAccuracy: 65.90%\n",
      "104\tValidation loss: 1.458437\tBest loss: 1.456464\tAccuracy: 65.60%\n",
      "105\tValidation loss: 1.450675\tBest loss: 1.450675\tAccuracy: 65.70%\n",
      "106\tValidation loss: 1.462996\tBest loss: 1.450675\tAccuracy: 65.90%\n",
      "107\tValidation loss: 1.460095\tBest loss: 1.450675\tAccuracy: 66.50%\n",
      "108\tValidation loss: 1.452336\tBest loss: 1.450675\tAccuracy: 66.40%\n",
      "109\tValidation loss: 1.444500\tBest loss: 1.444500\tAccuracy: 67.00%\n",
      "110\tValidation loss: 1.445608\tBest loss: 1.444500\tAccuracy: 66.20%\n",
      "111\tValidation loss: 1.437724\tBest loss: 1.437724\tAccuracy: 67.50%\n",
      "112\tValidation loss: 1.455947\tBest loss: 1.437724\tAccuracy: 66.10%\n",
      "113\tValidation loss: 1.449505\tBest loss: 1.437724\tAccuracy: 66.30%\n",
      "114\tValidation loss: 1.439495\tBest loss: 1.437724\tAccuracy: 67.00%\n",
      "115\tValidation loss: 1.443648\tBest loss: 1.437724\tAccuracy: 66.70%\n",
      "116\tValidation loss: 1.448377\tBest loss: 1.437724\tAccuracy: 66.20%\n",
      "117\tValidation loss: 1.439359\tBest loss: 1.437724\tAccuracy: 67.00%\n",
      "118\tValidation loss: 1.432971\tBest loss: 1.432971\tAccuracy: 66.90%\n",
      "119\tValidation loss: 1.431056\tBest loss: 1.431056\tAccuracy: 67.20%\n",
      "120\tValidation loss: 1.429226\tBest loss: 1.429226\tAccuracy: 67.30%\n",
      "121\tValidation loss: 1.433505\tBest loss: 1.429226\tAccuracy: 66.80%\n",
      "122\tValidation loss: 1.437081\tBest loss: 1.429226\tAccuracy: 66.70%\n",
      "123\tValidation loss: 1.429061\tBest loss: 1.429061\tAccuracy: 66.80%\n",
      "124\tValidation loss: 1.422607\tBest loss: 1.422607\tAccuracy: 67.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 1.428854\tBest loss: 1.422607\tAccuracy: 67.10%\n",
      "126\tValidation loss: 1.427760\tBest loss: 1.422607\tAccuracy: 66.40%\n",
      "127\tValidation loss: 1.424209\tBest loss: 1.422607\tAccuracy: 66.50%\n",
      "128\tValidation loss: 1.434533\tBest loss: 1.422607\tAccuracy: 66.50%\n",
      "129\tValidation loss: 1.427675\tBest loss: 1.422607\tAccuracy: 66.00%\n",
      "130\tValidation loss: 1.413455\tBest loss: 1.413455\tAccuracy: 66.80%\n",
      "131\tValidation loss: 1.411965\tBest loss: 1.411965\tAccuracy: 67.00%\n",
      "132\tValidation loss: 1.419605\tBest loss: 1.411965\tAccuracy: 66.40%\n",
      "133\tValidation loss: 1.419138\tBest loss: 1.411965\tAccuracy: 66.90%\n",
      "134\tValidation loss: 1.400957\tBest loss: 1.400957\tAccuracy: 67.30%\n",
      "135\tValidation loss: 1.414510\tBest loss: 1.400957\tAccuracy: 66.40%\n",
      "136\tValidation loss: 1.413983\tBest loss: 1.400957\tAccuracy: 66.00%\n",
      "137\tValidation loss: 1.411424\tBest loss: 1.400957\tAccuracy: 66.20%\n",
      "138\tValidation loss: 1.409026\tBest loss: 1.400957\tAccuracy: 66.50%\n",
      "139\tValidation loss: 1.407783\tBest loss: 1.400957\tAccuracy: 67.10%\n",
      "140\tValidation loss: 1.406494\tBest loss: 1.400957\tAccuracy: 67.40%\n",
      "141\tValidation loss: 1.410825\tBest loss: 1.400957\tAccuracy: 66.20%\n",
      "142\tValidation loss: 1.402851\tBest loss: 1.400957\tAccuracy: 66.70%\n",
      "143\tValidation loss: 1.400104\tBest loss: 1.400104\tAccuracy: 66.70%\n",
      "144\tValidation loss: 1.402023\tBest loss: 1.400104\tAccuracy: 66.60%\n",
      "145\tValidation loss: 1.399442\tBest loss: 1.399442\tAccuracy: 67.20%\n",
      "146\tValidation loss: 1.396525\tBest loss: 1.396525\tAccuracy: 67.20%\n",
      "147\tValidation loss: 1.396760\tBest loss: 1.396525\tAccuracy: 66.80%\n",
      "148\tValidation loss: 1.398089\tBest loss: 1.396525\tAccuracy: 66.70%\n",
      "149\tValidation loss: 1.395647\tBest loss: 1.395647\tAccuracy: 66.90%\n",
      "150\tValidation loss: 1.398887\tBest loss: 1.395647\tAccuracy: 66.90%\n",
      "151\tValidation loss: 1.397656\tBest loss: 1.395647\tAccuracy: 66.70%\n",
      "152\tValidation loss: 1.390728\tBest loss: 1.390728\tAccuracy: 67.20%\n",
      "153\tValidation loss: 1.396096\tBest loss: 1.390728\tAccuracy: 66.70%\n",
      "154\tValidation loss: 1.385550\tBest loss: 1.385550\tAccuracy: 66.80%\n",
      "155\tValidation loss: 1.382454\tBest loss: 1.382454\tAccuracy: 67.60%\n",
      "156\tValidation loss: 1.394177\tBest loss: 1.382454\tAccuracy: 66.60%\n",
      "157\tValidation loss: 1.379726\tBest loss: 1.379726\tAccuracy: 67.60%\n",
      "158\tValidation loss: 1.382933\tBest loss: 1.379726\tAccuracy: 66.90%\n",
      "159\tValidation loss: 1.384446\tBest loss: 1.379726\tAccuracy: 67.70%\n",
      "160\tValidation loss: 1.396386\tBest loss: 1.379726\tAccuracy: 66.90%\n",
      "161\tValidation loss: 1.385387\tBest loss: 1.379726\tAccuracy: 67.70%\n",
      "162\tValidation loss: 1.385203\tBest loss: 1.379726\tAccuracy: 67.50%\n",
      "163\tValidation loss: 1.379341\tBest loss: 1.379341\tAccuracy: 67.10%\n",
      "164\tValidation loss: 1.386618\tBest loss: 1.379341\tAccuracy: 67.30%\n",
      "165\tValidation loss: 1.383711\tBest loss: 1.379341\tAccuracy: 67.10%\n",
      "166\tValidation loss: 1.371282\tBest loss: 1.371282\tAccuracy: 67.70%\n",
      "167\tValidation loss: 1.376809\tBest loss: 1.371282\tAccuracy: 67.40%\n",
      "168\tValidation loss: 1.375037\tBest loss: 1.371282\tAccuracy: 67.70%\n",
      "169\tValidation loss: 1.368884\tBest loss: 1.368884\tAccuracy: 67.20%\n",
      "170\tValidation loss: 1.378237\tBest loss: 1.368884\tAccuracy: 67.00%\n",
      "171\tValidation loss: 1.376825\tBest loss: 1.368884\tAccuracy: 66.90%\n",
      "172\tValidation loss: 1.371642\tBest loss: 1.368884\tAccuracy: 67.50%\n",
      "173\tValidation loss: 1.375087\tBest loss: 1.368884\tAccuracy: 66.80%\n",
      "174\tValidation loss: 1.368670\tBest loss: 1.368670\tAccuracy: 68.30%\n",
      "175\tValidation loss: 1.373681\tBest loss: 1.368670\tAccuracy: 67.60%\n",
      "176\tValidation loss: 1.374530\tBest loss: 1.368670\tAccuracy: 67.20%\n",
      "177\tValidation loss: 1.371907\tBest loss: 1.368670\tAccuracy: 67.90%\n",
      "178\tValidation loss: 1.380156\tBest loss: 1.368670\tAccuracy: 67.30%\n",
      "179\tValidation loss: 1.373308\tBest loss: 1.368670\tAccuracy: 67.60%\n",
      "180\tValidation loss: 1.364889\tBest loss: 1.364889\tAccuracy: 67.70%\n",
      "181\tValidation loss: 1.368884\tBest loss: 1.364889\tAccuracy: 67.80%\n",
      "182\tValidation loss: 1.362732\tBest loss: 1.362732\tAccuracy: 68.10%\n",
      "183\tValidation loss: 1.368988\tBest loss: 1.362732\tAccuracy: 67.30%\n",
      "184\tValidation loss: 1.369682\tBest loss: 1.362732\tAccuracy: 67.40%\n",
      "185\tValidation loss: 1.362722\tBest loss: 1.362722\tAccuracy: 67.50%\n",
      "186\tValidation loss: 1.363026\tBest loss: 1.362722\tAccuracy: 67.60%\n",
      "187\tValidation loss: 1.359680\tBest loss: 1.359680\tAccuracy: 68.10%\n",
      "188\tValidation loss: 1.357677\tBest loss: 1.357677\tAccuracy: 68.00%\n",
      "189\tValidation loss: 1.365685\tBest loss: 1.357677\tAccuracy: 67.60%\n",
      "190\tValidation loss: 1.361287\tBest loss: 1.357677\tAccuracy: 68.20%\n",
      "191\tValidation loss: 1.370695\tBest loss: 1.357677\tAccuracy: 67.50%\n",
      "192\tValidation loss: 1.355312\tBest loss: 1.355312\tAccuracy: 68.10%\n",
      "193\tValidation loss: 1.358341\tBest loss: 1.355312\tAccuracy: 67.70%\n",
      "194\tValidation loss: 1.361268\tBest loss: 1.355312\tAccuracy: 67.50%\n",
      "195\tValidation loss: 1.359694\tBest loss: 1.355312\tAccuracy: 67.40%\n",
      "196\tValidation loss: 1.359798\tBest loss: 1.355312\tAccuracy: 67.40%\n",
      "197\tValidation loss: 1.357355\tBest loss: 1.355312\tAccuracy: 67.90%\n",
      "198\tValidation loss: 1.350638\tBest loss: 1.350638\tAccuracy: 67.90%\n",
      "199\tValidation loss: 1.352644\tBest loss: 1.350638\tAccuracy: 68.10%\n",
      "200\tValidation loss: 1.359051\tBest loss: 1.350638\tAccuracy: 68.40%\n",
      "201\tValidation loss: 1.349801\tBest loss: 1.349801\tAccuracy: 68.30%\n",
      "202\tValidation loss: 1.357928\tBest loss: 1.349801\tAccuracy: 68.00%\n",
      "203\tValidation loss: 1.350616\tBest loss: 1.349801\tAccuracy: 67.80%\n",
      "204\tValidation loss: 1.356797\tBest loss: 1.349801\tAccuracy: 67.90%\n",
      "205\tValidation loss: 1.349954\tBest loss: 1.349801\tAccuracy: 68.30%\n",
      "206\tValidation loss: 1.357492\tBest loss: 1.349801\tAccuracy: 67.30%\n",
      "207\tValidation loss: 1.354922\tBest loss: 1.349801\tAccuracy: 67.80%\n",
      "208\tValidation loss: 1.351876\tBest loss: 1.349801\tAccuracy: 68.00%\n",
      "209\tValidation loss: 1.346747\tBest loss: 1.346747\tAccuracy: 68.10%\n",
      "210\tValidation loss: 1.350397\tBest loss: 1.346747\tAccuracy: 68.50%\n",
      "211\tValidation loss: 1.349543\tBest loss: 1.346747\tAccuracy: 68.10%\n",
      "212\tValidation loss: 1.341206\tBest loss: 1.341206\tAccuracy: 69.10%\n",
      "213\tValidation loss: 1.345008\tBest loss: 1.341206\tAccuracy: 69.10%\n",
      "214\tValidation loss: 1.347989\tBest loss: 1.341206\tAccuracy: 68.40%\n",
      "215\tValidation loss: 1.341738\tBest loss: 1.341206\tAccuracy: 68.70%\n",
      "216\tValidation loss: 1.337304\tBest loss: 1.337304\tAccuracy: 68.80%\n",
      "217\tValidation loss: 1.347846\tBest loss: 1.337304\tAccuracy: 68.30%\n",
      "218\tValidation loss: 1.340519\tBest loss: 1.337304\tAccuracy: 68.60%\n",
      "219\tValidation loss: 1.345024\tBest loss: 1.337304\tAccuracy: 68.00%\n",
      "220\tValidation loss: 1.341099\tBest loss: 1.337304\tAccuracy: 68.40%\n",
      "221\tValidation loss: 1.348127\tBest loss: 1.337304\tAccuracy: 68.20%\n",
      "222\tValidation loss: 1.341227\tBest loss: 1.337304\tAccuracy: 68.80%\n",
      "223\tValidation loss: 1.338337\tBest loss: 1.337304\tAccuracy: 68.50%\n",
      "224\tValidation loss: 1.339253\tBest loss: 1.337304\tAccuracy: 68.80%\n",
      "225\tValidation loss: 1.341451\tBest loss: 1.337304\tAccuracy: 68.40%\n",
      "226\tValidation loss: 1.341979\tBest loss: 1.337304\tAccuracy: 68.20%\n",
      "227\tValidation loss: 1.339954\tBest loss: 1.337304\tAccuracy: 68.40%\n",
      "228\tValidation loss: 1.338241\tBest loss: 1.337304\tAccuracy: 68.30%\n",
      "229\tValidation loss: 1.336242\tBest loss: 1.336242\tAccuracy: 68.20%\n",
      "230\tValidation loss: 1.335549\tBest loss: 1.335549\tAccuracy: 68.40%\n",
      "231\tValidation loss: 1.336359\tBest loss: 1.335549\tAccuracy: 68.40%\n",
      "232\tValidation loss: 1.332996\tBest loss: 1.332996\tAccuracy: 68.50%\n",
      "233\tValidation loss: 1.327994\tBest loss: 1.327994\tAccuracy: 69.00%\n",
      "234\tValidation loss: 1.330682\tBest loss: 1.327994\tAccuracy: 68.90%\n",
      "235\tValidation loss: 1.328792\tBest loss: 1.327994\tAccuracy: 68.60%\n",
      "236\tValidation loss: 1.334383\tBest loss: 1.327994\tAccuracy: 68.50%\n",
      "237\tValidation loss: 1.330074\tBest loss: 1.327994\tAccuracy: 68.60%\n",
      "238\tValidation loss: 1.338482\tBest loss: 1.327994\tAccuracy: 68.50%\n",
      "239\tValidation loss: 1.334589\tBest loss: 1.327994\tAccuracy: 68.80%\n",
      "240\tValidation loss: 1.333277\tBest loss: 1.327994\tAccuracy: 68.80%\n",
      "241\tValidation loss: 1.333199\tBest loss: 1.327994\tAccuracy: 68.40%\n",
      "242\tValidation loss: 1.331042\tBest loss: 1.327994\tAccuracy: 68.80%\n",
      "243\tValidation loss: 1.331585\tBest loss: 1.327994\tAccuracy: 68.90%\n",
      "244\tValidation loss: 1.328190\tBest loss: 1.327994\tAccuracy: 68.60%\n",
      "245\tValidation loss: 1.332481\tBest loss: 1.327994\tAccuracy: 68.50%\n",
      "246\tValidation loss: 1.325264\tBest loss: 1.325264\tAccuracy: 68.50%\n",
      "247\tValidation loss: 1.329072\tBest loss: 1.325264\tAccuracy: 68.60%\n",
      "248\tValidation loss: 1.332201\tBest loss: 1.325264\tAccuracy: 68.30%\n",
      "249\tValidation loss: 1.329988\tBest loss: 1.325264\tAccuracy: 68.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 1.329886\tBest loss: 1.325264\tAccuracy: 68.80%\n",
      "251\tValidation loss: 1.333876\tBest loss: 1.325264\tAccuracy: 68.60%\n",
      "252\tValidation loss: 1.332532\tBest loss: 1.325264\tAccuracy: 68.70%\n",
      "253\tValidation loss: 1.323533\tBest loss: 1.323533\tAccuracy: 68.60%\n",
      "254\tValidation loss: 1.334464\tBest loss: 1.323533\tAccuracy: 68.20%\n",
      "255\tValidation loss: 1.329084\tBest loss: 1.323533\tAccuracy: 68.20%\n",
      "256\tValidation loss: 1.325550\tBest loss: 1.323533\tAccuracy: 68.60%\n",
      "257\tValidation loss: 1.330493\tBest loss: 1.323533\tAccuracy: 68.30%\n",
      "258\tValidation loss: 1.321940\tBest loss: 1.321940\tAccuracy: 68.60%\n",
      "259\tValidation loss: 1.325826\tBest loss: 1.321940\tAccuracy: 68.60%\n",
      "260\tValidation loss: 1.320690\tBest loss: 1.320690\tAccuracy: 68.60%\n",
      "261\tValidation loss: 1.331339\tBest loss: 1.320690\tAccuracy: 68.00%\n",
      "262\tValidation loss: 1.324606\tBest loss: 1.320690\tAccuracy: 68.40%\n",
      "263\tValidation loss: 1.327413\tBest loss: 1.320690\tAccuracy: 68.80%\n",
      "264\tValidation loss: 1.325692\tBest loss: 1.320690\tAccuracy: 68.50%\n",
      "265\tValidation loss: 1.321670\tBest loss: 1.320690\tAccuracy: 68.50%\n",
      "266\tValidation loss: 1.326577\tBest loss: 1.320690\tAccuracy: 67.90%\n",
      "267\tValidation loss: 1.316638\tBest loss: 1.316638\tAccuracy: 69.00%\n",
      "268\tValidation loss: 1.324736\tBest loss: 1.316638\tAccuracy: 68.60%\n",
      "269\tValidation loss: 1.318184\tBest loss: 1.316638\tAccuracy: 68.80%\n",
      "270\tValidation loss: 1.324028\tBest loss: 1.316638\tAccuracy: 68.60%\n",
      "271\tValidation loss: 1.323795\tBest loss: 1.316638\tAccuracy: 68.30%\n",
      "272\tValidation loss: 1.324822\tBest loss: 1.316638\tAccuracy: 68.90%\n",
      "273\tValidation loss: 1.316906\tBest loss: 1.316638\tAccuracy: 68.80%\n",
      "274\tValidation loss: 1.316319\tBest loss: 1.316319\tAccuracy: 68.50%\n",
      "275\tValidation loss: 1.319288\tBest loss: 1.316319\tAccuracy: 69.00%\n",
      "276\tValidation loss: 1.321060\tBest loss: 1.316319\tAccuracy: 68.50%\n",
      "277\tValidation loss: 1.321938\tBest loss: 1.316319\tAccuracy: 68.60%\n",
      "278\tValidation loss: 1.312363\tBest loss: 1.312363\tAccuracy: 68.70%\n",
      "279\tValidation loss: 1.322589\tBest loss: 1.312363\tAccuracy: 68.30%\n",
      "280\tValidation loss: 1.316955\tBest loss: 1.312363\tAccuracy: 68.70%\n",
      "281\tValidation loss: 1.313881\tBest loss: 1.312363\tAccuracy: 68.50%\n",
      "282\tValidation loss: 1.311873\tBest loss: 1.311873\tAccuracy: 68.90%\n",
      "283\tValidation loss: 1.318420\tBest loss: 1.311873\tAccuracy: 68.50%\n",
      "284\tValidation loss: 1.315744\tBest loss: 1.311873\tAccuracy: 68.90%\n",
      "285\tValidation loss: 1.324818\tBest loss: 1.311873\tAccuracy: 68.10%\n",
      "286\tValidation loss: 1.320173\tBest loss: 1.311873\tAccuracy: 67.90%\n",
      "287\tValidation loss: 1.317993\tBest loss: 1.311873\tAccuracy: 68.40%\n",
      "288\tValidation loss: 1.315412\tBest loss: 1.311873\tAccuracy: 69.00%\n",
      "289\tValidation loss: 1.318581\tBest loss: 1.311873\tAccuracy: 68.40%\n",
      "290\tValidation loss: 1.319153\tBest loss: 1.311873\tAccuracy: 68.40%\n",
      "291\tValidation loss: 1.311150\tBest loss: 1.311150\tAccuracy: 68.70%\n",
      "292\tValidation loss: 1.322719\tBest loss: 1.311150\tAccuracy: 68.60%\n",
      "293\tValidation loss: 1.317545\tBest loss: 1.311150\tAccuracy: 68.40%\n",
      "294\tValidation loss: 1.310983\tBest loss: 1.310983\tAccuracy: 68.60%\n",
      "295\tValidation loss: 1.310266\tBest loss: 1.310266\tAccuracy: 68.60%\n",
      "296\tValidation loss: 1.314893\tBest loss: 1.310266\tAccuracy: 68.40%\n",
      "297\tValidation loss: 1.316526\tBest loss: 1.310266\tAccuracy: 68.70%\n",
      "298\tValidation loss: 1.311149\tBest loss: 1.310266\tAccuracy: 68.50%\n",
      "299\tValidation loss: 1.309471\tBest loss: 1.309471\tAccuracy: 68.70%\n",
      "300\tValidation loss: 1.315344\tBest loss: 1.309471\tAccuracy: 68.30%\n",
      "301\tValidation loss: 1.312369\tBest loss: 1.309471\tAccuracy: 68.60%\n",
      "302\tValidation loss: 1.310908\tBest loss: 1.309471\tAccuracy: 68.50%\n",
      "303\tValidation loss: 1.311385\tBest loss: 1.309471\tAccuracy: 68.70%\n",
      "304\tValidation loss: 1.312716\tBest loss: 1.309471\tAccuracy: 68.80%\n",
      "305\tValidation loss: 1.305874\tBest loss: 1.305874\tAccuracy: 68.60%\n",
      "306\tValidation loss: 1.306240\tBest loss: 1.305874\tAccuracy: 68.60%\n",
      "307\tValidation loss: 1.301777\tBest loss: 1.301777\tAccuracy: 68.90%\n",
      "308\tValidation loss: 1.307338\tBest loss: 1.301777\tAccuracy: 68.50%\n",
      "309\tValidation loss: 1.306636\tBest loss: 1.301777\tAccuracy: 68.90%\n",
      "310\tValidation loss: 1.305196\tBest loss: 1.301777\tAccuracy: 68.40%\n",
      "311\tValidation loss: 1.305947\tBest loss: 1.301777\tAccuracy: 69.10%\n",
      "312\tValidation loss: 1.307586\tBest loss: 1.301777\tAccuracy: 68.60%\n",
      "313\tValidation loss: 1.307990\tBest loss: 1.301777\tAccuracy: 68.70%\n",
      "314\tValidation loss: 1.302814\tBest loss: 1.301777\tAccuracy: 68.80%\n",
      "315\tValidation loss: 1.307158\tBest loss: 1.301777\tAccuracy: 68.50%\n",
      "316\tValidation loss: 1.302745\tBest loss: 1.301777\tAccuracy: 68.90%\n",
      "317\tValidation loss: 1.301559\tBest loss: 1.301559\tAccuracy: 68.70%\n",
      "318\tValidation loss: 1.310236\tBest loss: 1.301559\tAccuracy: 68.50%\n",
      "319\tValidation loss: 1.303663\tBest loss: 1.301559\tAccuracy: 69.00%\n",
      "320\tValidation loss: 1.307557\tBest loss: 1.301559\tAccuracy: 68.60%\n",
      "321\tValidation loss: 1.302240\tBest loss: 1.301559\tAccuracy: 68.90%\n",
      "322\tValidation loss: 1.309459\tBest loss: 1.301559\tAccuracy: 69.10%\n",
      "323\tValidation loss: 1.302690\tBest loss: 1.301559\tAccuracy: 68.80%\n",
      "324\tValidation loss: 1.303336\tBest loss: 1.301559\tAccuracy: 68.90%\n",
      "325\tValidation loss: 1.302406\tBest loss: 1.301559\tAccuracy: 69.10%\n",
      "326\tValidation loss: 1.303544\tBest loss: 1.301559\tAccuracy: 69.20%\n",
      "327\tValidation loss: 1.305169\tBest loss: 1.301559\tAccuracy: 68.70%\n",
      "328\tValidation loss: 1.303306\tBest loss: 1.301559\tAccuracy: 68.70%\n",
      "329\tValidation loss: 1.306977\tBest loss: 1.301559\tAccuracy: 68.60%\n",
      "330\tValidation loss: 1.294693\tBest loss: 1.294693\tAccuracy: 68.70%\n",
      "331\tValidation loss: 1.293480\tBest loss: 1.293480\tAccuracy: 68.80%\n",
      "332\tValidation loss: 1.303566\tBest loss: 1.293480\tAccuracy: 69.00%\n",
      "333\tValidation loss: 1.296180\tBest loss: 1.293480\tAccuracy: 69.10%\n",
      "334\tValidation loss: 1.301125\tBest loss: 1.293480\tAccuracy: 68.70%\n",
      "335\tValidation loss: 1.296421\tBest loss: 1.293480\tAccuracy: 68.80%\n",
      "336\tValidation loss: 1.302652\tBest loss: 1.293480\tAccuracy: 69.10%\n",
      "337\tValidation loss: 1.302003\tBest loss: 1.293480\tAccuracy: 68.70%\n",
      "338\tValidation loss: 1.299227\tBest loss: 1.293480\tAccuracy: 69.00%\n",
      "339\tValidation loss: 1.302413\tBest loss: 1.293480\tAccuracy: 69.10%\n",
      "340\tValidation loss: 1.303462\tBest loss: 1.293480\tAccuracy: 68.90%\n",
      "341\tValidation loss: 1.306023\tBest loss: 1.293480\tAccuracy: 68.90%\n",
      "342\tValidation loss: 1.298759\tBest loss: 1.293480\tAccuracy: 69.00%\n",
      "343\tValidation loss: 1.302999\tBest loss: 1.293480\tAccuracy: 68.50%\n",
      "344\tValidation loss: 1.295214\tBest loss: 1.293480\tAccuracy: 68.70%\n",
      "345\tValidation loss: 1.303858\tBest loss: 1.293480\tAccuracy: 69.10%\n",
      "346\tValidation loss: 1.298390\tBest loss: 1.293480\tAccuracy: 68.90%\n",
      "347\tValidation loss: 1.296877\tBest loss: 1.293480\tAccuracy: 69.00%\n",
      "348\tValidation loss: 1.300396\tBest loss: 1.293480\tAccuracy: 69.10%\n",
      "349\tValidation loss: 1.297233\tBest loss: 1.293480\tAccuracy: 69.30%\n",
      "350\tValidation loss: 1.302282\tBest loss: 1.293480\tAccuracy: 69.30%\n",
      "351\tValidation loss: 1.302574\tBest loss: 1.293480\tAccuracy: 69.20%\n",
      "352\tValidation loss: 1.301634\tBest loss: 1.293480\tAccuracy: 68.80%\n",
      "Early stopping!\n",
      "[[  2.65700868e-16   9.42416589e-10   4.91792264e-07 ...,   2.63853516e-16\n",
      "    2.54327863e-16   9.34513832e-14]\n",
      " [  4.87909392e-02   3.41944210e-02   4.06088829e-02 ...,   1.59015693e-02\n",
      "    1.19906580e-02   9.84176435e-03]\n",
      " [  3.27393459e-19   2.60690518e-26   1.44765737e-08 ...,   2.43103536e-25\n",
      "    9.33697573e-32   2.36263124e-32]\n",
      " ..., \n",
      " [  3.74782616e-22   1.77726244e-23   1.36257246e-20 ...,   3.04183889e-15\n",
      "    1.76324360e-15   2.74336590e-14]\n",
      " [  1.02275005e-02   8.97339173e-03   5.53470068e-02 ...,   1.38596728e-01\n",
      "    1.90066092e-03   4.77612624e-03]\n",
      " [  1.21878911e-25   1.98539627e-14   2.19370312e-12 ...,   3.76405643e-11\n",
      "    6.56522892e-10   1.81591895e-05]]\n",
      "[22  0 16 ...,  6 24 25]\n",
      "[[  1.13675068e-11   7.45964428e-08   3.46885213e-06 ...,   9.58742460e-11\n",
      "    4.23090035e-12   8.58319424e-07]\n",
      " [  2.09939134e-20   5.07594921e-12   2.84447135e-13 ...,   1.51633265e-22\n",
      "    1.01624777e-23   4.16053319e-17]\n",
      " [  5.16538678e-12   1.62238711e-09   6.29881433e-12 ...,   4.71987345e-11\n",
      "    5.55419987e-20   2.12522952e-13]\n",
      " ..., \n",
      " [  1.63803104e-08   7.84526577e-09   9.13729714e-09 ...,   2.11736296e-18\n",
      "    2.42401534e-14   9.50937137e-13]\n",
      " [  2.69224197e-02   2.24119034e-02   2.69840434e-02 ...,   1.97346024e-02\n",
      "    1.82575062e-02   1.42545821e-02]\n",
      " [  8.87933394e-24   1.25924233e-16   1.37792466e-17 ...,   1.56118375e-07\n",
      "    8.84092588e-04   9.97253358e-01]]\n",
      "[43 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=  15.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 7.548899\tBest loss: 7.548899\tAccuracy: 12.70%\n",
      "1\tValidation loss: 5.391316\tBest loss: 5.391316\tAccuracy: 19.50%\n",
      "2\tValidation loss: 4.267971\tBest loss: 4.267971\tAccuracy: 24.00%\n",
      "3\tValidation loss: 3.654444\tBest loss: 3.654444\tAccuracy: 30.60%\n",
      "4\tValidation loss: 3.341819\tBest loss: 3.341819\tAccuracy: 33.00%\n",
      "5\tValidation loss: 3.150927\tBest loss: 3.150927\tAccuracy: 34.70%\n",
      "6\tValidation loss: 2.944806\tBest loss: 2.944806\tAccuracy: 38.40%\n",
      "7\tValidation loss: 2.788992\tBest loss: 2.788992\tAccuracy: 39.30%\n",
      "8\tValidation loss: 2.681052\tBest loss: 2.681052\tAccuracy: 43.10%\n",
      "9\tValidation loss: 2.608603\tBest loss: 2.608603\tAccuracy: 43.80%\n",
      "10\tValidation loss: 2.512391\tBest loss: 2.512391\tAccuracy: 44.20%\n",
      "11\tValidation loss: 2.493779\tBest loss: 2.493779\tAccuracy: 45.10%\n",
      "12\tValidation loss: 2.418501\tBest loss: 2.418501\tAccuracy: 46.80%\n",
      "13\tValidation loss: 2.351308\tBest loss: 2.351308\tAccuracy: 48.00%\n",
      "14\tValidation loss: 2.290629\tBest loss: 2.290629\tAccuracy: 49.00%\n",
      "15\tValidation loss: 2.291908\tBest loss: 2.290629\tAccuracy: 47.90%\n",
      "16\tValidation loss: 2.197514\tBest loss: 2.197514\tAccuracy: 50.20%\n",
      "17\tValidation loss: 2.160305\tBest loss: 2.160305\tAccuracy: 52.00%\n",
      "18\tValidation loss: 2.160671\tBest loss: 2.160305\tAccuracy: 52.50%\n",
      "19\tValidation loss: 2.102120\tBest loss: 2.102120\tAccuracy: 52.40%\n",
      "20\tValidation loss: 2.108257\tBest loss: 2.102120\tAccuracy: 53.30%\n",
      "21\tValidation loss: 2.045689\tBest loss: 2.045689\tAccuracy: 53.70%\n",
      "22\tValidation loss: 2.044008\tBest loss: 2.044008\tAccuracy: 54.70%\n",
      "23\tValidation loss: 2.050359\tBest loss: 2.044008\tAccuracy: 53.50%\n",
      "24\tValidation loss: 1.982643\tBest loss: 1.982643\tAccuracy: 55.20%\n",
      "25\tValidation loss: 1.964878\tBest loss: 1.964878\tAccuracy: 55.90%\n",
      "26\tValidation loss: 1.954167\tBest loss: 1.954167\tAccuracy: 56.20%\n",
      "27\tValidation loss: 1.930798\tBest loss: 1.930798\tAccuracy: 56.50%\n",
      "28\tValidation loss: 1.915047\tBest loss: 1.915047\tAccuracy: 56.70%\n",
      "29\tValidation loss: 1.912421\tBest loss: 1.912421\tAccuracy: 57.30%\n",
      "30\tValidation loss: 1.878670\tBest loss: 1.878670\tAccuracy: 56.90%\n",
      "31\tValidation loss: 1.883840\tBest loss: 1.878670\tAccuracy: 57.90%\n",
      "32\tValidation loss: 1.856961\tBest loss: 1.856961\tAccuracy: 58.10%\n",
      "33\tValidation loss: 1.855951\tBest loss: 1.855951\tAccuracy: 57.60%\n",
      "34\tValidation loss: 1.840876\tBest loss: 1.840876\tAccuracy: 58.10%\n",
      "35\tValidation loss: 1.825907\tBest loss: 1.825907\tAccuracy: 59.20%\n",
      "36\tValidation loss: 1.800805\tBest loss: 1.800805\tAccuracy: 58.70%\n",
      "37\tValidation loss: 1.798915\tBest loss: 1.798915\tAccuracy: 59.50%\n",
      "38\tValidation loss: 1.796006\tBest loss: 1.796006\tAccuracy: 58.60%\n",
      "39\tValidation loss: 1.782860\tBest loss: 1.782860\tAccuracy: 59.40%\n",
      "40\tValidation loss: 1.798770\tBest loss: 1.782860\tAccuracy: 59.80%\n",
      "41\tValidation loss: 1.777116\tBest loss: 1.777116\tAccuracy: 60.20%\n",
      "42\tValidation loss: 1.752572\tBest loss: 1.752572\tAccuracy: 61.20%\n",
      "43\tValidation loss: 1.751536\tBest loss: 1.751536\tAccuracy: 60.40%\n",
      "44\tValidation loss: 1.753401\tBest loss: 1.751536\tAccuracy: 60.70%\n",
      "45\tValidation loss: 1.718642\tBest loss: 1.718642\tAccuracy: 60.70%\n",
      "46\tValidation loss: 1.732263\tBest loss: 1.718642\tAccuracy: 60.30%\n",
      "47\tValidation loss: 1.723924\tBest loss: 1.718642\tAccuracy: 60.50%\n",
      "48\tValidation loss: 1.723520\tBest loss: 1.718642\tAccuracy: 60.10%\n",
      "49\tValidation loss: 1.726838\tBest loss: 1.718642\tAccuracy: 60.30%\n",
      "50\tValidation loss: 1.701144\tBest loss: 1.701144\tAccuracy: 61.50%\n",
      "51\tValidation loss: 1.718255\tBest loss: 1.701144\tAccuracy: 61.20%\n",
      "52\tValidation loss: 1.699287\tBest loss: 1.699287\tAccuracy: 61.20%\n",
      "53\tValidation loss: 1.686308\tBest loss: 1.686308\tAccuracy: 61.70%\n",
      "54\tValidation loss: 1.677085\tBest loss: 1.677085\tAccuracy: 62.00%\n",
      "55\tValidation loss: 1.681864\tBest loss: 1.677085\tAccuracy: 61.30%\n",
      "56\tValidation loss: 1.665769\tBest loss: 1.665769\tAccuracy: 60.90%\n",
      "57\tValidation loss: 1.667825\tBest loss: 1.665769\tAccuracy: 61.50%\n",
      "58\tValidation loss: 1.662065\tBest loss: 1.662065\tAccuracy: 61.60%\n",
      "59\tValidation loss: 1.649673\tBest loss: 1.649673\tAccuracy: 62.50%\n",
      "60\tValidation loss: 1.647408\tBest loss: 1.647408\tAccuracy: 62.50%\n",
      "61\tValidation loss: 1.644774\tBest loss: 1.644774\tAccuracy: 62.60%\n",
      "62\tValidation loss: 1.640558\tBest loss: 1.640558\tAccuracy: 62.90%\n",
      "63\tValidation loss: 1.630624\tBest loss: 1.630624\tAccuracy: 62.30%\n",
      "64\tValidation loss: 1.636256\tBest loss: 1.630624\tAccuracy: 62.70%\n",
      "65\tValidation loss: 1.624183\tBest loss: 1.624183\tAccuracy: 62.90%\n",
      "66\tValidation loss: 1.625254\tBest loss: 1.624183\tAccuracy: 64.10%\n",
      "67\tValidation loss: 1.617315\tBest loss: 1.617315\tAccuracy: 63.80%\n",
      "68\tValidation loss: 1.622549\tBest loss: 1.617315\tAccuracy: 63.80%\n",
      "69\tValidation loss: 1.605445\tBest loss: 1.605445\tAccuracy: 64.00%\n",
      "70\tValidation loss: 1.601786\tBest loss: 1.601786\tAccuracy: 64.80%\n",
      "71\tValidation loss: 1.603993\tBest loss: 1.601786\tAccuracy: 62.60%\n",
      "72\tValidation loss: 1.600553\tBest loss: 1.600553\tAccuracy: 64.10%\n",
      "73\tValidation loss: 1.589412\tBest loss: 1.589412\tAccuracy: 64.40%\n",
      "74\tValidation loss: 1.589964\tBest loss: 1.589412\tAccuracy: 64.60%\n",
      "75\tValidation loss: 1.593969\tBest loss: 1.589412\tAccuracy: 64.60%\n",
      "76\tValidation loss: 1.578986\tBest loss: 1.578986\tAccuracy: 64.60%\n",
      "77\tValidation loss: 1.597745\tBest loss: 1.578986\tAccuracy: 64.10%\n",
      "78\tValidation loss: 1.582355\tBest loss: 1.578986\tAccuracy: 64.10%\n",
      "79\tValidation loss: 1.572705\tBest loss: 1.572705\tAccuracy: 65.20%\n",
      "80\tValidation loss: 1.569553\tBest loss: 1.569553\tAccuracy: 64.90%\n",
      "81\tValidation loss: 1.571611\tBest loss: 1.569553\tAccuracy: 64.10%\n",
      "82\tValidation loss: 1.574122\tBest loss: 1.569553\tAccuracy: 65.10%\n",
      "83\tValidation loss: 1.565729\tBest loss: 1.565729\tAccuracy: 65.20%\n",
      "84\tValidation loss: 1.568300\tBest loss: 1.565729\tAccuracy: 64.50%\n",
      "85\tValidation loss: 1.555893\tBest loss: 1.555893\tAccuracy: 65.70%\n",
      "86\tValidation loss: 1.549157\tBest loss: 1.549157\tAccuracy: 65.90%\n",
      "87\tValidation loss: 1.559190\tBest loss: 1.549157\tAccuracy: 64.80%\n",
      "88\tValidation loss: 1.561288\tBest loss: 1.549157\tAccuracy: 64.50%\n",
      "89\tValidation loss: 1.538111\tBest loss: 1.538111\tAccuracy: 66.20%\n",
      "90\tValidation loss: 1.542186\tBest loss: 1.538111\tAccuracy: 64.70%\n",
      "91\tValidation loss: 1.542574\tBest loss: 1.538111\tAccuracy: 65.20%\n",
      "92\tValidation loss: 1.543830\tBest loss: 1.538111\tAccuracy: 66.20%\n",
      "93\tValidation loss: 1.533888\tBest loss: 1.533888\tAccuracy: 65.20%\n",
      "94\tValidation loss: 1.545243\tBest loss: 1.533888\tAccuracy: 65.70%\n",
      "95\tValidation loss: 1.539338\tBest loss: 1.533888\tAccuracy: 65.60%\n",
      "96\tValidation loss: 1.528098\tBest loss: 1.528098\tAccuracy: 66.20%\n",
      "97\tValidation loss: 1.531071\tBest loss: 1.528098\tAccuracy: 65.30%\n",
      "98\tValidation loss: 1.526923\tBest loss: 1.526923\tAccuracy: 64.50%\n",
      "99\tValidation loss: 1.530178\tBest loss: 1.526923\tAccuracy: 65.90%\n",
      "100\tValidation loss: 1.517279\tBest loss: 1.517279\tAccuracy: 65.80%\n",
      "101\tValidation loss: 1.525438\tBest loss: 1.517279\tAccuracy: 65.80%\n",
      "102\tValidation loss: 1.519797\tBest loss: 1.517279\tAccuracy: 66.30%\n",
      "103\tValidation loss: 1.513064\tBest loss: 1.513064\tAccuracy: 65.70%\n",
      "104\tValidation loss: 1.520493\tBest loss: 1.513064\tAccuracy: 65.60%\n",
      "105\tValidation loss: 1.520978\tBest loss: 1.513064\tAccuracy: 66.80%\n",
      "106\tValidation loss: 1.504256\tBest loss: 1.504256\tAccuracy: 66.50%\n",
      "107\tValidation loss: 1.502843\tBest loss: 1.502843\tAccuracy: 66.70%\n",
      "108\tValidation loss: 1.509075\tBest loss: 1.502843\tAccuracy: 65.70%\n",
      "109\tValidation loss: 1.502275\tBest loss: 1.502275\tAccuracy: 67.10%\n",
      "110\tValidation loss: 1.509449\tBest loss: 1.502275\tAccuracy: 67.20%\n",
      "111\tValidation loss: 1.505633\tBest loss: 1.502275\tAccuracy: 66.40%\n",
      "112\tValidation loss: 1.501222\tBest loss: 1.501222\tAccuracy: 65.90%\n",
      "113\tValidation loss: 1.499144\tBest loss: 1.499144\tAccuracy: 66.60%\n",
      "114\tValidation loss: 1.501464\tBest loss: 1.499144\tAccuracy: 67.10%\n",
      "115\tValidation loss: 1.499343\tBest loss: 1.499144\tAccuracy: 67.10%\n",
      "116\tValidation loss: 1.493010\tBest loss: 1.493010\tAccuracy: 66.70%\n",
      "117\tValidation loss: 1.487239\tBest loss: 1.487239\tAccuracy: 67.50%\n",
      "118\tValidation loss: 1.494283\tBest loss: 1.487239\tAccuracy: 66.60%\n",
      "119\tValidation loss: 1.491449\tBest loss: 1.487239\tAccuracy: 66.90%\n",
      "120\tValidation loss: 1.486323\tBest loss: 1.486323\tAccuracy: 67.20%\n",
      "121\tValidation loss: 1.485232\tBest loss: 1.485232\tAccuracy: 67.20%\n",
      "122\tValidation loss: 1.486328\tBest loss: 1.485232\tAccuracy: 66.50%\n",
      "123\tValidation loss: 1.483003\tBest loss: 1.483003\tAccuracy: 67.30%\n",
      "124\tValidation loss: 1.484273\tBest loss: 1.483003\tAccuracy: 66.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 1.479272\tBest loss: 1.479272\tAccuracy: 67.20%\n",
      "126\tValidation loss: 1.476884\tBest loss: 1.476884\tAccuracy: 66.80%\n",
      "127\tValidation loss: 1.481609\tBest loss: 1.476884\tAccuracy: 67.20%\n",
      "128\tValidation loss: 1.474831\tBest loss: 1.474831\tAccuracy: 66.90%\n",
      "129\tValidation loss: 1.473941\tBest loss: 1.473941\tAccuracy: 66.90%\n",
      "130\tValidation loss: 1.467418\tBest loss: 1.467418\tAccuracy: 67.10%\n",
      "131\tValidation loss: 1.468506\tBest loss: 1.467418\tAccuracy: 66.60%\n",
      "132\tValidation loss: 1.474199\tBest loss: 1.467418\tAccuracy: 66.60%\n",
      "133\tValidation loss: 1.463730\tBest loss: 1.463730\tAccuracy: 67.00%\n",
      "134\tValidation loss: 1.463979\tBest loss: 1.463730\tAccuracy: 67.80%\n",
      "135\tValidation loss: 1.463326\tBest loss: 1.463326\tAccuracy: 67.20%\n",
      "136\tValidation loss: 1.457330\tBest loss: 1.457330\tAccuracy: 68.00%\n",
      "137\tValidation loss: 1.461341\tBest loss: 1.457330\tAccuracy: 67.40%\n",
      "138\tValidation loss: 1.460472\tBest loss: 1.457330\tAccuracy: 67.40%\n",
      "139\tValidation loss: 1.460242\tBest loss: 1.457330\tAccuracy: 67.60%\n",
      "140\tValidation loss: 1.452837\tBest loss: 1.452837\tAccuracy: 66.90%\n",
      "141\tValidation loss: 1.457965\tBest loss: 1.452837\tAccuracy: 67.60%\n",
      "142\tValidation loss: 1.449193\tBest loss: 1.449193\tAccuracy: 66.90%\n",
      "143\tValidation loss: 1.450315\tBest loss: 1.449193\tAccuracy: 67.50%\n",
      "144\tValidation loss: 1.451484\tBest loss: 1.449193\tAccuracy: 66.80%\n",
      "145\tValidation loss: 1.446798\tBest loss: 1.446798\tAccuracy: 67.00%\n",
      "146\tValidation loss: 1.449434\tBest loss: 1.446798\tAccuracy: 67.20%\n",
      "147\tValidation loss: 1.449337\tBest loss: 1.446798\tAccuracy: 67.10%\n",
      "148\tValidation loss: 1.454806\tBest loss: 1.446798\tAccuracy: 66.60%\n",
      "149\tValidation loss: 1.443228\tBest loss: 1.443228\tAccuracy: 67.20%\n",
      "150\tValidation loss: 1.451079\tBest loss: 1.443228\tAccuracy: 67.40%\n",
      "151\tValidation loss: 1.442192\tBest loss: 1.442192\tAccuracy: 67.60%\n",
      "152\tValidation loss: 1.437359\tBest loss: 1.437359\tAccuracy: 67.80%\n",
      "153\tValidation loss: 1.437223\tBest loss: 1.437223\tAccuracy: 67.50%\n",
      "154\tValidation loss: 1.439713\tBest loss: 1.437223\tAccuracy: 67.60%\n",
      "155\tValidation loss: 1.441990\tBest loss: 1.437223\tAccuracy: 67.40%\n",
      "156\tValidation loss: 1.434115\tBest loss: 1.434115\tAccuracy: 67.70%\n",
      "157\tValidation loss: 1.437424\tBest loss: 1.434115\tAccuracy: 67.80%\n",
      "158\tValidation loss: 1.432954\tBest loss: 1.432954\tAccuracy: 67.60%\n",
      "159\tValidation loss: 1.436437\tBest loss: 1.432954\tAccuracy: 67.70%\n",
      "160\tValidation loss: 1.429723\tBest loss: 1.429723\tAccuracy: 68.50%\n",
      "161\tValidation loss: 1.436227\tBest loss: 1.429723\tAccuracy: 67.80%\n",
      "162\tValidation loss: 1.426408\tBest loss: 1.426408\tAccuracy: 67.20%\n",
      "163\tValidation loss: 1.430031\tBest loss: 1.426408\tAccuracy: 67.80%\n",
      "164\tValidation loss: 1.432545\tBest loss: 1.426408\tAccuracy: 67.60%\n",
      "165\tValidation loss: 1.421425\tBest loss: 1.421425\tAccuracy: 67.90%\n",
      "166\tValidation loss: 1.421189\tBest loss: 1.421189\tAccuracy: 67.80%\n",
      "167\tValidation loss: 1.420454\tBest loss: 1.420454\tAccuracy: 67.80%\n",
      "168\tValidation loss: 1.424186\tBest loss: 1.420454\tAccuracy: 67.90%\n",
      "169\tValidation loss: 1.422583\tBest loss: 1.420454\tAccuracy: 67.50%\n",
      "170\tValidation loss: 1.424053\tBest loss: 1.420454\tAccuracy: 67.40%\n",
      "171\tValidation loss: 1.422867\tBest loss: 1.420454\tAccuracy: 68.00%\n",
      "172\tValidation loss: 1.424587\tBest loss: 1.420454\tAccuracy: 67.60%\n",
      "173\tValidation loss: 1.414459\tBest loss: 1.414459\tAccuracy: 67.80%\n",
      "174\tValidation loss: 1.415248\tBest loss: 1.414459\tAccuracy: 67.90%\n",
      "175\tValidation loss: 1.415205\tBest loss: 1.414459\tAccuracy: 67.60%\n",
      "176\tValidation loss: 1.409557\tBest loss: 1.409557\tAccuracy: 67.90%\n",
      "177\tValidation loss: 1.415787\tBest loss: 1.409557\tAccuracy: 67.90%\n",
      "178\tValidation loss: 1.413965\tBest loss: 1.409557\tAccuracy: 67.70%\n",
      "179\tValidation loss: 1.409791\tBest loss: 1.409557\tAccuracy: 67.80%\n",
      "180\tValidation loss: 1.412069\tBest loss: 1.409557\tAccuracy: 67.50%\n",
      "181\tValidation loss: 1.403862\tBest loss: 1.403862\tAccuracy: 68.20%\n",
      "182\tValidation loss: 1.408105\tBest loss: 1.403862\tAccuracy: 68.10%\n",
      "183\tValidation loss: 1.404911\tBest loss: 1.403862\tAccuracy: 67.70%\n",
      "184\tValidation loss: 1.402959\tBest loss: 1.402959\tAccuracy: 68.40%\n",
      "185\tValidation loss: 1.411568\tBest loss: 1.402959\tAccuracy: 67.90%\n",
      "186\tValidation loss: 1.403350\tBest loss: 1.402959\tAccuracy: 67.80%\n",
      "187\tValidation loss: 1.404824\tBest loss: 1.402959\tAccuracy: 67.80%\n",
      "188\tValidation loss: 1.407922\tBest loss: 1.402959\tAccuracy: 68.30%\n",
      "189\tValidation loss: 1.407558\tBest loss: 1.402959\tAccuracy: 68.30%\n",
      "190\tValidation loss: 1.406864\tBest loss: 1.402959\tAccuracy: 68.10%\n",
      "191\tValidation loss: 1.399444\tBest loss: 1.399444\tAccuracy: 68.60%\n",
      "192\tValidation loss: 1.401607\tBest loss: 1.399444\tAccuracy: 68.50%\n",
      "193\tValidation loss: 1.397551\tBest loss: 1.397551\tAccuracy: 67.50%\n",
      "194\tValidation loss: 1.400192\tBest loss: 1.397551\tAccuracy: 68.30%\n",
      "195\tValidation loss: 1.398466\tBest loss: 1.397551\tAccuracy: 68.50%\n",
      "196\tValidation loss: 1.397053\tBest loss: 1.397053\tAccuracy: 68.40%\n",
      "197\tValidation loss: 1.394231\tBest loss: 1.394231\tAccuracy: 68.10%\n",
      "198\tValidation loss: 1.399050\tBest loss: 1.394231\tAccuracy: 68.40%\n",
      "199\tValidation loss: 1.394769\tBest loss: 1.394231\tAccuracy: 68.60%\n",
      "200\tValidation loss: 1.398235\tBest loss: 1.394231\tAccuracy: 67.50%\n",
      "201\tValidation loss: 1.391560\tBest loss: 1.391560\tAccuracy: 67.90%\n",
      "202\tValidation loss: 1.389361\tBest loss: 1.389361\tAccuracy: 68.60%\n",
      "203\tValidation loss: 1.392251\tBest loss: 1.389361\tAccuracy: 68.30%\n",
      "204\tValidation loss: 1.394342\tBest loss: 1.389361\tAccuracy: 67.90%\n",
      "205\tValidation loss: 1.386751\tBest loss: 1.386751\tAccuracy: 68.40%\n",
      "206\tValidation loss: 1.394906\tBest loss: 1.386751\tAccuracy: 68.40%\n",
      "207\tValidation loss: 1.390197\tBest loss: 1.386751\tAccuracy: 68.40%\n",
      "208\tValidation loss: 1.387034\tBest loss: 1.386751\tAccuracy: 67.80%\n",
      "209\tValidation loss: 1.385883\tBest loss: 1.385883\tAccuracy: 68.00%\n",
      "210\tValidation loss: 1.384745\tBest loss: 1.384745\tAccuracy: 68.60%\n",
      "211\tValidation loss: 1.387847\tBest loss: 1.384745\tAccuracy: 68.10%\n",
      "212\tValidation loss: 1.384383\tBest loss: 1.384383\tAccuracy: 68.50%\n",
      "213\tValidation loss: 1.385102\tBest loss: 1.384383\tAccuracy: 68.40%\n",
      "214\tValidation loss: 1.382787\tBest loss: 1.382787\tAccuracy: 68.30%\n",
      "215\tValidation loss: 1.382972\tBest loss: 1.382787\tAccuracy: 68.40%\n",
      "216\tValidation loss: 1.379229\tBest loss: 1.379229\tAccuracy: 68.40%\n",
      "217\tValidation loss: 1.382171\tBest loss: 1.379229\tAccuracy: 68.40%\n",
      "218\tValidation loss: 1.377184\tBest loss: 1.377184\tAccuracy: 68.20%\n",
      "219\tValidation loss: 1.383449\tBest loss: 1.377184\tAccuracy: 68.30%\n",
      "220\tValidation loss: 1.383364\tBest loss: 1.377184\tAccuracy: 68.20%\n",
      "221\tValidation loss: 1.377628\tBest loss: 1.377184\tAccuracy: 68.60%\n",
      "222\tValidation loss: 1.375038\tBest loss: 1.375038\tAccuracy: 68.30%\n",
      "223\tValidation loss: 1.378337\tBest loss: 1.375038\tAccuracy: 67.90%\n",
      "224\tValidation loss: 1.377611\tBest loss: 1.375038\tAccuracy: 68.10%\n",
      "225\tValidation loss: 1.371829\tBest loss: 1.371829\tAccuracy: 68.20%\n",
      "226\tValidation loss: 1.369342\tBest loss: 1.369342\tAccuracy: 68.00%\n",
      "227\tValidation loss: 1.372024\tBest loss: 1.369342\tAccuracy: 68.40%\n",
      "228\tValidation loss: 1.367290\tBest loss: 1.367290\tAccuracy: 68.60%\n",
      "229\tValidation loss: 1.371913\tBest loss: 1.367290\tAccuracy: 68.30%\n",
      "230\tValidation loss: 1.371110\tBest loss: 1.367290\tAccuracy: 68.90%\n",
      "231\tValidation loss: 1.372539\tBest loss: 1.367290\tAccuracy: 68.10%\n",
      "232\tValidation loss: 1.368261\tBest loss: 1.367290\tAccuracy: 69.20%\n",
      "233\tValidation loss: 1.369678\tBest loss: 1.367290\tAccuracy: 68.10%\n",
      "234\tValidation loss: 1.377275\tBest loss: 1.367290\tAccuracy: 68.70%\n",
      "235\tValidation loss: 1.376052\tBest loss: 1.367290\tAccuracy: 68.00%\n",
      "236\tValidation loss: 1.363685\tBest loss: 1.363685\tAccuracy: 68.50%\n",
      "237\tValidation loss: 1.366092\tBest loss: 1.363685\tAccuracy: 68.50%\n",
      "238\tValidation loss: 1.368519\tBest loss: 1.363685\tAccuracy: 68.50%\n",
      "239\tValidation loss: 1.364113\tBest loss: 1.363685\tAccuracy: 68.90%\n",
      "240\tValidation loss: 1.363486\tBest loss: 1.363486\tAccuracy: 68.70%\n",
      "241\tValidation loss: 1.358880\tBest loss: 1.358880\tAccuracy: 68.50%\n",
      "242\tValidation loss: 1.359901\tBest loss: 1.358880\tAccuracy: 68.20%\n",
      "243\tValidation loss: 1.359156\tBest loss: 1.358880\tAccuracy: 68.60%\n",
      "244\tValidation loss: 1.362381\tBest loss: 1.358880\tAccuracy: 68.60%\n",
      "245\tValidation loss: 1.362476\tBest loss: 1.358880\tAccuracy: 69.20%\n",
      "246\tValidation loss: 1.361284\tBest loss: 1.358880\tAccuracy: 68.80%\n",
      "247\tValidation loss: 1.360225\tBest loss: 1.358880\tAccuracy: 68.70%\n",
      "248\tValidation loss: 1.367901\tBest loss: 1.358880\tAccuracy: 68.70%\n",
      "249\tValidation loss: 1.358853\tBest loss: 1.358853\tAccuracy: 68.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\tValidation loss: 1.356250\tBest loss: 1.356250\tAccuracy: 68.70%\n",
      "251\tValidation loss: 1.360364\tBest loss: 1.356250\tAccuracy: 68.40%\n",
      "252\tValidation loss: 1.357681\tBest loss: 1.356250\tAccuracy: 68.50%\n",
      "253\tValidation loss: 1.354623\tBest loss: 1.354623\tAccuracy: 68.80%\n",
      "254\tValidation loss: 1.359169\tBest loss: 1.354623\tAccuracy: 68.40%\n",
      "255\tValidation loss: 1.356302\tBest loss: 1.354623\tAccuracy: 68.90%\n",
      "256\tValidation loss: 1.357270\tBest loss: 1.354623\tAccuracy: 69.10%\n",
      "257\tValidation loss: 1.350784\tBest loss: 1.350784\tAccuracy: 69.00%\n",
      "258\tValidation loss: 1.356024\tBest loss: 1.350784\tAccuracy: 68.80%\n",
      "259\tValidation loss: 1.358093\tBest loss: 1.350784\tAccuracy: 69.10%\n",
      "260\tValidation loss: 1.355318\tBest loss: 1.350784\tAccuracy: 68.40%\n",
      "261\tValidation loss: 1.356775\tBest loss: 1.350784\tAccuracy: 69.10%\n",
      "262\tValidation loss: 1.350645\tBest loss: 1.350645\tAccuracy: 68.60%\n",
      "263\tValidation loss: 1.351178\tBest loss: 1.350645\tAccuracy: 68.70%\n",
      "264\tValidation loss: 1.347626\tBest loss: 1.347626\tAccuracy: 68.80%\n",
      "265\tValidation loss: 1.348478\tBest loss: 1.347626\tAccuracy: 69.20%\n",
      "266\tValidation loss: 1.347586\tBest loss: 1.347586\tAccuracy: 68.50%\n",
      "267\tValidation loss: 1.348266\tBest loss: 1.347586\tAccuracy: 69.30%\n",
      "268\tValidation loss: 1.351028\tBest loss: 1.347586\tAccuracy: 68.90%\n",
      "269\tValidation loss: 1.347242\tBest loss: 1.347242\tAccuracy: 68.50%\n",
      "270\tValidation loss: 1.350402\tBest loss: 1.347242\tAccuracy: 68.90%\n",
      "271\tValidation loss: 1.349085\tBest loss: 1.347242\tAccuracy: 69.20%\n",
      "272\tValidation loss: 1.345485\tBest loss: 1.345485\tAccuracy: 69.10%\n",
      "273\tValidation loss: 1.345601\tBest loss: 1.345485\tAccuracy: 69.00%\n",
      "274\tValidation loss: 1.344212\tBest loss: 1.344212\tAccuracy: 69.10%\n",
      "275\tValidation loss: 1.347633\tBest loss: 1.344212\tAccuracy: 68.90%\n",
      "276\tValidation loss: 1.347248\tBest loss: 1.344212\tAccuracy: 68.60%\n",
      "277\tValidation loss: 1.348104\tBest loss: 1.344212\tAccuracy: 69.00%\n",
      "278\tValidation loss: 1.340982\tBest loss: 1.340982\tAccuracy: 69.20%\n",
      "279\tValidation loss: 1.342342\tBest loss: 1.340982\tAccuracy: 68.90%\n",
      "280\tValidation loss: 1.344434\tBest loss: 1.340982\tAccuracy: 68.70%\n",
      "281\tValidation loss: 1.343795\tBest loss: 1.340982\tAccuracy: 69.00%\n",
      "282\tValidation loss: 1.341433\tBest loss: 1.340982\tAccuracy: 68.70%\n",
      "283\tValidation loss: 1.343667\tBest loss: 1.340982\tAccuracy: 69.20%\n",
      "284\tValidation loss: 1.341217\tBest loss: 1.340982\tAccuracy: 69.00%\n",
      "285\tValidation loss: 1.342404\tBest loss: 1.340982\tAccuracy: 69.00%\n",
      "286\tValidation loss: 1.336864\tBest loss: 1.336864\tAccuracy: 69.00%\n",
      "287\tValidation loss: 1.339500\tBest loss: 1.336864\tAccuracy: 68.90%\n",
      "288\tValidation loss: 1.342420\tBest loss: 1.336864\tAccuracy: 68.60%\n",
      "289\tValidation loss: 1.336480\tBest loss: 1.336480\tAccuracy: 69.20%\n",
      "290\tValidation loss: 1.338161\tBest loss: 1.336480\tAccuracy: 69.00%\n",
      "291\tValidation loss: 1.340576\tBest loss: 1.336480\tAccuracy: 69.40%\n",
      "292\tValidation loss: 1.337554\tBest loss: 1.336480\tAccuracy: 68.50%\n",
      "293\tValidation loss: 1.337335\tBest loss: 1.336480\tAccuracy: 69.00%\n",
      "294\tValidation loss: 1.338992\tBest loss: 1.336480\tAccuracy: 69.20%\n",
      "295\tValidation loss: 1.335912\tBest loss: 1.335912\tAccuracy: 69.00%\n",
      "296\tValidation loss: 1.334368\tBest loss: 1.334368\tAccuracy: 69.40%\n",
      "297\tValidation loss: 1.338195\tBest loss: 1.334368\tAccuracy: 69.00%\n",
      "298\tValidation loss: 1.332873\tBest loss: 1.332873\tAccuracy: 69.70%\n",
      "299\tValidation loss: 1.332702\tBest loss: 1.332702\tAccuracy: 69.60%\n",
      "300\tValidation loss: 1.334154\tBest loss: 1.332702\tAccuracy: 68.80%\n",
      "301\tValidation loss: 1.332610\tBest loss: 1.332610\tAccuracy: 69.10%\n",
      "302\tValidation loss: 1.331596\tBest loss: 1.331596\tAccuracy: 69.20%\n",
      "303\tValidation loss: 1.334644\tBest loss: 1.331596\tAccuracy: 69.20%\n",
      "304\tValidation loss: 1.335538\tBest loss: 1.331596\tAccuracy: 69.00%\n",
      "305\tValidation loss: 1.335010\tBest loss: 1.331596\tAccuracy: 69.60%\n",
      "306\tValidation loss: 1.330292\tBest loss: 1.330292\tAccuracy: 69.10%\n",
      "307\tValidation loss: 1.326411\tBest loss: 1.326411\tAccuracy: 69.20%\n",
      "308\tValidation loss: 1.327043\tBest loss: 1.326411\tAccuracy: 69.50%\n",
      "309\tValidation loss: 1.327096\tBest loss: 1.326411\tAccuracy: 69.40%\n",
      "310\tValidation loss: 1.329227\tBest loss: 1.326411\tAccuracy: 69.20%\n",
      "311\tValidation loss: 1.326435\tBest loss: 1.326411\tAccuracy: 69.00%\n",
      "312\tValidation loss: 1.330024\tBest loss: 1.326411\tAccuracy: 69.40%\n",
      "313\tValidation loss: 1.327709\tBest loss: 1.326411\tAccuracy: 69.00%\n",
      "314\tValidation loss: 1.324784\tBest loss: 1.324784\tAccuracy: 69.30%\n",
      "315\tValidation loss: 1.328508\tBest loss: 1.324784\tAccuracy: 69.60%\n",
      "316\tValidation loss: 1.324855\tBest loss: 1.324784\tAccuracy: 69.20%\n",
      "317\tValidation loss: 1.324472\tBest loss: 1.324472\tAccuracy: 69.70%\n",
      "318\tValidation loss: 1.324310\tBest loss: 1.324310\tAccuracy: 69.10%\n",
      "319\tValidation loss: 1.328941\tBest loss: 1.324310\tAccuracy: 68.90%\n",
      "320\tValidation loss: 1.322515\tBest loss: 1.322515\tAccuracy: 69.30%\n",
      "321\tValidation loss: 1.321995\tBest loss: 1.321995\tAccuracy: 69.10%\n",
      "322\tValidation loss: 1.329809\tBest loss: 1.321995\tAccuracy: 68.90%\n",
      "323\tValidation loss: 1.328063\tBest loss: 1.321995\tAccuracy: 69.70%\n",
      "324\tValidation loss: 1.321895\tBest loss: 1.321895\tAccuracy: 68.90%\n",
      "325\tValidation loss: 1.323242\tBest loss: 1.321895\tAccuracy: 69.20%\n",
      "326\tValidation loss: 1.321693\tBest loss: 1.321693\tAccuracy: 69.50%\n",
      "327\tValidation loss: 1.319311\tBest loss: 1.319311\tAccuracy: 69.70%\n",
      "328\tValidation loss: 1.318401\tBest loss: 1.318401\tAccuracy: 69.30%\n",
      "329\tValidation loss: 1.323405\tBest loss: 1.318401\tAccuracy: 69.40%\n",
      "330\tValidation loss: 1.318399\tBest loss: 1.318399\tAccuracy: 69.50%\n",
      "331\tValidation loss: 1.320944\tBest loss: 1.318399\tAccuracy: 69.00%\n",
      "332\tValidation loss: 1.320276\tBest loss: 1.318399\tAccuracy: 69.20%\n",
      "333\tValidation loss: 1.320421\tBest loss: 1.318399\tAccuracy: 69.20%\n",
      "334\tValidation loss: 1.315830\tBest loss: 1.315830\tAccuracy: 69.90%\n",
      "335\tValidation loss: 1.315946\tBest loss: 1.315830\tAccuracy: 69.30%\n",
      "336\tValidation loss: 1.321121\tBest loss: 1.315830\tAccuracy: 69.90%\n",
      "337\tValidation loss: 1.319721\tBest loss: 1.315830\tAccuracy: 69.70%\n",
      "338\tValidation loss: 1.317826\tBest loss: 1.315830\tAccuracy: 69.10%\n",
      "339\tValidation loss: 1.314374\tBest loss: 1.314374\tAccuracy: 69.70%\n",
      "340\tValidation loss: 1.318775\tBest loss: 1.314374\tAccuracy: 69.40%\n",
      "341\tValidation loss: 1.318112\tBest loss: 1.314374\tAccuracy: 69.30%\n",
      "342\tValidation loss: 1.317285\tBest loss: 1.314374\tAccuracy: 69.90%\n",
      "343\tValidation loss: 1.318620\tBest loss: 1.314374\tAccuracy: 69.40%\n",
      "344\tValidation loss: 1.317469\tBest loss: 1.314374\tAccuracy: 69.30%\n",
      "345\tValidation loss: 1.316230\tBest loss: 1.314374\tAccuracy: 69.30%\n",
      "346\tValidation loss: 1.311842\tBest loss: 1.311842\tAccuracy: 69.70%\n",
      "347\tValidation loss: 1.313783\tBest loss: 1.311842\tAccuracy: 69.50%\n",
      "348\tValidation loss: 1.312862\tBest loss: 1.311842\tAccuracy: 69.30%\n",
      "349\tValidation loss: 1.314729\tBest loss: 1.311842\tAccuracy: 69.60%\n",
      "350\tValidation loss: 1.317859\tBest loss: 1.311842\tAccuracy: 69.40%\n",
      "351\tValidation loss: 1.310990\tBest loss: 1.310990\tAccuracy: 69.70%\n",
      "352\tValidation loss: 1.313638\tBest loss: 1.310990\tAccuracy: 69.70%\n",
      "353\tValidation loss: 1.311788\tBest loss: 1.310990\tAccuracy: 69.90%\n",
      "354\tValidation loss: 1.310052\tBest loss: 1.310052\tAccuracy: 69.70%\n",
      "355\tValidation loss: 1.310309\tBest loss: 1.310052\tAccuracy: 69.40%\n",
      "356\tValidation loss: 1.311159\tBest loss: 1.310052\tAccuracy: 69.70%\n",
      "357\tValidation loss: 1.307494\tBest loss: 1.307494\tAccuracy: 69.50%\n",
      "358\tValidation loss: 1.310437\tBest loss: 1.307494\tAccuracy: 69.90%\n",
      "359\tValidation loss: 1.311530\tBest loss: 1.307494\tAccuracy: 69.60%\n",
      "360\tValidation loss: 1.308825\tBest loss: 1.307494\tAccuracy: 69.50%\n",
      "361\tValidation loss: 1.310441\tBest loss: 1.307494\tAccuracy: 69.50%\n",
      "362\tValidation loss: 1.308902\tBest loss: 1.307494\tAccuracy: 70.10%\n",
      "363\tValidation loss: 1.305571\tBest loss: 1.305571\tAccuracy: 69.80%\n",
      "364\tValidation loss: 1.306923\tBest loss: 1.305571\tAccuracy: 69.80%\n",
      "365\tValidation loss: 1.307010\tBest loss: 1.305571\tAccuracy: 69.50%\n",
      "366\tValidation loss: 1.304103\tBest loss: 1.304103\tAccuracy: 70.00%\n",
      "367\tValidation loss: 1.307035\tBest loss: 1.304103\tAccuracy: 69.80%\n",
      "368\tValidation loss: 1.308299\tBest loss: 1.304103\tAccuracy: 69.60%\n",
      "369\tValidation loss: 1.307243\tBest loss: 1.304103\tAccuracy: 69.60%\n",
      "370\tValidation loss: 1.310259\tBest loss: 1.304103\tAccuracy: 70.00%\n",
      "371\tValidation loss: 1.307485\tBest loss: 1.304103\tAccuracy: 69.30%\n",
      "372\tValidation loss: 1.306734\tBest loss: 1.304103\tAccuracy: 70.10%\n",
      "373\tValidation loss: 1.303184\tBest loss: 1.303184\tAccuracy: 69.80%\n",
      "374\tValidation loss: 1.305413\tBest loss: 1.303184\tAccuracy: 69.60%\n",
      "375\tValidation loss: 1.304685\tBest loss: 1.303184\tAccuracy: 70.00%\n",
      "376\tValidation loss: 1.301568\tBest loss: 1.301568\tAccuracy: 69.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\tValidation loss: 1.302075\tBest loss: 1.301568\tAccuracy: 69.70%\n",
      "378\tValidation loss: 1.303197\tBest loss: 1.301568\tAccuracy: 70.20%\n",
      "379\tValidation loss: 1.296969\tBest loss: 1.296969\tAccuracy: 70.20%\n",
      "380\tValidation loss: 1.303793\tBest loss: 1.296969\tAccuracy: 69.40%\n",
      "381\tValidation loss: 1.301197\tBest loss: 1.296969\tAccuracy: 69.80%\n",
      "382\tValidation loss: 1.298679\tBest loss: 1.296969\tAccuracy: 69.70%\n",
      "383\tValidation loss: 1.297644\tBest loss: 1.296969\tAccuracy: 69.80%\n",
      "384\tValidation loss: 1.301285\tBest loss: 1.296969\tAccuracy: 69.70%\n",
      "385\tValidation loss: 1.297657\tBest loss: 1.296969\tAccuracy: 70.10%\n",
      "386\tValidation loss: 1.299053\tBest loss: 1.296969\tAccuracy: 70.00%\n",
      "387\tValidation loss: 1.298811\tBest loss: 1.296969\tAccuracy: 69.70%\n",
      "388\tValidation loss: 1.298360\tBest loss: 1.296969\tAccuracy: 69.80%\n",
      "389\tValidation loss: 1.298752\tBest loss: 1.296969\tAccuracy: 69.60%\n",
      "390\tValidation loss: 1.295479\tBest loss: 1.295479\tAccuracy: 70.00%\n",
      "391\tValidation loss: 1.296367\tBest loss: 1.295479\tAccuracy: 70.00%\n",
      "392\tValidation loss: 1.296377\tBest loss: 1.295479\tAccuracy: 69.90%\n",
      "393\tValidation loss: 1.298760\tBest loss: 1.295479\tAccuracy: 69.90%\n",
      "394\tValidation loss: 1.295373\tBest loss: 1.295373\tAccuracy: 70.10%\n",
      "395\tValidation loss: 1.297863\tBest loss: 1.295373\tAccuracy: 70.20%\n",
      "396\tValidation loss: 1.295629\tBest loss: 1.295373\tAccuracy: 69.60%\n",
      "397\tValidation loss: 1.301104\tBest loss: 1.295373\tAccuracy: 70.20%\n",
      "398\tValidation loss: 1.296451\tBest loss: 1.295373\tAccuracy: 69.80%\n",
      "399\tValidation loss: 1.295886\tBest loss: 1.295373\tAccuracy: 69.90%\n",
      "400\tValidation loss: 1.294038\tBest loss: 1.294038\tAccuracy: 70.00%\n",
      "401\tValidation loss: 1.295514\tBest loss: 1.294038\tAccuracy: 70.00%\n",
      "402\tValidation loss: 1.293313\tBest loss: 1.293313\tAccuracy: 69.90%\n",
      "403\tValidation loss: 1.293940\tBest loss: 1.293313\tAccuracy: 70.10%\n",
      "404\tValidation loss: 1.295224\tBest loss: 1.293313\tAccuracy: 69.80%\n",
      "405\tValidation loss: 1.294912\tBest loss: 1.293313\tAccuracy: 69.90%\n",
      "406\tValidation loss: 1.292827\tBest loss: 1.292827\tAccuracy: 69.90%\n",
      "407\tValidation loss: 1.292380\tBest loss: 1.292380\tAccuracy: 70.10%\n",
      "408\tValidation loss: 1.293807\tBest loss: 1.292380\tAccuracy: 70.10%\n",
      "409\tValidation loss: 1.290755\tBest loss: 1.290755\tAccuracy: 70.20%\n",
      "410\tValidation loss: 1.287951\tBest loss: 1.287951\tAccuracy: 70.10%\n",
      "411\tValidation loss: 1.288368\tBest loss: 1.287951\tAccuracy: 70.30%\n",
      "412\tValidation loss: 1.288490\tBest loss: 1.287951\tAccuracy: 70.20%\n",
      "413\tValidation loss: 1.292613\tBest loss: 1.287951\tAccuracy: 70.10%\n",
      "414\tValidation loss: 1.295232\tBest loss: 1.287951\tAccuracy: 69.80%\n",
      "415\tValidation loss: 1.289116\tBest loss: 1.287951\tAccuracy: 69.90%\n",
      "416\tValidation loss: 1.289523\tBest loss: 1.287951\tAccuracy: 69.80%\n",
      "417\tValidation loss: 1.287719\tBest loss: 1.287719\tAccuracy: 70.30%\n",
      "418\tValidation loss: 1.290446\tBest loss: 1.287719\tAccuracy: 70.30%\n",
      "419\tValidation loss: 1.288923\tBest loss: 1.287719\tAccuracy: 70.20%\n",
      "420\tValidation loss: 1.290508\tBest loss: 1.287719\tAccuracy: 70.10%\n",
      "421\tValidation loss: 1.288867\tBest loss: 1.287719\tAccuracy: 70.40%\n",
      "422\tValidation loss: 1.289536\tBest loss: 1.287719\tAccuracy: 70.30%\n",
      "423\tValidation loss: 1.293524\tBest loss: 1.287719\tAccuracy: 70.70%\n",
      "424\tValidation loss: 1.285978\tBest loss: 1.285978\tAccuracy: 70.30%\n",
      "425\tValidation loss: 1.288774\tBest loss: 1.285978\tAccuracy: 70.20%\n",
      "426\tValidation loss: 1.293836\tBest loss: 1.285978\tAccuracy: 70.20%\n",
      "427\tValidation loss: 1.287871\tBest loss: 1.285978\tAccuracy: 70.10%\n",
      "428\tValidation loss: 1.290304\tBest loss: 1.285978\tAccuracy: 69.80%\n",
      "429\tValidation loss: 1.286727\tBest loss: 1.285978\tAccuracy: 70.10%\n",
      "430\tValidation loss: 1.284677\tBest loss: 1.284677\tAccuracy: 70.00%\n",
      "431\tValidation loss: 1.284537\tBest loss: 1.284537\tAccuracy: 70.10%\n",
      "432\tValidation loss: 1.285178\tBest loss: 1.284537\tAccuracy: 70.40%\n",
      "433\tValidation loss: 1.290400\tBest loss: 1.284537\tAccuracy: 70.00%\n",
      "434\tValidation loss: 1.284376\tBest loss: 1.284376\tAccuracy: 70.20%\n",
      "435\tValidation loss: 1.287368\tBest loss: 1.284376\tAccuracy: 70.20%\n",
      "436\tValidation loss: 1.283212\tBest loss: 1.283212\tAccuracy: 70.20%\n",
      "437\tValidation loss: 1.287155\tBest loss: 1.283212\tAccuracy: 70.40%\n",
      "438\tValidation loss: 1.286006\tBest loss: 1.283212\tAccuracy: 70.10%\n",
      "439\tValidation loss: 1.281022\tBest loss: 1.281022\tAccuracy: 70.40%\n",
      "440\tValidation loss: 1.285101\tBest loss: 1.281022\tAccuracy: 70.40%\n",
      "441\tValidation loss: 1.283943\tBest loss: 1.281022\tAccuracy: 70.50%\n",
      "442\tValidation loss: 1.287084\tBest loss: 1.281022\tAccuracy: 70.70%\n",
      "443\tValidation loss: 1.286109\tBest loss: 1.281022\tAccuracy: 70.20%\n",
      "444\tValidation loss: 1.279282\tBest loss: 1.279282\tAccuracy: 70.20%\n",
      "445\tValidation loss: 1.282446\tBest loss: 1.279282\tAccuracy: 70.50%\n",
      "446\tValidation loss: 1.282845\tBest loss: 1.279282\tAccuracy: 70.70%\n",
      "447\tValidation loss: 1.284320\tBest loss: 1.279282\tAccuracy: 70.60%\n",
      "448\tValidation loss: 1.283619\tBest loss: 1.279282\tAccuracy: 70.40%\n",
      "449\tValidation loss: 1.282354\tBest loss: 1.279282\tAccuracy: 69.90%\n",
      "450\tValidation loss: 1.281819\tBest loss: 1.279282\tAccuracy: 70.50%\n",
      "451\tValidation loss: 1.281790\tBest loss: 1.279282\tAccuracy: 70.10%\n",
      "452\tValidation loss: 1.283113\tBest loss: 1.279282\tAccuracy: 70.70%\n",
      "453\tValidation loss: 1.280490\tBest loss: 1.279282\tAccuracy: 70.20%\n",
      "454\tValidation loss: 1.282642\tBest loss: 1.279282\tAccuracy: 70.50%\n",
      "455\tValidation loss: 1.278500\tBest loss: 1.278500\tAccuracy: 70.20%\n",
      "456\tValidation loss: 1.279323\tBest loss: 1.278500\tAccuracy: 70.60%\n",
      "457\tValidation loss: 1.280114\tBest loss: 1.278500\tAccuracy: 70.50%\n",
      "458\tValidation loss: 1.280536\tBest loss: 1.278500\tAccuracy: 70.60%\n",
      "459\tValidation loss: 1.279416\tBest loss: 1.278500\tAccuracy: 70.10%\n",
      "460\tValidation loss: 1.279030\tBest loss: 1.278500\tAccuracy: 70.40%\n",
      "461\tValidation loss: 1.280151\tBest loss: 1.278500\tAccuracy: 70.70%\n",
      "462\tValidation loss: 1.280498\tBest loss: 1.278500\tAccuracy: 70.50%\n",
      "463\tValidation loss: 1.281348\tBest loss: 1.278500\tAccuracy: 70.40%\n",
      "464\tValidation loss: 1.278564\tBest loss: 1.278500\tAccuracy: 70.40%\n",
      "465\tValidation loss: 1.273510\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "466\tValidation loss: 1.281226\tBest loss: 1.273510\tAccuracy: 70.40%\n",
      "467\tValidation loss: 1.278641\tBest loss: 1.273510\tAccuracy: 70.60%\n",
      "468\tValidation loss: 1.280328\tBest loss: 1.273510\tAccuracy: 70.30%\n",
      "469\tValidation loss: 1.277709\tBest loss: 1.273510\tAccuracy: 70.60%\n",
      "470\tValidation loss: 1.275786\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "471\tValidation loss: 1.277280\tBest loss: 1.273510\tAccuracy: 70.60%\n",
      "472\tValidation loss: 1.279280\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "473\tValidation loss: 1.278723\tBest loss: 1.273510\tAccuracy: 70.40%\n",
      "474\tValidation loss: 1.280326\tBest loss: 1.273510\tAccuracy: 70.40%\n",
      "475\tValidation loss: 1.274507\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "476\tValidation loss: 1.277501\tBest loss: 1.273510\tAccuracy: 70.40%\n",
      "477\tValidation loss: 1.277270\tBest loss: 1.273510\tAccuracy: 70.40%\n",
      "478\tValidation loss: 1.275820\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "479\tValidation loss: 1.276249\tBest loss: 1.273510\tAccuracy: 70.60%\n",
      "480\tValidation loss: 1.274499\tBest loss: 1.273510\tAccuracy: 70.50%\n",
      "481\tValidation loss: 1.271747\tBest loss: 1.271747\tAccuracy: 70.60%\n",
      "482\tValidation loss: 1.277734\tBest loss: 1.271747\tAccuracy: 70.60%\n",
      "483\tValidation loss: 1.275076\tBest loss: 1.271747\tAccuracy: 70.70%\n",
      "484\tValidation loss: 1.276271\tBest loss: 1.271747\tAccuracy: 70.60%\n",
      "485\tValidation loss: 1.271800\tBest loss: 1.271747\tAccuracy: 70.40%\n",
      "486\tValidation loss: 1.271442\tBest loss: 1.271442\tAccuracy: 70.90%\n",
      "487\tValidation loss: 1.274603\tBest loss: 1.271442\tAccuracy: 70.40%\n",
      "488\tValidation loss: 1.271649\tBest loss: 1.271442\tAccuracy: 70.20%\n",
      "489\tValidation loss: 1.273300\tBest loss: 1.271442\tAccuracy: 70.40%\n",
      "490\tValidation loss: 1.272980\tBest loss: 1.271442\tAccuracy: 70.20%\n",
      "491\tValidation loss: 1.272227\tBest loss: 1.271442\tAccuracy: 70.70%\n",
      "492\tValidation loss: 1.272239\tBest loss: 1.271442\tAccuracy: 70.60%\n",
      "493\tValidation loss: 1.272623\tBest loss: 1.271442\tAccuracy: 70.50%\n",
      "494\tValidation loss: 1.272210\tBest loss: 1.271442\tAccuracy: 70.60%\n",
      "495\tValidation loss: 1.269517\tBest loss: 1.269517\tAccuracy: 71.00%\n",
      "496\tValidation loss: 1.271536\tBest loss: 1.269517\tAccuracy: 70.80%\n",
      "497\tValidation loss: 1.271061\tBest loss: 1.269517\tAccuracy: 70.60%\n",
      "498\tValidation loss: 1.269642\tBest loss: 1.269517\tAccuracy: 70.80%\n",
      "499\tValidation loss: 1.272560\tBest loss: 1.269517\tAccuracy: 70.40%\n",
      "500\tValidation loss: 1.269248\tBest loss: 1.269248\tAccuracy: 70.40%\n",
      "501\tValidation loss: 1.269915\tBest loss: 1.269248\tAccuracy: 70.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\tValidation loss: 1.270835\tBest loss: 1.269248\tAccuracy: 70.80%\n",
      "503\tValidation loss: 1.272577\tBest loss: 1.269248\tAccuracy: 70.70%\n",
      "504\tValidation loss: 1.268742\tBest loss: 1.268742\tAccuracy: 70.60%\n",
      "505\tValidation loss: 1.270843\tBest loss: 1.268742\tAccuracy: 70.60%\n",
      "506\tValidation loss: 1.266163\tBest loss: 1.266163\tAccuracy: 71.00%\n",
      "507\tValidation loss: 1.269647\tBest loss: 1.266163\tAccuracy: 70.70%\n",
      "508\tValidation loss: 1.272019\tBest loss: 1.266163\tAccuracy: 70.40%\n",
      "509\tValidation loss: 1.267890\tBest loss: 1.266163\tAccuracy: 70.70%\n",
      "510\tValidation loss: 1.266975\tBest loss: 1.266163\tAccuracy: 70.50%\n",
      "511\tValidation loss: 1.267525\tBest loss: 1.266163\tAccuracy: 70.50%\n",
      "512\tValidation loss: 1.265887\tBest loss: 1.265887\tAccuracy: 70.80%\n",
      "513\tValidation loss: 1.267276\tBest loss: 1.265887\tAccuracy: 70.80%\n",
      "514\tValidation loss: 1.265554\tBest loss: 1.265554\tAccuracy: 70.60%\n",
      "515\tValidation loss: 1.266852\tBest loss: 1.265554\tAccuracy: 70.60%\n",
      "516\tValidation loss: 1.268843\tBest loss: 1.265554\tAccuracy: 70.40%\n",
      "517\tValidation loss: 1.268188\tBest loss: 1.265554\tAccuracy: 70.70%\n",
      "518\tValidation loss: 1.265605\tBest loss: 1.265554\tAccuracy: 70.60%\n",
      "519\tValidation loss: 1.266821\tBest loss: 1.265554\tAccuracy: 70.70%\n",
      "520\tValidation loss: 1.267073\tBest loss: 1.265554\tAccuracy: 70.50%\n",
      "521\tValidation loss: 1.267580\tBest loss: 1.265554\tAccuracy: 70.60%\n",
      "522\tValidation loss: 1.264768\tBest loss: 1.264768\tAccuracy: 70.60%\n",
      "523\tValidation loss: 1.264263\tBest loss: 1.264263\tAccuracy: 70.70%\n",
      "524\tValidation loss: 1.265470\tBest loss: 1.264263\tAccuracy: 70.80%\n",
      "525\tValidation loss: 1.264316\tBest loss: 1.264263\tAccuracy: 70.80%\n",
      "526\tValidation loss: 1.266377\tBest loss: 1.264263\tAccuracy: 71.00%\n",
      "527\tValidation loss: 1.268542\tBest loss: 1.264263\tAccuracy: 70.60%\n",
      "528\tValidation loss: 1.265129\tBest loss: 1.264263\tAccuracy: 70.90%\n",
      "529\tValidation loss: 1.260864\tBest loss: 1.260864\tAccuracy: 70.80%\n",
      "530\tValidation loss: 1.265053\tBest loss: 1.260864\tAccuracy: 70.80%\n",
      "531\tValidation loss: 1.263704\tBest loss: 1.260864\tAccuracy: 70.30%\n",
      "532\tValidation loss: 1.264986\tBest loss: 1.260864\tAccuracy: 70.80%\n",
      "533\tValidation loss: 1.264290\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "534\tValidation loss: 1.263041\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "535\tValidation loss: 1.263951\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "536\tValidation loss: 1.266664\tBest loss: 1.260864\tAccuracy: 70.70%\n",
      "537\tValidation loss: 1.263317\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "538\tValidation loss: 1.265325\tBest loss: 1.260864\tAccuracy: 70.70%\n",
      "539\tValidation loss: 1.262295\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "540\tValidation loss: 1.261599\tBest loss: 1.260864\tAccuracy: 70.80%\n",
      "541\tValidation loss: 1.265801\tBest loss: 1.260864\tAccuracy: 70.80%\n",
      "542\tValidation loss: 1.261656\tBest loss: 1.260864\tAccuracy: 70.70%\n",
      "543\tValidation loss: 1.261714\tBest loss: 1.260864\tAccuracy: 70.60%\n",
      "544\tValidation loss: 1.262149\tBest loss: 1.260864\tAccuracy: 70.90%\n",
      "545\tValidation loss: 1.259927\tBest loss: 1.259927\tAccuracy: 70.60%\n",
      "546\tValidation loss: 1.262067\tBest loss: 1.259927\tAccuracy: 70.90%\n",
      "547\tValidation loss: 1.259101\tBest loss: 1.259101\tAccuracy: 71.00%\n",
      "548\tValidation loss: 1.262767\tBest loss: 1.259101\tAccuracy: 70.90%\n",
      "549\tValidation loss: 1.259592\tBest loss: 1.259101\tAccuracy: 71.20%\n",
      "550\tValidation loss: 1.266506\tBest loss: 1.259101\tAccuracy: 70.60%\n",
      "551\tValidation loss: 1.260709\tBest loss: 1.259101\tAccuracy: 70.90%\n",
      "552\tValidation loss: 1.258965\tBest loss: 1.258965\tAccuracy: 70.80%\n",
      "553\tValidation loss: 1.260255\tBest loss: 1.258965\tAccuracy: 70.60%\n",
      "554\tValidation loss: 1.260243\tBest loss: 1.258965\tAccuracy: 70.80%\n",
      "555\tValidation loss: 1.259860\tBest loss: 1.258965\tAccuracy: 71.00%\n",
      "556\tValidation loss: 1.255869\tBest loss: 1.255869\tAccuracy: 70.80%\n",
      "557\tValidation loss: 1.256668\tBest loss: 1.255869\tAccuracy: 71.10%\n",
      "558\tValidation loss: 1.261850\tBest loss: 1.255869\tAccuracy: 70.80%\n",
      "559\tValidation loss: 1.257781\tBest loss: 1.255869\tAccuracy: 70.70%\n",
      "560\tValidation loss: 1.258961\tBest loss: 1.255869\tAccuracy: 70.90%\n",
      "561\tValidation loss: 1.259616\tBest loss: 1.255869\tAccuracy: 71.00%\n",
      "562\tValidation loss: 1.257403\tBest loss: 1.255869\tAccuracy: 70.60%\n",
      "563\tValidation loss: 1.257463\tBest loss: 1.255869\tAccuracy: 70.60%\n",
      "564\tValidation loss: 1.259513\tBest loss: 1.255869\tAccuracy: 70.70%\n",
      "565\tValidation loss: 1.260412\tBest loss: 1.255869\tAccuracy: 70.70%\n",
      "566\tValidation loss: 1.257655\tBest loss: 1.255869\tAccuracy: 71.00%\n",
      "567\tValidation loss: 1.256240\tBest loss: 1.255869\tAccuracy: 71.10%\n",
      "568\tValidation loss: 1.259091\tBest loss: 1.255869\tAccuracy: 70.70%\n",
      "569\tValidation loss: 1.257848\tBest loss: 1.255869\tAccuracy: 71.00%\n",
      "570\tValidation loss: 1.258207\tBest loss: 1.255869\tAccuracy: 70.60%\n",
      "571\tValidation loss: 1.257342\tBest loss: 1.255869\tAccuracy: 70.70%\n",
      "572\tValidation loss: 1.255991\tBest loss: 1.255869\tAccuracy: 70.80%\n",
      "573\tValidation loss: 1.253207\tBest loss: 1.253207\tAccuracy: 70.80%\n",
      "574\tValidation loss: 1.255755\tBest loss: 1.253207\tAccuracy: 70.80%\n",
      "575\tValidation loss: 1.256905\tBest loss: 1.253207\tAccuracy: 70.80%\n",
      "576\tValidation loss: 1.256514\tBest loss: 1.253207\tAccuracy: 70.90%\n",
      "577\tValidation loss: 1.259634\tBest loss: 1.253207\tAccuracy: 70.50%\n",
      "578\tValidation loss: 1.256910\tBest loss: 1.253207\tAccuracy: 70.90%\n",
      "579\tValidation loss: 1.259572\tBest loss: 1.253207\tAccuracy: 70.80%\n",
      "580\tValidation loss: 1.257927\tBest loss: 1.253207\tAccuracy: 70.70%\n",
      "581\tValidation loss: 1.252831\tBest loss: 1.252831\tAccuracy: 70.90%\n",
      "582\tValidation loss: 1.254317\tBest loss: 1.252831\tAccuracy: 70.80%\n",
      "583\tValidation loss: 1.256877\tBest loss: 1.252831\tAccuracy: 70.60%\n",
      "584\tValidation loss: 1.251887\tBest loss: 1.251887\tAccuracy: 71.20%\n",
      "585\tValidation loss: 1.255565\tBest loss: 1.251887\tAccuracy: 70.90%\n",
      "586\tValidation loss: 1.252909\tBest loss: 1.251887\tAccuracy: 71.00%\n",
      "587\tValidation loss: 1.252655\tBest loss: 1.251887\tAccuracy: 71.10%\n",
      "588\tValidation loss: 1.256972\tBest loss: 1.251887\tAccuracy: 70.70%\n",
      "589\tValidation loss: 1.252998\tBest loss: 1.251887\tAccuracy: 70.70%\n",
      "590\tValidation loss: 1.254421\tBest loss: 1.251887\tAccuracy: 71.00%\n",
      "591\tValidation loss: 1.251596\tBest loss: 1.251596\tAccuracy: 70.80%\n",
      "592\tValidation loss: 1.250010\tBest loss: 1.250010\tAccuracy: 71.00%\n",
      "593\tValidation loss: 1.250983\tBest loss: 1.250010\tAccuracy: 70.70%\n",
      "594\tValidation loss: 1.252882\tBest loss: 1.250010\tAccuracy: 71.10%\n",
      "595\tValidation loss: 1.254513\tBest loss: 1.250010\tAccuracy: 70.60%\n",
      "596\tValidation loss: 1.252639\tBest loss: 1.250010\tAccuracy: 70.50%\n",
      "597\tValidation loss: 1.251885\tBest loss: 1.250010\tAccuracy: 70.90%\n",
      "598\tValidation loss: 1.253054\tBest loss: 1.250010\tAccuracy: 71.10%\n",
      "599\tValidation loss: 1.252360\tBest loss: 1.250010\tAccuracy: 70.50%\n",
      "600\tValidation loss: 1.252411\tBest loss: 1.250010\tAccuracy: 70.90%\n",
      "601\tValidation loss: 1.251884\tBest loss: 1.250010\tAccuracy: 70.90%\n",
      "602\tValidation loss: 1.252946\tBest loss: 1.250010\tAccuracy: 70.60%\n",
      "603\tValidation loss: 1.251372\tBest loss: 1.250010\tAccuracy: 71.10%\n",
      "604\tValidation loss: 1.252064\tBest loss: 1.250010\tAccuracy: 71.10%\n",
      "605\tValidation loss: 1.255206\tBest loss: 1.250010\tAccuracy: 70.80%\n",
      "606\tValidation loss: 1.253827\tBest loss: 1.250010\tAccuracy: 71.10%\n",
      "607\tValidation loss: 1.252049\tBest loss: 1.250010\tAccuracy: 70.70%\n",
      "608\tValidation loss: 1.249942\tBest loss: 1.249942\tAccuracy: 71.40%\n",
      "609\tValidation loss: 1.252082\tBest loss: 1.249942\tAccuracy: 71.20%\n",
      "610\tValidation loss: 1.252680\tBest loss: 1.249942\tAccuracy: 71.20%\n",
      "611\tValidation loss: 1.252150\tBest loss: 1.249942\tAccuracy: 70.70%\n",
      "612\tValidation loss: 1.250293\tBest loss: 1.249942\tAccuracy: 70.90%\n",
      "613\tValidation loss: 1.250671\tBest loss: 1.249942\tAccuracy: 71.20%\n",
      "614\tValidation loss: 1.251922\tBest loss: 1.249942\tAccuracy: 71.00%\n",
      "615\tValidation loss: 1.251548\tBest loss: 1.249942\tAccuracy: 70.80%\n",
      "616\tValidation loss: 1.251706\tBest loss: 1.249942\tAccuracy: 70.90%\n",
      "617\tValidation loss: 1.251747\tBest loss: 1.249942\tAccuracy: 70.80%\n",
      "618\tValidation loss: 1.252036\tBest loss: 1.249942\tAccuracy: 71.00%\n",
      "619\tValidation loss: 1.251277\tBest loss: 1.249942\tAccuracy: 71.00%\n",
      "620\tValidation loss: 1.249297\tBest loss: 1.249297\tAccuracy: 70.70%\n",
      "621\tValidation loss: 1.246932\tBest loss: 1.246932\tAccuracy: 71.10%\n",
      "622\tValidation loss: 1.248265\tBest loss: 1.246932\tAccuracy: 71.40%\n",
      "623\tValidation loss: 1.246635\tBest loss: 1.246635\tAccuracy: 71.10%\n",
      "624\tValidation loss: 1.249285\tBest loss: 1.246635\tAccuracy: 70.80%\n",
      "625\tValidation loss: 1.248098\tBest loss: 1.246635\tAccuracy: 71.40%\n",
      "626\tValidation loss: 1.252063\tBest loss: 1.246635\tAccuracy: 70.90%\n",
      "627\tValidation loss: 1.247444\tBest loss: 1.246635\tAccuracy: 71.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\tValidation loss: 1.249457\tBest loss: 1.246635\tAccuracy: 70.80%\n",
      "629\tValidation loss: 1.247264\tBest loss: 1.246635\tAccuracy: 71.00%\n",
      "630\tValidation loss: 1.249088\tBest loss: 1.246635\tAccuracy: 71.20%\n",
      "631\tValidation loss: 1.244890\tBest loss: 1.244890\tAccuracy: 71.30%\n",
      "632\tValidation loss: 1.244803\tBest loss: 1.244803\tAccuracy: 71.20%\n",
      "633\tValidation loss: 1.245141\tBest loss: 1.244803\tAccuracy: 71.10%\n",
      "634\tValidation loss: 1.245955\tBest loss: 1.244803\tAccuracy: 70.90%\n",
      "635\tValidation loss: 1.245609\tBest loss: 1.244803\tAccuracy: 71.10%\n",
      "636\tValidation loss: 1.246276\tBest loss: 1.244803\tAccuracy: 71.10%\n",
      "637\tValidation loss: 1.248200\tBest loss: 1.244803\tAccuracy: 71.20%\n",
      "638\tValidation loss: 1.246411\tBest loss: 1.244803\tAccuracy: 70.90%\n",
      "639\tValidation loss: 1.247686\tBest loss: 1.244803\tAccuracy: 70.40%\n",
      "640\tValidation loss: 1.247029\tBest loss: 1.244803\tAccuracy: 70.40%\n",
      "641\tValidation loss: 1.244490\tBest loss: 1.244490\tAccuracy: 71.10%\n",
      "642\tValidation loss: 1.247562\tBest loss: 1.244490\tAccuracy: 70.90%\n",
      "643\tValidation loss: 1.245941\tBest loss: 1.244490\tAccuracy: 70.90%\n",
      "644\tValidation loss: 1.248532\tBest loss: 1.244490\tAccuracy: 71.00%\n",
      "645\tValidation loss: 1.245126\tBest loss: 1.244490\tAccuracy: 70.90%\n",
      "646\tValidation loss: 1.245637\tBest loss: 1.244490\tAccuracy: 70.90%\n",
      "647\tValidation loss: 1.242095\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "648\tValidation loss: 1.244857\tBest loss: 1.242095\tAccuracy: 71.00%\n",
      "649\tValidation loss: 1.243321\tBest loss: 1.242095\tAccuracy: 71.70%\n",
      "650\tValidation loss: 1.246848\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "651\tValidation loss: 1.245277\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "652\tValidation loss: 1.243851\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "653\tValidation loss: 1.245622\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "654\tValidation loss: 1.244164\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "655\tValidation loss: 1.244952\tBest loss: 1.242095\tAccuracy: 71.00%\n",
      "656\tValidation loss: 1.243211\tBest loss: 1.242095\tAccuracy: 71.20%\n",
      "657\tValidation loss: 1.245465\tBest loss: 1.242095\tAccuracy: 70.80%\n",
      "658\tValidation loss: 1.242169\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "659\tValidation loss: 1.242306\tBest loss: 1.242095\tAccuracy: 71.10%\n",
      "660\tValidation loss: 1.242997\tBest loss: 1.242095\tAccuracy: 70.90%\n",
      "661\tValidation loss: 1.241970\tBest loss: 1.241970\tAccuracy: 71.10%\n",
      "662\tValidation loss: 1.242440\tBest loss: 1.241970\tAccuracy: 71.10%\n",
      "663\tValidation loss: 1.242858\tBest loss: 1.241970\tAccuracy: 70.60%\n",
      "664\tValidation loss: 1.242786\tBest loss: 1.241970\tAccuracy: 70.90%\n",
      "665\tValidation loss: 1.242271\tBest loss: 1.241970\tAccuracy: 71.10%\n",
      "666\tValidation loss: 1.244735\tBest loss: 1.241970\tAccuracy: 70.90%\n",
      "667\tValidation loss: 1.242633\tBest loss: 1.241970\tAccuracy: 71.10%\n",
      "668\tValidation loss: 1.245986\tBest loss: 1.241970\tAccuracy: 71.10%\n",
      "669\tValidation loss: 1.247678\tBest loss: 1.241970\tAccuracy: 70.90%\n",
      "670\tValidation loss: 1.242616\tBest loss: 1.241970\tAccuracy: 71.00%\n",
      "671\tValidation loss: 1.244085\tBest loss: 1.241970\tAccuracy: 70.90%\n",
      "672\tValidation loss: 1.245308\tBest loss: 1.241970\tAccuracy: 70.80%\n",
      "673\tValidation loss: 1.245400\tBest loss: 1.241970\tAccuracy: 71.00%\n",
      "674\tValidation loss: 1.240828\tBest loss: 1.240828\tAccuracy: 71.30%\n",
      "675\tValidation loss: 1.244851\tBest loss: 1.240828\tAccuracy: 70.70%\n",
      "676\tValidation loss: 1.244027\tBest loss: 1.240828\tAccuracy: 71.00%\n",
      "677\tValidation loss: 1.241958\tBest loss: 1.240828\tAccuracy: 71.00%\n",
      "678\tValidation loss: 1.245681\tBest loss: 1.240828\tAccuracy: 71.20%\n",
      "679\tValidation loss: 1.242174\tBest loss: 1.240828\tAccuracy: 71.30%\n",
      "680\tValidation loss: 1.245680\tBest loss: 1.240828\tAccuracy: 70.80%\n",
      "681\tValidation loss: 1.245468\tBest loss: 1.240828\tAccuracy: 71.00%\n",
      "682\tValidation loss: 1.241217\tBest loss: 1.240828\tAccuracy: 71.30%\n",
      "683\tValidation loss: 1.242485\tBest loss: 1.240828\tAccuracy: 71.20%\n",
      "684\tValidation loss: 1.241711\tBest loss: 1.240828\tAccuracy: 71.30%\n",
      "685\tValidation loss: 1.243583\tBest loss: 1.240828\tAccuracy: 71.00%\n",
      "686\tValidation loss: 1.240294\tBest loss: 1.240294\tAccuracy: 71.30%\n",
      "687\tValidation loss: 1.242877\tBest loss: 1.240294\tAccuracy: 71.10%\n",
      "688\tValidation loss: 1.243410\tBest loss: 1.240294\tAccuracy: 70.80%\n",
      "689\tValidation loss: 1.239427\tBest loss: 1.239427\tAccuracy: 71.20%\n",
      "690\tValidation loss: 1.238236\tBest loss: 1.238236\tAccuracy: 71.50%\n",
      "691\tValidation loss: 1.238328\tBest loss: 1.238236\tAccuracy: 71.40%\n",
      "692\tValidation loss: 1.242323\tBest loss: 1.238236\tAccuracy: 70.90%\n",
      "693\tValidation loss: 1.239949\tBest loss: 1.238236\tAccuracy: 71.30%\n",
      "694\tValidation loss: 1.239078\tBest loss: 1.238236\tAccuracy: 71.30%\n",
      "695\tValidation loss: 1.242576\tBest loss: 1.238236\tAccuracy: 71.10%\n",
      "696\tValidation loss: 1.243308\tBest loss: 1.238236\tAccuracy: 70.80%\n",
      "697\tValidation loss: 1.243541\tBest loss: 1.238236\tAccuracy: 70.70%\n",
      "698\tValidation loss: 1.244102\tBest loss: 1.238236\tAccuracy: 70.90%\n",
      "699\tValidation loss: 1.240787\tBest loss: 1.238236\tAccuracy: 70.80%\n",
      "700\tValidation loss: 1.238044\tBest loss: 1.238044\tAccuracy: 71.30%\n",
      "701\tValidation loss: 1.240941\tBest loss: 1.238044\tAccuracy: 71.30%\n",
      "702\tValidation loss: 1.237360\tBest loss: 1.237360\tAccuracy: 71.40%\n",
      "703\tValidation loss: 1.239280\tBest loss: 1.237360\tAccuracy: 71.60%\n",
      "704\tValidation loss: 1.240346\tBest loss: 1.237360\tAccuracy: 71.10%\n",
      "705\tValidation loss: 1.239558\tBest loss: 1.237360\tAccuracy: 71.60%\n",
      "706\tValidation loss: 1.239012\tBest loss: 1.237360\tAccuracy: 71.20%\n",
      "707\tValidation loss: 1.239188\tBest loss: 1.237360\tAccuracy: 71.10%\n",
      "708\tValidation loss: 1.239931\tBest loss: 1.237360\tAccuracy: 71.30%\n",
      "709\tValidation loss: 1.240090\tBest loss: 1.237360\tAccuracy: 70.80%\n",
      "710\tValidation loss: 1.234990\tBest loss: 1.234990\tAccuracy: 71.70%\n",
      "711\tValidation loss: 1.238115\tBest loss: 1.234990\tAccuracy: 71.10%\n",
      "712\tValidation loss: 1.237736\tBest loss: 1.234990\tAccuracy: 71.70%\n",
      "713\tValidation loss: 1.240358\tBest loss: 1.234990\tAccuracy: 71.40%\n",
      "714\tValidation loss: 1.238487\tBest loss: 1.234990\tAccuracy: 71.30%\n",
      "715\tValidation loss: 1.236089\tBest loss: 1.234990\tAccuracy: 71.60%\n",
      "716\tValidation loss: 1.235773\tBest loss: 1.234990\tAccuracy: 71.50%\n",
      "717\tValidation loss: 1.239250\tBest loss: 1.234990\tAccuracy: 71.30%\n",
      "718\tValidation loss: 1.238528\tBest loss: 1.234990\tAccuracy: 71.40%\n",
      "719\tValidation loss: 1.240856\tBest loss: 1.234990\tAccuracy: 71.30%\n",
      "720\tValidation loss: 1.241783\tBest loss: 1.234990\tAccuracy: 71.30%\n",
      "721\tValidation loss: 1.241467\tBest loss: 1.234990\tAccuracy: 71.20%\n",
      "722\tValidation loss: 1.239244\tBest loss: 1.234990\tAccuracy: 70.80%\n",
      "723\tValidation loss: 1.239488\tBest loss: 1.234990\tAccuracy: 70.80%\n",
      "724\tValidation loss: 1.240972\tBest loss: 1.234990\tAccuracy: 71.50%\n",
      "725\tValidation loss: 1.237786\tBest loss: 1.234990\tAccuracy: 70.90%\n",
      "726\tValidation loss: 1.239605\tBest loss: 1.234990\tAccuracy: 70.90%\n",
      "727\tValidation loss: 1.239073\tBest loss: 1.234990\tAccuracy: 71.20%\n",
      "728\tValidation loss: 1.238281\tBest loss: 1.234990\tAccuracy: 70.90%\n",
      "729\tValidation loss: 1.238701\tBest loss: 1.234990\tAccuracy: 71.00%\n",
      "730\tValidation loss: 1.234143\tBest loss: 1.234143\tAccuracy: 71.50%\n",
      "731\tValidation loss: 1.238156\tBest loss: 1.234143\tAccuracy: 71.00%\n",
      "732\tValidation loss: 1.236863\tBest loss: 1.234143\tAccuracy: 71.00%\n",
      "733\tValidation loss: 1.238165\tBest loss: 1.234143\tAccuracy: 71.40%\n",
      "734\tValidation loss: 1.236596\tBest loss: 1.234143\tAccuracy: 71.40%\n",
      "735\tValidation loss: 1.234877\tBest loss: 1.234143\tAccuracy: 71.10%\n",
      "736\tValidation loss: 1.237735\tBest loss: 1.234143\tAccuracy: 71.00%\n",
      "737\tValidation loss: 1.236820\tBest loss: 1.234143\tAccuracy: 71.30%\n",
      "738\tValidation loss: 1.237977\tBest loss: 1.234143\tAccuracy: 71.30%\n",
      "739\tValidation loss: 1.237008\tBest loss: 1.234143\tAccuracy: 71.30%\n",
      "740\tValidation loss: 1.235185\tBest loss: 1.234143\tAccuracy: 71.20%\n",
      "741\tValidation loss: 1.235404\tBest loss: 1.234143\tAccuracy: 71.40%\n",
      "742\tValidation loss: 1.234831\tBest loss: 1.234143\tAccuracy: 71.30%\n",
      "743\tValidation loss: 1.234454\tBest loss: 1.234143\tAccuracy: 71.40%\n",
      "744\tValidation loss: 1.233288\tBest loss: 1.233288\tAccuracy: 71.30%\n",
      "745\tValidation loss: 1.236888\tBest loss: 1.233288\tAccuracy: 71.00%\n",
      "746\tValidation loss: 1.237948\tBest loss: 1.233288\tAccuracy: 71.10%\n",
      "747\tValidation loss: 1.239439\tBest loss: 1.233288\tAccuracy: 71.20%\n",
      "748\tValidation loss: 1.237199\tBest loss: 1.233288\tAccuracy: 71.20%\n",
      "749\tValidation loss: 1.236806\tBest loss: 1.233288\tAccuracy: 71.20%\n",
      "750\tValidation loss: 1.234628\tBest loss: 1.233288\tAccuracy: 71.50%\n",
      "751\tValidation loss: 1.234556\tBest loss: 1.233288\tAccuracy: 71.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752\tValidation loss: 1.234789\tBest loss: 1.233288\tAccuracy: 71.50%\n",
      "753\tValidation loss: 1.233531\tBest loss: 1.233288\tAccuracy: 71.50%\n",
      "754\tValidation loss: 1.235765\tBest loss: 1.233288\tAccuracy: 71.40%\n",
      "755\tValidation loss: 1.233902\tBest loss: 1.233288\tAccuracy: 71.10%\n",
      "756\tValidation loss: 1.234380\tBest loss: 1.233288\tAccuracy: 71.40%\n",
      "757\tValidation loss: 1.235528\tBest loss: 1.233288\tAccuracy: 71.40%\n",
      "758\tValidation loss: 1.236481\tBest loss: 1.233288\tAccuracy: 71.00%\n",
      "759\tValidation loss: 1.232621\tBest loss: 1.232621\tAccuracy: 71.50%\n",
      "760\tValidation loss: 1.233323\tBest loss: 1.232621\tAccuracy: 71.80%\n",
      "761\tValidation loss: 1.235453\tBest loss: 1.232621\tAccuracy: 71.10%\n",
      "762\tValidation loss: 1.233073\tBest loss: 1.232621\tAccuracy: 71.20%\n",
      "763\tValidation loss: 1.229589\tBest loss: 1.229589\tAccuracy: 71.50%\n",
      "764\tValidation loss: 1.233769\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "765\tValidation loss: 1.231943\tBest loss: 1.229589\tAccuracy: 71.50%\n",
      "766\tValidation loss: 1.234491\tBest loss: 1.229589\tAccuracy: 71.40%\n",
      "767\tValidation loss: 1.237838\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "768\tValidation loss: 1.235612\tBest loss: 1.229589\tAccuracy: 71.20%\n",
      "769\tValidation loss: 1.233892\tBest loss: 1.229589\tAccuracy: 71.50%\n",
      "770\tValidation loss: 1.234739\tBest loss: 1.229589\tAccuracy: 71.30%\n",
      "771\tValidation loss: 1.232016\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "772\tValidation loss: 1.235084\tBest loss: 1.229589\tAccuracy: 71.30%\n",
      "773\tValidation loss: 1.234878\tBest loss: 1.229589\tAccuracy: 71.40%\n",
      "774\tValidation loss: 1.230272\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "775\tValidation loss: 1.231088\tBest loss: 1.229589\tAccuracy: 71.30%\n",
      "776\tValidation loss: 1.232394\tBest loss: 1.229589\tAccuracy: 71.50%\n",
      "777\tValidation loss: 1.235122\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "778\tValidation loss: 1.233040\tBest loss: 1.229589\tAccuracy: 71.10%\n",
      "779\tValidation loss: 1.232000\tBest loss: 1.229589\tAccuracy: 71.60%\n",
      "780\tValidation loss: 1.230756\tBest loss: 1.229589\tAccuracy: 71.40%\n",
      "781\tValidation loss: 1.231191\tBest loss: 1.229589\tAccuracy: 71.20%\n",
      "782\tValidation loss: 1.231705\tBest loss: 1.229589\tAccuracy: 71.50%\n",
      "783\tValidation loss: 1.232227\tBest loss: 1.229589\tAccuracy: 71.20%\n",
      "784\tValidation loss: 1.232609\tBest loss: 1.229589\tAccuracy: 71.30%\n",
      "Early stopping!\n",
      "[[  1.72400021e-14   1.55707269e-08   8.07102970e-06 ...,   1.09031640e-14\n",
      "    1.70372841e-12   9.17705582e-12]\n",
      " [  2.22214519e-21   3.67545000e-17   1.76579648e-16 ...,   1.14783748e-25\n",
      "    2.10256826e-29   7.93726451e-18]\n",
      " [  9.66331008e-12   4.17673229e-10   1.76717896e-12 ...,   1.00020747e-11\n",
      "    6.74318144e-24   1.20070969e-14]\n",
      " ..., \n",
      " [  1.96425219e-07   1.29987720e-05   6.65360349e-05 ...,   1.15103018e-03\n",
      "    1.74664296e-04   8.72204266e-03]\n",
      " [  6.59290933e-09   3.38943913e-08   3.13711568e-09 ...,   8.61580047e-05\n",
      "    1.33332624e-05   8.71665892e-04]\n",
      " [  1.53146048e-37   1.41368658e-22   2.73608829e-21 ...,   1.26514103e-11\n",
      "    2.00274101e-15   8.45291993e-07]]\n",
      "[26 43 43 ..., 36 27 27]\n",
      "[[  7.75266228e-17   4.47738652e-11   8.05469302e-11 ...,   9.36232239e-22\n",
      "    4.89037216e-21   3.99721726e-14]\n",
      " [  6.11418150e-02   3.88315991e-02   4.66611050e-02 ...,   1.26651078e-02\n",
      "    8.94915033e-03   8.59137531e-03]\n",
      " [  2.63730106e-27   1.45218380e-35   6.67235045e-10 ...,   9.23497757e-28\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  7.02990999e-11   3.71741787e-12   9.75029571e-11 ...,   6.03981176e-24\n",
      "    2.54968500e-15   4.95761039e-17]\n",
      " [  3.45953777e-02   2.75142472e-02   2.57099960e-02 ...,   1.36198029e-02\n",
      "    1.73237678e-02   1.33059695e-02]\n",
      " [  1.45729649e-27   3.89785356e-23   2.81456389e-23 ...,   5.09062348e-10\n",
      "    6.70536201e-06   9.99636054e-01]]\n",
      "[20  0 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=  34.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 8.119034\tBest loss: 8.119034\tAccuracy: 14.10%\n",
      "1\tValidation loss: 5.456878\tBest loss: 5.456878\tAccuracy: 21.20%\n",
      "2\tValidation loss: 4.172535\tBest loss: 4.172535\tAccuracy: 26.00%\n",
      "3\tValidation loss: 3.659809\tBest loss: 3.659809\tAccuracy: 30.80%\n",
      "4\tValidation loss: 3.372550\tBest loss: 3.372550\tAccuracy: 30.90%\n",
      "5\tValidation loss: 3.144982\tBest loss: 3.144982\tAccuracy: 34.00%\n",
      "6\tValidation loss: 2.932431\tBest loss: 2.932431\tAccuracy: 39.60%\n",
      "7\tValidation loss: 2.754297\tBest loss: 2.754297\tAccuracy: 40.10%\n",
      "8\tValidation loss: 2.609089\tBest loss: 2.609089\tAccuracy: 42.80%\n",
      "9\tValidation loss: 2.533744\tBest loss: 2.533744\tAccuracy: 44.00%\n",
      "10\tValidation loss: 2.494565\tBest loss: 2.494565\tAccuracy: 44.60%\n",
      "11\tValidation loss: 2.407070\tBest loss: 2.407070\tAccuracy: 47.00%\n",
      "12\tValidation loss: 2.345230\tBest loss: 2.345230\tAccuracy: 47.30%\n",
      "13\tValidation loss: 2.298877\tBest loss: 2.298877\tAccuracy: 48.40%\n",
      "14\tValidation loss: 2.263232\tBest loss: 2.263232\tAccuracy: 47.70%\n",
      "15\tValidation loss: 2.222765\tBest loss: 2.222765\tAccuracy: 50.70%\n",
      "16\tValidation loss: 2.181669\tBest loss: 2.181669\tAccuracy: 50.60%\n",
      "17\tValidation loss: 2.163331\tBest loss: 2.163331\tAccuracy: 50.80%\n",
      "18\tValidation loss: 2.090970\tBest loss: 2.090970\tAccuracy: 52.90%\n",
      "19\tValidation loss: 2.057140\tBest loss: 2.057140\tAccuracy: 53.00%\n",
      "20\tValidation loss: 2.040010\tBest loss: 2.040010\tAccuracy: 54.80%\n",
      "21\tValidation loss: 2.009413\tBest loss: 2.009413\tAccuracy: 54.20%\n",
      "22\tValidation loss: 2.002949\tBest loss: 2.002949\tAccuracy: 54.40%\n",
      "23\tValidation loss: 1.961208\tBest loss: 1.961208\tAccuracy: 56.50%\n",
      "24\tValidation loss: 1.945644\tBest loss: 1.945644\tAccuracy: 56.80%\n",
      "25\tValidation loss: 1.964131\tBest loss: 1.945644\tAccuracy: 56.00%\n",
      "26\tValidation loss: 1.914124\tBest loss: 1.914124\tAccuracy: 57.60%\n",
      "27\tValidation loss: 1.906200\tBest loss: 1.906200\tAccuracy: 58.00%\n",
      "28\tValidation loss: 1.901388\tBest loss: 1.901388\tAccuracy: 56.80%\n",
      "29\tValidation loss: 1.848472\tBest loss: 1.848472\tAccuracy: 58.20%\n",
      "30\tValidation loss: 1.850507\tBest loss: 1.848472\tAccuracy: 59.30%\n",
      "31\tValidation loss: 1.832060\tBest loss: 1.832060\tAccuracy: 59.00%\n",
      "32\tValidation loss: 1.810804\tBest loss: 1.810804\tAccuracy: 60.00%\n",
      "33\tValidation loss: 1.811822\tBest loss: 1.810804\tAccuracy: 60.10%\n",
      "34\tValidation loss: 1.804419\tBest loss: 1.804419\tAccuracy: 59.80%\n",
      "35\tValidation loss: 1.794988\tBest loss: 1.794988\tAccuracy: 59.20%\n",
      "36\tValidation loss: 1.771989\tBest loss: 1.771989\tAccuracy: 60.30%\n",
      "37\tValidation loss: 1.748071\tBest loss: 1.748071\tAccuracy: 61.20%\n",
      "38\tValidation loss: 1.748369\tBest loss: 1.748071\tAccuracy: 60.00%\n",
      "39\tValidation loss: 1.732990\tBest loss: 1.732990\tAccuracy: 61.30%\n",
      "40\tValidation loss: 1.739983\tBest loss: 1.732990\tAccuracy: 61.20%\n",
      "41\tValidation loss: 1.719682\tBest loss: 1.719682\tAccuracy: 62.60%\n",
      "42\tValidation loss: 1.716152\tBest loss: 1.716152\tAccuracy: 61.50%\n",
      "43\tValidation loss: 1.695709\tBest loss: 1.695709\tAccuracy: 61.40%\n",
      "44\tValidation loss: 1.727645\tBest loss: 1.695709\tAccuracy: 61.90%\n",
      "45\tValidation loss: 1.698590\tBest loss: 1.695709\tAccuracy: 62.40%\n",
      "46\tValidation loss: 1.684755\tBest loss: 1.684755\tAccuracy: 62.00%\n",
      "47\tValidation loss: 1.682770\tBest loss: 1.682770\tAccuracy: 62.40%\n",
      "48\tValidation loss: 1.674271\tBest loss: 1.674271\tAccuracy: 62.20%\n",
      "49\tValidation loss: 1.667571\tBest loss: 1.667571\tAccuracy: 62.80%\n",
      "50\tValidation loss: 1.652860\tBest loss: 1.652860\tAccuracy: 63.00%\n",
      "51\tValidation loss: 1.658567\tBest loss: 1.652860\tAccuracy: 62.90%\n",
      "52\tValidation loss: 1.658671\tBest loss: 1.652860\tAccuracy: 62.70%\n",
      "53\tValidation loss: 1.639927\tBest loss: 1.639927\tAccuracy: 63.00%\n",
      "54\tValidation loss: 1.640919\tBest loss: 1.639927\tAccuracy: 62.80%\n",
      "55\tValidation loss: 1.632713\tBest loss: 1.632713\tAccuracy: 63.60%\n",
      "56\tValidation loss: 1.622683\tBest loss: 1.622683\tAccuracy: 63.40%\n",
      "57\tValidation loss: 1.634362\tBest loss: 1.622683\tAccuracy: 62.70%\n",
      "58\tValidation loss: 1.606475\tBest loss: 1.606475\tAccuracy: 63.70%\n",
      "59\tValidation loss: 1.608572\tBest loss: 1.606475\tAccuracy: 64.10%\n",
      "60\tValidation loss: 1.603944\tBest loss: 1.603944\tAccuracy: 63.30%\n",
      "61\tValidation loss: 1.599912\tBest loss: 1.599912\tAccuracy: 63.60%\n",
      "62\tValidation loss: 1.594946\tBest loss: 1.594946\tAccuracy: 64.90%\n",
      "63\tValidation loss: 1.603929\tBest loss: 1.594946\tAccuracy: 63.80%\n",
      "64\tValidation loss: 1.571422\tBest loss: 1.571422\tAccuracy: 64.60%\n",
      "65\tValidation loss: 1.574688\tBest loss: 1.571422\tAccuracy: 64.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\tValidation loss: 1.570135\tBest loss: 1.570135\tAccuracy: 64.80%\n",
      "67\tValidation loss: 1.583495\tBest loss: 1.570135\tAccuracy: 63.90%\n",
      "68\tValidation loss: 1.570312\tBest loss: 1.570135\tAccuracy: 64.90%\n",
      "69\tValidation loss: 1.563522\tBest loss: 1.563522\tAccuracy: 64.60%\n",
      "70\tValidation loss: 1.570058\tBest loss: 1.563522\tAccuracy: 64.10%\n",
      "71\tValidation loss: 1.542521\tBest loss: 1.542521\tAccuracy: 64.50%\n",
      "72\tValidation loss: 1.564404\tBest loss: 1.542521\tAccuracy: 64.70%\n",
      "73\tValidation loss: 1.555769\tBest loss: 1.542521\tAccuracy: 64.60%\n",
      "74\tValidation loss: 1.552648\tBest loss: 1.542521\tAccuracy: 64.20%\n",
      "75\tValidation loss: 1.548076\tBest loss: 1.542521\tAccuracy: 65.10%\n",
      "76\tValidation loss: 1.540018\tBest loss: 1.540018\tAccuracy: 65.10%\n",
      "77\tValidation loss: 1.539823\tBest loss: 1.539823\tAccuracy: 65.30%\n",
      "78\tValidation loss: 1.531674\tBest loss: 1.531674\tAccuracy: 65.10%\n",
      "79\tValidation loss: 1.542094\tBest loss: 1.531674\tAccuracy: 65.20%\n",
      "80\tValidation loss: 1.525819\tBest loss: 1.525819\tAccuracy: 65.20%\n",
      "81\tValidation loss: 1.522529\tBest loss: 1.522529\tAccuracy: 65.50%\n",
      "82\tValidation loss: 1.522100\tBest loss: 1.522100\tAccuracy: 65.30%\n",
      "83\tValidation loss: 1.528754\tBest loss: 1.522100\tAccuracy: 65.00%\n",
      "84\tValidation loss: 1.502898\tBest loss: 1.502898\tAccuracy: 66.10%\n",
      "85\tValidation loss: 1.522317\tBest loss: 1.502898\tAccuracy: 64.70%\n",
      "86\tValidation loss: 1.505512\tBest loss: 1.502898\tAccuracy: 65.40%\n",
      "87\tValidation loss: 1.509141\tBest loss: 1.502898\tAccuracy: 65.40%\n",
      "88\tValidation loss: 1.499469\tBest loss: 1.499469\tAccuracy: 65.40%\n",
      "89\tValidation loss: 1.502600\tBest loss: 1.499469\tAccuracy: 65.30%\n",
      "90\tValidation loss: 1.503452\tBest loss: 1.499469\tAccuracy: 65.30%\n",
      "91\tValidation loss: 1.500433\tBest loss: 1.499469\tAccuracy: 66.50%\n",
      "92\tValidation loss: 1.507159\tBest loss: 1.499469\tAccuracy: 65.70%\n",
      "93\tValidation loss: 1.499004\tBest loss: 1.499004\tAccuracy: 66.20%\n",
      "94\tValidation loss: 1.490366\tBest loss: 1.490366\tAccuracy: 65.40%\n",
      "95\tValidation loss: 1.487277\tBest loss: 1.487277\tAccuracy: 65.60%\n",
      "96\tValidation loss: 1.488397\tBest loss: 1.487277\tAccuracy: 66.00%\n",
      "97\tValidation loss: 1.480468\tBest loss: 1.480468\tAccuracy: 65.80%\n",
      "98\tValidation loss: 1.475153\tBest loss: 1.475153\tAccuracy: 66.30%\n",
      "99\tValidation loss: 1.477347\tBest loss: 1.475153\tAccuracy: 66.20%\n",
      "100\tValidation loss: 1.466444\tBest loss: 1.466444\tAccuracy: 66.00%\n",
      "101\tValidation loss: 1.467852\tBest loss: 1.466444\tAccuracy: 66.80%\n",
      "102\tValidation loss: 1.472493\tBest loss: 1.466444\tAccuracy: 65.90%\n",
      "103\tValidation loss: 1.463818\tBest loss: 1.463818\tAccuracy: 66.20%\n",
      "104\tValidation loss: 1.460925\tBest loss: 1.460925\tAccuracy: 66.90%\n",
      "105\tValidation loss: 1.460907\tBest loss: 1.460907\tAccuracy: 66.60%\n",
      "106\tValidation loss: 1.466652\tBest loss: 1.460907\tAccuracy: 66.40%\n",
      "107\tValidation loss: 1.456709\tBest loss: 1.456709\tAccuracy: 66.40%\n",
      "108\tValidation loss: 1.453719\tBest loss: 1.453719\tAccuracy: 66.50%\n",
      "109\tValidation loss: 1.469223\tBest loss: 1.453719\tAccuracy: 66.20%\n",
      "110\tValidation loss: 1.460926\tBest loss: 1.453719\tAccuracy: 66.40%\n",
      "111\tValidation loss: 1.461123\tBest loss: 1.453719\tAccuracy: 66.30%\n",
      "112\tValidation loss: 1.445359\tBest loss: 1.445359\tAccuracy: 67.10%\n",
      "113\tValidation loss: 1.455219\tBest loss: 1.445359\tAccuracy: 66.70%\n",
      "114\tValidation loss: 1.445724\tBest loss: 1.445359\tAccuracy: 67.10%\n",
      "115\tValidation loss: 1.454096\tBest loss: 1.445359\tAccuracy: 66.70%\n",
      "116\tValidation loss: 1.448546\tBest loss: 1.445359\tAccuracy: 66.40%\n",
      "117\tValidation loss: 1.440821\tBest loss: 1.440821\tAccuracy: 66.80%\n",
      "118\tValidation loss: 1.438392\tBest loss: 1.438392\tAccuracy: 67.30%\n",
      "119\tValidation loss: 1.449600\tBest loss: 1.438392\tAccuracy: 67.00%\n",
      "120\tValidation loss: 1.443537\tBest loss: 1.438392\tAccuracy: 66.40%\n",
      "121\tValidation loss: 1.431012\tBest loss: 1.431012\tAccuracy: 67.50%\n",
      "122\tValidation loss: 1.428689\tBest loss: 1.428689\tAccuracy: 67.00%\n",
      "123\tValidation loss: 1.436248\tBest loss: 1.428689\tAccuracy: 67.10%\n",
      "124\tValidation loss: 1.421039\tBest loss: 1.421039\tAccuracy: 67.60%\n",
      "125\tValidation loss: 1.427444\tBest loss: 1.421039\tAccuracy: 67.10%\n",
      "126\tValidation loss: 1.426679\tBest loss: 1.421039\tAccuracy: 67.40%\n",
      "127\tValidation loss: 1.427976\tBest loss: 1.421039\tAccuracy: 67.20%\n",
      "128\tValidation loss: 1.425927\tBest loss: 1.421039\tAccuracy: 67.10%\n",
      "129\tValidation loss: 1.425050\tBest loss: 1.421039\tAccuracy: 66.70%\n",
      "130\tValidation loss: 1.413453\tBest loss: 1.413453\tAccuracy: 67.50%\n",
      "131\tValidation loss: 1.421458\tBest loss: 1.413453\tAccuracy: 67.20%\n",
      "132\tValidation loss: 1.420896\tBest loss: 1.413453\tAccuracy: 67.40%\n",
      "133\tValidation loss: 1.411985\tBest loss: 1.411985\tAccuracy: 67.50%\n",
      "134\tValidation loss: 1.411494\tBest loss: 1.411494\tAccuracy: 67.70%\n",
      "135\tValidation loss: 1.415075\tBest loss: 1.411494\tAccuracy: 67.80%\n",
      "136\tValidation loss: 1.419005\tBest loss: 1.411494\tAccuracy: 67.10%\n",
      "137\tValidation loss: 1.415649\tBest loss: 1.411494\tAccuracy: 67.70%\n",
      "138\tValidation loss: 1.410836\tBest loss: 1.410836\tAccuracy: 67.50%\n",
      "139\tValidation loss: 1.412132\tBest loss: 1.410836\tAccuracy: 67.50%\n",
      "140\tValidation loss: 1.406954\tBest loss: 1.406954\tAccuracy: 68.00%\n",
      "141\tValidation loss: 1.405686\tBest loss: 1.405686\tAccuracy: 67.40%\n",
      "142\tValidation loss: 1.406894\tBest loss: 1.405686\tAccuracy: 67.40%\n",
      "143\tValidation loss: 1.403720\tBest loss: 1.403720\tAccuracy: 67.90%\n",
      "144\tValidation loss: 1.409092\tBest loss: 1.403720\tAccuracy: 67.50%\n",
      "145\tValidation loss: 1.400149\tBest loss: 1.400149\tAccuracy: 68.00%\n",
      "146\tValidation loss: 1.400235\tBest loss: 1.400149\tAccuracy: 67.60%\n",
      "147\tValidation loss: 1.406011\tBest loss: 1.400149\tAccuracy: 67.70%\n",
      "148\tValidation loss: 1.402412\tBest loss: 1.400149\tAccuracy: 67.80%\n",
      "149\tValidation loss: 1.393920\tBest loss: 1.393920\tAccuracy: 68.00%\n",
      "150\tValidation loss: 1.402043\tBest loss: 1.393920\tAccuracy: 67.20%\n",
      "151\tValidation loss: 1.391084\tBest loss: 1.391084\tAccuracy: 68.00%\n",
      "152\tValidation loss: 1.390352\tBest loss: 1.390352\tAccuracy: 68.00%\n",
      "153\tValidation loss: 1.385379\tBest loss: 1.385379\tAccuracy: 68.30%\n",
      "154\tValidation loss: 1.394657\tBest loss: 1.385379\tAccuracy: 67.50%\n",
      "155\tValidation loss: 1.395905\tBest loss: 1.385379\tAccuracy: 68.00%\n",
      "156\tValidation loss: 1.391612\tBest loss: 1.385379\tAccuracy: 68.00%\n",
      "157\tValidation loss: 1.390303\tBest loss: 1.385379\tAccuracy: 68.00%\n",
      "158\tValidation loss: 1.393033\tBest loss: 1.385379\tAccuracy: 67.30%\n",
      "159\tValidation loss: 1.385778\tBest loss: 1.385379\tAccuracy: 67.80%\n",
      "160\tValidation loss: 1.385441\tBest loss: 1.385379\tAccuracy: 67.90%\n",
      "161\tValidation loss: 1.385225\tBest loss: 1.385225\tAccuracy: 68.30%\n",
      "162\tValidation loss: 1.388296\tBest loss: 1.385225\tAccuracy: 67.90%\n",
      "163\tValidation loss: 1.375784\tBest loss: 1.375784\tAccuracy: 68.20%\n",
      "164\tValidation loss: 1.375950\tBest loss: 1.375784\tAccuracy: 68.30%\n",
      "165\tValidation loss: 1.374380\tBest loss: 1.374380\tAccuracy: 68.20%\n",
      "166\tValidation loss: 1.381415\tBest loss: 1.374380\tAccuracy: 67.30%\n",
      "167\tValidation loss: 1.379906\tBest loss: 1.374380\tAccuracy: 67.90%\n",
      "168\tValidation loss: 1.374425\tBest loss: 1.374380\tAccuracy: 67.60%\n",
      "169\tValidation loss: 1.371722\tBest loss: 1.371722\tAccuracy: 67.90%\n",
      "170\tValidation loss: 1.370542\tBest loss: 1.370542\tAccuracy: 68.10%\n",
      "171\tValidation loss: 1.373570\tBest loss: 1.370542\tAccuracy: 68.30%\n",
      "172\tValidation loss: 1.372981\tBest loss: 1.370542\tAccuracy: 68.60%\n",
      "173\tValidation loss: 1.372676\tBest loss: 1.370542\tAccuracy: 68.40%\n",
      "174\tValidation loss: 1.366941\tBest loss: 1.366941\tAccuracy: 68.50%\n",
      "175\tValidation loss: 1.372970\tBest loss: 1.366941\tAccuracy: 67.90%\n",
      "176\tValidation loss: 1.370067\tBest loss: 1.366941\tAccuracy: 68.60%\n",
      "177\tValidation loss: 1.371144\tBest loss: 1.366941\tAccuracy: 68.10%\n",
      "178\tValidation loss: 1.364818\tBest loss: 1.364818\tAccuracy: 68.30%\n",
      "179\tValidation loss: 1.364237\tBest loss: 1.364237\tAccuracy: 68.40%\n",
      "180\tValidation loss: 1.366924\tBest loss: 1.364237\tAccuracy: 67.70%\n",
      "181\tValidation loss: 1.360709\tBest loss: 1.360709\tAccuracy: 68.50%\n",
      "182\tValidation loss: 1.356165\tBest loss: 1.356165\tAccuracy: 68.60%\n",
      "183\tValidation loss: 1.363039\tBest loss: 1.356165\tAccuracy: 67.90%\n",
      "184\tValidation loss: 1.358659\tBest loss: 1.356165\tAccuracy: 68.70%\n",
      "185\tValidation loss: 1.358145\tBest loss: 1.356165\tAccuracy: 68.50%\n",
      "186\tValidation loss: 1.360688\tBest loss: 1.356165\tAccuracy: 68.70%\n",
      "187\tValidation loss: 1.360282\tBest loss: 1.356165\tAccuracy: 68.60%\n",
      "188\tValidation loss: 1.357603\tBest loss: 1.356165\tAccuracy: 68.70%\n",
      "189\tValidation loss: 1.361637\tBest loss: 1.356165\tAccuracy: 68.10%\n",
      "190\tValidation loss: 1.352055\tBest loss: 1.352055\tAccuracy: 68.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\tValidation loss: 1.348748\tBest loss: 1.348748\tAccuracy: 68.90%\n",
      "192\tValidation loss: 1.361678\tBest loss: 1.348748\tAccuracy: 67.90%\n",
      "193\tValidation loss: 1.356140\tBest loss: 1.348748\tAccuracy: 68.50%\n",
      "194\tValidation loss: 1.351004\tBest loss: 1.348748\tAccuracy: 68.30%\n",
      "195\tValidation loss: 1.354557\tBest loss: 1.348748\tAccuracy: 68.60%\n",
      "196\tValidation loss: 1.348612\tBest loss: 1.348612\tAccuracy: 67.90%\n",
      "197\tValidation loss: 1.345718\tBest loss: 1.345718\tAccuracy: 68.80%\n",
      "198\tValidation loss: 1.349636\tBest loss: 1.345718\tAccuracy: 68.10%\n",
      "199\tValidation loss: 1.350713\tBest loss: 1.345718\tAccuracy: 68.70%\n",
      "200\tValidation loss: 1.353895\tBest loss: 1.345718\tAccuracy: 67.80%\n",
      "201\tValidation loss: 1.352361\tBest loss: 1.345718\tAccuracy: 68.20%\n",
      "202\tValidation loss: 1.348619\tBest loss: 1.345718\tAccuracy: 68.30%\n",
      "203\tValidation loss: 1.351832\tBest loss: 1.345718\tAccuracy: 68.80%\n",
      "204\tValidation loss: 1.348122\tBest loss: 1.345718\tAccuracy: 68.40%\n",
      "205\tValidation loss: 1.349439\tBest loss: 1.345718\tAccuracy: 68.20%\n",
      "206\tValidation loss: 1.352112\tBest loss: 1.345718\tAccuracy: 68.30%\n",
      "207\tValidation loss: 1.342629\tBest loss: 1.342629\tAccuracy: 68.70%\n",
      "208\tValidation loss: 1.342367\tBest loss: 1.342367\tAccuracy: 68.30%\n",
      "209\tValidation loss: 1.345966\tBest loss: 1.342367\tAccuracy: 68.30%\n",
      "210\tValidation loss: 1.336137\tBest loss: 1.336137\tAccuracy: 68.70%\n",
      "211\tValidation loss: 1.340135\tBest loss: 1.336137\tAccuracy: 68.80%\n",
      "212\tValidation loss: 1.340004\tBest loss: 1.336137\tAccuracy: 68.80%\n",
      "213\tValidation loss: 1.333544\tBest loss: 1.333544\tAccuracy: 69.10%\n",
      "214\tValidation loss: 1.336593\tBest loss: 1.333544\tAccuracy: 68.80%\n",
      "215\tValidation loss: 1.339956\tBest loss: 1.333544\tAccuracy: 68.70%\n",
      "216\tValidation loss: 1.336991\tBest loss: 1.333544\tAccuracy: 69.10%\n",
      "217\tValidation loss: 1.335584\tBest loss: 1.333544\tAccuracy: 68.70%\n",
      "218\tValidation loss: 1.336347\tBest loss: 1.333544\tAccuracy: 68.80%\n",
      "219\tValidation loss: 1.339355\tBest loss: 1.333544\tAccuracy: 68.60%\n",
      "220\tValidation loss: 1.330553\tBest loss: 1.330553\tAccuracy: 69.30%\n",
      "221\tValidation loss: 1.341766\tBest loss: 1.330553\tAccuracy: 68.90%\n",
      "222\tValidation loss: 1.335777\tBest loss: 1.330553\tAccuracy: 69.00%\n",
      "223\tValidation loss: 1.331384\tBest loss: 1.330553\tAccuracy: 68.90%\n",
      "224\tValidation loss: 1.337498\tBest loss: 1.330553\tAccuracy: 68.50%\n",
      "225\tValidation loss: 1.340632\tBest loss: 1.330553\tAccuracy: 68.80%\n",
      "226\tValidation loss: 1.338030\tBest loss: 1.330553\tAccuracy: 68.80%\n",
      "227\tValidation loss: 1.332897\tBest loss: 1.330553\tAccuracy: 68.60%\n",
      "228\tValidation loss: 1.333404\tBest loss: 1.330553\tAccuracy: 68.40%\n",
      "229\tValidation loss: 1.333855\tBest loss: 1.330553\tAccuracy: 68.80%\n",
      "230\tValidation loss: 1.330463\tBest loss: 1.330463\tAccuracy: 68.90%\n",
      "231\tValidation loss: 1.331160\tBest loss: 1.330463\tAccuracy: 68.40%\n",
      "232\tValidation loss: 1.327956\tBest loss: 1.327956\tAccuracy: 68.70%\n",
      "233\tValidation loss: 1.331447\tBest loss: 1.327956\tAccuracy: 68.80%\n",
      "234\tValidation loss: 1.328722\tBest loss: 1.327956\tAccuracy: 68.90%\n",
      "235\tValidation loss: 1.333962\tBest loss: 1.327956\tAccuracy: 68.70%\n",
      "236\tValidation loss: 1.325057\tBest loss: 1.325057\tAccuracy: 68.90%\n",
      "237\tValidation loss: 1.327960\tBest loss: 1.325057\tAccuracy: 68.60%\n",
      "238\tValidation loss: 1.325786\tBest loss: 1.325057\tAccuracy: 69.00%\n",
      "239\tValidation loss: 1.324673\tBest loss: 1.324673\tAccuracy: 69.00%\n",
      "240\tValidation loss: 1.322628\tBest loss: 1.322628\tAccuracy: 68.80%\n",
      "241\tValidation loss: 1.321079\tBest loss: 1.321079\tAccuracy: 69.30%\n",
      "242\tValidation loss: 1.326249\tBest loss: 1.321079\tAccuracy: 68.50%\n",
      "243\tValidation loss: 1.323502\tBest loss: 1.321079\tAccuracy: 68.70%\n",
      "244\tValidation loss: 1.329318\tBest loss: 1.321079\tAccuracy: 68.50%\n",
      "245\tValidation loss: 1.319632\tBest loss: 1.319632\tAccuracy: 69.00%\n",
      "246\tValidation loss: 1.321493\tBest loss: 1.319632\tAccuracy: 69.50%\n",
      "247\tValidation loss: 1.318817\tBest loss: 1.318817\tAccuracy: 68.50%\n",
      "248\tValidation loss: 1.317046\tBest loss: 1.317046\tAccuracy: 69.60%\n",
      "249\tValidation loss: 1.317518\tBest loss: 1.317046\tAccuracy: 68.90%\n",
      "250\tValidation loss: 1.320235\tBest loss: 1.317046\tAccuracy: 68.90%\n",
      "251\tValidation loss: 1.317997\tBest loss: 1.317046\tAccuracy: 69.10%\n",
      "252\tValidation loss: 1.318142\tBest loss: 1.317046\tAccuracy: 69.30%\n",
      "253\tValidation loss: 1.317587\tBest loss: 1.317046\tAccuracy: 69.10%\n",
      "254\tValidation loss: 1.312339\tBest loss: 1.312339\tAccuracy: 68.90%\n",
      "255\tValidation loss: 1.318676\tBest loss: 1.312339\tAccuracy: 68.50%\n",
      "256\tValidation loss: 1.315776\tBest loss: 1.312339\tAccuracy: 69.00%\n",
      "257\tValidation loss: 1.314786\tBest loss: 1.312339\tAccuracy: 69.10%\n",
      "258\tValidation loss: 1.312634\tBest loss: 1.312339\tAccuracy: 69.10%\n",
      "259\tValidation loss: 1.315171\tBest loss: 1.312339\tAccuracy: 69.50%\n",
      "260\tValidation loss: 1.312991\tBest loss: 1.312339\tAccuracy: 69.40%\n",
      "261\tValidation loss: 1.319918\tBest loss: 1.312339\tAccuracy: 69.00%\n",
      "262\tValidation loss: 1.313861\tBest loss: 1.312339\tAccuracy: 69.40%\n",
      "263\tValidation loss: 1.320282\tBest loss: 1.312339\tAccuracy: 68.90%\n",
      "264\tValidation loss: 1.315006\tBest loss: 1.312339\tAccuracy: 68.80%\n",
      "265\tValidation loss: 1.316940\tBest loss: 1.312339\tAccuracy: 69.20%\n",
      "266\tValidation loss: 1.312099\tBest loss: 1.312099\tAccuracy: 69.50%\n",
      "267\tValidation loss: 1.314302\tBest loss: 1.312099\tAccuracy: 69.50%\n",
      "268\tValidation loss: 1.312066\tBest loss: 1.312066\tAccuracy: 68.90%\n",
      "269\tValidation loss: 1.310586\tBest loss: 1.310586\tAccuracy: 69.50%\n",
      "270\tValidation loss: 1.311355\tBest loss: 1.310586\tAccuracy: 69.40%\n",
      "271\tValidation loss: 1.307288\tBest loss: 1.307288\tAccuracy: 68.40%\n",
      "272\tValidation loss: 1.310592\tBest loss: 1.307288\tAccuracy: 69.10%\n",
      "273\tValidation loss: 1.313514\tBest loss: 1.307288\tAccuracy: 69.90%\n",
      "274\tValidation loss: 1.307398\tBest loss: 1.307288\tAccuracy: 69.30%\n",
      "275\tValidation loss: 1.306571\tBest loss: 1.306571\tAccuracy: 69.60%\n",
      "276\tValidation loss: 1.309927\tBest loss: 1.306571\tAccuracy: 69.50%\n",
      "277\tValidation loss: 1.311321\tBest loss: 1.306571\tAccuracy: 69.70%\n",
      "278\tValidation loss: 1.308825\tBest loss: 1.306571\tAccuracy: 69.00%\n",
      "279\tValidation loss: 1.306797\tBest loss: 1.306571\tAccuracy: 70.20%\n",
      "280\tValidation loss: 1.306365\tBest loss: 1.306365\tAccuracy: 69.70%\n",
      "281\tValidation loss: 1.304365\tBest loss: 1.304365\tAccuracy: 69.80%\n",
      "282\tValidation loss: 1.304497\tBest loss: 1.304365\tAccuracy: 69.80%\n",
      "283\tValidation loss: 1.307121\tBest loss: 1.304365\tAccuracy: 69.40%\n",
      "284\tValidation loss: 1.305745\tBest loss: 1.304365\tAccuracy: 70.20%\n",
      "285\tValidation loss: 1.304199\tBest loss: 1.304199\tAccuracy: 69.50%\n",
      "286\tValidation loss: 1.306437\tBest loss: 1.304199\tAccuracy: 69.40%\n",
      "287\tValidation loss: 1.304854\tBest loss: 1.304199\tAccuracy: 69.50%\n",
      "288\tValidation loss: 1.306138\tBest loss: 1.304199\tAccuracy: 69.40%\n",
      "289\tValidation loss: 1.302324\tBest loss: 1.302324\tAccuracy: 69.70%\n",
      "290\tValidation loss: 1.306271\tBest loss: 1.302324\tAccuracy: 69.50%\n",
      "291\tValidation loss: 1.303854\tBest loss: 1.302324\tAccuracy: 69.80%\n",
      "292\tValidation loss: 1.299245\tBest loss: 1.299245\tAccuracy: 69.70%\n",
      "293\tValidation loss: 1.301704\tBest loss: 1.299245\tAccuracy: 69.40%\n",
      "294\tValidation loss: 1.296622\tBest loss: 1.296622\tAccuracy: 69.70%\n",
      "295\tValidation loss: 1.299616\tBest loss: 1.296622\tAccuracy: 69.90%\n",
      "296\tValidation loss: 1.298136\tBest loss: 1.296622\tAccuracy: 70.30%\n",
      "297\tValidation loss: 1.301576\tBest loss: 1.296622\tAccuracy: 69.80%\n",
      "298\tValidation loss: 1.296462\tBest loss: 1.296462\tAccuracy: 69.50%\n",
      "299\tValidation loss: 1.298568\tBest loss: 1.296462\tAccuracy: 70.00%\n",
      "300\tValidation loss: 1.294696\tBest loss: 1.294696\tAccuracy: 70.50%\n",
      "301\tValidation loss: 1.297156\tBest loss: 1.294696\tAccuracy: 69.50%\n",
      "302\tValidation loss: 1.296428\tBest loss: 1.294696\tAccuracy: 69.60%\n",
      "303\tValidation loss: 1.300015\tBest loss: 1.294696\tAccuracy: 70.50%\n",
      "304\tValidation loss: 1.295832\tBest loss: 1.294696\tAccuracy: 69.50%\n",
      "305\tValidation loss: 1.297722\tBest loss: 1.294696\tAccuracy: 69.50%\n",
      "306\tValidation loss: 1.296234\tBest loss: 1.294696\tAccuracy: 69.80%\n",
      "307\tValidation loss: 1.296412\tBest loss: 1.294696\tAccuracy: 69.50%\n",
      "308\tValidation loss: 1.293713\tBest loss: 1.293713\tAccuracy: 69.40%\n",
      "309\tValidation loss: 1.298646\tBest loss: 1.293713\tAccuracy: 70.10%\n",
      "310\tValidation loss: 1.293951\tBest loss: 1.293713\tAccuracy: 69.60%\n",
      "311\tValidation loss: 1.295635\tBest loss: 1.293713\tAccuracy: 70.20%\n",
      "312\tValidation loss: 1.293996\tBest loss: 1.293713\tAccuracy: 69.60%\n",
      "313\tValidation loss: 1.288980\tBest loss: 1.288980\tAccuracy: 69.60%\n",
      "314\tValidation loss: 1.293797\tBest loss: 1.288980\tAccuracy: 69.40%\n",
      "315\tValidation loss: 1.296173\tBest loss: 1.288980\tAccuracy: 69.70%\n",
      "316\tValidation loss: 1.296816\tBest loss: 1.288980\tAccuracy: 69.60%\n",
      "317\tValidation loss: 1.295653\tBest loss: 1.288980\tAccuracy: 69.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\tValidation loss: 1.294400\tBest loss: 1.288980\tAccuracy: 70.50%\n",
      "319\tValidation loss: 1.296368\tBest loss: 1.288980\tAccuracy: 70.10%\n",
      "320\tValidation loss: 1.293877\tBest loss: 1.288980\tAccuracy: 70.30%\n",
      "321\tValidation loss: 1.293540\tBest loss: 1.288980\tAccuracy: 69.60%\n",
      "322\tValidation loss: 1.294835\tBest loss: 1.288980\tAccuracy: 70.40%\n",
      "323\tValidation loss: 1.293375\tBest loss: 1.288980\tAccuracy: 70.00%\n",
      "324\tValidation loss: 1.287610\tBest loss: 1.287610\tAccuracy: 70.20%\n",
      "325\tValidation loss: 1.291939\tBest loss: 1.287610\tAccuracy: 70.30%\n",
      "326\tValidation loss: 1.289889\tBest loss: 1.287610\tAccuracy: 69.80%\n",
      "327\tValidation loss: 1.290930\tBest loss: 1.287610\tAccuracy: 70.30%\n",
      "328\tValidation loss: 1.295095\tBest loss: 1.287610\tAccuracy: 69.80%\n",
      "329\tValidation loss: 1.291261\tBest loss: 1.287610\tAccuracy: 69.70%\n",
      "330\tValidation loss: 1.289690\tBest loss: 1.287610\tAccuracy: 70.20%\n",
      "331\tValidation loss: 1.286758\tBest loss: 1.286758\tAccuracy: 70.40%\n",
      "332\tValidation loss: 1.288783\tBest loss: 1.286758\tAccuracy: 70.40%\n",
      "333\tValidation loss: 1.289177\tBest loss: 1.286758\tAccuracy: 70.20%\n",
      "334\tValidation loss: 1.290397\tBest loss: 1.286758\tAccuracy: 70.10%\n",
      "335\tValidation loss: 1.283474\tBest loss: 1.283474\tAccuracy: 70.70%\n",
      "336\tValidation loss: 1.287100\tBest loss: 1.283474\tAccuracy: 70.10%\n",
      "337\tValidation loss: 1.288797\tBest loss: 1.283474\tAccuracy: 69.50%\n",
      "338\tValidation loss: 1.284870\tBest loss: 1.283474\tAccuracy: 70.00%\n",
      "339\tValidation loss: 1.286994\tBest loss: 1.283474\tAccuracy: 69.80%\n",
      "340\tValidation loss: 1.289606\tBest loss: 1.283474\tAccuracy: 70.50%\n",
      "341\tValidation loss: 1.287960\tBest loss: 1.283474\tAccuracy: 70.00%\n",
      "342\tValidation loss: 1.285192\tBest loss: 1.283474\tAccuracy: 70.10%\n",
      "343\tValidation loss: 1.291511\tBest loss: 1.283474\tAccuracy: 70.00%\n",
      "344\tValidation loss: 1.290411\tBest loss: 1.283474\tAccuracy: 70.50%\n",
      "345\tValidation loss: 1.281589\tBest loss: 1.281589\tAccuracy: 70.70%\n",
      "346\tValidation loss: 1.287397\tBest loss: 1.281589\tAccuracy: 70.10%\n",
      "347\tValidation loss: 1.287512\tBest loss: 1.281589\tAccuracy: 70.70%\n",
      "348\tValidation loss: 1.283382\tBest loss: 1.281589\tAccuracy: 70.20%\n",
      "349\tValidation loss: 1.285123\tBest loss: 1.281589\tAccuracy: 70.80%\n",
      "350\tValidation loss: 1.280621\tBest loss: 1.280621\tAccuracy: 70.80%\n",
      "351\tValidation loss: 1.284327\tBest loss: 1.280621\tAccuracy: 70.10%\n",
      "352\tValidation loss: 1.282986\tBest loss: 1.280621\tAccuracy: 70.50%\n",
      "353\tValidation loss: 1.283417\tBest loss: 1.280621\tAccuracy: 70.30%\n",
      "354\tValidation loss: 1.282694\tBest loss: 1.280621\tAccuracy: 70.20%\n",
      "355\tValidation loss: 1.282509\tBest loss: 1.280621\tAccuracy: 70.00%\n",
      "356\tValidation loss: 1.282138\tBest loss: 1.280621\tAccuracy: 70.20%\n",
      "357\tValidation loss: 1.283893\tBest loss: 1.280621\tAccuracy: 70.00%\n",
      "358\tValidation loss: 1.281692\tBest loss: 1.280621\tAccuracy: 70.30%\n",
      "359\tValidation loss: 1.284603\tBest loss: 1.280621\tAccuracy: 70.20%\n",
      "360\tValidation loss: 1.280376\tBest loss: 1.280376\tAccuracy: 70.30%\n",
      "361\tValidation loss: 1.286628\tBest loss: 1.280376\tAccuracy: 70.50%\n",
      "362\tValidation loss: 1.283662\tBest loss: 1.280376\tAccuracy: 70.20%\n",
      "363\tValidation loss: 1.283618\tBest loss: 1.280376\tAccuracy: 70.70%\n",
      "364\tValidation loss: 1.284993\tBest loss: 1.280376\tAccuracy: 70.10%\n",
      "365\tValidation loss: 1.284704\tBest loss: 1.280376\tAccuracy: 70.50%\n",
      "366\tValidation loss: 1.280957\tBest loss: 1.280376\tAccuracy: 70.20%\n",
      "367\tValidation loss: 1.282917\tBest loss: 1.280376\tAccuracy: 70.50%\n",
      "368\tValidation loss: 1.281390\tBest loss: 1.280376\tAccuracy: 70.90%\n",
      "369\tValidation loss: 1.281014\tBest loss: 1.280376\tAccuracy: 70.70%\n",
      "370\tValidation loss: 1.280767\tBest loss: 1.280376\tAccuracy: 70.70%\n",
      "371\tValidation loss: 1.280447\tBest loss: 1.280376\tAccuracy: 70.50%\n",
      "372\tValidation loss: 1.277283\tBest loss: 1.277283\tAccuracy: 70.50%\n",
      "373\tValidation loss: 1.283202\tBest loss: 1.277283\tAccuracy: 70.70%\n",
      "374\tValidation loss: 1.280170\tBest loss: 1.277283\tAccuracy: 70.60%\n",
      "375\tValidation loss: 1.275741\tBest loss: 1.275741\tAccuracy: 70.70%\n",
      "376\tValidation loss: 1.276011\tBest loss: 1.275741\tAccuracy: 70.70%\n",
      "377\tValidation loss: 1.281304\tBest loss: 1.275741\tAccuracy: 70.10%\n",
      "378\tValidation loss: 1.275200\tBest loss: 1.275200\tAccuracy: 71.20%\n",
      "379\tValidation loss: 1.280260\tBest loss: 1.275200\tAccuracy: 70.60%\n",
      "380\tValidation loss: 1.278317\tBest loss: 1.275200\tAccuracy: 70.70%\n",
      "381\tValidation loss: 1.275725\tBest loss: 1.275200\tAccuracy: 70.70%\n",
      "382\tValidation loss: 1.279762\tBest loss: 1.275200\tAccuracy: 70.60%\n",
      "383\tValidation loss: 1.278896\tBest loss: 1.275200\tAccuracy: 70.70%\n",
      "384\tValidation loss: 1.277410\tBest loss: 1.275200\tAccuracy: 70.30%\n",
      "385\tValidation loss: 1.277811\tBest loss: 1.275200\tAccuracy: 70.50%\n",
      "386\tValidation loss: 1.276564\tBest loss: 1.275200\tAccuracy: 70.80%\n",
      "387\tValidation loss: 1.270746\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "388\tValidation loss: 1.272541\tBest loss: 1.270746\tAccuracy: 70.80%\n",
      "389\tValidation loss: 1.276832\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "390\tValidation loss: 1.271701\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "391\tValidation loss: 1.272287\tBest loss: 1.270746\tAccuracy: 70.80%\n",
      "392\tValidation loss: 1.275933\tBest loss: 1.270746\tAccuracy: 70.50%\n",
      "393\tValidation loss: 1.278718\tBest loss: 1.270746\tAccuracy: 70.80%\n",
      "394\tValidation loss: 1.276095\tBest loss: 1.270746\tAccuracy: 70.30%\n",
      "395\tValidation loss: 1.274095\tBest loss: 1.270746\tAccuracy: 70.80%\n",
      "396\tValidation loss: 1.273812\tBest loss: 1.270746\tAccuracy: 70.90%\n",
      "397\tValidation loss: 1.275660\tBest loss: 1.270746\tAccuracy: 70.90%\n",
      "398\tValidation loss: 1.271804\tBest loss: 1.270746\tAccuracy: 70.80%\n",
      "399\tValidation loss: 1.275117\tBest loss: 1.270746\tAccuracy: 70.50%\n",
      "400\tValidation loss: 1.276393\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "401\tValidation loss: 1.275669\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "402\tValidation loss: 1.273856\tBest loss: 1.270746\tAccuracy: 71.20%\n",
      "403\tValidation loss: 1.273015\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "404\tValidation loss: 1.272337\tBest loss: 1.270746\tAccuracy: 71.00%\n",
      "405\tValidation loss: 1.271561\tBest loss: 1.270746\tAccuracy: 70.90%\n",
      "406\tValidation loss: 1.273877\tBest loss: 1.270746\tAccuracy: 70.70%\n",
      "407\tValidation loss: 1.274148\tBest loss: 1.270746\tAccuracy: 70.30%\n",
      "408\tValidation loss: 1.272021\tBest loss: 1.270746\tAccuracy: 70.60%\n",
      "Early stopping!\n",
      "[[  1.95734762e-03   8.17516074e-03   1.51396485e-03 ...,   1.31701045e-02\n",
      "    2.14230458e-05   4.73958952e-03]\n",
      " [  3.87495811e-29   6.01271015e-25   1.64840203e-21 ...,   9.19940747e-23\n",
      "    8.34099254e-29   1.88376268e-21]\n",
      " [  2.93190605e-09   1.55005715e-08   8.18535191e-05 ...,   1.57213449e-07\n",
      "    2.11179904e-05   1.85382017e-03]\n",
      " ..., \n",
      " [  1.08162201e-09   2.57810107e-09   1.50500767e-08 ...,   7.37592752e-20\n",
      "    8.19741952e-14   4.66699094e-14]\n",
      " [  3.28121744e-02   2.15534344e-02   1.93691421e-02 ...,   1.87892672e-02\n",
      "    1.71177331e-02   1.43008558e-02]\n",
      " [  1.85830143e-21   2.38173588e-18   3.48725775e-19 ...,   4.61314016e-07\n",
      "    7.41899945e-04   9.97423530e-01]]\n",
      "[41 41 22 ...,  6  8 47]\n",
      "[[  2.31926938e-15   1.00698039e-09   6.30155569e-07 ...,   2.68547511e-17\n",
      "    7.79508804e-16   7.53424558e-13]\n",
      " [  4.74450998e-02   3.85814533e-02   3.57243866e-02 ...,   1.67389270e-02\n",
      "    1.09952409e-02   9.52406041e-03]\n",
      " [  1.37544803e-22   2.40966538e-27   2.79667289e-09 ...,   3.34043308e-23\n",
      "    1.20738492e-32   1.96527670e-37]\n",
      " ..., \n",
      " [  3.67251823e-06   9.53713752e-05   4.67157297e-05 ...,   1.87954516e-03\n",
      "    7.58640526e-04   2.72854697e-02]\n",
      " [  1.37267179e-07   8.11853454e-07   5.35778817e-08 ...,   2.73581740e-04\n",
      "    4.74800800e-05   4.15167655e-04]\n",
      " [  1.29262775e-29   1.41085633e-16   6.98848784e-23 ...,   2.06545211e-10\n",
      "    2.02884220e-11   8.82105087e-06]]\n",
      "[20  0 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.4, n_hidden_layers=0, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=  17.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.860905\tBest loss: 3.860905\tAccuracy: 4.10%\n",
      "1\tValidation loss: 3.850872\tBest loss: 3.850872\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.843726\tBest loss: 3.843726\tAccuracy: 4.10%\n",
      "3\tValidation loss: 3.836944\tBest loss: 3.836944\tAccuracy: 4.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\tValidation loss: 3.833921\tBest loss: 3.833921\tAccuracy: 4.10%\n",
      "5\tValidation loss: 3.829815\tBest loss: 3.829815\tAccuracy: 4.10%\n",
      "6\tValidation loss: 3.824899\tBest loss: 3.824899\tAccuracy: 4.10%\n",
      "7\tValidation loss: 3.818809\tBest loss: 3.818809\tAccuracy: 4.10%\n",
      "8\tValidation loss: 3.814227\tBest loss: 3.814227\tAccuracy: 4.10%\n",
      "9\tValidation loss: 3.810496\tBest loss: 3.810496\tAccuracy: 4.10%\n",
      "10\tValidation loss: 3.809010\tBest loss: 3.809010\tAccuracy: 4.10%\n",
      "11\tValidation loss: 3.806741\tBest loss: 3.806741\tAccuracy: 4.10%\n",
      "12\tValidation loss: 3.803928\tBest loss: 3.803928\tAccuracy: 4.10%\n",
      "13\tValidation loss: 3.799829\tBest loss: 3.799829\tAccuracy: 4.10%\n",
      "14\tValidation loss: 3.797580\tBest loss: 3.797580\tAccuracy: 4.10%\n",
      "15\tValidation loss: 3.795085\tBest loss: 3.795085\tAccuracy: 4.10%\n",
      "16\tValidation loss: 3.794287\tBest loss: 3.794287\tAccuracy: 4.10%\n",
      "17\tValidation loss: 3.793250\tBest loss: 3.793250\tAccuracy: 4.10%\n",
      "18\tValidation loss: 3.791711\tBest loss: 3.791711\tAccuracy: 4.10%\n",
      "19\tValidation loss: 3.790824\tBest loss: 3.790824\tAccuracy: 4.10%\n",
      "20\tValidation loss: 3.788220\tBest loss: 3.788220\tAccuracy: 4.10%\n",
      "21\tValidation loss: 3.787796\tBest loss: 3.787796\tAccuracy: 4.10%\n",
      "22\tValidation loss: 3.786372\tBest loss: 3.786372\tAccuracy: 4.20%\n",
      "23\tValidation loss: 3.786159\tBest loss: 3.786159\tAccuracy: 4.20%\n",
      "24\tValidation loss: 3.784215\tBest loss: 3.784215\tAccuracy: 4.30%\n",
      "25\tValidation loss: 3.784161\tBest loss: 3.784161\tAccuracy: 4.00%\n",
      "26\tValidation loss: 3.784374\tBest loss: 3.784161\tAccuracy: 4.30%\n",
      "27\tValidation loss: 3.781278\tBest loss: 3.781278\tAccuracy: 4.40%\n",
      "28\tValidation loss: 3.782486\tBest loss: 3.781278\tAccuracy: 3.90%\n",
      "29\tValidation loss: 3.777938\tBest loss: 3.777938\tAccuracy: 4.20%\n",
      "30\tValidation loss: 3.768280\tBest loss: 3.768280\tAccuracy: 4.70%\n",
      "31\tValidation loss: 3.769688\tBest loss: 3.768280\tAccuracy: 4.60%\n",
      "32\tValidation loss: 3.768366\tBest loss: 3.768280\tAccuracy: 4.30%\n",
      "33\tValidation loss: 3.769338\tBest loss: 3.768280\tAccuracy: 4.20%\n",
      "34\tValidation loss: 3.743409\tBest loss: 3.743409\tAccuracy: 4.70%\n",
      "35\tValidation loss: 3.741394\tBest loss: 3.741394\tAccuracy: 4.40%\n",
      "36\tValidation loss: 3.729255\tBest loss: 3.729255\tAccuracy: 4.60%\n",
      "37\tValidation loss: 3.736136\tBest loss: 3.729255\tAccuracy: 4.50%\n",
      "38\tValidation loss: 3.718072\tBest loss: 3.718072\tAccuracy: 4.90%\n",
      "39\tValidation loss: 3.690913\tBest loss: 3.690913\tAccuracy: 5.60%\n",
      "40\tValidation loss: 3.715106\tBest loss: 3.690913\tAccuracy: 4.90%\n",
      "41\tValidation loss: 3.712345\tBest loss: 3.690913\tAccuracy: 4.70%\n",
      "42\tValidation loss: 3.702919\tBest loss: 3.690913\tAccuracy: 5.10%\n",
      "43\tValidation loss: 3.688702\tBest loss: 3.688702\tAccuracy: 5.00%\n",
      "44\tValidation loss: 3.697071\tBest loss: 3.688702\tAccuracy: 4.70%\n",
      "45\tValidation loss: 3.692370\tBest loss: 3.688702\tAccuracy: 5.40%\n",
      "46\tValidation loss: 3.709508\tBest loss: 3.688702\tAccuracy: 4.80%\n",
      "47\tValidation loss: 3.702450\tBest loss: 3.688702\tAccuracy: 4.80%\n",
      "48\tValidation loss: 3.708642\tBest loss: 3.688702\tAccuracy: 5.10%\n",
      "49\tValidation loss: 3.703833\tBest loss: 3.688702\tAccuracy: 5.60%\n",
      "50\tValidation loss: 3.680086\tBest loss: 3.680086\tAccuracy: 5.70%\n",
      "51\tValidation loss: 3.656664\tBest loss: 3.656664\tAccuracy: 6.60%\n",
      "52\tValidation loss: 3.680408\tBest loss: 3.656664\tAccuracy: 5.70%\n",
      "53\tValidation loss: 3.681780\tBest loss: 3.656664\tAccuracy: 5.90%\n",
      "54\tValidation loss: 3.684294\tBest loss: 3.656664\tAccuracy: 5.70%\n",
      "55\tValidation loss: 3.685900\tBest loss: 3.656664\tAccuracy: 5.90%\n",
      "56\tValidation loss: 3.670043\tBest loss: 3.656664\tAccuracy: 5.80%\n",
      "57\tValidation loss: 3.660649\tBest loss: 3.656664\tAccuracy: 6.40%\n",
      "58\tValidation loss: 3.672485\tBest loss: 3.656664\tAccuracy: 6.50%\n",
      "59\tValidation loss: 3.663498\tBest loss: 3.656664\tAccuracy: 5.90%\n",
      "60\tValidation loss: 3.672200\tBest loss: 3.656664\tAccuracy: 6.70%\n",
      "61\tValidation loss: 3.655135\tBest loss: 3.655135\tAccuracy: 7.10%\n",
      "62\tValidation loss: 3.660089\tBest loss: 3.655135\tAccuracy: 6.80%\n",
      "63\tValidation loss: 3.651900\tBest loss: 3.651900\tAccuracy: 6.70%\n",
      "64\tValidation loss: 3.630456\tBest loss: 3.630456\tAccuracy: 7.20%\n",
      "65\tValidation loss: 3.627805\tBest loss: 3.627805\tAccuracy: 7.90%\n",
      "66\tValidation loss: 3.636828\tBest loss: 3.627805\tAccuracy: 7.30%\n",
      "67\tValidation loss: 3.613820\tBest loss: 3.613820\tAccuracy: 8.40%\n",
      "68\tValidation loss: 3.614709\tBest loss: 3.613820\tAccuracy: 8.60%\n",
      "69\tValidation loss: 3.602529\tBest loss: 3.602529\tAccuracy: 8.80%\n",
      "70\tValidation loss: 3.618472\tBest loss: 3.602529\tAccuracy: 8.10%\n",
      "71\tValidation loss: 3.601998\tBest loss: 3.601998\tAccuracy: 7.50%\n",
      "72\tValidation loss: 3.607639\tBest loss: 3.601998\tAccuracy: 7.80%\n",
      "73\tValidation loss: 3.568747\tBest loss: 3.568747\tAccuracy: 9.40%\n",
      "74\tValidation loss: 3.592397\tBest loss: 3.568747\tAccuracy: 8.20%\n",
      "75\tValidation loss: 3.602235\tBest loss: 3.568747\tAccuracy: 9.90%\n",
      "76\tValidation loss: 3.609059\tBest loss: 3.568747\tAccuracy: 8.90%\n",
      "77\tValidation loss: 3.572863\tBest loss: 3.568747\tAccuracy: 10.50%\n",
      "78\tValidation loss: 3.556247\tBest loss: 3.556247\tAccuracy: 10.80%\n",
      "79\tValidation loss: 3.546570\tBest loss: 3.546570\tAccuracy: 10.60%\n",
      "80\tValidation loss: 3.567559\tBest loss: 3.546570\tAccuracy: 9.20%\n",
      "81\tValidation loss: 3.549259\tBest loss: 3.546570\tAccuracy: 9.40%\n",
      "82\tValidation loss: 3.528879\tBest loss: 3.528879\tAccuracy: 10.80%\n",
      "83\tValidation loss: 3.561250\tBest loss: 3.528879\tAccuracy: 10.80%\n",
      "84\tValidation loss: 3.523835\tBest loss: 3.523835\tAccuracy: 10.40%\n",
      "85\tValidation loss: 3.512037\tBest loss: 3.512037\tAccuracy: 11.80%\n",
      "86\tValidation loss: 3.500075\tBest loss: 3.500075\tAccuracy: 12.20%\n",
      "87\tValidation loss: 3.525517\tBest loss: 3.500075\tAccuracy: 11.30%\n",
      "88\tValidation loss: 3.511911\tBest loss: 3.500075\tAccuracy: 11.70%\n",
      "89\tValidation loss: 3.509037\tBest loss: 3.500075\tAccuracy: 11.10%\n",
      "90\tValidation loss: 3.492696\tBest loss: 3.492696\tAccuracy: 11.90%\n",
      "91\tValidation loss: 3.499754\tBest loss: 3.492696\tAccuracy: 11.50%\n",
      "92\tValidation loss: 3.532541\tBest loss: 3.492696\tAccuracy: 10.60%\n",
      "93\tValidation loss: 3.486001\tBest loss: 3.486001\tAccuracy: 13.00%\n",
      "94\tValidation loss: 3.479943\tBest loss: 3.479943\tAccuracy: 11.90%\n",
      "95\tValidation loss: 3.494495\tBest loss: 3.479943\tAccuracy: 12.60%\n",
      "96\tValidation loss: 3.487041\tBest loss: 3.479943\tAccuracy: 10.40%\n",
      "97\tValidation loss: 3.448572\tBest loss: 3.448572\tAccuracy: 12.70%\n",
      "98\tValidation loss: 3.451756\tBest loss: 3.448572\tAccuracy: 13.00%\n",
      "99\tValidation loss: 3.428963\tBest loss: 3.428963\tAccuracy: 13.10%\n",
      "100\tValidation loss: 3.437258\tBest loss: 3.428963\tAccuracy: 13.10%\n",
      "101\tValidation loss: 3.421643\tBest loss: 3.421643\tAccuracy: 14.10%\n",
      "102\tValidation loss: 3.377661\tBest loss: 3.377661\tAccuracy: 13.70%\n",
      "103\tValidation loss: 3.392564\tBest loss: 3.377661\tAccuracy: 13.00%\n",
      "104\tValidation loss: 3.405286\tBest loss: 3.377661\tAccuracy: 14.00%\n",
      "105\tValidation loss: 3.405350\tBest loss: 3.377661\tAccuracy: 13.80%\n",
      "106\tValidation loss: 3.404675\tBest loss: 3.377661\tAccuracy: 14.40%\n",
      "107\tValidation loss: 3.396885\tBest loss: 3.377661\tAccuracy: 13.60%\n",
      "108\tValidation loss: 3.383646\tBest loss: 3.377661\tAccuracy: 13.30%\n",
      "109\tValidation loss: 3.361579\tBest loss: 3.361579\tAccuracy: 15.90%\n",
      "110\tValidation loss: 3.359182\tBest loss: 3.359182\tAccuracy: 15.70%\n",
      "111\tValidation loss: 3.355426\tBest loss: 3.355426\tAccuracy: 15.10%\n",
      "112\tValidation loss: 3.328667\tBest loss: 3.328667\tAccuracy: 15.70%\n",
      "113\tValidation loss: 3.314997\tBest loss: 3.314997\tAccuracy: 16.60%\n",
      "114\tValidation loss: 3.325278\tBest loss: 3.314997\tAccuracy: 16.00%\n",
      "115\tValidation loss: 3.323867\tBest loss: 3.314997\tAccuracy: 15.90%\n",
      "116\tValidation loss: 3.340823\tBest loss: 3.314997\tAccuracy: 15.30%\n",
      "117\tValidation loss: 3.309755\tBest loss: 3.309755\tAccuracy: 16.80%\n",
      "118\tValidation loss: 3.361353\tBest loss: 3.309755\tAccuracy: 14.80%\n",
      "119\tValidation loss: 3.321749\tBest loss: 3.309755\tAccuracy: 14.90%\n",
      "120\tValidation loss: 3.310633\tBest loss: 3.309755\tAccuracy: 16.00%\n",
      "121\tValidation loss: 3.307644\tBest loss: 3.307644\tAccuracy: 16.80%\n",
      "122\tValidation loss: 3.278500\tBest loss: 3.278500\tAccuracy: 17.00%\n",
      "123\tValidation loss: 3.298588\tBest loss: 3.278500\tAccuracy: 16.10%\n",
      "124\tValidation loss: 3.265962\tBest loss: 3.265962\tAccuracy: 17.50%\n",
      "125\tValidation loss: 3.259123\tBest loss: 3.259123\tAccuracy: 16.40%\n",
      "126\tValidation loss: 3.299576\tBest loss: 3.259123\tAccuracy: 16.20%\n",
      "127\tValidation loss: 3.329871\tBest loss: 3.259123\tAccuracy: 15.40%\n",
      "128\tValidation loss: 3.284700\tBest loss: 3.259123\tAccuracy: 16.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\tValidation loss: 3.263372\tBest loss: 3.259123\tAccuracy: 16.00%\n",
      "130\tValidation loss: 3.282600\tBest loss: 3.259123\tAccuracy: 16.40%\n",
      "131\tValidation loss: 3.257725\tBest loss: 3.257725\tAccuracy: 17.90%\n",
      "132\tValidation loss: 3.199221\tBest loss: 3.199221\tAccuracy: 18.40%\n",
      "133\tValidation loss: 3.281191\tBest loss: 3.199221\tAccuracy: 15.10%\n",
      "134\tValidation loss: 3.234536\tBest loss: 3.199221\tAccuracy: 18.10%\n",
      "135\tValidation loss: 3.233431\tBest loss: 3.199221\tAccuracy: 18.40%\n",
      "136\tValidation loss: 3.222143\tBest loss: 3.199221\tAccuracy: 17.50%\n",
      "137\tValidation loss: 3.239678\tBest loss: 3.199221\tAccuracy: 17.20%\n",
      "138\tValidation loss: 3.255740\tBest loss: 3.199221\tAccuracy: 17.90%\n",
      "139\tValidation loss: 3.223669\tBest loss: 3.199221\tAccuracy: 17.60%\n",
      "140\tValidation loss: 3.208804\tBest loss: 3.199221\tAccuracy: 17.30%\n",
      "141\tValidation loss: 3.237892\tBest loss: 3.199221\tAccuracy: 16.50%\n",
      "142\tValidation loss: 3.207325\tBest loss: 3.199221\tAccuracy: 17.50%\n",
      "143\tValidation loss: 3.174205\tBest loss: 3.174205\tAccuracy: 19.60%\n",
      "144\tValidation loss: 3.184765\tBest loss: 3.174205\tAccuracy: 19.30%\n",
      "145\tValidation loss: 3.213948\tBest loss: 3.174205\tAccuracy: 16.30%\n",
      "146\tValidation loss: 3.181333\tBest loss: 3.174205\tAccuracy: 17.50%\n",
      "147\tValidation loss: 3.220152\tBest loss: 3.174205\tAccuracy: 17.30%\n",
      "148\tValidation loss: 3.181244\tBest loss: 3.174205\tAccuracy: 16.20%\n",
      "149\tValidation loss: 3.169320\tBest loss: 3.169320\tAccuracy: 17.20%\n",
      "150\tValidation loss: 3.144886\tBest loss: 3.144886\tAccuracy: 18.60%\n",
      "151\tValidation loss: 3.130512\tBest loss: 3.130512\tAccuracy: 19.00%\n",
      "152\tValidation loss: 3.174377\tBest loss: 3.130512\tAccuracy: 18.30%\n",
      "153\tValidation loss: 3.133921\tBest loss: 3.130512\tAccuracy: 19.20%\n",
      "154\tValidation loss: 3.116413\tBest loss: 3.116413\tAccuracy: 18.80%\n",
      "155\tValidation loss: 3.124079\tBest loss: 3.116413\tAccuracy: 19.10%\n",
      "156\tValidation loss: 3.116756\tBest loss: 3.116413\tAccuracy: 18.90%\n",
      "157\tValidation loss: 3.134822\tBest loss: 3.116413\tAccuracy: 18.40%\n",
      "158\tValidation loss: 3.135792\tBest loss: 3.116413\tAccuracy: 18.80%\n",
      "159\tValidation loss: 3.101003\tBest loss: 3.101003\tAccuracy: 19.70%\n",
      "160\tValidation loss: 3.106452\tBest loss: 3.101003\tAccuracy: 19.30%\n",
      "161\tValidation loss: 3.106971\tBest loss: 3.101003\tAccuracy: 18.80%\n",
      "162\tValidation loss: 3.106572\tBest loss: 3.101003\tAccuracy: 20.30%\n",
      "163\tValidation loss: 3.100848\tBest loss: 3.100848\tAccuracy: 18.90%\n",
      "164\tValidation loss: 3.100584\tBest loss: 3.100584\tAccuracy: 19.40%\n",
      "165\tValidation loss: 3.095424\tBest loss: 3.095424\tAccuracy: 20.00%\n",
      "166\tValidation loss: 3.090736\tBest loss: 3.090736\tAccuracy: 19.10%\n",
      "167\tValidation loss: 3.097850\tBest loss: 3.090736\tAccuracy: 20.20%\n",
      "168\tValidation loss: 3.085543\tBest loss: 3.085543\tAccuracy: 20.10%\n",
      "169\tValidation loss: 3.063656\tBest loss: 3.063656\tAccuracy: 19.60%\n",
      "170\tValidation loss: 3.053777\tBest loss: 3.053777\tAccuracy: 21.10%\n",
      "171\tValidation loss: 3.064783\tBest loss: 3.053777\tAccuracy: 20.00%\n",
      "172\tValidation loss: 3.070796\tBest loss: 3.053777\tAccuracy: 20.50%\n",
      "173\tValidation loss: 3.065832\tBest loss: 3.053777\tAccuracy: 20.60%\n",
      "174\tValidation loss: 3.041742\tBest loss: 3.041742\tAccuracy: 21.40%\n",
      "175\tValidation loss: 3.037270\tBest loss: 3.037270\tAccuracy: 20.00%\n",
      "176\tValidation loss: 3.036657\tBest loss: 3.036657\tAccuracy: 21.50%\n",
      "177\tValidation loss: 3.023667\tBest loss: 3.023667\tAccuracy: 21.20%\n",
      "178\tValidation loss: 3.049867\tBest loss: 3.023667\tAccuracy: 19.80%\n",
      "179\tValidation loss: 3.034564\tBest loss: 3.023667\tAccuracy: 21.40%\n",
      "180\tValidation loss: 3.025383\tBest loss: 3.023667\tAccuracy: 21.30%\n",
      "181\tValidation loss: 3.049102\tBest loss: 3.023667\tAccuracy: 20.50%\n",
      "182\tValidation loss: 3.053399\tBest loss: 3.023667\tAccuracy: 21.00%\n",
      "183\tValidation loss: 3.018463\tBest loss: 3.018463\tAccuracy: 21.80%\n",
      "184\tValidation loss: 3.004966\tBest loss: 3.004966\tAccuracy: 21.80%\n",
      "185\tValidation loss: 3.001873\tBest loss: 3.001873\tAccuracy: 21.80%\n",
      "186\tValidation loss: 2.985417\tBest loss: 2.985417\tAccuracy: 20.90%\n",
      "187\tValidation loss: 2.994117\tBest loss: 2.985417\tAccuracy: 22.40%\n",
      "188\tValidation loss: 3.003059\tBest loss: 2.985417\tAccuracy: 22.30%\n",
      "189\tValidation loss: 2.987676\tBest loss: 2.985417\tAccuracy: 22.00%\n",
      "190\tValidation loss: 3.002621\tBest loss: 2.985417\tAccuracy: 21.30%\n",
      "191\tValidation loss: 2.954886\tBest loss: 2.954886\tAccuracy: 23.10%\n",
      "192\tValidation loss: 2.976998\tBest loss: 2.954886\tAccuracy: 22.60%\n",
      "193\tValidation loss: 2.971387\tBest loss: 2.954886\tAccuracy: 22.10%\n",
      "194\tValidation loss: 2.998733\tBest loss: 2.954886\tAccuracy: 21.30%\n",
      "195\tValidation loss: 2.961526\tBest loss: 2.954886\tAccuracy: 23.00%\n",
      "196\tValidation loss: 2.974318\tBest loss: 2.954886\tAccuracy: 22.40%\n",
      "197\tValidation loss: 2.952271\tBest loss: 2.952271\tAccuracy: 22.80%\n",
      "198\tValidation loss: 2.932019\tBest loss: 2.932019\tAccuracy: 23.30%\n",
      "199\tValidation loss: 2.955196\tBest loss: 2.932019\tAccuracy: 22.70%\n",
      "200\tValidation loss: 2.931326\tBest loss: 2.931326\tAccuracy: 22.60%\n",
      "201\tValidation loss: 2.919545\tBest loss: 2.919545\tAccuracy: 22.10%\n",
      "202\tValidation loss: 2.938980\tBest loss: 2.919545\tAccuracy: 22.90%\n",
      "203\tValidation loss: 2.916261\tBest loss: 2.916261\tAccuracy: 23.50%\n",
      "204\tValidation loss: 2.935542\tBest loss: 2.916261\tAccuracy: 23.00%\n",
      "205\tValidation loss: 2.928793\tBest loss: 2.916261\tAccuracy: 22.70%\n",
      "206\tValidation loss: 2.904652\tBest loss: 2.904652\tAccuracy: 24.00%\n",
      "207\tValidation loss: 2.913004\tBest loss: 2.904652\tAccuracy: 23.50%\n",
      "208\tValidation loss: 2.933576\tBest loss: 2.904652\tAccuracy: 23.00%\n",
      "209\tValidation loss: 2.928953\tBest loss: 2.904652\tAccuracy: 23.00%\n",
      "210\tValidation loss: 2.877468\tBest loss: 2.877468\tAccuracy: 23.20%\n",
      "211\tValidation loss: 2.905213\tBest loss: 2.877468\tAccuracy: 23.20%\n",
      "212\tValidation loss: 2.898474\tBest loss: 2.877468\tAccuracy: 23.70%\n",
      "213\tValidation loss: 2.906565\tBest loss: 2.877468\tAccuracy: 22.10%\n",
      "214\tValidation loss: 2.895145\tBest loss: 2.877468\tAccuracy: 23.30%\n",
      "215\tValidation loss: 2.887717\tBest loss: 2.877468\tAccuracy: 24.70%\n",
      "216\tValidation loss: 2.888206\tBest loss: 2.877468\tAccuracy: 23.40%\n",
      "217\tValidation loss: 2.865533\tBest loss: 2.865533\tAccuracy: 24.00%\n",
      "218\tValidation loss: 2.846386\tBest loss: 2.846386\tAccuracy: 25.00%\n",
      "219\tValidation loss: 2.890463\tBest loss: 2.846386\tAccuracy: 23.40%\n",
      "220\tValidation loss: 2.860121\tBest loss: 2.846386\tAccuracy: 23.50%\n",
      "221\tValidation loss: 2.838512\tBest loss: 2.838512\tAccuracy: 24.70%\n",
      "222\tValidation loss: 2.866420\tBest loss: 2.838512\tAccuracy: 24.40%\n",
      "223\tValidation loss: 2.854234\tBest loss: 2.838512\tAccuracy: 25.10%\n",
      "224\tValidation loss: 2.843690\tBest loss: 2.838512\tAccuracy: 24.50%\n",
      "225\tValidation loss: 2.824185\tBest loss: 2.824185\tAccuracy: 25.00%\n",
      "226\tValidation loss: 2.836546\tBest loss: 2.824185\tAccuracy: 24.10%\n",
      "227\tValidation loss: 2.863552\tBest loss: 2.824185\tAccuracy: 23.80%\n",
      "228\tValidation loss: 2.857844\tBest loss: 2.824185\tAccuracy: 25.20%\n",
      "229\tValidation loss: 2.834795\tBest loss: 2.824185\tAccuracy: 23.50%\n",
      "230\tValidation loss: 2.831664\tBest loss: 2.824185\tAccuracy: 24.70%\n",
      "231\tValidation loss: 2.837846\tBest loss: 2.824185\tAccuracy: 26.30%\n",
      "232\tValidation loss: 2.834737\tBest loss: 2.824185\tAccuracy: 25.10%\n",
      "233\tValidation loss: 2.872060\tBest loss: 2.824185\tAccuracy: 23.70%\n",
      "234\tValidation loss: 2.857319\tBest loss: 2.824185\tAccuracy: 24.10%\n",
      "235\tValidation loss: 2.804525\tBest loss: 2.804525\tAccuracy: 25.00%\n",
      "236\tValidation loss: 2.806471\tBest loss: 2.804525\tAccuracy: 25.50%\n",
      "237\tValidation loss: 2.811156\tBest loss: 2.804525\tAccuracy: 25.00%\n",
      "238\tValidation loss: 2.822565\tBest loss: 2.804525\tAccuracy: 24.40%\n",
      "239\tValidation loss: 2.818768\tBest loss: 2.804525\tAccuracy: 25.30%\n",
      "240\tValidation loss: 2.818161\tBest loss: 2.804525\tAccuracy: 25.30%\n",
      "241\tValidation loss: 2.811491\tBest loss: 2.804525\tAccuracy: 24.00%\n",
      "242\tValidation loss: 2.825297\tBest loss: 2.804525\tAccuracy: 24.30%\n",
      "243\tValidation loss: 2.757415\tBest loss: 2.757415\tAccuracy: 25.30%\n",
      "244\tValidation loss: 2.780843\tBest loss: 2.757415\tAccuracy: 25.10%\n",
      "245\tValidation loss: 2.764701\tBest loss: 2.757415\tAccuracy: 26.30%\n",
      "246\tValidation loss: 2.791494\tBest loss: 2.757415\tAccuracy: 25.10%\n",
      "247\tValidation loss: 2.779101\tBest loss: 2.757415\tAccuracy: 24.60%\n",
      "248\tValidation loss: 2.787016\tBest loss: 2.757415\tAccuracy: 25.20%\n",
      "249\tValidation loss: 2.770067\tBest loss: 2.757415\tAccuracy: 25.60%\n",
      "250\tValidation loss: 2.764997\tBest loss: 2.757415\tAccuracy: 25.10%\n",
      "251\tValidation loss: 2.767138\tBest loss: 2.757415\tAccuracy: 27.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\tValidation loss: 2.799367\tBest loss: 2.757415\tAccuracy: 26.40%\n",
      "253\tValidation loss: 2.788515\tBest loss: 2.757415\tAccuracy: 25.10%\n",
      "254\tValidation loss: 2.765870\tBest loss: 2.757415\tAccuracy: 25.60%\n",
      "255\tValidation loss: 2.782882\tBest loss: 2.757415\tAccuracy: 24.80%\n",
      "256\tValidation loss: 2.744120\tBest loss: 2.744120\tAccuracy: 27.20%\n",
      "257\tValidation loss: 2.770355\tBest loss: 2.744120\tAccuracy: 25.50%\n",
      "258\tValidation loss: 2.763684\tBest loss: 2.744120\tAccuracy: 25.20%\n",
      "259\tValidation loss: 2.742872\tBest loss: 2.742872\tAccuracy: 26.50%\n",
      "260\tValidation loss: 2.753307\tBest loss: 2.742872\tAccuracy: 25.90%\n",
      "261\tValidation loss: 2.745467\tBest loss: 2.742872\tAccuracy: 25.50%\n",
      "262\tValidation loss: 2.766905\tBest loss: 2.742872\tAccuracy: 26.60%\n",
      "263\tValidation loss: 2.755901\tBest loss: 2.742872\tAccuracy: 26.00%\n",
      "264\tValidation loss: 2.734806\tBest loss: 2.734806\tAccuracy: 26.60%\n",
      "265\tValidation loss: 2.742902\tBest loss: 2.734806\tAccuracy: 26.40%\n",
      "266\tValidation loss: 2.772731\tBest loss: 2.734806\tAccuracy: 26.40%\n",
      "267\tValidation loss: 2.728557\tBest loss: 2.728557\tAccuracy: 27.90%\n",
      "268\tValidation loss: 2.741751\tBest loss: 2.728557\tAccuracy: 27.50%\n",
      "269\tValidation loss: 2.702816\tBest loss: 2.702816\tAccuracy: 26.50%\n",
      "270\tValidation loss: 2.737523\tBest loss: 2.702816\tAccuracy: 27.10%\n",
      "271\tValidation loss: 2.729698\tBest loss: 2.702816\tAccuracy: 26.00%\n",
      "272\tValidation loss: 2.702120\tBest loss: 2.702120\tAccuracy: 26.60%\n",
      "273\tValidation loss: 2.725382\tBest loss: 2.702120\tAccuracy: 26.10%\n",
      "274\tValidation loss: 2.715390\tBest loss: 2.702120\tAccuracy: 26.90%\n",
      "275\tValidation loss: 2.705085\tBest loss: 2.702120\tAccuracy: 27.60%\n",
      "276\tValidation loss: 2.721268\tBest loss: 2.702120\tAccuracy: 26.40%\n",
      "277\tValidation loss: 2.694697\tBest loss: 2.694697\tAccuracy: 27.10%\n",
      "278\tValidation loss: 2.713847\tBest loss: 2.694697\tAccuracy: 26.30%\n",
      "279\tValidation loss: 2.712554\tBest loss: 2.694697\tAccuracy: 26.40%\n",
      "280\tValidation loss: 2.682190\tBest loss: 2.682190\tAccuracy: 27.20%\n",
      "281\tValidation loss: 2.663088\tBest loss: 2.663088\tAccuracy: 27.00%\n",
      "282\tValidation loss: 2.691866\tBest loss: 2.663088\tAccuracy: 26.90%\n",
      "283\tValidation loss: 2.698648\tBest loss: 2.663088\tAccuracy: 26.10%\n",
      "284\tValidation loss: 2.700225\tBest loss: 2.663088\tAccuracy: 26.50%\n",
      "285\tValidation loss: 2.677385\tBest loss: 2.663088\tAccuracy: 26.40%\n",
      "286\tValidation loss: 2.688125\tBest loss: 2.663088\tAccuracy: 26.00%\n",
      "287\tValidation loss: 2.678803\tBest loss: 2.663088\tAccuracy: 26.00%\n",
      "288\tValidation loss: 2.680777\tBest loss: 2.663088\tAccuracy: 27.10%\n",
      "289\tValidation loss: 2.666492\tBest loss: 2.663088\tAccuracy: 27.10%\n",
      "290\tValidation loss: 2.662333\tBest loss: 2.662333\tAccuracy: 27.80%\n",
      "291\tValidation loss: 2.700237\tBest loss: 2.662333\tAccuracy: 26.00%\n",
      "292\tValidation loss: 2.674636\tBest loss: 2.662333\tAccuracy: 27.40%\n",
      "293\tValidation loss: 2.668498\tBest loss: 2.662333\tAccuracy: 26.90%\n",
      "294\tValidation loss: 2.670753\tBest loss: 2.662333\tAccuracy: 25.30%\n",
      "295\tValidation loss: 2.682279\tBest loss: 2.662333\tAccuracy: 25.80%\n",
      "296\tValidation loss: 2.663767\tBest loss: 2.662333\tAccuracy: 26.60%\n",
      "297\tValidation loss: 2.669721\tBest loss: 2.662333\tAccuracy: 26.30%\n",
      "298\tValidation loss: 2.651769\tBest loss: 2.651769\tAccuracy: 27.00%\n",
      "299\tValidation loss: 2.687399\tBest loss: 2.651769\tAccuracy: 27.50%\n",
      "300\tValidation loss: 2.660340\tBest loss: 2.651769\tAccuracy: 26.70%\n",
      "301\tValidation loss: 2.635655\tBest loss: 2.635655\tAccuracy: 27.60%\n",
      "302\tValidation loss: 2.664601\tBest loss: 2.635655\tAccuracy: 27.60%\n",
      "303\tValidation loss: 2.653850\tBest loss: 2.635655\tAccuracy: 28.50%\n",
      "304\tValidation loss: 2.634958\tBest loss: 2.634958\tAccuracy: 27.80%\n",
      "305\tValidation loss: 2.646278\tBest loss: 2.634958\tAccuracy: 28.00%\n",
      "306\tValidation loss: 2.655606\tBest loss: 2.634958\tAccuracy: 27.10%\n",
      "307\tValidation loss: 2.621448\tBest loss: 2.621448\tAccuracy: 29.20%\n",
      "308\tValidation loss: 2.639054\tBest loss: 2.621448\tAccuracy: 26.80%\n",
      "309\tValidation loss: 2.636345\tBest loss: 2.621448\tAccuracy: 27.90%\n",
      "310\tValidation loss: 2.636504\tBest loss: 2.621448\tAccuracy: 28.50%\n",
      "311\tValidation loss: 2.635848\tBest loss: 2.621448\tAccuracy: 28.80%\n",
      "312\tValidation loss: 2.620698\tBest loss: 2.620698\tAccuracy: 28.80%\n",
      "313\tValidation loss: 2.637765\tBest loss: 2.620698\tAccuracy: 28.30%\n",
      "314\tValidation loss: 2.651130\tBest loss: 2.620698\tAccuracy: 27.90%\n",
      "315\tValidation loss: 2.624721\tBest loss: 2.620698\tAccuracy: 28.00%\n",
      "316\tValidation loss: 2.615817\tBest loss: 2.615817\tAccuracy: 28.90%\n",
      "317\tValidation loss: 2.632420\tBest loss: 2.615817\tAccuracy: 28.50%\n",
      "318\tValidation loss: 2.627861\tBest loss: 2.615817\tAccuracy: 28.70%\n",
      "319\tValidation loss: 2.629103\tBest loss: 2.615817\tAccuracy: 28.20%\n",
      "320\tValidation loss: 2.603555\tBest loss: 2.603555\tAccuracy: 28.80%\n",
      "321\tValidation loss: 2.614120\tBest loss: 2.603555\tAccuracy: 28.60%\n",
      "322\tValidation loss: 2.608856\tBest loss: 2.603555\tAccuracy: 28.70%\n",
      "323\tValidation loss: 2.571141\tBest loss: 2.571141\tAccuracy: 28.50%\n",
      "324\tValidation loss: 2.605309\tBest loss: 2.571141\tAccuracy: 29.30%\n",
      "325\tValidation loss: 2.597133\tBest loss: 2.571141\tAccuracy: 28.00%\n",
      "326\tValidation loss: 2.576374\tBest loss: 2.571141\tAccuracy: 29.40%\n",
      "327\tValidation loss: 2.589972\tBest loss: 2.571141\tAccuracy: 30.00%\n",
      "328\tValidation loss: 2.588098\tBest loss: 2.571141\tAccuracy: 30.80%\n",
      "329\tValidation loss: 2.574766\tBest loss: 2.571141\tAccuracy: 29.20%\n",
      "330\tValidation loss: 2.587307\tBest loss: 2.571141\tAccuracy: 28.60%\n",
      "331\tValidation loss: 2.576642\tBest loss: 2.571141\tAccuracy: 28.70%\n",
      "332\tValidation loss: 2.583765\tBest loss: 2.571141\tAccuracy: 29.50%\n",
      "333\tValidation loss: 2.596738\tBest loss: 2.571141\tAccuracy: 26.70%\n",
      "334\tValidation loss: 2.607615\tBest loss: 2.571141\tAccuracy: 29.30%\n",
      "335\tValidation loss: 2.571803\tBest loss: 2.571141\tAccuracy: 28.60%\n",
      "336\tValidation loss: 2.577601\tBest loss: 2.571141\tAccuracy: 29.30%\n",
      "337\tValidation loss: 2.579576\tBest loss: 2.571141\tAccuracy: 28.60%\n",
      "338\tValidation loss: 2.560776\tBest loss: 2.560776\tAccuracy: 29.30%\n",
      "339\tValidation loss: 2.569921\tBest loss: 2.560776\tAccuracy: 29.20%\n",
      "340\tValidation loss: 2.543856\tBest loss: 2.543856\tAccuracy: 30.60%\n",
      "341\tValidation loss: 2.537977\tBest loss: 2.537977\tAccuracy: 29.20%\n",
      "342\tValidation loss: 2.578793\tBest loss: 2.537977\tAccuracy: 29.80%\n",
      "343\tValidation loss: 2.550425\tBest loss: 2.537977\tAccuracy: 29.90%\n",
      "344\tValidation loss: 2.558199\tBest loss: 2.537977\tAccuracy: 30.10%\n",
      "345\tValidation loss: 2.534487\tBest loss: 2.534487\tAccuracy: 31.10%\n",
      "346\tValidation loss: 2.552449\tBest loss: 2.534487\tAccuracy: 28.90%\n",
      "347\tValidation loss: 2.597538\tBest loss: 2.534487\tAccuracy: 29.40%\n",
      "348\tValidation loss: 2.561542\tBest loss: 2.534487\tAccuracy: 29.10%\n",
      "349\tValidation loss: 2.540402\tBest loss: 2.534487\tAccuracy: 30.20%\n",
      "350\tValidation loss: 2.565730\tBest loss: 2.534487\tAccuracy: 28.80%\n",
      "351\tValidation loss: 2.572724\tBest loss: 2.534487\tAccuracy: 29.80%\n",
      "352\tValidation loss: 2.532785\tBest loss: 2.532785\tAccuracy: 30.70%\n",
      "353\tValidation loss: 2.517066\tBest loss: 2.517066\tAccuracy: 31.30%\n",
      "354\tValidation loss: 2.557928\tBest loss: 2.517066\tAccuracy: 28.80%\n",
      "355\tValidation loss: 2.506723\tBest loss: 2.506723\tAccuracy: 31.40%\n",
      "356\tValidation loss: 2.527158\tBest loss: 2.506723\tAccuracy: 31.60%\n",
      "357\tValidation loss: 2.536834\tBest loss: 2.506723\tAccuracy: 30.50%\n",
      "358\tValidation loss: 2.537580\tBest loss: 2.506723\tAccuracy: 30.70%\n",
      "359\tValidation loss: 2.538390\tBest loss: 2.506723\tAccuracy: 30.20%\n",
      "360\tValidation loss: 2.552219\tBest loss: 2.506723\tAccuracy: 29.00%\n",
      "361\tValidation loss: 2.520448\tBest loss: 2.506723\tAccuracy: 30.70%\n",
      "362\tValidation loss: 2.546929\tBest loss: 2.506723\tAccuracy: 29.20%\n",
      "363\tValidation loss: 2.516409\tBest loss: 2.506723\tAccuracy: 30.90%\n",
      "364\tValidation loss: 2.540609\tBest loss: 2.506723\tAccuracy: 30.00%\n",
      "365\tValidation loss: 2.512272\tBest loss: 2.506723\tAccuracy: 30.70%\n",
      "366\tValidation loss: 2.519538\tBest loss: 2.506723\tAccuracy: 30.30%\n",
      "367\tValidation loss: 2.523649\tBest loss: 2.506723\tAccuracy: 30.10%\n",
      "368\tValidation loss: 2.479687\tBest loss: 2.479687\tAccuracy: 31.70%\n",
      "369\tValidation loss: 2.510689\tBest loss: 2.479687\tAccuracy: 30.80%\n",
      "370\tValidation loss: 2.510523\tBest loss: 2.479687\tAccuracy: 31.20%\n",
      "371\tValidation loss: 2.519357\tBest loss: 2.479687\tAccuracy: 31.20%\n",
      "372\tValidation loss: 2.511154\tBest loss: 2.479687\tAccuracy: 30.50%\n",
      "373\tValidation loss: 2.472311\tBest loss: 2.472311\tAccuracy: 31.30%\n",
      "374\tValidation loss: 2.476090\tBest loss: 2.472311\tAccuracy: 31.40%\n",
      "375\tValidation loss: 2.499569\tBest loss: 2.472311\tAccuracy: 31.30%\n",
      "376\tValidation loss: 2.512956\tBest loss: 2.472311\tAccuracy: 31.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\tValidation loss: 2.491060\tBest loss: 2.472311\tAccuracy: 31.70%\n",
      "378\tValidation loss: 2.490664\tBest loss: 2.472311\tAccuracy: 31.80%\n",
      "379\tValidation loss: 2.514874\tBest loss: 2.472311\tAccuracy: 31.70%\n",
      "380\tValidation loss: 2.485630\tBest loss: 2.472311\tAccuracy: 31.70%\n",
      "381\tValidation loss: 2.483612\tBest loss: 2.472311\tAccuracy: 32.10%\n",
      "382\tValidation loss: 2.499484\tBest loss: 2.472311\tAccuracy: 31.20%\n",
      "383\tValidation loss: 2.480767\tBest loss: 2.472311\tAccuracy: 32.30%\n",
      "384\tValidation loss: 2.495908\tBest loss: 2.472311\tAccuracy: 31.50%\n",
      "385\tValidation loss: 2.478503\tBest loss: 2.472311\tAccuracy: 30.90%\n",
      "386\tValidation loss: 2.485486\tBest loss: 2.472311\tAccuracy: 32.10%\n",
      "387\tValidation loss: 2.495131\tBest loss: 2.472311\tAccuracy: 32.10%\n",
      "388\tValidation loss: 2.453639\tBest loss: 2.453639\tAccuracy: 31.80%\n",
      "389\tValidation loss: 2.461087\tBest loss: 2.453639\tAccuracy: 32.10%\n",
      "390\tValidation loss: 2.479485\tBest loss: 2.453639\tAccuracy: 32.30%\n",
      "391\tValidation loss: 2.468563\tBest loss: 2.453639\tAccuracy: 32.80%\n",
      "392\tValidation loss: 2.492180\tBest loss: 2.453639\tAccuracy: 32.20%\n",
      "393\tValidation loss: 2.478159\tBest loss: 2.453639\tAccuracy: 31.90%\n",
      "394\tValidation loss: 2.456074\tBest loss: 2.453639\tAccuracy: 31.90%\n",
      "395\tValidation loss: 2.459493\tBest loss: 2.453639\tAccuracy: 33.40%\n",
      "396\tValidation loss: 2.435743\tBest loss: 2.435743\tAccuracy: 32.80%\n",
      "397\tValidation loss: 2.452818\tBest loss: 2.435743\tAccuracy: 33.30%\n",
      "398\tValidation loss: 2.457546\tBest loss: 2.435743\tAccuracy: 32.90%\n",
      "399\tValidation loss: 2.438766\tBest loss: 2.435743\tAccuracy: 33.40%\n",
      "400\tValidation loss: 2.468403\tBest loss: 2.435743\tAccuracy: 33.80%\n",
      "401\tValidation loss: 2.462613\tBest loss: 2.435743\tAccuracy: 31.60%\n",
      "402\tValidation loss: 2.449134\tBest loss: 2.435743\tAccuracy: 33.30%\n",
      "403\tValidation loss: 2.435204\tBest loss: 2.435204\tAccuracy: 32.30%\n",
      "404\tValidation loss: 2.448771\tBest loss: 2.435204\tAccuracy: 32.50%\n",
      "405\tValidation loss: 2.446533\tBest loss: 2.435204\tAccuracy: 32.10%\n",
      "406\tValidation loss: 2.445577\tBest loss: 2.435204\tAccuracy: 33.40%\n",
      "407\tValidation loss: 2.430640\tBest loss: 2.430640\tAccuracy: 33.30%\n",
      "408\tValidation loss: 2.441399\tBest loss: 2.430640\tAccuracy: 33.10%\n",
      "409\tValidation loss: 2.427525\tBest loss: 2.427525\tAccuracy: 34.30%\n",
      "410\tValidation loss: 2.444597\tBest loss: 2.427525\tAccuracy: 33.50%\n",
      "411\tValidation loss: 2.447806\tBest loss: 2.427525\tAccuracy: 32.80%\n",
      "412\tValidation loss: 2.455225\tBest loss: 2.427525\tAccuracy: 32.90%\n",
      "413\tValidation loss: 2.434843\tBest loss: 2.427525\tAccuracy: 33.80%\n",
      "414\tValidation loss: 2.446828\tBest loss: 2.427525\tAccuracy: 32.20%\n",
      "415\tValidation loss: 2.422364\tBest loss: 2.422364\tAccuracy: 32.10%\n",
      "416\tValidation loss: 2.438102\tBest loss: 2.422364\tAccuracy: 33.00%\n",
      "417\tValidation loss: 2.445765\tBest loss: 2.422364\tAccuracy: 33.40%\n",
      "418\tValidation loss: 2.461411\tBest loss: 2.422364\tAccuracy: 33.50%\n",
      "419\tValidation loss: 2.426997\tBest loss: 2.422364\tAccuracy: 32.70%\n",
      "420\tValidation loss: 2.421220\tBest loss: 2.421220\tAccuracy: 33.80%\n",
      "421\tValidation loss: 2.429065\tBest loss: 2.421220\tAccuracy: 33.80%\n",
      "422\tValidation loss: 2.451107\tBest loss: 2.421220\tAccuracy: 32.90%\n",
      "423\tValidation loss: 2.434352\tBest loss: 2.421220\tAccuracy: 33.00%\n",
      "424\tValidation loss: 2.430762\tBest loss: 2.421220\tAccuracy: 32.70%\n",
      "425\tValidation loss: 2.434261\tBest loss: 2.421220\tAccuracy: 33.90%\n",
      "426\tValidation loss: 2.411005\tBest loss: 2.411005\tAccuracy: 33.40%\n",
      "427\tValidation loss: 2.426395\tBest loss: 2.411005\tAccuracy: 33.50%\n",
      "428\tValidation loss: 2.404342\tBest loss: 2.404342\tAccuracy: 33.50%\n",
      "429\tValidation loss: 2.416724\tBest loss: 2.404342\tAccuracy: 32.60%\n",
      "430\tValidation loss: 2.396393\tBest loss: 2.396393\tAccuracy: 33.00%\n",
      "431\tValidation loss: 2.406421\tBest loss: 2.396393\tAccuracy: 33.00%\n",
      "432\tValidation loss: 2.401215\tBest loss: 2.396393\tAccuracy: 33.30%\n",
      "433\tValidation loss: 2.402003\tBest loss: 2.396393\tAccuracy: 33.40%\n",
      "434\tValidation loss: 2.413991\tBest loss: 2.396393\tAccuracy: 33.90%\n",
      "435\tValidation loss: 2.411826\tBest loss: 2.396393\tAccuracy: 32.70%\n",
      "436\tValidation loss: 2.401876\tBest loss: 2.396393\tAccuracy: 34.10%\n",
      "437\tValidation loss: 2.380454\tBest loss: 2.380454\tAccuracy: 33.40%\n",
      "438\tValidation loss: 2.387917\tBest loss: 2.380454\tAccuracy: 33.50%\n",
      "439\tValidation loss: 2.383815\tBest loss: 2.380454\tAccuracy: 34.50%\n",
      "440\tValidation loss: 2.399752\tBest loss: 2.380454\tAccuracy: 34.40%\n",
      "441\tValidation loss: 2.392440\tBest loss: 2.380454\tAccuracy: 34.40%\n",
      "442\tValidation loss: 2.386653\tBest loss: 2.380454\tAccuracy: 33.60%\n",
      "443\tValidation loss: 2.381875\tBest loss: 2.380454\tAccuracy: 33.30%\n",
      "444\tValidation loss: 2.398505\tBest loss: 2.380454\tAccuracy: 33.90%\n",
      "445\tValidation loss: 2.391325\tBest loss: 2.380454\tAccuracy: 34.00%\n",
      "446\tValidation loss: 2.395532\tBest loss: 2.380454\tAccuracy: 34.40%\n",
      "447\tValidation loss: 2.378691\tBest loss: 2.378691\tAccuracy: 34.80%\n",
      "448\tValidation loss: 2.373554\tBest loss: 2.373554\tAccuracy: 34.80%\n",
      "449\tValidation loss: 2.399672\tBest loss: 2.373554\tAccuracy: 33.30%\n",
      "450\tValidation loss: 2.398531\tBest loss: 2.373554\tAccuracy: 33.40%\n",
      "451\tValidation loss: 2.372629\tBest loss: 2.372629\tAccuracy: 34.40%\n",
      "452\tValidation loss: 2.385470\tBest loss: 2.372629\tAccuracy: 33.70%\n",
      "453\tValidation loss: 2.394650\tBest loss: 2.372629\tAccuracy: 34.70%\n",
      "454\tValidation loss: 2.379038\tBest loss: 2.372629\tAccuracy: 34.00%\n",
      "455\tValidation loss: 2.373698\tBest loss: 2.372629\tAccuracy: 34.40%\n",
      "456\tValidation loss: 2.382240\tBest loss: 2.372629\tAccuracy: 34.20%\n",
      "457\tValidation loss: 2.366702\tBest loss: 2.366702\tAccuracy: 35.00%\n",
      "458\tValidation loss: 2.370635\tBest loss: 2.366702\tAccuracy: 33.80%\n",
      "459\tValidation loss: 2.372713\tBest loss: 2.366702\tAccuracy: 35.20%\n",
      "460\tValidation loss: 2.348758\tBest loss: 2.348758\tAccuracy: 35.00%\n",
      "461\tValidation loss: 2.365648\tBest loss: 2.348758\tAccuracy: 34.70%\n",
      "462\tValidation loss: 2.385729\tBest loss: 2.348758\tAccuracy: 33.80%\n",
      "463\tValidation loss: 2.371097\tBest loss: 2.348758\tAccuracy: 35.20%\n",
      "464\tValidation loss: 2.350088\tBest loss: 2.348758\tAccuracy: 35.20%\n",
      "465\tValidation loss: 2.337709\tBest loss: 2.337709\tAccuracy: 35.60%\n",
      "466\tValidation loss: 2.341342\tBest loss: 2.337709\tAccuracy: 34.80%\n",
      "467\tValidation loss: 2.358792\tBest loss: 2.337709\tAccuracy: 33.40%\n",
      "468\tValidation loss: 2.374285\tBest loss: 2.337709\tAccuracy: 34.40%\n",
      "469\tValidation loss: 2.369065\tBest loss: 2.337709\tAccuracy: 34.70%\n",
      "470\tValidation loss: 2.345213\tBest loss: 2.337709\tAccuracy: 35.10%\n",
      "471\tValidation loss: 2.348280\tBest loss: 2.337709\tAccuracy: 35.60%\n",
      "472\tValidation loss: 2.375458\tBest loss: 2.337709\tAccuracy: 33.20%\n",
      "473\tValidation loss: 2.353426\tBest loss: 2.337709\tAccuracy: 35.10%\n",
      "474\tValidation loss: 2.362369\tBest loss: 2.337709\tAccuracy: 34.00%\n",
      "475\tValidation loss: 2.350814\tBest loss: 2.337709\tAccuracy: 34.70%\n",
      "476\tValidation loss: 2.353417\tBest loss: 2.337709\tAccuracy: 34.70%\n",
      "477\tValidation loss: 2.345294\tBest loss: 2.337709\tAccuracy: 34.20%\n",
      "478\tValidation loss: 2.360688\tBest loss: 2.337709\tAccuracy: 35.00%\n",
      "479\tValidation loss: 2.358109\tBest loss: 2.337709\tAccuracy: 34.00%\n",
      "480\tValidation loss: 2.335079\tBest loss: 2.335079\tAccuracy: 35.80%\n",
      "481\tValidation loss: 2.321591\tBest loss: 2.321591\tAccuracy: 35.30%\n",
      "482\tValidation loss: 2.353753\tBest loss: 2.321591\tAccuracy: 34.10%\n",
      "483\tValidation loss: 2.338003\tBest loss: 2.321591\tAccuracy: 35.20%\n",
      "484\tValidation loss: 2.308662\tBest loss: 2.308662\tAccuracy: 37.40%\n",
      "485\tValidation loss: 2.344059\tBest loss: 2.308662\tAccuracy: 36.80%\n",
      "486\tValidation loss: 2.334433\tBest loss: 2.308662\tAccuracy: 35.60%\n",
      "487\tValidation loss: 2.321113\tBest loss: 2.308662\tAccuracy: 35.80%\n",
      "488\tValidation loss: 2.331211\tBest loss: 2.308662\tAccuracy: 36.40%\n",
      "489\tValidation loss: 2.340399\tBest loss: 2.308662\tAccuracy: 34.90%\n",
      "490\tValidation loss: 2.332062\tBest loss: 2.308662\tAccuracy: 35.90%\n",
      "491\tValidation loss: 2.350576\tBest loss: 2.308662\tAccuracy: 35.90%\n",
      "492\tValidation loss: 2.341145\tBest loss: 2.308662\tAccuracy: 35.60%\n",
      "493\tValidation loss: 2.333914\tBest loss: 2.308662\tAccuracy: 35.90%\n",
      "494\tValidation loss: 2.350559\tBest loss: 2.308662\tAccuracy: 35.10%\n",
      "495\tValidation loss: 2.333461\tBest loss: 2.308662\tAccuracy: 34.80%\n",
      "496\tValidation loss: 2.346023\tBest loss: 2.308662\tAccuracy: 35.10%\n",
      "497\tValidation loss: 2.326939\tBest loss: 2.308662\tAccuracy: 36.50%\n",
      "498\tValidation loss: 2.319806\tBest loss: 2.308662\tAccuracy: 35.40%\n",
      "499\tValidation loss: 2.323430\tBest loss: 2.308662\tAccuracy: 37.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\tValidation loss: 2.319073\tBest loss: 2.308662\tAccuracy: 36.60%\n",
      "501\tValidation loss: 2.312105\tBest loss: 2.308662\tAccuracy: 37.10%\n",
      "502\tValidation loss: 2.337144\tBest loss: 2.308662\tAccuracy: 36.20%\n",
      "503\tValidation loss: 2.300713\tBest loss: 2.300713\tAccuracy: 36.50%\n",
      "504\tValidation loss: 2.326991\tBest loss: 2.300713\tAccuracy: 35.50%\n",
      "505\tValidation loss: 2.320380\tBest loss: 2.300713\tAccuracy: 35.90%\n",
      "506\tValidation loss: 2.299444\tBest loss: 2.299444\tAccuracy: 36.10%\n",
      "507\tValidation loss: 2.312384\tBest loss: 2.299444\tAccuracy: 37.40%\n",
      "508\tValidation loss: 2.324762\tBest loss: 2.299444\tAccuracy: 34.80%\n",
      "509\tValidation loss: 2.314852\tBest loss: 2.299444\tAccuracy: 35.80%\n",
      "510\tValidation loss: 2.318892\tBest loss: 2.299444\tAccuracy: 36.30%\n",
      "511\tValidation loss: 2.327444\tBest loss: 2.299444\tAccuracy: 35.80%\n",
      "512\tValidation loss: 2.294325\tBest loss: 2.294325\tAccuracy: 35.90%\n",
      "513\tValidation loss: 2.314309\tBest loss: 2.294325\tAccuracy: 35.80%\n",
      "514\tValidation loss: 2.322269\tBest loss: 2.294325\tAccuracy: 35.90%\n",
      "515\tValidation loss: 2.319134\tBest loss: 2.294325\tAccuracy: 36.50%\n",
      "516\tValidation loss: 2.312999\tBest loss: 2.294325\tAccuracy: 35.30%\n",
      "517\tValidation loss: 2.305919\tBest loss: 2.294325\tAccuracy: 36.30%\n",
      "518\tValidation loss: 2.314997\tBest loss: 2.294325\tAccuracy: 37.70%\n",
      "519\tValidation loss: 2.309171\tBest loss: 2.294325\tAccuracy: 37.20%\n",
      "520\tValidation loss: 2.307328\tBest loss: 2.294325\tAccuracy: 37.30%\n",
      "521\tValidation loss: 2.289144\tBest loss: 2.289144\tAccuracy: 37.10%\n",
      "522\tValidation loss: 2.313669\tBest loss: 2.289144\tAccuracy: 36.50%\n",
      "523\tValidation loss: 2.312123\tBest loss: 2.289144\tAccuracy: 36.10%\n",
      "524\tValidation loss: 2.285914\tBest loss: 2.285914\tAccuracy: 37.60%\n",
      "525\tValidation loss: 2.302456\tBest loss: 2.285914\tAccuracy: 35.90%\n",
      "526\tValidation loss: 2.306965\tBest loss: 2.285914\tAccuracy: 36.20%\n",
      "527\tValidation loss: 2.312247\tBest loss: 2.285914\tAccuracy: 36.40%\n",
      "528\tValidation loss: 2.288244\tBest loss: 2.285914\tAccuracy: 36.40%\n",
      "529\tValidation loss: 2.299971\tBest loss: 2.285914\tAccuracy: 36.50%\n",
      "530\tValidation loss: 2.300967\tBest loss: 2.285914\tAccuracy: 36.50%\n",
      "531\tValidation loss: 2.296212\tBest loss: 2.285914\tAccuracy: 35.90%\n",
      "532\tValidation loss: 2.288003\tBest loss: 2.285914\tAccuracy: 37.50%\n",
      "533\tValidation loss: 2.280499\tBest loss: 2.280499\tAccuracy: 37.20%\n",
      "534\tValidation loss: 2.281439\tBest loss: 2.280499\tAccuracy: 37.30%\n",
      "535\tValidation loss: 2.300699\tBest loss: 2.280499\tAccuracy: 36.20%\n",
      "536\tValidation loss: 2.279282\tBest loss: 2.279282\tAccuracy: 36.80%\n",
      "537\tValidation loss: 2.294652\tBest loss: 2.279282\tAccuracy: 35.80%\n",
      "538\tValidation loss: 2.272665\tBest loss: 2.272665\tAccuracy: 37.30%\n",
      "539\tValidation loss: 2.291939\tBest loss: 2.272665\tAccuracy: 37.10%\n",
      "540\tValidation loss: 2.271496\tBest loss: 2.271496\tAccuracy: 38.50%\n",
      "541\tValidation loss: 2.288292\tBest loss: 2.271496\tAccuracy: 37.20%\n",
      "542\tValidation loss: 2.286232\tBest loss: 2.271496\tAccuracy: 36.90%\n",
      "543\tValidation loss: 2.268160\tBest loss: 2.268160\tAccuracy: 37.40%\n",
      "544\tValidation loss: 2.265006\tBest loss: 2.265006\tAccuracy: 37.20%\n",
      "545\tValidation loss: 2.277506\tBest loss: 2.265006\tAccuracy: 36.30%\n",
      "546\tValidation loss: 2.293519\tBest loss: 2.265006\tAccuracy: 36.50%\n",
      "547\tValidation loss: 2.296570\tBest loss: 2.265006\tAccuracy: 36.70%\n",
      "548\tValidation loss: 2.279860\tBest loss: 2.265006\tAccuracy: 37.40%\n",
      "549\tValidation loss: 2.284612\tBest loss: 2.265006\tAccuracy: 38.00%\n",
      "550\tValidation loss: 2.280403\tBest loss: 2.265006\tAccuracy: 37.60%\n",
      "551\tValidation loss: 2.274362\tBest loss: 2.265006\tAccuracy: 37.50%\n",
      "552\tValidation loss: 2.268713\tBest loss: 2.265006\tAccuracy: 38.10%\n",
      "553\tValidation loss: 2.270948\tBest loss: 2.265006\tAccuracy: 36.60%\n",
      "554\tValidation loss: 2.288734\tBest loss: 2.265006\tAccuracy: 37.60%\n",
      "555\tValidation loss: 2.256517\tBest loss: 2.256517\tAccuracy: 38.30%\n",
      "556\tValidation loss: 2.268411\tBest loss: 2.256517\tAccuracy: 38.50%\n",
      "557\tValidation loss: 2.248666\tBest loss: 2.248666\tAccuracy: 38.80%\n",
      "558\tValidation loss: 2.265081\tBest loss: 2.248666\tAccuracy: 37.50%\n",
      "559\tValidation loss: 2.268382\tBest loss: 2.248666\tAccuracy: 38.10%\n",
      "560\tValidation loss: 2.256774\tBest loss: 2.248666\tAccuracy: 38.00%\n",
      "561\tValidation loss: 2.247869\tBest loss: 2.247869\tAccuracy: 37.90%\n",
      "562\tValidation loss: 2.245194\tBest loss: 2.245194\tAccuracy: 37.60%\n",
      "563\tValidation loss: 2.246263\tBest loss: 2.245194\tAccuracy: 38.80%\n",
      "564\tValidation loss: 2.253267\tBest loss: 2.245194\tAccuracy: 39.10%\n",
      "565\tValidation loss: 2.256316\tBest loss: 2.245194\tAccuracy: 37.80%\n",
      "566\tValidation loss: 2.266653\tBest loss: 2.245194\tAccuracy: 37.00%\n",
      "567\tValidation loss: 2.266032\tBest loss: 2.245194\tAccuracy: 36.70%\n",
      "568\tValidation loss: 2.233560\tBest loss: 2.233560\tAccuracy: 38.80%\n",
      "569\tValidation loss: 2.257934\tBest loss: 2.233560\tAccuracy: 38.30%\n",
      "570\tValidation loss: 2.248466\tBest loss: 2.233560\tAccuracy: 39.20%\n",
      "571\tValidation loss: 2.243498\tBest loss: 2.233560\tAccuracy: 39.40%\n",
      "572\tValidation loss: 2.253906\tBest loss: 2.233560\tAccuracy: 38.70%\n",
      "573\tValidation loss: 2.247610\tBest loss: 2.233560\tAccuracy: 38.40%\n",
      "574\tValidation loss: 2.227147\tBest loss: 2.227147\tAccuracy: 39.40%\n",
      "575\tValidation loss: 2.238739\tBest loss: 2.227147\tAccuracy: 39.40%\n",
      "576\tValidation loss: 2.236964\tBest loss: 2.227147\tAccuracy: 39.00%\n",
      "577\tValidation loss: 2.268701\tBest loss: 2.227147\tAccuracy: 37.90%\n",
      "578\tValidation loss: 2.232633\tBest loss: 2.227147\tAccuracy: 38.10%\n",
      "579\tValidation loss: 2.230714\tBest loss: 2.227147\tAccuracy: 38.50%\n",
      "580\tValidation loss: 2.233057\tBest loss: 2.227147\tAccuracy: 37.80%\n",
      "581\tValidation loss: 2.237992\tBest loss: 2.227147\tAccuracy: 38.10%\n",
      "582\tValidation loss: 2.248950\tBest loss: 2.227147\tAccuracy: 37.90%\n",
      "583\tValidation loss: 2.242578\tBest loss: 2.227147\tAccuracy: 38.50%\n",
      "584\tValidation loss: 2.240937\tBest loss: 2.227147\tAccuracy: 38.50%\n",
      "585\tValidation loss: 2.262983\tBest loss: 2.227147\tAccuracy: 37.40%\n",
      "586\tValidation loss: 2.231037\tBest loss: 2.227147\tAccuracy: 37.80%\n",
      "587\tValidation loss: 2.219320\tBest loss: 2.219320\tAccuracy: 39.00%\n",
      "588\tValidation loss: 2.256379\tBest loss: 2.219320\tAccuracy: 38.00%\n",
      "589\tValidation loss: 2.260804\tBest loss: 2.219320\tAccuracy: 37.40%\n",
      "590\tValidation loss: 2.227188\tBest loss: 2.219320\tAccuracy: 38.90%\n",
      "591\tValidation loss: 2.232759\tBest loss: 2.219320\tAccuracy: 38.50%\n",
      "592\tValidation loss: 2.237985\tBest loss: 2.219320\tAccuracy: 37.70%\n",
      "593\tValidation loss: 2.241858\tBest loss: 2.219320\tAccuracy: 38.50%\n",
      "594\tValidation loss: 2.226295\tBest loss: 2.219320\tAccuracy: 38.80%\n",
      "595\tValidation loss: 2.246053\tBest loss: 2.219320\tAccuracy: 37.60%\n",
      "596\tValidation loss: 2.235724\tBest loss: 2.219320\tAccuracy: 37.90%\n",
      "597\tValidation loss: 2.230248\tBest loss: 2.219320\tAccuracy: 37.30%\n",
      "598\tValidation loss: 2.220147\tBest loss: 2.219320\tAccuracy: 38.40%\n",
      "599\tValidation loss: 2.226118\tBest loss: 2.219320\tAccuracy: 37.80%\n",
      "600\tValidation loss: 2.238194\tBest loss: 2.219320\tAccuracy: 37.80%\n",
      "601\tValidation loss: 2.235557\tBest loss: 2.219320\tAccuracy: 38.00%\n",
      "602\tValidation loss: 2.225498\tBest loss: 2.219320\tAccuracy: 38.80%\n",
      "603\tValidation loss: 2.214984\tBest loss: 2.214984\tAccuracy: 38.20%\n",
      "604\tValidation loss: 2.248465\tBest loss: 2.214984\tAccuracy: 37.10%\n",
      "605\tValidation loss: 2.222823\tBest loss: 2.214984\tAccuracy: 37.70%\n",
      "606\tValidation loss: 2.215456\tBest loss: 2.214984\tAccuracy: 37.90%\n",
      "607\tValidation loss: 2.217845\tBest loss: 2.214984\tAccuracy: 38.20%\n",
      "608\tValidation loss: 2.232719\tBest loss: 2.214984\tAccuracy: 38.60%\n",
      "609\tValidation loss: 2.224871\tBest loss: 2.214984\tAccuracy: 38.80%\n",
      "610\tValidation loss: 2.232591\tBest loss: 2.214984\tAccuracy: 38.50%\n",
      "611\tValidation loss: 2.204029\tBest loss: 2.204029\tAccuracy: 38.60%\n",
      "612\tValidation loss: 2.213598\tBest loss: 2.204029\tAccuracy: 37.80%\n",
      "613\tValidation loss: 2.214556\tBest loss: 2.204029\tAccuracy: 38.40%\n",
      "614\tValidation loss: 2.219154\tBest loss: 2.204029\tAccuracy: 37.80%\n",
      "615\tValidation loss: 2.204894\tBest loss: 2.204029\tAccuracy: 37.60%\n",
      "616\tValidation loss: 2.215090\tBest loss: 2.204029\tAccuracy: 39.00%\n",
      "617\tValidation loss: 2.223058\tBest loss: 2.204029\tAccuracy: 38.80%\n",
      "618\tValidation loss: 2.228180\tBest loss: 2.204029\tAccuracy: 37.60%\n",
      "619\tValidation loss: 2.205262\tBest loss: 2.204029\tAccuracy: 39.30%\n",
      "620\tValidation loss: 2.208090\tBest loss: 2.204029\tAccuracy: 37.80%\n",
      "621\tValidation loss: 2.210268\tBest loss: 2.204029\tAccuracy: 37.50%\n",
      "622\tValidation loss: 2.211166\tBest loss: 2.204029\tAccuracy: 37.40%\n",
      "623\tValidation loss: 2.205031\tBest loss: 2.204029\tAccuracy: 39.20%\n",
      "624\tValidation loss: 2.203969\tBest loss: 2.203969\tAccuracy: 38.60%\n",
      "625\tValidation loss: 2.210291\tBest loss: 2.203969\tAccuracy: 39.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\tValidation loss: 2.182834\tBest loss: 2.182834\tAccuracy: 39.50%\n",
      "627\tValidation loss: 2.202872\tBest loss: 2.182834\tAccuracy: 38.40%\n",
      "628\tValidation loss: 2.197843\tBest loss: 2.182834\tAccuracy: 39.70%\n",
      "629\tValidation loss: 2.198847\tBest loss: 2.182834\tAccuracy: 39.40%\n",
      "630\tValidation loss: 2.210244\tBest loss: 2.182834\tAccuracy: 39.00%\n",
      "631\tValidation loss: 2.203810\tBest loss: 2.182834\tAccuracy: 39.60%\n",
      "632\tValidation loss: 2.198455\tBest loss: 2.182834\tAccuracy: 38.60%\n",
      "633\tValidation loss: 2.202831\tBest loss: 2.182834\tAccuracy: 39.70%\n",
      "634\tValidation loss: 2.215244\tBest loss: 2.182834\tAccuracy: 40.00%\n",
      "635\tValidation loss: 2.187905\tBest loss: 2.182834\tAccuracy: 39.40%\n",
      "636\tValidation loss: 2.192832\tBest loss: 2.182834\tAccuracy: 39.70%\n",
      "637\tValidation loss: 2.201940\tBest loss: 2.182834\tAccuracy: 39.30%\n",
      "638\tValidation loss: 2.189536\tBest loss: 2.182834\tAccuracy: 38.80%\n",
      "639\tValidation loss: 2.181879\tBest loss: 2.181879\tAccuracy: 40.00%\n",
      "640\tValidation loss: 2.185244\tBest loss: 2.181879\tAccuracy: 38.60%\n",
      "641\tValidation loss: 2.187673\tBest loss: 2.181879\tAccuracy: 38.60%\n",
      "642\tValidation loss: 2.210734\tBest loss: 2.181879\tAccuracy: 37.70%\n",
      "643\tValidation loss: 2.181417\tBest loss: 2.181417\tAccuracy: 40.00%\n",
      "644\tValidation loss: 2.192980\tBest loss: 2.181417\tAccuracy: 38.70%\n",
      "645\tValidation loss: 2.197298\tBest loss: 2.181417\tAccuracy: 38.60%\n",
      "646\tValidation loss: 2.182794\tBest loss: 2.181417\tAccuracy: 39.30%\n",
      "647\tValidation loss: 2.186390\tBest loss: 2.181417\tAccuracy: 39.70%\n",
      "648\tValidation loss: 2.172887\tBest loss: 2.172887\tAccuracy: 38.50%\n",
      "649\tValidation loss: 2.184174\tBest loss: 2.172887\tAccuracy: 39.40%\n",
      "650\tValidation loss: 2.170708\tBest loss: 2.170708\tAccuracy: 38.80%\n",
      "651\tValidation loss: 2.181747\tBest loss: 2.170708\tAccuracy: 39.90%\n",
      "652\tValidation loss: 2.163934\tBest loss: 2.163934\tAccuracy: 39.70%\n",
      "653\tValidation loss: 2.175711\tBest loss: 2.163934\tAccuracy: 40.10%\n",
      "654\tValidation loss: 2.179712\tBest loss: 2.163934\tAccuracy: 40.50%\n",
      "655\tValidation loss: 2.165758\tBest loss: 2.163934\tAccuracy: 39.60%\n",
      "656\tValidation loss: 2.190510\tBest loss: 2.163934\tAccuracy: 38.70%\n",
      "657\tValidation loss: 2.197392\tBest loss: 2.163934\tAccuracy: 40.00%\n",
      "658\tValidation loss: 2.187029\tBest loss: 2.163934\tAccuracy: 38.80%\n",
      "659\tValidation loss: 2.164376\tBest loss: 2.163934\tAccuracy: 39.90%\n",
      "660\tValidation loss: 2.187648\tBest loss: 2.163934\tAccuracy: 38.60%\n",
      "661\tValidation loss: 2.195789\tBest loss: 2.163934\tAccuracy: 38.70%\n",
      "662\tValidation loss: 2.189595\tBest loss: 2.163934\tAccuracy: 39.00%\n",
      "663\tValidation loss: 2.169431\tBest loss: 2.163934\tAccuracy: 40.00%\n",
      "664\tValidation loss: 2.195455\tBest loss: 2.163934\tAccuracy: 38.60%\n",
      "665\tValidation loss: 2.192141\tBest loss: 2.163934\tAccuracy: 39.90%\n",
      "666\tValidation loss: 2.169755\tBest loss: 2.163934\tAccuracy: 39.50%\n",
      "667\tValidation loss: 2.174754\tBest loss: 2.163934\tAccuracy: 39.10%\n",
      "668\tValidation loss: 2.163983\tBest loss: 2.163934\tAccuracy: 40.30%\n",
      "669\tValidation loss: 2.173826\tBest loss: 2.163934\tAccuracy: 40.30%\n",
      "670\tValidation loss: 2.179295\tBest loss: 2.163934\tAccuracy: 38.60%\n",
      "671\tValidation loss: 2.183476\tBest loss: 2.163934\tAccuracy: 39.00%\n",
      "672\tValidation loss: 2.164621\tBest loss: 2.163934\tAccuracy: 39.20%\n",
      "673\tValidation loss: 2.179048\tBest loss: 2.163934\tAccuracy: 38.60%\n",
      "Early stopping!\n",
      "[[  1.55336907e-04   2.11560037e-02   5.00390399e-03 ...,   4.78484752e-10\n",
      "    7.86916462e-06   4.89870035e-06]\n",
      " [  1.08722545e-01   4.26843241e-02   7.96520486e-02 ...,   6.47901418e-03\n",
      "    4.37212875e-03   2.87881563e-03]\n",
      " [  9.17289406e-03   4.07330708e-06   5.65511398e-02 ...,   3.02037679e-05\n",
      "    8.63877148e-08   2.36738118e-09]\n",
      " ..., \n",
      " [  3.81386699e-03   1.34935947e-02   3.72854085e-03 ...,   7.74166896e-04\n",
      "    5.09810913e-03   1.82700856e-03]\n",
      " [  4.84576542e-03   6.66010845e-03   4.86714160e-03 ...,   9.97736454e-02\n",
      "    3.31763215e-02   4.39337976e-02]\n",
      " [  2.35710479e-03   7.91114697e-04   2.06200313e-03 ...,   1.91193745e-02\n",
      "    9.86350980e-03   1.61238220e-02]]\n",
      "[ 9  0 16 ...,  6 45  8]\n",
      "[[  3.83001682e-03   5.90247894e-03   9.13893990e-03 ...,   4.95170616e-02\n",
      "    8.28991737e-03   1.10825710e-02]\n",
      " [  4.30345644e-05   9.86237172e-03   1.25199044e-03 ...,   7.98568156e-11\n",
      "    1.58991259e-06   5.20490858e-07]\n",
      " [  8.35384184e-04   4.83077019e-03   2.63510132e-03 ...,   6.36161349e-05\n",
      "    7.73477717e-04   4.54313995e-04]\n",
      " ..., \n",
      " [  9.81515087e-03   5.19548394e-02   7.98605103e-03 ...,   3.84454106e-05\n",
      "    5.35961117e-05   8.20007153e-06]\n",
      " [  3.96419391e-02   1.48704881e-02   2.80203111e-02 ...,   1.52078634e-02\n",
      "    1.27121918e-02   1.09855607e-02]\n",
      " [  1.05522822e-05   1.73787688e-04   1.72259715e-05 ...,   7.30618536e-02\n",
      "    6.12861440e-02   1.39766768e-01]]\n",
      "[26 43  9 ...,  6  9  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  35.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.869473\tBest loss: 3.869473\tAccuracy: 4.00%\n",
      "1\tValidation loss: 3.858691\tBest loss: 3.858691\tAccuracy: 3.90%\n",
      "2\tValidation loss: 3.847337\tBest loss: 3.847337\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.838050\tBest loss: 3.838050\tAccuracy: 4.10%\n",
      "4\tValidation loss: 3.833459\tBest loss: 3.833459\tAccuracy: 4.10%\n",
      "5\tValidation loss: 3.828053\tBest loss: 3.828053\tAccuracy: 4.10%\n",
      "6\tValidation loss: 3.822744\tBest loss: 3.822744\tAccuracy: 4.20%\n",
      "7\tValidation loss: 3.819656\tBest loss: 3.819656\tAccuracy: 4.00%\n",
      "8\tValidation loss: 3.814679\tBest loss: 3.814679\tAccuracy: 4.20%\n",
      "9\tValidation loss: 3.809735\tBest loss: 3.809735\tAccuracy: 4.20%\n",
      "10\tValidation loss: 3.808975\tBest loss: 3.808975\tAccuracy: 4.20%\n",
      "11\tValidation loss: 3.804837\tBest loss: 3.804837\tAccuracy: 4.20%\n",
      "12\tValidation loss: 3.800625\tBest loss: 3.800625\tAccuracy: 4.20%\n",
      "13\tValidation loss: 3.797501\tBest loss: 3.797501\tAccuracy: 4.20%\n",
      "14\tValidation loss: 3.793960\tBest loss: 3.793960\tAccuracy: 4.30%\n",
      "15\tValidation loss: 3.792992\tBest loss: 3.792992\tAccuracy: 4.30%\n",
      "16\tValidation loss: 3.791054\tBest loss: 3.791054\tAccuracy: 4.30%\n",
      "17\tValidation loss: 3.789606\tBest loss: 3.789606\tAccuracy: 4.30%\n",
      "18\tValidation loss: 3.788078\tBest loss: 3.788078\tAccuracy: 4.30%\n",
      "19\tValidation loss: 3.788125\tBest loss: 3.788078\tAccuracy: 4.20%\n",
      "20\tValidation loss: 3.784904\tBest loss: 3.784904\tAccuracy: 4.20%\n",
      "21\tValidation loss: 3.782717\tBest loss: 3.782717\tAccuracy: 4.30%\n",
      "22\tValidation loss: 3.785373\tBest loss: 3.782717\tAccuracy: 4.00%\n",
      "23\tValidation loss: 3.781595\tBest loss: 3.781595\tAccuracy: 4.20%\n",
      "24\tValidation loss: 3.782452\tBest loss: 3.781595\tAccuracy: 4.20%\n",
      "25\tValidation loss: 3.780712\tBest loss: 3.780712\tAccuracy: 4.30%\n",
      "26\tValidation loss: 3.779455\tBest loss: 3.779455\tAccuracy: 4.20%\n",
      "27\tValidation loss: 3.780271\tBest loss: 3.779455\tAccuracy: 4.00%\n",
      "28\tValidation loss: 3.788150\tBest loss: 3.779455\tAccuracy: 3.90%\n",
      "29\tValidation loss: 3.779624\tBest loss: 3.779455\tAccuracy: 4.00%\n",
      "30\tValidation loss: 3.774974\tBest loss: 3.774974\tAccuracy: 4.20%\n",
      "31\tValidation loss: 3.773724\tBest loss: 3.773724\tAccuracy: 4.00%\n",
      "32\tValidation loss: 3.778085\tBest loss: 3.773724\tAccuracy: 4.10%\n",
      "33\tValidation loss: 3.765602\tBest loss: 3.765602\tAccuracy: 4.70%\n",
      "34\tValidation loss: 3.762906\tBest loss: 3.762906\tAccuracy: 4.70%\n",
      "35\tValidation loss: 3.774562\tBest loss: 3.762906\tAccuracy: 3.90%\n",
      "36\tValidation loss: 3.769098\tBest loss: 3.762906\tAccuracy: 4.30%\n",
      "37\tValidation loss: 3.761430\tBest loss: 3.761430\tAccuracy: 4.30%\n",
      "38\tValidation loss: 3.756822\tBest loss: 3.756822\tAccuracy: 4.50%\n",
      "39\tValidation loss: 3.761352\tBest loss: 3.756822\tAccuracy: 4.00%\n",
      "40\tValidation loss: 3.755986\tBest loss: 3.755986\tAccuracy: 4.10%\n",
      "41\tValidation loss: 3.749996\tBest loss: 3.749996\tAccuracy: 4.30%\n",
      "42\tValidation loss: 3.755221\tBest loss: 3.749996\tAccuracy: 4.10%\n",
      "43\tValidation loss: 3.740106\tBest loss: 3.740106\tAccuracy: 4.60%\n",
      "44\tValidation loss: 3.734640\tBest loss: 3.734640\tAccuracy: 4.60%\n",
      "45\tValidation loss: 3.734739\tBest loss: 3.734640\tAccuracy: 4.40%\n",
      "46\tValidation loss: 3.725746\tBest loss: 3.725746\tAccuracy: 4.70%\n",
      "47\tValidation loss: 3.727985\tBest loss: 3.725746\tAccuracy: 4.60%\n",
      "48\tValidation loss: 3.726137\tBest loss: 3.725746\tAccuracy: 4.20%\n",
      "49\tValidation loss: 3.717556\tBest loss: 3.717556\tAccuracy: 4.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\tValidation loss: 3.711071\tBest loss: 3.711071\tAccuracy: 4.80%\n",
      "51\tValidation loss: 3.704177\tBest loss: 3.704177\tAccuracy: 4.80%\n",
      "52\tValidation loss: 3.670655\tBest loss: 3.670655\tAccuracy: 4.90%\n",
      "53\tValidation loss: 3.698924\tBest loss: 3.670655\tAccuracy: 4.70%\n",
      "54\tValidation loss: 3.677726\tBest loss: 3.670655\tAccuracy: 5.10%\n",
      "55\tValidation loss: 3.698960\tBest loss: 3.670655\tAccuracy: 4.70%\n",
      "56\tValidation loss: 3.688363\tBest loss: 3.670655\tAccuracy: 4.90%\n",
      "57\tValidation loss: 3.697513\tBest loss: 3.670655\tAccuracy: 4.90%\n",
      "58\tValidation loss: 3.666066\tBest loss: 3.666066\tAccuracy: 4.40%\n",
      "59\tValidation loss: 3.698668\tBest loss: 3.666066\tAccuracy: 4.60%\n",
      "60\tValidation loss: 3.678168\tBest loss: 3.666066\tAccuracy: 5.30%\n",
      "61\tValidation loss: 3.681606\tBest loss: 3.666066\tAccuracy: 4.50%\n",
      "62\tValidation loss: 3.662161\tBest loss: 3.662161\tAccuracy: 4.80%\n",
      "63\tValidation loss: 3.664866\tBest loss: 3.662161\tAccuracy: 5.00%\n",
      "64\tValidation loss: 3.654154\tBest loss: 3.654154\tAccuracy: 5.40%\n",
      "65\tValidation loss: 3.657377\tBest loss: 3.654154\tAccuracy: 5.60%\n",
      "66\tValidation loss: 3.653455\tBest loss: 3.653455\tAccuracy: 4.90%\n",
      "67\tValidation loss: 3.637635\tBest loss: 3.637635\tAccuracy: 4.70%\n",
      "68\tValidation loss: 3.631844\tBest loss: 3.631844\tAccuracy: 5.50%\n",
      "69\tValidation loss: 3.623292\tBest loss: 3.623292\tAccuracy: 5.70%\n",
      "70\tValidation loss: 3.643128\tBest loss: 3.623292\tAccuracy: 5.60%\n",
      "71\tValidation loss: 3.626459\tBest loss: 3.623292\tAccuracy: 6.40%\n",
      "72\tValidation loss: 3.632170\tBest loss: 3.623292\tAccuracy: 9.80%\n",
      "73\tValidation loss: 3.619484\tBest loss: 3.619484\tAccuracy: 8.60%\n",
      "74\tValidation loss: 3.603194\tBest loss: 3.603194\tAccuracy: 9.50%\n",
      "75\tValidation loss: 3.595871\tBest loss: 3.595871\tAccuracy: 10.50%\n",
      "76\tValidation loss: 3.601511\tBest loss: 3.595871\tAccuracy: 9.60%\n",
      "77\tValidation loss: 3.599929\tBest loss: 3.595871\tAccuracy: 9.80%\n",
      "78\tValidation loss: 3.609602\tBest loss: 3.595871\tAccuracy: 10.20%\n",
      "79\tValidation loss: 3.615108\tBest loss: 3.595871\tAccuracy: 9.60%\n",
      "80\tValidation loss: 3.595871\tBest loss: 3.595871\tAccuracy: 9.70%\n",
      "81\tValidation loss: 3.573036\tBest loss: 3.573036\tAccuracy: 9.70%\n",
      "82\tValidation loss: 3.579433\tBest loss: 3.573036\tAccuracy: 10.40%\n",
      "83\tValidation loss: 3.559867\tBest loss: 3.559867\tAccuracy: 10.20%\n",
      "84\tValidation loss: 3.573452\tBest loss: 3.559867\tAccuracy: 10.70%\n",
      "85\tValidation loss: 3.575012\tBest loss: 3.559867\tAccuracy: 9.70%\n",
      "86\tValidation loss: 3.560364\tBest loss: 3.559867\tAccuracy: 10.90%\n",
      "87\tValidation loss: 3.555272\tBest loss: 3.555272\tAccuracy: 10.50%\n",
      "88\tValidation loss: 3.555272\tBest loss: 3.555272\tAccuracy: 11.30%\n",
      "89\tValidation loss: 3.544503\tBest loss: 3.544503\tAccuracy: 10.70%\n",
      "90\tValidation loss: 3.546654\tBest loss: 3.544503\tAccuracy: 10.90%\n",
      "91\tValidation loss: 3.548124\tBest loss: 3.544503\tAccuracy: 11.70%\n",
      "92\tValidation loss: 3.546826\tBest loss: 3.544503\tAccuracy: 11.20%\n",
      "93\tValidation loss: 3.552613\tBest loss: 3.544503\tAccuracy: 11.30%\n",
      "94\tValidation loss: 3.516928\tBest loss: 3.516928\tAccuracy: 11.80%\n",
      "95\tValidation loss: 3.517787\tBest loss: 3.516928\tAccuracy: 11.20%\n",
      "96\tValidation loss: 3.526789\tBest loss: 3.516928\tAccuracy: 11.10%\n",
      "97\tValidation loss: 3.520610\tBest loss: 3.516928\tAccuracy: 12.50%\n",
      "98\tValidation loss: 3.508475\tBest loss: 3.508475\tAccuracy: 12.00%\n",
      "99\tValidation loss: 3.516771\tBest loss: 3.508475\tAccuracy: 11.00%\n",
      "100\tValidation loss: 3.491016\tBest loss: 3.491016\tAccuracy: 12.60%\n",
      "101\tValidation loss: 3.493937\tBest loss: 3.491016\tAccuracy: 12.80%\n",
      "102\tValidation loss: 3.493932\tBest loss: 3.491016\tAccuracy: 12.70%\n",
      "103\tValidation loss: 3.470072\tBest loss: 3.470072\tAccuracy: 12.50%\n",
      "104\tValidation loss: 3.454354\tBest loss: 3.454354\tAccuracy: 14.00%\n",
      "105\tValidation loss: 3.467705\tBest loss: 3.454354\tAccuracy: 13.00%\n",
      "106\tValidation loss: 3.476029\tBest loss: 3.454354\tAccuracy: 12.40%\n",
      "107\tValidation loss: 3.466673\tBest loss: 3.454354\tAccuracy: 12.80%\n",
      "108\tValidation loss: 3.436162\tBest loss: 3.436162\tAccuracy: 13.70%\n",
      "109\tValidation loss: 3.436093\tBest loss: 3.436093\tAccuracy: 13.40%\n",
      "110\tValidation loss: 3.430719\tBest loss: 3.430719\tAccuracy: 13.50%\n",
      "111\tValidation loss: 3.446736\tBest loss: 3.430719\tAccuracy: 13.30%\n",
      "112\tValidation loss: 3.452667\tBest loss: 3.430719\tAccuracy: 13.40%\n",
      "113\tValidation loss: 3.457175\tBest loss: 3.430719\tAccuracy: 12.80%\n",
      "114\tValidation loss: 3.440747\tBest loss: 3.430719\tAccuracy: 12.40%\n",
      "115\tValidation loss: 3.427675\tBest loss: 3.427675\tAccuracy: 12.70%\n",
      "116\tValidation loss: 3.433293\tBest loss: 3.427675\tAccuracy: 12.60%\n",
      "117\tValidation loss: 3.418805\tBest loss: 3.418805\tAccuracy: 12.80%\n",
      "118\tValidation loss: 3.397843\tBest loss: 3.397843\tAccuracy: 13.30%\n",
      "119\tValidation loss: 3.430859\tBest loss: 3.397843\tAccuracy: 13.20%\n",
      "120\tValidation loss: 3.414541\tBest loss: 3.397843\tAccuracy: 13.60%\n",
      "121\tValidation loss: 3.408780\tBest loss: 3.397843\tAccuracy: 13.10%\n",
      "122\tValidation loss: 3.411655\tBest loss: 3.397843\tAccuracy: 13.20%\n",
      "123\tValidation loss: 3.433544\tBest loss: 3.397843\tAccuracy: 13.90%\n",
      "124\tValidation loss: 3.402229\tBest loss: 3.397843\tAccuracy: 13.80%\n",
      "125\tValidation loss: 3.409522\tBest loss: 3.397843\tAccuracy: 13.30%\n",
      "126\tValidation loss: 3.393492\tBest loss: 3.393492\tAccuracy: 13.60%\n",
      "127\tValidation loss: 3.374868\tBest loss: 3.374868\tAccuracy: 14.00%\n",
      "128\tValidation loss: 3.378620\tBest loss: 3.374868\tAccuracy: 14.30%\n",
      "129\tValidation loss: 3.365441\tBest loss: 3.365441\tAccuracy: 14.30%\n",
      "130\tValidation loss: 3.385281\tBest loss: 3.365441\tAccuracy: 14.30%\n",
      "131\tValidation loss: 3.373628\tBest loss: 3.365441\tAccuracy: 13.80%\n",
      "132\tValidation loss: 3.377100\tBest loss: 3.365441\tAccuracy: 14.50%\n",
      "133\tValidation loss: 3.385594\tBest loss: 3.365441\tAccuracy: 13.90%\n",
      "134\tValidation loss: 3.398573\tBest loss: 3.365441\tAccuracy: 12.90%\n",
      "135\tValidation loss: 3.365255\tBest loss: 3.365255\tAccuracy: 13.40%\n",
      "136\tValidation loss: 3.353475\tBest loss: 3.353475\tAccuracy: 13.50%\n",
      "137\tValidation loss: 3.337150\tBest loss: 3.337150\tAccuracy: 15.00%\n",
      "138\tValidation loss: 3.336836\tBest loss: 3.336836\tAccuracy: 13.90%\n",
      "139\tValidation loss: 3.350288\tBest loss: 3.336836\tAccuracy: 15.10%\n",
      "140\tValidation loss: 3.345371\tBest loss: 3.336836\tAccuracy: 14.30%\n",
      "141\tValidation loss: 3.331872\tBest loss: 3.331872\tAccuracy: 15.20%\n",
      "142\tValidation loss: 3.329355\tBest loss: 3.329355\tAccuracy: 14.50%\n",
      "143\tValidation loss: 3.325286\tBest loss: 3.325286\tAccuracy: 15.20%\n",
      "144\tValidation loss: 3.324464\tBest loss: 3.324464\tAccuracy: 14.20%\n",
      "145\tValidation loss: 3.332096\tBest loss: 3.324464\tAccuracy: 15.20%\n",
      "146\tValidation loss: 3.314180\tBest loss: 3.314180\tAccuracy: 15.40%\n",
      "147\tValidation loss: 3.304983\tBest loss: 3.304983\tAccuracy: 15.80%\n",
      "148\tValidation loss: 3.298493\tBest loss: 3.298493\tAccuracy: 16.20%\n",
      "149\tValidation loss: 3.295525\tBest loss: 3.295525\tAccuracy: 14.60%\n",
      "150\tValidation loss: 3.298543\tBest loss: 3.295525\tAccuracy: 15.00%\n",
      "151\tValidation loss: 3.279873\tBest loss: 3.279873\tAccuracy: 16.30%\n",
      "152\tValidation loss: 3.286821\tBest loss: 3.279873\tAccuracy: 15.60%\n",
      "153\tValidation loss: 3.276727\tBest loss: 3.276727\tAccuracy: 15.10%\n",
      "154\tValidation loss: 3.316142\tBest loss: 3.276727\tAccuracy: 15.60%\n",
      "155\tValidation loss: 3.267223\tBest loss: 3.267223\tAccuracy: 16.90%\n",
      "156\tValidation loss: 3.290755\tBest loss: 3.267223\tAccuracy: 16.00%\n",
      "157\tValidation loss: 3.259711\tBest loss: 3.259711\tAccuracy: 15.20%\n",
      "158\tValidation loss: 3.255662\tBest loss: 3.255662\tAccuracy: 14.30%\n",
      "159\tValidation loss: 3.292152\tBest loss: 3.255662\tAccuracy: 15.70%\n",
      "160\tValidation loss: 3.266248\tBest loss: 3.255662\tAccuracy: 15.40%\n",
      "161\tValidation loss: 3.274810\tBest loss: 3.255662\tAccuracy: 16.20%\n",
      "162\tValidation loss: 3.276313\tBest loss: 3.255662\tAccuracy: 16.80%\n",
      "163\tValidation loss: 3.254949\tBest loss: 3.254949\tAccuracy: 16.30%\n",
      "164\tValidation loss: 3.247188\tBest loss: 3.247188\tAccuracy: 16.50%\n",
      "165\tValidation loss: 3.257236\tBest loss: 3.247188\tAccuracy: 17.20%\n",
      "166\tValidation loss: 3.253977\tBest loss: 3.247188\tAccuracy: 16.20%\n",
      "167\tValidation loss: 3.243407\tBest loss: 3.243407\tAccuracy: 16.30%\n",
      "168\tValidation loss: 3.235780\tBest loss: 3.235780\tAccuracy: 17.20%\n",
      "169\tValidation loss: 3.221798\tBest loss: 3.221798\tAccuracy: 16.20%\n",
      "170\tValidation loss: 3.217346\tBest loss: 3.217346\tAccuracy: 16.90%\n",
      "171\tValidation loss: 3.232358\tBest loss: 3.217346\tAccuracy: 16.10%\n",
      "172\tValidation loss: 3.200935\tBest loss: 3.200935\tAccuracy: 16.80%\n",
      "173\tValidation loss: 3.217896\tBest loss: 3.200935\tAccuracy: 15.70%\n",
      "174\tValidation loss: 3.197645\tBest loss: 3.197645\tAccuracy: 16.80%\n",
      "175\tValidation loss: 3.207698\tBest loss: 3.197645\tAccuracy: 15.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\tValidation loss: 3.207107\tBest loss: 3.197645\tAccuracy: 15.60%\n",
      "177\tValidation loss: 3.198272\tBest loss: 3.197645\tAccuracy: 16.90%\n",
      "178\tValidation loss: 3.192204\tBest loss: 3.192204\tAccuracy: 17.10%\n",
      "179\tValidation loss: 3.202632\tBest loss: 3.192204\tAccuracy: 17.00%\n",
      "180\tValidation loss: 3.205080\tBest loss: 3.192204\tAccuracy: 17.60%\n",
      "181\tValidation loss: 3.201371\tBest loss: 3.192204\tAccuracy: 16.00%\n",
      "182\tValidation loss: 3.183966\tBest loss: 3.183966\tAccuracy: 17.00%\n",
      "183\tValidation loss: 3.193323\tBest loss: 3.183966\tAccuracy: 16.60%\n",
      "184\tValidation loss: 3.170119\tBest loss: 3.170119\tAccuracy: 16.90%\n",
      "185\tValidation loss: 3.193624\tBest loss: 3.170119\tAccuracy: 17.10%\n",
      "186\tValidation loss: 3.202338\tBest loss: 3.170119\tAccuracy: 17.10%\n",
      "187\tValidation loss: 3.187022\tBest loss: 3.170119\tAccuracy: 18.10%\n",
      "188\tValidation loss: 3.202086\tBest loss: 3.170119\tAccuracy: 17.80%\n",
      "189\tValidation loss: 3.173557\tBest loss: 3.170119\tAccuracy: 18.00%\n",
      "190\tValidation loss: 3.163043\tBest loss: 3.163043\tAccuracy: 17.20%\n",
      "191\tValidation loss: 3.160775\tBest loss: 3.160775\tAccuracy: 18.70%\n",
      "192\tValidation loss: 3.143985\tBest loss: 3.143985\tAccuracy: 18.60%\n",
      "193\tValidation loss: 3.119917\tBest loss: 3.119917\tAccuracy: 19.60%\n",
      "194\tValidation loss: 3.128242\tBest loss: 3.119917\tAccuracy: 19.00%\n",
      "195\tValidation loss: 3.139164\tBest loss: 3.119917\tAccuracy: 17.50%\n",
      "196\tValidation loss: 3.164937\tBest loss: 3.119917\tAccuracy: 18.90%\n",
      "197\tValidation loss: 3.159737\tBest loss: 3.119917\tAccuracy: 17.10%\n",
      "198\tValidation loss: 3.137884\tBest loss: 3.119917\tAccuracy: 17.60%\n",
      "199\tValidation loss: 3.134464\tBest loss: 3.119917\tAccuracy: 18.90%\n",
      "200\tValidation loss: 3.123142\tBest loss: 3.119917\tAccuracy: 17.40%\n",
      "201\tValidation loss: 3.132814\tBest loss: 3.119917\tAccuracy: 18.80%\n",
      "202\tValidation loss: 3.115797\tBest loss: 3.115797\tAccuracy: 19.20%\n",
      "203\tValidation loss: 3.124949\tBest loss: 3.115797\tAccuracy: 17.90%\n",
      "204\tValidation loss: 3.143411\tBest loss: 3.115797\tAccuracy: 18.00%\n",
      "205\tValidation loss: 3.111713\tBest loss: 3.111713\tAccuracy: 18.70%\n",
      "206\tValidation loss: 3.124251\tBest loss: 3.111713\tAccuracy: 19.40%\n",
      "207\tValidation loss: 3.115079\tBest loss: 3.111713\tAccuracy: 19.10%\n",
      "208\tValidation loss: 3.104963\tBest loss: 3.104963\tAccuracy: 19.70%\n",
      "209\tValidation loss: 3.085227\tBest loss: 3.085227\tAccuracy: 19.40%\n",
      "210\tValidation loss: 3.082247\tBest loss: 3.082247\tAccuracy: 19.70%\n",
      "211\tValidation loss: 3.063589\tBest loss: 3.063589\tAccuracy: 20.20%\n",
      "212\tValidation loss: 3.089481\tBest loss: 3.063589\tAccuracy: 18.50%\n",
      "213\tValidation loss: 3.102018\tBest loss: 3.063589\tAccuracy: 19.20%\n",
      "214\tValidation loss: 3.071072\tBest loss: 3.063589\tAccuracy: 21.00%\n",
      "215\tValidation loss: 3.067206\tBest loss: 3.063589\tAccuracy: 20.00%\n",
      "216\tValidation loss: 3.059671\tBest loss: 3.059671\tAccuracy: 20.00%\n",
      "217\tValidation loss: 3.094465\tBest loss: 3.059671\tAccuracy: 19.20%\n",
      "218\tValidation loss: 3.055532\tBest loss: 3.055532\tAccuracy: 20.60%\n",
      "219\tValidation loss: 3.074369\tBest loss: 3.055532\tAccuracy: 20.40%\n",
      "220\tValidation loss: 3.053138\tBest loss: 3.053138\tAccuracy: 20.80%\n",
      "221\tValidation loss: 3.090417\tBest loss: 3.053138\tAccuracy: 19.40%\n",
      "222\tValidation loss: 3.053327\tBest loss: 3.053138\tAccuracy: 20.00%\n",
      "223\tValidation loss: 3.040233\tBest loss: 3.040233\tAccuracy: 21.20%\n",
      "224\tValidation loss: 3.048307\tBest loss: 3.040233\tAccuracy: 20.80%\n",
      "225\tValidation loss: 3.040189\tBest loss: 3.040189\tAccuracy: 20.70%\n",
      "226\tValidation loss: 3.057356\tBest loss: 3.040189\tAccuracy: 20.70%\n",
      "227\tValidation loss: 3.044502\tBest loss: 3.040189\tAccuracy: 21.10%\n",
      "228\tValidation loss: 3.047857\tBest loss: 3.040189\tAccuracy: 20.90%\n",
      "229\tValidation loss: 3.048395\tBest loss: 3.040189\tAccuracy: 21.10%\n",
      "230\tValidation loss: 3.022081\tBest loss: 3.022081\tAccuracy: 22.30%\n",
      "231\tValidation loss: 3.015647\tBest loss: 3.015647\tAccuracy: 23.10%\n",
      "232\tValidation loss: 3.020413\tBest loss: 3.015647\tAccuracy: 22.00%\n",
      "233\tValidation loss: 3.017709\tBest loss: 3.015647\tAccuracy: 22.60%\n",
      "234\tValidation loss: 3.005599\tBest loss: 3.005599\tAccuracy: 22.20%\n",
      "235\tValidation loss: 3.039142\tBest loss: 3.005599\tAccuracy: 20.90%\n",
      "236\tValidation loss: 3.015620\tBest loss: 3.005599\tAccuracy: 20.80%\n",
      "237\tValidation loss: 3.013559\tBest loss: 3.005599\tAccuracy: 21.50%\n",
      "238\tValidation loss: 3.014915\tBest loss: 3.005599\tAccuracy: 21.00%\n",
      "239\tValidation loss: 3.014247\tBest loss: 3.005599\tAccuracy: 21.00%\n",
      "240\tValidation loss: 3.007808\tBest loss: 3.005599\tAccuracy: 20.80%\n",
      "241\tValidation loss: 2.974502\tBest loss: 2.974502\tAccuracy: 21.00%\n",
      "242\tValidation loss: 2.981576\tBest loss: 2.974502\tAccuracy: 21.10%\n",
      "243\tValidation loss: 2.980290\tBest loss: 2.974502\tAccuracy: 21.60%\n",
      "244\tValidation loss: 2.999083\tBest loss: 2.974502\tAccuracy: 22.00%\n",
      "245\tValidation loss: 3.002334\tBest loss: 2.974502\tAccuracy: 20.90%\n",
      "246\tValidation loss: 2.989735\tBest loss: 2.974502\tAccuracy: 21.70%\n",
      "247\tValidation loss: 2.985475\tBest loss: 2.974502\tAccuracy: 21.80%\n",
      "248\tValidation loss: 2.996393\tBest loss: 2.974502\tAccuracy: 21.10%\n",
      "249\tValidation loss: 2.990859\tBest loss: 2.974502\tAccuracy: 22.60%\n",
      "250\tValidation loss: 2.974913\tBest loss: 2.974502\tAccuracy: 23.20%\n",
      "251\tValidation loss: 2.971639\tBest loss: 2.971639\tAccuracy: 23.60%\n",
      "252\tValidation loss: 2.978774\tBest loss: 2.971639\tAccuracy: 23.20%\n",
      "253\tValidation loss: 2.983263\tBest loss: 2.971639\tAccuracy: 23.00%\n",
      "254\tValidation loss: 2.953818\tBest loss: 2.953818\tAccuracy: 23.40%\n",
      "255\tValidation loss: 2.982315\tBest loss: 2.953818\tAccuracy: 21.30%\n",
      "256\tValidation loss: 2.976175\tBest loss: 2.953818\tAccuracy: 21.60%\n",
      "257\tValidation loss: 2.972173\tBest loss: 2.953818\tAccuracy: 22.30%\n",
      "258\tValidation loss: 2.945649\tBest loss: 2.945649\tAccuracy: 23.20%\n",
      "259\tValidation loss: 2.927496\tBest loss: 2.927496\tAccuracy: 24.00%\n",
      "260\tValidation loss: 2.925703\tBest loss: 2.925703\tAccuracy: 23.80%\n",
      "261\tValidation loss: 2.921989\tBest loss: 2.921989\tAccuracy: 23.30%\n",
      "262\tValidation loss: 2.971840\tBest loss: 2.921989\tAccuracy: 22.20%\n",
      "263\tValidation loss: 2.927288\tBest loss: 2.921989\tAccuracy: 23.60%\n",
      "264\tValidation loss: 2.916783\tBest loss: 2.916783\tAccuracy: 23.80%\n",
      "265\tValidation loss: 2.934134\tBest loss: 2.916783\tAccuracy: 22.50%\n",
      "266\tValidation loss: 2.931823\tBest loss: 2.916783\tAccuracy: 22.90%\n",
      "267\tValidation loss: 2.919070\tBest loss: 2.916783\tAccuracy: 23.40%\n",
      "268\tValidation loss: 2.925792\tBest loss: 2.916783\tAccuracy: 23.90%\n",
      "269\tValidation loss: 2.897763\tBest loss: 2.897763\tAccuracy: 24.70%\n",
      "270\tValidation loss: 2.915539\tBest loss: 2.897763\tAccuracy: 23.50%\n",
      "271\tValidation loss: 2.924269\tBest loss: 2.897763\tAccuracy: 22.20%\n",
      "272\tValidation loss: 2.900506\tBest loss: 2.897763\tAccuracy: 24.20%\n",
      "273\tValidation loss: 2.889748\tBest loss: 2.889748\tAccuracy: 24.20%\n",
      "274\tValidation loss: 2.888083\tBest loss: 2.888083\tAccuracy: 24.20%\n",
      "275\tValidation loss: 2.905059\tBest loss: 2.888083\tAccuracy: 23.80%\n",
      "276\tValidation loss: 2.893870\tBest loss: 2.888083\tAccuracy: 24.10%\n",
      "277\tValidation loss: 2.874784\tBest loss: 2.874784\tAccuracy: 24.40%\n",
      "278\tValidation loss: 2.897387\tBest loss: 2.874784\tAccuracy: 24.10%\n",
      "279\tValidation loss: 2.910506\tBest loss: 2.874784\tAccuracy: 24.40%\n",
      "280\tValidation loss: 2.889356\tBest loss: 2.874784\tAccuracy: 24.20%\n",
      "281\tValidation loss: 2.874014\tBest loss: 2.874014\tAccuracy: 23.90%\n",
      "282\tValidation loss: 2.903909\tBest loss: 2.874014\tAccuracy: 24.10%\n",
      "283\tValidation loss: 2.891057\tBest loss: 2.874014\tAccuracy: 23.60%\n",
      "284\tValidation loss: 2.875309\tBest loss: 2.874014\tAccuracy: 24.70%\n",
      "285\tValidation loss: 2.850094\tBest loss: 2.850094\tAccuracy: 25.50%\n",
      "286\tValidation loss: 2.877858\tBest loss: 2.850094\tAccuracy: 24.80%\n",
      "287\tValidation loss: 2.873371\tBest loss: 2.850094\tAccuracy: 25.20%\n",
      "288\tValidation loss: 2.841536\tBest loss: 2.841536\tAccuracy: 25.10%\n",
      "289\tValidation loss: 2.848451\tBest loss: 2.841536\tAccuracy: 24.50%\n",
      "290\tValidation loss: 2.864762\tBest loss: 2.841536\tAccuracy: 24.10%\n",
      "291\tValidation loss: 2.832352\tBest loss: 2.832352\tAccuracy: 25.90%\n",
      "292\tValidation loss: 2.868145\tBest loss: 2.832352\tAccuracy: 24.80%\n",
      "293\tValidation loss: 2.824561\tBest loss: 2.824561\tAccuracy: 25.70%\n",
      "294\tValidation loss: 2.815278\tBest loss: 2.815278\tAccuracy: 26.70%\n",
      "295\tValidation loss: 2.854107\tBest loss: 2.815278\tAccuracy: 25.50%\n",
      "296\tValidation loss: 2.812493\tBest loss: 2.812493\tAccuracy: 25.10%\n",
      "297\tValidation loss: 2.803678\tBest loss: 2.803678\tAccuracy: 25.60%\n",
      "298\tValidation loss: 2.844454\tBest loss: 2.803678\tAccuracy: 25.50%\n",
      "299\tValidation loss: 2.798145\tBest loss: 2.798145\tAccuracy: 26.70%\n",
      "300\tValidation loss: 2.824314\tBest loss: 2.798145\tAccuracy: 25.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\tValidation loss: 2.808490\tBest loss: 2.798145\tAccuracy: 25.40%\n",
      "302\tValidation loss: 2.794403\tBest loss: 2.794403\tAccuracy: 26.50%\n",
      "303\tValidation loss: 2.819839\tBest loss: 2.794403\tAccuracy: 25.90%\n",
      "304\tValidation loss: 2.793550\tBest loss: 2.793550\tAccuracy: 25.60%\n",
      "305\tValidation loss: 2.788170\tBest loss: 2.788170\tAccuracy: 27.00%\n",
      "306\tValidation loss: 2.775667\tBest loss: 2.775667\tAccuracy: 26.20%\n",
      "307\tValidation loss: 2.775211\tBest loss: 2.775211\tAccuracy: 25.70%\n",
      "308\tValidation loss: 2.801862\tBest loss: 2.775211\tAccuracy: 26.40%\n",
      "309\tValidation loss: 2.803774\tBest loss: 2.775211\tAccuracy: 26.30%\n",
      "310\tValidation loss: 2.778959\tBest loss: 2.775211\tAccuracy: 27.00%\n",
      "311\tValidation loss: 2.756525\tBest loss: 2.756525\tAccuracy: 27.10%\n",
      "312\tValidation loss: 2.771044\tBest loss: 2.756525\tAccuracy: 25.80%\n",
      "313\tValidation loss: 2.773973\tBest loss: 2.756525\tAccuracy: 26.60%\n",
      "314\tValidation loss: 2.772392\tBest loss: 2.756525\tAccuracy: 25.50%\n",
      "315\tValidation loss: 2.758996\tBest loss: 2.756525\tAccuracy: 26.00%\n",
      "316\tValidation loss: 2.776250\tBest loss: 2.756525\tAccuracy: 25.80%\n",
      "317\tValidation loss: 2.769976\tBest loss: 2.756525\tAccuracy: 27.00%\n",
      "318\tValidation loss: 2.754552\tBest loss: 2.754552\tAccuracy: 26.60%\n",
      "319\tValidation loss: 2.753716\tBest loss: 2.753716\tAccuracy: 27.10%\n",
      "320\tValidation loss: 2.751980\tBest loss: 2.751980\tAccuracy: 27.00%\n",
      "321\tValidation loss: 2.743283\tBest loss: 2.743283\tAccuracy: 25.70%\n",
      "322\tValidation loss: 2.758754\tBest loss: 2.743283\tAccuracy: 26.70%\n",
      "323\tValidation loss: 2.755037\tBest loss: 2.743283\tAccuracy: 25.50%\n",
      "324\tValidation loss: 2.744124\tBest loss: 2.743283\tAccuracy: 25.10%\n",
      "325\tValidation loss: 2.710148\tBest loss: 2.710148\tAccuracy: 26.30%\n",
      "326\tValidation loss: 2.717253\tBest loss: 2.710148\tAccuracy: 26.20%\n",
      "327\tValidation loss: 2.739088\tBest loss: 2.710148\tAccuracy: 26.10%\n",
      "328\tValidation loss: 2.719264\tBest loss: 2.710148\tAccuracy: 25.90%\n",
      "329\tValidation loss: 2.725233\tBest loss: 2.710148\tAccuracy: 26.70%\n",
      "330\tValidation loss: 2.727483\tBest loss: 2.710148\tAccuracy: 26.70%\n",
      "331\tValidation loss: 2.734427\tBest loss: 2.710148\tAccuracy: 25.90%\n",
      "332\tValidation loss: 2.718908\tBest loss: 2.710148\tAccuracy: 25.90%\n",
      "333\tValidation loss: 2.701896\tBest loss: 2.701896\tAccuracy: 28.30%\n",
      "334\tValidation loss: 2.721174\tBest loss: 2.701896\tAccuracy: 26.70%\n",
      "335\tValidation loss: 2.722291\tBest loss: 2.701896\tAccuracy: 26.50%\n",
      "336\tValidation loss: 2.688445\tBest loss: 2.688445\tAccuracy: 27.10%\n",
      "337\tValidation loss: 2.715619\tBest loss: 2.688445\tAccuracy: 24.60%\n",
      "338\tValidation loss: 2.694955\tBest loss: 2.688445\tAccuracy: 27.10%\n",
      "339\tValidation loss: 2.705399\tBest loss: 2.688445\tAccuracy: 26.90%\n",
      "340\tValidation loss: 2.709860\tBest loss: 2.688445\tAccuracy: 26.70%\n",
      "341\tValidation loss: 2.687295\tBest loss: 2.687295\tAccuracy: 25.30%\n",
      "342\tValidation loss: 2.698537\tBest loss: 2.687295\tAccuracy: 26.90%\n",
      "343\tValidation loss: 2.686014\tBest loss: 2.686014\tAccuracy: 28.20%\n",
      "344\tValidation loss: 2.665731\tBest loss: 2.665731\tAccuracy: 28.10%\n",
      "345\tValidation loss: 2.660846\tBest loss: 2.660846\tAccuracy: 29.00%\n",
      "346\tValidation loss: 2.691696\tBest loss: 2.660846\tAccuracy: 27.10%\n",
      "347\tValidation loss: 2.685775\tBest loss: 2.660846\tAccuracy: 25.90%\n",
      "348\tValidation loss: 2.671127\tBest loss: 2.660846\tAccuracy: 27.60%\n",
      "349\tValidation loss: 2.671888\tBest loss: 2.660846\tAccuracy: 28.20%\n",
      "350\tValidation loss: 2.663477\tBest loss: 2.660846\tAccuracy: 28.50%\n",
      "351\tValidation loss: 2.658155\tBest loss: 2.658155\tAccuracy: 29.50%\n",
      "352\tValidation loss: 2.680515\tBest loss: 2.658155\tAccuracy: 27.80%\n",
      "353\tValidation loss: 2.676368\tBest loss: 2.658155\tAccuracy: 27.30%\n",
      "354\tValidation loss: 2.682170\tBest loss: 2.658155\tAccuracy: 27.70%\n",
      "355\tValidation loss: 2.648140\tBest loss: 2.648140\tAccuracy: 28.10%\n",
      "356\tValidation loss: 2.651819\tBest loss: 2.648140\tAccuracy: 27.50%\n",
      "357\tValidation loss: 2.665801\tBest loss: 2.648140\tAccuracy: 27.60%\n",
      "358\tValidation loss: 2.652572\tBest loss: 2.648140\tAccuracy: 28.90%\n",
      "359\tValidation loss: 2.646021\tBest loss: 2.646021\tAccuracy: 28.50%\n",
      "360\tValidation loss: 2.657992\tBest loss: 2.646021\tAccuracy: 27.40%\n",
      "361\tValidation loss: 2.647557\tBest loss: 2.646021\tAccuracy: 28.20%\n",
      "362\tValidation loss: 2.630985\tBest loss: 2.630985\tAccuracy: 28.40%\n",
      "363\tValidation loss: 2.644441\tBest loss: 2.630985\tAccuracy: 28.60%\n",
      "364\tValidation loss: 2.632871\tBest loss: 2.630985\tAccuracy: 28.70%\n",
      "365\tValidation loss: 2.645156\tBest loss: 2.630985\tAccuracy: 28.20%\n",
      "366\tValidation loss: 2.641560\tBest loss: 2.630985\tAccuracy: 27.30%\n",
      "367\tValidation loss: 2.620529\tBest loss: 2.620529\tAccuracy: 28.60%\n",
      "368\tValidation loss: 2.613154\tBest loss: 2.613154\tAccuracy: 29.00%\n",
      "369\tValidation loss: 2.610144\tBest loss: 2.610144\tAccuracy: 29.50%\n",
      "370\tValidation loss: 2.596693\tBest loss: 2.596693\tAccuracy: 30.70%\n",
      "371\tValidation loss: 2.609513\tBest loss: 2.596693\tAccuracy: 30.10%\n",
      "372\tValidation loss: 2.639139\tBest loss: 2.596693\tAccuracy: 28.30%\n",
      "373\tValidation loss: 2.627586\tBest loss: 2.596693\tAccuracy: 29.50%\n",
      "374\tValidation loss: 2.628038\tBest loss: 2.596693\tAccuracy: 28.80%\n",
      "375\tValidation loss: 2.594824\tBest loss: 2.594824\tAccuracy: 29.90%\n",
      "376\tValidation loss: 2.597669\tBest loss: 2.594824\tAccuracy: 30.20%\n",
      "377\tValidation loss: 2.613157\tBest loss: 2.594824\tAccuracy: 30.00%\n",
      "378\tValidation loss: 2.590636\tBest loss: 2.590636\tAccuracy: 29.90%\n",
      "379\tValidation loss: 2.599669\tBest loss: 2.590636\tAccuracy: 30.20%\n",
      "380\tValidation loss: 2.606225\tBest loss: 2.590636\tAccuracy: 30.10%\n",
      "381\tValidation loss: 2.601110\tBest loss: 2.590636\tAccuracy: 29.20%\n",
      "382\tValidation loss: 2.600954\tBest loss: 2.590636\tAccuracy: 30.20%\n",
      "383\tValidation loss: 2.608842\tBest loss: 2.590636\tAccuracy: 29.80%\n",
      "384\tValidation loss: 2.598599\tBest loss: 2.590636\tAccuracy: 28.40%\n",
      "385\tValidation loss: 2.600874\tBest loss: 2.590636\tAccuracy: 28.90%\n",
      "386\tValidation loss: 2.581515\tBest loss: 2.581515\tAccuracy: 29.10%\n",
      "387\tValidation loss: 2.621475\tBest loss: 2.581515\tAccuracy: 28.70%\n",
      "388\tValidation loss: 2.617452\tBest loss: 2.581515\tAccuracy: 28.90%\n",
      "389\tValidation loss: 2.586087\tBest loss: 2.581515\tAccuracy: 30.30%\n",
      "390\tValidation loss: 2.576786\tBest loss: 2.576786\tAccuracy: 29.40%\n",
      "391\tValidation loss: 2.578397\tBest loss: 2.576786\tAccuracy: 29.80%\n",
      "392\tValidation loss: 2.585742\tBest loss: 2.576786\tAccuracy: 28.80%\n",
      "393\tValidation loss: 2.590354\tBest loss: 2.576786\tAccuracy: 28.60%\n",
      "394\tValidation loss: 2.561317\tBest loss: 2.561317\tAccuracy: 30.80%\n",
      "395\tValidation loss: 2.536959\tBest loss: 2.536959\tAccuracy: 31.20%\n",
      "396\tValidation loss: 2.585121\tBest loss: 2.536959\tAccuracy: 30.60%\n",
      "397\tValidation loss: 2.583464\tBest loss: 2.536959\tAccuracy: 30.60%\n",
      "398\tValidation loss: 2.560288\tBest loss: 2.536959\tAccuracy: 31.00%\n",
      "399\tValidation loss: 2.562871\tBest loss: 2.536959\tAccuracy: 30.10%\n",
      "400\tValidation loss: 2.559848\tBest loss: 2.536959\tAccuracy: 31.20%\n",
      "401\tValidation loss: 2.572817\tBest loss: 2.536959\tAccuracy: 29.10%\n",
      "402\tValidation loss: 2.556914\tBest loss: 2.536959\tAccuracy: 30.20%\n",
      "403\tValidation loss: 2.581286\tBest loss: 2.536959\tAccuracy: 29.30%\n",
      "404\tValidation loss: 2.563418\tBest loss: 2.536959\tAccuracy: 29.30%\n",
      "405\tValidation loss: 2.551281\tBest loss: 2.536959\tAccuracy: 31.00%\n",
      "406\tValidation loss: 2.560131\tBest loss: 2.536959\tAccuracy: 30.70%\n",
      "407\tValidation loss: 2.547331\tBest loss: 2.536959\tAccuracy: 30.00%\n",
      "408\tValidation loss: 2.549741\tBest loss: 2.536959\tAccuracy: 30.30%\n",
      "409\tValidation loss: 2.560790\tBest loss: 2.536959\tAccuracy: 28.80%\n",
      "410\tValidation loss: 2.555142\tBest loss: 2.536959\tAccuracy: 30.20%\n",
      "411\tValidation loss: 2.551440\tBest loss: 2.536959\tAccuracy: 31.00%\n",
      "412\tValidation loss: 2.559262\tBest loss: 2.536959\tAccuracy: 29.10%\n",
      "413\tValidation loss: 2.532847\tBest loss: 2.532847\tAccuracy: 31.60%\n",
      "414\tValidation loss: 2.552928\tBest loss: 2.532847\tAccuracy: 31.30%\n",
      "415\tValidation loss: 2.530690\tBest loss: 2.530690\tAccuracy: 31.90%\n",
      "416\tValidation loss: 2.555332\tBest loss: 2.530690\tAccuracy: 31.80%\n",
      "417\tValidation loss: 2.541284\tBest loss: 2.530690\tAccuracy: 32.10%\n",
      "418\tValidation loss: 2.538834\tBest loss: 2.530690\tAccuracy: 30.20%\n",
      "419\tValidation loss: 2.515566\tBest loss: 2.515566\tAccuracy: 31.80%\n",
      "420\tValidation loss: 2.541476\tBest loss: 2.515566\tAccuracy: 31.90%\n",
      "421\tValidation loss: 2.522913\tBest loss: 2.515566\tAccuracy: 31.50%\n",
      "422\tValidation loss: 2.535132\tBest loss: 2.515566\tAccuracy: 31.30%\n",
      "423\tValidation loss: 2.542686\tBest loss: 2.515566\tAccuracy: 31.40%\n",
      "424\tValidation loss: 2.532846\tBest loss: 2.515566\tAccuracy: 31.60%\n",
      "425\tValidation loss: 2.533987\tBest loss: 2.515566\tAccuracy: 30.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\tValidation loss: 2.535343\tBest loss: 2.515566\tAccuracy: 30.50%\n",
      "427\tValidation loss: 2.496968\tBest loss: 2.496968\tAccuracy: 32.30%\n",
      "428\tValidation loss: 2.504427\tBest loss: 2.496968\tAccuracy: 31.70%\n",
      "429\tValidation loss: 2.526939\tBest loss: 2.496968\tAccuracy: 30.40%\n",
      "430\tValidation loss: 2.497237\tBest loss: 2.496968\tAccuracy: 33.70%\n",
      "431\tValidation loss: 2.502925\tBest loss: 2.496968\tAccuracy: 31.50%\n",
      "432\tValidation loss: 2.517025\tBest loss: 2.496968\tAccuracy: 32.80%\n",
      "433\tValidation loss: 2.505859\tBest loss: 2.496968\tAccuracy: 31.20%\n",
      "434\tValidation loss: 2.502863\tBest loss: 2.496968\tAccuracy: 31.50%\n",
      "435\tValidation loss: 2.529928\tBest loss: 2.496968\tAccuracy: 30.40%\n",
      "436\tValidation loss: 2.517163\tBest loss: 2.496968\tAccuracy: 31.80%\n",
      "437\tValidation loss: 2.541048\tBest loss: 2.496968\tAccuracy: 31.20%\n",
      "438\tValidation loss: 2.508036\tBest loss: 2.496968\tAccuracy: 33.00%\n",
      "439\tValidation loss: 2.506135\tBest loss: 2.496968\tAccuracy: 32.40%\n",
      "440\tValidation loss: 2.497366\tBest loss: 2.496968\tAccuracy: 33.20%\n",
      "441\tValidation loss: 2.505531\tBest loss: 2.496968\tAccuracy: 33.20%\n",
      "442\tValidation loss: 2.486342\tBest loss: 2.486342\tAccuracy: 33.10%\n",
      "443\tValidation loss: 2.478933\tBest loss: 2.478933\tAccuracy: 34.90%\n",
      "444\tValidation loss: 2.515937\tBest loss: 2.478933\tAccuracy: 34.30%\n",
      "445\tValidation loss: 2.490665\tBest loss: 2.478933\tAccuracy: 33.40%\n",
      "446\tValidation loss: 2.515207\tBest loss: 2.478933\tAccuracy: 33.00%\n",
      "447\tValidation loss: 2.472027\tBest loss: 2.472027\tAccuracy: 33.40%\n",
      "448\tValidation loss: 2.493557\tBest loss: 2.472027\tAccuracy: 32.90%\n",
      "449\tValidation loss: 2.489470\tBest loss: 2.472027\tAccuracy: 33.60%\n",
      "450\tValidation loss: 2.480903\tBest loss: 2.472027\tAccuracy: 33.40%\n",
      "451\tValidation loss: 2.485516\tBest loss: 2.472027\tAccuracy: 33.20%\n",
      "452\tValidation loss: 2.478068\tBest loss: 2.472027\tAccuracy: 33.40%\n",
      "453\tValidation loss: 2.483235\tBest loss: 2.472027\tAccuracy: 32.40%\n",
      "454\tValidation loss: 2.477752\tBest loss: 2.472027\tAccuracy: 32.10%\n",
      "455\tValidation loss: 2.475212\tBest loss: 2.472027\tAccuracy: 33.50%\n",
      "456\tValidation loss: 2.507542\tBest loss: 2.472027\tAccuracy: 32.60%\n",
      "457\tValidation loss: 2.480375\tBest loss: 2.472027\tAccuracy: 33.00%\n",
      "458\tValidation loss: 2.487948\tBest loss: 2.472027\tAccuracy: 31.90%\n",
      "459\tValidation loss: 2.461254\tBest loss: 2.461254\tAccuracy: 33.00%\n",
      "460\tValidation loss: 2.477387\tBest loss: 2.461254\tAccuracy: 33.10%\n",
      "461\tValidation loss: 2.479832\tBest loss: 2.461254\tAccuracy: 33.40%\n",
      "462\tValidation loss: 2.487785\tBest loss: 2.461254\tAccuracy: 33.40%\n",
      "463\tValidation loss: 2.465311\tBest loss: 2.461254\tAccuracy: 33.00%\n",
      "464\tValidation loss: 2.450184\tBest loss: 2.450184\tAccuracy: 34.30%\n",
      "465\tValidation loss: 2.466734\tBest loss: 2.450184\tAccuracy: 33.80%\n",
      "466\tValidation loss: 2.449027\tBest loss: 2.449027\tAccuracy: 34.00%\n",
      "467\tValidation loss: 2.461939\tBest loss: 2.449027\tAccuracy: 33.60%\n",
      "468\tValidation loss: 2.456882\tBest loss: 2.449027\tAccuracy: 34.60%\n",
      "469\tValidation loss: 2.482410\tBest loss: 2.449027\tAccuracy: 33.00%\n",
      "470\tValidation loss: 2.454141\tBest loss: 2.449027\tAccuracy: 33.40%\n",
      "471\tValidation loss: 2.457143\tBest loss: 2.449027\tAccuracy: 32.70%\n",
      "472\tValidation loss: 2.445938\tBest loss: 2.445938\tAccuracy: 33.90%\n",
      "473\tValidation loss: 2.438116\tBest loss: 2.438116\tAccuracy: 34.50%\n",
      "474\tValidation loss: 2.470106\tBest loss: 2.438116\tAccuracy: 33.70%\n",
      "475\tValidation loss: 2.462297\tBest loss: 2.438116\tAccuracy: 33.10%\n",
      "476\tValidation loss: 2.459342\tBest loss: 2.438116\tAccuracy: 33.60%\n",
      "477\tValidation loss: 2.448768\tBest loss: 2.438116\tAccuracy: 34.00%\n",
      "478\tValidation loss: 2.461873\tBest loss: 2.438116\tAccuracy: 33.60%\n",
      "479\tValidation loss: 2.442554\tBest loss: 2.438116\tAccuracy: 33.70%\n",
      "480\tValidation loss: 2.457167\tBest loss: 2.438116\tAccuracy: 33.00%\n",
      "481\tValidation loss: 2.442605\tBest loss: 2.438116\tAccuracy: 33.90%\n",
      "482\tValidation loss: 2.453685\tBest loss: 2.438116\tAccuracy: 32.60%\n",
      "483\tValidation loss: 2.439465\tBest loss: 2.438116\tAccuracy: 33.90%\n",
      "484\tValidation loss: 2.451229\tBest loss: 2.438116\tAccuracy: 33.40%\n",
      "485\tValidation loss: 2.455459\tBest loss: 2.438116\tAccuracy: 33.20%\n",
      "486\tValidation loss: 2.435949\tBest loss: 2.435949\tAccuracy: 33.80%\n",
      "487\tValidation loss: 2.431970\tBest loss: 2.431970\tAccuracy: 35.10%\n",
      "488\tValidation loss: 2.431297\tBest loss: 2.431297\tAccuracy: 33.40%\n",
      "489\tValidation loss: 2.446422\tBest loss: 2.431297\tAccuracy: 33.20%\n",
      "490\tValidation loss: 2.413566\tBest loss: 2.413566\tAccuracy: 34.60%\n",
      "491\tValidation loss: 2.462208\tBest loss: 2.413566\tAccuracy: 33.10%\n",
      "492\tValidation loss: 2.426359\tBest loss: 2.413566\tAccuracy: 33.70%\n",
      "493\tValidation loss: 2.438646\tBest loss: 2.413566\tAccuracy: 32.40%\n",
      "494\tValidation loss: 2.427604\tBest loss: 2.413566\tAccuracy: 34.20%\n",
      "495\tValidation loss: 2.423784\tBest loss: 2.413566\tAccuracy: 33.40%\n",
      "496\tValidation loss: 2.431604\tBest loss: 2.413566\tAccuracy: 32.70%\n",
      "497\tValidation loss: 2.463167\tBest loss: 2.413566\tAccuracy: 33.00%\n",
      "498\tValidation loss: 2.417117\tBest loss: 2.413566\tAccuracy: 33.90%\n",
      "499\tValidation loss: 2.418844\tBest loss: 2.413566\tAccuracy: 33.00%\n",
      "500\tValidation loss: 2.422843\tBest loss: 2.413566\tAccuracy: 33.60%\n",
      "501\tValidation loss: 2.420667\tBest loss: 2.413566\tAccuracy: 32.90%\n",
      "502\tValidation loss: 2.414407\tBest loss: 2.413566\tAccuracy: 33.80%\n",
      "503\tValidation loss: 2.414262\tBest loss: 2.413566\tAccuracy: 34.80%\n",
      "504\tValidation loss: 2.432329\tBest loss: 2.413566\tAccuracy: 33.70%\n",
      "505\tValidation loss: 2.426769\tBest loss: 2.413566\tAccuracy: 34.20%\n",
      "506\tValidation loss: 2.424681\tBest loss: 2.413566\tAccuracy: 33.30%\n",
      "507\tValidation loss: 2.394409\tBest loss: 2.394409\tAccuracy: 33.80%\n",
      "508\tValidation loss: 2.399961\tBest loss: 2.394409\tAccuracy: 33.70%\n",
      "509\tValidation loss: 2.413892\tBest loss: 2.394409\tAccuracy: 34.70%\n",
      "510\tValidation loss: 2.407993\tBest loss: 2.394409\tAccuracy: 34.30%\n",
      "511\tValidation loss: 2.399132\tBest loss: 2.394409\tAccuracy: 33.90%\n",
      "512\tValidation loss: 2.395397\tBest loss: 2.394409\tAccuracy: 34.40%\n",
      "513\tValidation loss: 2.411840\tBest loss: 2.394409\tAccuracy: 34.30%\n",
      "514\tValidation loss: 2.411005\tBest loss: 2.394409\tAccuracy: 33.00%\n",
      "515\tValidation loss: 2.394278\tBest loss: 2.394278\tAccuracy: 33.60%\n",
      "516\tValidation loss: 2.414561\tBest loss: 2.394278\tAccuracy: 33.80%\n",
      "517\tValidation loss: 2.386509\tBest loss: 2.386509\tAccuracy: 35.20%\n",
      "518\tValidation loss: 2.409555\tBest loss: 2.386509\tAccuracy: 34.30%\n",
      "519\tValidation loss: 2.387450\tBest loss: 2.386509\tAccuracy: 33.30%\n",
      "520\tValidation loss: 2.396275\tBest loss: 2.386509\tAccuracy: 33.70%\n",
      "521\tValidation loss: 2.391811\tBest loss: 2.386509\tAccuracy: 33.20%\n",
      "522\tValidation loss: 2.392846\tBest loss: 2.386509\tAccuracy: 35.00%\n",
      "523\tValidation loss: 2.375329\tBest loss: 2.375329\tAccuracy: 34.20%\n",
      "524\tValidation loss: 2.378378\tBest loss: 2.375329\tAccuracy: 34.80%\n",
      "525\tValidation loss: 2.380343\tBest loss: 2.375329\tAccuracy: 35.70%\n",
      "526\tValidation loss: 2.377281\tBest loss: 2.375329\tAccuracy: 35.50%\n",
      "527\tValidation loss: 2.401246\tBest loss: 2.375329\tAccuracy: 35.10%\n",
      "528\tValidation loss: 2.360379\tBest loss: 2.360379\tAccuracy: 35.90%\n",
      "529\tValidation loss: 2.366126\tBest loss: 2.360379\tAccuracy: 35.20%\n",
      "530\tValidation loss: 2.395250\tBest loss: 2.360379\tAccuracy: 33.90%\n",
      "531\tValidation loss: 2.377922\tBest loss: 2.360379\tAccuracy: 34.90%\n",
      "532\tValidation loss: 2.386101\tBest loss: 2.360379\tAccuracy: 34.00%\n",
      "533\tValidation loss: 2.389704\tBest loss: 2.360379\tAccuracy: 34.50%\n",
      "534\tValidation loss: 2.376035\tBest loss: 2.360379\tAccuracy: 35.20%\n",
      "535\tValidation loss: 2.361829\tBest loss: 2.360379\tAccuracy: 36.70%\n",
      "536\tValidation loss: 2.373748\tBest loss: 2.360379\tAccuracy: 35.40%\n",
      "537\tValidation loss: 2.358275\tBest loss: 2.358275\tAccuracy: 36.50%\n",
      "538\tValidation loss: 2.368839\tBest loss: 2.358275\tAccuracy: 35.30%\n",
      "539\tValidation loss: 2.349753\tBest loss: 2.349753\tAccuracy: 36.40%\n",
      "540\tValidation loss: 2.368826\tBest loss: 2.349753\tAccuracy: 37.60%\n",
      "541\tValidation loss: 2.356434\tBest loss: 2.349753\tAccuracy: 35.30%\n",
      "542\tValidation loss: 2.367603\tBest loss: 2.349753\tAccuracy: 34.50%\n",
      "543\tValidation loss: 2.370925\tBest loss: 2.349753\tAccuracy: 34.50%\n",
      "544\tValidation loss: 2.355705\tBest loss: 2.349753\tAccuracy: 35.50%\n",
      "545\tValidation loss: 2.377765\tBest loss: 2.349753\tAccuracy: 33.70%\n",
      "546\tValidation loss: 2.370004\tBest loss: 2.349753\tAccuracy: 34.30%\n",
      "547\tValidation loss: 2.356614\tBest loss: 2.349753\tAccuracy: 34.70%\n",
      "548\tValidation loss: 2.370173\tBest loss: 2.349753\tAccuracy: 34.40%\n",
      "549\tValidation loss: 2.328901\tBest loss: 2.328901\tAccuracy: 35.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\tValidation loss: 2.335773\tBest loss: 2.328901\tAccuracy: 36.80%\n",
      "551\tValidation loss: 2.352451\tBest loss: 2.328901\tAccuracy: 33.90%\n",
      "552\tValidation loss: 2.347579\tBest loss: 2.328901\tAccuracy: 34.40%\n",
      "553\tValidation loss: 2.351778\tBest loss: 2.328901\tAccuracy: 34.90%\n",
      "554\tValidation loss: 2.355908\tBest loss: 2.328901\tAccuracy: 34.10%\n",
      "555\tValidation loss: 2.362689\tBest loss: 2.328901\tAccuracy: 35.10%\n",
      "556\tValidation loss: 2.359195\tBest loss: 2.328901\tAccuracy: 35.80%\n",
      "557\tValidation loss: 2.357341\tBest loss: 2.328901\tAccuracy: 34.80%\n",
      "558\tValidation loss: 2.332190\tBest loss: 2.328901\tAccuracy: 36.40%\n",
      "559\tValidation loss: 2.335101\tBest loss: 2.328901\tAccuracy: 36.40%\n",
      "560\tValidation loss: 2.335012\tBest loss: 2.328901\tAccuracy: 34.10%\n",
      "561\tValidation loss: 2.345959\tBest loss: 2.328901\tAccuracy: 35.30%\n",
      "562\tValidation loss: 2.334645\tBest loss: 2.328901\tAccuracy: 35.30%\n",
      "563\tValidation loss: 2.323849\tBest loss: 2.323849\tAccuracy: 35.80%\n",
      "564\tValidation loss: 2.342045\tBest loss: 2.323849\tAccuracy: 36.00%\n",
      "565\tValidation loss: 2.339493\tBest loss: 2.323849\tAccuracy: 35.70%\n",
      "566\tValidation loss: 2.338135\tBest loss: 2.323849\tAccuracy: 35.50%\n",
      "567\tValidation loss: 2.348675\tBest loss: 2.323849\tAccuracy: 33.20%\n",
      "568\tValidation loss: 2.349510\tBest loss: 2.323849\tAccuracy: 36.10%\n",
      "569\tValidation loss: 2.340439\tBest loss: 2.323849\tAccuracy: 35.30%\n",
      "570\tValidation loss: 2.344453\tBest loss: 2.323849\tAccuracy: 34.20%\n",
      "571\tValidation loss: 2.370828\tBest loss: 2.323849\tAccuracy: 34.60%\n",
      "572\tValidation loss: 2.316495\tBest loss: 2.316495\tAccuracy: 36.30%\n",
      "573\tValidation loss: 2.332724\tBest loss: 2.316495\tAccuracy: 36.20%\n",
      "574\tValidation loss: 2.331381\tBest loss: 2.316495\tAccuracy: 35.40%\n",
      "575\tValidation loss: 2.313076\tBest loss: 2.313076\tAccuracy: 34.90%\n",
      "576\tValidation loss: 2.334422\tBest loss: 2.313076\tAccuracy: 34.50%\n",
      "577\tValidation loss: 2.338982\tBest loss: 2.313076\tAccuracy: 34.50%\n",
      "578\tValidation loss: 2.307870\tBest loss: 2.307870\tAccuracy: 36.50%\n",
      "579\tValidation loss: 2.329533\tBest loss: 2.307870\tAccuracy: 35.60%\n",
      "580\tValidation loss: 2.315634\tBest loss: 2.307870\tAccuracy: 36.80%\n",
      "581\tValidation loss: 2.321401\tBest loss: 2.307870\tAccuracy: 36.60%\n",
      "582\tValidation loss: 2.329128\tBest loss: 2.307870\tAccuracy: 35.40%\n",
      "583\tValidation loss: 2.313320\tBest loss: 2.307870\tAccuracy: 36.40%\n",
      "584\tValidation loss: 2.315002\tBest loss: 2.307870\tAccuracy: 37.10%\n",
      "585\tValidation loss: 2.299267\tBest loss: 2.299267\tAccuracy: 37.10%\n",
      "586\tValidation loss: 2.309572\tBest loss: 2.299267\tAccuracy: 36.20%\n",
      "587\tValidation loss: 2.324292\tBest loss: 2.299267\tAccuracy: 37.30%\n",
      "588\tValidation loss: 2.314545\tBest loss: 2.299267\tAccuracy: 35.20%\n",
      "589\tValidation loss: 2.301260\tBest loss: 2.299267\tAccuracy: 35.60%\n",
      "590\tValidation loss: 2.300492\tBest loss: 2.299267\tAccuracy: 36.80%\n",
      "591\tValidation loss: 2.312855\tBest loss: 2.299267\tAccuracy: 35.90%\n",
      "592\tValidation loss: 2.290075\tBest loss: 2.290075\tAccuracy: 36.80%\n",
      "593\tValidation loss: 2.304555\tBest loss: 2.290075\tAccuracy: 35.60%\n",
      "594\tValidation loss: 2.292010\tBest loss: 2.290075\tAccuracy: 36.70%\n",
      "595\tValidation loss: 2.291702\tBest loss: 2.290075\tAccuracy: 36.50%\n",
      "596\tValidation loss: 2.287571\tBest loss: 2.287571\tAccuracy: 36.00%\n",
      "597\tValidation loss: 2.292272\tBest loss: 2.287571\tAccuracy: 36.00%\n",
      "598\tValidation loss: 2.274041\tBest loss: 2.274041\tAccuracy: 37.10%\n",
      "599\tValidation loss: 2.289372\tBest loss: 2.274041\tAccuracy: 36.70%\n",
      "600\tValidation loss: 2.276456\tBest loss: 2.274041\tAccuracy: 36.40%\n",
      "601\tValidation loss: 2.289030\tBest loss: 2.274041\tAccuracy: 35.40%\n",
      "602\tValidation loss: 2.263332\tBest loss: 2.263332\tAccuracy: 37.60%\n",
      "603\tValidation loss: 2.306412\tBest loss: 2.263332\tAccuracy: 36.10%\n",
      "604\tValidation loss: 2.277996\tBest loss: 2.263332\tAccuracy: 36.60%\n",
      "605\tValidation loss: 2.282588\tBest loss: 2.263332\tAccuracy: 37.50%\n",
      "606\tValidation loss: 2.290727\tBest loss: 2.263332\tAccuracy: 37.00%\n",
      "607\tValidation loss: 2.271916\tBest loss: 2.263332\tAccuracy: 37.10%\n",
      "608\tValidation loss: 2.289799\tBest loss: 2.263332\tAccuracy: 36.00%\n",
      "609\tValidation loss: 2.291929\tBest loss: 2.263332\tAccuracy: 36.90%\n",
      "610\tValidation loss: 2.276812\tBest loss: 2.263332\tAccuracy: 36.10%\n",
      "611\tValidation loss: 2.272200\tBest loss: 2.263332\tAccuracy: 36.60%\n",
      "612\tValidation loss: 2.265932\tBest loss: 2.263332\tAccuracy: 38.10%\n",
      "613\tValidation loss: 2.298652\tBest loss: 2.263332\tAccuracy: 34.90%\n",
      "614\tValidation loss: 2.284513\tBest loss: 2.263332\tAccuracy: 36.20%\n",
      "615\tValidation loss: 2.276783\tBest loss: 2.263332\tAccuracy: 37.30%\n",
      "616\tValidation loss: 2.267462\tBest loss: 2.263332\tAccuracy: 37.40%\n",
      "617\tValidation loss: 2.277062\tBest loss: 2.263332\tAccuracy: 36.80%\n",
      "618\tValidation loss: 2.275271\tBest loss: 2.263332\tAccuracy: 36.20%\n",
      "619\tValidation loss: 2.269106\tBest loss: 2.263332\tAccuracy: 36.70%\n",
      "620\tValidation loss: 2.285184\tBest loss: 2.263332\tAccuracy: 36.10%\n",
      "621\tValidation loss: 2.271662\tBest loss: 2.263332\tAccuracy: 36.60%\n",
      "622\tValidation loss: 2.261897\tBest loss: 2.261897\tAccuracy: 38.40%\n",
      "623\tValidation loss: 2.246215\tBest loss: 2.246215\tAccuracy: 37.70%\n",
      "624\tValidation loss: 2.271454\tBest loss: 2.246215\tAccuracy: 38.40%\n",
      "625\tValidation loss: 2.259063\tBest loss: 2.246215\tAccuracy: 37.90%\n",
      "626\tValidation loss: 2.286296\tBest loss: 2.246215\tAccuracy: 36.80%\n",
      "627\tValidation loss: 2.266650\tBest loss: 2.246215\tAccuracy: 37.80%\n",
      "628\tValidation loss: 2.252626\tBest loss: 2.246215\tAccuracy: 38.20%\n",
      "629\tValidation loss: 2.267334\tBest loss: 2.246215\tAccuracy: 38.50%\n",
      "630\tValidation loss: 2.260706\tBest loss: 2.246215\tAccuracy: 38.20%\n",
      "631\tValidation loss: 2.268758\tBest loss: 2.246215\tAccuracy: 37.10%\n",
      "632\tValidation loss: 2.235147\tBest loss: 2.235147\tAccuracy: 38.40%\n",
      "633\tValidation loss: 2.241577\tBest loss: 2.235147\tAccuracy: 38.20%\n",
      "634\tValidation loss: 2.269217\tBest loss: 2.235147\tAccuracy: 38.20%\n",
      "635\tValidation loss: 2.280976\tBest loss: 2.235147\tAccuracy: 37.30%\n",
      "636\tValidation loss: 2.256389\tBest loss: 2.235147\tAccuracy: 36.90%\n",
      "637\tValidation loss: 2.244959\tBest loss: 2.235147\tAccuracy: 37.80%\n",
      "638\tValidation loss: 2.245639\tBest loss: 2.235147\tAccuracy: 38.00%\n",
      "639\tValidation loss: 2.262987\tBest loss: 2.235147\tAccuracy: 38.00%\n",
      "640\tValidation loss: 2.250620\tBest loss: 2.235147\tAccuracy: 37.90%\n",
      "641\tValidation loss: 2.234446\tBest loss: 2.234446\tAccuracy: 38.00%\n",
      "642\tValidation loss: 2.246838\tBest loss: 2.234446\tAccuracy: 37.70%\n",
      "643\tValidation loss: 2.224435\tBest loss: 2.224435\tAccuracy: 38.30%\n",
      "644\tValidation loss: 2.249584\tBest loss: 2.224435\tAccuracy: 37.30%\n",
      "645\tValidation loss: 2.233685\tBest loss: 2.224435\tAccuracy: 37.80%\n",
      "646\tValidation loss: 2.247057\tBest loss: 2.224435\tAccuracy: 38.50%\n",
      "647\tValidation loss: 2.242322\tBest loss: 2.224435\tAccuracy: 38.20%\n",
      "648\tValidation loss: 2.231568\tBest loss: 2.224435\tAccuracy: 39.20%\n",
      "649\tValidation loss: 2.228638\tBest loss: 2.224435\tAccuracy: 39.30%\n",
      "650\tValidation loss: 2.236729\tBest loss: 2.224435\tAccuracy: 39.30%\n",
      "651\tValidation loss: 2.243210\tBest loss: 2.224435\tAccuracy: 37.10%\n",
      "652\tValidation loss: 2.228554\tBest loss: 2.224435\tAccuracy: 38.50%\n",
      "653\tValidation loss: 2.230939\tBest loss: 2.224435\tAccuracy: 38.80%\n",
      "654\tValidation loss: 2.224699\tBest loss: 2.224435\tAccuracy: 39.40%\n",
      "655\tValidation loss: 2.233148\tBest loss: 2.224435\tAccuracy: 39.70%\n",
      "656\tValidation loss: 2.227852\tBest loss: 2.224435\tAccuracy: 38.70%\n",
      "657\tValidation loss: 2.224044\tBest loss: 2.224044\tAccuracy: 39.20%\n",
      "658\tValidation loss: 2.225988\tBest loss: 2.224044\tAccuracy: 38.40%\n",
      "659\tValidation loss: 2.238153\tBest loss: 2.224044\tAccuracy: 40.10%\n",
      "660\tValidation loss: 2.222837\tBest loss: 2.222837\tAccuracy: 39.60%\n",
      "661\tValidation loss: 2.237644\tBest loss: 2.222837\tAccuracy: 38.50%\n",
      "662\tValidation loss: 2.243368\tBest loss: 2.222837\tAccuracy: 37.70%\n",
      "663\tValidation loss: 2.238694\tBest loss: 2.222837\tAccuracy: 38.20%\n",
      "664\tValidation loss: 2.226213\tBest loss: 2.222837\tAccuracy: 38.50%\n",
      "665\tValidation loss: 2.227492\tBest loss: 2.222837\tAccuracy: 37.90%\n",
      "666\tValidation loss: 2.225338\tBest loss: 2.222837\tAccuracy: 37.10%\n",
      "667\tValidation loss: 2.205108\tBest loss: 2.205108\tAccuracy: 38.70%\n",
      "668\tValidation loss: 2.210625\tBest loss: 2.205108\tAccuracy: 38.40%\n",
      "669\tValidation loss: 2.228200\tBest loss: 2.205108\tAccuracy: 38.10%\n",
      "670\tValidation loss: 2.215657\tBest loss: 2.205108\tAccuracy: 38.10%\n",
      "671\tValidation loss: 2.229762\tBest loss: 2.205108\tAccuracy: 38.90%\n",
      "672\tValidation loss: 2.214225\tBest loss: 2.205108\tAccuracy: 38.60%\n",
      "673\tValidation loss: 2.220709\tBest loss: 2.205108\tAccuracy: 38.20%\n",
      "674\tValidation loss: 2.195947\tBest loss: 2.195947\tAccuracy: 39.80%\n",
      "675\tValidation loss: 2.217247\tBest loss: 2.195947\tAccuracy: 37.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\tValidation loss: 2.208368\tBest loss: 2.195947\tAccuracy: 39.20%\n",
      "677\tValidation loss: 2.209518\tBest loss: 2.195947\tAccuracy: 39.70%\n",
      "678\tValidation loss: 2.205842\tBest loss: 2.195947\tAccuracy: 40.30%\n",
      "679\tValidation loss: 2.211967\tBest loss: 2.195947\tAccuracy: 38.60%\n",
      "680\tValidation loss: 2.214856\tBest loss: 2.195947\tAccuracy: 38.90%\n",
      "681\tValidation loss: 2.204599\tBest loss: 2.195947\tAccuracy: 38.00%\n",
      "682\tValidation loss: 2.216658\tBest loss: 2.195947\tAccuracy: 38.10%\n",
      "683\tValidation loss: 2.204361\tBest loss: 2.195947\tAccuracy: 38.60%\n",
      "684\tValidation loss: 2.202096\tBest loss: 2.195947\tAccuracy: 38.20%\n",
      "685\tValidation loss: 2.203862\tBest loss: 2.195947\tAccuracy: 39.60%\n",
      "686\tValidation loss: 2.205243\tBest loss: 2.195947\tAccuracy: 39.40%\n",
      "687\tValidation loss: 2.199364\tBest loss: 2.195947\tAccuracy: 40.20%\n",
      "688\tValidation loss: 2.229619\tBest loss: 2.195947\tAccuracy: 38.80%\n",
      "689\tValidation loss: 2.211828\tBest loss: 2.195947\tAccuracy: 39.20%\n",
      "690\tValidation loss: 2.206617\tBest loss: 2.195947\tAccuracy: 39.40%\n",
      "691\tValidation loss: 2.222309\tBest loss: 2.195947\tAccuracy: 39.30%\n",
      "692\tValidation loss: 2.192478\tBest loss: 2.192478\tAccuracy: 37.40%\n",
      "693\tValidation loss: 2.180590\tBest loss: 2.180590\tAccuracy: 39.70%\n",
      "694\tValidation loss: 2.201378\tBest loss: 2.180590\tAccuracy: 38.90%\n",
      "695\tValidation loss: 2.194205\tBest loss: 2.180590\tAccuracy: 39.40%\n",
      "696\tValidation loss: 2.179190\tBest loss: 2.179190\tAccuracy: 38.60%\n",
      "697\tValidation loss: 2.186185\tBest loss: 2.179190\tAccuracy: 39.10%\n",
      "698\tValidation loss: 2.190971\tBest loss: 2.179190\tAccuracy: 39.20%\n",
      "699\tValidation loss: 2.187957\tBest loss: 2.179190\tAccuracy: 39.10%\n",
      "700\tValidation loss: 2.210474\tBest loss: 2.179190\tAccuracy: 37.50%\n",
      "701\tValidation loss: 2.206635\tBest loss: 2.179190\tAccuracy: 38.40%\n",
      "702\tValidation loss: 2.197270\tBest loss: 2.179190\tAccuracy: 39.40%\n",
      "703\tValidation loss: 2.187992\tBest loss: 2.179190\tAccuracy: 40.30%\n",
      "704\tValidation loss: 2.192640\tBest loss: 2.179190\tAccuracy: 38.90%\n",
      "705\tValidation loss: 2.194585\tBest loss: 2.179190\tAccuracy: 38.10%\n",
      "706\tValidation loss: 2.189769\tBest loss: 2.179190\tAccuracy: 39.00%\n",
      "707\tValidation loss: 2.183810\tBest loss: 2.179190\tAccuracy: 40.50%\n",
      "708\tValidation loss: 2.173026\tBest loss: 2.173026\tAccuracy: 38.70%\n",
      "709\tValidation loss: 2.192253\tBest loss: 2.173026\tAccuracy: 38.60%\n",
      "710\tValidation loss: 2.183713\tBest loss: 2.173026\tAccuracy: 39.20%\n",
      "711\tValidation loss: 2.172706\tBest loss: 2.172706\tAccuracy: 40.10%\n",
      "712\tValidation loss: 2.180956\tBest loss: 2.172706\tAccuracy: 39.70%\n",
      "713\tValidation loss: 2.170281\tBest loss: 2.170281\tAccuracy: 40.40%\n",
      "714\tValidation loss: 2.172972\tBest loss: 2.170281\tAccuracy: 38.60%\n",
      "715\tValidation loss: 2.163458\tBest loss: 2.163458\tAccuracy: 38.90%\n",
      "716\tValidation loss: 2.177076\tBest loss: 2.163458\tAccuracy: 39.10%\n",
      "717\tValidation loss: 2.173324\tBest loss: 2.163458\tAccuracy: 40.80%\n",
      "718\tValidation loss: 2.173604\tBest loss: 2.163458\tAccuracy: 39.10%\n",
      "719\tValidation loss: 2.160908\tBest loss: 2.160908\tAccuracy: 40.50%\n",
      "720\tValidation loss: 2.164557\tBest loss: 2.160908\tAccuracy: 40.90%\n",
      "721\tValidation loss: 2.173558\tBest loss: 2.160908\tAccuracy: 38.60%\n",
      "722\tValidation loss: 2.160179\tBest loss: 2.160179\tAccuracy: 38.30%\n",
      "723\tValidation loss: 2.172184\tBest loss: 2.160179\tAccuracy: 38.20%\n",
      "724\tValidation loss: 2.166731\tBest loss: 2.160179\tAccuracy: 40.20%\n",
      "725\tValidation loss: 2.164270\tBest loss: 2.160179\tAccuracy: 39.90%\n",
      "726\tValidation loss: 2.166254\tBest loss: 2.160179\tAccuracy: 40.00%\n",
      "727\tValidation loss: 2.191706\tBest loss: 2.160179\tAccuracy: 40.80%\n",
      "728\tValidation loss: 2.174911\tBest loss: 2.160179\tAccuracy: 39.00%\n",
      "729\tValidation loss: 2.172053\tBest loss: 2.160179\tAccuracy: 40.40%\n",
      "730\tValidation loss: 2.171516\tBest loss: 2.160179\tAccuracy: 39.80%\n",
      "731\tValidation loss: 2.156420\tBest loss: 2.156420\tAccuracy: 39.50%\n",
      "732\tValidation loss: 2.157784\tBest loss: 2.156420\tAccuracy: 39.10%\n",
      "733\tValidation loss: 2.161666\tBest loss: 2.156420\tAccuracy: 39.50%\n",
      "734\tValidation loss: 2.141109\tBest loss: 2.141109\tAccuracy: 39.20%\n",
      "735\tValidation loss: 2.174612\tBest loss: 2.141109\tAccuracy: 39.50%\n",
      "736\tValidation loss: 2.145353\tBest loss: 2.141109\tAccuracy: 40.90%\n",
      "737\tValidation loss: 2.159241\tBest loss: 2.141109\tAccuracy: 39.90%\n",
      "738\tValidation loss: 2.150503\tBest loss: 2.141109\tAccuracy: 39.40%\n",
      "739\tValidation loss: 2.171592\tBest loss: 2.141109\tAccuracy: 39.20%\n",
      "740\tValidation loss: 2.161389\tBest loss: 2.141109\tAccuracy: 40.50%\n",
      "741\tValidation loss: 2.158326\tBest loss: 2.141109\tAccuracy: 40.80%\n",
      "742\tValidation loss: 2.145702\tBest loss: 2.141109\tAccuracy: 40.50%\n",
      "743\tValidation loss: 2.156569\tBest loss: 2.141109\tAccuracy: 40.30%\n",
      "744\tValidation loss: 2.158657\tBest loss: 2.141109\tAccuracy: 40.00%\n",
      "745\tValidation loss: 2.156714\tBest loss: 2.141109\tAccuracy: 39.70%\n",
      "746\tValidation loss: 2.170596\tBest loss: 2.141109\tAccuracy: 39.80%\n",
      "747\tValidation loss: 2.142948\tBest loss: 2.141109\tAccuracy: 41.40%\n",
      "748\tValidation loss: 2.177155\tBest loss: 2.141109\tAccuracy: 38.80%\n",
      "749\tValidation loss: 2.149922\tBest loss: 2.141109\tAccuracy: 40.60%\n",
      "750\tValidation loss: 2.160135\tBest loss: 2.141109\tAccuracy: 40.70%\n",
      "751\tValidation loss: 2.142585\tBest loss: 2.141109\tAccuracy: 42.40%\n",
      "752\tValidation loss: 2.145931\tBest loss: 2.141109\tAccuracy: 39.90%\n",
      "753\tValidation loss: 2.142341\tBest loss: 2.141109\tAccuracy: 40.90%\n",
      "754\tValidation loss: 2.125294\tBest loss: 2.125294\tAccuracy: 40.80%\n",
      "755\tValidation loss: 2.142376\tBest loss: 2.125294\tAccuracy: 41.10%\n",
      "756\tValidation loss: 2.143281\tBest loss: 2.125294\tAccuracy: 41.00%\n",
      "757\tValidation loss: 2.132956\tBest loss: 2.125294\tAccuracy: 40.70%\n",
      "758\tValidation loss: 2.146930\tBest loss: 2.125294\tAccuracy: 42.10%\n",
      "759\tValidation loss: 2.132648\tBest loss: 2.125294\tAccuracy: 40.80%\n",
      "760\tValidation loss: 2.150824\tBest loss: 2.125294\tAccuracy: 39.80%\n",
      "761\tValidation loss: 2.129219\tBest loss: 2.125294\tAccuracy: 40.50%\n",
      "762\tValidation loss: 2.134363\tBest loss: 2.125294\tAccuracy: 41.80%\n",
      "763\tValidation loss: 2.145655\tBest loss: 2.125294\tAccuracy: 41.30%\n",
      "764\tValidation loss: 2.131688\tBest loss: 2.125294\tAccuracy: 41.60%\n",
      "765\tValidation loss: 2.132159\tBest loss: 2.125294\tAccuracy: 40.80%\n",
      "766\tValidation loss: 2.117974\tBest loss: 2.117974\tAccuracy: 42.90%\n",
      "767\tValidation loss: 2.127070\tBest loss: 2.117974\tAccuracy: 41.60%\n",
      "768\tValidation loss: 2.105443\tBest loss: 2.105443\tAccuracy: 42.20%\n",
      "769\tValidation loss: 2.112277\tBest loss: 2.105443\tAccuracy: 42.70%\n",
      "770\tValidation loss: 2.128273\tBest loss: 2.105443\tAccuracy: 41.50%\n",
      "771\tValidation loss: 2.118976\tBest loss: 2.105443\tAccuracy: 41.60%\n",
      "772\tValidation loss: 2.126703\tBest loss: 2.105443\tAccuracy: 40.40%\n",
      "773\tValidation loss: 2.126107\tBest loss: 2.105443\tAccuracy: 42.80%\n",
      "774\tValidation loss: 2.133687\tBest loss: 2.105443\tAccuracy: 39.70%\n",
      "775\tValidation loss: 2.128255\tBest loss: 2.105443\tAccuracy: 41.70%\n",
      "776\tValidation loss: 2.111681\tBest loss: 2.105443\tAccuracy: 40.30%\n",
      "777\tValidation loss: 2.120980\tBest loss: 2.105443\tAccuracy: 42.20%\n",
      "778\tValidation loss: 2.120395\tBest loss: 2.105443\tAccuracy: 41.40%\n",
      "779\tValidation loss: 2.106524\tBest loss: 2.105443\tAccuracy: 41.60%\n",
      "780\tValidation loss: 2.124702\tBest loss: 2.105443\tAccuracy: 40.80%\n",
      "781\tValidation loss: 2.110269\tBest loss: 2.105443\tAccuracy: 42.00%\n",
      "782\tValidation loss: 2.123703\tBest loss: 2.105443\tAccuracy: 42.30%\n",
      "783\tValidation loss: 2.117026\tBest loss: 2.105443\tAccuracy: 42.10%\n",
      "784\tValidation loss: 2.123364\tBest loss: 2.105443\tAccuracy: 42.40%\n",
      "785\tValidation loss: 2.125698\tBest loss: 2.105443\tAccuracy: 42.60%\n",
      "786\tValidation loss: 2.118783\tBest loss: 2.105443\tAccuracy: 42.00%\n",
      "787\tValidation loss: 2.100632\tBest loss: 2.100632\tAccuracy: 42.60%\n",
      "788\tValidation loss: 2.111389\tBest loss: 2.100632\tAccuracy: 41.20%\n",
      "789\tValidation loss: 2.089528\tBest loss: 2.089528\tAccuracy: 42.10%\n",
      "790\tValidation loss: 2.121430\tBest loss: 2.089528\tAccuracy: 42.00%\n",
      "791\tValidation loss: 2.111773\tBest loss: 2.089528\tAccuracy: 42.60%\n",
      "792\tValidation loss: 2.098621\tBest loss: 2.089528\tAccuracy: 42.20%\n",
      "793\tValidation loss: 2.090931\tBest loss: 2.089528\tAccuracy: 42.80%\n",
      "794\tValidation loss: 2.094522\tBest loss: 2.089528\tAccuracy: 42.90%\n",
      "795\tValidation loss: 2.109887\tBest loss: 2.089528\tAccuracy: 42.60%\n",
      "796\tValidation loss: 2.091804\tBest loss: 2.089528\tAccuracy: 41.90%\n",
      "797\tValidation loss: 2.095312\tBest loss: 2.089528\tAccuracy: 44.10%\n",
      "798\tValidation loss: 2.127982\tBest loss: 2.089528\tAccuracy: 41.70%\n",
      "799\tValidation loss: 2.118168\tBest loss: 2.089528\tAccuracy: 42.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\tValidation loss: 2.099621\tBest loss: 2.089528\tAccuracy: 41.30%\n",
      "801\tValidation loss: 2.108003\tBest loss: 2.089528\tAccuracy: 43.30%\n",
      "802\tValidation loss: 2.109102\tBest loss: 2.089528\tAccuracy: 42.80%\n",
      "803\tValidation loss: 2.113799\tBest loss: 2.089528\tAccuracy: 41.60%\n",
      "804\tValidation loss: 2.091796\tBest loss: 2.089528\tAccuracy: 42.40%\n",
      "805\tValidation loss: 2.093734\tBest loss: 2.089528\tAccuracy: 41.90%\n",
      "806\tValidation loss: 2.122568\tBest loss: 2.089528\tAccuracy: 42.90%\n",
      "807\tValidation loss: 2.104241\tBest loss: 2.089528\tAccuracy: 41.60%\n",
      "808\tValidation loss: 2.093649\tBest loss: 2.089528\tAccuracy: 42.20%\n",
      "809\tValidation loss: 2.097991\tBest loss: 2.089528\tAccuracy: 41.90%\n",
      "810\tValidation loss: 2.089862\tBest loss: 2.089528\tAccuracy: 42.10%\n",
      "Early stopping!\n",
      "[[  9.72455833e-03   3.74475569e-02   1.36993611e-02 ...,   6.89476449e-03\n",
      "    2.30897777e-03   2.18785903e-03]\n",
      " [  3.62089922e-05   1.06958859e-02   5.21287962e-04 ...,   1.00775777e-09\n",
      "    1.07830374e-05   7.97284156e-06]\n",
      " [  7.38871284e-04   9.82667413e-03   1.59738783e-03 ...,   4.34489884e-05\n",
      "    8.73662648e-04   7.79383816e-04]\n",
      " ..., \n",
      " [  3.45257507e-03   1.81047490e-03   6.66926149e-03 ...,   1.33107258e-02\n",
      "    1.03540979e-02   1.64740589e-02]\n",
      " [  3.03875003e-03   5.32230642e-03   4.41214116e-03 ...,   9.30195600e-02\n",
      "    5.74778914e-02   6.18465841e-02]\n",
      " [  1.03427956e-04   6.96455361e-04   2.15371459e-04 ...,   1.03138179e-01\n",
      "    2.45142709e-02   1.36218499e-02]]\n",
      "[12 43 43 ...,  8  8 24]\n",
      "[[  1.54656562e-04   2.81521473e-02   8.18599481e-03 ...,   6.77676082e-10\n",
      "    1.06616884e-04   3.66397217e-05]\n",
      " [  1.13033935e-01   3.29371989e-02   6.05844408e-02 ...,   4.66587953e-03\n",
      "    3.73942661e-03   3.49979149e-03]\n",
      " [  1.29197302e-04   5.58942439e-08   7.16766529e-03 ...,   5.25868672e-04\n",
      "    3.65541233e-08   5.07897092e-11]\n",
      " ..., \n",
      " [  8.93045124e-03   2.04377025e-02   3.42737022e-03 ...,   2.09906830e-05\n",
      "    4.91557403e-05   6.35367951e-06]\n",
      " [  4.00659405e-02   2.01161485e-02   3.66409160e-02 ...,   6.51753135e-03\n",
      "    6.98974729e-03   6.00695051e-03]\n",
      " [  7.71886553e-05   5.39259752e-04   2.07925943e-04 ...,   1.57302439e-01\n",
      "    8.86796266e-02   1.69786558e-01]]\n",
      "[ 9  0 18 ...,  6  9  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  42.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.862026\tBest loss: 3.862026\tAccuracy: 4.00%\n",
      "1\tValidation loss: 3.852046\tBest loss: 3.852046\tAccuracy: 4.20%\n",
      "2\tValidation loss: 3.845815\tBest loss: 3.845815\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.838315\tBest loss: 3.838315\tAccuracy: 4.00%\n",
      "4\tValidation loss: 3.831233\tBest loss: 3.831233\tAccuracy: 4.00%\n",
      "5\tValidation loss: 3.827051\tBest loss: 3.827051\tAccuracy: 3.90%\n",
      "6\tValidation loss: 3.821006\tBest loss: 3.821006\tAccuracy: 4.10%\n",
      "7\tValidation loss: 3.817135\tBest loss: 3.817135\tAccuracy: 4.00%\n",
      "8\tValidation loss: 3.814626\tBest loss: 3.814626\tAccuracy: 4.20%\n",
      "9\tValidation loss: 3.813280\tBest loss: 3.813280\tAccuracy: 4.00%\n",
      "10\tValidation loss: 3.810104\tBest loss: 3.810104\tAccuracy: 3.90%\n",
      "11\tValidation loss: 3.806846\tBest loss: 3.806846\tAccuracy: 4.00%\n",
      "12\tValidation loss: 3.802412\tBest loss: 3.802412\tAccuracy: 4.10%\n",
      "13\tValidation loss: 3.799594\tBest loss: 3.799594\tAccuracy: 4.00%\n",
      "14\tValidation loss: 3.797423\tBest loss: 3.797423\tAccuracy: 4.00%\n",
      "15\tValidation loss: 3.795252\tBest loss: 3.795252\tAccuracy: 4.10%\n",
      "16\tValidation loss: 3.793379\tBest loss: 3.793379\tAccuracy: 4.10%\n",
      "17\tValidation loss: 3.791121\tBest loss: 3.791121\tAccuracy: 4.10%\n",
      "18\tValidation loss: 3.790874\tBest loss: 3.790874\tAccuracy: 4.20%\n",
      "19\tValidation loss: 3.788743\tBest loss: 3.788743\tAccuracy: 4.20%\n",
      "20\tValidation loss: 3.790003\tBest loss: 3.788743\tAccuracy: 4.20%\n",
      "21\tValidation loss: 3.789316\tBest loss: 3.788743\tAccuracy: 4.20%\n",
      "22\tValidation loss: 3.788033\tBest loss: 3.788033\tAccuracy: 4.20%\n",
      "23\tValidation loss: 3.787119\tBest loss: 3.787119\tAccuracy: 4.20%\n",
      "24\tValidation loss: 3.787329\tBest loss: 3.787119\tAccuracy: 4.20%\n",
      "25\tValidation loss: 3.786707\tBest loss: 3.786707\tAccuracy: 4.20%\n",
      "26\tValidation loss: 3.786403\tBest loss: 3.786403\tAccuracy: 4.20%\n",
      "27\tValidation loss: 3.788352\tBest loss: 3.786403\tAccuracy: 4.00%\n",
      "28\tValidation loss: 3.786770\tBest loss: 3.786403\tAccuracy: 4.20%\n",
      "29\tValidation loss: 3.786837\tBest loss: 3.786403\tAccuracy: 4.10%\n",
      "30\tValidation loss: 3.786387\tBest loss: 3.786387\tAccuracy: 4.20%\n",
      "31\tValidation loss: 3.783329\tBest loss: 3.783329\tAccuracy: 4.30%\n",
      "32\tValidation loss: 3.784863\tBest loss: 3.783329\tAccuracy: 4.00%\n",
      "33\tValidation loss: 3.783817\tBest loss: 3.783329\tAccuracy: 4.20%\n",
      "34\tValidation loss: 3.783892\tBest loss: 3.783329\tAccuracy: 4.20%\n",
      "35\tValidation loss: 3.783872\tBest loss: 3.783329\tAccuracy: 4.10%\n",
      "36\tValidation loss: 3.781705\tBest loss: 3.781705\tAccuracy: 4.30%\n",
      "37\tValidation loss: 3.780873\tBest loss: 3.780873\tAccuracy: 4.10%\n",
      "38\tValidation loss: 3.781827\tBest loss: 3.780873\tAccuracy: 3.90%\n",
      "39\tValidation loss: 3.776842\tBest loss: 3.776842\tAccuracy: 4.20%\n",
      "40\tValidation loss: 3.777734\tBest loss: 3.776842\tAccuracy: 4.00%\n",
      "41\tValidation loss: 3.776937\tBest loss: 3.776842\tAccuracy: 4.10%\n",
      "42\tValidation loss: 3.775829\tBest loss: 3.775829\tAccuracy: 4.00%\n",
      "43\tValidation loss: 3.777183\tBest loss: 3.775829\tAccuracy: 4.10%\n",
      "44\tValidation loss: 3.775523\tBest loss: 3.775523\tAccuracy: 4.40%\n",
      "45\tValidation loss: 3.773530\tBest loss: 3.773530\tAccuracy: 4.00%\n",
      "46\tValidation loss: 3.768601\tBest loss: 3.768601\tAccuracy: 4.50%\n",
      "47\tValidation loss: 3.767908\tBest loss: 3.767908\tAccuracy: 4.40%\n",
      "48\tValidation loss: 3.771412\tBest loss: 3.767908\tAccuracy: 3.80%\n",
      "49\tValidation loss: 3.766695\tBest loss: 3.766695\tAccuracy: 4.30%\n",
      "50\tValidation loss: 3.766495\tBest loss: 3.766495\tAccuracy: 4.20%\n",
      "51\tValidation loss: 3.764184\tBest loss: 3.764184\tAccuracy: 4.20%\n",
      "52\tValidation loss: 3.761786\tBest loss: 3.761786\tAccuracy: 4.00%\n",
      "53\tValidation loss: 3.755933\tBest loss: 3.755933\tAccuracy: 4.20%\n",
      "54\tValidation loss: 3.762000\tBest loss: 3.755933\tAccuracy: 3.80%\n",
      "55\tValidation loss: 3.754167\tBest loss: 3.754167\tAccuracy: 4.20%\n",
      "56\tValidation loss: 3.749990\tBest loss: 3.749990\tAccuracy: 4.20%\n",
      "57\tValidation loss: 3.748703\tBest loss: 3.748703\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.750342\tBest loss: 3.748703\tAccuracy: 4.10%\n",
      "59\tValidation loss: 3.741526\tBest loss: 3.741526\tAccuracy: 4.40%\n",
      "60\tValidation loss: 3.733781\tBest loss: 3.733781\tAccuracy: 4.50%\n",
      "61\tValidation loss: 3.716192\tBest loss: 3.716192\tAccuracy: 4.90%\n",
      "62\tValidation loss: 3.724161\tBest loss: 3.716192\tAccuracy: 4.50%\n",
      "63\tValidation loss: 3.733568\tBest loss: 3.716192\tAccuracy: 4.30%\n",
      "64\tValidation loss: 3.720520\tBest loss: 3.716192\tAccuracy: 4.60%\n",
      "65\tValidation loss: 3.706626\tBest loss: 3.706626\tAccuracy: 4.60%\n",
      "66\tValidation loss: 3.719456\tBest loss: 3.706626\tAccuracy: 4.10%\n",
      "67\tValidation loss: 3.714142\tBest loss: 3.706626\tAccuracy: 4.80%\n",
      "68\tValidation loss: 3.703829\tBest loss: 3.703829\tAccuracy: 4.70%\n",
      "69\tValidation loss: 3.706894\tBest loss: 3.703829\tAccuracy: 4.90%\n",
      "70\tValidation loss: 3.704473\tBest loss: 3.703829\tAccuracy: 4.30%\n",
      "71\tValidation loss: 3.673954\tBest loss: 3.673954\tAccuracy: 5.40%\n",
      "72\tValidation loss: 3.693115\tBest loss: 3.673954\tAccuracy: 5.60%\n",
      "73\tValidation loss: 3.664893\tBest loss: 3.664893\tAccuracy: 5.50%\n",
      "74\tValidation loss: 3.683120\tBest loss: 3.664893\tAccuracy: 5.00%\n",
      "75\tValidation loss: 3.677809\tBest loss: 3.664893\tAccuracy: 4.90%\n",
      "76\tValidation loss: 3.654685\tBest loss: 3.654685\tAccuracy: 5.60%\n",
      "77\tValidation loss: 3.654963\tBest loss: 3.654685\tAccuracy: 5.50%\n",
      "78\tValidation loss: 3.655839\tBest loss: 3.654685\tAccuracy: 5.50%\n",
      "79\tValidation loss: 3.652406\tBest loss: 3.652406\tAccuracy: 5.60%\n",
      "80\tValidation loss: 3.643886\tBest loss: 3.643886\tAccuracy: 5.70%\n",
      "81\tValidation loss: 3.635173\tBest loss: 3.635173\tAccuracy: 6.20%\n",
      "82\tValidation loss: 3.645676\tBest loss: 3.635173\tAccuracy: 5.60%\n",
      "83\tValidation loss: 3.595114\tBest loss: 3.595114\tAccuracy: 6.90%\n",
      "84\tValidation loss: 3.593949\tBest loss: 3.593949\tAccuracy: 9.90%\n",
      "85\tValidation loss: 3.607056\tBest loss: 3.593949\tAccuracy: 9.90%\n",
      "86\tValidation loss: 3.610365\tBest loss: 3.593949\tAccuracy: 8.90%\n",
      "87\tValidation loss: 3.598834\tBest loss: 3.593949\tAccuracy: 9.30%\n",
      "88\tValidation loss: 3.562604\tBest loss: 3.562604\tAccuracy: 11.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\tValidation loss: 3.563455\tBest loss: 3.562604\tAccuracy: 10.90%\n",
      "90\tValidation loss: 3.547978\tBest loss: 3.547978\tAccuracy: 11.50%\n",
      "91\tValidation loss: 3.542155\tBest loss: 3.542155\tAccuracy: 11.00%\n",
      "92\tValidation loss: 3.531867\tBest loss: 3.531867\tAccuracy: 11.40%\n",
      "93\tValidation loss: 3.552598\tBest loss: 3.531867\tAccuracy: 10.80%\n",
      "94\tValidation loss: 3.531020\tBest loss: 3.531020\tAccuracy: 12.60%\n",
      "95\tValidation loss: 3.507372\tBest loss: 3.507372\tAccuracy: 12.70%\n",
      "96\tValidation loss: 3.524142\tBest loss: 3.507372\tAccuracy: 11.80%\n",
      "97\tValidation loss: 3.503421\tBest loss: 3.503421\tAccuracy: 11.60%\n",
      "98\tValidation loss: 3.476512\tBest loss: 3.476512\tAccuracy: 11.90%\n",
      "99\tValidation loss: 3.484567\tBest loss: 3.476512\tAccuracy: 12.50%\n",
      "100\tValidation loss: 3.465731\tBest loss: 3.465731\tAccuracy: 12.60%\n",
      "101\tValidation loss: 3.463926\tBest loss: 3.463926\tAccuracy: 11.90%\n",
      "102\tValidation loss: 3.413755\tBest loss: 3.413755\tAccuracy: 13.00%\n",
      "103\tValidation loss: 3.424992\tBest loss: 3.413755\tAccuracy: 13.70%\n",
      "104\tValidation loss: 3.408903\tBest loss: 3.408903\tAccuracy: 13.00%\n",
      "105\tValidation loss: 3.429170\tBest loss: 3.408903\tAccuracy: 14.70%\n",
      "106\tValidation loss: 3.385958\tBest loss: 3.385958\tAccuracy: 13.70%\n",
      "107\tValidation loss: 3.395304\tBest loss: 3.385958\tAccuracy: 12.10%\n",
      "108\tValidation loss: 3.376709\tBest loss: 3.376709\tAccuracy: 12.70%\n",
      "109\tValidation loss: 3.416403\tBest loss: 3.376709\tAccuracy: 13.60%\n",
      "110\tValidation loss: 3.417540\tBest loss: 3.376709\tAccuracy: 12.80%\n",
      "111\tValidation loss: 3.363372\tBest loss: 3.363372\tAccuracy: 13.40%\n",
      "112\tValidation loss: 3.348803\tBest loss: 3.348803\tAccuracy: 14.40%\n",
      "113\tValidation loss: 3.365749\tBest loss: 3.348803\tAccuracy: 12.20%\n",
      "114\tValidation loss: 3.369967\tBest loss: 3.348803\tAccuracy: 14.60%\n",
      "115\tValidation loss: 3.346808\tBest loss: 3.346808\tAccuracy: 13.70%\n",
      "116\tValidation loss: 3.342949\tBest loss: 3.342949\tAccuracy: 14.40%\n",
      "117\tValidation loss: 3.341423\tBest loss: 3.341423\tAccuracy: 13.60%\n",
      "118\tValidation loss: 3.314101\tBest loss: 3.314101\tAccuracy: 14.60%\n",
      "119\tValidation loss: 3.338978\tBest loss: 3.314101\tAccuracy: 14.60%\n",
      "120\tValidation loss: 3.313032\tBest loss: 3.313032\tAccuracy: 15.90%\n",
      "121\tValidation loss: 3.313334\tBest loss: 3.313032\tAccuracy: 16.60%\n",
      "122\tValidation loss: 3.296172\tBest loss: 3.296172\tAccuracy: 14.80%\n",
      "123\tValidation loss: 3.303348\tBest loss: 3.296172\tAccuracy: 14.40%\n",
      "124\tValidation loss: 3.271771\tBest loss: 3.271771\tAccuracy: 14.90%\n",
      "125\tValidation loss: 3.278803\tBest loss: 3.271771\tAccuracy: 15.50%\n",
      "126\tValidation loss: 3.272119\tBest loss: 3.271771\tAccuracy: 15.60%\n",
      "127\tValidation loss: 3.283519\tBest loss: 3.271771\tAccuracy: 15.60%\n",
      "128\tValidation loss: 3.269116\tBest loss: 3.269116\tAccuracy: 14.90%\n",
      "129\tValidation loss: 3.269636\tBest loss: 3.269116\tAccuracy: 16.10%\n",
      "130\tValidation loss: 3.246753\tBest loss: 3.246753\tAccuracy: 16.70%\n",
      "131\tValidation loss: 3.273344\tBest loss: 3.246753\tAccuracy: 15.30%\n",
      "132\tValidation loss: 3.243033\tBest loss: 3.243033\tAccuracy: 16.70%\n",
      "133\tValidation loss: 3.246862\tBest loss: 3.243033\tAccuracy: 18.10%\n",
      "134\tValidation loss: 3.217441\tBest loss: 3.217441\tAccuracy: 16.10%\n",
      "135\tValidation loss: 3.207887\tBest loss: 3.207887\tAccuracy: 18.40%\n",
      "136\tValidation loss: 3.215247\tBest loss: 3.207887\tAccuracy: 17.60%\n",
      "137\tValidation loss: 3.216785\tBest loss: 3.207887\tAccuracy: 16.60%\n",
      "138\tValidation loss: 3.215533\tBest loss: 3.207887\tAccuracy: 17.90%\n",
      "139\tValidation loss: 3.174504\tBest loss: 3.174504\tAccuracy: 18.20%\n",
      "140\tValidation loss: 3.186802\tBest loss: 3.174504\tAccuracy: 17.60%\n",
      "141\tValidation loss: 3.181565\tBest loss: 3.174504\tAccuracy: 18.70%\n",
      "142\tValidation loss: 3.205854\tBest loss: 3.174504\tAccuracy: 17.40%\n",
      "143\tValidation loss: 3.179305\tBest loss: 3.174504\tAccuracy: 17.40%\n",
      "144\tValidation loss: 3.192969\tBest loss: 3.174504\tAccuracy: 16.80%\n",
      "145\tValidation loss: 3.173026\tBest loss: 3.173026\tAccuracy: 18.60%\n",
      "146\tValidation loss: 3.185746\tBest loss: 3.173026\tAccuracy: 18.20%\n",
      "147\tValidation loss: 3.173688\tBest loss: 3.173026\tAccuracy: 18.30%\n",
      "148\tValidation loss: 3.161929\tBest loss: 3.161929\tAccuracy: 18.70%\n",
      "149\tValidation loss: 3.166580\tBest loss: 3.161929\tAccuracy: 18.20%\n",
      "150\tValidation loss: 3.133946\tBest loss: 3.133946\tAccuracy: 18.30%\n",
      "151\tValidation loss: 3.151200\tBest loss: 3.133946\tAccuracy: 19.30%\n",
      "152\tValidation loss: 3.151291\tBest loss: 3.133946\tAccuracy: 18.20%\n",
      "153\tValidation loss: 3.136961\tBest loss: 3.133946\tAccuracy: 19.70%\n",
      "154\tValidation loss: 3.120561\tBest loss: 3.120561\tAccuracy: 19.40%\n",
      "155\tValidation loss: 3.120687\tBest loss: 3.120561\tAccuracy: 19.90%\n",
      "156\tValidation loss: 3.142160\tBest loss: 3.120561\tAccuracy: 18.70%\n",
      "157\tValidation loss: 3.130332\tBest loss: 3.120561\tAccuracy: 19.70%\n",
      "158\tValidation loss: 3.142068\tBest loss: 3.120561\tAccuracy: 18.70%\n",
      "159\tValidation loss: 3.128647\tBest loss: 3.120561\tAccuracy: 18.70%\n",
      "160\tValidation loss: 3.127351\tBest loss: 3.120561\tAccuracy: 19.60%\n",
      "161\tValidation loss: 3.094512\tBest loss: 3.094512\tAccuracy: 19.40%\n",
      "162\tValidation loss: 3.130590\tBest loss: 3.094512\tAccuracy: 20.50%\n",
      "163\tValidation loss: 3.110610\tBest loss: 3.094512\tAccuracy: 20.10%\n",
      "164\tValidation loss: 3.104092\tBest loss: 3.094512\tAccuracy: 19.70%\n",
      "165\tValidation loss: 3.106214\tBest loss: 3.094512\tAccuracy: 19.00%\n",
      "166\tValidation loss: 3.076769\tBest loss: 3.076769\tAccuracy: 19.70%\n",
      "167\tValidation loss: 3.082888\tBest loss: 3.076769\tAccuracy: 19.80%\n",
      "168\tValidation loss: 3.074731\tBest loss: 3.074731\tAccuracy: 19.40%\n",
      "169\tValidation loss: 3.071821\tBest loss: 3.071821\tAccuracy: 19.20%\n",
      "170\tValidation loss: 3.071120\tBest loss: 3.071120\tAccuracy: 19.80%\n",
      "171\tValidation loss: 3.049936\tBest loss: 3.049936\tAccuracy: 19.40%\n",
      "172\tValidation loss: 3.074932\tBest loss: 3.049936\tAccuracy: 19.00%\n",
      "173\tValidation loss: 3.074647\tBest loss: 3.049936\tAccuracy: 19.20%\n",
      "174\tValidation loss: 3.047984\tBest loss: 3.047984\tAccuracy: 20.10%\n",
      "175\tValidation loss: 3.114356\tBest loss: 3.047984\tAccuracy: 18.70%\n",
      "176\tValidation loss: 3.090456\tBest loss: 3.047984\tAccuracy: 18.90%\n",
      "177\tValidation loss: 3.052526\tBest loss: 3.047984\tAccuracy: 21.00%\n",
      "178\tValidation loss: 3.031394\tBest loss: 3.031394\tAccuracy: 21.30%\n",
      "179\tValidation loss: 3.010863\tBest loss: 3.010863\tAccuracy: 21.40%\n",
      "180\tValidation loss: 3.068249\tBest loss: 3.010863\tAccuracy: 18.70%\n",
      "181\tValidation loss: 3.012662\tBest loss: 3.010863\tAccuracy: 21.40%\n",
      "182\tValidation loss: 3.047355\tBest loss: 3.010863\tAccuracy: 20.70%\n",
      "183\tValidation loss: 3.013205\tBest loss: 3.010863\tAccuracy: 21.70%\n",
      "184\tValidation loss: 3.022973\tBest loss: 3.010863\tAccuracy: 21.60%\n",
      "185\tValidation loss: 2.999355\tBest loss: 2.999355\tAccuracy: 22.20%\n",
      "186\tValidation loss: 3.011726\tBest loss: 2.999355\tAccuracy: 21.50%\n",
      "187\tValidation loss: 3.021104\tBest loss: 2.999355\tAccuracy: 21.60%\n",
      "188\tValidation loss: 2.979299\tBest loss: 2.979299\tAccuracy: 22.70%\n",
      "189\tValidation loss: 3.014966\tBest loss: 2.979299\tAccuracy: 21.00%\n",
      "190\tValidation loss: 3.010900\tBest loss: 2.979299\tAccuracy: 20.70%\n",
      "191\tValidation loss: 2.994452\tBest loss: 2.979299\tAccuracy: 22.90%\n",
      "192\tValidation loss: 3.007620\tBest loss: 2.979299\tAccuracy: 22.10%\n",
      "193\tValidation loss: 2.986796\tBest loss: 2.979299\tAccuracy: 22.30%\n",
      "194\tValidation loss: 3.010118\tBest loss: 2.979299\tAccuracy: 22.00%\n",
      "195\tValidation loss: 2.986600\tBest loss: 2.979299\tAccuracy: 21.40%\n",
      "196\tValidation loss: 2.966956\tBest loss: 2.966956\tAccuracy: 23.20%\n",
      "197\tValidation loss: 2.972158\tBest loss: 2.966956\tAccuracy: 22.70%\n",
      "198\tValidation loss: 2.984968\tBest loss: 2.966956\tAccuracy: 21.90%\n",
      "199\tValidation loss: 2.961051\tBest loss: 2.961051\tAccuracy: 22.50%\n",
      "200\tValidation loss: 2.960528\tBest loss: 2.960528\tAccuracy: 23.60%\n",
      "201\tValidation loss: 2.963497\tBest loss: 2.960528\tAccuracy: 23.20%\n",
      "202\tValidation loss: 2.937875\tBest loss: 2.937875\tAccuracy: 23.10%\n",
      "203\tValidation loss: 2.936171\tBest loss: 2.936171\tAccuracy: 23.60%\n",
      "204\tValidation loss: 2.963133\tBest loss: 2.936171\tAccuracy: 22.50%\n",
      "205\tValidation loss: 2.997262\tBest loss: 2.936171\tAccuracy: 21.50%\n",
      "206\tValidation loss: 2.950713\tBest loss: 2.936171\tAccuracy: 23.00%\n",
      "207\tValidation loss: 2.973855\tBest loss: 2.936171\tAccuracy: 21.70%\n",
      "208\tValidation loss: 2.955499\tBest loss: 2.936171\tAccuracy: 23.30%\n",
      "209\tValidation loss: 2.938112\tBest loss: 2.936171\tAccuracy: 23.00%\n",
      "210\tValidation loss: 2.948345\tBest loss: 2.936171\tAccuracy: 21.90%\n",
      "211\tValidation loss: 2.954005\tBest loss: 2.936171\tAccuracy: 21.50%\n",
      "212\tValidation loss: 2.915864\tBest loss: 2.915864\tAccuracy: 23.30%\n",
      "213\tValidation loss: 2.963530\tBest loss: 2.915864\tAccuracy: 23.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\tValidation loss: 2.919492\tBest loss: 2.915864\tAccuracy: 24.50%\n",
      "215\tValidation loss: 2.933331\tBest loss: 2.915864\tAccuracy: 23.80%\n",
      "216\tValidation loss: 2.914385\tBest loss: 2.914385\tAccuracy: 24.80%\n",
      "217\tValidation loss: 2.940202\tBest loss: 2.914385\tAccuracy: 23.70%\n",
      "218\tValidation loss: 2.935357\tBest loss: 2.914385\tAccuracy: 22.30%\n",
      "219\tValidation loss: 2.892778\tBest loss: 2.892778\tAccuracy: 24.90%\n",
      "220\tValidation loss: 2.911986\tBest loss: 2.892778\tAccuracy: 24.60%\n",
      "221\tValidation loss: 2.891496\tBest loss: 2.891496\tAccuracy: 24.10%\n",
      "222\tValidation loss: 2.911067\tBest loss: 2.891496\tAccuracy: 23.60%\n",
      "223\tValidation loss: 2.909593\tBest loss: 2.891496\tAccuracy: 22.50%\n",
      "224\tValidation loss: 2.902332\tBest loss: 2.891496\tAccuracy: 23.40%\n",
      "225\tValidation loss: 2.899096\tBest loss: 2.891496\tAccuracy: 23.40%\n",
      "226\tValidation loss: 2.897157\tBest loss: 2.891496\tAccuracy: 25.00%\n",
      "227\tValidation loss: 2.895654\tBest loss: 2.891496\tAccuracy: 26.00%\n",
      "228\tValidation loss: 2.881516\tBest loss: 2.881516\tAccuracy: 25.10%\n",
      "229\tValidation loss: 2.909936\tBest loss: 2.881516\tAccuracy: 23.90%\n",
      "230\tValidation loss: 2.893027\tBest loss: 2.881516\tAccuracy: 24.20%\n",
      "231\tValidation loss: 2.901852\tBest loss: 2.881516\tAccuracy: 23.90%\n",
      "232\tValidation loss: 2.881197\tBest loss: 2.881197\tAccuracy: 24.80%\n",
      "233\tValidation loss: 2.892154\tBest loss: 2.881197\tAccuracy: 22.90%\n",
      "234\tValidation loss: 2.877535\tBest loss: 2.877535\tAccuracy: 25.00%\n",
      "235\tValidation loss: 2.887181\tBest loss: 2.877535\tAccuracy: 22.80%\n",
      "236\tValidation loss: 2.905398\tBest loss: 2.877535\tAccuracy: 23.60%\n",
      "237\tValidation loss: 2.889093\tBest loss: 2.877535\tAccuracy: 24.30%\n",
      "238\tValidation loss: 2.868090\tBest loss: 2.868090\tAccuracy: 25.30%\n",
      "239\tValidation loss: 2.877549\tBest loss: 2.868090\tAccuracy: 25.20%\n",
      "240\tValidation loss: 2.875390\tBest loss: 2.868090\tAccuracy: 24.20%\n",
      "241\tValidation loss: 2.869855\tBest loss: 2.868090\tAccuracy: 23.60%\n",
      "242\tValidation loss: 2.900835\tBest loss: 2.868090\tAccuracy: 22.90%\n",
      "243\tValidation loss: 2.856292\tBest loss: 2.856292\tAccuracy: 26.30%\n",
      "244\tValidation loss: 2.875141\tBest loss: 2.856292\tAccuracy: 24.70%\n",
      "245\tValidation loss: 2.850740\tBest loss: 2.850740\tAccuracy: 24.50%\n",
      "246\tValidation loss: 2.865164\tBest loss: 2.850740\tAccuracy: 25.40%\n",
      "247\tValidation loss: 2.836905\tBest loss: 2.836905\tAccuracy: 25.70%\n",
      "248\tValidation loss: 2.871632\tBest loss: 2.836905\tAccuracy: 24.20%\n",
      "249\tValidation loss: 2.847490\tBest loss: 2.836905\tAccuracy: 24.60%\n",
      "250\tValidation loss: 2.844024\tBest loss: 2.836905\tAccuracy: 24.90%\n",
      "251\tValidation loss: 2.847273\tBest loss: 2.836905\tAccuracy: 24.90%\n",
      "252\tValidation loss: 2.858623\tBest loss: 2.836905\tAccuracy: 25.10%\n",
      "253\tValidation loss: 2.865755\tBest loss: 2.836905\tAccuracy: 25.70%\n",
      "254\tValidation loss: 2.830875\tBest loss: 2.830875\tAccuracy: 24.90%\n",
      "255\tValidation loss: 2.821496\tBest loss: 2.821496\tAccuracy: 25.60%\n",
      "256\tValidation loss: 2.851457\tBest loss: 2.821496\tAccuracy: 24.70%\n",
      "257\tValidation loss: 2.846106\tBest loss: 2.821496\tAccuracy: 26.60%\n",
      "258\tValidation loss: 2.854741\tBest loss: 2.821496\tAccuracy: 25.30%\n",
      "259\tValidation loss: 2.827021\tBest loss: 2.821496\tAccuracy: 25.70%\n",
      "260\tValidation loss: 2.837527\tBest loss: 2.821496\tAccuracy: 25.20%\n",
      "261\tValidation loss: 2.803600\tBest loss: 2.803600\tAccuracy: 26.70%\n",
      "262\tValidation loss: 2.815613\tBest loss: 2.803600\tAccuracy: 26.20%\n",
      "263\tValidation loss: 2.822165\tBest loss: 2.803600\tAccuracy: 25.10%\n",
      "264\tValidation loss: 2.801188\tBest loss: 2.801188\tAccuracy: 25.70%\n",
      "265\tValidation loss: 2.800603\tBest loss: 2.800603\tAccuracy: 27.10%\n",
      "266\tValidation loss: 2.810956\tBest loss: 2.800603\tAccuracy: 25.90%\n",
      "267\tValidation loss: 2.810433\tBest loss: 2.800603\tAccuracy: 26.20%\n",
      "268\tValidation loss: 2.805360\tBest loss: 2.800603\tAccuracy: 26.30%\n",
      "269\tValidation loss: 2.795170\tBest loss: 2.795170\tAccuracy: 26.50%\n",
      "270\tValidation loss: 2.806491\tBest loss: 2.795170\tAccuracy: 26.10%\n",
      "271\tValidation loss: 2.832550\tBest loss: 2.795170\tAccuracy: 26.20%\n",
      "272\tValidation loss: 2.797496\tBest loss: 2.795170\tAccuracy: 25.90%\n",
      "273\tValidation loss: 2.799318\tBest loss: 2.795170\tAccuracy: 24.80%\n",
      "274\tValidation loss: 2.806214\tBest loss: 2.795170\tAccuracy: 25.10%\n",
      "275\tValidation loss: 2.793767\tBest loss: 2.793767\tAccuracy: 26.90%\n",
      "276\tValidation loss: 2.784738\tBest loss: 2.784738\tAccuracy: 27.20%\n",
      "277\tValidation loss: 2.813364\tBest loss: 2.784738\tAccuracy: 25.40%\n",
      "278\tValidation loss: 2.770461\tBest loss: 2.770461\tAccuracy: 27.40%\n",
      "279\tValidation loss: 2.788130\tBest loss: 2.770461\tAccuracy: 26.00%\n",
      "280\tValidation loss: 2.780317\tBest loss: 2.770461\tAccuracy: 26.10%\n",
      "281\tValidation loss: 2.768640\tBest loss: 2.768640\tAccuracy: 27.20%\n",
      "282\tValidation loss: 2.759499\tBest loss: 2.759499\tAccuracy: 25.80%\n",
      "283\tValidation loss: 2.803820\tBest loss: 2.759499\tAccuracy: 25.60%\n",
      "284\tValidation loss: 2.780396\tBest loss: 2.759499\tAccuracy: 26.10%\n",
      "285\tValidation loss: 2.785349\tBest loss: 2.759499\tAccuracy: 25.30%\n",
      "286\tValidation loss: 2.789204\tBest loss: 2.759499\tAccuracy: 26.70%\n",
      "287\tValidation loss: 2.759213\tBest loss: 2.759213\tAccuracy: 28.40%\n",
      "288\tValidation loss: 2.765290\tBest loss: 2.759213\tAccuracy: 27.30%\n",
      "289\tValidation loss: 2.770198\tBest loss: 2.759213\tAccuracy: 26.50%\n",
      "290\tValidation loss: 2.755984\tBest loss: 2.755984\tAccuracy: 26.30%\n",
      "291\tValidation loss: 2.737494\tBest loss: 2.737494\tAccuracy: 27.50%\n",
      "292\tValidation loss: 2.773690\tBest loss: 2.737494\tAccuracy: 26.60%\n",
      "293\tValidation loss: 2.765332\tBest loss: 2.737494\tAccuracy: 27.20%\n",
      "294\tValidation loss: 2.738101\tBest loss: 2.737494\tAccuracy: 26.80%\n",
      "295\tValidation loss: 2.738649\tBest loss: 2.737494\tAccuracy: 27.30%\n",
      "296\tValidation loss: 2.726799\tBest loss: 2.726799\tAccuracy: 28.80%\n",
      "297\tValidation loss: 2.753416\tBest loss: 2.726799\tAccuracy: 28.70%\n",
      "298\tValidation loss: 2.735922\tBest loss: 2.726799\tAccuracy: 27.30%\n",
      "299\tValidation loss: 2.740859\tBest loss: 2.726799\tAccuracy: 28.90%\n",
      "300\tValidation loss: 2.745118\tBest loss: 2.726799\tAccuracy: 27.40%\n",
      "301\tValidation loss: 2.741876\tBest loss: 2.726799\tAccuracy: 28.00%\n",
      "302\tValidation loss: 2.724669\tBest loss: 2.724669\tAccuracy: 29.30%\n",
      "303\tValidation loss: 2.749509\tBest loss: 2.724669\tAccuracy: 27.30%\n",
      "304\tValidation loss: 2.697878\tBest loss: 2.697878\tAccuracy: 29.30%\n",
      "305\tValidation loss: 2.716528\tBest loss: 2.697878\tAccuracy: 27.40%\n",
      "306\tValidation loss: 2.720656\tBest loss: 2.697878\tAccuracy: 27.60%\n",
      "307\tValidation loss: 2.686530\tBest loss: 2.686530\tAccuracy: 28.50%\n",
      "308\tValidation loss: 2.740884\tBest loss: 2.686530\tAccuracy: 27.40%\n",
      "309\tValidation loss: 2.729753\tBest loss: 2.686530\tAccuracy: 27.70%\n",
      "310\tValidation loss: 2.713244\tBest loss: 2.686530\tAccuracy: 29.80%\n",
      "311\tValidation loss: 2.718558\tBest loss: 2.686530\tAccuracy: 27.60%\n",
      "312\tValidation loss: 2.731059\tBest loss: 2.686530\tAccuracy: 28.70%\n",
      "313\tValidation loss: 2.716647\tBest loss: 2.686530\tAccuracy: 28.30%\n",
      "314\tValidation loss: 2.693460\tBest loss: 2.686530\tAccuracy: 28.60%\n",
      "315\tValidation loss: 2.707510\tBest loss: 2.686530\tAccuracy: 27.90%\n",
      "316\tValidation loss: 2.697080\tBest loss: 2.686530\tAccuracy: 29.20%\n",
      "317\tValidation loss: 2.703559\tBest loss: 2.686530\tAccuracy: 29.40%\n",
      "318\tValidation loss: 2.735170\tBest loss: 2.686530\tAccuracy: 26.80%\n",
      "319\tValidation loss: 2.704680\tBest loss: 2.686530\tAccuracy: 29.20%\n",
      "320\tValidation loss: 2.681493\tBest loss: 2.681493\tAccuracy: 28.60%\n",
      "321\tValidation loss: 2.703914\tBest loss: 2.681493\tAccuracy: 29.30%\n",
      "322\tValidation loss: 2.701387\tBest loss: 2.681493\tAccuracy: 28.70%\n",
      "323\tValidation loss: 2.689190\tBest loss: 2.681493\tAccuracy: 28.70%\n",
      "324\tValidation loss: 2.694556\tBest loss: 2.681493\tAccuracy: 28.10%\n",
      "325\tValidation loss: 2.682276\tBest loss: 2.681493\tAccuracy: 29.60%\n",
      "326\tValidation loss: 2.689011\tBest loss: 2.681493\tAccuracy: 29.20%\n",
      "327\tValidation loss: 2.685276\tBest loss: 2.681493\tAccuracy: 29.70%\n",
      "328\tValidation loss: 2.680926\tBest loss: 2.680926\tAccuracy: 29.30%\n",
      "329\tValidation loss: 2.702003\tBest loss: 2.680926\tAccuracy: 28.00%\n",
      "330\tValidation loss: 2.671984\tBest loss: 2.671984\tAccuracy: 29.70%\n",
      "331\tValidation loss: 2.705397\tBest loss: 2.671984\tAccuracy: 28.50%\n",
      "332\tValidation loss: 2.690175\tBest loss: 2.671984\tAccuracy: 29.00%\n",
      "333\tValidation loss: 2.674014\tBest loss: 2.671984\tAccuracy: 29.30%\n",
      "334\tValidation loss: 2.675869\tBest loss: 2.671984\tAccuracy: 28.70%\n",
      "335\tValidation loss: 2.700280\tBest loss: 2.671984\tAccuracy: 27.90%\n",
      "336\tValidation loss: 2.677619\tBest loss: 2.671984\tAccuracy: 29.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\tValidation loss: 2.645720\tBest loss: 2.645720\tAccuracy: 29.70%\n",
      "338\tValidation loss: 2.662933\tBest loss: 2.645720\tAccuracy: 29.20%\n",
      "339\tValidation loss: 2.687107\tBest loss: 2.645720\tAccuracy: 28.90%\n",
      "340\tValidation loss: 2.662013\tBest loss: 2.645720\tAccuracy: 29.20%\n",
      "341\tValidation loss: 2.644589\tBest loss: 2.644589\tAccuracy: 29.90%\n",
      "342\tValidation loss: 2.654840\tBest loss: 2.644589\tAccuracy: 29.80%\n",
      "343\tValidation loss: 2.672472\tBest loss: 2.644589\tAccuracy: 29.50%\n",
      "344\tValidation loss: 2.661149\tBest loss: 2.644589\tAccuracy: 29.20%\n",
      "345\tValidation loss: 2.667071\tBest loss: 2.644589\tAccuracy: 29.30%\n",
      "346\tValidation loss: 2.670047\tBest loss: 2.644589\tAccuracy: 28.60%\n",
      "347\tValidation loss: 2.664571\tBest loss: 2.644589\tAccuracy: 29.50%\n",
      "348\tValidation loss: 2.641706\tBest loss: 2.641706\tAccuracy: 30.00%\n",
      "349\tValidation loss: 2.668824\tBest loss: 2.641706\tAccuracy: 29.90%\n",
      "350\tValidation loss: 2.644802\tBest loss: 2.641706\tAccuracy: 29.20%\n",
      "351\tValidation loss: 2.656448\tBest loss: 2.641706\tAccuracy: 30.30%\n",
      "352\tValidation loss: 2.630219\tBest loss: 2.630219\tAccuracy: 29.20%\n",
      "353\tValidation loss: 2.657384\tBest loss: 2.630219\tAccuracy: 28.40%\n",
      "354\tValidation loss: 2.641322\tBest loss: 2.630219\tAccuracy: 29.00%\n",
      "355\tValidation loss: 2.651650\tBest loss: 2.630219\tAccuracy: 30.00%\n",
      "356\tValidation loss: 2.612303\tBest loss: 2.612303\tAccuracy: 32.10%\n",
      "357\tValidation loss: 2.629139\tBest loss: 2.612303\tAccuracy: 29.80%\n",
      "358\tValidation loss: 2.639617\tBest loss: 2.612303\tAccuracy: 30.30%\n",
      "359\tValidation loss: 2.644988\tBest loss: 2.612303\tAccuracy: 28.50%\n",
      "360\tValidation loss: 2.627571\tBest loss: 2.612303\tAccuracy: 31.60%\n",
      "361\tValidation loss: 2.622400\tBest loss: 2.612303\tAccuracy: 29.30%\n",
      "362\tValidation loss: 2.628820\tBest loss: 2.612303\tAccuracy: 30.30%\n",
      "363\tValidation loss: 2.622146\tBest loss: 2.612303\tAccuracy: 31.20%\n",
      "364\tValidation loss: 2.618770\tBest loss: 2.612303\tAccuracy: 30.30%\n",
      "365\tValidation loss: 2.605888\tBest loss: 2.605888\tAccuracy: 30.40%\n",
      "366\tValidation loss: 2.622546\tBest loss: 2.605888\tAccuracy: 30.90%\n",
      "367\tValidation loss: 2.612716\tBest loss: 2.605888\tAccuracy: 31.50%\n",
      "368\tValidation loss: 2.596447\tBest loss: 2.596447\tAccuracy: 31.00%\n",
      "369\tValidation loss: 2.622699\tBest loss: 2.596447\tAccuracy: 30.00%\n",
      "370\tValidation loss: 2.627553\tBest loss: 2.596447\tAccuracy: 30.40%\n",
      "371\tValidation loss: 2.605679\tBest loss: 2.596447\tAccuracy: 30.00%\n",
      "372\tValidation loss: 2.631492\tBest loss: 2.596447\tAccuracy: 30.10%\n",
      "373\tValidation loss: 2.605671\tBest loss: 2.596447\tAccuracy: 29.50%\n",
      "374\tValidation loss: 2.615084\tBest loss: 2.596447\tAccuracy: 30.30%\n",
      "375\tValidation loss: 2.592829\tBest loss: 2.592829\tAccuracy: 31.70%\n",
      "376\tValidation loss: 2.611978\tBest loss: 2.592829\tAccuracy: 31.20%\n",
      "377\tValidation loss: 2.587272\tBest loss: 2.587272\tAccuracy: 30.90%\n",
      "378\tValidation loss: 2.595230\tBest loss: 2.587272\tAccuracy: 31.60%\n",
      "379\tValidation loss: 2.586173\tBest loss: 2.586173\tAccuracy: 31.10%\n",
      "380\tValidation loss: 2.600718\tBest loss: 2.586173\tAccuracy: 31.20%\n",
      "381\tValidation loss: 2.593978\tBest loss: 2.586173\tAccuracy: 31.60%\n",
      "382\tValidation loss: 2.581160\tBest loss: 2.581160\tAccuracy: 30.90%\n",
      "383\tValidation loss: 2.587006\tBest loss: 2.581160\tAccuracy: 31.30%\n",
      "384\tValidation loss: 2.585194\tBest loss: 2.581160\tAccuracy: 31.90%\n",
      "385\tValidation loss: 2.587688\tBest loss: 2.581160\tAccuracy: 32.40%\n",
      "386\tValidation loss: 2.581635\tBest loss: 2.581160\tAccuracy: 31.40%\n",
      "387\tValidation loss: 2.589832\tBest loss: 2.581160\tAccuracy: 31.90%\n",
      "388\tValidation loss: 2.583193\tBest loss: 2.581160\tAccuracy: 30.30%\n",
      "389\tValidation loss: 2.586438\tBest loss: 2.581160\tAccuracy: 31.30%\n",
      "390\tValidation loss: 2.570346\tBest loss: 2.570346\tAccuracy: 30.90%\n",
      "391\tValidation loss: 2.571903\tBest loss: 2.570346\tAccuracy: 32.60%\n",
      "392\tValidation loss: 2.548822\tBest loss: 2.548822\tAccuracy: 33.00%\n",
      "393\tValidation loss: 2.572268\tBest loss: 2.548822\tAccuracy: 32.20%\n",
      "394\tValidation loss: 2.580228\tBest loss: 2.548822\tAccuracy: 30.50%\n",
      "395\tValidation loss: 2.589417\tBest loss: 2.548822\tAccuracy: 29.90%\n",
      "396\tValidation loss: 2.585041\tBest loss: 2.548822\tAccuracy: 31.30%\n",
      "397\tValidation loss: 2.569027\tBest loss: 2.548822\tAccuracy: 30.60%\n",
      "398\tValidation loss: 2.569072\tBest loss: 2.548822\tAccuracy: 30.60%\n",
      "399\tValidation loss: 2.564183\tBest loss: 2.548822\tAccuracy: 32.10%\n",
      "400\tValidation loss: 2.564853\tBest loss: 2.548822\tAccuracy: 32.50%\n",
      "401\tValidation loss: 2.544235\tBest loss: 2.544235\tAccuracy: 32.70%\n",
      "402\tValidation loss: 2.561605\tBest loss: 2.544235\tAccuracy: 31.20%\n",
      "403\tValidation loss: 2.567842\tBest loss: 2.544235\tAccuracy: 31.60%\n",
      "404\tValidation loss: 2.554348\tBest loss: 2.544235\tAccuracy: 30.40%\n",
      "405\tValidation loss: 2.556503\tBest loss: 2.544235\tAccuracy: 31.60%\n",
      "406\tValidation loss: 2.559293\tBest loss: 2.544235\tAccuracy: 31.20%\n",
      "407\tValidation loss: 2.564672\tBest loss: 2.544235\tAccuracy: 31.10%\n",
      "408\tValidation loss: 2.562599\tBest loss: 2.544235\tAccuracy: 29.80%\n",
      "409\tValidation loss: 2.543638\tBest loss: 2.543638\tAccuracy: 32.40%\n",
      "410\tValidation loss: 2.565688\tBest loss: 2.543638\tAccuracy: 31.30%\n",
      "411\tValidation loss: 2.537662\tBest loss: 2.537662\tAccuracy: 31.80%\n",
      "412\tValidation loss: 2.552510\tBest loss: 2.537662\tAccuracy: 31.30%\n",
      "413\tValidation loss: 2.547538\tBest loss: 2.537662\tAccuracy: 32.50%\n",
      "414\tValidation loss: 2.572559\tBest loss: 2.537662\tAccuracy: 31.30%\n",
      "415\tValidation loss: 2.539994\tBest loss: 2.537662\tAccuracy: 31.60%\n",
      "416\tValidation loss: 2.542111\tBest loss: 2.537662\tAccuracy: 32.20%\n",
      "417\tValidation loss: 2.530107\tBest loss: 2.530107\tAccuracy: 32.40%\n",
      "418\tValidation loss: 2.550050\tBest loss: 2.530107\tAccuracy: 32.70%\n",
      "419\tValidation loss: 2.541605\tBest loss: 2.530107\tAccuracy: 31.90%\n",
      "420\tValidation loss: 2.531084\tBest loss: 2.530107\tAccuracy: 32.00%\n",
      "421\tValidation loss: 2.536576\tBest loss: 2.530107\tAccuracy: 32.30%\n",
      "422\tValidation loss: 2.538903\tBest loss: 2.530107\tAccuracy: 31.40%\n",
      "423\tValidation loss: 2.518827\tBest loss: 2.518827\tAccuracy: 33.00%\n",
      "424\tValidation loss: 2.524014\tBest loss: 2.518827\tAccuracy: 32.70%\n",
      "425\tValidation loss: 2.543714\tBest loss: 2.518827\tAccuracy: 32.50%\n",
      "426\tValidation loss: 2.533095\tBest loss: 2.518827\tAccuracy: 31.90%\n",
      "427\tValidation loss: 2.539227\tBest loss: 2.518827\tAccuracy: 30.10%\n",
      "428\tValidation loss: 2.537138\tBest loss: 2.518827\tAccuracy: 31.00%\n",
      "429\tValidation loss: 2.512190\tBest loss: 2.512190\tAccuracy: 32.10%\n",
      "430\tValidation loss: 2.527480\tBest loss: 2.512190\tAccuracy: 32.20%\n",
      "431\tValidation loss: 2.524442\tBest loss: 2.512190\tAccuracy: 31.30%\n",
      "432\tValidation loss: 2.517942\tBest loss: 2.512190\tAccuracy: 31.10%\n",
      "433\tValidation loss: 2.514490\tBest loss: 2.512190\tAccuracy: 31.80%\n",
      "434\tValidation loss: 2.520169\tBest loss: 2.512190\tAccuracy: 32.20%\n",
      "435\tValidation loss: 2.515230\tBest loss: 2.512190\tAccuracy: 31.80%\n",
      "436\tValidation loss: 2.555609\tBest loss: 2.512190\tAccuracy: 31.80%\n",
      "437\tValidation loss: 2.522945\tBest loss: 2.512190\tAccuracy: 31.60%\n",
      "438\tValidation loss: 2.516679\tBest loss: 2.512190\tAccuracy: 33.20%\n",
      "439\tValidation loss: 2.514364\tBest loss: 2.512190\tAccuracy: 32.10%\n",
      "440\tValidation loss: 2.497718\tBest loss: 2.497718\tAccuracy: 32.80%\n",
      "441\tValidation loss: 2.504872\tBest loss: 2.497718\tAccuracy: 31.30%\n",
      "442\tValidation loss: 2.491345\tBest loss: 2.491345\tAccuracy: 32.30%\n",
      "443\tValidation loss: 2.522830\tBest loss: 2.491345\tAccuracy: 32.50%\n",
      "444\tValidation loss: 2.496771\tBest loss: 2.491345\tAccuracy: 32.50%\n",
      "445\tValidation loss: 2.487134\tBest loss: 2.487134\tAccuracy: 33.90%\n",
      "446\tValidation loss: 2.471357\tBest loss: 2.471357\tAccuracy: 33.70%\n",
      "447\tValidation loss: 2.488643\tBest loss: 2.471357\tAccuracy: 32.20%\n",
      "448\tValidation loss: 2.509147\tBest loss: 2.471357\tAccuracy: 32.90%\n",
      "449\tValidation loss: 2.492110\tBest loss: 2.471357\tAccuracy: 32.70%\n",
      "450\tValidation loss: 2.492401\tBest loss: 2.471357\tAccuracy: 32.60%\n",
      "451\tValidation loss: 2.491819\tBest loss: 2.471357\tAccuracy: 33.30%\n",
      "452\tValidation loss: 2.491822\tBest loss: 2.471357\tAccuracy: 32.60%\n",
      "453\tValidation loss: 2.491974\tBest loss: 2.471357\tAccuracy: 33.50%\n",
      "454\tValidation loss: 2.490349\tBest loss: 2.471357\tAccuracy: 31.50%\n",
      "455\tValidation loss: 2.488160\tBest loss: 2.471357\tAccuracy: 33.10%\n",
      "456\tValidation loss: 2.474674\tBest loss: 2.471357\tAccuracy: 32.70%\n",
      "457\tValidation loss: 2.482733\tBest loss: 2.471357\tAccuracy: 32.70%\n",
      "458\tValidation loss: 2.482043\tBest loss: 2.471357\tAccuracy: 33.00%\n",
      "459\tValidation loss: 2.489004\tBest loss: 2.471357\tAccuracy: 33.30%\n",
      "460\tValidation loss: 2.469086\tBest loss: 2.469086\tAccuracy: 33.80%\n",
      "461\tValidation loss: 2.451524\tBest loss: 2.451524\tAccuracy: 34.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\tValidation loss: 2.490709\tBest loss: 2.451524\tAccuracy: 31.30%\n",
      "463\tValidation loss: 2.471842\tBest loss: 2.451524\tAccuracy: 33.30%\n",
      "464\tValidation loss: 2.474529\tBest loss: 2.451524\tAccuracy: 31.70%\n",
      "465\tValidation loss: 2.483020\tBest loss: 2.451524\tAccuracy: 32.70%\n",
      "466\tValidation loss: 2.458873\tBest loss: 2.451524\tAccuracy: 32.90%\n",
      "467\tValidation loss: 2.471224\tBest loss: 2.451524\tAccuracy: 32.30%\n",
      "468\tValidation loss: 2.489966\tBest loss: 2.451524\tAccuracy: 30.50%\n",
      "469\tValidation loss: 2.459833\tBest loss: 2.451524\tAccuracy: 32.60%\n",
      "470\tValidation loss: 2.458011\tBest loss: 2.451524\tAccuracy: 32.70%\n",
      "471\tValidation loss: 2.462519\tBest loss: 2.451524\tAccuracy: 34.20%\n",
      "472\tValidation loss: 2.469122\tBest loss: 2.451524\tAccuracy: 32.90%\n",
      "473\tValidation loss: 2.466885\tBest loss: 2.451524\tAccuracy: 34.00%\n",
      "474\tValidation loss: 2.462383\tBest loss: 2.451524\tAccuracy: 34.50%\n",
      "475\tValidation loss: 2.462013\tBest loss: 2.451524\tAccuracy: 34.20%\n",
      "476\tValidation loss: 2.451087\tBest loss: 2.451087\tAccuracy: 33.70%\n",
      "477\tValidation loss: 2.452242\tBest loss: 2.451087\tAccuracy: 34.80%\n",
      "478\tValidation loss: 2.451045\tBest loss: 2.451045\tAccuracy: 35.20%\n",
      "479\tValidation loss: 2.469678\tBest loss: 2.451045\tAccuracy: 33.90%\n",
      "480\tValidation loss: 2.451992\tBest loss: 2.451045\tAccuracy: 33.60%\n",
      "481\tValidation loss: 2.452785\tBest loss: 2.451045\tAccuracy: 34.50%\n",
      "482\tValidation loss: 2.431294\tBest loss: 2.431294\tAccuracy: 35.10%\n",
      "483\tValidation loss: 2.426533\tBest loss: 2.426533\tAccuracy: 35.30%\n",
      "484\tValidation loss: 2.433342\tBest loss: 2.426533\tAccuracy: 33.60%\n",
      "485\tValidation loss: 2.432567\tBest loss: 2.426533\tAccuracy: 33.50%\n",
      "486\tValidation loss: 2.445101\tBest loss: 2.426533\tAccuracy: 34.60%\n",
      "487\tValidation loss: 2.443911\tBest loss: 2.426533\tAccuracy: 33.90%\n",
      "488\tValidation loss: 2.446675\tBest loss: 2.426533\tAccuracy: 32.90%\n",
      "489\tValidation loss: 2.448567\tBest loss: 2.426533\tAccuracy: 32.90%\n",
      "490\tValidation loss: 2.442320\tBest loss: 2.426533\tAccuracy: 33.90%\n",
      "491\tValidation loss: 2.429582\tBest loss: 2.426533\tAccuracy: 35.60%\n",
      "492\tValidation loss: 2.404583\tBest loss: 2.404583\tAccuracy: 35.20%\n",
      "493\tValidation loss: 2.445415\tBest loss: 2.404583\tAccuracy: 35.00%\n",
      "494\tValidation loss: 2.418318\tBest loss: 2.404583\tAccuracy: 35.90%\n",
      "495\tValidation loss: 2.424175\tBest loss: 2.404583\tAccuracy: 33.60%\n",
      "496\tValidation loss: 2.418110\tBest loss: 2.404583\tAccuracy: 35.50%\n",
      "497\tValidation loss: 2.412948\tBest loss: 2.404583\tAccuracy: 34.70%\n",
      "498\tValidation loss: 2.427134\tBest loss: 2.404583\tAccuracy: 34.50%\n",
      "499\tValidation loss: 2.439152\tBest loss: 2.404583\tAccuracy: 34.80%\n",
      "500\tValidation loss: 2.421351\tBest loss: 2.404583\tAccuracy: 35.20%\n",
      "501\tValidation loss: 2.413656\tBest loss: 2.404583\tAccuracy: 33.90%\n",
      "502\tValidation loss: 2.411560\tBest loss: 2.404583\tAccuracy: 33.50%\n",
      "503\tValidation loss: 2.407499\tBest loss: 2.404583\tAccuracy: 35.40%\n",
      "504\tValidation loss: 2.418716\tBest loss: 2.404583\tAccuracy: 33.90%\n",
      "505\tValidation loss: 2.426181\tBest loss: 2.404583\tAccuracy: 34.20%\n",
      "506\tValidation loss: 2.399773\tBest loss: 2.399773\tAccuracy: 35.10%\n",
      "507\tValidation loss: 2.425181\tBest loss: 2.399773\tAccuracy: 34.60%\n",
      "508\tValidation loss: 2.408085\tBest loss: 2.399773\tAccuracy: 34.60%\n",
      "509\tValidation loss: 2.405985\tBest loss: 2.399773\tAccuracy: 35.00%\n",
      "510\tValidation loss: 2.397687\tBest loss: 2.397687\tAccuracy: 35.30%\n",
      "511\tValidation loss: 2.418631\tBest loss: 2.397687\tAccuracy: 33.80%\n",
      "512\tValidation loss: 2.427133\tBest loss: 2.397687\tAccuracy: 35.30%\n",
      "513\tValidation loss: 2.413451\tBest loss: 2.397687\tAccuracy: 34.40%\n",
      "514\tValidation loss: 2.423934\tBest loss: 2.397687\tAccuracy: 34.10%\n",
      "515\tValidation loss: 2.427213\tBest loss: 2.397687\tAccuracy: 33.30%\n",
      "516\tValidation loss: 2.415582\tBest loss: 2.397687\tAccuracy: 33.50%\n",
      "517\tValidation loss: 2.398673\tBest loss: 2.397687\tAccuracy: 36.00%\n",
      "518\tValidation loss: 2.415513\tBest loss: 2.397687\tAccuracy: 34.70%\n",
      "519\tValidation loss: 2.385957\tBest loss: 2.385957\tAccuracy: 34.30%\n",
      "520\tValidation loss: 2.417304\tBest loss: 2.385957\tAccuracy: 33.40%\n",
      "521\tValidation loss: 2.398432\tBest loss: 2.385957\tAccuracy: 34.90%\n",
      "522\tValidation loss: 2.393106\tBest loss: 2.385957\tAccuracy: 36.50%\n",
      "523\tValidation loss: 2.395273\tBest loss: 2.385957\tAccuracy: 35.30%\n",
      "524\tValidation loss: 2.416802\tBest loss: 2.385957\tAccuracy: 33.80%\n",
      "525\tValidation loss: 2.387873\tBest loss: 2.385957\tAccuracy: 34.80%\n",
      "526\tValidation loss: 2.393623\tBest loss: 2.385957\tAccuracy: 34.40%\n",
      "527\tValidation loss: 2.380559\tBest loss: 2.380559\tAccuracy: 34.00%\n",
      "528\tValidation loss: 2.371173\tBest loss: 2.371173\tAccuracy: 35.60%\n",
      "529\tValidation loss: 2.377462\tBest loss: 2.371173\tAccuracy: 36.30%\n",
      "530\tValidation loss: 2.396959\tBest loss: 2.371173\tAccuracy: 34.50%\n",
      "531\tValidation loss: 2.378849\tBest loss: 2.371173\tAccuracy: 35.90%\n",
      "532\tValidation loss: 2.367214\tBest loss: 2.367214\tAccuracy: 36.10%\n",
      "533\tValidation loss: 2.389123\tBest loss: 2.367214\tAccuracy: 35.60%\n",
      "534\tValidation loss: 2.370207\tBest loss: 2.367214\tAccuracy: 35.20%\n",
      "535\tValidation loss: 2.398582\tBest loss: 2.367214\tAccuracy: 34.60%\n",
      "536\tValidation loss: 2.384159\tBest loss: 2.367214\tAccuracy: 34.10%\n",
      "537\tValidation loss: 2.368359\tBest loss: 2.367214\tAccuracy: 34.50%\n",
      "538\tValidation loss: 2.374950\tBest loss: 2.367214\tAccuracy: 35.10%\n",
      "539\tValidation loss: 2.369892\tBest loss: 2.367214\tAccuracy: 35.00%\n",
      "540\tValidation loss: 2.385154\tBest loss: 2.367214\tAccuracy: 34.80%\n",
      "541\tValidation loss: 2.367150\tBest loss: 2.367150\tAccuracy: 35.10%\n",
      "542\tValidation loss: 2.369863\tBest loss: 2.367150\tAccuracy: 35.70%\n",
      "543\tValidation loss: 2.363806\tBest loss: 2.363806\tAccuracy: 36.30%\n",
      "544\tValidation loss: 2.372796\tBest loss: 2.363806\tAccuracy: 36.30%\n",
      "545\tValidation loss: 2.353470\tBest loss: 2.353470\tAccuracy: 37.00%\n",
      "546\tValidation loss: 2.357842\tBest loss: 2.353470\tAccuracy: 35.90%\n",
      "547\tValidation loss: 2.380019\tBest loss: 2.353470\tAccuracy: 35.00%\n",
      "548\tValidation loss: 2.355951\tBest loss: 2.353470\tAccuracy: 35.40%\n",
      "549\tValidation loss: 2.356782\tBest loss: 2.353470\tAccuracy: 34.50%\n",
      "550\tValidation loss: 2.378487\tBest loss: 2.353470\tAccuracy: 35.20%\n",
      "551\tValidation loss: 2.343742\tBest loss: 2.343742\tAccuracy: 36.30%\n",
      "552\tValidation loss: 2.337691\tBest loss: 2.337691\tAccuracy: 37.50%\n",
      "553\tValidation loss: 2.337651\tBest loss: 2.337651\tAccuracy: 36.60%\n",
      "554\tValidation loss: 2.331899\tBest loss: 2.331899\tAccuracy: 35.50%\n",
      "555\tValidation loss: 2.350206\tBest loss: 2.331899\tAccuracy: 35.10%\n",
      "556\tValidation loss: 2.338513\tBest loss: 2.331899\tAccuracy: 37.00%\n",
      "557\tValidation loss: 2.360171\tBest loss: 2.331899\tAccuracy: 36.20%\n",
      "558\tValidation loss: 2.332323\tBest loss: 2.331899\tAccuracy: 37.20%\n",
      "559\tValidation loss: 2.367201\tBest loss: 2.331899\tAccuracy: 34.70%\n",
      "560\tValidation loss: 2.355440\tBest loss: 2.331899\tAccuracy: 35.80%\n",
      "561\tValidation loss: 2.355895\tBest loss: 2.331899\tAccuracy: 34.60%\n",
      "562\tValidation loss: 2.314101\tBest loss: 2.314101\tAccuracy: 38.30%\n",
      "563\tValidation loss: 2.340595\tBest loss: 2.314101\tAccuracy: 35.30%\n",
      "564\tValidation loss: 2.336900\tBest loss: 2.314101\tAccuracy: 35.40%\n",
      "565\tValidation loss: 2.324660\tBest loss: 2.314101\tAccuracy: 35.80%\n",
      "566\tValidation loss: 2.329349\tBest loss: 2.314101\tAccuracy: 36.30%\n",
      "567\tValidation loss: 2.323598\tBest loss: 2.314101\tAccuracy: 36.10%\n",
      "568\tValidation loss: 2.322231\tBest loss: 2.314101\tAccuracy: 36.00%\n",
      "569\tValidation loss: 2.347672\tBest loss: 2.314101\tAccuracy: 35.70%\n",
      "570\tValidation loss: 2.321508\tBest loss: 2.314101\tAccuracy: 37.60%\n",
      "571\tValidation loss: 2.330403\tBest loss: 2.314101\tAccuracy: 36.60%\n",
      "572\tValidation loss: 2.312891\tBest loss: 2.312891\tAccuracy: 38.10%\n",
      "573\tValidation loss: 2.339735\tBest loss: 2.312891\tAccuracy: 36.10%\n",
      "574\tValidation loss: 2.328527\tBest loss: 2.312891\tAccuracy: 36.40%\n",
      "575\tValidation loss: 2.324786\tBest loss: 2.312891\tAccuracy: 35.50%\n",
      "576\tValidation loss: 2.315840\tBest loss: 2.312891\tAccuracy: 36.30%\n",
      "577\tValidation loss: 2.307593\tBest loss: 2.307593\tAccuracy: 37.40%\n",
      "578\tValidation loss: 2.325184\tBest loss: 2.307593\tAccuracy: 35.80%\n",
      "579\tValidation loss: 2.311157\tBest loss: 2.307593\tAccuracy: 35.10%\n",
      "580\tValidation loss: 2.299411\tBest loss: 2.299411\tAccuracy: 37.60%\n",
      "581\tValidation loss: 2.324151\tBest loss: 2.299411\tAccuracy: 36.00%\n",
      "582\tValidation loss: 2.307471\tBest loss: 2.299411\tAccuracy: 37.00%\n",
      "583\tValidation loss: 2.305140\tBest loss: 2.299411\tAccuracy: 36.00%\n",
      "584\tValidation loss: 2.312453\tBest loss: 2.299411\tAccuracy: 36.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\tValidation loss: 2.312143\tBest loss: 2.299411\tAccuracy: 35.60%\n",
      "586\tValidation loss: 2.313814\tBest loss: 2.299411\tAccuracy: 35.40%\n",
      "587\tValidation loss: 2.323113\tBest loss: 2.299411\tAccuracy: 35.90%\n",
      "588\tValidation loss: 2.300492\tBest loss: 2.299411\tAccuracy: 36.20%\n",
      "589\tValidation loss: 2.287205\tBest loss: 2.287205\tAccuracy: 37.10%\n",
      "590\tValidation loss: 2.279414\tBest loss: 2.279414\tAccuracy: 37.40%\n",
      "591\tValidation loss: 2.299931\tBest loss: 2.279414\tAccuracy: 36.30%\n",
      "592\tValidation loss: 2.310264\tBest loss: 2.279414\tAccuracy: 36.30%\n",
      "593\tValidation loss: 2.296177\tBest loss: 2.279414\tAccuracy: 36.60%\n",
      "594\tValidation loss: 2.308697\tBest loss: 2.279414\tAccuracy: 35.80%\n",
      "595\tValidation loss: 2.296794\tBest loss: 2.279414\tAccuracy: 37.00%\n",
      "596\tValidation loss: 2.313870\tBest loss: 2.279414\tAccuracy: 37.40%\n",
      "597\tValidation loss: 2.285655\tBest loss: 2.279414\tAccuracy: 37.30%\n",
      "598\tValidation loss: 2.306520\tBest loss: 2.279414\tAccuracy: 37.60%\n",
      "599\tValidation loss: 2.293091\tBest loss: 2.279414\tAccuracy: 37.30%\n",
      "600\tValidation loss: 2.305688\tBest loss: 2.279414\tAccuracy: 37.50%\n",
      "601\tValidation loss: 2.292861\tBest loss: 2.279414\tAccuracy: 36.80%\n",
      "602\tValidation loss: 2.299346\tBest loss: 2.279414\tAccuracy: 36.90%\n",
      "603\tValidation loss: 2.304221\tBest loss: 2.279414\tAccuracy: 36.60%\n",
      "604\tValidation loss: 2.309223\tBest loss: 2.279414\tAccuracy: 36.20%\n",
      "605\tValidation loss: 2.291654\tBest loss: 2.279414\tAccuracy: 36.80%\n",
      "606\tValidation loss: 2.296371\tBest loss: 2.279414\tAccuracy: 36.90%\n",
      "607\tValidation loss: 2.290190\tBest loss: 2.279414\tAccuracy: 37.10%\n",
      "608\tValidation loss: 2.293151\tBest loss: 2.279414\tAccuracy: 37.10%\n",
      "609\tValidation loss: 2.290848\tBest loss: 2.279414\tAccuracy: 37.60%\n",
      "610\tValidation loss: 2.296926\tBest loss: 2.279414\tAccuracy: 35.40%\n",
      "611\tValidation loss: 2.271682\tBest loss: 2.271682\tAccuracy: 37.30%\n",
      "612\tValidation loss: 2.282230\tBest loss: 2.271682\tAccuracy: 37.70%\n",
      "613\tValidation loss: 2.274235\tBest loss: 2.271682\tAccuracy: 37.90%\n",
      "614\tValidation loss: 2.285098\tBest loss: 2.271682\tAccuracy: 37.70%\n",
      "615\tValidation loss: 2.281788\tBest loss: 2.271682\tAccuracy: 37.10%\n",
      "616\tValidation loss: 2.292591\tBest loss: 2.271682\tAccuracy: 37.80%\n",
      "617\tValidation loss: 2.283633\tBest loss: 2.271682\tAccuracy: 37.10%\n",
      "618\tValidation loss: 2.284820\tBest loss: 2.271682\tAccuracy: 36.80%\n",
      "619\tValidation loss: 2.279308\tBest loss: 2.271682\tAccuracy: 35.50%\n",
      "620\tValidation loss: 2.267768\tBest loss: 2.267768\tAccuracy: 38.30%\n",
      "621\tValidation loss: 2.267520\tBest loss: 2.267520\tAccuracy: 37.50%\n",
      "622\tValidation loss: 2.270946\tBest loss: 2.267520\tAccuracy: 36.50%\n",
      "623\tValidation loss: 2.265450\tBest loss: 2.265450\tAccuracy: 36.70%\n",
      "624\tValidation loss: 2.272607\tBest loss: 2.265450\tAccuracy: 37.50%\n",
      "625\tValidation loss: 2.288500\tBest loss: 2.265450\tAccuracy: 36.70%\n",
      "626\tValidation loss: 2.276859\tBest loss: 2.265450\tAccuracy: 35.90%\n",
      "627\tValidation loss: 2.274054\tBest loss: 2.265450\tAccuracy: 37.20%\n",
      "628\tValidation loss: 2.252347\tBest loss: 2.252347\tAccuracy: 37.70%\n",
      "629\tValidation loss: 2.255266\tBest loss: 2.252347\tAccuracy: 38.20%\n",
      "630\tValidation loss: 2.272916\tBest loss: 2.252347\tAccuracy: 37.10%\n",
      "631\tValidation loss: 2.269542\tBest loss: 2.252347\tAccuracy: 36.70%\n",
      "632\tValidation loss: 2.252326\tBest loss: 2.252326\tAccuracy: 38.20%\n",
      "633\tValidation loss: 2.243654\tBest loss: 2.243654\tAccuracy: 37.30%\n",
      "634\tValidation loss: 2.265480\tBest loss: 2.243654\tAccuracy: 37.60%\n",
      "635\tValidation loss: 2.263744\tBest loss: 2.243654\tAccuracy: 36.70%\n",
      "636\tValidation loss: 2.267626\tBest loss: 2.243654\tAccuracy: 37.70%\n",
      "637\tValidation loss: 2.268289\tBest loss: 2.243654\tAccuracy: 36.20%\n",
      "638\tValidation loss: 2.252146\tBest loss: 2.243654\tAccuracy: 38.40%\n",
      "639\tValidation loss: 2.247041\tBest loss: 2.243654\tAccuracy: 38.10%\n",
      "640\tValidation loss: 2.260243\tBest loss: 2.243654\tAccuracy: 37.80%\n",
      "641\tValidation loss: 2.264992\tBest loss: 2.243654\tAccuracy: 37.00%\n",
      "642\tValidation loss: 2.275340\tBest loss: 2.243654\tAccuracy: 38.00%\n",
      "643\tValidation loss: 2.292424\tBest loss: 2.243654\tAccuracy: 35.60%\n",
      "644\tValidation loss: 2.260234\tBest loss: 2.243654\tAccuracy: 38.10%\n",
      "645\tValidation loss: 2.246107\tBest loss: 2.243654\tAccuracy: 38.50%\n",
      "646\tValidation loss: 2.253742\tBest loss: 2.243654\tAccuracy: 37.70%\n",
      "647\tValidation loss: 2.248572\tBest loss: 2.243654\tAccuracy: 37.30%\n",
      "648\tValidation loss: 2.246961\tBest loss: 2.243654\tAccuracy: 37.40%\n",
      "649\tValidation loss: 2.244757\tBest loss: 2.243654\tAccuracy: 37.20%\n",
      "650\tValidation loss: 2.261716\tBest loss: 2.243654\tAccuracy: 36.30%\n",
      "651\tValidation loss: 2.232515\tBest loss: 2.232515\tAccuracy: 38.50%\n",
      "652\tValidation loss: 2.236058\tBest loss: 2.232515\tAccuracy: 37.40%\n",
      "653\tValidation loss: 2.253751\tBest loss: 2.232515\tAccuracy: 37.20%\n",
      "654\tValidation loss: 2.265517\tBest loss: 2.232515\tAccuracy: 37.40%\n",
      "655\tValidation loss: 2.237750\tBest loss: 2.232515\tAccuracy: 37.20%\n",
      "656\tValidation loss: 2.235629\tBest loss: 2.232515\tAccuracy: 37.20%\n",
      "657\tValidation loss: 2.239369\tBest loss: 2.232515\tAccuracy: 38.60%\n",
      "658\tValidation loss: 2.232504\tBest loss: 2.232504\tAccuracy: 38.00%\n",
      "659\tValidation loss: 2.235209\tBest loss: 2.232504\tAccuracy: 37.40%\n",
      "660\tValidation loss: 2.235559\tBest loss: 2.232504\tAccuracy: 37.10%\n",
      "661\tValidation loss: 2.240215\tBest loss: 2.232504\tAccuracy: 39.00%\n",
      "662\tValidation loss: 2.217965\tBest loss: 2.217965\tAccuracy: 39.30%\n",
      "663\tValidation loss: 2.228187\tBest loss: 2.217965\tAccuracy: 39.00%\n",
      "664\tValidation loss: 2.231921\tBest loss: 2.217965\tAccuracy: 39.50%\n",
      "665\tValidation loss: 2.237791\tBest loss: 2.217965\tAccuracy: 37.90%\n",
      "666\tValidation loss: 2.229661\tBest loss: 2.217965\tAccuracy: 39.70%\n",
      "667\tValidation loss: 2.233390\tBest loss: 2.217965\tAccuracy: 39.10%\n",
      "668\tValidation loss: 2.216395\tBest loss: 2.216395\tAccuracy: 38.90%\n",
      "669\tValidation loss: 2.213618\tBest loss: 2.213618\tAccuracy: 39.10%\n",
      "670\tValidation loss: 2.225297\tBest loss: 2.213618\tAccuracy: 38.10%\n",
      "671\tValidation loss: 2.227062\tBest loss: 2.213618\tAccuracy: 39.10%\n",
      "672\tValidation loss: 2.221478\tBest loss: 2.213618\tAccuracy: 38.90%\n",
      "673\tValidation loss: 2.202626\tBest loss: 2.202626\tAccuracy: 39.20%\n",
      "674\tValidation loss: 2.215327\tBest loss: 2.202626\tAccuracy: 39.00%\n",
      "675\tValidation loss: 2.205697\tBest loss: 2.202626\tAccuracy: 40.10%\n",
      "676\tValidation loss: 2.230839\tBest loss: 2.202626\tAccuracy: 38.20%\n",
      "677\tValidation loss: 2.234295\tBest loss: 2.202626\tAccuracy: 37.90%\n",
      "678\tValidation loss: 2.226028\tBest loss: 2.202626\tAccuracy: 40.10%\n",
      "679\tValidation loss: 2.226742\tBest loss: 2.202626\tAccuracy: 40.20%\n",
      "680\tValidation loss: 2.212209\tBest loss: 2.202626\tAccuracy: 39.00%\n",
      "681\tValidation loss: 2.223326\tBest loss: 2.202626\tAccuracy: 39.20%\n",
      "682\tValidation loss: 2.209182\tBest loss: 2.202626\tAccuracy: 40.90%\n",
      "683\tValidation loss: 2.214810\tBest loss: 2.202626\tAccuracy: 39.90%\n",
      "684\tValidation loss: 2.210917\tBest loss: 2.202626\tAccuracy: 39.10%\n",
      "685\tValidation loss: 2.215951\tBest loss: 2.202626\tAccuracy: 39.60%\n",
      "686\tValidation loss: 2.217362\tBest loss: 2.202626\tAccuracy: 39.30%\n",
      "687\tValidation loss: 2.196303\tBest loss: 2.196303\tAccuracy: 40.30%\n",
      "688\tValidation loss: 2.202314\tBest loss: 2.196303\tAccuracy: 38.80%\n",
      "689\tValidation loss: 2.216027\tBest loss: 2.196303\tAccuracy: 38.90%\n",
      "690\tValidation loss: 2.206632\tBest loss: 2.196303\tAccuracy: 39.00%\n",
      "691\tValidation loss: 2.213912\tBest loss: 2.196303\tAccuracy: 39.20%\n",
      "692\tValidation loss: 2.204778\tBest loss: 2.196303\tAccuracy: 39.50%\n",
      "693\tValidation loss: 2.207913\tBest loss: 2.196303\tAccuracy: 38.80%\n",
      "694\tValidation loss: 2.203058\tBest loss: 2.196303\tAccuracy: 40.60%\n",
      "695\tValidation loss: 2.211353\tBest loss: 2.196303\tAccuracy: 39.70%\n",
      "696\tValidation loss: 2.209182\tBest loss: 2.196303\tAccuracy: 38.40%\n",
      "697\tValidation loss: 2.217107\tBest loss: 2.196303\tAccuracy: 39.40%\n",
      "698\tValidation loss: 2.199291\tBest loss: 2.196303\tAccuracy: 39.30%\n",
      "699\tValidation loss: 2.195908\tBest loss: 2.195908\tAccuracy: 40.20%\n",
      "700\tValidation loss: 2.198197\tBest loss: 2.195908\tAccuracy: 40.20%\n",
      "701\tValidation loss: 2.198834\tBest loss: 2.195908\tAccuracy: 38.70%\n",
      "702\tValidation loss: 2.191117\tBest loss: 2.191117\tAccuracy: 39.10%\n",
      "703\tValidation loss: 2.207747\tBest loss: 2.191117\tAccuracy: 39.10%\n",
      "704\tValidation loss: 2.187892\tBest loss: 2.187892\tAccuracy: 39.40%\n",
      "705\tValidation loss: 2.181171\tBest loss: 2.181171\tAccuracy: 39.90%\n",
      "706\tValidation loss: 2.201998\tBest loss: 2.181171\tAccuracy: 38.00%\n",
      "707\tValidation loss: 2.194542\tBest loss: 2.181171\tAccuracy: 40.50%\n",
      "708\tValidation loss: 2.198625\tBest loss: 2.181171\tAccuracy: 39.50%\n",
      "709\tValidation loss: 2.188205\tBest loss: 2.181171\tAccuracy: 39.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\tValidation loss: 2.195392\tBest loss: 2.181171\tAccuracy: 40.30%\n",
      "711\tValidation loss: 2.219281\tBest loss: 2.181171\tAccuracy: 37.40%\n",
      "712\tValidation loss: 2.183998\tBest loss: 2.181171\tAccuracy: 40.30%\n",
      "713\tValidation loss: 2.201143\tBest loss: 2.181171\tAccuracy: 39.00%\n",
      "714\tValidation loss: 2.204487\tBest loss: 2.181171\tAccuracy: 39.40%\n",
      "715\tValidation loss: 2.187865\tBest loss: 2.181171\tAccuracy: 39.10%\n",
      "716\tValidation loss: 2.189607\tBest loss: 2.181171\tAccuracy: 40.10%\n",
      "717\tValidation loss: 2.185589\tBest loss: 2.181171\tAccuracy: 38.10%\n",
      "718\tValidation loss: 2.178104\tBest loss: 2.178104\tAccuracy: 40.20%\n",
      "719\tValidation loss: 2.186869\tBest loss: 2.178104\tAccuracy: 40.10%\n",
      "720\tValidation loss: 2.177864\tBest loss: 2.177864\tAccuracy: 39.70%\n",
      "721\tValidation loss: 2.165802\tBest loss: 2.165802\tAccuracy: 40.10%\n",
      "722\tValidation loss: 2.188385\tBest loss: 2.165802\tAccuracy: 39.00%\n",
      "723\tValidation loss: 2.177831\tBest loss: 2.165802\tAccuracy: 39.10%\n",
      "724\tValidation loss: 2.173738\tBest loss: 2.165802\tAccuracy: 40.40%\n",
      "725\tValidation loss: 2.167089\tBest loss: 2.165802\tAccuracy: 40.10%\n",
      "726\tValidation loss: 2.171652\tBest loss: 2.165802\tAccuracy: 39.80%\n",
      "727\tValidation loss: 2.167267\tBest loss: 2.165802\tAccuracy: 40.90%\n",
      "728\tValidation loss: 2.188656\tBest loss: 2.165802\tAccuracy: 40.00%\n",
      "729\tValidation loss: 2.174003\tBest loss: 2.165802\tAccuracy: 39.80%\n",
      "730\tValidation loss: 2.162408\tBest loss: 2.162408\tAccuracy: 41.20%\n",
      "731\tValidation loss: 2.160598\tBest loss: 2.160598\tAccuracy: 41.20%\n",
      "732\tValidation loss: 2.166405\tBest loss: 2.160598\tAccuracy: 41.10%\n",
      "733\tValidation loss: 2.155584\tBest loss: 2.155584\tAccuracy: 40.60%\n",
      "734\tValidation loss: 2.165770\tBest loss: 2.155584\tAccuracy: 40.70%\n",
      "735\tValidation loss: 2.170380\tBest loss: 2.155584\tAccuracy: 40.60%\n",
      "736\tValidation loss: 2.183288\tBest loss: 2.155584\tAccuracy: 40.30%\n",
      "737\tValidation loss: 2.161708\tBest loss: 2.155584\tAccuracy: 39.70%\n",
      "738\tValidation loss: 2.169729\tBest loss: 2.155584\tAccuracy: 39.50%\n",
      "739\tValidation loss: 2.179101\tBest loss: 2.155584\tAccuracy: 39.40%\n",
      "740\tValidation loss: 2.172184\tBest loss: 2.155584\tAccuracy: 39.80%\n",
      "741\tValidation loss: 2.172838\tBest loss: 2.155584\tAccuracy: 39.70%\n",
      "742\tValidation loss: 2.181767\tBest loss: 2.155584\tAccuracy: 39.60%\n",
      "743\tValidation loss: 2.160988\tBest loss: 2.155584\tAccuracy: 39.40%\n",
      "744\tValidation loss: 2.157023\tBest loss: 2.155584\tAccuracy: 41.30%\n",
      "745\tValidation loss: 2.159675\tBest loss: 2.155584\tAccuracy: 41.80%\n",
      "746\tValidation loss: 2.170688\tBest loss: 2.155584\tAccuracy: 39.80%\n",
      "747\tValidation loss: 2.156323\tBest loss: 2.155584\tAccuracy: 41.50%\n",
      "748\tValidation loss: 2.163521\tBest loss: 2.155584\tAccuracy: 40.40%\n",
      "749\tValidation loss: 2.160471\tBest loss: 2.155584\tAccuracy: 39.80%\n",
      "750\tValidation loss: 2.173429\tBest loss: 2.155584\tAccuracy: 40.40%\n",
      "751\tValidation loss: 2.164598\tBest loss: 2.155584\tAccuracy: 40.60%\n",
      "752\tValidation loss: 2.143946\tBest loss: 2.143946\tAccuracy: 40.20%\n",
      "753\tValidation loss: 2.163760\tBest loss: 2.143946\tAccuracy: 39.70%\n",
      "754\tValidation loss: 2.151209\tBest loss: 2.143946\tAccuracy: 40.00%\n",
      "755\tValidation loss: 2.142011\tBest loss: 2.142011\tAccuracy: 40.60%\n",
      "756\tValidation loss: 2.143277\tBest loss: 2.142011\tAccuracy: 40.40%\n",
      "757\tValidation loss: 2.130250\tBest loss: 2.130250\tAccuracy: 40.60%\n",
      "758\tValidation loss: 2.142853\tBest loss: 2.130250\tAccuracy: 40.20%\n",
      "759\tValidation loss: 2.142195\tBest loss: 2.130250\tAccuracy: 41.40%\n",
      "760\tValidation loss: 2.159179\tBest loss: 2.130250\tAccuracy: 40.70%\n",
      "761\tValidation loss: 2.148180\tBest loss: 2.130250\tAccuracy: 41.10%\n",
      "762\tValidation loss: 2.139969\tBest loss: 2.130250\tAccuracy: 40.20%\n",
      "763\tValidation loss: 2.139802\tBest loss: 2.130250\tAccuracy: 40.60%\n",
      "764\tValidation loss: 2.145476\tBest loss: 2.130250\tAccuracy: 42.20%\n",
      "765\tValidation loss: 2.146142\tBest loss: 2.130250\tAccuracy: 39.80%\n",
      "766\tValidation loss: 2.143229\tBest loss: 2.130250\tAccuracy: 39.80%\n",
      "767\tValidation loss: 2.130098\tBest loss: 2.130098\tAccuracy: 40.40%\n",
      "768\tValidation loss: 2.141885\tBest loss: 2.130098\tAccuracy: 40.70%\n",
      "769\tValidation loss: 2.140237\tBest loss: 2.130098\tAccuracy: 42.60%\n",
      "770\tValidation loss: 2.136668\tBest loss: 2.130098\tAccuracy: 40.90%\n",
      "771\tValidation loss: 2.149430\tBest loss: 2.130098\tAccuracy: 39.90%\n",
      "772\tValidation loss: 2.123229\tBest loss: 2.123229\tAccuracy: 42.30%\n",
      "773\tValidation loss: 2.144382\tBest loss: 2.123229\tAccuracy: 41.20%\n",
      "774\tValidation loss: 2.129715\tBest loss: 2.123229\tAccuracy: 42.50%\n",
      "775\tValidation loss: 2.135221\tBest loss: 2.123229\tAccuracy: 41.70%\n",
      "776\tValidation loss: 2.136572\tBest loss: 2.123229\tAccuracy: 40.50%\n",
      "777\tValidation loss: 2.137299\tBest loss: 2.123229\tAccuracy: 41.20%\n",
      "778\tValidation loss: 2.121050\tBest loss: 2.121050\tAccuracy: 40.60%\n",
      "779\tValidation loss: 2.133915\tBest loss: 2.121050\tAccuracy: 40.10%\n",
      "780\tValidation loss: 2.147245\tBest loss: 2.121050\tAccuracy: 40.50%\n",
      "781\tValidation loss: 2.135865\tBest loss: 2.121050\tAccuracy: 40.80%\n",
      "782\tValidation loss: 2.124798\tBest loss: 2.121050\tAccuracy: 41.00%\n",
      "783\tValidation loss: 2.126618\tBest loss: 2.121050\tAccuracy: 40.50%\n",
      "784\tValidation loss: 2.123849\tBest loss: 2.121050\tAccuracy: 41.70%\n",
      "785\tValidation loss: 2.104965\tBest loss: 2.104965\tAccuracy: 42.70%\n",
      "786\tValidation loss: 2.120764\tBest loss: 2.104965\tAccuracy: 41.00%\n",
      "787\tValidation loss: 2.111516\tBest loss: 2.104965\tAccuracy: 41.40%\n",
      "788\tValidation loss: 2.114069\tBest loss: 2.104965\tAccuracy: 42.40%\n",
      "789\tValidation loss: 2.120311\tBest loss: 2.104965\tAccuracy: 41.40%\n",
      "790\tValidation loss: 2.122203\tBest loss: 2.104965\tAccuracy: 40.30%\n",
      "791\tValidation loss: 2.104922\tBest loss: 2.104922\tAccuracy: 42.00%\n",
      "792\tValidation loss: 2.108438\tBest loss: 2.104922\tAccuracy: 41.40%\n",
      "793\tValidation loss: 2.107229\tBest loss: 2.104922\tAccuracy: 39.70%\n",
      "794\tValidation loss: 2.114438\tBest loss: 2.104922\tAccuracy: 41.10%\n",
      "795\tValidation loss: 2.114648\tBest loss: 2.104922\tAccuracy: 41.50%\n",
      "796\tValidation loss: 2.110848\tBest loss: 2.104922\tAccuracy: 40.60%\n",
      "797\tValidation loss: 2.105584\tBest loss: 2.104922\tAccuracy: 41.40%\n",
      "798\tValidation loss: 2.120291\tBest loss: 2.104922\tAccuracy: 41.80%\n",
      "799\tValidation loss: 2.100082\tBest loss: 2.100082\tAccuracy: 42.10%\n",
      "800\tValidation loss: 2.098778\tBest loss: 2.098778\tAccuracy: 42.00%\n",
      "801\tValidation loss: 2.099422\tBest loss: 2.098778\tAccuracy: 42.70%\n",
      "802\tValidation loss: 2.111332\tBest loss: 2.098778\tAccuracy: 42.60%\n",
      "803\tValidation loss: 2.109506\tBest loss: 2.098778\tAccuracy: 40.80%\n",
      "804\tValidation loss: 2.106528\tBest loss: 2.098778\tAccuracy: 41.90%\n",
      "805\tValidation loss: 2.108991\tBest loss: 2.098778\tAccuracy: 42.20%\n",
      "806\tValidation loss: 2.094907\tBest loss: 2.094907\tAccuracy: 42.10%\n",
      "807\tValidation loss: 2.109380\tBest loss: 2.094907\tAccuracy: 40.80%\n",
      "808\tValidation loss: 2.117040\tBest loss: 2.094907\tAccuracy: 41.70%\n",
      "809\tValidation loss: 2.097103\tBest loss: 2.094907\tAccuracy: 43.00%\n",
      "810\tValidation loss: 2.113917\tBest loss: 2.094907\tAccuracy: 41.90%\n",
      "811\tValidation loss: 2.095854\tBest loss: 2.094907\tAccuracy: 42.80%\n",
      "812\tValidation loss: 2.093939\tBest loss: 2.093939\tAccuracy: 42.20%\n",
      "813\tValidation loss: 2.107125\tBest loss: 2.093939\tAccuracy: 40.90%\n",
      "814\tValidation loss: 2.100234\tBest loss: 2.093939\tAccuracy: 41.70%\n",
      "815\tValidation loss: 2.117129\tBest loss: 2.093939\tAccuracy: 41.60%\n",
      "816\tValidation loss: 2.106647\tBest loss: 2.093939\tAccuracy: 41.70%\n",
      "817\tValidation loss: 2.110947\tBest loss: 2.093939\tAccuracy: 41.90%\n",
      "818\tValidation loss: 2.114731\tBest loss: 2.093939\tAccuracy: 41.40%\n",
      "819\tValidation loss: 2.110367\tBest loss: 2.093939\tAccuracy: 42.70%\n",
      "820\tValidation loss: 2.113465\tBest loss: 2.093939\tAccuracy: 42.10%\n",
      "821\tValidation loss: 2.097265\tBest loss: 2.093939\tAccuracy: 42.00%\n",
      "822\tValidation loss: 2.083522\tBest loss: 2.083522\tAccuracy: 42.50%\n",
      "823\tValidation loss: 2.089826\tBest loss: 2.083522\tAccuracy: 43.00%\n",
      "824\tValidation loss: 2.098382\tBest loss: 2.083522\tAccuracy: 42.50%\n",
      "825\tValidation loss: 2.084939\tBest loss: 2.083522\tAccuracy: 42.60%\n",
      "826\tValidation loss: 2.093098\tBest loss: 2.083522\tAccuracy: 42.80%\n",
      "827\tValidation loss: 2.092192\tBest loss: 2.083522\tAccuracy: 43.60%\n",
      "828\tValidation loss: 2.091558\tBest loss: 2.083522\tAccuracy: 43.40%\n",
      "829\tValidation loss: 2.099241\tBest loss: 2.083522\tAccuracy: 42.40%\n",
      "830\tValidation loss: 2.110879\tBest loss: 2.083522\tAccuracy: 43.10%\n",
      "831\tValidation loss: 2.099959\tBest loss: 2.083522\tAccuracy: 42.00%\n",
      "832\tValidation loss: 2.093352\tBest loss: 2.083522\tAccuracy: 42.70%\n",
      "833\tValidation loss: 2.083330\tBest loss: 2.083330\tAccuracy: 42.30%\n",
      "834\tValidation loss: 2.086110\tBest loss: 2.083330\tAccuracy: 42.80%\n",
      "835\tValidation loss: 2.089126\tBest loss: 2.083330\tAccuracy: 42.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\tValidation loss: 2.085023\tBest loss: 2.083330\tAccuracy: 43.50%\n",
      "837\tValidation loss: 2.077669\tBest loss: 2.077669\tAccuracy: 43.90%\n",
      "838\tValidation loss: 2.086065\tBest loss: 2.077669\tAccuracy: 42.80%\n",
      "839\tValidation loss: 2.086955\tBest loss: 2.077669\tAccuracy: 42.00%\n",
      "840\tValidation loss: 2.085882\tBest loss: 2.077669\tAccuracy: 42.40%\n",
      "841\tValidation loss: 2.079760\tBest loss: 2.077669\tAccuracy: 43.20%\n",
      "842\tValidation loss: 2.091413\tBest loss: 2.077669\tAccuracy: 42.50%\n",
      "843\tValidation loss: 2.089263\tBest loss: 2.077669\tAccuracy: 42.90%\n",
      "844\tValidation loss: 2.089375\tBest loss: 2.077669\tAccuracy: 42.40%\n",
      "845\tValidation loss: 2.078731\tBest loss: 2.077669\tAccuracy: 42.60%\n",
      "846\tValidation loss: 2.081134\tBest loss: 2.077669\tAccuracy: 41.80%\n",
      "847\tValidation loss: 2.072298\tBest loss: 2.072298\tAccuracy: 43.10%\n",
      "848\tValidation loss: 2.090296\tBest loss: 2.072298\tAccuracy: 42.30%\n",
      "849\tValidation loss: 2.087750\tBest loss: 2.072298\tAccuracy: 42.10%\n",
      "850\tValidation loss: 2.094624\tBest loss: 2.072298\tAccuracy: 42.20%\n",
      "851\tValidation loss: 2.073782\tBest loss: 2.072298\tAccuracy: 43.30%\n",
      "852\tValidation loss: 2.063543\tBest loss: 2.063543\tAccuracy: 43.20%\n",
      "853\tValidation loss: 2.092474\tBest loss: 2.063543\tAccuracy: 42.50%\n",
      "854\tValidation loss: 2.078944\tBest loss: 2.063543\tAccuracy: 43.80%\n",
      "855\tValidation loss: 2.080442\tBest loss: 2.063543\tAccuracy: 42.50%\n",
      "856\tValidation loss: 2.084395\tBest loss: 2.063543\tAccuracy: 43.20%\n",
      "857\tValidation loss: 2.067398\tBest loss: 2.063543\tAccuracy: 43.30%\n",
      "858\tValidation loss: 2.084285\tBest loss: 2.063543\tAccuracy: 43.90%\n",
      "859\tValidation loss: 2.089480\tBest loss: 2.063543\tAccuracy: 42.60%\n",
      "860\tValidation loss: 2.070916\tBest loss: 2.063543\tAccuracy: 43.40%\n",
      "861\tValidation loss: 2.064716\tBest loss: 2.063543\tAccuracy: 43.90%\n",
      "862\tValidation loss: 2.063182\tBest loss: 2.063182\tAccuracy: 42.80%\n",
      "863\tValidation loss: 2.084845\tBest loss: 2.063182\tAccuracy: 42.60%\n",
      "864\tValidation loss: 2.073015\tBest loss: 2.063182\tAccuracy: 43.60%\n",
      "865\tValidation loss: 2.065813\tBest loss: 2.063182\tAccuracy: 44.00%\n",
      "866\tValidation loss: 2.070710\tBest loss: 2.063182\tAccuracy: 43.70%\n",
      "867\tValidation loss: 2.060782\tBest loss: 2.060782\tAccuracy: 44.00%\n",
      "868\tValidation loss: 2.062143\tBest loss: 2.060782\tAccuracy: 44.80%\n",
      "869\tValidation loss: 2.064953\tBest loss: 2.060782\tAccuracy: 44.20%\n",
      "870\tValidation loss: 2.067981\tBest loss: 2.060782\tAccuracy: 44.00%\n",
      "871\tValidation loss: 2.069521\tBest loss: 2.060782\tAccuracy: 44.50%\n",
      "872\tValidation loss: 2.077363\tBest loss: 2.060782\tAccuracy: 43.30%\n",
      "873\tValidation loss: 2.077931\tBest loss: 2.060782\tAccuracy: 42.80%\n",
      "874\tValidation loss: 2.075898\tBest loss: 2.060782\tAccuracy: 42.10%\n",
      "875\tValidation loss: 2.062950\tBest loss: 2.060782\tAccuracy: 43.50%\n",
      "876\tValidation loss: 2.059122\tBest loss: 2.059122\tAccuracy: 44.10%\n",
      "877\tValidation loss: 2.073063\tBest loss: 2.059122\tAccuracy: 43.20%\n",
      "878\tValidation loss: 2.052482\tBest loss: 2.052482\tAccuracy: 43.00%\n",
      "879\tValidation loss: 2.066723\tBest loss: 2.052482\tAccuracy: 42.80%\n",
      "880\tValidation loss: 2.089754\tBest loss: 2.052482\tAccuracy: 42.20%\n",
      "881\tValidation loss: 2.055828\tBest loss: 2.052482\tAccuracy: 42.70%\n",
      "882\tValidation loss: 2.059108\tBest loss: 2.052482\tAccuracy: 43.70%\n",
      "883\tValidation loss: 2.066041\tBest loss: 2.052482\tAccuracy: 42.10%\n",
      "884\tValidation loss: 2.054964\tBest loss: 2.052482\tAccuracy: 43.00%\n",
      "885\tValidation loss: 2.059155\tBest loss: 2.052482\tAccuracy: 43.40%\n",
      "886\tValidation loss: 2.051570\tBest loss: 2.051570\tAccuracy: 43.50%\n",
      "887\tValidation loss: 2.063714\tBest loss: 2.051570\tAccuracy: 43.40%\n",
      "888\tValidation loss: 2.050532\tBest loss: 2.050532\tAccuracy: 43.20%\n",
      "889\tValidation loss: 2.052242\tBest loss: 2.050532\tAccuracy: 44.30%\n",
      "890\tValidation loss: 2.072191\tBest loss: 2.050532\tAccuracy: 43.10%\n",
      "891\tValidation loss: 2.053488\tBest loss: 2.050532\tAccuracy: 43.80%\n",
      "892\tValidation loss: 2.053164\tBest loss: 2.050532\tAccuracy: 43.70%\n",
      "893\tValidation loss: 2.040907\tBest loss: 2.040907\tAccuracy: 43.30%\n",
      "894\tValidation loss: 2.072947\tBest loss: 2.040907\tAccuracy: 43.10%\n",
      "895\tValidation loss: 2.055626\tBest loss: 2.040907\tAccuracy: 43.30%\n",
      "896\tValidation loss: 2.059346\tBest loss: 2.040907\tAccuracy: 42.90%\n",
      "897\tValidation loss: 2.047286\tBest loss: 2.040907\tAccuracy: 44.00%\n",
      "898\tValidation loss: 2.063232\tBest loss: 2.040907\tAccuracy: 43.40%\n",
      "899\tValidation loss: 2.043144\tBest loss: 2.040907\tAccuracy: 44.10%\n",
      "900\tValidation loss: 2.043656\tBest loss: 2.040907\tAccuracy: 43.90%\n",
      "901\tValidation loss: 2.042194\tBest loss: 2.040907\tAccuracy: 43.70%\n",
      "902\tValidation loss: 2.038635\tBest loss: 2.038635\tAccuracy: 43.20%\n",
      "903\tValidation loss: 2.049679\tBest loss: 2.038635\tAccuracy: 44.40%\n",
      "904\tValidation loss: 2.043282\tBest loss: 2.038635\tAccuracy: 44.40%\n",
      "905\tValidation loss: 2.052756\tBest loss: 2.038635\tAccuracy: 42.70%\n",
      "906\tValidation loss: 2.061548\tBest loss: 2.038635\tAccuracy: 44.10%\n",
      "907\tValidation loss: 2.037108\tBest loss: 2.037108\tAccuracy: 42.60%\n",
      "908\tValidation loss: 2.046481\tBest loss: 2.037108\tAccuracy: 42.30%\n",
      "909\tValidation loss: 2.042299\tBest loss: 2.037108\tAccuracy: 43.70%\n",
      "910\tValidation loss: 2.027827\tBest loss: 2.027827\tAccuracy: 44.00%\n",
      "911\tValidation loss: 2.041313\tBest loss: 2.027827\tAccuracy: 44.10%\n",
      "912\tValidation loss: 2.029134\tBest loss: 2.027827\tAccuracy: 43.20%\n",
      "913\tValidation loss: 2.027771\tBest loss: 2.027771\tAccuracy: 44.70%\n",
      "914\tValidation loss: 2.025504\tBest loss: 2.025504\tAccuracy: 44.20%\n",
      "915\tValidation loss: 2.031367\tBest loss: 2.025504\tAccuracy: 44.60%\n",
      "916\tValidation loss: 2.040773\tBest loss: 2.025504\tAccuracy: 43.60%\n",
      "917\tValidation loss: 2.035774\tBest loss: 2.025504\tAccuracy: 45.00%\n",
      "918\tValidation loss: 2.041072\tBest loss: 2.025504\tAccuracy: 44.80%\n",
      "919\tValidation loss: 2.042984\tBest loss: 2.025504\tAccuracy: 45.00%\n",
      "920\tValidation loss: 2.051525\tBest loss: 2.025504\tAccuracy: 44.40%\n",
      "921\tValidation loss: 2.040327\tBest loss: 2.025504\tAccuracy: 43.90%\n",
      "922\tValidation loss: 2.039412\tBest loss: 2.025504\tAccuracy: 44.20%\n",
      "923\tValidation loss: 2.035656\tBest loss: 2.025504\tAccuracy: 44.30%\n",
      "924\tValidation loss: 2.028953\tBest loss: 2.025504\tAccuracy: 43.60%\n",
      "925\tValidation loss: 2.024249\tBest loss: 2.024249\tAccuracy: 45.50%\n",
      "926\tValidation loss: 2.038896\tBest loss: 2.024249\tAccuracy: 43.90%\n",
      "927\tValidation loss: 2.033097\tBest loss: 2.024249\tAccuracy: 44.20%\n",
      "928\tValidation loss: 2.018310\tBest loss: 2.018310\tAccuracy: 44.80%\n",
      "929\tValidation loss: 2.024356\tBest loss: 2.018310\tAccuracy: 43.60%\n",
      "930\tValidation loss: 2.030376\tBest loss: 2.018310\tAccuracy: 42.70%\n",
      "931\tValidation loss: 2.036272\tBest loss: 2.018310\tAccuracy: 45.20%\n",
      "932\tValidation loss: 2.026430\tBest loss: 2.018310\tAccuracy: 44.70%\n",
      "933\tValidation loss: 2.031950\tBest loss: 2.018310\tAccuracy: 45.50%\n",
      "934\tValidation loss: 2.035291\tBest loss: 2.018310\tAccuracy: 44.30%\n",
      "935\tValidation loss: 2.039000\tBest loss: 2.018310\tAccuracy: 45.00%\n",
      "936\tValidation loss: 2.028490\tBest loss: 2.018310\tAccuracy: 44.70%\n",
      "937\tValidation loss: 2.020110\tBest loss: 2.018310\tAccuracy: 44.10%\n",
      "938\tValidation loss: 2.025830\tBest loss: 2.018310\tAccuracy: 44.70%\n",
      "939\tValidation loss: 2.018348\tBest loss: 2.018310\tAccuracy: 43.90%\n",
      "940\tValidation loss: 2.017027\tBest loss: 2.017027\tAccuracy: 44.40%\n",
      "941\tValidation loss: 2.018480\tBest loss: 2.017027\tAccuracy: 43.60%\n",
      "942\tValidation loss: 2.038503\tBest loss: 2.017027\tAccuracy: 44.50%\n",
      "943\tValidation loss: 2.014964\tBest loss: 2.014964\tAccuracy: 44.30%\n",
      "944\tValidation loss: 2.027517\tBest loss: 2.014964\tAccuracy: 44.40%\n",
      "945\tValidation loss: 2.019742\tBest loss: 2.014964\tAccuracy: 44.80%\n",
      "946\tValidation loss: 2.013977\tBest loss: 2.013977\tAccuracy: 43.90%\n",
      "947\tValidation loss: 2.023138\tBest loss: 2.013977\tAccuracy: 43.70%\n",
      "948\tValidation loss: 2.020720\tBest loss: 2.013977\tAccuracy: 44.80%\n",
      "949\tValidation loss: 2.011987\tBest loss: 2.011987\tAccuracy: 44.70%\n",
      "950\tValidation loss: 2.025048\tBest loss: 2.011987\tAccuracy: 44.60%\n",
      "951\tValidation loss: 2.013821\tBest loss: 2.011987\tAccuracy: 44.60%\n",
      "952\tValidation loss: 2.008577\tBest loss: 2.008577\tAccuracy: 44.60%\n",
      "953\tValidation loss: 1.998383\tBest loss: 1.998383\tAccuracy: 46.00%\n",
      "954\tValidation loss: 2.014210\tBest loss: 1.998383\tAccuracy: 45.30%\n",
      "955\tValidation loss: 2.009676\tBest loss: 1.998383\tAccuracy: 44.90%\n",
      "956\tValidation loss: 2.013336\tBest loss: 1.998383\tAccuracy: 44.20%\n",
      "957\tValidation loss: 2.020665\tBest loss: 1.998383\tAccuracy: 45.00%\n",
      "958\tValidation loss: 2.009798\tBest loss: 1.998383\tAccuracy: 45.00%\n",
      "959\tValidation loss: 2.007501\tBest loss: 1.998383\tAccuracy: 44.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\tValidation loss: 2.003649\tBest loss: 1.998383\tAccuracy: 45.10%\n",
      "961\tValidation loss: 2.010238\tBest loss: 1.998383\tAccuracy: 46.00%\n",
      "962\tValidation loss: 2.011523\tBest loss: 1.998383\tAccuracy: 45.30%\n",
      "963\tValidation loss: 2.015065\tBest loss: 1.998383\tAccuracy: 44.60%\n",
      "964\tValidation loss: 2.012289\tBest loss: 1.998383\tAccuracy: 44.00%\n",
      "965\tValidation loss: 2.005049\tBest loss: 1.998383\tAccuracy: 45.00%\n",
      "966\tValidation loss: 2.002962\tBest loss: 1.998383\tAccuracy: 44.70%\n",
      "967\tValidation loss: 2.008625\tBest loss: 1.998383\tAccuracy: 46.40%\n",
      "968\tValidation loss: 2.009020\tBest loss: 1.998383\tAccuracy: 46.80%\n",
      "969\tValidation loss: 2.016694\tBest loss: 1.998383\tAccuracy: 45.60%\n",
      "970\tValidation loss: 2.009980\tBest loss: 1.998383\tAccuracy: 44.60%\n",
      "971\tValidation loss: 2.004408\tBest loss: 1.998383\tAccuracy: 45.40%\n",
      "972\tValidation loss: 2.019168\tBest loss: 1.998383\tAccuracy: 44.00%\n",
      "973\tValidation loss: 2.017620\tBest loss: 1.998383\tAccuracy: 43.50%\n",
      "974\tValidation loss: 2.005858\tBest loss: 1.998383\tAccuracy: 45.40%\n",
      "Early stopping!\n",
      "[[  4.26840363e-03   8.94144736e-03   3.07847839e-03 ...,   3.14495526e-02\n",
      "    5.41170780e-03   9.34525393e-03]\n",
      " [  6.85414716e-06   3.37796009e-05   2.68775402e-05 ...,   9.19055165e-05\n",
      "    2.34878826e-06   2.80730474e-05]\n",
      " [  5.78264659e-03   1.30653149e-02   6.58906018e-03 ...,   2.61439040e-04\n",
      "    2.23848363e-03   3.45007866e-03]\n",
      " ..., \n",
      " [  3.77464145e-02   3.82169150e-02   1.35856448e-02 ...,   1.15736126e-04\n",
      "    2.32098697e-04   9.02176835e-05]\n",
      " [  4.80567031e-02   2.77847536e-02   4.23000380e-02 ...,   1.62762739e-02\n",
      "    1.27414027e-02   1.15303034e-02]\n",
      " [  1.49317730e-05   5.19859546e-04   9.51817856e-05 ...,   2.26458848e-01\n",
      "    1.05766118e-01   2.06157327e-01]]\n",
      "[15 40 20 ...,  6  9 45]\n",
      "[[  1.72081156e-04   1.46155003e-02   5.71740465e-03 ...,   4.93926890e-08\n",
      "    8.51893637e-05   4.13984963e-05]\n",
      " [  1.14443175e-01   3.97597812e-02   5.79386279e-02 ...,   7.42417946e-03\n",
      "    5.57202520e-03   4.46119672e-03]\n",
      " [  2.78509891e-04   4.46541708e-06   9.43637267e-03 ...,   1.46209641e-04\n",
      "    2.62021331e-06   2.48402330e-08]\n",
      " ..., \n",
      " [  3.96867376e-03   1.54434075e-03   4.00725286e-03 ...,   1.23934029e-02\n",
      "    9.00813285e-03   1.66858584e-02]\n",
      " [  3.50652059e-04   1.10904872e-03   7.31299224e-04 ...,   2.46772796e-01\n",
      "    9.23031196e-02   7.48107955e-02]\n",
      " [  1.03519275e-03   5.56011742e-04   6.51632610e-04 ...,   6.68934062e-02\n",
      "    2.63077710e-02   3.92075740e-02]]\n",
      "[ 9  0 16 ..., 36 45  8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=2, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  51.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.941407\tBest loss: 3.941407\tAccuracy: 3.40%\n",
      "1\tValidation loss: 4.094126\tBest loss: 3.941407\tAccuracy: 3.60%\n",
      "2\tValidation loss: 4.053977\tBest loss: 3.941407\tAccuracy: 3.60%\n",
      "3\tValidation loss: 4.088418\tBest loss: 3.941407\tAccuracy: 1.70%\n",
      "4\tValidation loss: 3.938688\tBest loss: 3.938688\tAccuracy: 3.90%\n",
      "5\tValidation loss: 4.071423\tBest loss: 3.938688\tAccuracy: 4.20%\n",
      "6\tValidation loss: 3.997314\tBest loss: 3.938688\tAccuracy: 3.00%\n",
      "7\tValidation loss: 4.147562\tBest loss: 3.938688\tAccuracy: 4.30%\n",
      "8\tValidation loss: 3.975381\tBest loss: 3.938688\tAccuracy: 4.30%\n",
      "9\tValidation loss: 4.131170\tBest loss: 3.938688\tAccuracy: 2.60%\n",
      "10\tValidation loss: 4.031297\tBest loss: 3.938688\tAccuracy: 4.20%\n",
      "11\tValidation loss: 3.996374\tBest loss: 3.938688\tAccuracy: 4.10%\n",
      "12\tValidation loss: 4.085317\tBest loss: 3.938688\tAccuracy: 2.20%\n",
      "13\tValidation loss: 4.028151\tBest loss: 3.938688\tAccuracy: 3.90%\n",
      "14\tValidation loss: 4.080612\tBest loss: 3.938688\tAccuracy: 4.10%\n",
      "15\tValidation loss: 4.081858\tBest loss: 3.938688\tAccuracy: 2.90%\n",
      "16\tValidation loss: 3.992088\tBest loss: 3.938688\tAccuracy: 1.60%\n",
      "17\tValidation loss: 4.066257\tBest loss: 3.938688\tAccuracy: 4.10%\n",
      "18\tValidation loss: 4.096741\tBest loss: 3.938688\tAccuracy: 3.00%\n",
      "19\tValidation loss: 4.033288\tBest loss: 3.938688\tAccuracy: 4.00%\n",
      "20\tValidation loss: 4.039166\tBest loss: 3.938688\tAccuracy: 3.60%\n",
      "21\tValidation loss: 3.984022\tBest loss: 3.938688\tAccuracy: 1.40%\n",
      "22\tValidation loss: 4.039976\tBest loss: 3.938688\tAccuracy: 5.00%\n",
      "23\tValidation loss: 4.124781\tBest loss: 3.938688\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.975878\tBest loss: 3.938688\tAccuracy: 4.80%\n",
      "25\tValidation loss: 4.073190\tBest loss: 3.938688\tAccuracy: 3.10%\n",
      "Early stopping!\n",
      "[[ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02556342  0.01685312  0.01973077 ...,  0.01865728  0.01019425\n",
      "   0.01308394]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " ..., \n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[[ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " ..., \n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]\n",
      " [ 0.02783738  0.01780182  0.02002127 ...,  0.01853669  0.01037461\n",
      "   0.01350872]\n",
      " [ 0.02506433  0.01715167  0.0192129  ...,  0.01861318  0.01027477\n",
      "   0.01344213]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=  28.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.946907\tBest loss: 3.946907\tAccuracy: 2.70%\n",
      "1\tValidation loss: 3.992785\tBest loss: 3.946907\tAccuracy: 4.30%\n",
      "2\tValidation loss: 4.003182\tBest loss: 3.946907\tAccuracy: 4.10%\n",
      "3\tValidation loss: 4.041838\tBest loss: 3.946907\tAccuracy: 3.00%\n",
      "4\tValidation loss: 4.008241\tBest loss: 3.946907\tAccuracy: 4.50%\n",
      "5\tValidation loss: 3.960579\tBest loss: 3.946907\tAccuracy: 4.20%\n",
      "6\tValidation loss: 4.019975\tBest loss: 3.946907\tAccuracy: 2.00%\n",
      "7\tValidation loss: 4.124730\tBest loss: 3.946907\tAccuracy: 1.50%\n",
      "8\tValidation loss: 3.989402\tBest loss: 3.946907\tAccuracy: 3.50%\n",
      "9\tValidation loss: 3.974856\tBest loss: 3.946907\tAccuracy: 2.10%\n",
      "10\tValidation loss: 4.105820\tBest loss: 3.946907\tAccuracy: 2.50%\n",
      "11\tValidation loss: 4.041563\tBest loss: 3.946907\tAccuracy: 3.00%\n",
      "12\tValidation loss: 4.099774\tBest loss: 3.946907\tAccuracy: 2.60%\n",
      "13\tValidation loss: 4.036611\tBest loss: 3.946907\tAccuracy: 4.00%\n",
      "14\tValidation loss: 4.029275\tBest loss: 3.946907\tAccuracy: 3.90%\n",
      "15\tValidation loss: 4.047067\tBest loss: 3.946907\tAccuracy: 3.70%\n",
      "16\tValidation loss: 4.041232\tBest loss: 3.946907\tAccuracy: 4.40%\n",
      "17\tValidation loss: 4.010058\tBest loss: 3.946907\tAccuracy: 4.00%\n",
      "18\tValidation loss: 4.012871\tBest loss: 3.946907\tAccuracy: 2.60%\n",
      "19\tValidation loss: 3.930468\tBest loss: 3.930468\tAccuracy: 4.40%\n",
      "20\tValidation loss: 4.201865\tBest loss: 3.930468\tAccuracy: 2.10%\n",
      "21\tValidation loss: 3.983575\tBest loss: 3.930468\tAccuracy: 5.40%\n",
      "22\tValidation loss: 4.002845\tBest loss: 3.930468\tAccuracy: 2.50%\n",
      "23\tValidation loss: 4.132782\tBest loss: 3.930468\tAccuracy: 2.80%\n",
      "24\tValidation loss: 4.060554\tBest loss: 3.930468\tAccuracy: 3.70%\n",
      "25\tValidation loss: 4.071886\tBest loss: 3.930468\tAccuracy: 2.80%\n",
      "26\tValidation loss: 3.949581\tBest loss: 3.930468\tAccuracy: 4.30%\n",
      "27\tValidation loss: 3.994370\tBest loss: 3.930468\tAccuracy: 5.00%\n",
      "28\tValidation loss: 3.980767\tBest loss: 3.930468\tAccuracy: 2.40%\n",
      "29\tValidation loss: 4.089942\tBest loss: 3.930468\tAccuracy: 2.90%\n",
      "30\tValidation loss: 4.087229\tBest loss: 3.930468\tAccuracy: 2.50%\n",
      "31\tValidation loss: 4.090998\tBest loss: 3.930468\tAccuracy: 5.00%\n",
      "32\tValidation loss: 3.955662\tBest loss: 3.930468\tAccuracy: 4.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\tValidation loss: 4.016632\tBest loss: 3.930468\tAccuracy: 4.50%\n",
      "34\tValidation loss: 4.059473\tBest loss: 3.930468\tAccuracy: 3.30%\n",
      "35\tValidation loss: 4.103975\tBest loss: 3.930468\tAccuracy: 4.50%\n",
      "36\tValidation loss: 4.107755\tBest loss: 3.930468\tAccuracy: 4.60%\n",
      "37\tValidation loss: 4.048635\tBest loss: 3.930468\tAccuracy: 1.70%\n",
      "38\tValidation loss: 4.024023\tBest loss: 3.930468\tAccuracy: 3.00%\n",
      "39\tValidation loss: 3.907981\tBest loss: 3.907981\tAccuracy: 3.90%\n",
      "40\tValidation loss: 4.081758\tBest loss: 3.907981\tAccuracy: 3.80%\n",
      "41\tValidation loss: 4.050135\tBest loss: 3.907981\tAccuracy: 2.30%\n",
      "42\tValidation loss: 4.020883\tBest loss: 3.907981\tAccuracy: 2.50%\n",
      "43\tValidation loss: 3.993814\tBest loss: 3.907981\tAccuracy: 4.10%\n",
      "44\tValidation loss: 4.022240\tBest loss: 3.907981\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.982763\tBest loss: 3.907981\tAccuracy: 2.90%\n",
      "46\tValidation loss: 3.967372\tBest loss: 3.907981\tAccuracy: 3.90%\n",
      "47\tValidation loss: 4.009489\tBest loss: 3.907981\tAccuracy: 4.60%\n",
      "48\tValidation loss: 4.058722\tBest loss: 3.907981\tAccuracy: 1.50%\n",
      "49\tValidation loss: 4.084633\tBest loss: 3.907981\tAccuracy: 1.20%\n",
      "50\tValidation loss: 4.072103\tBest loss: 3.907981\tAccuracy: 3.10%\n",
      "51\tValidation loss: 4.011824\tBest loss: 3.907981\tAccuracy: 4.20%\n",
      "52\tValidation loss: 4.032258\tBest loss: 3.907981\tAccuracy: 4.50%\n",
      "53\tValidation loss: 4.045649\tBest loss: 3.907981\tAccuracy: 3.80%\n",
      "54\tValidation loss: 4.034963\tBest loss: 3.907981\tAccuracy: 2.30%\n",
      "55\tValidation loss: 4.016055\tBest loss: 3.907981\tAccuracy: 2.50%\n",
      "56\tValidation loss: 3.986874\tBest loss: 3.907981\tAccuracy: 4.60%\n",
      "57\tValidation loss: 4.066296\tBest loss: 3.907981\tAccuracy: 3.80%\n",
      "58\tValidation loss: 4.094101\tBest loss: 3.907981\tAccuracy: 3.20%\n",
      "59\tValidation loss: 4.024965\tBest loss: 3.907981\tAccuracy: 4.00%\n",
      "60\tValidation loss: 4.010705\tBest loss: 3.907981\tAccuracy: 4.20%\n",
      "Early stopping!\n",
      "[[ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " ..., \n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[[ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00557039  0.0611968   0.00570827 ...,  0.01307076  0.00668718\n",
      "   0.02148484]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " ..., \n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]\n",
      " [ 0.00556884  0.06132341  0.00570443 ...,  0.0131194   0.00668812\n",
      "   0.02154448]\n",
      " [ 0.00556265  0.06118343  0.0056984  ...,  0.01311098  0.00668614\n",
      "   0.02151223]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total= 1.1min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.899197\tBest loss: 3.899197\tAccuracy: 4.60%\n",
      "1\tValidation loss: 3.995279\tBest loss: 3.899197\tAccuracy: 3.90%\n",
      "2\tValidation loss: 3.988059\tBest loss: 3.899197\tAccuracy: 1.90%\n",
      "3\tValidation loss: 3.929896\tBest loss: 3.899197\tAccuracy: 2.70%\n",
      "4\tValidation loss: 4.047015\tBest loss: 3.899197\tAccuracy: 3.70%\n",
      "5\tValidation loss: 4.078672\tBest loss: 3.899197\tAccuracy: 4.00%\n",
      "6\tValidation loss: 4.111421\tBest loss: 3.899197\tAccuracy: 2.50%\n",
      "7\tValidation loss: 4.028784\tBest loss: 3.899197\tAccuracy: 4.90%\n",
      "8\tValidation loss: 3.979539\tBest loss: 3.899197\tAccuracy: 3.40%\n",
      "9\tValidation loss: 4.047369\tBest loss: 3.899197\tAccuracy: 2.30%\n",
      "10\tValidation loss: 4.186660\tBest loss: 3.899197\tAccuracy: 3.60%\n",
      "11\tValidation loss: 4.074335\tBest loss: 3.899197\tAccuracy: 3.70%\n",
      "12\tValidation loss: 4.037960\tBest loss: 3.899197\tAccuracy: 3.30%\n",
      "13\tValidation loss: 3.964320\tBest loss: 3.899197\tAccuracy: 3.10%\n",
      "14\tValidation loss: 3.960513\tBest loss: 3.899197\tAccuracy: 2.60%\n",
      "15\tValidation loss: 3.918112\tBest loss: 3.899197\tAccuracy: 3.70%\n",
      "16\tValidation loss: 4.033387\tBest loss: 3.899197\tAccuracy: 2.40%\n",
      "17\tValidation loss: 4.139050\tBest loss: 3.899197\tAccuracy: 3.30%\n",
      "18\tValidation loss: 3.929815\tBest loss: 3.899197\tAccuracy: 4.10%\n",
      "19\tValidation loss: 4.005845\tBest loss: 3.899197\tAccuracy: 4.90%\n",
      "20\tValidation loss: 4.119533\tBest loss: 3.899197\tAccuracy: 4.30%\n",
      "21\tValidation loss: 4.048108\tBest loss: 3.899197\tAccuracy: 4.40%\n",
      "Early stopping!\n",
      "[[ 0.00318095  0.01836044  0.03798972 ...,  0.07141377  0.01007482\n",
      "   0.02114907]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]\n",
      " ..., \n",
      " [ 0.00317885  0.01836526  0.03798903 ...,  0.07144377  0.01007549\n",
      "   0.0211638 ]\n",
      " [ 0.00477228  0.02156715  0.03440319 ...,  0.05054438  0.01216953\n",
      "   0.01932867]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]]\n",
      "[45 45 45 ..., 45 28 45]\n",
      "[[ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]\n",
      " [ 0.00496179  0.02264355  0.0399519  ...,  0.05715538  0.01168835\n",
      "   0.01867341]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]\n",
      " ..., \n",
      " [ 0.00317885  0.01836524  0.03798904 ...,  0.07144375  0.01007549\n",
      "   0.0211638 ]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]\n",
      " [ 0.00317885  0.01836525  0.03798904 ...,  0.0714438   0.01007549\n",
      "   0.02116382]]\n",
      "[45 45 45 ..., 45 45 45]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=1, n_neurons=50, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=  23.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 23.735434\tBest loss: 23.735434\tAccuracy: 1.60%\n",
      "1\tValidation loss: 4.181823\tBest loss: 4.181823\tAccuracy: 4.50%\n",
      "2\tValidation loss: 4.011440\tBest loss: 4.011440\tAccuracy: 5.70%\n",
      "3\tValidation loss: 4.075131\tBest loss: 4.011440\tAccuracy: 4.30%\n",
      "4\tValidation loss: 3.751273\tBest loss: 3.751273\tAccuracy: 6.40%\n",
      "5\tValidation loss: 3.844293\tBest loss: 3.751273\tAccuracy: 4.60%\n",
      "6\tValidation loss: 3.756846\tBest loss: 3.751273\tAccuracy: 5.00%\n",
      "7\tValidation loss: 3.732630\tBest loss: 3.732630\tAccuracy: 7.90%\n",
      "8\tValidation loss: 118049.046875\tBest loss: 3.732630\tAccuracy: 1.80%\n",
      "9\tValidation loss: 8445.592773\tBest loss: 3.732630\tAccuracy: 2.00%\n",
      "10\tValidation loss: 2632.014160\tBest loss: 3.732630\tAccuracy: 3.60%\n",
      "11\tValidation loss: 949.420471\tBest loss: 3.732630\tAccuracy: 3.80%\n",
      "12\tValidation loss: 714.903748\tBest loss: 3.732630\tAccuracy: 2.60%\n",
      "13\tValidation loss: 1059.329346\tBest loss: 3.732630\tAccuracy: 2.50%\n",
      "14\tValidation loss: 1451.170776\tBest loss: 3.732630\tAccuracy: 2.60%\n",
      "15\tValidation loss: 610.150818\tBest loss: 3.732630\tAccuracy: 2.20%\n",
      "16\tValidation loss: 927.767151\tBest loss: 3.732630\tAccuracy: 4.40%\n",
      "17\tValidation loss: 509.327698\tBest loss: 3.732630\tAccuracy: 3.90%\n",
      "18\tValidation loss: 484.402313\tBest loss: 3.732630\tAccuracy: 5.50%\n",
      "19\tValidation loss: 460.155273\tBest loss: 3.732630\tAccuracy: 3.50%\n",
      "20\tValidation loss: 230.183228\tBest loss: 3.732630\tAccuracy: 2.10%\n",
      "21\tValidation loss: 302.767395\tBest loss: 3.732630\tAccuracy: 4.30%\n",
      "22\tValidation loss: 387.033234\tBest loss: 3.732630\tAccuracy: 1.60%\n",
      "23\tValidation loss: 273.965210\tBest loss: 3.732630\tAccuracy: 4.50%\n",
      "24\tValidation loss: 294.861481\tBest loss: 3.732630\tAccuracy: 4.40%\n",
      "25\tValidation loss: 302.169159\tBest loss: 3.732630\tAccuracy: 6.70%\n",
      "26\tValidation loss: 307.260834\tBest loss: 3.732630\tAccuracy: 2.60%\n",
      "27\tValidation loss: 163.479614\tBest loss: 3.732630\tAccuracy: 6.50%\n",
      "28\tValidation loss: 93.976807\tBest loss: 3.732630\tAccuracy: 4.90%\n",
      "Early stopping!\n",
      "[[  2.55859853e-03   2.22430239e-03   3.83147318e-03 ...,   4.44383249e-02\n",
      "    1.49602434e-02   2.98887882e-02]\n",
      " [  4.43486311e-02   2.48949379e-02   3.24051417e-02 ...,   2.89981198e-02\n",
      "    1.30743431e-02   1.61526650e-02]\n",
      " [  2.43339059e-03   7.01616751e-03   9.64555889e-03 ...,   2.95336675e-02\n",
      "    1.45169236e-02   3.20882946e-02]\n",
      " ..., \n",
      " [  2.71179360e-05   3.99968179e-04   8.07136646e-04 ...,   1.67597290e-02\n",
      "    1.02111306e-02   4.83469628e-02]\n",
      " [  3.11274882e-02   2.35041715e-02   3.03598810e-02 ...,   3.17489132e-02\n",
      "    1.19388187e-02   1.75389312e-02]\n",
      " [  8.40946450e-04   4.45128855e-04   9.31231305e-04 ...,   4.29146998e-02\n",
      "    9.78191849e-03   2.78610867e-02]]\n",
      "[37  8 16 ..., 35 19 37]\n",
      "[[ 0.004308    0.00467047  0.00733264 ...,  0.03634178  0.01410222\n",
      "   0.02872622]\n",
      " [ 0.00141722  0.00124451  0.00178836 ...,  0.04408899  0.00970512\n",
      "   0.02748059]\n",
      " [ 0.00673482  0.0074207   0.00769053 ...,  0.03757862  0.00868014\n",
      "   0.02246994]\n",
      " ..., \n",
      " [ 0.01353739  0.04266709  0.03650762 ...,  0.01775768  0.00877371\n",
      "   0.01699073]\n",
      " [ 0.04460413  0.02386031  0.0317223  ...,  0.02951187  0.01333993\n",
      "   0.01623518]\n",
      " [ 0.00243033  0.00443742  0.00704601 ...,  0.03492603  0.01449664\n",
      "   0.03397947]]\n",
      "[37  9  9 ..., 17  8 37]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 130.899399\tBest loss: 130.899399\tAccuracy: 3.60%\n",
      "1\tValidation loss: 6.599061\tBest loss: 6.599061\tAccuracy: 4.00%\n",
      "2\tValidation loss: 6.374370\tBest loss: 6.374370\tAccuracy: 4.60%\n",
      "3\tValidation loss: 4.537153\tBest loss: 4.537153\tAccuracy: 5.00%\n",
      "4\tValidation loss: 4.388543\tBest loss: 4.388543\tAccuracy: 4.70%\n",
      "5\tValidation loss: 4.127429\tBest loss: 4.127429\tAccuracy: 5.20%\n",
      "6\tValidation loss: 4.199055\tBest loss: 4.127429\tAccuracy: 8.30%\n",
      "7\tValidation loss: 4.043480\tBest loss: 4.043480\tAccuracy: 6.20%\n",
      "8\tValidation loss: 165193.609375\tBest loss: 4.043480\tAccuracy: 1.80%\n",
      "9\tValidation loss: 67834.703125\tBest loss: 4.043480\tAccuracy: 4.10%\n",
      "10\tValidation loss: 3982.201904\tBest loss: 4.043480\tAccuracy: 2.60%\n",
      "11\tValidation loss: 5801.439941\tBest loss: 4.043480\tAccuracy: 2.20%\n",
      "12\tValidation loss: 1141.411499\tBest loss: 4.043480\tAccuracy: 2.80%\n",
      "13\tValidation loss: 831.373230\tBest loss: 4.043480\tAccuracy: 2.20%\n",
      "14\tValidation loss: 745.380737\tBest loss: 4.043480\tAccuracy: 2.90%\n",
      "15\tValidation loss: 558.168091\tBest loss: 4.043480\tAccuracy: 2.80%\n",
      "16\tValidation loss: 684.117371\tBest loss: 4.043480\tAccuracy: 2.40%\n",
      "17\tValidation loss: 463.845612\tBest loss: 4.043480\tAccuracy: 5.10%\n",
      "18\tValidation loss: 380.706482\tBest loss: 4.043480\tAccuracy: 4.00%\n",
      "19\tValidation loss: 276.472168\tBest loss: 4.043480\tAccuracy: 2.60%\n",
      "20\tValidation loss: 337.030945\tBest loss: 4.043480\tAccuracy: 2.60%\n",
      "21\tValidation loss: 166.062897\tBest loss: 4.043480\tAccuracy: 5.40%\n",
      "22\tValidation loss: 339.580078\tBest loss: 4.043480\tAccuracy: 3.20%\n",
      "23\tValidation loss: 166.757263\tBest loss: 4.043480\tAccuracy: 5.50%\n",
      "24\tValidation loss: 236.385712\tBest loss: 4.043480\tAccuracy: 4.30%\n",
      "25\tValidation loss: 118.368393\tBest loss: 4.043480\tAccuracy: 5.30%\n",
      "26\tValidation loss: 213.477142\tBest loss: 4.043480\tAccuracy: 5.90%\n",
      "27\tValidation loss: 486.555908\tBest loss: 4.043480\tAccuracy: 2.60%\n",
      "28\tValidation loss: 602.519470\tBest loss: 4.043480\tAccuracy: 3.10%\n",
      "Early stopping!\n",
      "[[  1.96234486e-03   2.00818237e-02   5.71722304e-03 ...,   2.47499011e-02\n",
      "    1.22018484e-02   8.28221720e-03]\n",
      " [  5.79137013e-05   2.08797958e-03   3.10656382e-04 ...,   1.00076124e-02\n",
      "    5.28006768e-03   2.28252332e-03]\n",
      " [  3.84591473e-03   3.26332413e-02   7.86654279e-03 ...,   2.96327788e-02\n",
      "    1.22216688e-02   9.46781039e-03]\n",
      " ..., \n",
      " [  1.47436270e-02   1.93810202e-02   1.92696378e-02 ...,   2.60764919e-02\n",
      "    2.02469379e-02   1.34191569e-02]\n",
      " [  1.53544331e-02   1.99792534e-02   2.77629104e-02 ...,   2.89837010e-02\n",
      "    4.27324325e-02   2.12597102e-02]\n",
      " [  1.06584317e-04   1.49127608e-03   6.50233356e-04 ...,   2.23545227e-02\n",
      "    1.96105056e-02   6.23088330e-03]]\n",
      "[41 41 41 ...,  9 10 41]\n",
      "[[ 0.00157436  0.00839076  0.00904825 ...,  0.04376204  0.06099292\n",
      "   0.0231416 ]\n",
      " [ 0.04172252  0.0295356   0.03734848 ...,  0.01788693  0.01368909\n",
      "   0.01117088]\n",
      " [ 0.00626009  0.00861449  0.02380886 ...,  0.01794307  0.08806328\n",
      "   0.02571638]\n",
      " ..., \n",
      " [ 0.02523478  0.02668595  0.03205639 ...,  0.02333221  0.02811524\n",
      "   0.01639542]\n",
      " [ 0.04114419  0.02733001  0.03686773 ...,  0.01779267  0.01434833\n",
      "   0.01141941]\n",
      " [ 0.00543871  0.01039256  0.01690802 ...,  0.03048069  0.08109932\n",
      "   0.02838969]]\n",
      "[35 18 37 ..., 10 18 10]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 53.230587\tBest loss: 53.230587\tAccuracy: 4.30%\n",
      "1\tValidation loss: 18.126413\tBest loss: 18.126413\tAccuracy: 3.50%\n",
      "2\tValidation loss: 7.562020\tBest loss: 7.562020\tAccuracy: 3.90%\n",
      "3\tValidation loss: 8.593158\tBest loss: 7.562020\tAccuracy: 4.40%\n",
      "4\tValidation loss: 656.865662\tBest loss: 7.562020\tAccuracy: 1.80%\n",
      "5\tValidation loss: 19266.519531\tBest loss: 7.562020\tAccuracy: 2.30%\n",
      "6\tValidation loss: 3627.465820\tBest loss: 7.562020\tAccuracy: 4.50%\n",
      "7\tValidation loss: 1336.420898\tBest loss: 7.562020\tAccuracy: 2.00%\n",
      "8\tValidation loss: 788.321838\tBest loss: 7.562020\tAccuracy: 2.60%\n",
      "9\tValidation loss: 274.161865\tBest loss: 7.562020\tAccuracy: 4.50%\n",
      "10\tValidation loss: 264.577759\tBest loss: 7.562020\tAccuracy: 4.20%\n",
      "11\tValidation loss: 178.012604\tBest loss: 7.562020\tAccuracy: 3.80%\n",
      "12\tValidation loss: 294.925507\tBest loss: 7.562020\tAccuracy: 1.70%\n",
      "13\tValidation loss: 320.505188\tBest loss: 7.562020\tAccuracy: 2.40%\n",
      "14\tValidation loss: 478.364929\tBest loss: 7.562020\tAccuracy: 2.00%\n",
      "15\tValidation loss: 156.852005\tBest loss: 7.562020\tAccuracy: 2.10%\n",
      "16\tValidation loss: 269.627991\tBest loss: 7.562020\tAccuracy: 1.50%\n",
      "17\tValidation loss: 195.485031\tBest loss: 7.562020\tAccuracy: 3.60%\n",
      "18\tValidation loss: 119.111145\tBest loss: 7.562020\tAccuracy: 2.10%\n",
      "19\tValidation loss: 96.647079\tBest loss: 7.562020\tAccuracy: 1.40%\n",
      "20\tValidation loss: 91.040100\tBest loss: 7.562020\tAccuracy: 4.30%\n",
      "21\tValidation loss: 105.561447\tBest loss: 7.562020\tAccuracy: 4.30%\n",
      "22\tValidation loss: 174.274506\tBest loss: 7.562020\tAccuracy: 4.80%\n",
      "23\tValidation loss: 76.868942\tBest loss: 7.562020\tAccuracy: 2.80%\n",
      "Early stopping!\n",
      "[[  4.40690480e-02   2.66860444e-02   1.41667342e-02 ...,   2.09996589e-02\n",
      "    2.41896743e-03   2.30541304e-02]\n",
      " [  2.25256896e-03   3.25898416e-02   4.95039858e-04 ...,   1.47421043e-02\n",
      "    9.91158140e-06   1.82374306e-02]\n",
      " [  3.06712952e-03   2.97498032e-02   8.14368716e-04 ...,   1.46439876e-02\n",
      "    2.09432510e-05   1.16397962e-02]\n",
      " ..., \n",
      " [  1.21377325e-02   3.23760249e-02   2.70936126e-03 ...,   2.00411323e-02\n",
      "    1.56617563e-04   1.99623127e-02]\n",
      " [  9.11473185e-02   1.84376463e-02   3.08532175e-02 ...,   1.77600458e-02\n",
      "    1.13749253e-02   1.86675712e-02]\n",
      " [  3.28466704e-04   2.60629505e-02   3.84386331e-05 ...,   6.61263615e-03\n",
      "    2.58066478e-07   1.17500238e-02]]\n",
      "[19 19 19 ..., 19  0 28]\n",
      "[[  1.54764319e-04   2.56928951e-02   2.35626576e-05 ...,   6.40732236e-03\n",
      "    1.06404428e-07   1.07526798e-02]\n",
      " [  9.18495655e-02   1.83998812e-02   3.05338092e-02 ...,   1.74078066e-02\n",
      "    1.10837109e-02   1.89857278e-02]\n",
      " [  1.78868213e-04   2.12691203e-02   1.69902833e-05 ...,   4.62090084e-03\n",
      "    8.14353314e-08   1.02994442e-02]\n",
      " ..., \n",
      " [  1.50649548e-02   3.27703506e-02   4.88434918e-03 ...,   2.16185451e-02\n",
      "    4.62004216e-04   2.05191914e-02]\n",
      " [  6.32278994e-03   3.09234075e-02   1.11068098e-03 ...,   1.41068492e-02\n",
      "    4.64848126e-05   2.12592874e-02]\n",
      " [  1.12738030e-06   9.72268824e-03   6.67708377e-08 ...,   8.41729867e-04\n",
      "    1.82691501e-11   2.95557408e-03]]\n",
      "[28  0 28 ..., 19 19 28]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=None, n_hidden_layers=3, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   4.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.587613\tBest loss: 3.587613\tAccuracy: 14.50%\n",
      "1\tValidation loss: 3.244048\tBest loss: 3.244048\tAccuracy: 21.60%\n",
      "2\tValidation loss: 3.010906\tBest loss: 3.010906\tAccuracy: 27.20%\n",
      "3\tValidation loss: 3.009476\tBest loss: 3.009476\tAccuracy: 25.40%\n",
      "4\tValidation loss: 2.954728\tBest loss: 2.954728\tAccuracy: 28.10%\n",
      "5\tValidation loss: 2.842190\tBest loss: 2.842190\tAccuracy: 33.30%\n",
      "6\tValidation loss: 2.777610\tBest loss: 2.777610\tAccuracy: 33.40%\n",
      "7\tValidation loss: 2.811550\tBest loss: 2.777610\tAccuracy: 35.00%\n",
      "8\tValidation loss: 2.811241\tBest loss: 2.777610\tAccuracy: 32.80%\n",
      "9\tValidation loss: 2.819245\tBest loss: 2.777610\tAccuracy: 32.30%\n",
      "10\tValidation loss: 2.697029\tBest loss: 2.697029\tAccuracy: 35.40%\n",
      "11\tValidation loss: 2.674201\tBest loss: 2.674201\tAccuracy: 36.40%\n",
      "12\tValidation loss: 2.669137\tBest loss: 2.669137\tAccuracy: 35.80%\n",
      "13\tValidation loss: 2.661702\tBest loss: 2.661702\tAccuracy: 36.70%\n",
      "14\tValidation loss: 2.634433\tBest loss: 2.634433\tAccuracy: 38.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\tValidation loss: 2.593656\tBest loss: 2.593656\tAccuracy: 38.90%\n",
      "16\tValidation loss: 2.583581\tBest loss: 2.583581\tAccuracy: 39.70%\n",
      "17\tValidation loss: 2.559188\tBest loss: 2.559188\tAccuracy: 37.10%\n",
      "18\tValidation loss: 2.554854\tBest loss: 2.554854\tAccuracy: 39.40%\n",
      "19\tValidation loss: 2.503115\tBest loss: 2.503115\tAccuracy: 40.10%\n",
      "20\tValidation loss: 2.529062\tBest loss: 2.503115\tAccuracy: 42.30%\n",
      "21\tValidation loss: 2.458476\tBest loss: 2.458476\tAccuracy: 42.90%\n",
      "22\tValidation loss: 2.476714\tBest loss: 2.458476\tAccuracy: 42.10%\n",
      "23\tValidation loss: 2.453422\tBest loss: 2.453422\tAccuracy: 42.00%\n",
      "24\tValidation loss: 2.470054\tBest loss: 2.453422\tAccuracy: 40.60%\n",
      "25\tValidation loss: 2.441307\tBest loss: 2.441307\tAccuracy: 41.80%\n",
      "26\tValidation loss: 2.425252\tBest loss: 2.425252\tAccuracy: 44.10%\n",
      "27\tValidation loss: 2.426650\tBest loss: 2.425252\tAccuracy: 40.90%\n",
      "28\tValidation loss: 2.415612\tBest loss: 2.415612\tAccuracy: 41.50%\n",
      "29\tValidation loss: 2.385009\tBest loss: 2.385009\tAccuracy: 44.00%\n",
      "30\tValidation loss: 2.382650\tBest loss: 2.382650\tAccuracy: 44.50%\n",
      "31\tValidation loss: 2.359443\tBest loss: 2.359443\tAccuracy: 44.10%\n",
      "32\tValidation loss: 2.360410\tBest loss: 2.359443\tAccuracy: 44.70%\n",
      "33\tValidation loss: 2.339555\tBest loss: 2.339555\tAccuracy: 45.50%\n",
      "34\tValidation loss: 2.350504\tBest loss: 2.339555\tAccuracy: 42.10%\n",
      "35\tValidation loss: 2.336930\tBest loss: 2.336930\tAccuracy: 44.50%\n",
      "36\tValidation loss: 2.341039\tBest loss: 2.336930\tAccuracy: 43.50%\n",
      "37\tValidation loss: 2.309872\tBest loss: 2.309872\tAccuracy: 46.30%\n",
      "38\tValidation loss: 2.320803\tBest loss: 2.309872\tAccuracy: 45.80%\n",
      "39\tValidation loss: 2.285695\tBest loss: 2.285695\tAccuracy: 47.30%\n",
      "40\tValidation loss: 2.293962\tBest loss: 2.285695\tAccuracy: 48.70%\n",
      "41\tValidation loss: 2.294346\tBest loss: 2.285695\tAccuracy: 44.20%\n",
      "42\tValidation loss: 2.287091\tBest loss: 2.285695\tAccuracy: 46.00%\n",
      "43\tValidation loss: 2.274419\tBest loss: 2.274419\tAccuracy: 47.30%\n",
      "44\tValidation loss: 2.288439\tBest loss: 2.274419\tAccuracy: 43.80%\n",
      "45\tValidation loss: 2.255229\tBest loss: 2.255229\tAccuracy: 48.90%\n",
      "46\tValidation loss: 2.253906\tBest loss: 2.253906\tAccuracy: 46.90%\n",
      "47\tValidation loss: 2.259609\tBest loss: 2.253906\tAccuracy: 47.20%\n",
      "48\tValidation loss: 2.224880\tBest loss: 2.224880\tAccuracy: 48.10%\n",
      "49\tValidation loss: 2.225641\tBest loss: 2.224880\tAccuracy: 47.70%\n",
      "50\tValidation loss: 2.243742\tBest loss: 2.224880\tAccuracy: 48.10%\n",
      "51\tValidation loss: 2.205203\tBest loss: 2.205203\tAccuracy: 46.30%\n",
      "52\tValidation loss: 2.228437\tBest loss: 2.205203\tAccuracy: 46.90%\n",
      "53\tValidation loss: 2.180154\tBest loss: 2.180154\tAccuracy: 50.30%\n",
      "54\tValidation loss: 2.177953\tBest loss: 2.177953\tAccuracy: 48.80%\n",
      "55\tValidation loss: 2.186590\tBest loss: 2.177953\tAccuracy: 48.50%\n",
      "56\tValidation loss: 2.174900\tBest loss: 2.174900\tAccuracy: 48.10%\n",
      "57\tValidation loss: 2.162026\tBest loss: 2.162026\tAccuracy: 49.70%\n",
      "58\tValidation loss: 2.153784\tBest loss: 2.153784\tAccuracy: 48.80%\n",
      "59\tValidation loss: 2.177408\tBest loss: 2.153784\tAccuracy: 45.70%\n",
      "60\tValidation loss: 2.152850\tBest loss: 2.152850\tAccuracy: 50.00%\n",
      "61\tValidation loss: 2.156531\tBest loss: 2.152850\tAccuracy: 48.10%\n",
      "62\tValidation loss: 2.125046\tBest loss: 2.125046\tAccuracy: 51.00%\n",
      "63\tValidation loss: 2.125328\tBest loss: 2.125046\tAccuracy: 51.00%\n",
      "64\tValidation loss: 2.122971\tBest loss: 2.122971\tAccuracy: 49.80%\n",
      "65\tValidation loss: 2.100269\tBest loss: 2.100269\tAccuracy: 52.30%\n",
      "66\tValidation loss: 2.089259\tBest loss: 2.089259\tAccuracy: 50.20%\n",
      "67\tValidation loss: 2.122738\tBest loss: 2.089259\tAccuracy: 49.30%\n",
      "68\tValidation loss: 2.097045\tBest loss: 2.089259\tAccuracy: 49.70%\n",
      "69\tValidation loss: 2.086593\tBest loss: 2.086593\tAccuracy: 51.60%\n",
      "70\tValidation loss: 2.067924\tBest loss: 2.067924\tAccuracy: 50.80%\n",
      "71\tValidation loss: 2.077632\tBest loss: 2.067924\tAccuracy: 51.50%\n",
      "72\tValidation loss: 2.051919\tBest loss: 2.051919\tAccuracy: 54.00%\n",
      "73\tValidation loss: 2.061955\tBest loss: 2.051919\tAccuracy: 50.50%\n",
      "74\tValidation loss: 2.060040\tBest loss: 2.051919\tAccuracy: 51.90%\n",
      "75\tValidation loss: 2.061152\tBest loss: 2.051919\tAccuracy: 50.50%\n",
      "76\tValidation loss: 2.046722\tBest loss: 2.046722\tAccuracy: 52.50%\n",
      "77\tValidation loss: 2.019172\tBest loss: 2.019172\tAccuracy: 53.60%\n",
      "78\tValidation loss: 2.006998\tBest loss: 2.006998\tAccuracy: 52.40%\n",
      "79\tValidation loss: 2.021117\tBest loss: 2.006998\tAccuracy: 52.80%\n",
      "80\tValidation loss: 2.021366\tBest loss: 2.006998\tAccuracy: 52.10%\n",
      "81\tValidation loss: 2.011611\tBest loss: 2.006998\tAccuracy: 52.00%\n",
      "82\tValidation loss: 2.013601\tBest loss: 2.006998\tAccuracy: 51.10%\n",
      "83\tValidation loss: 1.996597\tBest loss: 1.996597\tAccuracy: 52.30%\n",
      "84\tValidation loss: 1.999193\tBest loss: 1.996597\tAccuracy: 52.30%\n",
      "85\tValidation loss: 1.985743\tBest loss: 1.985743\tAccuracy: 51.70%\n",
      "86\tValidation loss: 1.984982\tBest loss: 1.984982\tAccuracy: 52.40%\n",
      "87\tValidation loss: 1.978705\tBest loss: 1.978705\tAccuracy: 52.40%\n",
      "88\tValidation loss: 1.977630\tBest loss: 1.977630\tAccuracy: 53.10%\n",
      "89\tValidation loss: 1.978548\tBest loss: 1.977630\tAccuracy: 52.10%\n",
      "90\tValidation loss: 1.968635\tBest loss: 1.968635\tAccuracy: 54.10%\n",
      "91\tValidation loss: 1.959127\tBest loss: 1.959127\tAccuracy: 53.50%\n",
      "92\tValidation loss: 1.947744\tBest loss: 1.947744\tAccuracy: 53.70%\n",
      "93\tValidation loss: 1.959010\tBest loss: 1.947744\tAccuracy: 53.00%\n",
      "94\tValidation loss: 1.947778\tBest loss: 1.947744\tAccuracy: 53.50%\n",
      "95\tValidation loss: 1.942819\tBest loss: 1.942819\tAccuracy: 55.40%\n",
      "96\tValidation loss: 1.952014\tBest loss: 1.942819\tAccuracy: 53.70%\n",
      "97\tValidation loss: 1.932421\tBest loss: 1.932421\tAccuracy: 54.00%\n",
      "98\tValidation loss: 1.932510\tBest loss: 1.932421\tAccuracy: 55.50%\n",
      "99\tValidation loss: 1.924362\tBest loss: 1.924362\tAccuracy: 55.10%\n",
      "100\tValidation loss: 1.912355\tBest loss: 1.912355\tAccuracy: 54.80%\n",
      "101\tValidation loss: 1.933223\tBest loss: 1.912355\tAccuracy: 55.00%\n",
      "102\tValidation loss: 1.910586\tBest loss: 1.910586\tAccuracy: 54.90%\n",
      "103\tValidation loss: 1.920952\tBest loss: 1.910586\tAccuracy: 54.50%\n",
      "104\tValidation loss: 1.912316\tBest loss: 1.910586\tAccuracy: 55.00%\n",
      "105\tValidation loss: 1.924543\tBest loss: 1.910586\tAccuracy: 53.90%\n",
      "106\tValidation loss: 1.908743\tBest loss: 1.908743\tAccuracy: 55.40%\n",
      "107\tValidation loss: 1.915684\tBest loss: 1.908743\tAccuracy: 54.30%\n",
      "108\tValidation loss: 1.888858\tBest loss: 1.888858\tAccuracy: 55.60%\n",
      "109\tValidation loss: 1.916691\tBest loss: 1.888858\tAccuracy: 56.90%\n",
      "110\tValidation loss: 1.888411\tBest loss: 1.888411\tAccuracy: 56.20%\n",
      "111\tValidation loss: 1.865943\tBest loss: 1.865943\tAccuracy: 55.40%\n",
      "112\tValidation loss: 1.906610\tBest loss: 1.865943\tAccuracy: 55.70%\n",
      "113\tValidation loss: 1.866353\tBest loss: 1.865943\tAccuracy: 56.10%\n",
      "114\tValidation loss: 1.868317\tBest loss: 1.865943\tAccuracy: 56.30%\n",
      "115\tValidation loss: 1.867245\tBest loss: 1.865943\tAccuracy: 57.20%\n",
      "116\tValidation loss: 1.853675\tBest loss: 1.853675\tAccuracy: 56.30%\n",
      "117\tValidation loss: 1.860032\tBest loss: 1.853675\tAccuracy: 57.20%\n",
      "118\tValidation loss: 1.866159\tBest loss: 1.853675\tAccuracy: 56.40%\n",
      "119\tValidation loss: 1.835030\tBest loss: 1.835030\tAccuracy: 56.20%\n",
      "120\tValidation loss: 1.829825\tBest loss: 1.829825\tAccuracy: 56.20%\n",
      "121\tValidation loss: 1.838121\tBest loss: 1.829825\tAccuracy: 56.40%\n",
      "122\tValidation loss: 1.837182\tBest loss: 1.829825\tAccuracy: 56.60%\n",
      "123\tValidation loss: 1.823186\tBest loss: 1.823186\tAccuracy: 58.70%\n",
      "124\tValidation loss: 1.816878\tBest loss: 1.816878\tAccuracy: 57.30%\n",
      "125\tValidation loss: 1.822929\tBest loss: 1.816878\tAccuracy: 57.30%\n",
      "126\tValidation loss: 1.818391\tBest loss: 1.816878\tAccuracy: 55.90%\n",
      "127\tValidation loss: 1.823939\tBest loss: 1.816878\tAccuracy: 56.90%\n",
      "128\tValidation loss: 1.828474\tBest loss: 1.816878\tAccuracy: 56.60%\n",
      "129\tValidation loss: 1.826196\tBest loss: 1.816878\tAccuracy: 56.90%\n",
      "130\tValidation loss: 1.812094\tBest loss: 1.812094\tAccuracy: 57.60%\n",
      "131\tValidation loss: 1.794038\tBest loss: 1.794038\tAccuracy: 57.70%\n",
      "132\tValidation loss: 1.815604\tBest loss: 1.794038\tAccuracy: 56.20%\n",
      "133\tValidation loss: 1.808199\tBest loss: 1.794038\tAccuracy: 57.60%\n",
      "134\tValidation loss: 1.805546\tBest loss: 1.794038\tAccuracy: 56.20%\n",
      "135\tValidation loss: 1.780367\tBest loss: 1.780367\tAccuracy: 58.40%\n",
      "136\tValidation loss: 1.794332\tBest loss: 1.780367\tAccuracy: 58.10%\n",
      "137\tValidation loss: 1.790706\tBest loss: 1.780367\tAccuracy: 58.30%\n",
      "138\tValidation loss: 1.779180\tBest loss: 1.779180\tAccuracy: 58.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\tValidation loss: 1.796850\tBest loss: 1.779180\tAccuracy: 57.80%\n",
      "140\tValidation loss: 1.773496\tBest loss: 1.773496\tAccuracy: 59.50%\n",
      "141\tValidation loss: 1.779152\tBest loss: 1.773496\tAccuracy: 57.10%\n",
      "142\tValidation loss: 1.771863\tBest loss: 1.771863\tAccuracy: 58.20%\n",
      "143\tValidation loss: 1.776616\tBest loss: 1.771863\tAccuracy: 57.80%\n",
      "144\tValidation loss: 1.776146\tBest loss: 1.771863\tAccuracy: 59.00%\n",
      "145\tValidation loss: 1.769355\tBest loss: 1.769355\tAccuracy: 58.90%\n",
      "146\tValidation loss: 1.777393\tBest loss: 1.769355\tAccuracy: 58.70%\n",
      "147\tValidation loss: 1.760930\tBest loss: 1.760930\tAccuracy: 59.20%\n",
      "148\tValidation loss: 1.756273\tBest loss: 1.756273\tAccuracy: 58.40%\n",
      "149\tValidation loss: 1.748096\tBest loss: 1.748096\tAccuracy: 58.70%\n",
      "150\tValidation loss: 1.754267\tBest loss: 1.748096\tAccuracy: 58.50%\n",
      "151\tValidation loss: 1.748911\tBest loss: 1.748096\tAccuracy: 58.80%\n",
      "152\tValidation loss: 1.734299\tBest loss: 1.734299\tAccuracy: 58.00%\n",
      "153\tValidation loss: 1.749115\tBest loss: 1.734299\tAccuracy: 58.90%\n",
      "154\tValidation loss: 1.730514\tBest loss: 1.730514\tAccuracy: 60.00%\n",
      "155\tValidation loss: 1.734490\tBest loss: 1.730514\tAccuracy: 59.70%\n",
      "156\tValidation loss: 1.745973\tBest loss: 1.730514\tAccuracy: 59.90%\n",
      "157\tValidation loss: 1.722903\tBest loss: 1.722903\tAccuracy: 59.40%\n",
      "158\tValidation loss: 1.728035\tBest loss: 1.722903\tAccuracy: 60.50%\n",
      "159\tValidation loss: 1.722923\tBest loss: 1.722903\tAccuracy: 59.70%\n",
      "160\tValidation loss: 1.729243\tBest loss: 1.722903\tAccuracy: 59.70%\n",
      "161\tValidation loss: 1.735293\tBest loss: 1.722903\tAccuracy: 59.60%\n",
      "162\tValidation loss: 1.724722\tBest loss: 1.722903\tAccuracy: 61.00%\n",
      "163\tValidation loss: 1.719773\tBest loss: 1.719773\tAccuracy: 60.70%\n",
      "164\tValidation loss: 1.724797\tBest loss: 1.719773\tAccuracy: 59.50%\n",
      "165\tValidation loss: 1.711768\tBest loss: 1.711768\tAccuracy: 60.40%\n",
      "166\tValidation loss: 1.707725\tBest loss: 1.707725\tAccuracy: 61.00%\n",
      "167\tValidation loss: 1.705294\tBest loss: 1.705294\tAccuracy: 60.60%\n",
      "168\tValidation loss: 1.717936\tBest loss: 1.705294\tAccuracy: 60.00%\n",
      "169\tValidation loss: 1.706196\tBest loss: 1.705294\tAccuracy: 61.70%\n",
      "170\tValidation loss: 1.708411\tBest loss: 1.705294\tAccuracy: 59.30%\n",
      "171\tValidation loss: 1.691490\tBest loss: 1.691490\tAccuracy: 61.00%\n",
      "172\tValidation loss: 1.721412\tBest loss: 1.691490\tAccuracy: 59.30%\n",
      "173\tValidation loss: 1.702538\tBest loss: 1.691490\tAccuracy: 60.90%\n",
      "174\tValidation loss: 1.683534\tBest loss: 1.683534\tAccuracy: 59.60%\n",
      "175\tValidation loss: 1.687898\tBest loss: 1.683534\tAccuracy: 60.90%\n",
      "176\tValidation loss: 1.697433\tBest loss: 1.683534\tAccuracy: 60.10%\n",
      "177\tValidation loss: 1.686613\tBest loss: 1.683534\tAccuracy: 60.80%\n",
      "178\tValidation loss: 1.691434\tBest loss: 1.683534\tAccuracy: 60.50%\n",
      "179\tValidation loss: 1.689018\tBest loss: 1.683534\tAccuracy: 61.00%\n",
      "180\tValidation loss: 1.670385\tBest loss: 1.670385\tAccuracy: 61.00%\n",
      "181\tValidation loss: 1.675627\tBest loss: 1.670385\tAccuracy: 59.30%\n",
      "182\tValidation loss: 1.710357\tBest loss: 1.670385\tAccuracy: 60.70%\n",
      "183\tValidation loss: 1.683684\tBest loss: 1.670385\tAccuracy: 61.20%\n",
      "184\tValidation loss: 1.676226\tBest loss: 1.670385\tAccuracy: 62.00%\n",
      "185\tValidation loss: 1.676369\tBest loss: 1.670385\tAccuracy: 62.00%\n",
      "186\tValidation loss: 1.683577\tBest loss: 1.670385\tAccuracy: 60.80%\n",
      "187\tValidation loss: 1.668734\tBest loss: 1.668734\tAccuracy: 61.20%\n",
      "188\tValidation loss: 1.674015\tBest loss: 1.668734\tAccuracy: 61.20%\n",
      "189\tValidation loss: 1.676281\tBest loss: 1.668734\tAccuracy: 62.00%\n",
      "190\tValidation loss: 1.668032\tBest loss: 1.668032\tAccuracy: 62.00%\n",
      "191\tValidation loss: 1.662837\tBest loss: 1.662837\tAccuracy: 60.00%\n",
      "192\tValidation loss: 1.652819\tBest loss: 1.652819\tAccuracy: 60.80%\n",
      "193\tValidation loss: 1.669587\tBest loss: 1.652819\tAccuracy: 59.90%\n",
      "194\tValidation loss: 1.650029\tBest loss: 1.650029\tAccuracy: 60.70%\n",
      "195\tValidation loss: 1.657520\tBest loss: 1.650029\tAccuracy: 60.50%\n",
      "196\tValidation loss: 1.649099\tBest loss: 1.649099\tAccuracy: 61.70%\n",
      "197\tValidation loss: 1.659045\tBest loss: 1.649099\tAccuracy: 59.50%\n",
      "198\tValidation loss: 1.647939\tBest loss: 1.647939\tAccuracy: 61.20%\n",
      "199\tValidation loss: 1.643733\tBest loss: 1.643733\tAccuracy: 61.70%\n",
      "200\tValidation loss: 1.653672\tBest loss: 1.643733\tAccuracy: 60.90%\n",
      "201\tValidation loss: 1.647438\tBest loss: 1.643733\tAccuracy: 61.50%\n",
      "202\tValidation loss: 1.644202\tBest loss: 1.643733\tAccuracy: 61.10%\n",
      "203\tValidation loss: 1.638765\tBest loss: 1.638765\tAccuracy: 61.60%\n",
      "204\tValidation loss: 1.639286\tBest loss: 1.638765\tAccuracy: 61.10%\n",
      "205\tValidation loss: 1.640506\tBest loss: 1.638765\tAccuracy: 61.60%\n",
      "206\tValidation loss: 1.646834\tBest loss: 1.638765\tAccuracy: 62.50%\n",
      "207\tValidation loss: 1.639293\tBest loss: 1.638765\tAccuracy: 62.00%\n",
      "208\tValidation loss: 1.641814\tBest loss: 1.638765\tAccuracy: 60.60%\n",
      "209\tValidation loss: 1.628693\tBest loss: 1.628693\tAccuracy: 61.70%\n",
      "210\tValidation loss: 1.638133\tBest loss: 1.628693\tAccuracy: 61.50%\n",
      "211\tValidation loss: 1.640267\tBest loss: 1.628693\tAccuracy: 61.20%\n",
      "212\tValidation loss: 1.644825\tBest loss: 1.628693\tAccuracy: 61.60%\n",
      "213\tValidation loss: 1.627936\tBest loss: 1.627936\tAccuracy: 62.10%\n",
      "214\tValidation loss: 1.631707\tBest loss: 1.627936\tAccuracy: 61.90%\n",
      "215\tValidation loss: 1.615647\tBest loss: 1.615647\tAccuracy: 61.10%\n",
      "216\tValidation loss: 1.617010\tBest loss: 1.615647\tAccuracy: 61.30%\n",
      "217\tValidation loss: 1.641673\tBest loss: 1.615647\tAccuracy: 60.50%\n",
      "218\tValidation loss: 1.611510\tBest loss: 1.611510\tAccuracy: 62.00%\n",
      "219\tValidation loss: 1.620630\tBest loss: 1.611510\tAccuracy: 61.40%\n",
      "220\tValidation loss: 1.617795\tBest loss: 1.611510\tAccuracy: 62.20%\n",
      "221\tValidation loss: 1.614103\tBest loss: 1.611510\tAccuracy: 62.10%\n",
      "222\tValidation loss: 1.622729\tBest loss: 1.611510\tAccuracy: 61.40%\n",
      "223\tValidation loss: 1.610059\tBest loss: 1.610059\tAccuracy: 61.90%\n",
      "224\tValidation loss: 1.611504\tBest loss: 1.610059\tAccuracy: 63.20%\n",
      "225\tValidation loss: 1.605187\tBest loss: 1.605187\tAccuracy: 62.70%\n",
      "226\tValidation loss: 1.602500\tBest loss: 1.602500\tAccuracy: 61.90%\n",
      "227\tValidation loss: 1.598903\tBest loss: 1.598903\tAccuracy: 62.30%\n",
      "228\tValidation loss: 1.605900\tBest loss: 1.598903\tAccuracy: 62.60%\n",
      "229\tValidation loss: 1.612308\tBest loss: 1.598903\tAccuracy: 61.30%\n",
      "230\tValidation loss: 1.612525\tBest loss: 1.598903\tAccuracy: 60.90%\n",
      "231\tValidation loss: 1.604204\tBest loss: 1.598903\tAccuracy: 61.90%\n",
      "232\tValidation loss: 1.596039\tBest loss: 1.596039\tAccuracy: 62.40%\n",
      "233\tValidation loss: 1.586914\tBest loss: 1.586914\tAccuracy: 62.40%\n",
      "234\tValidation loss: 1.597724\tBest loss: 1.586914\tAccuracy: 62.00%\n",
      "235\tValidation loss: 1.593638\tBest loss: 1.586914\tAccuracy: 62.10%\n",
      "236\tValidation loss: 1.596568\tBest loss: 1.586914\tAccuracy: 62.00%\n",
      "237\tValidation loss: 1.584909\tBest loss: 1.584909\tAccuracy: 62.50%\n",
      "238\tValidation loss: 1.581761\tBest loss: 1.581761\tAccuracy: 62.30%\n",
      "239\tValidation loss: 1.587741\tBest loss: 1.581761\tAccuracy: 62.50%\n",
      "240\tValidation loss: 1.588790\tBest loss: 1.581761\tAccuracy: 62.20%\n",
      "241\tValidation loss: 1.582668\tBest loss: 1.581761\tAccuracy: 62.90%\n",
      "242\tValidation loss: 1.573181\tBest loss: 1.573181\tAccuracy: 63.40%\n",
      "243\tValidation loss: 1.578977\tBest loss: 1.573181\tAccuracy: 63.60%\n",
      "244\tValidation loss: 1.574480\tBest loss: 1.573181\tAccuracy: 63.40%\n",
      "245\tValidation loss: 1.572386\tBest loss: 1.572386\tAccuracy: 63.90%\n",
      "246\tValidation loss: 1.567245\tBest loss: 1.567245\tAccuracy: 62.70%\n",
      "247\tValidation loss: 1.560852\tBest loss: 1.560852\tAccuracy: 63.10%\n",
      "248\tValidation loss: 1.574194\tBest loss: 1.560852\tAccuracy: 62.10%\n",
      "249\tValidation loss: 1.560734\tBest loss: 1.560734\tAccuracy: 63.10%\n",
      "250\tValidation loss: 1.564840\tBest loss: 1.560734\tAccuracy: 62.60%\n",
      "251\tValidation loss: 1.569496\tBest loss: 1.560734\tAccuracy: 63.10%\n",
      "252\tValidation loss: 1.559422\tBest loss: 1.559422\tAccuracy: 63.70%\n",
      "253\tValidation loss: 1.561181\tBest loss: 1.559422\tAccuracy: 63.80%\n",
      "254\tValidation loss: 1.568917\tBest loss: 1.559422\tAccuracy: 63.50%\n",
      "255\tValidation loss: 1.564101\tBest loss: 1.559422\tAccuracy: 63.20%\n",
      "256\tValidation loss: 1.560613\tBest loss: 1.559422\tAccuracy: 63.40%\n",
      "257\tValidation loss: 1.546679\tBest loss: 1.546679\tAccuracy: 61.70%\n",
      "258\tValidation loss: 1.557080\tBest loss: 1.546679\tAccuracy: 62.90%\n",
      "259\tValidation loss: 1.568165\tBest loss: 1.546679\tAccuracy: 62.70%\n",
      "260\tValidation loss: 1.537468\tBest loss: 1.537468\tAccuracy: 63.00%\n",
      "261\tValidation loss: 1.550975\tBest loss: 1.537468\tAccuracy: 62.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\tValidation loss: 1.547255\tBest loss: 1.537468\tAccuracy: 63.70%\n",
      "263\tValidation loss: 1.554931\tBest loss: 1.537468\tAccuracy: 62.70%\n",
      "264\tValidation loss: 1.545069\tBest loss: 1.537468\tAccuracy: 63.40%\n",
      "265\tValidation loss: 1.543009\tBest loss: 1.537468\tAccuracy: 63.60%\n",
      "266\tValidation loss: 1.538499\tBest loss: 1.537468\tAccuracy: 62.20%\n",
      "267\tValidation loss: 1.539012\tBest loss: 1.537468\tAccuracy: 64.30%\n",
      "268\tValidation loss: 1.538186\tBest loss: 1.537468\tAccuracy: 63.00%\n",
      "269\tValidation loss: 1.547720\tBest loss: 1.537468\tAccuracy: 63.20%\n",
      "270\tValidation loss: 1.545219\tBest loss: 1.537468\tAccuracy: 63.50%\n",
      "271\tValidation loss: 1.536208\tBest loss: 1.536208\tAccuracy: 63.20%\n",
      "272\tValidation loss: 1.533517\tBest loss: 1.533517\tAccuracy: 64.00%\n",
      "273\tValidation loss: 1.538029\tBest loss: 1.533517\tAccuracy: 63.60%\n",
      "274\tValidation loss: 1.541849\tBest loss: 1.533517\tAccuracy: 63.70%\n",
      "275\tValidation loss: 1.534198\tBest loss: 1.533517\tAccuracy: 64.00%\n",
      "276\tValidation loss: 1.536799\tBest loss: 1.533517\tAccuracy: 64.10%\n",
      "277\tValidation loss: 1.530129\tBest loss: 1.530129\tAccuracy: 63.70%\n",
      "278\tValidation loss: 1.539525\tBest loss: 1.530129\tAccuracy: 63.50%\n",
      "279\tValidation loss: 1.531393\tBest loss: 1.530129\tAccuracy: 62.50%\n",
      "280\tValidation loss: 1.532406\tBest loss: 1.530129\tAccuracy: 63.10%\n",
      "281\tValidation loss: 1.527961\tBest loss: 1.527961\tAccuracy: 63.30%\n",
      "282\tValidation loss: 1.540735\tBest loss: 1.527961\tAccuracy: 63.50%\n",
      "283\tValidation loss: 1.537726\tBest loss: 1.527961\tAccuracy: 63.00%\n",
      "284\tValidation loss: 1.531260\tBest loss: 1.527961\tAccuracy: 63.70%\n",
      "285\tValidation loss: 1.531578\tBest loss: 1.527961\tAccuracy: 63.50%\n",
      "286\tValidation loss: 1.527216\tBest loss: 1.527216\tAccuracy: 63.30%\n",
      "287\tValidation loss: 1.526035\tBest loss: 1.526035\tAccuracy: 62.90%\n",
      "288\tValidation loss: 1.530023\tBest loss: 1.526035\tAccuracy: 64.30%\n",
      "289\tValidation loss: 1.522890\tBest loss: 1.522890\tAccuracy: 64.50%\n",
      "290\tValidation loss: 1.517514\tBest loss: 1.517514\tAccuracy: 63.00%\n",
      "291\tValidation loss: 1.512163\tBest loss: 1.512163\tAccuracy: 63.60%\n",
      "292\tValidation loss: 1.519557\tBest loss: 1.512163\tAccuracy: 63.60%\n",
      "293\tValidation loss: 1.523516\tBest loss: 1.512163\tAccuracy: 63.60%\n",
      "294\tValidation loss: 1.526780\tBest loss: 1.512163\tAccuracy: 64.00%\n",
      "295\tValidation loss: 1.512774\tBest loss: 1.512163\tAccuracy: 63.70%\n",
      "296\tValidation loss: 1.514040\tBest loss: 1.512163\tAccuracy: 64.60%\n",
      "297\tValidation loss: 1.519761\tBest loss: 1.512163\tAccuracy: 63.40%\n",
      "298\tValidation loss: 1.511417\tBest loss: 1.511417\tAccuracy: 63.80%\n",
      "299\tValidation loss: 1.516904\tBest loss: 1.511417\tAccuracy: 63.80%\n",
      "300\tValidation loss: 1.502349\tBest loss: 1.502349\tAccuracy: 64.50%\n",
      "301\tValidation loss: 1.504977\tBest loss: 1.502349\tAccuracy: 63.40%\n",
      "302\tValidation loss: 1.506440\tBest loss: 1.502349\tAccuracy: 63.20%\n",
      "303\tValidation loss: 1.505642\tBest loss: 1.502349\tAccuracy: 64.10%\n",
      "304\tValidation loss: 1.511269\tBest loss: 1.502349\tAccuracy: 64.20%\n",
      "305\tValidation loss: 1.506811\tBest loss: 1.502349\tAccuracy: 64.40%\n",
      "306\tValidation loss: 1.519013\tBest loss: 1.502349\tAccuracy: 64.30%\n",
      "307\tValidation loss: 1.515181\tBest loss: 1.502349\tAccuracy: 63.60%\n",
      "308\tValidation loss: 1.491951\tBest loss: 1.491951\tAccuracy: 62.70%\n",
      "309\tValidation loss: 1.497006\tBest loss: 1.491951\tAccuracy: 63.80%\n",
      "310\tValidation loss: 1.499236\tBest loss: 1.491951\tAccuracy: 65.20%\n",
      "311\tValidation loss: 1.503217\tBest loss: 1.491951\tAccuracy: 64.30%\n",
      "312\tValidation loss: 1.494487\tBest loss: 1.491951\tAccuracy: 63.50%\n",
      "313\tValidation loss: 1.490975\tBest loss: 1.490975\tAccuracy: 63.90%\n",
      "314\tValidation loss: 1.484973\tBest loss: 1.484973\tAccuracy: 65.30%\n",
      "315\tValidation loss: 1.482033\tBest loss: 1.482033\tAccuracy: 64.00%\n",
      "316\tValidation loss: 1.484741\tBest loss: 1.482033\tAccuracy: 63.00%\n",
      "317\tValidation loss: 1.480543\tBest loss: 1.480543\tAccuracy: 64.50%\n",
      "318\tValidation loss: 1.494167\tBest loss: 1.480543\tAccuracy: 63.70%\n",
      "319\tValidation loss: 1.484057\tBest loss: 1.480543\tAccuracy: 64.90%\n",
      "320\tValidation loss: 1.476079\tBest loss: 1.476079\tAccuracy: 64.40%\n",
      "321\tValidation loss: 1.501885\tBest loss: 1.476079\tAccuracy: 64.50%\n",
      "322\tValidation loss: 1.501471\tBest loss: 1.476079\tAccuracy: 64.50%\n",
      "323\tValidation loss: 1.496384\tBest loss: 1.476079\tAccuracy: 65.10%\n",
      "324\tValidation loss: 1.492825\tBest loss: 1.476079\tAccuracy: 62.90%\n",
      "325\tValidation loss: 1.481895\tBest loss: 1.476079\tAccuracy: 64.20%\n",
      "326\tValidation loss: 1.488276\tBest loss: 1.476079\tAccuracy: 64.00%\n",
      "327\tValidation loss: 1.477824\tBest loss: 1.476079\tAccuracy: 64.90%\n",
      "328\tValidation loss: 1.466501\tBest loss: 1.466501\tAccuracy: 65.00%\n",
      "329\tValidation loss: 1.475765\tBest loss: 1.466501\tAccuracy: 63.80%\n",
      "330\tValidation loss: 1.477962\tBest loss: 1.466501\tAccuracy: 63.60%\n",
      "331\tValidation loss: 1.455834\tBest loss: 1.455834\tAccuracy: 64.60%\n",
      "332\tValidation loss: 1.465343\tBest loss: 1.455834\tAccuracy: 65.00%\n",
      "333\tValidation loss: 1.462642\tBest loss: 1.455834\tAccuracy: 65.70%\n",
      "334\tValidation loss: 1.472799\tBest loss: 1.455834\tAccuracy: 64.40%\n",
      "335\tValidation loss: 1.457595\tBest loss: 1.455834\tAccuracy: 65.10%\n",
      "336\tValidation loss: 1.461470\tBest loss: 1.455834\tAccuracy: 65.20%\n",
      "337\tValidation loss: 1.465223\tBest loss: 1.455834\tAccuracy: 65.40%\n",
      "338\tValidation loss: 1.477052\tBest loss: 1.455834\tAccuracy: 65.40%\n",
      "339\tValidation loss: 1.455042\tBest loss: 1.455042\tAccuracy: 64.70%\n",
      "340\tValidation loss: 1.471855\tBest loss: 1.455042\tAccuracy: 65.50%\n",
      "341\tValidation loss: 1.461142\tBest loss: 1.455042\tAccuracy: 64.90%\n",
      "342\tValidation loss: 1.466620\tBest loss: 1.455042\tAccuracy: 64.90%\n",
      "343\tValidation loss: 1.461911\tBest loss: 1.455042\tAccuracy: 65.90%\n",
      "344\tValidation loss: 1.456276\tBest loss: 1.455042\tAccuracy: 65.10%\n",
      "345\tValidation loss: 1.446491\tBest loss: 1.446491\tAccuracy: 65.70%\n",
      "346\tValidation loss: 1.462682\tBest loss: 1.446491\tAccuracy: 64.90%\n",
      "347\tValidation loss: 1.456832\tBest loss: 1.446491\tAccuracy: 66.00%\n",
      "348\tValidation loss: 1.459626\tBest loss: 1.446491\tAccuracy: 64.80%\n",
      "349\tValidation loss: 1.458640\tBest loss: 1.446491\tAccuracy: 65.50%\n",
      "350\tValidation loss: 1.461345\tBest loss: 1.446491\tAccuracy: 65.70%\n",
      "351\tValidation loss: 1.451702\tBest loss: 1.446491\tAccuracy: 64.60%\n",
      "352\tValidation loss: 1.459369\tBest loss: 1.446491\tAccuracy: 65.10%\n",
      "353\tValidation loss: 1.462614\tBest loss: 1.446491\tAccuracy: 65.40%\n",
      "354\tValidation loss: 1.461419\tBest loss: 1.446491\tAccuracy: 65.40%\n",
      "355\tValidation loss: 1.454598\tBest loss: 1.446491\tAccuracy: 64.90%\n",
      "356\tValidation loss: 1.452408\tBest loss: 1.446491\tAccuracy: 64.80%\n",
      "357\tValidation loss: 1.455428\tBest loss: 1.446491\tAccuracy: 65.60%\n",
      "358\tValidation loss: 1.456161\tBest loss: 1.446491\tAccuracy: 65.20%\n",
      "359\tValidation loss: 1.453854\tBest loss: 1.446491\tAccuracy: 65.30%\n",
      "360\tValidation loss: 1.450102\tBest loss: 1.446491\tAccuracy: 64.90%\n",
      "361\tValidation loss: 1.446270\tBest loss: 1.446270\tAccuracy: 65.60%\n",
      "362\tValidation loss: 1.454997\tBest loss: 1.446270\tAccuracy: 64.80%\n",
      "363\tValidation loss: 1.445351\tBest loss: 1.445351\tAccuracy: 65.80%\n",
      "364\tValidation loss: 1.437708\tBest loss: 1.437708\tAccuracy: 65.20%\n",
      "365\tValidation loss: 1.439460\tBest loss: 1.437708\tAccuracy: 65.00%\n",
      "366\tValidation loss: 1.440474\tBest loss: 1.437708\tAccuracy: 65.70%\n",
      "367\tValidation loss: 1.435533\tBest loss: 1.435533\tAccuracy: 65.00%\n",
      "368\tValidation loss: 1.446333\tBest loss: 1.435533\tAccuracy: 65.00%\n",
      "369\tValidation loss: 1.448299\tBest loss: 1.435533\tAccuracy: 65.70%\n",
      "370\tValidation loss: 1.441558\tBest loss: 1.435533\tAccuracy: 65.20%\n",
      "371\tValidation loss: 1.438322\tBest loss: 1.435533\tAccuracy: 65.60%\n",
      "372\tValidation loss: 1.437446\tBest loss: 1.435533\tAccuracy: 65.60%\n",
      "373\tValidation loss: 1.433030\tBest loss: 1.433030\tAccuracy: 65.20%\n",
      "374\tValidation loss: 1.434868\tBest loss: 1.433030\tAccuracy: 66.30%\n",
      "375\tValidation loss: 1.442504\tBest loss: 1.433030\tAccuracy: 66.00%\n",
      "376\tValidation loss: 1.436669\tBest loss: 1.433030\tAccuracy: 65.40%\n",
      "377\tValidation loss: 1.447347\tBest loss: 1.433030\tAccuracy: 65.60%\n",
      "378\tValidation loss: 1.433957\tBest loss: 1.433030\tAccuracy: 65.10%\n",
      "379\tValidation loss: 1.439894\tBest loss: 1.433030\tAccuracy: 66.30%\n",
      "380\tValidation loss: 1.434272\tBest loss: 1.433030\tAccuracy: 64.90%\n",
      "381\tValidation loss: 1.428652\tBest loss: 1.428652\tAccuracy: 65.00%\n",
      "382\tValidation loss: 1.436096\tBest loss: 1.428652\tAccuracy: 65.10%\n",
      "383\tValidation loss: 1.429474\tBest loss: 1.428652\tAccuracy: 66.30%\n",
      "384\tValidation loss: 1.428504\tBest loss: 1.428504\tAccuracy: 65.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\tValidation loss: 1.436894\tBest loss: 1.428504\tAccuracy: 65.30%\n",
      "386\tValidation loss: 1.422951\tBest loss: 1.422951\tAccuracy: 65.10%\n",
      "387\tValidation loss: 1.418224\tBest loss: 1.418224\tAccuracy: 65.90%\n",
      "388\tValidation loss: 1.432245\tBest loss: 1.418224\tAccuracy: 64.70%\n",
      "389\tValidation loss: 1.436207\tBest loss: 1.418224\tAccuracy: 65.80%\n",
      "390\tValidation loss: 1.426834\tBest loss: 1.418224\tAccuracy: 65.20%\n",
      "391\tValidation loss: 1.409901\tBest loss: 1.409901\tAccuracy: 66.40%\n",
      "392\tValidation loss: 1.421891\tBest loss: 1.409901\tAccuracy: 65.80%\n",
      "393\tValidation loss: 1.431732\tBest loss: 1.409901\tAccuracy: 65.20%\n",
      "394\tValidation loss: 1.425410\tBest loss: 1.409901\tAccuracy: 65.30%\n",
      "395\tValidation loss: 1.418679\tBest loss: 1.409901\tAccuracy: 66.20%\n",
      "396\tValidation loss: 1.431401\tBest loss: 1.409901\tAccuracy: 64.80%\n",
      "397\tValidation loss: 1.419326\tBest loss: 1.409901\tAccuracy: 65.50%\n",
      "398\tValidation loss: 1.426138\tBest loss: 1.409901\tAccuracy: 65.90%\n",
      "399\tValidation loss: 1.419100\tBest loss: 1.409901\tAccuracy: 65.60%\n",
      "400\tValidation loss: 1.417784\tBest loss: 1.409901\tAccuracy: 65.80%\n",
      "401\tValidation loss: 1.418146\tBest loss: 1.409901\tAccuracy: 65.40%\n",
      "402\tValidation loss: 1.420825\tBest loss: 1.409901\tAccuracy: 65.90%\n",
      "403\tValidation loss: 1.413921\tBest loss: 1.409901\tAccuracy: 66.30%\n",
      "404\tValidation loss: 1.431325\tBest loss: 1.409901\tAccuracy: 65.30%\n",
      "405\tValidation loss: 1.411726\tBest loss: 1.409901\tAccuracy: 65.80%\n",
      "406\tValidation loss: 1.410573\tBest loss: 1.409901\tAccuracy: 66.90%\n",
      "407\tValidation loss: 1.415021\tBest loss: 1.409901\tAccuracy: 65.70%\n",
      "408\tValidation loss: 1.413154\tBest loss: 1.409901\tAccuracy: 65.90%\n",
      "409\tValidation loss: 1.416385\tBest loss: 1.409901\tAccuracy: 66.00%\n",
      "410\tValidation loss: 1.413874\tBest loss: 1.409901\tAccuracy: 65.70%\n",
      "411\tValidation loss: 1.424997\tBest loss: 1.409901\tAccuracy: 65.80%\n",
      "412\tValidation loss: 1.413395\tBest loss: 1.409901\tAccuracy: 65.40%\n",
      "Early stopping!\n",
      "[[  2.20840471e-10   2.79138305e-07   8.99783501e-08 ...,   1.86110198e-12\n",
      "    4.89523248e-11   2.04195061e-09]\n",
      " [  7.51420856e-02   4.00347374e-02   5.92137910e-02 ...,   8.27743858e-03\n",
      "    4.75353654e-03   3.41197290e-03]\n",
      " [  1.49788681e-09   1.44153691e-13   2.06121185e-05 ...,   1.16939833e-16\n",
      "    6.09746455e-21   9.24534694e-23]\n",
      " ..., \n",
      " [  1.50480548e-17   8.27596997e-14   3.50954536e-13 ...,   2.67365197e-09\n",
      "    5.04734698e-10   9.01524100e-09]\n",
      " [  1.18791554e-02   1.70139614e-02   6.10721530e-03 ...,   6.16845749e-02\n",
      "    1.60360057e-02   1.62141342e-02]\n",
      " [  1.61852782e-07   3.30949188e-05   2.40795794e-06 ...,   3.58646102e-02\n",
      "    5.19567681e-03   1.27491979e-02]]\n",
      "[20  0 16 ...,  6 24  8]\n",
      "[[  4.95053155e-06   1.53027446e-04   4.31770645e-03 ...,   7.75677654e-06\n",
      "    4.86445962e-04   1.45730330e-03]\n",
      " [  1.98855290e-11   7.28834806e-08   4.51535653e-09 ...,   2.90306603e-12\n",
      "    1.70589636e-11   7.20393634e-10]\n",
      " [  3.26578811e-05   1.76111265e-04   3.29291506e-05 ...,   8.44142960e-07\n",
      "    1.20347397e-06   2.59998978e-06]\n",
      " ..., \n",
      " [  5.34470659e-04   7.52400095e-03   1.98717648e-03 ...,   3.47317441e-09\n",
      "    1.15196002e-07   9.07602615e-09]\n",
      " [  3.83242369e-02   2.52810158e-02   2.78378613e-02 ...,   1.83161162e-02\n",
      "    8.39084201e-03   5.67688327e-03]\n",
      " [  6.10694295e-09   1.23092335e-07   3.57131191e-09 ...,   2.98330747e-03\n",
      "    8.25112686e-03   9.62830186e-01]]\n",
      "[43 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 1.6min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.660380\tBest loss: 3.660380\tAccuracy: 15.50%\n",
      "1\tValidation loss: 3.340741\tBest loss: 3.340741\tAccuracy: 19.30%\n",
      "2\tValidation loss: 3.133517\tBest loss: 3.133517\tAccuracy: 23.00%\n",
      "3\tValidation loss: 3.125602\tBest loss: 3.125602\tAccuracy: 24.10%\n",
      "4\tValidation loss: 2.866283\tBest loss: 2.866283\tAccuracy: 31.50%\n",
      "5\tValidation loss: 2.898321\tBest loss: 2.866283\tAccuracy: 28.20%\n",
      "6\tValidation loss: 2.833660\tBest loss: 2.833660\tAccuracy: 29.70%\n",
      "7\tValidation loss: 2.825231\tBest loss: 2.825231\tAccuracy: 32.10%\n",
      "8\tValidation loss: 2.727978\tBest loss: 2.727978\tAccuracy: 34.60%\n",
      "9\tValidation loss: 2.706426\tBest loss: 2.706426\tAccuracy: 36.90%\n",
      "10\tValidation loss: 2.723984\tBest loss: 2.706426\tAccuracy: 32.40%\n",
      "11\tValidation loss: 2.650696\tBest loss: 2.650696\tAccuracy: 37.10%\n",
      "12\tValidation loss: 2.692473\tBest loss: 2.650696\tAccuracy: 32.30%\n",
      "13\tValidation loss: 2.640476\tBest loss: 2.640476\tAccuracy: 35.40%\n",
      "14\tValidation loss: 2.619575\tBest loss: 2.619575\tAccuracy: 34.30%\n",
      "15\tValidation loss: 2.583398\tBest loss: 2.583398\tAccuracy: 39.00%\n",
      "16\tValidation loss: 2.560750\tBest loss: 2.560750\tAccuracy: 37.20%\n",
      "17\tValidation loss: 2.553605\tBest loss: 2.553605\tAccuracy: 39.40%\n",
      "18\tValidation loss: 2.603229\tBest loss: 2.553605\tAccuracy: 37.80%\n",
      "19\tValidation loss: 2.495582\tBest loss: 2.495582\tAccuracy: 40.70%\n",
      "20\tValidation loss: 2.525316\tBest loss: 2.495582\tAccuracy: 37.80%\n",
      "21\tValidation loss: 2.497255\tBest loss: 2.495582\tAccuracy: 40.10%\n",
      "22\tValidation loss: 2.501429\tBest loss: 2.495582\tAccuracy: 39.70%\n",
      "23\tValidation loss: 2.599025\tBest loss: 2.495582\tAccuracy: 36.30%\n",
      "24\tValidation loss: 2.460678\tBest loss: 2.460678\tAccuracy: 41.70%\n",
      "25\tValidation loss: 2.422237\tBest loss: 2.422237\tAccuracy: 42.20%\n",
      "26\tValidation loss: 2.411227\tBest loss: 2.411227\tAccuracy: 44.20%\n",
      "27\tValidation loss: 2.401372\tBest loss: 2.401372\tAccuracy: 43.90%\n",
      "28\tValidation loss: 2.407847\tBest loss: 2.401372\tAccuracy: 39.90%\n",
      "29\tValidation loss: 2.392542\tBest loss: 2.392542\tAccuracy: 42.30%\n",
      "30\tValidation loss: 2.365912\tBest loss: 2.365912\tAccuracy: 44.00%\n",
      "31\tValidation loss: 2.369205\tBest loss: 2.365912\tAccuracy: 42.00%\n",
      "32\tValidation loss: 2.345888\tBest loss: 2.345888\tAccuracy: 44.90%\n",
      "33\tValidation loss: 2.353079\tBest loss: 2.345888\tAccuracy: 44.60%\n",
      "34\tValidation loss: 2.378159\tBest loss: 2.345888\tAccuracy: 40.70%\n",
      "35\tValidation loss: 2.319028\tBest loss: 2.319028\tAccuracy: 45.60%\n",
      "36\tValidation loss: 2.326097\tBest loss: 2.319028\tAccuracy: 42.90%\n",
      "37\tValidation loss: 2.312143\tBest loss: 2.312143\tAccuracy: 44.70%\n",
      "38\tValidation loss: 2.297071\tBest loss: 2.297071\tAccuracy: 44.70%\n",
      "39\tValidation loss: 2.297983\tBest loss: 2.297071\tAccuracy: 43.50%\n",
      "40\tValidation loss: 2.273736\tBest loss: 2.273736\tAccuracy: 46.70%\n",
      "41\tValidation loss: 2.278261\tBest loss: 2.273736\tAccuracy: 46.10%\n",
      "42\tValidation loss: 2.285979\tBest loss: 2.273736\tAccuracy: 44.60%\n",
      "43\tValidation loss: 2.286225\tBest loss: 2.273736\tAccuracy: 44.70%\n",
      "44\tValidation loss: 2.251446\tBest loss: 2.251446\tAccuracy: 46.80%\n",
      "45\tValidation loss: 2.241386\tBest loss: 2.241386\tAccuracy: 46.60%\n",
      "46\tValidation loss: 2.241710\tBest loss: 2.241386\tAccuracy: 46.30%\n",
      "47\tValidation loss: 2.246749\tBest loss: 2.241386\tAccuracy: 45.10%\n",
      "48\tValidation loss: 2.216725\tBest loss: 2.216725\tAccuracy: 46.40%\n",
      "49\tValidation loss: 2.238801\tBest loss: 2.216725\tAccuracy: 44.00%\n",
      "50\tValidation loss: 2.206711\tBest loss: 2.206711\tAccuracy: 48.80%\n",
      "51\tValidation loss: 2.237560\tBest loss: 2.206711\tAccuracy: 46.70%\n",
      "52\tValidation loss: 2.194554\tBest loss: 2.194554\tAccuracy: 48.80%\n",
      "53\tValidation loss: 2.168730\tBest loss: 2.168730\tAccuracy: 48.20%\n",
      "54\tValidation loss: 2.170171\tBest loss: 2.168730\tAccuracy: 48.70%\n",
      "55\tValidation loss: 2.191921\tBest loss: 2.168730\tAccuracy: 47.50%\n",
      "56\tValidation loss: 2.147964\tBest loss: 2.147964\tAccuracy: 49.50%\n",
      "57\tValidation loss: 2.148096\tBest loss: 2.147964\tAccuracy: 49.10%\n",
      "58\tValidation loss: 2.138597\tBest loss: 2.138597\tAccuracy: 51.40%\n",
      "59\tValidation loss: 2.145808\tBest loss: 2.138597\tAccuracy: 48.80%\n",
      "60\tValidation loss: 2.144518\tBest loss: 2.138597\tAccuracy: 49.00%\n",
      "61\tValidation loss: 2.121006\tBest loss: 2.121006\tAccuracy: 48.80%\n",
      "62\tValidation loss: 2.129767\tBest loss: 2.121006\tAccuracy: 49.20%\n",
      "63\tValidation loss: 2.118418\tBest loss: 2.118418\tAccuracy: 49.80%\n",
      "64\tValidation loss: 2.097419\tBest loss: 2.097419\tAccuracy: 51.30%\n",
      "65\tValidation loss: 2.091751\tBest loss: 2.091751\tAccuracy: 51.00%\n",
      "66\tValidation loss: 2.111540\tBest loss: 2.091751\tAccuracy: 49.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\tValidation loss: 2.086179\tBest loss: 2.086179\tAccuracy: 50.30%\n",
      "68\tValidation loss: 2.091617\tBest loss: 2.086179\tAccuracy: 49.90%\n",
      "69\tValidation loss: 2.080948\tBest loss: 2.080948\tAccuracy: 50.70%\n",
      "70\tValidation loss: 2.065418\tBest loss: 2.065418\tAccuracy: 50.20%\n",
      "71\tValidation loss: 2.066499\tBest loss: 2.065418\tAccuracy: 50.80%\n",
      "72\tValidation loss: 2.080204\tBest loss: 2.065418\tAccuracy: 49.40%\n",
      "73\tValidation loss: 2.056071\tBest loss: 2.056071\tAccuracy: 51.60%\n",
      "74\tValidation loss: 2.050056\tBest loss: 2.050056\tAccuracy: 51.10%\n",
      "75\tValidation loss: 2.040331\tBest loss: 2.040331\tAccuracy: 51.00%\n",
      "76\tValidation loss: 2.037826\tBest loss: 2.037826\tAccuracy: 51.20%\n",
      "77\tValidation loss: 2.036389\tBest loss: 2.036389\tAccuracy: 52.40%\n",
      "78\tValidation loss: 2.037570\tBest loss: 2.036389\tAccuracy: 51.40%\n",
      "79\tValidation loss: 2.041995\tBest loss: 2.036389\tAccuracy: 50.70%\n",
      "80\tValidation loss: 2.028575\tBest loss: 2.028575\tAccuracy: 51.70%\n",
      "81\tValidation loss: 2.025930\tBest loss: 2.025930\tAccuracy: 50.80%\n",
      "82\tValidation loss: 2.012353\tBest loss: 2.012353\tAccuracy: 51.70%\n",
      "83\tValidation loss: 2.011035\tBest loss: 2.011035\tAccuracy: 51.60%\n",
      "84\tValidation loss: 1.989210\tBest loss: 1.989210\tAccuracy: 52.50%\n",
      "85\tValidation loss: 1.993604\tBest loss: 1.989210\tAccuracy: 53.30%\n",
      "86\tValidation loss: 1.983580\tBest loss: 1.983580\tAccuracy: 53.20%\n",
      "87\tValidation loss: 1.977633\tBest loss: 1.977633\tAccuracy: 52.80%\n",
      "88\tValidation loss: 1.988995\tBest loss: 1.977633\tAccuracy: 52.20%\n",
      "89\tValidation loss: 1.976083\tBest loss: 1.976083\tAccuracy: 53.40%\n",
      "90\tValidation loss: 1.980938\tBest loss: 1.976083\tAccuracy: 52.00%\n",
      "91\tValidation loss: 1.989119\tBest loss: 1.976083\tAccuracy: 52.70%\n",
      "92\tValidation loss: 1.958142\tBest loss: 1.958142\tAccuracy: 53.40%\n",
      "93\tValidation loss: 1.955391\tBest loss: 1.955391\tAccuracy: 53.50%\n",
      "94\tValidation loss: 1.957093\tBest loss: 1.955391\tAccuracy: 54.30%\n",
      "95\tValidation loss: 1.968012\tBest loss: 1.955391\tAccuracy: 53.20%\n",
      "96\tValidation loss: 1.942717\tBest loss: 1.942717\tAccuracy: 53.00%\n",
      "97\tValidation loss: 1.940197\tBest loss: 1.940197\tAccuracy: 53.60%\n",
      "98\tValidation loss: 1.940580\tBest loss: 1.940197\tAccuracy: 53.20%\n",
      "99\tValidation loss: 1.928190\tBest loss: 1.928190\tAccuracy: 55.20%\n",
      "100\tValidation loss: 1.915145\tBest loss: 1.915145\tAccuracy: 53.60%\n",
      "101\tValidation loss: 1.915778\tBest loss: 1.915145\tAccuracy: 53.30%\n",
      "102\tValidation loss: 1.910847\tBest loss: 1.910847\tAccuracy: 55.40%\n",
      "103\tValidation loss: 1.940524\tBest loss: 1.910847\tAccuracy: 53.40%\n",
      "104\tValidation loss: 1.894453\tBest loss: 1.894453\tAccuracy: 54.00%\n",
      "105\tValidation loss: 1.890167\tBest loss: 1.890167\tAccuracy: 54.20%\n",
      "106\tValidation loss: 1.880445\tBest loss: 1.880445\tAccuracy: 55.10%\n",
      "107\tValidation loss: 1.881291\tBest loss: 1.880445\tAccuracy: 54.20%\n",
      "108\tValidation loss: 1.886947\tBest loss: 1.880445\tAccuracy: 55.20%\n",
      "109\tValidation loss: 1.865011\tBest loss: 1.865011\tAccuracy: 55.70%\n",
      "110\tValidation loss: 1.876936\tBest loss: 1.865011\tAccuracy: 54.70%\n",
      "111\tValidation loss: 1.851152\tBest loss: 1.851152\tAccuracy: 55.20%\n",
      "112\tValidation loss: 1.860495\tBest loss: 1.851152\tAccuracy: 53.80%\n",
      "113\tValidation loss: 1.855202\tBest loss: 1.851152\tAccuracy: 53.00%\n",
      "114\tValidation loss: 1.847344\tBest loss: 1.847344\tAccuracy: 55.20%\n",
      "115\tValidation loss: 1.847169\tBest loss: 1.847169\tAccuracy: 54.50%\n",
      "116\tValidation loss: 1.835364\tBest loss: 1.835364\tAccuracy: 56.00%\n",
      "117\tValidation loss: 1.833516\tBest loss: 1.833516\tAccuracy: 55.70%\n",
      "118\tValidation loss: 1.853189\tBest loss: 1.833516\tAccuracy: 53.00%\n",
      "119\tValidation loss: 1.844266\tBest loss: 1.833516\tAccuracy: 55.20%\n",
      "120\tValidation loss: 1.854302\tBest loss: 1.833516\tAccuracy: 55.40%\n",
      "121\tValidation loss: 1.835957\tBest loss: 1.833516\tAccuracy: 56.10%\n",
      "122\tValidation loss: 1.820770\tBest loss: 1.820770\tAccuracy: 56.20%\n",
      "123\tValidation loss: 1.838421\tBest loss: 1.820770\tAccuracy: 55.90%\n",
      "124\tValidation loss: 1.818312\tBest loss: 1.818312\tAccuracy: 56.10%\n",
      "125\tValidation loss: 1.806783\tBest loss: 1.806783\tAccuracy: 56.40%\n",
      "126\tValidation loss: 1.817837\tBest loss: 1.806783\tAccuracy: 55.60%\n",
      "127\tValidation loss: 1.808001\tBest loss: 1.806783\tAccuracy: 55.50%\n",
      "128\tValidation loss: 1.818031\tBest loss: 1.806783\tAccuracy: 55.50%\n",
      "129\tValidation loss: 1.798769\tBest loss: 1.798769\tAccuracy: 56.70%\n",
      "130\tValidation loss: 1.791674\tBest loss: 1.791674\tAccuracy: 57.60%\n",
      "131\tValidation loss: 1.789793\tBest loss: 1.789793\tAccuracy: 57.30%\n",
      "132\tValidation loss: 1.808231\tBest loss: 1.789793\tAccuracy: 54.70%\n",
      "133\tValidation loss: 1.792643\tBest loss: 1.789793\tAccuracy: 56.70%\n",
      "134\tValidation loss: 1.782492\tBest loss: 1.782492\tAccuracy: 56.20%\n",
      "135\tValidation loss: 1.802971\tBest loss: 1.782492\tAccuracy: 56.60%\n",
      "136\tValidation loss: 1.790732\tBest loss: 1.782492\tAccuracy: 57.30%\n",
      "137\tValidation loss: 1.774580\tBest loss: 1.774580\tAccuracy: 57.50%\n",
      "138\tValidation loss: 1.793428\tBest loss: 1.774580\tAccuracy: 56.50%\n",
      "139\tValidation loss: 1.773330\tBest loss: 1.773330\tAccuracy: 56.70%\n",
      "140\tValidation loss: 1.768133\tBest loss: 1.768133\tAccuracy: 57.80%\n",
      "141\tValidation loss: 1.786311\tBest loss: 1.768133\tAccuracy: 55.50%\n",
      "142\tValidation loss: 1.771879\tBest loss: 1.768133\tAccuracy: 55.50%\n",
      "143\tValidation loss: 1.764799\tBest loss: 1.764799\tAccuracy: 56.00%\n",
      "144\tValidation loss: 1.763953\tBest loss: 1.763953\tAccuracy: 57.00%\n",
      "145\tValidation loss: 1.752997\tBest loss: 1.752997\tAccuracy: 58.20%\n",
      "146\tValidation loss: 1.741516\tBest loss: 1.741516\tAccuracy: 57.00%\n",
      "147\tValidation loss: 1.773215\tBest loss: 1.741516\tAccuracy: 56.50%\n",
      "148\tValidation loss: 1.755072\tBest loss: 1.741516\tAccuracy: 58.20%\n",
      "149\tValidation loss: 1.763825\tBest loss: 1.741516\tAccuracy: 56.50%\n",
      "150\tValidation loss: 1.741420\tBest loss: 1.741420\tAccuracy: 56.90%\n",
      "151\tValidation loss: 1.737360\tBest loss: 1.737360\tAccuracy: 58.10%\n",
      "152\tValidation loss: 1.731455\tBest loss: 1.731455\tAccuracy: 57.50%\n",
      "153\tValidation loss: 1.737972\tBest loss: 1.731455\tAccuracy: 58.20%\n",
      "154\tValidation loss: 1.740981\tBest loss: 1.731455\tAccuracy: 57.00%\n",
      "155\tValidation loss: 1.744634\tBest loss: 1.731455\tAccuracy: 57.40%\n",
      "156\tValidation loss: 1.729319\tBest loss: 1.729319\tAccuracy: 59.70%\n",
      "157\tValidation loss: 1.728174\tBest loss: 1.728174\tAccuracy: 59.10%\n",
      "158\tValidation loss: 1.709584\tBest loss: 1.709584\tAccuracy: 58.40%\n",
      "159\tValidation loss: 1.717572\tBest loss: 1.709584\tAccuracy: 57.90%\n",
      "160\tValidation loss: 1.724814\tBest loss: 1.709584\tAccuracy: 58.30%\n",
      "161\tValidation loss: 1.722131\tBest loss: 1.709584\tAccuracy: 57.10%\n",
      "162\tValidation loss: 1.702250\tBest loss: 1.702250\tAccuracy: 59.00%\n",
      "163\tValidation loss: 1.700914\tBest loss: 1.700914\tAccuracy: 59.40%\n",
      "164\tValidation loss: 1.723191\tBest loss: 1.700914\tAccuracy: 58.70%\n",
      "165\tValidation loss: 1.703753\tBest loss: 1.700914\tAccuracy: 58.60%\n",
      "166\tValidation loss: 1.692707\tBest loss: 1.692707\tAccuracy: 59.00%\n",
      "167\tValidation loss: 1.713663\tBest loss: 1.692707\tAccuracy: 58.00%\n",
      "168\tValidation loss: 1.693109\tBest loss: 1.692707\tAccuracy: 59.90%\n",
      "169\tValidation loss: 1.702127\tBest loss: 1.692707\tAccuracy: 58.70%\n",
      "170\tValidation loss: 1.706621\tBest loss: 1.692707\tAccuracy: 57.90%\n",
      "171\tValidation loss: 1.690674\tBest loss: 1.690674\tAccuracy: 57.80%\n",
      "172\tValidation loss: 1.689362\tBest loss: 1.689362\tAccuracy: 59.00%\n",
      "173\tValidation loss: 1.677443\tBest loss: 1.677443\tAccuracy: 59.10%\n",
      "174\tValidation loss: 1.683432\tBest loss: 1.677443\tAccuracy: 59.70%\n",
      "175\tValidation loss: 1.695000\tBest loss: 1.677443\tAccuracy: 57.40%\n",
      "176\tValidation loss: 1.677781\tBest loss: 1.677443\tAccuracy: 58.70%\n",
      "177\tValidation loss: 1.683492\tBest loss: 1.677443\tAccuracy: 59.30%\n",
      "178\tValidation loss: 1.684287\tBest loss: 1.677443\tAccuracy: 57.50%\n",
      "179\tValidation loss: 1.661096\tBest loss: 1.661096\tAccuracy: 59.20%\n",
      "180\tValidation loss: 1.677121\tBest loss: 1.661096\tAccuracy: 58.40%\n",
      "181\tValidation loss: 1.661625\tBest loss: 1.661096\tAccuracy: 57.70%\n",
      "182\tValidation loss: 1.666187\tBest loss: 1.661096\tAccuracy: 58.70%\n",
      "183\tValidation loss: 1.668532\tBest loss: 1.661096\tAccuracy: 57.40%\n",
      "184\tValidation loss: 1.662416\tBest loss: 1.661096\tAccuracy: 58.50%\n",
      "185\tValidation loss: 1.655608\tBest loss: 1.655608\tAccuracy: 59.60%\n",
      "186\tValidation loss: 1.663861\tBest loss: 1.655608\tAccuracy: 59.70%\n",
      "187\tValidation loss: 1.640428\tBest loss: 1.640428\tAccuracy: 59.70%\n",
      "188\tValidation loss: 1.644520\tBest loss: 1.640428\tAccuracy: 59.10%\n",
      "189\tValidation loss: 1.645663\tBest loss: 1.640428\tAccuracy: 60.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\tValidation loss: 1.627250\tBest loss: 1.627250\tAccuracy: 60.40%\n",
      "191\tValidation loss: 1.638579\tBest loss: 1.627250\tAccuracy: 59.50%\n",
      "192\tValidation loss: 1.636736\tBest loss: 1.627250\tAccuracy: 60.90%\n",
      "193\tValidation loss: 1.641992\tBest loss: 1.627250\tAccuracy: 60.20%\n",
      "194\tValidation loss: 1.640658\tBest loss: 1.627250\tAccuracy: 59.90%\n",
      "195\tValidation loss: 1.640145\tBest loss: 1.627250\tAccuracy: 59.60%\n",
      "196\tValidation loss: 1.638786\tBest loss: 1.627250\tAccuracy: 59.90%\n",
      "197\tValidation loss: 1.629468\tBest loss: 1.627250\tAccuracy: 59.90%\n",
      "198\tValidation loss: 1.629228\tBest loss: 1.627250\tAccuracy: 59.60%\n",
      "199\tValidation loss: 1.637584\tBest loss: 1.627250\tAccuracy: 61.00%\n",
      "200\tValidation loss: 1.635584\tBest loss: 1.627250\tAccuracy: 59.00%\n",
      "201\tValidation loss: 1.625638\tBest loss: 1.625638\tAccuracy: 58.90%\n",
      "202\tValidation loss: 1.625907\tBest loss: 1.625638\tAccuracy: 61.20%\n",
      "203\tValidation loss: 1.604327\tBest loss: 1.604327\tAccuracy: 61.00%\n",
      "204\tValidation loss: 1.611589\tBest loss: 1.604327\tAccuracy: 60.40%\n",
      "205\tValidation loss: 1.608862\tBest loss: 1.604327\tAccuracy: 61.00%\n",
      "206\tValidation loss: 1.609873\tBest loss: 1.604327\tAccuracy: 60.60%\n",
      "207\tValidation loss: 1.608891\tBest loss: 1.604327\tAccuracy: 59.90%\n",
      "208\tValidation loss: 1.600323\tBest loss: 1.600323\tAccuracy: 61.80%\n",
      "209\tValidation loss: 1.609022\tBest loss: 1.600323\tAccuracy: 60.10%\n",
      "210\tValidation loss: 1.602428\tBest loss: 1.600323\tAccuracy: 61.10%\n",
      "211\tValidation loss: 1.590505\tBest loss: 1.590505\tAccuracy: 60.70%\n",
      "212\tValidation loss: 1.594314\tBest loss: 1.590505\tAccuracy: 61.20%\n",
      "213\tValidation loss: 1.598137\tBest loss: 1.590505\tAccuracy: 61.60%\n",
      "214\tValidation loss: 1.590807\tBest loss: 1.590505\tAccuracy: 61.30%\n",
      "215\tValidation loss: 1.594460\tBest loss: 1.590505\tAccuracy: 61.50%\n",
      "216\tValidation loss: 1.595320\tBest loss: 1.590505\tAccuracy: 60.60%\n",
      "217\tValidation loss: 1.590906\tBest loss: 1.590505\tAccuracy: 62.00%\n",
      "218\tValidation loss: 1.592640\tBest loss: 1.590505\tAccuracy: 61.70%\n",
      "219\tValidation loss: 1.593752\tBest loss: 1.590505\tAccuracy: 62.20%\n",
      "220\tValidation loss: 1.592312\tBest loss: 1.590505\tAccuracy: 61.30%\n",
      "221\tValidation loss: 1.587354\tBest loss: 1.587354\tAccuracy: 62.30%\n",
      "222\tValidation loss: 1.589162\tBest loss: 1.587354\tAccuracy: 60.70%\n",
      "223\tValidation loss: 1.578711\tBest loss: 1.578711\tAccuracy: 61.60%\n",
      "224\tValidation loss: 1.579028\tBest loss: 1.578711\tAccuracy: 61.90%\n",
      "225\tValidation loss: 1.591941\tBest loss: 1.578711\tAccuracy: 61.60%\n",
      "226\tValidation loss: 1.590555\tBest loss: 1.578711\tAccuracy: 61.00%\n",
      "227\tValidation loss: 1.591873\tBest loss: 1.578711\tAccuracy: 61.40%\n",
      "228\tValidation loss: 1.569796\tBest loss: 1.569796\tAccuracy: 61.90%\n",
      "229\tValidation loss: 1.567599\tBest loss: 1.567599\tAccuracy: 62.50%\n",
      "230\tValidation loss: 1.569314\tBest loss: 1.567599\tAccuracy: 62.80%\n",
      "231\tValidation loss: 1.564880\tBest loss: 1.564880\tAccuracy: 62.10%\n",
      "232\tValidation loss: 1.566796\tBest loss: 1.564880\tAccuracy: 62.50%\n",
      "233\tValidation loss: 1.569273\tBest loss: 1.564880\tAccuracy: 61.90%\n",
      "234\tValidation loss: 1.575105\tBest loss: 1.564880\tAccuracy: 61.30%\n",
      "235\tValidation loss: 1.573789\tBest loss: 1.564880\tAccuracy: 62.80%\n",
      "236\tValidation loss: 1.562300\tBest loss: 1.562300\tAccuracy: 61.80%\n",
      "237\tValidation loss: 1.548314\tBest loss: 1.548314\tAccuracy: 61.90%\n",
      "238\tValidation loss: 1.554972\tBest loss: 1.548314\tAccuracy: 62.50%\n",
      "239\tValidation loss: 1.551380\tBest loss: 1.548314\tAccuracy: 62.90%\n",
      "240\tValidation loss: 1.554020\tBest loss: 1.548314\tAccuracy: 62.90%\n",
      "241\tValidation loss: 1.552967\tBest loss: 1.548314\tAccuracy: 63.50%\n",
      "242\tValidation loss: 1.568451\tBest loss: 1.548314\tAccuracy: 61.80%\n",
      "243\tValidation loss: 1.555781\tBest loss: 1.548314\tAccuracy: 62.00%\n",
      "244\tValidation loss: 1.551102\tBest loss: 1.548314\tAccuracy: 62.30%\n",
      "245\tValidation loss: 1.553390\tBest loss: 1.548314\tAccuracy: 64.10%\n",
      "246\tValidation loss: 1.538975\tBest loss: 1.538975\tAccuracy: 63.70%\n",
      "247\tValidation loss: 1.550231\tBest loss: 1.538975\tAccuracy: 63.40%\n",
      "248\tValidation loss: 1.551458\tBest loss: 1.538975\tAccuracy: 62.90%\n",
      "249\tValidation loss: 1.551210\tBest loss: 1.538975\tAccuracy: 63.30%\n",
      "250\tValidation loss: 1.545090\tBest loss: 1.538975\tAccuracy: 62.70%\n",
      "251\tValidation loss: 1.538817\tBest loss: 1.538817\tAccuracy: 63.20%\n",
      "252\tValidation loss: 1.536619\tBest loss: 1.536619\tAccuracy: 62.80%\n",
      "253\tValidation loss: 1.537426\tBest loss: 1.536619\tAccuracy: 63.10%\n",
      "254\tValidation loss: 1.540368\tBest loss: 1.536619\tAccuracy: 64.40%\n",
      "255\tValidation loss: 1.543748\tBest loss: 1.536619\tAccuracy: 63.10%\n",
      "256\tValidation loss: 1.537864\tBest loss: 1.536619\tAccuracy: 63.40%\n",
      "257\tValidation loss: 1.540563\tBest loss: 1.536619\tAccuracy: 63.10%\n",
      "258\tValidation loss: 1.535508\tBest loss: 1.535508\tAccuracy: 62.30%\n",
      "259\tValidation loss: 1.536371\tBest loss: 1.535508\tAccuracy: 64.20%\n",
      "260\tValidation loss: 1.530966\tBest loss: 1.530966\tAccuracy: 62.50%\n",
      "261\tValidation loss: 1.521357\tBest loss: 1.521357\tAccuracy: 63.50%\n",
      "262\tValidation loss: 1.519476\tBest loss: 1.519476\tAccuracy: 62.80%\n",
      "263\tValidation loss: 1.530323\tBest loss: 1.519476\tAccuracy: 63.20%\n",
      "264\tValidation loss: 1.532374\tBest loss: 1.519476\tAccuracy: 63.30%\n",
      "265\tValidation loss: 1.520535\tBest loss: 1.519476\tAccuracy: 63.80%\n",
      "266\tValidation loss: 1.518547\tBest loss: 1.518547\tAccuracy: 63.80%\n",
      "267\tValidation loss: 1.513175\tBest loss: 1.513175\tAccuracy: 64.00%\n",
      "268\tValidation loss: 1.509971\tBest loss: 1.509971\tAccuracy: 63.20%\n",
      "269\tValidation loss: 1.516259\tBest loss: 1.509971\tAccuracy: 63.20%\n",
      "270\tValidation loss: 1.514882\tBest loss: 1.509971\tAccuracy: 63.70%\n",
      "271\tValidation loss: 1.505617\tBest loss: 1.505617\tAccuracy: 63.00%\n",
      "272\tValidation loss: 1.513877\tBest loss: 1.505617\tAccuracy: 63.40%\n",
      "273\tValidation loss: 1.509330\tBest loss: 1.505617\tAccuracy: 64.00%\n",
      "274\tValidation loss: 1.507999\tBest loss: 1.505617\tAccuracy: 64.10%\n",
      "275\tValidation loss: 1.509955\tBest loss: 1.505617\tAccuracy: 63.70%\n",
      "276\tValidation loss: 1.513384\tBest loss: 1.505617\tAccuracy: 63.40%\n",
      "277\tValidation loss: 1.517698\tBest loss: 1.505617\tAccuracy: 63.40%\n",
      "278\tValidation loss: 1.510229\tBest loss: 1.505617\tAccuracy: 62.40%\n",
      "279\tValidation loss: 1.513546\tBest loss: 1.505617\tAccuracy: 64.10%\n",
      "280\tValidation loss: 1.513174\tBest loss: 1.505617\tAccuracy: 62.80%\n",
      "281\tValidation loss: 1.501083\tBest loss: 1.501083\tAccuracy: 63.80%\n",
      "282\tValidation loss: 1.510928\tBest loss: 1.501083\tAccuracy: 63.30%\n",
      "283\tValidation loss: 1.497479\tBest loss: 1.497479\tAccuracy: 63.70%\n",
      "284\tValidation loss: 1.499547\tBest loss: 1.497479\tAccuracy: 62.50%\n",
      "285\tValidation loss: 1.503553\tBest loss: 1.497479\tAccuracy: 63.60%\n",
      "286\tValidation loss: 1.495122\tBest loss: 1.495122\tAccuracy: 63.10%\n",
      "287\tValidation loss: 1.493456\tBest loss: 1.493456\tAccuracy: 63.30%\n",
      "288\tValidation loss: 1.502662\tBest loss: 1.493456\tAccuracy: 64.00%\n",
      "289\tValidation loss: 1.495248\tBest loss: 1.493456\tAccuracy: 63.90%\n",
      "290\tValidation loss: 1.500928\tBest loss: 1.493456\tAccuracy: 64.20%\n",
      "291\tValidation loss: 1.501774\tBest loss: 1.493456\tAccuracy: 63.30%\n",
      "292\tValidation loss: 1.498180\tBest loss: 1.493456\tAccuracy: 63.50%\n",
      "293\tValidation loss: 1.495654\tBest loss: 1.493456\tAccuracy: 62.40%\n",
      "294\tValidation loss: 1.499948\tBest loss: 1.493456\tAccuracy: 63.10%\n",
      "295\tValidation loss: 1.502426\tBest loss: 1.493456\tAccuracy: 64.60%\n",
      "296\tValidation loss: 1.512941\tBest loss: 1.493456\tAccuracy: 61.30%\n",
      "297\tValidation loss: 1.505148\tBest loss: 1.493456\tAccuracy: 63.30%\n",
      "298\tValidation loss: 1.501750\tBest loss: 1.493456\tAccuracy: 62.90%\n",
      "299\tValidation loss: 1.486029\tBest loss: 1.486029\tAccuracy: 63.10%\n",
      "300\tValidation loss: 1.483969\tBest loss: 1.483969\tAccuracy: 63.20%\n",
      "301\tValidation loss: 1.499570\tBest loss: 1.483969\tAccuracy: 64.90%\n",
      "302\tValidation loss: 1.480852\tBest loss: 1.480852\tAccuracy: 64.00%\n",
      "303\tValidation loss: 1.489808\tBest loss: 1.480852\tAccuracy: 64.00%\n",
      "304\tValidation loss: 1.476410\tBest loss: 1.476410\tAccuracy: 64.40%\n",
      "305\tValidation loss: 1.481398\tBest loss: 1.476410\tAccuracy: 64.40%\n",
      "306\tValidation loss: 1.480506\tBest loss: 1.476410\tAccuracy: 63.90%\n",
      "307\tValidation loss: 1.486698\tBest loss: 1.476410\tAccuracy: 64.20%\n",
      "308\tValidation loss: 1.480633\tBest loss: 1.476410\tAccuracy: 64.80%\n",
      "309\tValidation loss: 1.475488\tBest loss: 1.475488\tAccuracy: 64.40%\n",
      "310\tValidation loss: 1.474684\tBest loss: 1.474684\tAccuracy: 63.80%\n",
      "311\tValidation loss: 1.479534\tBest loss: 1.474684\tAccuracy: 64.20%\n",
      "312\tValidation loss: 1.491971\tBest loss: 1.474684\tAccuracy: 63.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\tValidation loss: 1.486231\tBest loss: 1.474684\tAccuracy: 64.00%\n",
      "314\tValidation loss: 1.471698\tBest loss: 1.471698\tAccuracy: 64.00%\n",
      "315\tValidation loss: 1.475289\tBest loss: 1.471698\tAccuracy: 64.30%\n",
      "316\tValidation loss: 1.477129\tBest loss: 1.471698\tAccuracy: 63.80%\n",
      "317\tValidation loss: 1.476358\tBest loss: 1.471698\tAccuracy: 63.90%\n",
      "318\tValidation loss: 1.467950\tBest loss: 1.467950\tAccuracy: 63.80%\n",
      "319\tValidation loss: 1.477282\tBest loss: 1.467950\tAccuracy: 63.40%\n",
      "320\tValidation loss: 1.472458\tBest loss: 1.467950\tAccuracy: 64.10%\n",
      "321\tValidation loss: 1.464539\tBest loss: 1.464539\tAccuracy: 63.60%\n",
      "322\tValidation loss: 1.473959\tBest loss: 1.464539\tAccuracy: 63.20%\n",
      "323\tValidation loss: 1.474473\tBest loss: 1.464539\tAccuracy: 63.70%\n",
      "324\tValidation loss: 1.472233\tBest loss: 1.464539\tAccuracy: 63.10%\n",
      "325\tValidation loss: 1.473152\tBest loss: 1.464539\tAccuracy: 63.80%\n",
      "326\tValidation loss: 1.471526\tBest loss: 1.464539\tAccuracy: 63.70%\n",
      "327\tValidation loss: 1.474865\tBest loss: 1.464539\tAccuracy: 63.10%\n",
      "328\tValidation loss: 1.473936\tBest loss: 1.464539\tAccuracy: 63.60%\n",
      "329\tValidation loss: 1.469102\tBest loss: 1.464539\tAccuracy: 64.20%\n",
      "330\tValidation loss: 1.467085\tBest loss: 1.464539\tAccuracy: 65.00%\n",
      "331\tValidation loss: 1.458148\tBest loss: 1.458148\tAccuracy: 64.20%\n",
      "332\tValidation loss: 1.454246\tBest loss: 1.454246\tAccuracy: 64.20%\n",
      "333\tValidation loss: 1.466925\tBest loss: 1.454246\tAccuracy: 65.80%\n",
      "334\tValidation loss: 1.444279\tBest loss: 1.444279\tAccuracy: 65.40%\n",
      "335\tValidation loss: 1.457440\tBest loss: 1.444279\tAccuracy: 64.80%\n",
      "336\tValidation loss: 1.449561\tBest loss: 1.444279\tAccuracy: 64.40%\n",
      "337\tValidation loss: 1.441417\tBest loss: 1.441417\tAccuracy: 65.10%\n",
      "338\tValidation loss: 1.447144\tBest loss: 1.441417\tAccuracy: 65.10%\n",
      "339\tValidation loss: 1.440891\tBest loss: 1.440891\tAccuracy: 64.50%\n",
      "340\tValidation loss: 1.456486\tBest loss: 1.440891\tAccuracy: 65.00%\n",
      "341\tValidation loss: 1.443628\tBest loss: 1.440891\tAccuracy: 63.60%\n",
      "342\tValidation loss: 1.451931\tBest loss: 1.440891\tAccuracy: 64.60%\n",
      "343\tValidation loss: 1.442060\tBest loss: 1.440891\tAccuracy: 64.90%\n",
      "344\tValidation loss: 1.447400\tBest loss: 1.440891\tAccuracy: 65.50%\n",
      "345\tValidation loss: 1.452726\tBest loss: 1.440891\tAccuracy: 65.70%\n",
      "346\tValidation loss: 1.451921\tBest loss: 1.440891\tAccuracy: 66.00%\n",
      "347\tValidation loss: 1.454554\tBest loss: 1.440891\tAccuracy: 64.50%\n",
      "348\tValidation loss: 1.446200\tBest loss: 1.440891\tAccuracy: 65.70%\n",
      "349\tValidation loss: 1.440321\tBest loss: 1.440321\tAccuracy: 64.30%\n",
      "350\tValidation loss: 1.447449\tBest loss: 1.440321\tAccuracy: 64.20%\n",
      "351\tValidation loss: 1.444910\tBest loss: 1.440321\tAccuracy: 65.10%\n",
      "352\tValidation loss: 1.441685\tBest loss: 1.440321\tAccuracy: 64.30%\n",
      "353\tValidation loss: 1.445843\tBest loss: 1.440321\tAccuracy: 64.50%\n",
      "354\tValidation loss: 1.452996\tBest loss: 1.440321\tAccuracy: 64.30%\n",
      "355\tValidation loss: 1.450307\tBest loss: 1.440321\tAccuracy: 65.00%\n",
      "356\tValidation loss: 1.460631\tBest loss: 1.440321\tAccuracy: 65.30%\n",
      "357\tValidation loss: 1.452576\tBest loss: 1.440321\tAccuracy: 65.40%\n",
      "358\tValidation loss: 1.442777\tBest loss: 1.440321\tAccuracy: 65.30%\n",
      "359\tValidation loss: 1.447630\tBest loss: 1.440321\tAccuracy: 64.80%\n",
      "360\tValidation loss: 1.435834\tBest loss: 1.435834\tAccuracy: 65.70%\n",
      "361\tValidation loss: 1.438711\tBest loss: 1.435834\tAccuracy: 65.00%\n",
      "362\tValidation loss: 1.436663\tBest loss: 1.435834\tAccuracy: 65.30%\n",
      "363\tValidation loss: 1.436384\tBest loss: 1.435834\tAccuracy: 65.20%\n",
      "364\tValidation loss: 1.435967\tBest loss: 1.435834\tAccuracy: 64.40%\n",
      "365\tValidation loss: 1.438045\tBest loss: 1.435834\tAccuracy: 64.80%\n",
      "366\tValidation loss: 1.429744\tBest loss: 1.429744\tAccuracy: 65.50%\n",
      "367\tValidation loss: 1.428712\tBest loss: 1.428712\tAccuracy: 65.70%\n",
      "368\tValidation loss: 1.435911\tBest loss: 1.428712\tAccuracy: 64.70%\n",
      "369\tValidation loss: 1.441278\tBest loss: 1.428712\tAccuracy: 65.00%\n",
      "370\tValidation loss: 1.444620\tBest loss: 1.428712\tAccuracy: 65.10%\n",
      "371\tValidation loss: 1.430846\tBest loss: 1.428712\tAccuracy: 64.90%\n",
      "372\tValidation loss: 1.422426\tBest loss: 1.422426\tAccuracy: 64.80%\n",
      "373\tValidation loss: 1.429693\tBest loss: 1.422426\tAccuracy: 65.20%\n",
      "374\tValidation loss: 1.446183\tBest loss: 1.422426\tAccuracy: 64.20%\n",
      "375\tValidation loss: 1.432191\tBest loss: 1.422426\tAccuracy: 65.60%\n",
      "376\tValidation loss: 1.426844\tBest loss: 1.422426\tAccuracy: 64.80%\n",
      "377\tValidation loss: 1.435448\tBest loss: 1.422426\tAccuracy: 65.20%\n",
      "378\tValidation loss: 1.425803\tBest loss: 1.422426\tAccuracy: 65.10%\n",
      "379\tValidation loss: 1.423242\tBest loss: 1.422426\tAccuracy: 65.90%\n",
      "380\tValidation loss: 1.414272\tBest loss: 1.414272\tAccuracy: 65.80%\n",
      "381\tValidation loss: 1.435334\tBest loss: 1.414272\tAccuracy: 65.40%\n",
      "382\tValidation loss: 1.422193\tBest loss: 1.414272\tAccuracy: 65.40%\n",
      "383\tValidation loss: 1.425464\tBest loss: 1.414272\tAccuracy: 65.80%\n",
      "384\tValidation loss: 1.408582\tBest loss: 1.408582\tAccuracy: 65.80%\n",
      "385\tValidation loss: 1.423742\tBest loss: 1.408582\tAccuracy: 66.20%\n",
      "386\tValidation loss: 1.427294\tBest loss: 1.408582\tAccuracy: 66.00%\n",
      "387\tValidation loss: 1.429132\tBest loss: 1.408582\tAccuracy: 65.60%\n",
      "388\tValidation loss: 1.416370\tBest loss: 1.408582\tAccuracy: 66.40%\n",
      "389\tValidation loss: 1.434489\tBest loss: 1.408582\tAccuracy: 65.10%\n",
      "390\tValidation loss: 1.409258\tBest loss: 1.408582\tAccuracy: 67.10%\n",
      "391\tValidation loss: 1.422186\tBest loss: 1.408582\tAccuracy: 65.10%\n",
      "392\tValidation loss: 1.413437\tBest loss: 1.408582\tAccuracy: 65.70%\n",
      "393\tValidation loss: 1.418028\tBest loss: 1.408582\tAccuracy: 65.60%\n",
      "394\tValidation loss: 1.415832\tBest loss: 1.408582\tAccuracy: 65.20%\n",
      "395\tValidation loss: 1.409090\tBest loss: 1.408582\tAccuracy: 65.20%\n",
      "396\tValidation loss: 1.416286\tBest loss: 1.408582\tAccuracy: 64.60%\n",
      "397\tValidation loss: 1.409136\tBest loss: 1.408582\tAccuracy: 65.80%\n",
      "398\tValidation loss: 1.429888\tBest loss: 1.408582\tAccuracy: 65.10%\n",
      "399\tValidation loss: 1.406693\tBest loss: 1.406693\tAccuracy: 66.20%\n",
      "400\tValidation loss: 1.415034\tBest loss: 1.406693\tAccuracy: 65.90%\n",
      "401\tValidation loss: 1.411767\tBest loss: 1.406693\tAccuracy: 65.10%\n",
      "402\tValidation loss: 1.418956\tBest loss: 1.406693\tAccuracy: 66.10%\n",
      "403\tValidation loss: 1.411706\tBest loss: 1.406693\tAccuracy: 65.90%\n",
      "404\tValidation loss: 1.403455\tBest loss: 1.403455\tAccuracy: 65.70%\n",
      "405\tValidation loss: 1.410940\tBest loss: 1.403455\tAccuracy: 65.70%\n",
      "406\tValidation loss: 1.417302\tBest loss: 1.403455\tAccuracy: 66.10%\n",
      "407\tValidation loss: 1.412609\tBest loss: 1.403455\tAccuracy: 66.60%\n",
      "408\tValidation loss: 1.404214\tBest loss: 1.403455\tAccuracy: 66.00%\n",
      "409\tValidation loss: 1.402042\tBest loss: 1.402042\tAccuracy: 66.10%\n",
      "410\tValidation loss: 1.412795\tBest loss: 1.402042\tAccuracy: 65.70%\n",
      "411\tValidation loss: 1.412025\tBest loss: 1.402042\tAccuracy: 65.70%\n",
      "412\tValidation loss: 1.410478\tBest loss: 1.402042\tAccuracy: 65.60%\n",
      "413\tValidation loss: 1.417497\tBest loss: 1.402042\tAccuracy: 64.40%\n",
      "414\tValidation loss: 1.408377\tBest loss: 1.402042\tAccuracy: 65.90%\n",
      "415\tValidation loss: 1.406285\tBest loss: 1.402042\tAccuracy: 66.00%\n",
      "416\tValidation loss: 1.409229\tBest loss: 1.402042\tAccuracy: 65.80%\n",
      "417\tValidation loss: 1.411253\tBest loss: 1.402042\tAccuracy: 65.20%\n",
      "418\tValidation loss: 1.406667\tBest loss: 1.402042\tAccuracy: 65.80%\n",
      "419\tValidation loss: 1.389452\tBest loss: 1.389452\tAccuracy: 67.20%\n",
      "420\tValidation loss: 1.396923\tBest loss: 1.389452\tAccuracy: 65.80%\n",
      "421\tValidation loss: 1.400339\tBest loss: 1.389452\tAccuracy: 65.80%\n",
      "422\tValidation loss: 1.405479\tBest loss: 1.389452\tAccuracy: 66.90%\n",
      "423\tValidation loss: 1.399187\tBest loss: 1.389452\tAccuracy: 65.90%\n",
      "424\tValidation loss: 1.398406\tBest loss: 1.389452\tAccuracy: 66.80%\n",
      "425\tValidation loss: 1.399964\tBest loss: 1.389452\tAccuracy: 66.40%\n",
      "426\tValidation loss: 1.411289\tBest loss: 1.389452\tAccuracy: 65.50%\n",
      "427\tValidation loss: 1.394295\tBest loss: 1.389452\tAccuracy: 65.90%\n",
      "428\tValidation loss: 1.403481\tBest loss: 1.389452\tAccuracy: 65.40%\n",
      "429\tValidation loss: 1.401113\tBest loss: 1.389452\tAccuracy: 65.90%\n",
      "430\tValidation loss: 1.396628\tBest loss: 1.389452\tAccuracy: 65.60%\n",
      "431\tValidation loss: 1.391910\tBest loss: 1.389452\tAccuracy: 66.60%\n",
      "432\tValidation loss: 1.391941\tBest loss: 1.389452\tAccuracy: 66.20%\n",
      "433\tValidation loss: 1.392920\tBest loss: 1.389452\tAccuracy: 66.30%\n",
      "434\tValidation loss: 1.382233\tBest loss: 1.382233\tAccuracy: 66.40%\n",
      "435\tValidation loss: 1.387872\tBest loss: 1.382233\tAccuracy: 65.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\tValidation loss: 1.387368\tBest loss: 1.382233\tAccuracy: 65.80%\n",
      "437\tValidation loss: 1.379033\tBest loss: 1.379033\tAccuracy: 65.00%\n",
      "438\tValidation loss: 1.390993\tBest loss: 1.379033\tAccuracy: 65.80%\n",
      "439\tValidation loss: 1.388504\tBest loss: 1.379033\tAccuracy: 65.90%\n",
      "440\tValidation loss: 1.385996\tBest loss: 1.379033\tAccuracy: 65.80%\n",
      "441\tValidation loss: 1.376908\tBest loss: 1.376908\tAccuracy: 66.20%\n",
      "442\tValidation loss: 1.398351\tBest loss: 1.376908\tAccuracy: 65.30%\n",
      "443\tValidation loss: 1.386507\tBest loss: 1.376908\tAccuracy: 66.40%\n",
      "444\tValidation loss: 1.391206\tBest loss: 1.376908\tAccuracy: 66.70%\n",
      "445\tValidation loss: 1.379126\tBest loss: 1.376908\tAccuracy: 66.70%\n",
      "446\tValidation loss: 1.385416\tBest loss: 1.376908\tAccuracy: 66.60%\n",
      "447\tValidation loss: 1.391026\tBest loss: 1.376908\tAccuracy: 65.80%\n",
      "448\tValidation loss: 1.387018\tBest loss: 1.376908\tAccuracy: 65.80%\n",
      "449\tValidation loss: 1.395148\tBest loss: 1.376908\tAccuracy: 65.90%\n",
      "450\tValidation loss: 1.378937\tBest loss: 1.376908\tAccuracy: 66.60%\n",
      "451\tValidation loss: 1.387908\tBest loss: 1.376908\tAccuracy: 65.90%\n",
      "452\tValidation loss: 1.392217\tBest loss: 1.376908\tAccuracy: 65.80%\n",
      "453\tValidation loss: 1.380352\tBest loss: 1.376908\tAccuracy: 66.40%\n",
      "454\tValidation loss: 1.386492\tBest loss: 1.376908\tAccuracy: 66.50%\n",
      "455\tValidation loss: 1.380543\tBest loss: 1.376908\tAccuracy: 66.90%\n",
      "456\tValidation loss: 1.386915\tBest loss: 1.376908\tAccuracy: 65.70%\n",
      "457\tValidation loss: 1.388702\tBest loss: 1.376908\tAccuracy: 65.30%\n",
      "458\tValidation loss: 1.383647\tBest loss: 1.376908\tAccuracy: 66.00%\n",
      "459\tValidation loss: 1.377348\tBest loss: 1.376908\tAccuracy: 67.30%\n",
      "460\tValidation loss: 1.377618\tBest loss: 1.376908\tAccuracy: 66.80%\n",
      "461\tValidation loss: 1.368134\tBest loss: 1.368134\tAccuracy: 66.50%\n",
      "462\tValidation loss: 1.379475\tBest loss: 1.368134\tAccuracy: 65.40%\n",
      "463\tValidation loss: 1.373762\tBest loss: 1.368134\tAccuracy: 64.80%\n",
      "464\tValidation loss: 1.383148\tBest loss: 1.368134\tAccuracy: 66.70%\n",
      "465\tValidation loss: 1.380905\tBest loss: 1.368134\tAccuracy: 67.40%\n",
      "466\tValidation loss: 1.383685\tBest loss: 1.368134\tAccuracy: 65.80%\n",
      "467\tValidation loss: 1.386386\tBest loss: 1.368134\tAccuracy: 66.00%\n",
      "468\tValidation loss: 1.378108\tBest loss: 1.368134\tAccuracy: 65.40%\n",
      "469\tValidation loss: 1.375677\tBest loss: 1.368134\tAccuracy: 66.10%\n",
      "470\tValidation loss: 1.369396\tBest loss: 1.368134\tAccuracy: 67.40%\n",
      "471\tValidation loss: 1.363038\tBest loss: 1.363038\tAccuracy: 66.00%\n",
      "472\tValidation loss: 1.374577\tBest loss: 1.363038\tAccuracy: 66.70%\n",
      "473\tValidation loss: 1.371401\tBest loss: 1.363038\tAccuracy: 67.10%\n",
      "474\tValidation loss: 1.380050\tBest loss: 1.363038\tAccuracy: 66.70%\n",
      "475\tValidation loss: 1.367865\tBest loss: 1.363038\tAccuracy: 66.30%\n",
      "476\tValidation loss: 1.378467\tBest loss: 1.363038\tAccuracy: 66.70%\n",
      "477\tValidation loss: 1.375909\tBest loss: 1.363038\tAccuracy: 67.00%\n",
      "478\tValidation loss: 1.368583\tBest loss: 1.363038\tAccuracy: 65.60%\n",
      "479\tValidation loss: 1.375000\tBest loss: 1.363038\tAccuracy: 66.20%\n",
      "480\tValidation loss: 1.381049\tBest loss: 1.363038\tAccuracy: 66.00%\n",
      "481\tValidation loss: 1.361909\tBest loss: 1.361909\tAccuracy: 65.30%\n",
      "482\tValidation loss: 1.362481\tBest loss: 1.361909\tAccuracy: 65.80%\n",
      "483\tValidation loss: 1.370133\tBest loss: 1.361909\tAccuracy: 66.00%\n",
      "484\tValidation loss: 1.366850\tBest loss: 1.361909\tAccuracy: 66.70%\n",
      "485\tValidation loss: 1.355011\tBest loss: 1.355011\tAccuracy: 65.40%\n",
      "486\tValidation loss: 1.365824\tBest loss: 1.355011\tAccuracy: 67.60%\n",
      "487\tValidation loss: 1.361552\tBest loss: 1.355011\tAccuracy: 67.20%\n",
      "488\tValidation loss: 1.359499\tBest loss: 1.355011\tAccuracy: 67.10%\n",
      "489\tValidation loss: 1.358330\tBest loss: 1.355011\tAccuracy: 67.00%\n",
      "490\tValidation loss: 1.363931\tBest loss: 1.355011\tAccuracy: 67.20%\n",
      "491\tValidation loss: 1.369532\tBest loss: 1.355011\tAccuracy: 66.50%\n",
      "492\tValidation loss: 1.368574\tBest loss: 1.355011\tAccuracy: 66.30%\n",
      "493\tValidation loss: 1.347230\tBest loss: 1.347230\tAccuracy: 66.50%\n",
      "494\tValidation loss: 1.344973\tBest loss: 1.344973\tAccuracy: 67.00%\n",
      "495\tValidation loss: 1.355595\tBest loss: 1.344973\tAccuracy: 67.40%\n",
      "496\tValidation loss: 1.351459\tBest loss: 1.344973\tAccuracy: 67.30%\n",
      "497\tValidation loss: 1.348295\tBest loss: 1.344973\tAccuracy: 66.00%\n",
      "498\tValidation loss: 1.343392\tBest loss: 1.343392\tAccuracy: 67.00%\n",
      "499\tValidation loss: 1.346658\tBest loss: 1.343392\tAccuracy: 67.50%\n",
      "500\tValidation loss: 1.346398\tBest loss: 1.343392\tAccuracy: 67.00%\n",
      "501\tValidation loss: 1.354916\tBest loss: 1.343392\tAccuracy: 66.70%\n",
      "502\tValidation loss: 1.356811\tBest loss: 1.343392\tAccuracy: 66.70%\n",
      "503\tValidation loss: 1.348839\tBest loss: 1.343392\tAccuracy: 66.70%\n",
      "504\tValidation loss: 1.347195\tBest loss: 1.343392\tAccuracy: 68.30%\n",
      "505\tValidation loss: 1.349736\tBest loss: 1.343392\tAccuracy: 66.10%\n",
      "506\tValidation loss: 1.351975\tBest loss: 1.343392\tAccuracy: 66.80%\n",
      "507\tValidation loss: 1.346696\tBest loss: 1.343392\tAccuracy: 66.90%\n",
      "508\tValidation loss: 1.344032\tBest loss: 1.343392\tAccuracy: 67.00%\n",
      "509\tValidation loss: 1.352991\tBest loss: 1.343392\tAccuracy: 66.30%\n",
      "510\tValidation loss: 1.346516\tBest loss: 1.343392\tAccuracy: 66.60%\n",
      "511\tValidation loss: 1.345655\tBest loss: 1.343392\tAccuracy: 67.20%\n",
      "512\tValidation loss: 1.352626\tBest loss: 1.343392\tAccuracy: 66.40%\n",
      "513\tValidation loss: 1.346514\tBest loss: 1.343392\tAccuracy: 66.70%\n",
      "514\tValidation loss: 1.347862\tBest loss: 1.343392\tAccuracy: 66.00%\n",
      "515\tValidation loss: 1.347992\tBest loss: 1.343392\tAccuracy: 67.10%\n",
      "516\tValidation loss: 1.347003\tBest loss: 1.343392\tAccuracy: 66.40%\n",
      "517\tValidation loss: 1.346096\tBest loss: 1.343392\tAccuracy: 66.10%\n",
      "518\tValidation loss: 1.346309\tBest loss: 1.343392\tAccuracy: 66.40%\n",
      "519\tValidation loss: 1.342511\tBest loss: 1.342511\tAccuracy: 66.20%\n",
      "520\tValidation loss: 1.353872\tBest loss: 1.342511\tAccuracy: 66.60%\n",
      "521\tValidation loss: 1.335818\tBest loss: 1.335818\tAccuracy: 66.30%\n",
      "522\tValidation loss: 1.341779\tBest loss: 1.335818\tAccuracy: 67.00%\n",
      "523\tValidation loss: 1.348947\tBest loss: 1.335818\tAccuracy: 66.80%\n",
      "524\tValidation loss: 1.343191\tBest loss: 1.335818\tAccuracy: 66.40%\n",
      "525\tValidation loss: 1.340120\tBest loss: 1.335818\tAccuracy: 66.40%\n",
      "526\tValidation loss: 1.338975\tBest loss: 1.335818\tAccuracy: 66.90%\n",
      "527\tValidation loss: 1.348478\tBest loss: 1.335818\tAccuracy: 66.60%\n",
      "528\tValidation loss: 1.344148\tBest loss: 1.335818\tAccuracy: 67.20%\n",
      "529\tValidation loss: 1.342032\tBest loss: 1.335818\tAccuracy: 67.50%\n",
      "530\tValidation loss: 1.341842\tBest loss: 1.335818\tAccuracy: 67.40%\n",
      "531\tValidation loss: 1.345658\tBest loss: 1.335818\tAccuracy: 66.10%\n",
      "532\tValidation loss: 1.346344\tBest loss: 1.335818\tAccuracy: 67.30%\n",
      "533\tValidation loss: 1.335481\tBest loss: 1.335481\tAccuracy: 67.60%\n",
      "534\tValidation loss: 1.333065\tBest loss: 1.333065\tAccuracy: 67.60%\n",
      "535\tValidation loss: 1.348122\tBest loss: 1.333065\tAccuracy: 66.80%\n",
      "536\tValidation loss: 1.337052\tBest loss: 1.333065\tAccuracy: 67.50%\n",
      "537\tValidation loss: 1.334835\tBest loss: 1.333065\tAccuracy: 67.10%\n",
      "538\tValidation loss: 1.326198\tBest loss: 1.326198\tAccuracy: 66.40%\n",
      "539\tValidation loss: 1.336644\tBest loss: 1.326198\tAccuracy: 65.80%\n",
      "540\tValidation loss: 1.338541\tBest loss: 1.326198\tAccuracy: 67.00%\n",
      "541\tValidation loss: 1.333035\tBest loss: 1.326198\tAccuracy: 67.20%\n",
      "542\tValidation loss: 1.341955\tBest loss: 1.326198\tAccuracy: 66.90%\n",
      "543\tValidation loss: 1.330886\tBest loss: 1.326198\tAccuracy: 66.70%\n",
      "544\tValidation loss: 1.332338\tBest loss: 1.326198\tAccuracy: 66.80%\n",
      "545\tValidation loss: 1.336574\tBest loss: 1.326198\tAccuracy: 67.10%\n",
      "546\tValidation loss: 1.333621\tBest loss: 1.326198\tAccuracy: 67.20%\n",
      "547\tValidation loss: 1.335416\tBest loss: 1.326198\tAccuracy: 67.60%\n",
      "548\tValidation loss: 1.339077\tBest loss: 1.326198\tAccuracy: 67.10%\n",
      "549\tValidation loss: 1.341903\tBest loss: 1.326198\tAccuracy: 67.10%\n",
      "550\tValidation loss: 1.331474\tBest loss: 1.326198\tAccuracy: 67.90%\n",
      "551\tValidation loss: 1.340128\tBest loss: 1.326198\tAccuracy: 67.90%\n",
      "552\tValidation loss: 1.338634\tBest loss: 1.326198\tAccuracy: 66.80%\n",
      "553\tValidation loss: 1.336695\tBest loss: 1.326198\tAccuracy: 67.90%\n",
      "554\tValidation loss: 1.334308\tBest loss: 1.326198\tAccuracy: 67.00%\n",
      "555\tValidation loss: 1.333612\tBest loss: 1.326198\tAccuracy: 67.30%\n",
      "556\tValidation loss: 1.333655\tBest loss: 1.326198\tAccuracy: 67.80%\n",
      "557\tValidation loss: 1.334045\tBest loss: 1.326198\tAccuracy: 67.80%\n",
      "558\tValidation loss: 1.329060\tBest loss: 1.326198\tAccuracy: 66.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\tValidation loss: 1.339283\tBest loss: 1.326198\tAccuracy: 67.60%\n",
      "Early stopping!\n",
      "[[  2.77498821e-05   2.23033226e-06   1.36338221e-02 ...,   1.55238956e-06\n",
      "    1.41060473e-02   2.82229536e-04]\n",
      " [  8.32400894e-14   1.67530914e-08   1.42557788e-11 ...,   5.86234362e-16\n",
      "    8.39975839e-16   3.16987872e-15]\n",
      " [  6.69960855e-06   1.29803247e-03   3.82761864e-05 ...,   9.72876819e-08\n",
      "    3.47795570e-08   4.72306390e-08]\n",
      " ..., \n",
      " [  5.21215261e-04   9.00296262e-04   9.14628676e-04 ...,   7.41597312e-03\n",
      "    3.48277064e-03   6.02855580e-03]\n",
      " [  6.60118531e-05   1.15949800e-03   1.46824212e-04 ...,   8.74434561e-02\n",
      "    1.83779374e-02   5.13035581e-02]\n",
      " [  4.48820003e-09   4.51823462e-06   1.28130409e-07 ...,   3.61147267e-03\n",
      "    3.59752625e-02   3.39823626e-02]]\n",
      "[26 43 43 ...,  9 27 27]\n",
      "[[  2.04337155e-11   7.29493337e-08   9.19032939e-09 ...,   3.58486070e-15\n",
      "    1.24269548e-15   1.17735181e-13]\n",
      " [  8.13895613e-02   3.74227278e-02   8.03355202e-02 ...,   6.21126685e-03\n",
      "    4.36272006e-03   2.29100767e-03]\n",
      " [  3.01980801e-10   2.66381820e-17   4.53899247e-08 ...,   6.70261777e-16\n",
      "    5.65132682e-22   6.82823948e-26]\n",
      " ..., \n",
      " [  1.95549824e-03   4.59634187e-03   9.07610171e-04 ...,   5.67145975e-08\n",
      "    3.04981108e-06   1.26545999e-07]\n",
      " [  3.16666439e-02   1.79115776e-02   2.99969707e-02 ...,   1.54549927e-02\n",
      "    9.61426459e-03   6.14822423e-03]\n",
      " [  2.11939910e-09   2.26036683e-08   9.98644500e-10 ...,   2.21161498e-03\n",
      "    9.22064879e-04   9.34638023e-01]]\n",
      "[20  0 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 2.2min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.659758\tBest loss: 3.659758\tAccuracy: 15.60%\n",
      "1\tValidation loss: 3.338500\tBest loss: 3.338500\tAccuracy: 18.20%\n",
      "2\tValidation loss: 3.027429\tBest loss: 3.027429\tAccuracy: 28.60%\n",
      "3\tValidation loss: 2.954901\tBest loss: 2.954901\tAccuracy: 26.00%\n",
      "4\tValidation loss: 2.968202\tBest loss: 2.954901\tAccuracy: 26.00%\n",
      "5\tValidation loss: 2.903738\tBest loss: 2.903738\tAccuracy: 27.00%\n",
      "6\tValidation loss: 2.855363\tBest loss: 2.855363\tAccuracy: 32.10%\n",
      "7\tValidation loss: 2.751261\tBest loss: 2.751261\tAccuracy: 36.50%\n",
      "8\tValidation loss: 2.753265\tBest loss: 2.751261\tAccuracy: 34.90%\n",
      "9\tValidation loss: 2.725474\tBest loss: 2.725474\tAccuracy: 34.70%\n",
      "10\tValidation loss: 2.721848\tBest loss: 2.721848\tAccuracy: 34.80%\n",
      "11\tValidation loss: 2.656730\tBest loss: 2.656730\tAccuracy: 36.10%\n",
      "12\tValidation loss: 2.653178\tBest loss: 2.653178\tAccuracy: 37.10%\n",
      "13\tValidation loss: 2.625912\tBest loss: 2.625912\tAccuracy: 38.20%\n",
      "14\tValidation loss: 2.617821\tBest loss: 2.617821\tAccuracy: 39.80%\n",
      "15\tValidation loss: 2.602490\tBest loss: 2.602490\tAccuracy: 37.80%\n",
      "16\tValidation loss: 2.607578\tBest loss: 2.602490\tAccuracy: 38.30%\n",
      "17\tValidation loss: 2.569208\tBest loss: 2.569208\tAccuracy: 37.70%\n",
      "18\tValidation loss: 2.539545\tBest loss: 2.539545\tAccuracy: 40.50%\n",
      "19\tValidation loss: 2.524878\tBest loss: 2.524878\tAccuracy: 41.80%\n",
      "20\tValidation loss: 2.499018\tBest loss: 2.499018\tAccuracy: 40.70%\n",
      "21\tValidation loss: 2.468125\tBest loss: 2.468125\tAccuracy: 41.60%\n",
      "22\tValidation loss: 2.533222\tBest loss: 2.468125\tAccuracy: 39.80%\n",
      "23\tValidation loss: 2.475184\tBest loss: 2.468125\tAccuracy: 42.50%\n",
      "24\tValidation loss: 2.445685\tBest loss: 2.445685\tAccuracy: 41.60%\n",
      "25\tValidation loss: 2.443876\tBest loss: 2.443876\tAccuracy: 41.80%\n",
      "26\tValidation loss: 2.408951\tBest loss: 2.408951\tAccuracy: 43.80%\n",
      "27\tValidation loss: 2.385542\tBest loss: 2.385542\tAccuracy: 41.00%\n",
      "28\tValidation loss: 2.398549\tBest loss: 2.385542\tAccuracy: 44.40%\n",
      "29\tValidation loss: 2.405442\tBest loss: 2.385542\tAccuracy: 42.90%\n",
      "30\tValidation loss: 2.352841\tBest loss: 2.352841\tAccuracy: 44.30%\n",
      "31\tValidation loss: 2.367420\tBest loss: 2.352841\tAccuracy: 45.00%\n",
      "32\tValidation loss: 2.352760\tBest loss: 2.352760\tAccuracy: 46.20%\n",
      "33\tValidation loss: 2.324253\tBest loss: 2.324253\tAccuracy: 45.20%\n",
      "34\tValidation loss: 2.325703\tBest loss: 2.324253\tAccuracy: 45.30%\n",
      "35\tValidation loss: 2.322088\tBest loss: 2.322088\tAccuracy: 46.70%\n",
      "36\tValidation loss: 2.317677\tBest loss: 2.317677\tAccuracy: 43.90%\n",
      "37\tValidation loss: 2.269790\tBest loss: 2.269790\tAccuracy: 45.90%\n",
      "38\tValidation loss: 2.279353\tBest loss: 2.269790\tAccuracy: 45.60%\n",
      "39\tValidation loss: 2.268888\tBest loss: 2.268888\tAccuracy: 47.00%\n",
      "40\tValidation loss: 2.272098\tBest loss: 2.268888\tAccuracy: 45.60%\n",
      "41\tValidation loss: 2.223488\tBest loss: 2.223488\tAccuracy: 47.30%\n",
      "42\tValidation loss: 2.237287\tBest loss: 2.223488\tAccuracy: 46.60%\n",
      "43\tValidation loss: 2.206954\tBest loss: 2.206954\tAccuracy: 47.60%\n",
      "44\tValidation loss: 2.227073\tBest loss: 2.206954\tAccuracy: 45.80%\n",
      "45\tValidation loss: 2.235106\tBest loss: 2.206954\tAccuracy: 44.00%\n",
      "46\tValidation loss: 2.214104\tBest loss: 2.206954\tAccuracy: 47.20%\n",
      "47\tValidation loss: 2.176749\tBest loss: 2.176749\tAccuracy: 47.40%\n",
      "48\tValidation loss: 2.176891\tBest loss: 2.176749\tAccuracy: 46.40%\n",
      "49\tValidation loss: 2.166276\tBest loss: 2.166276\tAccuracy: 47.90%\n",
      "50\tValidation loss: 2.159651\tBest loss: 2.159651\tAccuracy: 48.50%\n",
      "51\tValidation loss: 2.170940\tBest loss: 2.159651\tAccuracy: 49.30%\n",
      "52\tValidation loss: 2.144976\tBest loss: 2.144976\tAccuracy: 48.00%\n",
      "53\tValidation loss: 2.130148\tBest loss: 2.130148\tAccuracy: 49.30%\n",
      "54\tValidation loss: 2.133117\tBest loss: 2.130148\tAccuracy: 47.90%\n",
      "55\tValidation loss: 2.120809\tBest loss: 2.120809\tAccuracy: 48.80%\n",
      "56\tValidation loss: 2.115747\tBest loss: 2.115747\tAccuracy: 49.00%\n",
      "57\tValidation loss: 2.092877\tBest loss: 2.092877\tAccuracy: 49.20%\n",
      "58\tValidation loss: 2.115871\tBest loss: 2.092877\tAccuracy: 49.50%\n",
      "59\tValidation loss: 2.093793\tBest loss: 2.092877\tAccuracy: 50.40%\n",
      "60\tValidation loss: 2.098602\tBest loss: 2.092877\tAccuracy: 48.20%\n",
      "61\tValidation loss: 2.092679\tBest loss: 2.092679\tAccuracy: 47.60%\n",
      "62\tValidation loss: 2.078922\tBest loss: 2.078922\tAccuracy: 49.40%\n",
      "63\tValidation loss: 2.091435\tBest loss: 2.078922\tAccuracy: 49.60%\n",
      "64\tValidation loss: 2.046845\tBest loss: 2.046845\tAccuracy: 50.80%\n",
      "65\tValidation loss: 2.059078\tBest loss: 2.046845\tAccuracy: 48.30%\n",
      "66\tValidation loss: 2.071927\tBest loss: 2.046845\tAccuracy: 48.80%\n",
      "67\tValidation loss: 2.044806\tBest loss: 2.044806\tAccuracy: 52.30%\n",
      "68\tValidation loss: 2.054359\tBest loss: 2.044806\tAccuracy: 50.20%\n",
      "69\tValidation loss: 2.034778\tBest loss: 2.034778\tAccuracy: 50.70%\n",
      "70\tValidation loss: 2.049901\tBest loss: 2.034778\tAccuracy: 49.50%\n",
      "71\tValidation loss: 2.010829\tBest loss: 2.010829\tAccuracy: 50.90%\n",
      "72\tValidation loss: 2.003650\tBest loss: 2.003650\tAccuracy: 51.30%\n",
      "73\tValidation loss: 2.008283\tBest loss: 2.003650\tAccuracy: 50.50%\n",
      "74\tValidation loss: 2.015674\tBest loss: 2.003650\tAccuracy: 51.30%\n",
      "75\tValidation loss: 2.005170\tBest loss: 2.003650\tAccuracy: 51.70%\n",
      "76\tValidation loss: 2.018328\tBest loss: 2.003650\tAccuracy: 50.90%\n",
      "77\tValidation loss: 1.988683\tBest loss: 1.988683\tAccuracy: 51.60%\n",
      "78\tValidation loss: 1.983576\tBest loss: 1.983576\tAccuracy: 50.80%\n",
      "79\tValidation loss: 1.985836\tBest loss: 1.983576\tAccuracy: 52.20%\n",
      "80\tValidation loss: 1.989781\tBest loss: 1.983576\tAccuracy: 50.70%\n",
      "81\tValidation loss: 1.963600\tBest loss: 1.963600\tAccuracy: 51.80%\n",
      "82\tValidation loss: 1.974114\tBest loss: 1.963600\tAccuracy: 53.40%\n",
      "83\tValidation loss: 1.953741\tBest loss: 1.953741\tAccuracy: 53.30%\n",
      "84\tValidation loss: 1.951963\tBest loss: 1.951963\tAccuracy: 53.30%\n",
      "85\tValidation loss: 1.986872\tBest loss: 1.951963\tAccuracy: 50.40%\n",
      "86\tValidation loss: 1.954829\tBest loss: 1.951963\tAccuracy: 53.00%\n",
      "87\tValidation loss: 1.957389\tBest loss: 1.951963\tAccuracy: 53.10%\n",
      "88\tValidation loss: 1.955215\tBest loss: 1.951963\tAccuracy: 52.50%\n",
      "89\tValidation loss: 1.959852\tBest loss: 1.951963\tAccuracy: 53.10%\n",
      "90\tValidation loss: 1.944094\tBest loss: 1.944094\tAccuracy: 53.40%\n",
      "91\tValidation loss: 1.930410\tBest loss: 1.930410\tAccuracy: 52.80%\n",
      "92\tValidation loss: 1.937326\tBest loss: 1.930410\tAccuracy: 52.20%\n",
      "93\tValidation loss: 1.926682\tBest loss: 1.926682\tAccuracy: 51.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\tValidation loss: 1.918254\tBest loss: 1.918254\tAccuracy: 52.30%\n",
      "95\tValidation loss: 1.908069\tBest loss: 1.908069\tAccuracy: 53.10%\n",
      "96\tValidation loss: 1.895673\tBest loss: 1.895673\tAccuracy: 53.90%\n",
      "97\tValidation loss: 1.902107\tBest loss: 1.895673\tAccuracy: 53.50%\n",
      "98\tValidation loss: 1.893069\tBest loss: 1.893069\tAccuracy: 53.20%\n",
      "99\tValidation loss: 1.901245\tBest loss: 1.893069\tAccuracy: 53.30%\n",
      "100\tValidation loss: 1.884117\tBest loss: 1.884117\tAccuracy: 53.60%\n",
      "101\tValidation loss: 1.875938\tBest loss: 1.875938\tAccuracy: 55.20%\n",
      "102\tValidation loss: 1.902502\tBest loss: 1.875938\tAccuracy: 54.70%\n",
      "103\tValidation loss: 1.881823\tBest loss: 1.875938\tAccuracy: 53.60%\n",
      "104\tValidation loss: 1.887575\tBest loss: 1.875938\tAccuracy: 54.50%\n",
      "105\tValidation loss: 1.889201\tBest loss: 1.875938\tAccuracy: 53.30%\n",
      "106\tValidation loss: 1.873099\tBest loss: 1.873099\tAccuracy: 53.60%\n",
      "107\tValidation loss: 1.879732\tBest loss: 1.873099\tAccuracy: 53.80%\n",
      "108\tValidation loss: 1.863313\tBest loss: 1.863313\tAccuracy: 54.60%\n",
      "109\tValidation loss: 1.880112\tBest loss: 1.863313\tAccuracy: 53.10%\n",
      "110\tValidation loss: 1.874410\tBest loss: 1.863313\tAccuracy: 53.80%\n",
      "111\tValidation loss: 1.849768\tBest loss: 1.849768\tAccuracy: 54.20%\n",
      "112\tValidation loss: 1.845246\tBest loss: 1.845246\tAccuracy: 54.50%\n",
      "113\tValidation loss: 1.852016\tBest loss: 1.845246\tAccuracy: 53.60%\n",
      "114\tValidation loss: 1.844744\tBest loss: 1.844744\tAccuracy: 54.30%\n",
      "115\tValidation loss: 1.865858\tBest loss: 1.844744\tAccuracy: 54.10%\n",
      "116\tValidation loss: 1.868211\tBest loss: 1.844744\tAccuracy: 53.30%\n",
      "117\tValidation loss: 1.833260\tBest loss: 1.833260\tAccuracy: 54.40%\n",
      "118\tValidation loss: 1.827644\tBest loss: 1.827644\tAccuracy: 53.70%\n",
      "119\tValidation loss: 1.836832\tBest loss: 1.827644\tAccuracy: 54.60%\n",
      "120\tValidation loss: 1.828239\tBest loss: 1.827644\tAccuracy: 55.00%\n",
      "121\tValidation loss: 1.833294\tBest loss: 1.827644\tAccuracy: 55.20%\n",
      "122\tValidation loss: 1.840816\tBest loss: 1.827644\tAccuracy: 54.90%\n",
      "123\tValidation loss: 1.826396\tBest loss: 1.826396\tAccuracy: 54.40%\n",
      "124\tValidation loss: 1.811917\tBest loss: 1.811917\tAccuracy: 56.10%\n",
      "125\tValidation loss: 1.810672\tBest loss: 1.810672\tAccuracy: 54.00%\n",
      "126\tValidation loss: 1.810800\tBest loss: 1.810672\tAccuracy: 55.20%\n",
      "127\tValidation loss: 1.820624\tBest loss: 1.810672\tAccuracy: 55.10%\n",
      "128\tValidation loss: 1.807193\tBest loss: 1.807193\tAccuracy: 55.00%\n",
      "129\tValidation loss: 1.801770\tBest loss: 1.801770\tAccuracy: 54.60%\n",
      "130\tValidation loss: 1.796935\tBest loss: 1.796935\tAccuracy: 54.20%\n",
      "131\tValidation loss: 1.787481\tBest loss: 1.787481\tAccuracy: 56.10%\n",
      "132\tValidation loss: 1.784405\tBest loss: 1.784405\tAccuracy: 55.70%\n",
      "133\tValidation loss: 1.786493\tBest loss: 1.784405\tAccuracy: 54.00%\n",
      "134\tValidation loss: 1.777187\tBest loss: 1.777187\tAccuracy: 55.50%\n",
      "135\tValidation loss: 1.786596\tBest loss: 1.777187\tAccuracy: 56.20%\n",
      "136\tValidation loss: 1.786373\tBest loss: 1.777187\tAccuracy: 55.30%\n",
      "137\tValidation loss: 1.776603\tBest loss: 1.776603\tAccuracy: 55.30%\n",
      "138\tValidation loss: 1.769941\tBest loss: 1.769941\tAccuracy: 56.20%\n",
      "139\tValidation loss: 1.760414\tBest loss: 1.760414\tAccuracy: 56.40%\n",
      "140\tValidation loss: 1.766389\tBest loss: 1.760414\tAccuracy: 55.90%\n",
      "141\tValidation loss: 1.774666\tBest loss: 1.760414\tAccuracy: 56.20%\n",
      "142\tValidation loss: 1.766954\tBest loss: 1.760414\tAccuracy: 56.10%\n",
      "143\tValidation loss: 1.772788\tBest loss: 1.760414\tAccuracy: 54.90%\n",
      "144\tValidation loss: 1.776719\tBest loss: 1.760414\tAccuracy: 56.50%\n",
      "145\tValidation loss: 1.748564\tBest loss: 1.748564\tAccuracy: 55.80%\n",
      "146\tValidation loss: 1.732699\tBest loss: 1.732699\tAccuracy: 58.20%\n",
      "147\tValidation loss: 1.737105\tBest loss: 1.732699\tAccuracy: 57.30%\n",
      "148\tValidation loss: 1.749440\tBest loss: 1.732699\tAccuracy: 55.70%\n",
      "149\tValidation loss: 1.746186\tBest loss: 1.732699\tAccuracy: 57.20%\n",
      "150\tValidation loss: 1.741777\tBest loss: 1.732699\tAccuracy: 56.90%\n",
      "151\tValidation loss: 1.730313\tBest loss: 1.730313\tAccuracy: 57.60%\n",
      "152\tValidation loss: 1.733992\tBest loss: 1.730313\tAccuracy: 58.20%\n",
      "153\tValidation loss: 1.736306\tBest loss: 1.730313\tAccuracy: 56.80%\n",
      "154\tValidation loss: 1.737107\tBest loss: 1.730313\tAccuracy: 58.00%\n",
      "155\tValidation loss: 1.742238\tBest loss: 1.730313\tAccuracy: 57.00%\n",
      "156\tValidation loss: 1.724862\tBest loss: 1.724862\tAccuracy: 58.10%\n",
      "157\tValidation loss: 1.722609\tBest loss: 1.722609\tAccuracy: 57.40%\n",
      "158\tValidation loss: 1.737725\tBest loss: 1.722609\tAccuracy: 55.60%\n",
      "159\tValidation loss: 1.714734\tBest loss: 1.714734\tAccuracy: 58.00%\n",
      "160\tValidation loss: 1.735844\tBest loss: 1.714734\tAccuracy: 57.20%\n",
      "161\tValidation loss: 1.707888\tBest loss: 1.707888\tAccuracy: 58.30%\n",
      "162\tValidation loss: 1.723186\tBest loss: 1.707888\tAccuracy: 58.30%\n",
      "163\tValidation loss: 1.717474\tBest loss: 1.707888\tAccuracy: 57.10%\n",
      "164\tValidation loss: 1.700348\tBest loss: 1.700348\tAccuracy: 58.10%\n",
      "165\tValidation loss: 1.717539\tBest loss: 1.700348\tAccuracy: 57.40%\n",
      "166\tValidation loss: 1.703753\tBest loss: 1.700348\tAccuracy: 58.10%\n",
      "167\tValidation loss: 1.694802\tBest loss: 1.694802\tAccuracy: 57.90%\n",
      "168\tValidation loss: 1.702396\tBest loss: 1.694802\tAccuracy: 57.40%\n",
      "169\tValidation loss: 1.713784\tBest loss: 1.694802\tAccuracy: 55.80%\n",
      "170\tValidation loss: 1.694788\tBest loss: 1.694788\tAccuracy: 58.00%\n",
      "171\tValidation loss: 1.688763\tBest loss: 1.688763\tAccuracy: 57.20%\n",
      "172\tValidation loss: 1.675133\tBest loss: 1.675133\tAccuracy: 58.00%\n",
      "173\tValidation loss: 1.699763\tBest loss: 1.675133\tAccuracy: 59.30%\n",
      "174\tValidation loss: 1.680422\tBest loss: 1.675133\tAccuracy: 57.90%\n",
      "175\tValidation loss: 1.693543\tBest loss: 1.675133\tAccuracy: 56.50%\n",
      "176\tValidation loss: 1.680624\tBest loss: 1.675133\tAccuracy: 57.80%\n",
      "177\tValidation loss: 1.679878\tBest loss: 1.675133\tAccuracy: 57.30%\n",
      "178\tValidation loss: 1.681611\tBest loss: 1.675133\tAccuracy: 58.60%\n",
      "179\tValidation loss: 1.699901\tBest loss: 1.675133\tAccuracy: 57.50%\n",
      "180\tValidation loss: 1.678588\tBest loss: 1.675133\tAccuracy: 58.50%\n",
      "181\tValidation loss: 1.668838\tBest loss: 1.668838\tAccuracy: 57.90%\n",
      "182\tValidation loss: 1.670708\tBest loss: 1.668838\tAccuracy: 59.00%\n",
      "183\tValidation loss: 1.677898\tBest loss: 1.668838\tAccuracy: 57.50%\n",
      "184\tValidation loss: 1.667749\tBest loss: 1.667749\tAccuracy: 58.60%\n",
      "185\tValidation loss: 1.677285\tBest loss: 1.667749\tAccuracy: 57.50%\n",
      "186\tValidation loss: 1.657954\tBest loss: 1.657954\tAccuracy: 59.10%\n",
      "187\tValidation loss: 1.674017\tBest loss: 1.657954\tAccuracy: 58.40%\n",
      "188\tValidation loss: 1.665915\tBest loss: 1.657954\tAccuracy: 59.30%\n",
      "189\tValidation loss: 1.676025\tBest loss: 1.657954\tAccuracy: 57.80%\n",
      "190\tValidation loss: 1.640567\tBest loss: 1.640567\tAccuracy: 59.60%\n",
      "191\tValidation loss: 1.651385\tBest loss: 1.640567\tAccuracy: 58.00%\n",
      "192\tValidation loss: 1.650456\tBest loss: 1.640567\tAccuracy: 59.10%\n",
      "193\tValidation loss: 1.635752\tBest loss: 1.635752\tAccuracy: 58.70%\n",
      "194\tValidation loss: 1.639739\tBest loss: 1.635752\tAccuracy: 59.50%\n",
      "195\tValidation loss: 1.628415\tBest loss: 1.628415\tAccuracy: 59.60%\n",
      "196\tValidation loss: 1.637429\tBest loss: 1.628415\tAccuracy: 58.90%\n",
      "197\tValidation loss: 1.639849\tBest loss: 1.628415\tAccuracy: 60.60%\n",
      "198\tValidation loss: 1.630628\tBest loss: 1.628415\tAccuracy: 59.20%\n",
      "199\tValidation loss: 1.649055\tBest loss: 1.628415\tAccuracy: 59.90%\n",
      "200\tValidation loss: 1.645465\tBest loss: 1.628415\tAccuracy: 59.00%\n",
      "201\tValidation loss: 1.646722\tBest loss: 1.628415\tAccuracy: 58.10%\n",
      "202\tValidation loss: 1.636499\tBest loss: 1.628415\tAccuracy: 59.10%\n",
      "203\tValidation loss: 1.625373\tBest loss: 1.625373\tAccuracy: 60.40%\n",
      "204\tValidation loss: 1.637724\tBest loss: 1.625373\tAccuracy: 58.70%\n",
      "205\tValidation loss: 1.622278\tBest loss: 1.622278\tAccuracy: 59.70%\n",
      "206\tValidation loss: 1.621247\tBest loss: 1.621247\tAccuracy: 58.70%\n",
      "207\tValidation loss: 1.627600\tBest loss: 1.621247\tAccuracy: 59.30%\n",
      "208\tValidation loss: 1.637867\tBest loss: 1.621247\tAccuracy: 59.00%\n",
      "209\tValidation loss: 1.617127\tBest loss: 1.617127\tAccuracy: 58.50%\n",
      "210\tValidation loss: 1.625126\tBest loss: 1.617127\tAccuracy: 59.10%\n",
      "211\tValidation loss: 1.614156\tBest loss: 1.614156\tAccuracy: 60.00%\n",
      "212\tValidation loss: 1.622205\tBest loss: 1.614156\tAccuracy: 60.30%\n",
      "213\tValidation loss: 1.605266\tBest loss: 1.605266\tAccuracy: 59.00%\n",
      "214\tValidation loss: 1.603146\tBest loss: 1.603146\tAccuracy: 60.00%\n",
      "215\tValidation loss: 1.608939\tBest loss: 1.603146\tAccuracy: 58.60%\n",
      "216\tValidation loss: 1.599122\tBest loss: 1.599122\tAccuracy: 60.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\tValidation loss: 1.606989\tBest loss: 1.599122\tAccuracy: 60.80%\n",
      "218\tValidation loss: 1.613323\tBest loss: 1.599122\tAccuracy: 58.90%\n",
      "219\tValidation loss: 1.600070\tBest loss: 1.599122\tAccuracy: 60.60%\n",
      "220\tValidation loss: 1.590701\tBest loss: 1.590701\tAccuracy: 60.80%\n",
      "221\tValidation loss: 1.595149\tBest loss: 1.590701\tAccuracy: 60.10%\n",
      "222\tValidation loss: 1.604087\tBest loss: 1.590701\tAccuracy: 59.70%\n",
      "223\tValidation loss: 1.591953\tBest loss: 1.590701\tAccuracy: 60.60%\n",
      "224\tValidation loss: 1.588637\tBest loss: 1.588637\tAccuracy: 61.00%\n",
      "225\tValidation loss: 1.595539\tBest loss: 1.588637\tAccuracy: 60.50%\n",
      "226\tValidation loss: 1.594915\tBest loss: 1.588637\tAccuracy: 60.30%\n",
      "227\tValidation loss: 1.589754\tBest loss: 1.588637\tAccuracy: 59.90%\n",
      "228\tValidation loss: 1.594973\tBest loss: 1.588637\tAccuracy: 59.50%\n",
      "229\tValidation loss: 1.583149\tBest loss: 1.583149\tAccuracy: 59.70%\n",
      "230\tValidation loss: 1.578296\tBest loss: 1.578296\tAccuracy: 60.20%\n",
      "231\tValidation loss: 1.591447\tBest loss: 1.578296\tAccuracy: 60.40%\n",
      "232\tValidation loss: 1.587373\tBest loss: 1.578296\tAccuracy: 60.30%\n",
      "233\tValidation loss: 1.578087\tBest loss: 1.578087\tAccuracy: 60.60%\n",
      "234\tValidation loss: 1.573087\tBest loss: 1.573087\tAccuracy: 60.50%\n",
      "235\tValidation loss: 1.591303\tBest loss: 1.573087\tAccuracy: 60.30%\n",
      "236\tValidation loss: 1.595402\tBest loss: 1.573087\tAccuracy: 59.60%\n",
      "237\tValidation loss: 1.573334\tBest loss: 1.573087\tAccuracy: 61.10%\n",
      "238\tValidation loss: 1.584599\tBest loss: 1.573087\tAccuracy: 61.40%\n",
      "239\tValidation loss: 1.563484\tBest loss: 1.563484\tAccuracy: 61.50%\n",
      "240\tValidation loss: 1.550058\tBest loss: 1.550058\tAccuracy: 61.40%\n",
      "241\tValidation loss: 1.565582\tBest loss: 1.550058\tAccuracy: 62.30%\n",
      "242\tValidation loss: 1.576342\tBest loss: 1.550058\tAccuracy: 61.00%\n",
      "243\tValidation loss: 1.551942\tBest loss: 1.550058\tAccuracy: 60.80%\n",
      "244\tValidation loss: 1.560925\tBest loss: 1.550058\tAccuracy: 61.40%\n",
      "245\tValidation loss: 1.562947\tBest loss: 1.550058\tAccuracy: 60.50%\n",
      "246\tValidation loss: 1.566742\tBest loss: 1.550058\tAccuracy: 61.20%\n",
      "247\tValidation loss: 1.577958\tBest loss: 1.550058\tAccuracy: 61.10%\n",
      "248\tValidation loss: 1.558146\tBest loss: 1.550058\tAccuracy: 60.50%\n",
      "249\tValidation loss: 1.561745\tBest loss: 1.550058\tAccuracy: 60.00%\n",
      "250\tValidation loss: 1.563639\tBest loss: 1.550058\tAccuracy: 60.10%\n",
      "251\tValidation loss: 1.561504\tBest loss: 1.550058\tAccuracy: 60.80%\n",
      "252\tValidation loss: 1.561744\tBest loss: 1.550058\tAccuracy: 61.90%\n",
      "253\tValidation loss: 1.547680\tBest loss: 1.547680\tAccuracy: 61.90%\n",
      "254\tValidation loss: 1.545342\tBest loss: 1.545342\tAccuracy: 62.30%\n",
      "255\tValidation loss: 1.547323\tBest loss: 1.545342\tAccuracy: 61.90%\n",
      "256\tValidation loss: 1.551255\tBest loss: 1.545342\tAccuracy: 62.20%\n",
      "257\tValidation loss: 1.546329\tBest loss: 1.545342\tAccuracy: 62.30%\n",
      "258\tValidation loss: 1.559411\tBest loss: 1.545342\tAccuracy: 61.40%\n",
      "259\tValidation loss: 1.559154\tBest loss: 1.545342\tAccuracy: 61.20%\n",
      "260\tValidation loss: 1.552123\tBest loss: 1.545342\tAccuracy: 60.20%\n",
      "261\tValidation loss: 1.551798\tBest loss: 1.545342\tAccuracy: 61.50%\n",
      "262\tValidation loss: 1.549995\tBest loss: 1.545342\tAccuracy: 62.00%\n",
      "263\tValidation loss: 1.559213\tBest loss: 1.545342\tAccuracy: 61.70%\n",
      "264\tValidation loss: 1.537508\tBest loss: 1.537508\tAccuracy: 61.70%\n",
      "265\tValidation loss: 1.545207\tBest loss: 1.537508\tAccuracy: 61.80%\n",
      "266\tValidation loss: 1.550588\tBest loss: 1.537508\tAccuracy: 61.10%\n",
      "267\tValidation loss: 1.541641\tBest loss: 1.537508\tAccuracy: 60.90%\n",
      "268\tValidation loss: 1.524661\tBest loss: 1.524661\tAccuracy: 61.70%\n",
      "269\tValidation loss: 1.541731\tBest loss: 1.524661\tAccuracy: 62.20%\n",
      "270\tValidation loss: 1.544975\tBest loss: 1.524661\tAccuracy: 61.50%\n",
      "271\tValidation loss: 1.543155\tBest loss: 1.524661\tAccuracy: 62.30%\n",
      "272\tValidation loss: 1.536853\tBest loss: 1.524661\tAccuracy: 61.40%\n",
      "273\tValidation loss: 1.543235\tBest loss: 1.524661\tAccuracy: 61.80%\n",
      "274\tValidation loss: 1.536588\tBest loss: 1.524661\tAccuracy: 59.50%\n",
      "275\tValidation loss: 1.539943\tBest loss: 1.524661\tAccuracy: 62.40%\n",
      "276\tValidation loss: 1.525209\tBest loss: 1.524661\tAccuracy: 61.70%\n",
      "277\tValidation loss: 1.530191\tBest loss: 1.524661\tAccuracy: 62.20%\n",
      "278\tValidation loss: 1.542325\tBest loss: 1.524661\tAccuracy: 61.00%\n",
      "279\tValidation loss: 1.538290\tBest loss: 1.524661\tAccuracy: 61.60%\n",
      "280\tValidation loss: 1.537812\tBest loss: 1.524661\tAccuracy: 62.30%\n",
      "281\tValidation loss: 1.514428\tBest loss: 1.514428\tAccuracy: 62.80%\n",
      "282\tValidation loss: 1.526146\tBest loss: 1.514428\tAccuracy: 63.10%\n",
      "283\tValidation loss: 1.526213\tBest loss: 1.514428\tAccuracy: 62.50%\n",
      "284\tValidation loss: 1.521421\tBest loss: 1.514428\tAccuracy: 62.30%\n",
      "285\tValidation loss: 1.528799\tBest loss: 1.514428\tAccuracy: 62.50%\n",
      "286\tValidation loss: 1.522180\tBest loss: 1.514428\tAccuracy: 62.70%\n",
      "287\tValidation loss: 1.517618\tBest loss: 1.514428\tAccuracy: 64.30%\n",
      "288\tValidation loss: 1.513785\tBest loss: 1.513785\tAccuracy: 62.60%\n",
      "289\tValidation loss: 1.512889\tBest loss: 1.512889\tAccuracy: 63.70%\n",
      "290\tValidation loss: 1.525461\tBest loss: 1.512889\tAccuracy: 61.30%\n",
      "291\tValidation loss: 1.516748\tBest loss: 1.512889\tAccuracy: 63.00%\n",
      "292\tValidation loss: 1.509956\tBest loss: 1.509956\tAccuracy: 61.40%\n",
      "293\tValidation loss: 1.519040\tBest loss: 1.509956\tAccuracy: 62.80%\n",
      "294\tValidation loss: 1.512383\tBest loss: 1.509956\tAccuracy: 63.60%\n",
      "295\tValidation loss: 1.509963\tBest loss: 1.509956\tAccuracy: 63.10%\n",
      "296\tValidation loss: 1.529967\tBest loss: 1.509956\tAccuracy: 61.60%\n",
      "297\tValidation loss: 1.533324\tBest loss: 1.509956\tAccuracy: 62.00%\n",
      "298\tValidation loss: 1.508074\tBest loss: 1.508074\tAccuracy: 63.00%\n",
      "299\tValidation loss: 1.505519\tBest loss: 1.505519\tAccuracy: 63.70%\n",
      "300\tValidation loss: 1.491808\tBest loss: 1.491808\tAccuracy: 62.90%\n",
      "301\tValidation loss: 1.504485\tBest loss: 1.491808\tAccuracy: 62.80%\n",
      "302\tValidation loss: 1.503805\tBest loss: 1.491808\tAccuracy: 63.40%\n",
      "303\tValidation loss: 1.508514\tBest loss: 1.491808\tAccuracy: 63.50%\n",
      "304\tValidation loss: 1.498821\tBest loss: 1.491808\tAccuracy: 63.30%\n",
      "305\tValidation loss: 1.490609\tBest loss: 1.490609\tAccuracy: 62.50%\n",
      "306\tValidation loss: 1.499195\tBest loss: 1.490609\tAccuracy: 63.30%\n",
      "307\tValidation loss: 1.505510\tBest loss: 1.490609\tAccuracy: 63.60%\n",
      "308\tValidation loss: 1.513589\tBest loss: 1.490609\tAccuracy: 61.80%\n",
      "309\tValidation loss: 1.501346\tBest loss: 1.490609\tAccuracy: 63.70%\n",
      "310\tValidation loss: 1.499036\tBest loss: 1.490609\tAccuracy: 64.00%\n",
      "311\tValidation loss: 1.502797\tBest loss: 1.490609\tAccuracy: 63.90%\n",
      "312\tValidation loss: 1.502220\tBest loss: 1.490609\tAccuracy: 63.10%\n",
      "313\tValidation loss: 1.514530\tBest loss: 1.490609\tAccuracy: 62.80%\n",
      "314\tValidation loss: 1.505043\tBest loss: 1.490609\tAccuracy: 62.80%\n",
      "315\tValidation loss: 1.506628\tBest loss: 1.490609\tAccuracy: 64.30%\n",
      "316\tValidation loss: 1.497455\tBest loss: 1.490609\tAccuracy: 63.10%\n",
      "317\tValidation loss: 1.499741\tBest loss: 1.490609\tAccuracy: 63.00%\n",
      "318\tValidation loss: 1.490220\tBest loss: 1.490220\tAccuracy: 63.10%\n",
      "319\tValidation loss: 1.493735\tBest loss: 1.490220\tAccuracy: 63.90%\n",
      "320\tValidation loss: 1.501042\tBest loss: 1.490220\tAccuracy: 63.40%\n",
      "321\tValidation loss: 1.490219\tBest loss: 1.490219\tAccuracy: 63.10%\n",
      "322\tValidation loss: 1.493274\tBest loss: 1.490219\tAccuracy: 63.00%\n",
      "323\tValidation loss: 1.482049\tBest loss: 1.482049\tAccuracy: 63.40%\n",
      "324\tValidation loss: 1.500526\tBest loss: 1.482049\tAccuracy: 63.40%\n",
      "325\tValidation loss: 1.474444\tBest loss: 1.474444\tAccuracy: 64.50%\n",
      "326\tValidation loss: 1.476292\tBest loss: 1.474444\tAccuracy: 63.50%\n",
      "327\tValidation loss: 1.481928\tBest loss: 1.474444\tAccuracy: 63.30%\n",
      "328\tValidation loss: 1.481985\tBest loss: 1.474444\tAccuracy: 63.50%\n",
      "329\tValidation loss: 1.473379\tBest loss: 1.473379\tAccuracy: 64.80%\n",
      "330\tValidation loss: 1.471935\tBest loss: 1.471935\tAccuracy: 64.30%\n",
      "331\tValidation loss: 1.469141\tBest loss: 1.469141\tAccuracy: 64.40%\n",
      "332\tValidation loss: 1.466683\tBest loss: 1.466683\tAccuracy: 64.10%\n",
      "333\tValidation loss: 1.470372\tBest loss: 1.466683\tAccuracy: 63.40%\n",
      "334\tValidation loss: 1.472881\tBest loss: 1.466683\tAccuracy: 62.90%\n",
      "335\tValidation loss: 1.472786\tBest loss: 1.466683\tAccuracy: 63.40%\n",
      "336\tValidation loss: 1.465798\tBest loss: 1.465798\tAccuracy: 64.00%\n",
      "337\tValidation loss: 1.463882\tBest loss: 1.463882\tAccuracy: 64.00%\n",
      "338\tValidation loss: 1.469501\tBest loss: 1.463882\tAccuracy: 64.00%\n",
      "339\tValidation loss: 1.466205\tBest loss: 1.463882\tAccuracy: 64.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\tValidation loss: 1.460669\tBest loss: 1.460669\tAccuracy: 64.50%\n",
      "341\tValidation loss: 1.466164\tBest loss: 1.460669\tAccuracy: 63.00%\n",
      "342\tValidation loss: 1.472938\tBest loss: 1.460669\tAccuracy: 63.00%\n",
      "343\tValidation loss: 1.471689\tBest loss: 1.460669\tAccuracy: 64.20%\n",
      "344\tValidation loss: 1.481878\tBest loss: 1.460669\tAccuracy: 64.20%\n",
      "345\tValidation loss: 1.469675\tBest loss: 1.460669\tAccuracy: 63.90%\n",
      "346\tValidation loss: 1.467914\tBest loss: 1.460669\tAccuracy: 64.30%\n",
      "347\tValidation loss: 1.462126\tBest loss: 1.460669\tAccuracy: 64.50%\n",
      "348\tValidation loss: 1.470754\tBest loss: 1.460669\tAccuracy: 64.20%\n",
      "349\tValidation loss: 1.458836\tBest loss: 1.458836\tAccuracy: 63.70%\n",
      "350\tValidation loss: 1.471769\tBest loss: 1.458836\tAccuracy: 62.60%\n",
      "351\tValidation loss: 1.459119\tBest loss: 1.458836\tAccuracy: 64.50%\n",
      "352\tValidation loss: 1.469392\tBest loss: 1.458836\tAccuracy: 63.10%\n",
      "353\tValidation loss: 1.462072\tBest loss: 1.458836\tAccuracy: 63.80%\n",
      "354\tValidation loss: 1.465778\tBest loss: 1.458836\tAccuracy: 63.10%\n",
      "355\tValidation loss: 1.453234\tBest loss: 1.453234\tAccuracy: 63.70%\n",
      "356\tValidation loss: 1.460589\tBest loss: 1.453234\tAccuracy: 63.80%\n",
      "357\tValidation loss: 1.461856\tBest loss: 1.453234\tAccuracy: 64.00%\n",
      "358\tValidation loss: 1.441310\tBest loss: 1.441310\tAccuracy: 63.40%\n",
      "359\tValidation loss: 1.470749\tBest loss: 1.441310\tAccuracy: 63.10%\n",
      "360\tValidation loss: 1.450894\tBest loss: 1.441310\tAccuracy: 64.30%\n",
      "361\tValidation loss: 1.454662\tBest loss: 1.441310\tAccuracy: 63.50%\n",
      "362\tValidation loss: 1.455194\tBest loss: 1.441310\tAccuracy: 64.10%\n",
      "363\tValidation loss: 1.455398\tBest loss: 1.441310\tAccuracy: 63.30%\n",
      "364\tValidation loss: 1.452718\tBest loss: 1.441310\tAccuracy: 63.80%\n",
      "365\tValidation loss: 1.452496\tBest loss: 1.441310\tAccuracy: 64.00%\n",
      "366\tValidation loss: 1.454399\tBest loss: 1.441310\tAccuracy: 63.40%\n",
      "367\tValidation loss: 1.457988\tBest loss: 1.441310\tAccuracy: 64.00%\n",
      "368\tValidation loss: 1.453417\tBest loss: 1.441310\tAccuracy: 63.60%\n",
      "369\tValidation loss: 1.444205\tBest loss: 1.441310\tAccuracy: 65.80%\n",
      "370\tValidation loss: 1.444790\tBest loss: 1.441310\tAccuracy: 63.20%\n",
      "371\tValidation loss: 1.453512\tBest loss: 1.441310\tAccuracy: 64.00%\n",
      "372\tValidation loss: 1.457874\tBest loss: 1.441310\tAccuracy: 64.30%\n",
      "373\tValidation loss: 1.461067\tBest loss: 1.441310\tAccuracy: 64.20%\n",
      "374\tValidation loss: 1.436751\tBest loss: 1.436751\tAccuracy: 64.90%\n",
      "375\tValidation loss: 1.441278\tBest loss: 1.436751\tAccuracy: 65.10%\n",
      "376\tValidation loss: 1.452904\tBest loss: 1.436751\tAccuracy: 64.90%\n",
      "377\tValidation loss: 1.444376\tBest loss: 1.436751\tAccuracy: 63.50%\n",
      "378\tValidation loss: 1.451409\tBest loss: 1.436751\tAccuracy: 63.90%\n",
      "379\tValidation loss: 1.469701\tBest loss: 1.436751\tAccuracy: 63.70%\n",
      "380\tValidation loss: 1.455599\tBest loss: 1.436751\tAccuracy: 64.70%\n",
      "381\tValidation loss: 1.446107\tBest loss: 1.436751\tAccuracy: 63.80%\n",
      "382\tValidation loss: 1.436332\tBest loss: 1.436332\tAccuracy: 64.50%\n",
      "383\tValidation loss: 1.445508\tBest loss: 1.436332\tAccuracy: 64.00%\n",
      "384\tValidation loss: 1.434516\tBest loss: 1.434516\tAccuracy: 64.30%\n",
      "385\tValidation loss: 1.438258\tBest loss: 1.434516\tAccuracy: 64.40%\n",
      "386\tValidation loss: 1.436320\tBest loss: 1.434516\tAccuracy: 65.00%\n",
      "387\tValidation loss: 1.436469\tBest loss: 1.434516\tAccuracy: 65.20%\n",
      "388\tValidation loss: 1.446435\tBest loss: 1.434516\tAccuracy: 64.70%\n",
      "389\tValidation loss: 1.435417\tBest loss: 1.434516\tAccuracy: 65.80%\n",
      "390\tValidation loss: 1.439214\tBest loss: 1.434516\tAccuracy: 65.70%\n",
      "391\tValidation loss: 1.433754\tBest loss: 1.433754\tAccuracy: 64.90%\n",
      "392\tValidation loss: 1.438420\tBest loss: 1.433754\tAccuracy: 64.70%\n",
      "393\tValidation loss: 1.439167\tBest loss: 1.433754\tAccuracy: 63.70%\n",
      "394\tValidation loss: 1.447328\tBest loss: 1.433754\tAccuracy: 63.60%\n",
      "395\tValidation loss: 1.439738\tBest loss: 1.433754\tAccuracy: 64.50%\n",
      "396\tValidation loss: 1.449019\tBest loss: 1.433754\tAccuracy: 65.20%\n",
      "397\tValidation loss: 1.436184\tBest loss: 1.433754\tAccuracy: 64.80%\n",
      "398\tValidation loss: 1.439131\tBest loss: 1.433754\tAccuracy: 64.30%\n",
      "399\tValidation loss: 1.440835\tBest loss: 1.433754\tAccuracy: 64.00%\n",
      "400\tValidation loss: 1.423865\tBest loss: 1.423865\tAccuracy: 65.10%\n",
      "401\tValidation loss: 1.431609\tBest loss: 1.423865\tAccuracy: 64.60%\n",
      "402\tValidation loss: 1.435971\tBest loss: 1.423865\tAccuracy: 63.90%\n",
      "403\tValidation loss: 1.449818\tBest loss: 1.423865\tAccuracy: 64.00%\n",
      "404\tValidation loss: 1.449570\tBest loss: 1.423865\tAccuracy: 64.70%\n",
      "405\tValidation loss: 1.438198\tBest loss: 1.423865\tAccuracy: 64.40%\n",
      "406\tValidation loss: 1.435375\tBest loss: 1.423865\tAccuracy: 64.20%\n",
      "407\tValidation loss: 1.440643\tBest loss: 1.423865\tAccuracy: 64.20%\n",
      "408\tValidation loss: 1.438982\tBest loss: 1.423865\tAccuracy: 63.90%\n",
      "409\tValidation loss: 1.436716\tBest loss: 1.423865\tAccuracy: 65.50%\n",
      "410\tValidation loss: 1.439980\tBest loss: 1.423865\tAccuracy: 64.20%\n",
      "411\tValidation loss: 1.444452\tBest loss: 1.423865\tAccuracy: 64.30%\n",
      "412\tValidation loss: 1.437292\tBest loss: 1.423865\tAccuracy: 64.70%\n",
      "413\tValidation loss: 1.431925\tBest loss: 1.423865\tAccuracy: 64.30%\n",
      "414\tValidation loss: 1.438652\tBest loss: 1.423865\tAccuracy: 64.30%\n",
      "415\tValidation loss: 1.439115\tBest loss: 1.423865\tAccuracy: 63.80%\n",
      "416\tValidation loss: 1.434996\tBest loss: 1.423865\tAccuracy: 65.50%\n",
      "417\tValidation loss: 1.432297\tBest loss: 1.423865\tAccuracy: 65.40%\n",
      "418\tValidation loss: 1.415315\tBest loss: 1.415315\tAccuracy: 65.00%\n",
      "419\tValidation loss: 1.450218\tBest loss: 1.415315\tAccuracy: 64.50%\n",
      "420\tValidation loss: 1.434482\tBest loss: 1.415315\tAccuracy: 64.50%\n",
      "421\tValidation loss: 1.440339\tBest loss: 1.415315\tAccuracy: 64.30%\n",
      "422\tValidation loss: 1.430388\tBest loss: 1.415315\tAccuracy: 64.70%\n",
      "423\tValidation loss: 1.427826\tBest loss: 1.415315\tAccuracy: 65.60%\n",
      "424\tValidation loss: 1.418334\tBest loss: 1.415315\tAccuracy: 66.00%\n",
      "425\tValidation loss: 1.427621\tBest loss: 1.415315\tAccuracy: 65.20%\n",
      "426\tValidation loss: 1.418071\tBest loss: 1.415315\tAccuracy: 64.60%\n",
      "427\tValidation loss: 1.424864\tBest loss: 1.415315\tAccuracy: 65.20%\n",
      "428\tValidation loss: 1.425586\tBest loss: 1.415315\tAccuracy: 65.10%\n",
      "429\tValidation loss: 1.424271\tBest loss: 1.415315\tAccuracy: 64.50%\n",
      "430\tValidation loss: 1.419278\tBest loss: 1.415315\tAccuracy: 64.10%\n",
      "431\tValidation loss: 1.413423\tBest loss: 1.413423\tAccuracy: 65.40%\n",
      "432\tValidation loss: 1.417460\tBest loss: 1.413423\tAccuracy: 64.70%\n",
      "433\tValidation loss: 1.413005\tBest loss: 1.413005\tAccuracy: 65.40%\n",
      "434\tValidation loss: 1.401509\tBest loss: 1.401509\tAccuracy: 65.70%\n",
      "435\tValidation loss: 1.412228\tBest loss: 1.401509\tAccuracy: 65.70%\n",
      "436\tValidation loss: 1.414649\tBest loss: 1.401509\tAccuracy: 64.90%\n",
      "437\tValidation loss: 1.419220\tBest loss: 1.401509\tAccuracy: 65.10%\n",
      "438\tValidation loss: 1.420254\tBest loss: 1.401509\tAccuracy: 65.60%\n",
      "439\tValidation loss: 1.432575\tBest loss: 1.401509\tAccuracy: 64.80%\n",
      "440\tValidation loss: 1.430863\tBest loss: 1.401509\tAccuracy: 64.70%\n",
      "441\tValidation loss: 1.411052\tBest loss: 1.401509\tAccuracy: 64.50%\n",
      "442\tValidation loss: 1.421906\tBest loss: 1.401509\tAccuracy: 64.60%\n",
      "443\tValidation loss: 1.414574\tBest loss: 1.401509\tAccuracy: 65.30%\n",
      "444\tValidation loss: 1.421822\tBest loss: 1.401509\tAccuracy: 66.00%\n",
      "445\tValidation loss: 1.417705\tBest loss: 1.401509\tAccuracy: 65.50%\n",
      "446\tValidation loss: 1.413220\tBest loss: 1.401509\tAccuracy: 65.90%\n",
      "447\tValidation loss: 1.402499\tBest loss: 1.401509\tAccuracy: 64.60%\n",
      "448\tValidation loss: 1.408099\tBest loss: 1.401509\tAccuracy: 64.80%\n",
      "449\tValidation loss: 1.411198\tBest loss: 1.401509\tAccuracy: 65.80%\n",
      "450\tValidation loss: 1.415123\tBest loss: 1.401509\tAccuracy: 64.90%\n",
      "451\tValidation loss: 1.426391\tBest loss: 1.401509\tAccuracy: 65.90%\n",
      "452\tValidation loss: 1.422102\tBest loss: 1.401509\tAccuracy: 65.30%\n",
      "453\tValidation loss: 1.415053\tBest loss: 1.401509\tAccuracy: 64.80%\n",
      "454\tValidation loss: 1.412240\tBest loss: 1.401509\tAccuracy: 65.30%\n",
      "455\tValidation loss: 1.399542\tBest loss: 1.399542\tAccuracy: 66.60%\n",
      "456\tValidation loss: 1.418540\tBest loss: 1.399542\tAccuracy: 65.40%\n",
      "457\tValidation loss: 1.409861\tBest loss: 1.399542\tAccuracy: 65.20%\n",
      "458\tValidation loss: 1.414910\tBest loss: 1.399542\tAccuracy: 65.30%\n",
      "459\tValidation loss: 1.399018\tBest loss: 1.399018\tAccuracy: 65.80%\n",
      "460\tValidation loss: 1.411322\tBest loss: 1.399018\tAccuracy: 65.50%\n",
      "461\tValidation loss: 1.397376\tBest loss: 1.397376\tAccuracy: 65.80%\n",
      "462\tValidation loss: 1.415110\tBest loss: 1.397376\tAccuracy: 65.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\tValidation loss: 1.408478\tBest loss: 1.397376\tAccuracy: 64.50%\n",
      "464\tValidation loss: 1.403694\tBest loss: 1.397376\tAccuracy: 65.30%\n",
      "465\tValidation loss: 1.395514\tBest loss: 1.395514\tAccuracy: 66.40%\n",
      "466\tValidation loss: 1.398977\tBest loss: 1.395514\tAccuracy: 65.40%\n",
      "467\tValidation loss: 1.395668\tBest loss: 1.395514\tAccuracy: 65.40%\n",
      "468\tValidation loss: 1.398107\tBest loss: 1.395514\tAccuracy: 65.70%\n",
      "469\tValidation loss: 1.390533\tBest loss: 1.390533\tAccuracy: 65.10%\n",
      "470\tValidation loss: 1.403618\tBest loss: 1.390533\tAccuracy: 66.40%\n",
      "471\tValidation loss: 1.387737\tBest loss: 1.387737\tAccuracy: 65.70%\n",
      "472\tValidation loss: 1.396432\tBest loss: 1.387737\tAccuracy: 65.60%\n",
      "473\tValidation loss: 1.386511\tBest loss: 1.386511\tAccuracy: 65.70%\n",
      "474\tValidation loss: 1.393162\tBest loss: 1.386511\tAccuracy: 66.40%\n",
      "475\tValidation loss: 1.389540\tBest loss: 1.386511\tAccuracy: 65.40%\n",
      "476\tValidation loss: 1.389568\tBest loss: 1.386511\tAccuracy: 64.50%\n",
      "477\tValidation loss: 1.386890\tBest loss: 1.386511\tAccuracy: 65.60%\n",
      "478\tValidation loss: 1.377217\tBest loss: 1.377217\tAccuracy: 65.20%\n",
      "479\tValidation loss: 1.394626\tBest loss: 1.377217\tAccuracy: 66.30%\n",
      "480\tValidation loss: 1.388662\tBest loss: 1.377217\tAccuracy: 65.30%\n",
      "481\tValidation loss: 1.379951\tBest loss: 1.377217\tAccuracy: 64.90%\n",
      "482\tValidation loss: 1.401482\tBest loss: 1.377217\tAccuracy: 65.00%\n",
      "483\tValidation loss: 1.372327\tBest loss: 1.372327\tAccuracy: 65.80%\n",
      "484\tValidation loss: 1.389501\tBest loss: 1.372327\tAccuracy: 65.50%\n",
      "485\tValidation loss: 1.383211\tBest loss: 1.372327\tAccuracy: 65.80%\n",
      "486\tValidation loss: 1.379102\tBest loss: 1.372327\tAccuracy: 65.70%\n",
      "487\tValidation loss: 1.389499\tBest loss: 1.372327\tAccuracy: 64.90%\n",
      "488\tValidation loss: 1.389806\tBest loss: 1.372327\tAccuracy: 65.20%\n",
      "489\tValidation loss: 1.382806\tBest loss: 1.372327\tAccuracy: 65.30%\n",
      "490\tValidation loss: 1.371960\tBest loss: 1.371960\tAccuracy: 65.60%\n",
      "491\tValidation loss: 1.386472\tBest loss: 1.371960\tAccuracy: 64.50%\n",
      "492\tValidation loss: 1.380695\tBest loss: 1.371960\tAccuracy: 64.50%\n",
      "493\tValidation loss: 1.380026\tBest loss: 1.371960\tAccuracy: 65.90%\n",
      "494\tValidation loss: 1.380026\tBest loss: 1.371960\tAccuracy: 65.80%\n",
      "495\tValidation loss: 1.389376\tBest loss: 1.371960\tAccuracy: 66.30%\n",
      "496\tValidation loss: 1.378227\tBest loss: 1.371960\tAccuracy: 65.20%\n",
      "497\tValidation loss: 1.371299\tBest loss: 1.371299\tAccuracy: 65.40%\n",
      "498\tValidation loss: 1.370314\tBest loss: 1.370314\tAccuracy: 66.10%\n",
      "499\tValidation loss: 1.381733\tBest loss: 1.370314\tAccuracy: 65.40%\n",
      "500\tValidation loss: 1.376897\tBest loss: 1.370314\tAccuracy: 66.20%\n",
      "501\tValidation loss: 1.379183\tBest loss: 1.370314\tAccuracy: 65.50%\n",
      "502\tValidation loss: 1.377253\tBest loss: 1.370314\tAccuracy: 65.50%\n",
      "503\tValidation loss: 1.368854\tBest loss: 1.368854\tAccuracy: 65.70%\n",
      "504\tValidation loss: 1.389660\tBest loss: 1.368854\tAccuracy: 66.00%\n",
      "505\tValidation loss: 1.377289\tBest loss: 1.368854\tAccuracy: 66.30%\n",
      "506\tValidation loss: 1.379836\tBest loss: 1.368854\tAccuracy: 65.60%\n",
      "507\tValidation loss: 1.381217\tBest loss: 1.368854\tAccuracy: 65.80%\n",
      "508\tValidation loss: 1.373582\tBest loss: 1.368854\tAccuracy: 66.30%\n",
      "509\tValidation loss: 1.375966\tBest loss: 1.368854\tAccuracy: 66.10%\n",
      "510\tValidation loss: 1.377617\tBest loss: 1.368854\tAccuracy: 65.80%\n",
      "511\tValidation loss: 1.376777\tBest loss: 1.368854\tAccuracy: 65.50%\n",
      "512\tValidation loss: 1.368929\tBest loss: 1.368854\tAccuracy: 66.60%\n",
      "513\tValidation loss: 1.385501\tBest loss: 1.368854\tAccuracy: 65.90%\n",
      "514\tValidation loss: 1.380847\tBest loss: 1.368854\tAccuracy: 66.10%\n",
      "515\tValidation loss: 1.381142\tBest loss: 1.368854\tAccuracy: 65.90%\n",
      "516\tValidation loss: 1.382697\tBest loss: 1.368854\tAccuracy: 65.80%\n",
      "517\tValidation loss: 1.361605\tBest loss: 1.361605\tAccuracy: 66.30%\n",
      "518\tValidation loss: 1.387185\tBest loss: 1.361605\tAccuracy: 66.50%\n",
      "519\tValidation loss: 1.377831\tBest loss: 1.361605\tAccuracy: 65.60%\n",
      "520\tValidation loss: 1.395687\tBest loss: 1.361605\tAccuracy: 66.10%\n",
      "521\tValidation loss: 1.381319\tBest loss: 1.361605\tAccuracy: 66.50%\n",
      "522\tValidation loss: 1.384972\tBest loss: 1.361605\tAccuracy: 67.00%\n",
      "523\tValidation loss: 1.373712\tBest loss: 1.361605\tAccuracy: 65.90%\n",
      "524\tValidation loss: 1.368692\tBest loss: 1.361605\tAccuracy: 66.60%\n",
      "525\tValidation loss: 1.369229\tBest loss: 1.361605\tAccuracy: 65.10%\n",
      "526\tValidation loss: 1.358876\tBest loss: 1.358876\tAccuracy: 66.00%\n",
      "527\tValidation loss: 1.370874\tBest loss: 1.358876\tAccuracy: 66.20%\n",
      "528\tValidation loss: 1.363306\tBest loss: 1.358876\tAccuracy: 66.40%\n",
      "529\tValidation loss: 1.367642\tBest loss: 1.358876\tAccuracy: 66.50%\n",
      "530\tValidation loss: 1.370989\tBest loss: 1.358876\tAccuracy: 66.40%\n",
      "531\tValidation loss: 1.376255\tBest loss: 1.358876\tAccuracy: 66.30%\n",
      "532\tValidation loss: 1.357367\tBest loss: 1.357367\tAccuracy: 67.10%\n",
      "533\tValidation loss: 1.369882\tBest loss: 1.357367\tAccuracy: 66.50%\n",
      "534\tValidation loss: 1.369588\tBest loss: 1.357367\tAccuracy: 67.20%\n",
      "535\tValidation loss: 1.353992\tBest loss: 1.353992\tAccuracy: 67.40%\n",
      "536\tValidation loss: 1.368071\tBest loss: 1.353992\tAccuracy: 67.20%\n",
      "537\tValidation loss: 1.368218\tBest loss: 1.353992\tAccuracy: 66.20%\n",
      "538\tValidation loss: 1.370435\tBest loss: 1.353992\tAccuracy: 67.40%\n",
      "539\tValidation loss: 1.367047\tBest loss: 1.353992\tAccuracy: 67.30%\n",
      "540\tValidation loss: 1.355749\tBest loss: 1.353992\tAccuracy: 67.10%\n",
      "541\tValidation loss: 1.356987\tBest loss: 1.353992\tAccuracy: 66.40%\n",
      "542\tValidation loss: 1.341388\tBest loss: 1.341388\tAccuracy: 67.30%\n",
      "543\tValidation loss: 1.358765\tBest loss: 1.341388\tAccuracy: 67.00%\n",
      "544\tValidation loss: 1.349626\tBest loss: 1.341388\tAccuracy: 66.50%\n",
      "545\tValidation loss: 1.360848\tBest loss: 1.341388\tAccuracy: 67.30%\n",
      "546\tValidation loss: 1.359492\tBest loss: 1.341388\tAccuracy: 66.30%\n",
      "547\tValidation loss: 1.360145\tBest loss: 1.341388\tAccuracy: 67.70%\n",
      "548\tValidation loss: 1.363096\tBest loss: 1.341388\tAccuracy: 67.00%\n",
      "549\tValidation loss: 1.357562\tBest loss: 1.341388\tAccuracy: 67.20%\n",
      "550\tValidation loss: 1.359423\tBest loss: 1.341388\tAccuracy: 67.60%\n",
      "551\tValidation loss: 1.375244\tBest loss: 1.341388\tAccuracy: 65.70%\n",
      "552\tValidation loss: 1.369335\tBest loss: 1.341388\tAccuracy: 66.00%\n",
      "553\tValidation loss: 1.351794\tBest loss: 1.341388\tAccuracy: 67.70%\n",
      "554\tValidation loss: 1.358380\tBest loss: 1.341388\tAccuracy: 66.50%\n",
      "555\tValidation loss: 1.359869\tBest loss: 1.341388\tAccuracy: 67.30%\n",
      "556\tValidation loss: 1.356600\tBest loss: 1.341388\tAccuracy: 67.20%\n",
      "557\tValidation loss: 1.354007\tBest loss: 1.341388\tAccuracy: 66.90%\n",
      "558\tValidation loss: 1.356582\tBest loss: 1.341388\tAccuracy: 67.50%\n",
      "559\tValidation loss: 1.353231\tBest loss: 1.341388\tAccuracy: 67.50%\n",
      "560\tValidation loss: 1.351718\tBest loss: 1.341388\tAccuracy: 67.00%\n",
      "561\tValidation loss: 1.348119\tBest loss: 1.341388\tAccuracy: 66.60%\n",
      "562\tValidation loss: 1.354417\tBest loss: 1.341388\tAccuracy: 66.00%\n",
      "563\tValidation loss: 1.355061\tBest loss: 1.341388\tAccuracy: 67.70%\n",
      "Early stopping!\n",
      "[[  3.13174655e-03   1.45363929e-02   6.58785086e-03 ...,   8.28966405e-03\n",
      "    1.03985611e-03   2.90350523e-03]\n",
      " [  7.21466751e-23   8.56892527e-18   5.19852358e-19 ...,   1.03448882e-18\n",
      "    5.91957394e-20   2.49247015e-20]\n",
      " [  1.22126643e-04   6.67493150e-04   2.34363228e-03 ...,   3.05814065e-05\n",
      "    8.80312364e-05   6.49137946e-04]\n",
      " ..., \n",
      " [  2.77264556e-03   3.43734748e-03   1.07280891e-02 ...,   3.12198303e-08\n",
      "    6.90683521e-07   9.95570701e-08]\n",
      " [  4.05061617e-02   2.64546201e-02   2.23725066e-02 ...,   1.93689726e-02\n",
      "    1.16062332e-02   9.15868394e-03]\n",
      " [  3.58015201e-10   2.71446310e-09   4.44004451e-11 ...,   2.68699229e-03\n",
      "    1.19250931e-03   9.22928691e-01]]\n",
      "[41 41 20 ...,  6 10 47]\n",
      "[[  7.81121923e-09   1.29727568e-05   4.28900330e-06 ...,   1.31745916e-17\n",
      "    6.36278783e-15   8.12072035e-14]\n",
      " [  8.30950439e-02   5.23761027e-02   6.53179735e-02 ...,   9.89471655e-03\n",
      "    4.65000002e-03   3.96841113e-03]\n",
      " [  7.32983940e-09   9.28785603e-15   7.03351191e-07 ...,   5.47382125e-16\n",
      "    4.72750457e-23   1.53314932e-26]\n",
      " ..., \n",
      " [  1.25564786e-03   1.42653997e-03   8.74565216e-04 ...,   1.07354727e-02\n",
      "    9.27200634e-03   1.74519401e-02]\n",
      " [  1.09106086e-05   8.75065380e-05   6.47726347e-06 ...,   2.21421003e-01\n",
      "    9.41072404e-03   2.09955722e-02]\n",
      " [  2.68718541e-08   4.62087883e-06   4.12956041e-07 ...,   1.47670833e-02\n",
      "    1.28703415e-01   1.19945452e-01]]\n",
      "[20  0 16 ...,  9 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=1, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 2.2min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  33.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  34.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.4, n_hidden_layers=3, n_neurons=120, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  33.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 8.327847\tBest loss: 8.327847\tAccuracy: 3.60%\n",
      "1\tValidation loss: 11.219629\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "2\tValidation loss: 19.174765\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "3\tValidation loss: 24.965088\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "4\tValidation loss: 25.569815\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "5\tValidation loss: 25.669495\tBest loss: 8.327847\tAccuracy: 3.20%\n",
      "6\tValidation loss: 25.558701\tBest loss: 8.327847\tAccuracy: 3.20%\n",
      "7\tValidation loss: 25.084583\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "8\tValidation loss: 24.416027\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "9\tValidation loss: 24.885569\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "10\tValidation loss: 23.040335\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "11\tValidation loss: 23.561792\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "12\tValidation loss: 22.458681\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "13\tValidation loss: 22.107542\tBest loss: 8.327847\tAccuracy: 3.20%\n",
      "14\tValidation loss: 21.651333\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "15\tValidation loss: 22.456512\tBest loss: 8.327847\tAccuracy: 3.20%\n",
      "16\tValidation loss: 21.862915\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "17\tValidation loss: 22.062664\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "18\tValidation loss: 21.993883\tBest loss: 8.327847\tAccuracy: 3.20%\n",
      "19\tValidation loss: 22.240332\tBest loss: 8.327847\tAccuracy: 4.00%\n",
      "20\tValidation loss: 22.022383\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "21\tValidation loss: 22.438030\tBest loss: 8.327847\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " ..., \n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]]\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[[ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " ..., \n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]\n",
      " [ 0.01968358  0.0956014   0.02200077 ...,  0.01747701  0.01096538\n",
      "   0.00241604]]\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   1.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 4.424863\tBest loss: 4.424863\tAccuracy: 4.90%\n",
      "1\tValidation loss: 3.759179\tBest loss: 3.759179\tAccuracy: 3.20%\n",
      "2\tValidation loss: 3.729104\tBest loss: 3.729104\tAccuracy: 6.00%\n",
      "3\tValidation loss: 3.668865\tBest loss: 3.668865\tAccuracy: 4.50%\n",
      "4\tValidation loss: 3.668250\tBest loss: 3.668250\tAccuracy: 4.70%\n",
      "5\tValidation loss: 3.656094\tBest loss: 3.656094\tAccuracy: 5.10%\n",
      "6\tValidation loss: 3.668920\tBest loss: 3.656094\tAccuracy: 4.80%\n",
      "7\tValidation loss: 3.653383\tBest loss: 3.653383\tAccuracy: 5.00%\n",
      "8\tValidation loss: 3.643206\tBest loss: 3.643206\tAccuracy: 4.90%\n",
      "9\tValidation loss: 3.637904\tBest loss: 3.637904\tAccuracy: 5.40%\n",
      "10\tValidation loss: 3.648570\tBest loss: 3.637904\tAccuracy: 5.00%\n",
      "11\tValidation loss: 3.633759\tBest loss: 3.633759\tAccuracy: 5.00%\n",
      "12\tValidation loss: 3.640465\tBest loss: 3.633759\tAccuracy: 6.00%\n",
      "13\tValidation loss: 3.644889\tBest loss: 3.633759\tAccuracy: 4.40%\n",
      "14\tValidation loss: 3.624986\tBest loss: 3.624986\tAccuracy: 4.90%\n",
      "15\tValidation loss: 3.620652\tBest loss: 3.620652\tAccuracy: 5.40%\n",
      "16\tValidation loss: 3.628310\tBest loss: 3.620652\tAccuracy: 5.00%\n",
      "17\tValidation loss: 3.615378\tBest loss: 3.615378\tAccuracy: 5.10%\n",
      "18\tValidation loss: 3.623849\tBest loss: 3.615378\tAccuracy: 4.90%\n",
      "19\tValidation loss: 3.616430\tBest loss: 3.615378\tAccuracy: 5.30%\n",
      "20\tValidation loss: 3.624708\tBest loss: 3.615378\tAccuracy: 4.50%\n",
      "21\tValidation loss: 3.634956\tBest loss: 3.615378\tAccuracy: 5.60%\n",
      "22\tValidation loss: 3.720302\tBest loss: 3.615378\tAccuracy: 4.20%\n",
      "23\tValidation loss: 3.685165\tBest loss: 3.615378\tAccuracy: 4.20%\n",
      "24\tValidation loss: 3.961293\tBest loss: 3.615378\tAccuracy: 5.00%\n",
      "25\tValidation loss: 3.655402\tBest loss: 3.615378\tAccuracy: 5.00%\n",
      "26\tValidation loss: 3.662141\tBest loss: 3.615378\tAccuracy: 5.10%\n",
      "27\tValidation loss: 3.666496\tBest loss: 3.615378\tAccuracy: 4.60%\n",
      "28\tValidation loss: 3.645745\tBest loss: 3.615378\tAccuracy: 5.50%\n",
      "29\tValidation loss: 3.641609\tBest loss: 3.615378\tAccuracy: 5.30%\n",
      "30\tValidation loss: 3.645974\tBest loss: 3.615378\tAccuracy: 5.50%\n",
      "31\tValidation loss: 3.642833\tBest loss: 3.615378\tAccuracy: 5.00%\n",
      "32\tValidation loss: 3.629873\tBest loss: 3.615378\tAccuracy: 4.70%\n",
      "33\tValidation loss: 3.630466\tBest loss: 3.615378\tAccuracy: 5.10%\n",
      "34\tValidation loss: 3.635519\tBest loss: 3.615378\tAccuracy: 5.10%\n",
      "35\tValidation loss: 3.626865\tBest loss: 3.615378\tAccuracy: 4.80%\n",
      "36\tValidation loss: 3.648479\tBest loss: 3.615378\tAccuracy: 5.00%\n",
      "37\tValidation loss: 3.632861\tBest loss: 3.615378\tAccuracy: 5.10%\n",
      "38\tValidation loss: 3.630207\tBest loss: 3.615378\tAccuracy: 4.60%\n",
      "Early stopping!\n",
      "[[ 0.00797799  0.02329322  0.01435992 ...,  0.04441265  0.00750389\n",
      "   0.01215551]\n",
      " [ 0.00460227  0.01535491  0.00840168 ...,  0.04546577  0.00394806\n",
      "   0.00784538]\n",
      " [ 0.0032296   0.01157825  0.00594085 ...,  0.04345931  0.00263643\n",
      "   0.00584877]\n",
      " ..., \n",
      " [ 0.01258229  0.02981627  0.02514285 ...,  0.03764359  0.01217487\n",
      "   0.01665127]\n",
      " [ 0.02192977  0.03848955  0.03740114 ...,  0.01368927  0.02930543\n",
      "   0.02177181]\n",
      " [ 0.00574235  0.01823043  0.01042798 ...,  0.04582197  0.00509782\n",
      "   0.00938815]]\n",
      "[36 38 24 ..., 16 19 38]\n",
      "[[ 0.01201008  0.0291343   0.02379459 ...,  0.03878887  0.01155101\n",
      "   0.01616112]\n",
      " [ 0.01545178  0.03535982  0.0271039  ...,  0.03017894  0.01719422\n",
      "   0.01917837]\n",
      " [ 0.02192977  0.03848955  0.03740114 ...,  0.01368927  0.02930543\n",
      "   0.02177181]\n",
      " ..., \n",
      " [ 0.02192977  0.03848955  0.03740114 ...,  0.01368927  0.02930543\n",
      "   0.02177181]\n",
      " [ 0.02192977  0.03848955  0.03740114 ...,  0.01368927  0.02930543\n",
      "   0.02177181]\n",
      " [ 0.02192977  0.03848955  0.03740114 ...,  0.01368927  0.02930543\n",
      "   0.02177181]]\n",
      "[ 8 16 19 ..., 19 19 19]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   2.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.595919\tBest loss: 4.595919\tAccuracy: 2.80%\n",
      "1\tValidation loss: 3.814559\tBest loss: 3.814559\tAccuracy: 3.70%\n",
      "2\tValidation loss: 3.800024\tBest loss: 3.800024\tAccuracy: 3.20%\n",
      "3\tValidation loss: 3.796833\tBest loss: 3.796833\tAccuracy: 4.00%\n",
      "4\tValidation loss: 3.795802\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.801009\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.802273\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "7\tValidation loss: 3.797709\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.796630\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.796173\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "10\tValidation loss: 3.801068\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.798554\tBest loss: 3.795802\tAccuracy: 4.00%\n",
      "12\tValidation loss: 3.796694\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.796104\tBest loss: 3.795802\tAccuracy: 4.00%\n",
      "14\tValidation loss: 3.797856\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.799369\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.797369\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.800727\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.802108\tBest loss: 3.795802\tAccuracy: 3.00%\n",
      "19\tValidation loss: 3.796682\tBest loss: 3.795802\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.799190\tBest loss: 3.795802\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.794454\tBest loss: 3.794454\tAccuracy: 3.20%\n",
      "22\tValidation loss: 3.797690\tBest loss: 3.794454\tAccuracy: 3.20%\n",
      "23\tValidation loss: 3.797006\tBest loss: 3.794454\tAccuracy: 3.20%\n",
      "24\tValidation loss: 3.800283\tBest loss: 3.794454\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.792994\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.798708\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "27\tValidation loss: 3.795042\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.798042\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "29\tValidation loss: 3.799287\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.799726\tBest loss: 3.792994\tAccuracy: 4.00%\n",
      "31\tValidation loss: 3.797763\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.796216\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.802025\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.798262\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.795229\tBest loss: 3.792994\tAccuracy: 4.00%\n",
      "36\tValidation loss: 3.797230\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "37\tValidation loss: 3.796148\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.795805\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.797283\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "40\tValidation loss: 3.794878\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.796289\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "42\tValidation loss: 3.795515\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.800325\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.795318\tBest loss: 3.792994\tAccuracy: 3.20%\n",
      "45\tValidation loss: 3.796123\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.798193\tBest loss: 3.792994\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " ..., \n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " ..., \n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]\n",
      " [ 0.01812766  0.03207837  0.02127543 ...,  0.02796748  0.01722462\n",
      "   0.01812449]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=4, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   3.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 10.485460\tBest loss: 10.485460\tAccuracy: 0.50%\n",
      "1\tValidation loss: 10.070869\tBest loss: 10.070869\tAccuracy: 4.00%\n",
      "2\tValidation loss: 11.482233\tBest loss: 10.070869\tAccuracy: 3.10%\n",
      "3\tValidation loss: 10.983829\tBest loss: 10.070869\tAccuracy: 1.80%\n",
      "4\tValidation loss: 8.333693\tBest loss: 8.333693\tAccuracy: 2.00%\n",
      "5\tValidation loss: 12.849791\tBest loss: 8.333693\tAccuracy: 1.80%\n",
      "6\tValidation loss: 7.897793\tBest loss: 7.897793\tAccuracy: 1.90%\n",
      "7\tValidation loss: 9.882668\tBest loss: 7.897793\tAccuracy: 1.80%\n",
      "8\tValidation loss: 10.490090\tBest loss: 7.897793\tAccuracy: 1.00%\n",
      "9\tValidation loss: 11.941393\tBest loss: 7.897793\tAccuracy: 1.90%\n",
      "10\tValidation loss: 8.599749\tBest loss: 7.897793\tAccuracy: 1.90%\n",
      "11\tValidation loss: 10.610826\tBest loss: 7.897793\tAccuracy: 2.20%\n",
      "12\tValidation loss: 9.811027\tBest loss: 7.897793\tAccuracy: 2.70%\n",
      "13\tValidation loss: 10.526495\tBest loss: 7.897793\tAccuracy: 3.60%\n",
      "14\tValidation loss: 12.745902\tBest loss: 7.897793\tAccuracy: 3.70%\n",
      "15\tValidation loss: 13.112439\tBest loss: 7.897793\tAccuracy: 2.20%\n",
      "16\tValidation loss: 8.169921\tBest loss: 7.897793\tAccuracy: 3.70%\n",
      "17\tValidation loss: 15.176189\tBest loss: 7.897793\tAccuracy: 2.20%\n",
      "18\tValidation loss: 10.164034\tBest loss: 7.897793\tAccuracy: 0.90%\n",
      "19\tValidation loss: 11.968848\tBest loss: 7.897793\tAccuracy: 2.30%\n",
      "20\tValidation loss: 13.005111\tBest loss: 7.897793\tAccuracy: 3.00%\n",
      "21\tValidation loss: 12.397346\tBest loss: 7.897793\tAccuracy: 2.70%\n",
      "22\tValidation loss: 10.414204\tBest loss: 7.897793\tAccuracy: 4.50%\n",
      "23\tValidation loss: 10.007561\tBest loss: 7.897793\tAccuracy: 3.60%\n",
      "24\tValidation loss: 10.565596\tBest loss: 7.897793\tAccuracy: 0.50%\n",
      "25\tValidation loss: 9.067800\tBest loss: 7.897793\tAccuracy: 3.60%\n",
      "26\tValidation loss: 9.042507\tBest loss: 7.897793\tAccuracy: 3.20%\n",
      "27\tValidation loss: 9.472088\tBest loss: 7.897793\tAccuracy: 1.40%\n",
      "Early stopping!\n",
      "[[  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " ..., \n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]]\n",
      "[39 39 39 ..., 39 39 39]\n",
      "[[  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " ..., \n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]\n",
      " [  1.64691683e-05   5.44700166e-03   2.55607674e-03 ...,   1.65476534e-03\n",
      "    1.34708564e-04   1.40058557e-06]]\n",
      "[39 39 39 ..., 39 39 39]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=   9.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 10.246563\tBest loss: 10.246563\tAccuracy: 1.90%\n",
      "1\tValidation loss: 12.441072\tBest loss: 10.246563\tAccuracy: 3.60%\n",
      "2\tValidation loss: 11.172643\tBest loss: 10.246563\tAccuracy: 3.60%\n",
      "3\tValidation loss: 12.077017\tBest loss: 10.246563\tAccuracy: 2.60%\n",
      "4\tValidation loss: 9.203952\tBest loss: 9.203952\tAccuracy: 1.90%\n",
      "5\tValidation loss: 8.896609\tBest loss: 8.896609\tAccuracy: 1.10%\n",
      "6\tValidation loss: 11.981220\tBest loss: 8.896609\tAccuracy: 1.80%\n",
      "7\tValidation loss: 11.468636\tBest loss: 8.896609\tAccuracy: 2.20%\n",
      "8\tValidation loss: 14.226768\tBest loss: 8.896609\tAccuracy: 1.00%\n",
      "9\tValidation loss: 9.089437\tBest loss: 8.896609\tAccuracy: 4.00%\n",
      "10\tValidation loss: 11.481721\tBest loss: 8.896609\tAccuracy: 3.10%\n",
      "11\tValidation loss: 10.383935\tBest loss: 8.896609\tAccuracy: 4.00%\n",
      "12\tValidation loss: 11.496677\tBest loss: 8.896609\tAccuracy: 2.50%\n",
      "13\tValidation loss: 10.277830\tBest loss: 8.896609\tAccuracy: 3.70%\n",
      "14\tValidation loss: 10.642259\tBest loss: 8.896609\tAccuracy: 2.30%\n",
      "15\tValidation loss: 12.736467\tBest loss: 8.896609\tAccuracy: 3.20%\n",
      "16\tValidation loss: 10.961651\tBest loss: 8.896609\tAccuracy: 3.70%\n",
      "17\tValidation loss: 9.487722\tBest loss: 8.896609\tAccuracy: 3.60%\n",
      "18\tValidation loss: 8.775013\tBest loss: 8.775013\tAccuracy: 4.00%\n",
      "19\tValidation loss: 8.956414\tBest loss: 8.775013\tAccuracy: 2.00%\n",
      "20\tValidation loss: 10.096754\tBest loss: 8.775013\tAccuracy: 3.00%\n",
      "21\tValidation loss: 11.416050\tBest loss: 8.775013\tAccuracy: 2.20%\n",
      "22\tValidation loss: 11.018660\tBest loss: 8.775013\tAccuracy: 1.90%\n",
      "23\tValidation loss: 11.243210\tBest loss: 8.775013\tAccuracy: 2.00%\n",
      "24\tValidation loss: 9.465412\tBest loss: 8.775013\tAccuracy: 2.20%\n",
      "25\tValidation loss: 9.559531\tBest loss: 8.775013\tAccuracy: 1.20%\n",
      "26\tValidation loss: 7.580089\tBest loss: 7.580089\tAccuracy: 1.70%\n",
      "27\tValidation loss: 13.739872\tBest loss: 7.580089\tAccuracy: 1.90%\n",
      "28\tValidation loss: 11.006673\tBest loss: 7.580089\tAccuracy: 1.60%\n",
      "29\tValidation loss: 7.533243\tBest loss: 7.533243\tAccuracy: 1.00%\n",
      "30\tValidation loss: 13.055021\tBest loss: 7.533243\tAccuracy: 1.90%\n",
      "31\tValidation loss: 9.312652\tBest loss: 7.533243\tAccuracy: 3.20%\n",
      "32\tValidation loss: 14.260114\tBest loss: 7.533243\tAccuracy: 1.50%\n",
      "33\tValidation loss: 12.716275\tBest loss: 7.533243\tAccuracy: 1.90%\n",
      "34\tValidation loss: 7.823692\tBest loss: 7.533243\tAccuracy: 3.20%\n",
      "35\tValidation loss: 10.094067\tBest loss: 7.533243\tAccuracy: 4.00%\n",
      "36\tValidation loss: 10.903952\tBest loss: 7.533243\tAccuracy: 2.30%\n",
      "37\tValidation loss: 10.147937\tBest loss: 7.533243\tAccuracy: 2.30%\n",
      "38\tValidation loss: 10.055370\tBest loss: 7.533243\tAccuracy: 1.20%\n",
      "39\tValidation loss: 10.575348\tBest loss: 7.533243\tAccuracy: 3.70%\n",
      "40\tValidation loss: 10.521534\tBest loss: 7.533243\tAccuracy: 3.20%\n",
      "41\tValidation loss: 8.099583\tBest loss: 7.533243\tAccuracy: 4.50%\n",
      "42\tValidation loss: 12.918015\tBest loss: 7.533243\tAccuracy: 2.20%\n",
      "43\tValidation loss: 12.246859\tBest loss: 7.533243\tAccuracy: 2.70%\n",
      "44\tValidation loss: 8.638856\tBest loss: 7.533243\tAccuracy: 2.30%\n",
      "45\tValidation loss: 10.138820\tBest loss: 7.533243\tAccuracy: 3.10%\n",
      "46\tValidation loss: 9.265826\tBest loss: 7.533243\tAccuracy: 2.30%\n",
      "47\tValidation loss: 12.629797\tBest loss: 7.533243\tAccuracy: 2.60%\n",
      "48\tValidation loss: 10.432932\tBest loss: 7.533243\tAccuracy: 2.50%\n",
      "49\tValidation loss: 11.545984\tBest loss: 7.533243\tAccuracy: 0.50%\n",
      "50\tValidation loss: 10.754876\tBest loss: 7.533243\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[[  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " ..., \n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]]\n",
      "[40 40 40 ..., 40 40 40]\n",
      "[[  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " ..., \n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]\n",
      " [  8.24229233e-03   1.28873406e-04   2.82131350e-05 ...,   9.75126028e-02\n",
      "    1.14993015e-02   1.65573256e-05]]\n",
      "[40 40 40 ..., 40 40 40]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=  16.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 11.419352\tBest loss: 11.419352\tAccuracy: 4.10%\n",
      "1\tValidation loss: 10.780404\tBest loss: 10.780404\tAccuracy: 2.00%\n",
      "2\tValidation loss: 8.503694\tBest loss: 8.503694\tAccuracy: 0.90%\n",
      "3\tValidation loss: 11.662046\tBest loss: 8.503694\tAccuracy: 1.40%\n",
      "4\tValidation loss: 11.168734\tBest loss: 8.503694\tAccuracy: 1.40%\n",
      "5\tValidation loss: 11.381472\tBest loss: 8.503694\tAccuracy: 4.00%\n",
      "6\tValidation loss: 10.500916\tBest loss: 8.503694\tAccuracy: 1.80%\n",
      "7\tValidation loss: 10.141942\tBest loss: 8.503694\tAccuracy: 0.90%\n",
      "8\tValidation loss: 10.139604\tBest loss: 8.503694\tAccuracy: 1.20%\n",
      "9\tValidation loss: 10.522568\tBest loss: 8.503694\tAccuracy: 3.20%\n",
      "10\tValidation loss: 9.648532\tBest loss: 8.503694\tAccuracy: 3.60%\n",
      "11\tValidation loss: 12.637619\tBest loss: 8.503694\tAccuracy: 2.50%\n",
      "12\tValidation loss: 9.709320\tBest loss: 8.503694\tAccuracy: 1.40%\n",
      "13\tValidation loss: 11.109625\tBest loss: 8.503694\tAccuracy: 1.90%\n",
      "14\tValidation loss: 7.209196\tBest loss: 7.209196\tAccuracy: 1.90%\n",
      "15\tValidation loss: 9.541753\tBest loss: 7.209196\tAccuracy: 1.60%\n",
      "16\tValidation loss: 8.719304\tBest loss: 7.209196\tAccuracy: 1.80%\n",
      "17\tValidation loss: 12.214835\tBest loss: 7.209196\tAccuracy: 1.70%\n",
      "18\tValidation loss: 8.681836\tBest loss: 7.209196\tAccuracy: 1.50%\n",
      "19\tValidation loss: 11.641488\tBest loss: 7.209196\tAccuracy: 2.20%\n",
      "20\tValidation loss: 10.725759\tBest loss: 7.209196\tAccuracy: 3.70%\n",
      "21\tValidation loss: 12.472015\tBest loss: 7.209196\tAccuracy: 3.70%\n",
      "22\tValidation loss: 10.993315\tBest loss: 7.209196\tAccuracy: 3.70%\n",
      "23\tValidation loss: 10.334344\tBest loss: 7.209196\tAccuracy: 1.80%\n",
      "24\tValidation loss: 13.186731\tBest loss: 7.209196\tAccuracy: 3.70%\n",
      "25\tValidation loss: 12.146129\tBest loss: 7.209196\tAccuracy: 1.80%\n",
      "26\tValidation loss: 11.758987\tBest loss: 7.209196\tAccuracy: 1.90%\n",
      "27\tValidation loss: 13.007254\tBest loss: 7.209196\tAccuracy: 1.70%\n",
      "28\tValidation loss: 11.430436\tBest loss: 7.209196\tAccuracy: 1.70%\n",
      "29\tValidation loss: 8.559631\tBest loss: 7.209196\tAccuracy: 1.90%\n",
      "30\tValidation loss: 8.212331\tBest loss: 7.209196\tAccuracy: 1.70%\n",
      "31\tValidation loss: 10.015172\tBest loss: 7.209196\tAccuracy: 3.70%\n",
      "32\tValidation loss: 10.716557\tBest loss: 7.209196\tAccuracy: 3.30%\n",
      "33\tValidation loss: 11.931690\tBest loss: 7.209196\tAccuracy: 1.40%\n",
      "34\tValidation loss: 10.512431\tBest loss: 7.209196\tAccuracy: 2.20%\n",
      "35\tValidation loss: 17.526579\tBest loss: 7.209196\tAccuracy: 2.30%\n",
      "Early stopping!\n",
      "[[ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " ..., \n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " ..., \n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]\n",
      " [ 0.41094789  0.02622296  0.01246877 ...,  0.00576394  0.00856756\n",
      "   0.03154609]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=3, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=  11.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.039748\tBest loss: 4.039748\tAccuracy: 4.20%\n",
      "1\tValidation loss: 3.803979\tBest loss: 3.803979\tAccuracy: 6.00%\n",
      "2\tValidation loss: 3.858112\tBest loss: 3.803979\tAccuracy: 6.40%\n",
      "3\tValidation loss: 3.793397\tBest loss: 3.793397\tAccuracy: 4.00%\n",
      "4\tValidation loss: 3.874547\tBest loss: 3.793397\tAccuracy: 4.90%\n",
      "5\tValidation loss: 7.092836\tBest loss: 3.793397\tAccuracy: 4.80%\n",
      "6\tValidation loss: 4.077231\tBest loss: 3.793397\tAccuracy: 8.70%\n",
      "7\tValidation loss: 11.344271\tBest loss: 3.793397\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.522328\tBest loss: 3.522328\tAccuracy: 9.00%\n",
      "9\tValidation loss: 3.993443\tBest loss: 3.522328\tAccuracy: 8.40%\n",
      "10\tValidation loss: 3.538634\tBest loss: 3.522328\tAccuracy: 13.80%\n",
      "11\tValidation loss: 3.805842\tBest loss: 3.522328\tAccuracy: 9.60%\n",
      "12\tValidation loss: 3.618888\tBest loss: 3.522328\tAccuracy: 11.10%\n",
      "13\tValidation loss: 4.057398\tBest loss: 3.522328\tAccuracy: 10.90%\n",
      "14\tValidation loss: 11.546278\tBest loss: 3.522328\tAccuracy: 6.60%\n",
      "15\tValidation loss: 3.627421\tBest loss: 3.522328\tAccuracy: 16.80%\n",
      "16\tValidation loss: 3.768641\tBest loss: 3.522328\tAccuracy: 10.60%\n",
      "17\tValidation loss: 4.189570\tBest loss: 3.522328\tAccuracy: 16.50%\n",
      "18\tValidation loss: 4.478990\tBest loss: 3.522328\tAccuracy: 8.90%\n",
      "19\tValidation loss: 15.039012\tBest loss: 3.522328\tAccuracy: 7.20%\n",
      "20\tValidation loss: 3.038098\tBest loss: 3.038098\tAccuracy: 21.80%\n",
      "21\tValidation loss: 3.137509\tBest loss: 3.038098\tAccuracy: 18.70%\n",
      "22\tValidation loss: 3.917127\tBest loss: 3.038098\tAccuracy: 13.20%\n",
      "23\tValidation loss: 2.983382\tBest loss: 2.983382\tAccuracy: 20.00%\n",
      "24\tValidation loss: 2.999848\tBest loss: 2.983382\tAccuracy: 23.40%\n",
      "25\tValidation loss: 2.845403\tBest loss: 2.845403\tAccuracy: 27.40%\n",
      "26\tValidation loss: 2.662106\tBest loss: 2.662106\tAccuracy: 30.30%\n",
      "27\tValidation loss: 2.699148\tBest loss: 2.662106\tAccuracy: 25.50%\n",
      "28\tValidation loss: 3.468013\tBest loss: 2.662106\tAccuracy: 22.20%\n",
      "29\tValidation loss: 3.562188\tBest loss: 2.662106\tAccuracy: 17.60%\n",
      "30\tValidation loss: 2.734633\tBest loss: 2.662106\tAccuracy: 27.50%\n",
      "31\tValidation loss: 2.987547\tBest loss: 2.662106\tAccuracy: 26.20%\n",
      "32\tValidation loss: 2.623051\tBest loss: 2.623051\tAccuracy: 33.70%\n",
      "33\tValidation loss: 3.860062\tBest loss: 2.623051\tAccuracy: 19.60%\n",
      "34\tValidation loss: 2.438492\tBest loss: 2.438492\tAccuracy: 33.30%\n",
      "35\tValidation loss: 2.830005\tBest loss: 2.438492\tAccuracy: 28.80%\n",
      "36\tValidation loss: 4.023492\tBest loss: 2.438492\tAccuracy: 18.40%\n",
      "37\tValidation loss: 2.477445\tBest loss: 2.438492\tAccuracy: 36.50%\n",
      "38\tValidation loss: 2.907509\tBest loss: 2.438492\tAccuracy: 35.50%\n",
      "39\tValidation loss: 3.037342\tBest loss: 2.438492\tAccuracy: 28.60%\n",
      "40\tValidation loss: 2.850968\tBest loss: 2.438492\tAccuracy: 30.20%\n",
      "41\tValidation loss: 3.260465\tBest loss: 2.438492\tAccuracy: 31.60%\n",
      "42\tValidation loss: 2.412995\tBest loss: 2.412995\tAccuracy: 36.80%\n",
      "43\tValidation loss: 2.404868\tBest loss: 2.404868\tAccuracy: 40.40%\n",
      "44\tValidation loss: 2.464811\tBest loss: 2.404868\tAccuracy: 38.80%\n",
      "45\tValidation loss: 3.404386\tBest loss: 2.404868\tAccuracy: 36.30%\n",
      "46\tValidation loss: 2.493907\tBest loss: 2.404868\tAccuracy: 39.80%\n",
      "47\tValidation loss: 2.239158\tBest loss: 2.239158\tAccuracy: 43.70%\n",
      "48\tValidation loss: 2.282037\tBest loss: 2.239158\tAccuracy: 43.90%\n",
      "49\tValidation loss: 3.536664\tBest loss: 2.239158\tAccuracy: 30.80%\n",
      "50\tValidation loss: 2.745347\tBest loss: 2.239158\tAccuracy: 35.80%\n",
      "51\tValidation loss: 2.545172\tBest loss: 2.239158\tAccuracy: 37.40%\n",
      "52\tValidation loss: 2.302064\tBest loss: 2.239158\tAccuracy: 45.50%\n",
      "53\tValidation loss: 2.411937\tBest loss: 2.239158\tAccuracy: 46.10%\n",
      "54\tValidation loss: 2.189716\tBest loss: 2.189716\tAccuracy: 45.90%\n",
      "55\tValidation loss: 2.222092\tBest loss: 2.189716\tAccuracy: 45.50%\n",
      "56\tValidation loss: 2.974161\tBest loss: 2.189716\tAccuracy: 43.20%\n",
      "57\tValidation loss: 2.791407\tBest loss: 2.189716\tAccuracy: 43.00%\n",
      "58\tValidation loss: 2.487471\tBest loss: 2.189716\tAccuracy: 44.80%\n",
      "59\tValidation loss: 3.403763\tBest loss: 2.189716\tAccuracy: 35.40%\n",
      "60\tValidation loss: 2.425282\tBest loss: 2.189716\tAccuracy: 53.60%\n",
      "61\tValidation loss: 3.879779\tBest loss: 2.189716\tAccuracy: 40.30%\n",
      "62\tValidation loss: 3.246992\tBest loss: 2.189716\tAccuracy: 41.60%\n",
      "63\tValidation loss: 2.326081\tBest loss: 2.189716\tAccuracy: 51.30%\n",
      "64\tValidation loss: 2.827131\tBest loss: 2.189716\tAccuracy: 41.90%\n",
      "65\tValidation loss: 2.827662\tBest loss: 2.189716\tAccuracy: 45.70%\n",
      "66\tValidation loss: 2.096697\tBest loss: 2.096697\tAccuracy: 57.30%\n",
      "67\tValidation loss: 2.458341\tBest loss: 2.096697\tAccuracy: 53.70%\n",
      "68\tValidation loss: 2.421799\tBest loss: 2.096697\tAccuracy: 56.00%\n",
      "69\tValidation loss: 2.742348\tBest loss: 2.096697\tAccuracy: 48.20%\n",
      "70\tValidation loss: 2.664133\tBest loss: 2.096697\tAccuracy: 52.60%\n",
      "71\tValidation loss: 2.128281\tBest loss: 2.096697\tAccuracy: 56.20%\n",
      "72\tValidation loss: 2.150693\tBest loss: 2.096697\tAccuracy: 57.30%\n",
      "73\tValidation loss: 2.316673\tBest loss: 2.096697\tAccuracy: 53.60%\n",
      "74\tValidation loss: 2.430254\tBest loss: 2.096697\tAccuracy: 55.20%\n",
      "75\tValidation loss: 3.170094\tBest loss: 2.096697\tAccuracy: 49.70%\n",
      "76\tValidation loss: 2.223334\tBest loss: 2.096697\tAccuracy: 61.20%\n",
      "77\tValidation loss: 2.524449\tBest loss: 2.096697\tAccuracy: 51.10%\n",
      "78\tValidation loss: 2.503852\tBest loss: 2.096697\tAccuracy: 54.00%\n",
      "79\tValidation loss: 2.355295\tBest loss: 2.096697\tAccuracy: 58.50%\n",
      "80\tValidation loss: 2.006092\tBest loss: 2.006092\tAccuracy: 65.00%\n",
      "81\tValidation loss: 2.249429\tBest loss: 2.006092\tAccuracy: 57.90%\n",
      "82\tValidation loss: 2.294147\tBest loss: 2.006092\tAccuracy: 56.90%\n",
      "83\tValidation loss: 2.680145\tBest loss: 2.006092\tAccuracy: 56.10%\n",
      "84\tValidation loss: 2.652977\tBest loss: 2.006092\tAccuracy: 53.20%\n",
      "85\tValidation loss: 3.308606\tBest loss: 2.006092\tAccuracy: 49.80%\n",
      "86\tValidation loss: 3.076967\tBest loss: 2.006092\tAccuracy: 52.50%\n",
      "87\tValidation loss: 3.128586\tBest loss: 2.006092\tAccuracy: 52.80%\n",
      "88\tValidation loss: 2.225316\tBest loss: 2.006092\tAccuracy: 62.90%\n",
      "89\tValidation loss: 3.662428\tBest loss: 2.006092\tAccuracy: 54.10%\n",
      "90\tValidation loss: 2.604615\tBest loss: 2.006092\tAccuracy: 59.50%\n",
      "91\tValidation loss: 2.368363\tBest loss: 2.006092\tAccuracy: 63.70%\n",
      "92\tValidation loss: 2.641131\tBest loss: 2.006092\tAccuracy: 66.20%\n",
      "93\tValidation loss: 2.597916\tBest loss: 2.006092\tAccuracy: 65.70%\n",
      "94\tValidation loss: 3.279566\tBest loss: 2.006092\tAccuracy: 53.00%\n",
      "95\tValidation loss: 4.963017\tBest loss: 2.006092\tAccuracy: 46.30%\n",
      "96\tValidation loss: 2.330103\tBest loss: 2.006092\tAccuracy: 65.80%\n",
      "97\tValidation loss: 2.498859\tBest loss: 2.006092\tAccuracy: 65.70%\n",
      "98\tValidation loss: 2.617678\tBest loss: 2.006092\tAccuracy: 64.90%\n",
      "99\tValidation loss: 2.587376\tBest loss: 2.006092\tAccuracy: 62.90%\n",
      "100\tValidation loss: 2.990109\tBest loss: 2.006092\tAccuracy: 56.20%\n",
      "101\tValidation loss: 2.469275\tBest loss: 2.006092\tAccuracy: 66.20%\n",
      "Early stopping!\n",
      "[[  7.59469265e-10   5.11707867e-08   5.02868325e-08 ...,   9.23460846e-07\n",
      "    8.33095110e-05   1.41246187e-06]\n",
      " [  1.27914501e-03   7.80709524e-06   3.00206875e-06 ...,   1.05017087e-07\n",
      "    1.57953349e-12   6.77578382e-10]\n",
      " [  1.60552311e-15   6.73268486e-24   1.90705451e-10 ...,   4.38402925e-11\n",
      "    2.32956957e-16   2.08351384e-20]\n",
      " ..., \n",
      " [  4.88374620e-19   4.49142231e-17   1.33729421e-17 ...,   4.99214602e-12\n",
      "    2.69948419e-08   5.11884285e-12]\n",
      " [  3.08991782e-03   1.24282669e-03   6.16995106e-03 ...,   4.03608590e-01\n",
      "    3.14814411e-02   2.19643880e-02]\n",
      " [  8.32177209e-12   7.66663903e-12   7.70967379e-09 ...,   3.32029771e-07\n",
      "    2.04347799e-07   2.74992926e-05]]\n",
      "[42 19 16 ..., 21 45 36]\n",
      "[[  2.03961157e-03   4.11015790e-04   5.02533838e-03 ...,   8.01351038e-04\n",
      "    2.70690816e-05   4.84346492e-05]\n",
      " [  5.52263491e-15   3.20904679e-15   6.03639317e-14 ...,   3.70282277e-12\n",
      "    2.91520443e-13   5.11113267e-14]\n",
      " [  1.00197219e-10   2.62773933e-13   7.72123486e-24 ...,   8.07694098e-19\n",
      "    1.77604038e-29   3.61488090e-25]\n",
      " ..., \n",
      " [  9.40697832e-27   4.28089738e-28   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.10269309e-06   1.94615168e-07   9.62938770e-07 ...,   8.11552400e-06\n",
      "    1.76548050e-03   2.40365480e-04]\n",
      " [  4.28821633e-29   9.26112077e-30   9.61931308e-24 ...,   1.09516004e-05\n",
      "    6.15743261e-08   8.92254949e-01]]\n",
      "[38 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   5.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.940228\tBest loss: 3.940228\tAccuracy: 4.50%\n",
      "1\tValidation loss: 3.840739\tBest loss: 3.840739\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.840831\tBest loss: 3.840739\tAccuracy: 4.20%\n",
      "3\tValidation loss: 3.757210\tBest loss: 3.757210\tAccuracy: 6.30%\n",
      "4\tValidation loss: 3.789182\tBest loss: 3.757210\tAccuracy: 5.90%\n",
      "5\tValidation loss: 5.275306\tBest loss: 3.757210\tAccuracy: 5.00%\n",
      "6\tValidation loss: 5.484539\tBest loss: 3.757210\tAccuracy: 5.30%\n",
      "7\tValidation loss: 3.740162\tBest loss: 3.740162\tAccuracy: 7.80%\n",
      "8\tValidation loss: 3.860444\tBest loss: 3.740162\tAccuracy: 5.40%\n",
      "9\tValidation loss: 3.686765\tBest loss: 3.686765\tAccuracy: 7.30%\n",
      "10\tValidation loss: 23.309383\tBest loss: 3.686765\tAccuracy: 1.50%\n",
      "11\tValidation loss: 3.531772\tBest loss: 3.531772\tAccuracy: 11.80%\n",
      "12\tValidation loss: 4.146548\tBest loss: 3.531772\tAccuracy: 9.80%\n",
      "13\tValidation loss: 3.583512\tBest loss: 3.531772\tAccuracy: 12.40%\n",
      "14\tValidation loss: 4.736096\tBest loss: 3.531772\tAccuracy: 12.40%\n",
      "15\tValidation loss: 3.484730\tBest loss: 3.484730\tAccuracy: 14.90%\n",
      "16\tValidation loss: 3.373221\tBest loss: 3.373221\tAccuracy: 14.60%\n",
      "17\tValidation loss: 3.226307\tBest loss: 3.226307\tAccuracy: 14.60%\n",
      "18\tValidation loss: 3.348924\tBest loss: 3.226307\tAccuracy: 17.20%\n",
      "19\tValidation loss: 3.029325\tBest loss: 3.029325\tAccuracy: 20.60%\n",
      "20\tValidation loss: 3.766789\tBest loss: 3.029325\tAccuracy: 11.90%\n",
      "21\tValidation loss: 3.092781\tBest loss: 3.029325\tAccuracy: 19.70%\n",
      "22\tValidation loss: 3.348187\tBest loss: 3.029325\tAccuracy: 17.80%\n",
      "23\tValidation loss: 3.065484\tBest loss: 3.029325\tAccuracy: 22.10%\n",
      "24\tValidation loss: 8.880488\tBest loss: 3.029325\tAccuracy: 10.80%\n",
      "25\tValidation loss: 3.419837\tBest loss: 3.029325\tAccuracy: 19.70%\n",
      "26\tValidation loss: 3.428718\tBest loss: 3.029325\tAccuracy: 17.80%\n",
      "27\tValidation loss: 3.519044\tBest loss: 3.029325\tAccuracy: 19.40%\n",
      "28\tValidation loss: 3.168927\tBest loss: 3.029325\tAccuracy: 20.90%\n",
      "29\tValidation loss: 3.459483\tBest loss: 3.029325\tAccuracy: 20.10%\n",
      "30\tValidation loss: 3.290298\tBest loss: 3.029325\tAccuracy: 21.20%\n",
      "31\tValidation loss: 2.866345\tBest loss: 2.866345\tAccuracy: 25.50%\n",
      "32\tValidation loss: 2.606925\tBest loss: 2.606925\tAccuracy: 31.40%\n",
      "33\tValidation loss: 3.037965\tBest loss: 2.606925\tAccuracy: 23.50%\n",
      "34\tValidation loss: 2.720287\tBest loss: 2.606925\tAccuracy: 28.10%\n",
      "35\tValidation loss: 3.244586\tBest loss: 2.606925\tAccuracy: 24.30%\n",
      "36\tValidation loss: 2.812136\tBest loss: 2.606925\tAccuracy: 28.20%\n",
      "37\tValidation loss: 2.883589\tBest loss: 2.606925\tAccuracy: 27.70%\n",
      "38\tValidation loss: 5.653586\tBest loss: 2.606925\tAccuracy: 18.10%\n",
      "39\tValidation loss: 2.722435\tBest loss: 2.606925\tAccuracy: 30.00%\n",
      "40\tValidation loss: 2.888333\tBest loss: 2.606925\tAccuracy: 30.40%\n",
      "41\tValidation loss: 2.582112\tBest loss: 2.582112\tAccuracy: 33.10%\n",
      "42\tValidation loss: 3.181284\tBest loss: 2.582112\tAccuracy: 26.60%\n",
      "43\tValidation loss: 2.727634\tBest loss: 2.582112\tAccuracy: 33.00%\n",
      "44\tValidation loss: 2.634872\tBest loss: 2.582112\tAccuracy: 38.30%\n",
      "45\tValidation loss: 2.469072\tBest loss: 2.469072\tAccuracy: 37.90%\n",
      "46\tValidation loss: 2.601156\tBest loss: 2.469072\tAccuracy: 33.80%\n",
      "47\tValidation loss: 2.419719\tBest loss: 2.419719\tAccuracy: 34.10%\n",
      "48\tValidation loss: 2.425926\tBest loss: 2.419719\tAccuracy: 38.40%\n",
      "49\tValidation loss: 2.623544\tBest loss: 2.419719\tAccuracy: 31.50%\n",
      "50\tValidation loss: 3.032076\tBest loss: 2.419719\tAccuracy: 32.10%\n",
      "51\tValidation loss: 2.851383\tBest loss: 2.419719\tAccuracy: 32.50%\n",
      "52\tValidation loss: 2.931967\tBest loss: 2.419719\tAccuracy: 31.20%\n",
      "53\tValidation loss: 2.489039\tBest loss: 2.419719\tAccuracy: 39.70%\n",
      "54\tValidation loss: 2.194614\tBest loss: 2.194614\tAccuracy: 44.20%\n",
      "55\tValidation loss: 2.164050\tBest loss: 2.164050\tAccuracy: 44.40%\n",
      "56\tValidation loss: 2.241114\tBest loss: 2.164050\tAccuracy: 48.10%\n",
      "57\tValidation loss: 3.876819\tBest loss: 2.164050\tAccuracy: 27.80%\n",
      "58\tValidation loss: 2.865539\tBest loss: 2.164050\tAccuracy: 39.90%\n",
      "59\tValidation loss: 2.930430\tBest loss: 2.164050\tAccuracy: 37.80%\n",
      "60\tValidation loss: 3.448009\tBest loss: 2.164050\tAccuracy: 42.40%\n",
      "61\tValidation loss: 2.725115\tBest loss: 2.164050\tAccuracy: 39.80%\n",
      "62\tValidation loss: 2.723008\tBest loss: 2.164050\tAccuracy: 40.90%\n",
      "63\tValidation loss: 2.294580\tBest loss: 2.164050\tAccuracy: 44.90%\n",
      "64\tValidation loss: 3.901855\tBest loss: 2.164050\tAccuracy: 34.00%\n",
      "65\tValidation loss: 2.359431\tBest loss: 2.164050\tAccuracy: 47.40%\n",
      "66\tValidation loss: 2.297075\tBest loss: 2.164050\tAccuracy: 48.80%\n",
      "67\tValidation loss: 2.393927\tBest loss: 2.164050\tAccuracy: 49.40%\n",
      "68\tValidation loss: 2.640076\tBest loss: 2.164050\tAccuracy: 46.60%\n",
      "69\tValidation loss: 3.382432\tBest loss: 2.164050\tAccuracy: 40.30%\n",
      "70\tValidation loss: 2.222514\tBest loss: 2.164050\tAccuracy: 54.40%\n",
      "71\tValidation loss: 3.361809\tBest loss: 2.164050\tAccuracy: 40.90%\n",
      "72\tValidation loss: 2.680811\tBest loss: 2.164050\tAccuracy: 49.30%\n",
      "73\tValidation loss: 2.175107\tBest loss: 2.164050\tAccuracy: 51.90%\n",
      "74\tValidation loss: 4.348230\tBest loss: 2.164050\tAccuracy: 40.60%\n",
      "75\tValidation loss: 2.489067\tBest loss: 2.164050\tAccuracy: 51.00%\n",
      "76\tValidation loss: 2.467342\tBest loss: 2.164050\tAccuracy: 52.80%\n",
      "Early stopping!\n",
      "[[  3.12560168e-03   2.92141060e-03   4.64671617e-03 ...,   3.00390739e-03\n",
      "    1.21589117e-04   3.83071194e-04]\n",
      " [  6.61076194e-11   4.00412897e-10   1.53965451e-09 ...,   3.49844242e-07\n",
      "    7.55398105e-06   1.68405022e-05]\n",
      " [  5.27210068e-06   2.93736884e-05   2.87424955e-05 ...,   9.84331273e-05\n",
      "    9.63928869e-06   4.30126711e-05]\n",
      " ..., \n",
      " [  5.99695777e-04   2.56075262e-04   7.48193124e-03 ...,   1.08220316e-02\n",
      "    1.23926420e-02   2.28348952e-02]\n",
      " [  1.20591815e-03   1.30942638e-03   1.20673038e-03 ...,   6.86747879e-02\n",
      "    2.37809978e-02   3.87789533e-02]\n",
      " [  2.66790116e-13   2.30126226e-12   2.27757965e-10 ...,   2.14076917e-05\n",
      "    6.29405986e-06   3.85406660e-04]]\n",
      "[38  9 43 ..., 36 30 25]\n",
      "[[  2.58008703e-09   1.96768446e-09   1.93590139e-08 ...,   5.60802619e-07\n",
      "    4.98836511e-04   6.87312349e-05]\n",
      " [  1.33064359e-01   4.87297215e-03   6.02847189e-02 ...,   3.27069918e-03\n",
      "    1.22366613e-03   3.82076891e-04]\n",
      " [  2.10011189e-15   2.32931718e-22   4.73239237e-20 ...,   1.43416773e-17\n",
      "    5.92109347e-28   4.27767134e-30]\n",
      " ..., \n",
      " [  8.66252654e-17   1.13208377e-17   1.02481246e-21 ...,   9.19809686e-24\n",
      "    7.36265573e-31   1.01403327e-35]\n",
      " [  1.21563447e-04   3.18888524e-08   1.62786036e-03 ...,   3.14286328e-04\n",
      "    6.16855687e-05   2.94821948e-04]\n",
      " [  2.00166134e-10   1.05476114e-10   1.87223623e-08 ...,   6.34153956e-04\n",
      "    2.71051824e-01   5.68617642e-01]]\n",
      "[20 18 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   4.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 3.977285\tBest loss: 3.977285\tAccuracy: 3.00%\n",
      "1\tValidation loss: 3.851768\tBest loss: 3.851768\tAccuracy: 6.30%\n",
      "2\tValidation loss: 3.778493\tBest loss: 3.778493\tAccuracy: 5.40%\n",
      "3\tValidation loss: 3.676859\tBest loss: 3.676859\tAccuracy: 7.30%\n",
      "4\tValidation loss: 3.549838\tBest loss: 3.549838\tAccuracy: 9.90%\n",
      "5\tValidation loss: 3.573137\tBest loss: 3.549838\tAccuracy: 10.10%\n",
      "6\tValidation loss: 3.517046\tBest loss: 3.517046\tAccuracy: 9.00%\n",
      "7\tValidation loss: 3.223327\tBest loss: 3.223327\tAccuracy: 16.00%\n",
      "8\tValidation loss: 3.531397\tBest loss: 3.223327\tAccuracy: 14.30%\n",
      "9\tValidation loss: 3.216972\tBest loss: 3.216972\tAccuracy: 17.70%\n",
      "10\tValidation loss: 3.001307\tBest loss: 3.001307\tAccuracy: 21.80%\n",
      "11\tValidation loss: 2.848438\tBest loss: 2.848438\tAccuracy: 25.00%\n",
      "12\tValidation loss: 2.766846\tBest loss: 2.766846\tAccuracy: 23.30%\n",
      "13\tValidation loss: 2.526719\tBest loss: 2.526719\tAccuracy: 29.20%\n",
      "14\tValidation loss: 2.847638\tBest loss: 2.526719\tAccuracy: 30.00%\n",
      "15\tValidation loss: 2.523203\tBest loss: 2.523203\tAccuracy: 30.90%\n",
      "16\tValidation loss: 2.827017\tBest loss: 2.523203\tAccuracy: 26.80%\n",
      "17\tValidation loss: 2.441558\tBest loss: 2.441558\tAccuracy: 33.00%\n",
      "18\tValidation loss: 2.566228\tBest loss: 2.441558\tAccuracy: 31.00%\n",
      "19\tValidation loss: 2.643664\tBest loss: 2.441558\tAccuracy: 33.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\tValidation loss: 2.583556\tBest loss: 2.441558\tAccuracy: 31.70%\n",
      "21\tValidation loss: 2.361481\tBest loss: 2.361481\tAccuracy: 39.10%\n",
      "22\tValidation loss: 2.253997\tBest loss: 2.253997\tAccuracy: 38.40%\n",
      "23\tValidation loss: 2.191268\tBest loss: 2.191268\tAccuracy: 39.70%\n",
      "24\tValidation loss: 2.080230\tBest loss: 2.080230\tAccuracy: 40.60%\n",
      "25\tValidation loss: 2.553603\tBest loss: 2.080230\tAccuracy: 39.40%\n",
      "26\tValidation loss: 2.193796\tBest loss: 2.080230\tAccuracy: 41.30%\n",
      "27\tValidation loss: 2.356752\tBest loss: 2.080230\tAccuracy: 37.90%\n",
      "28\tValidation loss: 2.518163\tBest loss: 2.080230\tAccuracy: 37.30%\n",
      "29\tValidation loss: 2.032647\tBest loss: 2.032647\tAccuracy: 45.10%\n",
      "30\tValidation loss: 2.084565\tBest loss: 2.032647\tAccuracy: 46.10%\n",
      "31\tValidation loss: 2.158187\tBest loss: 2.032647\tAccuracy: 45.20%\n",
      "32\tValidation loss: 2.124230\tBest loss: 2.032647\tAccuracy: 46.90%\n",
      "33\tValidation loss: 1.884641\tBest loss: 1.884641\tAccuracy: 49.60%\n",
      "34\tValidation loss: 1.848437\tBest loss: 1.848437\tAccuracy: 52.60%\n",
      "35\tValidation loss: 2.042558\tBest loss: 1.848437\tAccuracy: 49.70%\n",
      "36\tValidation loss: 2.139847\tBest loss: 1.848437\tAccuracy: 45.90%\n",
      "37\tValidation loss: 1.786488\tBest loss: 1.786488\tAccuracy: 55.70%\n",
      "38\tValidation loss: 2.535942\tBest loss: 1.786488\tAccuracy: 43.40%\n",
      "39\tValidation loss: 2.219993\tBest loss: 1.786488\tAccuracy: 46.00%\n",
      "40\tValidation loss: 2.466596\tBest loss: 1.786488\tAccuracy: 45.60%\n",
      "41\tValidation loss: 2.168934\tBest loss: 1.786488\tAccuracy: 50.60%\n",
      "42\tValidation loss: 2.693126\tBest loss: 1.786488\tAccuracy: 48.30%\n",
      "43\tValidation loss: 2.209762\tBest loss: 1.786488\tAccuracy: 53.20%\n",
      "44\tValidation loss: 2.097446\tBest loss: 1.786488\tAccuracy: 51.80%\n",
      "45\tValidation loss: 2.314352\tBest loss: 1.786488\tAccuracy: 54.10%\n",
      "46\tValidation loss: 2.243667\tBest loss: 1.786488\tAccuracy: 53.80%\n",
      "47\tValidation loss: 2.108894\tBest loss: 1.786488\tAccuracy: 54.50%\n",
      "48\tValidation loss: 2.609790\tBest loss: 1.786488\tAccuracy: 54.10%\n",
      "49\tValidation loss: 2.375839\tBest loss: 1.786488\tAccuracy: 52.80%\n",
      "50\tValidation loss: 2.455781\tBest loss: 1.786488\tAccuracy: 55.60%\n",
      "51\tValidation loss: 2.783371\tBest loss: 1.786488\tAccuracy: 48.10%\n",
      "52\tValidation loss: 2.308627\tBest loss: 1.786488\tAccuracy: 54.30%\n",
      "53\tValidation loss: 2.916765\tBest loss: 1.786488\tAccuracy: 40.20%\n",
      "54\tValidation loss: 2.535890\tBest loss: 1.786488\tAccuracy: 55.30%\n",
      "55\tValidation loss: 2.525825\tBest loss: 1.786488\tAccuracy: 55.80%\n",
      "56\tValidation loss: 2.552742\tBest loss: 1.786488\tAccuracy: 55.80%\n",
      "57\tValidation loss: 2.839431\tBest loss: 1.786488\tAccuracy: 51.60%\n",
      "58\tValidation loss: 1.939926\tBest loss: 1.786488\tAccuracy: 59.60%\n",
      "Early stopping!\n",
      "[[  1.75163877e-05   1.21353827e-04   8.11698701e-05 ...,   1.29248435e-03\n",
      "    4.02342053e-08   2.43614022e-06]\n",
      " [  0.00000000e+00   4.49529577e-25   5.55716497e-37 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.31028206e-06   1.38602511e-03   2.30785212e-04 ...,   2.57222496e-07\n",
      "    9.44650892e-05   1.75748020e-04]\n",
      " ..., \n",
      " [  5.35271064e-11   3.76101852e-08   2.68322864e-11 ...,   1.24587575e-16\n",
      "    3.30179965e-15   1.26586047e-19]\n",
      " [  1.16162477e-02   1.60119757e-02   1.54159861e-02 ...,   1.61545612e-02\n",
      "    1.47665581e-02   1.85409673e-02]\n",
      " [  1.47142627e-21   4.16210748e-17   4.21825309e-20 ...,   1.14616287e-05\n",
      "    1.79755986e-01   3.63439947e-01]]\n",
      "[41 41 22 ...,  6 10  8]\n",
      "[[  6.05071182e-06   1.68452284e-03   1.93994096e-03 ...,   3.77917341e-19\n",
      "    6.87985359e-16   1.72354386e-13]\n",
      " [  2.21137926e-02   9.72424224e-02   2.89262682e-02 ...,   1.72072239e-02\n",
      "    9.47187888e-04   8.99791485e-04]\n",
      " [  5.08101014e-14   6.62133493e-23   5.46575112e-12 ...,   1.42043568e-08\n",
      "    2.40478982e-19   1.72486448e-20]\n",
      " ..., \n",
      " [  2.40440451e-04   1.68074330e-05   1.14839023e-03 ...,   1.43610395e-03\n",
      "    2.81975721e-03   1.28365401e-03]\n",
      " [  4.07958636e-04   1.52836019e-05   8.44834358e-05 ...,   3.03138196e-01\n",
      "    6.77763894e-02   1.89050324e-02]\n",
      " [  9.92422394e-11   1.55225361e-08   3.27875769e-12 ...,   7.50750478e-05\n",
      "    1.90528937e-07   1.74684031e-03]]\n",
      "[20 19 18 ..., 36 45 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   3.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 7.571006\tBest loss: 7.571006\tAccuracy: 6.90%\n",
      "1\tValidation loss: 5.729097\tBest loss: 5.729097\tAccuracy: 10.50%\n",
      "2\tValidation loss: 5.834401\tBest loss: 5.729097\tAccuracy: 9.40%\n",
      "3\tValidation loss: 5.987480\tBest loss: 5.729097\tAccuracy: 12.30%\n",
      "4\tValidation loss: 5.524032\tBest loss: 5.524032\tAccuracy: 14.40%\n",
      "5\tValidation loss: 4.413701\tBest loss: 4.413701\tAccuracy: 9.90%\n",
      "6\tValidation loss: 4.231502\tBest loss: 4.231502\tAccuracy: 7.80%\n",
      "7\tValidation loss: 3.421943\tBest loss: 3.421943\tAccuracy: 20.30%\n",
      "8\tValidation loss: 5.174392\tBest loss: 3.421943\tAccuracy: 12.90%\n",
      "9\tValidation loss: 4.018040\tBest loss: 3.421943\tAccuracy: 17.60%\n",
      "10\tValidation loss: 3.456529\tBest loss: 3.421943\tAccuracy: 22.10%\n",
      "11\tValidation loss: 3.412826\tBest loss: 3.412826\tAccuracy: 24.00%\n",
      "12\tValidation loss: 3.235669\tBest loss: 3.235669\tAccuracy: 24.90%\n",
      "13\tValidation loss: 3.277216\tBest loss: 3.235669\tAccuracy: 22.00%\n",
      "14\tValidation loss: 3.184367\tBest loss: 3.184367\tAccuracy: 19.70%\n",
      "15\tValidation loss: 3.370382\tBest loss: 3.184367\tAccuracy: 25.20%\n",
      "16\tValidation loss: 3.116255\tBest loss: 3.116255\tAccuracy: 24.40%\n",
      "17\tValidation loss: 3.144162\tBest loss: 3.116255\tAccuracy: 25.40%\n",
      "18\tValidation loss: 3.250841\tBest loss: 3.116255\tAccuracy: 20.90%\n",
      "19\tValidation loss: 3.023045\tBest loss: 3.023045\tAccuracy: 26.30%\n",
      "20\tValidation loss: 3.345204\tBest loss: 3.023045\tAccuracy: 20.70%\n",
      "21\tValidation loss: 3.245582\tBest loss: 3.023045\tAccuracy: 25.10%\n",
      "22\tValidation loss: 3.050201\tBest loss: 3.023045\tAccuracy: 22.40%\n",
      "23\tValidation loss: 2.962306\tBest loss: 2.962306\tAccuracy: 30.60%\n",
      "24\tValidation loss: 2.996941\tBest loss: 2.962306\tAccuracy: 24.70%\n",
      "25\tValidation loss: 2.930612\tBest loss: 2.930612\tAccuracy: 27.20%\n",
      "26\tValidation loss: 2.908780\tBest loss: 2.908780\tAccuracy: 29.50%\n",
      "27\tValidation loss: 3.130064\tBest loss: 2.908780\tAccuracy: 25.40%\n",
      "28\tValidation loss: 2.863850\tBest loss: 2.863850\tAccuracy: 30.50%\n",
      "29\tValidation loss: 2.902987\tBest loss: 2.863850\tAccuracy: 28.90%\n",
      "30\tValidation loss: 2.870978\tBest loss: 2.863850\tAccuracy: 30.10%\n",
      "31\tValidation loss: 2.941274\tBest loss: 2.863850\tAccuracy: 24.70%\n",
      "32\tValidation loss: 2.947644\tBest loss: 2.863850\tAccuracy: 31.60%\n",
      "33\tValidation loss: 2.883935\tBest loss: 2.863850\tAccuracy: 29.50%\n",
      "34\tValidation loss: 2.816557\tBest loss: 2.816557\tAccuracy: 29.30%\n",
      "35\tValidation loss: 2.839567\tBest loss: 2.816557\tAccuracy: 29.10%\n",
      "36\tValidation loss: 2.810845\tBest loss: 2.810845\tAccuracy: 31.50%\n",
      "37\tValidation loss: 2.851030\tBest loss: 2.810845\tAccuracy: 30.50%\n",
      "38\tValidation loss: 3.144254\tBest loss: 2.810845\tAccuracy: 26.90%\n",
      "39\tValidation loss: 2.924790\tBest loss: 2.810845\tAccuracy: 25.50%\n",
      "40\tValidation loss: 2.963488\tBest loss: 2.810845\tAccuracy: 27.40%\n",
      "41\tValidation loss: 2.988738\tBest loss: 2.810845\tAccuracy: 26.30%\n",
      "42\tValidation loss: 2.752762\tBest loss: 2.752762\tAccuracy: 34.90%\n",
      "43\tValidation loss: 2.821812\tBest loss: 2.752762\tAccuracy: 31.40%\n",
      "44\tValidation loss: 2.731365\tBest loss: 2.731365\tAccuracy: 34.60%\n",
      "45\tValidation loss: 2.799766\tBest loss: 2.731365\tAccuracy: 31.60%\n",
      "46\tValidation loss: 2.724118\tBest loss: 2.724118\tAccuracy: 33.90%\n",
      "47\tValidation loss: 2.743869\tBest loss: 2.724118\tAccuracy: 32.10%\n",
      "48\tValidation loss: 2.714734\tBest loss: 2.714734\tAccuracy: 32.70%\n",
      "49\tValidation loss: 2.716418\tBest loss: 2.714734\tAccuracy: 34.60%\n",
      "50\tValidation loss: 2.756176\tBest loss: 2.714734\tAccuracy: 32.90%\n",
      "51\tValidation loss: 2.755161\tBest loss: 2.714734\tAccuracy: 33.00%\n",
      "52\tValidation loss: 2.761822\tBest loss: 2.714734\tAccuracy: 29.90%\n",
      "53\tValidation loss: 2.656708\tBest loss: 2.656708\tAccuracy: 36.50%\n",
      "54\tValidation loss: 2.663841\tBest loss: 2.656708\tAccuracy: 37.10%\n",
      "55\tValidation loss: 2.688270\tBest loss: 2.656708\tAccuracy: 34.50%\n",
      "56\tValidation loss: 2.664896\tBest loss: 2.656708\tAccuracy: 32.80%\n",
      "57\tValidation loss: 2.660563\tBest loss: 2.656708\tAccuracy: 34.90%\n",
      "58\tValidation loss: 2.637608\tBest loss: 2.637608\tAccuracy: 34.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\tValidation loss: 2.956776\tBest loss: 2.637608\tAccuracy: 27.60%\n",
      "60\tValidation loss: 2.607981\tBest loss: 2.607981\tAccuracy: 36.90%\n",
      "61\tValidation loss: 2.677136\tBest loss: 2.607981\tAccuracy: 34.50%\n",
      "62\tValidation loss: 2.591709\tBest loss: 2.591709\tAccuracy: 36.70%\n",
      "63\tValidation loss: 2.701657\tBest loss: 2.591709\tAccuracy: 34.20%\n",
      "64\tValidation loss: 2.729841\tBest loss: 2.591709\tAccuracy: 32.40%\n",
      "65\tValidation loss: 2.740724\tBest loss: 2.591709\tAccuracy: 31.80%\n",
      "66\tValidation loss: 2.625820\tBest loss: 2.591709\tAccuracy: 33.20%\n",
      "67\tValidation loss: 2.583204\tBest loss: 2.583204\tAccuracy: 37.40%\n",
      "68\tValidation loss: 2.693360\tBest loss: 2.583204\tAccuracy: 33.90%\n",
      "69\tValidation loss: 2.674328\tBest loss: 2.583204\tAccuracy: 32.80%\n",
      "70\tValidation loss: 2.678639\tBest loss: 2.583204\tAccuracy: 29.40%\n",
      "71\tValidation loss: 2.563257\tBest loss: 2.563257\tAccuracy: 38.10%\n",
      "72\tValidation loss: 2.545675\tBest loss: 2.545675\tAccuracy: 38.40%\n",
      "73\tValidation loss: 2.566447\tBest loss: 2.545675\tAccuracy: 35.90%\n",
      "74\tValidation loss: 2.601186\tBest loss: 2.545675\tAccuracy: 35.50%\n",
      "75\tValidation loss: 2.716086\tBest loss: 2.545675\tAccuracy: 34.80%\n",
      "76\tValidation loss: 2.831218\tBest loss: 2.545675\tAccuracy: 31.40%\n",
      "77\tValidation loss: 2.644702\tBest loss: 2.545675\tAccuracy: 33.40%\n",
      "78\tValidation loss: 2.529932\tBest loss: 2.529932\tAccuracy: 37.90%\n",
      "79\tValidation loss: 2.574908\tBest loss: 2.529932\tAccuracy: 36.90%\n",
      "80\tValidation loss: 2.571775\tBest loss: 2.529932\tAccuracy: 35.60%\n",
      "81\tValidation loss: 2.512161\tBest loss: 2.512161\tAccuracy: 39.20%\n",
      "82\tValidation loss: 2.612091\tBest loss: 2.512161\tAccuracy: 35.20%\n",
      "83\tValidation loss: 2.554208\tBest loss: 2.512161\tAccuracy: 35.50%\n",
      "84\tValidation loss: 2.526605\tBest loss: 2.512161\tAccuracy: 39.10%\n",
      "85\tValidation loss: 2.577033\tBest loss: 2.512161\tAccuracy: 34.60%\n",
      "86\tValidation loss: 2.518006\tBest loss: 2.512161\tAccuracy: 38.30%\n",
      "87\tValidation loss: 2.665354\tBest loss: 2.512161\tAccuracy: 31.20%\n",
      "88\tValidation loss: 2.553593\tBest loss: 2.512161\tAccuracy: 37.20%\n",
      "89\tValidation loss: 2.479445\tBest loss: 2.479445\tAccuracy: 37.90%\n",
      "90\tValidation loss: 2.523076\tBest loss: 2.479445\tAccuracy: 37.70%\n",
      "91\tValidation loss: 2.552597\tBest loss: 2.479445\tAccuracy: 36.60%\n",
      "92\tValidation loss: 2.525317\tBest loss: 2.479445\tAccuracy: 37.80%\n",
      "93\tValidation loss: 2.694807\tBest loss: 2.479445\tAccuracy: 38.20%\n",
      "94\tValidation loss: 2.537511\tBest loss: 2.479445\tAccuracy: 37.90%\n",
      "95\tValidation loss: 2.521671\tBest loss: 2.479445\tAccuracy: 37.00%\n",
      "96\tValidation loss: 2.555313\tBest loss: 2.479445\tAccuracy: 36.90%\n",
      "97\tValidation loss: 2.497366\tBest loss: 2.479445\tAccuracy: 38.10%\n",
      "98\tValidation loss: 2.470848\tBest loss: 2.470848\tAccuracy: 40.70%\n",
      "99\tValidation loss: 2.530197\tBest loss: 2.470848\tAccuracy: 38.80%\n",
      "100\tValidation loss: 2.477576\tBest loss: 2.470848\tAccuracy: 38.60%\n",
      "101\tValidation loss: 2.635209\tBest loss: 2.470848\tAccuracy: 32.00%\n",
      "102\tValidation loss: 2.514935\tBest loss: 2.470848\tAccuracy: 36.80%\n",
      "103\tValidation loss: 2.447321\tBest loss: 2.447321\tAccuracy: 39.50%\n",
      "104\tValidation loss: 2.497943\tBest loss: 2.447321\tAccuracy: 36.90%\n",
      "105\tValidation loss: 2.446530\tBest loss: 2.446530\tAccuracy: 40.80%\n",
      "106\tValidation loss: 2.470836\tBest loss: 2.446530\tAccuracy: 37.70%\n",
      "107\tValidation loss: 2.454962\tBest loss: 2.446530\tAccuracy: 38.10%\n",
      "108\tValidation loss: 2.679114\tBest loss: 2.446530\tAccuracy: 31.90%\n",
      "109\tValidation loss: 2.426804\tBest loss: 2.426804\tAccuracy: 39.70%\n",
      "110\tValidation loss: 2.544935\tBest loss: 2.426804\tAccuracy: 35.60%\n",
      "111\tValidation loss: 2.391844\tBest loss: 2.391844\tAccuracy: 43.60%\n",
      "112\tValidation loss: 2.475360\tBest loss: 2.391844\tAccuracy: 36.80%\n",
      "113\tValidation loss: 2.502468\tBest loss: 2.391844\tAccuracy: 40.30%\n",
      "114\tValidation loss: 2.456521\tBest loss: 2.391844\tAccuracy: 40.10%\n",
      "115\tValidation loss: 2.604136\tBest loss: 2.391844\tAccuracy: 34.60%\n",
      "116\tValidation loss: 2.408987\tBest loss: 2.391844\tAccuracy: 41.30%\n",
      "117\tValidation loss: 2.474545\tBest loss: 2.391844\tAccuracy: 36.70%\n",
      "118\tValidation loss: 2.454774\tBest loss: 2.391844\tAccuracy: 38.20%\n",
      "119\tValidation loss: 2.416935\tBest loss: 2.391844\tAccuracy: 39.70%\n",
      "120\tValidation loss: 2.392224\tBest loss: 2.391844\tAccuracy: 40.80%\n",
      "121\tValidation loss: 2.409183\tBest loss: 2.391844\tAccuracy: 41.80%\n",
      "122\tValidation loss: 2.366015\tBest loss: 2.366015\tAccuracy: 40.90%\n",
      "123\tValidation loss: 2.397409\tBest loss: 2.366015\tAccuracy: 41.70%\n",
      "124\tValidation loss: 2.485718\tBest loss: 2.366015\tAccuracy: 36.70%\n",
      "125\tValidation loss: 2.577218\tBest loss: 2.366015\tAccuracy: 31.90%\n",
      "126\tValidation loss: 2.547931\tBest loss: 2.366015\tAccuracy: 35.40%\n",
      "127\tValidation loss: 2.584119\tBest loss: 2.366015\tAccuracy: 34.80%\n",
      "128\tValidation loss: 2.371569\tBest loss: 2.366015\tAccuracy: 40.70%\n",
      "129\tValidation loss: 2.576883\tBest loss: 2.366015\tAccuracy: 34.70%\n",
      "130\tValidation loss: 2.358212\tBest loss: 2.358212\tAccuracy: 40.90%\n",
      "131\tValidation loss: 2.385931\tBest loss: 2.358212\tAccuracy: 38.30%\n",
      "132\tValidation loss: 2.419016\tBest loss: 2.358212\tAccuracy: 39.00%\n",
      "133\tValidation loss: 2.505547\tBest loss: 2.358212\tAccuracy: 37.90%\n",
      "134\tValidation loss: 2.347202\tBest loss: 2.347202\tAccuracy: 42.40%\n",
      "135\tValidation loss: 2.401163\tBest loss: 2.347202\tAccuracy: 39.20%\n",
      "136\tValidation loss: 2.385405\tBest loss: 2.347202\tAccuracy: 40.60%\n",
      "137\tValidation loss: 2.311724\tBest loss: 2.311724\tAccuracy: 44.90%\n",
      "138\tValidation loss: 2.457969\tBest loss: 2.311724\tAccuracy: 35.80%\n",
      "139\tValidation loss: 2.631567\tBest loss: 2.311724\tAccuracy: 33.30%\n",
      "140\tValidation loss: 2.371632\tBest loss: 2.311724\tAccuracy: 39.50%\n",
      "141\tValidation loss: 2.413200\tBest loss: 2.311724\tAccuracy: 38.10%\n",
      "142\tValidation loss: 2.349140\tBest loss: 2.311724\tAccuracy: 41.10%\n",
      "143\tValidation loss: 2.358478\tBest loss: 2.311724\tAccuracy: 40.80%\n",
      "144\tValidation loss: 2.322876\tBest loss: 2.311724\tAccuracy: 41.60%\n",
      "145\tValidation loss: 2.442222\tBest loss: 2.311724\tAccuracy: 38.20%\n",
      "146\tValidation loss: 2.361843\tBest loss: 2.311724\tAccuracy: 39.30%\n",
      "147\tValidation loss: 2.401075\tBest loss: 2.311724\tAccuracy: 39.50%\n",
      "148\tValidation loss: 2.346347\tBest loss: 2.311724\tAccuracy: 42.20%\n",
      "149\tValidation loss: 2.308970\tBest loss: 2.308970\tAccuracy: 42.80%\n",
      "150\tValidation loss: 2.323902\tBest loss: 2.308970\tAccuracy: 41.60%\n",
      "151\tValidation loss: 2.342999\tBest loss: 2.308970\tAccuracy: 41.40%\n",
      "152\tValidation loss: 2.366716\tBest loss: 2.308970\tAccuracy: 38.80%\n",
      "153\tValidation loss: 2.283855\tBest loss: 2.283855\tAccuracy: 43.50%\n",
      "154\tValidation loss: 2.324118\tBest loss: 2.283855\tAccuracy: 41.30%\n",
      "155\tValidation loss: 2.324445\tBest loss: 2.283855\tAccuracy: 39.70%\n",
      "156\tValidation loss: 2.368084\tBest loss: 2.283855\tAccuracy: 42.10%\n",
      "157\tValidation loss: 2.289266\tBest loss: 2.283855\tAccuracy: 45.20%\n",
      "158\tValidation loss: 2.397519\tBest loss: 2.283855\tAccuracy: 40.80%\n",
      "159\tValidation loss: 2.473926\tBest loss: 2.283855\tAccuracy: 38.80%\n",
      "160\tValidation loss: 2.321820\tBest loss: 2.283855\tAccuracy: 40.00%\n",
      "161\tValidation loss: 2.395082\tBest loss: 2.283855\tAccuracy: 37.60%\n",
      "162\tValidation loss: 2.334043\tBest loss: 2.283855\tAccuracy: 40.50%\n",
      "163\tValidation loss: 2.327984\tBest loss: 2.283855\tAccuracy: 41.10%\n",
      "164\tValidation loss: 2.414718\tBest loss: 2.283855\tAccuracy: 39.20%\n",
      "165\tValidation loss: 2.357504\tBest loss: 2.283855\tAccuracy: 41.30%\n",
      "166\tValidation loss: 2.362357\tBest loss: 2.283855\tAccuracy: 39.40%\n",
      "167\tValidation loss: 2.537456\tBest loss: 2.283855\tAccuracy: 37.60%\n",
      "168\tValidation loss: 2.357890\tBest loss: 2.283855\tAccuracy: 40.70%\n",
      "169\tValidation loss: 2.335702\tBest loss: 2.283855\tAccuracy: 39.60%\n",
      "170\tValidation loss: 2.291949\tBest loss: 2.283855\tAccuracy: 42.00%\n",
      "171\tValidation loss: 2.319574\tBest loss: 2.283855\tAccuracy: 42.30%\n",
      "172\tValidation loss: 2.310501\tBest loss: 2.283855\tAccuracy: 41.30%\n",
      "173\tValidation loss: 2.342054\tBest loss: 2.283855\tAccuracy: 40.00%\n",
      "174\tValidation loss: 2.279339\tBest loss: 2.279339\tAccuracy: 42.50%\n",
      "175\tValidation loss: 2.291180\tBest loss: 2.279339\tAccuracy: 43.20%\n",
      "176\tValidation loss: 2.259429\tBest loss: 2.259429\tAccuracy: 44.00%\n",
      "177\tValidation loss: 2.337944\tBest loss: 2.259429\tAccuracy: 40.80%\n",
      "178\tValidation loss: 2.343948\tBest loss: 2.259429\tAccuracy: 37.80%\n",
      "179\tValidation loss: 2.242841\tBest loss: 2.242841\tAccuracy: 45.10%\n",
      "180\tValidation loss: 2.260210\tBest loss: 2.242841\tAccuracy: 42.30%\n",
      "181\tValidation loss: 2.240758\tBest loss: 2.240758\tAccuracy: 44.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\tValidation loss: 2.436746\tBest loss: 2.240758\tAccuracy: 39.30%\n",
      "183\tValidation loss: 2.368056\tBest loss: 2.240758\tAccuracy: 38.10%\n",
      "184\tValidation loss: 2.499373\tBest loss: 2.240758\tAccuracy: 35.50%\n",
      "185\tValidation loss: 2.350180\tBest loss: 2.240758\tAccuracy: 39.40%\n",
      "186\tValidation loss: 2.383638\tBest loss: 2.240758\tAccuracy: 38.90%\n",
      "187\tValidation loss: 2.477641\tBest loss: 2.240758\tAccuracy: 38.50%\n",
      "188\tValidation loss: 2.303133\tBest loss: 2.240758\tAccuracy: 41.90%\n",
      "189\tValidation loss: 2.318780\tBest loss: 2.240758\tAccuracy: 42.20%\n",
      "190\tValidation loss: 2.245931\tBest loss: 2.240758\tAccuracy: 44.40%\n",
      "191\tValidation loss: 2.240722\tBest loss: 2.240722\tAccuracy: 44.70%\n",
      "192\tValidation loss: 2.358326\tBest loss: 2.240722\tAccuracy: 40.50%\n",
      "193\tValidation loss: 2.369265\tBest loss: 2.240722\tAccuracy: 40.80%\n",
      "194\tValidation loss: 2.254993\tBest loss: 2.240722\tAccuracy: 44.20%\n",
      "195\tValidation loss: 2.289313\tBest loss: 2.240722\tAccuracy: 41.70%\n",
      "196\tValidation loss: 2.319498\tBest loss: 2.240722\tAccuracy: 41.60%\n",
      "197\tValidation loss: 2.361050\tBest loss: 2.240722\tAccuracy: 38.30%\n",
      "198\tValidation loss: 2.280097\tBest loss: 2.240722\tAccuracy: 41.20%\n",
      "199\tValidation loss: 2.217634\tBest loss: 2.217634\tAccuracy: 47.40%\n",
      "200\tValidation loss: 2.251593\tBest loss: 2.217634\tAccuracy: 43.30%\n",
      "201\tValidation loss: 2.252285\tBest loss: 2.217634\tAccuracy: 42.70%\n",
      "202\tValidation loss: 2.246183\tBest loss: 2.217634\tAccuracy: 42.90%\n",
      "203\tValidation loss: 2.330007\tBest loss: 2.217634\tAccuracy: 41.00%\n",
      "204\tValidation loss: 2.292288\tBest loss: 2.217634\tAccuracy: 39.30%\n",
      "205\tValidation loss: 2.225511\tBest loss: 2.217634\tAccuracy: 45.30%\n",
      "206\tValidation loss: 2.296223\tBest loss: 2.217634\tAccuracy: 40.10%\n",
      "207\tValidation loss: 2.250764\tBest loss: 2.217634\tAccuracy: 42.60%\n",
      "208\tValidation loss: 2.566072\tBest loss: 2.217634\tAccuracy: 36.20%\n",
      "209\tValidation loss: 2.306716\tBest loss: 2.217634\tAccuracy: 39.20%\n",
      "210\tValidation loss: 2.265312\tBest loss: 2.217634\tAccuracy: 42.50%\n",
      "211\tValidation loss: 2.286430\tBest loss: 2.217634\tAccuracy: 43.10%\n",
      "212\tValidation loss: 2.248584\tBest loss: 2.217634\tAccuracy: 43.30%\n",
      "213\tValidation loss: 2.301502\tBest loss: 2.217634\tAccuracy: 42.60%\n",
      "214\tValidation loss: 2.262274\tBest loss: 2.217634\tAccuracy: 42.30%\n",
      "215\tValidation loss: 2.217749\tBest loss: 2.217634\tAccuracy: 42.80%\n",
      "216\tValidation loss: 2.258552\tBest loss: 2.217634\tAccuracy: 43.30%\n",
      "217\tValidation loss: 2.241020\tBest loss: 2.217634\tAccuracy: 45.00%\n",
      "218\tValidation loss: 2.289399\tBest loss: 2.217634\tAccuracy: 41.10%\n",
      "219\tValidation loss: 2.499653\tBest loss: 2.217634\tAccuracy: 35.10%\n",
      "220\tValidation loss: 2.259241\tBest loss: 2.217634\tAccuracy: 42.10%\n",
      "Early stopping!\n",
      "[[  7.08508787e-06   1.22913020e-03   8.95073390e-05 ...,   2.41591351e-05\n",
      "    1.22879246e-05   4.52167587e-05]\n",
      " [  4.27670181e-02   3.15919146e-02   4.08174582e-02 ...,   1.67740453e-02\n",
      "    1.07193030e-02   8.85141362e-03]\n",
      " [  2.56020929e-08   9.55616142e-11   2.93456542e-05 ...,   9.72554676e-12\n",
      "    3.09537941e-15   1.26104134e-16]\n",
      " ..., \n",
      " [  1.83994575e-06   1.91464656e-04   2.81836474e-05 ...,   1.93268377e-02\n",
      "    3.51917860e-03   1.91603843e-02]\n",
      " [  1.51814567e-02   2.24811174e-02   1.17408773e-02 ...,   6.12572134e-02\n",
      "    3.33489925e-02   3.06042470e-02]\n",
      " [  2.51102338e-05   3.98125063e-04   4.94311040e-04 ...,   5.11626676e-02\n",
      "    1.49081089e-02   3.43979076e-02]]\n",
      "[11 16 16 ...,  6 24 36]\n",
      "[[  1.73709891e-03   6.34786161e-03   2.49907840e-02 ...,   1.18734753e-02\n",
      "    6.24232087e-03   1.22847613e-02]\n",
      " [  1.86216512e-05   2.82380590e-03   2.29632336e-04 ...,   2.71613768e-04\n",
      "    2.24922784e-04   3.80391022e-04]\n",
      " [  4.05608816e-03   1.23845953e-02   7.67912017e-03 ...,   1.84564199e-02\n",
      "    3.05989268e-03   8.38653278e-03]\n",
      " ..., \n",
      " [  1.94972556e-03   2.23505255e-02   3.08643375e-03 ...,   1.19685660e-06\n",
      "    2.03803711e-06   1.71124077e-06]\n",
      " [  2.97900476e-02   2.54149828e-02   2.56658886e-02 ...,   2.47469991e-02\n",
      "    1.46391755e-02   1.42995622e-02]\n",
      " [  1.94398854e-05   2.28974415e-04   2.58719228e-05 ...,   5.20881526e-02\n",
      "    1.69115633e-01   5.92526734e-01]]\n",
      "[38 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  10.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 1600.443237\tBest loss: 1600.443237\tAccuracy: 1.60%\n",
      "1\tValidation loss: 23353268.000000\tBest loss: 1600.443237\tAccuracy: 1.90%\n",
      "2\tValidation loss: 106699696.000000\tBest loss: 1600.443237\tAccuracy: 2.40%\n",
      "3\tValidation loss: 27353792.000000\tBest loss: 1600.443237\tAccuracy: 5.30%\n",
      "4\tValidation loss: 26537094.000000\tBest loss: 1600.443237\tAccuracy: 2.70%\n",
      "5\tValidation loss: 18185816.000000\tBest loss: 1600.443237\tAccuracy: 2.90%\n",
      "6\tValidation loss: 18850802.000000\tBest loss: 1600.443237\tAccuracy: 2.50%\n",
      "7\tValidation loss: 29566244.000000\tBest loss: 1600.443237\tAccuracy: 4.10%\n",
      "8\tValidation loss: 39095804.000000\tBest loss: 1600.443237\tAccuracy: 3.80%\n",
      "9\tValidation loss: 24580276.000000\tBest loss: 1600.443237\tAccuracy: 3.20%\n",
      "10\tValidation loss: 15228721.000000\tBest loss: 1600.443237\tAccuracy: 6.20%\n",
      "11\tValidation loss: 28070184.000000\tBest loss: 1600.443237\tAccuracy: 4.90%\n",
      "12\tValidation loss: 25565552.000000\tBest loss: 1600.443237\tAccuracy: 1.80%\n",
      "13\tValidation loss: 35331124.000000\tBest loss: 1600.443237\tAccuracy: 4.50%\n",
      "14\tValidation loss: 28875594.000000\tBest loss: 1600.443237\tAccuracy: 6.60%\n",
      "15\tValidation loss: 88270752.000000\tBest loss: 1600.443237\tAccuracy: 3.10%\n",
      "16\tValidation loss: 33112688.000000\tBest loss: 1600.443237\tAccuracy: 5.80%\n",
      "17\tValidation loss: 19278350.000000\tBest loss: 1600.443237\tAccuracy: 6.90%\n",
      "18\tValidation loss: 38735532.000000\tBest loss: 1600.443237\tAccuracy: 6.00%\n",
      "19\tValidation loss: 52273176.000000\tBest loss: 1600.443237\tAccuracy: 6.50%\n",
      "20\tValidation loss: 71257920.000000\tBest loss: 1600.443237\tAccuracy: 7.40%\n",
      "21\tValidation loss: 78816960.000000\tBest loss: 1600.443237\tAccuracy: 6.80%\n",
      "Early stopping!\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[15 15 15 ..., 24 24 24]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.29628609e-15   1.39330547e-08   4.14065804e-09 ...,   1.34251786e-34\n",
      "    4.86843325e-15   1.20920713e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.54664749e-18   1.30637254e-11   6.77530601e-11 ...,   0.00000000e+00\n",
      "    2.23353747e-16   2.36838149e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[24 24 24 ..., 38 24 24]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   1.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 4017377.000000\tBest loss: 4017377.000000\tAccuracy: 1.70%\n",
      "1\tValidation loss: 136531877888.000000\tBest loss: 4017377.000000\tAccuracy: 1.90%\n",
      "2\tValidation loss: 94727651196928.000000\tBest loss: 4017377.000000\tAccuracy: 1.80%\n",
      "3\tValidation loss: 1706416070346145792.000000\tBest loss: 4017377.000000\tAccuracy: 2.30%\n",
      "4\tValidation loss: 824035723945443328.000000\tBest loss: 4017377.000000\tAccuracy: 1.60%\n",
      "5\tValidation loss: 38170422331572224.000000\tBest loss: 4017377.000000\tAccuracy: 3.50%\n",
      "6\tValidation loss: 307926408976400384.000000\tBest loss: 4017377.000000\tAccuracy: 2.20%\n",
      "7\tValidation loss: 70476796964896768.000000\tBest loss: 4017377.000000\tAccuracy: 1.70%\n",
      "8\tValidation loss: 33265876769701888.000000\tBest loss: 4017377.000000\tAccuracy: 2.30%\n",
      "9\tValidation loss: 8156574539317248.000000\tBest loss: 4017377.000000\tAccuracy: 3.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 21263296455770112.000000\tBest loss: 4017377.000000\tAccuracy: 2.00%\n",
      "11\tValidation loss: 7905973935013888.000000\tBest loss: 4017377.000000\tAccuracy: 6.20%\n",
      "12\tValidation loss: 7413178514276352.000000\tBest loss: 4017377.000000\tAccuracy: 4.90%\n",
      "13\tValidation loss: 26636352082673664.000000\tBest loss: 4017377.000000\tAccuracy: 2.40%\n",
      "14\tValidation loss: 14757730967355392.000000\tBest loss: 4017377.000000\tAccuracy: 4.40%\n",
      "15\tValidation loss: 183102375748173824.000000\tBest loss: 4017377.000000\tAccuracy: 2.00%\n",
      "16\tValidation loss: 95138990728945860608.000000\tBest loss: 4017377.000000\tAccuracy: 2.60%\n",
      "17\tValidation loss: 136498675021773787814166528.000000\tBest loss: 4017377.000000\tAccuracy: 2.00%\n",
      "18\tValidation loss: 7821994255922212915442249367552.000000\tBest loss: 4017377.000000\tAccuracy: 1.20%\n",
      "19\tValidation loss: 26894532659968315524668704423936.000000\tBest loss: 4017377.000000\tAccuracy: 1.20%\n",
      "20\tValidation loss: 1565676999361461447604005186926804992.000000\tBest loss: 4017377.000000\tAccuracy: 2.00%\n",
      "21\tValidation loss: nan\tBest loss: 4017377.000000\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[25 25 25 ..., 25 25 25]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[25 25 25 ..., 25 25 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=1, n_neurons=150, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   1.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 5.842736\tBest loss: 5.842736\tAccuracy: 9.80%\n",
      "1\tValidation loss: 4.628721\tBest loss: 4.628721\tAccuracy: 11.80%\n",
      "2\tValidation loss: 4.211458\tBest loss: 4.211458\tAccuracy: 14.10%\n",
      "3\tValidation loss: 4.029497\tBest loss: 4.029497\tAccuracy: 13.60%\n",
      "4\tValidation loss: 3.885586\tBest loss: 3.885586\tAccuracy: 13.60%\n",
      "5\tValidation loss: 3.782078\tBest loss: 3.782078\tAccuracy: 14.90%\n",
      "6\tValidation loss: 3.682736\tBest loss: 3.682736\tAccuracy: 14.80%\n",
      "7\tValidation loss: 3.652431\tBest loss: 3.652431\tAccuracy: 15.40%\n",
      "8\tValidation loss: 3.559624\tBest loss: 3.559624\tAccuracy: 16.00%\n",
      "9\tValidation loss: 3.508015\tBest loss: 3.508015\tAccuracy: 17.10%\n",
      "10\tValidation loss: 3.481076\tBest loss: 3.481076\tAccuracy: 17.80%\n",
      "11\tValidation loss: 3.436216\tBest loss: 3.436216\tAccuracy: 18.90%\n",
      "12\tValidation loss: 3.391929\tBest loss: 3.391929\tAccuracy: 19.20%\n",
      "13\tValidation loss: 3.353552\tBest loss: 3.353552\tAccuracy: 20.60%\n",
      "14\tValidation loss: 3.322686\tBest loss: 3.322686\tAccuracy: 20.10%\n",
      "15\tValidation loss: 3.275888\tBest loss: 3.275888\tAccuracy: 20.50%\n",
      "16\tValidation loss: 3.253370\tBest loss: 3.253370\tAccuracy: 21.20%\n",
      "17\tValidation loss: 3.215308\tBest loss: 3.215308\tAccuracy: 21.30%\n",
      "18\tValidation loss: 3.206882\tBest loss: 3.206882\tAccuracy: 22.80%\n",
      "19\tValidation loss: 3.177679\tBest loss: 3.177679\tAccuracy: 23.30%\n",
      "20\tValidation loss: 3.143193\tBest loss: 3.143193\tAccuracy: 23.80%\n",
      "21\tValidation loss: 3.108061\tBest loss: 3.108061\tAccuracy: 24.00%\n",
      "22\tValidation loss: 3.074366\tBest loss: 3.074366\tAccuracy: 25.70%\n",
      "23\tValidation loss: 3.056158\tBest loss: 3.056158\tAccuracy: 26.10%\n",
      "24\tValidation loss: 3.030347\tBest loss: 3.030347\tAccuracy: 25.60%\n",
      "25\tValidation loss: 3.003187\tBest loss: 3.003187\tAccuracy: 26.20%\n",
      "26\tValidation loss: 2.977580\tBest loss: 2.977580\tAccuracy: 27.20%\n",
      "27\tValidation loss: 2.962883\tBest loss: 2.962883\tAccuracy: 28.00%\n",
      "28\tValidation loss: 2.935024\tBest loss: 2.935024\tAccuracy: 28.20%\n",
      "29\tValidation loss: 2.910695\tBest loss: 2.910695\tAccuracy: 29.50%\n",
      "30\tValidation loss: 2.887714\tBest loss: 2.887714\tAccuracy: 29.20%\n",
      "31\tValidation loss: 2.863215\tBest loss: 2.863215\tAccuracy: 30.00%\n",
      "32\tValidation loss: 2.847603\tBest loss: 2.847603\tAccuracy: 29.40%\n",
      "33\tValidation loss: 2.825521\tBest loss: 2.825521\tAccuracy: 30.90%\n",
      "34\tValidation loss: 2.813452\tBest loss: 2.813452\tAccuracy: 30.40%\n",
      "35\tValidation loss: 2.788451\tBest loss: 2.788451\tAccuracy: 31.10%\n",
      "36\tValidation loss: 2.779786\tBest loss: 2.779786\tAccuracy: 32.10%\n",
      "37\tValidation loss: 2.752989\tBest loss: 2.752989\tAccuracy: 31.80%\n",
      "38\tValidation loss: 2.730509\tBest loss: 2.730509\tAccuracy: 32.40%\n",
      "39\tValidation loss: 2.716313\tBest loss: 2.716313\tAccuracy: 31.80%\n",
      "40\tValidation loss: 2.693110\tBest loss: 2.693110\tAccuracy: 32.70%\n",
      "41\tValidation loss: 2.670103\tBest loss: 2.670103\tAccuracy: 32.90%\n",
      "42\tValidation loss: 2.654215\tBest loss: 2.654215\tAccuracy: 34.80%\n",
      "43\tValidation loss: 2.637739\tBest loss: 2.637739\tAccuracy: 34.60%\n",
      "44\tValidation loss: 2.627488\tBest loss: 2.627488\tAccuracy: 35.10%\n",
      "45\tValidation loss: 2.608862\tBest loss: 2.608862\tAccuracy: 34.80%\n",
      "46\tValidation loss: 2.587559\tBest loss: 2.587559\tAccuracy: 35.30%\n",
      "47\tValidation loss: 2.578701\tBest loss: 2.578701\tAccuracy: 35.10%\n",
      "48\tValidation loss: 2.562051\tBest loss: 2.562051\tAccuracy: 34.90%\n",
      "49\tValidation loss: 2.543089\tBest loss: 2.543089\tAccuracy: 36.60%\n",
      "50\tValidation loss: 2.532857\tBest loss: 2.532857\tAccuracy: 36.70%\n",
      "51\tValidation loss: 2.507694\tBest loss: 2.507694\tAccuracy: 36.60%\n",
      "52\tValidation loss: 2.502109\tBest loss: 2.502109\tAccuracy: 37.50%\n",
      "53\tValidation loss: 2.484633\tBest loss: 2.484633\tAccuracy: 36.40%\n",
      "54\tValidation loss: 2.474249\tBest loss: 2.474249\tAccuracy: 37.50%\n",
      "55\tValidation loss: 2.466479\tBest loss: 2.466479\tAccuracy: 37.40%\n",
      "56\tValidation loss: 2.442720\tBest loss: 2.442720\tAccuracy: 38.40%\n",
      "57\tValidation loss: 2.428533\tBest loss: 2.428533\tAccuracy: 39.00%\n",
      "58\tValidation loss: 2.415159\tBest loss: 2.415159\tAccuracy: 38.10%\n",
      "59\tValidation loss: 2.398980\tBest loss: 2.398980\tAccuracy: 39.40%\n",
      "60\tValidation loss: 2.388162\tBest loss: 2.388162\tAccuracy: 39.90%\n",
      "61\tValidation loss: 2.373428\tBest loss: 2.373428\tAccuracy: 40.00%\n",
      "62\tValidation loss: 2.360376\tBest loss: 2.360376\tAccuracy: 40.10%\n",
      "63\tValidation loss: 2.353288\tBest loss: 2.353288\tAccuracy: 39.40%\n",
      "64\tValidation loss: 2.351940\tBest loss: 2.351940\tAccuracy: 40.90%\n",
      "65\tValidation loss: 2.338958\tBest loss: 2.338958\tAccuracy: 40.80%\n",
      "66\tValidation loss: 2.316114\tBest loss: 2.316114\tAccuracy: 42.20%\n",
      "67\tValidation loss: 2.317311\tBest loss: 2.316114\tAccuracy: 41.90%\n",
      "68\tValidation loss: 2.297819\tBest loss: 2.297819\tAccuracy: 43.10%\n",
      "69\tValidation loss: 2.284419\tBest loss: 2.284419\tAccuracy: 43.20%\n",
      "70\tValidation loss: 2.273017\tBest loss: 2.273017\tAccuracy: 43.20%\n",
      "71\tValidation loss: 2.266957\tBest loss: 2.266957\tAccuracy: 44.30%\n",
      "72\tValidation loss: 2.258770\tBest loss: 2.258770\tAccuracy: 44.00%\n",
      "73\tValidation loss: 2.233436\tBest loss: 2.233436\tAccuracy: 43.80%\n",
      "74\tValidation loss: 2.235229\tBest loss: 2.233436\tAccuracy: 44.60%\n",
      "75\tValidation loss: 2.236225\tBest loss: 2.233436\tAccuracy: 44.70%\n",
      "76\tValidation loss: 2.203246\tBest loss: 2.203246\tAccuracy: 45.70%\n",
      "77\tValidation loss: 2.195615\tBest loss: 2.195615\tAccuracy: 45.60%\n",
      "78\tValidation loss: 2.191629\tBest loss: 2.191629\tAccuracy: 45.60%\n",
      "79\tValidation loss: 2.185393\tBest loss: 2.185393\tAccuracy: 45.60%\n",
      "80\tValidation loss: 2.177076\tBest loss: 2.177076\tAccuracy: 45.70%\n",
      "81\tValidation loss: 2.174983\tBest loss: 2.174983\tAccuracy: 46.10%\n",
      "82\tValidation loss: 2.154451\tBest loss: 2.154451\tAccuracy: 47.30%\n",
      "83\tValidation loss: 2.153067\tBest loss: 2.153067\tAccuracy: 47.20%\n",
      "84\tValidation loss: 2.147001\tBest loss: 2.147001\tAccuracy: 47.00%\n",
      "85\tValidation loss: 2.140871\tBest loss: 2.140871\tAccuracy: 47.10%\n",
      "86\tValidation loss: 2.134567\tBest loss: 2.134567\tAccuracy: 47.70%\n",
      "87\tValidation loss: 2.126682\tBest loss: 2.126682\tAccuracy: 47.90%\n",
      "88\tValidation loss: 2.126486\tBest loss: 2.126486\tAccuracy: 48.80%\n",
      "89\tValidation loss: 2.107562\tBest loss: 2.107562\tAccuracy: 48.80%\n",
      "90\tValidation loss: 2.104217\tBest loss: 2.104217\tAccuracy: 48.20%\n",
      "91\tValidation loss: 2.100646\tBest loss: 2.100646\tAccuracy: 48.70%\n",
      "92\tValidation loss: 2.098774\tBest loss: 2.098774\tAccuracy: 48.70%\n",
      "93\tValidation loss: 2.082313\tBest loss: 2.082313\tAccuracy: 48.90%\n",
      "94\tValidation loss: 2.075580\tBest loss: 2.075580\tAccuracy: 49.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\tValidation loss: 2.065019\tBest loss: 2.065019\tAccuracy: 49.40%\n",
      "96\tValidation loss: 2.073330\tBest loss: 2.065019\tAccuracy: 49.20%\n",
      "97\tValidation loss: 2.054352\tBest loss: 2.054352\tAccuracy: 51.30%\n",
      "98\tValidation loss: 2.051111\tBest loss: 2.051111\tAccuracy: 51.40%\n",
      "99\tValidation loss: 2.045951\tBest loss: 2.045951\tAccuracy: 50.00%\n",
      "100\tValidation loss: 2.042242\tBest loss: 2.042242\tAccuracy: 50.70%\n",
      "101\tValidation loss: 2.028489\tBest loss: 2.028489\tAccuracy: 51.00%\n",
      "102\tValidation loss: 2.019597\tBest loss: 2.019597\tAccuracy: 50.70%\n",
      "103\tValidation loss: 2.011221\tBest loss: 2.011221\tAccuracy: 51.40%\n",
      "104\tValidation loss: 2.003972\tBest loss: 2.003972\tAccuracy: 50.50%\n",
      "105\tValidation loss: 2.007060\tBest loss: 2.003972\tAccuracy: 51.30%\n",
      "106\tValidation loss: 1.995127\tBest loss: 1.995127\tAccuracy: 51.10%\n",
      "107\tValidation loss: 2.004340\tBest loss: 1.995127\tAccuracy: 51.10%\n",
      "108\tValidation loss: 1.994809\tBest loss: 1.994809\tAccuracy: 50.60%\n",
      "109\tValidation loss: 2.001987\tBest loss: 1.994809\tAccuracy: 51.00%\n",
      "110\tValidation loss: 1.980542\tBest loss: 1.980542\tAccuracy: 52.20%\n",
      "111\tValidation loss: 1.977069\tBest loss: 1.977069\tAccuracy: 51.30%\n",
      "112\tValidation loss: 1.979871\tBest loss: 1.977069\tAccuracy: 51.40%\n",
      "113\tValidation loss: 1.962739\tBest loss: 1.962739\tAccuracy: 52.90%\n",
      "114\tValidation loss: 1.959172\tBest loss: 1.959172\tAccuracy: 52.30%\n",
      "115\tValidation loss: 1.949378\tBest loss: 1.949378\tAccuracy: 52.40%\n",
      "116\tValidation loss: 1.942764\tBest loss: 1.942764\tAccuracy: 52.70%\n",
      "117\tValidation loss: 1.944762\tBest loss: 1.942764\tAccuracy: 52.70%\n",
      "118\tValidation loss: 1.941389\tBest loss: 1.941389\tAccuracy: 52.40%\n",
      "119\tValidation loss: 1.931245\tBest loss: 1.931245\tAccuracy: 52.60%\n",
      "120\tValidation loss: 1.933083\tBest loss: 1.931245\tAccuracy: 52.60%\n",
      "121\tValidation loss: 1.925068\tBest loss: 1.925068\tAccuracy: 53.00%\n",
      "122\tValidation loss: 1.921111\tBest loss: 1.921111\tAccuracy: 53.40%\n",
      "123\tValidation loss: 1.911242\tBest loss: 1.911242\tAccuracy: 53.40%\n",
      "124\tValidation loss: 1.915671\tBest loss: 1.911242\tAccuracy: 52.40%\n",
      "125\tValidation loss: 1.918916\tBest loss: 1.911242\tAccuracy: 52.80%\n",
      "126\tValidation loss: 1.915962\tBest loss: 1.911242\tAccuracy: 53.50%\n",
      "127\tValidation loss: 1.899206\tBest loss: 1.899206\tAccuracy: 53.80%\n",
      "128\tValidation loss: 1.899281\tBest loss: 1.899206\tAccuracy: 54.00%\n",
      "129\tValidation loss: 1.894001\tBest loss: 1.894001\tAccuracy: 54.10%\n",
      "130\tValidation loss: 1.892669\tBest loss: 1.892669\tAccuracy: 53.40%\n",
      "131\tValidation loss: 1.875693\tBest loss: 1.875693\tAccuracy: 53.90%\n",
      "132\tValidation loss: 1.875562\tBest loss: 1.875562\tAccuracy: 54.40%\n",
      "133\tValidation loss: 1.870925\tBest loss: 1.870925\tAccuracy: 54.70%\n",
      "134\tValidation loss: 1.870625\tBest loss: 1.870625\tAccuracy: 54.00%\n",
      "135\tValidation loss: 1.858816\tBest loss: 1.858816\tAccuracy: 54.80%\n",
      "136\tValidation loss: 1.863109\tBest loss: 1.858816\tAccuracy: 54.40%\n",
      "137\tValidation loss: 1.849436\tBest loss: 1.849436\tAccuracy: 55.50%\n",
      "138\tValidation loss: 1.850301\tBest loss: 1.849436\tAccuracy: 55.50%\n",
      "139\tValidation loss: 1.854598\tBest loss: 1.849436\tAccuracy: 54.90%\n",
      "140\tValidation loss: 1.847323\tBest loss: 1.847323\tAccuracy: 55.10%\n",
      "141\tValidation loss: 1.846375\tBest loss: 1.846375\tAccuracy: 55.70%\n",
      "142\tValidation loss: 1.843571\tBest loss: 1.843571\tAccuracy: 55.60%\n",
      "143\tValidation loss: 1.836706\tBest loss: 1.836706\tAccuracy: 55.70%\n",
      "144\tValidation loss: 1.836132\tBest loss: 1.836132\tAccuracy: 56.30%\n",
      "145\tValidation loss: 1.828001\tBest loss: 1.828001\tAccuracy: 55.80%\n",
      "146\tValidation loss: 1.830101\tBest loss: 1.828001\tAccuracy: 56.20%\n",
      "147\tValidation loss: 1.818581\tBest loss: 1.818581\tAccuracy: 55.70%\n",
      "148\tValidation loss: 1.820916\tBest loss: 1.818581\tAccuracy: 55.20%\n",
      "149\tValidation loss: 1.826540\tBest loss: 1.818581\tAccuracy: 55.60%\n",
      "150\tValidation loss: 1.807900\tBest loss: 1.807900\tAccuracy: 56.50%\n",
      "151\tValidation loss: 1.807858\tBest loss: 1.807858\tAccuracy: 56.20%\n",
      "152\tValidation loss: 1.809567\tBest loss: 1.807858\tAccuracy: 56.10%\n",
      "153\tValidation loss: 1.798658\tBest loss: 1.798658\tAccuracy: 57.40%\n",
      "154\tValidation loss: 1.796780\tBest loss: 1.796780\tAccuracy: 56.00%\n",
      "155\tValidation loss: 1.801202\tBest loss: 1.796780\tAccuracy: 56.20%\n",
      "156\tValidation loss: 1.799213\tBest loss: 1.796780\tAccuracy: 57.10%\n",
      "157\tValidation loss: 1.793666\tBest loss: 1.793666\tAccuracy: 57.00%\n",
      "158\tValidation loss: 1.786053\tBest loss: 1.786053\tAccuracy: 57.30%\n",
      "159\tValidation loss: 1.789545\tBest loss: 1.786053\tAccuracy: 56.90%\n",
      "160\tValidation loss: 1.780222\tBest loss: 1.780222\tAccuracy: 56.40%\n",
      "161\tValidation loss: 1.777358\tBest loss: 1.777358\tAccuracy: 57.10%\n",
      "162\tValidation loss: 1.776204\tBest loss: 1.776204\tAccuracy: 57.40%\n",
      "163\tValidation loss: 1.768607\tBest loss: 1.768607\tAccuracy: 57.30%\n",
      "164\tValidation loss: 1.779366\tBest loss: 1.768607\tAccuracy: 57.10%\n",
      "165\tValidation loss: 1.768896\tBest loss: 1.768607\tAccuracy: 57.90%\n",
      "166\tValidation loss: 1.765407\tBest loss: 1.765407\tAccuracy: 57.20%\n",
      "167\tValidation loss: 1.766882\tBest loss: 1.765407\tAccuracy: 57.30%\n",
      "168\tValidation loss: 1.761057\tBest loss: 1.761057\tAccuracy: 58.00%\n",
      "169\tValidation loss: 1.755416\tBest loss: 1.755416\tAccuracy: 57.40%\n",
      "170\tValidation loss: 1.757057\tBest loss: 1.755416\tAccuracy: 57.40%\n",
      "171\tValidation loss: 1.752713\tBest loss: 1.752713\tAccuracy: 57.50%\n",
      "172\tValidation loss: 1.739576\tBest loss: 1.739576\tAccuracy: 58.00%\n",
      "173\tValidation loss: 1.748949\tBest loss: 1.739576\tAccuracy: 57.60%\n",
      "174\tValidation loss: 1.738932\tBest loss: 1.738932\tAccuracy: 57.40%\n",
      "175\tValidation loss: 1.737032\tBest loss: 1.737032\tAccuracy: 57.60%\n",
      "176\tValidation loss: 1.730327\tBest loss: 1.730327\tAccuracy: 57.70%\n",
      "177\tValidation loss: 1.734043\tBest loss: 1.730327\tAccuracy: 58.30%\n",
      "178\tValidation loss: 1.728647\tBest loss: 1.728647\tAccuracy: 58.50%\n",
      "179\tValidation loss: 1.738220\tBest loss: 1.728647\tAccuracy: 58.30%\n",
      "180\tValidation loss: 1.727199\tBest loss: 1.727199\tAccuracy: 58.90%\n",
      "181\tValidation loss: 1.721534\tBest loss: 1.721534\tAccuracy: 58.60%\n",
      "182\tValidation loss: 1.718351\tBest loss: 1.718351\tAccuracy: 57.90%\n",
      "183\tValidation loss: 1.717742\tBest loss: 1.717742\tAccuracy: 57.90%\n",
      "184\tValidation loss: 1.720060\tBest loss: 1.717742\tAccuracy: 58.10%\n",
      "185\tValidation loss: 1.718743\tBest loss: 1.717742\tAccuracy: 58.40%\n",
      "186\tValidation loss: 1.714996\tBest loss: 1.714996\tAccuracy: 58.00%\n",
      "187\tValidation loss: 1.710775\tBest loss: 1.710775\tAccuracy: 58.20%\n",
      "188\tValidation loss: 1.706839\tBest loss: 1.706839\tAccuracy: 58.40%\n",
      "189\tValidation loss: 1.707855\tBest loss: 1.706839\tAccuracy: 57.70%\n",
      "190\tValidation loss: 1.695783\tBest loss: 1.695783\tAccuracy: 58.50%\n",
      "191\tValidation loss: 1.695336\tBest loss: 1.695336\tAccuracy: 58.50%\n",
      "192\tValidation loss: 1.700485\tBest loss: 1.695336\tAccuracy: 58.40%\n",
      "193\tValidation loss: 1.697286\tBest loss: 1.695336\tAccuracy: 58.90%\n",
      "194\tValidation loss: 1.697778\tBest loss: 1.695336\tAccuracy: 58.10%\n",
      "195\tValidation loss: 1.693775\tBest loss: 1.693775\tAccuracy: 58.70%\n",
      "196\tValidation loss: 1.687608\tBest loss: 1.687608\tAccuracy: 58.90%\n",
      "197\tValidation loss: 1.687738\tBest loss: 1.687608\tAccuracy: 58.90%\n",
      "198\tValidation loss: 1.683055\tBest loss: 1.683055\tAccuracy: 58.60%\n",
      "199\tValidation loss: 1.686990\tBest loss: 1.683055\tAccuracy: 58.60%\n",
      "200\tValidation loss: 1.685608\tBest loss: 1.683055\tAccuracy: 58.90%\n",
      "201\tValidation loss: 1.685503\tBest loss: 1.683055\tAccuracy: 58.00%\n",
      "202\tValidation loss: 1.685034\tBest loss: 1.683055\tAccuracy: 58.80%\n",
      "203\tValidation loss: 1.682224\tBest loss: 1.682224\tAccuracy: 58.50%\n",
      "204\tValidation loss: 1.681662\tBest loss: 1.681662\tAccuracy: 59.60%\n",
      "205\tValidation loss: 1.675542\tBest loss: 1.675542\tAccuracy: 58.80%\n",
      "206\tValidation loss: 1.677704\tBest loss: 1.675542\tAccuracy: 59.00%\n",
      "207\tValidation loss: 1.678282\tBest loss: 1.675542\tAccuracy: 59.20%\n",
      "208\tValidation loss: 1.669447\tBest loss: 1.669447\tAccuracy: 59.30%\n",
      "209\tValidation loss: 1.668078\tBest loss: 1.668078\tAccuracy: 59.60%\n",
      "210\tValidation loss: 1.667838\tBest loss: 1.667838\tAccuracy: 58.40%\n",
      "211\tValidation loss: 1.663723\tBest loss: 1.663723\tAccuracy: 58.40%\n",
      "212\tValidation loss: 1.657686\tBest loss: 1.657686\tAccuracy: 58.80%\n",
      "213\tValidation loss: 1.665450\tBest loss: 1.657686\tAccuracy: 58.60%\n",
      "214\tValidation loss: 1.657452\tBest loss: 1.657452\tAccuracy: 58.40%\n",
      "215\tValidation loss: 1.651420\tBest loss: 1.651420\tAccuracy: 59.90%\n",
      "216\tValidation loss: 1.645824\tBest loss: 1.645824\tAccuracy: 59.50%\n",
      "217\tValidation loss: 1.648091\tBest loss: 1.645824\tAccuracy: 60.10%\n",
      "218\tValidation loss: 1.650355\tBest loss: 1.645824\tAccuracy: 59.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\tValidation loss: 1.649331\tBest loss: 1.645824\tAccuracy: 60.60%\n",
      "220\tValidation loss: 1.637970\tBest loss: 1.637970\tAccuracy: 60.10%\n",
      "221\tValidation loss: 1.636528\tBest loss: 1.636528\tAccuracy: 59.80%\n",
      "222\tValidation loss: 1.633028\tBest loss: 1.633028\tAccuracy: 60.30%\n",
      "223\tValidation loss: 1.641441\tBest loss: 1.633028\tAccuracy: 59.90%\n",
      "224\tValidation loss: 1.637342\tBest loss: 1.633028\tAccuracy: 60.60%\n",
      "225\tValidation loss: 1.633813\tBest loss: 1.633028\tAccuracy: 60.50%\n",
      "226\tValidation loss: 1.634695\tBest loss: 1.633028\tAccuracy: 60.30%\n",
      "227\tValidation loss: 1.627594\tBest loss: 1.627594\tAccuracy: 60.30%\n",
      "228\tValidation loss: 1.628201\tBest loss: 1.627594\tAccuracy: 59.60%\n",
      "229\tValidation loss: 1.624527\tBest loss: 1.624527\tAccuracy: 59.60%\n",
      "230\tValidation loss: 1.623729\tBest loss: 1.623729\tAccuracy: 60.20%\n",
      "231\tValidation loss: 1.623425\tBest loss: 1.623425\tAccuracy: 60.70%\n",
      "232\tValidation loss: 1.619855\tBest loss: 1.619855\tAccuracy: 61.20%\n",
      "233\tValidation loss: 1.624640\tBest loss: 1.619855\tAccuracy: 60.80%\n",
      "234\tValidation loss: 1.616196\tBest loss: 1.616196\tAccuracy: 59.90%\n",
      "235\tValidation loss: 1.608581\tBest loss: 1.608581\tAccuracy: 60.80%\n",
      "236\tValidation loss: 1.613692\tBest loss: 1.608581\tAccuracy: 60.40%\n",
      "237\tValidation loss: 1.611357\tBest loss: 1.608581\tAccuracy: 60.30%\n",
      "238\tValidation loss: 1.611542\tBest loss: 1.608581\tAccuracy: 59.90%\n",
      "239\tValidation loss: 1.608748\tBest loss: 1.608581\tAccuracy: 60.40%\n",
      "240\tValidation loss: 1.611503\tBest loss: 1.608581\tAccuracy: 60.20%\n",
      "241\tValidation loss: 1.612610\tBest loss: 1.608581\tAccuracy: 60.00%\n",
      "242\tValidation loss: 1.617943\tBest loss: 1.608581\tAccuracy: 60.40%\n",
      "243\tValidation loss: 1.607206\tBest loss: 1.607206\tAccuracy: 60.50%\n",
      "244\tValidation loss: 1.605997\tBest loss: 1.605997\tAccuracy: 60.70%\n",
      "245\tValidation loss: 1.605715\tBest loss: 1.605715\tAccuracy: 61.00%\n",
      "246\tValidation loss: 1.600835\tBest loss: 1.600835\tAccuracy: 60.40%\n",
      "247\tValidation loss: 1.600682\tBest loss: 1.600682\tAccuracy: 60.60%\n",
      "248\tValidation loss: 1.600536\tBest loss: 1.600536\tAccuracy: 60.80%\n",
      "249\tValidation loss: 1.595092\tBest loss: 1.595092\tAccuracy: 62.00%\n",
      "250\tValidation loss: 1.591061\tBest loss: 1.591061\tAccuracy: 61.50%\n",
      "251\tValidation loss: 1.594931\tBest loss: 1.591061\tAccuracy: 60.50%\n",
      "252\tValidation loss: 1.587983\tBest loss: 1.587983\tAccuracy: 61.20%\n",
      "253\tValidation loss: 1.589538\tBest loss: 1.587983\tAccuracy: 61.20%\n",
      "254\tValidation loss: 1.586699\tBest loss: 1.586699\tAccuracy: 62.30%\n",
      "255\tValidation loss: 1.590827\tBest loss: 1.586699\tAccuracy: 61.60%\n",
      "256\tValidation loss: 1.589717\tBest loss: 1.586699\tAccuracy: 61.10%\n",
      "257\tValidation loss: 1.580943\tBest loss: 1.580943\tAccuracy: 61.60%\n",
      "258\tValidation loss: 1.581921\tBest loss: 1.580943\tAccuracy: 61.10%\n",
      "259\tValidation loss: 1.582897\tBest loss: 1.580943\tAccuracy: 61.40%\n",
      "260\tValidation loss: 1.587020\tBest loss: 1.580943\tAccuracy: 61.30%\n",
      "261\tValidation loss: 1.577694\tBest loss: 1.577694\tAccuracy: 61.40%\n",
      "262\tValidation loss: 1.578186\tBest loss: 1.577694\tAccuracy: 62.40%\n",
      "263\tValidation loss: 1.583720\tBest loss: 1.577694\tAccuracy: 61.40%\n",
      "264\tValidation loss: 1.574541\tBest loss: 1.574541\tAccuracy: 61.50%\n",
      "265\tValidation loss: 1.573640\tBest loss: 1.573640\tAccuracy: 61.50%\n",
      "266\tValidation loss: 1.572410\tBest loss: 1.572410\tAccuracy: 61.90%\n",
      "267\tValidation loss: 1.570540\tBest loss: 1.570540\tAccuracy: 61.10%\n",
      "268\tValidation loss: 1.576908\tBest loss: 1.570540\tAccuracy: 61.10%\n",
      "269\tValidation loss: 1.571277\tBest loss: 1.570540\tAccuracy: 61.70%\n",
      "270\tValidation loss: 1.572725\tBest loss: 1.570540\tAccuracy: 61.90%\n",
      "271\tValidation loss: 1.565711\tBest loss: 1.565711\tAccuracy: 61.20%\n",
      "272\tValidation loss: 1.562899\tBest loss: 1.562899\tAccuracy: 61.30%\n",
      "273\tValidation loss: 1.565854\tBest loss: 1.562899\tAccuracy: 61.80%\n",
      "274\tValidation loss: 1.562952\tBest loss: 1.562899\tAccuracy: 61.70%\n",
      "275\tValidation loss: 1.565169\tBest loss: 1.562899\tAccuracy: 61.80%\n",
      "276\tValidation loss: 1.562032\tBest loss: 1.562032\tAccuracy: 61.70%\n",
      "277\tValidation loss: 1.562730\tBest loss: 1.562032\tAccuracy: 61.60%\n",
      "278\tValidation loss: 1.565452\tBest loss: 1.562032\tAccuracy: 62.00%\n",
      "279\tValidation loss: 1.562228\tBest loss: 1.562032\tAccuracy: 62.60%\n",
      "280\tValidation loss: 1.559966\tBest loss: 1.559966\tAccuracy: 62.00%\n",
      "281\tValidation loss: 1.554110\tBest loss: 1.554110\tAccuracy: 62.30%\n",
      "282\tValidation loss: 1.552891\tBest loss: 1.552891\tAccuracy: 62.30%\n",
      "283\tValidation loss: 1.549978\tBest loss: 1.549978\tAccuracy: 62.30%\n",
      "284\tValidation loss: 1.552881\tBest loss: 1.549978\tAccuracy: 62.00%\n",
      "285\tValidation loss: 1.552645\tBest loss: 1.549978\tAccuracy: 62.00%\n",
      "286\tValidation loss: 1.552619\tBest loss: 1.549978\tAccuracy: 61.90%\n",
      "287\tValidation loss: 1.553643\tBest loss: 1.549978\tAccuracy: 62.20%\n",
      "288\tValidation loss: 1.550574\tBest loss: 1.549978\tAccuracy: 62.00%\n",
      "289\tValidation loss: 1.550387\tBest loss: 1.549978\tAccuracy: 61.80%\n",
      "290\tValidation loss: 1.547928\tBest loss: 1.547928\tAccuracy: 62.30%\n",
      "291\tValidation loss: 1.543428\tBest loss: 1.543428\tAccuracy: 61.90%\n",
      "292\tValidation loss: 1.553073\tBest loss: 1.543428\tAccuracy: 62.10%\n",
      "293\tValidation loss: 1.540117\tBest loss: 1.540117\tAccuracy: 61.80%\n",
      "294\tValidation loss: 1.539441\tBest loss: 1.539441\tAccuracy: 62.00%\n",
      "295\tValidation loss: 1.535054\tBest loss: 1.535054\tAccuracy: 62.10%\n",
      "296\tValidation loss: 1.533400\tBest loss: 1.533400\tAccuracy: 62.60%\n",
      "297\tValidation loss: 1.536355\tBest loss: 1.533400\tAccuracy: 62.20%\n",
      "298\tValidation loss: 1.527215\tBest loss: 1.527215\tAccuracy: 62.50%\n",
      "299\tValidation loss: 1.534612\tBest loss: 1.527215\tAccuracy: 62.20%\n",
      "300\tValidation loss: 1.532316\tBest loss: 1.527215\tAccuracy: 62.60%\n",
      "301\tValidation loss: 1.535530\tBest loss: 1.527215\tAccuracy: 62.90%\n",
      "302\tValidation loss: 1.529273\tBest loss: 1.527215\tAccuracy: 61.60%\n",
      "303\tValidation loss: 1.528179\tBest loss: 1.527215\tAccuracy: 62.00%\n",
      "304\tValidation loss: 1.524605\tBest loss: 1.524605\tAccuracy: 62.90%\n",
      "305\tValidation loss: 1.524740\tBest loss: 1.524605\tAccuracy: 62.60%\n",
      "306\tValidation loss: 1.528910\tBest loss: 1.524605\tAccuracy: 62.40%\n",
      "307\tValidation loss: 1.519557\tBest loss: 1.519557\tAccuracy: 63.00%\n",
      "308\tValidation loss: 1.529174\tBest loss: 1.519557\tAccuracy: 62.20%\n",
      "309\tValidation loss: 1.533359\tBest loss: 1.519557\tAccuracy: 62.20%\n",
      "310\tValidation loss: 1.523290\tBest loss: 1.519557\tAccuracy: 62.30%\n",
      "311\tValidation loss: 1.526995\tBest loss: 1.519557\tAccuracy: 62.30%\n",
      "312\tValidation loss: 1.525713\tBest loss: 1.519557\tAccuracy: 62.20%\n",
      "313\tValidation loss: 1.517857\tBest loss: 1.517857\tAccuracy: 62.30%\n",
      "314\tValidation loss: 1.525984\tBest loss: 1.517857\tAccuracy: 62.90%\n",
      "315\tValidation loss: 1.530889\tBest loss: 1.517857\tAccuracy: 61.40%\n",
      "316\tValidation loss: 1.514113\tBest loss: 1.514113\tAccuracy: 62.40%\n",
      "317\tValidation loss: 1.519521\tBest loss: 1.514113\tAccuracy: 62.40%\n",
      "318\tValidation loss: 1.522365\tBest loss: 1.514113\tAccuracy: 62.70%\n",
      "319\tValidation loss: 1.517984\tBest loss: 1.514113\tAccuracy: 62.40%\n",
      "320\tValidation loss: 1.518434\tBest loss: 1.514113\tAccuracy: 62.40%\n",
      "321\tValidation loss: 1.518238\tBest loss: 1.514113\tAccuracy: 62.20%\n",
      "322\tValidation loss: 1.517764\tBest loss: 1.514113\tAccuracy: 62.10%\n",
      "323\tValidation loss: 1.516963\tBest loss: 1.514113\tAccuracy: 62.40%\n",
      "324\tValidation loss: 1.517802\tBest loss: 1.514113\tAccuracy: 62.20%\n",
      "325\tValidation loss: 1.508990\tBest loss: 1.508990\tAccuracy: 62.90%\n",
      "326\tValidation loss: 1.512120\tBest loss: 1.508990\tAccuracy: 62.40%\n",
      "327\tValidation loss: 1.513607\tBest loss: 1.508990\tAccuracy: 63.00%\n",
      "328\tValidation loss: 1.512148\tBest loss: 1.508990\tAccuracy: 62.50%\n",
      "329\tValidation loss: 1.512602\tBest loss: 1.508990\tAccuracy: 62.40%\n",
      "330\tValidation loss: 1.510772\tBest loss: 1.508990\tAccuracy: 62.90%\n",
      "331\tValidation loss: 1.512963\tBest loss: 1.508990\tAccuracy: 62.20%\n",
      "332\tValidation loss: 1.513962\tBest loss: 1.508990\tAccuracy: 62.60%\n",
      "333\tValidation loss: 1.504034\tBest loss: 1.504034\tAccuracy: 62.80%\n",
      "334\tValidation loss: 1.499987\tBest loss: 1.499987\tAccuracy: 62.60%\n",
      "335\tValidation loss: 1.488404\tBest loss: 1.488404\tAccuracy: 63.10%\n",
      "336\tValidation loss: 1.495327\tBest loss: 1.488404\tAccuracy: 62.90%\n",
      "337\tValidation loss: 1.500325\tBest loss: 1.488404\tAccuracy: 62.50%\n",
      "338\tValidation loss: 1.501471\tBest loss: 1.488404\tAccuracy: 62.10%\n",
      "339\tValidation loss: 1.498929\tBest loss: 1.488404\tAccuracy: 62.30%\n",
      "340\tValidation loss: 1.503567\tBest loss: 1.488404\tAccuracy: 62.50%\n",
      "341\tValidation loss: 1.494738\tBest loss: 1.488404\tAccuracy: 62.40%\n",
      "342\tValidation loss: 1.492630\tBest loss: 1.488404\tAccuracy: 62.60%\n",
      "343\tValidation loss: 1.490327\tBest loss: 1.488404\tAccuracy: 62.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\tValidation loss: 1.493411\tBest loss: 1.488404\tAccuracy: 62.50%\n",
      "345\tValidation loss: 1.492815\tBest loss: 1.488404\tAccuracy: 62.50%\n",
      "346\tValidation loss: 1.491289\tBest loss: 1.488404\tAccuracy: 62.30%\n",
      "347\tValidation loss: 1.487053\tBest loss: 1.487053\tAccuracy: 62.10%\n",
      "348\tValidation loss: 1.484155\tBest loss: 1.484155\tAccuracy: 62.50%\n",
      "349\tValidation loss: 1.484087\tBest loss: 1.484087\tAccuracy: 62.30%\n",
      "350\tValidation loss: 1.490272\tBest loss: 1.484087\tAccuracy: 62.50%\n",
      "351\tValidation loss: 1.490723\tBest loss: 1.484087\tAccuracy: 62.60%\n",
      "352\tValidation loss: 1.488654\tBest loss: 1.484087\tAccuracy: 62.10%\n",
      "353\tValidation loss: 1.487035\tBest loss: 1.484087\tAccuracy: 62.90%\n",
      "354\tValidation loss: 1.486064\tBest loss: 1.484087\tAccuracy: 62.80%\n",
      "355\tValidation loss: 1.483347\tBest loss: 1.483347\tAccuracy: 62.30%\n",
      "356\tValidation loss: 1.483229\tBest loss: 1.483229\tAccuracy: 62.80%\n",
      "357\tValidation loss: 1.484275\tBest loss: 1.483229\tAccuracy: 62.90%\n",
      "358\tValidation loss: 1.482091\tBest loss: 1.482091\tAccuracy: 62.90%\n",
      "359\tValidation loss: 1.482108\tBest loss: 1.482091\tAccuracy: 62.70%\n",
      "360\tValidation loss: 1.486964\tBest loss: 1.482091\tAccuracy: 62.90%\n",
      "361\tValidation loss: 1.484784\tBest loss: 1.482091\tAccuracy: 62.60%\n",
      "362\tValidation loss: 1.482141\tBest loss: 1.482091\tAccuracy: 63.20%\n",
      "363\tValidation loss: 1.483339\tBest loss: 1.482091\tAccuracy: 62.70%\n",
      "364\tValidation loss: 1.480012\tBest loss: 1.480012\tAccuracy: 63.60%\n",
      "365\tValidation loss: 1.480515\tBest loss: 1.480012\tAccuracy: 63.50%\n",
      "366\tValidation loss: 1.479703\tBest loss: 1.479703\tAccuracy: 63.30%\n",
      "367\tValidation loss: 1.474624\tBest loss: 1.474624\tAccuracy: 63.10%\n",
      "368\tValidation loss: 1.477696\tBest loss: 1.474624\tAccuracy: 63.80%\n",
      "369\tValidation loss: 1.475457\tBest loss: 1.474624\tAccuracy: 63.20%\n",
      "370\tValidation loss: 1.473482\tBest loss: 1.473482\tAccuracy: 63.10%\n",
      "371\tValidation loss: 1.470214\tBest loss: 1.470214\tAccuracy: 63.30%\n",
      "372\tValidation loss: 1.467442\tBest loss: 1.467442\tAccuracy: 64.00%\n",
      "373\tValidation loss: 1.466985\tBest loss: 1.466985\tAccuracy: 63.20%\n",
      "374\tValidation loss: 1.462161\tBest loss: 1.462161\tAccuracy: 63.30%\n",
      "375\tValidation loss: 1.464272\tBest loss: 1.462161\tAccuracy: 63.90%\n",
      "376\tValidation loss: 1.459568\tBest loss: 1.459568\tAccuracy: 63.20%\n",
      "377\tValidation loss: 1.467838\tBest loss: 1.459568\tAccuracy: 63.40%\n",
      "378\tValidation loss: 1.463693\tBest loss: 1.459568\tAccuracy: 63.10%\n",
      "379\tValidation loss: 1.467700\tBest loss: 1.459568\tAccuracy: 62.90%\n",
      "380\tValidation loss: 1.463728\tBest loss: 1.459568\tAccuracy: 63.50%\n",
      "381\tValidation loss: 1.455615\tBest loss: 1.455615\tAccuracy: 63.40%\n",
      "382\tValidation loss: 1.466953\tBest loss: 1.455615\tAccuracy: 63.40%\n",
      "383\tValidation loss: 1.459021\tBest loss: 1.455615\tAccuracy: 63.40%\n",
      "384\tValidation loss: 1.467415\tBest loss: 1.455615\tAccuracy: 63.60%\n",
      "385\tValidation loss: 1.462299\tBest loss: 1.455615\tAccuracy: 63.50%\n",
      "386\tValidation loss: 1.461962\tBest loss: 1.455615\tAccuracy: 63.20%\n",
      "387\tValidation loss: 1.457350\tBest loss: 1.455615\tAccuracy: 62.70%\n",
      "388\tValidation loss: 1.463522\tBest loss: 1.455615\tAccuracy: 63.20%\n",
      "389\tValidation loss: 1.459164\tBest loss: 1.455615\tAccuracy: 62.70%\n",
      "390\tValidation loss: 1.457990\tBest loss: 1.455615\tAccuracy: 62.90%\n",
      "391\tValidation loss: 1.457952\tBest loss: 1.455615\tAccuracy: 62.60%\n",
      "392\tValidation loss: 1.456934\tBest loss: 1.455615\tAccuracy: 62.90%\n",
      "393\tValidation loss: 1.457015\tBest loss: 1.455615\tAccuracy: 63.40%\n",
      "394\tValidation loss: 1.462175\tBest loss: 1.455615\tAccuracy: 63.10%\n",
      "395\tValidation loss: 1.457311\tBest loss: 1.455615\tAccuracy: 62.80%\n",
      "396\tValidation loss: 1.456093\tBest loss: 1.455615\tAccuracy: 63.10%\n",
      "397\tValidation loss: 1.464319\tBest loss: 1.455615\tAccuracy: 63.10%\n",
      "398\tValidation loss: 1.456793\tBest loss: 1.455615\tAccuracy: 63.20%\n",
      "399\tValidation loss: 1.455976\tBest loss: 1.455615\tAccuracy: 63.10%\n",
      "400\tValidation loss: 1.449260\tBest loss: 1.449260\tAccuracy: 63.10%\n",
      "401\tValidation loss: 1.446742\tBest loss: 1.446742\tAccuracy: 63.60%\n",
      "402\tValidation loss: 1.452478\tBest loss: 1.446742\tAccuracy: 63.30%\n",
      "403\tValidation loss: 1.450421\tBest loss: 1.446742\tAccuracy: 62.90%\n",
      "404\tValidation loss: 1.456507\tBest loss: 1.446742\tAccuracy: 63.30%\n",
      "405\tValidation loss: 1.451112\tBest loss: 1.446742\tAccuracy: 63.10%\n",
      "406\tValidation loss: 1.450410\tBest loss: 1.446742\tAccuracy: 64.30%\n",
      "407\tValidation loss: 1.446737\tBest loss: 1.446737\tAccuracy: 63.60%\n",
      "408\tValidation loss: 1.446894\tBest loss: 1.446737\tAccuracy: 63.50%\n",
      "409\tValidation loss: 1.444080\tBest loss: 1.444080\tAccuracy: 63.70%\n",
      "410\tValidation loss: 1.444859\tBest loss: 1.444080\tAccuracy: 63.90%\n",
      "411\tValidation loss: 1.441976\tBest loss: 1.441976\tAccuracy: 64.00%\n",
      "412\tValidation loss: 1.441684\tBest loss: 1.441684\tAccuracy: 63.80%\n",
      "413\tValidation loss: 1.438650\tBest loss: 1.438650\tAccuracy: 63.80%\n",
      "414\tValidation loss: 1.440632\tBest loss: 1.438650\tAccuracy: 63.50%\n",
      "415\tValidation loss: 1.440554\tBest loss: 1.438650\tAccuracy: 64.20%\n",
      "416\tValidation loss: 1.433476\tBest loss: 1.433476\tAccuracy: 64.30%\n",
      "417\tValidation loss: 1.443552\tBest loss: 1.433476\tAccuracy: 63.90%\n",
      "418\tValidation loss: 1.439759\tBest loss: 1.433476\tAccuracy: 63.30%\n",
      "419\tValidation loss: 1.439472\tBest loss: 1.433476\tAccuracy: 64.20%\n",
      "420\tValidation loss: 1.438787\tBest loss: 1.433476\tAccuracy: 63.40%\n",
      "421\tValidation loss: 1.441839\tBest loss: 1.433476\tAccuracy: 63.80%\n",
      "422\tValidation loss: 1.435319\tBest loss: 1.433476\tAccuracy: 63.80%\n",
      "423\tValidation loss: 1.435058\tBest loss: 1.433476\tAccuracy: 64.00%\n",
      "424\tValidation loss: 1.433470\tBest loss: 1.433470\tAccuracy: 64.70%\n",
      "425\tValidation loss: 1.430916\tBest loss: 1.430916\tAccuracy: 63.90%\n",
      "426\tValidation loss: 1.430337\tBest loss: 1.430337\tAccuracy: 63.60%\n",
      "427\tValidation loss: 1.434707\tBest loss: 1.430337\tAccuracy: 64.10%\n",
      "428\tValidation loss: 1.431557\tBest loss: 1.430337\tAccuracy: 64.30%\n",
      "429\tValidation loss: 1.434064\tBest loss: 1.430337\tAccuracy: 63.90%\n",
      "430\tValidation loss: 1.430056\tBest loss: 1.430056\tAccuracy: 64.10%\n",
      "431\tValidation loss: 1.426586\tBest loss: 1.426586\tAccuracy: 64.00%\n",
      "432\tValidation loss: 1.425564\tBest loss: 1.425564\tAccuracy: 64.00%\n",
      "433\tValidation loss: 1.421514\tBest loss: 1.421514\tAccuracy: 63.90%\n",
      "434\tValidation loss: 1.427996\tBest loss: 1.421514\tAccuracy: 64.50%\n",
      "435\tValidation loss: 1.421987\tBest loss: 1.421514\tAccuracy: 64.50%\n",
      "436\tValidation loss: 1.419801\tBest loss: 1.419801\tAccuracy: 64.20%\n",
      "437\tValidation loss: 1.425193\tBest loss: 1.419801\tAccuracy: 63.80%\n",
      "438\tValidation loss: 1.426818\tBest loss: 1.419801\tAccuracy: 64.30%\n",
      "439\tValidation loss: 1.425336\tBest loss: 1.419801\tAccuracy: 64.40%\n",
      "440\tValidation loss: 1.418941\tBest loss: 1.418941\tAccuracy: 64.40%\n",
      "441\tValidation loss: 1.424187\tBest loss: 1.418941\tAccuracy: 64.30%\n",
      "442\tValidation loss: 1.424908\tBest loss: 1.418941\tAccuracy: 64.80%\n",
      "443\tValidation loss: 1.428349\tBest loss: 1.418941\tAccuracy: 64.60%\n",
      "444\tValidation loss: 1.422692\tBest loss: 1.418941\tAccuracy: 63.70%\n",
      "445\tValidation loss: 1.416367\tBest loss: 1.416367\tAccuracy: 64.30%\n",
      "446\tValidation loss: 1.420552\tBest loss: 1.416367\tAccuracy: 64.70%\n",
      "447\tValidation loss: 1.417745\tBest loss: 1.416367\tAccuracy: 64.80%\n",
      "448\tValidation loss: 1.415944\tBest loss: 1.415944\tAccuracy: 64.60%\n",
      "449\tValidation loss: 1.417705\tBest loss: 1.415944\tAccuracy: 64.30%\n",
      "450\tValidation loss: 1.416351\tBest loss: 1.415944\tAccuracy: 64.80%\n",
      "451\tValidation loss: 1.408205\tBest loss: 1.408205\tAccuracy: 64.40%\n",
      "452\tValidation loss: 1.416532\tBest loss: 1.408205\tAccuracy: 64.60%\n",
      "453\tValidation loss: 1.415676\tBest loss: 1.408205\tAccuracy: 64.60%\n",
      "454\tValidation loss: 1.410249\tBest loss: 1.408205\tAccuracy: 63.90%\n",
      "455\tValidation loss: 1.411595\tBest loss: 1.408205\tAccuracy: 63.60%\n",
      "456\tValidation loss: 1.411724\tBest loss: 1.408205\tAccuracy: 64.80%\n",
      "457\tValidation loss: 1.417395\tBest loss: 1.408205\tAccuracy: 64.50%\n",
      "458\tValidation loss: 1.414094\tBest loss: 1.408205\tAccuracy: 64.00%\n",
      "459\tValidation loss: 1.406394\tBest loss: 1.406394\tAccuracy: 64.20%\n",
      "460\tValidation loss: 1.408707\tBest loss: 1.406394\tAccuracy: 64.30%\n",
      "461\tValidation loss: 1.410354\tBest loss: 1.406394\tAccuracy: 64.40%\n",
      "462\tValidation loss: 1.407677\tBest loss: 1.406394\tAccuracy: 64.50%\n",
      "463\tValidation loss: 1.404857\tBest loss: 1.404857\tAccuracy: 64.10%\n",
      "464\tValidation loss: 1.408497\tBest loss: 1.404857\tAccuracy: 65.00%\n",
      "465\tValidation loss: 1.406753\tBest loss: 1.404857\tAccuracy: 65.10%\n",
      "466\tValidation loss: 1.405584\tBest loss: 1.404857\tAccuracy: 64.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\tValidation loss: 1.409670\tBest loss: 1.404857\tAccuracy: 64.60%\n",
      "468\tValidation loss: 1.410367\tBest loss: 1.404857\tAccuracy: 64.70%\n",
      "469\tValidation loss: 1.401661\tBest loss: 1.401661\tAccuracy: 64.50%\n",
      "470\tValidation loss: 1.398103\tBest loss: 1.398103\tAccuracy: 64.10%\n",
      "471\tValidation loss: 1.395850\tBest loss: 1.395850\tAccuracy: 64.40%\n",
      "472\tValidation loss: 1.399650\tBest loss: 1.395850\tAccuracy: 64.90%\n",
      "473\tValidation loss: 1.402708\tBest loss: 1.395850\tAccuracy: 64.20%\n",
      "474\tValidation loss: 1.396448\tBest loss: 1.395850\tAccuracy: 64.30%\n",
      "475\tValidation loss: 1.400434\tBest loss: 1.395850\tAccuracy: 64.80%\n",
      "476\tValidation loss: 1.396657\tBest loss: 1.395850\tAccuracy: 64.70%\n",
      "477\tValidation loss: 1.392161\tBest loss: 1.392161\tAccuracy: 64.90%\n",
      "478\tValidation loss: 1.391295\tBest loss: 1.391295\tAccuracy: 65.20%\n",
      "479\tValidation loss: 1.393114\tBest loss: 1.391295\tAccuracy: 65.20%\n",
      "480\tValidation loss: 1.388663\tBest loss: 1.388663\tAccuracy: 64.70%\n",
      "481\tValidation loss: 1.389706\tBest loss: 1.388663\tAccuracy: 64.40%\n",
      "482\tValidation loss: 1.390812\tBest loss: 1.388663\tAccuracy: 65.70%\n",
      "483\tValidation loss: 1.391343\tBest loss: 1.388663\tAccuracy: 64.70%\n",
      "484\tValidation loss: 1.392519\tBest loss: 1.388663\tAccuracy: 64.90%\n",
      "485\tValidation loss: 1.388336\tBest loss: 1.388336\tAccuracy: 65.30%\n",
      "486\tValidation loss: 1.388292\tBest loss: 1.388292\tAccuracy: 65.50%\n",
      "487\tValidation loss: 1.388489\tBest loss: 1.388292\tAccuracy: 65.60%\n",
      "488\tValidation loss: 1.392413\tBest loss: 1.388292\tAccuracy: 64.70%\n",
      "489\tValidation loss: 1.385890\tBest loss: 1.385890\tAccuracy: 65.60%\n",
      "490\tValidation loss: 1.387343\tBest loss: 1.385890\tAccuracy: 65.50%\n",
      "491\tValidation loss: 1.381227\tBest loss: 1.381227\tAccuracy: 65.20%\n",
      "492\tValidation loss: 1.391165\tBest loss: 1.381227\tAccuracy: 65.40%\n",
      "493\tValidation loss: 1.390125\tBest loss: 1.381227\tAccuracy: 64.40%\n",
      "494\tValidation loss: 1.390368\tBest loss: 1.381227\tAccuracy: 64.70%\n",
      "495\tValidation loss: 1.384355\tBest loss: 1.381227\tAccuracy: 64.80%\n",
      "496\tValidation loss: 1.384891\tBest loss: 1.381227\tAccuracy: 65.40%\n",
      "497\tValidation loss: 1.383608\tBest loss: 1.381227\tAccuracy: 65.20%\n",
      "498\tValidation loss: 1.384654\tBest loss: 1.381227\tAccuracy: 65.10%\n",
      "499\tValidation loss: 1.386484\tBest loss: 1.381227\tAccuracy: 65.00%\n",
      "500\tValidation loss: 1.388595\tBest loss: 1.381227\tAccuracy: 64.80%\n",
      "501\tValidation loss: 1.384539\tBest loss: 1.381227\tAccuracy: 65.20%\n",
      "502\tValidation loss: 1.386158\tBest loss: 1.381227\tAccuracy: 63.80%\n",
      "503\tValidation loss: 1.381820\tBest loss: 1.381227\tAccuracy: 64.60%\n",
      "504\tValidation loss: 1.378583\tBest loss: 1.378583\tAccuracy: 65.60%\n",
      "505\tValidation loss: 1.375481\tBest loss: 1.375481\tAccuracy: 65.60%\n",
      "506\tValidation loss: 1.380101\tBest loss: 1.375481\tAccuracy: 65.40%\n",
      "507\tValidation loss: 1.376185\tBest loss: 1.375481\tAccuracy: 65.40%\n",
      "508\tValidation loss: 1.379767\tBest loss: 1.375481\tAccuracy: 65.30%\n",
      "509\tValidation loss: 1.382575\tBest loss: 1.375481\tAccuracy: 65.10%\n",
      "510\tValidation loss: 1.386373\tBest loss: 1.375481\tAccuracy: 64.90%\n",
      "511\tValidation loss: 1.382577\tBest loss: 1.375481\tAccuracy: 64.90%\n",
      "512\tValidation loss: 1.379386\tBest loss: 1.375481\tAccuracy: 65.60%\n",
      "513\tValidation loss: 1.370628\tBest loss: 1.370628\tAccuracy: 65.40%\n",
      "514\tValidation loss: 1.386917\tBest loss: 1.370628\tAccuracy: 66.20%\n",
      "515\tValidation loss: 1.379817\tBest loss: 1.370628\tAccuracy: 66.10%\n",
      "516\tValidation loss: 1.378694\tBest loss: 1.370628\tAccuracy: 65.30%\n",
      "517\tValidation loss: 1.378490\tBest loss: 1.370628\tAccuracy: 65.40%\n",
      "518\tValidation loss: 1.377396\tBest loss: 1.370628\tAccuracy: 64.90%\n",
      "519\tValidation loss: 1.372756\tBest loss: 1.370628\tAccuracy: 65.70%\n",
      "520\tValidation loss: 1.375843\tBest loss: 1.370628\tAccuracy: 65.60%\n",
      "521\tValidation loss: 1.373870\tBest loss: 1.370628\tAccuracy: 65.10%\n",
      "522\tValidation loss: 1.373525\tBest loss: 1.370628\tAccuracy: 65.90%\n",
      "523\tValidation loss: 1.371452\tBest loss: 1.370628\tAccuracy: 65.80%\n",
      "524\tValidation loss: 1.370154\tBest loss: 1.370154\tAccuracy: 65.10%\n",
      "525\tValidation loss: 1.370474\tBest loss: 1.370154\tAccuracy: 65.40%\n",
      "526\tValidation loss: 1.374083\tBest loss: 1.370154\tAccuracy: 65.20%\n",
      "527\tValidation loss: 1.371664\tBest loss: 1.370154\tAccuracy: 64.80%\n",
      "528\tValidation loss: 1.369487\tBest loss: 1.369487\tAccuracy: 65.50%\n",
      "529\tValidation loss: 1.364621\tBest loss: 1.364621\tAccuracy: 65.20%\n",
      "530\tValidation loss: 1.369953\tBest loss: 1.364621\tAccuracy: 65.10%\n",
      "531\tValidation loss: 1.368782\tBest loss: 1.364621\tAccuracy: 65.50%\n",
      "532\tValidation loss: 1.364400\tBest loss: 1.364400\tAccuracy: 65.60%\n",
      "533\tValidation loss: 1.370579\tBest loss: 1.364400\tAccuracy: 66.40%\n",
      "534\tValidation loss: 1.364488\tBest loss: 1.364400\tAccuracy: 65.60%\n",
      "535\tValidation loss: 1.365633\tBest loss: 1.364400\tAccuracy: 65.70%\n",
      "536\tValidation loss: 1.368440\tBest loss: 1.364400\tAccuracy: 65.80%\n",
      "537\tValidation loss: 1.364745\tBest loss: 1.364400\tAccuracy: 65.50%\n",
      "538\tValidation loss: 1.365368\tBest loss: 1.364400\tAccuracy: 65.80%\n",
      "539\tValidation loss: 1.364837\tBest loss: 1.364400\tAccuracy: 66.10%\n",
      "540\tValidation loss: 1.364959\tBest loss: 1.364400\tAccuracy: 65.90%\n",
      "541\tValidation loss: 1.365989\tBest loss: 1.364400\tAccuracy: 65.90%\n",
      "542\tValidation loss: 1.368743\tBest loss: 1.364400\tAccuracy: 65.50%\n",
      "543\tValidation loss: 1.358369\tBest loss: 1.358369\tAccuracy: 66.00%\n",
      "544\tValidation loss: 1.358383\tBest loss: 1.358369\tAccuracy: 65.90%\n",
      "545\tValidation loss: 1.359166\tBest loss: 1.358369\tAccuracy: 66.50%\n",
      "546\tValidation loss: 1.364444\tBest loss: 1.358369\tAccuracy: 65.70%\n",
      "547\tValidation loss: 1.355324\tBest loss: 1.355324\tAccuracy: 65.10%\n",
      "548\tValidation loss: 1.352490\tBest loss: 1.352490\tAccuracy: 65.40%\n",
      "549\tValidation loss: 1.358507\tBest loss: 1.352490\tAccuracy: 66.10%\n",
      "550\tValidation loss: 1.357951\tBest loss: 1.352490\tAccuracy: 65.50%\n",
      "551\tValidation loss: 1.356472\tBest loss: 1.352490\tAccuracy: 65.90%\n",
      "552\tValidation loss: 1.360444\tBest loss: 1.352490\tAccuracy: 66.20%\n",
      "553\tValidation loss: 1.356318\tBest loss: 1.352490\tAccuracy: 65.60%\n",
      "554\tValidation loss: 1.353477\tBest loss: 1.352490\tAccuracy: 66.30%\n",
      "555\tValidation loss: 1.353266\tBest loss: 1.352490\tAccuracy: 65.90%\n",
      "556\tValidation loss: 1.354771\tBest loss: 1.352490\tAccuracy: 66.10%\n",
      "557\tValidation loss: 1.360927\tBest loss: 1.352490\tAccuracy: 65.70%\n",
      "558\tValidation loss: 1.360346\tBest loss: 1.352490\tAccuracy: 65.60%\n",
      "559\tValidation loss: 1.357142\tBest loss: 1.352490\tAccuracy: 65.30%\n",
      "560\tValidation loss: 1.356148\tBest loss: 1.352490\tAccuracy: 66.10%\n",
      "561\tValidation loss: 1.353312\tBest loss: 1.352490\tAccuracy: 65.70%\n",
      "562\tValidation loss: 1.348755\tBest loss: 1.348755\tAccuracy: 65.80%\n",
      "563\tValidation loss: 1.357710\tBest loss: 1.348755\tAccuracy: 65.90%\n",
      "564\tValidation loss: 1.354683\tBest loss: 1.348755\tAccuracy: 65.90%\n",
      "565\tValidation loss: 1.360988\tBest loss: 1.348755\tAccuracy: 66.00%\n",
      "566\tValidation loss: 1.358647\tBest loss: 1.348755\tAccuracy: 66.00%\n",
      "567\tValidation loss: 1.359489\tBest loss: 1.348755\tAccuracy: 66.20%\n",
      "568\tValidation loss: 1.360500\tBest loss: 1.348755\tAccuracy: 65.70%\n",
      "569\tValidation loss: 1.358176\tBest loss: 1.348755\tAccuracy: 65.70%\n",
      "570\tValidation loss: 1.352486\tBest loss: 1.348755\tAccuracy: 66.00%\n",
      "571\tValidation loss: 1.352310\tBest loss: 1.348755\tAccuracy: 66.10%\n",
      "572\tValidation loss: 1.358281\tBest loss: 1.348755\tAccuracy: 66.50%\n",
      "573\tValidation loss: 1.355754\tBest loss: 1.348755\tAccuracy: 65.80%\n",
      "574\tValidation loss: 1.356319\tBest loss: 1.348755\tAccuracy: 65.50%\n",
      "575\tValidation loss: 1.355398\tBest loss: 1.348755\tAccuracy: 66.00%\n",
      "576\tValidation loss: 1.352102\tBest loss: 1.348755\tAccuracy: 66.20%\n",
      "577\tValidation loss: 1.349705\tBest loss: 1.348755\tAccuracy: 66.20%\n",
      "578\tValidation loss: 1.354900\tBest loss: 1.348755\tAccuracy: 66.50%\n",
      "579\tValidation loss: 1.362713\tBest loss: 1.348755\tAccuracy: 65.80%\n",
      "580\tValidation loss: 1.351275\tBest loss: 1.348755\tAccuracy: 66.20%\n",
      "581\tValidation loss: 1.350588\tBest loss: 1.348755\tAccuracy: 66.50%\n",
      "582\tValidation loss: 1.354671\tBest loss: 1.348755\tAccuracy: 65.80%\n",
      "583\tValidation loss: 1.351427\tBest loss: 1.348755\tAccuracy: 65.80%\n",
      "Early stopping!\n",
      "[[  1.37847988e-14   9.00279986e-07   3.29717711e-11 ...,   8.93572156e-22\n",
      "    2.22910749e-17   1.92479555e-16]\n",
      " [  6.00285977e-02   3.44149768e-02   6.05461001e-02 ...,   1.75322220e-02\n",
      "    8.41546059e-03   8.23601894e-03]\n",
      " [  6.71970726e-12   1.30675361e-23   4.16731564e-06 ...,   8.57906656e-22\n",
      "    7.08130400e-28   4.85788962e-28]\n",
      " ..., \n",
      " [  8.83689170e-28   1.10895439e-17   3.50346638e-28 ...,   1.49488928e-11\n",
      "    1.21130677e-12   9.53086395e-12]\n",
      " [  1.50038563e-02   1.62029639e-02   1.95145386e-03 ...,   8.85819793e-02\n",
      "    6.38084486e-03   1.38279321e-02]\n",
      " [  6.21399972e-14   4.50047821e-08   3.40395587e-08 ...,   5.17321110e-04\n",
      "    2.13746189e-05   6.21713174e-04]]\n",
      "[22  2 16 ...,  6 24 36]\n",
      "[[  8.43193160e-09   3.07633059e-07   4.66926731e-02 ...,   3.70410502e-09\n",
      "    3.25960303e-09   2.30933711e-06]\n",
      " [  9.54420959e-20   2.22357521e-10   6.97807722e-15 ...,   2.73927697e-26\n",
      "    2.24542984e-22   4.33947512e-20]\n",
      " [  5.72213108e-14   2.01635042e-09   3.60369221e-12 ...,   3.12096980e-14\n",
      "    7.45052298e-17   1.37179677e-12]\n",
      " ..., \n",
      " [  1.23317500e-06   4.54862857e-05   2.32901093e-05 ...,   2.41034975e-13\n",
      "    1.47928273e-13   4.10834908e-12]\n",
      " [  3.75946052e-02   2.11872701e-02   3.25625055e-02 ...,   2.09916700e-02\n",
      "    1.33329220e-02   1.43728592e-02]\n",
      " [  7.64413889e-20   2.18738275e-15   1.58900459e-20 ...,   2.31523172e-05\n",
      "    6.75663631e-03   9.91781294e-01]]\n",
      "[43 43 43 ...,  6 37 47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  28.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 5.991362\tBest loss: 5.991362\tAccuracy: 9.50%\n",
      "1\tValidation loss: 4.719052\tBest loss: 4.719052\tAccuracy: 11.50%\n",
      "2\tValidation loss: 4.269307\tBest loss: 4.269307\tAccuracy: 12.60%\n",
      "3\tValidation loss: 3.999174\tBest loss: 3.999174\tAccuracy: 12.80%\n",
      "4\tValidation loss: 3.836628\tBest loss: 3.836628\tAccuracy: 12.50%\n",
      "5\tValidation loss: 3.745742\tBest loss: 3.745742\tAccuracy: 13.20%\n",
      "6\tValidation loss: 3.692087\tBest loss: 3.692087\tAccuracy: 13.10%\n",
      "7\tValidation loss: 3.651290\tBest loss: 3.651290\tAccuracy: 13.80%\n",
      "8\tValidation loss: 3.583798\tBest loss: 3.583798\tAccuracy: 15.60%\n",
      "9\tValidation loss: 3.532226\tBest loss: 3.532226\tAccuracy: 16.30%\n",
      "10\tValidation loss: 3.473691\tBest loss: 3.473691\tAccuracy: 16.40%\n",
      "11\tValidation loss: 3.443913\tBest loss: 3.443913\tAccuracy: 16.10%\n",
      "12\tValidation loss: 3.422953\tBest loss: 3.422953\tAccuracy: 16.40%\n",
      "13\tValidation loss: 3.380053\tBest loss: 3.380053\tAccuracy: 17.50%\n",
      "14\tValidation loss: 3.353358\tBest loss: 3.353358\tAccuracy: 18.20%\n",
      "15\tValidation loss: 3.313728\tBest loss: 3.313728\tAccuracy: 19.00%\n",
      "16\tValidation loss: 3.286401\tBest loss: 3.286401\tAccuracy: 19.10%\n",
      "17\tValidation loss: 3.271910\tBest loss: 3.271910\tAccuracy: 19.50%\n",
      "18\tValidation loss: 3.253873\tBest loss: 3.253873\tAccuracy: 19.50%\n",
      "19\tValidation loss: 3.211209\tBest loss: 3.211209\tAccuracy: 20.40%\n",
      "20\tValidation loss: 3.179511\tBest loss: 3.179511\tAccuracy: 21.70%\n",
      "21\tValidation loss: 3.159872\tBest loss: 3.159872\tAccuracy: 21.70%\n",
      "22\tValidation loss: 3.139942\tBest loss: 3.139942\tAccuracy: 22.40%\n",
      "23\tValidation loss: 3.113094\tBest loss: 3.113094\tAccuracy: 23.10%\n",
      "24\tValidation loss: 3.083462\tBest loss: 3.083462\tAccuracy: 24.10%\n",
      "25\tValidation loss: 3.057912\tBest loss: 3.057912\tAccuracy: 23.80%\n",
      "26\tValidation loss: 3.043687\tBest loss: 3.043687\tAccuracy: 24.80%\n",
      "27\tValidation loss: 3.016864\tBest loss: 3.016864\tAccuracy: 25.00%\n",
      "28\tValidation loss: 2.993063\tBest loss: 2.993063\tAccuracy: 26.50%\n",
      "29\tValidation loss: 2.959923\tBest loss: 2.959923\tAccuracy: 27.10%\n",
      "30\tValidation loss: 2.941338\tBest loss: 2.941338\tAccuracy: 26.90%\n",
      "31\tValidation loss: 2.917372\tBest loss: 2.917372\tAccuracy: 28.30%\n",
      "32\tValidation loss: 2.900804\tBest loss: 2.900804\tAccuracy: 28.00%\n",
      "33\tValidation loss: 2.882869\tBest loss: 2.882869\tAccuracy: 28.60%\n",
      "34\tValidation loss: 2.867792\tBest loss: 2.867792\tAccuracy: 29.40%\n",
      "35\tValidation loss: 2.840908\tBest loss: 2.840908\tAccuracy: 28.80%\n",
      "36\tValidation loss: 2.814667\tBest loss: 2.814667\tAccuracy: 31.10%\n",
      "37\tValidation loss: 2.794512\tBest loss: 2.794512\tAccuracy: 31.50%\n",
      "38\tValidation loss: 2.774600\tBest loss: 2.774600\tAccuracy: 31.80%\n",
      "39\tValidation loss: 2.762846\tBest loss: 2.762846\tAccuracy: 32.50%\n",
      "40\tValidation loss: 2.740530\tBest loss: 2.740530\tAccuracy: 33.40%\n",
      "41\tValidation loss: 2.715494\tBest loss: 2.715494\tAccuracy: 33.20%\n",
      "42\tValidation loss: 2.687487\tBest loss: 2.687487\tAccuracy: 33.50%\n",
      "43\tValidation loss: 2.677379\tBest loss: 2.677379\tAccuracy: 33.90%\n",
      "44\tValidation loss: 2.662573\tBest loss: 2.662573\tAccuracy: 34.80%\n",
      "45\tValidation loss: 2.640344\tBest loss: 2.640344\tAccuracy: 35.10%\n",
      "46\tValidation loss: 2.619390\tBest loss: 2.619390\tAccuracy: 35.60%\n",
      "47\tValidation loss: 2.600990\tBest loss: 2.600990\tAccuracy: 34.50%\n",
      "48\tValidation loss: 2.591534\tBest loss: 2.591534\tAccuracy: 35.00%\n",
      "49\tValidation loss: 2.573715\tBest loss: 2.573715\tAccuracy: 35.90%\n",
      "50\tValidation loss: 2.560183\tBest loss: 2.560183\tAccuracy: 35.90%\n",
      "51\tValidation loss: 2.541133\tBest loss: 2.541133\tAccuracy: 36.50%\n",
      "52\tValidation loss: 2.528475\tBest loss: 2.528475\tAccuracy: 36.50%\n",
      "53\tValidation loss: 2.512409\tBest loss: 2.512409\tAccuracy: 36.90%\n",
      "54\tValidation loss: 2.502570\tBest loss: 2.502570\tAccuracy: 36.60%\n",
      "55\tValidation loss: 2.475185\tBest loss: 2.475185\tAccuracy: 37.90%\n",
      "56\tValidation loss: 2.474302\tBest loss: 2.474302\tAccuracy: 37.50%\n",
      "57\tValidation loss: 2.454448\tBest loss: 2.454448\tAccuracy: 37.60%\n",
      "58\tValidation loss: 2.445516\tBest loss: 2.445516\tAccuracy: 37.60%\n",
      "59\tValidation loss: 2.432227\tBest loss: 2.432227\tAccuracy: 37.50%\n",
      "60\tValidation loss: 2.432163\tBest loss: 2.432163\tAccuracy: 39.40%\n",
      "61\tValidation loss: 2.413223\tBest loss: 2.413223\tAccuracy: 40.90%\n",
      "62\tValidation loss: 2.388586\tBest loss: 2.388586\tAccuracy: 39.20%\n",
      "63\tValidation loss: 2.375253\tBest loss: 2.375253\tAccuracy: 40.40%\n",
      "64\tValidation loss: 2.357636\tBest loss: 2.357636\tAccuracy: 40.90%\n",
      "65\tValidation loss: 2.345338\tBest loss: 2.345338\tAccuracy: 41.60%\n",
      "66\tValidation loss: 2.342264\tBest loss: 2.342264\tAccuracy: 42.00%\n",
      "67\tValidation loss: 2.326794\tBest loss: 2.326794\tAccuracy: 41.40%\n",
      "68\tValidation loss: 2.307290\tBest loss: 2.307290\tAccuracy: 42.50%\n",
      "69\tValidation loss: 2.296498\tBest loss: 2.296498\tAccuracy: 43.10%\n",
      "70\tValidation loss: 2.285887\tBest loss: 2.285887\tAccuracy: 42.40%\n",
      "71\tValidation loss: 2.281573\tBest loss: 2.281573\tAccuracy: 42.20%\n",
      "72\tValidation loss: 2.275768\tBest loss: 2.275768\tAccuracy: 43.40%\n",
      "73\tValidation loss: 2.263592\tBest loss: 2.263592\tAccuracy: 43.90%\n",
      "74\tValidation loss: 2.255039\tBest loss: 2.255039\tAccuracy: 44.20%\n",
      "75\tValidation loss: 2.249978\tBest loss: 2.249978\tAccuracy: 44.00%\n",
      "76\tValidation loss: 2.244661\tBest loss: 2.244661\tAccuracy: 43.70%\n",
      "77\tValidation loss: 2.236499\tBest loss: 2.236499\tAccuracy: 44.00%\n",
      "78\tValidation loss: 2.225351\tBest loss: 2.225351\tAccuracy: 44.80%\n",
      "79\tValidation loss: 2.211644\tBest loss: 2.211644\tAccuracy: 46.40%\n",
      "80\tValidation loss: 2.207400\tBest loss: 2.207400\tAccuracy: 46.30%\n",
      "81\tValidation loss: 2.203012\tBest loss: 2.203012\tAccuracy: 45.50%\n",
      "82\tValidation loss: 2.187649\tBest loss: 2.187649\tAccuracy: 47.20%\n",
      "83\tValidation loss: 2.190344\tBest loss: 2.187649\tAccuracy: 46.70%\n",
      "84\tValidation loss: 2.176941\tBest loss: 2.176941\tAccuracy: 46.70%\n",
      "85\tValidation loss: 2.166565\tBest loss: 2.166565\tAccuracy: 48.00%\n",
      "86\tValidation loss: 2.160730\tBest loss: 2.160730\tAccuracy: 47.50%\n",
      "87\tValidation loss: 2.149602\tBest loss: 2.149602\tAccuracy: 48.20%\n",
      "88\tValidation loss: 2.139366\tBest loss: 2.139366\tAccuracy: 48.00%\n",
      "89\tValidation loss: 2.129620\tBest loss: 2.129620\tAccuracy: 48.60%\n",
      "90\tValidation loss: 2.122131\tBest loss: 2.122131\tAccuracy: 47.90%\n",
      "91\tValidation loss: 2.116978\tBest loss: 2.116978\tAccuracy: 48.00%\n",
      "92\tValidation loss: 2.111438\tBest loss: 2.111438\tAccuracy: 48.50%\n",
      "93\tValidation loss: 2.102196\tBest loss: 2.102196\tAccuracy: 48.70%\n",
      "94\tValidation loss: 2.099272\tBest loss: 2.099272\tAccuracy: 49.70%\n",
      "95\tValidation loss: 2.088093\tBest loss: 2.088093\tAccuracy: 49.50%\n",
      "96\tValidation loss: 2.084552\tBest loss: 2.084552\tAccuracy: 49.00%\n",
      "97\tValidation loss: 2.063331\tBest loss: 2.063331\tAccuracy: 49.70%\n",
      "98\tValidation loss: 2.063773\tBest loss: 2.063331\tAccuracy: 49.30%\n",
      "99\tValidation loss: 2.058991\tBest loss: 2.058991\tAccuracy: 50.40%\n",
      "100\tValidation loss: 2.053260\tBest loss: 2.053260\tAccuracy: 50.50%\n",
      "101\tValidation loss: 2.038425\tBest loss: 2.038425\tAccuracy: 50.60%\n",
      "102\tValidation loss: 2.041038\tBest loss: 2.038425\tAccuracy: 50.90%\n",
      "103\tValidation loss: 2.032651\tBest loss: 2.032651\tAccuracy: 51.10%\n",
      "104\tValidation loss: 2.014259\tBest loss: 2.014259\tAccuracy: 50.50%\n",
      "105\tValidation loss: 2.018165\tBest loss: 2.014259\tAccuracy: 51.70%\n",
      "106\tValidation loss: 2.008145\tBest loss: 2.008145\tAccuracy: 51.70%\n",
      "107\tValidation loss: 2.010761\tBest loss: 2.008145\tAccuracy: 51.10%\n",
      "108\tValidation loss: 1.998129\tBest loss: 1.998129\tAccuracy: 52.20%\n",
      "109\tValidation loss: 1.998990\tBest loss: 1.998129\tAccuracy: 52.60%\n",
      "110\tValidation loss: 1.990599\tBest loss: 1.990599\tAccuracy: 53.20%\n",
      "111\tValidation loss: 1.983319\tBest loss: 1.983319\tAccuracy: 53.20%\n",
      "112\tValidation loss: 1.971988\tBest loss: 1.971988\tAccuracy: 53.00%\n",
      "113\tValidation loss: 1.964835\tBest loss: 1.964835\tAccuracy: 53.00%\n",
      "114\tValidation loss: 1.962566\tBest loss: 1.962566\tAccuracy: 53.60%\n",
      "115\tValidation loss: 1.957227\tBest loss: 1.957227\tAccuracy: 52.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\tValidation loss: 1.954020\tBest loss: 1.954020\tAccuracy: 53.60%\n",
      "117\tValidation loss: 1.947719\tBest loss: 1.947719\tAccuracy: 53.60%\n",
      "118\tValidation loss: 1.945621\tBest loss: 1.945621\tAccuracy: 52.90%\n",
      "119\tValidation loss: 1.940595\tBest loss: 1.940595\tAccuracy: 53.70%\n",
      "120\tValidation loss: 1.935208\tBest loss: 1.935208\tAccuracy: 52.80%\n",
      "121\tValidation loss: 1.927594\tBest loss: 1.927594\tAccuracy: 54.20%\n",
      "122\tValidation loss: 1.924058\tBest loss: 1.924058\tAccuracy: 53.50%\n",
      "123\tValidation loss: 1.919860\tBest loss: 1.919860\tAccuracy: 53.40%\n",
      "124\tValidation loss: 1.915172\tBest loss: 1.915172\tAccuracy: 54.30%\n",
      "125\tValidation loss: 1.912615\tBest loss: 1.912615\tAccuracy: 54.20%\n",
      "126\tValidation loss: 1.910588\tBest loss: 1.910588\tAccuracy: 54.50%\n",
      "127\tValidation loss: 1.896437\tBest loss: 1.896437\tAccuracy: 54.10%\n",
      "128\tValidation loss: 1.891629\tBest loss: 1.891629\tAccuracy: 54.10%\n",
      "129\tValidation loss: 1.888421\tBest loss: 1.888421\tAccuracy: 54.60%\n",
      "130\tValidation loss: 1.885329\tBest loss: 1.885329\tAccuracy: 55.20%\n",
      "131\tValidation loss: 1.885732\tBest loss: 1.885329\tAccuracy: 55.30%\n",
      "132\tValidation loss: 1.877922\tBest loss: 1.877922\tAccuracy: 54.20%\n",
      "133\tValidation loss: 1.875264\tBest loss: 1.875264\tAccuracy: 54.90%\n",
      "134\tValidation loss: 1.870026\tBest loss: 1.870026\tAccuracy: 55.70%\n",
      "135\tValidation loss: 1.862335\tBest loss: 1.862335\tAccuracy: 55.50%\n",
      "136\tValidation loss: 1.861729\tBest loss: 1.861729\tAccuracy: 55.00%\n",
      "137\tValidation loss: 1.856579\tBest loss: 1.856579\tAccuracy: 55.70%\n",
      "138\tValidation loss: 1.861634\tBest loss: 1.856579\tAccuracy: 55.90%\n",
      "139\tValidation loss: 1.848244\tBest loss: 1.848244\tAccuracy: 55.10%\n",
      "140\tValidation loss: 1.841375\tBest loss: 1.841375\tAccuracy: 55.20%\n",
      "141\tValidation loss: 1.842124\tBest loss: 1.841375\tAccuracy: 55.10%\n",
      "142\tValidation loss: 1.838517\tBest loss: 1.838517\tAccuracy: 54.90%\n",
      "143\tValidation loss: 1.839920\tBest loss: 1.838517\tAccuracy: 55.30%\n",
      "144\tValidation loss: 1.834144\tBest loss: 1.834144\tAccuracy: 55.70%\n",
      "145\tValidation loss: 1.827044\tBest loss: 1.827044\tAccuracy: 57.20%\n",
      "146\tValidation loss: 1.829310\tBest loss: 1.827044\tAccuracy: 55.90%\n",
      "147\tValidation loss: 1.823189\tBest loss: 1.823189\tAccuracy: 55.80%\n",
      "148\tValidation loss: 1.827131\tBest loss: 1.823189\tAccuracy: 55.90%\n",
      "149\tValidation loss: 1.824290\tBest loss: 1.823189\tAccuracy: 56.00%\n",
      "150\tValidation loss: 1.810759\tBest loss: 1.810759\tAccuracy: 56.10%\n",
      "151\tValidation loss: 1.814343\tBest loss: 1.810759\tAccuracy: 56.50%\n",
      "152\tValidation loss: 1.809336\tBest loss: 1.809336\tAccuracy: 56.00%\n",
      "153\tValidation loss: 1.810877\tBest loss: 1.809336\tAccuracy: 57.20%\n",
      "154\tValidation loss: 1.808052\tBest loss: 1.808052\tAccuracy: 56.40%\n",
      "155\tValidation loss: 1.805287\tBest loss: 1.805287\tAccuracy: 57.00%\n",
      "156\tValidation loss: 1.798765\tBest loss: 1.798765\tAccuracy: 57.10%\n",
      "157\tValidation loss: 1.795989\tBest loss: 1.795989\tAccuracy: 57.70%\n",
      "158\tValidation loss: 1.794518\tBest loss: 1.794518\tAccuracy: 57.50%\n",
      "159\tValidation loss: 1.782555\tBest loss: 1.782555\tAccuracy: 57.30%\n",
      "160\tValidation loss: 1.778481\tBest loss: 1.778481\tAccuracy: 58.00%\n",
      "161\tValidation loss: 1.787548\tBest loss: 1.778481\tAccuracy: 57.60%\n",
      "162\tValidation loss: 1.779156\tBest loss: 1.778481\tAccuracy: 58.10%\n",
      "163\tValidation loss: 1.781268\tBest loss: 1.778481\tAccuracy: 57.90%\n",
      "164\tValidation loss: 1.771948\tBest loss: 1.771948\tAccuracy: 57.60%\n",
      "165\tValidation loss: 1.773092\tBest loss: 1.771948\tAccuracy: 58.30%\n",
      "166\tValidation loss: 1.771225\tBest loss: 1.771225\tAccuracy: 57.10%\n",
      "167\tValidation loss: 1.769179\tBest loss: 1.769179\tAccuracy: 56.90%\n",
      "168\tValidation loss: 1.767320\tBest loss: 1.767320\tAccuracy: 58.40%\n",
      "169\tValidation loss: 1.765117\tBest loss: 1.765117\tAccuracy: 57.80%\n",
      "170\tValidation loss: 1.760465\tBest loss: 1.760465\tAccuracy: 57.60%\n",
      "171\tValidation loss: 1.755886\tBest loss: 1.755886\tAccuracy: 58.60%\n",
      "172\tValidation loss: 1.754911\tBest loss: 1.754911\tAccuracy: 58.40%\n",
      "173\tValidation loss: 1.747928\tBest loss: 1.747928\tAccuracy: 57.40%\n",
      "174\tValidation loss: 1.748880\tBest loss: 1.747928\tAccuracy: 58.30%\n",
      "175\tValidation loss: 1.749334\tBest loss: 1.747928\tAccuracy: 58.00%\n",
      "176\tValidation loss: 1.744757\tBest loss: 1.744757\tAccuracy: 57.80%\n",
      "177\tValidation loss: 1.747647\tBest loss: 1.744757\tAccuracy: 58.50%\n",
      "178\tValidation loss: 1.739137\tBest loss: 1.739137\tAccuracy: 58.60%\n",
      "179\tValidation loss: 1.731878\tBest loss: 1.731878\tAccuracy: 58.80%\n",
      "180\tValidation loss: 1.743694\tBest loss: 1.731878\tAccuracy: 58.40%\n",
      "181\tValidation loss: 1.725831\tBest loss: 1.725831\tAccuracy: 58.80%\n",
      "182\tValidation loss: 1.726361\tBest loss: 1.725831\tAccuracy: 58.90%\n",
      "183\tValidation loss: 1.729822\tBest loss: 1.725831\tAccuracy: 58.60%\n",
      "184\tValidation loss: 1.725331\tBest loss: 1.725331\tAccuracy: 58.00%\n",
      "185\tValidation loss: 1.725394\tBest loss: 1.725331\tAccuracy: 58.30%\n",
      "186\tValidation loss: 1.719618\tBest loss: 1.719618\tAccuracy: 58.80%\n",
      "187\tValidation loss: 1.720482\tBest loss: 1.719618\tAccuracy: 58.20%\n",
      "188\tValidation loss: 1.714253\tBest loss: 1.714253\tAccuracy: 58.90%\n",
      "189\tValidation loss: 1.713164\tBest loss: 1.713164\tAccuracy: 58.40%\n",
      "190\tValidation loss: 1.709370\tBest loss: 1.709370\tAccuracy: 59.70%\n",
      "191\tValidation loss: 1.707138\tBest loss: 1.707138\tAccuracy: 58.90%\n",
      "192\tValidation loss: 1.706823\tBest loss: 1.706823\tAccuracy: 59.40%\n",
      "193\tValidation loss: 1.705348\tBest loss: 1.705348\tAccuracy: 59.20%\n",
      "194\tValidation loss: 1.701972\tBest loss: 1.701972\tAccuracy: 59.20%\n",
      "195\tValidation loss: 1.704358\tBest loss: 1.701972\tAccuracy: 58.50%\n",
      "196\tValidation loss: 1.707318\tBest loss: 1.701972\tAccuracy: 58.70%\n",
      "197\tValidation loss: 1.699177\tBest loss: 1.699177\tAccuracy: 59.50%\n",
      "198\tValidation loss: 1.699237\tBest loss: 1.699177\tAccuracy: 60.20%\n",
      "199\tValidation loss: 1.701966\tBest loss: 1.699177\tAccuracy: 59.60%\n",
      "200\tValidation loss: 1.697115\tBest loss: 1.697115\tAccuracy: 59.90%\n",
      "201\tValidation loss: 1.689489\tBest loss: 1.689489\tAccuracy: 60.00%\n",
      "202\tValidation loss: 1.692191\tBest loss: 1.689489\tAccuracy: 59.90%\n",
      "203\tValidation loss: 1.683627\tBest loss: 1.683627\tAccuracy: 59.30%\n",
      "204\tValidation loss: 1.688574\tBest loss: 1.683627\tAccuracy: 60.00%\n",
      "205\tValidation loss: 1.680593\tBest loss: 1.680593\tAccuracy: 59.60%\n",
      "206\tValidation loss: 1.680341\tBest loss: 1.680341\tAccuracy: 59.80%\n",
      "207\tValidation loss: 1.673013\tBest loss: 1.673013\tAccuracy: 59.70%\n",
      "208\tValidation loss: 1.671159\tBest loss: 1.671159\tAccuracy: 59.80%\n",
      "209\tValidation loss: 1.674074\tBest loss: 1.671159\tAccuracy: 59.90%\n",
      "210\tValidation loss: 1.670361\tBest loss: 1.670361\tAccuracy: 59.10%\n",
      "211\tValidation loss: 1.672053\tBest loss: 1.670361\tAccuracy: 60.40%\n",
      "212\tValidation loss: 1.664483\tBest loss: 1.664483\tAccuracy: 59.40%\n",
      "213\tValidation loss: 1.666954\tBest loss: 1.664483\tAccuracy: 60.10%\n",
      "214\tValidation loss: 1.663704\tBest loss: 1.663704\tAccuracy: 60.10%\n",
      "215\tValidation loss: 1.666919\tBest loss: 1.663704\tAccuracy: 59.50%\n",
      "216\tValidation loss: 1.660241\tBest loss: 1.660241\tAccuracy: 60.00%\n",
      "217\tValidation loss: 1.663152\tBest loss: 1.660241\tAccuracy: 59.60%\n",
      "218\tValidation loss: 1.649306\tBest loss: 1.649306\tAccuracy: 59.50%\n",
      "219\tValidation loss: 1.654256\tBest loss: 1.649306\tAccuracy: 60.40%\n",
      "220\tValidation loss: 1.657107\tBest loss: 1.649306\tAccuracy: 60.00%\n",
      "221\tValidation loss: 1.652591\tBest loss: 1.649306\tAccuracy: 60.20%\n",
      "222\tValidation loss: 1.648798\tBest loss: 1.648798\tAccuracy: 60.00%\n",
      "223\tValidation loss: 1.646673\tBest loss: 1.646673\tAccuracy: 59.90%\n",
      "224\tValidation loss: 1.637865\tBest loss: 1.637865\tAccuracy: 59.50%\n",
      "225\tValidation loss: 1.644463\tBest loss: 1.637865\tAccuracy: 59.30%\n",
      "226\tValidation loss: 1.640259\tBest loss: 1.637865\tAccuracy: 59.70%\n",
      "227\tValidation loss: 1.638118\tBest loss: 1.637865\tAccuracy: 59.60%\n",
      "228\tValidation loss: 1.639437\tBest loss: 1.637865\tAccuracy: 59.90%\n",
      "229\tValidation loss: 1.629793\tBest loss: 1.629793\tAccuracy: 59.40%\n",
      "230\tValidation loss: 1.635435\tBest loss: 1.629793\tAccuracy: 60.00%\n",
      "231\tValidation loss: 1.629046\tBest loss: 1.629046\tAccuracy: 60.20%\n",
      "232\tValidation loss: 1.634345\tBest loss: 1.629046\tAccuracy: 59.40%\n",
      "233\tValidation loss: 1.624686\tBest loss: 1.624686\tAccuracy: 59.90%\n",
      "234\tValidation loss: 1.627162\tBest loss: 1.624686\tAccuracy: 59.80%\n",
      "235\tValidation loss: 1.631022\tBest loss: 1.624686\tAccuracy: 60.40%\n",
      "236\tValidation loss: 1.624225\tBest loss: 1.624225\tAccuracy: 59.60%\n",
      "237\tValidation loss: 1.621547\tBest loss: 1.621547\tAccuracy: 59.70%\n",
      "238\tValidation loss: 1.623626\tBest loss: 1.621547\tAccuracy: 60.20%\n",
      "239\tValidation loss: 1.621724\tBest loss: 1.621547\tAccuracy: 60.30%\n",
      "240\tValidation loss: 1.623749\tBest loss: 1.621547\tAccuracy: 60.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\tValidation loss: 1.616605\tBest loss: 1.616605\tAccuracy: 60.10%\n",
      "242\tValidation loss: 1.611294\tBest loss: 1.611294\tAccuracy: 60.40%\n",
      "243\tValidation loss: 1.607928\tBest loss: 1.607928\tAccuracy: 60.30%\n",
      "244\tValidation loss: 1.606781\tBest loss: 1.606781\tAccuracy: 60.60%\n",
      "245\tValidation loss: 1.610480\tBest loss: 1.606781\tAccuracy: 60.70%\n",
      "246\tValidation loss: 1.607224\tBest loss: 1.606781\tAccuracy: 60.40%\n",
      "247\tValidation loss: 1.600834\tBest loss: 1.600834\tAccuracy: 60.90%\n",
      "248\tValidation loss: 1.603496\tBest loss: 1.600834\tAccuracy: 61.20%\n",
      "249\tValidation loss: 1.602232\tBest loss: 1.600834\tAccuracy: 60.80%\n",
      "250\tValidation loss: 1.601837\tBest loss: 1.600834\tAccuracy: 60.80%\n",
      "251\tValidation loss: 1.605571\tBest loss: 1.600834\tAccuracy: 60.70%\n",
      "252\tValidation loss: 1.597922\tBest loss: 1.597922\tAccuracy: 60.20%\n",
      "253\tValidation loss: 1.599756\tBest loss: 1.597922\tAccuracy: 60.40%\n",
      "254\tValidation loss: 1.599541\tBest loss: 1.597922\tAccuracy: 60.60%\n",
      "255\tValidation loss: 1.600342\tBest loss: 1.597922\tAccuracy: 60.80%\n",
      "256\tValidation loss: 1.599427\tBest loss: 1.597922\tAccuracy: 60.50%\n",
      "257\tValidation loss: 1.595935\tBest loss: 1.595935\tAccuracy: 60.40%\n",
      "258\tValidation loss: 1.591057\tBest loss: 1.591057\tAccuracy: 60.50%\n",
      "259\tValidation loss: 1.589561\tBest loss: 1.589561\tAccuracy: 61.10%\n",
      "260\tValidation loss: 1.592116\tBest loss: 1.589561\tAccuracy: 60.70%\n",
      "261\tValidation loss: 1.590719\tBest loss: 1.589561\tAccuracy: 60.20%\n",
      "262\tValidation loss: 1.595121\tBest loss: 1.589561\tAccuracy: 59.90%\n",
      "263\tValidation loss: 1.591970\tBest loss: 1.589561\tAccuracy: 60.70%\n",
      "264\tValidation loss: 1.589645\tBest loss: 1.589561\tAccuracy: 60.70%\n",
      "265\tValidation loss: 1.589817\tBest loss: 1.589561\tAccuracy: 59.70%\n",
      "266\tValidation loss: 1.587187\tBest loss: 1.587187\tAccuracy: 60.60%\n",
      "267\tValidation loss: 1.581276\tBest loss: 1.581276\tAccuracy: 60.50%\n",
      "268\tValidation loss: 1.578632\tBest loss: 1.578632\tAccuracy: 59.70%\n",
      "269\tValidation loss: 1.579361\tBest loss: 1.578632\tAccuracy: 59.90%\n",
      "270\tValidation loss: 1.575075\tBest loss: 1.575075\tAccuracy: 61.10%\n",
      "271\tValidation loss: 1.575572\tBest loss: 1.575075\tAccuracy: 61.10%\n",
      "272\tValidation loss: 1.580605\tBest loss: 1.575075\tAccuracy: 60.30%\n",
      "273\tValidation loss: 1.579455\tBest loss: 1.575075\tAccuracy: 60.20%\n",
      "274\tValidation loss: 1.579532\tBest loss: 1.575075\tAccuracy: 60.50%\n",
      "275\tValidation loss: 1.576152\tBest loss: 1.575075\tAccuracy: 60.90%\n",
      "276\tValidation loss: 1.570188\tBest loss: 1.570188\tAccuracy: 61.30%\n",
      "277\tValidation loss: 1.576347\tBest loss: 1.570188\tAccuracy: 61.20%\n",
      "278\tValidation loss: 1.571837\tBest loss: 1.570188\tAccuracy: 61.30%\n",
      "279\tValidation loss: 1.577953\tBest loss: 1.570188\tAccuracy: 60.70%\n",
      "280\tValidation loss: 1.574605\tBest loss: 1.570188\tAccuracy: 60.70%\n",
      "281\tValidation loss: 1.572316\tBest loss: 1.570188\tAccuracy: 60.80%\n",
      "282\tValidation loss: 1.568341\tBest loss: 1.568341\tAccuracy: 60.60%\n",
      "283\tValidation loss: 1.561709\tBest loss: 1.561709\tAccuracy: 60.80%\n",
      "284\tValidation loss: 1.559675\tBest loss: 1.559675\tAccuracy: 61.00%\n",
      "285\tValidation loss: 1.561652\tBest loss: 1.559675\tAccuracy: 61.10%\n",
      "286\tValidation loss: 1.559638\tBest loss: 1.559638\tAccuracy: 60.60%\n",
      "287\tValidation loss: 1.561300\tBest loss: 1.559638\tAccuracy: 60.70%\n",
      "288\tValidation loss: 1.555812\tBest loss: 1.555812\tAccuracy: 60.80%\n",
      "289\tValidation loss: 1.565195\tBest loss: 1.555812\tAccuracy: 60.60%\n",
      "290\tValidation loss: 1.559871\tBest loss: 1.555812\tAccuracy: 60.80%\n",
      "291\tValidation loss: 1.563014\tBest loss: 1.555812\tAccuracy: 60.30%\n",
      "292\tValidation loss: 1.559869\tBest loss: 1.555812\tAccuracy: 60.40%\n",
      "293\tValidation loss: 1.560989\tBest loss: 1.555812\tAccuracy: 60.90%\n",
      "294\tValidation loss: 1.559083\tBest loss: 1.555812\tAccuracy: 60.80%\n",
      "295\tValidation loss: 1.557247\tBest loss: 1.555812\tAccuracy: 61.10%\n",
      "296\tValidation loss: 1.556069\tBest loss: 1.555812\tAccuracy: 61.00%\n",
      "297\tValidation loss: 1.548353\tBest loss: 1.548353\tAccuracy: 61.60%\n",
      "298\tValidation loss: 1.551251\tBest loss: 1.548353\tAccuracy: 61.70%\n",
      "299\tValidation loss: 1.547160\tBest loss: 1.547160\tAccuracy: 61.50%\n",
      "300\tValidation loss: 1.554214\tBest loss: 1.547160\tAccuracy: 61.30%\n",
      "301\tValidation loss: 1.549454\tBest loss: 1.547160\tAccuracy: 61.50%\n",
      "302\tValidation loss: 1.546692\tBest loss: 1.546692\tAccuracy: 61.30%\n",
      "303\tValidation loss: 1.541380\tBest loss: 1.541380\tAccuracy: 60.90%\n",
      "304\tValidation loss: 1.541342\tBest loss: 1.541342\tAccuracy: 60.70%\n",
      "305\tValidation loss: 1.537241\tBest loss: 1.537241\tAccuracy: 61.70%\n",
      "306\tValidation loss: 1.532541\tBest loss: 1.532541\tAccuracy: 61.80%\n",
      "307\tValidation loss: 1.532145\tBest loss: 1.532145\tAccuracy: 61.70%\n",
      "308\tValidation loss: 1.534564\tBest loss: 1.532145\tAccuracy: 61.70%\n",
      "309\tValidation loss: 1.540005\tBest loss: 1.532145\tAccuracy: 62.00%\n",
      "310\tValidation loss: 1.533688\tBest loss: 1.532145\tAccuracy: 61.50%\n",
      "311\tValidation loss: 1.530560\tBest loss: 1.530560\tAccuracy: 61.90%\n",
      "312\tValidation loss: 1.533969\tBest loss: 1.530560\tAccuracy: 62.20%\n",
      "313\tValidation loss: 1.529808\tBest loss: 1.529808\tAccuracy: 61.70%\n",
      "314\tValidation loss: 1.530989\tBest loss: 1.529808\tAccuracy: 61.20%\n",
      "315\tValidation loss: 1.529339\tBest loss: 1.529339\tAccuracy: 61.30%\n",
      "316\tValidation loss: 1.534295\tBest loss: 1.529339\tAccuracy: 61.90%\n",
      "317\tValidation loss: 1.533076\tBest loss: 1.529339\tAccuracy: 61.30%\n",
      "318\tValidation loss: 1.528801\tBest loss: 1.528801\tAccuracy: 61.30%\n",
      "319\tValidation loss: 1.527827\tBest loss: 1.527827\tAccuracy: 62.60%\n",
      "320\tValidation loss: 1.522623\tBest loss: 1.522623\tAccuracy: 61.90%\n",
      "321\tValidation loss: 1.526442\tBest loss: 1.522623\tAccuracy: 61.60%\n",
      "322\tValidation loss: 1.527244\tBest loss: 1.522623\tAccuracy: 61.50%\n",
      "323\tValidation loss: 1.519961\tBest loss: 1.519961\tAccuracy: 61.40%\n",
      "324\tValidation loss: 1.521674\tBest loss: 1.519961\tAccuracy: 61.70%\n",
      "325\tValidation loss: 1.518505\tBest loss: 1.518505\tAccuracy: 61.10%\n",
      "326\tValidation loss: 1.520346\tBest loss: 1.518505\tAccuracy: 61.70%\n",
      "327\tValidation loss: 1.522248\tBest loss: 1.518505\tAccuracy: 61.10%\n",
      "328\tValidation loss: 1.525624\tBest loss: 1.518505\tAccuracy: 62.00%\n",
      "329\tValidation loss: 1.518357\tBest loss: 1.518357\tAccuracy: 62.50%\n",
      "330\tValidation loss: 1.511819\tBest loss: 1.511819\tAccuracy: 62.80%\n",
      "331\tValidation loss: 1.517794\tBest loss: 1.511819\tAccuracy: 63.10%\n",
      "332\tValidation loss: 1.517440\tBest loss: 1.511819\tAccuracy: 62.00%\n",
      "333\tValidation loss: 1.515418\tBest loss: 1.511819\tAccuracy: 62.10%\n",
      "334\tValidation loss: 1.516416\tBest loss: 1.511819\tAccuracy: 62.20%\n",
      "335\tValidation loss: 1.510202\tBest loss: 1.510202\tAccuracy: 62.00%\n",
      "336\tValidation loss: 1.510473\tBest loss: 1.510202\tAccuracy: 61.40%\n",
      "337\tValidation loss: 1.509861\tBest loss: 1.509861\tAccuracy: 62.00%\n",
      "338\tValidation loss: 1.508816\tBest loss: 1.508816\tAccuracy: 62.30%\n",
      "339\tValidation loss: 1.502752\tBest loss: 1.502752\tAccuracy: 62.10%\n",
      "340\tValidation loss: 1.505973\tBest loss: 1.502752\tAccuracy: 62.20%\n",
      "341\tValidation loss: 1.501424\tBest loss: 1.501424\tAccuracy: 62.10%\n",
      "342\tValidation loss: 1.503855\tBest loss: 1.501424\tAccuracy: 62.30%\n",
      "343\tValidation loss: 1.508120\tBest loss: 1.501424\tAccuracy: 62.50%\n",
      "344\tValidation loss: 1.506050\tBest loss: 1.501424\tAccuracy: 62.20%\n",
      "345\tValidation loss: 1.500632\tBest loss: 1.500632\tAccuracy: 62.10%\n",
      "346\tValidation loss: 1.500407\tBest loss: 1.500407\tAccuracy: 62.00%\n",
      "347\tValidation loss: 1.500715\tBest loss: 1.500407\tAccuracy: 62.00%\n",
      "348\tValidation loss: 1.503907\tBest loss: 1.500407\tAccuracy: 61.90%\n",
      "349\tValidation loss: 1.500695\tBest loss: 1.500407\tAccuracy: 62.20%\n",
      "350\tValidation loss: 1.505446\tBest loss: 1.500407\tAccuracy: 61.80%\n",
      "351\tValidation loss: 1.502675\tBest loss: 1.500407\tAccuracy: 62.20%\n",
      "352\tValidation loss: 1.493868\tBest loss: 1.493868\tAccuracy: 62.40%\n",
      "353\tValidation loss: 1.496212\tBest loss: 1.493868\tAccuracy: 62.30%\n",
      "354\tValidation loss: 1.495238\tBest loss: 1.493868\tAccuracy: 61.80%\n",
      "355\tValidation loss: 1.496318\tBest loss: 1.493868\tAccuracy: 62.40%\n",
      "356\tValidation loss: 1.496765\tBest loss: 1.493868\tAccuracy: 63.00%\n",
      "357\tValidation loss: 1.500307\tBest loss: 1.493868\tAccuracy: 61.80%\n",
      "358\tValidation loss: 1.494616\tBest loss: 1.493868\tAccuracy: 62.50%\n",
      "359\tValidation loss: 1.495556\tBest loss: 1.493868\tAccuracy: 62.40%\n",
      "360\tValidation loss: 1.495259\tBest loss: 1.493868\tAccuracy: 62.60%\n",
      "361\tValidation loss: 1.489729\tBest loss: 1.489729\tAccuracy: 62.10%\n",
      "362\tValidation loss: 1.490249\tBest loss: 1.489729\tAccuracy: 62.50%\n",
      "363\tValidation loss: 1.494845\tBest loss: 1.489729\tAccuracy: 62.40%\n",
      "364\tValidation loss: 1.492574\tBest loss: 1.489729\tAccuracy: 62.20%\n",
      "365\tValidation loss: 1.494452\tBest loss: 1.489729\tAccuracy: 62.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\tValidation loss: 1.486834\tBest loss: 1.486834\tAccuracy: 62.70%\n",
      "367\tValidation loss: 1.480618\tBest loss: 1.480618\tAccuracy: 63.20%\n",
      "368\tValidation loss: 1.488393\tBest loss: 1.480618\tAccuracy: 63.10%\n",
      "369\tValidation loss: 1.487319\tBest loss: 1.480618\tAccuracy: 62.50%\n",
      "370\tValidation loss: 1.486834\tBest loss: 1.480618\tAccuracy: 62.50%\n",
      "371\tValidation loss: 1.487822\tBest loss: 1.480618\tAccuracy: 62.30%\n",
      "372\tValidation loss: 1.483056\tBest loss: 1.480618\tAccuracy: 63.00%\n",
      "373\tValidation loss: 1.485093\tBest loss: 1.480618\tAccuracy: 62.80%\n",
      "374\tValidation loss: 1.483162\tBest loss: 1.480618\tAccuracy: 62.90%\n",
      "375\tValidation loss: 1.482112\tBest loss: 1.480618\tAccuracy: 62.60%\n",
      "376\tValidation loss: 1.483435\tBest loss: 1.480618\tAccuracy: 62.40%\n",
      "377\tValidation loss: 1.478676\tBest loss: 1.478676\tAccuracy: 62.80%\n",
      "378\tValidation loss: 1.483168\tBest loss: 1.478676\tAccuracy: 63.40%\n",
      "379\tValidation loss: 1.476581\tBest loss: 1.476581\tAccuracy: 63.60%\n",
      "380\tValidation loss: 1.478479\tBest loss: 1.476581\tAccuracy: 62.60%\n",
      "381\tValidation loss: 1.479392\tBest loss: 1.476581\tAccuracy: 62.60%\n",
      "382\tValidation loss: 1.474777\tBest loss: 1.474777\tAccuracy: 63.10%\n",
      "383\tValidation loss: 1.477524\tBest loss: 1.474777\tAccuracy: 63.30%\n",
      "384\tValidation loss: 1.476002\tBest loss: 1.474777\tAccuracy: 63.30%\n",
      "385\tValidation loss: 1.479382\tBest loss: 1.474777\tAccuracy: 63.40%\n",
      "386\tValidation loss: 1.475655\tBest loss: 1.474777\tAccuracy: 63.10%\n",
      "387\tValidation loss: 1.476667\tBest loss: 1.474777\tAccuracy: 63.00%\n",
      "388\tValidation loss: 1.475568\tBest loss: 1.474777\tAccuracy: 63.50%\n",
      "389\tValidation loss: 1.475832\tBest loss: 1.474777\tAccuracy: 62.20%\n",
      "390\tValidation loss: 1.469237\tBest loss: 1.469237\tAccuracy: 63.40%\n",
      "391\tValidation loss: 1.474768\tBest loss: 1.469237\tAccuracy: 63.30%\n",
      "392\tValidation loss: 1.467850\tBest loss: 1.467850\tAccuracy: 62.70%\n",
      "393\tValidation loss: 1.470525\tBest loss: 1.467850\tAccuracy: 63.00%\n",
      "394\tValidation loss: 1.470510\tBest loss: 1.467850\tAccuracy: 62.80%\n",
      "395\tValidation loss: 1.465007\tBest loss: 1.465007\tAccuracy: 63.70%\n",
      "396\tValidation loss: 1.468869\tBest loss: 1.465007\tAccuracy: 63.10%\n",
      "397\tValidation loss: 1.467336\tBest loss: 1.465007\tAccuracy: 63.40%\n",
      "398\tValidation loss: 1.468733\tBest loss: 1.465007\tAccuracy: 63.00%\n",
      "399\tValidation loss: 1.461460\tBest loss: 1.461460\tAccuracy: 63.80%\n",
      "400\tValidation loss: 1.459485\tBest loss: 1.459485\tAccuracy: 63.40%\n",
      "401\tValidation loss: 1.465369\tBest loss: 1.459485\tAccuracy: 62.90%\n",
      "402\tValidation loss: 1.458924\tBest loss: 1.458924\tAccuracy: 63.30%\n",
      "403\tValidation loss: 1.456190\tBest loss: 1.456190\tAccuracy: 63.80%\n",
      "404\tValidation loss: 1.457218\tBest loss: 1.456190\tAccuracy: 63.20%\n",
      "405\tValidation loss: 1.460777\tBest loss: 1.456190\tAccuracy: 63.20%\n",
      "406\tValidation loss: 1.458177\tBest loss: 1.456190\tAccuracy: 62.90%\n",
      "407\tValidation loss: 1.464445\tBest loss: 1.456190\tAccuracy: 62.90%\n",
      "408\tValidation loss: 1.458017\tBest loss: 1.456190\tAccuracy: 63.10%\n",
      "409\tValidation loss: 1.455855\tBest loss: 1.455855\tAccuracy: 63.40%\n",
      "410\tValidation loss: 1.460987\tBest loss: 1.455855\tAccuracy: 63.00%\n",
      "411\tValidation loss: 1.453079\tBest loss: 1.453079\tAccuracy: 63.10%\n",
      "412\tValidation loss: 1.457335\tBest loss: 1.453079\tAccuracy: 63.10%\n",
      "413\tValidation loss: 1.460208\tBest loss: 1.453079\tAccuracy: 63.60%\n",
      "414\tValidation loss: 1.459083\tBest loss: 1.453079\tAccuracy: 63.70%\n",
      "415\tValidation loss: 1.454990\tBest loss: 1.453079\tAccuracy: 63.60%\n",
      "416\tValidation loss: 1.456447\tBest loss: 1.453079\tAccuracy: 63.40%\n",
      "417\tValidation loss: 1.446703\tBest loss: 1.446703\tAccuracy: 63.90%\n",
      "418\tValidation loss: 1.452369\tBest loss: 1.446703\tAccuracy: 64.20%\n",
      "419\tValidation loss: 1.449927\tBest loss: 1.446703\tAccuracy: 63.50%\n",
      "420\tValidation loss: 1.455552\tBest loss: 1.446703\tAccuracy: 63.50%\n",
      "421\tValidation loss: 1.453039\tBest loss: 1.446703\tAccuracy: 63.80%\n",
      "422\tValidation loss: 1.453784\tBest loss: 1.446703\tAccuracy: 63.70%\n",
      "423\tValidation loss: 1.449845\tBest loss: 1.446703\tAccuracy: 63.00%\n",
      "424\tValidation loss: 1.450613\tBest loss: 1.446703\tAccuracy: 63.10%\n",
      "425\tValidation loss: 1.449915\tBest loss: 1.446703\tAccuracy: 63.50%\n",
      "426\tValidation loss: 1.447861\tBest loss: 1.446703\tAccuracy: 63.80%\n",
      "427\tValidation loss: 1.447574\tBest loss: 1.446703\tAccuracy: 63.90%\n",
      "428\tValidation loss: 1.446088\tBest loss: 1.446088\tAccuracy: 63.80%\n",
      "429\tValidation loss: 1.444927\tBest loss: 1.444927\tAccuracy: 63.60%\n",
      "430\tValidation loss: 1.443570\tBest loss: 1.443570\tAccuracy: 63.60%\n",
      "431\tValidation loss: 1.443907\tBest loss: 1.443570\tAccuracy: 64.10%\n",
      "432\tValidation loss: 1.441427\tBest loss: 1.441427\tAccuracy: 63.40%\n",
      "433\tValidation loss: 1.439665\tBest loss: 1.439665\tAccuracy: 64.20%\n",
      "434\tValidation loss: 1.443556\tBest loss: 1.439665\tAccuracy: 63.60%\n",
      "435\tValidation loss: 1.439225\tBest loss: 1.439225\tAccuracy: 64.30%\n",
      "436\tValidation loss: 1.439899\tBest loss: 1.439225\tAccuracy: 64.30%\n",
      "437\tValidation loss: 1.442874\tBest loss: 1.439225\tAccuracy: 63.60%\n",
      "438\tValidation loss: 1.441150\tBest loss: 1.439225\tAccuracy: 63.80%\n",
      "439\tValidation loss: 1.442759\tBest loss: 1.439225\tAccuracy: 63.80%\n",
      "440\tValidation loss: 1.440740\tBest loss: 1.439225\tAccuracy: 63.80%\n",
      "441\tValidation loss: 1.443733\tBest loss: 1.439225\tAccuracy: 63.60%\n",
      "442\tValidation loss: 1.437614\tBest loss: 1.437614\tAccuracy: 64.20%\n",
      "443\tValidation loss: 1.436650\tBest loss: 1.436650\tAccuracy: 64.30%\n",
      "444\tValidation loss: 1.443616\tBest loss: 1.436650\tAccuracy: 63.70%\n",
      "445\tValidation loss: 1.437335\tBest loss: 1.436650\tAccuracy: 64.50%\n",
      "446\tValidation loss: 1.440977\tBest loss: 1.436650\tAccuracy: 64.70%\n",
      "447\tValidation loss: 1.442772\tBest loss: 1.436650\tAccuracy: 63.90%\n",
      "448\tValidation loss: 1.437107\tBest loss: 1.436650\tAccuracy: 64.50%\n",
      "449\tValidation loss: 1.442648\tBest loss: 1.436650\tAccuracy: 64.60%\n",
      "450\tValidation loss: 1.440354\tBest loss: 1.436650\tAccuracy: 64.10%\n",
      "451\tValidation loss: 1.435317\tBest loss: 1.435317\tAccuracy: 64.30%\n",
      "452\tValidation loss: 1.431259\tBest loss: 1.431259\tAccuracy: 64.20%\n",
      "453\tValidation loss: 1.431507\tBest loss: 1.431259\tAccuracy: 64.30%\n",
      "454\tValidation loss: 1.437582\tBest loss: 1.431259\tAccuracy: 63.90%\n",
      "455\tValidation loss: 1.431240\tBest loss: 1.431240\tAccuracy: 64.60%\n",
      "456\tValidation loss: 1.437185\tBest loss: 1.431240\tAccuracy: 63.80%\n",
      "457\tValidation loss: 1.434804\tBest loss: 1.431240\tAccuracy: 64.30%\n",
      "458\tValidation loss: 1.436682\tBest loss: 1.431240\tAccuracy: 63.90%\n",
      "459\tValidation loss: 1.430912\tBest loss: 1.430912\tAccuracy: 64.50%\n",
      "460\tValidation loss: 1.427561\tBest loss: 1.427561\tAccuracy: 64.60%\n",
      "461\tValidation loss: 1.430647\tBest loss: 1.427561\tAccuracy: 64.10%\n",
      "462\tValidation loss: 1.430049\tBest loss: 1.427561\tAccuracy: 63.90%\n",
      "463\tValidation loss: 1.421281\tBest loss: 1.421281\tAccuracy: 64.30%\n",
      "464\tValidation loss: 1.426187\tBest loss: 1.421281\tAccuracy: 64.40%\n",
      "465\tValidation loss: 1.430695\tBest loss: 1.421281\tAccuracy: 63.90%\n",
      "466\tValidation loss: 1.428706\tBest loss: 1.421281\tAccuracy: 64.60%\n",
      "467\tValidation loss: 1.429071\tBest loss: 1.421281\tAccuracy: 64.10%\n",
      "468\tValidation loss: 1.420405\tBest loss: 1.420405\tAccuracy: 65.00%\n",
      "469\tValidation loss: 1.419555\tBest loss: 1.419555\tAccuracy: 64.80%\n",
      "470\tValidation loss: 1.422299\tBest loss: 1.419555\tAccuracy: 64.30%\n",
      "471\tValidation loss: 1.424224\tBest loss: 1.419555\tAccuracy: 63.90%\n",
      "472\tValidation loss: 1.425211\tBest loss: 1.419555\tAccuracy: 64.70%\n",
      "473\tValidation loss: 1.428166\tBest loss: 1.419555\tAccuracy: 63.50%\n",
      "474\tValidation loss: 1.423317\tBest loss: 1.419555\tAccuracy: 64.40%\n",
      "475\tValidation loss: 1.420025\tBest loss: 1.419555\tAccuracy: 64.30%\n",
      "476\tValidation loss: 1.420567\tBest loss: 1.419555\tAccuracy: 64.10%\n",
      "477\tValidation loss: 1.417195\tBest loss: 1.417195\tAccuracy: 64.80%\n",
      "478\tValidation loss: 1.416716\tBest loss: 1.416716\tAccuracy: 64.50%\n",
      "479\tValidation loss: 1.419413\tBest loss: 1.416716\tAccuracy: 63.90%\n",
      "480\tValidation loss: 1.416916\tBest loss: 1.416716\tAccuracy: 64.30%\n",
      "481\tValidation loss: 1.412505\tBest loss: 1.412505\tAccuracy: 65.00%\n",
      "482\tValidation loss: 1.414115\tBest loss: 1.412505\tAccuracy: 65.20%\n",
      "483\tValidation loss: 1.415172\tBest loss: 1.412505\tAccuracy: 64.90%\n",
      "484\tValidation loss: 1.413363\tBest loss: 1.412505\tAccuracy: 64.40%\n",
      "485\tValidation loss: 1.412636\tBest loss: 1.412505\tAccuracy: 65.20%\n",
      "486\tValidation loss: 1.417071\tBest loss: 1.412505\tAccuracy: 64.40%\n",
      "487\tValidation loss: 1.414671\tBest loss: 1.412505\tAccuracy: 65.20%\n",
      "488\tValidation loss: 1.416932\tBest loss: 1.412505\tAccuracy: 64.70%\n",
      "489\tValidation loss: 1.414342\tBest loss: 1.412505\tAccuracy: 64.40%\n",
      "490\tValidation loss: 1.410350\tBest loss: 1.410350\tAccuracy: 64.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\tValidation loss: 1.415083\tBest loss: 1.410350\tAccuracy: 64.70%\n",
      "492\tValidation loss: 1.415439\tBest loss: 1.410350\tAccuracy: 64.40%\n",
      "493\tValidation loss: 1.411734\tBest loss: 1.410350\tAccuracy: 65.00%\n",
      "494\tValidation loss: 1.409730\tBest loss: 1.409730\tAccuracy: 64.60%\n",
      "495\tValidation loss: 1.407206\tBest loss: 1.407206\tAccuracy: 64.70%\n",
      "496\tValidation loss: 1.409912\tBest loss: 1.407206\tAccuracy: 65.00%\n",
      "497\tValidation loss: 1.411347\tBest loss: 1.407206\tAccuracy: 64.50%\n",
      "498\tValidation loss: 1.412955\tBest loss: 1.407206\tAccuracy: 65.10%\n",
      "499\tValidation loss: 1.414344\tBest loss: 1.407206\tAccuracy: 65.00%\n",
      "500\tValidation loss: 1.416882\tBest loss: 1.407206\tAccuracy: 64.70%\n",
      "501\tValidation loss: 1.409698\tBest loss: 1.407206\tAccuracy: 64.60%\n",
      "502\tValidation loss: 1.409032\tBest loss: 1.407206\tAccuracy: 65.00%\n",
      "503\tValidation loss: 1.403625\tBest loss: 1.403625\tAccuracy: 65.20%\n",
      "504\tValidation loss: 1.404300\tBest loss: 1.403625\tAccuracy: 65.00%\n",
      "505\tValidation loss: 1.399590\tBest loss: 1.399590\tAccuracy: 65.20%\n",
      "506\tValidation loss: 1.403075\tBest loss: 1.399590\tAccuracy: 64.60%\n",
      "507\tValidation loss: 1.400776\tBest loss: 1.399590\tAccuracy: 64.40%\n",
      "508\tValidation loss: 1.404131\tBest loss: 1.399590\tAccuracy: 64.90%\n",
      "509\tValidation loss: 1.403602\tBest loss: 1.399590\tAccuracy: 64.40%\n",
      "510\tValidation loss: 1.404588\tBest loss: 1.399590\tAccuracy: 64.90%\n",
      "511\tValidation loss: 1.400055\tBest loss: 1.399590\tAccuracy: 64.70%\n",
      "512\tValidation loss: 1.401489\tBest loss: 1.399590\tAccuracy: 65.40%\n",
      "513\tValidation loss: 1.402725\tBest loss: 1.399590\tAccuracy: 65.00%\n",
      "514\tValidation loss: 1.397843\tBest loss: 1.397843\tAccuracy: 64.80%\n",
      "515\tValidation loss: 1.401840\tBest loss: 1.397843\tAccuracy: 64.80%\n",
      "516\tValidation loss: 1.402308\tBest loss: 1.397843\tAccuracy: 65.50%\n",
      "517\tValidation loss: 1.404200\tBest loss: 1.397843\tAccuracy: 64.60%\n",
      "518\tValidation loss: 1.400620\tBest loss: 1.397843\tAccuracy: 64.80%\n",
      "519\tValidation loss: 1.390501\tBest loss: 1.390501\tAccuracy: 65.00%\n",
      "520\tValidation loss: 1.393516\tBest loss: 1.390501\tAccuracy: 65.00%\n",
      "521\tValidation loss: 1.399733\tBest loss: 1.390501\tAccuracy: 65.00%\n",
      "522\tValidation loss: 1.399432\tBest loss: 1.390501\tAccuracy: 65.30%\n",
      "523\tValidation loss: 1.400110\tBest loss: 1.390501\tAccuracy: 64.80%\n",
      "524\tValidation loss: 1.399325\tBest loss: 1.390501\tAccuracy: 64.80%\n",
      "525\tValidation loss: 1.398572\tBest loss: 1.390501\tAccuracy: 65.30%\n",
      "526\tValidation loss: 1.395830\tBest loss: 1.390501\tAccuracy: 65.40%\n",
      "527\tValidation loss: 1.394006\tBest loss: 1.390501\tAccuracy: 64.60%\n",
      "528\tValidation loss: 1.398974\tBest loss: 1.390501\tAccuracy: 65.00%\n",
      "529\tValidation loss: 1.399218\tBest loss: 1.390501\tAccuracy: 65.40%\n",
      "530\tValidation loss: 1.400740\tBest loss: 1.390501\tAccuracy: 65.00%\n",
      "531\tValidation loss: 1.398702\tBest loss: 1.390501\tAccuracy: 64.50%\n",
      "532\tValidation loss: 1.395062\tBest loss: 1.390501\tAccuracy: 65.40%\n",
      "533\tValidation loss: 1.392922\tBest loss: 1.390501\tAccuracy: 64.70%\n",
      "534\tValidation loss: 1.395656\tBest loss: 1.390501\tAccuracy: 64.80%\n",
      "535\tValidation loss: 1.389633\tBest loss: 1.389633\tAccuracy: 64.70%\n",
      "536\tValidation loss: 1.392658\tBest loss: 1.389633\tAccuracy: 64.90%\n",
      "537\tValidation loss: 1.391516\tBest loss: 1.389633\tAccuracy: 64.80%\n",
      "538\tValidation loss: 1.385679\tBest loss: 1.385679\tAccuracy: 65.50%\n",
      "539\tValidation loss: 1.389072\tBest loss: 1.385679\tAccuracy: 64.70%\n",
      "540\tValidation loss: 1.388383\tBest loss: 1.385679\tAccuracy: 65.20%\n",
      "541\tValidation loss: 1.392468\tBest loss: 1.385679\tAccuracy: 64.90%\n",
      "542\tValidation loss: 1.386624\tBest loss: 1.385679\tAccuracy: 65.70%\n",
      "543\tValidation loss: 1.392506\tBest loss: 1.385679\tAccuracy: 64.90%\n",
      "544\tValidation loss: 1.386161\tBest loss: 1.385679\tAccuracy: 65.50%\n",
      "545\tValidation loss: 1.385854\tBest loss: 1.385679\tAccuracy: 65.50%\n",
      "546\tValidation loss: 1.388812\tBest loss: 1.385679\tAccuracy: 64.60%\n",
      "547\tValidation loss: 1.385590\tBest loss: 1.385590\tAccuracy: 65.70%\n",
      "548\tValidation loss: 1.391384\tBest loss: 1.385590\tAccuracy: 64.30%\n",
      "549\tValidation loss: 1.389296\tBest loss: 1.385590\tAccuracy: 64.60%\n",
      "550\tValidation loss: 1.390940\tBest loss: 1.385590\tAccuracy: 65.20%\n",
      "551\tValidation loss: 1.387762\tBest loss: 1.385590\tAccuracy: 64.80%\n",
      "552\tValidation loss: 1.387708\tBest loss: 1.385590\tAccuracy: 64.60%\n",
      "553\tValidation loss: 1.395807\tBest loss: 1.385590\tAccuracy: 65.60%\n",
      "554\tValidation loss: 1.391578\tBest loss: 1.385590\tAccuracy: 65.00%\n",
      "555\tValidation loss: 1.394055\tBest loss: 1.385590\tAccuracy: 65.30%\n",
      "556\tValidation loss: 1.384351\tBest loss: 1.384351\tAccuracy: 65.90%\n",
      "557\tValidation loss: 1.383338\tBest loss: 1.383338\tAccuracy: 65.70%\n",
      "558\tValidation loss: 1.386219\tBest loss: 1.383338\tAccuracy: 65.20%\n",
      "559\tValidation loss: 1.384723\tBest loss: 1.383338\tAccuracy: 64.50%\n",
      "560\tValidation loss: 1.383074\tBest loss: 1.383074\tAccuracy: 65.40%\n",
      "561\tValidation loss: 1.381212\tBest loss: 1.381212\tAccuracy: 65.90%\n",
      "562\tValidation loss: 1.387315\tBest loss: 1.381212\tAccuracy: 64.90%\n",
      "563\tValidation loss: 1.385200\tBest loss: 1.381212\tAccuracy: 65.80%\n",
      "564\tValidation loss: 1.385651\tBest loss: 1.381212\tAccuracy: 65.80%\n",
      "565\tValidation loss: 1.381482\tBest loss: 1.381212\tAccuracy: 65.50%\n",
      "566\tValidation loss: 1.389332\tBest loss: 1.381212\tAccuracy: 66.10%\n",
      "567\tValidation loss: 1.385636\tBest loss: 1.381212\tAccuracy: 65.20%\n",
      "568\tValidation loss: 1.381999\tBest loss: 1.381212\tAccuracy: 65.30%\n",
      "569\tValidation loss: 1.379487\tBest loss: 1.379487\tAccuracy: 65.10%\n",
      "570\tValidation loss: 1.384297\tBest loss: 1.379487\tAccuracy: 65.40%\n",
      "571\tValidation loss: 1.384217\tBest loss: 1.379487\tAccuracy: 65.50%\n",
      "572\tValidation loss: 1.378770\tBest loss: 1.378770\tAccuracy: 65.50%\n",
      "573\tValidation loss: 1.379931\tBest loss: 1.378770\tAccuracy: 65.00%\n",
      "574\tValidation loss: 1.381895\tBest loss: 1.378770\tAccuracy: 64.90%\n",
      "575\tValidation loss: 1.380885\tBest loss: 1.378770\tAccuracy: 65.00%\n",
      "576\tValidation loss: 1.377261\tBest loss: 1.377261\tAccuracy: 65.30%\n",
      "577\tValidation loss: 1.382824\tBest loss: 1.377261\tAccuracy: 65.60%\n",
      "578\tValidation loss: 1.378363\tBest loss: 1.377261\tAccuracy: 65.40%\n",
      "579\tValidation loss: 1.377822\tBest loss: 1.377261\tAccuracy: 65.00%\n",
      "580\tValidation loss: 1.378205\tBest loss: 1.377261\tAccuracy: 65.20%\n",
      "581\tValidation loss: 1.377366\tBest loss: 1.377261\tAccuracy: 65.00%\n",
      "582\tValidation loss: 1.379527\tBest loss: 1.377261\tAccuracy: 64.80%\n",
      "583\tValidation loss: 1.373454\tBest loss: 1.373454\tAccuracy: 65.00%\n",
      "584\tValidation loss: 1.374018\tBest loss: 1.373454\tAccuracy: 65.40%\n",
      "585\tValidation loss: 1.375025\tBest loss: 1.373454\tAccuracy: 65.50%\n",
      "586\tValidation loss: 1.377250\tBest loss: 1.373454\tAccuracy: 65.50%\n",
      "587\tValidation loss: 1.372256\tBest loss: 1.372256\tAccuracy: 65.40%\n",
      "588\tValidation loss: 1.382120\tBest loss: 1.372256\tAccuracy: 65.10%\n",
      "589\tValidation loss: 1.372386\tBest loss: 1.372256\tAccuracy: 65.80%\n",
      "590\tValidation loss: 1.372235\tBest loss: 1.372235\tAccuracy: 65.80%\n",
      "591\tValidation loss: 1.375799\tBest loss: 1.372235\tAccuracy: 65.50%\n",
      "592\tValidation loss: 1.370530\tBest loss: 1.370530\tAccuracy: 66.50%\n",
      "593\tValidation loss: 1.378964\tBest loss: 1.370530\tAccuracy: 66.10%\n",
      "594\tValidation loss: 1.378175\tBest loss: 1.370530\tAccuracy: 66.30%\n",
      "595\tValidation loss: 1.375686\tBest loss: 1.370530\tAccuracy: 65.50%\n",
      "596\tValidation loss: 1.374324\tBest loss: 1.370530\tAccuracy: 65.60%\n",
      "597\tValidation loss: 1.371793\tBest loss: 1.370530\tAccuracy: 65.80%\n",
      "598\tValidation loss: 1.371507\tBest loss: 1.370530\tAccuracy: 65.70%\n",
      "599\tValidation loss: 1.369575\tBest loss: 1.369575\tAccuracy: 66.10%\n",
      "600\tValidation loss: 1.367411\tBest loss: 1.367411\tAccuracy: 66.00%\n",
      "601\tValidation loss: 1.373338\tBest loss: 1.367411\tAccuracy: 65.20%\n",
      "602\tValidation loss: 1.374236\tBest loss: 1.367411\tAccuracy: 65.60%\n",
      "603\tValidation loss: 1.372423\tBest loss: 1.367411\tAccuracy: 66.70%\n",
      "604\tValidation loss: 1.371500\tBest loss: 1.367411\tAccuracy: 65.50%\n",
      "605\tValidation loss: 1.378456\tBest loss: 1.367411\tAccuracy: 65.90%\n",
      "606\tValidation loss: 1.376541\tBest loss: 1.367411\tAccuracy: 65.80%\n",
      "607\tValidation loss: 1.370552\tBest loss: 1.367411\tAccuracy: 66.10%\n",
      "608\tValidation loss: 1.368034\tBest loss: 1.367411\tAccuracy: 65.50%\n",
      "609\tValidation loss: 1.371780\tBest loss: 1.367411\tAccuracy: 65.50%\n",
      "610\tValidation loss: 1.374243\tBest loss: 1.367411\tAccuracy: 66.00%\n",
      "611\tValidation loss: 1.364823\tBest loss: 1.364823\tAccuracy: 65.80%\n",
      "612\tValidation loss: 1.364065\tBest loss: 1.364065\tAccuracy: 66.30%\n",
      "613\tValidation loss: 1.371571\tBest loss: 1.364065\tAccuracy: 65.40%\n",
      "614\tValidation loss: 1.371588\tBest loss: 1.364065\tAccuracy: 66.00%\n",
      "615\tValidation loss: 1.370155\tBest loss: 1.364065\tAccuracy: 65.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\tValidation loss: 1.368181\tBest loss: 1.364065\tAccuracy: 65.60%\n",
      "617\tValidation loss: 1.363957\tBest loss: 1.363957\tAccuracy: 65.70%\n",
      "618\tValidation loss: 1.368885\tBest loss: 1.363957\tAccuracy: 66.10%\n",
      "619\tValidation loss: 1.372449\tBest loss: 1.363957\tAccuracy: 66.00%\n",
      "620\tValidation loss: 1.366748\tBest loss: 1.363957\tAccuracy: 66.60%\n",
      "621\tValidation loss: 1.370658\tBest loss: 1.363957\tAccuracy: 65.70%\n",
      "622\tValidation loss: 1.372194\tBest loss: 1.363957\tAccuracy: 66.10%\n",
      "623\tValidation loss: 1.360760\tBest loss: 1.360760\tAccuracy: 65.90%\n",
      "624\tValidation loss: 1.364874\tBest loss: 1.360760\tAccuracy: 66.40%\n",
      "625\tValidation loss: 1.359668\tBest loss: 1.359668\tAccuracy: 66.70%\n",
      "626\tValidation loss: 1.359817\tBest loss: 1.359668\tAccuracy: 66.70%\n",
      "627\tValidation loss: 1.363325\tBest loss: 1.359668\tAccuracy: 66.00%\n",
      "628\tValidation loss: 1.363202\tBest loss: 1.359668\tAccuracy: 65.60%\n",
      "629\tValidation loss: 1.363474\tBest loss: 1.359668\tAccuracy: 66.30%\n",
      "630\tValidation loss: 1.367737\tBest loss: 1.359668\tAccuracy: 66.00%\n",
      "631\tValidation loss: 1.365100\tBest loss: 1.359668\tAccuracy: 65.90%\n",
      "632\tValidation loss: 1.364837\tBest loss: 1.359668\tAccuracy: 66.30%\n",
      "633\tValidation loss: 1.366480\tBest loss: 1.359668\tAccuracy: 65.60%\n",
      "634\tValidation loss: 1.361978\tBest loss: 1.359668\tAccuracy: 65.70%\n",
      "635\tValidation loss: 1.361490\tBest loss: 1.359668\tAccuracy: 65.40%\n",
      "636\tValidation loss: 1.364091\tBest loss: 1.359668\tAccuracy: 65.80%\n",
      "637\tValidation loss: 1.360466\tBest loss: 1.359668\tAccuracy: 66.20%\n",
      "638\tValidation loss: 1.359035\tBest loss: 1.359035\tAccuracy: 66.10%\n",
      "639\tValidation loss: 1.362544\tBest loss: 1.359035\tAccuracy: 66.20%\n",
      "640\tValidation loss: 1.358355\tBest loss: 1.358355\tAccuracy: 65.10%\n",
      "641\tValidation loss: 1.349701\tBest loss: 1.349701\tAccuracy: 66.60%\n",
      "642\tValidation loss: 1.354125\tBest loss: 1.349701\tAccuracy: 66.00%\n",
      "643\tValidation loss: 1.354245\tBest loss: 1.349701\tAccuracy: 65.90%\n",
      "644\tValidation loss: 1.354162\tBest loss: 1.349701\tAccuracy: 65.30%\n",
      "645\tValidation loss: 1.352365\tBest loss: 1.349701\tAccuracy: 66.30%\n",
      "646\tValidation loss: 1.361191\tBest loss: 1.349701\tAccuracy: 65.30%\n",
      "647\tValidation loss: 1.361615\tBest loss: 1.349701\tAccuracy: 66.00%\n",
      "648\tValidation loss: 1.358977\tBest loss: 1.349701\tAccuracy: 64.90%\n",
      "649\tValidation loss: 1.358223\tBest loss: 1.349701\tAccuracy: 65.90%\n",
      "650\tValidation loss: 1.354957\tBest loss: 1.349701\tAccuracy: 66.10%\n",
      "651\tValidation loss: 1.357548\tBest loss: 1.349701\tAccuracy: 65.80%\n",
      "652\tValidation loss: 1.355986\tBest loss: 1.349701\tAccuracy: 66.30%\n",
      "653\tValidation loss: 1.360925\tBest loss: 1.349701\tAccuracy: 65.90%\n",
      "654\tValidation loss: 1.359631\tBest loss: 1.349701\tAccuracy: 65.70%\n",
      "655\tValidation loss: 1.357742\tBest loss: 1.349701\tAccuracy: 65.80%\n",
      "656\tValidation loss: 1.359189\tBest loss: 1.349701\tAccuracy: 66.40%\n",
      "657\tValidation loss: 1.348729\tBest loss: 1.348729\tAccuracy: 66.90%\n",
      "658\tValidation loss: 1.349472\tBest loss: 1.348729\tAccuracy: 66.80%\n",
      "659\tValidation loss: 1.350565\tBest loss: 1.348729\tAccuracy: 65.90%\n",
      "660\tValidation loss: 1.353750\tBest loss: 1.348729\tAccuracy: 66.40%\n",
      "661\tValidation loss: 1.348933\tBest loss: 1.348729\tAccuracy: 66.30%\n",
      "662\tValidation loss: 1.351870\tBest loss: 1.348729\tAccuracy: 65.70%\n",
      "663\tValidation loss: 1.358208\tBest loss: 1.348729\tAccuracy: 66.00%\n",
      "664\tValidation loss: 1.351611\tBest loss: 1.348729\tAccuracy: 66.20%\n",
      "665\tValidation loss: 1.350468\tBest loss: 1.348729\tAccuracy: 66.80%\n",
      "666\tValidation loss: 1.350532\tBest loss: 1.348729\tAccuracy: 66.90%\n",
      "667\tValidation loss: 1.353313\tBest loss: 1.348729\tAccuracy: 66.00%\n",
      "668\tValidation loss: 1.350216\tBest loss: 1.348729\tAccuracy: 66.00%\n",
      "669\tValidation loss: 1.345361\tBest loss: 1.345361\tAccuracy: 66.00%\n",
      "670\tValidation loss: 1.348411\tBest loss: 1.345361\tAccuracy: 66.20%\n",
      "671\tValidation loss: 1.349979\tBest loss: 1.345361\tAccuracy: 65.90%\n",
      "672\tValidation loss: 1.348201\tBest loss: 1.345361\tAccuracy: 66.30%\n",
      "673\tValidation loss: 1.351027\tBest loss: 1.345361\tAccuracy: 66.20%\n",
      "674\tValidation loss: 1.344613\tBest loss: 1.344613\tAccuracy: 66.30%\n",
      "675\tValidation loss: 1.348618\tBest loss: 1.344613\tAccuracy: 66.30%\n",
      "676\tValidation loss: 1.350491\tBest loss: 1.344613\tAccuracy: 66.40%\n",
      "677\tValidation loss: 1.346357\tBest loss: 1.344613\tAccuracy: 66.70%\n",
      "678\tValidation loss: 1.345671\tBest loss: 1.344613\tAccuracy: 66.80%\n",
      "679\tValidation loss: 1.340220\tBest loss: 1.340220\tAccuracy: 67.00%\n",
      "680\tValidation loss: 1.339377\tBest loss: 1.339377\tAccuracy: 66.90%\n",
      "681\tValidation loss: 1.339569\tBest loss: 1.339377\tAccuracy: 67.00%\n",
      "682\tValidation loss: 1.344978\tBest loss: 1.339377\tAccuracy: 66.30%\n",
      "683\tValidation loss: 1.344689\tBest loss: 1.339377\tAccuracy: 66.90%\n",
      "684\tValidation loss: 1.345176\tBest loss: 1.339377\tAccuracy: 66.70%\n",
      "685\tValidation loss: 1.340838\tBest loss: 1.339377\tAccuracy: 66.80%\n",
      "686\tValidation loss: 1.345417\tBest loss: 1.339377\tAccuracy: 66.20%\n",
      "687\tValidation loss: 1.344594\tBest loss: 1.339377\tAccuracy: 66.20%\n",
      "688\tValidation loss: 1.341320\tBest loss: 1.339377\tAccuracy: 66.50%\n",
      "689\tValidation loss: 1.338394\tBest loss: 1.338394\tAccuracy: 66.30%\n",
      "690\tValidation loss: 1.346774\tBest loss: 1.338394\tAccuracy: 65.90%\n",
      "691\tValidation loss: 1.347556\tBest loss: 1.338394\tAccuracy: 65.50%\n",
      "692\tValidation loss: 1.342421\tBest loss: 1.338394\tAccuracy: 65.80%\n",
      "693\tValidation loss: 1.340660\tBest loss: 1.338394\tAccuracy: 66.10%\n",
      "694\tValidation loss: 1.336163\tBest loss: 1.336163\tAccuracy: 67.00%\n",
      "695\tValidation loss: 1.341881\tBest loss: 1.336163\tAccuracy: 65.90%\n",
      "696\tValidation loss: 1.342155\tBest loss: 1.336163\tAccuracy: 65.90%\n",
      "697\tValidation loss: 1.339650\tBest loss: 1.336163\tAccuracy: 65.80%\n",
      "698\tValidation loss: 1.340654\tBest loss: 1.336163\tAccuracy: 65.50%\n",
      "699\tValidation loss: 1.340439\tBest loss: 1.336163\tAccuracy: 65.90%\n",
      "700\tValidation loss: 1.336877\tBest loss: 1.336163\tAccuracy: 66.70%\n",
      "701\tValidation loss: 1.339692\tBest loss: 1.336163\tAccuracy: 66.60%\n",
      "702\tValidation loss: 1.341088\tBest loss: 1.336163\tAccuracy: 66.60%\n",
      "703\tValidation loss: 1.339238\tBest loss: 1.336163\tAccuracy: 66.30%\n",
      "704\tValidation loss: 1.335460\tBest loss: 1.335460\tAccuracy: 67.00%\n",
      "705\tValidation loss: 1.337107\tBest loss: 1.335460\tAccuracy: 66.40%\n",
      "706\tValidation loss: 1.344430\tBest loss: 1.335460\tAccuracy: 66.00%\n",
      "707\tValidation loss: 1.344483\tBest loss: 1.335460\tAccuracy: 65.90%\n",
      "708\tValidation loss: 1.339314\tBest loss: 1.335460\tAccuracy: 66.30%\n",
      "709\tValidation loss: 1.343287\tBest loss: 1.335460\tAccuracy: 65.70%\n",
      "710\tValidation loss: 1.341153\tBest loss: 1.335460\tAccuracy: 66.10%\n",
      "711\tValidation loss: 1.337257\tBest loss: 1.335460\tAccuracy: 66.70%\n",
      "712\tValidation loss: 1.337064\tBest loss: 1.335460\tAccuracy: 66.30%\n",
      "713\tValidation loss: 1.332399\tBest loss: 1.332399\tAccuracy: 66.90%\n",
      "714\tValidation loss: 1.337263\tBest loss: 1.332399\tAccuracy: 66.70%\n",
      "715\tValidation loss: 1.335806\tBest loss: 1.332399\tAccuracy: 66.40%\n",
      "716\tValidation loss: 1.343012\tBest loss: 1.332399\tAccuracy: 66.40%\n",
      "717\tValidation loss: 1.339585\tBest loss: 1.332399\tAccuracy: 66.10%\n",
      "718\tValidation loss: 1.337193\tBest loss: 1.332399\tAccuracy: 66.40%\n",
      "719\tValidation loss: 1.331770\tBest loss: 1.331770\tAccuracy: 67.00%\n",
      "720\tValidation loss: 1.336159\tBest loss: 1.331770\tAccuracy: 66.80%\n",
      "721\tValidation loss: 1.342024\tBest loss: 1.331770\tAccuracy: 66.00%\n",
      "722\tValidation loss: 1.337442\tBest loss: 1.331770\tAccuracy: 66.80%\n",
      "723\tValidation loss: 1.334277\tBest loss: 1.331770\tAccuracy: 66.50%\n",
      "724\tValidation loss: 1.332788\tBest loss: 1.331770\tAccuracy: 66.50%\n",
      "725\tValidation loss: 1.332595\tBest loss: 1.331770\tAccuracy: 66.20%\n",
      "726\tValidation loss: 1.336561\tBest loss: 1.331770\tAccuracy: 66.80%\n",
      "727\tValidation loss: 1.334474\tBest loss: 1.331770\tAccuracy: 67.00%\n",
      "728\tValidation loss: 1.335008\tBest loss: 1.331770\tAccuracy: 66.50%\n",
      "729\tValidation loss: 1.336902\tBest loss: 1.331770\tAccuracy: 66.60%\n",
      "730\tValidation loss: 1.339332\tBest loss: 1.331770\tAccuracy: 66.70%\n",
      "731\tValidation loss: 1.331854\tBest loss: 1.331770\tAccuracy: 66.60%\n",
      "732\tValidation loss: 1.331328\tBest loss: 1.331328\tAccuracy: 66.80%\n",
      "733\tValidation loss: 1.335927\tBest loss: 1.331328\tAccuracy: 66.40%\n",
      "734\tValidation loss: 1.330709\tBest loss: 1.330709\tAccuracy: 66.80%\n",
      "735\tValidation loss: 1.329229\tBest loss: 1.329229\tAccuracy: 67.60%\n",
      "736\tValidation loss: 1.334579\tBest loss: 1.329229\tAccuracy: 66.90%\n",
      "737\tValidation loss: 1.334389\tBest loss: 1.329229\tAccuracy: 66.90%\n",
      "738\tValidation loss: 1.331812\tBest loss: 1.329229\tAccuracy: 67.00%\n",
      "739\tValidation loss: 1.330166\tBest loss: 1.329229\tAccuracy: 67.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\tValidation loss: 1.328846\tBest loss: 1.328846\tAccuracy: 67.20%\n",
      "741\tValidation loss: 1.331211\tBest loss: 1.328846\tAccuracy: 67.00%\n",
      "742\tValidation loss: 1.328945\tBest loss: 1.328846\tAccuracy: 66.80%\n",
      "743\tValidation loss: 1.332689\tBest loss: 1.328846\tAccuracy: 67.10%\n",
      "744\tValidation loss: 1.326228\tBest loss: 1.326228\tAccuracy: 67.10%\n",
      "745\tValidation loss: 1.323190\tBest loss: 1.323190\tAccuracy: 67.30%\n",
      "746\tValidation loss: 1.324198\tBest loss: 1.323190\tAccuracy: 66.20%\n",
      "747\tValidation loss: 1.324275\tBest loss: 1.323190\tAccuracy: 67.00%\n",
      "748\tValidation loss: 1.323204\tBest loss: 1.323190\tAccuracy: 67.00%\n",
      "749\tValidation loss: 1.323941\tBest loss: 1.323190\tAccuracy: 67.00%\n",
      "750\tValidation loss: 1.326852\tBest loss: 1.323190\tAccuracy: 67.20%\n",
      "751\tValidation loss: 1.323632\tBest loss: 1.323190\tAccuracy: 66.70%\n",
      "752\tValidation loss: 1.321685\tBest loss: 1.321685\tAccuracy: 66.70%\n",
      "753\tValidation loss: 1.324655\tBest loss: 1.321685\tAccuracy: 67.30%\n",
      "754\tValidation loss: 1.324250\tBest loss: 1.321685\tAccuracy: 66.80%\n",
      "755\tValidation loss: 1.321549\tBest loss: 1.321549\tAccuracy: 67.20%\n",
      "756\tValidation loss: 1.328491\tBest loss: 1.321549\tAccuracy: 67.00%\n",
      "757\tValidation loss: 1.320041\tBest loss: 1.320041\tAccuracy: 67.40%\n",
      "758\tValidation loss: 1.323205\tBest loss: 1.320041\tAccuracy: 67.10%\n",
      "759\tValidation loss: 1.322666\tBest loss: 1.320041\tAccuracy: 67.30%\n",
      "760\tValidation loss: 1.320044\tBest loss: 1.320041\tAccuracy: 67.20%\n",
      "761\tValidation loss: 1.322617\tBest loss: 1.320041\tAccuracy: 66.70%\n",
      "762\tValidation loss: 1.322385\tBest loss: 1.320041\tAccuracy: 66.90%\n",
      "763\tValidation loss: 1.323855\tBest loss: 1.320041\tAccuracy: 66.90%\n",
      "764\tValidation loss: 1.324648\tBest loss: 1.320041\tAccuracy: 66.70%\n",
      "765\tValidation loss: 1.320412\tBest loss: 1.320041\tAccuracy: 66.50%\n",
      "766\tValidation loss: 1.323482\tBest loss: 1.320041\tAccuracy: 66.80%\n",
      "767\tValidation loss: 1.322824\tBest loss: 1.320041\tAccuracy: 67.20%\n",
      "768\tValidation loss: 1.317580\tBest loss: 1.317580\tAccuracy: 66.70%\n",
      "769\tValidation loss: 1.322428\tBest loss: 1.317580\tAccuracy: 66.60%\n",
      "770\tValidation loss: 1.315410\tBest loss: 1.315410\tAccuracy: 66.70%\n",
      "771\tValidation loss: 1.318119\tBest loss: 1.315410\tAccuracy: 67.40%\n",
      "772\tValidation loss: 1.322336\tBest loss: 1.315410\tAccuracy: 66.20%\n",
      "773\tValidation loss: 1.326243\tBest loss: 1.315410\tAccuracy: 66.30%\n",
      "774\tValidation loss: 1.315566\tBest loss: 1.315410\tAccuracy: 66.90%\n",
      "775\tValidation loss: 1.322072\tBest loss: 1.315410\tAccuracy: 66.80%\n",
      "776\tValidation loss: 1.322200\tBest loss: 1.315410\tAccuracy: 66.30%\n",
      "777\tValidation loss: 1.323801\tBest loss: 1.315410\tAccuracy: 66.60%\n",
      "778\tValidation loss: 1.323706\tBest loss: 1.315410\tAccuracy: 67.00%\n",
      "779\tValidation loss: 1.319872\tBest loss: 1.315410\tAccuracy: 67.00%\n",
      "780\tValidation loss: 1.320333\tBest loss: 1.315410\tAccuracy: 66.40%\n",
      "781\tValidation loss: 1.322617\tBest loss: 1.315410\tAccuracy: 66.50%\n",
      "782\tValidation loss: 1.325890\tBest loss: 1.315410\tAccuracy: 66.70%\n",
      "783\tValidation loss: 1.323164\tBest loss: 1.315410\tAccuracy: 66.30%\n",
      "784\tValidation loss: 1.322683\tBest loss: 1.315410\tAccuracy: 66.40%\n",
      "785\tValidation loss: 1.322376\tBest loss: 1.315410\tAccuracy: 66.60%\n",
      "786\tValidation loss: 1.321412\tBest loss: 1.315410\tAccuracy: 66.90%\n",
      "787\tValidation loss: 1.322496\tBest loss: 1.315410\tAccuracy: 66.10%\n",
      "788\tValidation loss: 1.322319\tBest loss: 1.315410\tAccuracy: 67.00%\n",
      "789\tValidation loss: 1.315310\tBest loss: 1.315310\tAccuracy: 66.90%\n",
      "790\tValidation loss: 1.311734\tBest loss: 1.311734\tAccuracy: 67.10%\n",
      "791\tValidation loss: 1.315859\tBest loss: 1.311734\tAccuracy: 66.80%\n",
      "792\tValidation loss: 1.312845\tBest loss: 1.311734\tAccuracy: 67.10%\n",
      "793\tValidation loss: 1.313916\tBest loss: 1.311734\tAccuracy: 67.20%\n",
      "794\tValidation loss: 1.315824\tBest loss: 1.311734\tAccuracy: 66.80%\n",
      "795\tValidation loss: 1.307970\tBest loss: 1.307970\tAccuracy: 67.30%\n",
      "796\tValidation loss: 1.315135\tBest loss: 1.307970\tAccuracy: 66.80%\n",
      "797\tValidation loss: 1.313091\tBest loss: 1.307970\tAccuracy: 66.90%\n",
      "798\tValidation loss: 1.312093\tBest loss: 1.307970\tAccuracy: 67.20%\n",
      "799\tValidation loss: 1.316918\tBest loss: 1.307970\tAccuracy: 66.70%\n",
      "800\tValidation loss: 1.310618\tBest loss: 1.307970\tAccuracy: 66.70%\n",
      "801\tValidation loss: 1.312866\tBest loss: 1.307970\tAccuracy: 67.20%\n",
      "802\tValidation loss: 1.318076\tBest loss: 1.307970\tAccuracy: 67.20%\n",
      "803\tValidation loss: 1.315935\tBest loss: 1.307970\tAccuracy: 66.60%\n",
      "804\tValidation loss: 1.312779\tBest loss: 1.307970\tAccuracy: 67.30%\n",
      "805\tValidation loss: 1.315104\tBest loss: 1.307970\tAccuracy: 67.40%\n",
      "806\tValidation loss: 1.311820\tBest loss: 1.307970\tAccuracy: 67.10%\n",
      "807\tValidation loss: 1.310632\tBest loss: 1.307970\tAccuracy: 67.10%\n",
      "808\tValidation loss: 1.308490\tBest loss: 1.307970\tAccuracy: 67.20%\n",
      "809\tValidation loss: 1.311788\tBest loss: 1.307970\tAccuracy: 67.20%\n",
      "810\tValidation loss: 1.311245\tBest loss: 1.307970\tAccuracy: 67.00%\n",
      "811\tValidation loss: 1.307860\tBest loss: 1.307860\tAccuracy: 66.70%\n",
      "812\tValidation loss: 1.310831\tBest loss: 1.307860\tAccuracy: 66.00%\n",
      "813\tValidation loss: 1.308404\tBest loss: 1.307860\tAccuracy: 67.60%\n",
      "814\tValidation loss: 1.309355\tBest loss: 1.307860\tAccuracy: 67.40%\n",
      "815\tValidation loss: 1.307707\tBest loss: 1.307707\tAccuracy: 67.00%\n",
      "816\tValidation loss: 1.307528\tBest loss: 1.307528\tAccuracy: 66.90%\n",
      "817\tValidation loss: 1.314753\tBest loss: 1.307528\tAccuracy: 66.30%\n",
      "818\tValidation loss: 1.313810\tBest loss: 1.307528\tAccuracy: 66.90%\n",
      "819\tValidation loss: 1.309717\tBest loss: 1.307528\tAccuracy: 67.80%\n",
      "820\tValidation loss: 1.313418\tBest loss: 1.307528\tAccuracy: 66.80%\n",
      "821\tValidation loss: 1.310030\tBest loss: 1.307528\tAccuracy: 67.20%\n",
      "822\tValidation loss: 1.308410\tBest loss: 1.307528\tAccuracy: 67.20%\n",
      "823\tValidation loss: 1.310255\tBest loss: 1.307528\tAccuracy: 66.90%\n",
      "824\tValidation loss: 1.310487\tBest loss: 1.307528\tAccuracy: 66.60%\n",
      "825\tValidation loss: 1.307652\tBest loss: 1.307528\tAccuracy: 66.50%\n",
      "826\tValidation loss: 1.305764\tBest loss: 1.305764\tAccuracy: 67.20%\n",
      "827\tValidation loss: 1.310506\tBest loss: 1.305764\tAccuracy: 66.70%\n",
      "828\tValidation loss: 1.315485\tBest loss: 1.305764\tAccuracy: 67.10%\n",
      "829\tValidation loss: 1.314005\tBest loss: 1.305764\tAccuracy: 66.60%\n",
      "830\tValidation loss: 1.307989\tBest loss: 1.305764\tAccuracy: 67.30%\n",
      "831\tValidation loss: 1.315678\tBest loss: 1.305764\tAccuracy: 66.40%\n",
      "832\tValidation loss: 1.313613\tBest loss: 1.305764\tAccuracy: 66.60%\n",
      "833\tValidation loss: 1.313235\tBest loss: 1.305764\tAccuracy: 66.30%\n",
      "834\tValidation loss: 1.309834\tBest loss: 1.305764\tAccuracy: 66.70%\n",
      "835\tValidation loss: 1.311265\tBest loss: 1.305764\tAccuracy: 66.90%\n",
      "836\tValidation loss: 1.313644\tBest loss: 1.305764\tAccuracy: 66.60%\n",
      "837\tValidation loss: 1.306186\tBest loss: 1.305764\tAccuracy: 66.90%\n",
      "838\tValidation loss: 1.312744\tBest loss: 1.305764\tAccuracy: 66.10%\n",
      "839\tValidation loss: 1.307600\tBest loss: 1.305764\tAccuracy: 67.00%\n",
      "840\tValidation loss: 1.307584\tBest loss: 1.305764\tAccuracy: 67.20%\n",
      "841\tValidation loss: 1.308616\tBest loss: 1.305764\tAccuracy: 67.30%\n",
      "842\tValidation loss: 1.309670\tBest loss: 1.305764\tAccuracy: 66.90%\n",
      "843\tValidation loss: 1.311305\tBest loss: 1.305764\tAccuracy: 67.50%\n",
      "844\tValidation loss: 1.305906\tBest loss: 1.305764\tAccuracy: 66.70%\n",
      "845\tValidation loss: 1.304738\tBest loss: 1.304738\tAccuracy: 67.50%\n",
      "846\tValidation loss: 1.307010\tBest loss: 1.304738\tAccuracy: 67.70%\n",
      "847\tValidation loss: 1.308272\tBest loss: 1.304738\tAccuracy: 66.90%\n",
      "848\tValidation loss: 1.309562\tBest loss: 1.304738\tAccuracy: 67.30%\n",
      "849\tValidation loss: 1.303134\tBest loss: 1.303134\tAccuracy: 67.00%\n",
      "850\tValidation loss: 1.302679\tBest loss: 1.302679\tAccuracy: 67.40%\n",
      "851\tValidation loss: 1.306475\tBest loss: 1.302679\tAccuracy: 67.30%\n",
      "852\tValidation loss: 1.302676\tBest loss: 1.302676\tAccuracy: 67.90%\n",
      "853\tValidation loss: 1.303437\tBest loss: 1.302676\tAccuracy: 67.30%\n",
      "854\tValidation loss: 1.304640\tBest loss: 1.302676\tAccuracy: 67.80%\n",
      "855\tValidation loss: 1.304493\tBest loss: 1.302676\tAccuracy: 66.90%\n",
      "856\tValidation loss: 1.295363\tBest loss: 1.295363\tAccuracy: 67.80%\n",
      "857\tValidation loss: 1.300675\tBest loss: 1.295363\tAccuracy: 67.00%\n",
      "858\tValidation loss: 1.301056\tBest loss: 1.295363\tAccuracy: 67.30%\n",
      "859\tValidation loss: 1.304742\tBest loss: 1.295363\tAccuracy: 66.30%\n",
      "860\tValidation loss: 1.303852\tBest loss: 1.295363\tAccuracy: 66.80%\n",
      "861\tValidation loss: 1.303973\tBest loss: 1.295363\tAccuracy: 67.30%\n",
      "862\tValidation loss: 1.306476\tBest loss: 1.295363\tAccuracy: 66.40%\n",
      "863\tValidation loss: 1.300505\tBest loss: 1.295363\tAccuracy: 67.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\tValidation loss: 1.308388\tBest loss: 1.295363\tAccuracy: 67.10%\n",
      "865\tValidation loss: 1.305506\tBest loss: 1.295363\tAccuracy: 67.60%\n",
      "866\tValidation loss: 1.303724\tBest loss: 1.295363\tAccuracy: 67.30%\n",
      "867\tValidation loss: 1.304526\tBest loss: 1.295363\tAccuracy: 67.50%\n",
      "868\tValidation loss: 1.305359\tBest loss: 1.295363\tAccuracy: 66.70%\n",
      "869\tValidation loss: 1.303381\tBest loss: 1.295363\tAccuracy: 66.90%\n",
      "870\tValidation loss: 1.300074\tBest loss: 1.295363\tAccuracy: 67.30%\n",
      "871\tValidation loss: 1.299667\tBest loss: 1.295363\tAccuracy: 67.50%\n",
      "872\tValidation loss: 1.303715\tBest loss: 1.295363\tAccuracy: 66.90%\n",
      "873\tValidation loss: 1.300059\tBest loss: 1.295363\tAccuracy: 67.40%\n",
      "874\tValidation loss: 1.302035\tBest loss: 1.295363\tAccuracy: 67.50%\n",
      "875\tValidation loss: 1.303353\tBest loss: 1.295363\tAccuracy: 67.40%\n",
      "876\tValidation loss: 1.303433\tBest loss: 1.295363\tAccuracy: 67.30%\n",
      "877\tValidation loss: 1.305442\tBest loss: 1.295363\tAccuracy: 66.90%\n",
      "Early stopping!\n",
      "[[  2.00315719e-11   3.15426519e-07   2.81656869e-02 ...,   1.36181802e-10\n",
      "    1.88794715e-07   1.57790048e-09]\n",
      " [  8.65483599e-20   2.53308724e-12   3.69625268e-11 ...,   1.24807831e-30\n",
      "    1.80092765e-27   8.39285486e-25]\n",
      " [  6.66596162e-12   5.56806903e-08   2.68438105e-10 ...,   2.34574374e-14\n",
      "    3.24944040e-17   9.64827278e-15]\n",
      " ..., \n",
      " [  2.51052243e-05   6.18767517e-04   6.73798379e-04 ...,   8.03300180e-03\n",
      "    6.93634944e-03   2.29209997e-02]\n",
      " [  1.04321204e-10   1.89179557e-11   1.01165725e-11 ...,   2.13010520e-01\n",
      "    1.36579499e-02   1.10515570e-02]\n",
      " [  6.22572124e-20   1.21637043e-12   2.48559246e-12 ...,   3.49739275e-04\n",
      "    2.61036999e-04   9.40244272e-03]]\n",
      "[43 43 43 ..., 36 24 27]\n",
      "[[  6.64507670e-17   5.67650148e-13   5.90785667e-12 ...,   5.47561624e-29\n",
      "    4.08078363e-25   9.00807604e-24]\n",
      " [  7.83237517e-02   3.02254148e-02   7.51370415e-02 ...,   1.19181387e-02\n",
      "    6.79917168e-03   5.94273442e-03]\n",
      " [  6.57328363e-21   6.02493421e-33   2.03655964e-11 ...,   6.01394536e-22\n",
      "    4.13201258e-29   2.02535161e-31]\n",
      " ..., \n",
      " [  2.14827423e-06   9.10070958e-06   3.56193186e-06 ...,   6.99301889e-15\n",
      "    1.71113536e-12   2.05882318e-14]\n",
      " [  3.51915807e-02   2.46260054e-02   2.77728364e-02 ...,   1.66381020e-02\n",
      "    1.16022322e-02   1.46717150e-02]\n",
      " [  4.07893375e-25   2.98515421e-19   7.30091951e-25 ...,   2.86570980e-06\n",
      "    2.35959087e-05   9.98839915e-01]]\n",
      "[20  0 16 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  42.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 6.059563\tBest loss: 6.059563\tAccuracy: 8.90%\n",
      "1\tValidation loss: 4.807093\tBest loss: 4.807093\tAccuracy: 10.90%\n",
      "2\tValidation loss: 4.283303\tBest loss: 4.283303\tAccuracy: 10.80%\n",
      "3\tValidation loss: 4.004782\tBest loss: 4.004782\tAccuracy: 12.20%\n",
      "4\tValidation loss: 3.859682\tBest loss: 3.859682\tAccuracy: 11.50%\n",
      "5\tValidation loss: 3.774773\tBest loss: 3.774773\tAccuracy: 12.20%\n",
      "6\tValidation loss: 3.707478\tBest loss: 3.707478\tAccuracy: 13.60%\n",
      "7\tValidation loss: 3.648432\tBest loss: 3.648432\tAccuracy: 13.10%\n",
      "8\tValidation loss: 3.584576\tBest loss: 3.584576\tAccuracy: 14.90%\n",
      "9\tValidation loss: 3.549969\tBest loss: 3.549969\tAccuracy: 15.30%\n",
      "10\tValidation loss: 3.493976\tBest loss: 3.493976\tAccuracy: 15.80%\n",
      "11\tValidation loss: 3.452138\tBest loss: 3.452138\tAccuracy: 16.00%\n",
      "12\tValidation loss: 3.402633\tBest loss: 3.402633\tAccuracy: 17.80%\n",
      "13\tValidation loss: 3.390718\tBest loss: 3.390718\tAccuracy: 17.20%\n",
      "14\tValidation loss: 3.334189\tBest loss: 3.334189\tAccuracy: 18.80%\n",
      "15\tValidation loss: 3.312386\tBest loss: 3.312386\tAccuracy: 19.30%\n",
      "16\tValidation loss: 3.284132\tBest loss: 3.284132\tAccuracy: 20.50%\n",
      "17\tValidation loss: 3.249096\tBest loss: 3.249096\tAccuracy: 20.10%\n",
      "18\tValidation loss: 3.223508\tBest loss: 3.223508\tAccuracy: 21.40%\n",
      "19\tValidation loss: 3.182686\tBest loss: 3.182686\tAccuracy: 21.60%\n",
      "20\tValidation loss: 3.158123\tBest loss: 3.158123\tAccuracy: 23.00%\n",
      "21\tValidation loss: 3.135135\tBest loss: 3.135135\tAccuracy: 23.30%\n",
      "22\tValidation loss: 3.116076\tBest loss: 3.116076\tAccuracy: 25.10%\n",
      "23\tValidation loss: 3.082168\tBest loss: 3.082168\tAccuracy: 25.40%\n",
      "24\tValidation loss: 3.065213\tBest loss: 3.065213\tAccuracy: 25.20%\n",
      "25\tValidation loss: 3.032746\tBest loss: 3.032746\tAccuracy: 24.80%\n",
      "26\tValidation loss: 3.015206\tBest loss: 3.015206\tAccuracy: 27.40%\n",
      "27\tValidation loss: 3.008557\tBest loss: 3.008557\tAccuracy: 26.70%\n",
      "28\tValidation loss: 2.976975\tBest loss: 2.976975\tAccuracy: 26.50%\n",
      "29\tValidation loss: 2.951192\tBest loss: 2.951192\tAccuracy: 27.60%\n",
      "30\tValidation loss: 2.931627\tBest loss: 2.931627\tAccuracy: 29.10%\n",
      "31\tValidation loss: 2.910995\tBest loss: 2.910995\tAccuracy: 29.10%\n",
      "32\tValidation loss: 2.889448\tBest loss: 2.889448\tAccuracy: 28.40%\n",
      "33\tValidation loss: 2.858207\tBest loss: 2.858207\tAccuracy: 29.40%\n",
      "34\tValidation loss: 2.837051\tBest loss: 2.837051\tAccuracy: 30.60%\n",
      "35\tValidation loss: 2.822704\tBest loss: 2.822704\tAccuracy: 30.90%\n",
      "36\tValidation loss: 2.813004\tBest loss: 2.813004\tAccuracy: 30.50%\n",
      "37\tValidation loss: 2.777750\tBest loss: 2.777750\tAccuracy: 32.10%\n",
      "38\tValidation loss: 2.751684\tBest loss: 2.751684\tAccuracy: 32.10%\n",
      "39\tValidation loss: 2.738674\tBest loss: 2.738674\tAccuracy: 33.30%\n",
      "40\tValidation loss: 2.724679\tBest loss: 2.724679\tAccuracy: 33.30%\n",
      "41\tValidation loss: 2.710324\tBest loss: 2.710324\tAccuracy: 33.10%\n",
      "42\tValidation loss: 2.694835\tBest loss: 2.694835\tAccuracy: 34.90%\n",
      "43\tValidation loss: 2.673383\tBest loss: 2.673383\tAccuracy: 35.10%\n",
      "44\tValidation loss: 2.663065\tBest loss: 2.663065\tAccuracy: 35.00%\n",
      "45\tValidation loss: 2.643448\tBest loss: 2.643448\tAccuracy: 35.80%\n",
      "46\tValidation loss: 2.624064\tBest loss: 2.624064\tAccuracy: 36.90%\n",
      "47\tValidation loss: 2.611087\tBest loss: 2.611087\tAccuracy: 36.90%\n",
      "48\tValidation loss: 2.598039\tBest loss: 2.598039\tAccuracy: 37.30%\n",
      "49\tValidation loss: 2.580460\tBest loss: 2.580460\tAccuracy: 37.50%\n",
      "50\tValidation loss: 2.557367\tBest loss: 2.557367\tAccuracy: 38.20%\n",
      "51\tValidation loss: 2.542561\tBest loss: 2.542561\tAccuracy: 37.90%\n",
      "52\tValidation loss: 2.530309\tBest loss: 2.530309\tAccuracy: 38.60%\n",
      "53\tValidation loss: 2.522421\tBest loss: 2.522421\tAccuracy: 39.50%\n",
      "54\tValidation loss: 2.502735\tBest loss: 2.502735\tAccuracy: 39.40%\n",
      "55\tValidation loss: 2.487689\tBest loss: 2.487689\tAccuracy: 40.10%\n",
      "56\tValidation loss: 2.469446\tBest loss: 2.469446\tAccuracy: 40.90%\n",
      "57\tValidation loss: 2.463284\tBest loss: 2.463284\tAccuracy: 40.50%\n",
      "58\tValidation loss: 2.444915\tBest loss: 2.444915\tAccuracy: 41.50%\n",
      "59\tValidation loss: 2.427965\tBest loss: 2.427965\tAccuracy: 41.10%\n",
      "60\tValidation loss: 2.410612\tBest loss: 2.410612\tAccuracy: 42.20%\n",
      "61\tValidation loss: 2.395011\tBest loss: 2.395011\tAccuracy: 41.90%\n",
      "62\tValidation loss: 2.389415\tBest loss: 2.389415\tAccuracy: 42.40%\n",
      "63\tValidation loss: 2.371954\tBest loss: 2.371954\tAccuracy: 43.50%\n",
      "64\tValidation loss: 2.360774\tBest loss: 2.360774\tAccuracy: 42.80%\n",
      "65\tValidation loss: 2.351651\tBest loss: 2.351651\tAccuracy: 43.10%\n",
      "66\tValidation loss: 2.352480\tBest loss: 2.351651\tAccuracy: 43.70%\n",
      "67\tValidation loss: 2.326039\tBest loss: 2.326039\tAccuracy: 44.20%\n",
      "68\tValidation loss: 2.320756\tBest loss: 2.320756\tAccuracy: 43.90%\n",
      "69\tValidation loss: 2.306355\tBest loss: 2.306355\tAccuracy: 43.80%\n",
      "70\tValidation loss: 2.297318\tBest loss: 2.297318\tAccuracy: 43.30%\n",
      "71\tValidation loss: 2.283045\tBest loss: 2.283045\tAccuracy: 44.60%\n",
      "72\tValidation loss: 2.272212\tBest loss: 2.272212\tAccuracy: 45.00%\n",
      "73\tValidation loss: 2.262040\tBest loss: 2.262040\tAccuracy: 44.70%\n",
      "74\tValidation loss: 2.259411\tBest loss: 2.259411\tAccuracy: 45.40%\n",
      "75\tValidation loss: 2.253299\tBest loss: 2.253299\tAccuracy: 45.60%\n",
      "76\tValidation loss: 2.246745\tBest loss: 2.246745\tAccuracy: 45.70%\n",
      "77\tValidation loss: 2.231512\tBest loss: 2.231512\tAccuracy: 46.10%\n",
      "78\tValidation loss: 2.219514\tBest loss: 2.219514\tAccuracy: 45.90%\n",
      "79\tValidation loss: 2.207818\tBest loss: 2.207818\tAccuracy: 46.20%\n",
      "80\tValidation loss: 2.198918\tBest loss: 2.198918\tAccuracy: 46.80%\n",
      "81\tValidation loss: 2.192636\tBest loss: 2.192636\tAccuracy: 45.90%\n",
      "82\tValidation loss: 2.176369\tBest loss: 2.176369\tAccuracy: 46.90%\n",
      "83\tValidation loss: 2.171304\tBest loss: 2.171304\tAccuracy: 47.20%\n",
      "84\tValidation loss: 2.163634\tBest loss: 2.163634\tAccuracy: 46.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\tValidation loss: 2.158943\tBest loss: 2.158943\tAccuracy: 47.40%\n",
      "86\tValidation loss: 2.143660\tBest loss: 2.143660\tAccuracy: 47.00%\n",
      "87\tValidation loss: 2.132844\tBest loss: 2.132844\tAccuracy: 48.00%\n",
      "88\tValidation loss: 2.127217\tBest loss: 2.127217\tAccuracy: 48.50%\n",
      "89\tValidation loss: 2.123047\tBest loss: 2.123047\tAccuracy: 48.10%\n",
      "90\tValidation loss: 2.117527\tBest loss: 2.117527\tAccuracy: 47.50%\n",
      "91\tValidation loss: 2.107501\tBest loss: 2.107501\tAccuracy: 48.10%\n",
      "92\tValidation loss: 2.103781\tBest loss: 2.103781\tAccuracy: 47.90%\n",
      "93\tValidation loss: 2.090434\tBest loss: 2.090434\tAccuracy: 47.60%\n",
      "94\tValidation loss: 2.095590\tBest loss: 2.090434\tAccuracy: 48.20%\n",
      "95\tValidation loss: 2.076670\tBest loss: 2.076670\tAccuracy: 48.70%\n",
      "96\tValidation loss: 2.077735\tBest loss: 2.076670\tAccuracy: 48.50%\n",
      "97\tValidation loss: 2.065357\tBest loss: 2.065357\tAccuracy: 48.70%\n",
      "98\tValidation loss: 2.062971\tBest loss: 2.062971\tAccuracy: 49.40%\n",
      "99\tValidation loss: 2.049035\tBest loss: 2.049035\tAccuracy: 49.50%\n",
      "100\tValidation loss: 2.040023\tBest loss: 2.040023\tAccuracy: 50.40%\n",
      "101\tValidation loss: 2.033708\tBest loss: 2.033708\tAccuracy: 49.20%\n",
      "102\tValidation loss: 2.032109\tBest loss: 2.032109\tAccuracy: 49.80%\n",
      "103\tValidation loss: 2.024700\tBest loss: 2.024700\tAccuracy: 50.20%\n",
      "104\tValidation loss: 2.025749\tBest loss: 2.024700\tAccuracy: 49.50%\n",
      "105\tValidation loss: 2.016905\tBest loss: 2.016905\tAccuracy: 50.90%\n",
      "106\tValidation loss: 2.012628\tBest loss: 2.012628\tAccuracy: 50.20%\n",
      "107\tValidation loss: 2.000472\tBest loss: 2.000472\tAccuracy: 49.40%\n",
      "108\tValidation loss: 1.992131\tBest loss: 1.992131\tAccuracy: 49.00%\n",
      "109\tValidation loss: 1.990702\tBest loss: 1.990702\tAccuracy: 49.80%\n",
      "110\tValidation loss: 1.980397\tBest loss: 1.980397\tAccuracy: 50.80%\n",
      "111\tValidation loss: 1.968977\tBest loss: 1.968977\tAccuracy: 50.70%\n",
      "112\tValidation loss: 1.971581\tBest loss: 1.968977\tAccuracy: 50.20%\n",
      "113\tValidation loss: 1.965197\tBest loss: 1.965197\tAccuracy: 51.10%\n",
      "114\tValidation loss: 1.965337\tBest loss: 1.965197\tAccuracy: 50.40%\n",
      "115\tValidation loss: 1.949167\tBest loss: 1.949167\tAccuracy: 51.20%\n",
      "116\tValidation loss: 1.947797\tBest loss: 1.947797\tAccuracy: 51.00%\n",
      "117\tValidation loss: 1.941809\tBest loss: 1.941809\tAccuracy: 51.60%\n",
      "118\tValidation loss: 1.942140\tBest loss: 1.941809\tAccuracy: 51.10%\n",
      "119\tValidation loss: 1.934461\tBest loss: 1.934461\tAccuracy: 52.10%\n",
      "120\tValidation loss: 1.932229\tBest loss: 1.932229\tAccuracy: 51.10%\n",
      "121\tValidation loss: 1.924562\tBest loss: 1.924562\tAccuracy: 51.70%\n",
      "122\tValidation loss: 1.923407\tBest loss: 1.923407\tAccuracy: 51.40%\n",
      "123\tValidation loss: 1.921837\tBest loss: 1.921837\tAccuracy: 51.40%\n",
      "124\tValidation loss: 1.909498\tBest loss: 1.909498\tAccuracy: 52.10%\n",
      "125\tValidation loss: 1.903330\tBest loss: 1.903330\tAccuracy: 51.70%\n",
      "126\tValidation loss: 1.899441\tBest loss: 1.899441\tAccuracy: 52.30%\n",
      "127\tValidation loss: 1.887030\tBest loss: 1.887030\tAccuracy: 51.90%\n",
      "128\tValidation loss: 1.895235\tBest loss: 1.887030\tAccuracy: 52.30%\n",
      "129\tValidation loss: 1.886277\tBest loss: 1.886277\tAccuracy: 52.80%\n",
      "130\tValidation loss: 1.876041\tBest loss: 1.876041\tAccuracy: 52.30%\n",
      "131\tValidation loss: 1.867430\tBest loss: 1.867430\tAccuracy: 52.90%\n",
      "132\tValidation loss: 1.866799\tBest loss: 1.866799\tAccuracy: 53.30%\n",
      "133\tValidation loss: 1.864439\tBest loss: 1.864439\tAccuracy: 53.30%\n",
      "134\tValidation loss: 1.855886\tBest loss: 1.855886\tAccuracy: 54.20%\n",
      "135\tValidation loss: 1.855659\tBest loss: 1.855659\tAccuracy: 53.00%\n",
      "136\tValidation loss: 1.848028\tBest loss: 1.848028\tAccuracy: 52.90%\n",
      "137\tValidation loss: 1.838616\tBest loss: 1.838616\tAccuracy: 53.80%\n",
      "138\tValidation loss: 1.834227\tBest loss: 1.834227\tAccuracy: 53.20%\n",
      "139\tValidation loss: 1.833636\tBest loss: 1.833636\tAccuracy: 53.70%\n",
      "140\tValidation loss: 1.827207\tBest loss: 1.827207\tAccuracy: 53.50%\n",
      "141\tValidation loss: 1.831447\tBest loss: 1.827207\tAccuracy: 53.60%\n",
      "142\tValidation loss: 1.825650\tBest loss: 1.825650\tAccuracy: 53.70%\n",
      "143\tValidation loss: 1.820350\tBest loss: 1.820350\tAccuracy: 54.80%\n",
      "144\tValidation loss: 1.825062\tBest loss: 1.820350\tAccuracy: 54.00%\n",
      "145\tValidation loss: 1.821225\tBest loss: 1.820350\tAccuracy: 54.20%\n",
      "146\tValidation loss: 1.821256\tBest loss: 1.820350\tAccuracy: 54.10%\n",
      "147\tValidation loss: 1.821947\tBest loss: 1.820350\tAccuracy: 53.60%\n",
      "148\tValidation loss: 1.813620\tBest loss: 1.813620\tAccuracy: 53.40%\n",
      "149\tValidation loss: 1.808080\tBest loss: 1.808080\tAccuracy: 53.80%\n",
      "150\tValidation loss: 1.805851\tBest loss: 1.805851\tAccuracy: 53.20%\n",
      "151\tValidation loss: 1.800773\tBest loss: 1.800773\tAccuracy: 54.80%\n",
      "152\tValidation loss: 1.799687\tBest loss: 1.799687\tAccuracy: 54.40%\n",
      "153\tValidation loss: 1.797766\tBest loss: 1.797766\tAccuracy: 54.70%\n",
      "154\tValidation loss: 1.790647\tBest loss: 1.790647\tAccuracy: 54.80%\n",
      "155\tValidation loss: 1.791578\tBest loss: 1.790647\tAccuracy: 54.80%\n",
      "156\tValidation loss: 1.789196\tBest loss: 1.789196\tAccuracy: 54.90%\n",
      "157\tValidation loss: 1.785384\tBest loss: 1.785384\tAccuracy: 54.30%\n",
      "158\tValidation loss: 1.776282\tBest loss: 1.776282\tAccuracy: 55.60%\n",
      "159\tValidation loss: 1.774211\tBest loss: 1.774211\tAccuracy: 55.70%\n",
      "160\tValidation loss: 1.777973\tBest loss: 1.774211\tAccuracy: 55.20%\n",
      "161\tValidation loss: 1.771188\tBest loss: 1.771188\tAccuracy: 55.10%\n",
      "162\tValidation loss: 1.764650\tBest loss: 1.764650\tAccuracy: 55.70%\n",
      "163\tValidation loss: 1.764110\tBest loss: 1.764110\tAccuracy: 55.00%\n",
      "164\tValidation loss: 1.761130\tBest loss: 1.761130\tAccuracy: 55.30%\n",
      "165\tValidation loss: 1.757277\tBest loss: 1.757277\tAccuracy: 55.40%\n",
      "166\tValidation loss: 1.758617\tBest loss: 1.757277\tAccuracy: 55.10%\n",
      "167\tValidation loss: 1.751870\tBest loss: 1.751870\tAccuracy: 55.90%\n",
      "168\tValidation loss: 1.747982\tBest loss: 1.747982\tAccuracy: 55.20%\n",
      "169\tValidation loss: 1.743351\tBest loss: 1.743351\tAccuracy: 55.90%\n",
      "170\tValidation loss: 1.736738\tBest loss: 1.736738\tAccuracy: 55.60%\n",
      "171\tValidation loss: 1.740522\tBest loss: 1.736738\tAccuracy: 56.10%\n",
      "172\tValidation loss: 1.742100\tBest loss: 1.736738\tAccuracy: 55.40%\n",
      "173\tValidation loss: 1.735826\tBest loss: 1.735826\tAccuracy: 55.80%\n",
      "174\tValidation loss: 1.727662\tBest loss: 1.727662\tAccuracy: 55.60%\n",
      "175\tValidation loss: 1.726855\tBest loss: 1.726855\tAccuracy: 55.40%\n",
      "176\tValidation loss: 1.720465\tBest loss: 1.720465\tAccuracy: 57.20%\n",
      "177\tValidation loss: 1.718527\tBest loss: 1.718527\tAccuracy: 57.00%\n",
      "178\tValidation loss: 1.715651\tBest loss: 1.715651\tAccuracy: 56.50%\n",
      "179\tValidation loss: 1.722608\tBest loss: 1.715651\tAccuracy: 56.20%\n",
      "180\tValidation loss: 1.717687\tBest loss: 1.715651\tAccuracy: 56.60%\n",
      "181\tValidation loss: 1.708462\tBest loss: 1.708462\tAccuracy: 57.00%\n",
      "182\tValidation loss: 1.711472\tBest loss: 1.708462\tAccuracy: 57.00%\n",
      "183\tValidation loss: 1.705163\tBest loss: 1.705163\tAccuracy: 57.30%\n",
      "184\tValidation loss: 1.705635\tBest loss: 1.705163\tAccuracy: 57.40%\n",
      "185\tValidation loss: 1.705467\tBest loss: 1.705163\tAccuracy: 57.50%\n",
      "186\tValidation loss: 1.701124\tBest loss: 1.701124\tAccuracy: 57.40%\n",
      "187\tValidation loss: 1.696271\tBest loss: 1.696271\tAccuracy: 57.40%\n",
      "188\tValidation loss: 1.703325\tBest loss: 1.696271\tAccuracy: 56.90%\n",
      "189\tValidation loss: 1.697945\tBest loss: 1.696271\tAccuracy: 58.10%\n",
      "190\tValidation loss: 1.693153\tBest loss: 1.693153\tAccuracy: 57.40%\n",
      "191\tValidation loss: 1.683938\tBest loss: 1.683938\tAccuracy: 57.60%\n",
      "192\tValidation loss: 1.690632\tBest loss: 1.683938\tAccuracy: 58.00%\n",
      "193\tValidation loss: 1.682846\tBest loss: 1.682846\tAccuracy: 57.80%\n",
      "194\tValidation loss: 1.684404\tBest loss: 1.682846\tAccuracy: 58.00%\n",
      "195\tValidation loss: 1.681401\tBest loss: 1.681401\tAccuracy: 59.00%\n",
      "196\tValidation loss: 1.687117\tBest loss: 1.681401\tAccuracy: 56.90%\n",
      "197\tValidation loss: 1.680300\tBest loss: 1.680300\tAccuracy: 58.10%\n",
      "198\tValidation loss: 1.683028\tBest loss: 1.680300\tAccuracy: 58.80%\n",
      "199\tValidation loss: 1.682100\tBest loss: 1.680300\tAccuracy: 57.90%\n",
      "200\tValidation loss: 1.681449\tBest loss: 1.680300\tAccuracy: 58.80%\n",
      "201\tValidation loss: 1.674492\tBest loss: 1.674492\tAccuracy: 58.00%\n",
      "202\tValidation loss: 1.669409\tBest loss: 1.669409\tAccuracy: 58.50%\n",
      "203\tValidation loss: 1.667354\tBest loss: 1.667354\tAccuracy: 58.60%\n",
      "204\tValidation loss: 1.663859\tBest loss: 1.663859\tAccuracy: 58.60%\n",
      "205\tValidation loss: 1.665032\tBest loss: 1.663859\tAccuracy: 58.40%\n",
      "206\tValidation loss: 1.656649\tBest loss: 1.656649\tAccuracy: 59.20%\n",
      "207\tValidation loss: 1.656584\tBest loss: 1.656584\tAccuracy: 59.10%\n",
      "208\tValidation loss: 1.655535\tBest loss: 1.655535\tAccuracy: 58.90%\n",
      "209\tValidation loss: 1.652399\tBest loss: 1.652399\tAccuracy: 59.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\tValidation loss: 1.655157\tBest loss: 1.652399\tAccuracy: 59.40%\n",
      "211\tValidation loss: 1.647112\tBest loss: 1.647112\tAccuracy: 59.10%\n",
      "212\tValidation loss: 1.650394\tBest loss: 1.647112\tAccuracy: 59.40%\n",
      "213\tValidation loss: 1.646495\tBest loss: 1.646495\tAccuracy: 58.20%\n",
      "214\tValidation loss: 1.645975\tBest loss: 1.645975\tAccuracy: 58.90%\n",
      "215\tValidation loss: 1.639324\tBest loss: 1.639324\tAccuracy: 58.90%\n",
      "216\tValidation loss: 1.643471\tBest loss: 1.639324\tAccuracy: 58.30%\n",
      "217\tValidation loss: 1.633210\tBest loss: 1.633210\tAccuracy: 59.10%\n",
      "218\tValidation loss: 1.634313\tBest loss: 1.633210\tAccuracy: 59.30%\n",
      "219\tValidation loss: 1.637466\tBest loss: 1.633210\tAccuracy: 58.70%\n",
      "220\tValidation loss: 1.633613\tBest loss: 1.633210\tAccuracy: 59.70%\n",
      "221\tValidation loss: 1.635825\tBest loss: 1.633210\tAccuracy: 58.90%\n",
      "222\tValidation loss: 1.633014\tBest loss: 1.633014\tAccuracy: 59.40%\n",
      "223\tValidation loss: 1.628233\tBest loss: 1.628233\tAccuracy: 58.40%\n",
      "224\tValidation loss: 1.621850\tBest loss: 1.621850\tAccuracy: 59.60%\n",
      "225\tValidation loss: 1.628265\tBest loss: 1.621850\tAccuracy: 59.40%\n",
      "226\tValidation loss: 1.629969\tBest loss: 1.621850\tAccuracy: 60.00%\n",
      "227\tValidation loss: 1.619622\tBest loss: 1.619622\tAccuracy: 59.70%\n",
      "228\tValidation loss: 1.626024\tBest loss: 1.619622\tAccuracy: 59.20%\n",
      "229\tValidation loss: 1.627276\tBest loss: 1.619622\tAccuracy: 59.50%\n",
      "230\tValidation loss: 1.622193\tBest loss: 1.619622\tAccuracy: 59.80%\n",
      "231\tValidation loss: 1.616501\tBest loss: 1.616501\tAccuracy: 60.10%\n",
      "232\tValidation loss: 1.616274\tBest loss: 1.616274\tAccuracy: 60.10%\n",
      "233\tValidation loss: 1.612214\tBest loss: 1.612214\tAccuracy: 60.00%\n",
      "234\tValidation loss: 1.614479\tBest loss: 1.612214\tAccuracy: 59.60%\n",
      "235\tValidation loss: 1.618322\tBest loss: 1.612214\tAccuracy: 60.40%\n",
      "236\tValidation loss: 1.611057\tBest loss: 1.611057\tAccuracy: 59.80%\n",
      "237\tValidation loss: 1.606617\tBest loss: 1.606617\tAccuracy: 60.80%\n",
      "238\tValidation loss: 1.609131\tBest loss: 1.606617\tAccuracy: 60.10%\n",
      "239\tValidation loss: 1.605552\tBest loss: 1.605552\tAccuracy: 60.20%\n",
      "240\tValidation loss: 1.603032\tBest loss: 1.603032\tAccuracy: 60.80%\n",
      "241\tValidation loss: 1.606726\tBest loss: 1.603032\tAccuracy: 60.00%\n",
      "242\tValidation loss: 1.605778\tBest loss: 1.603032\tAccuracy: 59.90%\n",
      "243\tValidation loss: 1.601999\tBest loss: 1.601999\tAccuracy: 59.60%\n",
      "244\tValidation loss: 1.598565\tBest loss: 1.598565\tAccuracy: 59.80%\n",
      "245\tValidation loss: 1.593117\tBest loss: 1.593117\tAccuracy: 59.50%\n",
      "246\tValidation loss: 1.598547\tBest loss: 1.593117\tAccuracy: 59.60%\n",
      "247\tValidation loss: 1.599761\tBest loss: 1.593117\tAccuracy: 59.20%\n",
      "248\tValidation loss: 1.592588\tBest loss: 1.592588\tAccuracy: 60.20%\n",
      "249\tValidation loss: 1.587717\tBest loss: 1.587717\tAccuracy: 59.70%\n",
      "250\tValidation loss: 1.590056\tBest loss: 1.587717\tAccuracy: 59.70%\n",
      "251\tValidation loss: 1.587203\tBest loss: 1.587203\tAccuracy: 59.60%\n",
      "252\tValidation loss: 1.587027\tBest loss: 1.587027\tAccuracy: 60.20%\n",
      "253\tValidation loss: 1.585736\tBest loss: 1.585736\tAccuracy: 60.50%\n",
      "254\tValidation loss: 1.577609\tBest loss: 1.577609\tAccuracy: 60.20%\n",
      "255\tValidation loss: 1.579764\tBest loss: 1.577609\tAccuracy: 59.90%\n",
      "256\tValidation loss: 1.584167\tBest loss: 1.577609\tAccuracy: 60.80%\n",
      "257\tValidation loss: 1.580040\tBest loss: 1.577609\tAccuracy: 61.00%\n",
      "258\tValidation loss: 1.578582\tBest loss: 1.577609\tAccuracy: 60.20%\n",
      "259\tValidation loss: 1.578836\tBest loss: 1.577609\tAccuracy: 60.80%\n",
      "260\tValidation loss: 1.579316\tBest loss: 1.577609\tAccuracy: 60.20%\n",
      "261\tValidation loss: 1.571915\tBest loss: 1.571915\tAccuracy: 60.60%\n",
      "262\tValidation loss: 1.572978\tBest loss: 1.571915\tAccuracy: 60.50%\n",
      "263\tValidation loss: 1.575822\tBest loss: 1.571915\tAccuracy: 60.90%\n",
      "264\tValidation loss: 1.568712\tBest loss: 1.568712\tAccuracy: 60.80%\n",
      "265\tValidation loss: 1.572723\tBest loss: 1.568712\tAccuracy: 60.80%\n",
      "266\tValidation loss: 1.566965\tBest loss: 1.566965\tAccuracy: 60.90%\n",
      "267\tValidation loss: 1.570231\tBest loss: 1.566965\tAccuracy: 61.30%\n",
      "268\tValidation loss: 1.568590\tBest loss: 1.566965\tAccuracy: 61.40%\n",
      "269\tValidation loss: 1.569256\tBest loss: 1.566965\tAccuracy: 61.20%\n",
      "270\tValidation loss: 1.566056\tBest loss: 1.566056\tAccuracy: 60.80%\n",
      "271\tValidation loss: 1.564756\tBest loss: 1.564756\tAccuracy: 60.90%\n",
      "272\tValidation loss: 1.567886\tBest loss: 1.564756\tAccuracy: 61.20%\n",
      "273\tValidation loss: 1.569137\tBest loss: 1.564756\tAccuracy: 60.80%\n",
      "274\tValidation loss: 1.562392\tBest loss: 1.562392\tAccuracy: 61.20%\n",
      "275\tValidation loss: 1.560405\tBest loss: 1.560405\tAccuracy: 61.60%\n",
      "276\tValidation loss: 1.550518\tBest loss: 1.550518\tAccuracy: 61.40%\n",
      "277\tValidation loss: 1.552843\tBest loss: 1.550518\tAccuracy: 61.90%\n",
      "278\tValidation loss: 1.554954\tBest loss: 1.550518\tAccuracy: 60.90%\n",
      "279\tValidation loss: 1.550830\tBest loss: 1.550518\tAccuracy: 60.70%\n",
      "280\tValidation loss: 1.549648\tBest loss: 1.549648\tAccuracy: 61.60%\n",
      "281\tValidation loss: 1.551865\tBest loss: 1.549648\tAccuracy: 61.00%\n",
      "282\tValidation loss: 1.549327\tBest loss: 1.549327\tAccuracy: 61.30%\n",
      "283\tValidation loss: 1.548995\tBest loss: 1.548995\tAccuracy: 60.80%\n",
      "284\tValidation loss: 1.547476\tBest loss: 1.547476\tAccuracy: 61.40%\n",
      "285\tValidation loss: 1.543985\tBest loss: 1.543985\tAccuracy: 61.50%\n",
      "286\tValidation loss: 1.549909\tBest loss: 1.543985\tAccuracy: 61.00%\n",
      "287\tValidation loss: 1.544575\tBest loss: 1.543985\tAccuracy: 61.30%\n",
      "288\tValidation loss: 1.542685\tBest loss: 1.542685\tAccuracy: 61.20%\n",
      "289\tValidation loss: 1.539142\tBest loss: 1.539142\tAccuracy: 61.20%\n",
      "290\tValidation loss: 1.544337\tBest loss: 1.539142\tAccuracy: 61.30%\n",
      "291\tValidation loss: 1.542208\tBest loss: 1.539142\tAccuracy: 62.00%\n",
      "292\tValidation loss: 1.538553\tBest loss: 1.538553\tAccuracy: 61.70%\n",
      "293\tValidation loss: 1.533611\tBest loss: 1.533611\tAccuracy: 61.50%\n",
      "294\tValidation loss: 1.535705\tBest loss: 1.533611\tAccuracy: 61.50%\n",
      "295\tValidation loss: 1.544225\tBest loss: 1.533611\tAccuracy: 61.80%\n",
      "296\tValidation loss: 1.543218\tBest loss: 1.533611\tAccuracy: 61.40%\n",
      "297\tValidation loss: 1.532139\tBest loss: 1.532139\tAccuracy: 60.50%\n",
      "298\tValidation loss: 1.533813\tBest loss: 1.532139\tAccuracy: 61.40%\n",
      "299\tValidation loss: 1.529906\tBest loss: 1.529906\tAccuracy: 61.40%\n",
      "300\tValidation loss: 1.532240\tBest loss: 1.529906\tAccuracy: 60.80%\n",
      "301\tValidation loss: 1.527562\tBest loss: 1.527562\tAccuracy: 62.10%\n",
      "302\tValidation loss: 1.527595\tBest loss: 1.527562\tAccuracy: 61.10%\n",
      "303\tValidation loss: 1.532704\tBest loss: 1.527562\tAccuracy: 62.30%\n",
      "304\tValidation loss: 1.531668\tBest loss: 1.527562\tAccuracy: 61.40%\n",
      "305\tValidation loss: 1.530904\tBest loss: 1.527562\tAccuracy: 61.40%\n",
      "306\tValidation loss: 1.527650\tBest loss: 1.527562\tAccuracy: 61.40%\n",
      "307\tValidation loss: 1.529120\tBest loss: 1.527562\tAccuracy: 61.20%\n",
      "308\tValidation loss: 1.523497\tBest loss: 1.523497\tAccuracy: 61.50%\n",
      "309\tValidation loss: 1.517186\tBest loss: 1.517186\tAccuracy: 62.20%\n",
      "310\tValidation loss: 1.521389\tBest loss: 1.517186\tAccuracy: 61.60%\n",
      "311\tValidation loss: 1.519114\tBest loss: 1.517186\tAccuracy: 62.10%\n",
      "312\tValidation loss: 1.516455\tBest loss: 1.516455\tAccuracy: 61.80%\n",
      "313\tValidation loss: 1.516366\tBest loss: 1.516366\tAccuracy: 61.00%\n",
      "314\tValidation loss: 1.526020\tBest loss: 1.516366\tAccuracy: 61.70%\n",
      "315\tValidation loss: 1.518951\tBest loss: 1.516366\tAccuracy: 62.50%\n",
      "316\tValidation loss: 1.517927\tBest loss: 1.516366\tAccuracy: 61.80%\n",
      "317\tValidation loss: 1.519399\tBest loss: 1.516366\tAccuracy: 62.20%\n",
      "318\tValidation loss: 1.514071\tBest loss: 1.514071\tAccuracy: 61.70%\n",
      "319\tValidation loss: 1.515893\tBest loss: 1.514071\tAccuracy: 61.50%\n",
      "320\tValidation loss: 1.519953\tBest loss: 1.514071\tAccuracy: 61.70%\n",
      "321\tValidation loss: 1.522590\tBest loss: 1.514071\tAccuracy: 61.50%\n",
      "322\tValidation loss: 1.512347\tBest loss: 1.512347\tAccuracy: 62.20%\n",
      "323\tValidation loss: 1.511135\tBest loss: 1.511135\tAccuracy: 61.70%\n",
      "324\tValidation loss: 1.511563\tBest loss: 1.511135\tAccuracy: 62.30%\n",
      "325\tValidation loss: 1.512607\tBest loss: 1.511135\tAccuracy: 61.70%\n",
      "326\tValidation loss: 1.511695\tBest loss: 1.511135\tAccuracy: 61.60%\n",
      "327\tValidation loss: 1.510964\tBest loss: 1.510964\tAccuracy: 62.20%\n",
      "328\tValidation loss: 1.516274\tBest loss: 1.510964\tAccuracy: 62.10%\n",
      "329\tValidation loss: 1.508633\tBest loss: 1.508633\tAccuracy: 61.60%\n",
      "330\tValidation loss: 1.507050\tBest loss: 1.507050\tAccuracy: 61.20%\n",
      "331\tValidation loss: 1.505861\tBest loss: 1.505861\tAccuracy: 61.50%\n",
      "332\tValidation loss: 1.507871\tBest loss: 1.505861\tAccuracy: 61.80%\n",
      "333\tValidation loss: 1.502901\tBest loss: 1.502901\tAccuracy: 62.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\tValidation loss: 1.501136\tBest loss: 1.501136\tAccuracy: 61.80%\n",
      "335\tValidation loss: 1.504165\tBest loss: 1.501136\tAccuracy: 61.60%\n",
      "336\tValidation loss: 1.506750\tBest loss: 1.501136\tAccuracy: 62.50%\n",
      "337\tValidation loss: 1.497920\tBest loss: 1.497920\tAccuracy: 62.30%\n",
      "338\tValidation loss: 1.500505\tBest loss: 1.497920\tAccuracy: 62.30%\n",
      "339\tValidation loss: 1.497470\tBest loss: 1.497470\tAccuracy: 62.70%\n",
      "340\tValidation loss: 1.496263\tBest loss: 1.496263\tAccuracy: 62.60%\n",
      "341\tValidation loss: 1.492414\tBest loss: 1.492414\tAccuracy: 62.70%\n",
      "342\tValidation loss: 1.492858\tBest loss: 1.492414\tAccuracy: 62.60%\n",
      "343\tValidation loss: 1.485210\tBest loss: 1.485210\tAccuracy: 63.50%\n",
      "344\tValidation loss: 1.492368\tBest loss: 1.485210\tAccuracy: 63.20%\n",
      "345\tValidation loss: 1.489657\tBest loss: 1.485210\tAccuracy: 62.80%\n",
      "346\tValidation loss: 1.492655\tBest loss: 1.485210\tAccuracy: 62.90%\n",
      "347\tValidation loss: 1.488772\tBest loss: 1.485210\tAccuracy: 62.90%\n",
      "348\tValidation loss: 1.489902\tBest loss: 1.485210\tAccuracy: 62.20%\n",
      "349\tValidation loss: 1.490464\tBest loss: 1.485210\tAccuracy: 62.50%\n",
      "350\tValidation loss: 1.486799\tBest loss: 1.485210\tAccuracy: 62.20%\n",
      "351\tValidation loss: 1.485199\tBest loss: 1.485199\tAccuracy: 62.80%\n",
      "352\tValidation loss: 1.484010\tBest loss: 1.484010\tAccuracy: 63.30%\n",
      "353\tValidation loss: 1.483022\tBest loss: 1.483022\tAccuracy: 62.50%\n",
      "354\tValidation loss: 1.489819\tBest loss: 1.483022\tAccuracy: 62.40%\n",
      "355\tValidation loss: 1.482968\tBest loss: 1.482968\tAccuracy: 63.00%\n",
      "356\tValidation loss: 1.481224\tBest loss: 1.481224\tAccuracy: 62.90%\n",
      "357\tValidation loss: 1.482164\tBest loss: 1.481224\tAccuracy: 62.50%\n",
      "358\tValidation loss: 1.476830\tBest loss: 1.476830\tAccuracy: 63.00%\n",
      "359\tValidation loss: 1.479027\tBest loss: 1.476830\tAccuracy: 62.90%\n",
      "360\tValidation loss: 1.477530\tBest loss: 1.476830\tAccuracy: 62.90%\n",
      "361\tValidation loss: 1.479120\tBest loss: 1.476830\tAccuracy: 63.30%\n",
      "362\tValidation loss: 1.485662\tBest loss: 1.476830\tAccuracy: 62.50%\n",
      "363\tValidation loss: 1.476712\tBest loss: 1.476712\tAccuracy: 62.70%\n",
      "364\tValidation loss: 1.472766\tBest loss: 1.472766\tAccuracy: 63.30%\n",
      "365\tValidation loss: 1.471966\tBest loss: 1.471966\tAccuracy: 63.30%\n",
      "366\tValidation loss: 1.468887\tBest loss: 1.468887\tAccuracy: 63.10%\n",
      "367\tValidation loss: 1.474049\tBest loss: 1.468887\tAccuracy: 62.80%\n",
      "368\tValidation loss: 1.474403\tBest loss: 1.468887\tAccuracy: 63.20%\n",
      "369\tValidation loss: 1.469799\tBest loss: 1.468887\tAccuracy: 62.70%\n",
      "370\tValidation loss: 1.476738\tBest loss: 1.468887\tAccuracy: 63.00%\n",
      "371\tValidation loss: 1.469781\tBest loss: 1.468887\tAccuracy: 63.70%\n",
      "372\tValidation loss: 1.467710\tBest loss: 1.467710\tAccuracy: 63.10%\n",
      "373\tValidation loss: 1.466124\tBest loss: 1.466124\tAccuracy: 62.70%\n",
      "374\tValidation loss: 1.466050\tBest loss: 1.466050\tAccuracy: 63.40%\n",
      "375\tValidation loss: 1.464758\tBest loss: 1.464758\tAccuracy: 63.00%\n",
      "376\tValidation loss: 1.469068\tBest loss: 1.464758\tAccuracy: 63.00%\n",
      "377\tValidation loss: 1.464532\tBest loss: 1.464532\tAccuracy: 62.50%\n",
      "378\tValidation loss: 1.461801\tBest loss: 1.461801\tAccuracy: 62.90%\n",
      "379\tValidation loss: 1.467113\tBest loss: 1.461801\tAccuracy: 62.40%\n",
      "380\tValidation loss: 1.464348\tBest loss: 1.461801\tAccuracy: 62.90%\n",
      "381\tValidation loss: 1.466787\tBest loss: 1.461801\tAccuracy: 62.80%\n",
      "382\tValidation loss: 1.459651\tBest loss: 1.459651\tAccuracy: 63.60%\n",
      "383\tValidation loss: 1.463304\tBest loss: 1.459651\tAccuracy: 63.20%\n",
      "384\tValidation loss: 1.454650\tBest loss: 1.454650\tAccuracy: 63.30%\n",
      "385\tValidation loss: 1.460500\tBest loss: 1.454650\tAccuracy: 63.40%\n",
      "386\tValidation loss: 1.459469\tBest loss: 1.454650\tAccuracy: 63.30%\n",
      "387\tValidation loss: 1.459929\tBest loss: 1.454650\tAccuracy: 62.90%\n",
      "388\tValidation loss: 1.457556\tBest loss: 1.454650\tAccuracy: 64.10%\n",
      "389\tValidation loss: 1.454434\tBest loss: 1.454434\tAccuracy: 64.10%\n",
      "390\tValidation loss: 1.449868\tBest loss: 1.449868\tAccuracy: 63.40%\n",
      "391\tValidation loss: 1.450697\tBest loss: 1.449868\tAccuracy: 63.50%\n",
      "392\tValidation loss: 1.446596\tBest loss: 1.446596\tAccuracy: 63.50%\n",
      "393\tValidation loss: 1.451772\tBest loss: 1.446596\tAccuracy: 63.20%\n",
      "394\tValidation loss: 1.448694\tBest loss: 1.446596\tAccuracy: 63.30%\n",
      "395\tValidation loss: 1.446408\tBest loss: 1.446408\tAccuracy: 62.80%\n",
      "396\tValidation loss: 1.447922\tBest loss: 1.446408\tAccuracy: 62.50%\n",
      "397\tValidation loss: 1.443760\tBest loss: 1.443760\tAccuracy: 63.60%\n",
      "398\tValidation loss: 1.445970\tBest loss: 1.443760\tAccuracy: 63.40%\n",
      "399\tValidation loss: 1.445733\tBest loss: 1.443760\tAccuracy: 63.20%\n",
      "400\tValidation loss: 1.446016\tBest loss: 1.443760\tAccuracy: 63.50%\n",
      "401\tValidation loss: 1.443114\tBest loss: 1.443114\tAccuracy: 63.30%\n",
      "402\tValidation loss: 1.441040\tBest loss: 1.441040\tAccuracy: 63.30%\n",
      "403\tValidation loss: 1.442797\tBest loss: 1.441040\tAccuracy: 63.80%\n",
      "404\tValidation loss: 1.443995\tBest loss: 1.441040\tAccuracy: 62.50%\n",
      "405\tValidation loss: 1.444164\tBest loss: 1.441040\tAccuracy: 62.90%\n",
      "406\tValidation loss: 1.445624\tBest loss: 1.441040\tAccuracy: 63.70%\n",
      "407\tValidation loss: 1.439265\tBest loss: 1.439265\tAccuracy: 63.10%\n",
      "408\tValidation loss: 1.438242\tBest loss: 1.438242\tAccuracy: 63.60%\n",
      "409\tValidation loss: 1.438748\tBest loss: 1.438242\tAccuracy: 63.10%\n",
      "410\tValidation loss: 1.437523\tBest loss: 1.437523\tAccuracy: 63.30%\n",
      "411\tValidation loss: 1.436067\tBest loss: 1.436067\tAccuracy: 63.30%\n",
      "412\tValidation loss: 1.435791\tBest loss: 1.435791\tAccuracy: 63.30%\n",
      "413\tValidation loss: 1.432905\tBest loss: 1.432905\tAccuracy: 63.50%\n",
      "414\tValidation loss: 1.435790\tBest loss: 1.432905\tAccuracy: 63.10%\n",
      "415\tValidation loss: 1.433403\tBest loss: 1.432905\tAccuracy: 63.20%\n",
      "416\tValidation loss: 1.437357\tBest loss: 1.432905\tAccuracy: 64.00%\n",
      "417\tValidation loss: 1.431833\tBest loss: 1.431833\tAccuracy: 63.40%\n",
      "418\tValidation loss: 1.435537\tBest loss: 1.431833\tAccuracy: 63.40%\n",
      "419\tValidation loss: 1.435318\tBest loss: 1.431833\tAccuracy: 63.40%\n",
      "420\tValidation loss: 1.433883\tBest loss: 1.431833\tAccuracy: 63.20%\n",
      "421\tValidation loss: 1.434414\tBest loss: 1.431833\tAccuracy: 63.30%\n",
      "422\tValidation loss: 1.437476\tBest loss: 1.431833\tAccuracy: 63.60%\n",
      "423\tValidation loss: 1.433502\tBest loss: 1.431833\tAccuracy: 64.10%\n",
      "424\tValidation loss: 1.431291\tBest loss: 1.431291\tAccuracy: 63.70%\n",
      "425\tValidation loss: 1.433020\tBest loss: 1.431291\tAccuracy: 63.30%\n",
      "426\tValidation loss: 1.431473\tBest loss: 1.431291\tAccuracy: 64.10%\n",
      "427\tValidation loss: 1.426487\tBest loss: 1.426487\tAccuracy: 63.80%\n",
      "428\tValidation loss: 1.428718\tBest loss: 1.426487\tAccuracy: 63.40%\n",
      "429\tValidation loss: 1.425362\tBest loss: 1.425362\tAccuracy: 63.30%\n",
      "430\tValidation loss: 1.421470\tBest loss: 1.421470\tAccuracy: 64.00%\n",
      "431\tValidation loss: 1.419115\tBest loss: 1.419115\tAccuracy: 63.70%\n",
      "432\tValidation loss: 1.422168\tBest loss: 1.419115\tAccuracy: 63.50%\n",
      "433\tValidation loss: 1.423839\tBest loss: 1.419115\tAccuracy: 62.80%\n",
      "434\tValidation loss: 1.421575\tBest loss: 1.419115\tAccuracy: 64.10%\n",
      "435\tValidation loss: 1.420309\tBest loss: 1.419115\tAccuracy: 63.90%\n",
      "436\tValidation loss: 1.422876\tBest loss: 1.419115\tAccuracy: 63.30%\n",
      "437\tValidation loss: 1.422233\tBest loss: 1.419115\tAccuracy: 63.40%\n",
      "438\tValidation loss: 1.421024\tBest loss: 1.419115\tAccuracy: 63.30%\n",
      "439\tValidation loss: 1.422400\tBest loss: 1.419115\tAccuracy: 63.40%\n",
      "440\tValidation loss: 1.416536\tBest loss: 1.416536\tAccuracy: 63.60%\n",
      "441\tValidation loss: 1.418463\tBest loss: 1.416536\tAccuracy: 63.80%\n",
      "442\tValidation loss: 1.422093\tBest loss: 1.416536\tAccuracy: 63.40%\n",
      "443\tValidation loss: 1.419796\tBest loss: 1.416536\tAccuracy: 63.10%\n",
      "444\tValidation loss: 1.420384\tBest loss: 1.416536\tAccuracy: 63.80%\n",
      "445\tValidation loss: 1.418372\tBest loss: 1.416536\tAccuracy: 64.00%\n",
      "446\tValidation loss: 1.414866\tBest loss: 1.414866\tAccuracy: 64.20%\n",
      "447\tValidation loss: 1.414095\tBest loss: 1.414095\tAccuracy: 63.90%\n",
      "448\tValidation loss: 1.420558\tBest loss: 1.414095\tAccuracy: 64.20%\n",
      "449\tValidation loss: 1.417990\tBest loss: 1.414095\tAccuracy: 64.30%\n",
      "450\tValidation loss: 1.416618\tBest loss: 1.414095\tAccuracy: 63.80%\n",
      "451\tValidation loss: 1.408793\tBest loss: 1.408793\tAccuracy: 64.50%\n",
      "452\tValidation loss: 1.410976\tBest loss: 1.408793\tAccuracy: 64.10%\n",
      "453\tValidation loss: 1.411262\tBest loss: 1.408793\tAccuracy: 64.40%\n",
      "454\tValidation loss: 1.410551\tBest loss: 1.408793\tAccuracy: 64.80%\n",
      "455\tValidation loss: 1.408693\tBest loss: 1.408693\tAccuracy: 64.40%\n",
      "456\tValidation loss: 1.409406\tBest loss: 1.408693\tAccuracy: 64.00%\n",
      "457\tValidation loss: 1.411067\tBest loss: 1.408693\tAccuracy: 64.20%\n",
      "458\tValidation loss: 1.409998\tBest loss: 1.408693\tAccuracy: 64.20%\n",
      "459\tValidation loss: 1.409518\tBest loss: 1.408693\tAccuracy: 63.50%\n",
      "460\tValidation loss: 1.407887\tBest loss: 1.407887\tAccuracy: 65.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\tValidation loss: 1.401298\tBest loss: 1.401298\tAccuracy: 63.80%\n",
      "462\tValidation loss: 1.406088\tBest loss: 1.401298\tAccuracy: 64.70%\n",
      "463\tValidation loss: 1.401767\tBest loss: 1.401298\tAccuracy: 64.60%\n",
      "464\tValidation loss: 1.400866\tBest loss: 1.400866\tAccuracy: 63.80%\n",
      "465\tValidation loss: 1.401504\tBest loss: 1.400866\tAccuracy: 64.60%\n",
      "466\tValidation loss: 1.399374\tBest loss: 1.399374\tAccuracy: 63.50%\n",
      "467\tValidation loss: 1.397159\tBest loss: 1.397159\tAccuracy: 64.40%\n",
      "468\tValidation loss: 1.402680\tBest loss: 1.397159\tAccuracy: 64.30%\n",
      "469\tValidation loss: 1.403026\tBest loss: 1.397159\tAccuracy: 64.00%\n",
      "470\tValidation loss: 1.398574\tBest loss: 1.397159\tAccuracy: 64.10%\n",
      "471\tValidation loss: 1.400650\tBest loss: 1.397159\tAccuracy: 63.60%\n",
      "472\tValidation loss: 1.403208\tBest loss: 1.397159\tAccuracy: 64.30%\n",
      "473\tValidation loss: 1.401338\tBest loss: 1.397159\tAccuracy: 64.80%\n",
      "474\tValidation loss: 1.396009\tBest loss: 1.396009\tAccuracy: 64.00%\n",
      "475\tValidation loss: 1.394185\tBest loss: 1.394185\tAccuracy: 64.70%\n",
      "476\tValidation loss: 1.396015\tBest loss: 1.394185\tAccuracy: 64.40%\n",
      "477\tValidation loss: 1.393127\tBest loss: 1.393127\tAccuracy: 64.60%\n",
      "478\tValidation loss: 1.401705\tBest loss: 1.393127\tAccuracy: 64.40%\n",
      "479\tValidation loss: 1.401527\tBest loss: 1.393127\tAccuracy: 64.50%\n",
      "480\tValidation loss: 1.396740\tBest loss: 1.393127\tAccuracy: 64.20%\n",
      "481\tValidation loss: 1.394120\tBest loss: 1.393127\tAccuracy: 64.20%\n",
      "482\tValidation loss: 1.394377\tBest loss: 1.393127\tAccuracy: 64.40%\n",
      "483\tValidation loss: 1.389353\tBest loss: 1.389353\tAccuracy: 63.50%\n",
      "484\tValidation loss: 1.390255\tBest loss: 1.389353\tAccuracy: 63.10%\n",
      "485\tValidation loss: 1.396240\tBest loss: 1.389353\tAccuracy: 64.30%\n",
      "486\tValidation loss: 1.394638\tBest loss: 1.389353\tAccuracy: 64.80%\n",
      "487\tValidation loss: 1.391498\tBest loss: 1.389353\tAccuracy: 64.80%\n",
      "488\tValidation loss: 1.392716\tBest loss: 1.389353\tAccuracy: 64.70%\n",
      "489\tValidation loss: 1.386928\tBest loss: 1.386928\tAccuracy: 65.20%\n",
      "490\tValidation loss: 1.389933\tBest loss: 1.386928\tAccuracy: 64.60%\n",
      "491\tValidation loss: 1.386225\tBest loss: 1.386225\tAccuracy: 64.60%\n",
      "492\tValidation loss: 1.388065\tBest loss: 1.386225\tAccuracy: 63.40%\n",
      "493\tValidation loss: 1.386202\tBest loss: 1.386202\tAccuracy: 64.90%\n",
      "494\tValidation loss: 1.386950\tBest loss: 1.386202\tAccuracy: 64.30%\n",
      "495\tValidation loss: 1.382964\tBest loss: 1.382964\tAccuracy: 64.80%\n",
      "496\tValidation loss: 1.391303\tBest loss: 1.382964\tAccuracy: 64.90%\n",
      "497\tValidation loss: 1.386006\tBest loss: 1.382964\tAccuracy: 65.20%\n",
      "498\tValidation loss: 1.390039\tBest loss: 1.382964\tAccuracy: 65.30%\n",
      "499\tValidation loss: 1.381818\tBest loss: 1.381818\tAccuracy: 65.10%\n",
      "500\tValidation loss: 1.380663\tBest loss: 1.380663\tAccuracy: 64.60%\n",
      "501\tValidation loss: 1.382542\tBest loss: 1.380663\tAccuracy: 63.80%\n",
      "502\tValidation loss: 1.381776\tBest loss: 1.380663\tAccuracy: 64.60%\n",
      "503\tValidation loss: 1.376067\tBest loss: 1.376067\tAccuracy: 64.90%\n",
      "504\tValidation loss: 1.384313\tBest loss: 1.376067\tAccuracy: 64.40%\n",
      "505\tValidation loss: 1.379793\tBest loss: 1.376067\tAccuracy: 64.80%\n",
      "506\tValidation loss: 1.380060\tBest loss: 1.376067\tAccuracy: 64.70%\n",
      "507\tValidation loss: 1.381913\tBest loss: 1.376067\tAccuracy: 64.80%\n",
      "508\tValidation loss: 1.381674\tBest loss: 1.376067\tAccuracy: 64.60%\n",
      "509\tValidation loss: 1.381021\tBest loss: 1.376067\tAccuracy: 64.00%\n",
      "510\tValidation loss: 1.387496\tBest loss: 1.376067\tAccuracy: 64.80%\n",
      "511\tValidation loss: 1.382495\tBest loss: 1.376067\tAccuracy: 65.10%\n",
      "512\tValidation loss: 1.376995\tBest loss: 1.376067\tAccuracy: 64.40%\n",
      "513\tValidation loss: 1.378598\tBest loss: 1.376067\tAccuracy: 64.30%\n",
      "514\tValidation loss: 1.378759\tBest loss: 1.376067\tAccuracy: 64.00%\n",
      "515\tValidation loss: 1.375276\tBest loss: 1.375276\tAccuracy: 64.30%\n",
      "516\tValidation loss: 1.375426\tBest loss: 1.375276\tAccuracy: 64.20%\n",
      "517\tValidation loss: 1.374610\tBest loss: 1.374610\tAccuracy: 64.60%\n",
      "518\tValidation loss: 1.377184\tBest loss: 1.374610\tAccuracy: 65.10%\n",
      "519\tValidation loss: 1.378305\tBest loss: 1.374610\tAccuracy: 65.20%\n",
      "520\tValidation loss: 1.375260\tBest loss: 1.374610\tAccuracy: 65.30%\n",
      "521\tValidation loss: 1.370770\tBest loss: 1.370770\tAccuracy: 65.20%\n",
      "522\tValidation loss: 1.368560\tBest loss: 1.368560\tAccuracy: 65.00%\n",
      "523\tValidation loss: 1.370832\tBest loss: 1.368560\tAccuracy: 65.20%\n",
      "524\tValidation loss: 1.368549\tBest loss: 1.368549\tAccuracy: 65.20%\n",
      "525\tValidation loss: 1.369092\tBest loss: 1.368549\tAccuracy: 65.50%\n",
      "526\tValidation loss: 1.369501\tBest loss: 1.368549\tAccuracy: 65.00%\n",
      "527\tValidation loss: 1.372755\tBest loss: 1.368549\tAccuracy: 65.20%\n",
      "528\tValidation loss: 1.370329\tBest loss: 1.368549\tAccuracy: 65.00%\n",
      "529\tValidation loss: 1.373333\tBest loss: 1.368549\tAccuracy: 64.00%\n",
      "530\tValidation loss: 1.371452\tBest loss: 1.368549\tAccuracy: 65.00%\n",
      "531\tValidation loss: 1.376102\tBest loss: 1.368549\tAccuracy: 64.30%\n",
      "532\tValidation loss: 1.373911\tBest loss: 1.368549\tAccuracy: 64.60%\n",
      "533\tValidation loss: 1.372310\tBest loss: 1.368549\tAccuracy: 64.30%\n",
      "534\tValidation loss: 1.371962\tBest loss: 1.368549\tAccuracy: 64.30%\n",
      "535\tValidation loss: 1.367919\tBest loss: 1.367919\tAccuracy: 65.20%\n",
      "536\tValidation loss: 1.367689\tBest loss: 1.367689\tAccuracy: 65.20%\n",
      "537\tValidation loss: 1.369358\tBest loss: 1.367689\tAccuracy: 65.30%\n",
      "538\tValidation loss: 1.365521\tBest loss: 1.365521\tAccuracy: 64.90%\n",
      "539\tValidation loss: 1.371716\tBest loss: 1.365521\tAccuracy: 64.00%\n",
      "540\tValidation loss: 1.364359\tBest loss: 1.364359\tAccuracy: 65.80%\n",
      "541\tValidation loss: 1.363725\tBest loss: 1.363725\tAccuracy: 65.10%\n",
      "542\tValidation loss: 1.362949\tBest loss: 1.362949\tAccuracy: 64.80%\n",
      "543\tValidation loss: 1.364995\tBest loss: 1.362949\tAccuracy: 64.80%\n",
      "544\tValidation loss: 1.363785\tBest loss: 1.362949\tAccuracy: 65.30%\n",
      "545\tValidation loss: 1.366760\tBest loss: 1.362949\tAccuracy: 64.90%\n",
      "546\tValidation loss: 1.361288\tBest loss: 1.361288\tAccuracy: 64.80%\n",
      "547\tValidation loss: 1.364166\tBest loss: 1.361288\tAccuracy: 65.30%\n",
      "548\tValidation loss: 1.363530\tBest loss: 1.361288\tAccuracy: 64.80%\n",
      "549\tValidation loss: 1.362568\tBest loss: 1.361288\tAccuracy: 65.70%\n",
      "550\tValidation loss: 1.357320\tBest loss: 1.357320\tAccuracy: 65.40%\n",
      "551\tValidation loss: 1.359004\tBest loss: 1.357320\tAccuracy: 65.50%\n",
      "552\tValidation loss: 1.360872\tBest loss: 1.357320\tAccuracy: 65.30%\n",
      "553\tValidation loss: 1.360975\tBest loss: 1.357320\tAccuracy: 65.10%\n",
      "554\tValidation loss: 1.356905\tBest loss: 1.356905\tAccuracy: 65.20%\n",
      "555\tValidation loss: 1.353998\tBest loss: 1.353998\tAccuracy: 65.20%\n",
      "556\tValidation loss: 1.359257\tBest loss: 1.353998\tAccuracy: 65.40%\n",
      "557\tValidation loss: 1.354344\tBest loss: 1.353998\tAccuracy: 65.70%\n",
      "558\tValidation loss: 1.351832\tBest loss: 1.351832\tAccuracy: 65.70%\n",
      "559\tValidation loss: 1.354956\tBest loss: 1.351832\tAccuracy: 65.70%\n",
      "560\tValidation loss: 1.354183\tBest loss: 1.351832\tAccuracy: 65.50%\n",
      "561\tValidation loss: 1.353539\tBest loss: 1.351832\tAccuracy: 66.30%\n",
      "562\tValidation loss: 1.351395\tBest loss: 1.351395\tAccuracy: 65.50%\n",
      "563\tValidation loss: 1.349798\tBest loss: 1.349798\tAccuracy: 65.70%\n",
      "564\tValidation loss: 1.348615\tBest loss: 1.348615\tAccuracy: 66.20%\n",
      "565\tValidation loss: 1.348226\tBest loss: 1.348226\tAccuracy: 65.90%\n",
      "566\tValidation loss: 1.346516\tBest loss: 1.346516\tAccuracy: 65.60%\n",
      "567\tValidation loss: 1.342554\tBest loss: 1.342554\tAccuracy: 66.00%\n",
      "568\tValidation loss: 1.345884\tBest loss: 1.342554\tAccuracy: 65.50%\n",
      "569\tValidation loss: 1.345860\tBest loss: 1.342554\tAccuracy: 64.90%\n",
      "570\tValidation loss: 1.342684\tBest loss: 1.342554\tAccuracy: 64.80%\n",
      "571\tValidation loss: 1.347089\tBest loss: 1.342554\tAccuracy: 65.90%\n",
      "572\tValidation loss: 1.350379\tBest loss: 1.342554\tAccuracy: 66.00%\n",
      "573\tValidation loss: 1.350942\tBest loss: 1.342554\tAccuracy: 65.40%\n",
      "574\tValidation loss: 1.349321\tBest loss: 1.342554\tAccuracy: 65.40%\n",
      "575\tValidation loss: 1.347488\tBest loss: 1.342554\tAccuracy: 65.40%\n",
      "576\tValidation loss: 1.350438\tBest loss: 1.342554\tAccuracy: 65.90%\n",
      "577\tValidation loss: 1.350214\tBest loss: 1.342554\tAccuracy: 65.50%\n",
      "578\tValidation loss: 1.345561\tBest loss: 1.342554\tAccuracy: 66.10%\n",
      "579\tValidation loss: 1.345654\tBest loss: 1.342554\tAccuracy: 65.40%\n",
      "580\tValidation loss: 1.344636\tBest loss: 1.342554\tAccuracy: 65.80%\n",
      "581\tValidation loss: 1.342090\tBest loss: 1.342090\tAccuracy: 65.70%\n",
      "582\tValidation loss: 1.341376\tBest loss: 1.341376\tAccuracy: 66.10%\n",
      "583\tValidation loss: 1.338383\tBest loss: 1.338383\tAccuracy: 66.10%\n",
      "584\tValidation loss: 1.338363\tBest loss: 1.338363\tAccuracy: 66.10%\n",
      "585\tValidation loss: 1.341671\tBest loss: 1.338363\tAccuracy: 65.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586\tValidation loss: 1.346088\tBest loss: 1.338363\tAccuracy: 66.30%\n",
      "587\tValidation loss: 1.340277\tBest loss: 1.338363\tAccuracy: 65.50%\n",
      "588\tValidation loss: 1.341778\tBest loss: 1.338363\tAccuracy: 65.10%\n",
      "589\tValidation loss: 1.342319\tBest loss: 1.338363\tAccuracy: 65.70%\n",
      "590\tValidation loss: 1.343110\tBest loss: 1.338363\tAccuracy: 65.90%\n",
      "591\tValidation loss: 1.345812\tBest loss: 1.338363\tAccuracy: 65.80%\n",
      "592\tValidation loss: 1.345078\tBest loss: 1.338363\tAccuracy: 65.60%\n",
      "593\tValidation loss: 1.346340\tBest loss: 1.338363\tAccuracy: 65.60%\n",
      "594\tValidation loss: 1.343513\tBest loss: 1.338363\tAccuracy: 65.10%\n",
      "595\tValidation loss: 1.346901\tBest loss: 1.338363\tAccuracy: 64.90%\n",
      "596\tValidation loss: 1.346082\tBest loss: 1.338363\tAccuracy: 65.40%\n",
      "597\tValidation loss: 1.347045\tBest loss: 1.338363\tAccuracy: 65.70%\n",
      "598\tValidation loss: 1.338362\tBest loss: 1.338362\tAccuracy: 65.70%\n",
      "599\tValidation loss: 1.340969\tBest loss: 1.338362\tAccuracy: 65.30%\n",
      "600\tValidation loss: 1.340856\tBest loss: 1.338362\tAccuracy: 66.00%\n",
      "601\tValidation loss: 1.337204\tBest loss: 1.337204\tAccuracy: 66.10%\n",
      "602\tValidation loss: 1.341532\tBest loss: 1.337204\tAccuracy: 65.70%\n",
      "603\tValidation loss: 1.340754\tBest loss: 1.337204\tAccuracy: 65.50%\n",
      "604\tValidation loss: 1.335634\tBest loss: 1.335634\tAccuracy: 66.20%\n",
      "605\tValidation loss: 1.337214\tBest loss: 1.335634\tAccuracy: 66.10%\n",
      "606\tValidation loss: 1.338364\tBest loss: 1.335634\tAccuracy: 65.80%\n",
      "607\tValidation loss: 1.339606\tBest loss: 1.335634\tAccuracy: 65.90%\n",
      "608\tValidation loss: 1.335302\tBest loss: 1.335302\tAccuracy: 66.00%\n",
      "609\tValidation loss: 1.330384\tBest loss: 1.330384\tAccuracy: 65.10%\n",
      "610\tValidation loss: 1.332787\tBest loss: 1.330384\tAccuracy: 66.10%\n",
      "611\tValidation loss: 1.334677\tBest loss: 1.330384\tAccuracy: 65.10%\n",
      "612\tValidation loss: 1.331958\tBest loss: 1.330384\tAccuracy: 65.50%\n",
      "613\tValidation loss: 1.328305\tBest loss: 1.328305\tAccuracy: 65.90%\n",
      "614\tValidation loss: 1.330852\tBest loss: 1.328305\tAccuracy: 66.30%\n",
      "615\tValidation loss: 1.330282\tBest loss: 1.328305\tAccuracy: 66.60%\n",
      "616\tValidation loss: 1.329351\tBest loss: 1.328305\tAccuracy: 65.70%\n",
      "617\tValidation loss: 1.330616\tBest loss: 1.328305\tAccuracy: 65.60%\n",
      "618\tValidation loss: 1.331723\tBest loss: 1.328305\tAccuracy: 65.80%\n",
      "619\tValidation loss: 1.323532\tBest loss: 1.323532\tAccuracy: 65.60%\n",
      "620\tValidation loss: 1.324772\tBest loss: 1.323532\tAccuracy: 65.10%\n",
      "621\tValidation loss: 1.323384\tBest loss: 1.323384\tAccuracy: 66.40%\n",
      "622\tValidation loss: 1.326527\tBest loss: 1.323384\tAccuracy: 66.10%\n",
      "623\tValidation loss: 1.326805\tBest loss: 1.323384\tAccuracy: 65.80%\n",
      "624\tValidation loss: 1.329930\tBest loss: 1.323384\tAccuracy: 65.90%\n",
      "625\tValidation loss: 1.326823\tBest loss: 1.323384\tAccuracy: 65.40%\n",
      "626\tValidation loss: 1.334274\tBest loss: 1.323384\tAccuracy: 65.80%\n",
      "627\tValidation loss: 1.329367\tBest loss: 1.323384\tAccuracy: 66.10%\n",
      "628\tValidation loss: 1.325946\tBest loss: 1.323384\tAccuracy: 65.90%\n",
      "629\tValidation loss: 1.328415\tBest loss: 1.323384\tAccuracy: 65.80%\n",
      "630\tValidation loss: 1.327506\tBest loss: 1.323384\tAccuracy: 65.50%\n",
      "631\tValidation loss: 1.325643\tBest loss: 1.323384\tAccuracy: 66.20%\n",
      "632\tValidation loss: 1.324440\tBest loss: 1.323384\tAccuracy: 65.80%\n",
      "633\tValidation loss: 1.319561\tBest loss: 1.319561\tAccuracy: 66.10%\n",
      "634\tValidation loss: 1.316684\tBest loss: 1.316684\tAccuracy: 66.30%\n",
      "635\tValidation loss: 1.319553\tBest loss: 1.316684\tAccuracy: 66.00%\n",
      "636\tValidation loss: 1.324089\tBest loss: 1.316684\tAccuracy: 65.40%\n",
      "637\tValidation loss: 1.319819\tBest loss: 1.316684\tAccuracy: 66.80%\n",
      "638\tValidation loss: 1.321417\tBest loss: 1.316684\tAccuracy: 65.40%\n",
      "639\tValidation loss: 1.315132\tBest loss: 1.315132\tAccuracy: 66.40%\n",
      "640\tValidation loss: 1.317771\tBest loss: 1.315132\tAccuracy: 66.10%\n",
      "641\tValidation loss: 1.317778\tBest loss: 1.315132\tAccuracy: 66.70%\n",
      "642\tValidation loss: 1.321409\tBest loss: 1.315132\tAccuracy: 66.50%\n",
      "643\tValidation loss: 1.321130\tBest loss: 1.315132\tAccuracy: 65.70%\n",
      "644\tValidation loss: 1.314720\tBest loss: 1.314720\tAccuracy: 66.80%\n",
      "645\tValidation loss: 1.319446\tBest loss: 1.314720\tAccuracy: 66.80%\n",
      "646\tValidation loss: 1.314443\tBest loss: 1.314443\tAccuracy: 66.10%\n",
      "647\tValidation loss: 1.316287\tBest loss: 1.314443\tAccuracy: 65.90%\n",
      "648\tValidation loss: 1.313527\tBest loss: 1.313527\tAccuracy: 66.50%\n",
      "649\tValidation loss: 1.314731\tBest loss: 1.313527\tAccuracy: 66.50%\n",
      "650\tValidation loss: 1.313531\tBest loss: 1.313527\tAccuracy: 66.00%\n",
      "651\tValidation loss: 1.313865\tBest loss: 1.313527\tAccuracy: 66.10%\n",
      "652\tValidation loss: 1.314048\tBest loss: 1.313527\tAccuracy: 66.10%\n",
      "653\tValidation loss: 1.317953\tBest loss: 1.313527\tAccuracy: 66.10%\n",
      "654\tValidation loss: 1.316429\tBest loss: 1.313527\tAccuracy: 66.20%\n",
      "655\tValidation loss: 1.311485\tBest loss: 1.311485\tAccuracy: 67.00%\n",
      "656\tValidation loss: 1.317373\tBest loss: 1.311485\tAccuracy: 66.00%\n",
      "657\tValidation loss: 1.315143\tBest loss: 1.311485\tAccuracy: 65.70%\n",
      "658\tValidation loss: 1.315895\tBest loss: 1.311485\tAccuracy: 66.30%\n",
      "659\tValidation loss: 1.320293\tBest loss: 1.311485\tAccuracy: 65.30%\n",
      "660\tValidation loss: 1.318714\tBest loss: 1.311485\tAccuracy: 66.10%\n",
      "661\tValidation loss: 1.318924\tBest loss: 1.311485\tAccuracy: 66.50%\n",
      "662\tValidation loss: 1.318562\tBest loss: 1.311485\tAccuracy: 66.00%\n",
      "663\tValidation loss: 1.317709\tBest loss: 1.311485\tAccuracy: 67.00%\n",
      "664\tValidation loss: 1.314488\tBest loss: 1.311485\tAccuracy: 66.20%\n",
      "665\tValidation loss: 1.312670\tBest loss: 1.311485\tAccuracy: 66.10%\n",
      "666\tValidation loss: 1.312540\tBest loss: 1.311485\tAccuracy: 67.00%\n",
      "667\tValidation loss: 1.309127\tBest loss: 1.309127\tAccuracy: 65.90%\n",
      "668\tValidation loss: 1.313368\tBest loss: 1.309127\tAccuracy: 66.60%\n",
      "669\tValidation loss: 1.313725\tBest loss: 1.309127\tAccuracy: 66.00%\n",
      "670\tValidation loss: 1.310842\tBest loss: 1.309127\tAccuracy: 66.30%\n",
      "671\tValidation loss: 1.314528\tBest loss: 1.309127\tAccuracy: 67.10%\n",
      "672\tValidation loss: 1.310468\tBest loss: 1.309127\tAccuracy: 66.80%\n",
      "673\tValidation loss: 1.319234\tBest loss: 1.309127\tAccuracy: 66.10%\n",
      "674\tValidation loss: 1.317695\tBest loss: 1.309127\tAccuracy: 66.10%\n",
      "675\tValidation loss: 1.312174\tBest loss: 1.309127\tAccuracy: 66.30%\n",
      "676\tValidation loss: 1.309477\tBest loss: 1.309127\tAccuracy: 66.30%\n",
      "677\tValidation loss: 1.312250\tBest loss: 1.309127\tAccuracy: 66.20%\n",
      "678\tValidation loss: 1.316684\tBest loss: 1.309127\tAccuracy: 66.00%\n",
      "679\tValidation loss: 1.313472\tBest loss: 1.309127\tAccuracy: 66.40%\n",
      "680\tValidation loss: 1.311607\tBest loss: 1.309127\tAccuracy: 66.30%\n",
      "681\tValidation loss: 1.313343\tBest loss: 1.309127\tAccuracy: 66.40%\n",
      "682\tValidation loss: 1.311914\tBest loss: 1.309127\tAccuracy: 66.50%\n",
      "683\tValidation loss: 1.310728\tBest loss: 1.309127\tAccuracy: 66.20%\n",
      "684\tValidation loss: 1.310851\tBest loss: 1.309127\tAccuracy: 66.20%\n",
      "685\tValidation loss: 1.309323\tBest loss: 1.309127\tAccuracy: 66.80%\n",
      "686\tValidation loss: 1.308134\tBest loss: 1.308134\tAccuracy: 66.50%\n",
      "687\tValidation loss: 1.307715\tBest loss: 1.307715\tAccuracy: 66.60%\n",
      "688\tValidation loss: 1.309103\tBest loss: 1.307715\tAccuracy: 66.70%\n",
      "689\tValidation loss: 1.309295\tBest loss: 1.307715\tAccuracy: 66.50%\n",
      "690\tValidation loss: 1.310550\tBest loss: 1.307715\tAccuracy: 66.10%\n",
      "691\tValidation loss: 1.307748\tBest loss: 1.307715\tAccuracy: 66.50%\n",
      "692\tValidation loss: 1.307997\tBest loss: 1.307715\tAccuracy: 66.20%\n",
      "693\tValidation loss: 1.308840\tBest loss: 1.307715\tAccuracy: 65.40%\n",
      "694\tValidation loss: 1.307125\tBest loss: 1.307125\tAccuracy: 66.70%\n",
      "695\tValidation loss: 1.304289\tBest loss: 1.304289\tAccuracy: 66.80%\n",
      "696\tValidation loss: 1.306329\tBest loss: 1.304289\tAccuracy: 66.50%\n",
      "697\tValidation loss: 1.308134\tBest loss: 1.304289\tAccuracy: 66.50%\n",
      "698\tValidation loss: 1.303642\tBest loss: 1.303642\tAccuracy: 66.30%\n",
      "699\tValidation loss: 1.302975\tBest loss: 1.302975\tAccuracy: 66.70%\n",
      "700\tValidation loss: 1.306204\tBest loss: 1.302975\tAccuracy: 66.70%\n",
      "701\tValidation loss: 1.303721\tBest loss: 1.302975\tAccuracy: 66.20%\n",
      "702\tValidation loss: 1.302843\tBest loss: 1.302843\tAccuracy: 67.10%\n",
      "703\tValidation loss: 1.306764\tBest loss: 1.302843\tAccuracy: 66.40%\n",
      "704\tValidation loss: 1.307008\tBest loss: 1.302843\tAccuracy: 66.60%\n",
      "705\tValidation loss: 1.304847\tBest loss: 1.302843\tAccuracy: 66.40%\n",
      "706\tValidation loss: 1.306037\tBest loss: 1.302843\tAccuracy: 66.90%\n",
      "707\tValidation loss: 1.306460\tBest loss: 1.302843\tAccuracy: 66.70%\n",
      "708\tValidation loss: 1.305206\tBest loss: 1.302843\tAccuracy: 67.40%\n",
      "709\tValidation loss: 1.304815\tBest loss: 1.302843\tAccuracy: 66.70%\n",
      "710\tValidation loss: 1.302342\tBest loss: 1.302342\tAccuracy: 67.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711\tValidation loss: 1.301402\tBest loss: 1.301402\tAccuracy: 66.60%\n",
      "712\tValidation loss: 1.303134\tBest loss: 1.301402\tAccuracy: 66.80%\n",
      "713\tValidation loss: 1.301780\tBest loss: 1.301402\tAccuracy: 66.90%\n",
      "714\tValidation loss: 1.302651\tBest loss: 1.301402\tAccuracy: 66.60%\n",
      "715\tValidation loss: 1.304703\tBest loss: 1.301402\tAccuracy: 66.60%\n",
      "716\tValidation loss: 1.300070\tBest loss: 1.300070\tAccuracy: 66.60%\n",
      "717\tValidation loss: 1.300586\tBest loss: 1.300070\tAccuracy: 66.60%\n",
      "718\tValidation loss: 1.302495\tBest loss: 1.300070\tAccuracy: 66.40%\n",
      "719\tValidation loss: 1.302241\tBest loss: 1.300070\tAccuracy: 66.80%\n",
      "720\tValidation loss: 1.302679\tBest loss: 1.300070\tAccuracy: 66.80%\n",
      "721\tValidation loss: 1.304686\tBest loss: 1.300070\tAccuracy: 66.90%\n",
      "722\tValidation loss: 1.304937\tBest loss: 1.300070\tAccuracy: 66.80%\n",
      "723\tValidation loss: 1.298419\tBest loss: 1.298419\tAccuracy: 67.10%\n",
      "724\tValidation loss: 1.297349\tBest loss: 1.297349\tAccuracy: 66.90%\n",
      "725\tValidation loss: 1.303318\tBest loss: 1.297349\tAccuracy: 66.90%\n",
      "726\tValidation loss: 1.299323\tBest loss: 1.297349\tAccuracy: 67.00%\n",
      "727\tValidation loss: 1.297447\tBest loss: 1.297349\tAccuracy: 67.30%\n",
      "728\tValidation loss: 1.297485\tBest loss: 1.297349\tAccuracy: 67.10%\n",
      "729\tValidation loss: 1.298270\tBest loss: 1.297349\tAccuracy: 67.30%\n",
      "730\tValidation loss: 1.298114\tBest loss: 1.297349\tAccuracy: 67.10%\n",
      "731\tValidation loss: 1.300784\tBest loss: 1.297349\tAccuracy: 67.10%\n",
      "732\tValidation loss: 1.296537\tBest loss: 1.296537\tAccuracy: 67.10%\n",
      "733\tValidation loss: 1.293342\tBest loss: 1.293342\tAccuracy: 66.90%\n",
      "734\tValidation loss: 1.295771\tBest loss: 1.293342\tAccuracy: 66.50%\n",
      "735\tValidation loss: 1.297112\tBest loss: 1.293342\tAccuracy: 66.90%\n",
      "736\tValidation loss: 1.294680\tBest loss: 1.293342\tAccuracy: 67.20%\n",
      "737\tValidation loss: 1.289799\tBest loss: 1.289799\tAccuracy: 66.90%\n",
      "738\tValidation loss: 1.292506\tBest loss: 1.289799\tAccuracy: 66.90%\n",
      "739\tValidation loss: 1.292567\tBest loss: 1.289799\tAccuracy: 67.20%\n",
      "740\tValidation loss: 1.293558\tBest loss: 1.289799\tAccuracy: 66.70%\n",
      "741\tValidation loss: 1.296428\tBest loss: 1.289799\tAccuracy: 67.00%\n",
      "742\tValidation loss: 1.296225\tBest loss: 1.289799\tAccuracy: 66.70%\n",
      "743\tValidation loss: 1.289991\tBest loss: 1.289799\tAccuracy: 67.40%\n",
      "744\tValidation loss: 1.289345\tBest loss: 1.289345\tAccuracy: 67.20%\n",
      "745\tValidation loss: 1.293579\tBest loss: 1.289345\tAccuracy: 67.10%\n",
      "746\tValidation loss: 1.290955\tBest loss: 1.289345\tAccuracy: 66.90%\n",
      "747\tValidation loss: 1.295938\tBest loss: 1.289345\tAccuracy: 67.40%\n",
      "748\tValidation loss: 1.295187\tBest loss: 1.289345\tAccuracy: 66.50%\n",
      "749\tValidation loss: 1.298371\tBest loss: 1.289345\tAccuracy: 66.50%\n",
      "750\tValidation loss: 1.293363\tBest loss: 1.289345\tAccuracy: 67.20%\n",
      "751\tValidation loss: 1.292001\tBest loss: 1.289345\tAccuracy: 66.90%\n",
      "752\tValidation loss: 1.295194\tBest loss: 1.289345\tAccuracy: 66.80%\n",
      "753\tValidation loss: 1.292013\tBest loss: 1.289345\tAccuracy: 67.40%\n",
      "754\tValidation loss: 1.290029\tBest loss: 1.289345\tAccuracy: 67.00%\n",
      "755\tValidation loss: 1.284327\tBest loss: 1.284327\tAccuracy: 67.00%\n",
      "756\tValidation loss: 1.284856\tBest loss: 1.284327\tAccuracy: 67.20%\n",
      "757\tValidation loss: 1.294670\tBest loss: 1.284327\tAccuracy: 67.10%\n",
      "758\tValidation loss: 1.294832\tBest loss: 1.284327\tAccuracy: 66.70%\n",
      "759\tValidation loss: 1.293056\tBest loss: 1.284327\tAccuracy: 66.50%\n",
      "760\tValidation loss: 1.295236\tBest loss: 1.284327\tAccuracy: 66.60%\n",
      "761\tValidation loss: 1.293897\tBest loss: 1.284327\tAccuracy: 67.00%\n",
      "762\tValidation loss: 1.290705\tBest loss: 1.284327\tAccuracy: 66.90%\n",
      "763\tValidation loss: 1.285719\tBest loss: 1.284327\tAccuracy: 67.40%\n",
      "764\tValidation loss: 1.289742\tBest loss: 1.284327\tAccuracy: 67.10%\n",
      "765\tValidation loss: 1.291962\tBest loss: 1.284327\tAccuracy: 66.90%\n",
      "766\tValidation loss: 1.290928\tBest loss: 1.284327\tAccuracy: 67.20%\n",
      "767\tValidation loss: 1.286930\tBest loss: 1.284327\tAccuracy: 66.50%\n",
      "768\tValidation loss: 1.290187\tBest loss: 1.284327\tAccuracy: 66.80%\n",
      "769\tValidation loss: 1.291864\tBest loss: 1.284327\tAccuracy: 66.90%\n",
      "770\tValidation loss: 1.289270\tBest loss: 1.284327\tAccuracy: 67.10%\n",
      "771\tValidation loss: 1.288393\tBest loss: 1.284327\tAccuracy: 67.00%\n",
      "772\tValidation loss: 1.284739\tBest loss: 1.284327\tAccuracy: 66.70%\n",
      "773\tValidation loss: 1.287483\tBest loss: 1.284327\tAccuracy: 67.10%\n",
      "774\tValidation loss: 1.287525\tBest loss: 1.284327\tAccuracy: 67.20%\n",
      "775\tValidation loss: 1.285071\tBest loss: 1.284327\tAccuracy: 67.30%\n",
      "776\tValidation loss: 1.285514\tBest loss: 1.284327\tAccuracy: 67.20%\n",
      "Early stopping!\n",
      "[[  1.70820579e-03   1.22495666e-02   3.19160568e-03 ...,   8.09021294e-03\n",
      "    9.02843167e-05   7.53646542e-04]\n",
      " [  5.68864286e-38   1.30342711e-27   2.72990779e-24 ...,   6.36772000e-16\n",
      "    3.26824260e-25   8.58721835e-25]\n",
      " [  2.08534960e-11   3.34956610e-07   8.52039420e-07 ...,   3.99454620e-08\n",
      "    4.43297677e-06   5.77393075e-05]\n",
      " ..., \n",
      " [  2.03770142e-05   1.72305972e-05   8.74425859e-06 ...,   5.30780864e-14\n",
      "    7.08842653e-13   2.66085846e-13]\n",
      " [  3.69790383e-02   2.52984669e-02   2.46430337e-02 ...,   2.02042125e-02\n",
      "    1.19581074e-02   1.37803042e-02]\n",
      " [  4.27610849e-24   1.12428466e-18   1.32114401e-24 ...,   3.82655389e-06\n",
      "    1.17111478e-04   9.96419787e-01]]\n",
      "[41 41 22 ...,  6  9 47]\n",
      "[[  1.51503569e-16   1.28743974e-10   3.19909210e-10 ...,   5.52070561e-26\n",
      "    4.50639556e-21   9.65272083e-20]\n",
      " [  6.11352697e-02   3.92201655e-02   5.69746532e-02 ...,   1.81076843e-02\n",
      "    7.79338833e-03   8.19968153e-03]\n",
      " [  5.06962131e-20   6.70701791e-27   4.00292599e-09 ...,   6.85629936e-22\n",
      "    3.51989253e-31   1.03094633e-28]\n",
      " ..., \n",
      " [  3.06856004e-04   2.63039698e-03   5.05933771e-04 ...,   1.71029363e-02\n",
      "    6.58849394e-03   2.40206495e-02]\n",
      " [  1.20024893e-10   3.87241732e-11   1.01302057e-11 ...,   3.66298407e-02\n",
      "    1.13161048e-02   1.69151742e-02]\n",
      " [  1.19522656e-18   4.50818853e-12   3.82234988e-13 ...,   6.96442847e-04\n",
      "    1.60526688e-05   7.59250543e-04]]\n",
      "[20  0 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=0.2, n_hidden_layers=1, n_neurons=120, learning_rate=0.01, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  38.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.803187\tBest loss: 3.803187\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.781524\tBest loss: 3.781524\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.782576\tBest loss: 3.781524\tAccuracy: 4.30%\n",
      "3\tValidation loss: 3.765095\tBest loss: 3.765095\tAccuracy: 5.10%\n",
      "4\tValidation loss: 3.738501\tBest loss: 3.738501\tAccuracy: 4.80%\n",
      "5\tValidation loss: 3.685946\tBest loss: 3.685946\tAccuracy: 6.10%\n",
      "6\tValidation loss: 3.591867\tBest loss: 3.591867\tAccuracy: 7.10%\n",
      "7\tValidation loss: 3.499881\tBest loss: 3.499881\tAccuracy: 9.20%\n",
      "8\tValidation loss: 3.409712\tBest loss: 3.409712\tAccuracy: 10.60%\n",
      "9\tValidation loss: 3.283736\tBest loss: 3.283736\tAccuracy: 12.80%\n",
      "10\tValidation loss: 3.176990\tBest loss: 3.176990\tAccuracy: 13.70%\n",
      "11\tValidation loss: 3.098997\tBest loss: 3.098997\tAccuracy: 14.60%\n",
      "12\tValidation loss: 2.999403\tBest loss: 2.999403\tAccuracy: 18.30%\n",
      "13\tValidation loss: 2.958640\tBest loss: 2.958640\tAccuracy: 17.10%\n",
      "14\tValidation loss: 2.910368\tBest loss: 2.910368\tAccuracy: 18.80%\n",
      "15\tValidation loss: 2.849198\tBest loss: 2.849198\tAccuracy: 18.10%\n",
      "16\tValidation loss: 2.812748\tBest loss: 2.812748\tAccuracy: 21.30%\n",
      "17\tValidation loss: 2.750532\tBest loss: 2.750532\tAccuracy: 22.20%\n",
      "18\tValidation loss: 2.711132\tBest loss: 2.711132\tAccuracy: 23.40%\n",
      "19\tValidation loss: 2.656810\tBest loss: 2.656810\tAccuracy: 24.10%\n",
      "20\tValidation loss: 2.634771\tBest loss: 2.634771\tAccuracy: 24.50%\n",
      "21\tValidation loss: 2.576156\tBest loss: 2.576156\tAccuracy: 26.00%\n",
      "22\tValidation loss: 2.583749\tBest loss: 2.576156\tAccuracy: 26.30%\n",
      "23\tValidation loss: 2.534659\tBest loss: 2.534659\tAccuracy: 26.70%\n",
      "24\tValidation loss: 2.496054\tBest loss: 2.496054\tAccuracy: 28.90%\n",
      "25\tValidation loss: 2.444302\tBest loss: 2.444302\tAccuracy: 29.30%\n",
      "26\tValidation loss: 2.389445\tBest loss: 2.389445\tAccuracy: 30.00%\n",
      "27\tValidation loss: 2.432996\tBest loss: 2.389445\tAccuracy: 28.30%\n",
      "28\tValidation loss: 2.330409\tBest loss: 2.330409\tAccuracy: 32.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\tValidation loss: 2.291709\tBest loss: 2.291709\tAccuracy: 33.40%\n",
      "30\tValidation loss: 2.281775\tBest loss: 2.281775\tAccuracy: 31.80%\n",
      "31\tValidation loss: 2.258236\tBest loss: 2.258236\tAccuracy: 34.00%\n",
      "32\tValidation loss: 2.212626\tBest loss: 2.212626\tAccuracy: 38.60%\n",
      "33\tValidation loss: 2.192473\tBest loss: 2.192473\tAccuracy: 36.60%\n",
      "34\tValidation loss: 2.201580\tBest loss: 2.192473\tAccuracy: 36.90%\n",
      "35\tValidation loss: 2.115971\tBest loss: 2.115971\tAccuracy: 38.50%\n",
      "36\tValidation loss: 2.132715\tBest loss: 2.115971\tAccuracy: 39.40%\n",
      "37\tValidation loss: 2.119238\tBest loss: 2.115971\tAccuracy: 39.20%\n",
      "38\tValidation loss: 2.059420\tBest loss: 2.059420\tAccuracy: 39.60%\n",
      "39\tValidation loss: 2.069277\tBest loss: 2.059420\tAccuracy: 37.60%\n",
      "40\tValidation loss: 1.985764\tBest loss: 1.985764\tAccuracy: 41.70%\n",
      "41\tValidation loss: 2.008424\tBest loss: 1.985764\tAccuracy: 40.00%\n",
      "42\tValidation loss: 1.949922\tBest loss: 1.949922\tAccuracy: 43.50%\n",
      "43\tValidation loss: 1.992793\tBest loss: 1.949922\tAccuracy: 41.20%\n",
      "44\tValidation loss: 1.966568\tBest loss: 1.949922\tAccuracy: 41.90%\n",
      "45\tValidation loss: 1.941454\tBest loss: 1.941454\tAccuracy: 42.10%\n",
      "46\tValidation loss: 1.904141\tBest loss: 1.904141\tAccuracy: 43.70%\n",
      "47\tValidation loss: 1.950288\tBest loss: 1.904141\tAccuracy: 41.50%\n",
      "48\tValidation loss: 1.940245\tBest loss: 1.904141\tAccuracy: 42.90%\n",
      "49\tValidation loss: 1.894914\tBest loss: 1.894914\tAccuracy: 43.50%\n",
      "50\tValidation loss: 1.917183\tBest loss: 1.894914\tAccuracy: 42.10%\n",
      "51\tValidation loss: 1.867683\tBest loss: 1.867683\tAccuracy: 43.20%\n",
      "52\tValidation loss: 1.905521\tBest loss: 1.867683\tAccuracy: 42.80%\n",
      "53\tValidation loss: 1.846578\tBest loss: 1.846578\tAccuracy: 46.10%\n",
      "54\tValidation loss: 1.837069\tBest loss: 1.837069\tAccuracy: 45.10%\n",
      "55\tValidation loss: 1.838302\tBest loss: 1.837069\tAccuracy: 46.70%\n",
      "56\tValidation loss: 1.772383\tBest loss: 1.772383\tAccuracy: 47.50%\n",
      "57\tValidation loss: 1.796674\tBest loss: 1.772383\tAccuracy: 47.90%\n",
      "58\tValidation loss: 1.760043\tBest loss: 1.760043\tAccuracy: 47.20%\n",
      "59\tValidation loss: 1.815005\tBest loss: 1.760043\tAccuracy: 47.30%\n",
      "60\tValidation loss: 1.797228\tBest loss: 1.760043\tAccuracy: 47.10%\n",
      "61\tValidation loss: 1.736236\tBest loss: 1.736236\tAccuracy: 49.90%\n",
      "62\tValidation loss: 1.753534\tBest loss: 1.736236\tAccuracy: 48.40%\n",
      "63\tValidation loss: 1.772524\tBest loss: 1.736236\tAccuracy: 48.50%\n",
      "64\tValidation loss: 1.740637\tBest loss: 1.736236\tAccuracy: 48.00%\n",
      "65\tValidation loss: 1.717132\tBest loss: 1.717132\tAccuracy: 50.00%\n",
      "66\tValidation loss: 1.693141\tBest loss: 1.693141\tAccuracy: 49.30%\n",
      "67\tValidation loss: 1.731153\tBest loss: 1.693141\tAccuracy: 49.40%\n",
      "68\tValidation loss: 1.738409\tBest loss: 1.693141\tAccuracy: 47.80%\n",
      "69\tValidation loss: 1.665980\tBest loss: 1.665980\tAccuracy: 50.20%\n",
      "70\tValidation loss: 1.669184\tBest loss: 1.665980\tAccuracy: 50.30%\n",
      "71\tValidation loss: 1.658589\tBest loss: 1.658589\tAccuracy: 51.50%\n",
      "72\tValidation loss: 1.667558\tBest loss: 1.658589\tAccuracy: 50.00%\n",
      "73\tValidation loss: 1.635336\tBest loss: 1.635336\tAccuracy: 51.60%\n",
      "74\tValidation loss: 1.675288\tBest loss: 1.635336\tAccuracy: 49.70%\n",
      "75\tValidation loss: 1.647418\tBest loss: 1.635336\tAccuracy: 51.50%\n",
      "76\tValidation loss: 1.621785\tBest loss: 1.621785\tAccuracy: 51.40%\n",
      "77\tValidation loss: 1.613411\tBest loss: 1.613411\tAccuracy: 53.10%\n",
      "78\tValidation loss: 1.542318\tBest loss: 1.542318\tAccuracy: 53.90%\n",
      "79\tValidation loss: 1.576321\tBest loss: 1.542318\tAccuracy: 54.20%\n",
      "80\tValidation loss: 1.586370\tBest loss: 1.542318\tAccuracy: 52.70%\n",
      "81\tValidation loss: 1.521325\tBest loss: 1.521325\tAccuracy: 54.10%\n",
      "82\tValidation loss: 1.566012\tBest loss: 1.521325\tAccuracy: 52.70%\n",
      "83\tValidation loss: 1.552993\tBest loss: 1.521325\tAccuracy: 52.20%\n",
      "84\tValidation loss: 1.578344\tBest loss: 1.521325\tAccuracy: 51.90%\n",
      "85\tValidation loss: 1.598975\tBest loss: 1.521325\tAccuracy: 52.10%\n",
      "86\tValidation loss: 1.554150\tBest loss: 1.521325\tAccuracy: 52.80%\n",
      "87\tValidation loss: 1.526724\tBest loss: 1.521325\tAccuracy: 54.70%\n",
      "88\tValidation loss: 1.560172\tBest loss: 1.521325\tAccuracy: 53.50%\n",
      "89\tValidation loss: 1.565768\tBest loss: 1.521325\tAccuracy: 53.00%\n",
      "90\tValidation loss: 1.529971\tBest loss: 1.521325\tAccuracy: 55.10%\n",
      "91\tValidation loss: 1.517189\tBest loss: 1.517189\tAccuracy: 54.50%\n",
      "92\tValidation loss: 1.485243\tBest loss: 1.485243\tAccuracy: 55.70%\n",
      "93\tValidation loss: 1.485492\tBest loss: 1.485243\tAccuracy: 55.60%\n",
      "94\tValidation loss: 1.544267\tBest loss: 1.485243\tAccuracy: 55.40%\n",
      "95\tValidation loss: 1.454411\tBest loss: 1.454411\tAccuracy: 57.50%\n",
      "96\tValidation loss: 1.498168\tBest loss: 1.454411\tAccuracy: 57.50%\n",
      "97\tValidation loss: 1.490826\tBest loss: 1.454411\tAccuracy: 54.60%\n",
      "98\tValidation loss: 1.518037\tBest loss: 1.454411\tAccuracy: 54.10%\n",
      "99\tValidation loss: 1.491217\tBest loss: 1.454411\tAccuracy: 55.70%\n",
      "100\tValidation loss: 1.456777\tBest loss: 1.454411\tAccuracy: 57.70%\n",
      "101\tValidation loss: 1.474934\tBest loss: 1.454411\tAccuracy: 56.90%\n",
      "102\tValidation loss: 1.464403\tBest loss: 1.454411\tAccuracy: 56.30%\n",
      "103\tValidation loss: 1.457537\tBest loss: 1.454411\tAccuracy: 56.40%\n",
      "104\tValidation loss: 1.452301\tBest loss: 1.452301\tAccuracy: 57.60%\n",
      "105\tValidation loss: 1.457923\tBest loss: 1.452301\tAccuracy: 57.00%\n",
      "106\tValidation loss: 1.433043\tBest loss: 1.433043\tAccuracy: 57.20%\n",
      "107\tValidation loss: 1.489971\tBest loss: 1.433043\tAccuracy: 57.00%\n",
      "108\tValidation loss: 1.452909\tBest loss: 1.433043\tAccuracy: 57.10%\n",
      "109\tValidation loss: 1.446928\tBest loss: 1.433043\tAccuracy: 58.70%\n",
      "110\tValidation loss: 1.418551\tBest loss: 1.418551\tAccuracy: 59.30%\n",
      "111\tValidation loss: 1.405697\tBest loss: 1.405697\tAccuracy: 59.50%\n",
      "112\tValidation loss: 1.443383\tBest loss: 1.405697\tAccuracy: 57.20%\n",
      "113\tValidation loss: 1.422233\tBest loss: 1.405697\tAccuracy: 58.30%\n",
      "114\tValidation loss: 1.438507\tBest loss: 1.405697\tAccuracy: 56.80%\n",
      "115\tValidation loss: 1.436589\tBest loss: 1.405697\tAccuracy: 58.90%\n",
      "116\tValidation loss: 1.419281\tBest loss: 1.405697\tAccuracy: 58.90%\n",
      "117\tValidation loss: 1.420302\tBest loss: 1.405697\tAccuracy: 57.70%\n",
      "118\tValidation loss: 1.414661\tBest loss: 1.405697\tAccuracy: 57.60%\n",
      "119\tValidation loss: 1.408048\tBest loss: 1.405697\tAccuracy: 59.20%\n",
      "120\tValidation loss: 1.391373\tBest loss: 1.391373\tAccuracy: 58.90%\n",
      "121\tValidation loss: 1.446381\tBest loss: 1.391373\tAccuracy: 57.40%\n",
      "122\tValidation loss: 1.381716\tBest loss: 1.381716\tAccuracy: 58.90%\n",
      "123\tValidation loss: 1.414992\tBest loss: 1.381716\tAccuracy: 56.80%\n",
      "124\tValidation loss: 1.401017\tBest loss: 1.381716\tAccuracy: 57.90%\n",
      "125\tValidation loss: 1.386395\tBest loss: 1.381716\tAccuracy: 60.40%\n",
      "126\tValidation loss: 1.423104\tBest loss: 1.381716\tAccuracy: 58.20%\n",
      "127\tValidation loss: 1.402354\tBest loss: 1.381716\tAccuracy: 58.20%\n",
      "128\tValidation loss: 1.381102\tBest loss: 1.381102\tAccuracy: 59.10%\n",
      "129\tValidation loss: 1.373175\tBest loss: 1.373175\tAccuracy: 58.90%\n",
      "130\tValidation loss: 1.407269\tBest loss: 1.373175\tAccuracy: 60.00%\n",
      "131\tValidation loss: 1.374278\tBest loss: 1.373175\tAccuracy: 59.50%\n",
      "132\tValidation loss: 1.370372\tBest loss: 1.370372\tAccuracy: 59.70%\n",
      "133\tValidation loss: 1.353819\tBest loss: 1.353819\tAccuracy: 61.10%\n",
      "134\tValidation loss: 1.343500\tBest loss: 1.343500\tAccuracy: 59.40%\n",
      "135\tValidation loss: 1.358813\tBest loss: 1.343500\tAccuracy: 60.20%\n",
      "136\tValidation loss: 1.380736\tBest loss: 1.343500\tAccuracy: 59.70%\n",
      "137\tValidation loss: 1.370556\tBest loss: 1.343500\tAccuracy: 60.40%\n",
      "138\tValidation loss: 1.373110\tBest loss: 1.343500\tAccuracy: 59.20%\n",
      "139\tValidation loss: 1.360636\tBest loss: 1.343500\tAccuracy: 60.00%\n",
      "140\tValidation loss: 1.364600\tBest loss: 1.343500\tAccuracy: 58.80%\n",
      "141\tValidation loss: 1.353316\tBest loss: 1.343500\tAccuracy: 60.60%\n",
      "142\tValidation loss: 1.361522\tBest loss: 1.343500\tAccuracy: 59.10%\n",
      "143\tValidation loss: 1.355825\tBest loss: 1.343500\tAccuracy: 58.90%\n",
      "144\tValidation loss: 1.342649\tBest loss: 1.342649\tAccuracy: 60.90%\n",
      "145\tValidation loss: 1.332394\tBest loss: 1.332394\tAccuracy: 60.20%\n",
      "146\tValidation loss: 1.330633\tBest loss: 1.330633\tAccuracy: 62.50%\n",
      "147\tValidation loss: 1.343582\tBest loss: 1.330633\tAccuracy: 60.60%\n",
      "148\tValidation loss: 1.341980\tBest loss: 1.330633\tAccuracy: 61.40%\n",
      "149\tValidation loss: 1.333623\tBest loss: 1.330633\tAccuracy: 59.60%\n",
      "150\tValidation loss: 1.311686\tBest loss: 1.311686\tAccuracy: 61.60%\n",
      "151\tValidation loss: 1.334603\tBest loss: 1.311686\tAccuracy: 60.10%\n",
      "152\tValidation loss: 1.347875\tBest loss: 1.311686\tAccuracy: 58.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\tValidation loss: 1.332763\tBest loss: 1.311686\tAccuracy: 60.10%\n",
      "154\tValidation loss: 1.328173\tBest loss: 1.311686\tAccuracy: 59.70%\n",
      "155\tValidation loss: 1.341497\tBest loss: 1.311686\tAccuracy: 59.80%\n",
      "156\tValidation loss: 1.282180\tBest loss: 1.282180\tAccuracy: 61.40%\n",
      "157\tValidation loss: 1.324044\tBest loss: 1.282180\tAccuracy: 61.10%\n",
      "158\tValidation loss: 1.307421\tBest loss: 1.282180\tAccuracy: 62.00%\n",
      "159\tValidation loss: 1.303017\tBest loss: 1.282180\tAccuracy: 61.70%\n",
      "160\tValidation loss: 1.310611\tBest loss: 1.282180\tAccuracy: 61.20%\n",
      "161\tValidation loss: 1.325940\tBest loss: 1.282180\tAccuracy: 60.60%\n",
      "162\tValidation loss: 1.309481\tBest loss: 1.282180\tAccuracy: 60.80%\n",
      "163\tValidation loss: 1.301444\tBest loss: 1.282180\tAccuracy: 61.60%\n",
      "164\tValidation loss: 1.343289\tBest loss: 1.282180\tAccuracy: 60.50%\n",
      "165\tValidation loss: 1.301508\tBest loss: 1.282180\tAccuracy: 62.10%\n",
      "166\tValidation loss: 1.283877\tBest loss: 1.282180\tAccuracy: 62.80%\n",
      "167\tValidation loss: 1.304733\tBest loss: 1.282180\tAccuracy: 61.30%\n",
      "168\tValidation loss: 1.319884\tBest loss: 1.282180\tAccuracy: 61.50%\n",
      "169\tValidation loss: 1.279691\tBest loss: 1.279691\tAccuracy: 61.20%\n",
      "170\tValidation loss: 1.299445\tBest loss: 1.279691\tAccuracy: 60.60%\n",
      "171\tValidation loss: 1.295578\tBest loss: 1.279691\tAccuracy: 62.40%\n",
      "172\tValidation loss: 1.284660\tBest loss: 1.279691\tAccuracy: 63.20%\n",
      "173\tValidation loss: 1.285796\tBest loss: 1.279691\tAccuracy: 62.20%\n",
      "174\tValidation loss: 1.307509\tBest loss: 1.279691\tAccuracy: 61.80%\n",
      "175\tValidation loss: 1.280354\tBest loss: 1.279691\tAccuracy: 63.40%\n",
      "176\tValidation loss: 1.279781\tBest loss: 1.279691\tAccuracy: 63.10%\n",
      "177\tValidation loss: 1.276827\tBest loss: 1.276827\tAccuracy: 62.60%\n",
      "178\tValidation loss: 1.259601\tBest loss: 1.259601\tAccuracy: 64.40%\n",
      "179\tValidation loss: 1.311010\tBest loss: 1.259601\tAccuracy: 62.60%\n",
      "180\tValidation loss: 1.265765\tBest loss: 1.259601\tAccuracy: 63.10%\n",
      "181\tValidation loss: 1.290087\tBest loss: 1.259601\tAccuracy: 62.40%\n",
      "182\tValidation loss: 1.274905\tBest loss: 1.259601\tAccuracy: 62.30%\n",
      "183\tValidation loss: 1.314068\tBest loss: 1.259601\tAccuracy: 62.80%\n",
      "184\tValidation loss: 1.281371\tBest loss: 1.259601\tAccuracy: 63.90%\n",
      "185\tValidation loss: 1.264306\tBest loss: 1.259601\tAccuracy: 63.40%\n",
      "186\tValidation loss: 1.260076\tBest loss: 1.259601\tAccuracy: 61.80%\n",
      "187\tValidation loss: 1.280751\tBest loss: 1.259601\tAccuracy: 61.80%\n",
      "188\tValidation loss: 1.270081\tBest loss: 1.259601\tAccuracy: 62.00%\n",
      "189\tValidation loss: 1.267711\tBest loss: 1.259601\tAccuracy: 62.60%\n",
      "190\tValidation loss: 1.258464\tBest loss: 1.258464\tAccuracy: 63.90%\n",
      "191\tValidation loss: 1.239507\tBest loss: 1.239507\tAccuracy: 61.90%\n",
      "192\tValidation loss: 1.245814\tBest loss: 1.239507\tAccuracy: 64.50%\n",
      "193\tValidation loss: 1.233508\tBest loss: 1.233508\tAccuracy: 62.70%\n",
      "194\tValidation loss: 1.249260\tBest loss: 1.233508\tAccuracy: 63.00%\n",
      "195\tValidation loss: 1.238821\tBest loss: 1.233508\tAccuracy: 63.60%\n",
      "196\tValidation loss: 1.266863\tBest loss: 1.233508\tAccuracy: 62.20%\n",
      "197\tValidation loss: 1.255149\tBest loss: 1.233508\tAccuracy: 63.30%\n",
      "198\tValidation loss: 1.252719\tBest loss: 1.233508\tAccuracy: 63.50%\n",
      "199\tValidation loss: 1.233303\tBest loss: 1.233303\tAccuracy: 64.00%\n",
      "200\tValidation loss: 1.247229\tBest loss: 1.233303\tAccuracy: 62.30%\n",
      "201\tValidation loss: 1.230048\tBest loss: 1.230048\tAccuracy: 62.50%\n",
      "202\tValidation loss: 1.244523\tBest loss: 1.230048\tAccuracy: 63.70%\n",
      "203\tValidation loss: 1.220521\tBest loss: 1.220521\tAccuracy: 64.10%\n",
      "204\tValidation loss: 1.240411\tBest loss: 1.220521\tAccuracy: 63.60%\n",
      "205\tValidation loss: 1.240407\tBest loss: 1.220521\tAccuracy: 63.20%\n",
      "206\tValidation loss: 1.251737\tBest loss: 1.220521\tAccuracy: 62.90%\n",
      "207\tValidation loss: 1.232417\tBest loss: 1.220521\tAccuracy: 63.80%\n",
      "208\tValidation loss: 1.251726\tBest loss: 1.220521\tAccuracy: 63.60%\n",
      "209\tValidation loss: 1.247481\tBest loss: 1.220521\tAccuracy: 63.90%\n",
      "210\tValidation loss: 1.249097\tBest loss: 1.220521\tAccuracy: 63.60%\n",
      "211\tValidation loss: 1.229634\tBest loss: 1.220521\tAccuracy: 62.70%\n",
      "212\tValidation loss: 1.223815\tBest loss: 1.220521\tAccuracy: 64.20%\n",
      "213\tValidation loss: 1.243096\tBest loss: 1.220521\tAccuracy: 63.30%\n",
      "214\tValidation loss: 1.233912\tBest loss: 1.220521\tAccuracy: 64.20%\n",
      "215\tValidation loss: 1.206923\tBest loss: 1.206923\tAccuracy: 65.10%\n",
      "216\tValidation loss: 1.269262\tBest loss: 1.206923\tAccuracy: 61.80%\n",
      "217\tValidation loss: 1.222788\tBest loss: 1.206923\tAccuracy: 64.20%\n",
      "218\tValidation loss: 1.224027\tBest loss: 1.206923\tAccuracy: 64.20%\n",
      "219\tValidation loss: 1.230253\tBest loss: 1.206923\tAccuracy: 63.20%\n",
      "220\tValidation loss: 1.227551\tBest loss: 1.206923\tAccuracy: 64.60%\n",
      "221\tValidation loss: 1.266269\tBest loss: 1.206923\tAccuracy: 61.20%\n",
      "222\tValidation loss: 1.210075\tBest loss: 1.206923\tAccuracy: 64.50%\n",
      "223\tValidation loss: 1.199425\tBest loss: 1.199425\tAccuracy: 64.80%\n",
      "224\tValidation loss: 1.231055\tBest loss: 1.199425\tAccuracy: 64.60%\n",
      "225\tValidation loss: 1.215666\tBest loss: 1.199425\tAccuracy: 63.80%\n",
      "226\tValidation loss: 1.213723\tBest loss: 1.199425\tAccuracy: 63.90%\n",
      "227\tValidation loss: 1.218689\tBest loss: 1.199425\tAccuracy: 64.20%\n",
      "228\tValidation loss: 1.226527\tBest loss: 1.199425\tAccuracy: 64.60%\n",
      "229\tValidation loss: 1.222641\tBest loss: 1.199425\tAccuracy: 63.60%\n",
      "230\tValidation loss: 1.212724\tBest loss: 1.199425\tAccuracy: 63.10%\n",
      "231\tValidation loss: 1.230308\tBest loss: 1.199425\tAccuracy: 64.10%\n",
      "232\tValidation loss: 1.240695\tBest loss: 1.199425\tAccuracy: 64.20%\n",
      "233\tValidation loss: 1.201093\tBest loss: 1.199425\tAccuracy: 65.00%\n",
      "234\tValidation loss: 1.229118\tBest loss: 1.199425\tAccuracy: 66.10%\n",
      "235\tValidation loss: 1.189729\tBest loss: 1.189729\tAccuracy: 65.10%\n",
      "236\tValidation loss: 1.213841\tBest loss: 1.189729\tAccuracy: 64.70%\n",
      "237\tValidation loss: 1.206078\tBest loss: 1.189729\tAccuracy: 65.50%\n",
      "238\tValidation loss: 1.225348\tBest loss: 1.189729\tAccuracy: 64.90%\n",
      "239\tValidation loss: 1.199775\tBest loss: 1.189729\tAccuracy: 64.90%\n",
      "240\tValidation loss: 1.208198\tBest loss: 1.189729\tAccuracy: 64.00%\n",
      "241\tValidation loss: 1.219784\tBest loss: 1.189729\tAccuracy: 64.10%\n",
      "242\tValidation loss: 1.237685\tBest loss: 1.189729\tAccuracy: 64.10%\n",
      "243\tValidation loss: 1.216957\tBest loss: 1.189729\tAccuracy: 64.60%\n",
      "244\tValidation loss: 1.204811\tBest loss: 1.189729\tAccuracy: 65.10%\n",
      "245\tValidation loss: 1.223484\tBest loss: 1.189729\tAccuracy: 64.80%\n",
      "246\tValidation loss: 1.192418\tBest loss: 1.189729\tAccuracy: 65.50%\n",
      "247\tValidation loss: 1.186747\tBest loss: 1.186747\tAccuracy: 64.00%\n",
      "248\tValidation loss: 1.205374\tBest loss: 1.186747\tAccuracy: 65.20%\n",
      "249\tValidation loss: 1.207450\tBest loss: 1.186747\tAccuracy: 64.40%\n",
      "250\tValidation loss: 1.220135\tBest loss: 1.186747\tAccuracy: 64.70%\n",
      "251\tValidation loss: 1.189226\tBest loss: 1.186747\tAccuracy: 64.60%\n",
      "252\tValidation loss: 1.196025\tBest loss: 1.186747\tAccuracy: 62.90%\n",
      "253\tValidation loss: 1.178187\tBest loss: 1.178187\tAccuracy: 64.20%\n",
      "254\tValidation loss: 1.187457\tBest loss: 1.178187\tAccuracy: 64.60%\n",
      "255\tValidation loss: 1.197615\tBest loss: 1.178187\tAccuracy: 64.10%\n",
      "256\tValidation loss: 1.191489\tBest loss: 1.178187\tAccuracy: 65.30%\n",
      "257\tValidation loss: 1.160850\tBest loss: 1.160850\tAccuracy: 65.10%\n",
      "258\tValidation loss: 1.186064\tBest loss: 1.160850\tAccuracy: 65.90%\n",
      "259\tValidation loss: 1.172311\tBest loss: 1.160850\tAccuracy: 63.30%\n",
      "260\tValidation loss: 1.174897\tBest loss: 1.160850\tAccuracy: 65.50%\n",
      "261\tValidation loss: 1.193188\tBest loss: 1.160850\tAccuracy: 64.50%\n",
      "262\tValidation loss: 1.161126\tBest loss: 1.160850\tAccuracy: 66.30%\n",
      "263\tValidation loss: 1.165388\tBest loss: 1.160850\tAccuracy: 66.40%\n",
      "264\tValidation loss: 1.167151\tBest loss: 1.160850\tAccuracy: 66.10%\n",
      "265\tValidation loss: 1.181803\tBest loss: 1.160850\tAccuracy: 65.50%\n",
      "266\tValidation loss: 1.188726\tBest loss: 1.160850\tAccuracy: 64.60%\n",
      "267\tValidation loss: 1.213229\tBest loss: 1.160850\tAccuracy: 64.80%\n",
      "268\tValidation loss: 1.182084\tBest loss: 1.160850\tAccuracy: 65.30%\n",
      "269\tValidation loss: 1.192384\tBest loss: 1.160850\tAccuracy: 64.90%\n",
      "270\tValidation loss: 1.219417\tBest loss: 1.160850\tAccuracy: 65.80%\n",
      "271\tValidation loss: 1.168336\tBest loss: 1.160850\tAccuracy: 65.70%\n",
      "272\tValidation loss: 1.162231\tBest loss: 1.160850\tAccuracy: 66.10%\n",
      "273\tValidation loss: 1.192051\tBest loss: 1.160850\tAccuracy: 66.00%\n",
      "274\tValidation loss: 1.175864\tBest loss: 1.160850\tAccuracy: 64.60%\n",
      "275\tValidation loss: 1.161178\tBest loss: 1.160850\tAccuracy: 65.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\tValidation loss: 1.189630\tBest loss: 1.160850\tAccuracy: 65.70%\n",
      "277\tValidation loss: 1.175404\tBest loss: 1.160850\tAccuracy: 64.50%\n",
      "278\tValidation loss: 1.175470\tBest loss: 1.160850\tAccuracy: 66.70%\n",
      "Early stopping!\n",
      "[[  2.24059420e-08   5.96796512e-04   1.84841992e-05 ...,   1.48017866e-17\n",
      "    3.45506306e-12   6.61371743e-16]\n",
      " [  1.26602039e-01   2.10257806e-02   7.94370323e-02 ...,   1.44955004e-03\n",
      "    7.42948207e-04   6.82805083e-04]\n",
      " [  1.25252608e-09   8.97889060e-15   6.79016239e-07 ...,   2.07872375e-13\n",
      "    2.88945896e-13   2.21589416e-13]\n",
      " ..., \n",
      " [  6.37708787e-15   1.09556001e-11   9.54494628e-17 ...,   1.87057878e-12\n",
      "    3.31742134e-10   6.06078433e-14]\n",
      " [  7.89151178e-04   3.98191740e-04   2.39541964e-03 ...,   1.13384843e-01\n",
      "    9.84030403e-03   4.67809383e-03]\n",
      " [  4.70501874e-07   1.47705396e-06   1.12859625e-05 ...,   2.01942306e-03\n",
      "    1.18600787e-04   2.50072288e-03]]\n",
      "[20 19 16 ...,  6 26  9]\n",
      "[[  9.03565069e-06   1.69989682e-04   9.68435593e-03 ...,   4.25500366e-06\n",
      "    2.17571815e-05   2.32819802e-05]\n",
      " [  5.07162780e-13   5.99569603e-08   4.88058260e-10 ...,   4.55228976e-19\n",
      "    1.70696736e-13   1.28269698e-17]\n",
      " [  9.72223552e-06   4.03739796e-05   3.42729909e-05 ...,   2.48081733e-08\n",
      "    2.48755009e-06   5.98517289e-08]\n",
      " ..., \n",
      " [  5.16089244e-07   3.21843868e-06   6.86812973e-06 ...,   6.65014016e-11\n",
      "    6.36390163e-10   1.07103481e-13]\n",
      " [  2.14073583e-02   4.45672823e-03   1.05214659e-02 ...,   1.36887487e-02\n",
      "    9.07175802e-03   1.35644870e-02]\n",
      " [  4.94804926e-15   2.92489126e-08   9.17183742e-14 ...,   2.52298871e-03\n",
      "    4.46116962e-02   6.31413162e-01]]\n",
      "[31 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total= 1.2min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.788843\tBest loss: 3.788843\tAccuracy: 4.40%\n",
      "1\tValidation loss: 3.768047\tBest loss: 3.768047\tAccuracy: 4.40%\n",
      "2\tValidation loss: 3.744554\tBest loss: 3.744554\tAccuracy: 5.00%\n",
      "3\tValidation loss: 3.751976\tBest loss: 3.744554\tAccuracy: 4.50%\n",
      "4\tValidation loss: 3.725028\tBest loss: 3.725028\tAccuracy: 5.50%\n",
      "5\tValidation loss: 3.631087\tBest loss: 3.631087\tAccuracy: 7.00%\n",
      "6\tValidation loss: 3.573293\tBest loss: 3.573293\tAccuracy: 8.00%\n",
      "7\tValidation loss: 3.477650\tBest loss: 3.477650\tAccuracy: 8.90%\n",
      "8\tValidation loss: 3.436042\tBest loss: 3.436042\tAccuracy: 10.50%\n",
      "9\tValidation loss: 3.351019\tBest loss: 3.351019\tAccuracy: 12.20%\n",
      "10\tValidation loss: 3.175497\tBest loss: 3.175497\tAccuracy: 14.40%\n",
      "11\tValidation loss: 3.140409\tBest loss: 3.140409\tAccuracy: 14.40%\n",
      "12\tValidation loss: 2.995794\tBest loss: 2.995794\tAccuracy: 17.30%\n",
      "13\tValidation loss: 2.953400\tBest loss: 2.953400\tAccuracy: 18.70%\n",
      "14\tValidation loss: 2.853198\tBest loss: 2.853198\tAccuracy: 21.60%\n",
      "15\tValidation loss: 2.778714\tBest loss: 2.778714\tAccuracy: 23.40%\n",
      "16\tValidation loss: 2.660082\tBest loss: 2.660082\tAccuracy: 25.60%\n",
      "17\tValidation loss: 2.635111\tBest loss: 2.635111\tAccuracy: 26.70%\n",
      "18\tValidation loss: 2.582433\tBest loss: 2.582433\tAccuracy: 30.10%\n",
      "19\tValidation loss: 2.526361\tBest loss: 2.526361\tAccuracy: 28.90%\n",
      "20\tValidation loss: 2.452146\tBest loss: 2.452146\tAccuracy: 31.50%\n",
      "21\tValidation loss: 2.434132\tBest loss: 2.434132\tAccuracy: 30.30%\n",
      "22\tValidation loss: 2.378976\tBest loss: 2.378976\tAccuracy: 32.50%\n",
      "23\tValidation loss: 2.318679\tBest loss: 2.318679\tAccuracy: 33.90%\n",
      "24\tValidation loss: 2.303794\tBest loss: 2.303794\tAccuracy: 34.30%\n",
      "25\tValidation loss: 2.294939\tBest loss: 2.294939\tAccuracy: 34.10%\n",
      "26\tValidation loss: 2.265148\tBest loss: 2.265148\tAccuracy: 36.40%\n",
      "27\tValidation loss: 2.258810\tBest loss: 2.258810\tAccuracy: 33.90%\n",
      "28\tValidation loss: 2.204882\tBest loss: 2.204882\tAccuracy: 36.50%\n",
      "29\tValidation loss: 2.164777\tBest loss: 2.164777\tAccuracy: 38.20%\n",
      "30\tValidation loss: 2.114689\tBest loss: 2.114689\tAccuracy: 39.50%\n",
      "31\tValidation loss: 2.122616\tBest loss: 2.114689\tAccuracy: 35.10%\n",
      "32\tValidation loss: 2.157213\tBest loss: 2.114689\tAccuracy: 35.50%\n",
      "33\tValidation loss: 2.079369\tBest loss: 2.079369\tAccuracy: 38.80%\n",
      "34\tValidation loss: 2.074513\tBest loss: 2.074513\tAccuracy: 40.00%\n",
      "35\tValidation loss: 2.048800\tBest loss: 2.048800\tAccuracy: 40.50%\n",
      "36\tValidation loss: 2.020304\tBest loss: 2.020304\tAccuracy: 42.40%\n",
      "37\tValidation loss: 2.001930\tBest loss: 2.001930\tAccuracy: 42.50%\n",
      "38\tValidation loss: 1.970810\tBest loss: 1.970810\tAccuracy: 41.20%\n",
      "39\tValidation loss: 1.962137\tBest loss: 1.962137\tAccuracy: 41.60%\n",
      "40\tValidation loss: 1.898056\tBest loss: 1.898056\tAccuracy: 44.70%\n",
      "41\tValidation loss: 1.921584\tBest loss: 1.898056\tAccuracy: 45.40%\n",
      "42\tValidation loss: 1.865030\tBest loss: 1.865030\tAccuracy: 44.70%\n",
      "43\tValidation loss: 1.894682\tBest loss: 1.865030\tAccuracy: 44.50%\n",
      "44\tValidation loss: 1.844333\tBest loss: 1.844333\tAccuracy: 46.70%\n",
      "45\tValidation loss: 1.834522\tBest loss: 1.834522\tAccuracy: 48.10%\n",
      "46\tValidation loss: 1.821304\tBest loss: 1.821304\tAccuracy: 46.50%\n",
      "47\tValidation loss: 1.798270\tBest loss: 1.798270\tAccuracy: 45.50%\n",
      "48\tValidation loss: 1.765933\tBest loss: 1.765933\tAccuracy: 47.80%\n",
      "49\tValidation loss: 1.795047\tBest loss: 1.765933\tAccuracy: 48.00%\n",
      "50\tValidation loss: 1.742775\tBest loss: 1.742775\tAccuracy: 48.90%\n",
      "51\tValidation loss: 1.760982\tBest loss: 1.742775\tAccuracy: 49.20%\n",
      "52\tValidation loss: 1.737824\tBest loss: 1.737824\tAccuracy: 48.80%\n",
      "53\tValidation loss: 1.707030\tBest loss: 1.707030\tAccuracy: 49.40%\n",
      "54\tValidation loss: 1.715404\tBest loss: 1.707030\tAccuracy: 50.50%\n",
      "55\tValidation loss: 1.757150\tBest loss: 1.707030\tAccuracy: 48.60%\n",
      "56\tValidation loss: 1.745924\tBest loss: 1.707030\tAccuracy: 50.00%\n",
      "57\tValidation loss: 1.694324\tBest loss: 1.694324\tAccuracy: 50.50%\n",
      "58\tValidation loss: 1.724605\tBest loss: 1.694324\tAccuracy: 51.40%\n",
      "59\tValidation loss: 1.696413\tBest loss: 1.694324\tAccuracy: 51.50%\n",
      "60\tValidation loss: 1.684548\tBest loss: 1.684548\tAccuracy: 51.10%\n",
      "61\tValidation loss: 1.656697\tBest loss: 1.656697\tAccuracy: 54.00%\n",
      "62\tValidation loss: 1.654173\tBest loss: 1.654173\tAccuracy: 53.60%\n",
      "63\tValidation loss: 1.707333\tBest loss: 1.654173\tAccuracy: 49.20%\n",
      "64\tValidation loss: 1.665071\tBest loss: 1.654173\tAccuracy: 51.90%\n",
      "65\tValidation loss: 1.659054\tBest loss: 1.654173\tAccuracy: 52.80%\n",
      "66\tValidation loss: 1.679552\tBest loss: 1.654173\tAccuracy: 50.50%\n",
      "67\tValidation loss: 1.666333\tBest loss: 1.654173\tAccuracy: 51.30%\n",
      "68\tValidation loss: 1.652816\tBest loss: 1.652816\tAccuracy: 53.50%\n",
      "69\tValidation loss: 1.603433\tBest loss: 1.603433\tAccuracy: 53.40%\n",
      "70\tValidation loss: 1.607614\tBest loss: 1.603433\tAccuracy: 52.70%\n",
      "71\tValidation loss: 1.603444\tBest loss: 1.603433\tAccuracy: 54.50%\n",
      "72\tValidation loss: 1.601509\tBest loss: 1.601509\tAccuracy: 53.80%\n",
      "73\tValidation loss: 1.572270\tBest loss: 1.572270\tAccuracy: 53.30%\n",
      "74\tValidation loss: 1.580404\tBest loss: 1.572270\tAccuracy: 52.20%\n",
      "75\tValidation loss: 1.561561\tBest loss: 1.561561\tAccuracy: 54.90%\n",
      "76\tValidation loss: 1.563134\tBest loss: 1.561561\tAccuracy: 54.30%\n",
      "77\tValidation loss: 1.555813\tBest loss: 1.555813\tAccuracy: 54.20%\n",
      "78\tValidation loss: 1.523813\tBest loss: 1.523813\tAccuracy: 55.90%\n",
      "79\tValidation loss: 1.575687\tBest loss: 1.523813\tAccuracy: 54.20%\n",
      "80\tValidation loss: 1.529701\tBest loss: 1.523813\tAccuracy: 57.10%\n",
      "81\tValidation loss: 1.563020\tBest loss: 1.523813\tAccuracy: 54.40%\n",
      "82\tValidation loss: 1.555442\tBest loss: 1.523813\tAccuracy: 55.70%\n",
      "83\tValidation loss: 1.547858\tBest loss: 1.523813\tAccuracy: 54.50%\n",
      "84\tValidation loss: 1.520771\tBest loss: 1.520771\tAccuracy: 56.10%\n",
      "85\tValidation loss: 1.542229\tBest loss: 1.520771\tAccuracy: 55.80%\n",
      "86\tValidation loss: 1.525477\tBest loss: 1.520771\tAccuracy: 56.40%\n",
      "87\tValidation loss: 1.520015\tBest loss: 1.520015\tAccuracy: 56.80%\n",
      "88\tValidation loss: 1.500497\tBest loss: 1.500497\tAccuracy: 56.90%\n",
      "89\tValidation loss: 1.514040\tBest loss: 1.500497\tAccuracy: 57.20%\n",
      "90\tValidation loss: 1.499311\tBest loss: 1.499311\tAccuracy: 58.30%\n",
      "91\tValidation loss: 1.500769\tBest loss: 1.499311\tAccuracy: 56.70%\n",
      "92\tValidation loss: 1.494058\tBest loss: 1.494058\tAccuracy: 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\tValidation loss: 1.511048\tBest loss: 1.494058\tAccuracy: 57.80%\n",
      "94\tValidation loss: 1.524571\tBest loss: 1.494058\tAccuracy: 56.80%\n",
      "95\tValidation loss: 1.472652\tBest loss: 1.472652\tAccuracy: 57.90%\n",
      "96\tValidation loss: 1.479404\tBest loss: 1.472652\tAccuracy: 57.20%\n",
      "97\tValidation loss: 1.462389\tBest loss: 1.462389\tAccuracy: 57.70%\n",
      "98\tValidation loss: 1.454296\tBest loss: 1.454296\tAccuracy: 60.20%\n",
      "99\tValidation loss: 1.476097\tBest loss: 1.454296\tAccuracy: 57.90%\n",
      "100\tValidation loss: 1.481910\tBest loss: 1.454296\tAccuracy: 58.20%\n",
      "101\tValidation loss: 1.444853\tBest loss: 1.444853\tAccuracy: 60.50%\n",
      "102\tValidation loss: 1.441185\tBest loss: 1.441185\tAccuracy: 57.90%\n",
      "103\tValidation loss: 1.466303\tBest loss: 1.441185\tAccuracy: 56.20%\n",
      "104\tValidation loss: 1.453017\tBest loss: 1.441185\tAccuracy: 57.30%\n",
      "105\tValidation loss: 1.447138\tBest loss: 1.441185\tAccuracy: 58.50%\n",
      "106\tValidation loss: 1.428965\tBest loss: 1.428965\tAccuracy: 58.90%\n",
      "107\tValidation loss: 1.438136\tBest loss: 1.428965\tAccuracy: 59.30%\n",
      "108\tValidation loss: 1.500607\tBest loss: 1.428965\tAccuracy: 56.70%\n",
      "109\tValidation loss: 1.452547\tBest loss: 1.428965\tAccuracy: 58.00%\n",
      "110\tValidation loss: 1.411783\tBest loss: 1.411783\tAccuracy: 60.30%\n",
      "111\tValidation loss: 1.446127\tBest loss: 1.411783\tAccuracy: 58.70%\n",
      "112\tValidation loss: 1.415722\tBest loss: 1.411783\tAccuracy: 59.40%\n",
      "113\tValidation loss: 1.418637\tBest loss: 1.411783\tAccuracy: 60.20%\n",
      "114\tValidation loss: 1.443124\tBest loss: 1.411783\tAccuracy: 60.30%\n",
      "115\tValidation loss: 1.420078\tBest loss: 1.411783\tAccuracy: 60.20%\n",
      "116\tValidation loss: 1.418043\tBest loss: 1.411783\tAccuracy: 60.10%\n",
      "117\tValidation loss: 1.403559\tBest loss: 1.403559\tAccuracy: 60.90%\n",
      "118\tValidation loss: 1.399571\tBest loss: 1.399571\tAccuracy: 58.90%\n",
      "119\tValidation loss: 1.455155\tBest loss: 1.399571\tAccuracy: 57.00%\n",
      "120\tValidation loss: 1.420578\tBest loss: 1.399571\tAccuracy: 61.20%\n",
      "121\tValidation loss: 1.431876\tBest loss: 1.399571\tAccuracy: 58.40%\n",
      "122\tValidation loss: 1.402419\tBest loss: 1.399571\tAccuracy: 61.70%\n",
      "123\tValidation loss: 1.403993\tBest loss: 1.399571\tAccuracy: 59.70%\n",
      "124\tValidation loss: 1.397648\tBest loss: 1.397648\tAccuracy: 60.20%\n",
      "125\tValidation loss: 1.431376\tBest loss: 1.397648\tAccuracy: 59.60%\n",
      "126\tValidation loss: 1.369966\tBest loss: 1.369966\tAccuracy: 61.00%\n",
      "127\tValidation loss: 1.370603\tBest loss: 1.369966\tAccuracy: 60.60%\n",
      "128\tValidation loss: 1.394059\tBest loss: 1.369966\tAccuracy: 59.70%\n",
      "129\tValidation loss: 1.393107\tBest loss: 1.369966\tAccuracy: 61.20%\n",
      "130\tValidation loss: 1.373385\tBest loss: 1.369966\tAccuracy: 60.30%\n",
      "131\tValidation loss: 1.382540\tBest loss: 1.369966\tAccuracy: 59.80%\n",
      "132\tValidation loss: 1.384679\tBest loss: 1.369966\tAccuracy: 62.10%\n",
      "133\tValidation loss: 1.365378\tBest loss: 1.365378\tAccuracy: 61.60%\n",
      "134\tValidation loss: 1.361240\tBest loss: 1.361240\tAccuracy: 61.00%\n",
      "135\tValidation loss: 1.385564\tBest loss: 1.361240\tAccuracy: 61.80%\n",
      "136\tValidation loss: 1.363161\tBest loss: 1.361240\tAccuracy: 62.20%\n",
      "137\tValidation loss: 1.350786\tBest loss: 1.350786\tAccuracy: 62.30%\n",
      "138\tValidation loss: 1.385101\tBest loss: 1.350786\tAccuracy: 62.20%\n",
      "139\tValidation loss: 1.363074\tBest loss: 1.350786\tAccuracy: 62.10%\n",
      "140\tValidation loss: 1.377793\tBest loss: 1.350786\tAccuracy: 61.90%\n",
      "141\tValidation loss: 1.354164\tBest loss: 1.350786\tAccuracy: 61.30%\n",
      "142\tValidation loss: 1.372172\tBest loss: 1.350786\tAccuracy: 60.40%\n",
      "143\tValidation loss: 1.345923\tBest loss: 1.345923\tAccuracy: 62.40%\n",
      "144\tValidation loss: 1.351486\tBest loss: 1.345923\tAccuracy: 62.10%\n",
      "145\tValidation loss: 1.340053\tBest loss: 1.340053\tAccuracy: 62.60%\n",
      "146\tValidation loss: 1.329642\tBest loss: 1.329642\tAccuracy: 62.30%\n",
      "147\tValidation loss: 1.370921\tBest loss: 1.329642\tAccuracy: 61.20%\n",
      "148\tValidation loss: 1.374550\tBest loss: 1.329642\tAccuracy: 62.00%\n",
      "149\tValidation loss: 1.358343\tBest loss: 1.329642\tAccuracy: 62.80%\n",
      "150\tValidation loss: 1.335513\tBest loss: 1.329642\tAccuracy: 62.60%\n",
      "151\tValidation loss: 1.331363\tBest loss: 1.329642\tAccuracy: 63.30%\n",
      "152\tValidation loss: 1.312232\tBest loss: 1.312232\tAccuracy: 62.30%\n",
      "153\tValidation loss: 1.350424\tBest loss: 1.312232\tAccuracy: 62.40%\n",
      "154\tValidation loss: 1.361985\tBest loss: 1.312232\tAccuracy: 61.20%\n",
      "155\tValidation loss: 1.329667\tBest loss: 1.312232\tAccuracy: 61.50%\n",
      "156\tValidation loss: 1.322020\tBest loss: 1.312232\tAccuracy: 62.50%\n",
      "157\tValidation loss: 1.333895\tBest loss: 1.312232\tAccuracy: 61.70%\n",
      "158\tValidation loss: 1.333571\tBest loss: 1.312232\tAccuracy: 63.00%\n",
      "159\tValidation loss: 1.312067\tBest loss: 1.312067\tAccuracy: 62.30%\n",
      "160\tValidation loss: 1.319937\tBest loss: 1.312067\tAccuracy: 63.30%\n",
      "161\tValidation loss: 1.299262\tBest loss: 1.299262\tAccuracy: 63.00%\n",
      "162\tValidation loss: 1.316592\tBest loss: 1.299262\tAccuracy: 61.50%\n",
      "163\tValidation loss: 1.311576\tBest loss: 1.299262\tAccuracy: 63.00%\n",
      "164\tValidation loss: 1.320083\tBest loss: 1.299262\tAccuracy: 63.80%\n",
      "165\tValidation loss: 1.310808\tBest loss: 1.299262\tAccuracy: 62.40%\n",
      "166\tValidation loss: 1.300035\tBest loss: 1.299262\tAccuracy: 62.70%\n",
      "167\tValidation loss: 1.334750\tBest loss: 1.299262\tAccuracy: 62.00%\n",
      "168\tValidation loss: 1.319939\tBest loss: 1.299262\tAccuracy: 62.50%\n",
      "169\tValidation loss: 1.303050\tBest loss: 1.299262\tAccuracy: 62.00%\n",
      "170\tValidation loss: 1.323152\tBest loss: 1.299262\tAccuracy: 61.60%\n",
      "171\tValidation loss: 1.318737\tBest loss: 1.299262\tAccuracy: 62.30%\n",
      "172\tValidation loss: 1.292033\tBest loss: 1.292033\tAccuracy: 63.70%\n",
      "173\tValidation loss: 1.317536\tBest loss: 1.292033\tAccuracy: 61.00%\n",
      "174\tValidation loss: 1.310925\tBest loss: 1.292033\tAccuracy: 63.80%\n",
      "175\tValidation loss: 1.318791\tBest loss: 1.292033\tAccuracy: 62.20%\n",
      "176\tValidation loss: 1.307618\tBest loss: 1.292033\tAccuracy: 63.60%\n",
      "177\tValidation loss: 1.285188\tBest loss: 1.285188\tAccuracy: 62.80%\n",
      "178\tValidation loss: 1.297825\tBest loss: 1.285188\tAccuracy: 62.30%\n",
      "179\tValidation loss: 1.264779\tBest loss: 1.264779\tAccuracy: 62.70%\n",
      "180\tValidation loss: 1.275071\tBest loss: 1.264779\tAccuracy: 62.80%\n",
      "181\tValidation loss: 1.303149\tBest loss: 1.264779\tAccuracy: 61.60%\n",
      "182\tValidation loss: 1.268494\tBest loss: 1.264779\tAccuracy: 62.50%\n",
      "183\tValidation loss: 1.276127\tBest loss: 1.264779\tAccuracy: 63.50%\n",
      "184\tValidation loss: 1.265972\tBest loss: 1.264779\tAccuracy: 64.30%\n",
      "185\tValidation loss: 1.238289\tBest loss: 1.238289\tAccuracy: 64.10%\n",
      "186\tValidation loss: 1.267163\tBest loss: 1.238289\tAccuracy: 64.10%\n",
      "187\tValidation loss: 1.285383\tBest loss: 1.238289\tAccuracy: 64.20%\n",
      "188\tValidation loss: 1.272712\tBest loss: 1.238289\tAccuracy: 63.60%\n",
      "189\tValidation loss: 1.272112\tBest loss: 1.238289\tAccuracy: 63.50%\n",
      "190\tValidation loss: 1.259326\tBest loss: 1.238289\tAccuracy: 64.40%\n",
      "191\tValidation loss: 1.270120\tBest loss: 1.238289\tAccuracy: 63.50%\n",
      "192\tValidation loss: 1.270365\tBest loss: 1.238289\tAccuracy: 63.80%\n",
      "193\tValidation loss: 1.249419\tBest loss: 1.238289\tAccuracy: 63.10%\n",
      "194\tValidation loss: 1.276308\tBest loss: 1.238289\tAccuracy: 63.00%\n",
      "195\tValidation loss: 1.263278\tBest loss: 1.238289\tAccuracy: 64.00%\n",
      "196\tValidation loss: 1.259358\tBest loss: 1.238289\tAccuracy: 64.20%\n",
      "197\tValidation loss: 1.260954\tBest loss: 1.238289\tAccuracy: 64.20%\n",
      "198\tValidation loss: 1.241664\tBest loss: 1.238289\tAccuracy: 65.00%\n",
      "199\tValidation loss: 1.270055\tBest loss: 1.238289\tAccuracy: 64.00%\n",
      "200\tValidation loss: 1.270967\tBest loss: 1.238289\tAccuracy: 62.70%\n",
      "201\tValidation loss: 1.253084\tBest loss: 1.238289\tAccuracy: 64.70%\n",
      "202\tValidation loss: 1.277412\tBest loss: 1.238289\tAccuracy: 63.50%\n",
      "203\tValidation loss: 1.239921\tBest loss: 1.238289\tAccuracy: 63.80%\n",
      "204\tValidation loss: 1.311697\tBest loss: 1.238289\tAccuracy: 61.60%\n",
      "205\tValidation loss: 1.264093\tBest loss: 1.238289\tAccuracy: 64.00%\n",
      "206\tValidation loss: 1.274413\tBest loss: 1.238289\tAccuracy: 63.50%\n",
      "Early stopping!\n",
      "[[  8.01384798e-04   1.15854451e-02   8.68243258e-03 ...,   4.30189029e-05\n",
      "    8.69202995e-05   5.29307348e-04]\n",
      " [  2.94418929e-14   3.04277364e-07   1.26811361e-08 ...,   2.19668254e-15\n",
      "    1.15421318e-10   6.55900889e-11]\n",
      " [  8.43897851e-06   7.94896856e-04   1.02327824e-04 ...,   1.41057797e-07\n",
      "    3.27506910e-07   6.74631394e-07]\n",
      " ..., \n",
      " [  1.02807979e-04   2.53927010e-05   4.21146222e-04 ...,   4.35144547e-03\n",
      "    3.55284405e-03   1.08152507e-02]\n",
      " [  8.57197122e-08   5.53444181e-07   3.66680047e-06 ...,   2.13087484e-01\n",
      "    1.22633316e-01   5.32172062e-02]\n",
      " [  5.57348585e-07   5.11366011e-07   1.01514470e-05 ...,   2.75639743e-02\n",
      "    2.22741510e-03   8.58595129e-03]]\n",
      "[31 43 43 ...,  8 44 25]\n",
      "[[  1.61863838e-07   2.12135306e-03   1.37459347e-03 ...,   4.23906041e-14\n",
      "    6.51316645e-09   6.40206999e-09]\n",
      " [  1.31626904e-01   1.92149337e-02   8.90977606e-02 ...,   3.18249222e-03\n",
      "    7.55536254e-04   6.40630955e-04]\n",
      " [  2.44855915e-12   5.95028238e-28   1.61380825e-07 ...,   4.57316693e-12\n",
      "    7.89548331e-13   3.24891070e-15]\n",
      " ..., \n",
      " [  1.65644422e-04   3.69582063e-04   3.76635330e-06 ...,   1.73420517e-07\n",
      "    4.13504068e-07   4.93866779e-08]\n",
      " [  1.37263685e-02   6.21294975e-03   3.56363580e-02 ...,   9.91819892e-03\n",
      "    1.45345451e-02   9.08483099e-03]\n",
      " [  1.18500121e-16   1.34505486e-14   4.12781707e-16 ...,   2.60055123e-04\n",
      "    4.90449369e-03   8.95046055e-01]]\n",
      "[20 17 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=  54.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.809016\tBest loss: 3.809016\tAccuracy: 3.80%\n",
      "1\tValidation loss: 3.765511\tBest loss: 3.765511\tAccuracy: 5.40%\n",
      "2\tValidation loss: 3.687859\tBest loss: 3.687859\tAccuracy: 6.00%\n",
      "3\tValidation loss: 3.600165\tBest loss: 3.600165\tAccuracy: 6.10%\n",
      "4\tValidation loss: 3.488869\tBest loss: 3.488869\tAccuracy: 9.10%\n",
      "5\tValidation loss: 3.429860\tBest loss: 3.429860\tAccuracy: 11.00%\n",
      "6\tValidation loss: 3.319252\tBest loss: 3.319252\tAccuracy: 11.20%\n",
      "7\tValidation loss: 3.320110\tBest loss: 3.319252\tAccuracy: 11.90%\n",
      "8\tValidation loss: 3.196508\tBest loss: 3.196508\tAccuracy: 12.20%\n",
      "9\tValidation loss: 3.090586\tBest loss: 3.090586\tAccuracy: 14.50%\n",
      "10\tValidation loss: 3.063764\tBest loss: 3.063764\tAccuracy: 14.90%\n",
      "11\tValidation loss: 2.947860\tBest loss: 2.947860\tAccuracy: 17.70%\n",
      "12\tValidation loss: 2.934479\tBest loss: 2.934479\tAccuracy: 18.80%\n",
      "13\tValidation loss: 2.927091\tBest loss: 2.927091\tAccuracy: 19.90%\n",
      "14\tValidation loss: 2.787621\tBest loss: 2.787621\tAccuracy: 21.70%\n",
      "15\tValidation loss: 2.725030\tBest loss: 2.725030\tAccuracy: 23.40%\n",
      "16\tValidation loss: 2.666136\tBest loss: 2.666136\tAccuracy: 25.00%\n",
      "17\tValidation loss: 2.625318\tBest loss: 2.625318\tAccuracy: 22.50%\n",
      "18\tValidation loss: 2.571282\tBest loss: 2.571282\tAccuracy: 26.40%\n",
      "19\tValidation loss: 2.504594\tBest loss: 2.504594\tAccuracy: 28.30%\n",
      "20\tValidation loss: 2.469783\tBest loss: 2.469783\tAccuracy: 27.10%\n",
      "21\tValidation loss: 2.448879\tBest loss: 2.448879\tAccuracy: 27.20%\n",
      "22\tValidation loss: 2.393202\tBest loss: 2.393202\tAccuracy: 30.80%\n",
      "23\tValidation loss: 2.324951\tBest loss: 2.324951\tAccuracy: 32.20%\n",
      "24\tValidation loss: 2.375255\tBest loss: 2.324951\tAccuracy: 29.10%\n",
      "25\tValidation loss: 2.333970\tBest loss: 2.324951\tAccuracy: 30.10%\n",
      "26\tValidation loss: 2.318314\tBest loss: 2.318314\tAccuracy: 31.10%\n",
      "27\tValidation loss: 2.259780\tBest loss: 2.259780\tAccuracy: 32.70%\n",
      "28\tValidation loss: 2.224794\tBest loss: 2.224794\tAccuracy: 35.00%\n",
      "29\tValidation loss: 2.167548\tBest loss: 2.167548\tAccuracy: 36.30%\n",
      "30\tValidation loss: 2.181809\tBest loss: 2.167548\tAccuracy: 35.20%\n",
      "31\tValidation loss: 2.165755\tBest loss: 2.165755\tAccuracy: 34.40%\n",
      "32\tValidation loss: 2.084993\tBest loss: 2.084993\tAccuracy: 38.70%\n",
      "33\tValidation loss: 2.104627\tBest loss: 2.084993\tAccuracy: 37.60%\n",
      "34\tValidation loss: 2.046201\tBest loss: 2.046201\tAccuracy: 40.40%\n",
      "35\tValidation loss: 2.033072\tBest loss: 2.033072\tAccuracy: 39.10%\n",
      "36\tValidation loss: 2.056514\tBest loss: 2.033072\tAccuracy: 40.20%\n",
      "37\tValidation loss: 1.961977\tBest loss: 1.961977\tAccuracy: 41.40%\n",
      "38\tValidation loss: 1.946708\tBest loss: 1.946708\tAccuracy: 42.90%\n",
      "39\tValidation loss: 1.918076\tBest loss: 1.918076\tAccuracy: 43.50%\n",
      "40\tValidation loss: 1.982312\tBest loss: 1.918076\tAccuracy: 41.90%\n",
      "41\tValidation loss: 1.899689\tBest loss: 1.899689\tAccuracy: 44.30%\n",
      "42\tValidation loss: 1.890265\tBest loss: 1.890265\tAccuracy: 44.10%\n",
      "43\tValidation loss: 1.840162\tBest loss: 1.840162\tAccuracy: 45.90%\n",
      "44\tValidation loss: 1.842315\tBest loss: 1.840162\tAccuracy: 46.40%\n",
      "45\tValidation loss: 1.824619\tBest loss: 1.824619\tAccuracy: 47.40%\n",
      "46\tValidation loss: 1.804629\tBest loss: 1.804629\tAccuracy: 46.60%\n",
      "47\tValidation loss: 1.824989\tBest loss: 1.804629\tAccuracy: 46.50%\n",
      "48\tValidation loss: 1.814048\tBest loss: 1.804629\tAccuracy: 44.80%\n",
      "49\tValidation loss: 1.805345\tBest loss: 1.804629\tAccuracy: 47.40%\n",
      "50\tValidation loss: 1.757341\tBest loss: 1.757341\tAccuracy: 48.10%\n",
      "51\tValidation loss: 1.748374\tBest loss: 1.748374\tAccuracy: 48.50%\n",
      "52\tValidation loss: 1.755677\tBest loss: 1.748374\tAccuracy: 46.30%\n",
      "53\tValidation loss: 1.732735\tBest loss: 1.732735\tAccuracy: 48.00%\n",
      "54\tValidation loss: 1.750553\tBest loss: 1.732735\tAccuracy: 48.60%\n",
      "55\tValidation loss: 1.702136\tBest loss: 1.702136\tAccuracy: 50.00%\n",
      "56\tValidation loss: 1.707368\tBest loss: 1.702136\tAccuracy: 48.50%\n",
      "57\tValidation loss: 1.672490\tBest loss: 1.672490\tAccuracy: 50.80%\n",
      "58\tValidation loss: 1.669375\tBest loss: 1.669375\tAccuracy: 50.20%\n",
      "59\tValidation loss: 1.646329\tBest loss: 1.646329\tAccuracy: 50.30%\n",
      "60\tValidation loss: 1.684755\tBest loss: 1.646329\tAccuracy: 50.00%\n",
      "61\tValidation loss: 1.674963\tBest loss: 1.646329\tAccuracy: 49.30%\n",
      "62\tValidation loss: 1.625567\tBest loss: 1.625567\tAccuracy: 51.40%\n",
      "63\tValidation loss: 1.660261\tBest loss: 1.625567\tAccuracy: 51.20%\n",
      "64\tValidation loss: 1.647001\tBest loss: 1.625567\tAccuracy: 50.80%\n",
      "65\tValidation loss: 1.652998\tBest loss: 1.625567\tAccuracy: 51.20%\n",
      "66\tValidation loss: 1.682583\tBest loss: 1.625567\tAccuracy: 51.20%\n",
      "67\tValidation loss: 1.644874\tBest loss: 1.625567\tAccuracy: 51.40%\n",
      "68\tValidation loss: 1.612507\tBest loss: 1.612507\tAccuracy: 53.10%\n",
      "69\tValidation loss: 1.616062\tBest loss: 1.612507\tAccuracy: 54.70%\n",
      "70\tValidation loss: 1.616911\tBest loss: 1.612507\tAccuracy: 53.40%\n",
      "71\tValidation loss: 1.583624\tBest loss: 1.583624\tAccuracy: 53.20%\n",
      "72\tValidation loss: 1.587342\tBest loss: 1.583624\tAccuracy: 52.50%\n",
      "73\tValidation loss: 1.576547\tBest loss: 1.576547\tAccuracy: 55.30%\n",
      "74\tValidation loss: 1.591206\tBest loss: 1.576547\tAccuracy: 52.50%\n",
      "75\tValidation loss: 1.602590\tBest loss: 1.576547\tAccuracy: 54.30%\n",
      "76\tValidation loss: 1.588316\tBest loss: 1.576547\tAccuracy: 55.10%\n",
      "77\tValidation loss: 1.593604\tBest loss: 1.576547\tAccuracy: 52.70%\n",
      "78\tValidation loss: 1.606134\tBest loss: 1.576547\tAccuracy: 51.60%\n",
      "79\tValidation loss: 1.550945\tBest loss: 1.550945\tAccuracy: 54.20%\n",
      "80\tValidation loss: 1.550057\tBest loss: 1.550057\tAccuracy: 55.50%\n",
      "81\tValidation loss: 1.555095\tBest loss: 1.550057\tAccuracy: 55.40%\n",
      "82\tValidation loss: 1.553864\tBest loss: 1.550057\tAccuracy: 55.80%\n",
      "83\tValidation loss: 1.529699\tBest loss: 1.529699\tAccuracy: 57.60%\n",
      "84\tValidation loss: 1.531156\tBest loss: 1.529699\tAccuracy: 56.20%\n",
      "85\tValidation loss: 1.542055\tBest loss: 1.529699\tAccuracy: 55.50%\n",
      "86\tValidation loss: 1.538375\tBest loss: 1.529699\tAccuracy: 55.40%\n",
      "87\tValidation loss: 1.592882\tBest loss: 1.529699\tAccuracy: 54.50%\n",
      "88\tValidation loss: 1.535392\tBest loss: 1.529699\tAccuracy: 56.40%\n",
      "89\tValidation loss: 1.496759\tBest loss: 1.496759\tAccuracy: 56.00%\n",
      "90\tValidation loss: 1.498161\tBest loss: 1.496759\tAccuracy: 55.20%\n",
      "91\tValidation loss: 1.501042\tBest loss: 1.496759\tAccuracy: 55.40%\n",
      "92\tValidation loss: 1.461824\tBest loss: 1.461824\tAccuracy: 57.10%\n",
      "93\tValidation loss: 1.517123\tBest loss: 1.461824\tAccuracy: 55.60%\n",
      "94\tValidation loss: 1.479887\tBest loss: 1.461824\tAccuracy: 56.70%\n",
      "95\tValidation loss: 1.503575\tBest loss: 1.461824\tAccuracy: 56.70%\n",
      "96\tValidation loss: 1.503973\tBest loss: 1.461824\tAccuracy: 55.40%\n",
      "97\tValidation loss: 1.479940\tBest loss: 1.461824\tAccuracy: 54.90%\n",
      "98\tValidation loss: 1.512162\tBest loss: 1.461824\tAccuracy: 54.60%\n",
      "99\tValidation loss: 1.484126\tBest loss: 1.461824\tAccuracy: 57.50%\n",
      "100\tValidation loss: 1.489051\tBest loss: 1.461824\tAccuracy: 55.50%\n",
      "101\tValidation loss: 1.425494\tBest loss: 1.425494\tAccuracy: 56.90%\n",
      "102\tValidation loss: 1.444424\tBest loss: 1.425494\tAccuracy: 56.50%\n",
      "103\tValidation loss: 1.435380\tBest loss: 1.425494\tAccuracy: 57.80%\n",
      "104\tValidation loss: 1.458021\tBest loss: 1.425494\tAccuracy: 58.20%\n",
      "105\tValidation loss: 1.423695\tBest loss: 1.423695\tAccuracy: 57.30%\n",
      "106\tValidation loss: 1.431217\tBest loss: 1.423695\tAccuracy: 56.30%\n",
      "107\tValidation loss: 1.411231\tBest loss: 1.411231\tAccuracy: 58.00%\n",
      "108\tValidation loss: 1.415877\tBest loss: 1.411231\tAccuracy: 58.10%\n",
      "109\tValidation loss: 1.406170\tBest loss: 1.406170\tAccuracy: 57.20%\n",
      "110\tValidation loss: 1.403939\tBest loss: 1.403939\tAccuracy: 57.40%\n",
      "111\tValidation loss: 1.431672\tBest loss: 1.403939\tAccuracy: 58.00%\n",
      "112\tValidation loss: 1.420259\tBest loss: 1.403939\tAccuracy: 57.40%\n",
      "113\tValidation loss: 1.400506\tBest loss: 1.400506\tAccuracy: 59.30%\n",
      "114\tValidation loss: 1.372156\tBest loss: 1.372156\tAccuracy: 60.50%\n",
      "115\tValidation loss: 1.387739\tBest loss: 1.372156\tAccuracy: 58.00%\n",
      "116\tValidation loss: 1.399846\tBest loss: 1.372156\tAccuracy: 57.50%\n",
      "117\tValidation loss: 1.384392\tBest loss: 1.372156\tAccuracy: 58.80%\n",
      "118\tValidation loss: 1.357599\tBest loss: 1.357599\tAccuracy: 58.80%\n",
      "119\tValidation loss: 1.359052\tBest loss: 1.357599\tAccuracy: 58.50%\n",
      "120\tValidation loss: 1.363881\tBest loss: 1.357599\tAccuracy: 59.70%\n",
      "121\tValidation loss: 1.355590\tBest loss: 1.355590\tAccuracy: 60.20%\n",
      "122\tValidation loss: 1.363672\tBest loss: 1.355590\tAccuracy: 58.70%\n",
      "123\tValidation loss: 1.380120\tBest loss: 1.355590\tAccuracy: 60.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 1.338688\tBest loss: 1.338688\tAccuracy: 59.40%\n",
      "125\tValidation loss: 1.375022\tBest loss: 1.338688\tAccuracy: 58.10%\n",
      "126\tValidation loss: 1.364586\tBest loss: 1.338688\tAccuracy: 59.50%\n",
      "127\tValidation loss: 1.331299\tBest loss: 1.331299\tAccuracy: 59.90%\n",
      "128\tValidation loss: 1.338475\tBest loss: 1.331299\tAccuracy: 60.80%\n",
      "129\tValidation loss: 1.331620\tBest loss: 1.331299\tAccuracy: 60.50%\n",
      "130\tValidation loss: 1.327464\tBest loss: 1.327464\tAccuracy: 60.50%\n",
      "131\tValidation loss: 1.319378\tBest loss: 1.319378\tAccuracy: 61.60%\n",
      "132\tValidation loss: 1.353038\tBest loss: 1.319378\tAccuracy: 61.50%\n",
      "133\tValidation loss: 1.316954\tBest loss: 1.316954\tAccuracy: 61.50%\n",
      "134\tValidation loss: 1.354794\tBest loss: 1.316954\tAccuracy: 59.60%\n",
      "135\tValidation loss: 1.337741\tBest loss: 1.316954\tAccuracy: 59.30%\n",
      "136\tValidation loss: 1.351168\tBest loss: 1.316954\tAccuracy: 59.90%\n",
      "137\tValidation loss: 1.347612\tBest loss: 1.316954\tAccuracy: 59.50%\n",
      "138\tValidation loss: 1.348933\tBest loss: 1.316954\tAccuracy: 61.00%\n",
      "139\tValidation loss: 1.306353\tBest loss: 1.306353\tAccuracy: 61.40%\n",
      "140\tValidation loss: 1.311189\tBest loss: 1.306353\tAccuracy: 59.80%\n",
      "141\tValidation loss: 1.308519\tBest loss: 1.306353\tAccuracy: 61.80%\n",
      "142\tValidation loss: 1.315140\tBest loss: 1.306353\tAccuracy: 61.40%\n",
      "143\tValidation loss: 1.306701\tBest loss: 1.306353\tAccuracy: 60.90%\n",
      "144\tValidation loss: 1.318122\tBest loss: 1.306353\tAccuracy: 62.30%\n",
      "145\tValidation loss: 1.308588\tBest loss: 1.306353\tAccuracy: 59.60%\n",
      "146\tValidation loss: 1.293177\tBest loss: 1.293177\tAccuracy: 61.10%\n",
      "147\tValidation loss: 1.310625\tBest loss: 1.293177\tAccuracy: 60.90%\n",
      "148\tValidation loss: 1.311206\tBest loss: 1.293177\tAccuracy: 61.50%\n",
      "149\tValidation loss: 1.309302\tBest loss: 1.293177\tAccuracy: 61.90%\n",
      "150\tValidation loss: 1.308069\tBest loss: 1.293177\tAccuracy: 61.40%\n",
      "151\tValidation loss: 1.343200\tBest loss: 1.293177\tAccuracy: 61.00%\n",
      "152\tValidation loss: 1.287068\tBest loss: 1.287068\tAccuracy: 61.60%\n",
      "153\tValidation loss: 1.331906\tBest loss: 1.287068\tAccuracy: 59.40%\n",
      "154\tValidation loss: 1.312822\tBest loss: 1.287068\tAccuracy: 60.90%\n",
      "155\tValidation loss: 1.296397\tBest loss: 1.287068\tAccuracy: 60.30%\n",
      "156\tValidation loss: 1.306587\tBest loss: 1.287068\tAccuracy: 61.10%\n",
      "157\tValidation loss: 1.309461\tBest loss: 1.287068\tAccuracy: 59.20%\n",
      "158\tValidation loss: 1.289954\tBest loss: 1.287068\tAccuracy: 60.70%\n",
      "159\tValidation loss: 1.273529\tBest loss: 1.273529\tAccuracy: 61.40%\n",
      "160\tValidation loss: 1.285424\tBest loss: 1.273529\tAccuracy: 61.50%\n",
      "161\tValidation loss: 1.295408\tBest loss: 1.273529\tAccuracy: 60.50%\n",
      "162\tValidation loss: 1.289087\tBest loss: 1.273529\tAccuracy: 62.00%\n",
      "163\tValidation loss: 1.300190\tBest loss: 1.273529\tAccuracy: 62.40%\n",
      "164\tValidation loss: 1.277122\tBest loss: 1.273529\tAccuracy: 60.90%\n",
      "165\tValidation loss: 1.266041\tBest loss: 1.266041\tAccuracy: 62.60%\n",
      "166\tValidation loss: 1.278714\tBest loss: 1.266041\tAccuracy: 61.70%\n",
      "167\tValidation loss: 1.283505\tBest loss: 1.266041\tAccuracy: 61.00%\n",
      "168\tValidation loss: 1.270073\tBest loss: 1.266041\tAccuracy: 62.40%\n",
      "169\tValidation loss: 1.275955\tBest loss: 1.266041\tAccuracy: 61.80%\n",
      "170\tValidation loss: 1.293106\tBest loss: 1.266041\tAccuracy: 62.70%\n",
      "171\tValidation loss: 1.261774\tBest loss: 1.261774\tAccuracy: 61.60%\n",
      "172\tValidation loss: 1.262103\tBest loss: 1.261774\tAccuracy: 63.20%\n",
      "173\tValidation loss: 1.285697\tBest loss: 1.261774\tAccuracy: 61.50%\n",
      "174\tValidation loss: 1.273487\tBest loss: 1.261774\tAccuracy: 62.40%\n",
      "175\tValidation loss: 1.269998\tBest loss: 1.261774\tAccuracy: 61.70%\n",
      "176\tValidation loss: 1.274465\tBest loss: 1.261774\tAccuracy: 61.60%\n",
      "177\tValidation loss: 1.285044\tBest loss: 1.261774\tAccuracy: 62.00%\n",
      "178\tValidation loss: 1.247329\tBest loss: 1.247329\tAccuracy: 62.60%\n",
      "179\tValidation loss: 1.266512\tBest loss: 1.247329\tAccuracy: 62.00%\n",
      "180\tValidation loss: 1.243404\tBest loss: 1.243404\tAccuracy: 64.50%\n",
      "181\tValidation loss: 1.232849\tBest loss: 1.232849\tAccuracy: 63.50%\n",
      "182\tValidation loss: 1.230249\tBest loss: 1.230249\tAccuracy: 62.50%\n",
      "183\tValidation loss: 1.260955\tBest loss: 1.230249\tAccuracy: 62.90%\n",
      "184\tValidation loss: 1.221312\tBest loss: 1.221312\tAccuracy: 63.70%\n",
      "185\tValidation loss: 1.250257\tBest loss: 1.221312\tAccuracy: 63.00%\n",
      "186\tValidation loss: 1.244715\tBest loss: 1.221312\tAccuracy: 62.80%\n",
      "187\tValidation loss: 1.261112\tBest loss: 1.221312\tAccuracy: 63.50%\n",
      "188\tValidation loss: 1.240486\tBest loss: 1.221312\tAccuracy: 62.40%\n",
      "189\tValidation loss: 1.241085\tBest loss: 1.221312\tAccuracy: 63.60%\n",
      "190\tValidation loss: 1.233191\tBest loss: 1.221312\tAccuracy: 62.50%\n",
      "191\tValidation loss: 1.262650\tBest loss: 1.221312\tAccuracy: 62.50%\n",
      "192\tValidation loss: 1.238752\tBest loss: 1.221312\tAccuracy: 63.50%\n",
      "193\tValidation loss: 1.223331\tBest loss: 1.221312\tAccuracy: 62.40%\n",
      "194\tValidation loss: 1.256358\tBest loss: 1.221312\tAccuracy: 62.90%\n",
      "195\tValidation loss: 1.248204\tBest loss: 1.221312\tAccuracy: 63.60%\n",
      "196\tValidation loss: 1.251213\tBest loss: 1.221312\tAccuracy: 62.30%\n",
      "197\tValidation loss: 1.232144\tBest loss: 1.221312\tAccuracy: 63.80%\n",
      "198\tValidation loss: 1.225375\tBest loss: 1.221312\tAccuracy: 64.80%\n",
      "199\tValidation loss: 1.231146\tBest loss: 1.221312\tAccuracy: 63.50%\n",
      "200\tValidation loss: 1.221292\tBest loss: 1.221292\tAccuracy: 63.90%\n",
      "201\tValidation loss: 1.238717\tBest loss: 1.221292\tAccuracy: 62.70%\n",
      "202\tValidation loss: 1.214095\tBest loss: 1.214095\tAccuracy: 64.20%\n",
      "203\tValidation loss: 1.215489\tBest loss: 1.214095\tAccuracy: 63.70%\n",
      "204\tValidation loss: 1.209170\tBest loss: 1.209170\tAccuracy: 63.80%\n",
      "205\tValidation loss: 1.224669\tBest loss: 1.209170\tAccuracy: 63.80%\n",
      "206\tValidation loss: 1.234962\tBest loss: 1.209170\tAccuracy: 64.00%\n",
      "207\tValidation loss: 1.214636\tBest loss: 1.209170\tAccuracy: 63.40%\n",
      "208\tValidation loss: 1.212425\tBest loss: 1.209170\tAccuracy: 62.30%\n",
      "209\tValidation loss: 1.208035\tBest loss: 1.208035\tAccuracy: 65.60%\n",
      "210\tValidation loss: 1.215807\tBest loss: 1.208035\tAccuracy: 64.60%\n",
      "211\tValidation loss: 1.206358\tBest loss: 1.206358\tAccuracy: 63.60%\n",
      "212\tValidation loss: 1.198834\tBest loss: 1.198834\tAccuracy: 64.10%\n",
      "213\tValidation loss: 1.203769\tBest loss: 1.198834\tAccuracy: 64.40%\n",
      "214\tValidation loss: 1.219259\tBest loss: 1.198834\tAccuracy: 64.90%\n",
      "215\tValidation loss: 1.220806\tBest loss: 1.198834\tAccuracy: 64.10%\n",
      "216\tValidation loss: 1.199450\tBest loss: 1.198834\tAccuracy: 65.20%\n",
      "217\tValidation loss: 1.193368\tBest loss: 1.193368\tAccuracy: 64.40%\n",
      "218\tValidation loss: 1.192388\tBest loss: 1.192388\tAccuracy: 64.40%\n",
      "219\tValidation loss: 1.190940\tBest loss: 1.190940\tAccuracy: 64.30%\n",
      "220\tValidation loss: 1.203636\tBest loss: 1.190940\tAccuracy: 64.40%\n",
      "221\tValidation loss: 1.232727\tBest loss: 1.190940\tAccuracy: 63.40%\n",
      "222\tValidation loss: 1.184667\tBest loss: 1.184667\tAccuracy: 64.80%\n",
      "223\tValidation loss: 1.196923\tBest loss: 1.184667\tAccuracy: 63.60%\n",
      "224\tValidation loss: 1.200717\tBest loss: 1.184667\tAccuracy: 63.10%\n",
      "225\tValidation loss: 1.183550\tBest loss: 1.183550\tAccuracy: 65.80%\n",
      "226\tValidation loss: 1.179347\tBest loss: 1.179347\tAccuracy: 64.60%\n",
      "227\tValidation loss: 1.230833\tBest loss: 1.179347\tAccuracy: 63.90%\n",
      "228\tValidation loss: 1.194940\tBest loss: 1.179347\tAccuracy: 66.90%\n",
      "229\tValidation loss: 1.205804\tBest loss: 1.179347\tAccuracy: 64.00%\n",
      "230\tValidation loss: 1.168759\tBest loss: 1.168759\tAccuracy: 65.80%\n",
      "231\tValidation loss: 1.197457\tBest loss: 1.168759\tAccuracy: 65.90%\n",
      "232\tValidation loss: 1.160040\tBest loss: 1.160040\tAccuracy: 65.20%\n",
      "233\tValidation loss: 1.194802\tBest loss: 1.160040\tAccuracy: 65.10%\n",
      "234\tValidation loss: 1.179985\tBest loss: 1.160040\tAccuracy: 65.20%\n",
      "235\tValidation loss: 1.200077\tBest loss: 1.160040\tAccuracy: 65.10%\n",
      "236\tValidation loss: 1.205153\tBest loss: 1.160040\tAccuracy: 64.40%\n",
      "237\tValidation loss: 1.186468\tBest loss: 1.160040\tAccuracy: 64.00%\n",
      "238\tValidation loss: 1.186552\tBest loss: 1.160040\tAccuracy: 64.50%\n",
      "239\tValidation loss: 1.176244\tBest loss: 1.160040\tAccuracy: 65.50%\n",
      "240\tValidation loss: 1.172115\tBest loss: 1.160040\tAccuracy: 65.10%\n",
      "241\tValidation loss: 1.152677\tBest loss: 1.152677\tAccuracy: 66.40%\n",
      "242\tValidation loss: 1.184919\tBest loss: 1.152677\tAccuracy: 64.50%\n",
      "243\tValidation loss: 1.154881\tBest loss: 1.152677\tAccuracy: 66.60%\n",
      "244\tValidation loss: 1.172960\tBest loss: 1.152677\tAccuracy: 65.30%\n",
      "245\tValidation loss: 1.178951\tBest loss: 1.152677\tAccuracy: 64.90%\n",
      "246\tValidation loss: 1.152450\tBest loss: 1.152450\tAccuracy: 64.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\tValidation loss: 1.156619\tBest loss: 1.152450\tAccuracy: 65.50%\n",
      "248\tValidation loss: 1.155475\tBest loss: 1.152450\tAccuracy: 65.90%\n",
      "249\tValidation loss: 1.172807\tBest loss: 1.152450\tAccuracy: 65.40%\n",
      "250\tValidation loss: 1.154537\tBest loss: 1.152450\tAccuracy: 65.70%\n",
      "251\tValidation loss: 1.158302\tBest loss: 1.152450\tAccuracy: 65.00%\n",
      "252\tValidation loss: 1.154555\tBest loss: 1.152450\tAccuracy: 64.90%\n",
      "253\tValidation loss: 1.156193\tBest loss: 1.152450\tAccuracy: 65.60%\n",
      "254\tValidation loss: 1.154513\tBest loss: 1.152450\tAccuracy: 66.10%\n",
      "255\tValidation loss: 1.155908\tBest loss: 1.152450\tAccuracy: 66.10%\n",
      "256\tValidation loss: 1.193273\tBest loss: 1.152450\tAccuracy: 65.50%\n",
      "257\tValidation loss: 1.152570\tBest loss: 1.152450\tAccuracy: 66.70%\n",
      "258\tValidation loss: 1.158335\tBest loss: 1.152450\tAccuracy: 64.70%\n",
      "259\tValidation loss: 1.137771\tBest loss: 1.137771\tAccuracy: 65.70%\n",
      "260\tValidation loss: 1.165602\tBest loss: 1.137771\tAccuracy: 65.40%\n",
      "261\tValidation loss: 1.140919\tBest loss: 1.137771\tAccuracy: 66.50%\n",
      "262\tValidation loss: 1.151641\tBest loss: 1.137771\tAccuracy: 65.60%\n",
      "263\tValidation loss: 1.151529\tBest loss: 1.137771\tAccuracy: 66.50%\n",
      "264\tValidation loss: 1.122923\tBest loss: 1.122923\tAccuracy: 67.10%\n",
      "265\tValidation loss: 1.153866\tBest loss: 1.122923\tAccuracy: 65.40%\n",
      "266\tValidation loss: 1.151519\tBest loss: 1.122923\tAccuracy: 65.40%\n",
      "267\tValidation loss: 1.158032\tBest loss: 1.122923\tAccuracy: 65.30%\n",
      "268\tValidation loss: 1.156315\tBest loss: 1.122923\tAccuracy: 65.40%\n",
      "269\tValidation loss: 1.135718\tBest loss: 1.122923\tAccuracy: 66.40%\n",
      "270\tValidation loss: 1.129397\tBest loss: 1.122923\tAccuracy: 66.90%\n",
      "271\tValidation loss: 1.140783\tBest loss: 1.122923\tAccuracy: 66.20%\n",
      "272\tValidation loss: 1.122734\tBest loss: 1.122734\tAccuracy: 68.20%\n",
      "273\tValidation loss: 1.146038\tBest loss: 1.122734\tAccuracy: 66.30%\n",
      "274\tValidation loss: 1.147703\tBest loss: 1.122734\tAccuracy: 65.80%\n",
      "275\tValidation loss: 1.138489\tBest loss: 1.122734\tAccuracy: 67.00%\n",
      "276\tValidation loss: 1.134892\tBest loss: 1.122734\tAccuracy: 66.80%\n",
      "277\tValidation loss: 1.134579\tBest loss: 1.122734\tAccuracy: 67.10%\n",
      "278\tValidation loss: 1.163357\tBest loss: 1.122734\tAccuracy: 65.80%\n",
      "279\tValidation loss: 1.154589\tBest loss: 1.122734\tAccuracy: 66.90%\n",
      "280\tValidation loss: 1.139123\tBest loss: 1.122734\tAccuracy: 67.00%\n",
      "281\tValidation loss: 1.145957\tBest loss: 1.122734\tAccuracy: 65.80%\n",
      "282\tValidation loss: 1.129926\tBest loss: 1.122734\tAccuracy: 65.80%\n",
      "283\tValidation loss: 1.121394\tBest loss: 1.121394\tAccuracy: 67.50%\n",
      "284\tValidation loss: 1.116782\tBest loss: 1.116782\tAccuracy: 67.40%\n",
      "285\tValidation loss: 1.116220\tBest loss: 1.116220\tAccuracy: 67.80%\n",
      "286\tValidation loss: 1.138203\tBest loss: 1.116220\tAccuracy: 66.50%\n",
      "287\tValidation loss: 1.134991\tBest loss: 1.116220\tAccuracy: 65.70%\n",
      "288\tValidation loss: 1.123913\tBest loss: 1.116220\tAccuracy: 67.60%\n",
      "289\tValidation loss: 1.129294\tBest loss: 1.116220\tAccuracy: 65.70%\n",
      "290\tValidation loss: 1.151121\tBest loss: 1.116220\tAccuracy: 65.00%\n",
      "291\tValidation loss: 1.155865\tBest loss: 1.116220\tAccuracy: 63.70%\n",
      "292\tValidation loss: 1.122694\tBest loss: 1.116220\tAccuracy: 67.40%\n",
      "293\tValidation loss: 1.123372\tBest loss: 1.116220\tAccuracy: 68.30%\n",
      "294\tValidation loss: 1.111534\tBest loss: 1.111534\tAccuracy: 67.40%\n",
      "295\tValidation loss: 1.132140\tBest loss: 1.111534\tAccuracy: 66.70%\n",
      "296\tValidation loss: 1.135864\tBest loss: 1.111534\tAccuracy: 67.90%\n",
      "297\tValidation loss: 1.115131\tBest loss: 1.111534\tAccuracy: 68.60%\n",
      "298\tValidation loss: 1.124630\tBest loss: 1.111534\tAccuracy: 67.10%\n",
      "299\tValidation loss: 1.135480\tBest loss: 1.111534\tAccuracy: 67.60%\n",
      "300\tValidation loss: 1.118590\tBest loss: 1.111534\tAccuracy: 68.20%\n",
      "301\tValidation loss: 1.127257\tBest loss: 1.111534\tAccuracy: 67.80%\n",
      "302\tValidation loss: 1.120647\tBest loss: 1.111534\tAccuracy: 66.90%\n",
      "303\tValidation loss: 1.150219\tBest loss: 1.111534\tAccuracy: 68.00%\n",
      "304\tValidation loss: 1.132906\tBest loss: 1.111534\tAccuracy: 67.00%\n",
      "305\tValidation loss: 1.118170\tBest loss: 1.111534\tAccuracy: 67.80%\n",
      "306\tValidation loss: 1.116623\tBest loss: 1.111534\tAccuracy: 66.90%\n",
      "307\tValidation loss: 1.105521\tBest loss: 1.105521\tAccuracy: 68.00%\n",
      "308\tValidation loss: 1.139686\tBest loss: 1.105521\tAccuracy: 66.20%\n",
      "309\tValidation loss: 1.113588\tBest loss: 1.105521\tAccuracy: 66.90%\n",
      "310\tValidation loss: 1.119369\tBest loss: 1.105521\tAccuracy: 68.10%\n",
      "311\tValidation loss: 1.110405\tBest loss: 1.105521\tAccuracy: 68.10%\n",
      "312\tValidation loss: 1.124703\tBest loss: 1.105521\tAccuracy: 67.70%\n",
      "313\tValidation loss: 1.107002\tBest loss: 1.105521\tAccuracy: 68.40%\n",
      "314\tValidation loss: 1.134184\tBest loss: 1.105521\tAccuracy: 67.30%\n",
      "315\tValidation loss: 1.120754\tBest loss: 1.105521\tAccuracy: 68.30%\n",
      "316\tValidation loss: 1.098574\tBest loss: 1.098574\tAccuracy: 68.50%\n",
      "317\tValidation loss: 1.112464\tBest loss: 1.098574\tAccuracy: 68.50%\n",
      "318\tValidation loss: 1.109208\tBest loss: 1.098574\tAccuracy: 67.70%\n",
      "319\tValidation loss: 1.125064\tBest loss: 1.098574\tAccuracy: 67.20%\n",
      "320\tValidation loss: 1.110534\tBest loss: 1.098574\tAccuracy: 67.60%\n",
      "321\tValidation loss: 1.126221\tBest loss: 1.098574\tAccuracy: 66.10%\n",
      "322\tValidation loss: 1.118589\tBest loss: 1.098574\tAccuracy: 68.30%\n",
      "323\tValidation loss: 1.155388\tBest loss: 1.098574\tAccuracy: 66.40%\n",
      "324\tValidation loss: 1.111029\tBest loss: 1.098574\tAccuracy: 68.10%\n",
      "325\tValidation loss: 1.146096\tBest loss: 1.098574\tAccuracy: 65.70%\n",
      "326\tValidation loss: 1.101259\tBest loss: 1.098574\tAccuracy: 67.70%\n",
      "327\tValidation loss: 1.113924\tBest loss: 1.098574\tAccuracy: 67.10%\n",
      "328\tValidation loss: 1.101740\tBest loss: 1.098574\tAccuracy: 67.30%\n",
      "329\tValidation loss: 1.110187\tBest loss: 1.098574\tAccuracy: 66.40%\n",
      "330\tValidation loss: 1.120923\tBest loss: 1.098574\tAccuracy: 67.30%\n",
      "331\tValidation loss: 1.088884\tBest loss: 1.088884\tAccuracy: 68.90%\n",
      "332\tValidation loss: 1.101906\tBest loss: 1.088884\tAccuracy: 67.00%\n",
      "333\tValidation loss: 1.106228\tBest loss: 1.088884\tAccuracy: 67.90%\n",
      "334\tValidation loss: 1.116359\tBest loss: 1.088884\tAccuracy: 67.50%\n",
      "335\tValidation loss: 1.093528\tBest loss: 1.088884\tAccuracy: 67.40%\n",
      "336\tValidation loss: 1.120631\tBest loss: 1.088884\tAccuracy: 67.00%\n",
      "337\tValidation loss: 1.099823\tBest loss: 1.088884\tAccuracy: 67.70%\n",
      "338\tValidation loss: 1.098517\tBest loss: 1.088884\tAccuracy: 67.90%\n",
      "339\tValidation loss: 1.084404\tBest loss: 1.084404\tAccuracy: 68.40%\n",
      "340\tValidation loss: 1.076416\tBest loss: 1.076416\tAccuracy: 67.70%\n",
      "341\tValidation loss: 1.095051\tBest loss: 1.076416\tAccuracy: 68.80%\n",
      "342\tValidation loss: 1.105456\tBest loss: 1.076416\tAccuracy: 66.90%\n",
      "343\tValidation loss: 1.087860\tBest loss: 1.076416\tAccuracy: 66.80%\n",
      "344\tValidation loss: 1.087286\tBest loss: 1.076416\tAccuracy: 68.40%\n",
      "345\tValidation loss: 1.080001\tBest loss: 1.076416\tAccuracy: 67.90%\n",
      "346\tValidation loss: 1.103594\tBest loss: 1.076416\tAccuracy: 69.10%\n",
      "347\tValidation loss: 1.084024\tBest loss: 1.076416\tAccuracy: 68.00%\n",
      "348\tValidation loss: 1.080701\tBest loss: 1.076416\tAccuracy: 69.30%\n",
      "349\tValidation loss: 1.091507\tBest loss: 1.076416\tAccuracy: 69.10%\n",
      "350\tValidation loss: 1.086637\tBest loss: 1.076416\tAccuracy: 68.40%\n",
      "351\tValidation loss: 1.092544\tBest loss: 1.076416\tAccuracy: 68.40%\n",
      "352\tValidation loss: 1.104823\tBest loss: 1.076416\tAccuracy: 67.50%\n",
      "353\tValidation loss: 1.086182\tBest loss: 1.076416\tAccuracy: 67.70%\n",
      "354\tValidation loss: 1.064135\tBest loss: 1.064135\tAccuracy: 69.10%\n",
      "355\tValidation loss: 1.074952\tBest loss: 1.064135\tAccuracy: 67.50%\n",
      "356\tValidation loss: 1.091152\tBest loss: 1.064135\tAccuracy: 67.40%\n",
      "357\tValidation loss: 1.084985\tBest loss: 1.064135\tAccuracy: 67.90%\n",
      "358\tValidation loss: 1.094637\tBest loss: 1.064135\tAccuracy: 67.00%\n",
      "359\tValidation loss: 1.084171\tBest loss: 1.064135\tAccuracy: 68.30%\n",
      "360\tValidation loss: 1.088794\tBest loss: 1.064135\tAccuracy: 67.30%\n",
      "361\tValidation loss: 1.098451\tBest loss: 1.064135\tAccuracy: 66.90%\n",
      "362\tValidation loss: 1.104927\tBest loss: 1.064135\tAccuracy: 67.70%\n",
      "363\tValidation loss: 1.081725\tBest loss: 1.064135\tAccuracy: 67.80%\n",
      "364\tValidation loss: 1.093953\tBest loss: 1.064135\tAccuracy: 68.20%\n",
      "365\tValidation loss: 1.091050\tBest loss: 1.064135\tAccuracy: 68.90%\n",
      "366\tValidation loss: 1.069608\tBest loss: 1.064135\tAccuracy: 68.40%\n",
      "367\tValidation loss: 1.078071\tBest loss: 1.064135\tAccuracy: 68.60%\n",
      "368\tValidation loss: 1.118050\tBest loss: 1.064135\tAccuracy: 67.90%\n",
      "369\tValidation loss: 1.084415\tBest loss: 1.064135\tAccuracy: 68.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\tValidation loss: 1.082608\tBest loss: 1.064135\tAccuracy: 69.20%\n",
      "371\tValidation loss: 1.112514\tBest loss: 1.064135\tAccuracy: 68.10%\n",
      "372\tValidation loss: 1.076343\tBest loss: 1.064135\tAccuracy: 67.80%\n",
      "373\tValidation loss: 1.080403\tBest loss: 1.064135\tAccuracy: 67.60%\n",
      "374\tValidation loss: 1.080212\tBest loss: 1.064135\tAccuracy: 67.30%\n",
      "375\tValidation loss: 1.072332\tBest loss: 1.064135\tAccuracy: 67.80%\n",
      "Early stopping!\n",
      "[[  2.44632334e-04   6.98794785e-04   1.55718008e-03 ...,   6.11771597e-04\n",
      "    6.28266889e-06   9.33392948e-05]\n",
      " [  7.81846985e-23   9.76846206e-18   4.26844381e-15 ...,   7.23938243e-10\n",
      "    4.64270380e-18   4.69113748e-10]\n",
      " [  9.90677945e-05   3.14568961e-03   1.43783912e-03 ...,   2.03487161e-07\n",
      "    5.09905522e-06   2.25493704e-06]\n",
      " ..., \n",
      " [  6.69740530e-06   4.20214292e-06   8.88841532e-06 ...,   4.93336181e-08\n",
      "    9.49710497e-08   7.49749773e-08]\n",
      " [  1.68092232e-02   8.72911327e-03   8.67397245e-03 ...,   1.72632392e-02\n",
      "    1.42877763e-02   1.03021758e-02]\n",
      " [  5.76856068e-14   3.39391804e-14   1.64193136e-13 ...,   9.87067702e-04\n",
      "    1.22577213e-02   5.75105369e-01]]\n",
      "[41 41 20 ...,  6 10 47]\n",
      "[[  4.14946788e-09   2.44053808e-05   4.18084266e-04 ...,   1.04273330e-14\n",
      "    1.47498139e-10   1.71189709e-13]\n",
      " [  1.38225034e-01   1.91386398e-02   9.88386944e-02 ...,   1.18035486e-03\n",
      "    5.04631491e-04   4.57479095e-04]\n",
      " [  3.00338539e-11   1.17388006e-13   4.64732466e-08 ...,   1.11465151e-05\n",
      "    5.75350612e-09   8.80616990e-14]\n",
      " ..., \n",
      " [  2.59721273e-05   3.24578832e-05   4.91728715e-05 ...,   1.27443008e-03\n",
      "    6.17186946e-04   2.11927597e-03]\n",
      " [  1.42065380e-06   6.98451186e-06   3.25096653e-06 ...,   6.42187968e-02\n",
      "    1.26195205e-02   1.74788591e-02]\n",
      " [  3.05511719e-07   3.67472876e-06   3.56799768e-09 ...,   6.04713745e-02\n",
      "    4.78166575e-03   4.52112127e-03]]\n",
      "[22 19 16 ..., 36 27 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=2, n_neurons=100, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total= 1.6min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 11.090044\tBest loss: 11.090044\tAccuracy: 5.80%\n",
      "1\tValidation loss: 4.194715\tBest loss: 4.194715\tAccuracy: 9.80%\n",
      "2\tValidation loss: 3.687499\tBest loss: 3.687499\tAccuracy: 13.40%\n",
      "3\tValidation loss: 3.416706\tBest loss: 3.416706\tAccuracy: 15.40%\n",
      "4\tValidation loss: 3.798371\tBest loss: 3.416706\tAccuracy: 14.50%\n",
      "5\tValidation loss: 3.227530\tBest loss: 3.227530\tAccuracy: 20.90%\n",
      "6\tValidation loss: 3.088783\tBest loss: 3.088783\tAccuracy: 23.30%\n",
      "7\tValidation loss: 2.971990\tBest loss: 2.971990\tAccuracy: 24.40%\n",
      "8\tValidation loss: 2.923453\tBest loss: 2.923453\tAccuracy: 24.90%\n",
      "9\tValidation loss: 3.103712\tBest loss: 2.923453\tAccuracy: 24.70%\n",
      "10\tValidation loss: 2.893142\tBest loss: 2.893142\tAccuracy: 26.30%\n",
      "11\tValidation loss: 2.920550\tBest loss: 2.893142\tAccuracy: 28.30%\n",
      "12\tValidation loss: 2.621897\tBest loss: 2.621897\tAccuracy: 31.10%\n",
      "13\tValidation loss: 2.614508\tBest loss: 2.614508\tAccuracy: 32.40%\n",
      "14\tValidation loss: 2.550423\tBest loss: 2.550423\tAccuracy: 32.90%\n",
      "15\tValidation loss: 2.612909\tBest loss: 2.550423\tAccuracy: 32.20%\n",
      "16\tValidation loss: 2.469854\tBest loss: 2.469854\tAccuracy: 35.00%\n",
      "17\tValidation loss: 2.503601\tBest loss: 2.469854\tAccuracy: 35.80%\n",
      "18\tValidation loss: 2.338476\tBest loss: 2.338476\tAccuracy: 38.70%\n",
      "19\tValidation loss: 2.345158\tBest loss: 2.338476\tAccuracy: 37.40%\n",
      "20\tValidation loss: 2.389320\tBest loss: 2.338476\tAccuracy: 35.30%\n",
      "21\tValidation loss: 2.272005\tBest loss: 2.272005\tAccuracy: 39.00%\n",
      "22\tValidation loss: 2.314383\tBest loss: 2.272005\tAccuracy: 38.50%\n",
      "23\tValidation loss: 2.283048\tBest loss: 2.272005\tAccuracy: 40.10%\n",
      "24\tValidation loss: 2.393301\tBest loss: 2.272005\tAccuracy: 37.40%\n",
      "25\tValidation loss: 2.250719\tBest loss: 2.250719\tAccuracy: 40.70%\n",
      "26\tValidation loss: 2.251186\tBest loss: 2.250719\tAccuracy: 42.50%\n",
      "27\tValidation loss: 2.210901\tBest loss: 2.210901\tAccuracy: 43.00%\n",
      "28\tValidation loss: 2.096973\tBest loss: 2.096973\tAccuracy: 44.50%\n",
      "29\tValidation loss: 2.150187\tBest loss: 2.096973\tAccuracy: 43.30%\n",
      "30\tValidation loss: 2.041659\tBest loss: 2.041659\tAccuracy: 47.00%\n",
      "31\tValidation loss: 2.024168\tBest loss: 2.024168\tAccuracy: 47.80%\n",
      "32\tValidation loss: 2.114938\tBest loss: 2.024168\tAccuracy: 46.10%\n",
      "33\tValidation loss: 1.976985\tBest loss: 1.976985\tAccuracy: 48.80%\n",
      "34\tValidation loss: 2.108763\tBest loss: 1.976985\tAccuracy: 48.10%\n",
      "35\tValidation loss: 1.932160\tBest loss: 1.932160\tAccuracy: 49.30%\n",
      "36\tValidation loss: 2.023813\tBest loss: 1.932160\tAccuracy: 48.60%\n",
      "37\tValidation loss: 1.948176\tBest loss: 1.932160\tAccuracy: 49.40%\n",
      "38\tValidation loss: 1.922006\tBest loss: 1.922006\tAccuracy: 50.30%\n",
      "39\tValidation loss: 1.890118\tBest loss: 1.890118\tAccuracy: 51.40%\n",
      "40\tValidation loss: 2.056573\tBest loss: 1.890118\tAccuracy: 48.50%\n",
      "41\tValidation loss: 1.919081\tBest loss: 1.890118\tAccuracy: 51.10%\n",
      "42\tValidation loss: 1.857262\tBest loss: 1.857262\tAccuracy: 52.20%\n",
      "43\tValidation loss: 1.823209\tBest loss: 1.823209\tAccuracy: 53.20%\n",
      "44\tValidation loss: 1.917930\tBest loss: 1.823209\tAccuracy: 51.00%\n",
      "45\tValidation loss: 1.975936\tBest loss: 1.823209\tAccuracy: 51.70%\n",
      "46\tValidation loss: 1.835999\tBest loss: 1.823209\tAccuracy: 53.40%\n",
      "47\tValidation loss: 1.777513\tBest loss: 1.777513\tAccuracy: 55.80%\n",
      "48\tValidation loss: 1.783493\tBest loss: 1.777513\tAccuracy: 55.90%\n",
      "49\tValidation loss: 1.778201\tBest loss: 1.777513\tAccuracy: 55.30%\n",
      "50\tValidation loss: 1.967601\tBest loss: 1.777513\tAccuracy: 53.70%\n",
      "51\tValidation loss: 1.688401\tBest loss: 1.688401\tAccuracy: 57.90%\n",
      "52\tValidation loss: 2.016782\tBest loss: 1.688401\tAccuracy: 51.40%\n",
      "53\tValidation loss: 1.742965\tBest loss: 1.688401\tAccuracy: 56.20%\n",
      "54\tValidation loss: 1.705677\tBest loss: 1.688401\tAccuracy: 58.30%\n",
      "55\tValidation loss: 1.826243\tBest loss: 1.688401\tAccuracy: 55.50%\n",
      "56\tValidation loss: 1.748777\tBest loss: 1.688401\tAccuracy: 56.80%\n",
      "57\tValidation loss: 1.843774\tBest loss: 1.688401\tAccuracy: 55.20%\n",
      "58\tValidation loss: 1.716939\tBest loss: 1.688401\tAccuracy: 56.90%\n",
      "59\tValidation loss: 1.870936\tBest loss: 1.688401\tAccuracy: 54.40%\n",
      "60\tValidation loss: 1.673997\tBest loss: 1.673997\tAccuracy: 59.90%\n",
      "61\tValidation loss: 1.716076\tBest loss: 1.673997\tAccuracy: 57.50%\n",
      "62\tValidation loss: 1.734347\tBest loss: 1.673997\tAccuracy: 59.80%\n",
      "63\tValidation loss: 1.646731\tBest loss: 1.646731\tAccuracy: 59.80%\n",
      "64\tValidation loss: 1.750968\tBest loss: 1.646731\tAccuracy: 58.10%\n",
      "65\tValidation loss: 1.722242\tBest loss: 1.646731\tAccuracy: 59.40%\n",
      "66\tValidation loss: 1.624887\tBest loss: 1.624887\tAccuracy: 60.90%\n",
      "67\tValidation loss: 1.671673\tBest loss: 1.624887\tAccuracy: 59.90%\n",
      "68\tValidation loss: 2.305580\tBest loss: 1.624887\tAccuracy: 50.90%\n",
      "69\tValidation loss: 1.658764\tBest loss: 1.624887\tAccuracy: 59.80%\n",
      "70\tValidation loss: 1.658764\tBest loss: 1.624887\tAccuracy: 59.00%\n",
      "71\tValidation loss: 1.667241\tBest loss: 1.624887\tAccuracy: 59.90%\n",
      "72\tValidation loss: 1.643460\tBest loss: 1.624887\tAccuracy: 59.60%\n",
      "73\tValidation loss: 1.663258\tBest loss: 1.624887\tAccuracy: 59.20%\n",
      "74\tValidation loss: 1.615189\tBest loss: 1.615189\tAccuracy: 61.30%\n",
      "75\tValidation loss: 1.580083\tBest loss: 1.580083\tAccuracy: 61.20%\n",
      "76\tValidation loss: 1.671472\tBest loss: 1.580083\tAccuracy: 59.10%\n",
      "77\tValidation loss: 1.610990\tBest loss: 1.580083\tAccuracy: 62.70%\n",
      "78\tValidation loss: 1.620476\tBest loss: 1.580083\tAccuracy: 61.20%\n",
      "79\tValidation loss: 1.658388\tBest loss: 1.580083\tAccuracy: 60.50%\n",
      "80\tValidation loss: 1.641878\tBest loss: 1.580083\tAccuracy: 61.40%\n",
      "81\tValidation loss: 1.664903\tBest loss: 1.580083\tAccuracy: 60.90%\n",
      "82\tValidation loss: 1.649946\tBest loss: 1.580083\tAccuracy: 60.70%\n",
      "83\tValidation loss: 1.619870\tBest loss: 1.580083\tAccuracy: 61.90%\n",
      "84\tValidation loss: 2.337252\tBest loss: 1.580083\tAccuracy: 57.00%\n",
      "85\tValidation loss: 1.594387\tBest loss: 1.580083\tAccuracy: 63.40%\n",
      "86\tValidation loss: 1.581936\tBest loss: 1.580083\tAccuracy: 62.30%\n",
      "87\tValidation loss: 1.518685\tBest loss: 1.518685\tAccuracy: 63.80%\n",
      "88\tValidation loss: 1.563125\tBest loss: 1.518685\tAccuracy: 61.60%\n",
      "89\tValidation loss: 1.830457\tBest loss: 1.518685\tAccuracy: 60.00%\n",
      "90\tValidation loss: 1.554466\tBest loss: 1.518685\tAccuracy: 63.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\tValidation loss: 1.535479\tBest loss: 1.518685\tAccuracy: 63.40%\n",
      "92\tValidation loss: 1.520384\tBest loss: 1.518685\tAccuracy: 64.30%\n",
      "93\tValidation loss: 1.638055\tBest loss: 1.518685\tAccuracy: 62.20%\n",
      "94\tValidation loss: 1.517741\tBest loss: 1.517741\tAccuracy: 63.80%\n",
      "95\tValidation loss: 1.545971\tBest loss: 1.517741\tAccuracy: 63.80%\n",
      "96\tValidation loss: 1.736787\tBest loss: 1.517741\tAccuracy: 60.90%\n",
      "97\tValidation loss: 1.536666\tBest loss: 1.517741\tAccuracy: 63.40%\n",
      "98\tValidation loss: 1.520899\tBest loss: 1.517741\tAccuracy: 65.00%\n",
      "99\tValidation loss: 1.543449\tBest loss: 1.517741\tAccuracy: 63.60%\n",
      "100\tValidation loss: 1.555503\tBest loss: 1.517741\tAccuracy: 63.70%\n",
      "101\tValidation loss: 1.519823\tBest loss: 1.517741\tAccuracy: 64.40%\n",
      "102\tValidation loss: 1.507178\tBest loss: 1.507178\tAccuracy: 65.00%\n",
      "103\tValidation loss: 1.506680\tBest loss: 1.506680\tAccuracy: 64.40%\n",
      "104\tValidation loss: 1.542462\tBest loss: 1.506680\tAccuracy: 63.80%\n",
      "105\tValidation loss: 1.552880\tBest loss: 1.506680\tAccuracy: 63.90%\n",
      "106\tValidation loss: 1.589424\tBest loss: 1.506680\tAccuracy: 62.90%\n",
      "107\tValidation loss: 1.568098\tBest loss: 1.506680\tAccuracy: 64.00%\n",
      "108\tValidation loss: 1.621119\tBest loss: 1.506680\tAccuracy: 62.90%\n",
      "109\tValidation loss: 1.594904\tBest loss: 1.506680\tAccuracy: 63.60%\n",
      "110\tValidation loss: 1.639081\tBest loss: 1.506680\tAccuracy: 64.20%\n",
      "111\tValidation loss: 1.573959\tBest loss: 1.506680\tAccuracy: 64.60%\n",
      "112\tValidation loss: 1.616747\tBest loss: 1.506680\tAccuracy: 62.70%\n",
      "113\tValidation loss: 1.543526\tBest loss: 1.506680\tAccuracy: 65.20%\n",
      "114\tValidation loss: 1.549166\tBest loss: 1.506680\tAccuracy: 65.60%\n",
      "115\tValidation loss: 1.544469\tBest loss: 1.506680\tAccuracy: 65.80%\n",
      "116\tValidation loss: 1.525191\tBest loss: 1.506680\tAccuracy: 65.90%\n",
      "117\tValidation loss: 1.530610\tBest loss: 1.506680\tAccuracy: 66.70%\n",
      "118\tValidation loss: 1.570987\tBest loss: 1.506680\tAccuracy: 65.20%\n",
      "119\tValidation loss: 1.633300\tBest loss: 1.506680\tAccuracy: 64.00%\n",
      "120\tValidation loss: 1.616520\tBest loss: 1.506680\tAccuracy: 65.10%\n",
      "121\tValidation loss: 1.542056\tBest loss: 1.506680\tAccuracy: 66.10%\n",
      "122\tValidation loss: 1.531085\tBest loss: 1.506680\tAccuracy: 66.60%\n",
      "123\tValidation loss: 1.561757\tBest loss: 1.506680\tAccuracy: 66.50%\n",
      "124\tValidation loss: 1.581557\tBest loss: 1.506680\tAccuracy: 65.10%\n",
      "Early stopping!\n",
      "[[  6.21241050e-33   2.89607597e-20   3.98424181e-17 ...,   5.52989569e-28\n",
      "    0.00000000e+00   2.69113217e-35]\n",
      " [  7.97720104e-02   4.00021710e-02   8.23557451e-02 ...,   3.17619019e-03\n",
      "    3.28615610e-03   2.16735899e-03]\n",
      " [  8.27580269e-25   0.00000000e+00   9.75422813e-15 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.01899956e-35   9.48255217e-21   1.56193750e-26 ...,   2.61588341e-18\n",
      "    2.46584609e-18   4.88756484e-24]\n",
      " [  9.73385540e-05   4.39772839e-06   3.08136136e-04 ...,   5.57441041e-02\n",
      "    5.27777534e-04   5.56673564e-04]\n",
      " [  7.04361767e-15   1.00164772e-11   2.42548928e-13 ...,   1.63199024e-10\n",
      "    5.65180992e-11   2.60425614e-09]]\n",
      "[11 19 16 ..., 21 24 36]\n",
      "[[  2.43409772e-07   2.75486009e-03   7.68912651e-05 ...,   1.40470394e-04\n",
      "    2.75922304e-07   3.78366894e-06]\n",
      " [  3.13301056e-33   4.60370795e-20   3.16724458e-19 ...,   6.42876612e-33\n",
      "    0.00000000e+00   5.93690769e-34]\n",
      " [  7.21501209e-17   1.62247941e-13   6.17814610e-13 ...,   2.43165954e-18\n",
      "    1.86323128e-25   2.68730928e-21]\n",
      " ..., \n",
      " [  2.15552165e-19   3.32006438e-23   1.19701702e-20 ...,   2.27672571e-36\n",
      "    9.14010469e-23   0.00000000e+00]\n",
      " [  1.98372193e-02   1.21930800e-02   3.24268192e-02 ...,   7.67354667e-03\n",
      "    6.04131911e-03   7.16304732e-03]\n",
      " [  5.21760787e-25   3.37572511e-18   1.28068820e-20 ...,   2.35279799e-07\n",
      "    4.97917586e-04   9.82247412e-01]]\n",
      "[41 43 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   6.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 11.929480\tBest loss: 11.929480\tAccuracy: 5.30%\n",
      "1\tValidation loss: 4.445136\tBest loss: 4.445136\tAccuracy: 9.20%\n",
      "2\tValidation loss: 3.828130\tBest loss: 3.828130\tAccuracy: 11.50%\n",
      "3\tValidation loss: 3.503294\tBest loss: 3.503294\tAccuracy: 14.90%\n",
      "4\tValidation loss: 3.549543\tBest loss: 3.503294\tAccuracy: 14.30%\n",
      "5\tValidation loss: 3.281096\tBest loss: 3.281096\tAccuracy: 17.40%\n",
      "6\tValidation loss: 3.287620\tBest loss: 3.281096\tAccuracy: 18.50%\n",
      "7\tValidation loss: 3.205249\tBest loss: 3.205249\tAccuracy: 20.00%\n",
      "8\tValidation loss: 3.177994\tBest loss: 3.177994\tAccuracy: 20.90%\n",
      "9\tValidation loss: 2.903920\tBest loss: 2.903920\tAccuracy: 24.40%\n",
      "10\tValidation loss: 2.938534\tBest loss: 2.903920\tAccuracy: 25.80%\n",
      "11\tValidation loss: 2.825998\tBest loss: 2.825998\tAccuracy: 29.30%\n",
      "12\tValidation loss: 2.834998\tBest loss: 2.825998\tAccuracy: 27.00%\n",
      "13\tValidation loss: 2.705158\tBest loss: 2.705158\tAccuracy: 28.80%\n",
      "14\tValidation loss: 2.636637\tBest loss: 2.636637\tAccuracy: 30.60%\n",
      "15\tValidation loss: 2.634352\tBest loss: 2.634352\tAccuracy: 31.00%\n",
      "16\tValidation loss: 2.516770\tBest loss: 2.516770\tAccuracy: 33.50%\n",
      "17\tValidation loss: 2.481516\tBest loss: 2.481516\tAccuracy: 37.20%\n",
      "18\tValidation loss: 2.420514\tBest loss: 2.420514\tAccuracy: 37.50%\n",
      "19\tValidation loss: 2.320346\tBest loss: 2.320346\tAccuracy: 39.40%\n",
      "20\tValidation loss: 2.707034\tBest loss: 2.320346\tAccuracy: 31.70%\n",
      "21\tValidation loss: 2.320872\tBest loss: 2.320346\tAccuracy: 39.10%\n",
      "22\tValidation loss: 2.263821\tBest loss: 2.263821\tAccuracy: 40.10%\n",
      "23\tValidation loss: 2.223723\tBest loss: 2.223723\tAccuracy: 41.40%\n",
      "24\tValidation loss: 2.590276\tBest loss: 2.223723\tAccuracy: 34.80%\n",
      "25\tValidation loss: 2.207562\tBest loss: 2.207562\tAccuracy: 42.70%\n",
      "26\tValidation loss: 2.109750\tBest loss: 2.109750\tAccuracy: 45.40%\n",
      "27\tValidation loss: 2.111928\tBest loss: 2.109750\tAccuracy: 42.90%\n",
      "28\tValidation loss: 2.073659\tBest loss: 2.073659\tAccuracy: 45.60%\n",
      "29\tValidation loss: 2.132678\tBest loss: 2.073659\tAccuracy: 43.40%\n",
      "30\tValidation loss: 2.053034\tBest loss: 2.053034\tAccuracy: 45.30%\n",
      "31\tValidation loss: 1.943179\tBest loss: 1.943179\tAccuracy: 50.00%\n",
      "32\tValidation loss: 1.977705\tBest loss: 1.943179\tAccuracy: 50.00%\n",
      "33\tValidation loss: 2.170861\tBest loss: 1.943179\tAccuracy: 46.90%\n",
      "34\tValidation loss: 2.224173\tBest loss: 1.943179\tAccuracy: 43.30%\n",
      "35\tValidation loss: 2.047177\tBest loss: 1.943179\tAccuracy: 46.60%\n",
      "36\tValidation loss: 2.024612\tBest loss: 1.943179\tAccuracy: 46.30%\n",
      "37\tValidation loss: 2.124100\tBest loss: 1.943179\tAccuracy: 45.70%\n",
      "38\tValidation loss: 2.107225\tBest loss: 1.943179\tAccuracy: 46.50%\n",
      "39\tValidation loss: 1.873039\tBest loss: 1.873039\tAccuracy: 52.00%\n",
      "40\tValidation loss: 1.955377\tBest loss: 1.873039\tAccuracy: 51.30%\n",
      "41\tValidation loss: 1.893124\tBest loss: 1.873039\tAccuracy: 52.60%\n",
      "42\tValidation loss: 2.000714\tBest loss: 1.873039\tAccuracy: 48.20%\n",
      "43\tValidation loss: 1.925599\tBest loss: 1.873039\tAccuracy: 50.90%\n",
      "44\tValidation loss: 1.817029\tBest loss: 1.817029\tAccuracy: 53.80%\n",
      "45\tValidation loss: 1.764824\tBest loss: 1.764824\tAccuracy: 55.90%\n",
      "46\tValidation loss: 1.864774\tBest loss: 1.764824\tAccuracy: 51.70%\n",
      "47\tValidation loss: 1.969200\tBest loss: 1.764824\tAccuracy: 50.40%\n",
      "48\tValidation loss: 1.898061\tBest loss: 1.764824\tAccuracy: 54.00%\n",
      "49\tValidation loss: 1.796615\tBest loss: 1.764824\tAccuracy: 54.20%\n",
      "50\tValidation loss: 1.768021\tBest loss: 1.764824\tAccuracy: 55.50%\n",
      "51\tValidation loss: 1.818484\tBest loss: 1.764824\tAccuracy: 55.30%\n",
      "52\tValidation loss: 1.813481\tBest loss: 1.764824\tAccuracy: 55.20%\n",
      "53\tValidation loss: 1.752282\tBest loss: 1.752282\tAccuracy: 56.00%\n",
      "54\tValidation loss: 1.741845\tBest loss: 1.741845\tAccuracy: 55.10%\n",
      "55\tValidation loss: 1.745211\tBest loss: 1.741845\tAccuracy: 56.10%\n",
      "56\tValidation loss: 1.798608\tBest loss: 1.741845\tAccuracy: 56.00%\n",
      "57\tValidation loss: 1.901247\tBest loss: 1.741845\tAccuracy: 53.20%\n",
      "58\tValidation loss: 1.741751\tBest loss: 1.741751\tAccuracy: 56.10%\n",
      "59\tValidation loss: 1.807809\tBest loss: 1.741751\tAccuracy: 56.10%\n",
      "60\tValidation loss: 1.791190\tBest loss: 1.741751\tAccuracy: 57.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\tValidation loss: 1.670802\tBest loss: 1.670802\tAccuracy: 57.60%\n",
      "62\tValidation loss: 1.739839\tBest loss: 1.670802\tAccuracy: 57.20%\n",
      "63\tValidation loss: 1.941043\tBest loss: 1.670802\tAccuracy: 53.20%\n",
      "64\tValidation loss: 1.733408\tBest loss: 1.670802\tAccuracy: 56.80%\n",
      "65\tValidation loss: 1.843239\tBest loss: 1.670802\tAccuracy: 55.80%\n",
      "66\tValidation loss: 1.650010\tBest loss: 1.650010\tAccuracy: 59.10%\n",
      "67\tValidation loss: 1.662370\tBest loss: 1.650010\tAccuracy: 59.40%\n",
      "68\tValidation loss: 1.681568\tBest loss: 1.650010\tAccuracy: 59.80%\n",
      "69\tValidation loss: 1.657512\tBest loss: 1.650010\tAccuracy: 59.70%\n",
      "70\tValidation loss: 1.731284\tBest loss: 1.650010\tAccuracy: 58.70%\n",
      "71\tValidation loss: 1.640391\tBest loss: 1.640391\tAccuracy: 60.50%\n",
      "72\tValidation loss: 1.643318\tBest loss: 1.640391\tAccuracy: 60.50%\n",
      "73\tValidation loss: 1.616741\tBest loss: 1.616741\tAccuracy: 60.70%\n",
      "74\tValidation loss: 1.684984\tBest loss: 1.616741\tAccuracy: 60.40%\n",
      "75\tValidation loss: 1.777905\tBest loss: 1.616741\tAccuracy: 59.30%\n",
      "76\tValidation loss: 1.623340\tBest loss: 1.616741\tAccuracy: 61.30%\n",
      "77\tValidation loss: 1.673781\tBest loss: 1.616741\tAccuracy: 60.30%\n",
      "78\tValidation loss: 1.830999\tBest loss: 1.616741\tAccuracy: 55.50%\n",
      "79\tValidation loss: 1.607357\tBest loss: 1.607357\tAccuracy: 62.10%\n",
      "80\tValidation loss: 1.649636\tBest loss: 1.607357\tAccuracy: 62.30%\n",
      "81\tValidation loss: 1.631246\tBest loss: 1.607357\tAccuracy: 61.30%\n",
      "82\tValidation loss: 1.659804\tBest loss: 1.607357\tAccuracy: 59.90%\n",
      "83\tValidation loss: 1.672378\tBest loss: 1.607357\tAccuracy: 60.30%\n",
      "84\tValidation loss: 1.857841\tBest loss: 1.607357\tAccuracy: 56.90%\n",
      "85\tValidation loss: 1.575212\tBest loss: 1.575212\tAccuracy: 62.20%\n",
      "86\tValidation loss: 1.532769\tBest loss: 1.532769\tAccuracy: 63.70%\n",
      "87\tValidation loss: 1.576845\tBest loss: 1.532769\tAccuracy: 62.20%\n",
      "88\tValidation loss: 1.585495\tBest loss: 1.532769\tAccuracy: 60.90%\n",
      "89\tValidation loss: 1.587574\tBest loss: 1.532769\tAccuracy: 62.60%\n",
      "90\tValidation loss: 1.584855\tBest loss: 1.532769\tAccuracy: 62.50%\n",
      "91\tValidation loss: 1.700834\tBest loss: 1.532769\tAccuracy: 60.60%\n",
      "92\tValidation loss: 1.575093\tBest loss: 1.532769\tAccuracy: 61.90%\n",
      "93\tValidation loss: 1.601550\tBest loss: 1.532769\tAccuracy: 62.50%\n",
      "94\tValidation loss: 1.566796\tBest loss: 1.532769\tAccuracy: 62.00%\n",
      "95\tValidation loss: 1.734294\tBest loss: 1.532769\tAccuracy: 59.50%\n",
      "96\tValidation loss: 1.632870\tBest loss: 1.532769\tAccuracy: 64.00%\n",
      "97\tValidation loss: 1.584697\tBest loss: 1.532769\tAccuracy: 63.20%\n",
      "98\tValidation loss: 1.625036\tBest loss: 1.532769\tAccuracy: 64.00%\n",
      "99\tValidation loss: 1.553895\tBest loss: 1.532769\tAccuracy: 63.40%\n",
      "100\tValidation loss: 1.577290\tBest loss: 1.532769\tAccuracy: 64.10%\n",
      "101\tValidation loss: 1.611064\tBest loss: 1.532769\tAccuracy: 63.90%\n",
      "102\tValidation loss: 1.714661\tBest loss: 1.532769\tAccuracy: 61.60%\n",
      "103\tValidation loss: 1.726351\tBest loss: 1.532769\tAccuracy: 60.40%\n",
      "104\tValidation loss: 1.578054\tBest loss: 1.532769\tAccuracy: 63.80%\n",
      "105\tValidation loss: 1.582696\tBest loss: 1.532769\tAccuracy: 63.00%\n",
      "106\tValidation loss: 1.607281\tBest loss: 1.532769\tAccuracy: 61.90%\n",
      "107\tValidation loss: 1.709376\tBest loss: 1.532769\tAccuracy: 63.80%\n",
      "Early stopping!\n",
      "[[  4.51188243e-05   3.85083928e-04   9.42918006e-03 ...,   2.58194323e-05\n",
      "    5.52414736e-09   9.64764268e-09]\n",
      " [  2.89093793e-22   2.43827680e-10   5.97232767e-14 ...,   7.13743413e-26\n",
      "    1.13636731e-26   1.04723898e-24]\n",
      " [  1.18866614e-13   7.10569736e-09   6.10648613e-07 ...,   2.53853335e-13\n",
      "    1.49399863e-28   2.44928572e-18]\n",
      " ..., \n",
      " [  2.46127620e-05   2.37644417e-04   6.37806443e-05 ...,   1.04247115e-03\n",
      "    3.67516885e-03   5.33190975e-03]\n",
      " [  1.12540775e-11   4.75595840e-07   2.37633080e-10 ...,   4.55455901e-03\n",
      "    8.75643343e-02   8.22248384e-02]\n",
      " [  1.35200676e-18   4.05219342e-13   3.46290849e-15 ...,   6.47435314e-08\n",
      "    1.70264334e-12   7.14571913e-09]]\n",
      "[43 11 43 ..., 36 10 27]\n",
      "[[  8.39056819e-23   2.05566980e-10   3.38014790e-11 ...,   3.14735811e-23\n",
      "    4.59949680e-22   9.44806842e-23]\n",
      " [  1.57384828e-01   4.60164100e-02   6.66748434e-02 ...,   5.92126278e-03\n",
      "    2.18759151e-03   2.95644719e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   1.35284072e-33 ...,   2.13106106e-35\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  9.38348393e-16   1.39191755e-14   3.51144861e-14 ...,   1.04688508e-19\n",
      "    1.67045596e-19   2.21511446e-19]\n",
      " [  4.22955751e-02   1.56424921e-02   4.50584143e-02 ...,   6.79671392e-03\n",
      "    5.68417693e-03   2.59989444e-02]\n",
      " [  6.83903405e-28   5.31080447e-21   1.37354282e-24 ...,   2.23780290e-07\n",
      "    6.14684727e-03   9.80579674e-01]]\n",
      "[22  0 16 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   5.7s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 11.628471\tBest loss: 11.628471\tAccuracy: 3.10%\n",
      "1\tValidation loss: 4.301203\tBest loss: 4.301203\tAccuracy: 9.00%\n",
      "2\tValidation loss: 3.570999\tBest loss: 3.570999\tAccuracy: 11.70%\n",
      "3\tValidation loss: 3.587910\tBest loss: 3.570999\tAccuracy: 11.90%\n",
      "4\tValidation loss: 3.320426\tBest loss: 3.320426\tAccuracy: 14.60%\n",
      "5\tValidation loss: 3.234649\tBest loss: 3.234649\tAccuracy: 16.60%\n",
      "6\tValidation loss: 3.241303\tBest loss: 3.234649\tAccuracy: 19.40%\n",
      "7\tValidation loss: 3.078852\tBest loss: 3.078852\tAccuracy: 20.90%\n",
      "8\tValidation loss: 3.109402\tBest loss: 3.078852\tAccuracy: 19.50%\n",
      "9\tValidation loss: 2.943009\tBest loss: 2.943009\tAccuracy: 23.30%\n",
      "10\tValidation loss: 2.844949\tBest loss: 2.844949\tAccuracy: 25.50%\n",
      "11\tValidation loss: 2.789590\tBest loss: 2.789590\tAccuracy: 28.20%\n",
      "12\tValidation loss: 2.762615\tBest loss: 2.762615\tAccuracy: 28.70%\n",
      "13\tValidation loss: 2.699497\tBest loss: 2.699497\tAccuracy: 29.10%\n",
      "14\tValidation loss: 2.709488\tBest loss: 2.699497\tAccuracy: 27.80%\n",
      "15\tValidation loss: 2.713376\tBest loss: 2.699497\tAccuracy: 29.40%\n",
      "16\tValidation loss: 2.860108\tBest loss: 2.699497\tAccuracy: 27.00%\n",
      "17\tValidation loss: 2.599199\tBest loss: 2.599199\tAccuracy: 30.70%\n",
      "18\tValidation loss: 2.555077\tBest loss: 2.555077\tAccuracy: 34.20%\n",
      "19\tValidation loss: 2.417037\tBest loss: 2.417037\tAccuracy: 36.50%\n",
      "20\tValidation loss: 2.404562\tBest loss: 2.404562\tAccuracy: 36.00%\n",
      "21\tValidation loss: 2.522329\tBest loss: 2.404562\tAccuracy: 33.80%\n",
      "22\tValidation loss: 2.321983\tBest loss: 2.321983\tAccuracy: 36.50%\n",
      "23\tValidation loss: 2.281293\tBest loss: 2.281293\tAccuracy: 40.10%\n",
      "24\tValidation loss: 2.459012\tBest loss: 2.281293\tAccuracy: 35.20%\n",
      "25\tValidation loss: 2.503733\tBest loss: 2.281293\tAccuracy: 35.60%\n",
      "26\tValidation loss: 2.208822\tBest loss: 2.208822\tAccuracy: 40.90%\n",
      "27\tValidation loss: 2.185500\tBest loss: 2.185500\tAccuracy: 40.20%\n",
      "28\tValidation loss: 2.215384\tBest loss: 2.185500\tAccuracy: 40.30%\n",
      "29\tValidation loss: 2.133030\tBest loss: 2.133030\tAccuracy: 43.50%\n",
      "30\tValidation loss: 2.165169\tBest loss: 2.133030\tAccuracy: 41.00%\n",
      "31\tValidation loss: 2.110169\tBest loss: 2.110169\tAccuracy: 43.60%\n",
      "32\tValidation loss: 2.092050\tBest loss: 2.092050\tAccuracy: 44.30%\n",
      "33\tValidation loss: 2.186743\tBest loss: 2.092050\tAccuracy: 43.70%\n",
      "34\tValidation loss: 2.101206\tBest loss: 2.092050\tAccuracy: 46.10%\n",
      "35\tValidation loss: 2.042360\tBest loss: 2.042360\tAccuracy: 47.40%\n",
      "36\tValidation loss: 2.042067\tBest loss: 2.042067\tAccuracy: 47.20%\n",
      "37\tValidation loss: 1.916738\tBest loss: 1.916738\tAccuracy: 48.80%\n",
      "38\tValidation loss: 1.986516\tBest loss: 1.916738\tAccuracy: 49.10%\n",
      "39\tValidation loss: 1.983608\tBest loss: 1.916738\tAccuracy: 48.60%\n",
      "40\tValidation loss: 1.959000\tBest loss: 1.916738\tAccuracy: 50.50%\n",
      "41\tValidation loss: 1.893667\tBest loss: 1.893667\tAccuracy: 51.40%\n",
      "42\tValidation loss: 1.961443\tBest loss: 1.893667\tAccuracy: 49.90%\n",
      "43\tValidation loss: 1.865077\tBest loss: 1.865077\tAccuracy: 53.00%\n",
      "44\tValidation loss: 1.877008\tBest loss: 1.865077\tAccuracy: 51.30%\n",
      "45\tValidation loss: 1.968648\tBest loss: 1.865077\tAccuracy: 49.00%\n",
      "46\tValidation loss: 1.899514\tBest loss: 1.865077\tAccuracy: 53.40%\n",
      "47\tValidation loss: 1.994451\tBest loss: 1.865077\tAccuracy: 51.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\tValidation loss: 1.844536\tBest loss: 1.844536\tAccuracy: 53.10%\n",
      "49\tValidation loss: 2.104848\tBest loss: 1.844536\tAccuracy: 49.00%\n",
      "50\tValidation loss: 1.762539\tBest loss: 1.762539\tAccuracy: 55.40%\n",
      "51\tValidation loss: 1.772198\tBest loss: 1.762539\tAccuracy: 54.70%\n",
      "52\tValidation loss: 1.777846\tBest loss: 1.762539\tAccuracy: 55.30%\n",
      "53\tValidation loss: 1.872370\tBest loss: 1.762539\tAccuracy: 54.50%\n",
      "54\tValidation loss: 1.861322\tBest loss: 1.762539\tAccuracy: 53.00%\n",
      "55\tValidation loss: 1.785609\tBest loss: 1.762539\tAccuracy: 55.40%\n",
      "56\tValidation loss: 1.713742\tBest loss: 1.713742\tAccuracy: 58.10%\n",
      "57\tValidation loss: 1.719040\tBest loss: 1.713742\tAccuracy: 58.60%\n",
      "58\tValidation loss: 1.676386\tBest loss: 1.676386\tAccuracy: 58.30%\n",
      "59\tValidation loss: 1.879183\tBest loss: 1.676386\tAccuracy: 56.30%\n",
      "60\tValidation loss: 1.844182\tBest loss: 1.676386\tAccuracy: 56.30%\n",
      "61\tValidation loss: 1.744013\tBest loss: 1.676386\tAccuracy: 57.40%\n",
      "62\tValidation loss: 1.759974\tBest loss: 1.676386\tAccuracy: 56.90%\n",
      "63\tValidation loss: 1.735957\tBest loss: 1.676386\tAccuracy: 57.90%\n",
      "64\tValidation loss: 1.848747\tBest loss: 1.676386\tAccuracy: 56.30%\n",
      "65\tValidation loss: 1.780750\tBest loss: 1.676386\tAccuracy: 57.20%\n",
      "66\tValidation loss: 1.724801\tBest loss: 1.676386\tAccuracy: 58.60%\n",
      "67\tValidation loss: 2.397171\tBest loss: 1.676386\tAccuracy: 51.40%\n",
      "68\tValidation loss: 1.670025\tBest loss: 1.670025\tAccuracy: 59.70%\n",
      "69\tValidation loss: 1.721989\tBest loss: 1.670025\tAccuracy: 60.80%\n",
      "70\tValidation loss: 1.727329\tBest loss: 1.670025\tAccuracy: 59.80%\n",
      "71\tValidation loss: 1.717700\tBest loss: 1.670025\tAccuracy: 59.30%\n",
      "72\tValidation loss: 1.622081\tBest loss: 1.622081\tAccuracy: 61.90%\n",
      "73\tValidation loss: 1.690973\tBest loss: 1.622081\tAccuracy: 59.80%\n",
      "74\tValidation loss: 1.803318\tBest loss: 1.622081\tAccuracy: 58.80%\n",
      "75\tValidation loss: 1.713704\tBest loss: 1.622081\tAccuracy: 57.70%\n",
      "76\tValidation loss: 1.615387\tBest loss: 1.615387\tAccuracy: 61.50%\n",
      "77\tValidation loss: 1.643566\tBest loss: 1.615387\tAccuracy: 61.40%\n",
      "78\tValidation loss: 1.743950\tBest loss: 1.615387\tAccuracy: 58.90%\n",
      "79\tValidation loss: 1.629360\tBest loss: 1.615387\tAccuracy: 61.70%\n",
      "80\tValidation loss: 1.695217\tBest loss: 1.615387\tAccuracy: 61.00%\n",
      "81\tValidation loss: 1.787868\tBest loss: 1.615387\tAccuracy: 58.90%\n",
      "82\tValidation loss: 1.697307\tBest loss: 1.615387\tAccuracy: 60.50%\n",
      "83\tValidation loss: 1.959179\tBest loss: 1.615387\tAccuracy: 55.60%\n",
      "84\tValidation loss: 1.692531\tBest loss: 1.615387\tAccuracy: 62.60%\n",
      "85\tValidation loss: 1.589488\tBest loss: 1.589488\tAccuracy: 61.90%\n",
      "86\tValidation loss: 1.647952\tBest loss: 1.589488\tAccuracy: 61.40%\n",
      "87\tValidation loss: 1.897589\tBest loss: 1.589488\tAccuracy: 58.10%\n",
      "88\tValidation loss: 1.671203\tBest loss: 1.589488\tAccuracy: 61.10%\n",
      "89\tValidation loss: 1.593332\tBest loss: 1.589488\tAccuracy: 62.90%\n",
      "90\tValidation loss: 1.739652\tBest loss: 1.589488\tAccuracy: 61.10%\n",
      "91\tValidation loss: 1.608842\tBest loss: 1.589488\tAccuracy: 62.80%\n",
      "92\tValidation loss: 1.583671\tBest loss: 1.583671\tAccuracy: 63.80%\n",
      "93\tValidation loss: 1.597331\tBest loss: 1.583671\tAccuracy: 63.10%\n",
      "94\tValidation loss: 1.696823\tBest loss: 1.583671\tAccuracy: 60.60%\n",
      "95\tValidation loss: 1.626216\tBest loss: 1.583671\tAccuracy: 63.90%\n",
      "96\tValidation loss: 1.581798\tBest loss: 1.581798\tAccuracy: 62.70%\n",
      "97\tValidation loss: 1.564530\tBest loss: 1.564530\tAccuracy: 63.70%\n",
      "98\tValidation loss: 1.599008\tBest loss: 1.564530\tAccuracy: 63.10%\n",
      "99\tValidation loss: 1.597824\tBest loss: 1.564530\tAccuracy: 63.80%\n",
      "100\tValidation loss: 1.615331\tBest loss: 1.564530\tAccuracy: 63.10%\n",
      "101\tValidation loss: 1.586563\tBest loss: 1.564530\tAccuracy: 63.40%\n",
      "102\tValidation loss: 1.658933\tBest loss: 1.564530\tAccuracy: 62.70%\n",
      "103\tValidation loss: 1.812458\tBest loss: 1.564530\tAccuracy: 60.40%\n",
      "104\tValidation loss: 1.552754\tBest loss: 1.552754\tAccuracy: 65.10%\n",
      "105\tValidation loss: 1.598470\tBest loss: 1.552754\tAccuracy: 65.30%\n",
      "106\tValidation loss: 1.641901\tBest loss: 1.552754\tAccuracy: 62.50%\n",
      "107\tValidation loss: 1.827812\tBest loss: 1.552754\tAccuracy: 60.50%\n",
      "108\tValidation loss: 1.629530\tBest loss: 1.552754\tAccuracy: 63.40%\n",
      "109\tValidation loss: 1.713417\tBest loss: 1.552754\tAccuracy: 61.60%\n",
      "110\tValidation loss: 1.586898\tBest loss: 1.552754\tAccuracy: 63.90%\n",
      "111\tValidation loss: 1.573756\tBest loss: 1.552754\tAccuracy: 65.20%\n",
      "112\tValidation loss: 1.615898\tBest loss: 1.552754\tAccuracy: 63.40%\n",
      "113\tValidation loss: 1.566792\tBest loss: 1.552754\tAccuracy: 65.00%\n",
      "114\tValidation loss: 2.071058\tBest loss: 1.552754\tAccuracy: 59.10%\n",
      "115\tValidation loss: 1.653327\tBest loss: 1.552754\tAccuracy: 63.40%\n",
      "116\tValidation loss: 1.586199\tBest loss: 1.552754\tAccuracy: 64.50%\n",
      "117\tValidation loss: 1.575826\tBest loss: 1.552754\tAccuracy: 64.50%\n",
      "118\tValidation loss: 1.582947\tBest loss: 1.552754\tAccuracy: 65.10%\n",
      "119\tValidation loss: 1.632036\tBest loss: 1.552754\tAccuracy: 65.20%\n",
      "120\tValidation loss: 1.576600\tBest loss: 1.552754\tAccuracy: 64.80%\n",
      "121\tValidation loss: 1.609751\tBest loss: 1.552754\tAccuracy: 63.30%\n",
      "122\tValidation loss: 1.597557\tBest loss: 1.552754\tAccuracy: 64.80%\n",
      "123\tValidation loss: 1.735030\tBest loss: 1.552754\tAccuracy: 63.10%\n",
      "124\tValidation loss: 1.589637\tBest loss: 1.552754\tAccuracy: 64.80%\n",
      "125\tValidation loss: 1.684648\tBest loss: 1.552754\tAccuracy: 65.00%\n",
      "Early stopping!\n",
      "[[  1.65534293e-04   1.40683056e-04   1.13943464e-03 ...,   6.18384802e-04\n",
      "    1.32068533e-06   4.30062391e-05]\n",
      " [  6.38205179e-34   7.95387312e-26   7.38046538e-20 ...,   9.31406921e-19\n",
      "    1.59451243e-28   8.97830364e-24]\n",
      " [  8.34692671e-09   3.13442943e-05   5.14896385e-07 ...,   1.75253839e-11\n",
      "    3.08130438e-06   3.44158980e-06]\n",
      " ..., \n",
      " [  4.43607179e-26   1.45302007e-22   6.09043381e-22 ...,   1.73872351e-32\n",
      "    1.03076914e-24   0.00000000e+00]\n",
      " [  1.15000345e-02   1.98011268e-02   1.57014076e-02 ...,   8.50549340e-03\n",
      "    4.16308362e-03   1.22384308e-02]\n",
      " [  1.74048963e-20   9.94778478e-12   4.95538880e-15 ...,   1.03376668e-04\n",
      "    2.03016656e-03   7.07148015e-01]]\n",
      "[41 41 42 ...,  6 11 47]\n",
      "[[  9.56822250e-24   1.53671314e-12   9.58123826e-14 ...,   4.55375455e-37\n",
      "    5.47526620e-28   1.39692138e-27]\n",
      " [  1.22724824e-01   4.06299718e-02   5.38729839e-02 ...,   3.86538380e-03\n",
      "    6.14222791e-03   2.29808502e-03]\n",
      " [  6.72643217e-38   0.00000000e+00   1.10835412e-22 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  3.32237214e-05   4.02830803e-04   3.06818663e-04 ...,   8.48964381e-04\n",
      "    1.61410328e-02   3.06633022e-02]\n",
      " [  6.85006318e-09   5.51691664e-06   3.87266708e-09 ...,   8.75499696e-02\n",
      "    1.13883310e-04   1.88612335e-04]\n",
      " [  6.21705673e-11   9.34772659e-12   1.22236093e-11 ...,   2.04544524e-08\n",
      "    1.49641888e-09   4.58738350e-06]]\n",
      "[20 19 16 ..., 36 25 36]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=2, n_neurons=120, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   7.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=  34.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.832631\tBest loss: 3.832631\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.814192\tBest loss: 3.814192\tAccuracy: 3.70%\n",
      "2\tValidation loss: 3.805524\tBest loss: 3.805524\tAccuracy: 3.20%\n",
      "3\tValidation loss: 3.801151\tBest loss: 3.801151\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.799014\tBest loss: 3.799014\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.797870\tBest loss: 3.797870\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.797026\tBest loss: 3.797026\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.796571\tBest loss: 3.796571\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.796443\tBest loss: 3.796443\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.796256\tBest loss: 3.796256\tAccuracy: 3.20%\n",
      "10\tValidation loss: 3.796074\tBest loss: 3.796074\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.795921\tBest loss: 3.795921\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.795694\tBest loss: 3.795694\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.795811\tBest loss: 3.795694\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.795722\tBest loss: 3.795694\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.795739\tBest loss: 3.795694\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.795773\tBest loss: 3.795694\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.795713\tBest loss: 3.795694\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.795695\tBest loss: 3.795694\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.795674\tBest loss: 3.795674\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.795629\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.795536\tBest loss: 3.795536\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.795606\tBest loss: 3.795536\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.795589\tBest loss: 3.795536\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.795458\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.795666\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.795774\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "27\tValidation loss: 3.795915\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "28\tValidation loss: 3.795947\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.795799\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.795654\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.795677\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.795754\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "33\tValidation loss: 3.795901\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "34\tValidation loss: 3.795759\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.795664\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.795683\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.795654\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.795820\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.795800\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.795861\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.795753\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.795575\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.795627\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.795611\tBest loss: 3.795458\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.795854\tBest loss: 3.795458\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " ..., \n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " ..., \n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]\n",
      " [ 0.01682507  0.03275978  0.02259195 ...,  0.02891213  0.0169569\n",
      "   0.01765991]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total= 1.3min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=10, dropout_rate=0.6, n_hidden_layers=4, n_neurons=120, learning_rate=0.02, activation=<function relu at 0x000002EE6B242400>, total=  34.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 77.353798\tBest loss: 77.353798\tAccuracy: 8.40%\n",
      "1\tValidation loss: 51.722252\tBest loss: 51.722252\tAccuracy: 13.10%\n",
      "2\tValidation loss: 56.749447\tBest loss: 51.722252\tAccuracy: 18.40%\n",
      "3\tValidation loss: 47.892464\tBest loss: 47.892464\tAccuracy: 25.50%\n",
      "4\tValidation loss: 55.509460\tBest loss: 47.892464\tAccuracy: 20.30%\n",
      "5\tValidation loss: 62.301327\tBest loss: 47.892464\tAccuracy: 25.00%\n",
      "6\tValidation loss: 29.926313\tBest loss: 29.926313\tAccuracy: 38.10%\n",
      "7\tValidation loss: 28.903465\tBest loss: 28.903465\tAccuracy: 41.40%\n",
      "8\tValidation loss: 29.357548\tBest loss: 28.903465\tAccuracy: 45.80%\n",
      "9\tValidation loss: 33.120407\tBest loss: 28.903465\tAccuracy: 40.20%\n",
      "10\tValidation loss: 27.306335\tBest loss: 27.306335\tAccuracy: 46.30%\n",
      "11\tValidation loss: 22.359173\tBest loss: 22.359173\tAccuracy: 48.20%\n",
      "12\tValidation loss: 24.198753\tBest loss: 22.359173\tAccuracy: 51.20%\n",
      "13\tValidation loss: 28.072487\tBest loss: 22.359173\tAccuracy: 45.20%\n",
      "14\tValidation loss: 30.671282\tBest loss: 22.359173\tAccuracy: 45.50%\n",
      "15\tValidation loss: 29.998770\tBest loss: 22.359173\tAccuracy: 51.10%\n",
      "16\tValidation loss: 19.406776\tBest loss: 19.406776\tAccuracy: 55.60%\n",
      "17\tValidation loss: 30.688915\tBest loss: 19.406776\tAccuracy: 47.20%\n",
      "18\tValidation loss: 27.176878\tBest loss: 19.406776\tAccuracy: 54.80%\n",
      "19\tValidation loss: 20.049061\tBest loss: 19.406776\tAccuracy: 54.00%\n",
      "20\tValidation loss: 33.455460\tBest loss: 19.406776\tAccuracy: 44.40%\n",
      "21\tValidation loss: 27.037516\tBest loss: 19.406776\tAccuracy: 52.50%\n",
      "22\tValidation loss: 34.341770\tBest loss: 19.406776\tAccuracy: 47.10%\n",
      "23\tValidation loss: 24.318481\tBest loss: 19.406776\tAccuracy: 55.00%\n",
      "24\tValidation loss: 19.718376\tBest loss: 19.406776\tAccuracy: 60.70%\n",
      "25\tValidation loss: 29.291451\tBest loss: 19.406776\tAccuracy: 49.10%\n",
      "26\tValidation loss: 24.335266\tBest loss: 19.406776\tAccuracy: 55.50%\n",
      "27\tValidation loss: 25.616337\tBest loss: 19.406776\tAccuracy: 55.20%\n",
      "28\tValidation loss: 22.041964\tBest loss: 19.406776\tAccuracy: 57.50%\n",
      "29\tValidation loss: 38.941044\tBest loss: 19.406776\tAccuracy: 48.10%\n",
      "30\tValidation loss: 20.346663\tBest loss: 19.406776\tAccuracy: 59.60%\n",
      "31\tValidation loss: 17.490881\tBest loss: 17.490881\tAccuracy: 60.10%\n",
      "32\tValidation loss: 26.614819\tBest loss: 17.490881\tAccuracy: 56.30%\n",
      "33\tValidation loss: 21.715639\tBest loss: 17.490881\tAccuracy: 58.00%\n",
      "34\tValidation loss: 17.502970\tBest loss: 17.490881\tAccuracy: 62.60%\n",
      "35\tValidation loss: 22.506163\tBest loss: 17.490881\tAccuracy: 58.50%\n",
      "36\tValidation loss: 14.184048\tBest loss: 14.184048\tAccuracy: 63.50%\n",
      "37\tValidation loss: 20.341537\tBest loss: 14.184048\tAccuracy: 59.40%\n",
      "38\tValidation loss: 21.384562\tBest loss: 14.184048\tAccuracy: 58.60%\n",
      "39\tValidation loss: 22.232183\tBest loss: 14.184048\tAccuracy: 59.30%\n",
      "40\tValidation loss: 20.389381\tBest loss: 14.184048\tAccuracy: 60.50%\n",
      "41\tValidation loss: 26.406832\tBest loss: 14.184048\tAccuracy: 61.80%\n",
      "42\tValidation loss: 19.450439\tBest loss: 14.184048\tAccuracy: 59.90%\n",
      "43\tValidation loss: 30.907122\tBest loss: 14.184048\tAccuracy: 53.50%\n",
      "44\tValidation loss: 30.770811\tBest loss: 14.184048\tAccuracy: 55.40%\n",
      "45\tValidation loss: 27.778595\tBest loss: 14.184048\tAccuracy: 55.60%\n",
      "46\tValidation loss: 16.817055\tBest loss: 14.184048\tAccuracy: 65.30%\n",
      "47\tValidation loss: 21.432222\tBest loss: 14.184048\tAccuracy: 62.10%\n",
      "48\tValidation loss: 20.078844\tBest loss: 14.184048\tAccuracy: 65.00%\n",
      "49\tValidation loss: 16.202850\tBest loss: 14.184048\tAccuracy: 66.50%\n",
      "50\tValidation loss: 23.875481\tBest loss: 14.184048\tAccuracy: 59.90%\n",
      "51\tValidation loss: 19.182076\tBest loss: 14.184048\tAccuracy: 64.20%\n",
      "52\tValidation loss: 20.489334\tBest loss: 14.184048\tAccuracy: 63.60%\n",
      "53\tValidation loss: 19.597557\tBest loss: 14.184048\tAccuracy: 63.60%\n",
      "54\tValidation loss: 22.064455\tBest loss: 14.184048\tAccuracy: 62.30%\n",
      "55\tValidation loss: 24.343536\tBest loss: 14.184048\tAccuracy: 59.40%\n",
      "56\tValidation loss: 19.051828\tBest loss: 14.184048\tAccuracy: 64.40%\n",
      "57\tValidation loss: 27.453257\tBest loss: 14.184048\tAccuracy: 58.70%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.93327367e-02   1.08747889e-04   2.17185721e-01 ...,   1.16447836e-07\n",
      "    8.17985235e-09   1.04505427e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.62054521e-38   0.00000000e+00   2.62827292e-24 ...,   1.00000000e+00\n",
      "    0.00000000e+00   2.72458748e-27]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[20 19 16 ...,  6 45 25]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.34842460e-04   3.22959022e-05   1.67718660e-02 ...,   2.87262315e-04\n",
      "    3.12444201e-04   2.72128982e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[43 43 43 ...,  6 20 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   2.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 74.524734\tBest loss: 74.524734\tAccuracy: 9.90%\n",
      "1\tValidation loss: 57.360214\tBest loss: 57.360214\tAccuracy: 13.50%\n",
      "2\tValidation loss: 78.371422\tBest loss: 57.360214\tAccuracy: 11.20%\n",
      "3\tValidation loss: 49.443130\tBest loss: 49.443130\tAccuracy: 25.40%\n",
      "4\tValidation loss: 43.508942\tBest loss: 43.508942\tAccuracy: 28.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\tValidation loss: 52.947590\tBest loss: 43.508942\tAccuracy: 29.90%\n",
      "6\tValidation loss: 48.572582\tBest loss: 43.508942\tAccuracy: 38.40%\n",
      "7\tValidation loss: 60.314316\tBest loss: 43.508942\tAccuracy: 28.90%\n",
      "8\tValidation loss: 29.324270\tBest loss: 29.324270\tAccuracy: 43.70%\n",
      "9\tValidation loss: 28.863895\tBest loss: 28.863895\tAccuracy: 42.80%\n",
      "10\tValidation loss: 28.605581\tBest loss: 28.605581\tAccuracy: 44.60%\n",
      "11\tValidation loss: 31.812565\tBest loss: 28.605581\tAccuracy: 41.50%\n",
      "12\tValidation loss: 34.226341\tBest loss: 28.605581\tAccuracy: 48.40%\n",
      "13\tValidation loss: 24.474045\tBest loss: 24.474045\tAccuracy: 49.30%\n",
      "14\tValidation loss: 36.942421\tBest loss: 24.474045\tAccuracy: 41.60%\n",
      "15\tValidation loss: 27.442532\tBest loss: 24.474045\tAccuracy: 50.90%\n",
      "16\tValidation loss: 25.177647\tBest loss: 24.474045\tAccuracy: 49.20%\n",
      "17\tValidation loss: 27.680458\tBest loss: 24.474045\tAccuracy: 53.50%\n",
      "18\tValidation loss: 28.599482\tBest loss: 24.474045\tAccuracy: 47.90%\n",
      "19\tValidation loss: 34.051907\tBest loss: 24.474045\tAccuracy: 45.40%\n",
      "20\tValidation loss: 21.834227\tBest loss: 21.834227\tAccuracy: 53.80%\n",
      "21\tValidation loss: 27.413582\tBest loss: 21.834227\tAccuracy: 54.00%\n",
      "22\tValidation loss: 22.570431\tBest loss: 21.834227\tAccuracy: 53.80%\n",
      "23\tValidation loss: 19.504852\tBest loss: 19.504852\tAccuracy: 59.10%\n",
      "24\tValidation loss: 17.903345\tBest loss: 17.903345\tAccuracy: 59.50%\n",
      "25\tValidation loss: 25.616436\tBest loss: 17.903345\tAccuracy: 57.80%\n",
      "26\tValidation loss: 24.632143\tBest loss: 17.903345\tAccuracy: 56.40%\n",
      "27\tValidation loss: 25.672604\tBest loss: 17.903345\tAccuracy: 54.50%\n",
      "28\tValidation loss: 14.031532\tBest loss: 14.031532\tAccuracy: 63.50%\n",
      "29\tValidation loss: 26.068588\tBest loss: 14.031532\tAccuracy: 55.70%\n",
      "30\tValidation loss: 17.058029\tBest loss: 14.031532\tAccuracy: 64.50%\n",
      "31\tValidation loss: 16.757992\tBest loss: 14.031532\tAccuracy: 60.40%\n",
      "32\tValidation loss: 20.557226\tBest loss: 14.031532\tAccuracy: 57.00%\n",
      "33\tValidation loss: 27.384731\tBest loss: 14.031532\tAccuracy: 55.90%\n",
      "34\tValidation loss: 23.277555\tBest loss: 14.031532\tAccuracy: 55.50%\n",
      "35\tValidation loss: 21.271645\tBest loss: 14.031532\tAccuracy: 63.00%\n",
      "36\tValidation loss: 23.965715\tBest loss: 14.031532\tAccuracy: 56.70%\n",
      "37\tValidation loss: 12.771736\tBest loss: 12.771736\tAccuracy: 67.80%\n",
      "38\tValidation loss: 18.974205\tBest loss: 12.771736\tAccuracy: 60.70%\n",
      "39\tValidation loss: 19.312153\tBest loss: 12.771736\tAccuracy: 61.30%\n",
      "40\tValidation loss: 44.443138\tBest loss: 12.771736\tAccuracy: 58.40%\n",
      "41\tValidation loss: 12.654152\tBest loss: 12.654152\tAccuracy: 66.60%\n",
      "42\tValidation loss: 21.970980\tBest loss: 12.654152\tAccuracy: 58.80%\n",
      "43\tValidation loss: 23.969706\tBest loss: 12.654152\tAccuracy: 60.30%\n",
      "44\tValidation loss: 21.786974\tBest loss: 12.654152\tAccuracy: 60.90%\n",
      "45\tValidation loss: 19.229763\tBest loss: 12.654152\tAccuracy: 61.80%\n",
      "46\tValidation loss: 22.894268\tBest loss: 12.654152\tAccuracy: 61.40%\n",
      "47\tValidation loss: 21.513796\tBest loss: 12.654152\tAccuracy: 60.80%\n",
      "48\tValidation loss: 14.294103\tBest loss: 12.654152\tAccuracy: 66.90%\n",
      "49\tValidation loss: 20.994446\tBest loss: 12.654152\tAccuracy: 61.30%\n",
      "50\tValidation loss: 18.295506\tBest loss: 12.654152\tAccuracy: 64.20%\n",
      "51\tValidation loss: 17.686874\tBest loss: 12.654152\tAccuracy: 65.20%\n",
      "52\tValidation loss: 27.075369\tBest loss: 12.654152\tAccuracy: 59.40%\n",
      "53\tValidation loss: 20.069630\tBest loss: 12.654152\tAccuracy: 65.40%\n",
      "54\tValidation loss: 22.384588\tBest loss: 12.654152\tAccuracy: 64.00%\n",
      "55\tValidation loss: 18.363472\tBest loss: 12.654152\tAccuracy: 66.40%\n",
      "56\tValidation loss: 16.508770\tBest loss: 12.654152\tAccuracy: 65.20%\n",
      "57\tValidation loss: 19.093298\tBest loss: 12.654152\tAccuracy: 68.50%\n",
      "58\tValidation loss: 17.515715\tBest loss: 12.654152\tAccuracy: 64.50%\n",
      "59\tValidation loss: 18.205732\tBest loss: 12.654152\tAccuracy: 65.60%\n",
      "60\tValidation loss: 16.082840\tBest loss: 12.654152\tAccuracy: 67.10%\n",
      "61\tValidation loss: 15.325906\tBest loss: 12.654152\tAccuracy: 67.50%\n",
      "62\tValidation loss: 16.194935\tBest loss: 12.654152\tAccuracy: 66.40%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   4.19859656e-36\n",
      "    0.00000000e+00   2.17526941e-16]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   1.74037874e-17\n",
      "    0.00000000e+00   8.50474446e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[26 43 43 ..., 36 27 27]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.65557054e-02   2.42864451e-04   1.01996243e-01 ...,   7.46915307e-10\n",
      "    4.63489025e-10   1.35609490e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.69096368e-03   1.72200310e-03   2.07004510e-03 ...,   4.87950638e-06\n",
      "    2.33903807e-03   2.94098078e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[20 19 16 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   2.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 98.583229\tBest loss: 98.583229\tAccuracy: 10.20%\n",
      "1\tValidation loss: 62.843719\tBest loss: 62.843719\tAccuracy: 14.20%\n",
      "2\tValidation loss: 56.277725\tBest loss: 56.277725\tAccuracy: 20.90%\n",
      "3\tValidation loss: 48.960514\tBest loss: 48.960514\tAccuracy: 26.40%\n",
      "4\tValidation loss: 58.503212\tBest loss: 48.960514\tAccuracy: 25.20%\n",
      "5\tValidation loss: 37.662605\tBest loss: 37.662605\tAccuracy: 33.30%\n",
      "6\tValidation loss: 40.108299\tBest loss: 37.662605\tAccuracy: 34.20%\n",
      "7\tValidation loss: 31.359207\tBest loss: 31.359207\tAccuracy: 40.30%\n",
      "8\tValidation loss: 49.695698\tBest loss: 31.359207\tAccuracy: 32.40%\n",
      "9\tValidation loss: 43.399319\tBest loss: 31.359207\tAccuracy: 33.70%\n",
      "10\tValidation loss: 29.729618\tBest loss: 29.729618\tAccuracy: 43.00%\n",
      "11\tValidation loss: 19.667439\tBest loss: 19.667439\tAccuracy: 50.50%\n",
      "12\tValidation loss: 40.978565\tBest loss: 19.667439\tAccuracy: 41.70%\n",
      "13\tValidation loss: 40.429657\tBest loss: 19.667439\tAccuracy: 39.50%\n",
      "14\tValidation loss: 33.235813\tBest loss: 19.667439\tAccuracy: 46.90%\n",
      "15\tValidation loss: 27.815281\tBest loss: 19.667439\tAccuracy: 48.60%\n",
      "16\tValidation loss: 37.838802\tBest loss: 19.667439\tAccuracy: 40.90%\n",
      "17\tValidation loss: 26.495544\tBest loss: 19.667439\tAccuracy: 46.80%\n",
      "18\tValidation loss: 21.674761\tBest loss: 19.667439\tAccuracy: 54.50%\n",
      "19\tValidation loss: 30.930862\tBest loss: 19.667439\tAccuracy: 50.10%\n",
      "20\tValidation loss: 23.034075\tBest loss: 19.667439\tAccuracy: 53.80%\n",
      "21\tValidation loss: 33.075424\tBest loss: 19.667439\tAccuracy: 51.20%\n",
      "22\tValidation loss: 27.624155\tBest loss: 19.667439\tAccuracy: 53.60%\n",
      "23\tValidation loss: 15.311522\tBest loss: 15.311522\tAccuracy: 61.30%\n",
      "24\tValidation loss: 31.531055\tBest loss: 15.311522\tAccuracy: 50.30%\n",
      "25\tValidation loss: 26.456573\tBest loss: 15.311522\tAccuracy: 54.70%\n",
      "26\tValidation loss: 21.900723\tBest loss: 15.311522\tAccuracy: 57.10%\n",
      "27\tValidation loss: 22.771757\tBest loss: 15.311522\tAccuracy: 56.20%\n",
      "28\tValidation loss: 28.299892\tBest loss: 15.311522\tAccuracy: 50.90%\n",
      "29\tValidation loss: 22.600758\tBest loss: 15.311522\tAccuracy: 58.70%\n",
      "30\tValidation loss: 21.673447\tBest loss: 15.311522\tAccuracy: 57.80%\n",
      "31\tValidation loss: 29.031181\tBest loss: 15.311522\tAccuracy: 55.30%\n",
      "32\tValidation loss: 21.323826\tBest loss: 15.311522\tAccuracy: 61.00%\n",
      "33\tValidation loss: 20.099796\tBest loss: 15.311522\tAccuracy: 60.40%\n",
      "34\tValidation loss: 20.140812\tBest loss: 15.311522\tAccuracy: 61.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\tValidation loss: 18.561071\tBest loss: 15.311522\tAccuracy: 62.30%\n",
      "36\tValidation loss: 18.049765\tBest loss: 15.311522\tAccuracy: 62.70%\n",
      "37\tValidation loss: 19.393574\tBest loss: 15.311522\tAccuracy: 62.30%\n",
      "38\tValidation loss: 20.362202\tBest loss: 15.311522\tAccuracy: 61.30%\n",
      "39\tValidation loss: 20.149511\tBest loss: 15.311522\tAccuracy: 62.70%\n",
      "40\tValidation loss: 17.558451\tBest loss: 15.311522\tAccuracy: 63.60%\n",
      "41\tValidation loss: 21.010069\tBest loss: 15.311522\tAccuracy: 61.20%\n",
      "42\tValidation loss: 17.852823\tBest loss: 15.311522\tAccuracy: 65.80%\n",
      "43\tValidation loss: 18.510277\tBest loss: 15.311522\tAccuracy: 61.20%\n",
      "44\tValidation loss: 18.413738\tBest loss: 15.311522\tAccuracy: 63.70%\n",
      "Early stopping!\n",
      "[[  3.44079865e-26   4.15003213e-18   2.04218372e-21 ...,   4.28169516e-22\n",
      "    0.00000000e+00   4.68685860e-19]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   2.48123573e-29]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.28627196e-04   2.85609416e-03   3.49762297e-04 ...,   2.41699090e-04\n",
      "    1.08930385e-02   1.81884051e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[41 41 22 ...,  6  8 47]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.04162565e-03   1.53841805e-02   7.25465044e-02 ...,   4.47259595e-07\n",
      "    1.11712798e-05   1.46847549e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   5.72683583e-33\n",
      "    1.65267056e-32   1.27335081e-14]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   2.89598170e-37\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[22 19 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=None, n_hidden_layers=0, n_neurons=200, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   2.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 116.932579\tBest loss: 116.932579\tAccuracy: 15.90%\n",
      "1\tValidation loss: 99.581772\tBest loss: 99.581772\tAccuracy: 21.30%\n",
      "2\tValidation loss: 60.905571\tBest loss: 60.905571\tAccuracy: 25.70%\n",
      "3\tValidation loss: 65.642181\tBest loss: 60.905571\tAccuracy: 30.00%\n",
      "4\tValidation loss: 65.659271\tBest loss: 60.905571\tAccuracy: 27.30%\n",
      "5\tValidation loss: 70.704231\tBest loss: 60.905571\tAccuracy: 29.80%\n",
      "6\tValidation loss: 71.403336\tBest loss: 60.905571\tAccuracy: 30.80%\n",
      "7\tValidation loss: 62.877499\tBest loss: 60.905571\tAccuracy: 35.20%\n",
      "8\tValidation loss: 83.469727\tBest loss: 60.905571\tAccuracy: 31.90%\n",
      "9\tValidation loss: 99.833977\tBest loss: 60.905571\tAccuracy: 31.10%\n",
      "10\tValidation loss: 143.905365\tBest loss: 60.905571\tAccuracy: 23.60%\n",
      "11\tValidation loss: 182.292725\tBest loss: 60.905571\tAccuracy: 29.90%\n",
      "12\tValidation loss: 58.082657\tBest loss: 58.082657\tAccuracy: 38.60%\n",
      "13\tValidation loss: 57.822227\tBest loss: 57.822227\tAccuracy: 40.30%\n",
      "14\tValidation loss: 49.515083\tBest loss: 49.515083\tAccuracy: 41.90%\n",
      "15\tValidation loss: 67.757996\tBest loss: 49.515083\tAccuracy: 37.30%\n",
      "16\tValidation loss: 75.291794\tBest loss: 49.515083\tAccuracy: 35.60%\n",
      "17\tValidation loss: 58.339653\tBest loss: 49.515083\tAccuracy: 43.70%\n",
      "18\tValidation loss: 56.569237\tBest loss: 49.515083\tAccuracy: 41.70%\n",
      "19\tValidation loss: 76.722382\tBest loss: 49.515083\tAccuracy: 39.80%\n",
      "20\tValidation loss: 60.057934\tBest loss: 49.515083\tAccuracy: 40.10%\n",
      "21\tValidation loss: 57.774517\tBest loss: 49.515083\tAccuracy: 46.70%\n",
      "22\tValidation loss: 60.288601\tBest loss: 49.515083\tAccuracy: 41.40%\n",
      "23\tValidation loss: 65.973122\tBest loss: 49.515083\tAccuracy: 41.90%\n",
      "24\tValidation loss: 38.799011\tBest loss: 38.799011\tAccuracy: 50.30%\n",
      "25\tValidation loss: 93.826645\tBest loss: 38.799011\tAccuracy: 41.70%\n",
      "26\tValidation loss: 58.226822\tBest loss: 38.799011\tAccuracy: 44.90%\n",
      "27\tValidation loss: 38.522881\tBest loss: 38.522881\tAccuracy: 45.10%\n",
      "28\tValidation loss: 46.966690\tBest loss: 38.522881\tAccuracy: 47.10%\n",
      "29\tValidation loss: 96.052994\tBest loss: 38.522881\tAccuracy: 41.20%\n",
      "30\tValidation loss: 32.833458\tBest loss: 32.833458\tAccuracy: 50.60%\n",
      "31\tValidation loss: 65.184738\tBest loss: 32.833458\tAccuracy: 42.60%\n",
      "32\tValidation loss: 71.469849\tBest loss: 32.833458\tAccuracy: 39.60%\n",
      "33\tValidation loss: 33.234833\tBest loss: 32.833458\tAccuracy: 49.50%\n",
      "34\tValidation loss: 39.817467\tBest loss: 32.833458\tAccuracy: 48.40%\n",
      "35\tValidation loss: 114.412964\tBest loss: 32.833458\tAccuracy: 37.70%\n",
      "36\tValidation loss: 49.227554\tBest loss: 32.833458\tAccuracy: 46.90%\n",
      "37\tValidation loss: 36.127415\tBest loss: 32.833458\tAccuracy: 48.60%\n",
      "38\tValidation loss: 47.885780\tBest loss: 32.833458\tAccuracy: 45.40%\n",
      "39\tValidation loss: 60.748131\tBest loss: 32.833458\tAccuracy: 44.70%\n",
      "40\tValidation loss: 47.987602\tBest loss: 32.833458\tAccuracy: 46.20%\n",
      "41\tValidation loss: 69.251640\tBest loss: 32.833458\tAccuracy: 47.40%\n",
      "42\tValidation loss: 109.752464\tBest loss: 32.833458\tAccuracy: 36.50%\n",
      "43\tValidation loss: 40.720165\tBest loss: 32.833458\tAccuracy: 50.10%\n",
      "44\tValidation loss: 31.783340\tBest loss: 31.783340\tAccuracy: 51.40%\n",
      "45\tValidation loss: 48.705986\tBest loss: 31.783340\tAccuracy: 50.90%\n",
      "46\tValidation loss: 96.867584\tBest loss: 31.783340\tAccuracy: 37.10%\n",
      "47\tValidation loss: 36.488785\tBest loss: 31.783340\tAccuracy: 50.70%\n",
      "48\tValidation loss: 43.561287\tBest loss: 31.783340\tAccuracy: 52.00%\n",
      "49\tValidation loss: 40.248707\tBest loss: 31.783340\tAccuracy: 49.50%\n",
      "50\tValidation loss: 50.211918\tBest loss: 31.783340\tAccuracy: 48.20%\n",
      "51\tValidation loss: 53.742939\tBest loss: 31.783340\tAccuracy: 46.00%\n",
      "52\tValidation loss: 85.381126\tBest loss: 31.783340\tAccuracy: 42.30%\n",
      "53\tValidation loss: 83.778519\tBest loss: 31.783340\tAccuracy: 45.10%\n",
      "54\tValidation loss: 44.075218\tBest loss: 31.783340\tAccuracy: 51.80%\n",
      "55\tValidation loss: 38.848923\tBest loss: 31.783340\tAccuracy: 51.60%\n",
      "56\tValidation loss: 30.173685\tBest loss: 30.173685\tAccuracy: 52.80%\n",
      "57\tValidation loss: 65.429680\tBest loss: 30.173685\tAccuracy: 46.50%\n",
      "58\tValidation loss: 43.248295\tBest loss: 30.173685\tAccuracy: 46.60%\n",
      "59\tValidation loss: 113.242973\tBest loss: 30.173685\tAccuracy: 38.60%\n",
      "60\tValidation loss: 29.220053\tBest loss: 29.220053\tAccuracy: 52.60%\n",
      "61\tValidation loss: 68.057442\tBest loss: 29.220053\tAccuracy: 48.50%\n",
      "62\tValidation loss: 38.024090\tBest loss: 29.220053\tAccuracy: 50.00%\n",
      "63\tValidation loss: 50.376770\tBest loss: 29.220053\tAccuracy: 53.00%\n",
      "64\tValidation loss: 49.372856\tBest loss: 29.220053\tAccuracy: 48.00%\n",
      "65\tValidation loss: 51.391102\tBest loss: 29.220053\tAccuracy: 49.10%\n",
      "66\tValidation loss: 33.276165\tBest loss: 29.220053\tAccuracy: 56.50%\n",
      "67\tValidation loss: 37.443287\tBest loss: 29.220053\tAccuracy: 52.70%\n",
      "68\tValidation loss: 114.763931\tBest loss: 29.220053\tAccuracy: 45.00%\n",
      "69\tValidation loss: 41.077705\tBest loss: 29.220053\tAccuracy: 50.80%\n",
      "70\tValidation loss: 32.184158\tBest loss: 29.220053\tAccuracy: 51.70%\n",
      "71\tValidation loss: 26.988819\tBest loss: 26.988819\tAccuracy: 57.30%\n",
      "72\tValidation loss: 39.716484\tBest loss: 26.988819\tAccuracy: 54.00%\n",
      "73\tValidation loss: 42.182228\tBest loss: 26.988819\tAccuracy: 50.30%\n",
      "74\tValidation loss: 69.880684\tBest loss: 26.988819\tAccuracy: 50.30%\n",
      "75\tValidation loss: 35.891853\tBest loss: 26.988819\tAccuracy: 53.90%\n",
      "76\tValidation loss: 75.909409\tBest loss: 26.988819\tAccuracy: 48.80%\n",
      "77\tValidation loss: 36.382225\tBest loss: 26.988819\tAccuracy: 53.50%\n",
      "78\tValidation loss: 37.029228\tBest loss: 26.988819\tAccuracy: 51.40%\n",
      "79\tValidation loss: 45.600407\tBest loss: 26.988819\tAccuracy: 55.00%\n",
      "80\tValidation loss: 22.922415\tBest loss: 22.922415\tAccuracy: 56.40%\n",
      "81\tValidation loss: 29.319883\tBest loss: 22.922415\tAccuracy: 57.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\tValidation loss: 33.217876\tBest loss: 22.922415\tAccuracy: 56.30%\n",
      "83\tValidation loss: 39.172371\tBest loss: 22.922415\tAccuracy: 48.60%\n",
      "84\tValidation loss: 37.146858\tBest loss: 22.922415\tAccuracy: 52.30%\n",
      "85\tValidation loss: 31.958344\tBest loss: 22.922415\tAccuracy: 57.40%\n",
      "86\tValidation loss: 29.671837\tBest loss: 22.922415\tAccuracy: 52.10%\n",
      "87\tValidation loss: 30.818289\tBest loss: 22.922415\tAccuracy: 54.80%\n",
      "88\tValidation loss: 102.458687\tBest loss: 22.922415\tAccuracy: 48.20%\n",
      "89\tValidation loss: 48.603939\tBest loss: 22.922415\tAccuracy: 54.00%\n",
      "90\tValidation loss: 40.106232\tBest loss: 22.922415\tAccuracy: 52.00%\n",
      "91\tValidation loss: 35.563026\tBest loss: 22.922415\tAccuracy: 52.80%\n",
      "92\tValidation loss: 36.170712\tBest loss: 22.922415\tAccuracy: 55.00%\n",
      "93\tValidation loss: 34.411186\tBest loss: 22.922415\tAccuracy: 53.90%\n",
      "94\tValidation loss: 35.354912\tBest loss: 22.922415\tAccuracy: 54.10%\n",
      "95\tValidation loss: 32.952389\tBest loss: 22.922415\tAccuracy: 53.90%\n",
      "96\tValidation loss: 33.792068\tBest loss: 22.922415\tAccuracy: 51.00%\n",
      "97\tValidation loss: 40.315445\tBest loss: 22.922415\tAccuracy: 52.40%\n",
      "98\tValidation loss: 31.065598\tBest loss: 22.922415\tAccuracy: 56.30%\n",
      "99\tValidation loss: 36.684639\tBest loss: 22.922415\tAccuracy: 55.90%\n",
      "100\tValidation loss: 25.536381\tBest loss: 22.922415\tAccuracy: 58.60%\n",
      "101\tValidation loss: 74.813515\tBest loss: 22.922415\tAccuracy: 47.50%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.60063617e-02   3.91773460e-03   3.52429077e-02 ...,   7.15973272e-08\n",
      "    5.11309111e-07   6.21903666e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.13590892e-18   0.00000000e+00   6.51324914e-13 ...,   9.99878883e-01\n",
      "    0.00000000e+00   6.31403806e-28]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[22 19 18 ..., 18 45 25]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  5.98896353e-04   6.85391933e-05   1.25873080e-02 ...,   1.19760471e-05\n",
      "    1.71324878e-03   5.32122795e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    2.15437152e-13   1.00000000e+00]]\n",
      "[43 43 43 ...,  6 18 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  17.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 197.509598\tBest loss: 197.509598\tAccuracy: 9.70%\n",
      "1\tValidation loss: 138.006271\tBest loss: 138.006271\tAccuracy: 18.90%\n",
      "2\tValidation loss: 83.864365\tBest loss: 83.864365\tAccuracy: 24.10%\n",
      "3\tValidation loss: 210.578308\tBest loss: 83.864365\tAccuracy: 16.40%\n",
      "4\tValidation loss: 88.824486\tBest loss: 83.864365\tAccuracy: 29.60%\n",
      "5\tValidation loss: 78.901405\tBest loss: 78.901405\tAccuracy: 30.60%\n",
      "6\tValidation loss: 76.839752\tBest loss: 76.839752\tAccuracy: 31.90%\n",
      "7\tValidation loss: 86.031891\tBest loss: 76.839752\tAccuracy: 34.20%\n",
      "8\tValidation loss: 67.687965\tBest loss: 67.687965\tAccuracy: 31.30%\n",
      "9\tValidation loss: 64.406334\tBest loss: 64.406334\tAccuracy: 37.60%\n",
      "10\tValidation loss: 85.982834\tBest loss: 64.406334\tAccuracy: 34.70%\n",
      "11\tValidation loss: 100.039177\tBest loss: 64.406334\tAccuracy: 32.40%\n",
      "12\tValidation loss: 100.196465\tBest loss: 64.406334\tAccuracy: 29.90%\n",
      "13\tValidation loss: 72.069290\tBest loss: 64.406334\tAccuracy: 30.30%\n",
      "14\tValidation loss: 68.855156\tBest loss: 64.406334\tAccuracy: 35.00%\n",
      "15\tValidation loss: 54.210373\tBest loss: 54.210373\tAccuracy: 43.10%\n",
      "16\tValidation loss: 52.898335\tBest loss: 52.898335\tAccuracy: 40.00%\n",
      "17\tValidation loss: 41.926125\tBest loss: 41.926125\tAccuracy: 44.60%\n",
      "18\tValidation loss: 48.013767\tBest loss: 41.926125\tAccuracy: 43.60%\n",
      "19\tValidation loss: 69.266930\tBest loss: 41.926125\tAccuracy: 41.00%\n",
      "20\tValidation loss: 89.670532\tBest loss: 41.926125\tAccuracy: 34.60%\n",
      "21\tValidation loss: 67.222679\tBest loss: 41.926125\tAccuracy: 43.80%\n",
      "22\tValidation loss: 53.767349\tBest loss: 41.926125\tAccuracy: 44.80%\n",
      "23\tValidation loss: 36.833160\tBest loss: 36.833160\tAccuracy: 43.90%\n",
      "24\tValidation loss: 40.363289\tBest loss: 36.833160\tAccuracy: 46.10%\n",
      "25\tValidation loss: 56.493324\tBest loss: 36.833160\tAccuracy: 41.90%\n",
      "26\tValidation loss: 46.637291\tBest loss: 36.833160\tAccuracy: 48.30%\n",
      "27\tValidation loss: 55.270519\tBest loss: 36.833160\tAccuracy: 46.50%\n",
      "28\tValidation loss: 50.688000\tBest loss: 36.833160\tAccuracy: 46.20%\n",
      "29\tValidation loss: 72.419998\tBest loss: 36.833160\tAccuracy: 47.20%\n",
      "30\tValidation loss: 42.376167\tBest loss: 36.833160\tAccuracy: 47.20%\n",
      "31\tValidation loss: 36.225052\tBest loss: 36.225052\tAccuracy: 49.00%\n",
      "32\tValidation loss: 40.746086\tBest loss: 36.225052\tAccuracy: 43.70%\n",
      "33\tValidation loss: 46.163609\tBest loss: 36.225052\tAccuracy: 46.20%\n",
      "34\tValidation loss: 42.342144\tBest loss: 36.225052\tAccuracy: 49.70%\n",
      "35\tValidation loss: 36.317074\tBest loss: 36.225052\tAccuracy: 48.40%\n",
      "36\tValidation loss: 34.813332\tBest loss: 34.813332\tAccuracy: 53.30%\n",
      "37\tValidation loss: 41.447800\tBest loss: 34.813332\tAccuracy: 47.10%\n",
      "38\tValidation loss: 36.820850\tBest loss: 34.813332\tAccuracy: 47.90%\n",
      "39\tValidation loss: 43.695690\tBest loss: 34.813332\tAccuracy: 47.30%\n",
      "40\tValidation loss: 51.405964\tBest loss: 34.813332\tAccuracy: 45.40%\n",
      "41\tValidation loss: 35.710747\tBest loss: 34.813332\tAccuracy: 52.00%\n",
      "42\tValidation loss: 59.757896\tBest loss: 34.813332\tAccuracy: 46.30%\n",
      "43\tValidation loss: 154.918167\tBest loss: 34.813332\tAccuracy: 35.50%\n",
      "44\tValidation loss: 41.381870\tBest loss: 34.813332\tAccuracy: 48.40%\n",
      "45\tValidation loss: 32.311623\tBest loss: 32.311623\tAccuracy: 51.70%\n",
      "46\tValidation loss: 58.018543\tBest loss: 32.311623\tAccuracy: 46.50%\n",
      "47\tValidation loss: 40.568707\tBest loss: 32.311623\tAccuracy: 51.80%\n",
      "48\tValidation loss: 72.347237\tBest loss: 32.311623\tAccuracy: 43.40%\n",
      "49\tValidation loss: 31.735331\tBest loss: 31.735331\tAccuracy: 51.40%\n",
      "50\tValidation loss: 46.451180\tBest loss: 31.735331\tAccuracy: 50.40%\n",
      "51\tValidation loss: 39.218658\tBest loss: 31.735331\tAccuracy: 51.10%\n",
      "52\tValidation loss: 37.028763\tBest loss: 31.735331\tAccuracy: 52.90%\n",
      "53\tValidation loss: 43.331192\tBest loss: 31.735331\tAccuracy: 52.30%\n",
      "54\tValidation loss: 32.926888\tBest loss: 31.735331\tAccuracy: 50.40%\n",
      "55\tValidation loss: 59.777946\tBest loss: 31.735331\tAccuracy: 48.70%\n",
      "56\tValidation loss: 40.755272\tBest loss: 31.735331\tAccuracy: 49.80%\n",
      "57\tValidation loss: 38.677246\tBest loss: 31.735331\tAccuracy: 51.40%\n",
      "58\tValidation loss: 48.900120\tBest loss: 31.735331\tAccuracy: 43.60%\n",
      "59\tValidation loss: 50.410080\tBest loss: 31.735331\tAccuracy: 53.40%\n",
      "60\tValidation loss: 27.778290\tBest loss: 27.778290\tAccuracy: 54.80%\n",
      "61\tValidation loss: 45.932213\tBest loss: 27.778290\tAccuracy: 47.10%\n",
      "62\tValidation loss: 31.605360\tBest loss: 27.778290\tAccuracy: 52.30%\n",
      "63\tValidation loss: 33.429897\tBest loss: 27.778290\tAccuracy: 52.50%\n",
      "64\tValidation loss: 37.046356\tBest loss: 27.778290\tAccuracy: 53.40%\n",
      "65\tValidation loss: 25.471506\tBest loss: 25.471506\tAccuracy: 55.40%\n",
      "66\tValidation loss: 37.773724\tBest loss: 25.471506\tAccuracy: 53.50%\n",
      "67\tValidation loss: 57.491707\tBest loss: 25.471506\tAccuracy: 50.90%\n",
      "68\tValidation loss: 32.135269\tBest loss: 25.471506\tAccuracy: 53.00%\n",
      "69\tValidation loss: 43.432404\tBest loss: 25.471506\tAccuracy: 49.40%\n",
      "70\tValidation loss: 30.542234\tBest loss: 25.471506\tAccuracy: 54.00%\n",
      "71\tValidation loss: 47.568680\tBest loss: 25.471506\tAccuracy: 53.80%\n",
      "72\tValidation loss: 35.805565\tBest loss: 25.471506\tAccuracy: 52.70%\n",
      "73\tValidation loss: 72.104645\tBest loss: 25.471506\tAccuracy: 52.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\tValidation loss: 25.687618\tBest loss: 25.471506\tAccuracy: 57.30%\n",
      "75\tValidation loss: 32.188835\tBest loss: 25.471506\tAccuracy: 56.30%\n",
      "76\tValidation loss: 96.371422\tBest loss: 25.471506\tAccuracy: 46.10%\n",
      "77\tValidation loss: 31.181681\tBest loss: 25.471506\tAccuracy: 56.70%\n",
      "78\tValidation loss: 68.523666\tBest loss: 25.471506\tAccuracy: 41.40%\n",
      "79\tValidation loss: 25.439686\tBest loss: 25.439686\tAccuracy: 60.30%\n",
      "80\tValidation loss: 37.658863\tBest loss: 25.439686\tAccuracy: 54.50%\n",
      "81\tValidation loss: 34.443821\tBest loss: 25.439686\tAccuracy: 53.30%\n",
      "82\tValidation loss: 45.756817\tBest loss: 25.439686\tAccuracy: 57.30%\n",
      "83\tValidation loss: 47.644680\tBest loss: 25.439686\tAccuracy: 50.80%\n",
      "84\tValidation loss: 50.209755\tBest loss: 25.439686\tAccuracy: 54.70%\n",
      "85\tValidation loss: 37.234375\tBest loss: 25.439686\tAccuracy: 54.50%\n",
      "86\tValidation loss: 73.573257\tBest loss: 25.439686\tAccuracy: 51.70%\n",
      "87\tValidation loss: 88.409706\tBest loss: 25.439686\tAccuracy: 48.10%\n",
      "88\tValidation loss: 34.542076\tBest loss: 25.439686\tAccuracy: 56.90%\n",
      "89\tValidation loss: 28.818007\tBest loss: 25.439686\tAccuracy: 58.80%\n",
      "90\tValidation loss: 26.265030\tBest loss: 25.439686\tAccuracy: 56.80%\n",
      "91\tValidation loss: 60.581856\tBest loss: 25.439686\tAccuracy: 50.30%\n",
      "92\tValidation loss: 29.059929\tBest loss: 25.439686\tAccuracy: 58.60%\n",
      "93\tValidation loss: 29.642231\tBest loss: 25.439686\tAccuracy: 53.40%\n",
      "94\tValidation loss: 49.946526\tBest loss: 25.439686\tAccuracy: 52.10%\n",
      "95\tValidation loss: 29.921137\tBest loss: 25.439686\tAccuracy: 57.40%\n",
      "96\tValidation loss: 44.760872\tBest loss: 25.439686\tAccuracy: 48.40%\n",
      "97\tValidation loss: 41.237068\tBest loss: 25.439686\tAccuracy: 53.40%\n",
      "98\tValidation loss: 38.416801\tBest loss: 25.439686\tAccuracy: 55.70%\n",
      "99\tValidation loss: 25.257439\tBest loss: 25.257439\tAccuracy: 58.20%\n",
      "100\tValidation loss: 58.237335\tBest loss: 25.257439\tAccuracy: 56.00%\n",
      "101\tValidation loss: 30.849258\tBest loss: 25.257439\tAccuracy: 55.30%\n",
      "102\tValidation loss: 25.568548\tBest loss: 25.257439\tAccuracy: 58.90%\n",
      "103\tValidation loss: 48.582100\tBest loss: 25.257439\tAccuracy: 53.50%\n",
      "104\tValidation loss: 30.125019\tBest loss: 25.257439\tAccuracy: 56.20%\n",
      "105\tValidation loss: 34.393341\tBest loss: 25.257439\tAccuracy: 57.80%\n",
      "106\tValidation loss: 33.817760\tBest loss: 25.257439\tAccuracy: 59.30%\n",
      "107\tValidation loss: 47.118637\tBest loss: 25.257439\tAccuracy: 49.30%\n",
      "108\tValidation loss: 38.923145\tBest loss: 25.257439\tAccuracy: 54.10%\n",
      "109\tValidation loss: 36.964577\tBest loss: 25.257439\tAccuracy: 54.50%\n",
      "110\tValidation loss: 30.801426\tBest loss: 25.257439\tAccuracy: 58.00%\n",
      "111\tValidation loss: 63.102268\tBest loss: 25.257439\tAccuracy: 45.60%\n",
      "112\tValidation loss: 37.092842\tBest loss: 25.257439\tAccuracy: 55.60%\n",
      "113\tValidation loss: 28.749269\tBest loss: 25.257439\tAccuracy: 58.80%\n",
      "114\tValidation loss: 30.964777\tBest loss: 25.257439\tAccuracy: 59.00%\n",
      "115\tValidation loss: 40.339909\tBest loss: 25.257439\tAccuracy: 53.90%\n",
      "116\tValidation loss: 31.780960\tBest loss: 25.257439\tAccuracy: 55.50%\n",
      "117\tValidation loss: 30.092817\tBest loss: 25.257439\tAccuracy: 54.70%\n",
      "118\tValidation loss: 27.352032\tBest loss: 25.257439\tAccuracy: 58.20%\n",
      "119\tValidation loss: 35.513809\tBest loss: 25.257439\tAccuracy: 57.70%\n",
      "120\tValidation loss: 39.969189\tBest loss: 25.257439\tAccuracy: 54.40%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.70840555e-25]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[43 43 43 ..., 10  6 27]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  5.60834818e-03   2.00372119e-03   2.23330222e-02 ...,   2.32486430e-09\n",
      "    8.80926621e-08   1.02483035e-07]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.24852918e-03   6.54226242e-05   1.45244738e-03 ...,   1.61130447e-06\n",
      "    9.01708845e-04   6.86023734e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[11 19 16 ...,  6 20 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  21.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 162.905136\tBest loss: 162.905136\tAccuracy: 12.20%\n",
      "1\tValidation loss: 91.893456\tBest loss: 91.893456\tAccuracy: 19.30%\n",
      "2\tValidation loss: 80.536957\tBest loss: 80.536957\tAccuracy: 25.30%\n",
      "3\tValidation loss: 76.989380\tBest loss: 76.989380\tAccuracy: 28.40%\n",
      "4\tValidation loss: 91.253441\tBest loss: 76.989380\tAccuracy: 23.80%\n",
      "5\tValidation loss: 66.855545\tBest loss: 66.855545\tAccuracy: 31.50%\n",
      "6\tValidation loss: 64.275139\tBest loss: 64.275139\tAccuracy: 31.80%\n",
      "7\tValidation loss: 106.233665\tBest loss: 64.275139\tAccuracy: 34.70%\n",
      "8\tValidation loss: 106.774094\tBest loss: 64.275139\tAccuracy: 32.00%\n",
      "9\tValidation loss: 69.036102\tBest loss: 64.275139\tAccuracy: 33.40%\n",
      "10\tValidation loss: 67.104256\tBest loss: 64.275139\tAccuracy: 36.60%\n",
      "11\tValidation loss: 63.797138\tBest loss: 63.797138\tAccuracy: 36.10%\n",
      "12\tValidation loss: 57.670654\tBest loss: 57.670654\tAccuracy: 36.60%\n",
      "13\tValidation loss: 47.964005\tBest loss: 47.964005\tAccuracy: 41.10%\n",
      "14\tValidation loss: 62.429249\tBest loss: 47.964005\tAccuracy: 39.90%\n",
      "15\tValidation loss: 56.566620\tBest loss: 47.964005\tAccuracy: 35.80%\n",
      "16\tValidation loss: 53.404713\tBest loss: 47.964005\tAccuracy: 40.80%\n",
      "17\tValidation loss: 44.857246\tBest loss: 44.857246\tAccuracy: 40.90%\n",
      "18\tValidation loss: 77.568596\tBest loss: 44.857246\tAccuracy: 33.40%\n",
      "19\tValidation loss: 65.669258\tBest loss: 44.857246\tAccuracy: 39.70%\n",
      "20\tValidation loss: 72.475563\tBest loss: 44.857246\tAccuracy: 40.40%\n",
      "21\tValidation loss: 60.099251\tBest loss: 44.857246\tAccuracy: 43.20%\n",
      "22\tValidation loss: 43.881176\tBest loss: 43.881176\tAccuracy: 48.80%\n",
      "23\tValidation loss: 54.314163\tBest loss: 43.881176\tAccuracy: 45.30%\n",
      "24\tValidation loss: 100.778259\tBest loss: 43.881176\tAccuracy: 38.40%\n",
      "25\tValidation loss: 50.504265\tBest loss: 43.881176\tAccuracy: 43.70%\n",
      "26\tValidation loss: 55.203815\tBest loss: 43.881176\tAccuracy: 41.80%\n",
      "27\tValidation loss: 60.766674\tBest loss: 43.881176\tAccuracy: 38.30%\n",
      "28\tValidation loss: 53.839218\tBest loss: 43.881176\tAccuracy: 40.50%\n",
      "29\tValidation loss: 47.505196\tBest loss: 43.881176\tAccuracy: 44.70%\n",
      "30\tValidation loss: 54.082359\tBest loss: 43.881176\tAccuracy: 45.90%\n",
      "31\tValidation loss: 49.240475\tBest loss: 43.881176\tAccuracy: 45.90%\n",
      "32\tValidation loss: 32.127457\tBest loss: 32.127457\tAccuracy: 49.70%\n",
      "33\tValidation loss: 39.812115\tBest loss: 32.127457\tAccuracy: 49.50%\n",
      "34\tValidation loss: 46.892399\tBest loss: 32.127457\tAccuracy: 47.60%\n",
      "35\tValidation loss: 50.534271\tBest loss: 32.127457\tAccuracy: 48.90%\n",
      "36\tValidation loss: 38.764404\tBest loss: 32.127457\tAccuracy: 52.30%\n",
      "37\tValidation loss: 34.501144\tBest loss: 32.127457\tAccuracy: 52.00%\n",
      "38\tValidation loss: 41.377285\tBest loss: 32.127457\tAccuracy: 46.30%\n",
      "39\tValidation loss: 42.854797\tBest loss: 32.127457\tAccuracy: 48.30%\n",
      "40\tValidation loss: 40.464767\tBest loss: 32.127457\tAccuracy: 49.20%\n",
      "41\tValidation loss: 40.943729\tBest loss: 32.127457\tAccuracy: 46.50%\n",
      "42\tValidation loss: 77.962975\tBest loss: 32.127457\tAccuracy: 44.90%\n",
      "43\tValidation loss: 48.904694\tBest loss: 32.127457\tAccuracy: 48.00%\n",
      "44\tValidation loss: 43.380951\tBest loss: 32.127457\tAccuracy: 48.10%\n",
      "45\tValidation loss: 31.464363\tBest loss: 31.464363\tAccuracy: 52.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\tValidation loss: 32.864189\tBest loss: 31.464363\tAccuracy: 52.90%\n",
      "47\tValidation loss: 39.232979\tBest loss: 31.464363\tAccuracy: 52.90%\n",
      "48\tValidation loss: 24.749031\tBest loss: 24.749031\tAccuracy: 54.70%\n",
      "49\tValidation loss: 42.564339\tBest loss: 24.749031\tAccuracy: 47.30%\n",
      "50\tValidation loss: 45.758537\tBest loss: 24.749031\tAccuracy: 48.70%\n",
      "51\tValidation loss: 36.595158\tBest loss: 24.749031\tAccuracy: 50.90%\n",
      "52\tValidation loss: 39.472580\tBest loss: 24.749031\tAccuracy: 48.20%\n",
      "53\tValidation loss: 29.983072\tBest loss: 24.749031\tAccuracy: 53.80%\n",
      "54\tValidation loss: 55.505806\tBest loss: 24.749031\tAccuracy: 50.80%\n",
      "55\tValidation loss: 44.670506\tBest loss: 24.749031\tAccuracy: 47.70%\n",
      "56\tValidation loss: 47.537842\tBest loss: 24.749031\tAccuracy: 49.00%\n",
      "57\tValidation loss: 31.643791\tBest loss: 24.749031\tAccuracy: 54.20%\n",
      "58\tValidation loss: 41.044121\tBest loss: 24.749031\tAccuracy: 54.10%\n",
      "59\tValidation loss: 34.481415\tBest loss: 24.749031\tAccuracy: 52.40%\n",
      "60\tValidation loss: 46.206028\tBest loss: 24.749031\tAccuracy: 52.30%\n",
      "61\tValidation loss: 61.066990\tBest loss: 24.749031\tAccuracy: 46.80%\n",
      "62\tValidation loss: 50.252163\tBest loss: 24.749031\tAccuracy: 51.00%\n",
      "63\tValidation loss: 35.580601\tBest loss: 24.749031\tAccuracy: 53.70%\n",
      "64\tValidation loss: 39.454784\tBest loss: 24.749031\tAccuracy: 53.60%\n",
      "65\tValidation loss: 139.852509\tBest loss: 24.749031\tAccuracy: 39.20%\n",
      "66\tValidation loss: 42.579941\tBest loss: 24.749031\tAccuracy: 51.60%\n",
      "67\tValidation loss: 39.261578\tBest loss: 24.749031\tAccuracy: 50.60%\n",
      "68\tValidation loss: 43.021706\tBest loss: 24.749031\tAccuracy: 52.30%\n",
      "69\tValidation loss: 41.296417\tBest loss: 24.749031\tAccuracy: 53.70%\n",
      "Early stopping!\n",
      "[[  3.69701904e-34   4.17111522e-31   6.75109895e-38 ...,   9.96268589e-30\n",
      "    0.00000000e+00   5.92362862e-30]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   5.29014415e-35 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.14246639e-23]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.27684039e-03   5.56001251e-05   3.08507169e-03 ...,   3.79334961e-05\n",
      "    2.50818282e-02   1.06406212e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    5.85416493e-10   1.00000000e+00]]\n",
      "[41 41 22 ...,  6 20 47]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.51912817e-02   6.11968450e-02   8.69226530e-02 ...,   1.45275590e-06\n",
      "    2.41770453e-04   1.24429440e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[20 30 16 ..., 36  6 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=None, n_hidden_layers=0, n_neurons=100, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  13.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 9.416109\tBest loss: 9.416109\tAccuracy: 1.60%\n",
      "1\tValidation loss: 9.052753\tBest loss: 9.052753\tAccuracy: 2.70%\n",
      "2\tValidation loss: 13.298120\tBest loss: 9.052753\tAccuracy: 4.10%\n",
      "3\tValidation loss: 14.180862\tBest loss: 9.052753\tAccuracy: 3.60%\n",
      "4\tValidation loss: 20.917734\tBest loss: 9.052753\tAccuracy: 2.00%\n",
      "5\tValidation loss: 15.601779\tBest loss: 9.052753\tAccuracy: 2.20%\n",
      "6\tValidation loss: 11.604830\tBest loss: 9.052753\tAccuracy: 2.60%\n",
      "7\tValidation loss: 14.720634\tBest loss: 9.052753\tAccuracy: 2.00%\n",
      "8\tValidation loss: 13.705317\tBest loss: 9.052753\tAccuracy: 3.20%\n",
      "9\tValidation loss: 22.450493\tBest loss: 9.052753\tAccuracy: 1.90%\n",
      "10\tValidation loss: 14.149034\tBest loss: 9.052753\tAccuracy: 4.20%\n",
      "11\tValidation loss: 11.786459\tBest loss: 9.052753\tAccuracy: 4.20%\n",
      "12\tValidation loss: 12.538120\tBest loss: 9.052753\tAccuracy: 2.10%\n",
      "13\tValidation loss: 19.875999\tBest loss: 9.052753\tAccuracy: 3.70%\n",
      "14\tValidation loss: 15.628751\tBest loss: 9.052753\tAccuracy: 4.10%\n",
      "15\tValidation loss: 15.904682\tBest loss: 9.052753\tAccuracy: 3.20%\n",
      "16\tValidation loss: 17.441717\tBest loss: 9.052753\tAccuracy: 2.40%\n",
      "17\tValidation loss: 23.621716\tBest loss: 9.052753\tAccuracy: 2.30%\n",
      "18\tValidation loss: 22.280132\tBest loss: 9.052753\tAccuracy: 1.70%\n",
      "19\tValidation loss: 12.857407\tBest loss: 9.052753\tAccuracy: 3.90%\n",
      "20\tValidation loss: 22.752911\tBest loss: 9.052753\tAccuracy: 1.00%\n",
      "21\tValidation loss: 15.358834\tBest loss: 9.052753\tAccuracy: 4.50%\n",
      "22\tValidation loss: 14.639373\tBest loss: 9.052753\tAccuracy: 4.50%\n",
      "Early stopping!\n",
      "[[  5.26274016e-05   1.18684577e-04   1.08668621e-06 ...,   1.24047483e-08\n",
      "    1.42467655e-08   4.58628820e-05]\n",
      " [  3.23571153e-02   4.69700322e-02   3.37699652e-02 ...,   7.00328499e-03\n",
      "    4.56542009e-03   7.46419141e-03]\n",
      " [  1.94962536e-06   5.08084304e-06   1.26619772e-08 ...,   5.17146395e-11\n",
      "    6.33234368e-11   1.28924330e-06]\n",
      " ..., \n",
      " [  4.15498247e-10   2.07789941e-09   5.18066289e-14 ...,   7.27418743e-18\n",
      "    5.78523900e-17   3.50734497e-10]\n",
      " [  1.08948899e-02   2.50610076e-02   4.00157459e-03 ...,   4.53360582e-04\n",
      "    3.56696255e-04   3.35979974e-03]\n",
      " [  5.40057044e-06   4.04471666e-06   1.08063901e-07 ...,   1.13296539e-09\n",
      "    6.43238462e-10   3.35074765e-05]]\n",
      "[29  3 29 ..., 29 17 29]\n",
      "[[  6.08266681e-04   1.50170596e-03   5.00886672e-05 ...,   7.96250731e-07\n",
      "    7.08813616e-07   2.56795989e-04]\n",
      " [  3.54056419e-06   7.40697624e-06   2.04643218e-08 ...,   1.20123647e-10\n",
      "    1.21759575e-10   7.88017496e-06]\n",
      " [  6.36440745e-05   4.67993290e-04   7.23714174e-06 ...,   8.41115479e-08\n",
      "    3.58216319e-08   5.72415811e-05]\n",
      " ..., \n",
      " [  1.50370866e-03   4.42031957e-03   1.55509057e-04 ...,   6.54931728e-06\n",
      "    8.99237875e-06   5.01252653e-04]\n",
      " [  3.26485597e-02   4.55520339e-02   3.44351456e-02 ...,   7.29685184e-03\n",
      "    4.79642162e-03   7.59687973e-03]\n",
      " [  2.61929436e-05   7.31021137e-05   4.93641551e-07 ...,   3.61927865e-09\n",
      "    5.15841680e-09   2.12176783e-05]]\n",
      "[29 29 29 ..., 29  3 29]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   8.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 15.258081\tBest loss: 15.258081\tAccuracy: 4.50%\n",
      "1\tValidation loss: 12.434447\tBest loss: 12.434447\tAccuracy: 3.10%\n",
      "2\tValidation loss: 14.170990\tBest loss: 12.434447\tAccuracy: 4.00%\n",
      "3\tValidation loss: 31.797100\tBest loss: 12.434447\tAccuracy: 2.00%\n",
      "4\tValidation loss: 14.925840\tBest loss: 12.434447\tAccuracy: 2.70%\n",
      "5\tValidation loss: 14.006099\tBest loss: 12.434447\tAccuracy: 4.10%\n",
      "6\tValidation loss: 11.632165\tBest loss: 11.632165\tAccuracy: 3.90%\n",
      "7\tValidation loss: 17.408237\tBest loss: 11.632165\tAccuracy: 3.10%\n",
      "8\tValidation loss: 11.446535\tBest loss: 11.446535\tAccuracy: 2.10%\n",
      "9\tValidation loss: 17.691534\tBest loss: 11.446535\tAccuracy: 3.50%\n",
      "10\tValidation loss: 13.682773\tBest loss: 11.446535\tAccuracy: 4.50%\n",
      "11\tValidation loss: 15.088611\tBest loss: 11.446535\tAccuracy: 2.10%\n",
      "12\tValidation loss: 23.834028\tBest loss: 11.446535\tAccuracy: 1.20%\n",
      "13\tValidation loss: 10.661431\tBest loss: 10.661431\tAccuracy: 1.80%\n",
      "14\tValidation loss: 24.744997\tBest loss: 10.661431\tAccuracy: 2.30%\n",
      "15\tValidation loss: 17.044909\tBest loss: 10.661431\tAccuracy: 3.30%\n",
      "16\tValidation loss: 16.632954\tBest loss: 10.661431\tAccuracy: 1.50%\n",
      "17\tValidation loss: 16.335703\tBest loss: 10.661431\tAccuracy: 1.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\tValidation loss: 13.081396\tBest loss: 10.661431\tAccuracy: 2.70%\n",
      "19\tValidation loss: 14.551960\tBest loss: 10.661431\tAccuracy: 3.70%\n",
      "20\tValidation loss: 19.731153\tBest loss: 10.661431\tAccuracy: 1.40%\n",
      "21\tValidation loss: 12.486670\tBest loss: 10.661431\tAccuracy: 3.40%\n",
      "22\tValidation loss: 13.593355\tBest loss: 10.661431\tAccuracy: 2.20%\n",
      "23\tValidation loss: 18.625591\tBest loss: 10.661431\tAccuracy: 2.00%\n",
      "24\tValidation loss: 18.189753\tBest loss: 10.661431\tAccuracy: 1.90%\n",
      "25\tValidation loss: 12.456100\tBest loss: 10.661431\tAccuracy: 3.90%\n",
      "26\tValidation loss: 20.702276\tBest loss: 10.661431\tAccuracy: 3.80%\n",
      "27\tValidation loss: 24.520048\tBest loss: 10.661431\tAccuracy: 2.20%\n",
      "28\tValidation loss: 16.001888\tBest loss: 10.661431\tAccuracy: 2.30%\n",
      "29\tValidation loss: 14.878427\tBest loss: 10.661431\tAccuracy: 2.20%\n",
      "30\tValidation loss: 16.916538\tBest loss: 10.661431\tAccuracy: 2.60%\n",
      "31\tValidation loss: 11.037802\tBest loss: 10.661431\tAccuracy: 4.80%\n",
      "32\tValidation loss: 22.458237\tBest loss: 10.661431\tAccuracy: 0.80%\n",
      "33\tValidation loss: 17.253698\tBest loss: 10.661431\tAccuracy: 2.00%\n",
      "34\tValidation loss: 16.562021\tBest loss: 10.661431\tAccuracy: 2.60%\n",
      "Early stopping!\n",
      "[[  3.43630119e-04   1.04077428e-03   1.43128846e-05 ...,   1.40407152e-04\n",
      "    7.11963867e-06   1.06761081e-05]\n",
      " [  4.00280851e-06   2.32265720e-05   9.92802818e-09 ...,   4.18303273e-07\n",
      "    6.46835829e-08   2.95601268e-08]\n",
      " [  1.81046606e-04   8.38685315e-04   9.18315072e-06 ...,   4.65647754e-05\n",
      "    1.90740211e-05   4.59845251e-06]\n",
      " ..., \n",
      " [  1.77293513e-02   3.05169355e-02   2.31348025e-03 ...,   2.81995395e-03\n",
      "    1.65731006e-03   5.80989930e-04]\n",
      " [  2.16464605e-03   8.51807930e-03   7.59563336e-05 ...,   4.05238185e-04\n",
      "    2.97221442e-04   5.85728303e-05]\n",
      " [  1.75574939e-07   7.94034077e-06   5.19082832e-11 ...,   3.23988978e-08\n",
      "    1.00956923e-08   7.51878004e-10]]\n",
      "[42 42 42 ..., 42 42 27]\n",
      "[[  1.65347319e-05   3.36527737e-05   1.06542153e-07 ...,   3.32658919e-06\n",
      "    1.35498169e-07   5.14073406e-08]\n",
      " [  4.51730751e-02   5.64104207e-02   2.51310952e-02 ...,   8.49683955e-03\n",
      "    7.38623878e-03   3.12915328e-03]\n",
      " [  1.70512646e-06   1.47858937e-05   2.38606255e-08 ...,   4.78961056e-07\n",
      "    4.31111786e-08   3.29296412e-08]\n",
      " ..., \n",
      " [  6.55981991e-03   1.28981015e-02   8.60408647e-04 ...,   1.48824160e-03\n",
      "    6.41571067e-04   2.39854679e-04]\n",
      " [  4.59595583e-02   5.63813299e-02   2.43583340e-02 ...,   8.63620359e-03\n",
      "    7.63760414e-03   3.10125970e-03]\n",
      " [  3.73761686e-05   7.58967246e-04   1.57365903e-07 ...,   1.42784729e-05\n",
      "    6.06843787e-06   3.97117816e-07]]\n",
      "[42 37 27 ..., 42 37 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=  11.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 17.317631\tBest loss: 17.317631\tAccuracy: 2.00%\n",
      "1\tValidation loss: 9.616525\tBest loss: 9.616525\tAccuracy: 4.50%\n",
      "2\tValidation loss: 9.299764\tBest loss: 9.299764\tAccuracy: 4.00%\n",
      "3\tValidation loss: 10.676744\tBest loss: 9.299764\tAccuracy: 4.50%\n",
      "4\tValidation loss: 7.938468\tBest loss: 7.938468\tAccuracy: 2.60%\n",
      "5\tValidation loss: 16.597374\tBest loss: 7.938468\tAccuracy: 4.30%\n",
      "6\tValidation loss: 21.614374\tBest loss: 7.938468\tAccuracy: 2.30%\n",
      "7\tValidation loss: 13.307827\tBest loss: 7.938468\tAccuracy: 3.20%\n",
      "8\tValidation loss: 16.949242\tBest loss: 7.938468\tAccuracy: 3.60%\n",
      "9\tValidation loss: 11.818040\tBest loss: 7.938468\tAccuracy: 3.80%\n",
      "10\tValidation loss: 22.385172\tBest loss: 7.938468\tAccuracy: 1.40%\n",
      "11\tValidation loss: 11.018819\tBest loss: 7.938468\tAccuracy: 2.10%\n",
      "12\tValidation loss: 17.110521\tBest loss: 7.938468\tAccuracy: 2.00%\n",
      "13\tValidation loss: 12.015019\tBest loss: 7.938468\tAccuracy: 2.70%\n",
      "14\tValidation loss: 18.095739\tBest loss: 7.938468\tAccuracy: 1.90%\n",
      "15\tValidation loss: 18.117649\tBest loss: 7.938468\tAccuracy: 3.30%\n",
      "16\tValidation loss: 12.942514\tBest loss: 7.938468\tAccuracy: 4.20%\n",
      "17\tValidation loss: 12.775861\tBest loss: 7.938468\tAccuracy: 1.10%\n",
      "18\tValidation loss: 12.081179\tBest loss: 7.938468\tAccuracy: 4.10%\n",
      "19\tValidation loss: 13.009653\tBest loss: 7.938468\tAccuracy: 2.70%\n",
      "20\tValidation loss: 19.680124\tBest loss: 7.938468\tAccuracy: 3.20%\n",
      "21\tValidation loss: 21.885725\tBest loss: 7.938468\tAccuracy: 2.80%\n",
      "22\tValidation loss: 12.598393\tBest loss: 7.938468\tAccuracy: 3.80%\n",
      "23\tValidation loss: 12.687586\tBest loss: 7.938468\tAccuracy: 4.70%\n",
      "24\tValidation loss: 11.580301\tBest loss: 7.938468\tAccuracy: 4.70%\n",
      "25\tValidation loss: 11.951377\tBest loss: 7.938468\tAccuracy: 3.50%\n",
      "Early stopping!\n",
      "[[  1.53032348e-01   2.41839583e-03   1.09015626e-03 ...,   2.09766300e-03\n",
      "    1.35699119e-02   1.14263566e-02]\n",
      " [  2.42702410e-01   7.53750737e-06   1.64306095e-06 ...,   2.87771836e-05\n",
      "    8.67937226e-03   3.02811456e-03]\n",
      " [  2.01627001e-01   5.10482969e-05   3.88569651e-06 ...,   2.39375386e-05\n",
      "    1.65581293e-02   3.88725894e-03]\n",
      " ..., \n",
      " [  1.77932397e-01   2.87678704e-04   3.59270853e-05 ...,   1.36764516e-04\n",
      "    2.10608598e-02   7.14436127e-03]\n",
      " [  1.12456381e-01   1.29135596e-02   6.46087900e-03 ...,   5.47149219e-03\n",
      "    1.23777958e-02   1.17274243e-02]\n",
      " [  5.66834472e-02   1.66006359e-07   1.44324441e-09 ...,   7.37278469e-08\n",
      "    6.82047149e-03   6.52864983e-04]]\n",
      "[ 0 15 15 ..., 15  0 15]\n",
      "[[  2.29170024e-01   4.32664865e-06   9.84555157e-08 ...,   5.10683594e-06\n",
      "    2.10055206e-02   3.84440669e-03]\n",
      " [  1.13032348e-01   1.25355152e-02   6.42713252e-03 ...,   5.58906188e-03\n",
      "    1.22364927e-02   1.17124561e-02]\n",
      " [  4.60332707e-02   1.10926784e-07   4.32256037e-10 ...,   1.38067463e-07\n",
      "    3.90120596e-03   1.49170693e-03]\n",
      " ..., \n",
      " [  1.74618036e-01   5.41986083e-04   1.92262814e-04 ...,   7.84678094e-04\n",
      "    1.54094500e-02   1.11678140e-02]\n",
      " [  1.67224407e-01   5.42663329e-05   3.06884021e-06 ...,   2.61104778e-05\n",
      "    1.13518415e-02   4.78413561e-03]\n",
      " [  4.96745557e-02   2.67752320e-10   2.02821961e-12 ...,   2.34179276e-09\n",
      "    2.63426220e-03   3.26313137e-04]]\n",
      "[15  0 15 ...,  0 15 15]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=2, n_neurons=50, learning_rate=0.05, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   8.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.839760\tBest loss: 3.839760\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.819128\tBest loss: 3.819128\tAccuracy: 3.70%\n",
      "2\tValidation loss: 3.809212\tBest loss: 3.809212\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.804012\tBest loss: 3.804012\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.801229\tBest loss: 3.801229\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.799497\tBest loss: 3.799497\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.798395\tBest loss: 3.798395\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.797763\tBest loss: 3.797763\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.797281\tBest loss: 3.797281\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.796898\tBest loss: 3.796898\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.796634\tBest loss: 3.796634\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.796416\tBest loss: 3.796416\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.796284\tBest loss: 3.796284\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.796193\tBest loss: 3.796193\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.796097\tBest loss: 3.796097\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.796052\tBest loss: 3.796052\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.795979\tBest loss: 3.795979\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.795925\tBest loss: 3.795925\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.795886\tBest loss: 3.795886\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.795841\tBest loss: 3.795841\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.795839\tBest loss: 3.795839\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.795835\tBest loss: 3.795835\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.795807\tBest loss: 3.795807\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\tValidation loss: 3.795806\tBest loss: 3.795806\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.795795\tBest loss: 3.795795\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.795804\tBest loss: 3.795795\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.795797\tBest loss: 3.795795\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.795796\tBest loss: 3.795795\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.795784\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.795792\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.795784\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.795791\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.795791\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.795795\tBest loss: 3.795784\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.795782\tBest loss: 3.795782\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.795780\tBest loss: 3.795780\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.795764\tBest loss: 3.795764\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.795767\tBest loss: 3.795764\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.795774\tBest loss: 3.795764\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.795763\tBest loss: 3.795763\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.795765\tBest loss: 3.795763\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.795775\tBest loss: 3.795763\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.795757\tBest loss: 3.795757\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.795743\tBest loss: 3.795743\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.795741\tBest loss: 3.795741\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.795737\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.795741\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "47\tValidation loss: 3.795737\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "48\tValidation loss: 3.795741\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "49\tValidation loss: 3.795745\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "50\tValidation loss: 3.795753\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.795753\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.795757\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "53\tValidation loss: 3.795758\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "54\tValidation loss: 3.795747\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "55\tValidation loss: 3.795761\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.795757\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "57\tValidation loss: 3.795760\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.795760\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "59\tValidation loss: 3.795767\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "60\tValidation loss: 3.795765\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "61\tValidation loss: 3.795760\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "62\tValidation loss: 3.795757\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "63\tValidation loss: 3.795761\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "64\tValidation loss: 3.795753\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "65\tValidation loss: 3.795754\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "66\tValidation loss: 3.795756\tBest loss: 3.795737\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " ..., \n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " ..., \n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]\n",
      " [ 0.01691398  0.03279204  0.02271616 ...,  0.02859455  0.01700341\n",
      "   0.01770371]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  25.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.834534\tBest loss: 3.834534\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.815773\tBest loss: 3.815773\tAccuracy: 3.70%\n",
      "2\tValidation loss: 3.807095\tBest loss: 3.807095\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.802643\tBest loss: 3.802643\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.800279\tBest loss: 3.800279\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.798820\tBest loss: 3.798820\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.797900\tBest loss: 3.797900\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.797309\tBest loss: 3.797309\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.796949\tBest loss: 3.796949\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.796683\tBest loss: 3.796683\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.796468\tBest loss: 3.796468\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.796303\tBest loss: 3.796303\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.796159\tBest loss: 3.796159\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.796088\tBest loss: 3.796088\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.796023\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.795974\tBest loss: 3.795974\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.795933\tBest loss: 3.795933\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.795892\tBest loss: 3.795892\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.795858\tBest loss: 3.795858\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.795829\tBest loss: 3.795829\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.795799\tBest loss: 3.795799\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.795766\tBest loss: 3.795766\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.795753\tBest loss: 3.795753\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.795740\tBest loss: 3.795740\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.795708\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.795718\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.795724\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.795728\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.795734\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.795724\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.795708\tBest loss: 3.795708\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.795703\tBest loss: 3.795703\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.795708\tBest loss: 3.795703\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.795716\tBest loss: 3.795703\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.795713\tBest loss: 3.795703\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.795696\tBest loss: 3.795696\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.795699\tBest loss: 3.795696\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.795695\tBest loss: 3.795695\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.795700\tBest loss: 3.795695\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.795698\tBest loss: 3.795695\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.795702\tBest loss: 3.795695\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.795698\tBest loss: 3.795695\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.795686\tBest loss: 3.795686\tAccuracy: 3.70%\n",
      "43\tValidation loss: 3.795683\tBest loss: 3.795683\tAccuracy: 3.70%\n",
      "44\tValidation loss: 3.795678\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "45\tValidation loss: 3.795692\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "46\tValidation loss: 3.795697\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "47\tValidation loss: 3.795691\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "48\tValidation loss: 3.795696\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "49\tValidation loss: 3.795696\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "50\tValidation loss: 3.795697\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.795685\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.795693\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "53\tValidation loss: 3.795696\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "54\tValidation loss: 3.795694\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "55\tValidation loss: 3.795684\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.795690\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "57\tValidation loss: 3.795689\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "58\tValidation loss: 3.795695\tBest loss: 3.795678\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\tValidation loss: 3.795696\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "60\tValidation loss: 3.795686\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "61\tValidation loss: 3.795689\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "62\tValidation loss: 3.795692\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "63\tValidation loss: 3.795687\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "64\tValidation loss: 3.795679\tBest loss: 3.795678\tAccuracy: 3.70%\n",
      "65\tValidation loss: 3.795671\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "66\tValidation loss: 3.795678\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "67\tValidation loss: 3.795678\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "68\tValidation loss: 3.795676\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "69\tValidation loss: 3.795681\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "70\tValidation loss: 3.795677\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "71\tValidation loss: 3.795680\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "72\tValidation loss: 3.795682\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "73\tValidation loss: 3.795689\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "74\tValidation loss: 3.795681\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "75\tValidation loss: 3.795687\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "76\tValidation loss: 3.795681\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "77\tValidation loss: 3.795686\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "78\tValidation loss: 3.795683\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "79\tValidation loss: 3.795678\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "80\tValidation loss: 3.795676\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "81\tValidation loss: 3.795679\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "82\tValidation loss: 3.795677\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "83\tValidation loss: 3.795672\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "84\tValidation loss: 3.795670\tBest loss: 3.795670\tAccuracy: 3.70%\n",
      "85\tValidation loss: 3.795667\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "86\tValidation loss: 3.795673\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "87\tValidation loss: 3.795674\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "88\tValidation loss: 3.795674\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "89\tValidation loss: 3.795674\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "90\tValidation loss: 3.795672\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "91\tValidation loss: 3.795671\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "92\tValidation loss: 3.795668\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "93\tValidation loss: 3.795668\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "94\tValidation loss: 3.795675\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "95\tValidation loss: 3.795673\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "96\tValidation loss: 3.795672\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "97\tValidation loss: 3.795671\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "98\tValidation loss: 3.795668\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "99\tValidation loss: 3.795673\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "100\tValidation loss: 3.795671\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "101\tValidation loss: 3.795672\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "102\tValidation loss: 3.795668\tBest loss: 3.795667\tAccuracy: 3.70%\n",
      "103\tValidation loss: 3.795666\tBest loss: 3.795666\tAccuracy: 3.70%\n",
      "104\tValidation loss: 3.795660\tBest loss: 3.795660\tAccuracy: 3.70%\n",
      "105\tValidation loss: 3.795659\tBest loss: 3.795659\tAccuracy: 3.70%\n",
      "106\tValidation loss: 3.795657\tBest loss: 3.795657\tAccuracy: 3.70%\n",
      "107\tValidation loss: 3.795654\tBest loss: 3.795654\tAccuracy: 3.70%\n",
      "108\tValidation loss: 3.795651\tBest loss: 3.795651\tAccuracy: 3.70%\n",
      "109\tValidation loss: 3.795651\tBest loss: 3.795651\tAccuracy: 3.70%\n",
      "110\tValidation loss: 3.795647\tBest loss: 3.795647\tAccuracy: 3.70%\n",
      "111\tValidation loss: 3.795651\tBest loss: 3.795647\tAccuracy: 3.70%\n",
      "112\tValidation loss: 3.795646\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "113\tValidation loss: 3.795649\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "114\tValidation loss: 3.795651\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "115\tValidation loss: 3.795656\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "116\tValidation loss: 3.795659\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "117\tValidation loss: 3.795658\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "118\tValidation loss: 3.795655\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "119\tValidation loss: 3.795660\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "120\tValidation loss: 3.795659\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "121\tValidation loss: 3.795659\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "122\tValidation loss: 3.795661\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "123\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "124\tValidation loss: 3.795669\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "125\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "126\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "127\tValidation loss: 3.795668\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "128\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "129\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "130\tValidation loss: 3.795666\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "131\tValidation loss: 3.795665\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "132\tValidation loss: 3.795665\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "133\tValidation loss: 3.795663\tBest loss: 3.795646\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " ..., \n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " ..., \n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]\n",
      " [ 0.01685115  0.03274119  0.02267033 ...,  0.02871672  0.01696868\n",
      "   0.01769783]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  49.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.840069\tBest loss: 3.840069\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.819416\tBest loss: 3.819416\tAccuracy: 3.70%\n",
      "2\tValidation loss: 3.809242\tBest loss: 3.809242\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.803798\tBest loss: 3.803798\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.800808\tBest loss: 3.800808\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.799043\tBest loss: 3.799043\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.797939\tBest loss: 3.797939\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.797310\tBest loss: 3.797310\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.796845\tBest loss: 3.796845\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.796487\tBest loss: 3.796487\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.796277\tBest loss: 3.796277\tAccuracy: 3.70%\n",
      "11\tValidation loss: 3.796088\tBest loss: 3.796088\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.795925\tBest loss: 3.795925\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.795851\tBest loss: 3.795851\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.795776\tBest loss: 3.795776\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.795723\tBest loss: 3.795723\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.795680\tBest loss: 3.795680\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.795671\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.795681\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.795689\tBest loss: 3.795671\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.795645\tBest loss: 3.795645\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.795629\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.795645\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.795649\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.795642\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.795652\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.795642\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.795646\tBest loss: 3.795629\tAccuracy: 3.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 3.795644\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.795644\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "30\tValidation loss: 3.795647\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "31\tValidation loss: 3.795660\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.795662\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "33\tValidation loss: 3.795682\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "34\tValidation loss: 3.795688\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "35\tValidation loss: 3.795681\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.795669\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "37\tValidation loss: 3.795673\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.795648\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "39\tValidation loss: 3.795641\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.795650\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.795651\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "42\tValidation loss: 3.795647\tBest loss: 3.795629\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " ..., \n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " ..., \n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]\n",
      " [ 0.0171344   0.03256637  0.02293946 ...,  0.02834248  0.01697676\n",
      "   0.01763833]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=4, n_neurons=200, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=  15.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 13.075946\tBest loss: 13.075946\tAccuracy: 11.40%\n",
      "1\tValidation loss: 13.231866\tBest loss: 13.075946\tAccuracy: 14.00%\n",
      "2\tValidation loss: 11.868441\tBest loss: 11.868441\tAccuracy: 23.00%\n",
      "3\tValidation loss: 10.610250\tBest loss: 10.610250\tAccuracy: 20.90%\n",
      "4\tValidation loss: 9.833286\tBest loss: 9.833286\tAccuracy: 27.80%\n",
      "5\tValidation loss: 9.703427\tBest loss: 9.703427\tAccuracy: 30.10%\n",
      "6\tValidation loss: 6.951606\tBest loss: 6.951606\tAccuracy: 36.70%\n",
      "7\tValidation loss: 7.819804\tBest loss: 6.951606\tAccuracy: 36.80%\n",
      "8\tValidation loss: 7.322677\tBest loss: 6.951606\tAccuracy: 40.80%\n",
      "9\tValidation loss: 8.510206\tBest loss: 6.951606\tAccuracy: 40.80%\n",
      "10\tValidation loss: 8.076225\tBest loss: 6.951606\tAccuracy: 39.10%\n",
      "11\tValidation loss: 5.968988\tBest loss: 5.968988\tAccuracy: 47.60%\n",
      "12\tValidation loss: 6.531114\tBest loss: 5.968988\tAccuracy: 47.90%\n",
      "13\tValidation loss: 6.569458\tBest loss: 5.968988\tAccuracy: 43.60%\n",
      "14\tValidation loss: 5.392407\tBest loss: 5.392407\tAccuracy: 51.40%\n",
      "15\tValidation loss: 6.204354\tBest loss: 5.392407\tAccuracy: 48.40%\n",
      "16\tValidation loss: 3.803120\tBest loss: 3.803120\tAccuracy: 56.60%\n",
      "17\tValidation loss: 7.108688\tBest loss: 3.803120\tAccuracy: 50.20%\n",
      "18\tValidation loss: 3.915403\tBest loss: 3.803120\tAccuracy: 57.10%\n",
      "19\tValidation loss: 3.892381\tBest loss: 3.803120\tAccuracy: 56.40%\n",
      "20\tValidation loss: 5.523626\tBest loss: 3.803120\tAccuracy: 53.90%\n",
      "21\tValidation loss: 3.757025\tBest loss: 3.757025\tAccuracy: 59.30%\n",
      "22\tValidation loss: 6.448692\tBest loss: 3.757025\tAccuracy: 48.00%\n",
      "23\tValidation loss: 5.082375\tBest loss: 3.757025\tAccuracy: 54.10%\n",
      "24\tValidation loss: 4.982319\tBest loss: 3.757025\tAccuracy: 59.20%\n",
      "25\tValidation loss: 4.675362\tBest loss: 3.757025\tAccuracy: 55.10%\n",
      "26\tValidation loss: 3.476193\tBest loss: 3.476193\tAccuracy: 62.40%\n",
      "27\tValidation loss: 5.515753\tBest loss: 3.476193\tAccuracy: 51.60%\n",
      "28\tValidation loss: 3.873518\tBest loss: 3.476193\tAccuracy: 62.90%\n",
      "29\tValidation loss: 5.070327\tBest loss: 3.476193\tAccuracy: 55.40%\n",
      "30\tValidation loss: 4.654073\tBest loss: 3.476193\tAccuracy: 58.10%\n",
      "31\tValidation loss: 5.706188\tBest loss: 3.476193\tAccuracy: 53.10%\n",
      "32\tValidation loss: 4.578452\tBest loss: 3.476193\tAccuracy: 58.70%\n",
      "33\tValidation loss: 3.871296\tBest loss: 3.476193\tAccuracy: 61.20%\n",
      "34\tValidation loss: 2.793931\tBest loss: 2.793931\tAccuracy: 64.70%\n",
      "35\tValidation loss: 2.921724\tBest loss: 2.793931\tAccuracy: 66.30%\n",
      "36\tValidation loss: 4.939944\tBest loss: 2.793931\tAccuracy: 59.70%\n",
      "37\tValidation loss: 5.022450\tBest loss: 2.793931\tAccuracy: 61.70%\n",
      "38\tValidation loss: 4.096801\tBest loss: 2.793931\tAccuracy: 60.50%\n",
      "39\tValidation loss: 5.139521\tBest loss: 2.793931\tAccuracy: 56.70%\n",
      "40\tValidation loss: 5.055524\tBest loss: 2.793931\tAccuracy: 62.90%\n",
      "41\tValidation loss: 7.921808\tBest loss: 2.793931\tAccuracy: 54.90%\n",
      "42\tValidation loss: 4.731001\tBest loss: 2.793931\tAccuracy: 59.70%\n",
      "43\tValidation loss: 6.248921\tBest loss: 2.793931\tAccuracy: 58.20%\n",
      "44\tValidation loss: 6.672671\tBest loss: 2.793931\tAccuracy: 55.70%\n",
      "45\tValidation loss: 6.857732\tBest loss: 2.793931\tAccuracy: 53.60%\n",
      "46\tValidation loss: 4.207164\tBest loss: 2.793931\tAccuracy: 63.40%\n",
      "47\tValidation loss: 4.405850\tBest loss: 2.793931\tAccuracy: 60.80%\n",
      "48\tValidation loss: 3.793347\tBest loss: 2.793931\tAccuracy: 67.10%\n",
      "49\tValidation loss: 5.357716\tBest loss: 2.793931\tAccuracy: 61.40%\n",
      "50\tValidation loss: 4.789460\tBest loss: 2.793931\tAccuracy: 61.60%\n",
      "51\tValidation loss: 4.998255\tBest loss: 2.793931\tAccuracy: 61.70%\n",
      "52\tValidation loss: 2.925869\tBest loss: 2.793931\tAccuracy: 68.30%\n",
      "53\tValidation loss: 4.464173\tBest loss: 2.793931\tAccuracy: 66.60%\n",
      "54\tValidation loss: 3.616571\tBest loss: 2.793931\tAccuracy: 65.10%\n",
      "55\tValidation loss: 5.880451\tBest loss: 2.793931\tAccuracy: 58.30%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   1.25443118e-33   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.15340695e-01   5.49471751e-02   3.83325070e-02 ...,   2.61131767e-03\n",
      "    4.19766828e-03   2.48249457e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.70092444e-05   6.24831446e-05   1.70917573e-08 ...,   5.95068595e-05\n",
      "    3.58130308e-08   2.60879051e-06]\n",
      " [  0.00000000e+00   4.67652146e-35   0.00000000e+00 ...,   5.68381595e-35\n",
      "    3.87339899e-33   1.95699055e-19]]\n",
      "[22 19 16 ...,  6 24 36]\n",
      "[[  1.38668460e-36   1.74887268e-36   1.53743641e-33 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.70955526e-26]\n",
      " [  0.00000000e+00   7.51109724e-35   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.53635372e-35   1.50749975e-25   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.32769463e-16   1.76312859e-16   1.07866658e-25 ...,   0.00000000e+00\n",
      "    5.26422014e-35   8.20339947e-34]\n",
      " [  3.43404897e-02   1.88970808e-02   1.26550822e-02 ...,   1.00764623e-02\n",
      "    1.51950074e-02   8.52907449e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   8.55987088e-34\n",
      "    3.57136429e-18   1.00000000e+00]]\n",
      "[43 43 43 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   2.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 14.364122\tBest loss: 14.364122\tAccuracy: 8.00%\n",
      "1\tValidation loss: 13.412793\tBest loss: 13.412793\tAccuracy: 15.10%\n",
      "2\tValidation loss: 13.095148\tBest loss: 13.095148\tAccuracy: 18.40%\n",
      "3\tValidation loss: 9.717276\tBest loss: 9.717276\tAccuracy: 24.40%\n",
      "4\tValidation loss: 8.104632\tBest loss: 8.104632\tAccuracy: 26.90%\n",
      "5\tValidation loss: 10.807630\tBest loss: 8.104632\tAccuracy: 27.80%\n",
      "6\tValidation loss: 7.593039\tBest loss: 7.593039\tAccuracy: 38.70%\n",
      "7\tValidation loss: 8.623610\tBest loss: 7.593039\tAccuracy: 36.10%\n",
      "8\tValidation loss: 6.450252\tBest loss: 6.450252\tAccuracy: 43.50%\n",
      "9\tValidation loss: 6.518332\tBest loss: 6.450252\tAccuracy: 39.60%\n",
      "10\tValidation loss: 5.590674\tBest loss: 5.590674\tAccuracy: 49.80%\n",
      "11\tValidation loss: 8.605344\tBest loss: 5.590674\tAccuracy: 42.20%\n",
      "12\tValidation loss: 6.467073\tBest loss: 5.590674\tAccuracy: 47.90%\n",
      "13\tValidation loss: 6.582808\tBest loss: 5.590674\tAccuracy: 46.40%\n",
      "14\tValidation loss: 6.435370\tBest loss: 5.590674\tAccuracy: 47.80%\n",
      "15\tValidation loss: 4.860127\tBest loss: 4.860127\tAccuracy: 50.40%\n",
      "16\tValidation loss: 6.209484\tBest loss: 4.860127\tAccuracy: 50.90%\n",
      "17\tValidation loss: 4.541859\tBest loss: 4.541859\tAccuracy: 54.50%\n",
      "18\tValidation loss: 5.871251\tBest loss: 4.541859\tAccuracy: 51.70%\n",
      "19\tValidation loss: 6.569729\tBest loss: 4.541859\tAccuracy: 50.90%\n",
      "20\tValidation loss: 5.756474\tBest loss: 4.541859\tAccuracy: 51.00%\n",
      "21\tValidation loss: 5.782108\tBest loss: 4.541859\tAccuracy: 55.80%\n",
      "22\tValidation loss: 4.399861\tBest loss: 4.399861\tAccuracy: 58.50%\n",
      "23\tValidation loss: 4.688329\tBest loss: 4.399861\tAccuracy: 57.80%\n",
      "24\tValidation loss: 4.420069\tBest loss: 4.399861\tAccuracy: 57.80%\n",
      "25\tValidation loss: 6.124452\tBest loss: 4.399861\tAccuracy: 55.60%\n",
      "26\tValidation loss: 3.653663\tBest loss: 3.653663\tAccuracy: 61.10%\n",
      "27\tValidation loss: 3.238240\tBest loss: 3.238240\tAccuracy: 62.10%\n",
      "28\tValidation loss: 3.473486\tBest loss: 3.238240\tAccuracy: 62.30%\n",
      "29\tValidation loss: 6.365809\tBest loss: 3.238240\tAccuracy: 55.40%\n",
      "30\tValidation loss: 4.563926\tBest loss: 3.238240\tAccuracy: 58.80%\n",
      "31\tValidation loss: 3.888085\tBest loss: 3.238240\tAccuracy: 63.00%\n",
      "32\tValidation loss: 5.406080\tBest loss: 3.238240\tAccuracy: 55.40%\n",
      "33\tValidation loss: 3.868716\tBest loss: 3.238240\tAccuracy: 62.20%\n",
      "34\tValidation loss: 4.268366\tBest loss: 3.238240\tAccuracy: 60.30%\n",
      "35\tValidation loss: 5.517788\tBest loss: 3.238240\tAccuracy: 56.50%\n",
      "36\tValidation loss: 5.277663\tBest loss: 3.238240\tAccuracy: 55.40%\n",
      "37\tValidation loss: 4.955929\tBest loss: 3.238240\tAccuracy: 62.40%\n",
      "38\tValidation loss: 3.777707\tBest loss: 3.238240\tAccuracy: 64.30%\n",
      "39\tValidation loss: 3.940822\tBest loss: 3.238240\tAccuracy: 62.80%\n",
      "40\tValidation loss: 5.298998\tBest loss: 3.238240\tAccuracy: 64.90%\n",
      "41\tValidation loss: 3.665260\tBest loss: 3.238240\tAccuracy: 66.00%\n",
      "42\tValidation loss: 3.523453\tBest loss: 3.238240\tAccuracy: 64.30%\n",
      "43\tValidation loss: 4.324475\tBest loss: 3.238240\tAccuracy: 64.30%\n",
      "44\tValidation loss: 3.499735\tBest loss: 3.238240\tAccuracy: 66.00%\n",
      "45\tValidation loss: 2.930838\tBest loss: 2.930838\tAccuracy: 69.00%\n",
      "46\tValidation loss: 3.769991\tBest loss: 2.930838\tAccuracy: 67.20%\n",
      "47\tValidation loss: 4.154391\tBest loss: 2.930838\tAccuracy: 63.20%\n",
      "48\tValidation loss: 3.710280\tBest loss: 2.930838\tAccuracy: 64.60%\n",
      "49\tValidation loss: 5.338522\tBest loss: 2.930838\tAccuracy: 61.50%\n",
      "50\tValidation loss: 3.888257\tBest loss: 2.930838\tAccuracy: 62.70%\n",
      "51\tValidation loss: 4.460395\tBest loss: 2.930838\tAccuracy: 62.10%\n",
      "52\tValidation loss: 4.410949\tBest loss: 2.930838\tAccuracy: 65.30%\n",
      "53\tValidation loss: 4.605743\tBest loss: 2.930838\tAccuracy: 60.40%\n",
      "54\tValidation loss: 4.010981\tBest loss: 2.930838\tAccuracy: 65.00%\n",
      "55\tValidation loss: 3.732762\tBest loss: 2.930838\tAccuracy: 67.70%\n",
      "56\tValidation loss: 5.529788\tBest loss: 2.930838\tAccuracy: 59.10%\n",
      "57\tValidation loss: 5.738031\tBest loss: 2.930838\tAccuracy: 63.30%\n",
      "58\tValidation loss: 4.229513\tBest loss: 2.930838\tAccuracy: 64.70%\n",
      "59\tValidation loss: 3.693920\tBest loss: 2.930838\tAccuracy: 68.90%\n",
      "60\tValidation loss: 4.637500\tBest loss: 2.930838\tAccuracy: 63.20%\n",
      "61\tValidation loss: 3.832266\tBest loss: 2.930838\tAccuracy: 68.00%\n",
      "62\tValidation loss: 3.628421\tBest loss: 2.930838\tAccuracy: 64.90%\n",
      "63\tValidation loss: 3.005472\tBest loss: 2.930838\tAccuracy: 68.30%\n",
      "64\tValidation loss: 3.476026\tBest loss: 2.930838\tAccuracy: 67.50%\n",
      "65\tValidation loss: 3.112465\tBest loss: 2.930838\tAccuracy: 69.90%\n",
      "66\tValidation loss: 3.755996\tBest loss: 2.930838\tAccuracy: 68.10%\n",
      "Early stopping!\n",
      "[[  4.34379739e-34   2.31212636e-35   2.51624351e-18 ...,   0.00000000e+00\n",
      "    1.83320338e-30   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.33974247e-29   1.12017243e-24   0.00000000e+00 ...,   3.69735380e-37\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.06485673e-16   7.86434112e-12   3.92693834e-15 ...,   2.05365211e-10\n",
      "    3.80927711e-12   8.63298677e-09]\n",
      " [  4.75027227e-17   1.44100792e-16   7.87964444e-24 ...,   7.30024185e-04\n",
      "    5.47412888e-08   5.62735547e-09]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   3.56005215e-36\n",
      "    8.47423531e-38   1.81541639e-18]]\n",
      "[43 43 43 ..., 36  6 38]\n",
      "[[  0.00000000e+00   1.23508989e-38   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.59167752e-01   4.67130132e-02   6.86667562e-02 ...,   1.28019101e-03\n",
      "    1.77538872e-03   1.04395649e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   1.53251184e-34 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.69686047e-19   6.44281673e-20   4.37259573e-23 ...,   0.00000000e+00\n",
      "    4.28282987e-35   0.00000000e+00]\n",
      " [  3.22925225e-02   2.39165425e-02   1.76417492e-02 ...,   4.50031320e-03\n",
      "    1.79858580e-02   5.69752837e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   2.06001008e-35\n",
      "    1.02497676e-22   1.00000000e+00]]\n",
      "[20  0 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   3.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 13.103864\tBest loss: 13.103864\tAccuracy: 12.10%\n",
      "1\tValidation loss: 11.868806\tBest loss: 11.868806\tAccuracy: 18.40%\n",
      "2\tValidation loss: 9.767289\tBest loss: 9.767289\tAccuracy: 23.00%\n",
      "3\tValidation loss: 12.262579\tBest loss: 9.767289\tAccuracy: 22.80%\n",
      "4\tValidation loss: 8.213530\tBest loss: 8.213530\tAccuracy: 34.60%\n",
      "5\tValidation loss: 8.810670\tBest loss: 8.213530\tAccuracy: 29.00%\n",
      "6\tValidation loss: 7.643303\tBest loss: 7.643303\tAccuracy: 39.00%\n",
      "7\tValidation loss: 8.808973\tBest loss: 7.643303\tAccuracy: 35.90%\n",
      "8\tValidation loss: 8.306039\tBest loss: 7.643303\tAccuracy: 39.70%\n",
      "9\tValidation loss: 6.281837\tBest loss: 6.281837\tAccuracy: 42.90%\n",
      "10\tValidation loss: 7.522102\tBest loss: 6.281837\tAccuracy: 43.20%\n",
      "11\tValidation loss: 4.524758\tBest loss: 4.524758\tAccuracy: 53.50%\n",
      "12\tValidation loss: 7.924665\tBest loss: 4.524758\tAccuracy: 42.60%\n",
      "13\tValidation loss: 6.891617\tBest loss: 4.524758\tAccuracy: 45.50%\n",
      "14\tValidation loss: 6.490024\tBest loss: 4.524758\tAccuracy: 48.10%\n",
      "15\tValidation loss: 4.380130\tBest loss: 4.380130\tAccuracy: 53.30%\n",
      "16\tValidation loss: 7.841534\tBest loss: 4.380130\tAccuracy: 46.60%\n",
      "17\tValidation loss: 5.898426\tBest loss: 4.380130\tAccuracy: 52.00%\n",
      "18\tValidation loss: 4.052577\tBest loss: 4.052577\tAccuracy: 58.30%\n",
      "19\tValidation loss: 5.724973\tBest loss: 4.052577\tAccuracy: 53.90%\n",
      "20\tValidation loss: 5.003976\tBest loss: 4.052577\tAccuracy: 56.20%\n",
      "21\tValidation loss: 5.786992\tBest loss: 4.052577\tAccuracy: 54.90%\n",
      "22\tValidation loss: 3.784641\tBest loss: 3.784641\tAccuracy: 61.30%\n",
      "23\tValidation loss: 4.954760\tBest loss: 3.784641\tAccuracy: 56.80%\n",
      "24\tValidation loss: 5.532056\tBest loss: 3.784641\tAccuracy: 54.30%\n",
      "25\tValidation loss: 4.076295\tBest loss: 3.784641\tAccuracy: 58.30%\n",
      "26\tValidation loss: 6.300664\tBest loss: 3.784641\tAccuracy: 52.30%\n",
      "27\tValidation loss: 4.570465\tBest loss: 3.784641\tAccuracy: 58.40%\n",
      "28\tValidation loss: 5.267852\tBest loss: 3.784641\tAccuracy: 54.50%\n",
      "29\tValidation loss: 6.135912\tBest loss: 3.784641\tAccuracy: 56.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\tValidation loss: 4.445715\tBest loss: 3.784641\tAccuracy: 57.70%\n",
      "31\tValidation loss: 6.186139\tBest loss: 3.784641\tAccuracy: 57.10%\n",
      "32\tValidation loss: 4.117007\tBest loss: 3.784641\tAccuracy: 57.20%\n",
      "33\tValidation loss: 3.548671\tBest loss: 3.548671\tAccuracy: 63.20%\n",
      "34\tValidation loss: 5.930230\tBest loss: 3.548671\tAccuracy: 53.70%\n",
      "35\tValidation loss: 6.886022\tBest loss: 3.548671\tAccuracy: 57.30%\n",
      "36\tValidation loss: 3.887046\tBest loss: 3.548671\tAccuracy: 62.80%\n",
      "37\tValidation loss: 3.998037\tBest loss: 3.548671\tAccuracy: 64.70%\n",
      "38\tValidation loss: 4.088383\tBest loss: 3.548671\tAccuracy: 61.10%\n",
      "39\tValidation loss: 3.593956\tBest loss: 3.548671\tAccuracy: 66.70%\n",
      "40\tValidation loss: 5.544501\tBest loss: 3.548671\tAccuracy: 58.60%\n",
      "41\tValidation loss: 5.253602\tBest loss: 3.548671\tAccuracy: 59.70%\n",
      "42\tValidation loss: 5.835666\tBest loss: 3.548671\tAccuracy: 59.20%\n",
      "43\tValidation loss: 4.381659\tBest loss: 3.548671\tAccuracy: 63.80%\n",
      "44\tValidation loss: 4.456039\tBest loss: 3.548671\tAccuracy: 60.60%\n",
      "45\tValidation loss: 3.300768\tBest loss: 3.300768\tAccuracy: 66.90%\n",
      "46\tValidation loss: 3.930104\tBest loss: 3.300768\tAccuracy: 62.90%\n",
      "47\tValidation loss: 2.417257\tBest loss: 2.417257\tAccuracy: 70.70%\n",
      "48\tValidation loss: 3.207308\tBest loss: 2.417257\tAccuracy: 66.00%\n",
      "49\tValidation loss: 5.474857\tBest loss: 2.417257\tAccuracy: 61.40%\n",
      "50\tValidation loss: 4.520842\tBest loss: 2.417257\tAccuracy: 59.10%\n",
      "51\tValidation loss: 3.460042\tBest loss: 2.417257\tAccuracy: 68.50%\n",
      "52\tValidation loss: 2.786897\tBest loss: 2.417257\tAccuracy: 70.40%\n",
      "53\tValidation loss: 3.437294\tBest loss: 2.417257\tAccuracy: 66.80%\n",
      "54\tValidation loss: 4.011004\tBest loss: 2.417257\tAccuracy: 66.10%\n",
      "55\tValidation loss: 5.482590\tBest loss: 2.417257\tAccuracy: 61.00%\n",
      "56\tValidation loss: 4.380223\tBest loss: 2.417257\tAccuracy: 64.60%\n",
      "57\tValidation loss: 4.720992\tBest loss: 2.417257\tAccuracy: 65.10%\n",
      "58\tValidation loss: 5.285871\tBest loss: 2.417257\tAccuracy: 62.90%\n",
      "59\tValidation loss: 2.917038\tBest loss: 2.417257\tAccuracy: 68.70%\n",
      "60\tValidation loss: 4.396825\tBest loss: 2.417257\tAccuracy: 65.70%\n",
      "61\tValidation loss: 3.579756\tBest loss: 2.417257\tAccuracy: 68.90%\n",
      "62\tValidation loss: 4.771158\tBest loss: 2.417257\tAccuracy: 62.40%\n",
      "63\tValidation loss: 5.071733\tBest loss: 2.417257\tAccuracy: 63.40%\n",
      "64\tValidation loss: 3.387409\tBest loss: 2.417257\tAccuracy: 69.90%\n",
      "65\tValidation loss: 3.037355\tBest loss: 2.417257\tAccuracy: 70.40%\n",
      "66\tValidation loss: 4.894656\tBest loss: 2.417257\tAccuracy: 62.60%\n",
      "67\tValidation loss: 3.994806\tBest loss: 2.417257\tAccuracy: 65.10%\n",
      "68\tValidation loss: 3.052039\tBest loss: 2.417257\tAccuracy: 70.30%\n",
      "Early stopping!\n",
      "[[  3.21263443e-08   3.32000877e-06   4.17493567e-10 ...,   1.50445189e-07\n",
      "    2.82395524e-17   1.94115060e-07]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.29560007e-31   2.00013787e-26   5.09022883e-15 ...,   1.10195625e-31\n",
      "    9.20703675e-27   5.11338740e-08]\n",
      " ..., \n",
      " [  2.42945739e-25   9.88619837e-20   9.34819815e-24 ...,   0.00000000e+00\n",
      "    8.35283926e-37   8.90594365e-37]\n",
      " [  2.58052591e-02   2.76341438e-02   8.42540618e-03 ...,   6.34881388e-03\n",
      "    1.85614657e-02   9.04561765e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   2.11639107e-33\n",
      "    2.60994325e-21   1.00000000e+00]]\n",
      "[41 41 20 ...,  6  9 47]\n",
      "[[  0.00000000e+00   1.96730870e-37   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.52793476e-02   8.31614286e-02   5.83570041e-02 ...,   2.27732048e-03\n",
      "    2.44707451e-03   1.49632897e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  5.71574392e-17   3.50282825e-08   2.92881990e-17 ...,   4.48897391e-10\n",
      "    1.74875203e-09   4.21407307e-03]\n",
      " [  1.68911251e-26   5.52557890e-18   3.51587752e-33 ...,   2.27697949e-08\n",
      "    5.64550204e-14   1.14757214e-11]\n",
      " [  0.00000000e+00   3.48134246e-38   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.67292100e-11]]\n",
      "[20 19 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   3.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.482341\tBest loss: 3.482341\tAccuracy: 10.90%\n",
      "1\tValidation loss: 3.135854\tBest loss: 3.135854\tAccuracy: 21.20%\n",
      "2\tValidation loss: 2.895857\tBest loss: 2.895857\tAccuracy: 25.50%\n",
      "3\tValidation loss: 2.759528\tBest loss: 2.759528\tAccuracy: 29.90%\n",
      "4\tValidation loss: 2.609224\tBest loss: 2.609224\tAccuracy: 30.90%\n",
      "5\tValidation loss: 2.500574\tBest loss: 2.500574\tAccuracy: 34.00%\n",
      "6\tValidation loss: 2.385375\tBest loss: 2.385375\tAccuracy: 35.90%\n",
      "7\tValidation loss: 2.336340\tBest loss: 2.336340\tAccuracy: 38.00%\n",
      "8\tValidation loss: 2.264049\tBest loss: 2.264049\tAccuracy: 39.70%\n",
      "9\tValidation loss: 2.246742\tBest loss: 2.246742\tAccuracy: 39.40%\n",
      "10\tValidation loss: 2.162222\tBest loss: 2.162222\tAccuracy: 43.20%\n",
      "11\tValidation loss: 2.116605\tBest loss: 2.116605\tAccuracy: 43.60%\n",
      "12\tValidation loss: 2.102005\tBest loss: 2.102005\tAccuracy: 42.70%\n",
      "13\tValidation loss: 2.053227\tBest loss: 2.053227\tAccuracy: 45.60%\n",
      "14\tValidation loss: 2.052865\tBest loss: 2.052865\tAccuracy: 45.40%\n",
      "15\tValidation loss: 2.018136\tBest loss: 2.018136\tAccuracy: 46.10%\n",
      "16\tValidation loss: 2.010733\tBest loss: 2.010733\tAccuracy: 46.90%\n",
      "17\tValidation loss: 1.990924\tBest loss: 1.990924\tAccuracy: 48.20%\n",
      "18\tValidation loss: 1.949113\tBest loss: 1.949113\tAccuracy: 49.20%\n",
      "19\tValidation loss: 1.950130\tBest loss: 1.949113\tAccuracy: 49.40%\n",
      "20\tValidation loss: 1.923478\tBest loss: 1.923478\tAccuracy: 49.80%\n",
      "21\tValidation loss: 1.918037\tBest loss: 1.918037\tAccuracy: 50.50%\n",
      "22\tValidation loss: 1.914456\tBest loss: 1.914456\tAccuracy: 52.10%\n",
      "23\tValidation loss: 1.900377\tBest loss: 1.900377\tAccuracy: 52.30%\n",
      "24\tValidation loss: 1.903550\tBest loss: 1.900377\tAccuracy: 52.00%\n",
      "25\tValidation loss: 1.875030\tBest loss: 1.875030\tAccuracy: 53.40%\n",
      "26\tValidation loss: 1.888209\tBest loss: 1.875030\tAccuracy: 53.20%\n",
      "27\tValidation loss: 1.892107\tBest loss: 1.875030\tAccuracy: 54.20%\n",
      "28\tValidation loss: 1.883034\tBest loss: 1.875030\tAccuracy: 53.40%\n",
      "29\tValidation loss: 1.880260\tBest loss: 1.875030\tAccuracy: 54.20%\n",
      "30\tValidation loss: 1.871988\tBest loss: 1.871988\tAccuracy: 55.60%\n",
      "31\tValidation loss: 1.880616\tBest loss: 1.871988\tAccuracy: 54.60%\n",
      "32\tValidation loss: 1.891657\tBest loss: 1.871988\tAccuracy: 55.30%\n",
      "33\tValidation loss: 1.885602\tBest loss: 1.871988\tAccuracy: 55.40%\n",
      "34\tValidation loss: 1.913794\tBest loss: 1.871988\tAccuracy: 55.20%\n",
      "35\tValidation loss: 1.885715\tBest loss: 1.871988\tAccuracy: 56.40%\n",
      "36\tValidation loss: 1.881525\tBest loss: 1.871988\tAccuracy: 56.30%\n",
      "37\tValidation loss: 1.918957\tBest loss: 1.871988\tAccuracy: 55.90%\n",
      "38\tValidation loss: 1.930108\tBest loss: 1.871988\tAccuracy: 56.20%\n",
      "39\tValidation loss: 1.874751\tBest loss: 1.871988\tAccuracy: 56.60%\n",
      "40\tValidation loss: 1.921942\tBest loss: 1.871988\tAccuracy: 56.40%\n",
      "41\tValidation loss: 1.922217\tBest loss: 1.871988\tAccuracy: 56.20%\n",
      "42\tValidation loss: 1.924306\tBest loss: 1.871988\tAccuracy: 56.20%\n",
      "43\tValidation loss: 1.913977\tBest loss: 1.871988\tAccuracy: 57.00%\n",
      "44\tValidation loss: 1.932999\tBest loss: 1.871988\tAccuracy: 57.10%\n",
      "45\tValidation loss: 1.940949\tBest loss: 1.871988\tAccuracy: 56.10%\n",
      "46\tValidation loss: 1.951442\tBest loss: 1.871988\tAccuracy: 57.10%\n",
      "47\tValidation loss: 1.958611\tBest loss: 1.871988\tAccuracy: 57.40%\n",
      "48\tValidation loss: 1.953094\tBest loss: 1.871988\tAccuracy: 56.90%\n",
      "49\tValidation loss: 1.940224\tBest loss: 1.871988\tAccuracy: 57.70%\n",
      "50\tValidation loss: 1.959565\tBest loss: 1.871988\tAccuracy: 57.80%\n",
      "51\tValidation loss: 1.985228\tBest loss: 1.871988\tAccuracy: 58.40%\n",
      "Early stopping!\n",
      "[[  3.84342081e-14   3.89856858e-09   4.74522635e-12 ...,   3.53932920e-13\n",
      "    1.90957383e-08   1.61162841e-14]\n",
      " [  4.92410883e-02   2.49441266e-02   7.37589672e-02 ...,   4.89842054e-03\n",
      "    2.20223702e-03   3.08166794e-03]\n",
      " [  6.93710562e-20   1.00803346e-29   3.54887220e-07 ...,   5.38794623e-36\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.02206818e-19   1.22685443e-18   1.19111943e-10 ...,   1.03081660e-13\n",
      "    2.42861265e-15   2.82637742e-16]\n",
      " [  2.89592352e-02   3.26360023e-04   6.17573096e-04 ...,   2.91446298e-01\n",
      "    8.36477629e-05   1.54338431e-05]\n",
      " [  1.20453813e-15   1.23453400e-11   8.05171988e-12 ...,   1.41233488e-06\n",
      "    1.56564466e-11   2.44454990e-09]]\n",
      "[22 19 17 ...,  6 45 36]\n",
      "[[  3.17714221e-05   9.53264407e-06   4.71851308e-05 ...,   1.45652491e-04\n",
      "    3.76383741e-06   7.48504181e-06]\n",
      " [  4.90853772e-15   1.48397461e-10   3.13828222e-16 ...,   1.45389129e-16\n",
      "    6.67102312e-15   3.67510011e-14]\n",
      " [  4.77490737e-17   1.05115023e-11   2.46749300e-18 ...,   1.48788590e-15\n",
      "    8.77376050e-17   1.03278332e-11]\n",
      " ..., \n",
      " [  6.88045132e-09   1.44550973e-12   2.16804241e-09 ...,   3.05315611e-18\n",
      "    2.17797002e-23   1.09350599e-18]\n",
      " [  7.92018510e-03   1.30935032e-02   2.60480102e-02 ...,   2.30513569e-02\n",
      "    2.77123842e-02   1.96591616e-02]\n",
      " [  6.23078849e-30   1.66217233e-24   1.23958564e-20 ...,   3.33627526e-09\n",
      "    5.52230980e-04   9.98937070e-01]]\n",
      "[36 43 43 ...,  6 11 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  58.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.370460\tBest loss: 3.370460\tAccuracy: 17.40%\n",
      "1\tValidation loss: 3.078910\tBest loss: 3.078910\tAccuracy: 23.20%\n",
      "2\tValidation loss: 2.888291\tBest loss: 2.888291\tAccuracy: 30.10%\n",
      "3\tValidation loss: 2.819881\tBest loss: 2.819881\tAccuracy: 31.20%\n",
      "4\tValidation loss: 2.649026\tBest loss: 2.649026\tAccuracy: 35.00%\n",
      "5\tValidation loss: 2.570086\tBest loss: 2.570086\tAccuracy: 35.90%\n",
      "6\tValidation loss: 2.487888\tBest loss: 2.487888\tAccuracy: 39.60%\n",
      "7\tValidation loss: 2.417564\tBest loss: 2.417564\tAccuracy: 40.50%\n",
      "8\tValidation loss: 2.356566\tBest loss: 2.356566\tAccuracy: 40.90%\n",
      "9\tValidation loss: 2.326438\tBest loss: 2.326438\tAccuracy: 42.20%\n",
      "10\tValidation loss: 2.269638\tBest loss: 2.269638\tAccuracy: 44.10%\n",
      "11\tValidation loss: 2.230351\tBest loss: 2.230351\tAccuracy: 46.00%\n",
      "12\tValidation loss: 2.214265\tBest loss: 2.214265\tAccuracy: 46.30%\n",
      "13\tValidation loss: 2.169689\tBest loss: 2.169689\tAccuracy: 46.70%\n",
      "14\tValidation loss: 2.158054\tBest loss: 2.158054\tAccuracy: 47.60%\n",
      "15\tValidation loss: 2.147530\tBest loss: 2.147530\tAccuracy: 47.50%\n",
      "16\tValidation loss: 2.111480\tBest loss: 2.111480\tAccuracy: 48.30%\n",
      "17\tValidation loss: 2.099181\tBest loss: 2.099181\tAccuracy: 50.00%\n",
      "18\tValidation loss: 2.046866\tBest loss: 2.046866\tAccuracy: 50.90%\n",
      "19\tValidation loss: 2.038841\tBest loss: 2.038841\tAccuracy: 50.50%\n",
      "20\tValidation loss: 2.052050\tBest loss: 2.038841\tAccuracy: 50.50%\n",
      "21\tValidation loss: 2.053552\tBest loss: 2.038841\tAccuracy: 51.60%\n",
      "22\tValidation loss: 2.010221\tBest loss: 2.010221\tAccuracy: 51.80%\n",
      "23\tValidation loss: 2.002962\tBest loss: 2.002962\tAccuracy: 52.00%\n",
      "24\tValidation loss: 1.991122\tBest loss: 1.991122\tAccuracy: 52.40%\n",
      "25\tValidation loss: 2.008337\tBest loss: 1.991122\tAccuracy: 52.80%\n",
      "26\tValidation loss: 1.982898\tBest loss: 1.982898\tAccuracy: 53.50%\n",
      "27\tValidation loss: 1.983768\tBest loss: 1.982898\tAccuracy: 55.70%\n",
      "28\tValidation loss: 1.969588\tBest loss: 1.969588\tAccuracy: 54.40%\n",
      "29\tValidation loss: 1.968275\tBest loss: 1.968275\tAccuracy: 55.20%\n",
      "30\tValidation loss: 1.995624\tBest loss: 1.968275\tAccuracy: 55.40%\n",
      "31\tValidation loss: 1.978173\tBest loss: 1.968275\tAccuracy: 55.60%\n",
      "32\tValidation loss: 1.960654\tBest loss: 1.960654\tAccuracy: 55.90%\n",
      "33\tValidation loss: 1.974954\tBest loss: 1.960654\tAccuracy: 56.80%\n",
      "34\tValidation loss: 1.981393\tBest loss: 1.960654\tAccuracy: 55.70%\n",
      "35\tValidation loss: 1.966845\tBest loss: 1.960654\tAccuracy: 55.80%\n",
      "36\tValidation loss: 1.976456\tBest loss: 1.960654\tAccuracy: 55.80%\n",
      "37\tValidation loss: 1.972965\tBest loss: 1.960654\tAccuracy: 56.90%\n",
      "38\tValidation loss: 1.952631\tBest loss: 1.952631\tAccuracy: 56.70%\n",
      "39\tValidation loss: 1.973373\tBest loss: 1.952631\tAccuracy: 57.00%\n",
      "40\tValidation loss: 1.966074\tBest loss: 1.952631\tAccuracy: 56.90%\n",
      "41\tValidation loss: 1.949391\tBest loss: 1.949391\tAccuracy: 57.70%\n",
      "42\tValidation loss: 1.965050\tBest loss: 1.949391\tAccuracy: 57.30%\n",
      "43\tValidation loss: 1.956003\tBest loss: 1.949391\tAccuracy: 58.30%\n",
      "44\tValidation loss: 1.960039\tBest loss: 1.949391\tAccuracy: 58.20%\n",
      "45\tValidation loss: 1.958949\tBest loss: 1.949391\tAccuracy: 58.30%\n",
      "46\tValidation loss: 1.972652\tBest loss: 1.949391\tAccuracy: 58.50%\n",
      "47\tValidation loss: 1.965501\tBest loss: 1.949391\tAccuracy: 58.80%\n",
      "48\tValidation loss: 1.980792\tBest loss: 1.949391\tAccuracy: 59.40%\n",
      "49\tValidation loss: 1.996788\tBest loss: 1.949391\tAccuracy: 58.90%\n",
      "50\tValidation loss: 1.985029\tBest loss: 1.949391\tAccuracy: 59.70%\n",
      "51\tValidation loss: 1.990642\tBest loss: 1.949391\tAccuracy: 59.20%\n",
      "52\tValidation loss: 2.009232\tBest loss: 1.949391\tAccuracy: 59.50%\n",
      "53\tValidation loss: 1.992852\tBest loss: 1.949391\tAccuracy: 59.90%\n",
      "54\tValidation loss: 2.005121\tBest loss: 1.949391\tAccuracy: 59.90%\n",
      "55\tValidation loss: 1.998894\tBest loss: 1.949391\tAccuracy: 60.20%\n",
      "56\tValidation loss: 2.010454\tBest loss: 1.949391\tAccuracy: 60.00%\n",
      "57\tValidation loss: 2.010769\tBest loss: 1.949391\tAccuracy: 59.80%\n",
      "58\tValidation loss: 2.028262\tBest loss: 1.949391\tAccuracy: 59.80%\n",
      "59\tValidation loss: 2.040477\tBest loss: 1.949391\tAccuracy: 59.10%\n",
      "60\tValidation loss: 2.026586\tBest loss: 1.949391\tAccuracy: 60.40%\n",
      "61\tValidation loss: 2.016021\tBest loss: 1.949391\tAccuracy: 60.80%\n",
      "62\tValidation loss: 2.005813\tBest loss: 1.949391\tAccuracy: 60.40%\n",
      "Early stopping!\n",
      "[[  1.15060639e-05   2.13309904e-05   1.85200352e-05 ...,   1.98442904e-05\n",
      "    3.70687786e-07   1.46851036e-07]\n",
      " [  1.67931544e-17   1.06035538e-18   8.58132212e-19 ...,   6.10246581e-16\n",
      "    2.16759884e-17   3.31549805e-17]\n",
      " [  4.71745716e-14   7.16100797e-15   1.12735754e-12 ...,   2.89557522e-13\n",
      "    3.50086208e-16   5.69911031e-16]\n",
      " ..., \n",
      " [  1.65695077e-04   1.61317847e-04   6.17711397e-04 ...,   1.68501036e-04\n",
      "    2.42558331e-03   1.08468998e-02]\n",
      " [  8.24380830e-09   1.01650133e-09   1.82577446e-06 ...,   2.14827960e-05\n",
      "    9.21220180e-06   1.47092612e-02]\n",
      " [  5.75097466e-16   5.02128504e-13   1.85402383e-15 ...,   2.07609310e-06\n",
      "    1.01270183e-08   1.08657359e-05]]\n",
      "[38 43 43 ..., 36 25 27]\n",
      "[[  2.55941725e-13   2.21277857e-13   3.87463490e-15 ...,   3.25920874e-17\n",
      "    2.75465263e-12   1.00421236e-18]\n",
      " [  1.05067745e-01   3.93569991e-02   1.05926827e-01 ...,   3.40288668e-03\n",
      "    4.97013750e-03   8.81448388e-04]\n",
      " [  1.21936956e-19   2.65537286e-35   1.70775964e-13 ...,   3.68937770e-35\n",
      "    3.40867847e-37   0.00000000e+00]\n",
      " ..., \n",
      " [  5.20283593e-15   1.05861475e-14   5.41169106e-12 ...,   3.27889483e-24\n",
      "    4.15315955e-23   8.68011880e-26]\n",
      " [  1.59270484e-02   1.21625466e-02   4.60428968e-02 ...,   1.06999213e-02\n",
      "    3.35048698e-02   1.46033512e-02]\n",
      " [  3.82685064e-30   2.15456525e-26   1.33629301e-22 ...,   1.31810714e-15\n",
      "    2.97090999e-04   9.95274544e-01]]\n",
      "[20 19 16 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total= 1.2min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.530994\tBest loss: 3.530994\tAccuracy: 15.70%\n",
      "1\tValidation loss: 3.197056\tBest loss: 3.197056\tAccuracy: 20.20%\n",
      "2\tValidation loss: 2.982697\tBest loss: 2.982697\tAccuracy: 25.00%\n",
      "3\tValidation loss: 2.833611\tBest loss: 2.833611\tAccuracy: 27.90%\n",
      "4\tValidation loss: 2.699414\tBest loss: 2.699414\tAccuracy: 31.20%\n",
      "5\tValidation loss: 2.554499\tBest loss: 2.554499\tAccuracy: 33.90%\n",
      "6\tValidation loss: 2.501032\tBest loss: 2.501032\tAccuracy: 36.30%\n",
      "7\tValidation loss: 2.397357\tBest loss: 2.397357\tAccuracy: 38.20%\n",
      "8\tValidation loss: 2.335618\tBest loss: 2.335618\tAccuracy: 39.20%\n",
      "9\tValidation loss: 2.274705\tBest loss: 2.274705\tAccuracy: 41.50%\n",
      "10\tValidation loss: 2.230930\tBest loss: 2.230930\tAccuracy: 42.40%\n",
      "11\tValidation loss: 2.172270\tBest loss: 2.172270\tAccuracy: 45.30%\n",
      "12\tValidation loss: 2.158293\tBest loss: 2.158293\tAccuracy: 46.20%\n",
      "13\tValidation loss: 2.144990\tBest loss: 2.144990\tAccuracy: 46.00%\n",
      "14\tValidation loss: 2.088955\tBest loss: 2.088955\tAccuracy: 47.60%\n",
      "15\tValidation loss: 2.108003\tBest loss: 2.088955\tAccuracy: 46.80%\n",
      "16\tValidation loss: 2.072467\tBest loss: 2.072467\tAccuracy: 47.80%\n",
      "17\tValidation loss: 2.060335\tBest loss: 2.060335\tAccuracy: 48.60%\n",
      "18\tValidation loss: 2.027747\tBest loss: 2.027747\tAccuracy: 49.70%\n",
      "19\tValidation loss: 2.012946\tBest loss: 2.012946\tAccuracy: 49.10%\n",
      "20\tValidation loss: 2.013264\tBest loss: 2.012946\tAccuracy: 50.30%\n",
      "21\tValidation loss: 1.999676\tBest loss: 1.999676\tAccuracy: 51.20%\n",
      "22\tValidation loss: 2.000816\tBest loss: 1.999676\tAccuracy: 51.90%\n",
      "23\tValidation loss: 1.994796\tBest loss: 1.994796\tAccuracy: 51.20%\n",
      "24\tValidation loss: 1.977628\tBest loss: 1.977628\tAccuracy: 52.20%\n",
      "25\tValidation loss: 1.992016\tBest loss: 1.977628\tAccuracy: 52.90%\n",
      "26\tValidation loss: 1.987784\tBest loss: 1.977628\tAccuracy: 53.50%\n",
      "27\tValidation loss: 1.971592\tBest loss: 1.971592\tAccuracy: 54.30%\n",
      "28\tValidation loss: 2.021411\tBest loss: 1.971592\tAccuracy: 54.20%\n",
      "29\tValidation loss: 2.002488\tBest loss: 1.971592\tAccuracy: 54.10%\n",
      "30\tValidation loss: 2.002017\tBest loss: 1.971592\tAccuracy: 54.50%\n",
      "31\tValidation loss: 2.005414\tBest loss: 1.971592\tAccuracy: 53.90%\n",
      "32\tValidation loss: 2.010856\tBest loss: 1.971592\tAccuracy: 55.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\tValidation loss: 2.011768\tBest loss: 1.971592\tAccuracy: 55.50%\n",
      "34\tValidation loss: 2.002476\tBest loss: 1.971592\tAccuracy: 56.80%\n",
      "35\tValidation loss: 2.013453\tBest loss: 1.971592\tAccuracy: 55.50%\n",
      "36\tValidation loss: 2.006655\tBest loss: 1.971592\tAccuracy: 57.20%\n",
      "37\tValidation loss: 2.002794\tBest loss: 1.971592\tAccuracy: 56.10%\n",
      "38\tValidation loss: 2.006773\tBest loss: 1.971592\tAccuracy: 57.80%\n",
      "39\tValidation loss: 2.029061\tBest loss: 1.971592\tAccuracy: 57.30%\n",
      "40\tValidation loss: 2.019831\tBest loss: 1.971592\tAccuracy: 57.50%\n",
      "41\tValidation loss: 2.038043\tBest loss: 1.971592\tAccuracy: 58.10%\n",
      "42\tValidation loss: 2.037844\tBest loss: 1.971592\tAccuracy: 58.20%\n",
      "43\tValidation loss: 2.051048\tBest loss: 1.971592\tAccuracy: 58.00%\n",
      "44\tValidation loss: 2.054882\tBest loss: 1.971592\tAccuracy: 58.50%\n",
      "45\tValidation loss: 2.049739\tBest loss: 1.971592\tAccuracy: 59.10%\n",
      "46\tValidation loss: 2.072845\tBest loss: 1.971592\tAccuracy: 58.70%\n",
      "47\tValidation loss: 2.099413\tBest loss: 1.971592\tAccuracy: 59.10%\n",
      "48\tValidation loss: 2.093896\tBest loss: 1.971592\tAccuracy: 59.50%\n",
      "Early stopping!\n",
      "[[  3.38329352e-04   7.24432874e-04   1.35593605e-03 ...,   3.26502277e-03\n",
      "    4.32879257e-04   1.08517450e-03]\n",
      " [  4.05717065e-20   1.08518116e-16   4.27217716e-16 ...,   1.39527550e-12\n",
      "    4.40607863e-11   7.35384045e-11]\n",
      " [  4.37921175e-04   4.25929809e-03   1.61320362e-02 ...,   3.51762748e-04\n",
      "    5.71079028e-04   3.83529393e-03]\n",
      " ..., \n",
      " [  1.11657448e-06   1.71801878e-10   7.17159381e-08 ...,   3.72271827e-15\n",
      "    3.77005447e-13   1.86594836e-14]\n",
      " [  3.70193273e-02   2.12914571e-02   2.38958858e-02 ...,   1.90743860e-02\n",
      "    2.36926824e-02   2.11638995e-02]\n",
      " [  5.81574702e-23   2.23424917e-21   5.69040221e-28 ...,   9.93271784e-12\n",
      "    6.22232095e-04   8.44770133e-01]]\n",
      "[15 41 20 ...,  6 37 47]\n",
      "[[  8.06266338e-12   2.27021310e-12   2.02710418e-11 ...,   8.09418938e-12\n",
      "    9.68506608e-10   1.79333306e-12]\n",
      " [  1.01695277e-01   6.35570884e-02   6.76603168e-02 ...,   1.04818214e-02\n",
      "    7.08742905e-03   4.44118446e-03]\n",
      " [  5.90787076e-13   8.17951652e-21   1.09092634e-05 ...,   1.72962514e-33\n",
      "    6.53753240e-32   0.00000000e+00]\n",
      " ..., \n",
      " [  4.07445586e-05   4.49461193e-04   9.66863590e-05 ...,   1.86995219e-03\n",
      "    3.19791026e-02   6.60086870e-02]\n",
      " [  1.19161848e-06   1.95257556e-07   5.77252081e-07 ...,   3.79252359e-02\n",
      "    3.50860995e-03   2.34988526e-01]\n",
      " [  8.47601243e-12   6.36247444e-11   1.17007185e-12 ...,   1.87604621e-06\n",
      "    5.15172516e-10   1.70531348e-05]]\n",
      "[20  0 16 ..., 36 25 25]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=10, dropout_rate=None, n_hidden_layers=3, n_neurons=100, learning_rate=0.01, activation=<function relu at 0x000002EE6B242400>, total=  55.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 45.580605\tBest loss: 45.580605\tAccuracy: 24.90%\n",
      "1\tValidation loss: 19.196672\tBest loss: 19.196672\tAccuracy: 40.40%\n",
      "2\tValidation loss: 11.368406\tBest loss: 11.368406\tAccuracy: 49.10%\n",
      "3\tValidation loss: 8.616147\tBest loss: 8.616147\tAccuracy: 52.80%\n",
      "4\tValidation loss: 6.689987\tBest loss: 6.689987\tAccuracy: 57.40%\n",
      "5\tValidation loss: 7.089785\tBest loss: 6.689987\tAccuracy: 59.30%\n",
      "6\tValidation loss: 6.156809\tBest loss: 6.156809\tAccuracy: 59.50%\n",
      "7\tValidation loss: 7.001291\tBest loss: 6.156809\tAccuracy: 60.30%\n",
      "8\tValidation loss: 5.543439\tBest loss: 5.543439\tAccuracy: 60.20%\n",
      "9\tValidation loss: 6.078769\tBest loss: 5.543439\tAccuracy: 61.10%\n",
      "10\tValidation loss: 5.781901\tBest loss: 5.543439\tAccuracy: 62.10%\n",
      "11\tValidation loss: 5.594311\tBest loss: 5.543439\tAccuracy: 62.70%\n",
      "12\tValidation loss: 5.611159\tBest loss: 5.543439\tAccuracy: 62.50%\n",
      "13\tValidation loss: 5.813344\tBest loss: 5.543439\tAccuracy: 61.80%\n",
      "14\tValidation loss: 6.346197\tBest loss: 5.543439\tAccuracy: 63.00%\n",
      "15\tValidation loss: 6.040736\tBest loss: 5.543439\tAccuracy: 64.30%\n",
      "16\tValidation loss: 5.828888\tBest loss: 5.543439\tAccuracy: 62.70%\n",
      "17\tValidation loss: 8.220554\tBest loss: 5.543439\tAccuracy: 58.90%\n",
      "18\tValidation loss: 6.628849\tBest loss: 5.543439\tAccuracy: 63.30%\n",
      "19\tValidation loss: 6.713942\tBest loss: 5.543439\tAccuracy: 61.30%\n",
      "20\tValidation loss: 4.610735\tBest loss: 4.610735\tAccuracy: 67.80%\n",
      "21\tValidation loss: 6.334336\tBest loss: 4.610735\tAccuracy: 63.30%\n",
      "22\tValidation loss: 7.553367\tBest loss: 4.610735\tAccuracy: 62.10%\n",
      "23\tValidation loss: 6.832635\tBest loss: 4.610735\tAccuracy: 65.10%\n",
      "24\tValidation loss: 7.269211\tBest loss: 4.610735\tAccuracy: 65.80%\n",
      "25\tValidation loss: 6.063204\tBest loss: 4.610735\tAccuracy: 66.40%\n",
      "26\tValidation loss: 6.568548\tBest loss: 4.610735\tAccuracy: 63.40%\n",
      "27\tValidation loss: 6.454412\tBest loss: 4.610735\tAccuracy: 65.30%\n",
      "28\tValidation loss: 5.860743\tBest loss: 4.610735\tAccuracy: 67.20%\n",
      "29\tValidation loss: 7.293231\tBest loss: 4.610735\tAccuracy: 64.60%\n",
      "30\tValidation loss: 6.644214\tBest loss: 4.610735\tAccuracy: 66.10%\n",
      "31\tValidation loss: 6.562508\tBest loss: 4.610735\tAccuracy: 67.70%\n",
      "32\tValidation loss: 6.677976\tBest loss: 4.610735\tAccuracy: 64.80%\n",
      "33\tValidation loss: 6.277303\tBest loss: 4.610735\tAccuracy: 66.80%\n",
      "34\tValidation loss: 7.093125\tBest loss: 4.610735\tAccuracy: 64.60%\n",
      "35\tValidation loss: 6.057418\tBest loss: 4.610735\tAccuracy: 68.60%\n",
      "36\tValidation loss: 6.902723\tBest loss: 4.610735\tAccuracy: 65.60%\n",
      "37\tValidation loss: 7.121695\tBest loss: 4.610735\tAccuracy: 65.30%\n",
      "38\tValidation loss: 6.492161\tBest loss: 4.610735\tAccuracy: 66.20%\n",
      "39\tValidation loss: 6.484977\tBest loss: 4.610735\tAccuracy: 68.50%\n",
      "40\tValidation loss: 6.647154\tBest loss: 4.610735\tAccuracy: 68.30%\n",
      "41\tValidation loss: 8.039388\tBest loss: 4.610735\tAccuracy: 65.40%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.03523187e-01   3.61092500e-02   2.07520515e-01 ...,   1.49999833e-04\n",
      "    4.10751265e-04   1.51736211e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.30327129e-12   6.23899155e-09   2.85423045e-08 ...,   2.42729291e-01\n",
      "    1.37205370e-14   6.48382013e-07]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   7.38280117e-30]]\n",
      "[22 19 16 ...,  6 24 36]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  4.44296559e-21   1.37415425e-26   1.94543213e-32 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.08653999e-03   1.74849443e-02   2.03002784e-02 ...,   2.34923093e-03\n",
      "    1.17052598e-02   4.46191290e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    1.47484074e-37   1.00000000e+00]]\n",
      "[43 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   2.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 51.969543\tBest loss: 51.969543\tAccuracy: 23.70%\n",
      "1\tValidation loss: 20.124844\tBest loss: 20.124844\tAccuracy: 38.40%\n",
      "2\tValidation loss: 11.884830\tBest loss: 11.884830\tAccuracy: 48.30%\n",
      "3\tValidation loss: 8.420858\tBest loss: 8.420858\tAccuracy: 56.90%\n",
      "4\tValidation loss: 7.377200\tBest loss: 7.377200\tAccuracy: 58.60%\n",
      "5\tValidation loss: 6.201928\tBest loss: 6.201928\tAccuracy: 56.30%\n",
      "6\tValidation loss: 5.304171\tBest loss: 5.304171\tAccuracy: 62.00%\n",
      "7\tValidation loss: 4.687163\tBest loss: 4.687163\tAccuracy: 63.80%\n",
      "8\tValidation loss: 5.279654\tBest loss: 4.687163\tAccuracy: 62.20%\n",
      "9\tValidation loss: 6.714522\tBest loss: 4.687163\tAccuracy: 62.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 6.347700\tBest loss: 4.687163\tAccuracy: 60.90%\n",
      "11\tValidation loss: 5.138425\tBest loss: 4.687163\tAccuracy: 64.10%\n",
      "12\tValidation loss: 6.901737\tBest loss: 4.687163\tAccuracy: 61.00%\n",
      "13\tValidation loss: 7.286568\tBest loss: 4.687163\tAccuracy: 61.60%\n",
      "14\tValidation loss: 6.466806\tBest loss: 4.687163\tAccuracy: 61.00%\n",
      "15\tValidation loss: 7.225800\tBest loss: 4.687163\tAccuracy: 59.60%\n",
      "16\tValidation loss: 5.649024\tBest loss: 4.687163\tAccuracy: 62.10%\n",
      "17\tValidation loss: 6.076571\tBest loss: 4.687163\tAccuracy: 64.40%\n",
      "18\tValidation loss: 6.445955\tBest loss: 4.687163\tAccuracy: 65.80%\n",
      "19\tValidation loss: 5.546527\tBest loss: 4.687163\tAccuracy: 64.00%\n",
      "20\tValidation loss: 5.637329\tBest loss: 4.687163\tAccuracy: 64.40%\n",
      "21\tValidation loss: 6.112927\tBest loss: 4.687163\tAccuracy: 65.20%\n",
      "22\tValidation loss: 5.332571\tBest loss: 4.687163\tAccuracy: 66.70%\n",
      "23\tValidation loss: 5.164444\tBest loss: 4.687163\tAccuracy: 64.10%\n",
      "24\tValidation loss: 6.846861\tBest loss: 4.687163\tAccuracy: 66.80%\n",
      "25\tValidation loss: 5.973590\tBest loss: 4.687163\tAccuracy: 64.50%\n",
      "26\tValidation loss: 6.716527\tBest loss: 4.687163\tAccuracy: 64.90%\n",
      "27\tValidation loss: 4.704912\tBest loss: 4.687163\tAccuracy: 67.70%\n",
      "28\tValidation loss: 7.616018\tBest loss: 4.687163\tAccuracy: 63.00%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   6.12742407e-23 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.30928728e-36   6.89356246e-37   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  2.38028763e-26   9.09125215e-27   2.52173239e-17 ...,   9.70589220e-15\n",
      "    6.53632218e-14   3.07956061e-09]\n",
      " [  2.57284034e-32   1.34424058e-24   1.98024918e-25 ...,   3.27026868e-07\n",
      "    2.68831529e-15   8.02305358e-12]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   3.52815799e-23]]\n",
      "[26 43 43 ..., 36  6 36]\n",
      "[[  0.00000000e+00   0.00000000e+00   1.55864270e-38 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.19975880e-01   2.41114870e-02   1.65435240e-01 ...,   8.40197899e-04\n",
      "    2.01611337e-03   1.66679092e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   2.15130563e-38 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.60798705e-25   6.66075075e-26   5.35909143e-26 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.58290693e-02   4.44989791e-03   2.08164603e-02 ...,   2.70711561e-03\n",
      "    1.34848217e-02   8.30612984e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   1.77471970e-38\n",
      "    1.36836097e-23   1.00000000e+00]]\n",
      "[20 19 16 ...,  6  8 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   1.5s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 64.711166\tBest loss: 64.711166\tAccuracy: 18.60%\n",
      "1\tValidation loss: 22.750790\tBest loss: 22.750790\tAccuracy: 37.60%\n",
      "2\tValidation loss: 13.315295\tBest loss: 13.315295\tAccuracy: 45.20%\n",
      "3\tValidation loss: 8.091466\tBest loss: 8.091466\tAccuracy: 54.40%\n",
      "4\tValidation loss: 6.735051\tBest loss: 6.735051\tAccuracy: 58.70%\n",
      "5\tValidation loss: 6.602600\tBest loss: 6.602600\tAccuracy: 58.40%\n",
      "6\tValidation loss: 5.933362\tBest loss: 5.933362\tAccuracy: 60.60%\n",
      "7\tValidation loss: 6.565362\tBest loss: 5.933362\tAccuracy: 58.80%\n",
      "8\tValidation loss: 5.759472\tBest loss: 5.759472\tAccuracy: 63.40%\n",
      "9\tValidation loss: 6.120092\tBest loss: 5.759472\tAccuracy: 61.00%\n",
      "10\tValidation loss: 5.849668\tBest loss: 5.759472\tAccuracy: 62.00%\n",
      "11\tValidation loss: 5.927741\tBest loss: 5.759472\tAccuracy: 61.50%\n",
      "12\tValidation loss: 5.277500\tBest loss: 5.277500\tAccuracy: 64.00%\n",
      "13\tValidation loss: 6.322701\tBest loss: 5.277500\tAccuracy: 60.30%\n",
      "14\tValidation loss: 5.868208\tBest loss: 5.277500\tAccuracy: 64.00%\n",
      "15\tValidation loss: 5.149214\tBest loss: 5.149214\tAccuracy: 64.90%\n",
      "16\tValidation loss: 5.762305\tBest loss: 5.149214\tAccuracy: 60.90%\n",
      "17\tValidation loss: 5.684108\tBest loss: 5.149214\tAccuracy: 64.30%\n",
      "18\tValidation loss: 5.511922\tBest loss: 5.149214\tAccuracy: 66.60%\n",
      "19\tValidation loss: 6.461298\tBest loss: 5.149214\tAccuracy: 63.10%\n",
      "20\tValidation loss: 6.151944\tBest loss: 5.149214\tAccuracy: 63.40%\n",
      "21\tValidation loss: 5.288245\tBest loss: 5.149214\tAccuracy: 66.80%\n",
      "22\tValidation loss: 6.707160\tBest loss: 5.149214\tAccuracy: 64.80%\n",
      "23\tValidation loss: 5.881832\tBest loss: 5.149214\tAccuracy: 66.40%\n",
      "24\tValidation loss: 4.848600\tBest loss: 4.848600\tAccuracy: 67.60%\n",
      "25\tValidation loss: 5.667264\tBest loss: 4.848600\tAccuracy: 65.80%\n",
      "26\tValidation loss: 5.734166\tBest loss: 4.848600\tAccuracy: 69.10%\n",
      "27\tValidation loss: 6.892793\tBest loss: 4.848600\tAccuracy: 65.70%\n",
      "28\tValidation loss: 5.955913\tBest loss: 4.848600\tAccuracy: 68.60%\n",
      "29\tValidation loss: 6.186176\tBest loss: 4.848600\tAccuracy: 66.10%\n",
      "30\tValidation loss: 6.642599\tBest loss: 4.848600\tAccuracy: 65.60%\n",
      "31\tValidation loss: 7.083401\tBest loss: 4.848600\tAccuracy: 65.90%\n",
      "32\tValidation loss: 6.522106\tBest loss: 4.848600\tAccuracy: 67.50%\n",
      "33\tValidation loss: 6.554498\tBest loss: 4.848600\tAccuracy: 66.00%\n",
      "34\tValidation loss: 6.661400\tBest loss: 4.848600\tAccuracy: 69.20%\n",
      "35\tValidation loss: 6.353276\tBest loss: 4.848600\tAccuracy: 68.40%\n",
      "36\tValidation loss: 6.333570\tBest loss: 4.848600\tAccuracy: 68.40%\n",
      "37\tValidation loss: 6.589849\tBest loss: 4.848600\tAccuracy: 68.90%\n",
      "38\tValidation loss: 6.124859\tBest loss: 4.848600\tAccuracy: 68.40%\n",
      "39\tValidation loss: 5.480561\tBest loss: 4.848600\tAccuracy: 69.70%\n",
      "40\tValidation loss: 5.969872\tBest loss: 4.848600\tAccuracy: 69.20%\n",
      "41\tValidation loss: 6.498795\tBest loss: 4.848600\tAccuracy: 65.90%\n",
      "42\tValidation loss: 6.212784\tBest loss: 4.848600\tAccuracy: 71.20%\n",
      "43\tValidation loss: 7.564838\tBest loss: 4.848600\tAccuracy: 68.30%\n",
      "44\tValidation loss: 6.535692\tBest loss: 4.848600\tAccuracy: 69.40%\n",
      "45\tValidation loss: 5.892010\tBest loss: 4.848600\tAccuracy: 69.40%\n",
      "Early stopping!\n",
      "[[  2.00737213e-12   1.89251745e-13   3.15658036e-13 ...,   5.34074659e-11\n",
      "    2.98877881e-24   1.59767772e-12]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   4.55742995e-12 ...,   0.00000000e+00\n",
      "    1.70644807e-33   8.34600568e-16]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   2.45499785e-35 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  5.57264574e-02   7.45554501e-03   2.07199138e-02 ...,   2.52553588e-03\n",
      "    1.23862615e-02   2.43183202e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    1.71129257e-33   9.99999881e-01]]\n",
      "[41 41 33 ...,  6  8 47]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.25203107e-02   2.81114615e-02   3.04134846e-01 ...,   4.34026151e-04\n",
      "    7.19054835e-04   9.12083779e-05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  2.47855520e-15   1.25233874e-15   8.21367568e-21 ...,   2.01440766e-13\n",
      "    7.72901894e-15   1.01881223e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   5.12063861e-13\n",
      "    4.44835027e-18   4.57721355e-25]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.21731256e-34]]\n",
      "[20  2 16 ..., 36 35 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=0, n_neurons=150, learning_rate=0.1, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   2.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.533264\tBest loss: 4.533264\tAccuracy: 1.60%\n",
      "1\tValidation loss: 4.274505\tBest loss: 4.274505\tAccuracy: 2.30%\n",
      "2\tValidation loss: 3.842528\tBest loss: 3.842528\tAccuracy: 3.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\tValidation loss: 4.000318\tBest loss: 3.842528\tAccuracy: 3.90%\n",
      "4\tValidation loss: 4.708764\tBest loss: 3.842528\tAccuracy: 3.20%\n",
      "5\tValidation loss: 4.898722\tBest loss: 3.842528\tAccuracy: 0.80%\n",
      "6\tValidation loss: 4.765396\tBest loss: 3.842528\tAccuracy: 2.20%\n",
      "7\tValidation loss: 5.043684\tBest loss: 3.842528\tAccuracy: 3.70%\n",
      "8\tValidation loss: 5.353779\tBest loss: 3.842528\tAccuracy: 3.70%\n",
      "9\tValidation loss: 5.015028\tBest loss: 3.842528\tAccuracy: 2.10%\n",
      "10\tValidation loss: 5.027653\tBest loss: 3.842528\tAccuracy: 2.50%\n",
      "11\tValidation loss: 4.744986\tBest loss: 3.842528\tAccuracy: 4.50%\n",
      "12\tValidation loss: 4.842271\tBest loss: 3.842528\tAccuracy: 3.40%\n",
      "13\tValidation loss: 4.866688\tBest loss: 3.842528\tAccuracy: 1.90%\n",
      "14\tValidation loss: 4.694184\tBest loss: 3.842528\tAccuracy: 3.60%\n",
      "15\tValidation loss: 4.939378\tBest loss: 3.842528\tAccuracy: 1.50%\n",
      "16\tValidation loss: 5.188114\tBest loss: 3.842528\tAccuracy: 3.30%\n",
      "17\tValidation loss: 4.670026\tBest loss: 3.842528\tAccuracy: 3.80%\n",
      "18\tValidation loss: 5.177761\tBest loss: 3.842528\tAccuracy: 1.00%\n",
      "19\tValidation loss: 4.931545\tBest loss: 3.842528\tAccuracy: 2.30%\n",
      "20\tValidation loss: 4.859946\tBest loss: 3.842528\tAccuracy: 1.90%\n",
      "21\tValidation loss: 5.258004\tBest loss: 3.842528\tAccuracy: 2.50%\n",
      "22\tValidation loss: 5.094426\tBest loss: 3.842528\tAccuracy: 2.30%\n",
      "23\tValidation loss: 5.166638\tBest loss: 3.842528\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " [ 0.02822042  0.02772365  0.03875544 ...,  0.02239987  0.01659668\n",
      "   0.02192773]\n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " ..., \n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " [ 0.02973781  0.02693605  0.03954747 ...,  0.02155683  0.01566025\n",
      "   0.02090725]\n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]\n",
      " ..., \n",
      " [ 0.02973823  0.02693602  0.03954753 ...,  0.02155679  0.01566023\n",
      "   0.0209072 ]\n",
      " [ 0.02827639  0.02774488  0.03867116 ...,  0.02230213  0.01656355\n",
      "   0.02194262]\n",
      " [ 0.02973839  0.02693595  0.03954761 ...,  0.02155679  0.01566016\n",
      "   0.02090711]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   2.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.540241\tBest loss: 4.540241\tAccuracy: 1.70%\n",
      "1\tValidation loss: 4.231883\tBest loss: 4.231883\tAccuracy: 2.00%\n",
      "2\tValidation loss: 3.838024\tBest loss: 3.838024\tAccuracy: 3.50%\n",
      "3\tValidation loss: 4.032645\tBest loss: 3.838024\tAccuracy: 2.20%\n",
      "4\tValidation loss: 4.650370\tBest loss: 3.838024\tAccuracy: 2.30%\n",
      "5\tValidation loss: 4.934050\tBest loss: 3.838024\tAccuracy: 1.20%\n",
      "6\tValidation loss: 5.671669\tBest loss: 3.838024\tAccuracy: 2.10%\n",
      "7\tValidation loss: 4.507675\tBest loss: 3.838024\tAccuracy: 2.00%\n",
      "8\tValidation loss: 4.829711\tBest loss: 3.838024\tAccuracy: 2.30%\n",
      "9\tValidation loss: 5.138776\tBest loss: 3.838024\tAccuracy: 3.20%\n",
      "10\tValidation loss: 5.058799\tBest loss: 3.838024\tAccuracy: 2.30%\n",
      "11\tValidation loss: 5.078644\tBest loss: 3.838024\tAccuracy: 2.30%\n",
      "12\tValidation loss: 4.723439\tBest loss: 3.838024\tAccuracy: 3.50%\n",
      "13\tValidation loss: 5.096837\tBest loss: 3.838024\tAccuracy: 3.70%\n",
      "14\tValidation loss: 4.975278\tBest loss: 3.838024\tAccuracy: 3.50%\n",
      "15\tValidation loss: 4.949634\tBest loss: 3.838024\tAccuracy: 1.90%\n",
      "16\tValidation loss: 5.115274\tBest loss: 3.838024\tAccuracy: 3.70%\n",
      "17\tValidation loss: 4.681123\tBest loss: 3.838024\tAccuracy: 1.20%\n",
      "18\tValidation loss: 4.508687\tBest loss: 3.838024\tAccuracy: 1.80%\n",
      "19\tValidation loss: 5.095619\tBest loss: 3.838024\tAccuracy: 1.80%\n",
      "20\tValidation loss: 4.784096\tBest loss: 3.838024\tAccuracy: 3.70%\n",
      "21\tValidation loss: 4.992002\tBest loss: 3.838024\tAccuracy: 2.60%\n",
      "22\tValidation loss: 4.797909\tBest loss: 3.838024\tAccuracy: 3.10%\n",
      "23\tValidation loss: 4.753536\tBest loss: 3.838024\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " ..., \n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02225482  0.02129186  0.03216799 ...,  0.02646794  0.01125499\n",
      "   0.01861464]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " ..., \n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]\n",
      " [ 0.02227215  0.02125994  0.03226905 ...,  0.02641476  0.01125783\n",
      "   0.01865165]\n",
      " [ 0.02315926  0.02057276  0.03147288 ...,  0.02560931  0.01086283\n",
      "   0.01828788]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   3.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.508873\tBest loss: 4.508873\tAccuracy: 1.80%\n",
      "1\tValidation loss: 4.208097\tBest loss: 4.208097\tAccuracy: 2.30%\n",
      "2\tValidation loss: 3.843420\tBest loss: 3.843420\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.952498\tBest loss: 3.843420\tAccuracy: 3.20%\n",
      "4\tValidation loss: 4.907492\tBest loss: 3.843420\tAccuracy: 2.20%\n",
      "5\tValidation loss: 5.300132\tBest loss: 3.843420\tAccuracy: 2.20%\n",
      "6\tValidation loss: 4.886525\tBest loss: 3.843420\tAccuracy: 2.40%\n",
      "7\tValidation loss: 4.766751\tBest loss: 3.843420\tAccuracy: 4.00%\n",
      "8\tValidation loss: 4.532454\tBest loss: 3.843420\tAccuracy: 1.90%\n",
      "9\tValidation loss: 5.035241\tBest loss: 3.843420\tAccuracy: 1.30%\n",
      "10\tValidation loss: 5.025113\tBest loss: 3.843420\tAccuracy: 3.70%\n",
      "11\tValidation loss: 4.810335\tBest loss: 3.843420\tAccuracy: 2.90%\n",
      "12\tValidation loss: 5.320293\tBest loss: 3.843420\tAccuracy: 1.00%\n",
      "13\tValidation loss: 4.690157\tBest loss: 3.843420\tAccuracy: 1.90%\n",
      "14\tValidation loss: 5.174987\tBest loss: 3.843420\tAccuracy: 3.70%\n",
      "15\tValidation loss: 4.752392\tBest loss: 3.843420\tAccuracy: 3.70%\n",
      "16\tValidation loss: 5.757852\tBest loss: 3.843420\tAccuracy: 1.40%\n",
      "17\tValidation loss: 4.954420\tBest loss: 3.843420\tAccuracy: 1.70%\n",
      "18\tValidation loss: 4.744174\tBest loss: 3.843420\tAccuracy: 3.80%\n",
      "19\tValidation loss: 5.306057\tBest loss: 3.843420\tAccuracy: 3.70%\n",
      "20\tValidation loss: 4.839923\tBest loss: 3.843420\tAccuracy: 2.00%\n",
      "21\tValidation loss: 5.077916\tBest loss: 3.843420\tAccuracy: 3.00%\n",
      "22\tValidation loss: 4.735329\tBest loss: 3.843420\tAccuracy: 3.30%\n",
      "23\tValidation loss: 4.890152\tBest loss: 3.843420\tAccuracy: 1.70%\n",
      "Early stopping!\n",
      "[[ 0.03062969  0.02008345  0.03940866 ...,  0.02239319  0.01846908\n",
      "   0.01582014]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581305]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581306]\n",
      " ..., \n",
      " [ 0.03064917  0.02007608  0.03940558 ...,  0.02239342  0.0184668\n",
      "   0.01581309]\n",
      " [ 0.027696    0.02163826  0.03879702 ...,  0.02323337  0.01925986\n",
      "   0.01705733]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581305]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[[ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581305]\n",
      " [ 0.02764216  0.02164986  0.0381789  ...,  0.02342097  0.01939919\n",
      "   0.0169661 ]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581305]\n",
      " ..., \n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846673\n",
      "   0.01581306]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581306]\n",
      " [ 0.03064945  0.02007595  0.03940579 ...,  0.02239339  0.01846674\n",
      "   0.01581305]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=500, dropout_rate=0.6, n_hidden_layers=4, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=   2.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.813607\tBest loss: 3.813607\tAccuracy: 3.70%\n",
      "1\tValidation loss: 3.812197\tBest loss: 3.812197\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.813624\tBest loss: 3.812197\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.807253\tBest loss: 3.807253\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.810091\tBest loss: 3.807253\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.806287\tBest loss: 3.806287\tAccuracy: 4.00%\n",
      "6\tValidation loss: 3.811331\tBest loss: 3.806287\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.815583\tBest loss: 3.806287\tAccuracy: 4.50%\n",
      "8\tValidation loss: 3.811760\tBest loss: 3.806287\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.818171\tBest loss: 3.806287\tAccuracy: 3.20%\n",
      "10\tValidation loss: 3.808866\tBest loss: 3.806287\tAccuracy: 4.50%\n",
      "11\tValidation loss: 3.804528\tBest loss: 3.804528\tAccuracy: 3.20%\n",
      "12\tValidation loss: 3.803493\tBest loss: 3.803493\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.813638\tBest loss: 3.803493\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.808608\tBest loss: 3.803493\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.816201\tBest loss: 3.803493\tAccuracy: 3.00%\n",
      "16\tValidation loss: 3.800207\tBest loss: 3.800207\tAccuracy: 4.50%\n",
      "17\tValidation loss: 3.810598\tBest loss: 3.800207\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.800166\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "19\tValidation loss: 3.814762\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.809083\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.809563\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "22\tValidation loss: 3.807988\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.807129\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.815585\tBest loss: 3.800166\tAccuracy: 4.00%\n",
      "25\tValidation loss: 3.810249\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.806863\tBest loss: 3.800166\tAccuracy: 3.00%\n",
      "27\tValidation loss: 3.807621\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "28\tValidation loss: 3.806285\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.812785\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "30\tValidation loss: 3.800969\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "31\tValidation loss: 3.812900\tBest loss: 3.800166\tAccuracy: 3.00%\n",
      "32\tValidation loss: 3.807386\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "33\tValidation loss: 3.803494\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "34\tValidation loss: 3.809946\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "35\tValidation loss: 3.815089\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "36\tValidation loss: 3.807654\tBest loss: 3.800166\tAccuracy: 3.00%\n",
      "37\tValidation loss: 3.810018\tBest loss: 3.800166\tAccuracy: 3.70%\n",
      "38\tValidation loss: 3.805697\tBest loss: 3.800166\tAccuracy: 3.20%\n",
      "39\tValidation loss: 3.799746\tBest loss: 3.799746\tAccuracy: 3.70%\n",
      "40\tValidation loss: 3.802013\tBest loss: 3.799746\tAccuracy: 3.70%\n",
      "41\tValidation loss: 3.811884\tBest loss: 3.799746\tAccuracy: 3.20%\n",
      "42\tValidation loss: 3.800254\tBest loss: 3.799746\tAccuracy: 3.00%\n",
      "43\tValidation loss: 3.807892\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "44\tValidation loss: 3.814586\tBest loss: 3.799746\tAccuracy: 3.60%\n",
      "45\tValidation loss: 3.806212\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "46\tValidation loss: 3.810810\tBest loss: 3.799746\tAccuracy: 3.20%\n",
      "47\tValidation loss: 3.805674\tBest loss: 3.799746\tAccuracy: 3.00%\n",
      "48\tValidation loss: 3.808887\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "49\tValidation loss: 3.814662\tBest loss: 3.799746\tAccuracy: 3.20%\n",
      "50\tValidation loss: 3.809079\tBest loss: 3.799746\tAccuracy: 3.70%\n",
      "51\tValidation loss: 3.812411\tBest loss: 3.799746\tAccuracy: 3.70%\n",
      "52\tValidation loss: 3.815681\tBest loss: 3.799746\tAccuracy: 3.20%\n",
      "53\tValidation loss: 3.815627\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "54\tValidation loss: 3.811129\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "55\tValidation loss: 3.826511\tBest loss: 3.799746\tAccuracy: 3.70%\n",
      "56\tValidation loss: 3.813906\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "57\tValidation loss: 3.810469\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "58\tValidation loss: 3.802356\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "59\tValidation loss: 3.807565\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "60\tValidation loss: 3.809908\tBest loss: 3.799746\tAccuracy: 4.00%\n",
      "Early stopping!\n",
      "[[ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " ..., \n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " ..., \n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]\n",
      " [ 0.01801931  0.0395766   0.02305603 ...,  0.02461072  0.01386134\n",
      "   0.01352551]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   9.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.802978\tBest loss: 3.802978\tAccuracy: 3.20%\n",
      "1\tValidation loss: 3.797278\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "2\tValidation loss: 3.808890\tBest loss: 3.797278\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.811910\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.813215\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.813628\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.798851\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.803926\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.816448\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.802647\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.805397\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.809647\tBest loss: 3.797278\tAccuracy: 3.00%\n",
      "12\tValidation loss: 3.797920\tBest loss: 3.797278\tAccuracy: 3.80%\n",
      "13\tValidation loss: 3.813326\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.812143\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.808389\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.810867\tBest loss: 3.797278\tAccuracy: 4.00%\n",
      "17\tValidation loss: 3.808846\tBest loss: 3.797278\tAccuracy: 4.50%\n",
      "18\tValidation loss: 3.804407\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.807644\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "20\tValidation loss: 3.812104\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.806339\tBest loss: 3.797278\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.811639\tBest loss: 3.797278\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " ..., \n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[[ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " ..., \n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]\n",
      " [ 0.0154502   0.03687191  0.01859714 ...,  0.03426928  0.02089038\n",
      "   0.01678493]]\n",
      "[16 16 16 ..., 16 16 16]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   4.0s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.804930\tBest loss: 3.804930\tAccuracy: 3.60%\n",
      "1\tValidation loss: 3.894792\tBest loss: 3.804930\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.821291\tBest loss: 3.804930\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.811314\tBest loss: 3.804930\tAccuracy: 3.70%\n",
      "4\tValidation loss: 3.810342\tBest loss: 3.804930\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.808823\tBest loss: 3.804930\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.808998\tBest loss: 3.804930\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.811100\tBest loss: 3.804930\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.807217\tBest loss: 3.804930\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.808034\tBest loss: 3.804930\tAccuracy: 3.00%\n",
      "10\tValidation loss: 3.811382\tBest loss: 3.804930\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.803142\tBest loss: 3.803142\tAccuracy: 2.20%\n",
      "12\tValidation loss: 3.801228\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.811154\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.804096\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.802953\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.810715\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.813784\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.819636\tBest loss: 3.801228\tAccuracy: 4.00%\n",
      "19\tValidation loss: 3.819321\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "20\tValidation loss: 3.803064\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.806890\tBest loss: 3.801228\tAccuracy: 4.00%\n",
      "22\tValidation loss: 3.807527\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.809212\tBest loss: 3.801228\tAccuracy: 4.00%\n",
      "24\tValidation loss: 3.804002\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "25\tValidation loss: 3.812284\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.820929\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "27\tValidation loss: 3.821407\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "28\tValidation loss: 3.807806\tBest loss: 3.801228\tAccuracy: 4.00%\n",
      "29\tValidation loss: 3.815428\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "30\tValidation loss: 3.808642\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "31\tValidation loss: 3.810980\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "32\tValidation loss: 3.801804\tBest loss: 3.801228\tAccuracy: 3.20%\n",
      "33\tValidation loss: 3.822031\tBest loss: 3.801228\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " ..., \n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]]\n",
      "[19 19 19 ..., 19 19 19]\n",
      "[[ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " ..., \n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]\n",
      " [ 0.01189701  0.02944926  0.02694737 ...,  0.02848591  0.0159433\n",
      "   0.01208716]]\n",
      "[19 19 19 ..., 19 19 19]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=100, dropout_rate=0.6, n_hidden_layers=2, n_neurons=200, learning_rate=0.1, activation=<function relu at 0x000002EE6B242400>, total=   5.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.808098\tBest loss: 3.808098\tAccuracy: 3.40%\n",
      "1\tValidation loss: 3.805007\tBest loss: 3.805007\tAccuracy: 3.90%\n",
      "2\tValidation loss: 3.797536\tBest loss: 3.797536\tAccuracy: 3.70%\n",
      "3\tValidation loss: 3.798396\tBest loss: 3.797536\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.803137\tBest loss: 3.797536\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.804050\tBest loss: 3.797536\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.803855\tBest loss: 3.797536\tAccuracy: 3.20%\n",
      "7\tValidation loss: 3.805364\tBest loss: 3.797536\tAccuracy: 3.70%\n",
      "8\tValidation loss: 3.804750\tBest loss: 3.797536\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.803799\tBest loss: 3.797536\tAccuracy: 3.70%\n",
      "10\tValidation loss: 3.801594\tBest loss: 3.797536\tAccuracy: 4.50%\n",
      "11\tValidation loss: 3.794769\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.802416\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "13\tValidation loss: 3.802147\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "14\tValidation loss: 3.803347\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "15\tValidation loss: 3.808013\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "16\tValidation loss: 3.796729\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.802261\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "18\tValidation loss: 3.797470\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "19\tValidation loss: 3.800143\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.802139\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.800038\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.799751\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "23\tValidation loss: 3.802732\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "24\tValidation loss: 3.807850\tBest loss: 3.794769\tAccuracy: 4.00%\n",
      "25\tValidation loss: 3.804107\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "26\tValidation loss: 3.801842\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "27\tValidation loss: 3.805215\tBest loss: 3.794769\tAccuracy: 3.00%\n",
      "28\tValidation loss: 3.798458\tBest loss: 3.794769\tAccuracy: 3.70%\n",
      "29\tValidation loss: 3.800253\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "30\tValidation loss: 3.799297\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "31\tValidation loss: 3.805882\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "32\tValidation loss: 3.800603\tBest loss: 3.794769\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " ..., \n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[[ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " ..., \n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]\n",
      " [ 0.01867514  0.03264796  0.02585967 ...,  0.0306935   0.01867841\n",
      "   0.01641459]]\n",
      "[18 18 18 ..., 18 18 18]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=   7.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.814759\tBest loss: 3.814759\tAccuracy: 2.80%\n",
      "1\tValidation loss: 3.800674\tBest loss: 3.800674\tAccuracy: 3.20%\n",
      "2\tValidation loss: 3.803503\tBest loss: 3.800674\tAccuracy: 3.20%\n",
      "3\tValidation loss: 3.801068\tBest loss: 3.800674\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.803680\tBest loss: 3.800674\tAccuracy: 3.70%\n",
      "5\tValidation loss: 3.801688\tBest loss: 3.800674\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.795486\tBest loss: 3.795486\tAccuracy: 4.00%\n",
      "7\tValidation loss: 3.798277\tBest loss: 3.795486\tAccuracy: 4.00%\n",
      "8\tValidation loss: 3.805059\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "9\tValidation loss: 3.801622\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "10\tValidation loss: 3.799163\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.799404\tBest loss: 3.795486\tAccuracy: 3.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 3.798131\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.804827\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.801631\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.800712\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.801535\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.797748\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.798178\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.797136\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.801292\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "21\tValidation loss: 3.795913\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.803901\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "23\tValidation loss: 3.804771\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "24\tValidation loss: 3.795971\tBest loss: 3.795486\tAccuracy: 3.70%\n",
      "25\tValidation loss: 3.801735\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "26\tValidation loss: 3.804430\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "27\tValidation loss: 3.806970\tBest loss: 3.795486\tAccuracy: 3.20%\n",
      "Early stopping!\n",
      "[[ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " ..., \n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[[ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " ..., \n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]\n",
      " [ 0.01908295  0.03339672  0.02453766 ...,  0.02876674  0.01748872\n",
      "   0.01964876]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=   6.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400> \n",
      "0\tValidation loss: 3.810394\tBest loss: 3.810394\tAccuracy: 2.90%\n",
      "1\tValidation loss: 3.796023\tBest loss: 3.796023\tAccuracy: 4.00%\n",
      "2\tValidation loss: 3.804700\tBest loss: 3.796023\tAccuracy: 4.00%\n",
      "3\tValidation loss: 3.799219\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "4\tValidation loss: 3.805480\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "5\tValidation loss: 3.802882\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "6\tValidation loss: 3.801771\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "7\tValidation loss: 3.804479\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "8\tValidation loss: 3.803066\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "9\tValidation loss: 3.799190\tBest loss: 3.796023\tAccuracy: 3.00%\n",
      "10\tValidation loss: 3.802195\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "11\tValidation loss: 3.800025\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "12\tValidation loss: 3.800662\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "13\tValidation loss: 3.804291\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "14\tValidation loss: 3.798415\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "15\tValidation loss: 3.796915\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "16\tValidation loss: 3.809174\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "17\tValidation loss: 3.803542\tBest loss: 3.796023\tAccuracy: 3.20%\n",
      "18\tValidation loss: 3.806853\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "19\tValidation loss: 3.802359\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "20\tValidation loss: 3.798146\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "21\tValidation loss: 3.801625\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "22\tValidation loss: 3.802439\tBest loss: 3.796023\tAccuracy: 3.70%\n",
      "Early stopping!\n",
      "[[ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " ..., \n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[[ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " ..., \n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]\n",
      " [ 0.01559157  0.03152391  0.01973465 ...,  0.03341787  0.01628266\n",
      "   0.01519135]]\n",
      "[17 17 17 ..., 17 17 17]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=100, dropout_rate=0.4, n_hidden_layers=4, n_neurons=120, learning_rate=0.05, activation=<function relu at 0x000002EE6B242400>, total=   5.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.695435\tBest loss: 3.695435\tAccuracy: 11.70%\n",
      "1\tValidation loss: 3.966169\tBest loss: 3.695435\tAccuracy: 18.60%\n",
      "2\tValidation loss: 3.391771\tBest loss: 3.391771\tAccuracy: 26.90%\n",
      "3\tValidation loss: 3.341014\tBest loss: 3.341014\tAccuracy: 31.00%\n",
      "4\tValidation loss: 3.323890\tBest loss: 3.323890\tAccuracy: 35.90%\n",
      "5\tValidation loss: 2.777929\tBest loss: 2.777929\tAccuracy: 37.60%\n",
      "6\tValidation loss: 3.151017\tBest loss: 2.777929\tAccuracy: 35.50%\n",
      "7\tValidation loss: 3.402254\tBest loss: 2.777929\tAccuracy: 37.90%\n",
      "8\tValidation loss: 2.897547\tBest loss: 2.777929\tAccuracy: 39.30%\n",
      "9\tValidation loss: 3.587989\tBest loss: 2.777929\tAccuracy: 35.90%\n",
      "10\tValidation loss: 3.219127\tBest loss: 2.777929\tAccuracy: 46.40%\n",
      "11\tValidation loss: 3.380095\tBest loss: 2.777929\tAccuracy: 45.60%\n",
      "12\tValidation loss: 3.401670\tBest loss: 2.777929\tAccuracy: 43.70%\n",
      "13\tValidation loss: 3.459572\tBest loss: 2.777929\tAccuracy: 45.80%\n",
      "14\tValidation loss: 3.265527\tBest loss: 2.777929\tAccuracy: 47.10%\n",
      "15\tValidation loss: 3.366378\tBest loss: 2.777929\tAccuracy: 46.30%\n",
      "16\tValidation loss: 3.749069\tBest loss: 2.777929\tAccuracy: 45.80%\n",
      "17\tValidation loss: 3.258013\tBest loss: 2.777929\tAccuracy: 47.00%\n",
      "18\tValidation loss: 3.486455\tBest loss: 2.777929\tAccuracy: 48.90%\n",
      "19\tValidation loss: 3.691616\tBest loss: 2.777929\tAccuracy: 47.00%\n",
      "20\tValidation loss: 4.141802\tBest loss: 2.777929\tAccuracy: 44.00%\n",
      "21\tValidation loss: 2.945824\tBest loss: 2.777929\tAccuracy: 54.60%\n",
      "22\tValidation loss: 3.619950\tBest loss: 2.777929\tAccuracy: 52.90%\n",
      "23\tValidation loss: 3.575048\tBest loss: 2.777929\tAccuracy: 51.30%\n",
      "24\tValidation loss: 3.593207\tBest loss: 2.777929\tAccuracy: 52.10%\n",
      "25\tValidation loss: 3.186477\tBest loss: 2.777929\tAccuracy: 49.70%\n",
      "26\tValidation loss: 3.054816\tBest loss: 2.777929\tAccuracy: 51.40%\n",
      "Early stopping!\n",
      "[[  9.82383062e-06   1.13301841e-03   1.89820814e-04 ...,   1.09769317e-05\n",
      "    7.89108071e-06   4.51318228e-05]\n",
      " [  1.16397217e-02   9.30944271e-03   3.73598151e-02 ...,   7.89855665e-04\n",
      "    7.21622710e-05   9.85364841e-06]\n",
      " [  9.45250267e-11   8.71040007e-21   7.78518472e-10 ...,   7.32532198e-23\n",
      "    8.34113094e-27   0.00000000e+00]\n",
      " ..., \n",
      " [  5.22286072e-03   5.25375316e-03   1.86350551e-02 ...,   7.39728753e-03\n",
      "    2.16483092e-03   1.85767037e-03]\n",
      " [  6.77172284e-05   4.30059806e-03   3.64967360e-04 ...,   1.03714526e-01\n",
      "    6.47460402e-04   5.73408417e-03]\n",
      " [  1.40665840e-15   6.94209468e-10   8.03683595e-12 ...,   1.46775125e-08\n",
      "    1.48969965e-08   2.88744668e-05]]\n",
      "[ 9 19 39 ..., 21 44  9]\n",
      "[[  3.26271867e-03   2.70916405e-03   1.60343319e-01 ...,   6.20462745e-03\n",
      "    3.02494242e-04   1.56412658e-03]\n",
      " [  4.44791946e-12   1.63276854e-05   4.72440087e-09 ...,   8.69160755e-13\n",
      "    8.40058058e-12   6.96789348e-10]\n",
      " [  7.73370878e-09   3.90869187e-04   1.75369903e-04 ...,   4.57989063e-11\n",
      "    1.10920537e-10   1.21540495e-12]\n",
      " ..., \n",
      " [  2.22199009e-10   9.01335603e-11   3.10968508e-11 ...,   1.04493836e-16\n",
      "    3.90813080e-20   7.79353288e-20]\n",
      " [  1.99594628e-03   5.81555441e-03   3.83163709e-03 ...,   9.50809754e-03\n",
      "    2.64249975e-03   1.07321783e-03]\n",
      " [  9.10711362e-17   3.06322947e-13   1.40005501e-19 ...,   4.93615167e-04\n",
      "    5.63559160e-02   7.56840646e-01]]\n",
      "[37  9 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   6.4s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 4.492607\tBest loss: 4.492607\tAccuracy: 12.70%\n",
      "1\tValidation loss: 4.596238\tBest loss: 4.492607\tAccuracy: 13.50%\n",
      "2\tValidation loss: 3.470166\tBest loss: 3.470166\tAccuracy: 30.40%\n",
      "3\tValidation loss: 3.311723\tBest loss: 3.311723\tAccuracy: 27.00%\n",
      "4\tValidation loss: 3.397332\tBest loss: 3.311723\tAccuracy: 32.10%\n",
      "5\tValidation loss: 3.261400\tBest loss: 3.261400\tAccuracy: 37.00%\n",
      "6\tValidation loss: 3.154404\tBest loss: 3.154404\tAccuracy: 43.00%\n",
      "7\tValidation loss: 3.419310\tBest loss: 3.154404\tAccuracy: 35.90%\n",
      "8\tValidation loss: 2.986565\tBest loss: 2.986565\tAccuracy: 40.50%\n",
      "9\tValidation loss: 3.097297\tBest loss: 2.986565\tAccuracy: 43.30%\n",
      "10\tValidation loss: 2.733926\tBest loss: 2.733926\tAccuracy: 48.60%\n",
      "11\tValidation loss: 3.663296\tBest loss: 2.733926\tAccuracy: 41.40%\n",
      "12\tValidation loss: 3.226917\tBest loss: 2.733926\tAccuracy: 44.50%\n",
      "13\tValidation loss: 3.335769\tBest loss: 2.733926\tAccuracy: 43.70%\n",
      "14\tValidation loss: 3.619029\tBest loss: 2.733926\tAccuracy: 43.90%\n",
      "15\tValidation loss: 3.401313\tBest loss: 2.733926\tAccuracy: 46.90%\n",
      "16\tValidation loss: 3.589457\tBest loss: 2.733926\tAccuracy: 43.60%\n",
      "17\tValidation loss: 3.694427\tBest loss: 2.733926\tAccuracy: 48.20%\n",
      "18\tValidation loss: 2.995733\tBest loss: 2.733926\tAccuracy: 50.60%\n",
      "19\tValidation loss: 3.875551\tBest loss: 2.733926\tAccuracy: 47.50%\n",
      "20\tValidation loss: 3.205137\tBest loss: 2.733926\tAccuracy: 51.50%\n",
      "21\tValidation loss: 3.431483\tBest loss: 2.733926\tAccuracy: 50.00%\n",
      "22\tValidation loss: 3.851602\tBest loss: 2.733926\tAccuracy: 48.80%\n",
      "23\tValidation loss: 3.761019\tBest loss: 2.733926\tAccuracy: 49.90%\n",
      "24\tValidation loss: 3.228353\tBest loss: 2.733926\tAccuracy: 53.70%\n",
      "25\tValidation loss: 3.571013\tBest loss: 2.733926\tAccuracy: 54.90%\n",
      "26\tValidation loss: 3.432110\tBest loss: 2.733926\tAccuracy: 46.00%\n",
      "27\tValidation loss: 3.478670\tBest loss: 2.733926\tAccuracy: 51.20%\n",
      "28\tValidation loss: 3.714193\tBest loss: 2.733926\tAccuracy: 54.30%\n",
      "29\tValidation loss: 3.574985\tBest loss: 2.733926\tAccuracy: 51.70%\n",
      "30\tValidation loss: 3.489112\tBest loss: 2.733926\tAccuracy: 55.10%\n",
      "31\tValidation loss: 3.454345\tBest loss: 2.733926\tAccuracy: 51.40%\n",
      "Early stopping!\n",
      "[[  5.29406639e-03   8.54291394e-03   4.53505106e-02 ...,   3.22411870e-05\n",
      "    3.17603349e-06   3.86915868e-04]\n",
      " [  2.34342052e-28   1.75290067e-19   4.43930023e-21 ...,   1.12323287e-27\n",
      "    1.84220245e-27   3.31402323e-18]\n",
      " [  9.22330619e-15   1.36384442e-14   1.48879642e-09 ...,   1.69480572e-17\n",
      "    2.54413459e-19   2.92304592e-12]\n",
      " ..., \n",
      " [  1.22438983e-08   1.03103570e-08   6.23846530e-09 ...,   2.67801315e-05\n",
      "    7.17225134e-07   2.38731373e-05]\n",
      " [  2.12522633e-14   7.41943873e-14   7.74760258e-17 ...,   2.49850471e-02\n",
      "    1.47337769e-05   1.58521146e-01]\n",
      " [  1.95185342e-18   2.25000902e-18   7.41393420e-21 ...,   3.31758741e-07\n",
      "    5.23538723e-08   2.83682660e-08]]\n",
      "[ 3 42 43 ..., 36 27 25]\n",
      "[[  1.34450248e-25   1.08643588e-14   2.92045578e-16 ...,   6.69442340e-26\n",
      "    3.12970250e-24   2.70187251e-19]\n",
      " [  1.39758885e-01   3.18126916e-03   1.29265204e-01 ...,   4.89128695e-04\n",
      "    1.34853981e-04   2.49155331e-04]\n",
      " [  1.11576093e-14   0.00000000e+00   9.10563277e-16 ...,   4.95652365e-31\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  4.26540481e-18   4.28071986e-14   5.98691045e-19 ...,   4.42518707e-22\n",
      "    6.41358103e-22   2.40862615e-27]\n",
      " [  8.44253320e-03   2.23938681e-04   4.03790502e-03 ...,   1.74122602e-02\n",
      "    2.06472166e-03   8.76445696e-03]\n",
      " [  0.00000000e+00   1.40356178e-35   0.00000000e+00 ...,   2.80920120e-10\n",
      "    1.43418347e-07   9.97926712e-01]]\n",
      "[42 19 17 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   7.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 4.441695\tBest loss: 4.441695\tAccuracy: 9.50%\n",
      "1\tValidation loss: 3.399463\tBest loss: 3.399463\tAccuracy: 19.10%\n",
      "2\tValidation loss: 4.071831\tBest loss: 3.399463\tAccuracy: 23.80%\n",
      "3\tValidation loss: 3.231359\tBest loss: 3.231359\tAccuracy: 34.00%\n",
      "4\tValidation loss: 2.866769\tBest loss: 2.866769\tAccuracy: 33.80%\n",
      "5\tValidation loss: 2.913943\tBest loss: 2.866769\tAccuracy: 39.30%\n",
      "6\tValidation loss: 3.331258\tBest loss: 2.866769\tAccuracy: 39.00%\n",
      "7\tValidation loss: 3.478431\tBest loss: 2.866769\tAccuracy: 36.80%\n",
      "8\tValidation loss: 3.480682\tBest loss: 2.866769\tAccuracy: 39.30%\n",
      "9\tValidation loss: 3.865230\tBest loss: 2.866769\tAccuracy: 40.00%\n",
      "10\tValidation loss: 3.110750\tBest loss: 2.866769\tAccuracy: 41.60%\n",
      "11\tValidation loss: 3.277043\tBest loss: 2.866769\tAccuracy: 45.30%\n",
      "12\tValidation loss: 3.587578\tBest loss: 2.866769\tAccuracy: 40.80%\n",
      "13\tValidation loss: 2.886261\tBest loss: 2.866769\tAccuracy: 47.20%\n",
      "14\tValidation loss: 3.752012\tBest loss: 2.866769\tAccuracy: 43.10%\n",
      "15\tValidation loss: 3.127789\tBest loss: 2.866769\tAccuracy: 47.80%\n",
      "16\tValidation loss: 3.001747\tBest loss: 2.866769\tAccuracy: 48.20%\n",
      "17\tValidation loss: 2.942527\tBest loss: 2.866769\tAccuracy: 48.40%\n",
      "18\tValidation loss: 3.167614\tBest loss: 2.866769\tAccuracy: 48.60%\n",
      "19\tValidation loss: 3.058161\tBest loss: 2.866769\tAccuracy: 47.10%\n",
      "20\tValidation loss: 3.880036\tBest loss: 2.866769\tAccuracy: 47.00%\n",
      "21\tValidation loss: 3.332170\tBest loss: 2.866769\tAccuracy: 48.80%\n",
      "22\tValidation loss: 3.236451\tBest loss: 2.866769\tAccuracy: 51.50%\n",
      "23\tValidation loss: 4.112111\tBest loss: 2.866769\tAccuracy: 45.60%\n",
      "24\tValidation loss: 2.990872\tBest loss: 2.866769\tAccuracy: 51.10%\n",
      "25\tValidation loss: 3.174213\tBest loss: 2.866769\tAccuracy: 52.80%\n",
      "Early stopping!\n",
      "[[  2.06615077e-04   5.49555334e-05   2.21753471e-05 ...,   8.35097104e-04\n",
      "    1.95453522e-05   6.13265001e-05]\n",
      " [  0.00000000e+00   8.29763985e-36   4.74212696e-34 ...,   1.61001336e-21\n",
      "    0.00000000e+00   1.57479873e-31]\n",
      " [  2.09474321e-02   3.74485226e-03   2.41959328e-03 ...,   4.15340438e-03\n",
      "    1.25723388e-02   2.78212223e-02]\n",
      " ..., \n",
      " [  7.19701078e-12   3.74565786e-12   2.98955869e-12 ...,   1.19365670e-16\n",
      "    2.03950250e-20   2.45330440e-21]\n",
      " [  1.46670956e-02   1.48975779e-03   3.14585073e-03 ...,   2.02903561e-02\n",
      "    1.88735928e-02   1.17204236e-02]\n",
      " [  4.16082531e-15   4.51294991e-12   3.76559085e-17 ...,   1.50700137e-02\n",
      "    1.29985571e-01   8.54654729e-01]]\n",
      "[41 41 23 ...,  6 37 47]\n",
      "[[  2.01764421e-11   1.21326460e-08   8.97361241e-10 ...,   2.04335311e-06\n",
      "    2.35042101e-08   1.06049893e-05]\n",
      " [  3.05353347e-02   1.48150381e-02   9.57963988e-03 ...,   3.14499810e-03\n",
      "    5.50299231e-03   3.53593542e-03]\n",
      " [  4.23163181e-16   4.32751210e-28   4.43408099e-18 ...,   4.95641492e-26\n",
      "    5.91678954e-36   0.00000000e+00]\n",
      " ..., \n",
      " [  4.55027586e-03   1.96764921e-03   6.43922889e-04 ...,   1.57679897e-02\n",
      "    1.16012013e-02   4.58852127e-02]\n",
      " [  1.22530805e-03   1.36165734e-04   1.18973030e-05 ...,   1.22944832e-01\n",
      "    7.64261782e-02   1.68062329e-01]\n",
      " [  3.52476854e-06   8.26536528e-09   1.51030211e-09 ...,   2.05540142e-04\n",
      "    5.26204021e-05   2.88290921e-05]]\n",
      "[ 9 19 17 ..., 36 47 38]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=1, n_neurons=200, learning_rate=0.01, activation=<function elu at 0x000002EE6B234268>, total=   6.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 8.248425\tBest loss: 8.248425\tAccuracy: 40.70%\n",
      "1\tValidation loss: 11.462936\tBest loss: 8.248425\tAccuracy: 37.00%\n",
      "2\tValidation loss: 6.791573\tBest loss: 6.791573\tAccuracy: 49.40%\n",
      "3\tValidation loss: 8.522514\tBest loss: 6.791573\tAccuracy: 48.20%\n",
      "4\tValidation loss: 6.402296\tBest loss: 6.402296\tAccuracy: 55.40%\n",
      "5\tValidation loss: 5.629386\tBest loss: 5.629386\tAccuracy: 59.90%\n",
      "6\tValidation loss: 7.379334\tBest loss: 5.629386\tAccuracy: 54.10%\n",
      "7\tValidation loss: 5.976301\tBest loss: 5.629386\tAccuracy: 61.50%\n",
      "8\tValidation loss: 6.319929\tBest loss: 5.629386\tAccuracy: 60.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 6.550163\tBest loss: 5.629386\tAccuracy: 60.00%\n",
      "10\tValidation loss: 8.878683\tBest loss: 5.629386\tAccuracy: 57.60%\n",
      "11\tValidation loss: 6.548946\tBest loss: 5.629386\tAccuracy: 62.00%\n",
      "12\tValidation loss: 5.493425\tBest loss: 5.493425\tAccuracy: 65.70%\n",
      "13\tValidation loss: 6.296331\tBest loss: 5.493425\tAccuracy: 62.80%\n",
      "14\tValidation loss: 5.567153\tBest loss: 5.493425\tAccuracy: 65.60%\n",
      "15\tValidation loss: 7.952088\tBest loss: 5.493425\tAccuracy: 63.20%\n",
      "16\tValidation loss: 7.519616\tBest loss: 5.493425\tAccuracy: 62.20%\n",
      "17\tValidation loss: 5.760556\tBest loss: 5.493425\tAccuracy: 65.50%\n",
      "18\tValidation loss: 7.276788\tBest loss: 5.493425\tAccuracy: 62.00%\n",
      "19\tValidation loss: 7.916129\tBest loss: 5.493425\tAccuracy: 62.70%\n",
      "20\tValidation loss: 5.308698\tBest loss: 5.308698\tAccuracy: 66.80%\n",
      "21\tValidation loss: 5.528983\tBest loss: 5.308698\tAccuracy: 67.30%\n",
      "22\tValidation loss: 6.305981\tBest loss: 5.308698\tAccuracy: 65.80%\n",
      "23\tValidation loss: 8.374586\tBest loss: 5.308698\tAccuracy: 64.10%\n",
      "24\tValidation loss: 5.794215\tBest loss: 5.308698\tAccuracy: 69.60%\n",
      "25\tValidation loss: 6.503251\tBest loss: 5.308698\tAccuracy: 66.00%\n",
      "26\tValidation loss: 5.098082\tBest loss: 5.098082\tAccuracy: 69.20%\n",
      "27\tValidation loss: 7.159554\tBest loss: 5.098082\tAccuracy: 65.20%\n",
      "28\tValidation loss: 7.087750\tBest loss: 5.098082\tAccuracy: 67.90%\n",
      "29\tValidation loss: 7.305630\tBest loss: 5.098082\tAccuracy: 67.60%\n",
      "30\tValidation loss: 6.401899\tBest loss: 5.098082\tAccuracy: 67.20%\n",
      "31\tValidation loss: 6.201899\tBest loss: 5.098082\tAccuracy: 66.40%\n",
      "32\tValidation loss: 7.152350\tBest loss: 5.098082\tAccuracy: 68.10%\n",
      "33\tValidation loss: 7.134165\tBest loss: 5.098082\tAccuracy: 68.30%\n",
      "34\tValidation loss: 8.430260\tBest loss: 5.098082\tAccuracy: 67.40%\n",
      "35\tValidation loss: 5.607644\tBest loss: 5.098082\tAccuracy: 70.30%\n",
      "36\tValidation loss: 8.380556\tBest loss: 5.098082\tAccuracy: 65.30%\n",
      "37\tValidation loss: 7.144504\tBest loss: 5.098082\tAccuracy: 69.10%\n",
      "38\tValidation loss: 6.791389\tBest loss: 5.098082\tAccuracy: 67.30%\n",
      "39\tValidation loss: 6.031288\tBest loss: 5.098082\tAccuracy: 69.50%\n",
      "40\tValidation loss: 7.386008\tBest loss: 5.098082\tAccuracy: 69.90%\n",
      "41\tValidation loss: 5.788712\tBest loss: 5.098082\tAccuracy: 71.00%\n",
      "42\tValidation loss: 6.400146\tBest loss: 5.098082\tAccuracy: 69.40%\n",
      "43\tValidation loss: 6.593348\tBest loss: 5.098082\tAccuracy: 69.90%\n",
      "44\tValidation loss: 7.463531\tBest loss: 5.098082\tAccuracy: 69.10%\n",
      "45\tValidation loss: 7.652289\tBest loss: 5.098082\tAccuracy: 71.20%\n",
      "46\tValidation loss: 6.956972\tBest loss: 5.098082\tAccuracy: 69.60%\n",
      "47\tValidation loss: 6.673835\tBest loss: 5.098082\tAccuracy: 72.20%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.24763533e-01   7.22976867e-03   3.64186764e-02 ...,   4.43383469e-05\n",
      "    3.85704952e-05   3.95250800e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  8.31152320e-18   8.94770665e-16   1.66900092e-15 ...,   2.52469271e-01\n",
      "    3.86516584e-14   1.80237709e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   6.59360266e-25]]\n",
      "[22 19 16 ...,  6 24  9]\n",
      "[[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.01109552  0.01114945  0.04870856 ...,  0.0032365   0.01387021\n",
      "   0.00138438]\n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]]\n",
      "[43 43 43 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   9.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n",
      "0\tValidation loss: 16.277924\tBest loss: 16.277924\tAccuracy: 22.70%\n",
      "1\tValidation loss: 11.512366\tBest loss: 11.512366\tAccuracy: 36.60%\n",
      "2\tValidation loss: 8.562330\tBest loss: 8.562330\tAccuracy: 46.20%\n",
      "3\tValidation loss: 8.740153\tBest loss: 8.562330\tAccuracy: 51.70%\n",
      "4\tValidation loss: 7.706088\tBest loss: 7.706088\tAccuracy: 58.00%\n",
      "5\tValidation loss: 5.483544\tBest loss: 5.483544\tAccuracy: 58.70%\n",
      "6\tValidation loss: 7.218958\tBest loss: 5.483544\tAccuracy: 56.40%\n",
      "7\tValidation loss: 6.261975\tBest loss: 5.483544\tAccuracy: 61.30%\n",
      "8\tValidation loss: 5.053372\tBest loss: 5.053372\tAccuracy: 62.50%\n",
      "9\tValidation loss: 6.261585\tBest loss: 5.053372\tAccuracy: 59.50%\n",
      "10\tValidation loss: 5.390090\tBest loss: 5.053372\tAccuracy: 62.70%\n",
      "11\tValidation loss: 8.874223\tBest loss: 5.053372\tAccuracy: 56.60%\n",
      "12\tValidation loss: 6.466417\tBest loss: 5.053372\tAccuracy: 64.80%\n",
      "13\tValidation loss: 7.509213\tBest loss: 5.053372\tAccuracy: 58.00%\n",
      "14\tValidation loss: 5.975851\tBest loss: 5.053372\tAccuracy: 61.30%\n",
      "15\tValidation loss: 6.211407\tBest loss: 5.053372\tAccuracy: 64.00%\n",
      "16\tValidation loss: 6.458501\tBest loss: 5.053372\tAccuracy: 65.00%\n",
      "17\tValidation loss: 5.656335\tBest loss: 5.053372\tAccuracy: 66.30%\n",
      "18\tValidation loss: 6.415050\tBest loss: 5.053372\tAccuracy: 64.80%\n",
      "19\tValidation loss: 7.514609\tBest loss: 5.053372\tAccuracy: 65.10%\n",
      "20\tValidation loss: 7.188097\tBest loss: 5.053372\tAccuracy: 65.30%\n",
      "21\tValidation loss: 7.696350\tBest loss: 5.053372\tAccuracy: 65.10%\n",
      "22\tValidation loss: 6.814863\tBest loss: 5.053372\tAccuracy: 67.30%\n",
      "23\tValidation loss: 6.350628\tBest loss: 5.053372\tAccuracy: 65.50%\n",
      "24\tValidation loss: 6.545661\tBest loss: 5.053372\tAccuracy: 66.00%\n",
      "25\tValidation loss: 5.731044\tBest loss: 5.053372\tAccuracy: 70.20%\n",
      "26\tValidation loss: 6.263014\tBest loss: 5.053372\tAccuracy: 69.70%\n",
      "27\tValidation loss: 6.398530\tBest loss: 5.053372\tAccuracy: 67.70%\n",
      "28\tValidation loss: 5.706665\tBest loss: 5.053372\tAccuracy: 69.60%\n",
      "29\tValidation loss: 6.948173\tBest loss: 5.053372\tAccuracy: 66.90%\n",
      "Early stopping!\n",
      "[[  0.00000000e+00   0.00000000e+00   4.82520657e-24 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   3.46026087e-31   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  3.10054137e-26   2.31885624e-15   1.81032213e-21 ...,   1.24491609e-16\n",
      "    8.35791634e-15   7.53598911e-14]\n",
      " [  7.02881064e-31   3.93251327e-25   7.59052840e-34 ...,   5.29655616e-12\n",
      "    4.27568649e-21   5.69321231e-16]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   2.80277316e-37]]\n",
      "[26 43 43 ..., 36 27 27]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.46858343e-02   4.06686850e-02   8.54008496e-02 ...,   2.02662821e-04\n",
      "    1.14263163e-03   4.33919893e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.58252114e-29   3.75341718e-29   3.17103192e-29 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.97989044e-02   1.71194170e-02   1.33157149e-02 ...,   1.69457006e-03\n",
      "    1.41325267e-02   3.20242858e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    4.22994938e-34   1.00000000e+00]]\n",
      "[20 18 16 ...,  6  9 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=   5.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 14.215692\tBest loss: 14.215692\tAccuracy: 23.00%\n",
      "1\tValidation loss: 7.525086\tBest loss: 7.525086\tAccuracy: 47.20%\n",
      "2\tValidation loss: 7.196655\tBest loss: 7.196655\tAccuracy: 49.10%\n",
      "3\tValidation loss: 7.078836\tBest loss: 7.078836\tAccuracy: 54.30%\n",
      "4\tValidation loss: 6.994524\tBest loss: 6.994524\tAccuracy: 55.70%\n",
      "5\tValidation loss: 6.300757\tBest loss: 6.300757\tAccuracy: 59.20%\n",
      "6\tValidation loss: 6.309226\tBest loss: 6.300757\tAccuracy: 61.50%\n",
      "7\tValidation loss: 6.458819\tBest loss: 6.300757\tAccuracy: 59.60%\n",
      "8\tValidation loss: 5.948887\tBest loss: 5.948887\tAccuracy: 62.90%\n",
      "9\tValidation loss: 6.398993\tBest loss: 5.948887\tAccuracy: 60.60%\n",
      "10\tValidation loss: 6.293728\tBest loss: 5.948887\tAccuracy: 62.40%\n",
      "11\tValidation loss: 5.290680\tBest loss: 5.290680\tAccuracy: 64.20%\n",
      "12\tValidation loss: 8.020268\tBest loss: 5.290680\tAccuracy: 60.10%\n",
      "13\tValidation loss: 5.283593\tBest loss: 5.283593\tAccuracy: 64.50%\n",
      "14\tValidation loss: 5.576241\tBest loss: 5.283593\tAccuracy: 65.80%\n",
      "15\tValidation loss: 5.329501\tBest loss: 5.283593\tAccuracy: 66.70%\n",
      "16\tValidation loss: 6.129786\tBest loss: 5.283593\tAccuracy: 65.30%\n",
      "17\tValidation loss: 5.545528\tBest loss: 5.283593\tAccuracy: 65.90%\n",
      "18\tValidation loss: 6.317214\tBest loss: 5.283593\tAccuracy: 65.00%\n",
      "19\tValidation loss: 4.916414\tBest loss: 4.916414\tAccuracy: 70.20%\n",
      "20\tValidation loss: 5.818298\tBest loss: 4.916414\tAccuracy: 65.60%\n",
      "21\tValidation loss: 5.805826\tBest loss: 4.916414\tAccuracy: 70.90%\n",
      "22\tValidation loss: 5.537342\tBest loss: 4.916414\tAccuracy: 69.70%\n",
      "23\tValidation loss: 6.051750\tBest loss: 4.916414\tAccuracy: 66.80%\n",
      "24\tValidation loss: 5.217583\tBest loss: 4.916414\tAccuracy: 70.50%\n",
      "25\tValidation loss: 5.869455\tBest loss: 4.916414\tAccuracy: 69.10%\n",
      "26\tValidation loss: 6.252508\tBest loss: 4.916414\tAccuracy: 67.80%\n",
      "27\tValidation loss: 6.125226\tBest loss: 4.916414\tAccuracy: 68.50%\n",
      "28\tValidation loss: 5.069941\tBest loss: 4.916414\tAccuracy: 71.10%\n",
      "29\tValidation loss: 5.704000\tBest loss: 4.916414\tAccuracy: 69.40%\n",
      "30\tValidation loss: 5.935336\tBest loss: 4.916414\tAccuracy: 66.80%\n",
      "31\tValidation loss: 5.602503\tBest loss: 4.916414\tAccuracy: 70.60%\n",
      "32\tValidation loss: 6.245708\tBest loss: 4.916414\tAccuracy: 70.50%\n",
      "33\tValidation loss: 5.270263\tBest loss: 4.916414\tAccuracy: 70.90%\n",
      "34\tValidation loss: 7.706593\tBest loss: 4.916414\tAccuracy: 68.80%\n",
      "35\tValidation loss: 7.785909\tBest loss: 4.916414\tAccuracy: 67.30%\n",
      "36\tValidation loss: 5.315545\tBest loss: 4.916414\tAccuracy: 71.60%\n",
      "37\tValidation loss: 5.791749\tBest loss: 4.916414\tAccuracy: 70.90%\n",
      "38\tValidation loss: 5.527622\tBest loss: 4.916414\tAccuracy: 70.60%\n",
      "39\tValidation loss: 4.900417\tBest loss: 4.900417\tAccuracy: 71.50%\n",
      "40\tValidation loss: 6.022222\tBest loss: 4.900417\tAccuracy: 69.80%\n",
      "41\tValidation loss: 6.990224\tBest loss: 4.900417\tAccuracy: 68.60%\n",
      "42\tValidation loss: 6.043046\tBest loss: 4.900417\tAccuracy: 70.80%\n",
      "43\tValidation loss: 6.494833\tBest loss: 4.900417\tAccuracy: 69.40%\n",
      "44\tValidation loss: 6.252837\tBest loss: 4.900417\tAccuracy: 70.60%\n",
      "45\tValidation loss: 6.516943\tBest loss: 4.900417\tAccuracy: 73.30%\n",
      "46\tValidation loss: 6.966803\tBest loss: 4.900417\tAccuracy: 69.00%\n",
      "47\tValidation loss: 5.815150\tBest loss: 4.900417\tAccuracy: 72.30%\n",
      "48\tValidation loss: 6.964139\tBest loss: 4.900417\tAccuracy: 69.00%\n",
      "49\tValidation loss: 6.969811\tBest loss: 4.900417\tAccuracy: 71.40%\n",
      "50\tValidation loss: 6.671735\tBest loss: 4.900417\tAccuracy: 70.70%\n",
      "51\tValidation loss: 6.475787\tBest loss: 4.900417\tAccuracy: 72.70%\n",
      "52\tValidation loss: 6.294142\tBest loss: 4.900417\tAccuracy: 72.30%\n",
      "53\tValidation loss: 7.904118\tBest loss: 4.900417\tAccuracy: 68.90%\n",
      "54\tValidation loss: 7.626431\tBest loss: 4.900417\tAccuracy: 68.90%\n",
      "55\tValidation loss: 5.887115\tBest loss: 4.900417\tAccuracy: 73.00%\n",
      "56\tValidation loss: 6.495941\tBest loss: 4.900417\tAccuracy: 70.80%\n",
      "57\tValidation loss: 5.823709\tBest loss: 4.900417\tAccuracy: 72.40%\n",
      "58\tValidation loss: 7.037093\tBest loss: 4.900417\tAccuracy: 70.00%\n",
      "59\tValidation loss: 6.955519\tBest loss: 4.900417\tAccuracy: 70.00%\n",
      "60\tValidation loss: 6.974355\tBest loss: 4.900417\tAccuracy: 71.30%\n",
      "Early stopping!\n",
      "[[  6.10342212e-22   1.97367296e-17   8.04837952e-25 ...,   4.76195147e-15\n",
      "    0.00000000e+00   2.26979012e-14]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   1.55339593e-25 ...,   0.00000000e+00\n",
      "    0.00000000e+00   8.71139104e-36]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.31748281e-02   9.55372676e-03   4.91969427e-03 ...,   2.48474884e-03\n",
      "    1.42587619e-02   4.78263199e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00]]\n",
      "[41 41 33 ...,  6  9 47]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.02545705e-02   3.54027785e-02   9.08470154e-02 ...,   3.30993244e-05\n",
      "    5.56448822e-06   3.67697635e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  5.15001616e-34   2.81840274e-20   8.47799495e-34 ...,   6.40804502e-21\n",
      "    6.05763962e-24   4.15751720e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   1.82098240e-31\n",
      "    2.76903023e-38   1.82585516e-27]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   2.13585668e-06]]\n",
      "[20 19 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, batch_size=50, dropout_rate=0.6, n_hidden_layers=0, n_neurons=50, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7378>, total=  12.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   7.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n",
      "0\tValidation loss: 3.660847\tBest loss: 3.660847\tAccuracy: 7.90%\n",
      "1\tValidation loss: 3.507957\tBest loss: 3.507957\tAccuracy: 12.60%\n",
      "2\tValidation loss: 3.405772\tBest loss: 3.405772\tAccuracy: 15.30%\n",
      "3\tValidation loss: 3.301177\tBest loss: 3.301177\tAccuracy: 15.40%\n",
      "4\tValidation loss: 3.238401\tBest loss: 3.238401\tAccuracy: 17.50%\n",
      "5\tValidation loss: 3.191874\tBest loss: 3.191874\tAccuracy: 16.50%\n",
      "6\tValidation loss: 3.085364\tBest loss: 3.085364\tAccuracy: 22.50%\n",
      "7\tValidation loss: 3.064801\tBest loss: 3.064801\tAccuracy: 24.30%\n",
      "8\tValidation loss: 3.017688\tBest loss: 3.017688\tAccuracy: 22.00%\n",
      "9\tValidation loss: 2.945599\tBest loss: 2.945599\tAccuracy: 23.20%\n",
      "10\tValidation loss: 2.909668\tBest loss: 2.909668\tAccuracy: 26.00%\n",
      "11\tValidation loss: 2.867439\tBest loss: 2.867439\tAccuracy: 26.80%\n",
      "12\tValidation loss: 2.958763\tBest loss: 2.867439\tAccuracy: 21.80%\n",
      "13\tValidation loss: 2.794367\tBest loss: 2.794367\tAccuracy: 27.20%\n",
      "14\tValidation loss: 2.806346\tBest loss: 2.794367\tAccuracy: 27.90%\n",
      "15\tValidation loss: 2.755888\tBest loss: 2.755888\tAccuracy: 28.90%\n",
      "16\tValidation loss: 2.730407\tBest loss: 2.730407\tAccuracy: 27.50%\n",
      "17\tValidation loss: 2.697219\tBest loss: 2.697219\tAccuracy: 29.70%\n",
      "18\tValidation loss: 2.689570\tBest loss: 2.689570\tAccuracy: 30.50%\n",
      "19\tValidation loss: 2.639005\tBest loss: 2.639005\tAccuracy: 31.00%\n",
      "20\tValidation loss: 2.622038\tBest loss: 2.622038\tAccuracy: 31.10%\n",
      "21\tValidation loss: 2.641749\tBest loss: 2.622038\tAccuracy: 30.90%\n",
      "22\tValidation loss: 2.627710\tBest loss: 2.622038\tAccuracy: 31.10%\n",
      "23\tValidation loss: 2.550868\tBest loss: 2.550868\tAccuracy: 33.60%\n",
      "24\tValidation loss: 2.552723\tBest loss: 2.550868\tAccuracy: 32.50%\n",
      "25\tValidation loss: 2.487129\tBest loss: 2.487129\tAccuracy: 34.10%\n",
      "26\tValidation loss: 2.535470\tBest loss: 2.487129\tAccuracy: 33.80%\n",
      "27\tValidation loss: 2.519957\tBest loss: 2.487129\tAccuracy: 32.00%\n",
      "28\tValidation loss: 2.451777\tBest loss: 2.451777\tAccuracy: 35.80%\n",
      "29\tValidation loss: 2.462708\tBest loss: 2.451777\tAccuracy: 35.60%\n",
      "30\tValidation loss: 2.407991\tBest loss: 2.407991\tAccuracy: 33.70%\n",
      "31\tValidation loss: 2.392376\tBest loss: 2.392376\tAccuracy: 35.00%\n",
      "32\tValidation loss: 2.376912\tBest loss: 2.376912\tAccuracy: 35.80%\n",
      "33\tValidation loss: 2.378668\tBest loss: 2.376912\tAccuracy: 35.30%\n",
      "34\tValidation loss: 2.348910\tBest loss: 2.348910\tAccuracy: 35.20%\n",
      "35\tValidation loss: 2.348194\tBest loss: 2.348194\tAccuracy: 35.00%\n",
      "36\tValidation loss: 2.268634\tBest loss: 2.268634\tAccuracy: 37.30%\n",
      "37\tValidation loss: 2.272151\tBest loss: 2.268634\tAccuracy: 37.00%\n",
      "38\tValidation loss: 2.232361\tBest loss: 2.232361\tAccuracy: 39.00%\n",
      "39\tValidation loss: 2.290460\tBest loss: 2.232361\tAccuracy: 37.70%\n",
      "40\tValidation loss: 2.268807\tBest loss: 2.232361\tAccuracy: 37.30%\n",
      "41\tValidation loss: 2.161231\tBest loss: 2.161231\tAccuracy: 41.00%\n",
      "42\tValidation loss: 2.216320\tBest loss: 2.161231\tAccuracy: 40.30%\n",
      "43\tValidation loss: 2.230530\tBest loss: 2.161231\tAccuracy: 38.50%\n",
      "44\tValidation loss: 2.169440\tBest loss: 2.161231\tAccuracy: 38.20%\n",
      "45\tValidation loss: 2.160755\tBest loss: 2.160755\tAccuracy: 39.90%\n",
      "46\tValidation loss: 2.080729\tBest loss: 2.080729\tAccuracy: 43.30%\n",
      "47\tValidation loss: 2.081246\tBest loss: 2.080729\tAccuracy: 41.30%\n",
      "48\tValidation loss: 2.130067\tBest loss: 2.080729\tAccuracy: 40.70%\n",
      "49\tValidation loss: 2.124775\tBest loss: 2.080729\tAccuracy: 40.90%\n",
      "50\tValidation loss: 2.053517\tBest loss: 2.053517\tAccuracy: 43.10%\n",
      "51\tValidation loss: 2.078098\tBest loss: 2.053517\tAccuracy: 41.70%\n",
      "52\tValidation loss: 2.016983\tBest loss: 2.016983\tAccuracy: 45.30%\n",
      "53\tValidation loss: 1.968289\tBest loss: 1.968289\tAccuracy: 45.60%\n",
      "54\tValidation loss: 2.014418\tBest loss: 1.968289\tAccuracy: 43.80%\n",
      "55\tValidation loss: 1.966184\tBest loss: 1.966184\tAccuracy: 45.30%\n",
      "56\tValidation loss: 1.967588\tBest loss: 1.966184\tAccuracy: 44.70%\n",
      "57\tValidation loss: 1.916850\tBest loss: 1.916850\tAccuracy: 47.00%\n",
      "58\tValidation loss: 1.967013\tBest loss: 1.916850\tAccuracy: 47.00%\n",
      "59\tValidation loss: 1.926448\tBest loss: 1.916850\tAccuracy: 48.80%\n",
      "60\tValidation loss: 1.955756\tBest loss: 1.916850\tAccuracy: 47.90%\n",
      "61\tValidation loss: 1.983384\tBest loss: 1.916850\tAccuracy: 44.00%\n",
      "62\tValidation loss: 1.842624\tBest loss: 1.842624\tAccuracy: 47.20%\n",
      "63\tValidation loss: 1.886789\tBest loss: 1.842624\tAccuracy: 47.20%\n",
      "64\tValidation loss: 1.902211\tBest loss: 1.842624\tAccuracy: 47.60%\n",
      "65\tValidation loss: 1.868241\tBest loss: 1.842624\tAccuracy: 48.80%\n",
      "66\tValidation loss: 1.847837\tBest loss: 1.842624\tAccuracy: 50.20%\n",
      "67\tValidation loss: 1.923874\tBest loss: 1.842624\tAccuracy: 45.20%\n",
      "68\tValidation loss: 1.802894\tBest loss: 1.802894\tAccuracy: 49.60%\n",
      "69\tValidation loss: 1.966281\tBest loss: 1.802894\tAccuracy: 45.30%\n",
      "70\tValidation loss: 1.783697\tBest loss: 1.783697\tAccuracy: 50.30%\n",
      "71\tValidation loss: 1.828109\tBest loss: 1.783697\tAccuracy: 48.70%\n",
      "72\tValidation loss: 1.749279\tBest loss: 1.749279\tAccuracy: 52.50%\n",
      "73\tValidation loss: 1.805400\tBest loss: 1.749279\tAccuracy: 50.20%\n",
      "74\tValidation loss: 1.713332\tBest loss: 1.713332\tAccuracy: 53.80%\n",
      "75\tValidation loss: 1.732633\tBest loss: 1.713332\tAccuracy: 50.80%\n",
      "76\tValidation loss: 1.860324\tBest loss: 1.713332\tAccuracy: 45.90%\n",
      "77\tValidation loss: 1.729448\tBest loss: 1.713332\tAccuracy: 51.20%\n",
      "78\tValidation loss: 1.741542\tBest loss: 1.713332\tAccuracy: 50.80%\n",
      "79\tValidation loss: 1.679632\tBest loss: 1.679632\tAccuracy: 52.80%\n",
      "80\tValidation loss: 1.805181\tBest loss: 1.679632\tAccuracy: 50.70%\n",
      "81\tValidation loss: 1.697277\tBest loss: 1.679632\tAccuracy: 53.80%\n",
      "82\tValidation loss: 1.716266\tBest loss: 1.679632\tAccuracy: 53.00%\n",
      "83\tValidation loss: 1.716245\tBest loss: 1.679632\tAccuracy: 51.10%\n",
      "84\tValidation loss: 1.691154\tBest loss: 1.679632\tAccuracy: 52.60%\n",
      "85\tValidation loss: 1.755680\tBest loss: 1.679632\tAccuracy: 52.00%\n",
      "86\tValidation loss: 1.698357\tBest loss: 1.679632\tAccuracy: 52.30%\n",
      "87\tValidation loss: 1.665911\tBest loss: 1.665911\tAccuracy: 55.10%\n",
      "88\tValidation loss: 1.627995\tBest loss: 1.627995\tAccuracy: 53.10%\n",
      "89\tValidation loss: 1.665506\tBest loss: 1.627995\tAccuracy: 54.20%\n",
      "90\tValidation loss: 1.594413\tBest loss: 1.594413\tAccuracy: 53.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\tValidation loss: 1.705505\tBest loss: 1.594413\tAccuracy: 51.00%\n",
      "92\tValidation loss: 1.619121\tBest loss: 1.594413\tAccuracy: 54.80%\n",
      "93\tValidation loss: 1.663934\tBest loss: 1.594413\tAccuracy: 54.30%\n",
      "94\tValidation loss: 1.607252\tBest loss: 1.594413\tAccuracy: 54.60%\n",
      "95\tValidation loss: 1.622557\tBest loss: 1.594413\tAccuracy: 55.70%\n",
      "96\tValidation loss: 1.623392\tBest loss: 1.594413\tAccuracy: 53.80%\n",
      "97\tValidation loss: 1.597327\tBest loss: 1.594413\tAccuracy: 55.30%\n",
      "98\tValidation loss: 1.542121\tBest loss: 1.542121\tAccuracy: 56.60%\n",
      "99\tValidation loss: 1.555712\tBest loss: 1.542121\tAccuracy: 55.90%\n",
      "100\tValidation loss: 1.552843\tBest loss: 1.542121\tAccuracy: 55.90%\n",
      "101\tValidation loss: 1.530602\tBest loss: 1.530602\tAccuracy: 55.60%\n",
      "102\tValidation loss: 1.539404\tBest loss: 1.530602\tAccuracy: 56.50%\n",
      "103\tValidation loss: 1.528405\tBest loss: 1.528405\tAccuracy: 55.90%\n",
      "104\tValidation loss: 1.500231\tBest loss: 1.500231\tAccuracy: 58.70%\n",
      "105\tValidation loss: 1.542867\tBest loss: 1.500231\tAccuracy: 55.20%\n",
      "106\tValidation loss: 1.505195\tBest loss: 1.500231\tAccuracy: 54.70%\n",
      "107\tValidation loss: 1.596493\tBest loss: 1.500231\tAccuracy: 55.40%\n",
      "108\tValidation loss: 1.681736\tBest loss: 1.500231\tAccuracy: 52.20%\n",
      "109\tValidation loss: 1.450709\tBest loss: 1.450709\tAccuracy: 58.90%\n",
      "110\tValidation loss: 1.460257\tBest loss: 1.450709\tAccuracy: 56.70%\n",
      "111\tValidation loss: 1.447211\tBest loss: 1.447211\tAccuracy: 58.20%\n",
      "112\tValidation loss: 1.510538\tBest loss: 1.447211\tAccuracy: 55.50%\n",
      "113\tValidation loss: 1.506860\tBest loss: 1.447211\tAccuracy: 58.50%\n",
      "114\tValidation loss: 1.480237\tBest loss: 1.447211\tAccuracy: 56.40%\n",
      "115\tValidation loss: 1.430941\tBest loss: 1.430941\tAccuracy: 58.50%\n",
      "116\tValidation loss: 1.543225\tBest loss: 1.430941\tAccuracy: 54.90%\n",
      "117\tValidation loss: 1.519759\tBest loss: 1.430941\tAccuracy: 55.10%\n",
      "118\tValidation loss: 1.411842\tBest loss: 1.411842\tAccuracy: 60.10%\n",
      "119\tValidation loss: 1.456269\tBest loss: 1.411842\tAccuracy: 57.50%\n",
      "120\tValidation loss: 1.513057\tBest loss: 1.411842\tAccuracy: 56.60%\n",
      "121\tValidation loss: 1.426512\tBest loss: 1.411842\tAccuracy: 57.10%\n",
      "122\tValidation loss: 1.414739\tBest loss: 1.411842\tAccuracy: 59.90%\n",
      "123\tValidation loss: 1.402590\tBest loss: 1.402590\tAccuracy: 60.40%\n",
      "124\tValidation loss: 1.408492\tBest loss: 1.402590\tAccuracy: 58.50%\n",
      "125\tValidation loss: 1.429996\tBest loss: 1.402590\tAccuracy: 58.00%\n",
      "126\tValidation loss: 1.416025\tBest loss: 1.402590\tAccuracy: 58.70%\n",
      "127\tValidation loss: 1.448216\tBest loss: 1.402590\tAccuracy: 58.40%\n",
      "128\tValidation loss: 1.494480\tBest loss: 1.402590\tAccuracy: 55.80%\n",
      "129\tValidation loss: 1.400618\tBest loss: 1.400618\tAccuracy: 58.10%\n",
      "130\tValidation loss: 1.425290\tBest loss: 1.400618\tAccuracy: 59.30%\n",
      "131\tValidation loss: 1.448220\tBest loss: 1.400618\tAccuracy: 57.00%\n",
      "132\tValidation loss: 1.392658\tBest loss: 1.392658\tAccuracy: 60.00%\n",
      "133\tValidation loss: 1.398782\tBest loss: 1.392658\tAccuracy: 58.80%\n",
      "134\tValidation loss: 1.430099\tBest loss: 1.392658\tAccuracy: 58.70%\n",
      "135\tValidation loss: 1.379250\tBest loss: 1.379250\tAccuracy: 60.40%\n",
      "136\tValidation loss: 1.407805\tBest loss: 1.379250\tAccuracy: 60.30%\n",
      "137\tValidation loss: 1.401632\tBest loss: 1.379250\tAccuracy: 57.70%\n",
      "138\tValidation loss: 1.414734\tBest loss: 1.379250\tAccuracy: 59.90%\n",
      "139\tValidation loss: 1.436267\tBest loss: 1.379250\tAccuracy: 58.70%\n",
      "140\tValidation loss: 1.436244\tBest loss: 1.379250\tAccuracy: 58.70%\n",
      "141\tValidation loss: 1.424167\tBest loss: 1.379250\tAccuracy: 58.00%\n",
      "142\tValidation loss: 1.444373\tBest loss: 1.379250\tAccuracy: 57.80%\n",
      "143\tValidation loss: 1.373841\tBest loss: 1.373841\tAccuracy: 59.90%\n",
      "144\tValidation loss: 1.361544\tBest loss: 1.361544\tAccuracy: 58.50%\n",
      "145\tValidation loss: 1.392404\tBest loss: 1.361544\tAccuracy: 58.90%\n",
      "146\tValidation loss: 1.396737\tBest loss: 1.361544\tAccuracy: 59.10%\n",
      "147\tValidation loss: 1.386495\tBest loss: 1.361544\tAccuracy: 58.00%\n",
      "148\tValidation loss: 1.370648\tBest loss: 1.361544\tAccuracy: 61.00%\n",
      "149\tValidation loss: 1.342406\tBest loss: 1.342406\tAccuracy: 61.30%\n",
      "150\tValidation loss: 1.375284\tBest loss: 1.342406\tAccuracy: 56.70%\n",
      "151\tValidation loss: 1.451510\tBest loss: 1.342406\tAccuracy: 57.00%\n",
      "152\tValidation loss: 1.300687\tBest loss: 1.300687\tAccuracy: 61.60%\n",
      "153\tValidation loss: 1.306903\tBest loss: 1.300687\tAccuracy: 61.80%\n",
      "154\tValidation loss: 1.377140\tBest loss: 1.300687\tAccuracy: 60.60%\n",
      "155\tValidation loss: 1.333563\tBest loss: 1.300687\tAccuracy: 59.20%\n",
      "156\tValidation loss: 1.276115\tBest loss: 1.276115\tAccuracy: 63.50%\n",
      "157\tValidation loss: 1.329858\tBest loss: 1.276115\tAccuracy: 63.30%\n",
      "158\tValidation loss: 1.275754\tBest loss: 1.275754\tAccuracy: 64.10%\n",
      "159\tValidation loss: 1.383014\tBest loss: 1.275754\tAccuracy: 58.90%\n",
      "160\tValidation loss: 1.351975\tBest loss: 1.275754\tAccuracy: 57.90%\n",
      "161\tValidation loss: 1.334697\tBest loss: 1.275754\tAccuracy: 60.60%\n",
      "162\tValidation loss: 1.313198\tBest loss: 1.275754\tAccuracy: 58.90%\n",
      "163\tValidation loss: 1.321868\tBest loss: 1.275754\tAccuracy: 59.80%\n",
      "164\tValidation loss: 1.365930\tBest loss: 1.275754\tAccuracy: 58.60%\n",
      "165\tValidation loss: 1.261437\tBest loss: 1.261437\tAccuracy: 60.60%\n",
      "166\tValidation loss: 1.274729\tBest loss: 1.261437\tAccuracy: 62.10%\n",
      "167\tValidation loss: 1.273108\tBest loss: 1.261437\tAccuracy: 62.60%\n",
      "168\tValidation loss: 1.321026\tBest loss: 1.261437\tAccuracy: 60.00%\n",
      "169\tValidation loss: 1.327685\tBest loss: 1.261437\tAccuracy: 61.10%\n",
      "170\tValidation loss: 1.334200\tBest loss: 1.261437\tAccuracy: 60.00%\n",
      "171\tValidation loss: 1.342597\tBest loss: 1.261437\tAccuracy: 59.60%\n",
      "172\tValidation loss: 1.295282\tBest loss: 1.261437\tAccuracy: 60.20%\n",
      "173\tValidation loss: 1.312617\tBest loss: 1.261437\tAccuracy: 60.60%\n",
      "174\tValidation loss: 1.274575\tBest loss: 1.261437\tAccuracy: 62.40%\n",
      "175\tValidation loss: 1.383637\tBest loss: 1.261437\tAccuracy: 58.00%\n",
      "176\tValidation loss: 1.269102\tBest loss: 1.261437\tAccuracy: 62.80%\n",
      "177\tValidation loss: 1.274183\tBest loss: 1.261437\tAccuracy: 62.40%\n",
      "178\tValidation loss: 1.228985\tBest loss: 1.228985\tAccuracy: 63.40%\n",
      "179\tValidation loss: 1.311144\tBest loss: 1.228985\tAccuracy: 62.00%\n",
      "180\tValidation loss: 1.308701\tBest loss: 1.228985\tAccuracy: 61.60%\n",
      "181\tValidation loss: 1.270431\tBest loss: 1.228985\tAccuracy: 61.90%\n",
      "182\tValidation loss: 1.287037\tBest loss: 1.228985\tAccuracy: 60.40%\n",
      "183\tValidation loss: 1.305306\tBest loss: 1.228985\tAccuracy: 60.60%\n",
      "184\tValidation loss: 1.265991\tBest loss: 1.228985\tAccuracy: 64.60%\n",
      "185\tValidation loss: 1.310567\tBest loss: 1.228985\tAccuracy: 61.00%\n",
      "186\tValidation loss: 1.350664\tBest loss: 1.228985\tAccuracy: 57.60%\n",
      "187\tValidation loss: 1.308671\tBest loss: 1.228985\tAccuracy: 60.30%\n",
      "188\tValidation loss: 1.358006\tBest loss: 1.228985\tAccuracy: 59.50%\n",
      "189\tValidation loss: 1.307009\tBest loss: 1.228985\tAccuracy: 59.60%\n",
      "190\tValidation loss: 1.236853\tBest loss: 1.228985\tAccuracy: 61.40%\n",
      "191\tValidation loss: 1.274132\tBest loss: 1.228985\tAccuracy: 62.20%\n",
      "192\tValidation loss: 1.228003\tBest loss: 1.228003\tAccuracy: 62.50%\n",
      "193\tValidation loss: 1.292759\tBest loss: 1.228003\tAccuracy: 61.50%\n",
      "194\tValidation loss: 1.234015\tBest loss: 1.228003\tAccuracy: 63.00%\n",
      "195\tValidation loss: 1.269062\tBest loss: 1.228003\tAccuracy: 61.00%\n",
      "196\tValidation loss: 1.206720\tBest loss: 1.206720\tAccuracy: 63.70%\n",
      "197\tValidation loss: 1.304911\tBest loss: 1.206720\tAccuracy: 61.40%\n",
      "198\tValidation loss: 1.205956\tBest loss: 1.205956\tAccuracy: 64.70%\n",
      "199\tValidation loss: 1.241324\tBest loss: 1.205956\tAccuracy: 62.40%\n",
      "200\tValidation loss: 1.274241\tBest loss: 1.205956\tAccuracy: 61.90%\n",
      "201\tValidation loss: 1.249893\tBest loss: 1.205956\tAccuracy: 62.10%\n",
      "202\tValidation loss: 1.211560\tBest loss: 1.205956\tAccuracy: 63.50%\n",
      "203\tValidation loss: 1.203223\tBest loss: 1.203223\tAccuracy: 62.10%\n",
      "204\tValidation loss: 1.231408\tBest loss: 1.203223\tAccuracy: 63.00%\n",
      "205\tValidation loss: 1.273880\tBest loss: 1.203223\tAccuracy: 63.90%\n",
      "206\tValidation loss: 1.251432\tBest loss: 1.203223\tAccuracy: 62.60%\n",
      "207\tValidation loss: 1.285282\tBest loss: 1.203223\tAccuracy: 62.30%\n",
      "208\tValidation loss: 1.253721\tBest loss: 1.203223\tAccuracy: 61.80%\n",
      "209\tValidation loss: 1.250811\tBest loss: 1.203223\tAccuracy: 62.70%\n",
      "210\tValidation loss: 1.396290\tBest loss: 1.203223\tAccuracy: 61.00%\n",
      "211\tValidation loss: 1.340391\tBest loss: 1.203223\tAccuracy: 59.50%\n",
      "212\tValidation loss: 1.231565\tBest loss: 1.203223\tAccuracy: 62.60%\n",
      "213\tValidation loss: 1.271773\tBest loss: 1.203223\tAccuracy: 61.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\tValidation loss: 1.267884\tBest loss: 1.203223\tAccuracy: 62.20%\n",
      "215\tValidation loss: 1.384271\tBest loss: 1.203223\tAccuracy: 57.50%\n",
      "216\tValidation loss: 1.242273\tBest loss: 1.203223\tAccuracy: 62.80%\n",
      "217\tValidation loss: 1.341091\tBest loss: 1.203223\tAccuracy: 58.50%\n",
      "218\tValidation loss: 1.196638\tBest loss: 1.196638\tAccuracy: 63.90%\n",
      "219\tValidation loss: 1.245560\tBest loss: 1.196638\tAccuracy: 61.70%\n",
      "220\tValidation loss: 1.232807\tBest loss: 1.196638\tAccuracy: 62.70%\n",
      "221\tValidation loss: 1.295081\tBest loss: 1.196638\tAccuracy: 62.00%\n",
      "222\tValidation loss: 1.205282\tBest loss: 1.196638\tAccuracy: 64.30%\n",
      "223\tValidation loss: 1.214924\tBest loss: 1.196638\tAccuracy: 63.40%\n",
      "224\tValidation loss: 1.294054\tBest loss: 1.196638\tAccuracy: 60.50%\n",
      "225\tValidation loss: 1.224722\tBest loss: 1.196638\tAccuracy: 62.20%\n",
      "226\tValidation loss: 1.237349\tBest loss: 1.196638\tAccuracy: 63.40%\n",
      "227\tValidation loss: 1.210838\tBest loss: 1.196638\tAccuracy: 64.30%\n",
      "228\tValidation loss: 1.201543\tBest loss: 1.196638\tAccuracy: 65.60%\n",
      "229\tValidation loss: 1.248865\tBest loss: 1.196638\tAccuracy: 62.90%\n",
      "230\tValidation loss: 1.211886\tBest loss: 1.196638\tAccuracy: 63.90%\n",
      "231\tValidation loss: 1.297430\tBest loss: 1.196638\tAccuracy: 61.60%\n",
      "232\tValidation loss: 1.236405\tBest loss: 1.196638\tAccuracy: 61.40%\n",
      "233\tValidation loss: 1.226784\tBest loss: 1.196638\tAccuracy: 62.10%\n",
      "234\tValidation loss: 1.240714\tBest loss: 1.196638\tAccuracy: 62.40%\n",
      "235\tValidation loss: 1.212931\tBest loss: 1.196638\tAccuracy: 65.50%\n",
      "236\tValidation loss: 1.219712\tBest loss: 1.196638\tAccuracy: 63.40%\n",
      "237\tValidation loss: 1.193493\tBest loss: 1.193493\tAccuracy: 62.10%\n",
      "238\tValidation loss: 1.236221\tBest loss: 1.193493\tAccuracy: 60.20%\n",
      "239\tValidation loss: 1.163453\tBest loss: 1.163453\tAccuracy: 66.10%\n",
      "240\tValidation loss: 1.184653\tBest loss: 1.163453\tAccuracy: 65.30%\n",
      "241\tValidation loss: 1.175315\tBest loss: 1.163453\tAccuracy: 65.30%\n",
      "242\tValidation loss: 1.181879\tBest loss: 1.163453\tAccuracy: 63.60%\n",
      "243\tValidation loss: 1.183204\tBest loss: 1.163453\tAccuracy: 65.20%\n",
      "244\tValidation loss: 1.186594\tBest loss: 1.163453\tAccuracy: 63.80%\n",
      "245\tValidation loss: 1.184339\tBest loss: 1.163453\tAccuracy: 64.00%\n",
      "246\tValidation loss: 1.124494\tBest loss: 1.124494\tAccuracy: 65.50%\n",
      "247\tValidation loss: 1.169334\tBest loss: 1.124494\tAccuracy: 64.00%\n",
      "248\tValidation loss: 1.303679\tBest loss: 1.124494\tAccuracy: 61.20%\n",
      "249\tValidation loss: 1.270837\tBest loss: 1.124494\tAccuracy: 61.60%\n",
      "250\tValidation loss: 1.214750\tBest loss: 1.124494\tAccuracy: 62.60%\n",
      "251\tValidation loss: 1.205728\tBest loss: 1.124494\tAccuracy: 64.00%\n",
      "252\tValidation loss: 1.233425\tBest loss: 1.124494\tAccuracy: 62.20%\n",
      "253\tValidation loss: 1.230975\tBest loss: 1.124494\tAccuracy: 62.00%\n",
      "254\tValidation loss: 1.192212\tBest loss: 1.124494\tAccuracy: 63.50%\n",
      "255\tValidation loss: 1.226215\tBest loss: 1.124494\tAccuracy: 64.00%\n",
      "256\tValidation loss: 1.195791\tBest loss: 1.124494\tAccuracy: 63.70%\n",
      "257\tValidation loss: 1.214149\tBest loss: 1.124494\tAccuracy: 62.90%\n",
      "258\tValidation loss: 1.207128\tBest loss: 1.124494\tAccuracy: 63.00%\n",
      "259\tValidation loss: 1.218626\tBest loss: 1.124494\tAccuracy: 63.90%\n",
      "260\tValidation loss: 1.248410\tBest loss: 1.124494\tAccuracy: 63.30%\n",
      "261\tValidation loss: 1.179850\tBest loss: 1.124494\tAccuracy: 63.70%\n",
      "262\tValidation loss: 1.179501\tBest loss: 1.124494\tAccuracy: 64.60%\n",
      "263\tValidation loss: 1.177713\tBest loss: 1.124494\tAccuracy: 65.20%\n",
      "264\tValidation loss: 1.203405\tBest loss: 1.124494\tAccuracy: 63.20%\n",
      "265\tValidation loss: 1.213207\tBest loss: 1.124494\tAccuracy: 64.60%\n",
      "266\tValidation loss: 1.197722\tBest loss: 1.124494\tAccuracy: 64.00%\n",
      "267\tValidation loss: 1.170547\tBest loss: 1.124494\tAccuracy: 64.60%\n",
      "Early stopping!\n",
      "[[  2.94498969e-02   7.17721367e-03   1.63104646e-02 ...,   1.71272748e-03\n",
      "    8.78561259e-05   7.60786585e-04]\n",
      " [  5.04195075e-10   5.31754959e-05   1.95427037e-05 ...,   4.34043079e-12\n",
      "    1.15796218e-12   2.28766207e-11]\n",
      " [  7.09389569e-05   5.17367560e-04   1.00782153e-03 ...,   3.63030676e-06\n",
      "    3.25302167e-08   5.13886221e-07]\n",
      " ..., \n",
      " [  1.07921660e-05   7.85833254e-05   1.85941808e-05 ...,   9.35840770e-04\n",
      "    4.80241986e-04   3.88113549e-03]\n",
      " [  1.14151521e-06   3.29771581e-07   8.35187421e-08 ...,   1.05347380e-01\n",
      "    3.07171163e-03   1.37112886e-02]\n",
      " [  6.99808006e-05   7.07361323e-04   5.70395605e-05 ...,   1.96695160e-02\n",
      "    5.09081269e-03   3.29116695e-02]]\n",
      "[38 43 43 ...,  8 25 36]\n",
      "[[  4.22683777e-10   7.47705997e-07   4.03186596e-06 ...,   6.41770814e-09\n",
      "    1.05487041e-09   1.55052504e-09]\n",
      " [  5.60121015e-02   2.45176372e-03   5.35284393e-02 ...,   1.40855918e-04\n",
      "    3.96275020e-04   8.06929020e-05]\n",
      " [  9.50260759e-10   8.08389134e-16   8.14511747e-09 ...,   2.67379385e-09\n",
      "    9.65461738e-12   8.34284204e-12]\n",
      " ..., \n",
      " [  3.60656173e-07   4.51016575e-08   1.49063303e-10 ...,   3.14860138e-09\n",
      "    4.80885243e-09   1.05275559e-10]\n",
      " [  1.15200924e-02   3.64795141e-03   1.00020682e-02 ...,   3.28094047e-03\n",
      "    9.81137902e-03   8.37138295e-03]\n",
      " [  1.42914025e-09   1.72147352e-09   1.27115637e-10 ...,   5.23434812e-03\n",
      "    7.89689366e-03   7.98912764e-01]]\n",
      "[20 19 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total= 1.6min\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "1\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "2\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "3\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "4\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "5\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "6\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "7\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "8\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "9\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "10\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "11\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "12\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "13\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "14\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "15\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "16\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "17\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "18\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "19\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "20\tValidation loss: nan\tBest loss: inf\tAccuracy: 0.00%\n",
      "Early stopping!\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " ..., \n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]\n",
      " [ nan  nan  nan ...,  nan  nan  nan]]\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, batch_size=50, dropout_rate=0.2, n_hidden_layers=3, n_neurons=200, learning_rate=0.02, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x000002EE141E7488>, total=   8.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.633982\tBest loss: 3.633982\tAccuracy: 7.80%\n",
      "1\tValidation loss: 3.387405\tBest loss: 3.387405\tAccuracy: 10.60%\n",
      "2\tValidation loss: 3.186676\tBest loss: 3.186676\tAccuracy: 17.00%\n",
      "3\tValidation loss: 2.957418\tBest loss: 2.957418\tAccuracy: 19.60%\n",
      "4\tValidation loss: 2.867527\tBest loss: 2.867527\tAccuracy: 21.10%\n",
      "5\tValidation loss: 2.782952\tBest loss: 2.782952\tAccuracy: 24.40%\n",
      "6\tValidation loss: 2.605947\tBest loss: 2.605947\tAccuracy: 28.40%\n",
      "7\tValidation loss: 2.501261\tBest loss: 2.501261\tAccuracy: 33.40%\n",
      "8\tValidation loss: 2.357887\tBest loss: 2.357887\tAccuracy: 35.80%\n",
      "9\tValidation loss: 2.279851\tBest loss: 2.279851\tAccuracy: 36.40%\n",
      "10\tValidation loss: 2.127474\tBest loss: 2.127474\tAccuracy: 40.90%\n",
      "11\tValidation loss: 2.056612\tBest loss: 2.056612\tAccuracy: 42.00%\n",
      "12\tValidation loss: 1.982722\tBest loss: 1.982722\tAccuracy: 42.20%\n",
      "13\tValidation loss: 1.946626\tBest loss: 1.946626\tAccuracy: 46.10%\n",
      "14\tValidation loss: 1.887946\tBest loss: 1.887946\tAccuracy: 48.60%\n",
      "15\tValidation loss: 1.865414\tBest loss: 1.865414\tAccuracy: 50.20%\n",
      "16\tValidation loss: 1.866042\tBest loss: 1.865414\tAccuracy: 49.10%\n",
      "17\tValidation loss: 1.848233\tBest loss: 1.848233\tAccuracy: 48.10%\n",
      "18\tValidation loss: 1.726558\tBest loss: 1.726558\tAccuracy: 53.00%\n",
      "19\tValidation loss: 1.703478\tBest loss: 1.703478\tAccuracy: 51.50%\n",
      "20\tValidation loss: 1.673065\tBest loss: 1.673065\tAccuracy: 53.70%\n",
      "21\tValidation loss: 1.664969\tBest loss: 1.664969\tAccuracy: 54.90%\n",
      "22\tValidation loss: 1.638743\tBest loss: 1.638743\tAccuracy: 54.00%\n",
      "23\tValidation loss: 1.664245\tBest loss: 1.638743\tAccuracy: 54.50%\n",
      "24\tValidation loss: 1.622203\tBest loss: 1.622203\tAccuracy: 58.10%\n",
      "25\tValidation loss: 1.593439\tBest loss: 1.593439\tAccuracy: 56.00%\n",
      "26\tValidation loss: 1.603669\tBest loss: 1.593439\tAccuracy: 54.40%\n",
      "27\tValidation loss: 1.571111\tBest loss: 1.571111\tAccuracy: 56.30%\n",
      "28\tValidation loss: 1.542156\tBest loss: 1.542156\tAccuracy: 56.80%\n",
      "29\tValidation loss: 1.544984\tBest loss: 1.542156\tAccuracy: 57.50%\n",
      "30\tValidation loss: 1.487596\tBest loss: 1.487596\tAccuracy: 57.20%\n",
      "31\tValidation loss: 1.523374\tBest loss: 1.487596\tAccuracy: 58.80%\n",
      "32\tValidation loss: 1.495889\tBest loss: 1.487596\tAccuracy: 58.40%\n",
      "33\tValidation loss: 1.471600\tBest loss: 1.471600\tAccuracy: 58.70%\n",
      "34\tValidation loss: 1.477433\tBest loss: 1.471600\tAccuracy: 60.10%\n",
      "35\tValidation loss: 1.452855\tBest loss: 1.452855\tAccuracy: 59.10%\n",
      "36\tValidation loss: 1.483317\tBest loss: 1.452855\tAccuracy: 59.60%\n",
      "37\tValidation loss: 1.439943\tBest loss: 1.439943\tAccuracy: 61.00%\n",
      "38\tValidation loss: 1.423221\tBest loss: 1.423221\tAccuracy: 60.40%\n",
      "39\tValidation loss: 1.460330\tBest loss: 1.423221\tAccuracy: 60.00%\n",
      "40\tValidation loss: 1.410763\tBest loss: 1.410763\tAccuracy: 61.50%\n",
      "41\tValidation loss: 1.425453\tBest loss: 1.410763\tAccuracy: 60.50%\n",
      "42\tValidation loss: 1.415209\tBest loss: 1.410763\tAccuracy: 61.70%\n",
      "43\tValidation loss: 1.412751\tBest loss: 1.410763\tAccuracy: 61.10%\n",
      "44\tValidation loss: 1.434674\tBest loss: 1.410763\tAccuracy: 62.20%\n",
      "45\tValidation loss: 1.369655\tBest loss: 1.369655\tAccuracy: 63.90%\n",
      "46\tValidation loss: 1.415114\tBest loss: 1.369655\tAccuracy: 60.10%\n",
      "47\tValidation loss: 1.381813\tBest loss: 1.369655\tAccuracy: 62.70%\n",
      "48\tValidation loss: 1.350880\tBest loss: 1.350880\tAccuracy: 63.50%\n",
      "49\tValidation loss: 1.381612\tBest loss: 1.350880\tAccuracy: 61.70%\n",
      "50\tValidation loss: 1.356350\tBest loss: 1.350880\tAccuracy: 63.60%\n",
      "51\tValidation loss: 1.339622\tBest loss: 1.339622\tAccuracy: 63.80%\n",
      "52\tValidation loss: 1.388656\tBest loss: 1.339622\tAccuracy: 62.70%\n",
      "53\tValidation loss: 1.350952\tBest loss: 1.339622\tAccuracy: 62.40%\n",
      "54\tValidation loss: 1.357743\tBest loss: 1.339622\tAccuracy: 62.20%\n",
      "55\tValidation loss: 1.324585\tBest loss: 1.324585\tAccuracy: 63.10%\n",
      "56\tValidation loss: 1.351779\tBest loss: 1.324585\tAccuracy: 62.30%\n",
      "57\tValidation loss: 1.371433\tBest loss: 1.324585\tAccuracy: 63.20%\n",
      "58\tValidation loss: 1.346490\tBest loss: 1.324585\tAccuracy: 62.80%\n",
      "59\tValidation loss: 1.381597\tBest loss: 1.324585\tAccuracy: 62.10%\n",
      "60\tValidation loss: 1.360538\tBest loss: 1.324585\tAccuracy: 62.10%\n",
      "61\tValidation loss: 1.376718\tBest loss: 1.324585\tAccuracy: 63.00%\n",
      "62\tValidation loss: 1.334189\tBest loss: 1.324585\tAccuracy: 64.80%\n",
      "63\tValidation loss: 1.352912\tBest loss: 1.324585\tAccuracy: 62.70%\n",
      "64\tValidation loss: 1.329125\tBest loss: 1.324585\tAccuracy: 63.70%\n",
      "65\tValidation loss: 1.313970\tBest loss: 1.313970\tAccuracy: 64.00%\n",
      "66\tValidation loss: 1.328020\tBest loss: 1.313970\tAccuracy: 65.50%\n",
      "67\tValidation loss: 1.309650\tBest loss: 1.309650\tAccuracy: 64.10%\n",
      "68\tValidation loss: 1.313412\tBest loss: 1.309650\tAccuracy: 63.80%\n",
      "69\tValidation loss: 1.300452\tBest loss: 1.300452\tAccuracy: 63.60%\n",
      "70\tValidation loss: 1.329199\tBest loss: 1.300452\tAccuracy: 64.90%\n",
      "71\tValidation loss: 1.295854\tBest loss: 1.295854\tAccuracy: 65.00%\n",
      "72\tValidation loss: 1.288335\tBest loss: 1.288335\tAccuracy: 65.30%\n",
      "73\tValidation loss: 1.298311\tBest loss: 1.288335\tAccuracy: 64.40%\n",
      "74\tValidation loss: 1.273003\tBest loss: 1.273003\tAccuracy: 64.00%\n",
      "75\tValidation loss: 1.277129\tBest loss: 1.273003\tAccuracy: 64.90%\n",
      "76\tValidation loss: 1.292763\tBest loss: 1.273003\tAccuracy: 66.80%\n",
      "77\tValidation loss: 1.281349\tBest loss: 1.273003\tAccuracy: 66.20%\n",
      "78\tValidation loss: 1.279870\tBest loss: 1.273003\tAccuracy: 64.30%\n",
      "79\tValidation loss: 1.276749\tBest loss: 1.273003\tAccuracy: 66.20%\n",
      "80\tValidation loss: 1.282243\tBest loss: 1.273003\tAccuracy: 65.40%\n",
      "81\tValidation loss: 1.284456\tBest loss: 1.273003\tAccuracy: 64.80%\n",
      "82\tValidation loss: 1.266788\tBest loss: 1.266788\tAccuracy: 65.80%\n",
      "83\tValidation loss: 1.252790\tBest loss: 1.252790\tAccuracy: 65.10%\n",
      "84\tValidation loss: 1.275034\tBest loss: 1.252790\tAccuracy: 66.30%\n",
      "85\tValidation loss: 1.267038\tBest loss: 1.252790\tAccuracy: 65.80%\n",
      "86\tValidation loss: 1.257699\tBest loss: 1.252790\tAccuracy: 65.90%\n",
      "87\tValidation loss: 1.284743\tBest loss: 1.252790\tAccuracy: 66.10%\n",
      "88\tValidation loss: 1.294208\tBest loss: 1.252790\tAccuracy: 64.80%\n",
      "89\tValidation loss: 1.264766\tBest loss: 1.252790\tAccuracy: 65.30%\n",
      "90\tValidation loss: 1.266256\tBest loss: 1.252790\tAccuracy: 66.00%\n",
      "91\tValidation loss: 1.285237\tBest loss: 1.252790\tAccuracy: 65.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\tValidation loss: 1.254904\tBest loss: 1.252790\tAccuracy: 67.50%\n",
      "93\tValidation loss: 1.268165\tBest loss: 1.252790\tAccuracy: 66.40%\n",
      "94\tValidation loss: 1.276385\tBest loss: 1.252790\tAccuracy: 65.50%\n",
      "95\tValidation loss: 1.288677\tBest loss: 1.252790\tAccuracy: 65.60%\n",
      "96\tValidation loss: 1.282845\tBest loss: 1.252790\tAccuracy: 67.20%\n",
      "97\tValidation loss: 1.249793\tBest loss: 1.249793\tAccuracy: 66.50%\n",
      "98\tValidation loss: 1.253575\tBest loss: 1.249793\tAccuracy: 65.50%\n",
      "99\tValidation loss: 1.257168\tBest loss: 1.249793\tAccuracy: 67.00%\n",
      "100\tValidation loss: 1.242789\tBest loss: 1.242789\tAccuracy: 67.00%\n",
      "101\tValidation loss: 1.260136\tBest loss: 1.242789\tAccuracy: 67.20%\n",
      "102\tValidation loss: 1.245410\tBest loss: 1.242789\tAccuracy: 67.10%\n",
      "103\tValidation loss: 1.249725\tBest loss: 1.242789\tAccuracy: 66.60%\n",
      "104\tValidation loss: 1.258093\tBest loss: 1.242789\tAccuracy: 67.10%\n",
      "105\tValidation loss: 1.258101\tBest loss: 1.242789\tAccuracy: 68.00%\n",
      "106\tValidation loss: 1.255201\tBest loss: 1.242789\tAccuracy: 66.90%\n",
      "107\tValidation loss: 1.266801\tBest loss: 1.242789\tAccuracy: 66.30%\n",
      "108\tValidation loss: 1.251445\tBest loss: 1.242789\tAccuracy: 67.20%\n",
      "109\tValidation loss: 1.224259\tBest loss: 1.224259\tAccuracy: 67.40%\n",
      "110\tValidation loss: 1.239670\tBest loss: 1.224259\tAccuracy: 67.80%\n",
      "111\tValidation loss: 1.242295\tBest loss: 1.224259\tAccuracy: 68.70%\n",
      "112\tValidation loss: 1.253003\tBest loss: 1.224259\tAccuracy: 67.70%\n",
      "113\tValidation loss: 1.255050\tBest loss: 1.224259\tAccuracy: 66.70%\n",
      "114\tValidation loss: 1.259970\tBest loss: 1.224259\tAccuracy: 67.40%\n",
      "115\tValidation loss: 1.248294\tBest loss: 1.224259\tAccuracy: 68.00%\n",
      "116\tValidation loss: 1.230529\tBest loss: 1.224259\tAccuracy: 68.30%\n",
      "117\tValidation loss: 1.232487\tBest loss: 1.224259\tAccuracy: 67.80%\n",
      "118\tValidation loss: 1.229445\tBest loss: 1.224259\tAccuracy: 68.20%\n",
      "119\tValidation loss: 1.220838\tBest loss: 1.220838\tAccuracy: 67.20%\n",
      "120\tValidation loss: 1.221662\tBest loss: 1.220838\tAccuracy: 67.50%\n",
      "121\tValidation loss: 1.224881\tBest loss: 1.220838\tAccuracy: 67.60%\n",
      "122\tValidation loss: 1.219332\tBest loss: 1.219332\tAccuracy: 67.70%\n",
      "123\tValidation loss: 1.233622\tBest loss: 1.219332\tAccuracy: 67.70%\n",
      "124\tValidation loss: 1.252198\tBest loss: 1.219332\tAccuracy: 66.50%\n",
      "125\tValidation loss: 1.219754\tBest loss: 1.219332\tAccuracy: 67.10%\n",
      "126\tValidation loss: 1.221671\tBest loss: 1.219332\tAccuracy: 68.90%\n",
      "127\tValidation loss: 1.209295\tBest loss: 1.209295\tAccuracy: 68.10%\n",
      "128\tValidation loss: 1.227688\tBest loss: 1.209295\tAccuracy: 66.30%\n",
      "129\tValidation loss: 1.224263\tBest loss: 1.209295\tAccuracy: 68.10%\n",
      "130\tValidation loss: 1.225906\tBest loss: 1.209295\tAccuracy: 66.80%\n",
      "131\tValidation loss: 1.220383\tBest loss: 1.209295\tAccuracy: 66.20%\n",
      "132\tValidation loss: 1.232558\tBest loss: 1.209295\tAccuracy: 68.30%\n",
      "133\tValidation loss: 1.250271\tBest loss: 1.209295\tAccuracy: 66.30%\n",
      "134\tValidation loss: 1.229362\tBest loss: 1.209295\tAccuracy: 66.60%\n",
      "135\tValidation loss: 1.222655\tBest loss: 1.209295\tAccuracy: 67.00%\n",
      "136\tValidation loss: 1.207710\tBest loss: 1.207710\tAccuracy: 68.40%\n",
      "137\tValidation loss: 1.214029\tBest loss: 1.207710\tAccuracy: 68.30%\n",
      "138\tValidation loss: 1.228286\tBest loss: 1.207710\tAccuracy: 68.80%\n",
      "139\tValidation loss: 1.212632\tBest loss: 1.207710\tAccuracy: 68.30%\n",
      "140\tValidation loss: 1.206772\tBest loss: 1.206772\tAccuracy: 69.00%\n",
      "141\tValidation loss: 1.216596\tBest loss: 1.206772\tAccuracy: 68.00%\n",
      "142\tValidation loss: 1.216795\tBest loss: 1.206772\tAccuracy: 67.20%\n",
      "143\tValidation loss: 1.188655\tBest loss: 1.188655\tAccuracy: 69.10%\n",
      "144\tValidation loss: 1.181314\tBest loss: 1.181314\tAccuracy: 68.70%\n",
      "145\tValidation loss: 1.177053\tBest loss: 1.177053\tAccuracy: 68.60%\n",
      "146\tValidation loss: 1.212910\tBest loss: 1.177053\tAccuracy: 68.70%\n",
      "147\tValidation loss: 1.207080\tBest loss: 1.177053\tAccuracy: 67.20%\n",
      "148\tValidation loss: 1.189216\tBest loss: 1.177053\tAccuracy: 68.30%\n",
      "149\tValidation loss: 1.209102\tBest loss: 1.177053\tAccuracy: 67.80%\n",
      "150\tValidation loss: 1.202204\tBest loss: 1.177053\tAccuracy: 68.00%\n",
      "151\tValidation loss: 1.188664\tBest loss: 1.177053\tAccuracy: 68.80%\n",
      "152\tValidation loss: 1.199645\tBest loss: 1.177053\tAccuracy: 68.40%\n",
      "153\tValidation loss: 1.186968\tBest loss: 1.177053\tAccuracy: 67.30%\n",
      "154\tValidation loss: 1.206964\tBest loss: 1.177053\tAccuracy: 67.50%\n",
      "155\tValidation loss: 1.207515\tBest loss: 1.177053\tAccuracy: 69.20%\n",
      "156\tValidation loss: 1.190821\tBest loss: 1.177053\tAccuracy: 69.50%\n",
      "157\tValidation loss: 1.221739\tBest loss: 1.177053\tAccuracy: 68.00%\n",
      "158\tValidation loss: 1.214851\tBest loss: 1.177053\tAccuracy: 69.30%\n",
      "159\tValidation loss: 1.201749\tBest loss: 1.177053\tAccuracy: 67.50%\n",
      "160\tValidation loss: 1.184175\tBest loss: 1.177053\tAccuracy: 68.90%\n",
      "161\tValidation loss: 1.186060\tBest loss: 1.177053\tAccuracy: 69.30%\n",
      "162\tValidation loss: 1.194656\tBest loss: 1.177053\tAccuracy: 69.70%\n",
      "163\tValidation loss: 1.197908\tBest loss: 1.177053\tAccuracy: 69.00%\n",
      "164\tValidation loss: 1.180876\tBest loss: 1.177053\tAccuracy: 68.70%\n",
      "165\tValidation loss: 1.191336\tBest loss: 1.177053\tAccuracy: 68.70%\n",
      "166\tValidation loss: 1.198563\tBest loss: 1.177053\tAccuracy: 69.90%\n",
      "Early stopping!\n",
      "[[  1.00603816e-22   4.84637321e-14   1.60357091e-15 ...,   1.58238614e-32\n",
      "    8.46940101e-22   4.58947663e-22]\n",
      " [  6.07571080e-02   3.27754728e-02   5.68385459e-02 ...,   6.98336866e-03\n",
      "    4.30063950e-03   3.89037631e-03]\n",
      " [  1.44314399e-26   1.43952037e-34   7.29656018e-18 ...,   1.05155587e-30\n",
      "    5.90302283e-36   2.92483696e-38]\n",
      " ..., \n",
      " [  7.47845144e-37   2.98917455e-26   9.01761133e-28 ...,   4.63683408e-24\n",
      "    9.57258734e-18   1.40264851e-21]\n",
      " [  4.60604904e-03   4.37705033e-03   8.21200723e-04 ...,   4.01071087e-02\n",
      "    2.64229462e-03   3.57482140e-03]\n",
      " [  2.33147973e-10   3.24331864e-07   8.43238411e-07 ...,   3.69135500e-03\n",
      "    2.81343673e-04   2.46258080e-03]]\n",
      "[20 19 16 ...,  6 24  8]\n",
      "[[  8.54161034e-14   9.83045297e-14   2.06780169e-06 ...,   1.80524608e-14\n",
      "    2.71612105e-15   1.26782283e-11]\n",
      " [  9.27712134e-26   6.53831237e-14   2.08243474e-16 ...,   9.49949297e-30\n",
      "    3.01587163e-21   9.11542954e-20]\n",
      " [  3.58022497e-14   2.40410712e-11   8.72866918e-11 ...,   6.73932066e-15\n",
      "    8.98086564e-13   2.44148517e-12]\n",
      " ..., \n",
      " [  2.41547112e-11   9.32960553e-09   1.48889736e-08 ...,   1.80265687e-14\n",
      "    2.95207889e-14   3.17523408e-15]\n",
      " [  1.90418232e-02   1.10651758e-02   1.47653501e-02 ...,   1.68379527e-02\n",
      "    1.54334558e-02   9.07414965e-03]\n",
      " [  1.54383669e-26   1.81959753e-19   6.47043436e-25 ...,   9.75324292e-06\n",
      "    4.26082551e-07   9.96591449e-01]]\n",
      "[43 43 43 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=  20.3s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.682348\tBest loss: 3.682348\tAccuracy: 6.80%\n",
      "1\tValidation loss: 3.549366\tBest loss: 3.549366\tAccuracy: 8.90%\n",
      "2\tValidation loss: 3.305439\tBest loss: 3.305439\tAccuracy: 12.40%\n",
      "3\tValidation loss: 3.164350\tBest loss: 3.164350\tAccuracy: 14.10%\n",
      "4\tValidation loss: 3.011144\tBest loss: 3.011144\tAccuracy: 18.20%\n",
      "5\tValidation loss: 2.849351\tBest loss: 2.849351\tAccuracy: 22.90%\n",
      "6\tValidation loss: 2.705093\tBest loss: 2.705093\tAccuracy: 25.30%\n",
      "7\tValidation loss: 2.630143\tBest loss: 2.630143\tAccuracy: 27.80%\n",
      "8\tValidation loss: 2.473778\tBest loss: 2.473778\tAccuracy: 31.50%\n",
      "9\tValidation loss: 2.415436\tBest loss: 2.415436\tAccuracy: 32.50%\n",
      "10\tValidation loss: 2.292653\tBest loss: 2.292653\tAccuracy: 35.50%\n",
      "11\tValidation loss: 2.233078\tBest loss: 2.233078\tAccuracy: 38.30%\n",
      "12\tValidation loss: 2.130918\tBest loss: 2.130918\tAccuracy: 39.40%\n",
      "13\tValidation loss: 2.131422\tBest loss: 2.130918\tAccuracy: 37.80%\n",
      "14\tValidation loss: 2.060873\tBest loss: 2.060873\tAccuracy: 42.70%\n",
      "15\tValidation loss: 1.962760\tBest loss: 1.962760\tAccuracy: 45.20%\n",
      "16\tValidation loss: 1.938979\tBest loss: 1.938979\tAccuracy: 45.10%\n",
      "17\tValidation loss: 1.868841\tBest loss: 1.868841\tAccuracy: 48.50%\n",
      "18\tValidation loss: 1.876027\tBest loss: 1.868841\tAccuracy: 47.50%\n",
      "19\tValidation loss: 1.839097\tBest loss: 1.839097\tAccuracy: 48.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\tValidation loss: 1.780349\tBest loss: 1.780349\tAccuracy: 51.40%\n",
      "21\tValidation loss: 1.737409\tBest loss: 1.737409\tAccuracy: 51.60%\n",
      "22\tValidation loss: 1.701061\tBest loss: 1.701061\tAccuracy: 53.20%\n",
      "23\tValidation loss: 1.755109\tBest loss: 1.701061\tAccuracy: 52.70%\n",
      "24\tValidation loss: 1.670804\tBest loss: 1.670804\tAccuracy: 54.90%\n",
      "25\tValidation loss: 1.691047\tBest loss: 1.670804\tAccuracy: 54.00%\n",
      "26\tValidation loss: 1.649750\tBest loss: 1.649750\tAccuracy: 54.60%\n",
      "27\tValidation loss: 1.623857\tBest loss: 1.623857\tAccuracy: 54.70%\n",
      "28\tValidation loss: 1.614028\tBest loss: 1.614028\tAccuracy: 57.60%\n",
      "29\tValidation loss: 1.599007\tBest loss: 1.599007\tAccuracy: 56.50%\n",
      "30\tValidation loss: 1.549418\tBest loss: 1.549418\tAccuracy: 56.00%\n",
      "31\tValidation loss: 1.538841\tBest loss: 1.538841\tAccuracy: 56.80%\n",
      "32\tValidation loss: 1.561838\tBest loss: 1.538841\tAccuracy: 56.30%\n",
      "33\tValidation loss: 1.536330\tBest loss: 1.536330\tAccuracy: 57.80%\n",
      "34\tValidation loss: 1.530944\tBest loss: 1.530944\tAccuracy: 58.70%\n",
      "35\tValidation loss: 1.507651\tBest loss: 1.507651\tAccuracy: 57.50%\n",
      "36\tValidation loss: 1.555248\tBest loss: 1.507651\tAccuracy: 56.30%\n",
      "37\tValidation loss: 1.520787\tBest loss: 1.507651\tAccuracy: 58.50%\n",
      "38\tValidation loss: 1.470168\tBest loss: 1.470168\tAccuracy: 58.20%\n",
      "39\tValidation loss: 1.466193\tBest loss: 1.466193\tAccuracy: 60.30%\n",
      "40\tValidation loss: 1.486606\tBest loss: 1.466193\tAccuracy: 59.50%\n",
      "41\tValidation loss: 1.467378\tBest loss: 1.466193\tAccuracy: 59.40%\n",
      "42\tValidation loss: 1.462790\tBest loss: 1.462790\tAccuracy: 59.50%\n",
      "43\tValidation loss: 1.478538\tBest loss: 1.462790\tAccuracy: 60.90%\n",
      "44\tValidation loss: 1.465732\tBest loss: 1.462790\tAccuracy: 60.30%\n",
      "45\tValidation loss: 1.445261\tBest loss: 1.445261\tAccuracy: 60.60%\n",
      "46\tValidation loss: 1.447094\tBest loss: 1.445261\tAccuracy: 60.20%\n",
      "47\tValidation loss: 1.439544\tBest loss: 1.439544\tAccuracy: 61.30%\n",
      "48\tValidation loss: 1.398618\tBest loss: 1.398618\tAccuracy: 62.70%\n",
      "49\tValidation loss: 1.423054\tBest loss: 1.398618\tAccuracy: 62.20%\n",
      "50\tValidation loss: 1.430048\tBest loss: 1.398618\tAccuracy: 61.30%\n",
      "51\tValidation loss: 1.403386\tBest loss: 1.398618\tAccuracy: 61.60%\n",
      "52\tValidation loss: 1.398472\tBest loss: 1.398472\tAccuracy: 63.10%\n",
      "53\tValidation loss: 1.393340\tBest loss: 1.393340\tAccuracy: 61.90%\n",
      "54\tValidation loss: 1.402981\tBest loss: 1.393340\tAccuracy: 63.00%\n",
      "55\tValidation loss: 1.403643\tBest loss: 1.393340\tAccuracy: 63.00%\n",
      "56\tValidation loss: 1.413123\tBest loss: 1.393340\tAccuracy: 62.70%\n",
      "57\tValidation loss: 1.355193\tBest loss: 1.355193\tAccuracy: 63.40%\n",
      "58\tValidation loss: 1.402223\tBest loss: 1.355193\tAccuracy: 62.60%\n",
      "59\tValidation loss: 1.387596\tBest loss: 1.355193\tAccuracy: 61.70%\n",
      "60\tValidation loss: 1.385495\tBest loss: 1.355193\tAccuracy: 62.50%\n",
      "61\tValidation loss: 1.375517\tBest loss: 1.355193\tAccuracy: 63.20%\n",
      "62\tValidation loss: 1.380817\tBest loss: 1.355193\tAccuracy: 62.60%\n",
      "63\tValidation loss: 1.342331\tBest loss: 1.342331\tAccuracy: 62.90%\n",
      "64\tValidation loss: 1.356142\tBest loss: 1.342331\tAccuracy: 63.50%\n",
      "65\tValidation loss: 1.354209\tBest loss: 1.342331\tAccuracy: 62.90%\n",
      "66\tValidation loss: 1.349895\tBest loss: 1.342331\tAccuracy: 64.30%\n",
      "67\tValidation loss: 1.379755\tBest loss: 1.342331\tAccuracy: 63.60%\n",
      "68\tValidation loss: 1.377264\tBest loss: 1.342331\tAccuracy: 64.40%\n",
      "69\tValidation loss: 1.317949\tBest loss: 1.317949\tAccuracy: 65.30%\n",
      "70\tValidation loss: 1.333228\tBest loss: 1.317949\tAccuracy: 62.80%\n",
      "71\tValidation loss: 1.363768\tBest loss: 1.317949\tAccuracy: 63.10%\n",
      "72\tValidation loss: 1.335955\tBest loss: 1.317949\tAccuracy: 65.10%\n",
      "73\tValidation loss: 1.341854\tBest loss: 1.317949\tAccuracy: 63.60%\n",
      "74\tValidation loss: 1.328230\tBest loss: 1.317949\tAccuracy: 64.60%\n",
      "75\tValidation loss: 1.313835\tBest loss: 1.313835\tAccuracy: 65.40%\n",
      "76\tValidation loss: 1.347817\tBest loss: 1.313835\tAccuracy: 64.00%\n",
      "77\tValidation loss: 1.345913\tBest loss: 1.313835\tAccuracy: 64.70%\n",
      "78\tValidation loss: 1.323743\tBest loss: 1.313835\tAccuracy: 64.60%\n",
      "79\tValidation loss: 1.327539\tBest loss: 1.313835\tAccuracy: 64.50%\n",
      "80\tValidation loss: 1.347134\tBest loss: 1.313835\tAccuracy: 64.00%\n",
      "81\tValidation loss: 1.324769\tBest loss: 1.313835\tAccuracy: 65.60%\n",
      "82\tValidation loss: 1.291077\tBest loss: 1.291077\tAccuracy: 65.40%\n",
      "83\tValidation loss: 1.291563\tBest loss: 1.291077\tAccuracy: 64.60%\n",
      "84\tValidation loss: 1.291308\tBest loss: 1.291077\tAccuracy: 65.60%\n",
      "85\tValidation loss: 1.325973\tBest loss: 1.291077\tAccuracy: 65.40%\n",
      "86\tValidation loss: 1.300233\tBest loss: 1.291077\tAccuracy: 66.20%\n",
      "87\tValidation loss: 1.298833\tBest loss: 1.291077\tAccuracy: 66.00%\n",
      "88\tValidation loss: 1.306547\tBest loss: 1.291077\tAccuracy: 66.70%\n",
      "89\tValidation loss: 1.294937\tBest loss: 1.291077\tAccuracy: 65.80%\n",
      "90\tValidation loss: 1.275525\tBest loss: 1.275525\tAccuracy: 67.10%\n",
      "91\tValidation loss: 1.296621\tBest loss: 1.275525\tAccuracy: 66.50%\n",
      "92\tValidation loss: 1.280388\tBest loss: 1.275525\tAccuracy: 66.50%\n",
      "93\tValidation loss: 1.311210\tBest loss: 1.275525\tAccuracy: 66.00%\n",
      "94\tValidation loss: 1.258321\tBest loss: 1.258321\tAccuracy: 67.20%\n",
      "95\tValidation loss: 1.301673\tBest loss: 1.258321\tAccuracy: 65.00%\n",
      "96\tValidation loss: 1.269699\tBest loss: 1.258321\tAccuracy: 67.00%\n",
      "97\tValidation loss: 1.297444\tBest loss: 1.258321\tAccuracy: 66.30%\n",
      "98\tValidation loss: 1.257959\tBest loss: 1.257959\tAccuracy: 66.40%\n",
      "99\tValidation loss: 1.261025\tBest loss: 1.257959\tAccuracy: 67.60%\n",
      "100\tValidation loss: 1.266229\tBest loss: 1.257959\tAccuracy: 66.80%\n",
      "101\tValidation loss: 1.273337\tBest loss: 1.257959\tAccuracy: 67.00%\n",
      "102\tValidation loss: 1.282827\tBest loss: 1.257959\tAccuracy: 66.50%\n",
      "103\tValidation loss: 1.295716\tBest loss: 1.257959\tAccuracy: 66.70%\n",
      "104\tValidation loss: 1.250419\tBest loss: 1.250419\tAccuracy: 67.40%\n",
      "105\tValidation loss: 1.275031\tBest loss: 1.250419\tAccuracy: 67.90%\n",
      "106\tValidation loss: 1.278344\tBest loss: 1.250419\tAccuracy: 66.80%\n",
      "107\tValidation loss: 1.294881\tBest loss: 1.250419\tAccuracy: 66.60%\n",
      "108\tValidation loss: 1.274310\tBest loss: 1.250419\tAccuracy: 67.40%\n",
      "109\tValidation loss: 1.281013\tBest loss: 1.250419\tAccuracy: 66.20%\n",
      "110\tValidation loss: 1.250414\tBest loss: 1.250414\tAccuracy: 67.40%\n",
      "111\tValidation loss: 1.238380\tBest loss: 1.238380\tAccuracy: 67.80%\n",
      "112\tValidation loss: 1.258043\tBest loss: 1.238380\tAccuracy: 67.10%\n",
      "113\tValidation loss: 1.261886\tBest loss: 1.238380\tAccuracy: 67.20%\n",
      "114\tValidation loss: 1.269669\tBest loss: 1.238380\tAccuracy: 67.90%\n",
      "115\tValidation loss: 1.250520\tBest loss: 1.238380\tAccuracy: 67.70%\n",
      "116\tValidation loss: 1.233313\tBest loss: 1.233313\tAccuracy: 67.90%\n",
      "117\tValidation loss: 1.251447\tBest loss: 1.233313\tAccuracy: 68.90%\n",
      "118\tValidation loss: 1.261418\tBest loss: 1.233313\tAccuracy: 67.60%\n",
      "119\tValidation loss: 1.226216\tBest loss: 1.226216\tAccuracy: 68.30%\n",
      "120\tValidation loss: 1.271440\tBest loss: 1.226216\tAccuracy: 68.40%\n",
      "121\tValidation loss: 1.245041\tBest loss: 1.226216\tAccuracy: 67.60%\n",
      "122\tValidation loss: 1.256626\tBest loss: 1.226216\tAccuracy: 68.10%\n",
      "123\tValidation loss: 1.249954\tBest loss: 1.226216\tAccuracy: 67.50%\n",
      "124\tValidation loss: 1.253415\tBest loss: 1.226216\tAccuracy: 67.80%\n",
      "125\tValidation loss: 1.243445\tBest loss: 1.226216\tAccuracy: 68.00%\n",
      "126\tValidation loss: 1.267994\tBest loss: 1.226216\tAccuracy: 68.30%\n",
      "127\tValidation loss: 1.244328\tBest loss: 1.226216\tAccuracy: 68.30%\n",
      "128\tValidation loss: 1.263331\tBest loss: 1.226216\tAccuracy: 67.20%\n",
      "129\tValidation loss: 1.251924\tBest loss: 1.226216\tAccuracy: 68.00%\n",
      "130\tValidation loss: 1.246718\tBest loss: 1.226216\tAccuracy: 67.70%\n",
      "131\tValidation loss: 1.242183\tBest loss: 1.226216\tAccuracy: 66.90%\n",
      "132\tValidation loss: 1.253823\tBest loss: 1.226216\tAccuracy: 67.00%\n",
      "133\tValidation loss: 1.230597\tBest loss: 1.226216\tAccuracy: 68.50%\n",
      "134\tValidation loss: 1.238299\tBest loss: 1.226216\tAccuracy: 68.00%\n",
      "135\tValidation loss: 1.235746\tBest loss: 1.226216\tAccuracy: 68.80%\n",
      "136\tValidation loss: 1.252843\tBest loss: 1.226216\tAccuracy: 67.50%\n",
      "137\tValidation loss: 1.227687\tBest loss: 1.226216\tAccuracy: 69.20%\n",
      "138\tValidation loss: 1.236753\tBest loss: 1.226216\tAccuracy: 67.30%\n",
      "139\tValidation loss: 1.259120\tBest loss: 1.226216\tAccuracy: 67.60%\n",
      "140\tValidation loss: 1.224297\tBest loss: 1.224297\tAccuracy: 68.10%\n",
      "141\tValidation loss: 1.226953\tBest loss: 1.224297\tAccuracy: 68.60%\n",
      "142\tValidation loss: 1.248601\tBest loss: 1.224297\tAccuracy: 67.60%\n",
      "143\tValidation loss: 1.218486\tBest loss: 1.218486\tAccuracy: 69.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\tValidation loss: 1.232960\tBest loss: 1.218486\tAccuracy: 67.80%\n",
      "145\tValidation loss: 1.228467\tBest loss: 1.218486\tAccuracy: 69.40%\n",
      "146\tValidation loss: 1.230110\tBest loss: 1.218486\tAccuracy: 68.30%\n",
      "147\tValidation loss: 1.257957\tBest loss: 1.218486\tAccuracy: 68.40%\n",
      "148\tValidation loss: 1.235100\tBest loss: 1.218486\tAccuracy: 68.20%\n",
      "149\tValidation loss: 1.238682\tBest loss: 1.218486\tAccuracy: 67.20%\n",
      "150\tValidation loss: 1.237091\tBest loss: 1.218486\tAccuracy: 67.10%\n",
      "151\tValidation loss: 1.207436\tBest loss: 1.207436\tAccuracy: 68.70%\n",
      "152\tValidation loss: 1.211480\tBest loss: 1.207436\tAccuracy: 69.10%\n",
      "153\tValidation loss: 1.229741\tBest loss: 1.207436\tAccuracy: 68.30%\n",
      "154\tValidation loss: 1.242174\tBest loss: 1.207436\tAccuracy: 67.70%\n",
      "155\tValidation loss: 1.218442\tBest loss: 1.207436\tAccuracy: 68.10%\n",
      "156\tValidation loss: 1.239855\tBest loss: 1.207436\tAccuracy: 67.80%\n",
      "157\tValidation loss: 1.242787\tBest loss: 1.207436\tAccuracy: 67.60%\n",
      "158\tValidation loss: 1.207568\tBest loss: 1.207436\tAccuracy: 68.60%\n",
      "159\tValidation loss: 1.206846\tBest loss: 1.206846\tAccuracy: 70.10%\n",
      "160\tValidation loss: 1.230213\tBest loss: 1.206846\tAccuracy: 68.70%\n",
      "161\tValidation loss: 1.251129\tBest loss: 1.206846\tAccuracy: 68.10%\n",
      "162\tValidation loss: 1.255316\tBest loss: 1.206846\tAccuracy: 67.80%\n",
      "163\tValidation loss: 1.207804\tBest loss: 1.206846\tAccuracy: 68.60%\n",
      "164\tValidation loss: 1.218935\tBest loss: 1.206846\tAccuracy: 69.10%\n",
      "165\tValidation loss: 1.242727\tBest loss: 1.206846\tAccuracy: 68.80%\n",
      "166\tValidation loss: 1.213610\tBest loss: 1.206846\tAccuracy: 68.00%\n",
      "167\tValidation loss: 1.231624\tBest loss: 1.206846\tAccuracy: 67.50%\n",
      "168\tValidation loss: 1.188838\tBest loss: 1.188838\tAccuracy: 69.20%\n",
      "169\tValidation loss: 1.229083\tBest loss: 1.188838\tAccuracy: 68.50%\n",
      "170\tValidation loss: 1.222830\tBest loss: 1.188838\tAccuracy: 69.20%\n",
      "171\tValidation loss: 1.230316\tBest loss: 1.188838\tAccuracy: 69.10%\n",
      "172\tValidation loss: 1.210385\tBest loss: 1.188838\tAccuracy: 69.40%\n",
      "173\tValidation loss: 1.223383\tBest loss: 1.188838\tAccuracy: 68.30%\n",
      "174\tValidation loss: 1.262409\tBest loss: 1.188838\tAccuracy: 69.20%\n",
      "175\tValidation loss: 1.239101\tBest loss: 1.188838\tAccuracy: 68.70%\n",
      "176\tValidation loss: 1.222446\tBest loss: 1.188838\tAccuracy: 69.40%\n",
      "177\tValidation loss: 1.228943\tBest loss: 1.188838\tAccuracy: 67.80%\n",
      "178\tValidation loss: 1.250376\tBest loss: 1.188838\tAccuracy: 68.00%\n",
      "179\tValidation loss: 1.222611\tBest loss: 1.188838\tAccuracy: 69.80%\n",
      "180\tValidation loss: 1.231849\tBest loss: 1.188838\tAccuracy: 68.50%\n",
      "181\tValidation loss: 1.211092\tBest loss: 1.188838\tAccuracy: 69.40%\n",
      "182\tValidation loss: 1.213169\tBest loss: 1.188838\tAccuracy: 68.40%\n",
      "183\tValidation loss: 1.207163\tBest loss: 1.188838\tAccuracy: 69.20%\n",
      "184\tValidation loss: 1.223908\tBest loss: 1.188838\tAccuracy: 70.60%\n",
      "185\tValidation loss: 1.222549\tBest loss: 1.188838\tAccuracy: 69.20%\n",
      "186\tValidation loss: 1.221777\tBest loss: 1.188838\tAccuracy: 69.00%\n",
      "187\tValidation loss: 1.178718\tBest loss: 1.178718\tAccuracy: 69.80%\n",
      "188\tValidation loss: 1.213548\tBest loss: 1.178718\tAccuracy: 69.00%\n",
      "189\tValidation loss: 1.200783\tBest loss: 1.178718\tAccuracy: 69.90%\n",
      "190\tValidation loss: 1.227272\tBest loss: 1.178718\tAccuracy: 68.60%\n",
      "191\tValidation loss: 1.230098\tBest loss: 1.178718\tAccuracy: 68.60%\n",
      "192\tValidation loss: 1.227977\tBest loss: 1.178718\tAccuracy: 69.80%\n",
      "193\tValidation loss: 1.216279\tBest loss: 1.178718\tAccuracy: 69.20%\n",
      "194\tValidation loss: 1.210005\tBest loss: 1.178718\tAccuracy: 69.10%\n",
      "195\tValidation loss: 1.221596\tBest loss: 1.178718\tAccuracy: 68.70%\n",
      "196\tValidation loss: 1.207865\tBest loss: 1.178718\tAccuracy: 69.60%\n",
      "197\tValidation loss: 1.229608\tBest loss: 1.178718\tAccuracy: 67.30%\n",
      "198\tValidation loss: 1.243131\tBest loss: 1.178718\tAccuracy: 69.10%\n",
      "199\tValidation loss: 1.219429\tBest loss: 1.178718\tAccuracy: 69.20%\n",
      "200\tValidation loss: 1.247862\tBest loss: 1.178718\tAccuracy: 68.50%\n",
      "201\tValidation loss: 1.224287\tBest loss: 1.178718\tAccuracy: 68.90%\n",
      "202\tValidation loss: 1.200670\tBest loss: 1.178718\tAccuracy: 69.20%\n",
      "203\tValidation loss: 1.203646\tBest loss: 1.178718\tAccuracy: 68.00%\n",
      "204\tValidation loss: 1.201037\tBest loss: 1.178718\tAccuracy: 68.50%\n",
      "205\tValidation loss: 1.211904\tBest loss: 1.178718\tAccuracy: 69.20%\n",
      "206\tValidation loss: 1.205211\tBest loss: 1.178718\tAccuracy: 68.50%\n",
      "207\tValidation loss: 1.273480\tBest loss: 1.178718\tAccuracy: 67.10%\n",
      "208\tValidation loss: 1.231778\tBest loss: 1.178718\tAccuracy: 68.30%\n",
      "Early stopping!\n",
      "[[  2.27357043e-14   1.33164466e-10   1.31498261e-08 ...,   1.72147949e-17\n",
      "    1.89868457e-16   7.23086637e-21]\n",
      " [  1.76120016e-20   6.37662073e-15   8.24939018e-20 ...,   0.00000000e+00\n",
      "    2.70079184e-31   9.89397726e-32]\n",
      " [  1.38949850e-11   4.20687662e-09   1.04097064e-10 ...,   2.59084052e-18\n",
      "    5.59687542e-17   1.83400302e-17]\n",
      " ..., \n",
      " [  5.71942437e-05   2.38438923e-04   2.71155732e-04 ...,   1.28952658e-03\n",
      "    1.90697575e-03   3.86671349e-03]\n",
      " [  3.37367856e-13   1.54984289e-11   8.10449188e-14 ...,   2.43726955e-03\n",
      "    4.02842322e-03   2.26788616e-04]\n",
      " [  4.35444703e-13   1.59889411e-11   2.47006972e-12 ...,   1.58946772e-04\n",
      "    8.52566119e-03   2.38460761e-05]]\n",
      "[14 43 43 ..., 36 25 27]\n",
      "[[  6.19631344e-21   7.02952236e-12   2.87496217e-16 ...,   5.42585680e-37\n",
      "    1.84928661e-33   1.75643942e-36]\n",
      " [  6.51047230e-02   3.32886577e-02   1.00699358e-01 ...,   3.67404637e-03\n",
      "    4.11351165e-03   3.22474097e-03]\n",
      " [  1.01437746e-23   3.16719217e-35   4.55220171e-14 ...,   1.87920272e-32\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  3.25490390e-09   2.83539112e-08   1.38151532e-10 ...,   2.34371343e-16\n",
      "    2.52361069e-19   7.52643936e-19]\n",
      " [  9.20085143e-03   5.52516244e-03   1.89629532e-02 ...,   1.15823401e-02\n",
      "    2.24025249e-02   8.42596591e-03]\n",
      " [  1.54984729e-26   2.13334101e-21   3.64778835e-26 ...,   6.90695197e-06\n",
      "    2.29549002e-07   9.16943073e-01]]\n",
      "[20 19 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=  24.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.689018\tBest loss: 3.689018\tAccuracy: 7.20%\n",
      "1\tValidation loss: 3.547453\tBest loss: 3.547453\tAccuracy: 7.00%\n",
      "2\tValidation loss: 3.331954\tBest loss: 3.331954\tAccuracy: 12.90%\n",
      "3\tValidation loss: 2.994703\tBest loss: 2.994703\tAccuracy: 20.90%\n",
      "4\tValidation loss: 2.827204\tBest loss: 2.827204\tAccuracy: 22.30%\n",
      "5\tValidation loss: 2.714980\tBest loss: 2.714980\tAccuracy: 24.50%\n",
      "6\tValidation loss: 2.586893\tBest loss: 2.586893\tAccuracy: 26.30%\n",
      "7\tValidation loss: 2.477654\tBest loss: 2.477654\tAccuracy: 31.00%\n",
      "8\tValidation loss: 2.408820\tBest loss: 2.408820\tAccuracy: 33.60%\n",
      "9\tValidation loss: 2.385228\tBest loss: 2.385228\tAccuracy: 33.80%\n",
      "10\tValidation loss: 2.273571\tBest loss: 2.273571\tAccuracy: 34.40%\n",
      "11\tValidation loss: 2.222147\tBest loss: 2.222147\tAccuracy: 39.10%\n",
      "12\tValidation loss: 2.153182\tBest loss: 2.153182\tAccuracy: 37.90%\n",
      "13\tValidation loss: 2.055870\tBest loss: 2.055870\tAccuracy: 42.60%\n",
      "14\tValidation loss: 2.019711\tBest loss: 2.019711\tAccuracy: 44.70%\n",
      "15\tValidation loss: 1.939076\tBest loss: 1.939076\tAccuracy: 47.50%\n",
      "16\tValidation loss: 1.897465\tBest loss: 1.897465\tAccuracy: 49.00%\n",
      "17\tValidation loss: 1.852452\tBest loss: 1.852452\tAccuracy: 50.90%\n",
      "18\tValidation loss: 1.782538\tBest loss: 1.782538\tAccuracy: 52.10%\n",
      "19\tValidation loss: 1.779071\tBest loss: 1.779071\tAccuracy: 51.30%\n",
      "20\tValidation loss: 1.760804\tBest loss: 1.760804\tAccuracy: 51.70%\n",
      "21\tValidation loss: 1.708055\tBest loss: 1.708055\tAccuracy: 55.00%\n",
      "22\tValidation loss: 1.690586\tBest loss: 1.690586\tAccuracy: 54.80%\n",
      "23\tValidation loss: 1.648419\tBest loss: 1.648419\tAccuracy: 56.10%\n",
      "24\tValidation loss: 1.627247\tBest loss: 1.627247\tAccuracy: 55.30%\n",
      "25\tValidation loss: 1.608088\tBest loss: 1.608088\tAccuracy: 55.50%\n",
      "26\tValidation loss: 1.602597\tBest loss: 1.602597\tAccuracy: 56.20%\n",
      "27\tValidation loss: 1.588824\tBest loss: 1.588824\tAccuracy: 55.80%\n",
      "28\tValidation loss: 1.615521\tBest loss: 1.588824\tAccuracy: 55.40%\n",
      "29\tValidation loss: 1.535193\tBest loss: 1.535193\tAccuracy: 56.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\tValidation loss: 1.516348\tBest loss: 1.516348\tAccuracy: 57.00%\n",
      "31\tValidation loss: 1.509710\tBest loss: 1.509710\tAccuracy: 58.60%\n",
      "32\tValidation loss: 1.527119\tBest loss: 1.509710\tAccuracy: 58.10%\n",
      "33\tValidation loss: 1.479234\tBest loss: 1.479234\tAccuracy: 58.80%\n",
      "34\tValidation loss: 1.462484\tBest loss: 1.462484\tAccuracy: 59.00%\n",
      "35\tValidation loss: 1.495146\tBest loss: 1.462484\tAccuracy: 59.00%\n",
      "36\tValidation loss: 1.428567\tBest loss: 1.428567\tAccuracy: 61.20%\n",
      "37\tValidation loss: 1.416965\tBest loss: 1.416965\tAccuracy: 60.80%\n",
      "38\tValidation loss: 1.416824\tBest loss: 1.416824\tAccuracy: 61.50%\n",
      "39\tValidation loss: 1.432318\tBest loss: 1.416824\tAccuracy: 61.00%\n",
      "40\tValidation loss: 1.410756\tBest loss: 1.410756\tAccuracy: 61.40%\n",
      "41\tValidation loss: 1.379217\tBest loss: 1.379217\tAccuracy: 61.20%\n",
      "42\tValidation loss: 1.401565\tBest loss: 1.379217\tAccuracy: 62.30%\n",
      "43\tValidation loss: 1.365980\tBest loss: 1.365980\tAccuracy: 63.80%\n",
      "44\tValidation loss: 1.388988\tBest loss: 1.365980\tAccuracy: 61.90%\n",
      "45\tValidation loss: 1.387186\tBest loss: 1.365980\tAccuracy: 60.90%\n",
      "46\tValidation loss: 1.370203\tBest loss: 1.365980\tAccuracy: 61.20%\n",
      "47\tValidation loss: 1.359732\tBest loss: 1.359732\tAccuracy: 61.70%\n",
      "48\tValidation loss: 1.407979\tBest loss: 1.359732\tAccuracy: 61.00%\n",
      "49\tValidation loss: 1.351956\tBest loss: 1.351956\tAccuracy: 62.20%\n",
      "50\tValidation loss: 1.342976\tBest loss: 1.342976\tAccuracy: 62.80%\n",
      "51\tValidation loss: 1.347533\tBest loss: 1.342976\tAccuracy: 62.50%\n",
      "52\tValidation loss: 1.318627\tBest loss: 1.318627\tAccuracy: 63.60%\n",
      "53\tValidation loss: 1.331627\tBest loss: 1.318627\tAccuracy: 64.60%\n",
      "54\tValidation loss: 1.324296\tBest loss: 1.318627\tAccuracy: 64.40%\n",
      "55\tValidation loss: 1.324331\tBest loss: 1.318627\tAccuracy: 63.50%\n",
      "56\tValidation loss: 1.290142\tBest loss: 1.290142\tAccuracy: 65.20%\n",
      "57\tValidation loss: 1.306659\tBest loss: 1.290142\tAccuracy: 64.20%\n",
      "58\tValidation loss: 1.297217\tBest loss: 1.290142\tAccuracy: 64.80%\n",
      "59\tValidation loss: 1.298376\tBest loss: 1.290142\tAccuracy: 63.90%\n",
      "60\tValidation loss: 1.311548\tBest loss: 1.290142\tAccuracy: 64.60%\n",
      "61\tValidation loss: 1.300859\tBest loss: 1.290142\tAccuracy: 64.40%\n",
      "62\tValidation loss: 1.273636\tBest loss: 1.273636\tAccuracy: 64.80%\n",
      "63\tValidation loss: 1.276377\tBest loss: 1.273636\tAccuracy: 64.60%\n",
      "64\tValidation loss: 1.249493\tBest loss: 1.249493\tAccuracy: 65.60%\n",
      "65\tValidation loss: 1.276781\tBest loss: 1.249493\tAccuracy: 63.30%\n",
      "66\tValidation loss: 1.258337\tBest loss: 1.249493\tAccuracy: 65.40%\n",
      "67\tValidation loss: 1.242426\tBest loss: 1.242426\tAccuracy: 66.00%\n",
      "68\tValidation loss: 1.218089\tBest loss: 1.218089\tAccuracy: 66.40%\n",
      "69\tValidation loss: 1.261714\tBest loss: 1.218089\tAccuracy: 65.30%\n",
      "70\tValidation loss: 1.227163\tBest loss: 1.218089\tAccuracy: 65.50%\n",
      "71\tValidation loss: 1.238298\tBest loss: 1.218089\tAccuracy: 65.00%\n",
      "72\tValidation loss: 1.250728\tBest loss: 1.218089\tAccuracy: 65.00%\n",
      "73\tValidation loss: 1.233090\tBest loss: 1.218089\tAccuracy: 65.70%\n",
      "74\tValidation loss: 1.235441\tBest loss: 1.218089\tAccuracy: 65.60%\n",
      "75\tValidation loss: 1.206295\tBest loss: 1.206295\tAccuracy: 66.60%\n",
      "76\tValidation loss: 1.204795\tBest loss: 1.204795\tAccuracy: 66.70%\n",
      "77\tValidation loss: 1.207405\tBest loss: 1.204795\tAccuracy: 67.50%\n",
      "78\tValidation loss: 1.244648\tBest loss: 1.204795\tAccuracy: 65.10%\n",
      "79\tValidation loss: 1.236331\tBest loss: 1.204795\tAccuracy: 67.00%\n",
      "80\tValidation loss: 1.212780\tBest loss: 1.204795\tAccuracy: 66.30%\n",
      "81\tValidation loss: 1.232018\tBest loss: 1.204795\tAccuracy: 67.50%\n",
      "82\tValidation loss: 1.235488\tBest loss: 1.204795\tAccuracy: 66.40%\n",
      "83\tValidation loss: 1.232898\tBest loss: 1.204795\tAccuracy: 65.20%\n",
      "84\tValidation loss: 1.185008\tBest loss: 1.185008\tAccuracy: 68.80%\n",
      "85\tValidation loss: 1.203437\tBest loss: 1.185008\tAccuracy: 67.20%\n",
      "86\tValidation loss: 1.205434\tBest loss: 1.185008\tAccuracy: 67.30%\n",
      "87\tValidation loss: 1.201497\tBest loss: 1.185008\tAccuracy: 66.70%\n",
      "88\tValidation loss: 1.199189\tBest loss: 1.185008\tAccuracy: 68.60%\n",
      "89\tValidation loss: 1.197593\tBest loss: 1.185008\tAccuracy: 66.70%\n",
      "90\tValidation loss: 1.174031\tBest loss: 1.174031\tAccuracy: 67.90%\n",
      "91\tValidation loss: 1.167377\tBest loss: 1.167377\tAccuracy: 68.60%\n",
      "92\tValidation loss: 1.174428\tBest loss: 1.167377\tAccuracy: 68.10%\n",
      "93\tValidation loss: 1.177369\tBest loss: 1.167377\tAccuracy: 67.80%\n",
      "94\tValidation loss: 1.202196\tBest loss: 1.167377\tAccuracy: 67.70%\n",
      "95\tValidation loss: 1.191486\tBest loss: 1.167377\tAccuracy: 67.30%\n",
      "96\tValidation loss: 1.186174\tBest loss: 1.167377\tAccuracy: 68.60%\n",
      "97\tValidation loss: 1.182488\tBest loss: 1.167377\tAccuracy: 68.10%\n",
      "98\tValidation loss: 1.173058\tBest loss: 1.167377\tAccuracy: 68.20%\n",
      "99\tValidation loss: 1.161987\tBest loss: 1.161987\tAccuracy: 68.10%\n",
      "100\tValidation loss: 1.197107\tBest loss: 1.161987\tAccuracy: 67.60%\n",
      "101\tValidation loss: 1.165909\tBest loss: 1.161987\tAccuracy: 68.40%\n",
      "102\tValidation loss: 1.174676\tBest loss: 1.161987\tAccuracy: 69.30%\n",
      "103\tValidation loss: 1.156681\tBest loss: 1.156681\tAccuracy: 68.00%\n",
      "104\tValidation loss: 1.148926\tBest loss: 1.148926\tAccuracy: 69.60%\n",
      "105\tValidation loss: 1.146174\tBest loss: 1.146174\tAccuracy: 68.50%\n",
      "106\tValidation loss: 1.159758\tBest loss: 1.146174\tAccuracy: 67.60%\n",
      "107\tValidation loss: 1.155681\tBest loss: 1.146174\tAccuracy: 69.20%\n",
      "108\tValidation loss: 1.171832\tBest loss: 1.146174\tAccuracy: 68.70%\n",
      "109\tValidation loss: 1.166725\tBest loss: 1.146174\tAccuracy: 68.00%\n",
      "110\tValidation loss: 1.138070\tBest loss: 1.138070\tAccuracy: 69.60%\n",
      "111\tValidation loss: 1.166747\tBest loss: 1.138070\tAccuracy: 68.70%\n",
      "112\tValidation loss: 1.147193\tBest loss: 1.138070\tAccuracy: 68.90%\n",
      "113\tValidation loss: 1.157410\tBest loss: 1.138070\tAccuracy: 69.20%\n",
      "114\tValidation loss: 1.177261\tBest loss: 1.138070\tAccuracy: 67.70%\n",
      "115\tValidation loss: 1.179826\tBest loss: 1.138070\tAccuracy: 68.40%\n",
      "116\tValidation loss: 1.167249\tBest loss: 1.138070\tAccuracy: 67.90%\n",
      "117\tValidation loss: 1.172638\tBest loss: 1.138070\tAccuracy: 68.90%\n",
      "118\tValidation loss: 1.150765\tBest loss: 1.138070\tAccuracy: 68.10%\n",
      "119\tValidation loss: 1.143856\tBest loss: 1.138070\tAccuracy: 69.50%\n",
      "120\tValidation loss: 1.184274\tBest loss: 1.138070\tAccuracy: 69.00%\n",
      "121\tValidation loss: 1.142913\tBest loss: 1.138070\tAccuracy: 68.70%\n",
      "122\tValidation loss: 1.129462\tBest loss: 1.129462\tAccuracy: 69.00%\n",
      "123\tValidation loss: 1.115034\tBest loss: 1.115034\tAccuracy: 69.00%\n",
      "124\tValidation loss: 1.139694\tBest loss: 1.115034\tAccuracy: 68.00%\n",
      "125\tValidation loss: 1.135017\tBest loss: 1.115034\tAccuracy: 69.40%\n",
      "126\tValidation loss: 1.153078\tBest loss: 1.115034\tAccuracy: 69.20%\n",
      "127\tValidation loss: 1.185159\tBest loss: 1.115034\tAccuracy: 68.00%\n",
      "128\tValidation loss: 1.141730\tBest loss: 1.115034\tAccuracy: 69.70%\n",
      "129\tValidation loss: 1.150716\tBest loss: 1.115034\tAccuracy: 68.70%\n",
      "130\tValidation loss: 1.149679\tBest loss: 1.115034\tAccuracy: 68.70%\n",
      "131\tValidation loss: 1.153986\tBest loss: 1.115034\tAccuracy: 68.90%\n",
      "132\tValidation loss: 1.143532\tBest loss: 1.115034\tAccuracy: 69.50%\n",
      "133\tValidation loss: 1.155277\tBest loss: 1.115034\tAccuracy: 69.00%\n",
      "134\tValidation loss: 1.120089\tBest loss: 1.115034\tAccuracy: 69.10%\n",
      "135\tValidation loss: 1.114496\tBest loss: 1.114496\tAccuracy: 69.30%\n",
      "136\tValidation loss: 1.112121\tBest loss: 1.112121\tAccuracy: 70.00%\n",
      "137\tValidation loss: 1.119382\tBest loss: 1.112121\tAccuracy: 69.20%\n",
      "138\tValidation loss: 1.145539\tBest loss: 1.112121\tAccuracy: 69.00%\n",
      "139\tValidation loss: 1.107257\tBest loss: 1.107257\tAccuracy: 70.60%\n",
      "140\tValidation loss: 1.126003\tBest loss: 1.107257\tAccuracy: 69.40%\n",
      "141\tValidation loss: 1.142818\tBest loss: 1.107257\tAccuracy: 69.40%\n",
      "142\tValidation loss: 1.124207\tBest loss: 1.107257\tAccuracy: 71.30%\n",
      "143\tValidation loss: 1.111759\tBest loss: 1.107257\tAccuracy: 70.50%\n",
      "144\tValidation loss: 1.141815\tBest loss: 1.107257\tAccuracy: 69.20%\n",
      "145\tValidation loss: 1.137534\tBest loss: 1.107257\tAccuracy: 69.60%\n",
      "146\tValidation loss: 1.138050\tBest loss: 1.107257\tAccuracy: 69.90%\n",
      "147\tValidation loss: 1.140388\tBest loss: 1.107257\tAccuracy: 69.70%\n",
      "148\tValidation loss: 1.132164\tBest loss: 1.107257\tAccuracy: 68.60%\n",
      "149\tValidation loss: 1.109990\tBest loss: 1.107257\tAccuracy: 69.60%\n",
      "150\tValidation loss: 1.145635\tBest loss: 1.107257\tAccuracy: 69.20%\n",
      "151\tValidation loss: 1.113114\tBest loss: 1.107257\tAccuracy: 69.90%\n",
      "152\tValidation loss: 1.135382\tBest loss: 1.107257\tAccuracy: 69.80%\n",
      "153\tValidation loss: 1.124863\tBest loss: 1.107257\tAccuracy: 69.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\tValidation loss: 1.124435\tBest loss: 1.107257\tAccuracy: 70.70%\n",
      "155\tValidation loss: 1.123443\tBest loss: 1.107257\tAccuracy: 68.80%\n",
      "156\tValidation loss: 1.122854\tBest loss: 1.107257\tAccuracy: 69.40%\n",
      "157\tValidation loss: 1.111359\tBest loss: 1.107257\tAccuracy: 69.80%\n",
      "158\tValidation loss: 1.163495\tBest loss: 1.107257\tAccuracy: 69.10%\n",
      "159\tValidation loss: 1.134256\tBest loss: 1.107257\tAccuracy: 69.80%\n",
      "160\tValidation loss: 1.148469\tBest loss: 1.107257\tAccuracy: 70.90%\n",
      "Early stopping!\n",
      "[[  2.69918091e-04   1.30174123e-03   1.48583425e-03 ...,   3.57364514e-03\n",
      "    8.83291978e-06   2.53893202e-04]\n",
      " [  0.00000000e+00   3.96234620e-30   5.20112943e-26 ...,   2.68183771e-28\n",
      "    6.17719159e-29   7.13274625e-30]\n",
      " [  1.18542873e-08   2.04643413e-07   8.76425984e-05 ...,   1.71155150e-07\n",
      "    2.92753754e-07   7.96798702e-07]\n",
      " ..., \n",
      " [  2.70718807e-08   1.03156816e-08   9.04810236e-07 ...,   5.10021884e-16\n",
      "    2.18209187e-17   1.40684185e-14]\n",
      " [  1.96884666e-02   1.16628790e-02   9.61112231e-03 ...,   2.33990885e-02\n",
      "    1.28031094e-02   1.05645675e-02]\n",
      " [  2.68047174e-28   1.13203011e-20   1.03055687e-26 ...,   6.20248102e-06\n",
      "    3.40009422e-07   9.82537329e-01]]\n",
      "[41 41 22 ...,  6 37 47]\n",
      "[[  1.62256852e-14   1.83601453e-10   2.36931958e-12 ...,   1.33329915e-14\n",
      "    1.46787313e-12   3.23869993e-11]\n",
      " [  4.78756055e-02   5.09751551e-02   8.04258808e-02 ...,   9.42449737e-03\n",
      "    3.47336684e-03   6.76518632e-03]\n",
      " [  3.53740194e-21   0.00000000e+00   1.03506309e-11 ...,   1.12485578e-23\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  8.93384276e-05   1.56783513e-04   3.42313433e-04 ...,   9.87225585e-03\n",
      "    1.31468044e-03   7.87355006e-03]\n",
      " [  6.22475189e-20   5.84913970e-17   1.03422011e-17 ...,   3.04957479e-03\n",
      "    5.10259742e-05   2.01136640e-06]\n",
      " [  1.96597855e-14   1.10278086e-13   9.16466208e-12 ...,   1.17191253e-02\n",
      "    1.34727059e-04   9.81557299e-04]]\n",
      "[20 19 16 ..., 36 26 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=1, n_neurons=100, learning_rate=0.05, activation=<function elu at 0x000002EE6B234268>, total=  18.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 6.723788\tBest loss: 6.723788\tAccuracy: 1.90%\n",
      "1\tValidation loss: 6.893806\tBest loss: 6.723788\tAccuracy: 3.10%\n",
      "2\tValidation loss: 6.568884\tBest loss: 6.568884\tAccuracy: 1.20%\n",
      "3\tValidation loss: 6.935696\tBest loss: 6.568884\tAccuracy: 3.30%\n",
      "4\tValidation loss: 8.093205\tBest loss: 6.568884\tAccuracy: 2.30%\n",
      "5\tValidation loss: 8.136354\tBest loss: 6.568884\tAccuracy: 2.20%\n",
      "6\tValidation loss: 10.144063\tBest loss: 6.568884\tAccuracy: 2.30%\n",
      "7\tValidation loss: 10.654512\tBest loss: 6.568884\tAccuracy: 1.60%\n",
      "8\tValidation loss: 8.003658\tBest loss: 6.568884\tAccuracy: 4.50%\n",
      "9\tValidation loss: 8.076790\tBest loss: 6.568884\tAccuracy: 3.20%\n",
      "10\tValidation loss: 6.637420\tBest loss: 6.568884\tAccuracy: 1.90%\n",
      "11\tValidation loss: 8.410521\tBest loss: 6.568884\tAccuracy: 2.00%\n",
      "12\tValidation loss: 9.052250\tBest loss: 6.568884\tAccuracy: 3.20%\n",
      "13\tValidation loss: 10.838417\tBest loss: 6.568884\tAccuracy: 3.60%\n",
      "14\tValidation loss: 9.891930\tBest loss: 6.568884\tAccuracy: 3.70%\n",
      "15\tValidation loss: 8.177234\tBest loss: 6.568884\tAccuracy: 4.00%\n",
      "16\tValidation loss: 8.297087\tBest loss: 6.568884\tAccuracy: 1.50%\n",
      "17\tValidation loss: 11.646987\tBest loss: 6.568884\tAccuracy: 3.60%\n",
      "18\tValidation loss: 15.187544\tBest loss: 6.568884\tAccuracy: 3.70%\n",
      "19\tValidation loss: 9.268324\tBest loss: 6.568884\tAccuracy: 3.20%\n",
      "20\tValidation loss: 12.327320\tBest loss: 6.568884\tAccuracy: 1.40%\n",
      "21\tValidation loss: 8.862485\tBest loss: 6.568884\tAccuracy: 2.70%\n",
      "22\tValidation loss: 14.522306\tBest loss: 6.568884\tAccuracy: 2.00%\n",
      "23\tValidation loss: 7.269414\tBest loss: 6.568884\tAccuracy: 3.60%\n",
      "Early stopping!\n",
      "[[  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " ..., \n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]]\n",
      "[15 15 15 ..., 15 15 15]\n",
      "[[  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " ..., \n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]\n",
      " [  3.02007375e-05   6.92289099e-02   7.74646737e-03 ...,   6.40275935e-03\n",
      "    8.07636604e-03   7.30619940e-05]]\n",
      "[15 15 15 ..., 15 15 15]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   9.8s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 5.436135\tBest loss: 5.436135\tAccuracy: 3.30%\n",
      "1\tValidation loss: 5.602588\tBest loss: 5.436135\tAccuracy: 3.70%\n",
      "2\tValidation loss: 10.196102\tBest loss: 5.436135\tAccuracy: 0.50%\n",
      "3\tValidation loss: 7.302875\tBest loss: 5.436135\tAccuracy: 2.30%\n",
      "4\tValidation loss: 7.921029\tBest loss: 5.436135\tAccuracy: 3.60%\n",
      "5\tValidation loss: 9.449243\tBest loss: 5.436135\tAccuracy: 3.70%\n",
      "6\tValidation loss: 8.767764\tBest loss: 5.436135\tAccuracy: 2.00%\n",
      "7\tValidation loss: 11.336471\tBest loss: 5.436135\tAccuracy: 1.20%\n",
      "8\tValidation loss: 8.503058\tBest loss: 5.436135\tAccuracy: 3.00%\n",
      "9\tValidation loss: 7.628940\tBest loss: 5.436135\tAccuracy: 2.20%\n",
      "10\tValidation loss: 11.269234\tBest loss: 5.436135\tAccuracy: 1.70%\n",
      "11\tValidation loss: 10.724405\tBest loss: 5.436135\tAccuracy: 3.70%\n",
      "12\tValidation loss: 12.846623\tBest loss: 5.436135\tAccuracy: 1.90%\n",
      "13\tValidation loss: 13.896979\tBest loss: 5.436135\tAccuracy: 3.70%\n",
      "14\tValidation loss: 9.464076\tBest loss: 5.436135\tAccuracy: 1.20%\n",
      "15\tValidation loss: 12.546621\tBest loss: 5.436135\tAccuracy: 0.60%\n",
      "16\tValidation loss: 10.110996\tBest loss: 5.436135\tAccuracy: 2.20%\n",
      "17\tValidation loss: 12.109221\tBest loss: 5.436135\tAccuracy: 3.70%\n",
      "18\tValidation loss: 10.999882\tBest loss: 5.436135\tAccuracy: 1.40%\n",
      "19\tValidation loss: 9.018826\tBest loss: 5.436135\tAccuracy: 2.60%\n",
      "20\tValidation loss: 12.831084\tBest loss: 5.436135\tAccuracy: 3.60%\n",
      "21\tValidation loss: 10.130681\tBest loss: 5.436135\tAccuracy: 1.90%\n",
      "Early stopping!\n",
      "[[ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " ..., \n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]]\n",
      "[3 3 3 ..., 3 3 3]\n",
      "[[ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " ..., \n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]\n",
      " [ 0.00314656  0.02224267  0.0356618  ...,  0.01162462  0.00476288\n",
      "   0.00081606]]\n",
      "[3 3 3 ..., 3 3 3]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   9.2s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 5.153953\tBest loss: 5.153953\tAccuracy: 4.50%\n",
      "1\tValidation loss: 7.049808\tBest loss: 5.153953\tAccuracy: 3.70%\n",
      "2\tValidation loss: 6.637350\tBest loss: 5.153953\tAccuracy: 1.70%\n",
      "3\tValidation loss: 6.617365\tBest loss: 5.153953\tAccuracy: 1.20%\n",
      "4\tValidation loss: 6.243746\tBest loss: 5.153953\tAccuracy: 3.00%\n",
      "5\tValidation loss: 7.214180\tBest loss: 5.153953\tAccuracy: 3.70%\n",
      "6\tValidation loss: 8.366961\tBest loss: 5.153953\tAccuracy: 1.90%\n",
      "7\tValidation loss: 6.430330\tBest loss: 5.153953\tAccuracy: 4.50%\n",
      "8\tValidation loss: 7.954460\tBest loss: 5.153953\tAccuracy: 0.90%\n",
      "9\tValidation loss: 8.469584\tBest loss: 5.153953\tAccuracy: 2.50%\n",
      "10\tValidation loss: 8.009077\tBest loss: 5.153953\tAccuracy: 3.60%\n",
      "11\tValidation loss: 11.390429\tBest loss: 5.153953\tAccuracy: 3.00%\n",
      "12\tValidation loss: 8.611215\tBest loss: 5.153953\tAccuracy: 1.40%\n",
      "13\tValidation loss: 9.812904\tBest loss: 5.153953\tAccuracy: 2.20%\n",
      "14\tValidation loss: 14.405178\tBest loss: 5.153953\tAccuracy: 3.10%\n",
      "15\tValidation loss: 9.754241\tBest loss: 5.153953\tAccuracy: 3.70%\n",
      "16\tValidation loss: 10.990605\tBest loss: 5.153953\tAccuracy: 1.70%\n",
      "17\tValidation loss: 9.178077\tBest loss: 5.153953\tAccuracy: 3.20%\n",
      "18\tValidation loss: 12.353984\tBest loss: 5.153953\tAccuracy: 2.50%\n",
      "19\tValidation loss: 7.757852\tBest loss: 5.153953\tAccuracy: 4.00%\n",
      "20\tValidation loss: 14.201728\tBest loss: 5.153953\tAccuracy: 3.30%\n",
      "21\tValidation loss: 12.296251\tBest loss: 5.153953\tAccuracy: 2.30%\n",
      "Early stopping!\n",
      "[[ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " ..., \n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]]\n",
      "[8 8 8 ..., 8 8 8]\n",
      "[[ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " ..., \n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]\n",
      " [ 0.00098674  0.01368255  0.05792695 ...,  0.05671916  0.00613203\n",
      "   0.01562428]]\n",
      "[8 8 8 ..., 8 8 8]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>, batch_size=50, dropout_rate=0.4, n_hidden_layers=4, n_neurons=150, learning_rate=0.1, activation=<function elu at 0x000002EE6B234268>, total=   9.6s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.432618\tBest loss: 3.432618\tAccuracy: 11.60%\n",
      "1\tValidation loss: 3.197527\tBest loss: 3.197527\tAccuracy: 14.90%\n",
      "2\tValidation loss: 2.975078\tBest loss: 2.975078\tAccuracy: 20.20%\n",
      "3\tValidation loss: 2.796657\tBest loss: 2.796657\tAccuracy: 25.50%\n",
      "4\tValidation loss: 2.674515\tBest loss: 2.674515\tAccuracy: 27.90%\n",
      "5\tValidation loss: 2.557900\tBest loss: 2.557900\tAccuracy: 31.40%\n",
      "6\tValidation loss: 2.431270\tBest loss: 2.431270\tAccuracy: 30.70%\n",
      "7\tValidation loss: 2.352745\tBest loss: 2.352745\tAccuracy: 34.40%\n",
      "8\tValidation loss: 2.293812\tBest loss: 2.293812\tAccuracy: 34.60%\n",
      "9\tValidation loss: 2.192073\tBest loss: 2.192073\tAccuracy: 34.80%\n",
      "10\tValidation loss: 2.149213\tBest loss: 2.149213\tAccuracy: 38.00%\n",
      "11\tValidation loss: 2.068256\tBest loss: 2.068256\tAccuracy: 40.10%\n",
      "12\tValidation loss: 1.997147\tBest loss: 1.997147\tAccuracy: 41.70%\n",
      "13\tValidation loss: 1.944566\tBest loss: 1.944566\tAccuracy: 45.00%\n",
      "14\tValidation loss: 1.904760\tBest loss: 1.904760\tAccuracy: 45.60%\n",
      "15\tValidation loss: 1.878677\tBest loss: 1.878677\tAccuracy: 44.80%\n",
      "16\tValidation loss: 1.825350\tBest loss: 1.825350\tAccuracy: 49.30%\n",
      "17\tValidation loss: 1.813216\tBest loss: 1.813216\tAccuracy: 47.70%\n",
      "18\tValidation loss: 1.760612\tBest loss: 1.760612\tAccuracy: 50.00%\n",
      "19\tValidation loss: 1.739085\tBest loss: 1.739085\tAccuracy: 49.10%\n",
      "20\tValidation loss: 1.689142\tBest loss: 1.689142\tAccuracy: 52.20%\n",
      "21\tValidation loss: 1.655473\tBest loss: 1.655473\tAccuracy: 53.20%\n",
      "22\tValidation loss: 1.617996\tBest loss: 1.617996\tAccuracy: 54.10%\n",
      "23\tValidation loss: 1.599170\tBest loss: 1.599170\tAccuracy: 55.00%\n",
      "24\tValidation loss: 1.587786\tBest loss: 1.587786\tAccuracy: 55.60%\n",
      "25\tValidation loss: 1.560872\tBest loss: 1.560872\tAccuracy: 55.50%\n",
      "26\tValidation loss: 1.530327\tBest loss: 1.530327\tAccuracy: 56.60%\n",
      "27\tValidation loss: 1.514208\tBest loss: 1.514208\tAccuracy: 57.50%\n",
      "28\tValidation loss: 1.493890\tBest loss: 1.493890\tAccuracy: 57.50%\n",
      "29\tValidation loss: 1.478395\tBest loss: 1.478395\tAccuracy: 57.80%\n",
      "30\tValidation loss: 1.444614\tBest loss: 1.444614\tAccuracy: 58.60%\n",
      "31\tValidation loss: 1.442769\tBest loss: 1.442769\tAccuracy: 59.30%\n",
      "32\tValidation loss: 1.424674\tBest loss: 1.424674\tAccuracy: 59.50%\n",
      "33\tValidation loss: 1.406539\tBest loss: 1.406539\tAccuracy: 59.40%\n",
      "34\tValidation loss: 1.389837\tBest loss: 1.389837\tAccuracy: 58.60%\n",
      "35\tValidation loss: 1.376551\tBest loss: 1.376551\tAccuracy: 59.90%\n",
      "36\tValidation loss: 1.349928\tBest loss: 1.349928\tAccuracy: 60.60%\n",
      "37\tValidation loss: 1.353896\tBest loss: 1.349928\tAccuracy: 61.70%\n",
      "38\tValidation loss: 1.352228\tBest loss: 1.349928\tAccuracy: 60.00%\n",
      "39\tValidation loss: 1.325759\tBest loss: 1.325759\tAccuracy: 62.20%\n",
      "40\tValidation loss: 1.310822\tBest loss: 1.310822\tAccuracy: 62.10%\n",
      "41\tValidation loss: 1.315299\tBest loss: 1.310822\tAccuracy: 60.90%\n",
      "42\tValidation loss: 1.295168\tBest loss: 1.295168\tAccuracy: 61.60%\n",
      "43\tValidation loss: 1.280701\tBest loss: 1.280701\tAccuracy: 63.00%\n",
      "44\tValidation loss: 1.284536\tBest loss: 1.280701\tAccuracy: 62.40%\n",
      "45\tValidation loss: 1.271118\tBest loss: 1.271118\tAccuracy: 63.00%\n",
      "46\tValidation loss: 1.263228\tBest loss: 1.263228\tAccuracy: 62.70%\n",
      "47\tValidation loss: 1.243920\tBest loss: 1.243920\tAccuracy: 62.80%\n",
      "48\tValidation loss: 1.239766\tBest loss: 1.239766\tAccuracy: 63.20%\n",
      "49\tValidation loss: 1.258190\tBest loss: 1.239766\tAccuracy: 63.20%\n",
      "50\tValidation loss: 1.235016\tBest loss: 1.235016\tAccuracy: 63.90%\n",
      "51\tValidation loss: 1.232530\tBest loss: 1.232530\tAccuracy: 63.30%\n",
      "52\tValidation loss: 1.232504\tBest loss: 1.232504\tAccuracy: 63.20%\n",
      "53\tValidation loss: 1.209994\tBest loss: 1.209994\tAccuracy: 64.10%\n",
      "54\tValidation loss: 1.213898\tBest loss: 1.209994\tAccuracy: 64.50%\n",
      "55\tValidation loss: 1.197384\tBest loss: 1.197384\tAccuracy: 64.20%\n",
      "56\tValidation loss: 1.201729\tBest loss: 1.197384\tAccuracy: 64.80%\n",
      "57\tValidation loss: 1.171641\tBest loss: 1.171641\tAccuracy: 66.00%\n",
      "58\tValidation loss: 1.181971\tBest loss: 1.171641\tAccuracy: 65.00%\n",
      "59\tValidation loss: 1.192608\tBest loss: 1.171641\tAccuracy: 64.40%\n",
      "60\tValidation loss: 1.180302\tBest loss: 1.171641\tAccuracy: 64.80%\n",
      "61\tValidation loss: 1.191156\tBest loss: 1.171641\tAccuracy: 65.30%\n",
      "62\tValidation loss: 1.176081\tBest loss: 1.171641\tAccuracy: 65.40%\n",
      "63\tValidation loss: 1.180313\tBest loss: 1.171641\tAccuracy: 65.30%\n",
      "64\tValidation loss: 1.175654\tBest loss: 1.171641\tAccuracy: 65.30%\n",
      "65\tValidation loss: 1.150870\tBest loss: 1.150870\tAccuracy: 65.00%\n",
      "66\tValidation loss: 1.145536\tBest loss: 1.145536\tAccuracy: 65.10%\n",
      "67\tValidation loss: 1.135168\tBest loss: 1.135168\tAccuracy: 66.40%\n",
      "68\tValidation loss: 1.152000\tBest loss: 1.135168\tAccuracy: 65.20%\n",
      "69\tValidation loss: 1.134801\tBest loss: 1.134801\tAccuracy: 65.90%\n",
      "70\tValidation loss: 1.131196\tBest loss: 1.131196\tAccuracy: 66.40%\n",
      "71\tValidation loss: 1.132161\tBest loss: 1.131196\tAccuracy: 65.70%\n",
      "72\tValidation loss: 1.129402\tBest loss: 1.129402\tAccuracy: 67.50%\n",
      "73\tValidation loss: 1.118829\tBest loss: 1.118829\tAccuracy: 67.30%\n",
      "74\tValidation loss: 1.123724\tBest loss: 1.118829\tAccuracy: 65.90%\n",
      "75\tValidation loss: 1.120603\tBest loss: 1.118829\tAccuracy: 66.30%\n",
      "76\tValidation loss: 1.120849\tBest loss: 1.118829\tAccuracy: 66.30%\n",
      "77\tValidation loss: 1.113160\tBest loss: 1.113160\tAccuracy: 66.80%\n",
      "78\tValidation loss: 1.126880\tBest loss: 1.113160\tAccuracy: 66.80%\n",
      "79\tValidation loss: 1.096563\tBest loss: 1.096563\tAccuracy: 67.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\tValidation loss: 1.097989\tBest loss: 1.096563\tAccuracy: 66.60%\n",
      "81\tValidation loss: 1.090706\tBest loss: 1.090706\tAccuracy: 68.00%\n",
      "82\tValidation loss: 1.088207\tBest loss: 1.088207\tAccuracy: 66.40%\n",
      "83\tValidation loss: 1.080825\tBest loss: 1.080825\tAccuracy: 67.40%\n",
      "84\tValidation loss: 1.088618\tBest loss: 1.080825\tAccuracy: 67.30%\n",
      "85\tValidation loss: 1.075302\tBest loss: 1.075302\tAccuracy: 68.20%\n",
      "86\tValidation loss: 1.076226\tBest loss: 1.075302\tAccuracy: 67.00%\n",
      "87\tValidation loss: 1.081955\tBest loss: 1.075302\tAccuracy: 67.40%\n",
      "88\tValidation loss: 1.063049\tBest loss: 1.063049\tAccuracy: 67.50%\n",
      "89\tValidation loss: 1.063063\tBest loss: 1.063049\tAccuracy: 67.00%\n",
      "90\tValidation loss: 1.071767\tBest loss: 1.063049\tAccuracy: 66.70%\n",
      "91\tValidation loss: 1.070257\tBest loss: 1.063049\tAccuracy: 68.10%\n",
      "92\tValidation loss: 1.062534\tBest loss: 1.062534\tAccuracy: 68.10%\n",
      "93\tValidation loss: 1.055562\tBest loss: 1.055562\tAccuracy: 68.60%\n",
      "94\tValidation loss: 1.062480\tBest loss: 1.055562\tAccuracy: 67.90%\n",
      "95\tValidation loss: 1.059582\tBest loss: 1.055562\tAccuracy: 67.60%\n",
      "96\tValidation loss: 1.071813\tBest loss: 1.055562\tAccuracy: 67.70%\n",
      "97\tValidation loss: 1.052759\tBest loss: 1.052759\tAccuracy: 68.70%\n",
      "98\tValidation loss: 1.054417\tBest loss: 1.052759\tAccuracy: 68.40%\n",
      "99\tValidation loss: 1.066517\tBest loss: 1.052759\tAccuracy: 67.00%\n",
      "100\tValidation loss: 1.042175\tBest loss: 1.042175\tAccuracy: 68.40%\n",
      "101\tValidation loss: 1.029797\tBest loss: 1.029797\tAccuracy: 68.20%\n",
      "102\tValidation loss: 1.046415\tBest loss: 1.029797\tAccuracy: 68.10%\n",
      "103\tValidation loss: 1.038252\tBest loss: 1.029797\tAccuracy: 68.20%\n",
      "104\tValidation loss: 1.021721\tBest loss: 1.021721\tAccuracy: 68.20%\n",
      "105\tValidation loss: 1.028872\tBest loss: 1.021721\tAccuracy: 69.10%\n",
      "106\tValidation loss: 1.031051\tBest loss: 1.021721\tAccuracy: 68.50%\n",
      "107\tValidation loss: 1.043586\tBest loss: 1.021721\tAccuracy: 68.10%\n",
      "108\tValidation loss: 1.034173\tBest loss: 1.021721\tAccuracy: 69.70%\n",
      "109\tValidation loss: 1.022552\tBest loss: 1.021721\tAccuracy: 69.00%\n",
      "110\tValidation loss: 1.028347\tBest loss: 1.021721\tAccuracy: 69.20%\n",
      "111\tValidation loss: 1.025919\tBest loss: 1.021721\tAccuracy: 68.20%\n",
      "112\tValidation loss: 1.024894\tBest loss: 1.021721\tAccuracy: 69.60%\n",
      "113\tValidation loss: 1.018232\tBest loss: 1.018232\tAccuracy: 68.30%\n",
      "114\tValidation loss: 1.015377\tBest loss: 1.015377\tAccuracy: 69.30%\n",
      "115\tValidation loss: 1.027027\tBest loss: 1.015377\tAccuracy: 67.50%\n",
      "116\tValidation loss: 1.023681\tBest loss: 1.015377\tAccuracy: 68.60%\n",
      "117\tValidation loss: 1.008830\tBest loss: 1.008830\tAccuracy: 69.10%\n",
      "118\tValidation loss: 1.010858\tBest loss: 1.008830\tAccuracy: 68.40%\n",
      "119\tValidation loss: 1.016207\tBest loss: 1.008830\tAccuracy: 69.50%\n",
      "120\tValidation loss: 1.018055\tBest loss: 1.008830\tAccuracy: 68.20%\n",
      "121\tValidation loss: 1.013900\tBest loss: 1.008830\tAccuracy: 68.50%\n",
      "122\tValidation loss: 1.001270\tBest loss: 1.001270\tAccuracy: 69.30%\n",
      "123\tValidation loss: 1.000054\tBest loss: 1.000054\tAccuracy: 69.50%\n",
      "124\tValidation loss: 1.014765\tBest loss: 1.000054\tAccuracy: 69.90%\n",
      "125\tValidation loss: 1.010003\tBest loss: 1.000054\tAccuracy: 68.90%\n",
      "126\tValidation loss: 1.000193\tBest loss: 1.000054\tAccuracy: 69.90%\n",
      "127\tValidation loss: 0.996888\tBest loss: 0.996888\tAccuracy: 69.40%\n",
      "128\tValidation loss: 0.998717\tBest loss: 0.996888\tAccuracy: 68.50%\n",
      "129\tValidation loss: 1.001851\tBest loss: 0.996888\tAccuracy: 69.10%\n",
      "130\tValidation loss: 0.996156\tBest loss: 0.996156\tAccuracy: 69.10%\n",
      "131\tValidation loss: 0.993573\tBest loss: 0.993573\tAccuracy: 68.90%\n",
      "132\tValidation loss: 0.988014\tBest loss: 0.988014\tAccuracy: 69.40%\n",
      "133\tValidation loss: 0.991380\tBest loss: 0.988014\tAccuracy: 69.20%\n",
      "134\tValidation loss: 0.987755\tBest loss: 0.987755\tAccuracy: 69.80%\n",
      "135\tValidation loss: 0.989360\tBest loss: 0.987755\tAccuracy: 69.70%\n",
      "136\tValidation loss: 0.985620\tBest loss: 0.985620\tAccuracy: 69.20%\n",
      "137\tValidation loss: 0.972706\tBest loss: 0.972706\tAccuracy: 70.80%\n",
      "138\tValidation loss: 0.991307\tBest loss: 0.972706\tAccuracy: 69.60%\n",
      "139\tValidation loss: 0.987829\tBest loss: 0.972706\tAccuracy: 70.30%\n",
      "140\tValidation loss: 0.991744\tBest loss: 0.972706\tAccuracy: 70.30%\n",
      "141\tValidation loss: 0.979313\tBest loss: 0.972706\tAccuracy: 70.80%\n",
      "142\tValidation loss: 0.983857\tBest loss: 0.972706\tAccuracy: 69.30%\n",
      "143\tValidation loss: 0.984053\tBest loss: 0.972706\tAccuracy: 69.30%\n",
      "144\tValidation loss: 0.977442\tBest loss: 0.972706\tAccuracy: 70.50%\n",
      "145\tValidation loss: 0.976478\tBest loss: 0.972706\tAccuracy: 70.50%\n",
      "146\tValidation loss: 0.974434\tBest loss: 0.972706\tAccuracy: 70.20%\n",
      "147\tValidation loss: 0.972117\tBest loss: 0.972117\tAccuracy: 70.60%\n",
      "148\tValidation loss: 0.966749\tBest loss: 0.966749\tAccuracy: 70.40%\n",
      "149\tValidation loss: 0.966121\tBest loss: 0.966121\tAccuracy: 69.90%\n",
      "150\tValidation loss: 0.974885\tBest loss: 0.966121\tAccuracy: 70.20%\n",
      "151\tValidation loss: 0.971753\tBest loss: 0.966121\tAccuracy: 69.90%\n",
      "152\tValidation loss: 0.992218\tBest loss: 0.966121\tAccuracy: 69.20%\n",
      "153\tValidation loss: 0.958891\tBest loss: 0.958891\tAccuracy: 71.50%\n",
      "154\tValidation loss: 0.962756\tBest loss: 0.958891\tAccuracy: 70.20%\n",
      "155\tValidation loss: 0.960902\tBest loss: 0.958891\tAccuracy: 70.30%\n",
      "156\tValidation loss: 0.956157\tBest loss: 0.956157\tAccuracy: 70.90%\n",
      "157\tValidation loss: 0.967626\tBest loss: 0.956157\tAccuracy: 70.40%\n",
      "158\tValidation loss: 0.953365\tBest loss: 0.953365\tAccuracy: 70.20%\n",
      "159\tValidation loss: 0.964055\tBest loss: 0.953365\tAccuracy: 70.50%\n",
      "160\tValidation loss: 0.956449\tBest loss: 0.953365\tAccuracy: 71.30%\n",
      "161\tValidation loss: 0.950417\tBest loss: 0.950417\tAccuracy: 71.00%\n",
      "162\tValidation loss: 0.942009\tBest loss: 0.942009\tAccuracy: 70.80%\n",
      "163\tValidation loss: 0.954211\tBest loss: 0.942009\tAccuracy: 70.90%\n",
      "164\tValidation loss: 0.953758\tBest loss: 0.942009\tAccuracy: 71.10%\n",
      "165\tValidation loss: 0.950507\tBest loss: 0.942009\tAccuracy: 71.10%\n",
      "166\tValidation loss: 0.960255\tBest loss: 0.942009\tAccuracy: 70.90%\n",
      "167\tValidation loss: 0.966407\tBest loss: 0.942009\tAccuracy: 70.50%\n",
      "168\tValidation loss: 0.962370\tBest loss: 0.942009\tAccuracy: 71.10%\n",
      "169\tValidation loss: 0.962074\tBest loss: 0.942009\tAccuracy: 70.80%\n",
      "170\tValidation loss: 0.960078\tBest loss: 0.942009\tAccuracy: 70.50%\n",
      "171\tValidation loss: 0.949440\tBest loss: 0.942009\tAccuracy: 71.80%\n",
      "172\tValidation loss: 0.957697\tBest loss: 0.942009\tAccuracy: 71.70%\n",
      "173\tValidation loss: 0.958971\tBest loss: 0.942009\tAccuracy: 70.90%\n",
      "174\tValidation loss: 0.956747\tBest loss: 0.942009\tAccuracy: 71.20%\n",
      "175\tValidation loss: 0.952137\tBest loss: 0.942009\tAccuracy: 70.90%\n",
      "176\tValidation loss: 0.947254\tBest loss: 0.942009\tAccuracy: 71.40%\n",
      "177\tValidation loss: 0.947884\tBest loss: 0.942009\tAccuracy: 71.00%\n",
      "178\tValidation loss: 0.935568\tBest loss: 0.935568\tAccuracy: 71.20%\n",
      "179\tValidation loss: 0.949117\tBest loss: 0.935568\tAccuracy: 70.90%\n",
      "180\tValidation loss: 0.953655\tBest loss: 0.935568\tAccuracy: 71.10%\n",
      "181\tValidation loss: 0.954326\tBest loss: 0.935568\tAccuracy: 71.30%\n",
      "182\tValidation loss: 0.939004\tBest loss: 0.935568\tAccuracy: 70.90%\n",
      "183\tValidation loss: 0.947705\tBest loss: 0.935568\tAccuracy: 72.40%\n",
      "184\tValidation loss: 0.952983\tBest loss: 0.935568\tAccuracy: 71.80%\n",
      "185\tValidation loss: 0.942620\tBest loss: 0.935568\tAccuracy: 71.10%\n",
      "186\tValidation loss: 0.950633\tBest loss: 0.935568\tAccuracy: 71.10%\n",
      "187\tValidation loss: 0.945100\tBest loss: 0.935568\tAccuracy: 71.30%\n",
      "188\tValidation loss: 0.947870\tBest loss: 0.935568\tAccuracy: 70.90%\n",
      "189\tValidation loss: 0.938745\tBest loss: 0.935568\tAccuracy: 70.50%\n",
      "190\tValidation loss: 0.941145\tBest loss: 0.935568\tAccuracy: 71.60%\n",
      "191\tValidation loss: 0.951092\tBest loss: 0.935568\tAccuracy: 70.80%\n",
      "192\tValidation loss: 0.936810\tBest loss: 0.935568\tAccuracy: 71.10%\n",
      "193\tValidation loss: 0.943891\tBest loss: 0.935568\tAccuracy: 70.80%\n",
      "194\tValidation loss: 0.945464\tBest loss: 0.935568\tAccuracy: 71.90%\n",
      "195\tValidation loss: 0.934358\tBest loss: 0.934358\tAccuracy: 71.70%\n",
      "196\tValidation loss: 0.942684\tBest loss: 0.934358\tAccuracy: 71.50%\n",
      "197\tValidation loss: 0.939481\tBest loss: 0.934358\tAccuracy: 72.00%\n",
      "198\tValidation loss: 0.932678\tBest loss: 0.932678\tAccuracy: 71.80%\n",
      "199\tValidation loss: 0.934992\tBest loss: 0.932678\tAccuracy: 71.40%\n",
      "200\tValidation loss: 0.926714\tBest loss: 0.926714\tAccuracy: 71.90%\n",
      "201\tValidation loss: 0.936399\tBest loss: 0.926714\tAccuracy: 71.60%\n",
      "202\tValidation loss: 0.924360\tBest loss: 0.924360\tAccuracy: 72.30%\n",
      "203\tValidation loss: 0.939776\tBest loss: 0.924360\tAccuracy: 71.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\tValidation loss: 0.930258\tBest loss: 0.924360\tAccuracy: 71.70%\n",
      "205\tValidation loss: 0.933976\tBest loss: 0.924360\tAccuracy: 72.40%\n",
      "206\tValidation loss: 0.934849\tBest loss: 0.924360\tAccuracy: 71.10%\n",
      "207\tValidation loss: 0.937393\tBest loss: 0.924360\tAccuracy: 70.80%\n",
      "208\tValidation loss: 0.931032\tBest loss: 0.924360\tAccuracy: 71.90%\n",
      "209\tValidation loss: 0.934476\tBest loss: 0.924360\tAccuracy: 71.50%\n",
      "210\tValidation loss: 0.938689\tBest loss: 0.924360\tAccuracy: 71.50%\n",
      "211\tValidation loss: 0.929176\tBest loss: 0.924360\tAccuracy: 71.70%\n",
      "212\tValidation loss: 0.933003\tBest loss: 0.924360\tAccuracy: 71.80%\n",
      "213\tValidation loss: 0.926143\tBest loss: 0.924360\tAccuracy: 71.80%\n",
      "214\tValidation loss: 0.924028\tBest loss: 0.924028\tAccuracy: 72.00%\n",
      "215\tValidation loss: 0.926777\tBest loss: 0.924028\tAccuracy: 71.20%\n",
      "216\tValidation loss: 0.930319\tBest loss: 0.924028\tAccuracy: 71.70%\n",
      "217\tValidation loss: 0.926116\tBest loss: 0.924028\tAccuracy: 71.90%\n",
      "218\tValidation loss: 0.921748\tBest loss: 0.921748\tAccuracy: 71.40%\n",
      "219\tValidation loss: 0.922304\tBest loss: 0.921748\tAccuracy: 71.90%\n",
      "220\tValidation loss: 0.924740\tBest loss: 0.921748\tAccuracy: 71.90%\n",
      "221\tValidation loss: 0.924911\tBest loss: 0.921748\tAccuracy: 72.10%\n",
      "222\tValidation loss: 0.922718\tBest loss: 0.921748\tAccuracy: 72.10%\n",
      "223\tValidation loss: 0.945397\tBest loss: 0.921748\tAccuracy: 71.80%\n",
      "224\tValidation loss: 0.953869\tBest loss: 0.921748\tAccuracy: 71.30%\n",
      "225\tValidation loss: 0.936758\tBest loss: 0.921748\tAccuracy: 71.70%\n",
      "226\tValidation loss: 0.937771\tBest loss: 0.921748\tAccuracy: 72.20%\n",
      "227\tValidation loss: 0.935662\tBest loss: 0.921748\tAccuracy: 72.30%\n",
      "228\tValidation loss: 0.927336\tBest loss: 0.921748\tAccuracy: 72.50%\n",
      "229\tValidation loss: 0.933677\tBest loss: 0.921748\tAccuracy: 71.90%\n",
      "230\tValidation loss: 0.930857\tBest loss: 0.921748\tAccuracy: 71.70%\n",
      "231\tValidation loss: 0.935311\tBest loss: 0.921748\tAccuracy: 71.90%\n",
      "232\tValidation loss: 0.932030\tBest loss: 0.921748\tAccuracy: 71.40%\n",
      "233\tValidation loss: 0.926138\tBest loss: 0.921748\tAccuracy: 71.50%\n",
      "234\tValidation loss: 0.933627\tBest loss: 0.921748\tAccuracy: 71.50%\n",
      "235\tValidation loss: 0.922854\tBest loss: 0.921748\tAccuracy: 72.00%\n",
      "236\tValidation loss: 0.939087\tBest loss: 0.921748\tAccuracy: 70.80%\n",
      "237\tValidation loss: 0.942216\tBest loss: 0.921748\tAccuracy: 71.50%\n",
      "238\tValidation loss: 0.925904\tBest loss: 0.921748\tAccuracy: 71.40%\n",
      "239\tValidation loss: 0.926349\tBest loss: 0.921748\tAccuracy: 71.70%\n",
      "Early stopping!\n",
      "[[  9.66188463e-10   3.52904976e-06   1.41731584e-06 ...,   2.34015910e-12\n",
      "    2.80034026e-15   2.01470839e-13]\n",
      " [  5.10697141e-02   2.00939178e-02   1.25981018e-01 ...,   1.50357699e-03\n",
      "    1.20689860e-03   5.47321455e-04]\n",
      " [  4.87971573e-11   3.05397226e-16   1.36557172e-11 ...,   2.99766566e-11\n",
      "    1.55323023e-14   9.91162972e-15]\n",
      " ..., \n",
      " [  2.50763363e-16   1.98375561e-15   3.94927173e-19 ...,   1.81376067e-10\n",
      "    4.91008623e-11   2.35802506e-11]\n",
      " [  4.49260406e-04   9.64891806e-05   3.26542446e-04 ...,   8.81874487e-02\n",
      "    1.32852548e-03   3.73319048e-03]\n",
      " [  1.06843629e-06   3.63809356e-08   1.62437644e-07 ...,   2.50072364e-04\n",
      "    9.85831866e-06   1.58639465e-04]]\n",
      "[20 19 16 ...,  6 26 36]\n",
      "[[  2.90447042e-05   1.99903461e-05   2.61010224e-04 ...,   1.39084605e-07\n",
      "    1.21428478e-10   1.67625183e-06]\n",
      " [  1.82577686e-11   3.97508648e-09   4.37066688e-10 ...,   1.15474032e-15\n",
      "    8.82409278e-17   1.68213630e-17]\n",
      " [  3.52747542e-09   2.35714470e-09   4.94627506e-10 ...,   6.10378970e-11\n",
      "    1.81260863e-13   6.03235300e-12]\n",
      " ..., \n",
      " [  1.81436246e-06   1.50324070e-07   1.10441954e-06 ...,   7.09988202e-09\n",
      "    4.72443048e-12   6.73265055e-11]\n",
      " [  1.23272371e-02   4.33230819e-03   1.09717380e-02 ...,   2.01795064e-02\n",
      "    1.71957277e-02   1.45543655e-02]\n",
      " [  6.93522625e-16   1.16947549e-13   1.99051938e-15 ...,   4.23520163e-04\n",
      "    3.92073113e-03   9.58459616e-01]]\n",
      "[43 43 43 ...,  6 10 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=  33.9s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.519851\tBest loss: 3.519851\tAccuracy: 12.10%\n",
      "1\tValidation loss: 3.313138\tBest loss: 3.313138\tAccuracy: 14.20%\n",
      "2\tValidation loss: 3.072320\tBest loss: 3.072320\tAccuracy: 20.20%\n",
      "3\tValidation loss: 2.894504\tBest loss: 2.894504\tAccuracy: 22.80%\n",
      "4\tValidation loss: 2.730767\tBest loss: 2.730767\tAccuracy: 27.20%\n",
      "5\tValidation loss: 2.601940\tBest loss: 2.601940\tAccuracy: 26.80%\n",
      "6\tValidation loss: 2.487686\tBest loss: 2.487686\tAccuracy: 31.10%\n",
      "7\tValidation loss: 2.411232\tBest loss: 2.411232\tAccuracy: 33.60%\n",
      "8\tValidation loss: 2.311728\tBest loss: 2.311728\tAccuracy: 35.70%\n",
      "9\tValidation loss: 2.233124\tBest loss: 2.233124\tAccuracy: 36.20%\n",
      "10\tValidation loss: 2.183540\tBest loss: 2.183540\tAccuracy: 37.80%\n",
      "11\tValidation loss: 2.086061\tBest loss: 2.086061\tAccuracy: 39.10%\n",
      "12\tValidation loss: 2.060837\tBest loss: 2.060837\tAccuracy: 41.60%\n",
      "13\tValidation loss: 2.001522\tBest loss: 2.001522\tAccuracy: 42.10%\n",
      "14\tValidation loss: 1.971282\tBest loss: 1.971282\tAccuracy: 42.60%\n",
      "15\tValidation loss: 1.925763\tBest loss: 1.925763\tAccuracy: 45.80%\n",
      "16\tValidation loss: 1.872041\tBest loss: 1.872041\tAccuracy: 46.10%\n",
      "17\tValidation loss: 1.829480\tBest loss: 1.829480\tAccuracy: 47.70%\n",
      "18\tValidation loss: 1.816615\tBest loss: 1.816615\tAccuracy: 47.40%\n",
      "19\tValidation loss: 1.758807\tBest loss: 1.758807\tAccuracy: 50.20%\n",
      "20\tValidation loss: 1.726899\tBest loss: 1.726899\tAccuracy: 49.70%\n",
      "21\tValidation loss: 1.717471\tBest loss: 1.717471\tAccuracy: 51.40%\n",
      "22\tValidation loss: 1.671666\tBest loss: 1.671666\tAccuracy: 50.40%\n",
      "23\tValidation loss: 1.653732\tBest loss: 1.653732\tAccuracy: 52.30%\n",
      "24\tValidation loss: 1.612167\tBest loss: 1.612167\tAccuracy: 52.10%\n",
      "25\tValidation loss: 1.612617\tBest loss: 1.612167\tAccuracy: 51.90%\n",
      "26\tValidation loss: 1.596490\tBest loss: 1.596490\tAccuracy: 53.80%\n",
      "27\tValidation loss: 1.545756\tBest loss: 1.545756\tAccuracy: 55.20%\n",
      "28\tValidation loss: 1.541638\tBest loss: 1.541638\tAccuracy: 55.30%\n",
      "29\tValidation loss: 1.530304\tBest loss: 1.530304\tAccuracy: 55.30%\n",
      "30\tValidation loss: 1.495972\tBest loss: 1.495972\tAccuracy: 56.60%\n",
      "31\tValidation loss: 1.495358\tBest loss: 1.495358\tAccuracy: 57.20%\n",
      "32\tValidation loss: 1.476624\tBest loss: 1.476624\tAccuracy: 57.00%\n",
      "33\tValidation loss: 1.466929\tBest loss: 1.466929\tAccuracy: 58.40%\n",
      "34\tValidation loss: 1.452440\tBest loss: 1.452440\tAccuracy: 58.60%\n",
      "35\tValidation loss: 1.435386\tBest loss: 1.435386\tAccuracy: 59.00%\n",
      "36\tValidation loss: 1.428445\tBest loss: 1.428445\tAccuracy: 57.50%\n",
      "37\tValidation loss: 1.406271\tBest loss: 1.406271\tAccuracy: 60.40%\n",
      "38\tValidation loss: 1.392579\tBest loss: 1.392579\tAccuracy: 59.60%\n",
      "39\tValidation loss: 1.393069\tBest loss: 1.392579\tAccuracy: 60.20%\n",
      "40\tValidation loss: 1.383512\tBest loss: 1.383512\tAccuracy: 59.10%\n",
      "41\tValidation loss: 1.388903\tBest loss: 1.383512\tAccuracy: 59.50%\n",
      "42\tValidation loss: 1.357028\tBest loss: 1.357028\tAccuracy: 60.30%\n",
      "43\tValidation loss: 1.350263\tBest loss: 1.350263\tAccuracy: 61.00%\n",
      "44\tValidation loss: 1.332789\tBest loss: 1.332789\tAccuracy: 61.10%\n",
      "45\tValidation loss: 1.324599\tBest loss: 1.324599\tAccuracy: 61.90%\n",
      "46\tValidation loss: 1.310435\tBest loss: 1.310435\tAccuracy: 62.00%\n",
      "47\tValidation loss: 1.301668\tBest loss: 1.301668\tAccuracy: 62.00%\n",
      "48\tValidation loss: 1.299135\tBest loss: 1.299135\tAccuracy: 62.50%\n",
      "49\tValidation loss: 1.279238\tBest loss: 1.279238\tAccuracy: 63.30%\n",
      "50\tValidation loss: 1.275410\tBest loss: 1.275410\tAccuracy: 62.90%\n",
      "51\tValidation loss: 1.277236\tBest loss: 1.275410\tAccuracy: 63.50%\n",
      "52\tValidation loss: 1.263461\tBest loss: 1.263461\tAccuracy: 64.50%\n",
      "53\tValidation loss: 1.264570\tBest loss: 1.263461\tAccuracy: 64.30%\n",
      "54\tValidation loss: 1.258633\tBest loss: 1.258633\tAccuracy: 63.90%\n",
      "55\tValidation loss: 1.239380\tBest loss: 1.239380\tAccuracy: 64.90%\n",
      "56\tValidation loss: 1.251672\tBest loss: 1.239380\tAccuracy: 62.60%\n",
      "57\tValidation loss: 1.219459\tBest loss: 1.219459\tAccuracy: 65.90%\n",
      "58\tValidation loss: 1.227609\tBest loss: 1.219459\tAccuracy: 64.70%\n",
      "59\tValidation loss: 1.221779\tBest loss: 1.219459\tAccuracy: 64.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\tValidation loss: 1.214712\tBest loss: 1.214712\tAccuracy: 64.50%\n",
      "61\tValidation loss: 1.212635\tBest loss: 1.212635\tAccuracy: 65.70%\n",
      "62\tValidation loss: 1.210246\tBest loss: 1.210246\tAccuracy: 64.50%\n",
      "63\tValidation loss: 1.199062\tBest loss: 1.199062\tAccuracy: 65.50%\n",
      "64\tValidation loss: 1.192872\tBest loss: 1.192872\tAccuracy: 65.30%\n",
      "65\tValidation loss: 1.184028\tBest loss: 1.184028\tAccuracy: 65.30%\n",
      "66\tValidation loss: 1.183147\tBest loss: 1.183147\tAccuracy: 66.30%\n",
      "67\tValidation loss: 1.175207\tBest loss: 1.175207\tAccuracy: 65.80%\n",
      "68\tValidation loss: 1.169081\tBest loss: 1.169081\tAccuracy: 66.90%\n",
      "69\tValidation loss: 1.166291\tBest loss: 1.166291\tAccuracy: 66.30%\n",
      "70\tValidation loss: 1.161985\tBest loss: 1.161985\tAccuracy: 66.00%\n",
      "71\tValidation loss: 1.176201\tBest loss: 1.161985\tAccuracy: 64.80%\n",
      "72\tValidation loss: 1.154431\tBest loss: 1.154431\tAccuracy: 66.60%\n",
      "73\tValidation loss: 1.163262\tBest loss: 1.154431\tAccuracy: 65.70%\n",
      "74\tValidation loss: 1.140571\tBest loss: 1.140571\tAccuracy: 66.20%\n",
      "75\tValidation loss: 1.145368\tBest loss: 1.140571\tAccuracy: 66.90%\n",
      "76\tValidation loss: 1.156517\tBest loss: 1.140571\tAccuracy: 66.40%\n",
      "77\tValidation loss: 1.136399\tBest loss: 1.136399\tAccuracy: 67.40%\n",
      "78\tValidation loss: 1.136164\tBest loss: 1.136164\tAccuracy: 67.10%\n",
      "79\tValidation loss: 1.129659\tBest loss: 1.129659\tAccuracy: 67.80%\n",
      "80\tValidation loss: 1.121517\tBest loss: 1.121517\tAccuracy: 66.50%\n",
      "81\tValidation loss: 1.137955\tBest loss: 1.121517\tAccuracy: 66.50%\n",
      "82\tValidation loss: 1.113665\tBest loss: 1.113665\tAccuracy: 67.70%\n",
      "83\tValidation loss: 1.112755\tBest loss: 1.112755\tAccuracy: 67.20%\n",
      "84\tValidation loss: 1.117906\tBest loss: 1.112755\tAccuracy: 67.20%\n",
      "85\tValidation loss: 1.115299\tBest loss: 1.112755\tAccuracy: 68.80%\n",
      "86\tValidation loss: 1.108682\tBest loss: 1.108682\tAccuracy: 67.10%\n",
      "87\tValidation loss: 1.118705\tBest loss: 1.108682\tAccuracy: 66.20%\n",
      "88\tValidation loss: 1.107856\tBest loss: 1.107856\tAccuracy: 67.40%\n",
      "89\tValidation loss: 1.096418\tBest loss: 1.096418\tAccuracy: 67.90%\n",
      "90\tValidation loss: 1.093947\tBest loss: 1.093947\tAccuracy: 67.70%\n",
      "91\tValidation loss: 1.091184\tBest loss: 1.091184\tAccuracy: 68.20%\n",
      "92\tValidation loss: 1.101488\tBest loss: 1.091184\tAccuracy: 67.80%\n",
      "93\tValidation loss: 1.083069\tBest loss: 1.083069\tAccuracy: 68.10%\n",
      "94\tValidation loss: 1.090275\tBest loss: 1.083069\tAccuracy: 68.10%\n",
      "95\tValidation loss: 1.084671\tBest loss: 1.083069\tAccuracy: 68.00%\n",
      "96\tValidation loss: 1.088642\tBest loss: 1.083069\tAccuracy: 67.40%\n",
      "97\tValidation loss: 1.085035\tBest loss: 1.083069\tAccuracy: 67.60%\n",
      "98\tValidation loss: 1.078110\tBest loss: 1.078110\tAccuracy: 68.20%\n",
      "99\tValidation loss: 1.065652\tBest loss: 1.065652\tAccuracy: 69.50%\n",
      "100\tValidation loss: 1.077055\tBest loss: 1.065652\tAccuracy: 68.60%\n",
      "101\tValidation loss: 1.077345\tBest loss: 1.065652\tAccuracy: 69.00%\n",
      "102\tValidation loss: 1.062131\tBest loss: 1.062131\tAccuracy: 69.60%\n",
      "103\tValidation loss: 1.079988\tBest loss: 1.062131\tAccuracy: 69.20%\n",
      "104\tValidation loss: 1.063699\tBest loss: 1.062131\tAccuracy: 69.30%\n",
      "105\tValidation loss: 1.063499\tBest loss: 1.062131\tAccuracy: 69.20%\n",
      "106\tValidation loss: 1.057585\tBest loss: 1.057585\tAccuracy: 68.90%\n",
      "107\tValidation loss: 1.072445\tBest loss: 1.057585\tAccuracy: 68.70%\n",
      "108\tValidation loss: 1.063763\tBest loss: 1.057585\tAccuracy: 69.50%\n",
      "109\tValidation loss: 1.049604\tBest loss: 1.049604\tAccuracy: 69.80%\n",
      "110\tValidation loss: 1.051774\tBest loss: 1.049604\tAccuracy: 69.80%\n",
      "111\tValidation loss: 1.047397\tBest loss: 1.047397\tAccuracy: 69.90%\n",
      "112\tValidation loss: 1.059268\tBest loss: 1.047397\tAccuracy: 69.60%\n",
      "113\tValidation loss: 1.056552\tBest loss: 1.047397\tAccuracy: 69.60%\n",
      "114\tValidation loss: 1.046174\tBest loss: 1.046174\tAccuracy: 69.30%\n",
      "115\tValidation loss: 1.059423\tBest loss: 1.046174\tAccuracy: 69.40%\n",
      "116\tValidation loss: 1.052706\tBest loss: 1.046174\tAccuracy: 69.40%\n",
      "117\tValidation loss: 1.043778\tBest loss: 1.043778\tAccuracy: 70.20%\n",
      "118\tValidation loss: 1.047491\tBest loss: 1.043778\tAccuracy: 69.60%\n",
      "119\tValidation loss: 1.049380\tBest loss: 1.043778\tAccuracy: 69.70%\n",
      "120\tValidation loss: 1.040280\tBest loss: 1.040280\tAccuracy: 70.40%\n",
      "121\tValidation loss: 1.042605\tBest loss: 1.040280\tAccuracy: 69.50%\n",
      "122\tValidation loss: 1.035209\tBest loss: 1.035209\tAccuracy: 69.90%\n",
      "123\tValidation loss: 1.033070\tBest loss: 1.033070\tAccuracy: 69.60%\n",
      "124\tValidation loss: 1.032536\tBest loss: 1.032536\tAccuracy: 70.30%\n",
      "125\tValidation loss: 1.032481\tBest loss: 1.032481\tAccuracy: 70.20%\n",
      "126\tValidation loss: 1.027726\tBest loss: 1.027726\tAccuracy: 69.50%\n",
      "127\tValidation loss: 1.033049\tBest loss: 1.027726\tAccuracy: 70.50%\n",
      "128\tValidation loss: 1.034130\tBest loss: 1.027726\tAccuracy: 69.80%\n",
      "129\tValidation loss: 1.018081\tBest loss: 1.018081\tAccuracy: 71.00%\n",
      "130\tValidation loss: 1.014074\tBest loss: 1.014074\tAccuracy: 71.50%\n",
      "131\tValidation loss: 1.030138\tBest loss: 1.014074\tAccuracy: 70.60%\n",
      "132\tValidation loss: 1.022649\tBest loss: 1.014074\tAccuracy: 70.80%\n",
      "133\tValidation loss: 1.017975\tBest loss: 1.014074\tAccuracy: 70.70%\n",
      "134\tValidation loss: 1.031158\tBest loss: 1.014074\tAccuracy: 70.10%\n",
      "135\tValidation loss: 1.009612\tBest loss: 1.009612\tAccuracy: 70.40%\n",
      "136\tValidation loss: 1.012828\tBest loss: 1.009612\tAccuracy: 70.90%\n",
      "137\tValidation loss: 1.013801\tBest loss: 1.009612\tAccuracy: 70.50%\n",
      "138\tValidation loss: 1.019297\tBest loss: 1.009612\tAccuracy: 71.50%\n",
      "139\tValidation loss: 1.009408\tBest loss: 1.009408\tAccuracy: 70.00%\n",
      "140\tValidation loss: 1.009663\tBest loss: 1.009408\tAccuracy: 70.50%\n",
      "141\tValidation loss: 1.009539\tBest loss: 1.009408\tAccuracy: 70.00%\n",
      "142\tValidation loss: 1.008381\tBest loss: 1.008381\tAccuracy: 70.90%\n",
      "143\tValidation loss: 1.012071\tBest loss: 1.008381\tAccuracy: 70.90%\n",
      "144\tValidation loss: 1.004662\tBest loss: 1.004662\tAccuracy: 70.70%\n",
      "145\tValidation loss: 1.015004\tBest loss: 1.004662\tAccuracy: 71.00%\n",
      "146\tValidation loss: 1.006701\tBest loss: 1.004662\tAccuracy: 70.50%\n",
      "147\tValidation loss: 1.018513\tBest loss: 1.004662\tAccuracy: 70.60%\n",
      "148\tValidation loss: 0.998473\tBest loss: 0.998473\tAccuracy: 70.70%\n",
      "149\tValidation loss: 0.999263\tBest loss: 0.998473\tAccuracy: 70.40%\n",
      "150\tValidation loss: 1.008240\tBest loss: 0.998473\tAccuracy: 71.20%\n",
      "151\tValidation loss: 1.001424\tBest loss: 0.998473\tAccuracy: 70.20%\n",
      "152\tValidation loss: 0.997099\tBest loss: 0.997099\tAccuracy: 70.50%\n",
      "153\tValidation loss: 1.002488\tBest loss: 0.997099\tAccuracy: 70.10%\n",
      "154\tValidation loss: 1.005876\tBest loss: 0.997099\tAccuracy: 70.10%\n",
      "155\tValidation loss: 0.995346\tBest loss: 0.995346\tAccuracy: 70.30%\n",
      "156\tValidation loss: 1.001010\tBest loss: 0.995346\tAccuracy: 70.40%\n",
      "157\tValidation loss: 0.985391\tBest loss: 0.985391\tAccuracy: 71.20%\n",
      "158\tValidation loss: 0.996097\tBest loss: 0.985391\tAccuracy: 70.40%\n",
      "159\tValidation loss: 1.000369\tBest loss: 0.985391\tAccuracy: 71.00%\n",
      "160\tValidation loss: 0.990060\tBest loss: 0.985391\tAccuracy: 70.50%\n",
      "161\tValidation loss: 0.994311\tBest loss: 0.985391\tAccuracy: 69.80%\n",
      "162\tValidation loss: 0.998340\tBest loss: 0.985391\tAccuracy: 69.90%\n",
      "163\tValidation loss: 0.995777\tBest loss: 0.985391\tAccuracy: 70.60%\n",
      "164\tValidation loss: 0.986572\tBest loss: 0.985391\tAccuracy: 71.10%\n",
      "165\tValidation loss: 1.003780\tBest loss: 0.985391\tAccuracy: 70.20%\n",
      "166\tValidation loss: 0.982734\tBest loss: 0.982734\tAccuracy: 71.00%\n",
      "167\tValidation loss: 0.980137\tBest loss: 0.980137\tAccuracy: 71.90%\n",
      "168\tValidation loss: 0.981153\tBest loss: 0.980137\tAccuracy: 71.40%\n",
      "169\tValidation loss: 0.977935\tBest loss: 0.977935\tAccuracy: 71.00%\n",
      "170\tValidation loss: 0.986761\tBest loss: 0.977935\tAccuracy: 70.90%\n",
      "171\tValidation loss: 0.989553\tBest loss: 0.977935\tAccuracy: 71.30%\n",
      "172\tValidation loss: 0.976497\tBest loss: 0.976497\tAccuracy: 72.30%\n",
      "173\tValidation loss: 0.988671\tBest loss: 0.976497\tAccuracy: 71.80%\n",
      "174\tValidation loss: 0.977588\tBest loss: 0.976497\tAccuracy: 71.60%\n",
      "175\tValidation loss: 0.983624\tBest loss: 0.976497\tAccuracy: 71.50%\n",
      "176\tValidation loss: 0.975897\tBest loss: 0.975897\tAccuracy: 71.50%\n",
      "177\tValidation loss: 0.971475\tBest loss: 0.971475\tAccuracy: 72.10%\n",
      "178\tValidation loss: 0.973012\tBest loss: 0.971475\tAccuracy: 72.00%\n",
      "179\tValidation loss: 0.974482\tBest loss: 0.971475\tAccuracy: 71.80%\n",
      "180\tValidation loss: 0.969928\tBest loss: 0.969928\tAccuracy: 72.00%\n",
      "181\tValidation loss: 0.961143\tBest loss: 0.961143\tAccuracy: 71.60%\n",
      "182\tValidation loss: 0.974002\tBest loss: 0.961143\tAccuracy: 71.20%\n",
      "183\tValidation loss: 0.973650\tBest loss: 0.961143\tAccuracy: 71.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\tValidation loss: 0.972186\tBest loss: 0.961143\tAccuracy: 72.30%\n",
      "185\tValidation loss: 0.973118\tBest loss: 0.961143\tAccuracy: 70.70%\n",
      "186\tValidation loss: 0.970773\tBest loss: 0.961143\tAccuracy: 71.40%\n",
      "187\tValidation loss: 0.973735\tBest loss: 0.961143\tAccuracy: 70.50%\n",
      "188\tValidation loss: 0.975131\tBest loss: 0.961143\tAccuracy: 72.40%\n",
      "189\tValidation loss: 0.972796\tBest loss: 0.961143\tAccuracy: 72.00%\n",
      "190\tValidation loss: 0.964621\tBest loss: 0.961143\tAccuracy: 71.40%\n",
      "191\tValidation loss: 0.964852\tBest loss: 0.961143\tAccuracy: 72.70%\n",
      "192\tValidation loss: 0.985305\tBest loss: 0.961143\tAccuracy: 70.50%\n",
      "193\tValidation loss: 0.980265\tBest loss: 0.961143\tAccuracy: 71.20%\n",
      "194\tValidation loss: 0.968175\tBest loss: 0.961143\tAccuracy: 71.40%\n",
      "195\tValidation loss: 0.982679\tBest loss: 0.961143\tAccuracy: 71.40%\n",
      "196\tValidation loss: 0.966891\tBest loss: 0.961143\tAccuracy: 72.00%\n",
      "197\tValidation loss: 0.964692\tBest loss: 0.961143\tAccuracy: 72.30%\n",
      "198\tValidation loss: 0.974997\tBest loss: 0.961143\tAccuracy: 70.50%\n",
      "199\tValidation loss: 0.979816\tBest loss: 0.961143\tAccuracy: 71.20%\n",
      "200\tValidation loss: 0.965170\tBest loss: 0.961143\tAccuracy: 72.10%\n",
      "201\tValidation loss: 0.977605\tBest loss: 0.961143\tAccuracy: 70.70%\n",
      "202\tValidation loss: 0.963223\tBest loss: 0.961143\tAccuracy: 72.20%\n",
      "Early stopping!\n",
      "[[  2.17368461e-06   4.75626121e-06   3.32050520e-04 ...,   2.81807900e-07\n",
      "    4.93382913e-06   2.26264149e-07]\n",
      " [  1.11664150e-10   2.19302922e-08   9.59453317e-09 ...,   2.34824934e-15\n",
      "    3.44108855e-16   7.33920326e-16]\n",
      " [  4.32440785e-08   2.42938114e-07   4.70686956e-07 ...,   5.93324977e-13\n",
      "    1.44992254e-14   3.14188476e-12]\n",
      " ..., \n",
      " [  1.01765572e-05   5.16236105e-06   2.54309998e-05 ...,   2.93538294e-04\n",
      "    1.61352713e-04   3.20272899e-04]\n",
      " [  1.14654142e-09   1.32952671e-09   2.17604357e-09 ...,   5.33407331e-01\n",
      "    1.46152973e-02   1.86967347e-02]\n",
      " [  6.11675333e-08   2.13478888e-08   1.77559642e-07 ...,   4.87154932e-04\n",
      "    1.22008671e-03   5.68957592e-04]]\n",
      "[26 43 43 ..., 36 45 27]\n",
      "[[  4.84135565e-10   5.18793570e-07   1.13454730e-08 ...,   1.36077980e-11\n",
      "    8.35671159e-13   6.35857035e-12]\n",
      " [  1.04175046e-01   1.88302770e-02   1.47198066e-01 ...,   8.32748134e-04\n",
      "    8.46576120e-04   1.11271546e-03]\n",
      " [  1.32082073e-12   2.59512763e-20   1.25808508e-09 ...,   1.23903790e-10\n",
      "    6.00612071e-17   2.45894223e-18]\n",
      " ..., \n",
      " [  6.87937415e-07   4.48353489e-07   3.98405327e-08 ...,   5.53796049e-08\n",
      "    2.76870815e-09   5.58078250e-10]\n",
      " [  1.12907067e-02   4.41459008e-03   2.23536752e-02 ...,   1.33721111e-02\n",
      "    1.47537841e-02   1.01990895e-02]\n",
      " [  2.15540133e-16   2.61698300e-14   1.53420907e-16 ...,   1.13960973e-03\n",
      "    6.78461557e-03   7.66980171e-01]]\n",
      "[20 19 16 ...,  6 37 47]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=  29.1s\n",
      "[CV] optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268> \n",
      "0\tValidation loss: 3.491288\tBest loss: 3.491288\tAccuracy: 12.10%\n",
      "1\tValidation loss: 3.119315\tBest loss: 3.119315\tAccuracy: 19.10%\n",
      "2\tValidation loss: 2.968329\tBest loss: 2.968329\tAccuracy: 20.40%\n",
      "3\tValidation loss: 2.765667\tBest loss: 2.765667\tAccuracy: 24.40%\n",
      "4\tValidation loss: 2.677210\tBest loss: 2.677210\tAccuracy: 27.90%\n",
      "5\tValidation loss: 2.533810\tBest loss: 2.533810\tAccuracy: 29.80%\n",
      "6\tValidation loss: 2.446892\tBest loss: 2.446892\tAccuracy: 31.10%\n",
      "7\tValidation loss: 2.364950\tBest loss: 2.364950\tAccuracy: 33.60%\n",
      "8\tValidation loss: 2.266935\tBest loss: 2.266935\tAccuracy: 35.20%\n",
      "9\tValidation loss: 2.197291\tBest loss: 2.197291\tAccuracy: 38.10%\n",
      "10\tValidation loss: 2.133250\tBest loss: 2.133250\tAccuracy: 38.90%\n",
      "11\tValidation loss: 2.057857\tBest loss: 2.057857\tAccuracy: 41.60%\n",
      "12\tValidation loss: 2.007182\tBest loss: 2.007182\tAccuracy: 42.90%\n",
      "13\tValidation loss: 1.970056\tBest loss: 1.970056\tAccuracy: 43.40%\n",
      "14\tValidation loss: 1.915511\tBest loss: 1.915511\tAccuracy: 45.50%\n",
      "15\tValidation loss: 1.846514\tBest loss: 1.846514\tAccuracy: 48.30%\n",
      "16\tValidation loss: 1.844060\tBest loss: 1.844060\tAccuracy: 47.60%\n",
      "17\tValidation loss: 1.807731\tBest loss: 1.807731\tAccuracy: 48.00%\n",
      "18\tValidation loss: 1.754689\tBest loss: 1.754689\tAccuracy: 50.30%\n",
      "19\tValidation loss: 1.726431\tBest loss: 1.726431\tAccuracy: 50.00%\n",
      "20\tValidation loss: 1.688438\tBest loss: 1.688438\tAccuracy: 50.80%\n",
      "21\tValidation loss: 1.667905\tBest loss: 1.667905\tAccuracy: 52.10%\n",
      "22\tValidation loss: 1.639476\tBest loss: 1.639476\tAccuracy: 54.10%\n",
      "23\tValidation loss: 1.601559\tBest loss: 1.601559\tAccuracy: 54.10%\n",
      "24\tValidation loss: 1.575052\tBest loss: 1.575052\tAccuracy: 54.80%\n",
      "25\tValidation loss: 1.561706\tBest loss: 1.561706\tAccuracy: 54.90%\n",
      "26\tValidation loss: 1.531673\tBest loss: 1.531673\tAccuracy: 56.70%\n",
      "27\tValidation loss: 1.518866\tBest loss: 1.518866\tAccuracy: 56.90%\n",
      "28\tValidation loss: 1.512519\tBest loss: 1.512519\tAccuracy: 56.50%\n",
      "29\tValidation loss: 1.468018\tBest loss: 1.468018\tAccuracy: 57.90%\n",
      "30\tValidation loss: 1.468028\tBest loss: 1.468018\tAccuracy: 58.30%\n",
      "31\tValidation loss: 1.473425\tBest loss: 1.468018\tAccuracy: 57.00%\n",
      "32\tValidation loss: 1.423428\tBest loss: 1.423428\tAccuracy: 59.60%\n",
      "33\tValidation loss: 1.423909\tBest loss: 1.423428\tAccuracy: 60.40%\n",
      "34\tValidation loss: 1.393394\tBest loss: 1.393394\tAccuracy: 60.10%\n",
      "35\tValidation loss: 1.390307\tBest loss: 1.390307\tAccuracy: 59.50%\n",
      "36\tValidation loss: 1.383785\tBest loss: 1.383785\tAccuracy: 60.00%\n",
      "37\tValidation loss: 1.359461\tBest loss: 1.359461\tAccuracy: 60.90%\n",
      "38\tValidation loss: 1.341508\tBest loss: 1.341508\tAccuracy: 62.10%\n",
      "39\tValidation loss: 1.328729\tBest loss: 1.328729\tAccuracy: 61.30%\n",
      "40\tValidation loss: 1.356055\tBest loss: 1.328729\tAccuracy: 61.30%\n",
      "41\tValidation loss: 1.326226\tBest loss: 1.326226\tAccuracy: 62.40%\n",
      "42\tValidation loss: 1.329124\tBest loss: 1.326226\tAccuracy: 61.70%\n",
      "43\tValidation loss: 1.290241\tBest loss: 1.290241\tAccuracy: 64.00%\n",
      "44\tValidation loss: 1.274793\tBest loss: 1.274793\tAccuracy: 64.30%\n",
      "45\tValidation loss: 1.285579\tBest loss: 1.274793\tAccuracy: 63.50%\n",
      "46\tValidation loss: 1.276918\tBest loss: 1.274793\tAccuracy: 64.50%\n",
      "47\tValidation loss: 1.266588\tBest loss: 1.266588\tAccuracy: 64.90%\n",
      "48\tValidation loss: 1.252248\tBest loss: 1.252248\tAccuracy: 66.10%\n",
      "49\tValidation loss: 1.247053\tBest loss: 1.247053\tAccuracy: 65.80%\n",
      "50\tValidation loss: 1.228340\tBest loss: 1.228340\tAccuracy: 64.00%\n",
      "51\tValidation loss: 1.234635\tBest loss: 1.228340\tAccuracy: 65.80%\n",
      "52\tValidation loss: 1.218849\tBest loss: 1.218849\tAccuracy: 65.80%\n",
      "53\tValidation loss: 1.217741\tBest loss: 1.217741\tAccuracy: 65.70%\n",
      "54\tValidation loss: 1.203252\tBest loss: 1.203252\tAccuracy: 66.40%\n",
      "55\tValidation loss: 1.195423\tBest loss: 1.195423\tAccuracy: 66.30%\n",
      "56\tValidation loss: 1.183411\tBest loss: 1.183411\tAccuracy: 66.30%\n",
      "57\tValidation loss: 1.167960\tBest loss: 1.167960\tAccuracy: 67.20%\n",
      "58\tValidation loss: 1.185993\tBest loss: 1.167960\tAccuracy: 66.50%\n",
      "59\tValidation loss: 1.156993\tBest loss: 1.156993\tAccuracy: 66.70%\n",
      "60\tValidation loss: 1.180079\tBest loss: 1.156993\tAccuracy: 66.90%\n",
      "61\tValidation loss: 1.147520\tBest loss: 1.147520\tAccuracy: 67.00%\n",
      "62\tValidation loss: 1.172318\tBest loss: 1.147520\tAccuracy: 67.20%\n",
      "63\tValidation loss: 1.145255\tBest loss: 1.145255\tAccuracy: 67.70%\n",
      "64\tValidation loss: 1.148045\tBest loss: 1.145255\tAccuracy: 67.50%\n",
      "65\tValidation loss: 1.141808\tBest loss: 1.141808\tAccuracy: 67.70%\n",
      "66\tValidation loss: 1.132833\tBest loss: 1.132833\tAccuracy: 68.30%\n",
      "67\tValidation loss: 1.113128\tBest loss: 1.113128\tAccuracy: 69.90%\n",
      "68\tValidation loss: 1.125548\tBest loss: 1.113128\tAccuracy: 69.10%\n",
      "69\tValidation loss: 1.124054\tBest loss: 1.113128\tAccuracy: 68.40%\n",
      "70\tValidation loss: 1.111568\tBest loss: 1.111568\tAccuracy: 68.50%\n",
      "71\tValidation loss: 1.111702\tBest loss: 1.111568\tAccuracy: 69.70%\n",
      "72\tValidation loss: 1.095129\tBest loss: 1.095129\tAccuracy: 69.50%\n",
      "73\tValidation loss: 1.093721\tBest loss: 1.093721\tAccuracy: 69.80%\n",
      "74\tValidation loss: 1.110458\tBest loss: 1.093721\tAccuracy: 68.90%\n",
      "75\tValidation loss: 1.089627\tBest loss: 1.089627\tAccuracy: 69.30%\n",
      "76\tValidation loss: 1.088702\tBest loss: 1.088702\tAccuracy: 69.80%\n",
      "77\tValidation loss: 1.091903\tBest loss: 1.088702\tAccuracy: 69.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\tValidation loss: 1.080232\tBest loss: 1.080232\tAccuracy: 69.60%\n",
      "79\tValidation loss: 1.078811\tBest loss: 1.078811\tAccuracy: 70.30%\n",
      "80\tValidation loss: 1.085171\tBest loss: 1.078811\tAccuracy: 70.10%\n",
      "81\tValidation loss: 1.080619\tBest loss: 1.078811\tAccuracy: 69.00%\n",
      "82\tValidation loss: 1.072045\tBest loss: 1.072045\tAccuracy: 69.90%\n",
      "83\tValidation loss: 1.064484\tBest loss: 1.064484\tAccuracy: 70.30%\n",
      "84\tValidation loss: 1.062800\tBest loss: 1.062800\tAccuracy: 69.50%\n",
      "85\tValidation loss: 1.055553\tBest loss: 1.055553\tAccuracy: 70.40%\n",
      "86\tValidation loss: 1.062958\tBest loss: 1.055553\tAccuracy: 70.00%\n",
      "87\tValidation loss: 1.068902\tBest loss: 1.055553\tAccuracy: 68.80%\n",
      "88\tValidation loss: 1.062124\tBest loss: 1.055553\tAccuracy: 69.70%\n",
      "89\tValidation loss: 1.049280\tBest loss: 1.049280\tAccuracy: 69.70%\n",
      "90\tValidation loss: 1.050361\tBest loss: 1.049280\tAccuracy: 71.70%\n",
      "91\tValidation loss: 1.044479\tBest loss: 1.044479\tAccuracy: 71.10%\n",
      "92\tValidation loss: 1.035495\tBest loss: 1.035495\tAccuracy: 69.80%\n",
      "93\tValidation loss: 1.038149\tBest loss: 1.035495\tAccuracy: 70.40%\n",
      "94\tValidation loss: 1.032142\tBest loss: 1.032142\tAccuracy: 71.30%\n",
      "95\tValidation loss: 1.037804\tBest loss: 1.032142\tAccuracy: 70.90%\n",
      "96\tValidation loss: 1.036640\tBest loss: 1.032142\tAccuracy: 71.10%\n",
      "97\tValidation loss: 1.021526\tBest loss: 1.021526\tAccuracy: 71.60%\n",
      "98\tValidation loss: 1.024720\tBest loss: 1.021526\tAccuracy: 71.50%\n",
      "99\tValidation loss: 1.013239\tBest loss: 1.013239\tAccuracy: 71.30%\n",
      "100\tValidation loss: 1.016838\tBest loss: 1.013239\tAccuracy: 71.00%\n",
      "101\tValidation loss: 1.019241\tBest loss: 1.013239\tAccuracy: 71.40%\n",
      "102\tValidation loss: 1.015699\tBest loss: 1.013239\tAccuracy: 72.00%\n",
      "103\tValidation loss: 1.026796\tBest loss: 1.013239\tAccuracy: 71.60%\n",
      "104\tValidation loss: 1.027577\tBest loss: 1.013239\tAccuracy: 71.40%\n",
      "105\tValidation loss: 1.015988\tBest loss: 1.013239\tAccuracy: 70.40%\n",
      "106\tValidation loss: 1.021704\tBest loss: 1.013239\tAccuracy: 71.20%\n",
      "107\tValidation loss: 1.025125\tBest loss: 1.013239\tAccuracy: 71.10%\n",
      "108\tValidation loss: 1.012372\tBest loss: 1.012372\tAccuracy: 70.60%\n",
      "109\tValidation loss: 1.005036\tBest loss: 1.005036\tAccuracy: 71.50%\n",
      "110\tValidation loss: 1.005729\tBest loss: 1.005036\tAccuracy: 71.70%\n",
      "111\tValidation loss: 1.004057\tBest loss: 1.004057\tAccuracy: 70.80%\n",
      "112\tValidation loss: 0.999483\tBest loss: 0.999483\tAccuracy: 71.80%\n",
      "113\tValidation loss: 1.006408\tBest loss: 0.999483\tAccuracy: 71.90%\n",
      "114\tValidation loss: 0.997751\tBest loss: 0.997751\tAccuracy: 72.00%\n",
      "115\tValidation loss: 0.996739\tBest loss: 0.996739\tAccuracy: 71.50%\n",
      "116\tValidation loss: 1.007573\tBest loss: 0.996739\tAccuracy: 71.00%\n",
      "117\tValidation loss: 0.991541\tBest loss: 0.991541\tAccuracy: 71.00%\n",
      "118\tValidation loss: 0.997981\tBest loss: 0.991541\tAccuracy: 71.90%\n",
      "119\tValidation loss: 0.993559\tBest loss: 0.991541\tAccuracy: 71.00%\n",
      "120\tValidation loss: 0.996815\tBest loss: 0.991541\tAccuracy: 71.40%\n",
      "121\tValidation loss: 1.005108\tBest loss: 0.991541\tAccuracy: 70.80%\n",
      "122\tValidation loss: 0.994014\tBest loss: 0.991541\tAccuracy: 71.90%\n",
      "123\tValidation loss: 0.984274\tBest loss: 0.984274\tAccuracy: 72.10%\n",
      "124\tValidation loss: 0.986313\tBest loss: 0.984274\tAccuracy: 71.40%\n",
      "125\tValidation loss: 0.979698\tBest loss: 0.979698\tAccuracy: 72.70%\n",
      "126\tValidation loss: 0.980205\tBest loss: 0.979698\tAccuracy: 72.00%\n",
      "127\tValidation loss: 0.986667\tBest loss: 0.979698\tAccuracy: 71.80%\n",
      "128\tValidation loss: 0.978431\tBest loss: 0.978431\tAccuracy: 71.90%\n",
      "129\tValidation loss: 0.972727\tBest loss: 0.972727\tAccuracy: 72.90%\n",
      "130\tValidation loss: 0.969962\tBest loss: 0.969962\tAccuracy: 72.20%\n",
      "131\tValidation loss: 0.975076\tBest loss: 0.969962\tAccuracy: 72.80%\n",
      "132\tValidation loss: 0.970310\tBest loss: 0.969962\tAccuracy: 72.60%\n",
      "133\tValidation loss: 0.980767\tBest loss: 0.969962\tAccuracy: 72.00%\n",
      "134\tValidation loss: 0.978323\tBest loss: 0.969962\tAccuracy: 71.50%\n",
      "135\tValidation loss: 0.972924\tBest loss: 0.969962\tAccuracy: 72.20%\n",
      "136\tValidation loss: 0.965429\tBest loss: 0.965429\tAccuracy: 72.90%\n",
      "137\tValidation loss: 0.962531\tBest loss: 0.962531\tAccuracy: 72.30%\n",
      "138\tValidation loss: 0.966881\tBest loss: 0.962531\tAccuracy: 72.90%\n",
      "139\tValidation loss: 0.969788\tBest loss: 0.962531\tAccuracy: 72.60%\n",
      "140\tValidation loss: 0.963951\tBest loss: 0.962531\tAccuracy: 72.40%\n",
      "141\tValidation loss: 0.967279\tBest loss: 0.962531\tAccuracy: 71.90%\n",
      "142\tValidation loss: 0.974464\tBest loss: 0.962531\tAccuracy: 71.50%\n",
      "143\tValidation loss: 0.969956\tBest loss: 0.962531\tAccuracy: 72.60%\n",
      "144\tValidation loss: 0.983006\tBest loss: 0.962531\tAccuracy: 72.40%\n",
      "145\tValidation loss: 0.966304\tBest loss: 0.962531\tAccuracy: 72.20%\n",
      "146\tValidation loss: 0.968482\tBest loss: 0.962531\tAccuracy: 72.30%\n",
      "147\tValidation loss: 0.962914\tBest loss: 0.962531\tAccuracy: 72.80%\n",
      "148\tValidation loss: 0.973829\tBest loss: 0.962531\tAccuracy: 71.90%\n",
      "149\tValidation loss: 0.953430\tBest loss: 0.953430\tAccuracy: 73.40%\n",
      "150\tValidation loss: 0.965832\tBest loss: 0.953430\tAccuracy: 71.60%\n",
      "151\tValidation loss: 0.963391\tBest loss: 0.953430\tAccuracy: 72.20%\n",
      "152\tValidation loss: 0.955631\tBest loss: 0.953430\tAccuracy: 73.30%\n",
      "153\tValidation loss: 0.957512\tBest loss: 0.953430\tAccuracy: 73.00%\n",
      "154\tValidation loss: 0.955124\tBest loss: 0.953430\tAccuracy: 73.40%\n",
      "155\tValidation loss: 0.951019\tBest loss: 0.951019\tAccuracy: 73.10%\n",
      "156\tValidation loss: 0.955417\tBest loss: 0.951019\tAccuracy: 73.00%\n",
      "157\tValidation loss: 0.957106\tBest loss: 0.951019\tAccuracy: 72.90%\n",
      "158\tValidation loss: 0.952273\tBest loss: 0.951019\tAccuracy: 72.50%\n",
      "159\tValidation loss: 0.955292\tBest loss: 0.951019\tAccuracy: 72.40%\n",
      "160\tValidation loss: 0.950150\tBest loss: 0.950150\tAccuracy: 73.80%\n",
      "161\tValidation loss: 0.941755\tBest loss: 0.941755\tAccuracy: 73.50%\n",
      "162\tValidation loss: 0.954327\tBest loss: 0.941755\tAccuracy: 72.40%\n",
      "163\tValidation loss: 0.952123\tBest loss: 0.941755\tAccuracy: 73.00%\n",
      "164\tValidation loss: 0.949531\tBest loss: 0.941755\tAccuracy: 72.90%\n",
      "165\tValidation loss: 0.951532\tBest loss: 0.941755\tAccuracy: 73.10%\n",
      "166\tValidation loss: 0.946386\tBest loss: 0.941755\tAccuracy: 72.60%\n",
      "167\tValidation loss: 0.945222\tBest loss: 0.941755\tAccuracy: 71.80%\n",
      "168\tValidation loss: 0.945034\tBest loss: 0.941755\tAccuracy: 72.60%\n",
      "169\tValidation loss: 0.946821\tBest loss: 0.941755\tAccuracy: 72.90%\n",
      "170\tValidation loss: 0.944024\tBest loss: 0.941755\tAccuracy: 72.70%\n",
      "171\tValidation loss: 0.944366\tBest loss: 0.941755\tAccuracy: 73.20%\n",
      "172\tValidation loss: 0.941988\tBest loss: 0.941755\tAccuracy: 72.90%\n",
      "173\tValidation loss: 0.934296\tBest loss: 0.934296\tAccuracy: 73.30%\n",
      "174\tValidation loss: 0.937156\tBest loss: 0.934296\tAccuracy: 72.60%\n",
      "175\tValidation loss: 0.928783\tBest loss: 0.928783\tAccuracy: 73.00%\n",
      "176\tValidation loss: 0.939486\tBest loss: 0.928783\tAccuracy: 73.40%\n",
      "177\tValidation loss: 0.943803\tBest loss: 0.928783\tAccuracy: 73.10%\n",
      "178\tValidation loss: 0.936931\tBest loss: 0.928783\tAccuracy: 73.10%\n",
      "179\tValidation loss: 0.936066\tBest loss: 0.928783\tAccuracy: 73.10%\n",
      "180\tValidation loss: 0.932525\tBest loss: 0.928783\tAccuracy: 73.50%\n",
      "181\tValidation loss: 0.940372\tBest loss: 0.928783\tAccuracy: 73.20%\n",
      "182\tValidation loss: 0.935468\tBest loss: 0.928783\tAccuracy: 72.60%\n",
      "183\tValidation loss: 0.933880\tBest loss: 0.928783\tAccuracy: 72.80%\n",
      "184\tValidation loss: 0.922625\tBest loss: 0.922625\tAccuracy: 74.10%\n",
      "185\tValidation loss: 0.928311\tBest loss: 0.922625\tAccuracy: 73.10%\n",
      "186\tValidation loss: 0.925407\tBest loss: 0.922625\tAccuracy: 73.40%\n",
      "187\tValidation loss: 0.921410\tBest loss: 0.921410\tAccuracy: 73.70%\n",
      "188\tValidation loss: 0.920006\tBest loss: 0.920006\tAccuracy: 73.70%\n",
      "189\tValidation loss: 0.921025\tBest loss: 0.920006\tAccuracy: 72.80%\n",
      "190\tValidation loss: 0.914004\tBest loss: 0.914004\tAccuracy: 73.30%\n",
      "191\tValidation loss: 0.919945\tBest loss: 0.914004\tAccuracy: 73.10%\n",
      "192\tValidation loss: 0.926516\tBest loss: 0.914004\tAccuracy: 72.00%\n",
      "193\tValidation loss: 0.913053\tBest loss: 0.913053\tAccuracy: 73.60%\n",
      "194\tValidation loss: 0.909617\tBest loss: 0.909617\tAccuracy: 73.00%\n",
      "195\tValidation loss: 0.915323\tBest loss: 0.909617\tAccuracy: 73.60%\n",
      "196\tValidation loss: 0.909553\tBest loss: 0.909553\tAccuracy: 73.40%\n",
      "197\tValidation loss: 0.902654\tBest loss: 0.902654\tAccuracy: 73.50%\n",
      "198\tValidation loss: 0.902794\tBest loss: 0.902654\tAccuracy: 73.70%\n",
      "199\tValidation loss: 0.910958\tBest loss: 0.902654\tAccuracy: 74.00%\n",
      "200\tValidation loss: 0.906425\tBest loss: 0.902654\tAccuracy: 72.70%\n",
      "201\tValidation loss: 0.911042\tBest loss: 0.902654\tAccuracy: 73.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\tValidation loss: 0.911594\tBest loss: 0.902654\tAccuracy: 72.60%\n",
      "203\tValidation loss: 0.912934\tBest loss: 0.902654\tAccuracy: 73.10%\n",
      "204\tValidation loss: 0.903817\tBest loss: 0.902654\tAccuracy: 73.90%\n",
      "205\tValidation loss: 0.913198\tBest loss: 0.902654\tAccuracy: 73.70%\n",
      "206\tValidation loss: 0.929041\tBest loss: 0.902654\tAccuracy: 72.40%\n",
      "207\tValidation loss: 0.917533\tBest loss: 0.902654\tAccuracy: 73.00%\n",
      "208\tValidation loss: 0.906548\tBest loss: 0.902654\tAccuracy: 73.60%\n",
      "209\tValidation loss: 0.911785\tBest loss: 0.902654\tAccuracy: 72.30%\n",
      "210\tValidation loss: 0.908074\tBest loss: 0.902654\tAccuracy: 72.80%\n",
      "211\tValidation loss: 0.901262\tBest loss: 0.901262\tAccuracy: 74.10%\n",
      "212\tValidation loss: 0.905949\tBest loss: 0.901262\tAccuracy: 73.70%\n",
      "213\tValidation loss: 0.903393\tBest loss: 0.901262\tAccuracy: 73.40%\n",
      "214\tValidation loss: 0.913029\tBest loss: 0.901262\tAccuracy: 72.90%\n",
      "215\tValidation loss: 0.899585\tBest loss: 0.899585\tAccuracy: 73.90%\n",
      "216\tValidation loss: 0.893806\tBest loss: 0.893806\tAccuracy: 73.40%\n",
      "217\tValidation loss: 0.890714\tBest loss: 0.890714\tAccuracy: 73.70%\n",
      "218\tValidation loss: 0.897396\tBest loss: 0.890714\tAccuracy: 73.70%\n",
      "219\tValidation loss: 0.897864\tBest loss: 0.890714\tAccuracy: 73.50%\n",
      "220\tValidation loss: 0.905484\tBest loss: 0.890714\tAccuracy: 73.80%\n",
      "221\tValidation loss: 0.904697\tBest loss: 0.890714\tAccuracy: 74.40%\n",
      "222\tValidation loss: 0.904804\tBest loss: 0.890714\tAccuracy: 73.30%\n",
      "223\tValidation loss: 0.902215\tBest loss: 0.890714\tAccuracy: 73.10%\n",
      "224\tValidation loss: 0.905898\tBest loss: 0.890714\tAccuracy: 73.90%\n",
      "225\tValidation loss: 0.899322\tBest loss: 0.890714\tAccuracy: 73.40%\n",
      "226\tValidation loss: 0.900217\tBest loss: 0.890714\tAccuracy: 73.00%\n",
      "227\tValidation loss: 0.889757\tBest loss: 0.889757\tAccuracy: 73.10%\n",
      "228\tValidation loss: 0.887414\tBest loss: 0.887414\tAccuracy: 74.10%\n",
      "229\tValidation loss: 0.896723\tBest loss: 0.887414\tAccuracy: 73.20%\n",
      "230\tValidation loss: 0.898611\tBest loss: 0.887414\tAccuracy: 72.70%\n",
      "231\tValidation loss: 0.901778\tBest loss: 0.887414\tAccuracy: 72.90%\n",
      "232\tValidation loss: 0.904441\tBest loss: 0.887414\tAccuracy: 72.10%\n",
      "233\tValidation loss: 0.893168\tBest loss: 0.887414\tAccuracy: 72.40%\n",
      "234\tValidation loss: 0.898991\tBest loss: 0.887414\tAccuracy: 73.10%\n",
      "235\tValidation loss: 0.894194\tBest loss: 0.887414\tAccuracy: 73.90%\n",
      "236\tValidation loss: 0.906126\tBest loss: 0.887414\tAccuracy: 73.90%\n",
      "237\tValidation loss: 0.899285\tBest loss: 0.887414\tAccuracy: 73.00%\n",
      "238\tValidation loss: 0.894164\tBest loss: 0.887414\tAccuracy: 74.20%\n",
      "239\tValidation loss: 0.885703\tBest loss: 0.885703\tAccuracy: 74.80%\n",
      "240\tValidation loss: 0.894565\tBest loss: 0.885703\tAccuracy: 74.40%\n",
      "241\tValidation loss: 0.883805\tBest loss: 0.883805\tAccuracy: 73.40%\n",
      "242\tValidation loss: 0.884399\tBest loss: 0.883805\tAccuracy: 73.90%\n",
      "243\tValidation loss: 0.882895\tBest loss: 0.882895\tAccuracy: 74.30%\n",
      "244\tValidation loss: 0.882552\tBest loss: 0.882552\tAccuracy: 73.70%\n",
      "245\tValidation loss: 0.878978\tBest loss: 0.878978\tAccuracy: 74.20%\n",
      "246\tValidation loss: 0.877489\tBest loss: 0.877489\tAccuracy: 75.10%\n",
      "247\tValidation loss: 0.890186\tBest loss: 0.877489\tAccuracy: 74.60%\n",
      "248\tValidation loss: 0.880285\tBest loss: 0.877489\tAccuracy: 74.00%\n",
      "249\tValidation loss: 0.880089\tBest loss: 0.877489\tAccuracy: 74.10%\n",
      "250\tValidation loss: 0.896539\tBest loss: 0.877489\tAccuracy: 73.30%\n",
      "251\tValidation loss: 0.893798\tBest loss: 0.877489\tAccuracy: 73.50%\n",
      "252\tValidation loss: 0.887374\tBest loss: 0.877489\tAccuracy: 73.90%\n",
      "253\tValidation loss: 0.890608\tBest loss: 0.877489\tAccuracy: 73.70%\n",
      "254\tValidation loss: 0.888596\tBest loss: 0.877489\tAccuracy: 73.90%\n",
      "255\tValidation loss: 0.889693\tBest loss: 0.877489\tAccuracy: 73.60%\n",
      "256\tValidation loss: 0.893916\tBest loss: 0.877489\tAccuracy: 73.60%\n",
      "257\tValidation loss: 0.884258\tBest loss: 0.877489\tAccuracy: 73.40%\n",
      "258\tValidation loss: 0.888898\tBest loss: 0.877489\tAccuracy: 73.90%\n",
      "259\tValidation loss: 0.891302\tBest loss: 0.877489\tAccuracy: 72.80%\n",
      "260\tValidation loss: 0.889463\tBest loss: 0.877489\tAccuracy: 73.50%\n",
      "261\tValidation loss: 0.878702\tBest loss: 0.877489\tAccuracy: 73.60%\n",
      "262\tValidation loss: 0.881155\tBest loss: 0.877489\tAccuracy: 74.60%\n",
      "263\tValidation loss: 0.882402\tBest loss: 0.877489\tAccuracy: 74.10%\n",
      "264\tValidation loss: 0.883583\tBest loss: 0.877489\tAccuracy: 73.50%\n",
      "265\tValidation loss: 0.896758\tBest loss: 0.877489\tAccuracy: 72.40%\n",
      "266\tValidation loss: 0.893066\tBest loss: 0.877489\tAccuracy: 74.10%\n",
      "267\tValidation loss: 0.884227\tBest loss: 0.877489\tAccuracy: 74.60%\n",
      "Early stopping!\n",
      "[[  9.60703983e-06   5.87893373e-05   1.53264791e-05 ...,   2.70027467e-05\n",
      "    8.25945605e-08   1.94058907e-06]\n",
      " [  2.94804883e-15   1.67295032e-11   4.60711113e-14 ...,   2.11932516e-08\n",
      "    1.24683027e-07   2.24402857e-11]\n",
      " [  2.16335422e-07   2.25936892e-05   1.20548293e-07 ...,   3.99726963e-09\n",
      "    1.34252223e-05   3.53078613e-05]\n",
      " ..., \n",
      " [  1.33369622e-06   3.55458702e-08   4.67063046e-06 ...,   7.92949095e-10\n",
      "    1.42763438e-12   6.19277578e-13]\n",
      " [  2.13270504e-02   1.04903402e-02   9.69935209e-03 ...,   1.97514370e-02\n",
      "    1.78003274e-02   1.69958826e-02]\n",
      " [  1.91475355e-15   1.48891504e-15   4.74222534e-15 ...,   3.09431562e-05\n",
      "    1.02899903e-04   6.97239101e-01]]\n",
      "[41 41 22 ...,  6 37 47]\n",
      "[[  8.01345568e-09   2.16096778e-05   3.41928597e-07 ...,   2.17036336e-14\n",
      "    4.41781556e-10   3.67027901e-11]\n",
      " [  4.86303791e-02   3.45075466e-02   1.36126667e-01 ...,   1.30789250e-03\n",
      "    7.71236490e-04   7.43077777e-04]\n",
      " [  1.40573826e-12   1.61440959e-16   1.18816196e-07 ...,   1.17267319e-07\n",
      "    1.27351775e-12   1.40066109e-16]\n",
      " ..., \n",
      " [  6.03066519e-06   2.31090053e-06   2.16597869e-06 ...,   1.00378602e-04\n",
      "    8.39752684e-05   2.25012147e-04]\n",
      " [  3.33676448e-10   1.22334495e-11   1.98231015e-10 ...,   1.46377996e-01\n",
      "    6.73922617e-03   2.14837911e-03]\n",
      " [  5.22704724e-09   5.96292904e-10   1.08986908e-09 ...,   6.86027110e-03\n",
      "    8.13508965e-03   2.60860869e-03]]\n",
      "[20 19 16 ..., 36 27 27]\n",
      "[CV]  optimizer_class=<class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, batch_size=100, dropout_rate=0.2, n_hidden_layers=2, n_neurons=150, learning_rate=0.02, activation=<function elu at 0x000002EE6B234268>, total=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 77.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 3.221678\tBest loss: 3.221678\tAccuracy: 15.40%\n",
      "1\tValidation loss: 2.955151\tBest loss: 2.955151\tAccuracy: 21.20%\n",
      "2\tValidation loss: 2.717131\tBest loss: 2.717131\tAccuracy: 24.90%\n",
      "3\tValidation loss: 2.538676\tBest loss: 2.538676\tAccuracy: 30.90%\n",
      "4\tValidation loss: 2.364013\tBest loss: 2.364013\tAccuracy: 33.90%\n",
      "5\tValidation loss: 2.231282\tBest loss: 2.231282\tAccuracy: 36.20%\n",
      "6\tValidation loss: 2.153888\tBest loss: 2.153888\tAccuracy: 38.20%\n",
      "7\tValidation loss: 2.042270\tBest loss: 2.042270\tAccuracy: 41.50%\n",
      "8\tValidation loss: 1.963125\tBest loss: 1.963125\tAccuracy: 44.00%\n",
      "9\tValidation loss: 1.883102\tBest loss: 1.883102\tAccuracy: 45.90%\n",
      "10\tValidation loss: 1.833350\tBest loss: 1.833350\tAccuracy: 47.50%\n",
      "11\tValidation loss: 1.764169\tBest loss: 1.764169\tAccuracy: 49.00%\n",
      "12\tValidation loss: 1.723657\tBest loss: 1.723657\tAccuracy: 51.20%\n",
      "13\tValidation loss: 1.681191\tBest loss: 1.681191\tAccuracy: 51.30%\n",
      "14\tValidation loss: 1.639315\tBest loss: 1.639315\tAccuracy: 52.80%\n",
      "15\tValidation loss: 1.605236\tBest loss: 1.605236\tAccuracy: 54.40%\n",
      "16\tValidation loss: 1.558888\tBest loss: 1.558888\tAccuracy: 55.00%\n",
      "17\tValidation loss: 1.542146\tBest loss: 1.542146\tAccuracy: 55.70%\n",
      "18\tValidation loss: 1.507252\tBest loss: 1.507252\tAccuracy: 57.20%\n",
      "19\tValidation loss: 1.484850\tBest loss: 1.484850\tAccuracy: 57.50%\n",
      "20\tValidation loss: 1.466386\tBest loss: 1.466386\tAccuracy: 57.50%\n",
      "21\tValidation loss: 1.436609\tBest loss: 1.436609\tAccuracy: 57.40%\n",
      "22\tValidation loss: 1.419904\tBest loss: 1.419904\tAccuracy: 57.90%\n",
      "23\tValidation loss: 1.405402\tBest loss: 1.405402\tAccuracy: 59.70%\n",
      "24\tValidation loss: 1.371094\tBest loss: 1.371094\tAccuracy: 61.10%\n",
      "25\tValidation loss: 1.359389\tBest loss: 1.359389\tAccuracy: 60.50%\n",
      "26\tValidation loss: 1.339028\tBest loss: 1.339028\tAccuracy: 61.60%\n",
      "27\tValidation loss: 1.321177\tBest loss: 1.321177\tAccuracy: 61.80%\n",
      "28\tValidation loss: 1.324668\tBest loss: 1.321177\tAccuracy: 63.00%\n",
      "29\tValidation loss: 1.307902\tBest loss: 1.307902\tAccuracy: 61.90%\n",
      "30\tValidation loss: 1.274038\tBest loss: 1.274038\tAccuracy: 63.80%\n",
      "31\tValidation loss: 1.275873\tBest loss: 1.274038\tAccuracy: 63.10%\n",
      "32\tValidation loss: 1.253552\tBest loss: 1.253552\tAccuracy: 63.40%\n",
      "33\tValidation loss: 1.252133\tBest loss: 1.252133\tAccuracy: 64.10%\n",
      "34\tValidation loss: 1.234469\tBest loss: 1.234469\tAccuracy: 63.70%\n",
      "35\tValidation loss: 1.237230\tBest loss: 1.234469\tAccuracy: 65.40%\n",
      "36\tValidation loss: 1.214439\tBest loss: 1.214439\tAccuracy: 64.80%\n",
      "37\tValidation loss: 1.211769\tBest loss: 1.211769\tAccuracy: 64.20%\n",
      "38\tValidation loss: 1.184229\tBest loss: 1.184229\tAccuracy: 66.30%\n",
      "39\tValidation loss: 1.196112\tBest loss: 1.184229\tAccuracy: 65.10%\n",
      "40\tValidation loss: 1.168751\tBest loss: 1.168751\tAccuracy: 66.00%\n",
      "41\tValidation loss: 1.181790\tBest loss: 1.168751\tAccuracy: 66.20%\n",
      "42\tValidation loss: 1.164050\tBest loss: 1.164050\tAccuracy: 66.90%\n",
      "43\tValidation loss: 1.144978\tBest loss: 1.144978\tAccuracy: 66.50%\n",
      "44\tValidation loss: 1.164975\tBest loss: 1.144978\tAccuracy: 66.40%\n",
      "45\tValidation loss: 1.149973\tBest loss: 1.144978\tAccuracy: 67.70%\n",
      "46\tValidation loss: 1.139566\tBest loss: 1.139566\tAccuracy: 65.90%\n",
      "47\tValidation loss: 1.128269\tBest loss: 1.128269\tAccuracy: 66.50%\n",
      "48\tValidation loss: 1.120398\tBest loss: 1.120398\tAccuracy: 67.80%\n",
      "49\tValidation loss: 1.124292\tBest loss: 1.120398\tAccuracy: 68.10%\n",
      "50\tValidation loss: 1.114603\tBest loss: 1.114603\tAccuracy: 67.60%\n",
      "51\tValidation loss: 1.108014\tBest loss: 1.108014\tAccuracy: 67.40%\n",
      "52\tValidation loss: 1.107735\tBest loss: 1.107735\tAccuracy: 67.60%\n",
      "53\tValidation loss: 1.093014\tBest loss: 1.093014\tAccuracy: 68.40%\n",
      "54\tValidation loss: 1.098547\tBest loss: 1.093014\tAccuracy: 69.10%\n",
      "55\tValidation loss: 1.093372\tBest loss: 1.093014\tAccuracy: 67.70%\n",
      "56\tValidation loss: 1.102060\tBest loss: 1.093014\tAccuracy: 67.80%\n",
      "57\tValidation loss: 1.084142\tBest loss: 1.084142\tAccuracy: 68.80%\n",
      "58\tValidation loss: 1.070433\tBest loss: 1.070433\tAccuracy: 68.10%\n",
      "59\tValidation loss: 1.064397\tBest loss: 1.064397\tAccuracy: 69.60%\n",
      "60\tValidation loss: 1.060405\tBest loss: 1.060405\tAccuracy: 69.80%\n",
      "61\tValidation loss: 1.054498\tBest loss: 1.054498\tAccuracy: 69.20%\n",
      "62\tValidation loss: 1.049181\tBest loss: 1.049181\tAccuracy: 68.30%\n",
      "63\tValidation loss: 1.053144\tBest loss: 1.049181\tAccuracy: 69.60%\n",
      "64\tValidation loss: 1.048092\tBest loss: 1.048092\tAccuracy: 70.00%\n",
      "65\tValidation loss: 1.039837\tBest loss: 1.039837\tAccuracy: 70.20%\n",
      "66\tValidation loss: 1.044887\tBest loss: 1.039837\tAccuracy: 69.20%\n",
      "67\tValidation loss: 1.031545\tBest loss: 1.031545\tAccuracy: 69.90%\n",
      "68\tValidation loss: 1.032101\tBest loss: 1.031545\tAccuracy: 69.20%\n",
      "69\tValidation loss: 1.030779\tBest loss: 1.030779\tAccuracy: 69.80%\n",
      "70\tValidation loss: 1.012820\tBest loss: 1.012820\tAccuracy: 70.20%\n",
      "71\tValidation loss: 1.014815\tBest loss: 1.012820\tAccuracy: 70.80%\n",
      "72\tValidation loss: 1.019881\tBest loss: 1.012820\tAccuracy: 70.70%\n",
      "73\tValidation loss: 1.017585\tBest loss: 1.012820\tAccuracy: 70.60%\n",
      "74\tValidation loss: 1.000956\tBest loss: 1.000956\tAccuracy: 71.80%\n",
      "75\tValidation loss: 1.005185\tBest loss: 1.000956\tAccuracy: 71.40%\n",
      "76\tValidation loss: 0.989683\tBest loss: 0.989683\tAccuracy: 71.20%\n",
      "77\tValidation loss: 0.997574\tBest loss: 0.989683\tAccuracy: 70.70%\n",
      "78\tValidation loss: 1.002155\tBest loss: 0.989683\tAccuracy: 71.10%\n",
      "79\tValidation loss: 0.996921\tBest loss: 0.989683\tAccuracy: 70.90%\n",
      "80\tValidation loss: 0.992508\tBest loss: 0.989683\tAccuracy: 71.20%\n",
      "81\tValidation loss: 1.005862\tBest loss: 0.989683\tAccuracy: 71.20%\n",
      "82\tValidation loss: 0.987180\tBest loss: 0.987180\tAccuracy: 71.30%\n",
      "83\tValidation loss: 0.986674\tBest loss: 0.986674\tAccuracy: 70.50%\n",
      "84\tValidation loss: 0.975955\tBest loss: 0.975955\tAccuracy: 71.70%\n",
      "85\tValidation loss: 0.993313\tBest loss: 0.975955\tAccuracy: 71.40%\n",
      "86\tValidation loss: 0.977511\tBest loss: 0.975955\tAccuracy: 71.50%\n",
      "87\tValidation loss: 0.976517\tBest loss: 0.975955\tAccuracy: 71.70%\n",
      "88\tValidation loss: 0.986216\tBest loss: 0.975955\tAccuracy: 71.10%\n",
      "89\tValidation loss: 0.972541\tBest loss: 0.972541\tAccuracy: 71.60%\n",
      "90\tValidation loss: 0.973646\tBest loss: 0.972541\tAccuracy: 71.60%\n",
      "91\tValidation loss: 0.960895\tBest loss: 0.960895\tAccuracy: 71.80%\n",
      "92\tValidation loss: 0.969827\tBest loss: 0.960895\tAccuracy: 72.00%\n",
      "93\tValidation loss: 0.967562\tBest loss: 0.960895\tAccuracy: 71.70%\n",
      "94\tValidation loss: 0.956302\tBest loss: 0.956302\tAccuracy: 72.50%\n",
      "95\tValidation loss: 0.948859\tBest loss: 0.948859\tAccuracy: 71.90%\n",
      "96\tValidation loss: 0.945791\tBest loss: 0.945791\tAccuracy: 73.00%\n",
      "97\tValidation loss: 0.944178\tBest loss: 0.944178\tAccuracy: 71.70%\n",
      "98\tValidation loss: 0.950307\tBest loss: 0.944178\tAccuracy: 72.40%\n",
      "99\tValidation loss: 0.954520\tBest loss: 0.944178\tAccuracy: 71.90%\n",
      "100\tValidation loss: 0.946012\tBest loss: 0.944178\tAccuracy: 73.40%\n",
      "101\tValidation loss: 0.953065\tBest loss: 0.944178\tAccuracy: 71.30%\n",
      "102\tValidation loss: 0.932087\tBest loss: 0.932087\tAccuracy: 72.90%\n",
      "103\tValidation loss: 0.946963\tBest loss: 0.932087\tAccuracy: 72.40%\n",
      "104\tValidation loss: 0.945921\tBest loss: 0.932087\tAccuracy: 72.20%\n",
      "105\tValidation loss: 0.947006\tBest loss: 0.932087\tAccuracy: 72.30%\n",
      "106\tValidation loss: 0.940597\tBest loss: 0.932087\tAccuracy: 72.80%\n",
      "107\tValidation loss: 0.930961\tBest loss: 0.930961\tAccuracy: 73.10%\n",
      "108\tValidation loss: 0.933741\tBest loss: 0.930961\tAccuracy: 72.90%\n",
      "109\tValidation loss: 0.934223\tBest loss: 0.930961\tAccuracy: 72.80%\n",
      "110\tValidation loss: 0.932538\tBest loss: 0.930961\tAccuracy: 73.20%\n",
      "111\tValidation loss: 0.928019\tBest loss: 0.928019\tAccuracy: 73.30%\n",
      "112\tValidation loss: 0.926159\tBest loss: 0.926159\tAccuracy: 73.70%\n",
      "113\tValidation loss: 0.927829\tBest loss: 0.926159\tAccuracy: 73.20%\n",
      "114\tValidation loss: 0.931024\tBest loss: 0.926159\tAccuracy: 72.80%\n",
      "115\tValidation loss: 0.919175\tBest loss: 0.919175\tAccuracy: 73.50%\n",
      "116\tValidation loss: 0.915732\tBest loss: 0.915732\tAccuracy: 73.40%\n",
      "117\tValidation loss: 0.918387\tBest loss: 0.915732\tAccuracy: 73.30%\n",
      "118\tValidation loss: 0.907303\tBest loss: 0.907303\tAccuracy: 74.00%\n",
      "119\tValidation loss: 0.918091\tBest loss: 0.907303\tAccuracy: 73.00%\n",
      "120\tValidation loss: 0.915339\tBest loss: 0.907303\tAccuracy: 73.00%\n",
      "121\tValidation loss: 0.913806\tBest loss: 0.907303\tAccuracy: 72.50%\n",
      "122\tValidation loss: 0.907450\tBest loss: 0.907303\tAccuracy: 72.80%\n",
      "123\tValidation loss: 0.910536\tBest loss: 0.907303\tAccuracy: 74.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 0.909575\tBest loss: 0.907303\tAccuracy: 73.40%\n",
      "125\tValidation loss: 0.896365\tBest loss: 0.896365\tAccuracy: 73.60%\n",
      "126\tValidation loss: 0.891053\tBest loss: 0.891053\tAccuracy: 73.70%\n",
      "127\tValidation loss: 0.908581\tBest loss: 0.891053\tAccuracy: 73.30%\n",
      "128\tValidation loss: 0.901557\tBest loss: 0.891053\tAccuracy: 74.10%\n",
      "129\tValidation loss: 0.902803\tBest loss: 0.891053\tAccuracy: 73.10%\n",
      "130\tValidation loss: 0.902746\tBest loss: 0.891053\tAccuracy: 73.30%\n",
      "131\tValidation loss: 0.902176\tBest loss: 0.891053\tAccuracy: 73.20%\n",
      "132\tValidation loss: 0.895405\tBest loss: 0.891053\tAccuracy: 73.60%\n",
      "133\tValidation loss: 0.892365\tBest loss: 0.891053\tAccuracy: 73.90%\n",
      "134\tValidation loss: 0.889871\tBest loss: 0.889871\tAccuracy: 73.60%\n",
      "135\tValidation loss: 0.892599\tBest loss: 0.889871\tAccuracy: 74.30%\n",
      "136\tValidation loss: 0.884457\tBest loss: 0.884457\tAccuracy: 73.90%\n",
      "137\tValidation loss: 0.879100\tBest loss: 0.879100\tAccuracy: 74.30%\n",
      "138\tValidation loss: 0.884889\tBest loss: 0.879100\tAccuracy: 74.00%\n",
      "139\tValidation loss: 0.880351\tBest loss: 0.879100\tAccuracy: 73.90%\n",
      "140\tValidation loss: 0.876043\tBest loss: 0.876043\tAccuracy: 74.00%\n",
      "141\tValidation loss: 0.892828\tBest loss: 0.876043\tAccuracy: 73.70%\n",
      "142\tValidation loss: 0.881032\tBest loss: 0.876043\tAccuracy: 74.70%\n",
      "143\tValidation loss: 0.875673\tBest loss: 0.875673\tAccuracy: 75.10%\n",
      "144\tValidation loss: 0.883067\tBest loss: 0.875673\tAccuracy: 73.90%\n",
      "145\tValidation loss: 0.876913\tBest loss: 0.875673\tAccuracy: 74.10%\n",
      "146\tValidation loss: 0.883807\tBest loss: 0.875673\tAccuracy: 74.40%\n",
      "147\tValidation loss: 0.883905\tBest loss: 0.875673\tAccuracy: 75.20%\n",
      "148\tValidation loss: 0.873989\tBest loss: 0.873989\tAccuracy: 74.40%\n",
      "149\tValidation loss: 0.881581\tBest loss: 0.873989\tAccuracy: 74.30%\n",
      "150\tValidation loss: 0.872616\tBest loss: 0.872616\tAccuracy: 74.80%\n",
      "151\tValidation loss: 0.874603\tBest loss: 0.872616\tAccuracy: 75.20%\n",
      "152\tValidation loss: 0.871843\tBest loss: 0.871843\tAccuracy: 74.50%\n",
      "153\tValidation loss: 0.872321\tBest loss: 0.871843\tAccuracy: 74.60%\n",
      "154\tValidation loss: 0.869347\tBest loss: 0.869347\tAccuracy: 74.70%\n",
      "155\tValidation loss: 0.873412\tBest loss: 0.869347\tAccuracy: 73.40%\n",
      "156\tValidation loss: 0.866905\tBest loss: 0.866905\tAccuracy: 75.20%\n",
      "157\tValidation loss: 0.868991\tBest loss: 0.866905\tAccuracy: 74.30%\n",
      "158\tValidation loss: 0.863050\tBest loss: 0.863050\tAccuracy: 74.60%\n",
      "159\tValidation loss: 0.876965\tBest loss: 0.863050\tAccuracy: 73.80%\n",
      "160\tValidation loss: 0.868312\tBest loss: 0.863050\tAccuracy: 74.50%\n",
      "161\tValidation loss: 0.862090\tBest loss: 0.862090\tAccuracy: 73.80%\n",
      "162\tValidation loss: 0.873786\tBest loss: 0.862090\tAccuracy: 73.40%\n",
      "163\tValidation loss: 0.856350\tBest loss: 0.856350\tAccuracy: 73.90%\n",
      "164\tValidation loss: 0.866679\tBest loss: 0.856350\tAccuracy: 74.30%\n",
      "165\tValidation loss: 0.868786\tBest loss: 0.856350\tAccuracy: 74.20%\n",
      "166\tValidation loss: 0.865327\tBest loss: 0.856350\tAccuracy: 74.30%\n",
      "167\tValidation loss: 0.867398\tBest loss: 0.856350\tAccuracy: 73.50%\n",
      "168\tValidation loss: 0.860015\tBest loss: 0.856350\tAccuracy: 74.60%\n",
      "169\tValidation loss: 0.881602\tBest loss: 0.856350\tAccuracy: 74.00%\n",
      "170\tValidation loss: 0.861165\tBest loss: 0.856350\tAccuracy: 74.50%\n",
      "171\tValidation loss: 0.855216\tBest loss: 0.855216\tAccuracy: 74.60%\n",
      "172\tValidation loss: 0.864482\tBest loss: 0.855216\tAccuracy: 74.40%\n",
      "173\tValidation loss: 0.858645\tBest loss: 0.855216\tAccuracy: 75.00%\n",
      "174\tValidation loss: 0.858137\tBest loss: 0.855216\tAccuracy: 74.00%\n",
      "175\tValidation loss: 0.850463\tBest loss: 0.850463\tAccuracy: 74.10%\n",
      "176\tValidation loss: 0.862932\tBest loss: 0.850463\tAccuracy: 73.60%\n",
      "177\tValidation loss: 0.854831\tBest loss: 0.850463\tAccuracy: 74.80%\n",
      "178\tValidation loss: 0.853658\tBest loss: 0.850463\tAccuracy: 75.60%\n",
      "179\tValidation loss: 0.853148\tBest loss: 0.850463\tAccuracy: 74.60%\n",
      "180\tValidation loss: 0.848832\tBest loss: 0.848832\tAccuracy: 73.90%\n",
      "181\tValidation loss: 0.839849\tBest loss: 0.839849\tAccuracy: 74.80%\n",
      "182\tValidation loss: 0.851091\tBest loss: 0.839849\tAccuracy: 74.70%\n",
      "183\tValidation loss: 0.852696\tBest loss: 0.839849\tAccuracy: 74.00%\n",
      "184\tValidation loss: 0.846761\tBest loss: 0.839849\tAccuracy: 75.00%\n",
      "185\tValidation loss: 0.837049\tBest loss: 0.837049\tAccuracy: 75.20%\n",
      "186\tValidation loss: 0.835138\tBest loss: 0.835138\tAccuracy: 74.70%\n",
      "187\tValidation loss: 0.847926\tBest loss: 0.835138\tAccuracy: 74.10%\n",
      "188\tValidation loss: 0.845885\tBest loss: 0.835138\tAccuracy: 74.10%\n",
      "189\tValidation loss: 0.838884\tBest loss: 0.835138\tAccuracy: 75.30%\n",
      "190\tValidation loss: 0.833982\tBest loss: 0.833982\tAccuracy: 75.00%\n",
      "191\tValidation loss: 0.843379\tBest loss: 0.833982\tAccuracy: 74.00%\n",
      "192\tValidation loss: 0.837525\tBest loss: 0.833982\tAccuracy: 74.60%\n",
      "193\tValidation loss: 0.836804\tBest loss: 0.833982\tAccuracy: 75.10%\n",
      "194\tValidation loss: 0.833596\tBest loss: 0.833596\tAccuracy: 74.90%\n",
      "195\tValidation loss: 0.827673\tBest loss: 0.827673\tAccuracy: 76.40%\n",
      "196\tValidation loss: 0.828327\tBest loss: 0.827673\tAccuracy: 75.00%\n",
      "197\tValidation loss: 0.830344\tBest loss: 0.827673\tAccuracy: 76.30%\n",
      "198\tValidation loss: 0.838782\tBest loss: 0.827673\tAccuracy: 75.00%\n",
      "199\tValidation loss: 0.834904\tBest loss: 0.827673\tAccuracy: 75.30%\n",
      "200\tValidation loss: 0.835909\tBest loss: 0.827673\tAccuracy: 75.00%\n",
      "201\tValidation loss: 0.833019\tBest loss: 0.827673\tAccuracy: 75.40%\n",
      "202\tValidation loss: 0.833002\tBest loss: 0.827673\tAccuracy: 74.70%\n",
      "203\tValidation loss: 0.832240\tBest loss: 0.827673\tAccuracy: 74.90%\n",
      "204\tValidation loss: 0.826905\tBest loss: 0.826905\tAccuracy: 74.70%\n",
      "205\tValidation loss: 0.824448\tBest loss: 0.824448\tAccuracy: 75.30%\n",
      "206\tValidation loss: 0.839946\tBest loss: 0.824448\tAccuracy: 74.90%\n",
      "207\tValidation loss: 0.840164\tBest loss: 0.824448\tAccuracy: 74.10%\n",
      "208\tValidation loss: 0.824662\tBest loss: 0.824448\tAccuracy: 74.80%\n",
      "209\tValidation loss: 0.833497\tBest loss: 0.824448\tAccuracy: 75.10%\n",
      "210\tValidation loss: 0.828490\tBest loss: 0.824448\tAccuracy: 75.00%\n",
      "211\tValidation loss: 0.818982\tBest loss: 0.818982\tAccuracy: 75.60%\n",
      "212\tValidation loss: 0.823730\tBest loss: 0.818982\tAccuracy: 74.60%\n",
      "213\tValidation loss: 0.835560\tBest loss: 0.818982\tAccuracy: 74.90%\n",
      "214\tValidation loss: 0.826118\tBest loss: 0.818982\tAccuracy: 74.80%\n",
      "215\tValidation loss: 0.836867\tBest loss: 0.818982\tAccuracy: 74.90%\n",
      "216\tValidation loss: 0.825521\tBest loss: 0.818982\tAccuracy: 75.20%\n",
      "217\tValidation loss: 0.820040\tBest loss: 0.818982\tAccuracy: 75.40%\n",
      "218\tValidation loss: 0.813253\tBest loss: 0.813253\tAccuracy: 75.40%\n",
      "219\tValidation loss: 0.813129\tBest loss: 0.813129\tAccuracy: 75.80%\n",
      "220\tValidation loss: 0.817081\tBest loss: 0.813129\tAccuracy: 75.10%\n",
      "221\tValidation loss: 0.821650\tBest loss: 0.813129\tAccuracy: 75.60%\n",
      "222\tValidation loss: 0.823543\tBest loss: 0.813129\tAccuracy: 75.20%\n",
      "223\tValidation loss: 0.834269\tBest loss: 0.813129\tAccuracy: 74.30%\n",
      "224\tValidation loss: 0.818294\tBest loss: 0.813129\tAccuracy: 74.30%\n",
      "225\tValidation loss: 0.811668\tBest loss: 0.811668\tAccuracy: 75.10%\n",
      "226\tValidation loss: 0.821318\tBest loss: 0.811668\tAccuracy: 74.60%\n",
      "227\tValidation loss: 0.815893\tBest loss: 0.811668\tAccuracy: 75.00%\n",
      "228\tValidation loss: 0.809209\tBest loss: 0.809209\tAccuracy: 76.00%\n",
      "229\tValidation loss: 0.809730\tBest loss: 0.809209\tAccuracy: 75.60%\n",
      "230\tValidation loss: 0.808374\tBest loss: 0.808374\tAccuracy: 75.30%\n",
      "231\tValidation loss: 0.813966\tBest loss: 0.808374\tAccuracy: 75.30%\n",
      "232\tValidation loss: 0.812695\tBest loss: 0.808374\tAccuracy: 76.00%\n",
      "233\tValidation loss: 0.815839\tBest loss: 0.808374\tAccuracy: 75.50%\n",
      "234\tValidation loss: 0.804819\tBest loss: 0.804819\tAccuracy: 75.50%\n",
      "235\tValidation loss: 0.806452\tBest loss: 0.804819\tAccuracy: 75.70%\n",
      "236\tValidation loss: 0.810024\tBest loss: 0.804819\tAccuracy: 75.10%\n",
      "237\tValidation loss: 0.817705\tBest loss: 0.804819\tAccuracy: 76.00%\n",
      "238\tValidation loss: 0.806876\tBest loss: 0.804819\tAccuracy: 76.00%\n",
      "239\tValidation loss: 0.806667\tBest loss: 0.804819\tAccuracy: 75.30%\n",
      "240\tValidation loss: 0.815463\tBest loss: 0.804819\tAccuracy: 75.10%\n",
      "241\tValidation loss: 0.814396\tBest loss: 0.804819\tAccuracy: 75.40%\n",
      "242\tValidation loss: 0.823468\tBest loss: 0.804819\tAccuracy: 75.20%\n",
      "243\tValidation loss: 0.802573\tBest loss: 0.802573\tAccuracy: 76.20%\n",
      "244\tValidation loss: 0.812748\tBest loss: 0.802573\tAccuracy: 74.80%\n",
      "245\tValidation loss: 0.803481\tBest loss: 0.802573\tAccuracy: 75.80%\n",
      "246\tValidation loss: 0.804245\tBest loss: 0.802573\tAccuracy: 76.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\tValidation loss: 0.798320\tBest loss: 0.798320\tAccuracy: 75.70%\n",
      "248\tValidation loss: 0.803952\tBest loss: 0.798320\tAccuracy: 75.50%\n",
      "249\tValidation loss: 0.809795\tBest loss: 0.798320\tAccuracy: 76.40%\n",
      "250\tValidation loss: 0.797816\tBest loss: 0.797816\tAccuracy: 76.00%\n",
      "251\tValidation loss: 0.785842\tBest loss: 0.785842\tAccuracy: 77.20%\n",
      "252\tValidation loss: 0.793285\tBest loss: 0.785842\tAccuracy: 76.50%\n",
      "253\tValidation loss: 0.810546\tBest loss: 0.785842\tAccuracy: 74.80%\n",
      "254\tValidation loss: 0.795237\tBest loss: 0.785842\tAccuracy: 75.60%\n",
      "255\tValidation loss: 0.797163\tBest loss: 0.785842\tAccuracy: 75.90%\n",
      "256\tValidation loss: 0.800842\tBest loss: 0.785842\tAccuracy: 75.80%\n",
      "257\tValidation loss: 0.799518\tBest loss: 0.785842\tAccuracy: 76.60%\n",
      "258\tValidation loss: 0.798099\tBest loss: 0.785842\tAccuracy: 75.70%\n",
      "259\tValidation loss: 0.804655\tBest loss: 0.785842\tAccuracy: 75.90%\n",
      "260\tValidation loss: 0.799066\tBest loss: 0.785842\tAccuracy: 76.40%\n",
      "261\tValidation loss: 0.793209\tBest loss: 0.785842\tAccuracy: 75.90%\n",
      "262\tValidation loss: 0.803653\tBest loss: 0.785842\tAccuracy: 75.30%\n",
      "263\tValidation loss: 0.808150\tBest loss: 0.785842\tAccuracy: 75.60%\n",
      "264\tValidation loss: 0.807309\tBest loss: 0.785842\tAccuracy: 74.70%\n",
      "265\tValidation loss: 0.792737\tBest loss: 0.785842\tAccuracy: 76.40%\n",
      "266\tValidation loss: 0.798367\tBest loss: 0.785842\tAccuracy: 76.00%\n",
      "267\tValidation loss: 0.790878\tBest loss: 0.785842\tAccuracy: 76.10%\n",
      "268\tValidation loss: 0.794892\tBest loss: 0.785842\tAccuracy: 76.10%\n",
      "269\tValidation loss: 0.781798\tBest loss: 0.781798\tAccuracy: 76.60%\n",
      "270\tValidation loss: 0.798433\tBest loss: 0.781798\tAccuracy: 76.30%\n",
      "271\tValidation loss: 0.796040\tBest loss: 0.781798\tAccuracy: 75.70%\n",
      "272\tValidation loss: 0.789061\tBest loss: 0.781798\tAccuracy: 77.00%\n",
      "273\tValidation loss: 0.794019\tBest loss: 0.781798\tAccuracy: 76.20%\n",
      "274\tValidation loss: 0.788439\tBest loss: 0.781798\tAccuracy: 76.40%\n",
      "275\tValidation loss: 0.793518\tBest loss: 0.781798\tAccuracy: 76.40%\n",
      "276\tValidation loss: 0.790060\tBest loss: 0.781798\tAccuracy: 76.70%\n",
      "277\tValidation loss: 0.793807\tBest loss: 0.781798\tAccuracy: 75.60%\n",
      "278\tValidation loss: 0.794545\tBest loss: 0.781798\tAccuracy: 76.80%\n",
      "279\tValidation loss: 0.801301\tBest loss: 0.781798\tAccuracy: 76.10%\n",
      "280\tValidation loss: 0.797408\tBest loss: 0.781798\tAccuracy: 76.60%\n",
      "281\tValidation loss: 0.791831\tBest loss: 0.781798\tAccuracy: 76.70%\n",
      "282\tValidation loss: 0.785031\tBest loss: 0.781798\tAccuracy: 76.50%\n",
      "283\tValidation loss: 0.780397\tBest loss: 0.780397\tAccuracy: 76.50%\n",
      "284\tValidation loss: 0.781748\tBest loss: 0.780397\tAccuracy: 75.50%\n",
      "285\tValidation loss: 0.786586\tBest loss: 0.780397\tAccuracy: 76.70%\n",
      "286\tValidation loss: 0.789744\tBest loss: 0.780397\tAccuracy: 76.10%\n",
      "287\tValidation loss: 0.783821\tBest loss: 0.780397\tAccuracy: 76.10%\n",
      "288\tValidation loss: 0.785448\tBest loss: 0.780397\tAccuracy: 76.10%\n",
      "289\tValidation loss: 0.785436\tBest loss: 0.780397\tAccuracy: 76.40%\n",
      "290\tValidation loss: 0.784769\tBest loss: 0.780397\tAccuracy: 76.50%\n",
      "291\tValidation loss: 0.786133\tBest loss: 0.780397\tAccuracy: 76.50%\n",
      "292\tValidation loss: 0.787283\tBest loss: 0.780397\tAccuracy: 76.90%\n",
      "293\tValidation loss: 0.784918\tBest loss: 0.780397\tAccuracy: 75.80%\n",
      "294\tValidation loss: 0.802167\tBest loss: 0.780397\tAccuracy: 76.30%\n",
      "295\tValidation loss: 0.787067\tBest loss: 0.780397\tAccuracy: 77.00%\n",
      "296\tValidation loss: 0.783516\tBest loss: 0.780397\tAccuracy: 76.40%\n",
      "297\tValidation loss: 0.790015\tBest loss: 0.780397\tAccuracy: 75.90%\n",
      "298\tValidation loss: 0.786880\tBest loss: 0.780397\tAccuracy: 75.80%\n",
      "299\tValidation loss: 0.792377\tBest loss: 0.780397\tAccuracy: 76.40%\n",
      "300\tValidation loss: 0.784789\tBest loss: 0.780397\tAccuracy: 76.00%\n",
      "301\tValidation loss: 0.787511\tBest loss: 0.780397\tAccuracy: 76.10%\n",
      "302\tValidation loss: 0.778695\tBest loss: 0.778695\tAccuracy: 75.60%\n",
      "303\tValidation loss: 0.782746\tBest loss: 0.778695\tAccuracy: 76.20%\n",
      "304\tValidation loss: 0.780663\tBest loss: 0.778695\tAccuracy: 76.70%\n",
      "305\tValidation loss: 0.778524\tBest loss: 0.778524\tAccuracy: 76.60%\n",
      "306\tValidation loss: 0.778868\tBest loss: 0.778524\tAccuracy: 76.80%\n",
      "307\tValidation loss: 0.781748\tBest loss: 0.778524\tAccuracy: 76.80%\n",
      "308\tValidation loss: 0.767610\tBest loss: 0.767610\tAccuracy: 76.90%\n",
      "309\tValidation loss: 0.774927\tBest loss: 0.767610\tAccuracy: 76.70%\n",
      "310\tValidation loss: 0.779758\tBest loss: 0.767610\tAccuracy: 76.90%\n",
      "311\tValidation loss: 0.784161\tBest loss: 0.767610\tAccuracy: 76.30%\n",
      "312\tValidation loss: 0.780404\tBest loss: 0.767610\tAccuracy: 76.00%\n",
      "313\tValidation loss: 0.778265\tBest loss: 0.767610\tAccuracy: 76.50%\n",
      "314\tValidation loss: 0.777388\tBest loss: 0.767610\tAccuracy: 76.10%\n",
      "315\tValidation loss: 0.784929\tBest loss: 0.767610\tAccuracy: 76.00%\n",
      "316\tValidation loss: 0.770193\tBest loss: 0.767610\tAccuracy: 77.20%\n",
      "317\tValidation loss: 0.770691\tBest loss: 0.767610\tAccuracy: 76.30%\n",
      "318\tValidation loss: 0.769713\tBest loss: 0.767610\tAccuracy: 76.80%\n",
      "319\tValidation loss: 0.763191\tBest loss: 0.763191\tAccuracy: 76.50%\n",
      "320\tValidation loss: 0.781803\tBest loss: 0.763191\tAccuracy: 76.40%\n",
      "321\tValidation loss: 0.774832\tBest loss: 0.763191\tAccuracy: 76.10%\n",
      "322\tValidation loss: 0.773605\tBest loss: 0.763191\tAccuracy: 76.60%\n",
      "323\tValidation loss: 0.776425\tBest loss: 0.763191\tAccuracy: 77.60%\n",
      "324\tValidation loss: 0.772373\tBest loss: 0.763191\tAccuracy: 76.80%\n",
      "325\tValidation loss: 0.772243\tBest loss: 0.763191\tAccuracy: 76.80%\n",
      "326\tValidation loss: 0.780679\tBest loss: 0.763191\tAccuracy: 77.10%\n",
      "327\tValidation loss: 0.764883\tBest loss: 0.763191\tAccuracy: 77.00%\n",
      "328\tValidation loss: 0.774981\tBest loss: 0.763191\tAccuracy: 77.10%\n",
      "329\tValidation loss: 0.779688\tBest loss: 0.763191\tAccuracy: 76.70%\n",
      "330\tValidation loss: 0.784157\tBest loss: 0.763191\tAccuracy: 76.60%\n",
      "331\tValidation loss: 0.772973\tBest loss: 0.763191\tAccuracy: 76.30%\n",
      "332\tValidation loss: 0.769294\tBest loss: 0.763191\tAccuracy: 77.40%\n",
      "333\tValidation loss: 0.787242\tBest loss: 0.763191\tAccuracy: 76.00%\n",
      "334\tValidation loss: 0.778011\tBest loss: 0.763191\tAccuracy: 76.30%\n",
      "335\tValidation loss: 0.779504\tBest loss: 0.763191\tAccuracy: 76.40%\n",
      "336\tValidation loss: 0.775768\tBest loss: 0.763191\tAccuracy: 76.60%\n",
      "337\tValidation loss: 0.776717\tBest loss: 0.763191\tAccuracy: 76.70%\n",
      "338\tValidation loss: 0.778370\tBest loss: 0.763191\tAccuracy: 76.50%\n",
      "339\tValidation loss: 0.776021\tBest loss: 0.763191\tAccuracy: 76.90%\n",
      "340\tValidation loss: 0.773675\tBest loss: 0.763191\tAccuracy: 76.60%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x000002EE6B234268>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x000002EE0F424400>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([  2.,  37., ...,  46.,  38.]), 'X_valid': array([[  5.27161e-03,   3.47861e-03, ...,   2.16462e-07,   7.51249e-08],\n",
       "       [  2.88831e-01,   7.36522e-02, ...,   1.09547e-07,   4.23796e-07],\n",
       "       ...,\n",
       "       [  2.34210e-03,   4.08974e-02, ...,   9.08267e-08,   3.42403e-07],\n",
       "       [  9.99087e-01,   3.94313e-01, ...,   8.10373e-08,   2.55999e-08]]), 'n_epochs': 1000},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'optimizer_class': [<class 'tensorflow.python.training.adam.AdamOptimizer'>, <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>, <class 'tensorflow.python.training.adagrad.AdagradOptimizer...: [50, 100, 120, 150, 200], 'batch_size': [10, 50, 100, 500], 'dropout_rate': [0.6, 0.4, 0.2, None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [50, 100, 120, 150, 200],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    \"n_hidden_layers\": [0, 1, 2, 3, 4],\n",
    "    \"optimizer_class\": [tf.train.AdamOptimizer, tf.train.GradientDescentOptimizer, \n",
    "                        tf.train.RMSPropOptimizer, tf.train.AdagradOptimizer],\n",
    "    \"dropout_rate\": [0.6, 0.4, 0.2, None]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                fit_params={\"X_valid\": X_valid, \"y_valid\": y_valid, \"n_epochs\": 1000},\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.elu>,\n",
       " 'batch_size': 100,\n",
       " 'dropout_rate': 0.2,\n",
       " 'learning_rate': 0.02,\n",
       " 'n_hidden_layers': 2,\n",
       " 'n_neurons': 150,\n",
       " 'optimizer_class': tensorflow.python.training.adagrad.AdagradOptimizer}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.28300545e-04   4.77155425e-07   1.34728625e-05 ...,   2.16795542e-08\n",
      "    8.91873866e-11   3.28065006e-08]\n",
      " [  1.10444920e-02   8.83828179e-05   5.29741228e-01 ...,   1.00412073e-07\n",
      "    4.38719144e-05   4.51308233e-06]\n",
      " [  6.26538275e-03   4.81186248e-03   4.00571339e-02 ...,   1.45428647e-09\n",
      "    1.19893617e-09   3.40297279e-09]\n",
      " ..., \n",
      " [  1.52076900e-04   2.01185979e-03   1.31219436e-04 ...,   8.72209726e-04\n",
      "    4.01590478e-06   5.12033221e-05]\n",
      " [  4.99038547e-02   5.44130942e-03   1.75688919e-02 ...,   8.32371588e-04\n",
      "    1.15339833e-04   1.08991495e-04]\n",
      " [  1.26075553e-10   2.93015709e-08   1.12019094e-07 ...,   4.73598018e-04\n",
      "    7.73408497e-03   2.91218312e-04]]\n",
      "[36  2 11 34  1 19 39 30 11 16  1 10 35  9  9 19 16  3 45 19 16  6 27 28 19\n",
      " 44 38  2  0 18 23 29 34 38  6 43 45 10 18 19  1 22 22  0  5 28 30 39  3 12\n",
      " 29 16 23 25 16 34 39  8 11 29 17  5 38 11  0  3  3 23 39  3 41 28 18 16 20\n",
      "  5 19 16 38 17 18 11 26 23  5 28 45 28  9 47 24  0 13  1  4 38 11 23 37  6\n",
      " 18  8 18  8 37 34  9 25 44 17  5 47 36  8 16 33 44  6 18 10 10 13  8 45 17\n",
      "  2  0 18 19 16 34  6  6 37  4 45 19  3 10  1 27 13 19  0 38  1 45 44 32 19\n",
      " 28  2 22  3  2 34  8 15 21 39 45 36 18  3  4  1 17 31  3 35 10 34 28  0 44\n",
      " 43 28 36  2 12 13 44  2 45 35 38 25 17 13 26 17  8 18 19  3 17 24 24  0 24\n",
      " 26  3 15 47 14 20 45 11  5 15 16 16 31 35 28  5 37 45 20 20  9 35 39 33 25\n",
      " 18 37 47 16 19 44 47 17 18 45 24 43 14 47 47 15 18 37 26  7 39  3 19 35 36\n",
      " 34 13 30 43 37 28  9  7 17 36 33 34 26 26 44 22 15 22 23  9  3 21  1 17 37\n",
      " 34 31 42 23 13 13 30 41 28  9 12 13 45 47 39 16 45 34 18 33 36 20 36 16 10\n",
      " 24 22 37 17 16 20 29 17  9 18  1  8 18  5 28 16 41  4 41 12 29 19  0 17 21\n",
      " 29 28 42 18 33 43 16 19 25 24 24 23 27 34  8 26 15 36  5 44 19 14  2 26 25\n",
      " 20  6 17  8  3  7 34  3 30 45 26  6  2 15 39 29 20 36 36 26  8 15  2  1 15\n",
      " 18  1 28  3 21  7 32 13 34 44  4  8 19 26 43 43 19 35 41  9 36 32 19 36 27\n",
      " 26 32  8 14 41 29 45  5  4 15 44 10  1 20  8 26 16  0 30  0 46 11 16 31  0\n",
      " 16  9 10 21 47 40 17 17 44 18  0 46 15 10 31 20 10  8 38 17 16  4 29 34 44\n",
      " 40 23 17 18 37 35 36 37 46 18 46  8 41 17 18 23 45 13  2 18 11 23  3 18 17\n",
      " 12 20 36 46 11 38 38 22 30 37 41  0 16 38  3  2 43 16 32 26  4  0 19 14 18\n",
      " 19 35 19 40 27 10  9  8 30 46  6  2  8  9 12  7  2 14 36 28  3 45  3  6 32\n",
      " 20 19  1 34 30 38 36 24  2 19 10  7 30 37 12 11 15 37 31 16  9  7  6 28 13\n",
      " 43 12  8 38 14 35 35 23 45  3 28 24 46 46 24 10 24 37 43  1 25 19 37 10 36\n",
      " 25  1 37 23 34 30 26 37 33 20 12 10 24 15 37 18  2 13 20  9 29 26  2 16 23\n",
      " 21 32 24 16  8 20  9 42  1 19 23 20 26  8 14 16 40 11  5  1 32 18 43  6  6\n",
      " 16  2  3 44 11 13 28 45 28  2 47 36 25 16  0 13  2 30  0 24 41 29 32  5  7\n",
      "  0 16  2 37 10  0 15 36 24  2 29 17  9 21 36 37 10 17 45 25 16  3 36 15  2\n",
      " 17 45  5  9  3 26 20 35  1 16  1 24 38 16 17  4  3 25 18 39  0 14  2  0 14\n",
      "  9 11 37  0 39 19  0 15 39 20 13 22 37 42 17  4 19 18 13 25 26  0  8 46  9\n",
      "  9  6 39 14  6  9 17 46  8 23 32 47 16 18 30 19 45 15 26 20 45 23 26 37 39\n",
      " 10 46 36  7 11 10 10 19  8 26 35 12  2 22 13  1 40 24  1 30 33  3 17 45 16\n",
      " 36 22  9  5  8  7 36 20 17 15 18  0 17 43  4 31 39 14  9 45 41 22 23  4 18\n",
      " 38 22 20 47 20 19 43 20 25 41  4 18 20 18 19 16  6 45  1  7 28 12 16 28  8\n",
      "  5 19  2 40 40  9 38 11 19  3 16 24 43 44  1 19  3  0 28 16 17  6 36 18 17\n",
      " 21 16 37 25 12  8 14  0  4 17 44 16 38 26 16 30 28 45 13 11 32 47 36 16 21\n",
      " 30 34 24 29 43 21  3 37 45  8 25 19 17 19 15 18 37  3 17 25 17  2  2 16 12\n",
      " 42  3  4 18 34  7 38 36  1 23  1  3  0 22 28  9  7 18 17 36 17 33  9 19 34\n",
      " 42 34  0  1 28  0  8 38 25  6 27 17 41 16 28  1 16 32 19 45 36 29 20 10 37\n",
      "  5  8 21 20 30 21  7 16 12 36 47 41 28 26 12 25 25  3  8 14 21 23  2 37  6\n",
      " 31 45 22 16 36 37  7  8 18  7 24  6 11 35 45 12 28 30 20  8 46 29 41 11 35]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76400000000000001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
