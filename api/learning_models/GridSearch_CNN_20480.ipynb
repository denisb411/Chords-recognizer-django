{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NN_model import DNNClassifier, CNNClassifier, GridSearchCNN, GridSearchDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d422fa41f33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprocessedData_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessedDataX_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if already preprocessed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprocessedX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessedDataX_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprocessedy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessedDatay_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "processedDataX_path = \"preprocessedSamples_X_samples_allGuitar_20480_Mm7_R1B.data\"\n",
    "processedDatay_path = \"preprocessedSamples_y_samples_allGuitar_20480_Mm7_R1B.data\"\n",
    "processedData_path = \"\"\n",
    "\n",
    "if os.path.isfile(processedDataX_path): #if already preprocessed\n",
    "\tprocessedX = np.load(processedDataX_path)\n",
    "\tprocessedy = np.load(processedDatay_path)\n",
    "else:\n",
    "\timport pandas as pd\n",
    "\timport librosa\n",
    "\tdf = pd.read_csv('samples_allGuitar_20480_Mm7_R1B.csv')\n",
    "\t# df = pd.read_csv('samples_nylonGuitar_1024_Mm7_R03.csv')\n",
    "\t# df = pd.read_csv('../CachedData.csv')\n",
    "\n",
    "\tX_load = np.array(df.iloc[:,:-1], dtype=np.float)\n",
    "\ty_load = np.array(df.iloc[:,-1], dtype=np.float)\n",
    "\tprocessedX = np.zeros((len(X_load),12,80,1), dtype=np.float)\n",
    "\tprocessedy = np.zeros(len(y_load), dtype=np.float)\n",
    "\tfor i in range(len(X_load)):\n",
    "\t\t# sample = librosa.core.stft(y=X_load[i], n_fft=2048, win_length=128, window='hamming', center=True, dtype=np.float32, pad_mode='reflect')\n",
    "\t\tsample = librosa.feature.chroma_stft(y=X_load[i], sr=44100, n_fft=20480, hop_length=258)\n",
    "\t\tsample = np.atleast_3d(sample)\n",
    "\t\tprocessedX[i] = sample\n",
    "\t\tprocessedy[i] = y_load[i]\n",
    "\t\tif i % 400 == 0:\n",
    "\t\t\tprint(i)\n",
    "\t\n",
    "\tprocessedX.dump(processedDataX_path)\n",
    "\tprocessedy.dump(processedDatay_path)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "print(processedy)\n",
    "sprocessedX, sprocessedy = shuffle(processedX, processedy)\n",
    "print(len(sprocessedX))\n",
    "\t\n",
    "trainRange = int(len(sprocessedX) * 0.9)\n",
    "validRange = int(len(sprocessedX) * 1)\n",
    "testRange = int(len(sprocessedX) * 0.1)\n",
    "\n",
    "\n",
    "X_train = np.array(sprocessedX[:trainRange], dtype=np.float)\n",
    "y_train = np.array(sprocessedy[:trainRange], dtype=np.float)\n",
    "\n",
    "X_valid = np.array(sprocessedX[trainRange:validRange], dtype=np.float)\n",
    "y_valid = np.array(sprocessedy[trainRange:validRange], dtype=np.float)\n",
    "\n",
    "X_test = np.array(sprocessedX[testRange:], dtype=np.float)\n",
    "y_test = np.array(sprocessedy[testRange:], dtype=np.float)\n",
    "print(y_test[1])\n",
    "print(sprocessedX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trining CNN with parameters: n_hidden_layers: 5, n_neurons: 1000, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D2086ABF8>, dropout_rate: 0, architecture: 2, conv1: {'conv1_fmaps': 16, 'conv1_ksize': 5, 'conv1_stride': 1, 'conv1_dropout': 0.1, 'conv1_activation': <function relu at 0x0000014D1DB1A048>}, conv2: {'conv2_fmaps': 32, 'conv2_ksize': 5, 'conv2_stride': 1, 'conv2_dropout': 0.3, 'conv2_activation': <function relu at 0x0000014D1DB1A048>} .\n",
      "Training and testing fold 0\n",
      "ranges:\n",
      "1684 2105\n",
      "shapes:\n",
      "(1687, 12, 80, 1) (421, 12, 80, 1)\n",
      "(1687,) (421,)\n",
      "Epoch 0, train accuracy: 30.0000%, valid. accuracy: 28.0851%, valid. best loss: 3.136065\n",
      "Epoch 1, train accuracy: 55.0000%, valid. accuracy: 39.5745%, valid. best loss: 2.048710\n",
      "Epoch 2, train accuracy: 45.0000%, valid. accuracy: 52.3404%, valid. best loss: 1.740090\n",
      "Epoch 3, train accuracy: 70.0000%, valid. accuracy: 59.5745%, valid. best loss: 1.344059\n",
      "Epoch 4, train accuracy: 80.0000%, valid. accuracy: 69.3617%, valid. best loss: 1.072234\n",
      "Epoch 5, train accuracy: 90.0000%, valid. accuracy: 73.1915%, valid. best loss: 1.030482\n",
      "Epoch 6, train accuracy: 85.0000%, valid. accuracy: 72.7660%, valid. best loss: 0.902692\n",
      "Epoch 7, train accuracy: 85.0000%, valid. accuracy: 73.1915%, valid. best loss: 0.821129\n",
      "Epoch 8, train accuracy: 90.0000%, valid. accuracy: 72.7660%, valid. best loss: 0.821129\n",
      "Epoch 9, train accuracy: 90.0000%, valid. accuracy: 77.8723%, valid. best loss: 0.821129\n",
      "Epoch 10, train accuracy: 75.0000%, valid. accuracy: 77.0213%, valid. best loss: 0.821129\n",
      "Epoch 11, train accuracy: 90.0000%, valid. accuracy: 77.4468%, valid. best loss: 0.821129\n",
      "Epoch 12, train accuracy: 95.0000%, valid. accuracy: 78.2979%, valid. best loss: 0.816682\n",
      "Epoch 13, train accuracy: 90.0000%, valid. accuracy: 76.5957%, valid. best loss: 0.759686\n",
      "Epoch 14, train accuracy: 95.0000%, valid. accuracy: 80.4255%, valid. best loss: 0.759686\n",
      "Epoch 15, train accuracy: 95.0000%, valid. accuracy: 78.7234%, valid. best loss: 0.759686\n",
      "Epoch 16, train accuracy: 95.0000%, valid. accuracy: 80.4255%, valid. best loss: 0.759686\n",
      "Epoch 17, train accuracy: 95.0000%, valid. accuracy: 78.2979%, valid. best loss: 0.744633\n",
      "Epoch 18, train accuracy: 100.0000%, valid. accuracy: 82.9787%, valid. best loss: 0.744633\n",
      "Epoch 19, train accuracy: 85.0000%, valid. accuracy: 82.1277%, valid. best loss: 0.744633\n",
      "Epoch 20, train accuracy: 100.0000%, valid. accuracy: 82.1277%, valid. best loss: 0.744633\n",
      "Epoch 21, train accuracy: 90.0000%, valid. accuracy: 82.5532%, valid. best loss: 0.744633\n",
      "Epoch 22, train accuracy: 90.0000%, valid. accuracy: 79.5745%, valid. best loss: 0.744633\n",
      "Epoch 23, train accuracy: 95.0000%, valid. accuracy: 84.2553%, valid. best loss: 0.744633\n",
      "Epoch 24, train accuracy: 90.0000%, valid. accuracy: 79.1489%, valid. best loss: 0.718923\n",
      "Epoch 25, train accuracy: 95.0000%, valid. accuracy: 79.5745%, valid. best loss: 0.718923\n",
      "Epoch 26, train accuracy: 90.0000%, valid. accuracy: 83.4043%, valid. best loss: 0.718923\n",
      "Epoch 27, train accuracy: 100.0000%, valid. accuracy: 83.8298%, valid. best loss: 0.718923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fa103039211a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\Github_Projects\\TCC\\TCC_app\\server_Universal_Tuner\\api\\learning_models\\dataset\\backup\\NN_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_valid, y_valid)\u001b[0m\n\u001b[0;32m    628\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\tlearning_rate=learning_rate, activation=activation, conv1=conv1, conv2=conv2, architecture=architecture)\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m                                                                                                         \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m                                                                                                         \u001b[0maccuracy_rate\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                                                                                                         \u001b[1;32mdel\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Github_Projects\\TCC\\TCC_app\\server_Universal_Tuner\\api\\learning_models\\dataset\\backup\\NN_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[0;32m    488\u001b[0m                                                 \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                                                 \u001b[0mX_batch_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                                                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                                                 \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcheck_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                                                         \u001b[0mX_valid_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow_env_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "\t\tdef parametrized_leaky_relu(z, name=None):\n",
    "\t\t\treturn tf.maximum(alpha * z, z, name=name)\n",
    "\t\treturn parametrized_leaky_relu\n",
    "\n",
    "params = {'n_hidden_layers': [5],\n",
    "\t'n_neurons' : [1000],\n",
    "\t'optimizer_class' : [tf.train.AdagradOptimizer],\n",
    "\t'learning_rate' : [0.05],\n",
    "\t'batch_size' : [50],\n",
    "\t'activation' : [leaky_relu()],\n",
    "\t'dropout_rate' : [0.4],\n",
    "\t'conv1' : [{'conv1_fmaps':16, 'conv1_ksize':5, 'conv1_stride':1, 'conv1_dropout':0.1, 'conv1_activation':tf.nn.relu}],\n",
    "\t'conv2' : [{'conv2_fmaps':32, 'conv2_ksize':5, 'conv2_stride':1, 'conv2_dropout':0.3, 'conv2_activation':tf.nn.relu}],\n",
    "    'architecture' : [2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCNN(params, k_fold=5)\n",
    "grid_search.fit(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global cnn\n",
    "cnn = CNNClassifier(batch_size=50, learning_rate=0.01, n_hidden_layers=5, n_neurons=700, \n",
    "                    optimizer_class=tf.train.AdagradOptimizer, activation=leaky_relu(alpha=0.01), \n",
    "                    conv1={'conv1_fmaps':16, 'conv1_ksize':5, 'conv1_stride':1, 'conv1_dropout':0.2},\n",
    "                   conv2={'conv2_fmaps':32, 'conv2_ksize':5, 'conv2_stride':1, 'conv2_dropout':0.4})\n",
    "range1 = 0\n",
    "range2 = 350\n",
    "X_train2 = X_train[:range1]\n",
    "X_train2 = np.vstack([X_train2, X_train[range2:]])\n",
    "print(X_train2.shape)\n",
    "y_train2 = y_train[:range1]\n",
    "y_train2 = np.append(y_train2, y_train[range2:])\n",
    "\n",
    "X_test2 = X_test[range1:range2]\n",
    "y_test2 = y_test[range1:range2]\n",
    "\n",
    "#cnn.fit(X_train=X_train[350:], y_train=y_train[350:], X_valid=X_valid, y_valid=y_valid)\n",
    "cnn.fit(X_train=X_train2, y_train=y_train2, X_valid=None, y_valid=None)\n",
    "\n",
    "score = cnn.accuracy_score(X_test2, y_test2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 700, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, dropout_rate: 0, \n",
      "Training and testing fold 0\n",
      "ranges:\n",
      "1684 2105\n",
      "shapes:\n",
      "(1687, 960) (421, 960)\n",
      "(1687,) (421,)\n",
      "0\tValidation loss: 1.927824\tBest loss: 1.927824\tAccuracy: 41.28%\n",
      "1\tValidation loss: 1.332642\tBest loss: 1.332642\tAccuracy: 53.62%\n",
      "2\tValidation loss: 1.081540\tBest loss: 1.081540\tAccuracy: 67.23%\n",
      "3\tValidation loss: 1.061828\tBest loss: 1.061828\tAccuracy: 67.23%\n",
      "4\tValidation loss: 1.186352\tBest loss: 1.061828\tAccuracy: 63.83%\n",
      "5\tValidation loss: 0.728708\tBest loss: 0.728708\tAccuracy: 76.60%\n",
      "6\tValidation loss: 1.158489\tBest loss: 0.728708\tAccuracy: 72.77%\n",
      "7\tValidation loss: 0.832701\tBest loss: 0.728708\tAccuracy: 75.32%\n",
      "8\tValidation loss: 0.838882\tBest loss: 0.728708\tAccuracy: 75.74%\n",
      "9\tValidation loss: 0.788303\tBest loss: 0.728708\tAccuracy: 79.57%\n",
      "10\tValidation loss: 1.030414\tBest loss: 0.728708\tAccuracy: 74.47%\n",
      "11\tValidation loss: 0.978955\tBest loss: 0.728708\tAccuracy: 77.02%\n",
      "12\tValidation loss: 0.665173\tBest loss: 0.665173\tAccuracy: 85.53%\n",
      "13\tValidation loss: 0.753411\tBest loss: 0.665173\tAccuracy: 82.13%\n",
      "14\tValidation loss: 0.625198\tBest loss: 0.625198\tAccuracy: 84.26%\n",
      "15\tValidation loss: 0.811022\tBest loss: 0.625198\tAccuracy: 84.68%\n",
      "16\tValidation loss: 0.732044\tBest loss: 0.625198\tAccuracy: 84.26%\n",
      "17\tValidation loss: 0.700065\tBest loss: 0.625198\tAccuracy: 85.11%\n",
      "18\tValidation loss: 0.639123\tBest loss: 0.625198\tAccuracy: 86.38%\n",
      "19\tValidation loss: 0.995452\tBest loss: 0.625198\tAccuracy: 82.13%\n",
      "20\tValidation loss: 0.885097\tBest loss: 0.625198\tAccuracy: 83.83%\n",
      "21\tValidation loss: 0.705553\tBest loss: 0.625198\tAccuracy: 83.40%\n",
      "22\tValidation loss: 0.703253\tBest loss: 0.625198\tAccuracy: 84.26%\n",
      "23\tValidation loss: 0.833086\tBest loss: 0.625198\tAccuracy: 82.98%\n",
      "24\tValidation loss: 0.704232\tBest loss: 0.625198\tAccuracy: 83.83%\n",
      "25\tValidation loss: 0.722283\tBest loss: 0.625198\tAccuracy: 85.11%\n",
      "26\tValidation loss: 0.923522\tBest loss: 0.625198\tAccuracy: 82.55%\n",
      "27\tValidation loss: 0.805782\tBest loss: 0.625198\tAccuracy: 80.85%\n",
      "28\tValidation loss: 0.755777\tBest loss: 0.625198\tAccuracy: 83.40%\n",
      "29\tValidation loss: 0.627087\tBest loss: 0.625198\tAccuracy: 87.23%\n",
      "30\tValidation loss: 0.668345\tBest loss: 0.625198\tAccuracy: 85.53%\n",
      "31\tValidation loss: 0.688447\tBest loss: 0.625198\tAccuracy: 86.38%\n",
      "32\tValidation loss: 0.669412\tBest loss: 0.625198\tAccuracy: 87.23%\n",
      "33\tValidation loss: 0.646140\tBest loss: 0.625198\tAccuracy: 88.51%\n",
      "34\tValidation loss: 0.752120\tBest loss: 0.625198\tAccuracy: 85.11%\n",
      "35\tValidation loss: 0.677858\tBest loss: 0.625198\tAccuracy: 86.38%\n",
      "36\tValidation loss: 0.716953\tBest loss: 0.625198\tAccuracy: 85.96%\n",
      "37\tValidation loss: 0.756176\tBest loss: 0.625198\tAccuracy: 85.96%\n",
      "38\tValidation loss: 0.709790\tBest loss: 0.625198\tAccuracy: 86.38%\n",
      "39\tValidation loss: 0.762814\tBest loss: 0.625198\tAccuracy: 86.81%\n",
      "40\tValidation loss: 0.723670\tBest loss: 0.625198\tAccuracy: 88.09%\n",
      "41\tValidation loss: 0.771337\tBest loss: 0.625198\tAccuracy: 83.40%\n",
      "42\tValidation loss: 1.020932\tBest loss: 0.625198\tAccuracy: 82.98%\n",
      "43\tValidation loss: 0.669839\tBest loss: 0.625198\tAccuracy: 88.94%\n",
      "44\tValidation loss: 0.681119\tBest loss: 0.625198\tAccuracy: 88.51%\n",
      "45\tValidation loss: 0.687060\tBest loss: 0.625198\tAccuracy: 88.51%\n",
      "46\tValidation loss: 0.746809\tBest loss: 0.625198\tAccuracy: 88.51%\n",
      "47\tValidation loss: 0.722719\tBest loss: 0.625198\tAccuracy: 88.94%\n",
      "48\tValidation loss: 0.725657\tBest loss: 0.625198\tAccuracy: 88.09%\n",
      "49\tValidation loss: 0.749129\tBest loss: 0.625198\tAccuracy: 88.51%\n",
      "50\tValidation loss: 0.749228\tBest loss: 0.625198\tAccuracy: 88.94%\n",
      "51\tValidation loss: 0.777215\tBest loss: 0.625198\tAccuracy: 88.09%\n",
      "52\tValidation loss: 0.782112\tBest loss: 0.625198\tAccuracy: 88.09%\n",
      "53\tValidation loss: 0.809261\tBest loss: 0.625198\tAccuracy: 87.66%\n",
      "54\tValidation loss: 0.809387\tBest loss: 0.625198\tAccuracy: 88.09%\n",
      "55\tValidation loss: 0.771969\tBest loss: 0.625198\tAccuracy: 88.94%\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.850356\n",
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 700, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, dropout_rate: 0, \n",
      "Training and testing fold 1\n",
      "ranges:\n",
      "1263 1684\n",
      "shapes:\n",
      "(1687, 960) (421, 960)\n",
      "(1687,) (421,)\n",
      "0\tValidation loss: 2.098315\tBest loss: 2.098315\tAccuracy: 35.32%\n",
      "1\tValidation loss: 1.284756\tBest loss: 1.284756\tAccuracy: 57.87%\n",
      "2\tValidation loss: 1.316485\tBest loss: 1.284756\tAccuracy: 57.45%\n",
      "3\tValidation loss: 1.076209\tBest loss: 1.076209\tAccuracy: 65.53%\n",
      "4\tValidation loss: 1.099569\tBest loss: 1.076209\tAccuracy: 66.38%\n",
      "5\tValidation loss: 0.667031\tBest loss: 0.667031\tAccuracy: 78.30%\n",
      "6\tValidation loss: 0.938847\tBest loss: 0.667031\tAccuracy: 77.02%\n",
      "7\tValidation loss: 0.613918\tBest loss: 0.613918\tAccuracy: 80.85%\n",
      "8\tValidation loss: 0.652414\tBest loss: 0.613918\tAccuracy: 79.57%\n",
      "9\tValidation loss: 0.759423\tBest loss: 0.613918\tAccuracy: 76.17%\n",
      "10\tValidation loss: 0.681665\tBest loss: 0.613918\tAccuracy: 82.55%\n",
      "11\tValidation loss: 0.648560\tBest loss: 0.613918\tAccuracy: 82.98%\n",
      "12\tValidation loss: 0.537082\tBest loss: 0.537082\tAccuracy: 85.53%\n",
      "13\tValidation loss: 0.490069\tBest loss: 0.490069\tAccuracy: 85.96%\n",
      "14\tValidation loss: 0.682370\tBest loss: 0.490069\tAccuracy: 81.70%\n",
      "15\tValidation loss: 0.560089\tBest loss: 0.490069\tAccuracy: 84.68%\n",
      "16\tValidation loss: 0.736552\tBest loss: 0.490069\tAccuracy: 80.85%\n",
      "17\tValidation loss: 0.723834\tBest loss: 0.490069\tAccuracy: 82.55%\n",
      "18\tValidation loss: 0.703647\tBest loss: 0.490069\tAccuracy: 82.98%\n",
      "19\tValidation loss: 0.591931\tBest loss: 0.490069\tAccuracy: 85.11%\n",
      "20\tValidation loss: 0.605365\tBest loss: 0.490069\tAccuracy: 85.53%\n",
      "21\tValidation loss: 0.576728\tBest loss: 0.490069\tAccuracy: 84.68%\n",
      "22\tValidation loss: 0.562505\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "23\tValidation loss: 0.568494\tBest loss: 0.490069\tAccuracy: 88.51%\n",
      "24\tValidation loss: 0.731808\tBest loss: 0.490069\tAccuracy: 83.83%\n",
      "25\tValidation loss: 0.839138\tBest loss: 0.490069\tAccuracy: 80.43%\n",
      "26\tValidation loss: 0.581473\tBest loss: 0.490069\tAccuracy: 88.51%\n",
      "27\tValidation loss: 0.678109\tBest loss: 0.490069\tAccuracy: 84.26%\n",
      "28\tValidation loss: 0.695328\tBest loss: 0.490069\tAccuracy: 82.13%\n",
      "29\tValidation loss: 0.546595\tBest loss: 0.490069\tAccuracy: 88.94%\n",
      "30\tValidation loss: 0.607342\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "31\tValidation loss: 0.595087\tBest loss: 0.490069\tAccuracy: 88.51%\n",
      "32\tValidation loss: 0.590823\tBest loss: 0.490069\tAccuracy: 89.36%\n",
      "33\tValidation loss: 0.596588\tBest loss: 0.490069\tAccuracy: 88.09%\n",
      "34\tValidation loss: 0.586300\tBest loss: 0.490069\tAccuracy: 88.51%\n",
      "35\tValidation loss: 0.598063\tBest loss: 0.490069\tAccuracy: 88.51%\n",
      "36\tValidation loss: 1.292750\tBest loss: 0.490069\tAccuracy: 72.34%\n",
      "37\tValidation loss: 0.577390\tBest loss: 0.490069\tAccuracy: 86.38%\n",
      "38\tValidation loss: 0.671381\tBest loss: 0.490069\tAccuracy: 85.53%\n",
      "39\tValidation loss: 0.630432\tBest loss: 0.490069\tAccuracy: 85.96%\n",
      "40\tValidation loss: 0.581824\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "41\tValidation loss: 0.605442\tBest loss: 0.490069\tAccuracy: 85.96%\n",
      "42\tValidation loss: 0.603398\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "43\tValidation loss: 0.606207\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "44\tValidation loss: 0.617704\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "45\tValidation loss: 0.660168\tBest loss: 0.490069\tAccuracy: 85.96%\n",
      "46\tValidation loss: 0.671403\tBest loss: 0.490069\tAccuracy: 86.38%\n",
      "47\tValidation loss: 0.656044\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "48\tValidation loss: 0.673115\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "49\tValidation loss: 0.678776\tBest loss: 0.490069\tAccuracy: 86.38%\n",
      "50\tValidation loss: 0.688171\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "51\tValidation loss: 0.669993\tBest loss: 0.490069\tAccuracy: 86.81%\n",
      "52\tValidation loss: 0.680600\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "53\tValidation loss: 0.671775\tBest loss: 0.490069\tAccuracy: 87.66%\n",
      "54\tValidation loss: 0.684711\tBest loss: 0.490069\tAccuracy: 88.09%\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.869359\n",
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 700, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, dropout_rate: 0, \n",
      "Training and testing fold 2\n",
      "ranges:\n",
      "842 1263\n",
      "shapes:\n",
      "(1687, 960) (421, 960)\n",
      "(1687,) (421,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.012184\tBest loss: 2.012184\tAccuracy: 40.00%\n",
      "1\tValidation loss: 1.399388\tBest loss: 1.399388\tAccuracy: 59.15%\n",
      "2\tValidation loss: 0.922173\tBest loss: 0.922173\tAccuracy: 68.09%\n",
      "3\tValidation loss: 0.912935\tBest loss: 0.912935\tAccuracy: 71.49%\n",
      "4\tValidation loss: 0.908723\tBest loss: 0.908723\tAccuracy: 71.49%\n",
      "5\tValidation loss: 0.802367\tBest loss: 0.802367\tAccuracy: 74.47%\n",
      "6\tValidation loss: 0.947047\tBest loss: 0.802367\tAccuracy: 68.94%\n",
      "7\tValidation loss: 0.665976\tBest loss: 0.665976\tAccuracy: 78.72%\n",
      "8\tValidation loss: 0.714143\tBest loss: 0.665976\tAccuracy: 76.60%\n",
      "9\tValidation loss: 0.967501\tBest loss: 0.665976\tAccuracy: 72.34%\n",
      "10\tValidation loss: 0.673516\tBest loss: 0.665976\tAccuracy: 80.85%\n",
      "11\tValidation loss: 0.860106\tBest loss: 0.665976\tAccuracy: 78.30%\n",
      "12\tValidation loss: 0.701793\tBest loss: 0.665976\tAccuracy: 81.70%\n",
      "13\tValidation loss: 0.784266\tBest loss: 0.665976\tAccuracy: 81.28%\n",
      "14\tValidation loss: 0.699730\tBest loss: 0.665976\tAccuracy: 82.98%\n",
      "15\tValidation loss: 0.853757\tBest loss: 0.665976\tAccuracy: 80.00%\n",
      "16\tValidation loss: 0.633249\tBest loss: 0.633249\tAccuracy: 85.53%\n",
      "17\tValidation loss: 0.684689\tBest loss: 0.633249\tAccuracy: 81.70%\n",
      "18\tValidation loss: 0.719557\tBest loss: 0.633249\tAccuracy: 84.68%\n",
      "19\tValidation loss: 0.596229\tBest loss: 0.596229\tAccuracy: 85.11%\n",
      "20\tValidation loss: 0.809586\tBest loss: 0.596229\tAccuracy: 81.28%\n",
      "21\tValidation loss: 0.705545\tBest loss: 0.596229\tAccuracy: 85.11%\n",
      "22\tValidation loss: 0.689077\tBest loss: 0.596229\tAccuracy: 84.68%\n",
      "23\tValidation loss: 0.693954\tBest loss: 0.596229\tAccuracy: 83.83%\n",
      "24\tValidation loss: 0.734761\tBest loss: 0.596229\tAccuracy: 85.53%\n",
      "25\tValidation loss: 0.695777\tBest loss: 0.596229\tAccuracy: 83.40%\n",
      "26\tValidation loss: 0.824219\tBest loss: 0.596229\tAccuracy: 82.55%\n",
      "27\tValidation loss: 0.992118\tBest loss: 0.596229\tAccuracy: 78.72%\n",
      "28\tValidation loss: 0.727236\tBest loss: 0.596229\tAccuracy: 80.43%\n",
      "29\tValidation loss: 0.530605\tBest loss: 0.530605\tAccuracy: 85.96%\n",
      "30\tValidation loss: 0.578076\tBest loss: 0.530605\tAccuracy: 84.68%\n",
      "31\tValidation loss: 0.517311\tBest loss: 0.517311\tAccuracy: 87.23%\n",
      "32\tValidation loss: 0.709903\tBest loss: 0.517311\tAccuracy: 85.11%\n",
      "33\tValidation loss: 0.601201\tBest loss: 0.517311\tAccuracy: 82.55%\n",
      "34\tValidation loss: 0.626564\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "35\tValidation loss: 0.588974\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "36\tValidation loss: 0.571683\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "37\tValidation loss: 0.626004\tBest loss: 0.517311\tAccuracy: 86.38%\n",
      "38\tValidation loss: 0.783707\tBest loss: 0.517311\tAccuracy: 82.13%\n",
      "39\tValidation loss: 0.688360\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "40\tValidation loss: 0.690128\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "41\tValidation loss: 0.743877\tBest loss: 0.517311\tAccuracy: 83.83%\n",
      "42\tValidation loss: 0.725068\tBest loss: 0.517311\tAccuracy: 84.26%\n",
      "43\tValidation loss: 0.665448\tBest loss: 0.517311\tAccuracy: 83.40%\n",
      "44\tValidation loss: 0.695295\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "45\tValidation loss: 0.797232\tBest loss: 0.517311\tAccuracy: 83.83%\n",
      "46\tValidation loss: 0.656280\tBest loss: 0.517311\tAccuracy: 85.11%\n",
      "47\tValidation loss: 0.688736\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "48\tValidation loss: 0.659340\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "49\tValidation loss: 0.625746\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "50\tValidation loss: 0.653138\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "51\tValidation loss: 0.664621\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "52\tValidation loss: 0.664984\tBest loss: 0.517311\tAccuracy: 86.38%\n",
      "53\tValidation loss: 0.678456\tBest loss: 0.517311\tAccuracy: 86.38%\n",
      "54\tValidation loss: 0.818204\tBest loss: 0.517311\tAccuracy: 81.70%\n",
      "55\tValidation loss: 0.713776\tBest loss: 0.517311\tAccuracy: 83.83%\n",
      "56\tValidation loss: 0.684104\tBest loss: 0.517311\tAccuracy: 85.11%\n",
      "57\tValidation loss: 0.815404\tBest loss: 0.517311\tAccuracy: 82.13%\n",
      "58\tValidation loss: 0.679470\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "59\tValidation loss: 0.712745\tBest loss: 0.517311\tAccuracy: 85.11%\n",
      "60\tValidation loss: 0.736483\tBest loss: 0.517311\tAccuracy: 85.11%\n",
      "61\tValidation loss: 0.756497\tBest loss: 0.517311\tAccuracy: 83.83%\n",
      "62\tValidation loss: 0.747515\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "63\tValidation loss: 0.784205\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "64\tValidation loss: 0.773501\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "65\tValidation loss: 0.764929\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "66\tValidation loss: 0.773455\tBest loss: 0.517311\tAccuracy: 85.96%\n",
      "67\tValidation loss: 0.783199\tBest loss: 0.517311\tAccuracy: 85.53%\n",
      "68\tValidation loss: 0.775688\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "69\tValidation loss: 0.783499\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "70\tValidation loss: 0.794795\tBest loss: 0.517311\tAccuracy: 84.68%\n",
      "71\tValidation loss: 0.807395\tBest loss: 0.517311\tAccuracy: 84.26%\n",
      "72\tValidation loss: 0.811361\tBest loss: 0.517311\tAccuracy: 84.26%\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.864608\n",
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 700, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, dropout_rate: 0, \n",
      "Training and testing fold 3\n",
      "ranges:\n",
      "421 842\n",
      "shapes:\n",
      "(1687, 960) (421, 960)\n",
      "(1687,) (421,)\n",
      "0\tValidation loss: 1.749648\tBest loss: 1.749648\tAccuracy: 48.09%\n",
      "1\tValidation loss: 1.405729\tBest loss: 1.405729\tAccuracy: 57.02%\n",
      "2\tValidation loss: 1.177702\tBest loss: 1.177702\tAccuracy: 65.96%\n",
      "3\tValidation loss: 0.866492\tBest loss: 0.866492\tAccuracy: 74.47%\n",
      "4\tValidation loss: 1.067998\tBest loss: 0.866492\tAccuracy: 68.94%\n",
      "5\tValidation loss: 0.688478\tBest loss: 0.688478\tAccuracy: 81.70%\n",
      "6\tValidation loss: 0.714344\tBest loss: 0.688478\tAccuracy: 79.15%\n",
      "7\tValidation loss: 0.704124\tBest loss: 0.688478\tAccuracy: 80.00%\n",
      "8\tValidation loss: 0.734775\tBest loss: 0.688478\tAccuracy: 77.45%\n",
      "9\tValidation loss: 0.692832\tBest loss: 0.688478\tAccuracy: 83.83%\n",
      "10\tValidation loss: 0.674721\tBest loss: 0.674721\tAccuracy: 82.13%\n",
      "11\tValidation loss: 0.685563\tBest loss: 0.674721\tAccuracy: 82.98%\n",
      "12\tValidation loss: 0.707229\tBest loss: 0.674721\tAccuracy: 83.40%\n",
      "13\tValidation loss: 0.696086\tBest loss: 0.674721\tAccuracy: 82.98%\n",
      "14\tValidation loss: 0.880296\tBest loss: 0.674721\tAccuracy: 80.43%\n",
      "15\tValidation loss: 0.888207\tBest loss: 0.674721\tAccuracy: 81.70%\n",
      "16\tValidation loss: 0.838569\tBest loss: 0.674721\tAccuracy: 82.55%\n",
      "17\tValidation loss: 0.741664\tBest loss: 0.674721\tAccuracy: 83.83%\n",
      "18\tValidation loss: 0.957758\tBest loss: 0.674721\tAccuracy: 81.70%\n",
      "19\tValidation loss: 0.753918\tBest loss: 0.674721\tAccuracy: 81.70%\n",
      "20\tValidation loss: 0.695848\tBest loss: 0.674721\tAccuracy: 84.26%\n",
      "21\tValidation loss: 0.812808\tBest loss: 0.674721\tAccuracy: 83.83%\n",
      "22\tValidation loss: 0.980266\tBest loss: 0.674721\tAccuracy: 79.15%\n",
      "23\tValidation loss: 0.824635\tBest loss: 0.674721\tAccuracy: 79.57%\n",
      "24\tValidation loss: 0.817612\tBest loss: 0.674721\tAccuracy: 81.28%\n",
      "25\tValidation loss: 0.813038\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "26\tValidation loss: 0.762217\tBest loss: 0.674721\tAccuracy: 86.81%\n",
      "27\tValidation loss: 0.802303\tBest loss: 0.674721\tAccuracy: 84.26%\n",
      "28\tValidation loss: 0.809976\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "29\tValidation loss: 0.841054\tBest loss: 0.674721\tAccuracy: 86.38%\n",
      "30\tValidation loss: 0.797579\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "31\tValidation loss: 0.843971\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "32\tValidation loss: 0.839459\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "33\tValidation loss: 1.073442\tBest loss: 0.674721\tAccuracy: 81.28%\n",
      "34\tValidation loss: 0.894148\tBest loss: 0.674721\tAccuracy: 85.96%\n",
      "35\tValidation loss: 0.845562\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "36\tValidation loss: 0.936915\tBest loss: 0.674721\tAccuracy: 84.68%\n",
      "37\tValidation loss: 0.931412\tBest loss: 0.674721\tAccuracy: 85.96%\n",
      "38\tValidation loss: 0.878841\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "39\tValidation loss: 0.848525\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "40\tValidation loss: 0.869248\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "41\tValidation loss: 0.896890\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "42\tValidation loss: 1.026573\tBest loss: 0.674721\tAccuracy: 82.98%\n",
      "43\tValidation loss: 0.921449\tBest loss: 0.674721\tAccuracy: 84.68%\n",
      "44\tValidation loss: 0.987051\tBest loss: 0.674721\tAccuracy: 81.70%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\tValidation loss: 0.884266\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "46\tValidation loss: 0.931647\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "47\tValidation loss: 0.914701\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "48\tValidation loss: 0.911927\tBest loss: 0.674721\tAccuracy: 84.68%\n",
      "49\tValidation loss: 0.930058\tBest loss: 0.674721\tAccuracy: 84.26%\n",
      "50\tValidation loss: 0.931550\tBest loss: 0.674721\tAccuracy: 85.11%\n",
      "51\tValidation loss: 0.955821\tBest loss: 0.674721\tAccuracy: 85.53%\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.793349\n",
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 700, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, dropout_rate: 0, \n",
      "Training and testing fold 4\n",
      "ranges:\n",
      "0 421\n",
      "shapes:\n",
      "(1687, 960) (421, 960)\n",
      "(1687,) (421,)\n",
      "0\tValidation loss: 2.041788\tBest loss: 2.041788\tAccuracy: 35.74%\n",
      "1\tValidation loss: 1.408095\tBest loss: 1.408095\tAccuracy: 58.72%\n",
      "2\tValidation loss: 0.974582\tBest loss: 0.974582\tAccuracy: 65.96%\n",
      "3\tValidation loss: 1.016532\tBest loss: 0.974582\tAccuracy: 66.38%\n",
      "4\tValidation loss: 1.003922\tBest loss: 0.974582\tAccuracy: 66.81%\n",
      "5\tValidation loss: 0.947195\tBest loss: 0.947195\tAccuracy: 72.34%\n",
      "6\tValidation loss: 0.798048\tBest loss: 0.798048\tAccuracy: 75.32%\n",
      "7\tValidation loss: 0.729261\tBest loss: 0.729261\tAccuracy: 78.72%\n",
      "8\tValidation loss: 0.953173\tBest loss: 0.729261\tAccuracy: 71.06%\n",
      "9\tValidation loss: 0.647511\tBest loss: 0.647511\tAccuracy: 82.13%\n",
      "10\tValidation loss: 0.725276\tBest loss: 0.647511\tAccuracy: 79.57%\n",
      "11\tValidation loss: 0.757990\tBest loss: 0.647511\tAccuracy: 80.00%\n",
      "12\tValidation loss: 0.696071\tBest loss: 0.647511\tAccuracy: 81.28%\n",
      "13\tValidation loss: 0.811308\tBest loss: 0.647511\tAccuracy: 79.15%\n",
      "14\tValidation loss: 1.011185\tBest loss: 0.647511\tAccuracy: 80.85%\n",
      "15\tValidation loss: 0.635698\tBest loss: 0.635698\tAccuracy: 84.26%\n",
      "16\tValidation loss: 0.616628\tBest loss: 0.616628\tAccuracy: 87.23%\n",
      "17\tValidation loss: 0.795255\tBest loss: 0.616628\tAccuracy: 77.87%\n",
      "18\tValidation loss: 0.664321\tBest loss: 0.616628\tAccuracy: 85.11%\n",
      "19\tValidation loss: 0.612511\tBest loss: 0.612511\tAccuracy: 84.26%\n",
      "20\tValidation loss: 0.751935\tBest loss: 0.612511\tAccuracy: 80.43%\n",
      "21\tValidation loss: 0.705104\tBest loss: 0.612511\tAccuracy: 83.40%\n",
      "22\tValidation loss: 0.670606\tBest loss: 0.612511\tAccuracy: 86.38%\n",
      "23\tValidation loss: 0.695369\tBest loss: 0.612511\tAccuracy: 85.96%\n",
      "24\tValidation loss: 0.800311\tBest loss: 0.612511\tAccuracy: 82.98%\n",
      "25\tValidation loss: 0.642291\tBest loss: 0.612511\tAccuracy: 86.38%\n",
      "26\tValidation loss: 0.627890\tBest loss: 0.612511\tAccuracy: 87.66%\n",
      "27\tValidation loss: 0.655707\tBest loss: 0.612511\tAccuracy: 80.43%\n",
      "28\tValidation loss: 0.664667\tBest loss: 0.612511\tAccuracy: 82.55%\n",
      "29\tValidation loss: 0.715630\tBest loss: 0.612511\tAccuracy: 82.13%\n",
      "30\tValidation loss: 1.066375\tBest loss: 0.612511\tAccuracy: 80.00%\n",
      "31\tValidation loss: 0.960563\tBest loss: 0.612511\tAccuracy: 80.43%\n",
      "32\tValidation loss: 0.671350\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "33\tValidation loss: 0.644211\tBest loss: 0.612511\tAccuracy: 86.81%\n",
      "34\tValidation loss: 0.683340\tBest loss: 0.612511\tAccuracy: 85.96%\n",
      "35\tValidation loss: 0.734040\tBest loss: 0.612511\tAccuracy: 84.68%\n",
      "36\tValidation loss: 0.693532\tBest loss: 0.612511\tAccuracy: 84.26%\n",
      "37\tValidation loss: 0.712525\tBest loss: 0.612511\tAccuracy: 86.38%\n",
      "38\tValidation loss: 0.722763\tBest loss: 0.612511\tAccuracy: 85.96%\n",
      "39\tValidation loss: 0.734919\tBest loss: 0.612511\tAccuracy: 87.66%\n",
      "40\tValidation loss: 0.698189\tBest loss: 0.612511\tAccuracy: 87.66%\n",
      "41\tValidation loss: 0.703966\tBest loss: 0.612511\tAccuracy: 86.38%\n",
      "42\tValidation loss: 0.733433\tBest loss: 0.612511\tAccuracy: 84.68%\n",
      "43\tValidation loss: 0.708386\tBest loss: 0.612511\tAccuracy: 83.83%\n",
      "44\tValidation loss: 0.926381\tBest loss: 0.612511\tAccuracy: 81.28%\n",
      "45\tValidation loss: 0.665556\tBest loss: 0.612511\tAccuracy: 84.68%\n",
      "46\tValidation loss: 0.762167\tBest loss: 0.612511\tAccuracy: 84.68%\n",
      "47\tValidation loss: 0.685065\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "48\tValidation loss: 0.689328\tBest loss: 0.612511\tAccuracy: 86.81%\n",
      "49\tValidation loss: 0.708962\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "50\tValidation loss: 0.713439\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "51\tValidation loss: 0.726662\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "52\tValidation loss: 0.745050\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "53\tValidation loss: 0.743329\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "54\tValidation loss: 0.760561\tBest loss: 0.612511\tAccuracy: 87.66%\n",
      "55\tValidation loss: 0.750701\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "56\tValidation loss: 0.745222\tBest loss: 0.612511\tAccuracy: 87.66%\n",
      "57\tValidation loss: 0.724751\tBest loss: 0.612511\tAccuracy: 87.23%\n",
      "58\tValidation loss: 0.733528\tBest loss: 0.612511\tAccuracy: 88.09%\n",
      "59\tValidation loss: 0.751598\tBest loss: 0.612511\tAccuracy: 88.51%\n",
      "60\tValidation loss: 0.773272\tBest loss: 0.612511\tAccuracy: 88.09%\n",
      "Early stopping!\n",
      "Final accuracy on test set: 0.857482\n",
      "******************************************\n",
      "{'n_hidden_layers': 5, 'n_neurons': 700, 'optimizer_class': <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, 'learning_rate': 0.05, 'batch_size': 50, 'activation': <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, 'dropout_rate': 0.1, 'accuracy_rate': 0.84703091382980344}\n",
      "******************************************\n",
      "Best parameters:\n",
      "{'n_hidden_layers': 5, 'n_neurons': 700, 'optimizer_class': <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, 'learning_rate': 0.05, 'batch_size': 50, 'activation': <function leaky_relu.<locals>.parametrized_leaky_relu at 0x0000014D21404598>, 'dropout_rate': 0.1, 'accuracy_rate': 0.84703091382980344}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_reshaped = np.reshape(X_train,(len(X_train), -1))\n",
    "X_valid_reshaped = np.reshape(X_valid,(len(X_valid), -1))\n",
    "X_test_reshaped = np.reshape(X_test,(len(X_test), -1))\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "\t\tdef parametrized_leaky_relu(z, name=None):\n",
    "\t\t\treturn tf.maximum(alpha * z, z, name=name)\n",
    "\t\treturn parametrized_leaky_relu\n",
    "\n",
    "params = {'n_hidden_layers': [5],\n",
    "\t'n_neurons' : [700],\n",
    "\t'optimizer_class' : [tf.train.AdagradOptimizer],\n",
    "\t'learning_rate' : [0.05],\n",
    "\t'batch_size' : [50],\n",
    "\t'activation' : [leaky_relu()],\n",
    "\t'dropout_rate' : [0.1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchDNN(params, k_fold=5)\n",
    "grid_search.fit(X_train_reshaped, y_train, X_valid_reshaped, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trining DNN with parameters: n_hidden_layers: 5, n_neurons: 1000, optimizer_class: <class 'tensorflow.python.training.adagrad.AdagradOptimizer'>, learning_rate: 0, batch_size: 50, activation: <function leaky_relu.<locals>.parametrized_leaky_relu at 0x000001F1E24536A8>, dropout_rate: 0, \n",
      "Training and testing fold 0\n",
      "ranges:\n",
      "1540 1925\n",
      "shapes:\n",
      "(1544, 960) (385, 960)\n",
      "(1544,) (385,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e853fba0b3fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\Github_Projects\\TCC\\TCC_app\\server_Universal_Tuner\\api\\learning_models\\dataset\\backup\\NN_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_valid, y_valid)\u001b[0m\n\u001b[0;32m    588\u001b[0m \t\t\t\t\t\t\t\t\t\t\tlearning_rate=learning_rate, activation=activation)\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m                                                                                 \u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m                                                                                 \u001b[0maccuracy_rate\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m                                                                                 \u001b[1;32mdel\u001b[0m \u001b[0mdnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'X_train'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
